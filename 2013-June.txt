From dwinsemius at comcast.net  Sat Jun  1 00:02:31 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 31 May 2013 15:02:31 -0700
Subject: [R] tree in tree package - Error: cannot allocate vector of
	size 2.0 Gb
In-Reply-To: <51A9185B.9090908@auburn.edu>
References: <51A9185B.9090908@auburn.edu>
Message-ID: <AF0E49FF-05DE-4C22-A7BB-E959F2301145@comcast.net>


On May 31, 2013, at 2:38 PM, Stephen Sefick wrote:

> R version 3.0.0 (2013-04-03)
> Platform: x86_64-redhat-linux-gnu (64-bit)
> 
> locale:
> [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
> [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
> [5] LC_MONETARY=en_US.utf8    LC_MESSAGES=en_US.utf8
> [7] LC_PAPER=C                LC_NAME=C
> [9] LC_ADDRESS=C              LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> 
> 6GB RAM, intel core2 quad, Scientific Linux 6.4
> 
> I am using tree in the tree package.  and I get the following error:
> 
> Error: cannot allocate vector of size 2.0 Gb
> 
> shouldn't I be able to allocate more memory than 2GB?

I believe that should be read as "unable to allocate contiguous block of memory for a new object of size 2Gb".

The general rule is that you should have at least 3 times the free (non-OS/non-other-running-applications) RAM as the size of your largest objects. You seem to be in violation of that rule. 

-- 

David Winsemius
Alameda, CA, USA


From Achim.Zeileis at uibk.ac.at  Sat Jun  1 00:29:40 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Sat, 1 Jun 2013 00:29:40 +0200 (CEST)
Subject: [R] glmx specification of heteroskedasticity (and its use in
 Heckit)
In-Reply-To: <CALs_GZXF_hD99sg9orVdFYhgHZ3w-EetgjsNchEhhofnyG9jfw@mail.gmail.com>
References: <CALs_GZUwgZgXnw_PBdjVW9W8_4=mQmhjGtMZV5uwoVbHuN53gw@mail.gmail.com>
	<alpine.DEB.2.02.1305311203090.30240@paninaro.uibk.ac.at>
	<CALs_GZXF_hD99sg9orVdFYhgHZ3w-EetgjsNchEhhofnyG9jfw@mail.gmail.com>
Message-ID: <alpine.DEB.2.02.1306010026260.3191@paninaro.uibk.ac.at>

On Fri, 31 May 2013, Michal Kvasni?ka wrote:

> Hallo.
>
> Many thanks for your answer. Let me check please that I do understand
> it correctly. Does it mean that the estimated log-likelyhood function
> is (in the Gaussian case)
>
>  sum y * log F(x'b / exp(z'g)) + sum (1 - y) * log(1 - F(x'b / exp(z'g))
>
> where F is standard normal CDF, and the rest is as in your mail?

Yes, this is the likelihood.

In a GLM context, one would call this the "Gaussian" case though. It's the 
binomial case with a probit link: family = binomial(link = "logit"). And 
this is equivalent to observing a binary variable from a latent Gaussian.

However, it would also be possible to set family = gaussian where the 
likelihood itself would be Gaussian (typically with an identity link).

Best,
Z

> Many thanks once more.
>
> Best wishes
> Michal
>
> P.S. Sorry if you get this mail twice -- I'm not yet certain with this
> mailing list to what mail address I should reply.
>
>
> 2013/5/31 Achim Zeileis <Achim.Zeileis at uibk.ac.at>:
>> On Fri, 31 May 2013, Michal Kvasni?ka wrote:
>>
>>> Hallo.
>>>
>>> First many thanks to its authors for glmx package and hetglm()
>>> function especially. It is absolutely great.
>>
>>
>> Glad it is useful for you!
>>
>>
>>> Now, let me ask my question: what model of heteroskedasticity hetglm()
>>> uses? Is the random part of the Gaussian probit model
>>>
>>>     norm(0,  sd = exp(X2*beta2))
>>>
>>> where norm is the Gaussian distribution, 0 is its zero mean, and sd is
>>> its standard deviation modelled as a linear model with explanatory
>>> variables X2 (a matrix) and some unknown parameters beta2?
>>
>>
>> In the hetglm model the response y is distributed with mean mu and from some
>> exponential family (default: binomial). And the following equation holds:
>>
>> mu = h( x'b / exp(z'g) )
>>
>> where h() is the inverse link function. Thus if h() is the normal
>> distribution function (inverse probit link), then
>>
>> mu = P(X > 0)
>>
>> where X is normally distributed with mean x'b and standard deviation
>> exp(z'g).
>>
>> Hope that helps,
>> Z
>>
>>> I'm asking because after estimating a heteroskedastic probit, I want
>>> to estimate a Heckit. I plan to use two-stage estimation procedure. In
>>> the first step I want to estimate the heteroskedastic probit, and in
>>> the second step the linear part (with bootstrapped confidence
>>> intervals of parameters). The linear part includes inverse Mill's
>>> ration lambda where
>>>
>>>    lambda = dnorm(X1*beta1, sd=?) / pnorm(X1*beta1, sd=?)
>>>
>>> where X1 are the explanatory variables of the probit model, and beta1
>>> are their parameters. (I hope I can tweak the homoskedastic model this
>>> way.) (I plan to use two-step estimation to avoid further distribution
>>> assumptions on the linear part of the model.)
>>>
>>> Many thanks for your answer to my question (and also for any comment
>>> on the overall estimation procedure).
>>>
>>> Best wishes,
>>> Michal
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>


From ehlers at ucalgary.ca  Sat Jun  1 00:50:04 2013
From: ehlers at ucalgary.ca (Peter Ehlers)
Date: Fri, 31 May 2013 15:50:04 -0700
Subject: [R] wilcox_test function in coin package
In-Reply-To: <CAFCoDdC1asW6JGK5huY_kLgCQQCduw8s=YjhHDP0ptA_9YAhhw@mail.gmail.com>
References: <CAFCoDdDp64MFyvTTB6b_O6KgoTKYR41mCB2sPCC4c6ANQyWx1Q@mail.gmail.com>
	<CAFEqCdy6+NhK2hgcWQALYmYXx1a0tRqJTHYBXx-FUb9OYfFUKA@mail.gmail.com>
	<CAFCoDdBcm4B1tVW7BarkHXAgpqMpTCimmjhrLc3N7=yvSSEbbw@mail.gmail.com>
	<CAFEqCdz_=YBeeDYLfpDYyTAwjr6a4n2OKTbQaBsb9UC=G9sAag@mail.gmail.com>
	<CAFCoDdC1asW6JGK5huY_kLgCQQCduw8s=YjhHDP0ptA_9YAhhw@mail.gmail.com>
Message-ID: <51A9291C.70509@ucalgary.ca>

On 2013-05-30 20:20, Janh Anni wrote:
> Hello Greg,
>
> Thank you so much for your kind assistance.  It looks like there's no way
> around using the formula format.  I longed in vain for a simpler script
> more like the wilcox.test format.  Thanks again.
>
> Janh

I don't see why the formula syntax would be a problem, but to avoid it
you could use exactRankTests::wilcox.exact() which, I believe, was
written by the same author. It uses the same syntax as wilcox.test(). 
Note, though, that the package is no longer
being developed.

Peter Ehlers

>
>
> On Thu, May 30, 2013 at 6:21 PM, Greg Snow <538280 at gmail.com> wrote:
>
>> Ok, it looks like the function mainly works through the formula syntax.
>>   It still would have been nice to have a reproducible example of what your
>> data may look like, but I can show an example with simulated x and y:
>>
>>> x <- rpois(10, 3)
>>> y <- rpois(11, 3.1)
>>> mydf <- data.frame( vals = c(x,y),
>> +   group=rep( c('x','y'), c( length(x), length(y) ) ) )
>>> wilcox_test( vals ~ group, data=mydf )
>>
>>          Asymptotic Wilcoxon-Mann-Whitney Test
>>
>> data:  vals by group (x, y)
>> Z = -1.3718, p-value = 0.1701
>> alternative hypothesis: true mu is not equal to 0
>>
>> Does that help?  (maybe I am the heedlessness theorist after all)
>>
>>
>>
>> On Thu, May 30, 2013 at 4:14 PM, Janh Anni <annijanh at gmail.com> wrote:
>>
>>> I thought (hoped) wilcox_test(x,y) would do it but it doesn't and the
>>> package maintainer says the data have to be rearranged but does not specify
>>> how.  Thanks
>>>
>>> Janh
>>>
>>>
>>>
>>> On Thu, May 30, 2013 at 6:05 PM, Greg Snow <538280 at gmail.com> wrote:
>>>
>>>> What have you tried so far?  Have you read the help page? have you run
>>>> the examples on that page?
>>>>
>>>> I would expect that it is something as simple as
>>>>
>>>> library(coin)
>>>> wilcox_test(x,y)
>>>>
>>>> or
>>>>
>>>> wilcox_test( y ~ group )
>>>>
>>>> But you should trust the help page more than the expectations of someone
>>>> who has not read it recently (see fortune(14)).
>>>>
>>>> If that does not answer your question then give us more detail on what
>>>> you tried, what you expected the results to be, what the results actually
>>>> were, and how they differed.  Without that information we have to resort to
>>>> mind reading and the current implementation of the esp package is still
>>>> very pre-alpha, it suggests that the answer to your question is:
>>>>
>>>>> esp()
>>>> [1] "selflessly vigilantly pigeon theorist heedlessness"
>>>>
>>>> Which is either much to profound for the likes of me to understand or is
>>>> complete gibberish (which is only slightly less helpful than an overly
>>>> general question without a reproducible example).
>>>>
>>>>
>>>> On Thu, May 30, 2013 at 2:07 PM, Janh Anni <annijanh at gmail.com> wrote:
>>>>
>>>>> Dear All,
>>>>>
>>>>> I have two simple data samples (no groups or factors, etc.) and would
>>>>> just
>>>>> like to compute the two-sample Wilcoxon Rank Sum test using the
>>>>> wilcox_test
>>>>> function contained in the coin package, which is reportedly better than
>>>>> the
>>>>> regular wilcox.test function because it performs some adjustment for
>>>>> ties.
>>>>> Would anyone know how to craft a script to perform this task?  Much
>>>>> appreciated.
>>>>>
>>>>> Janh
>>>>>
>>>>>          [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> Gregory (Greg) L. Snow Ph.D.
>>>> 538280 at gmail.com
>>>>
>>>
>>>
>>
>>
>> --
>> Gregory (Greg) L. Snow Ph.D.
>> 538280 at gmail.com
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Sat Jun  1 00:59:19 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 31 May 2013 15:59:19 -0700 (PDT)
Subject: [R] Replace row value with corresponding column name
Message-ID: <1370041159.95670.YahooMailNeo@web142605.mail.bf1.yahoo.com>

HI,
Try this:
data1 <- data.frame("var1"=c(1,2,3),"var2"=c("A","B","C"),"var3"=c(4,5,6)) #your example

data2 <- data.frame("var1"=c(1,2,3),"var2"=c("5","6","9"),"var3"=c(4,5,6)) #your example
data3<- data.frame(var1=c(5,6,5,5),var2=c(4,4,5,3),var3=c(1,4,3,5))
?data4<- data.frame(var1=c(1,2,3),var2=c(1,4,6))
fun1<- function(dat,value){

?cols<- colnames(dat)
indx1<- rowSums(dat==value)
?if(any(indx1>1)){
?lst<-apply(dat,1,function(x) cols[x==value])
?lst[lapply(lst,length)==0]<-NA
?dat$newvar<-lst
dat
?}
else{??? 
?indx2<- (dat==value)%*%seq_along(cols)
?indx2[indx2==0]<-NA
?dat$newvar<-cols[indx2]
?dat
}
?}

data1New<-fun1(data1,5)
?data1New
#? var1 var2 var3 newvar
#1??? 1??? A??? 4?? <NA>
#2??? 2??? B??? 5?? var3
#3??? 3??? C??? 6?? <NA>

data2New<-fun1(data2,5)
?data2New
#? var1 var2 var3 newvar
#1??? 1??? 5??? 4?? var2
#2??? 2??? 6??? 5?? var3
#3??? 3??? 9??? 6?? <NA>
data3New<- fun1(data3,5)
?data3New
#? var1 var2 var3???? newvar
#1??? 5??? 4??? 1?????? var1
#2??? 6??? 4??? 4???????? NA
#??? 5??? 5??? 3 var1, var2
#4??? 5??? 3??? 5 var1, var3

fun1(data4,5)
#? var1 var2 newvar
#1??? 1??? 1?? <NA>
#2??? 2??? 4?? <NA>
#3??? 3??? 6?? <NA>


A.K.






Dear R Community, 
I tried searching the archives for the question below, but couldn't find what I was looking for - please help! 

Suppose I ?have a data frame like the following: 
data <- 
data.frame("var1"=c(1,2,3),"var2"=c("A","B","C"),"var3"=c(4,5,6)) > 
data <- 
data.frame("var1"=c(1,2,3),"var2"=c("5","6","9"),"var"=c(4,5,6)) 
> data 
? var1 var2 var3 
1 ? ?1 ? ?5 ? 4 
2 ? ?2 ? ?6 ? 5 
3 ? ?3 ? ?9 ? 6 

I would like to create a new variable that identifies the column name where the value 5 appears. ?the results should look 
like below: 
? var1 var2 var3 newvar 
1 ? ?1 ? ?5 ? ?4 ? var2 
2 ? ?2 ? ?6 ? ?5 ? var3 
3 ? ?3 ? ?9 ? ?6 ? <NA>
Can anyone share code that shows the most efficient way to accomplish this? 
Any help is much appreciated. 
Thanks!


From rbaer at atsu.edu  Sat Jun  1 01:10:19 2013
From: rbaer at atsu.edu (Robert Baer)
Date: Fri, 31 May 2013 18:10:19 -0500
Subject: [R] how to install R 3.0.1
In-Reply-To: <20130531115905.45a51e3ae3e707c2f7e44073@inbox.com>
References: <caeezrqqu7qrafun52safdqah0ukj-am5w50udcwo+tso73jgvg@mail.gmail.com>
	<bd740eead3d.000002edjrkrideau@inbox.com>
	<BDC06134AA3.0000034Fjrkrideau@inbox.com>
	<20130531115905.45a51e3ae3e707c2f7e44073@inbox.com>
Message-ID: <51A92DDB.5040001@atsu.edu>

On 5/31/2013 11:59 AM, Ranjan Maitra wrote:
> Hi John,
>
> I suspect you may be missing a c()?
>
> On Fri, 31 May 2013 06:05:45 -0800 John Kane <jrkrideau at inbox.com>
> wrote:
>
>> paks  <-  install.packages( "Hmisc", "plyr")
> paks <- install.packages( c("Hmisc", "plyr"))
>
>     
>>    install.packages(paks)
>> You can use the command  library()  to get a list of what is installed on your machine.
> Is it possible to get this as a vector of only the package names, or
> is post-processing the output of library() the only way out?
Do you mean something like:
paks = library()$results[,1]
save(paks, file = 'paks.RData')
Rob

-- 

Robert W. Baer, Ph.D.
Professor of Physiology
Kirksille College of Osteopathic Medicine
A. T. Still University of Health Sciences
Kirksville, MO 63501 USA


From jfox at mcmaster.ca  Sat Jun  1 01:42:08 2013
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 31 May 2013 19:42:08 -0400
Subject: [R] measuring distances between colours?
In-Reply-To: <CAKFxdiSHPCgsVCaaJDfedX8b2ZAHbTdNNYktjHzUk=0XtG=ayA@mail.gmail.com>
References: <4382_1369916184_r4UCGK5j024861_web-459777071@cgpsrv2.cis.mcmaster.ca>	<004601ce5d7a$9f16fc00$dd44f400$@mcmaster.ca>	<20904.20143.918220.744897@stat.math.ethz.ch>
	<CAKFxdiSHPCgsVCaaJDfedX8b2ZAHbTdNNYktjHzUk=0XtG=ayA@mail.gmail.com>
Message-ID: <007001ce5e58$7776a400$6663ec00$@mcmaster.ca>

Dear Kevin,

I generally prefer your solution. I didn't realize that col2rgb() worked
with hex-colour input (as opposed to named colours), so my code converting
hex numbers to decimal is unnecessary; and using ifelse() is clearer than
replacing the non-matches.

I'm not so sure about avoiding the closure, since for converting small
numbers of colours, your function will spend most of its time constructing
the local function find.near() and building all.hsv. Here's an example,
using your rgb2col() and a comparable function employing a closure, with one
of your examples executed 100 times:

> r2c <- function(){
+     all.names <- colors()
+     all.hsv <- rgb2hsv(col2rgb(all.names))
+     find.near <- function(x.hsv) {
+         # return the nearest R color name and distance
+         sq.dist <- colSums((all.hsv - x.hsv)^2)
+         rbind(all.names[which.min(sq.dist)], min(sq.dist))
+     }
+     function(cols.hex, near=.25){
+         cols.hsv <- rgb2hsv(col2rgb(cols.hex))
+         cols.near <- apply(cols.hsv, 2, find.near)
+         ifelse(cols.near[2,] < near^2, cols.near[1,], cols.hex)
+     }
+ }
 
> mycols <- c("#010101", "#EEEEEE", "#AA0000", "#00AA00", "#0000AA",
+     "#AAAA00", "#AA00AA", "#00AAAA")
 
> system.time(for (i in 1:100) oldnew <- c(mycols, rgb2col(mycols,
near=.25)))
   user  system elapsed 
   1.97    0.00    1.97 

> system.time({rgb2col2 <- r2c() 
+     for (i in 1:100) oldnew2 <- c(mycols, rgb2col2(mycols, near=.25))
+     })
   user  system elapsed 
   0.08    0.00    0.08 

> rbind(oldnew, oldnew2)
        [,1]      [,2]      [,3]      [,4]      [,5]      [,6]     
oldnew  "#010101" "#EEEEEE" "#AA0000" "#00AA00" "#0000AA" "#AAAA00"
oldnew2 "#010101" "#EEEEEE" "#AA0000" "#00AA00" "#0000AA" "#AAAA00"
        [,7]      [,8]      [,9]      [,10]     [,11]     [,12]   
oldnew  "#AA00AA" "#00AAAA" "#010101" "#EEEEEE" "darkred" "green4"
oldnew2 "#AA00AA" "#00AAAA" "#010101" "#EEEEEE" "darkred" "green4"
        [,13]   [,14]           [,15]         [,16]  
oldnew  "blue4" "darkgoldenrod" "darkmagenta" "cyan4"
oldnew2 "blue4" "darkgoldenrod" "darkmagenta" "cyan4" 

Does this really make a difference? Frankly, it wouldn't for my application
(for colour selection in the Rcmdr) where a user is likely to perform at
most one or two conversions of a small number of colours in a session. The
time advantage of the second approach will depend upon the number of times
the function is invoked and the number of colours converted each time.

Best,
 John

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Kevin Wright
> Sent: Friday, May 31, 2013 3:39 PM
> To: Martin Maechler
> Cc: r-help; John Fox
> Subject: Re: [R] measuring distances between colours?
> 
> Thanks for the discussion.  I've also wanted to be able to find nearest
> colors.  I took the code and comments in this thread and simplified the
> function even further.  (Personally, I think using closures results in
> Rube-Goldberg code.  YMMV.)  The first example below is what I use for
> 'group' colors in lattice.
> 
> Kevin Wright
> 
> rgb2col <- function(cols.hex, near=.25){
>   # Given a vector of hex colors, find the nearest 'named' R colors
>   # If no color closer than 'near' is found, return the hex color
>   # Authors: John Fox, Martin Maechler, Kevin Wright
>   # From r-help discussion 5.30.13
> 
>   find.near <- function(x.hsv) {
>     # return the nearest R color name and distance
>     sq.dist <- colSums((all.hsv - x.hsv)^2)
>     rbind(all.names[which.min(sq.dist)], min(sq.dist))
>   }
>   all.names <- colors()
>   all.hsv <- rgb2hsv(col2rgb(all.names))
>   cols.hsv <- rgb2hsv(col2rgb(cols.hex))
>   cols.near <- apply(cols.hsv, 2, find.near)
>   ifelse(cols.near[2,] < near^2, cols.near[1,], cols.hex)
> }
> 
> mycols <- c("royalblue", "red", "#009900", "dark orange", "#999999",
> "#a6761d", "#aa00da")
> mycols <- c("#010101", "#EEEEEE", "#AA0000", "#00AA00", "#0000AA",
> "#AAAA00", "#AA00AA", "#00AAAA")
> mycols <- c("#010101", "#090909", "#090000", "#000900", "#000009",
> "#090900", "#090009", "#000909")
> oldnew <- c(mycols, rgb2col(mycols, near=.25)) # Also try near=10
> pie(rep(1,2*length(mycols)), labels=oldnew, col=oldnew)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From maitra.mbox.ignored at inbox.com  Sat Jun  1 02:02:40 2013
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Fri, 31 May 2013 19:02:40 -0500
Subject: [R] how to install R 3.0.1
In-Reply-To: <51A92DDB.5040001@atsu.edu>
References: <caeezrqqu7qrafun52safdqah0ukj-am5w50udcwo+tso73jgvg@mail.gmail.com>
	<bd740eead3d.000002edjrkrideau@inbox.com>
	<BDC06134AA3.0000034Fjrkrideau@inbox.com>
	<20130531115905.45a51e3ae3e707c2f7e44073@inbox.com>
	<51A92DDB.5040001@atsu.edu>
Message-ID: <20130531190240.f313694544bd9f91c5a54425@inbox.com>

On Fri, 31 May 2013 18:10:19 -0500 Robert Baer <rbaer at atsu.edu> wrote:

> On 5/31/2013 11:59 AM, Ranjan Maitra wrote:
> > Hi John,
> >
> > I suspect you may be missing a c()?
> >
> > On Fri, 31 May 2013 06:05:45 -0800 John Kane <jrkrideau at inbox.com>
> > wrote:
> >
> >> paks  <-  install.packages( "Hmisc", "plyr")
> > paks <- install.packages( c("Hmisc", "plyr"))
> >
> >     
> >>    install.packages(paks)
> >> You can use the command  library()  to get a list of what is installed on your machine.
> > Is it possible to get this as a vector of only the package names, or
> > is post-processing the output of library() the only way out?
> Do you mean something like:
> paks = library()$results[,1]
> save(paks, file = 'paks.RData')
> Rob

Exactly! Then

install.packages(library()$results[,1])

does all the updated installs in one shot.

Thanks!
Ranjan

____________________________________________________________
GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at http://www.inbox.com/smileys
Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk? and most webmails


From luysgarcia at gmail.com  Sat Jun  1 03:27:46 2013
From: luysgarcia at gmail.com (=?ISO-8859-1?Q?Luis_Fernando_Garc=EDa_Hern=E1ndez?=)
Date: Fri, 31 May 2013 22:27:46 -0300
Subject: [R] GLMM in R
Message-ID: <CANxP2S45qBx8H3Bf-CYt0UJZFEnGKUk3F5C=ouT=wOwSOyP9xg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130531/0d2b5ae7/attachment.pl>

From jholtman at gmail.com  Sat Jun  1 03:53:55 2013
From: jholtman at gmail.com (jim holtman)
Date: Fri, 31 May 2013 21:53:55 -0400
Subject: [R] R help on loops
In-Reply-To: <51A8E5C7.1010306@ufl.edu>
References: <51A8E5C7.1010306@ufl.edu>
Message-ID: <CAAxdm-6=KLifDLfD=ZTxn8Mu7c0nPpuKUAf6BN6_Uh_jQqURTQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130531/0deb58a6/attachment.pl>

From tiago.pereira at mbe.bio.br  Sat Jun  1 06:26:27 2013
From: tiago.pereira at mbe.bio.br (Tiago V. Pereira)
Date: Sat, 1 Jun 2013 01:26:27 -0300 (BRT)
Subject: [R] How to compute a P-value for a complex mixture of chi-squared
 distributions in R
Message-ID: <53978.201.81.178.2.1370060787.squirrel@webmail.mbe.bio.br>

Hello, R users!

I am struggling with the following problem:

I need to compute a P-value for a mixture of two chi-squared
distributions. My P-value is given by:

P = 0.5*prob(sqrt(chi2(1)) <= x) + 0.5*prob(sqrt(chi2(2)) <= x)

In words, I need to compute the p-value for 50?50 mixture of the square
root of a chi-squared random variable with 1 degree of freedom and the
square root of a chi-squared with two degrees of freedom.

Although I can quickly simulate data, the P-values I am looking for are at
the tail of the distribution, that is, alpha levels below 10^-7. Hence,
simulation is not efficient.

Are you aware of smart approach?


All the best,

Tiago


From tiago.pereira at mbe.bio.br  Sat Jun  1 06:32:22 2013
From: tiago.pereira at mbe.bio.br (Tiago V. Pereira)
Date: Sat, 1 Jun 2013 01:32:22 -0300 (BRT)
Subject: [R] How to compute a P-value for a complex mixture of chi-squared
 distributions in R
Message-ID: <54649.201.81.178.2.1370061142.squirrel@webmail.mbe.bio.br>

Hello, R users!

I am struggling with the following problem:

I need to compute a P-value for a mixture of two chi-squared
distributions. My P-value is given by:

P = 0.5*prob(sqrt(chi2(1)) <= x) + 0.5*prob(sqrt(chi2(2)) <= x)

In words, I need to compute the p-value for 50?50 mixture of the square
root of a chi-squared random variable with 1 degree of freedom and the
square root of a chi-squared with two degrees of freedom.

Although I can quickly simulate data, the P-values I am looking for are at
the tail of the distribution, that is, alpha levels below 10^-7. Hence,
simulation is not efficient.

Are you aware of smart approach?


All the best,

Tiago


From dlyzxl at yahoo.com  Sat Jun  1 02:56:49 2013
From: dlyzxl at yahoo.com (Justin)
Date: Fri, 31 May 2013 17:56:49 -0700 (PDT)
Subject: [R] R CMD check package "mypkg-Ex.R" failed
Message-ID: <1370048209.27541.YahooMailClassic@web120301.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130531/fdc6c43b/attachment.pl>

From annijanh at gmail.com  Sat Jun  1 04:27:17 2013
From: annijanh at gmail.com (Janh Anni)
Date: Fri, 31 May 2013 22:27:17 -0400
Subject: [R] wilcox_test function in coin package
In-Reply-To: <51A9291C.70509@ucalgary.ca>
References: <CAFCoDdDp64MFyvTTB6b_O6KgoTKYR41mCB2sPCC4c6ANQyWx1Q@mail.gmail.com>
	<CAFEqCdy6+NhK2hgcWQALYmYXx1a0tRqJTHYBXx-FUb9OYfFUKA@mail.gmail.com>
	<CAFCoDdBcm4B1tVW7BarkHXAgpqMpTCimmjhrLc3N7=yvSSEbbw@mail.gmail.com>
	<CAFEqCdz_=YBeeDYLfpDYyTAwjr6a4n2OKTbQaBsb9UC=G9sAag@mail.gmail.com>
	<CAFCoDdC1asW6JGK5huY_kLgCQQCduw8s=YjhHDP0ptA_9YAhhw@mail.gmail.com>
	<51A9291C.70509@ucalgary.ca>
Message-ID: <CAFCoDdAOHSKSTTD8o+gkdoMppuMW_XhX63zoh-eveBcnE1HVHQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130531/11a33d38/attachment.pl>

From gunter.berton at gene.com  Sat Jun  1 07:48:56 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 31 May 2013 22:48:56 -0700
Subject: [R] GLMM in R
In-Reply-To: <CANxP2S45qBx8H3Bf-CYt0UJZFEnGKUk3F5C=ouT=wOwSOyP9xg@mail.gmail.com>
References: <CANxP2S45qBx8H3Bf-CYt0UJZFEnGKUk3F5C=ouT=wOwSOyP9xg@mail.gmail.com>
Message-ID: <CACk-te2VPhbSYjCAoZnQVbEm4LoT1=9PUz4NJYhNhjLAGgXpeg@mail.gmail.com>

You should seek local statistical help. This list is not the right
place to seek what appears to be statistical consulting and, indeed,
basic statistical instruction.

-- Bert

On Fri, May 31, 2013 at 6:27 PM, Luis Fernando Garc?a Hern?ndez
<luysgarcia at gmail.com> wrote:
> Dear Friends,
>
> I am new on R so I ask you to excuse me if this question sounds fool. I
> want to see if there is a significativa relationship between the mating
> (response variable) and several explanatory variables such as individual
> number (categorical), leg movemente (continous) and the reuse of
> individuals (categorical). My data looks like this
>
> MatingIDReplicationShaking1M1R1100M1R2140M2R1150M2R2121M3R1140M3R2171M4R1190
> M4R2221M5R1180M5R2161M6R117
>
>
>
> 1 means mating happened, 0 means did not occur.
>
> I am trying to organize the data to apply a GLMM to the data, but have not
>  been able to do it.I followed the model proposed by CRawley for binary
> response with pseudorreplication but does not wok. The script goes like this
>
> model2<-lmer(Mating~Replication+(1 ID),family=binomial,method=?PQL?)
>
> Can somebody tell me what part is wrong and how could I fix it? If you know
> a better method, will be really welcomed!
>
> All the best!
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From bhh at xs4all.nl  Sat Jun  1 08:26:32 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 1 Jun 2013 08:26:32 +0200
Subject: [R] R CMD check package "mypkg-Ex.R" failed
In-Reply-To: <1370048209.27541.YahooMailClassic@web120301.mail.ne1.yahoo.com>
References: <1370048209.27541.YahooMailClassic@web120301.mail.ne1.yahoo.com>
Message-ID: <E3DE20A5-0742-49D3-83A0-F7A0FB704AEE@xs4all.nl>


On 01-06-2013, at 02:56, Justin <dlyzxl at yahoo.com> wrote:

> I build a test package in order to publish my own package to bioconductor.
> 
> I am using package.skeleton
> Step 1. create test package "mypkg"
>   f <- function(x,y) x+y
>   package.skeleton(list=c("f"), name="mypkg")
> 
> Step 2. build tar.gz file
> 
> {mars:/local/workspace01/zhangju/R_autopackage_Elbow}../bin/R CMD build mypkg
> * checking for file ?mypkg/DESCRIPTION? ... OK
> * preparing ?mypkg?:
> * checking DESCRIPTION meta-information ... OK
> * checking for LF line-endings in source and make files
> * checking for empty or unneeded directories
> * building ?mypkg_1.0.tar.gz?
> 
> Step 3. check compressed package file
> 
> {mars:/local/workspace01/zhangju/R_autopackage_Elbow}../bin/R CMD check mypkg_1.0.tar.gz 
> * using log directory ?/local/workspace01/zhangju/R_autopackage_Elbow/mypkg.Rcheck?
> *
> using R version 2.14.0 (2011-10-31)
> * using platform: x86_64-unknown-linux-gnu (64-bit)
> * using session charset: UTF-8
> * checking for file ?mypkg/DESCRIPTION? ... OK
> * checking extension type ... Package
> * this is package ?mypkg? version ?1.0?
> * checking package namespace information ... OK
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking if there is a namespace ... OK
> * checking for executable files ... OK
> * checking whether package ?mypkg? can be installed ... ERROR
> Installation failed.
> See ?/local/workspace01/zhangju/R_autopackage_Elbow/mypkg.Rcheck/00install.out? for details.
> 
> Step 4. check error 
> 
> {mars:/local/workspace01/zhangju/R_autopackage_Elbow}head mypkg.Rcheck/00install.out 
> * installing *source* package ?mypkg? ...
> ** R
> ** preparing package for lazy loading
> ** help
> Warning:
> 
> 
> /local/workspace01/zhangju/R_autopackage_Elbow/mypkg.Rcheck/00_pkg_src/mypkg/man/mypkg-package.Rd:33:
> All text must be in a section
> Warning: 
> /local/workspace01/zhangju/R_autopackage_Elbow/mypkg.Rcheck/00_pkg_src/mypkg/man/mypkg-package.Rd:34:
> All text must be in a section
> *** installing help indices
> Error in Rd_info(db[[i]]) : 
>   missing/empty \title field in '/local/workspace01/zhangju/R_autopackage_Elbow/mypkg.Rcheck/00_pkg_src/mypkg/man/f.Rd'
> Rd files must have a non-empty \title.
> 
> Step 5. add "test package" to the title of f.Rd
> Step 6. build again
> 
> {mars:/local/workspace01/zhangju/R_autopackage_Elbow}../bin/R CMD build mypkg
> * checking for file ?mypkg/DESCRIPTION? ... OK
> * preparing ?mypkg?:
> * checking DESCRIPTION meta-information ... OK
> * checking for LF line-endings in source and make files
> * checking for empty or unneeded directories
> * building ?mypkg_1.0.tar.gz?
> 
> Step 7.
> check compressed package again
> 
> {mars:/local/workspace01/zhangju/R_autopackage_Elbow}../bin/R CMD check mypkg_1.0.tar.gz 
> * using log directory ?/local/workspace01/zhangju/R_autopackage_Elbow/mypkg.Rcheck?
> * using R version 2.14.0 (2011-10-31)
> * using platform: x86_64-unknown-linux-gnu (64-bit)
> * using session charset: UTF-8
> * checking for file ?mypkg/DESCRIPTION? ... OK
> * checking extension type ... Package
> * this is package ?mypkg? version ?1.0?
> * checking package namespace information ... OK
> * checking package dependencies ... OK
> * checking if this is a source package ... OK
> * checking if there is a namespace ... OK
> * checking for executable files ... OK
> * checking whether package ?mypkg? can be installed ... WARNING
> Found the following significant warnings:
>   Warning: /local/workspace01/zhangju/R_autopackage_Elbow/mypkg.Rcheck/00_pkg_src/mypkg/man/mypkg-package.Rd:33: All
> text must be in a section
>   Warning: 
> /local/workspace01/zhangju/R_autopackage_Elbow/mypkg.Rcheck/00_pkg_src/mypkg/man/mypkg-package.Rd:34:
> All text must be in a section
> See ?/local/workspace01/zhangju/R_autopackage_Elbow/mypkg.Rcheck/00install.out? for details.
> * checking installed package size ... OK
> * checking package directory ... OK
> * checking for portable file names ... OK
> * checking for sufficient/correct file permissions ... OK
> * checking DESCRIPTION meta-information ... WARNING
> Non-standard license specification:
>   What license is it under?
> Standardizable: FALSE
> * checking top-level files ... OK
> * checking index information ... OK
> * checking package subdirectories ... OK
> * checking R files for non-ASCII characters ... OK
> * checking R files for syntax errors ... OK
> * checking whether the package can be loaded ... OK
> * checking whether the package can be loaded with stated
> dependencies ... OK
> * checking whether the package can be unloaded cleanly ... OK
> * checking whether the namespace can be loaded with stated dependencies ... OK
> * checking whether the namespace can be unloaded cleanly ... OK
> * checking for unstated dependencies in R code ... OK
> * checking S3 generic/method consistency ... OK
> * checking replacement functions ... OK
> * checking foreign function calls ... OK
> * checking R code for possible problems ... OK
> * checking Rd files ... WARNING
> prepare_Rd: f.Rd:7-9: Dropping empty section \description
> prepare_Rd: f.Rd:22-24: Dropping empty section \details
> prepare_Rd: f.Rd:25-31: Dropping empty section \value
> prepare_Rd: f.Rd:38-40: Dropping empty section \note
> prepare_Rd: f.Rd:35-37: Dropping empty section \author
> prepare_Rd: f.Rd:32-34: Dropping empty section \references
> prepare_Rd: f.Rd:44-46: Dropping empty section \seealso
> checkRd: (5) f.Rd:0-60: Must have a
> \description
> prepare_Rd: mypkg-package.Rd:33: All text must be in a section
> prepare_Rd: mypkg-package.Rd:34: All text must be in a section
> * checking Rd metadata ... OK
> * checking Rd cross-references ... WARNING
> Unknown package(s) ?<pkg>? in Rd xrefs
> * checking for missing documentation entries ... OK
> * checking for code/documentation mismatches ... OK
> * checking Rd \usage sections ... OK
> * checking Rd contents ... OK
> * checking for unstated dependencies in examples ... NOTE
> Warning: parse error in file ?mypkg-Ex.R?:
> 11: unexpected symbol
> 42: 
> 43: " ~~ simple examples
>               ^
> * checking examples ... ERROR
> Running examples in ?mypkg-Ex.R? failed
> The error most likely occurred in:
> 
>> ### Name: mypkg-package
>> ### Title: What the package does (short line) ~~ package title ~~
>> ### Aliases:
> mypkg-package mypkg
>> ### Keywords: package
>> 
>> ### ** Examples
>> 
>> ~~ simple examples of the most important functions ~~
> Error: unexpected symbol in "~~ simple examples"
> Execution halted
> 
> 
> My question: How to correct the above error?
> 

How about making a working example replacing " ~~ simple examples"?
Have you tried entering the text " ~~ simple examples" (without the quotes) in R and looked at the error message you get?

Berend


From totangjie at gmail.com  Sat Jun  1 09:54:01 2013
From: totangjie at gmail.com (Jie Tang)
Date: Sat, 1 Jun 2013 15:54:01 +0800
Subject: [R] How to read a file including strings and numbers.
Message-ID: <CAMUSh4pcdrp0PDDNXCX9zBLq+p_1gh49RU+8NPF74f6DPgh_Zg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130601/6818c722/attachment.pl>

From jszhao at yeah.net  Sat Jun  1 10:09:22 2013
From: jszhao at yeah.net (Jinsong Zhao)
Date: Sat, 01 Jun 2013 16:09:22 +0800
Subject: [R] How to read a file including strings and numbers.
In-Reply-To: <CAMUSh4pcdrp0PDDNXCX9zBLq+p_1gh49RU+8NPF74f6DPgh_Zg@mail.gmail.com>
References: <CAMUSh4pcdrp0PDDNXCX9zBLq+p_1gh49RU+8NPF74f6DPgh_Zg@mail.gmail.com>
Message-ID: <51A9AC32.4010800@yeah.net>

On 2013/6/1 15:54, Jie Tang wrote:
> hi R-users,
>    I have a file as shown below,and the first column is time information.
>
> "2012-08-07 00:00:00",4174830,5,8.1,34.5,9.5,32,14
> "2012-08-07 00:00:01",4174831,4.7,8.6,34.5,9.9,29,14
> "2012-08-07 00:00:02",4174832,4.7,8.6,34.5,9.9,29,14
> "2012-08-07 00:00:03",4174833,5,8.5,34.5,9.8,30,14
> "2012-08-07 00:00:04",4174834,5,8.5,34.5,9.8,30,14
> "2012-08-07 00:00:05",4174835,5.4,8.3,34.6,9.9,33,14
> "2012-08-07 00:00:06",4174836,5.4,8.3,34.6,9.9,33,14
> "2012-08-07 00:00:07",4174837,5.1,7.8,34.5,9.3,33,14
> "2012-08-07 00:00:08",4174838,5.1,7.8,34.5,9.3,33,14
> "2012-08-07 00:00:09",4174839,5.3,7.8,34.5,9.4,34,14
> "2012-08-07 00:00:10",4174840,5.3,7.8,34.5,9.4,34,14
> "2012-08-07 00:00:11",4174841,5.4,8.3,34.5,9.9,33,14
> "2012-08-07 00:00:12",4174842,5.4,8.3,34.5,9.9,33,14
> "2012-08-07 00:00:13",4174843,5.6,8.3,34.5,10,34,14
> "2012-08-07 00:00:14",4174844,5.6,8.3,34.5,10,34,14
> "2012-08-07 00:00:15",4174845,5.5,8.1,34.5,9.8,34,14
> "2012-08-07 00:00:16",4174846,5.5,8.1,34.5,9.8,34,14
> "2012-08-07 00:00:17",4174847,4.3,7.4,34.4,8.6,30,14
>
> I want to read them into a array by such command
>
> wnd_data<-scan("obs.dat",sep=",",what=list(TIME="",rec=0,U=0,V=0,T=0,WS=0,WD=0,ST=0,TA=0,RH=0),na.strings
> = "NAN")

wnd_data <- read.table("obs.dat", header = FALSE, sep = ",")
colnames(wnd_data) <- c("TIME","rec","U","V","T","WS","WD","ST","TA","RH")

HIH...
>
> but R could not excute sucefully and says that :
> error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,
>   :
>    scan() require 'a real', but not "2012-08-0700:00:01"'
>
> How could I resolve this problem ?
> Thanks.
>


From ruipbarradas at sapo.pt  Sat Jun  1 11:43:00 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 01 Jun 2013 10:43:00 +0100
Subject: [R] How to read a file including strings and numbers.
In-Reply-To: <CAMUSh4pcdrp0PDDNXCX9zBLq+p_1gh49RU+8NPF74f6DPgh_Zg@mail.gmail.com>
References: <CAMUSh4pcdrp0PDDNXCX9zBLq+p_1gh49RU+8NPF74f6DPgh_Zg@mail.gmail.com>
Message-ID: <51A9C224.3010200@sapo.pt>

Hello,

Just use ?read.csv with argument header = FALSE.


wnd_data <- read.csv(text = '
"2012-08-07 00:00:00",4174830,5,8.1,34.5,9.5,32,14
"2012-08-07 00:00:01",4174831,4.7,8.6,34.5,9.9,29,14
"2012-08-07 00:00:02",4174832,4.7,8.6,34.5,9.9,29,14
"2012-08-07 00:00:03",4174833,5,8.5,34.5,9.8,30,14
"2012-08-07 00:00:04",4174834,5,8.5,34.5,9.8,30,14
"2012-08-07 00:00:05",4174835,5.4,8.3,34.6,9.9,33,14
"2012-08-07 00:00:06",4174836,5.4,8.3,34.6,9.9,33,14
"2012-08-07 00:00:07",4174837,5.1,7.8,34.5,9.3,33,14
"2012-08-07 00:00:08",4174838,5.1,7.8,34.5,9.3,33,14
"2012-08-07 00:00:09",4174839,5.3,7.8,34.5,9.4,34,14
"2012-08-07 00:00:10",4174840,5.3,7.8,34.5,9.4,34,14
"2012-08-07 00:00:11",4174841,5.4,8.3,34.5,9.9,33,14
"2012-08-07 00:00:12",4174842,5.4,8.3,34.5,9.9,33,14
"2012-08-07 00:00:13",4174843,5.6,8.3,34.5,10,34,14
"2012-08-07 00:00:14",4174844,5.6,8.3,34.5,10,34,14
"2012-08-07 00:00:15",4174845,5.5,8.1,34.5,9.8,34,14
"2012-08-07 00:00:16",4174846,5.5,8.1,34.5,9.8,34,14
"2012-08-07 00:00:17",4174847,4.3,7.4,34.4,8.6,30,14
', header = FALSE)

str(wnd_data)


Note also that your vector of column names is of length 10 and there are 
only 8 columns.

Hope this helps,

Rui Barradas

Em 01-06-2013 08:54, Jie Tang escreveu:
> hi R-users,
>    I have a file as shown below,and the first column is time information.
>
> "2012-08-07 00:00:00",4174830,5,8.1,34.5,9.5,32,14
> "2012-08-07 00:00:01",4174831,4.7,8.6,34.5,9.9,29,14
> "2012-08-07 00:00:02",4174832,4.7,8.6,34.5,9.9,29,14
> "2012-08-07 00:00:03",4174833,5,8.5,34.5,9.8,30,14
> "2012-08-07 00:00:04",4174834,5,8.5,34.5,9.8,30,14
> "2012-08-07 00:00:05",4174835,5.4,8.3,34.6,9.9,33,14
> "2012-08-07 00:00:06",4174836,5.4,8.3,34.6,9.9,33,14
> "2012-08-07 00:00:07",4174837,5.1,7.8,34.5,9.3,33,14
> "2012-08-07 00:00:08",4174838,5.1,7.8,34.5,9.3,33,14
> "2012-08-07 00:00:09",4174839,5.3,7.8,34.5,9.4,34,14
> "2012-08-07 00:00:10",4174840,5.3,7.8,34.5,9.4,34,14
> "2012-08-07 00:00:11",4174841,5.4,8.3,34.5,9.9,33,14
> "2012-08-07 00:00:12",4174842,5.4,8.3,34.5,9.9,33,14
> "2012-08-07 00:00:13",4174843,5.6,8.3,34.5,10,34,14
> "2012-08-07 00:00:14",4174844,5.6,8.3,34.5,10,34,14
> "2012-08-07 00:00:15",4174845,5.5,8.1,34.5,9.8,34,14
> "2012-08-07 00:00:16",4174846,5.5,8.1,34.5,9.8,34,14
> "2012-08-07 00:00:17",4174847,4.3,7.4,34.4,8.6,30,14
>
> I want to read them into a array by such command
>
> wnd_data<-scan("obs.dat",sep=",",what=list(TIME="",rec=0,U=0,V=0,T=0,WS=0,WD=0,ST=0,TA=0,RH=0),na.strings
> = "NAN")
>
> but R could not excute sucefully and says that :
> error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,
>   :
>    scan() require 'a real', but not "2012-08-0700:00:01"'
>
> How could I resolve this problem ?
> Thanks.
>


From nalimilan at club.fr  Sat Jun  1 11:54:48 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Sat, 01 Jun 2013 11:54:48 +0200
Subject: [R] GLMM in R
In-Reply-To: <CANxP2S45qBx8H3Bf-CYt0UJZFEnGKUk3F5C=ouT=wOwSOyP9xg@mail.gmail.com>
References: <CANxP2S45qBx8H3Bf-CYt0UJZFEnGKUk3F5C=ouT=wOwSOyP9xg@mail.gmail.com>
Message-ID: <1370080488.6693.10.camel@milan>

Le vendredi 31 mai 2013 ? 22:27 -0300, Luis Fernando Garc?a Hern?ndez a
?crit :
> Dear Friends,
> 
> I am new on R so I ask you to excuse me if this question sounds fool. I
> want to see if there is a significativa relationship between the mating
> (response variable) and several explanatory variables such as individual
> number (categorical), leg movemente (continous) and the reuse of
> individuals (categorical). My data looks like this
> 
> MatingIDReplicationShaking1M1R1100M1R2140M2R1150M2R2121M3R1140M3R2171M4R1190
> M4R2221M5R1180M5R2161M6R117
> 
> 
> 
> 1 means mating happened, 0 means did not occur.
> 
> I am trying to organize the data to apply a GLMM to the data, but have not
>  been able to do it.I followed the model proposed by CRawley for binary
> response with pseudorreplication but does not wok. The script goes like this
> 
> model2<-lmer(Mating~Replication+(1 ID),family=binomial,method=PQL)
> 
> Can somebody tell me what part is wrong and how could I fix it? If you know
> a better method, will be really welcomed!
You do not tell us what you mean by "wrong", but at least in the form
above it will not work. Try with (1|ID), and use "REML" and "nAGQ"
arguments instead of the deprecated "method".


Regards

> All the best!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Sat Jun  1 12:13:28 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 01 Jun 2013 11:13:28 +0100
Subject: [R] How to compute a P-value for a complex mixture of
 chi-squared distributions in R
In-Reply-To: <53978.201.81.178.2.1370060787.squirrel@webmail.mbe.bio.br>
References: <53978.201.81.178.2.1370060787.squirrel@webmail.mbe.bio.br>
Message-ID: <51A9C948.8010306@sapo.pt>

Hello,

Try the following.


dmix <- function(x){
	dens <- function(x, df) dchisq(x^2, df = df)*2*x
	0.5*dens(x, df = 1) + 0.5*dens(x, df = 2)
}
pmix <- function(x, lower.tail = TRUE){
	p <- integrate(dmix, lower = 0, upper = x)
	if(lower.tail) p$value else 1 - p$value
}

quant <- 1
pmix(quant, lower.tail = FALSE)


Hope this helps,

Rui Barradas

Em 01-06-2013 05:26, Tiago V. Pereira escreveu:
> Hello, R users!
>
> I am struggling with the following problem:
>
> I need to compute a P-value for a mixture of two chi-squared
> distributions. My P-value is given by:
>
> P = 0.5*prob(sqrt(chi2(1)) <= x) + 0.5*prob(sqrt(chi2(2)) <= x)
>
> In words, I need to compute the p-value for 50?50 mixture of the square
> root of a chi-squared random variable with 1 degree of freedom and the
> square root of a chi-squared with two degrees of freedom.
>
> Although I can quickly simulate data, the P-values I am looking for are at
> the tail of the distribution, that is, alpha levels below 10^-7. Hence,
> simulation is not efficient.
>
> Are you aware of smart approach?
>
>
> All the best,
>
> Tiago
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jeremy.ng.wk1990 at gmail.com  Sat Jun  1 12:18:17 2013
From: jeremy.ng.wk1990 at gmail.com (Jeremy Ng)
Date: Sat, 1 Jun 2013 18:18:17 +0800
Subject: [R] Loading an .RData file and assigning the loaded objects within
	a loop
Message-ID: <CAL93JYthgwUzpAjz_uXXVxKYywGdGXZRTqPyw3sAVogLXD99hQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130601/38d8710a/attachment.pl>

From ruipbarradas at sapo.pt  Sat Jun  1 12:46:54 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 01 Jun 2013 11:46:54 +0100
Subject: [R] How to compute a P-value for a complex mixture of
 chi-squared distributions in R
In-Reply-To: <51A9C948.8010306@sapo.pt>
References: <53978.201.81.178.2.1370060787.squirrel@webmail.mbe.bio.br>
	<51A9C948.8010306@sapo.pt>
Message-ID: <51A9D11E.5040000@sapo.pt>

Hello,

Or, if you want to pass a vector of quantiles to pmix,



pmix <- function(x, lower.tail = TRUE){
	p <- sapply(x, function(.x) integrate(dmix, lower = 0, upper = .x)$value)
	if(lower.tail) p else 1 - p
}


Rui Barradas

Em 01-06-2013 11:13, Rui Barradas escreveu:
> Hello,
>
> Try the following.
>
>
> dmix <- function(x){
>      dens <- function(x, df) dchisq(x^2, df = df)*2*x
>      0.5*dens(x, df = 1) + 0.5*dens(x, df = 2)
> }
> pmix <- function(x, lower.tail = TRUE){
>      p <- integrate(dmix, lower = 0, upper = x)
>      if(lower.tail) p$value else 1 - p$value
> }
>
> quant <- 1
> pmix(quant, lower.tail = FALSE)
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 01-06-2013 05:26, Tiago V. Pereira escreveu:
>> Hello, R users!
>>
>> I am struggling with the following problem:
>>
>> I need to compute a P-value for a mixture of two chi-squared
>> distributions. My P-value is given by:
>>
>> P = 0.5*prob(sqrt(chi2(1)) <= x) + 0.5*prob(sqrt(chi2(2)) <= x)
>>
>> In words, I need to compute the p-value for 50?50 mixture of the square
>> root of a chi-squared random variable with 1 degree of freedom and the
>> square root of a chi-squared with two degrees of freedom.
>>
>> Although I can quickly simulate data, the P-values I am looking for
>> are at
>> the tail of the distribution, that is, alpha levels below 10^-7. Hence,
>> simulation is not efficient.
>>
>> Are you aware of smart approach?
>>
>>
>> All the best,
>>
>> Tiago
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Sat Jun  1 12:52:03 2013
From: jholtman at gmail.com (Jim Holtman)
Date: Sat, 1 Jun 2013 06:52:03 -0400
Subject: [R] Loading an .RData file and assigning the loaded objects
	within a loop
In-Reply-To: <CAL93JYthgwUzpAjz_uXXVxKYywGdGXZRTqPyw3sAVogLXD99hQ@mail.gmail.com>
References: <CAL93JYthgwUzpAjz_uXXVxKYywGdGXZRTqPyw3sAVogLXD99hQ@mail.gmail.com>
Message-ID: <2B538D36-6D48-469D-8E54-848387F0518A@gmail.com>

use 'lapply' to read in the .RData file.  Therefore each file is stored as an element of a list thatb
 you can access and change as necessary.

Sent from my iPad

On Jun 1, 2013, at 6:18, Jeremy Ng <jeremy.ng.wk1990 at gmail.com> wrote:

> Hi all,
> 
> I tried to look this up online, but am still feeling a little stuck.
> 
> I have a bunch of Rdata files in side my directory, and I would like to
> load all of them in a loop. Each time the next is read in, it would
> over-write the previously read in object because they will be assigned the
> same workspace object name.
> 
> Is there anyway for each individually read in Rdata object to be assigned a
> new name?
> 
> Thanks!
> JEremy
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nilsson.henric at gmail.com  Sat Jun  1 13:02:22 2013
From: nilsson.henric at gmail.com (Henric Winell)
Date: Sat, 01 Jun 2013 13:02:22 +0200
Subject: [R] order panels in xyplot by increasing slope
In-Reply-To: <519E9390.9010008@bitwrit.com.au>
References: <47B608FEE918A14D8F904244DA87192E1C6537F0@WPVEXCMBX06.purdue.lcl>
	<519E9390.9010008@bitwrit.com.au>
Message-ID: <51A9D4BE.2070001@gmail.com>

Ethan,

Jim Lemon skrev 2013-05-24 00:09:
> On 05/24/2013 06:21 AM, Belair, Ethan D wrote:
>> example.plot = xyplot(ht ~ time|tree, data=data,
>>                  type = c("r", "g", "p"),
>>                  par.settings=simpleTheme(col="blue"),
>>               main="abc",
>>               )
>> example.plot
>  > ...

If you read '?xyplot' carefully, you'll note that 'index.cond' is 
allowed to be a function.  So I'd just use

update(example.plot, index.cond = function(x, y) coef(lm(y ~ x))[2])

to get the panels ordered by slope.


HTH,
Henric



>
> Hi Ethan,
> This may be what you want:
>
> panel.slope<-function(panel) {
>   return(diff(range(panel$y,na.rm=TRUE))/
>    diff(range(panel$x,na.rm=TRUE)))
> }
> panel.order<-
>   order(unlist(lapply(example.plot$panel.args,panel.slope)))
>
> Jim
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Sat Jun  1 14:58:22 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 1 Jun 2013 14:58:22 +0200
Subject: [R] how to install R 3.0.1
In-Reply-To: <20130531190240.f313694544bd9f91c5a54425@inbox.com>
References: <caeezrqqu7qrafun52safdqah0ukj-am5w50udcwo+tso73jgvg@mail.gmail.com>
	<bd740eead3d.000002edjrkrideau@inbox.com>
	<BDC06134AA3.0000034Fjrkrideau@inbox.com>
	<20130531115905.45a51e3ae3e707c2f7e44073@inbox.com>
	<51A92DDB.5040001@atsu.edu>
	<20130531190240.f313694544bd9f91c5a54425@inbox.com>
Message-ID: <51A9EFEE.8090406@statistik.tu-dortmund.de>



On 01.06.2013 02:02, Ranjan Maitra wrote:
> On Fri, 31 May 2013 18:10:19 -0500 Robert Baer <rbaer at atsu.edu> wrote:
>
>> On 5/31/2013 11:59 AM, Ranjan Maitra wrote:
>>> Hi John,
>>>
>>> I suspect you may be missing a c()?
>>>
>>> On Fri, 31 May 2013 06:05:45 -0800 John Kane <jrkrideau at inbox.com>
>>> wrote:
>>>
>>>> paks  <-  install.packages( "Hmisc", "plyr")
>>> paks <- install.packages( c("Hmisc", "plyr"))
>>>
>>>
>>>>     install.packages(paks)
>>>> You can use the command  library()  to get a list of what is installed on your machine.
>>> Is it possible to get this as a vector of only the package names, or
>>> is post-processing the output of library() the only way out?
>> Do you mean something like:
>> paks = library()$results[,1]
>> save(paks, file = 'paks.RData')
>> Rob
>
> Exactly! Then
>
> install.packages(library()$results[,1])
>
> does all the updated installs in one shot.


Why do you want to reinstall all packages?

I'd go for
udpate.packages(checkBuilt=TRUE)
if a reinstallation after an update of R is what you are aiming at.

Best,
Uwe Ligges



> Thanks!
> Ranjan
>
> ____________________________________________________________
> GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at http://www.inbox.com/smileys
> Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk? and most webmails
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Sat Jun  1 14:59:22 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 1 Jun 2013 14:59:22 +0200
Subject: [R] how to install R 3.0.1
In-Reply-To: <51A9EFEE.8090406@statistik.tu-dortmund.de>
References: <caeezrqqu7qrafun52safdqah0ukj-am5w50udcwo+tso73jgvg@mail.gmail.com>
	<bd740eead3d.000002edjrkrideau@inbox.com>
	<BDC06134AA3.0000034Fjrkrideau@inbox.com>
	<20130531115905.45a51e3ae3e707c2f7e44073@inbox.com>
	<51A92DDB.5040001@atsu.edu>
	<20130531190240.f313694544bd9f91c5a54425@inbox.com>
	<51A9EFEE.8090406@statistik.tu-dortmund.de>
Message-ID: <51A9F02A.2000503@statistik.tu-dortmund.de>



On 01.06.2013 14:58, Uwe Ligges wrote:
>
>
> On 01.06.2013 02:02, Ranjan Maitra wrote:
>> On Fri, 31 May 2013 18:10:19 -0500 Robert Baer <rbaer at atsu.edu> wrote:
>>
>>> On 5/31/2013 11:59 AM, Ranjan Maitra wrote:
>>>> Hi John,
>>>>
>>>> I suspect you may be missing a c()?
>>>>
>>>> On Fri, 31 May 2013 06:05:45 -0800 John Kane <jrkrideau at inbox.com>
>>>> wrote:
>>>>
>>>>> paks  <-  install.packages( "Hmisc", "plyr")
>>>> paks <- install.packages( c("Hmisc", "plyr"))
>>>>
>>>>
>>>>>     install.packages(paks)
>>>>> You can use the command  library()  to get a list of what is
>>>>> installed on your machine.
>>>> Is it possible to get this as a vector of only the package names, or
>>>> is post-processing the output of library() the only way out?
>>> Do you mean something like:
>>> paks = library()$results[,1]
>>> save(paks, file = 'paks.RData')
>>> Rob
>>
>> Exactly! Then
>>
>> install.packages(library()$results[,1])
>>
>> does all the updated installs in one shot.
>
>
> Why do you want to reinstall all packages?
>
> I'd go for
> udpate.packages(checkBuilt=TRUE)
> if a reinstallation after an update of R is what you are aiming at.


.... and forgot to add: installed.packages() is certainly more 
appropriate than library() to find the names of installed packages (with 
less overhead and hence faster).

Best,
Uwe Ligges

> Best,
> Uwe Ligges
>
>
>
>> Thanks!
>> Ranjan
>>
>> ____________________________________________________________
>> GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at
>> http://www.inbox.com/smileys
>> Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk?
>> and most webmails
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From ligges at statistik.tu-dortmund.de  Sat Jun  1 15:01:13 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 01 Jun 2013 15:01:13 +0200
Subject: [R] R CMD check package "mypkg-Ex.R" failed
In-Reply-To: <E3DE20A5-0742-49D3-83A0-F7A0FB704AEE@xs4all.nl>
References: <1370048209.27541.YahooMailClassic@web120301.mail.ne1.yahoo.com>
	<E3DE20A5-0742-49D3-83A0-F7A0FB704AEE@xs4all.nl>
Message-ID: <51A9F099.4010104@statistik.tu-dortmund.de>



On 01.06.2013 08:26, Berend Hasselman wrote:
>
> On 01-06-2013, at 02:56, Justin <dlyzxl at yahoo.com> wrote:
>
>> I build a test package in order to publish my own package to bioconductor.
>>
>> I am using package.skeleton
>> Step 1. create test package "mypkg"
>>    f <- function(x,y) x+y
>>    package.skeleton(list=c("f"), name="mypkg")
>>
>> Step 2. build tar.gz file
>>
>> {mars:/local/workspace01/zhangju/R_autopackage_Elbow}../bin/R CMD build mypkg
>> * checking for file ?mypkg/DESCRIPTION? ... OK
>> * preparing ?mypkg?:
>> * checking DESCRIPTION meta-information ... OK
>> * checking for LF line-endings in source and make files
>> * checking for empty or unneeded directories
>> * building ?mypkg_1.0.tar.gz?
>>
>> Step 3. check compressed package file
>>
>> {mars:/local/workspace01/zhangju/R_autopackage_Elbow}../bin/R CMD check mypkg_1.0.tar.gz
>> * using log directory ?/local/workspace01/zhangju/R_autopackage_Elbow/mypkg.Rcheck?
>> *
>> using R version 2.14.0 (2011-10-31)
>> * using platform: x86_64-unknown-linux-gnu (64-bit)
>> * using session charset: UTF-8
>> * checking for file ?mypkg/DESCRIPTION? ... OK
>> * checking extension type ... Package
>> * this is package ?mypkg? version ?1.0?
>> * checking package namespace information ... OK
>> * checking package dependencies ... OK
>> * checking if this is a source package ... OK
>> * checking if there is a namespace ... OK
>> * checking for executable files ... OK
>> * checking whether package ?mypkg? can be installed ... ERROR
>> Installation failed.
>> See ?/local/workspace01/zhangju/R_autopackage_Elbow/mypkg.Rcheck/00install.out? for details.
>>
>> Step 4. check error
>>
>> {mars:/local/workspace01/zhangju/R_autopackage_Elbow}head mypkg.Rcheck/00install.out
>> * installing *source* package ?mypkg? ...
>> ** R
>> ** preparing package for lazy loading
>> ** help
>> Warning:
>>
>>
>> /local/workspace01/zhangju/R_autopackage_Elbow/mypkg.Rcheck/00_pkg_src/mypkg/man/mypkg-package.Rd:33:
>> All text must be in a section
>> Warning:
>> /local/workspace01/zhangju/R_autopackage_Elbow/mypkg.Rcheck/00_pkg_src/mypkg/man/mypkg-package.Rd:34:
>> All text must be in a section
>> *** installing help indices
>> Error in Rd_info(db[[i]]) :
>>    missing/empty \title field in '/local/workspace01/zhangju/R_autopackage_Elbow/mypkg.Rcheck/00_pkg_src/mypkg/man/f.Rd'
>> Rd files must have a non-empty \title.
>>
>> Step 5. add "test package" to the title of f.Rd
>> Step 6. build again
>>
>> {mars:/local/workspace01/zhangju/R_autopackage_Elbow}../bin/R CMD build mypkg
>> * checking for file ?mypkg/DESCRIPTION? ... OK
>> * preparing ?mypkg?:
>> * checking DESCRIPTION meta-information ... OK
>> * checking for LF line-endings in source and make files
>> * checking for empty or unneeded directories
>> * building ?mypkg_1.0.tar.gz?
>>
>> Step 7.
>> check compressed package again
>>
>> {mars:/local/workspace01/zhangju/R_autopackage_Elbow}../bin/R CMD check mypkg_1.0.tar.gz
>> * using log directory ?/local/workspace01/zhangju/R_autopackage_Elbow/mypkg.Rcheck?
>> * using R version 2.14.0 (2011-10-31)
>> * using platform: x86_64-unknown-linux-gnu (64-bit)
>> * using session charset: UTF-8
>> * checking for file ?mypkg/DESCRIPTION? ... OK
>> * checking extension type ... Package
>> * this is package ?mypkg? version ?1.0?
>> * checking package namespace information ... OK
>> * checking package dependencies ... OK
>> * checking if this is a source package ... OK
>> * checking if there is a namespace ... OK
>> * checking for executable files ... OK
>> * checking whether package ?mypkg? can be installed ... WARNING
>> Found the following significant warnings:
>>    Warning: /local/workspace01/zhangju/R_autopackage_Elbow/mypkg.Rcheck/00_pkg_src/mypkg/man/mypkg-package.Rd:33: All
>> text must be in a section
>>    Warning:
>> /local/workspace01/zhangju/R_autopackage_Elbow/mypkg.Rcheck/00_pkg_src/mypkg/man/mypkg-package.Rd:34:
>> All text must be in a section
>> See ?/local/workspace01/zhangju/R_autopackage_Elbow/mypkg.Rcheck/00install.out? for details.
>> * checking installed package size ... OK
>> * checking package directory ... OK
>> * checking for portable file names ... OK
>> * checking for sufficient/correct file permissions ... OK
>> * checking DESCRIPTION meta-information ... WARNING
>> Non-standard license specification:
>>    What license is it under?
>> Standardizable: FALSE
>> * checking top-level files ... OK
>> * checking index information ... OK
>> * checking package subdirectories ... OK
>> * checking R files for non-ASCII characters ... OK
>> * checking R files for syntax errors ... OK
>> * checking whether the package can be loaded ... OK
>> * checking whether the package can be loaded with stated
>> dependencies ... OK
>> * checking whether the package can be unloaded cleanly ... OK
>> * checking whether the namespace can be loaded with stated dependencies ... OK
>> * checking whether the namespace can be unloaded cleanly ... OK
>> * checking for unstated dependencies in R code ... OK
>> * checking S3 generic/method consistency ... OK
>> * checking replacement functions ... OK
>> * checking foreign function calls ... OK
>> * checking R code for possible problems ... OK
>> * checking Rd files ... WARNING
>> prepare_Rd: f.Rd:7-9: Dropping empty section \description
>> prepare_Rd: f.Rd:22-24: Dropping empty section \details
>> prepare_Rd: f.Rd:25-31: Dropping empty section \value
>> prepare_Rd: f.Rd:38-40: Dropping empty section \note
>> prepare_Rd: f.Rd:35-37: Dropping empty section \author
>> prepare_Rd: f.Rd:32-34: Dropping empty section \references
>> prepare_Rd: f.Rd:44-46: Dropping empty section \seealso
>> checkRd: (5) f.Rd:0-60: Must have a
>> \description
>> prepare_Rd: mypkg-package.Rd:33: All text must be in a section
>> prepare_Rd: mypkg-package.Rd:34: All text must be in a section
>> * checking Rd metadata ... OK
>> * checking Rd cross-references ... WARNING
>> Unknown package(s) ?<pkg>? in Rd xrefs
>> * checking for missing documentation entries ... OK
>> * checking for code/documentation mismatches ... OK
>> * checking Rd \usage sections ... OK
>> * checking Rd contents ... OK
>> * checking for unstated dependencies in examples ... NOTE
>> Warning: parse error in file ?mypkg-Ex.R?:
>> 11: unexpected symbol
>> 42:
>> 43: " ~~ simple examples
>>                ^
>> * checking examples ... ERROR
>> Running examples in ?mypkg-Ex.R? failed
>> The error most likely occurred in:
>>
>>> ### Name: mypkg-package
>>> ### Title: What the package does (short line) ~~ package title ~~
>>> ### Aliases:
>> mypkg-package mypkg
>>> ### Keywords: package
>>>
>>> ### ** Examples
>>>
>>> ~~ simple examples of the most important functions ~~
>> Error: unexpected symbol in "~~ simple examples"
>> Execution halted
>>
>>
>> My question: How to correct the above error?
>>
>
> How about making a working example replacing " ~~ simple examples"?
> Have you tried entering the text " ~~ simple examples" (without the quotes) in R and looked at the error message you get?


Right, The Rd files generated from package.skeleton do not work right 
away, you need to remove those comments and fill it content.
This is by design and on prupose to force package developers to work on 
the documentation.

Best,
Uwe Ligges

> Berend
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jrkrideau at inbox.com  Sat Jun  1 15:21:06 2013
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 1 Jun 2013 05:21:06 -0800
Subject: [R] how to install R 3.0.1
In-Reply-To: <51A9F02A.2000503@statistik.tu-dortmund.de>
References: <51a9efee.8090406@statistik.tu-dortmund.de>
	<bdc06134aa3.0000034fjrkrideau@inbox.com>
	<caeezrqqu7qrafun52safdqah0ukj-am5w50udcwo+tso73jgvg@mail.gmail.com>
	<20130531115905.45a51e3ae3e707c2f7e44073@inbox.com>
	<51a92ddb.5040001@atsu.edu> <bd740eead3d.000002edjrkrideau@inbox.com>
	<20130531190240.f313694544bd9f91c5a54425@inbox.com>
Message-ID: <C9EF3CCCCBF.00000407jrkrideau@inbox.com>

Thanks Uwe. installed.packages()  is definitely faster and better. 

 I don't think I even knew installed.packages() existed. I think I gave up looking for something like it a year or so ago.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: ligges at statistik.tu-dortmund.de
> Sent: Sat, 1 Jun 2013 14:59:22 +0200
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] how to install R 3.0.1
> 
> 
> 
> On 01.06.2013 14:58, Uwe Ligges wrote:
>> 
>> 
>> On 01.06.2013 02:02, Ranjan Maitra wrote:
>>> On Fri, 31 May 2013 18:10:19 -0500 Robert Baer <rbaer at atsu.edu> wrote:
>>> 
>>>> On 5/31/2013 11:59 AM, Ranjan Maitra wrote:
>>>>> Hi John,
>>>>> 
>>>>> I suspect you may be missing a c()?
>>>>> 
>>>>> On Fri, 31 May 2013 06:05:45 -0800 John Kane <jrkrideau at inbox.com>
>>>>> wrote:
>>>>> 
>>>>>> paks  <-  install.packages( "Hmisc", "plyr")
>>>>> paks <- install.packages( c("Hmisc", "plyr"))
>>>>> 
>>>>> 
>>>>>>     install.packages(paks)
>>>>>> You can use the command  library()  to get a list of what is
>>>>>> installed on your machine.
>>>>> Is it possible to get this as a vector of only the package names, or
>>>>> is post-processing the output of library() the only way out?
>>>> Do you mean something like:
>>>> paks = library()$results[,1]
>>>> save(paks, file = 'paks.RData')
>>>> Rob
>>> 
>>> Exactly! Then
>>> 
>>> install.packages(library()$results[,1])
>>> 
>>> does all the updated installs in one shot.
>> 
>> 
>> Why do you want to reinstall all packages?
>> 
>> I'd go for
>> udpate.packages(checkBuilt=TRUE)
>> if a reinstallation after an update of R is what you are aiming at.
> 
> 
> .... and forgot to add: installed.packages() is certainly more
> appropriate than library() to find the names of installed packages (with
> less overhead and hence faster).
> 
> Best,
> Uwe Ligges
> 
>> Best,
>> Uwe Ligges
>> 
>> 
>> 
>>> Thanks!
>>> Ranjan
>>> 
>>> ____________________________________________________________
>>> GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at
>>> http://www.inbox.com/smileys
>>> Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk?
>>> and most webmails
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From pdalgd at gmail.com  Sat Jun  1 15:57:17 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 1 Jun 2013 15:57:17 +0200
Subject: [R] How to compute a P-value for a complex mixture of
	chi-squared distributions in R
In-Reply-To: <54649.201.81.178.2.1370061142.squirrel@webmail.mbe.bio.br>
References: <54649.201.81.178.2.1370061142.squirrel@webmail.mbe.bio.br>
Message-ID: <1CAE97A5-0B40-49CA-AC3F-D387D5EBA8EA@gmail.com>


On Jun 1, 2013, at 06:32 , Tiago V. Pereira wrote:

> Hello, R users!
> 
> I am struggling with the following problem:
> 
> I need to compute a P-value for a mixture of two chi-squared
> distributions. My P-value is given by:
> 
> P = 0.5*prob(sqrt(chi2(1)) <= x) + 0.5*prob(sqrt(chi2(2)) <= x)
> 
> In words, I need to compute the p-value for 50?50 mixture of the square
> root of a chi-squared random variable with 1 degree of freedom and the
> square root of a chi-squared with two degrees of freedom.
> 
> Although I can quickly simulate data, the P-values I am looking for are at
> the tail of the distribution, that is, alpha levels below 10^-7. Hence,
> simulation is not efficient.
> 
> Are you aware of smart approach?

Er,...

Anything wrong with 

0.5 * pchisq(x^2, 1) + 0.5 * pchisq(x^2, 2) 

???

-pd


> 
> 
> All the best,
> 
> Tiago
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From maitra.mbox.ignored at inbox.com  Sat Jun  1 15:58:08 2013
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Sat, 1 Jun 2013 08:58:08 -0500
Subject: [R] how to install R 3.0.1
In-Reply-To: <51A9EFEE.8090406@statistik.tu-dortmund.de>
References: <caeezrqqu7qrafun52safdqah0ukj-am5w50udcwo+tso73jgvg@mail.gmail.com>
	<bd740eead3d.000002edjrkrideau@inbox.com>
	<BDC06134AA3.0000034Fjrkrideau@inbox.com>
	<20130531115905.45a51e3ae3e707c2f7e44073@inbox.com>
	<51A92DDB.5040001@atsu.edu>
	<20130531190240.f313694544bd9f91c5a54425@inbox.com>
	<51A9EFEE.8090406@statistik.tu-dortmund.de>
Message-ID: <20130601085808.ea9ccc6322072efb42724f0c@inbox.com>

On Sat, 1 Jun 2013 14:58:22 +0200 Uwe Ligges
<ligges at statistik.tu-dortmund.de> wrote:

> 
> 
> On 01.06.2013 02:02, Ranjan Maitra wrote:
> > On Fri, 31 May 2013 18:10:19 -0500 Robert Baer <rbaer at atsu.edu> wrote:
> >
> >> On 5/31/2013 11:59 AM, Ranjan Maitra wrote:
> >>> Hi John,
> >>>
> >>> I suspect you may be missing a c()?
> >>>
> >>> On Fri, 31 May 2013 06:05:45 -0800 John Kane <jrkrideau at inbox.com>
> >>> wrote:
> >>>
> >>>> paks  <-  install.packages( "Hmisc", "plyr")
> >>> paks <- install.packages( c("Hmisc", "plyr"))
> >>>
> >>>
> >>>>     install.packages(paks)
> >>>> You can use the command  library()  to get a list of what is installed on your machine.
> >>> Is it possible to get this as a vector of only the package names, or
> >>> is post-processing the output of library() the only way out?
> >> Do you mean something like:
> >> paks = library()$results[,1]
> >> save(paks, file = 'paks.RData')
> >> Rob
> >
> > Exactly! Then
> >
> > install.packages(library()$results[,1])
> >
> > does all the updated installs in one shot.
> 
> 
> Why do you want to reinstall all packages?
> 
> I'd go for
> udpate.packages(checkBuilt=TRUE)
> if a reinstallation after an update of R is what you are aiming at.

Actually, this did not work (on multiple architectures from 2.15.2 to
3.0.0 as well as from 3.0.0 to 3.0.1) for me in the sense that it only
offered to update a very small subset packages, and that too, without
their dependencies. Which resulted in a failure also for a large subset
of the small subset of packages.

As an example, consider the following:

> update.packages(checkBuilt = TRUE)
> 

(nothing to update, since I updated some things yesterday, and did a
manual installation when the dependencies, eg lme4 comes to mind,
failed)

> installed.packages()[,"Built"]

shows that AnalyzeFMRI was Built for 3.0.0.

Perhaps not a big deal from 3.0.0 to 3.0.1 but was a big deal from
2.15.2 to 3.0.0.

But after doing a 

? install.packages("AnalyzeFMRI")

I get that 

AnalyzeFMRI is Built for 3.0.1.

Trying:

> install.packages(installed.packages()[,1])

I get that all are updated to 3.0.1, except for some, like XLConnectJars
which are not available.

(I was surprised: it may be a bug, but is definitely a desirable
feature that should be considered for inclusion.)

Perhaps the better thing to do would have been to:

> update.packages(installed.packages()[,1])

but I did not think about that earlier.

Many thanks and best wishes,
Ranjan



> Best,
> Uwe Ligges
> 
> 
> 
> > Thanks!
> > Ranjan
> >
> > ____________________________________________________________
> > GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at http://www.inbox.com/smileys
> > Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk? and most webmails
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be
deleted on receipt. For those needing to send personal or professional
e-mail, please use appropriate addresses.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From johnnyzhz at yahoo.com  Sat Jun  1 16:37:13 2013
From: johnnyzhz at yahoo.com (Johnny Zhang)
Date: Sat, 1 Jun 2013 07:37:13 -0700 (PDT)
Subject: [R] More discussion on R usage statistics
In-Reply-To: <CA+vqiLEEvOdrUs=WCFgBYJ8yFmpyK_p=t5XMbitJO6LaYJRLew@mail.gmail.com>
References: <1369848099.18317.YahooMailNeo@web122604.mail.ne1.yahoo.com>
	<3F85B85C-4816-443C-89C8-83A177EA2B62@gmail.com>
	<1369917646.73141.YahooMailNeo@web122602.mail.ne1.yahoo.com>
	<CABxs9Vm0TD_PZq2hubG=4UGEqBwCGE8O_dZcapGz+zf-60NL1Q@mail.gmail.com>
	<1370021122.18209.YahooMailNeo@web122603.mail.ne1.yahoo.com>
	<CA+vqiLEEvOdrUs=WCFgBYJ8yFmpyK_p=t5XMbitJO6LaYJRLew@mail.gmail.com>
Message-ID: <1370097433.33528.YahooMailNeo@web122606.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130601/7ad678e8/attachment.pl>

From ligges at statistik.tu-dortmund.de  Sat Jun  1 16:51:19 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 1 Jun 2013 16:51:19 +0200
Subject: [R] how to install R 3.0.1
In-Reply-To: <20130601085808.ea9ccc6322072efb42724f0c@inbox.com>
References: <caeezrqqu7qrafun52safdqah0ukj-am5w50udcwo+tso73jgvg@mail.gmail.com>
	<bd740eead3d.000002edjrkrideau@inbox.com>
	<BDC06134AA3.0000034Fjrkrideau@inbox.com>
	<20130531115905.45a51e3ae3e707c2f7e44073@inbox.com>
	<51A92DDB.5040001@atsu.edu>
	<20130531190240.f313694544bd9f91c5a54425@inbox.com>
	<51A9EFEE.8090406@statistik.tu-dortmund.de>
	<20130601085808.ea9ccc6322072efb42724f0c@inbox.com>
Message-ID: <51AA0A67.1030404@statistik.tu-dortmund.de>



On 01.06.2013 15:58, Ranjan Maitra wrote:
> On Sat, 1 Jun 2013 14:58:22 +0200 Uwe Ligges
> <ligges at statistik.tu-dortmund.de> wrote:
>
>>
>>
>> On 01.06.2013 02:02, Ranjan Maitra wrote:
>>> On Fri, 31 May 2013 18:10:19 -0500 Robert Baer <rbaer at atsu.edu> wrote:
>>>
>>>> On 5/31/2013 11:59 AM, Ranjan Maitra wrote:
>>>>> Hi John,
>>>>>
>>>>> I suspect you may be missing a c()?
>>>>>
>>>>> On Fri, 31 May 2013 06:05:45 -0800 John Kane <jrkrideau at inbox.com>
>>>>> wrote:
>>>>>
>>>>>> paks  <-  install.packages( "Hmisc", "plyr")
>>>>> paks <- install.packages( c("Hmisc", "plyr"))
>>>>>
>>>>>
>>>>>>      install.packages(paks)
>>>>>> You can use the command  library()  to get a list of what is installed on your machine.
>>>>> Is it possible to get this as a vector of only the package names, or
>>>>> is post-processing the output of library() the only way out?
>>>> Do you mean something like:
>>>> paks = library()$results[,1]
>>>> save(paks, file = 'paks.RData')
>>>> Rob
>>>
>>> Exactly! Then
>>>
>>> install.packages(library()$results[,1])
>>>
>>> does all the updated installs in one shot.
>>
>>
>> Why do you want to reinstall all packages?
>>
>> I'd go for
>> udpate.packages(checkBuilt=TRUE)
>> if a reinstallation after an update of R is what you are aiming at.
>
> Actually, this did not work (on multiple architectures from 2.15.2 to
> 3.0.0 as well as from 3.0.0 to 3.0.1) for me in the sense that it only
> offered to update a very small subset packages, and that too, without
> their dependencies. Which resulted in a failure also for a large subset
> of the small subset of packages.
>
> As an example, consider the following:
>
>> update.packages(checkBuilt = TRUE)
>>
>
> (nothing to update, since I updated some things yesterday, and did a
> manual installation when the dependencies, eg lme4 comes to mind,
> failed)
>
>> installed.packages()[,"Built"]
>
> shows that AnalyzeFMRI was Built for 3.0.0.
>
> Perhaps not a big deal from 3.0.0 to 3.0.1

Right, it won't reinstall here since that is not necessary and the 
package sources were not changed, hence it safes you time and bandwidth.


> but was a big deal from
> 2.15.2 to 3.0.0.
>

Right, and it would have updated there....


> But after doing a
>
> ? install.packages("AnalyzeFMRI")
>
> I get that
>
> AnalyzeFMRI is Built for 3.0.1.


Yes, sure.



> Trying:
>
>> install.packages(installed.packages()[,1])
>
> I get that all are updated to 3.0.1, except for some, like XLConnectJars
> which are not available.


This is not a CRAN package and binaries may not be available in the 
repository you tried to get it from (Omegahat) or you have not selected 
Omegahat as a repository via setRepositories().
You can try to install from sources, though.

As I said before, replacing all your packages unconditionally wastes 
bandwidth. There are rarely situations where the other updates are 
really needed.

Best,
Uwe Ligges



> (I was surprised: it may be a bug, but is definitely a desirable
> feature that should be considered for inclusion.)
>
> Perhaps the better thing to do would have been to:
>
>> update.packages(installed.packages()[,1])
>
> but I did not think about that earlier.
>
> Many thanks and best wishes,
> Ranjan
>
>
>
>> Best,
>> Uwe Ligges
>>
>>
>>
>>> Thanks!
>>> Ranjan
>>>
>>> ____________________________________________________________
>>> GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at http://www.inbox.com/smileys
>>> Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk? and most webmails
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


From maitra.mbox.ignored at inbox.com  Sat Jun  1 16:57:54 2013
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Sat, 1 Jun 2013 09:57:54 -0500
Subject: [R] how to install R 3.0.1
In-Reply-To: <51AA0A67.1030404@statistik.tu-dortmund.de>
References: <caeezrqqu7qrafun52safdqah0ukj-am5w50udcwo+tso73jgvg@mail.gmail.com>
	<bd740eead3d.000002edjrkrideau@inbox.com>
	<BDC06134AA3.0000034Fjrkrideau@inbox.com>
	<20130531115905.45a51e3ae3e707c2f7e44073@inbox.com>
	<51A92DDB.5040001@atsu.edu>
	<20130531190240.f313694544bd9f91c5a54425@inbox.com>
	<51A9EFEE.8090406@statistik.tu-dortmund.de>
	<20130601085808.ea9ccc6322072efb42724f0c@inbox.com>
	<51AA0A67.1030404@statistik.tu-dortmund.de>
Message-ID: <20130601095754.5db5edeebad0a5ecd1094328@inbox.com>

On Sat, 1 Jun 2013 16:51:19 +0200 Uwe Ligges
<ligges at statistik.tu-dortmund.de> wrote:

> 
> 
> On 01.06.2013 15:58, Ranjan Maitra wrote:
> > On Sat, 1 Jun 2013 14:58:22 +0200 Uwe Ligges
> > <ligges at statistik.tu-dortmund.de> wrote:
> >
> >>
> >>
> >> On 01.06.2013 02:02, Ranjan Maitra wrote:
> >>> On Fri, 31 May 2013 18:10:19 -0500 Robert Baer <rbaer at atsu.edu> wrote:
> >>>
> >>>> On 5/31/2013 11:59 AM, Ranjan Maitra wrote:
> >>>>> Hi John,
> >>>>>
> >>>>> I suspect you may be missing a c()?
> >>>>>
> >>>>> On Fri, 31 May 2013 06:05:45 -0800 John Kane <jrkrideau at inbox.com>
> >>>>> wrote:
> >>>>>
> >>>>>> paks  <-  install.packages( "Hmisc", "plyr")
> >>>>> paks <- install.packages( c("Hmisc", "plyr"))
> >>>>>
> >>>>>
> >>>>>>      install.packages(paks)
> >>>>>> You can use the command  library()  to get a list of what is installed on your machine.
> >>>>> Is it possible to get this as a vector of only the package names, or
> >>>>> is post-processing the output of library() the only way out?
> >>>> Do you mean something like:
> >>>> paks = library()$results[,1]
> >>>> save(paks, file = 'paks.RData')
> >>>> Rob
> >>>
> >>> Exactly! Then
> >>>
> >>> install.packages(library()$results[,1])
> >>>
> >>> does all the updated installs in one shot.
> >>
> >>
> >> Why do you want to reinstall all packages?
> >>
> >> I'd go for
> >> udpate.packages(checkBuilt=TRUE)
> >> if a reinstallation after an update of R is what you are aiming at.
> >
> > Actually, this did not work (on multiple architectures from 2.15.2 to
> > 3.0.0 as well as from 3.0.0 to 3.0.1) for me in the sense that it only
> > offered to update a very small subset packages, and that too, without
> > their dependencies. Which resulted in a failure also for a large subset
> > of the small subset of packages.
> >
> > As an example, consider the following:
> >
> >> update.packages(checkBuilt = TRUE)
> >>
> >
> > (nothing to update, since I updated some things yesterday, and did a
> > manual installation when the dependencies, eg lme4 comes to mind,
> > failed)
> >
> >> installed.packages()[,"Built"]
> >
> > shows that AnalyzeFMRI was Built for 3.0.0.
> >
> > Perhaps not a big deal from 3.0.0 to 3.0.1
> 
> Right, it won't reinstall here since that is not necessary and the 
> package sources were not changed, hence it safes you time and bandwidth.
> 
> 
> > but was a big deal from
> > 2.15.2 to 3.0.0.
> >
> 
> Right, and it would have updated there....

But it did not, and that is the point.

Ranjan

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From b.rowlingson at lancaster.ac.uk  Sat Jun  1 17:02:00 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sat, 1 Jun 2013 16:02:00 +0100
Subject: [R] Loading an .RData file and assigning the loaded objects
 within a loop
In-Reply-To: <cf61f67ba6e44a3c85d2447a36977c6b@EX-0-HT0.lancs.local>
References: <CAL93JYthgwUzpAjz_uXXVxKYywGdGXZRTqPyw3sAVogLXD99hQ@mail.gmail.com>
	<cf61f67ba6e44a3c85d2447a36977c6b@EX-0-HT0.lancs.local>
Message-ID: <CANVKczMk0RHwG_agPTasE-teMWpoMt0Wa3f+AX7pcUMVzw4gnQ@mail.gmail.com>

Within lapply load the file and return the value of the thing or
things in the file you want. Something like this:

 > files
[1] "x1.RData" "x2.RData" "x3.RData" "x4.RData"

 > lapply(files,function(z){load(z);x})
[[1]]
[1] 1

[[2]]
[1] 22

[[3]]
[1] 333

[[4]]
[1] 4444

Each of my files contains a single number stored in an object called
'x'. Within the loop 'x' has the value just loaded from the file.

Another method is to use the environment argument of load to save into
an environment other than the global one...




On Sat, Jun 1, 2013 at 11:52 AM, Jim Holtman <jholtman at gmail.com> wrote:
> use 'lapply' to read in the .RData file.  Therefore each file is stored as an element of a list thatb
>  you can access and change as necessary.
>
> Sent from my iPad
>
> On Jun 1, 2013, at 6:18, Jeremy Ng <jeremy.ng.wk1990 at gmail.com> wrote:
>
>> Hi all,
>>
>> I tried to look this up online, but am still feeling a little stuck.
>>
>> I have a bunch of Rdata files in side my directory, and I would like to
>> load all of them in a loop. Each time the next is read in, it would
>> over-write the previously read in object because they will be assigned the
>> same workspace object name.
>>
>> Is there anyway for each individually read in Rdata object to be assigned a
>> new name?
>>
>> Thanks!
>> JEremy
>>
>>    [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From friendly at yorku.ca  Sat Jun  1 17:33:10 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Sat, 01 Jun 2013 11:33:10 -0400
Subject: [R] measuring distances between colours?
In-Reply-To: <007001ce5e58$7776a400$6663ec00$@mcmaster.ca>
References: <4382_1369916184_r4UCGK5j024861_web-459777071@cgpsrv2.cis.mcmaster.ca>	<004601ce5d7a$9f16fc00$dd44f400$@mcmaster.ca>	<20904.20143.918220.744897@stat.math.ethz.ch>
	<CAKFxdiSHPCgsVCaaJDfedX8b2ZAHbTdNNYktjHzUk=0XtG=ayA@mail.gmail.com>
	<007001ce5e58$7776a400$6663ec00$@mcmaster.ca>
Message-ID: <51AA1436.2020909@yorku.ca>

Just a quick note:  The following two versions of your function don't 
give the same results.  I'm not sure why, and also not sure why the
criterion for 'near' should be expressed in squared distance.

# version 1
rgb2col <- local({
     hex2dec <- function(hexnums) {
         # suggestion of Eik Vettorazzi
         sapply(strtoi(hexnums, 16L), function(x) x %/% 256^(2:0) %% 256)
     }
     findMatch <- function(dec.col) {
         sq.dist <- colSums((hsv - dec.col)^2)
         rbind(which.min(sq.dist), min(sq.dist))
     }
     colors <- colors()
     hsv <- rgb2hsv(col2rgb(colors))

     function(cols, near=0.25) {
         cols <- sub("^#", "", toupper(cols))
         dec.cols <- rgb2hsv(hex2dec(cols))
         which.col <- apply(dec.cols, 2, findMatch)
         matches <- colors[which.col[1, ]]
         unmatched <- which.col[2, ] > near^2
         matches[unmatched] <- paste("#", cols[unmatched], sep="")
         matches
     }
})

# version 2
rgb2col2 <- local({
       all.names <- colors()
       all.hsv <- rgb2hsv(col2rgb(all.names))
       find.near <- function(x.hsv) {
           # return the nearest R color name and distance
           sq.dist <- colSums((all.hsv - x.hsv)^2)
           rbind(all.names[which.min(sq.dist)], min(sq.dist))
       }
       function(cols.hex, near=.25){
           cols.hsv <- rgb2hsv(col2rgb(cols.hex))
           cols.near <- apply(cols.hsv, 2, find.near)
           ifelse(cols.near[2,] < near^2, cols.near[1,], cols.hex)
       }
})

# tests
 > rgb2col(c("#010101", "#EEEEEE", "#AA0000", "#00AA00", "#0000AA", 
"#AAAA00", "#AA00AA", "#00AAAA"))
[1] "black"         "gray93"        "darkred"       "green4"
[5] "blue4"         "darkgoldenrod" "darkmagenta"   "cyan4"
 > rgb2col2(c("#010101", "#EEEEEE", "#AA0000", "#00AA00", "#0000AA", 
"#AAAA00", "#AA00AA", "#00AAAA"))
[1] "#010101"       "#EEEEEE"       "darkred"       "green4"
[5] "blue4"         "darkgoldenrod" "darkmagenta"   "cyan4"
 >


On 5/31/2013 7:42 PM, John Fox wrote:
> Dear Kevin,
>
> I generally prefer your solution. I didn't realize that col2rgb() worked
> with hex-colour input (as opposed to named colours), so my code converting
> hex numbers to decimal is unnecessary; and using ifelse() is clearer than
> replacing the non-matches.
>
> I'm not so sure about avoiding the closure, since for converting small
> numbers of colours, your function will spend most of its time constructing
> the local function find.near() and building all.hsv. Here's an example,
> using your rgb2col() and a comparable function employing a closure, with one
> of your examples executed 100 times:
>
>> r2c <- function(){
> +     all.names <- colors()
> +     all.hsv <- rgb2hsv(col2rgb(all.names))
> +     find.near <- function(x.hsv) {
> +         # return the nearest R color name and distance
> +         sq.dist <- colSums((all.hsv - x.hsv)^2)
> +         rbind(all.names[which.min(sq.dist)], min(sq.dist))
> +     }
> +     function(cols.hex, near=.25){
> +         cols.hsv <- rgb2hsv(col2rgb(cols.hex))
> +         cols.near <- apply(cols.hsv, 2, find.near)
> +         ifelse(cols.near[2,] < near^2, cols.near[1,], cols.hex)
> +     }
> + }
>
>> mycols <- c("#010101", "#EEEEEE", "#AA0000", "#00AA00", "#0000AA",
> +     "#AAAA00", "#AA00AA", "#00AAAA")
>
>> system.time(for (i in 1:100) oldnew <- c(mycols, rgb2col(mycols,
> near=.25)))
>     user  system elapsed
>     1.97    0.00    1.97
>
>> system.time({rgb2col2 <- r2c()
> +     for (i in 1:100) oldnew2 <- c(mycols, rgb2col2(mycols, near=.25))
> +     })
>     user  system elapsed
>     0.08    0.00    0.08
>
>> rbind(oldnew, oldnew2)
>          [,1]      [,2]      [,3]      [,4]      [,5]      [,6]
> oldnew  "#010101" "#EEEEEE" "#AA0000" "#00AA00" "#0000AA" "#AAAA00"
> oldnew2 "#010101" "#EEEEEE" "#AA0000" "#00AA00" "#0000AA" "#AAAA00"
>          [,7]      [,8]      [,9]      [,10]     [,11]     [,12]
> oldnew  "#AA00AA" "#00AAAA" "#010101" "#EEEEEE" "darkred" "green4"
> oldnew2 "#AA00AA" "#00AAAA" "#010101" "#EEEEEE" "darkred" "green4"
>          [,13]   [,14]           [,15]         [,16]
> oldnew  "blue4" "darkgoldenrod" "darkmagenta" "cyan4"
> oldnew2 "blue4" "darkgoldenrod" "darkmagenta" "cyan4"
>
> Does this really make a difference? Frankly, it wouldn't for my application
> (for colour selection in the Rcmdr) where a user is likely to perform at
> most one or two conversions of a small number of colours in a session. The
> time advantage of the second approach will depend upon the number of times
> the function is invoked and the number of colours converted each time.
>
> Best,
>   John
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Kevin Wright
>> Sent: Friday, May 31, 2013 3:39 PM
>> To: Martin Maechler
>> Cc: r-help; John Fox
>> Subject: Re: [R] measuring distances between colours?
>>
>> Thanks for the discussion.  I've also wanted to be able to find nearest
>> colors.  I took the code and comments in this thread and simplified the
>> function even further.  (Personally, I think using closures results in
>> Rube-Goldberg code.  YMMV.)  The first example below is what I use for
>> 'group' colors in lattice.
>>
>> Kevin Wright
>>
>> rgb2col <- function(cols.hex, near=.25){
>>    # Given a vector of hex colors, find the nearest 'named' R colors
>>    # If no color closer than 'near' is found, return the hex color
>>    # Authors: John Fox, Martin Maechler, Kevin Wright
>>    # From r-help discussion 5.30.13
>>
>>    find.near <- function(x.hsv) {
>>      # return the nearest R color name and distance
>>      sq.dist <- colSums((all.hsv - x.hsv)^2)
>>      rbind(all.names[which.min(sq.dist)], min(sq.dist))
>>    }
>>    all.names <- colors()
>>    all.hsv <- rgb2hsv(col2rgb(all.names))
>>    cols.hsv <- rgb2hsv(col2rgb(cols.hex))
>>    cols.near <- apply(cols.hsv, 2, find.near)
>>    ifelse(cols.near[2,] < near^2, cols.near[1,], cols.hex)
>> }
>>
>> mycols <- c("royalblue", "red", "#009900", "dark orange", "#999999",
>> "#a6761d", "#aa00da")
>> mycols <- c("#010101", "#EEEEEE", "#AA0000", "#00AA00", "#0000AA",
>> "#AAAA00", "#AA00AA", "#00AAAA")
>> mycols <- c("#010101", "#090909", "#090000", "#000900", "#000009",
>> "#090900", "#090009", "#000909")
>> oldnew <- c(mycols, rgb2col(mycols, near=.25)) # Also try near=10
>> pie(rep(1,2*length(mycols)), labels=oldnew, col=oldnew)
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From jfox at mcmaster.ca  Sat Jun  1 17:31:08 2013
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 1 Jun 2013 11:31:08 -0400
Subject: [R] measuring distances between colours?
In-Reply-To: <51A8B263.8040905@yorku.ca>
References: <4382_1369916184_r4UCGK5j024861_web-459777071@cgpsrv2.cis.mcmaster.ca>
	<004601ce5d7a$9f16fc00$dd44f400$@mcmaster.ca>
	<51A8B263.8040905@yorku.ca>
Message-ID: <000e01ce5edd$0a2e4170$1e8ac450$@mcmaster.ca>

Hi Michael,

Thanks for the Wikipedia tip -- I'd looked there but didn't find this
article. The article explains that the Lab colour space was formulated to
provide uniform perceptual differences between colours, with a JND of
approximately of 2.3. Ken Knoblauch made a similar point. The article goes
on to describe relatively complicated adjustments meant to improve the LAV
distance metric, which are probably overkill for my application.

I've programmed Lab colour matching as follows, using Euclidean distances
and adapting Kevin Wright's modification of my original code. I used
convertColor(), which Martin Maechler pointed out to me.

----------- snip --------------

r2c <- function(){
    all.names <- colors()
    all.lab <- t(convertColor(t(col2rgb(all.names)), from="sRGB", to="Lab",
scale.in=255))
    find.near <- function(x.lab) {
        sq.dist <- colSums((all.lab - x.lab)^2)
        rbind(all.names[which.min(sq.dist)], min(sq.dist))
    }
    function(cols.hex, near=2.3){
        cols.lab <- t(convertColor(t(col2rgb(cols.hex)), from="sRGB",
to="Lab", scale.in=255))
        cols.near <- apply(cols.lab, 2, find.near)
        ifelse(cols.near[2, ] < near^2, cols.near[1, ], cols.hex)
    }
}

rgb2col <- r2c()

----------- snip --------------

A bit of experimentation suggests that this works better than using (as I
did previously) direct RGB distances, matching more colours to names and
providing (to my eye, with my monitor) perceptually closer matches, though
sometimes with (again to my eye) perceptible differences. Here's an
illustration, adapting one of Kevin's examples:

----------- snip --------------

cols <- c("#010101", "#EEEEEE", "#AA0000", "#00AA00", "#0000AA", "#AAAA00",
"#AA00AA", "#00AAAA")
(nms <- rgb2col(cols))
pie(rep(1, 2*length(cols)), labels=c(cols, nms), col=c(cols, nms))

----------- snip --------------

Thanks again to everyone who responded to my original, na?ve, question.

Best,
 John

> -----Original Message-----
> From: Michael Friendly [mailto:friendly at yorku.ca]
> Sent: Friday, May 31, 2013 10:24 AM
> To: John Fox
> Cc: r-help at r-project.org; 'Martin Maechler'
> Subject: Re: measuring distances between colours?
> 
> Hi John
> This has been an interesting discussion.
> Though you have a solution for your needs, you might be interested in
> this javascript implementation that allows you to visually compare
> color
> distances in various color spaces
> 
> http://stevehanov.ca/blog/index.php?id=116
> 
> And, all the theory of color distance is described in
> http://en.wikipedia.org/wiki/Color_difference
> 
> PS: This is a very handy function.  When I last tried
> aplpack::bagplot(), it was annoying that the colors could *only*
> be specified in hex.
> 
> -Michael
> 
> 
> 
> On 5/30/2013 5:14 PM, John Fox wrote:
> > Dear all,
> >
> > My thanks to everyone who addressed my question. I've incorporated
> Eik
> > Vettorazzi's suggestion for improved conversion of hexadecimal RGB
> colours
> > to decimal numbers, and Martin Maechler's hint to look at
> demo(colors). I've
> > loosened the default definition of "close enough" from the latter,
> since the
> > following seems to work well for my purposes.
> >
> > r2c <- function(){
> >      hex2dec <- function(hexnums) {
> >          # suggestion of Eik Vettorazzi
> >          sapply(strtoi(hexnums, 16L), function(x) x %/% 256^(2:0) %%
> 256)
> >      }
> >      findMatch <- function(dec.col) {
> >          sq.dist <- colSums((hsv - dec.col)^2)
> >          rbind(which.min(sq.dist), min(sq.dist))
> >      }
> >      colors <- colors()
> >      hsv <- rgb2hsv(col2rgb(colors))
> >      function(cols, near=0.25){
> >          cols <- sub("^#", "", toupper(cols))
> >          dec.cols <- rgb2hsv(hex2dec(cols))
> >          which.col <- apply(dec.cols, 2, findMatch)
> >          matches <- colors[which.col[1, ]]
> >          unmatched <- which.col[2, ] > near^2
> >          matches[unmatched] <- paste("#", cols[unmatched], sep="")
> >          matches
> >      }
> > }
> >
> > rgb2col <- r2c()
> >
> > For example,
> >
> >> rgb2col(c("010101", "EEEEEE", "AA0000", "00AA00", "0000AA",
> "AAAA00",
> > "AA00AA", "00AAAA"))
> > [1] "black"         "gray93"        "darkred"       "green4"
> > [5] "blue4"         "darkgoldenrod" "darkmagenta"   "cyan4"
> >
> >> rgb2col(c("010101", "090909", "090000", "000900", "000009",
> "090900",
> > "090009", "000909"))
> > [1] "black"   "gray3"   "#090000" "#000900" "#000009" "#090900"
> > [7] "#090009" "#000909"
> >
> > Thanks again,
> >   John
> 
> 
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA


From ggrothendieck at gmail.com  Sat Jun  1 17:42:37 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 1 Jun 2013 11:42:37 -0400
Subject: [R] Loading an .RData file and assigning the loaded objects
 within a loop
In-Reply-To: <CAL93JYthgwUzpAjz_uXXVxKYywGdGXZRTqPyw3sAVogLXD99hQ@mail.gmail.com>
References: <CAL93JYthgwUzpAjz_uXXVxKYywGdGXZRTqPyw3sAVogLXD99hQ@mail.gmail.com>
Message-ID: <CAP01uRnZCYHdUtPqm57yg5=tUMD54ert83DCFy-6EsRRTZsFBQ@mail.gmail.com>

On Sat, Jun 1, 2013 at 6:18 AM, Jeremy Ng <jeremy.ng.wk1990 at gmail.com> wrote:
> Hi all,
>
> I tried to look this up online, but am still feeling a little stuck.
>
> I have a bunch of Rdata files in side my directory, and I would like to
> load all of them in a loop. Each time the next is read in, it would
> over-write the previously read in object because they will be assigned the
> same workspace object name.
>
> Is there anyway for each individually read in Rdata object to be assigned a
> new name?
>

If Files is a character vector containing the filenames then this
creates a list witih one componet per RData file. The list names will
be the file names.  Each component is itself a list containing the
objects in that file:

    L <- sapply(Files, function(x) mget(load(x)), simplify = FALSE)

(If it is known that each RData file contains only a single object
then mget could be replaced with get in which case each component of L
would be the object in the respective file.  In that case you will
lose the object names but as you indicated they are all the same that
likely won' t matter.)

--
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From ken.knoblauch at inserm.fr  Sat Jun  1 18:17:39 2013
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Sat, 1 Jun 2013 18:17:39 +0200
Subject: [R] measuring distances between colours?
In-Reply-To: <32399_1370100869_51AA1485_32399_14449_1_000e01ce5edd$0a2e4170$1e8ac450$@mcmaster.ca>
References: <4382_1369916184_r4UCGK5j024861_web-459777071@cgpsrv2.cis.mcmaster.ca>
	<004601ce5d7a$9f16fc00$dd44f400$@mcmaster.ca>
	<51A8B263.8040905@yorku.ca>
	<32399_1370100869_51AA1485_32399_14449_1_000e01ce5edd$0a2e4170$1e8ac450$@mcmaster.ca>
Message-ID: <A8E5759F-C0BC-4033-B4F3-A327554B7CEA@inserm.fr>

Hi John,

Out of curiosity and if it is not much trouble, I would be curious if Luv worked any better than Lab. I think that Luv is supposed to be preferred for monitors and Lab for surfaces but they are generally pretty similar. 

Best,

Ken

Sent from my iPhone

___
Ken Knoblauch
Inserm U846
Stem-Cell and Brain Research Institute
18 av du Doyen L?pine
69500 Bron France
Tel : 04 72 91 34 77
Fax :  04 72 91 34 61
portable : 06 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html

On 1 juin 2013, at 17:31, "John Fox" <jfox at mcmaster.ca> wrote:

> Hi Michael,
> 
> Thanks for the Wikipedia tip -- I'd looked there but didn't find this
> article. The article explains that the Lab colour space was formulated to
> provide uniform perceptual differences between colours, with a JND of
> approximately of 2.3. Ken Knoblauch made a similar point. The article goes
> on to describe relatively complicated adjustments meant to improve the LAV
> distance metric, which are probably overkill for my application.
> 
> I've programmed Lab colour matching as follows, using Euclidean distances
> and adapting Kevin Wright's modification of my original code. I used
> convertColor(), which Martin Maechler pointed out to me.
> 
> ----------- snip --------------
> 
> r2c <- function(){
>    all.names <- colors()
>    all.lab <- t(convertColor(t(col2rgb(all.names)), from="sRGB", to="Lab",
> scale.in=255))
>    find.near <- function(x.lab) {
>        sq.dist <- colSums((all.lab - x.lab)^2)
>        rbind(all.names[which.min(sq.dist)], min(sq.dist))
>    }
>    function(cols.hex, near=2.3){
>        cols.lab <- t(convertColor(t(col2rgb(cols.hex)), from="sRGB",
> to="Lab", scale.in=255))
>        cols.near <- apply(cols.lab, 2, find.near)
>        ifelse(cols.near[2, ] < near^2, cols.near[1, ], cols.hex)
>    }
> }
> 
> rgb2col <- r2c()
> 
> ----------- snip --------------
> 
> A bit of experimentation suggests that this works better than using (as I
> did previously) direct RGB distances, matching more colours to names and
> providing (to my eye, with my monitor) perceptually closer matches, though
> sometimes with (again to my eye) perceptible differences. Here's an
> illustration, adapting one of Kevin's examples:
> 
> ----------- snip --------------
> 
> cols <- c("#010101", "#EEEEEE", "#AA0000", "#00AA00", "#0000AA", "#AAAA00",
> "#AA00AA", "#00AAAA")
> (nms <- rgb2col(cols))
> pie(rep(1, 2*length(cols)), labels=c(cols, nms), col=c(cols, nms))
> 
> ----------- snip --------------
> 
> Thanks again to everyone who responded to my original, na?ve, question.
> 
> Best,
> John
> 
>> -----Original Message-----
>> From: Michael Friendly [mailto:friendly at yorku.ca]
>> Sent: Friday, May 31, 2013 10:24 AM
>> To: John Fox
>> Cc: r-help at r-project.org; 'Martin Maechler'
>> Subject: Re: measuring distances between colours?
>> 
>> Hi John
>> This has been an interesting discussion.
>> Though you have a solution for your needs, you might be interested in
>> this javascript implementation that allows you to visually compare
>> color
>> distances in various color spaces
>> 
>> http://stevehanov.ca/blog/index.php?id=116
>> 
>> And, all the theory of color distance is described in
>> http://en.wikipedia.org/wiki/Color_difference
>> 
>> PS: This is a very handy function.  When I last tried
>> aplpack::bagplot(), it was annoying that the colors could *only*
>> be specified in hex.
>> 
>> -Michael
>> 
>> 
>> 
>> On 5/30/2013 5:14 PM, John Fox wrote:
>>> Dear all,
>>> 
>>> My thanks to everyone who addressed my question. I've incorporated
>> Eik
>>> Vettorazzi's suggestion for improved conversion of hexadecimal RGB
>> colours
>>> to decimal numbers, and Martin Maechler's hint to look at
>> demo(colors). I've
>>> loosened the default definition of "close enough" from the latter,
>> since the
>>> following seems to work well for my purposes.
>>> 
>>> r2c <- function(){
>>>     hex2dec <- function(hexnums) {
>>>         # suggestion of Eik Vettorazzi
>>>         sapply(strtoi(hexnums, 16L), function(x) x %/% 256^(2:0) %%
>> 256)
>>>     }
>>>     findMatch <- function(dec.col) {
>>>         sq.dist <- colSums((hsv - dec.col)^2)
>>>         rbind(which.min(sq.dist), min(sq.dist))
>>>     }
>>>     colors <- colors()
>>>     hsv <- rgb2hsv(col2rgb(colors))
>>>     function(cols, near=0.25){
>>>         cols <- sub("^#", "", toupper(cols))
>>>         dec.cols <- rgb2hsv(hex2dec(cols))
>>>         which.col <- apply(dec.cols, 2, findMatch)
>>>         matches <- colors[which.col[1, ]]
>>>         unmatched <- which.col[2, ] > near^2
>>>         matches[unmatched] <- paste("#", cols[unmatched], sep="")
>>>         matches
>>>     }
>>> }
>>> 
>>> rgb2col <- r2c()
>>> 
>>> For example,
>>> 
>>>> rgb2col(c("010101", "EEEEEE", "AA0000", "00AA00", "0000AA",
>> "AAAA00",
>>> "AA00AA", "00AAAA"))
>>> [1] "black"         "gray93"        "darkred"       "green4"
>>> [5] "blue4"         "darkgoldenrod" "darkmagenta"   "cyan4"
>>> 
>>>> rgb2col(c("010101", "090909", "090000", "000900", "000009",
>> "090900",
>>> "090009", "000909"))
>>> [1] "black"   "gray3"   "#090000" "#000900" "#000009" "#090900"
>>> [7] "#090009" "#000909"
>>> 
>>> Thanks again,
>>>  John
>> 
>> 
>> --
>> Michael Friendly     Email: friendly AT yorku DOT ca
>> Professor, Psychology Dept. & Chair, Quantitative Methods
>> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
>> 4700 Keele Street    Web:   http://www.datavis.ca
>> Toronto, ONT  M3J 1P3 CANADA
> 


From bbolker at gmail.com  Sat Jun  1 18:21:38 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 1 Jun 2013 16:21:38 +0000
Subject: [R] GLMM in R
References: <CANxP2S45qBx8H3Bf-CYt0UJZFEnGKUk3F5C=ouT=wOwSOyP9xg@mail.gmail.com>
	<1370080488.6693.10.camel@milan>
Message-ID: <loom.20130601T181547-252@post.gmane.org>

Milan Bouchet-Valat <nalimilan <at> club.fr> writes:

> 
> Le vendredi 31 mai 2013 ? 22:27 -0300, Luis Fernando Garc?a Hern?ndez a
> ?crit :
> > Dear Friends,
> > 
> > I am new on R so I ask you to excuse me if this question sounds fool. I
> > want to see if there is a significativa relationship between the mating
> > (response variable) and several explanatory variables such as individual
> > number (categorical), leg movemente (continous) and the reuse of
> > individuals (categorical). My data looks like this
> > 

 [snip]

> > MatingIDReplicationShaking1M1R1100M1R2140M2R1150M2R
  2121M3R1140M3R2171M4R1190
> > M4R2221M5R1180M5R2161M6R117

 Your data seem to have gotten mangled in pasting (the mailing
list doesn't take HTML-format postings), so I'm
not *quite* sure what's going on here ...

> > 
> > 
> > 
> > 1 means mating happened, 0 means did not occur.
> > 
> > I am trying to organize the data to apply a GLMM to
>  the data, but have not
> >  been able to do it.I followed the model proposed by CRawley 
> for binary
> > response with pseudorreplication but does not wok. The script goes like this
> > 
> > model2<-lmer(Mating~Replication+(1 ID),family=binomial,method=PQL)

  As pointed out, there is at least one thing wrong here, and it
essentially has to do with following a printed/dead-tree representation
when lmer is a fairly rapidly moving target.

  As well as being obsolete, the method argument should have been
a string ("PQL") in any case.

  I would suggest

glmer(Mating~...+(1|ID), family=binomial,data=...)

(I strongly recommend the use of a 'data' argument to pass
the model variables rather than pulling them from the workspace.

  Further questions should probably go to
r-sig-mixed-models at r-project.org

> > 
> > Can somebody tell me what part is wrong and how could
> I fix it? If you know
> > a better method, will be really welcomed!
> You do not tell us what you mean by "wrong", but at least in the form
> above it will not work. Try with (1|ID), and use "REML" and "nAGQ"
> arguments instead of the deprecated "method".
>


From jfox at mcmaster.ca  Sat Jun  1 18:30:05 2013
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 1 Jun 2013 12:30:05 -0400
Subject: [R] measuring distances between colours?
In-Reply-To: <51AA1436.2020909@yorku.ca>
References: <4382_1369916184_r4UCGK5j024861_web-459777071@cgpsrv2.cis.mcmaster.ca>	<004601ce5d7a$9f16fc00$dd44f400$@mcmaster.ca>	<20904.20143.918220.744897@stat.math.ethz.ch>	<CAKFxdiSHPCgsVCaaJDfedX8b2ZAHbTdNNYktjHzUk=0XtG=ayA@mail.gmail.com>	<007001ce5e58$7776a400$6663ec00$@mcmaster.ca>
	<51AA1436.2020909@yorku.ca>
Message-ID: <000f01ce5ee5$46b1c420$d4154c60$@mcmaster.ca>

Hi Michael,

This has become a bit of a comedy of errors. 

The bug is in Kevin Wright's code, which I adapted, and you too in your
version, which uses local() rather than function() to produce the closure.
The matrix which.col contains character data, as a consequence of binding
the minimum squared distances to colour names, and thus the comparison
cols.near[2,] < near^2 doesn't work properly when, ironically, the distance
is small enough so that it's rendered in scientific notation. 

Converting to numeric appears to work:

> rgb2col2 <- local({
+     all.names <- colors()
+     all.hsv <- rgb2hsv(col2rgb(all.names))
+     find.near <- function(x.hsv) {
+         # return the nearest R color name and distance
+         sq.dist <- colSums((all.hsv - x.hsv)^2)
+         rbind(all.names[which.min(sq.dist)], min(sq.dist))
+     }
+     function(cols.hex, near=.25){
+         cols.hsv <- rgb2hsv(col2rgb(cols.hex))
+         cols.near <- apply(cols.hsv, 2, find.near)
+         ifelse(as.numeric(cols.near[2,]) <= near^2, cols.near[1,],
cols.hex)
+     }
+ })

> rgb2col2(c("#010101", "#EEEEEE", "#AA0000", "#00AA00", "#0000AA", 
+     "#AAAA00", "#AA00AA", "#00AAAA"))

[1] "black"         "gray93"        "darkred"       "green4"        "blue4"
"darkgoldenrod"
[7] "darkmagenta"   "cyan4"

The same bug is in the code that I just posted using Lab colours, so (for
posterity) here's a fixed version of that, using local():

> rgb2col <- local({
+     all.names <- colors()
+     all.lab <- t(convertColor(t(col2rgb(all.names)), from = "sRGB", 
+         to = "Lab", scale.in = 255))
+     find.near <- function(x.lab) {
+         sq.dist <- colSums((all.lab - x.lab)^2)
+         rbind(all.names[which.min(sq.dist)], min(sq.dist))
+     }
+     function(cols.hex, near = 2.3) {
+         cols.lab <- t(convertColor(t(col2rgb(cols.hex)), from = "sRGB", 
+             to = "Lab", scale.in = 255))
+         cols.near <- apply(cols.lab, 2, find.near)
+         ifelse(as.numeric(cols.near[2, ]) < near^2, cols.near[1, ],
toupper(cols.hex))
+     }
+ })

> rgb2col(c("#010101", "#EEEEEE", "#AA0000", "#00AA00", "#0000AA",
"#AAAA00", "#AA00AA", "#00AAAA"))

[1] "black"   "gray93"  "#AA0000" "#00AA00" "#0000AA" "#AAAA00"
[7] "#AA00AA" "#00AAAA"

> rgb2col(c("#010101", "#EEEEEE", "#AA0000", "#00AA00", "#0000AA",
"#AAAA00", "#AA00AA", "#00AAAA"), near=15)

[1] "black"         "gray93"        "firebrick3"    "limegreen"    
[5] "blue4"         "#AAAA00"       "darkmagenta"   "lightseagreen"

So with Lab colours, setting near to the JND of 2.3 leaves many of these
colours unmatched. I experimented a bit, and using 15 (as above) produces
matches that appear reasonably "close" to me.

I used squared distances to avoid taking the square-roots of all the
distances. Since the criterion for "near" colours, which is on the distance
scale, is squared to make the comparison, this shouldn't be problematic.

I hope that finally this will be a satisfactory solution.

Best,
 John

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Michael Friendly
> Sent: Saturday, June 01, 2013 11:33 AM
> To: John Fox
> Cc: 'r-help'; 'Martin Maechler'
> Subject: Re: [R] measuring distances between colours?
> 
> Just a quick note:  The following two versions of your function don't
> give the same results.  I'm not sure why, and also not sure why the
> criterion for 'near' should be expressed in squared distance.
> 
> # version 1
> rgb2col <- local({
>      hex2dec <- function(hexnums) {
>          # suggestion of Eik Vettorazzi
>          sapply(strtoi(hexnums, 16L), function(x) x %/% 256^(2:0) %%
> 256)
>      }
>      findMatch <- function(dec.col) {
>          sq.dist <- colSums((hsv - dec.col)^2)
>          rbind(which.min(sq.dist), min(sq.dist))
>      }
>      colors <- colors()
>      hsv <- rgb2hsv(col2rgb(colors))
> 
>      function(cols, near=0.25) {
>          cols <- sub("^#", "", toupper(cols))
>          dec.cols <- rgb2hsv(hex2dec(cols))
>          which.col <- apply(dec.cols, 2, findMatch)
>          matches <- colors[which.col[1, ]]
>          unmatched <- which.col[2, ] > near^2
>          matches[unmatched] <- paste("#", cols[unmatched], sep="")
>          matches
>      }
> })
> 
> # version 2
> rgb2col2 <- local({
>        all.names <- colors()
>        all.hsv <- rgb2hsv(col2rgb(all.names))
>        find.near <- function(x.hsv) {
>            # return the nearest R color name and distance
>            sq.dist <- colSums((all.hsv - x.hsv)^2)
>            rbind(all.names[which.min(sq.dist)], min(sq.dist))
>        }
>        function(cols.hex, near=.25){
>            cols.hsv <- rgb2hsv(col2rgb(cols.hex))
>            cols.near <- apply(cols.hsv, 2, find.near)
>            ifelse(cols.near[2,] < near^2, cols.near[1,], cols.hex)
>        }
> })
> 
> # tests
>  > rgb2col(c("#010101", "#EEEEEE", "#AA0000", "#00AA00", "#0000AA",
> "#AAAA00", "#AA00AA", "#00AAAA"))
> [1] "black"         "gray93"        "darkred"       "green4"
> [5] "blue4"         "darkgoldenrod" "darkmagenta"   "cyan4"
>  > rgb2col2(c("#010101", "#EEEEEE", "#AA0000", "#00AA00", "#0000AA",
> "#AAAA00", "#AA00AA", "#00AAAA"))
> [1] "#010101"       "#EEEEEE"       "darkred"       "green4"
> [5] "blue4"         "darkgoldenrod" "darkmagenta"   "cyan4"
>  >
> 
> 
> On 5/31/2013 7:42 PM, John Fox wrote:
> > Dear Kevin,
> >
> > I generally prefer your solution. I didn't realize that col2rgb()
> worked
> > with hex-colour input (as opposed to named colours), so my code
> converting
> > hex numbers to decimal is unnecessary; and using ifelse() is clearer
> than
> > replacing the non-matches.
> >
> > I'm not so sure about avoiding the closure, since for converting
> small
> > numbers of colours, your function will spend most of its time
> constructing
> > the local function find.near() and building all.hsv. Here's an
> example,
> > using your rgb2col() and a comparable function employing a closure,
> with one
> > of your examples executed 100 times:
> >
> >> r2c <- function(){
> > +     all.names <- colors()
> > +     all.hsv <- rgb2hsv(col2rgb(all.names))
> > +     find.near <- function(x.hsv) {
> > +         # return the nearest R color name and distance
> > +         sq.dist <- colSums((all.hsv - x.hsv)^2)
> > +         rbind(all.names[which.min(sq.dist)], min(sq.dist))
> > +     }
> > +     function(cols.hex, near=.25){
> > +         cols.hsv <- rgb2hsv(col2rgb(cols.hex))
> > +         cols.near <- apply(cols.hsv, 2, find.near)
> > +         ifelse(cols.near[2,] < near^2, cols.near[1,], cols.hex)
> > +     }
> > + }
> >
> >> mycols <- c("#010101", "#EEEEEE", "#AA0000", "#00AA00", "#0000AA",
> > +     "#AAAA00", "#AA00AA", "#00AAAA")
> >
> >> system.time(for (i in 1:100) oldnew <- c(mycols, rgb2col(mycols,
> > near=.25)))
> >     user  system elapsed
> >     1.97    0.00    1.97
> >
> >> system.time({rgb2col2 <- r2c()
> > +     for (i in 1:100) oldnew2 <- c(mycols, rgb2col2(mycols,
> near=.25))
> > +     })
> >     user  system elapsed
> >     0.08    0.00    0.08
> >
> >> rbind(oldnew, oldnew2)
> >          [,1]      [,2]      [,3]      [,4]      [,5]      [,6]
> > oldnew  "#010101" "#EEEEEE" "#AA0000" "#00AA00" "#0000AA" "#AAAA00"
> > oldnew2 "#010101" "#EEEEEE" "#AA0000" "#00AA00" "#0000AA" "#AAAA00"
> >          [,7]      [,8]      [,9]      [,10]     [,11]     [,12]
> > oldnew  "#AA00AA" "#00AAAA" "#010101" "#EEEEEE" "darkred" "green4"
> > oldnew2 "#AA00AA" "#00AAAA" "#010101" "#EEEEEE" "darkred" "green4"
> >          [,13]   [,14]           [,15]         [,16]
> > oldnew  "blue4" "darkgoldenrod" "darkmagenta" "cyan4"
> > oldnew2 "blue4" "darkgoldenrod" "darkmagenta" "cyan4"
> >
> > Does this really make a difference? Frankly, it wouldn't for my
> application
> > (for colour selection in the Rcmdr) where a user is likely to perform
> at
> > most one or two conversions of a small number of colours in a
> session. The
> > time advantage of the second approach will depend upon the number of
> times
> > the function is invoked and the number of colours converted each
> time.
> >
> > Best,
> >   John
> >
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> >> project.org] On Behalf Of Kevin Wright
> >> Sent: Friday, May 31, 2013 3:39 PM
> >> To: Martin Maechler
> >> Cc: r-help; John Fox
> >> Subject: Re: [R] measuring distances between colours?
> >>
> >> Thanks for the discussion.  I've also wanted to be able to find
> nearest
> >> colors.  I took the code and comments in this thread and simplified
> the
> >> function even further.  (Personally, I think using closures results
> in
> >> Rube-Goldberg code.  YMMV.)  The first example below is what I use
> for
> >> 'group' colors in lattice.
> >>
> >> Kevin Wright
> >>
> >> rgb2col <- function(cols.hex, near=.25){
> >>    # Given a vector of hex colors, find the nearest 'named' R colors
> >>    # If no color closer than 'near' is found, return the hex color
> >>    # Authors: John Fox, Martin Maechler, Kevin Wright
> >>    # From r-help discussion 5.30.13
> >>
> >>    find.near <- function(x.hsv) {
> >>      # return the nearest R color name and distance
> >>      sq.dist <- colSums((all.hsv - x.hsv)^2)
> >>      rbind(all.names[which.min(sq.dist)], min(sq.dist))
> >>    }
> >>    all.names <- colors()
> >>    all.hsv <- rgb2hsv(col2rgb(all.names))
> >>    cols.hsv <- rgb2hsv(col2rgb(cols.hex))
> >>    cols.near <- apply(cols.hsv, 2, find.near)
> >>    ifelse(cols.near[2,] < near^2, cols.near[1,], cols.hex)
> >> }
> >>
> >> mycols <- c("royalblue", "red", "#009900", "dark orange", "#999999",
> >> "#a6761d", "#aa00da")
> >> mycols <- c("#010101", "#EEEEEE", "#AA0000", "#00AA00", "#0000AA",
> >> "#AAAA00", "#AA00AA", "#00AAAA")
> >> mycols <- c("#010101", "#090909", "#090000", "#000900", "#000009",
> >> "#090900", "#090009", "#000909")
> >> oldnew <- c(mycols, rgb2col(mycols, near=.25)) # Also try near=10
> >> pie(rep(1,2*length(mycols)), labels=oldnew, col=oldnew)
> >>
> >> 	[[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> 
> 
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Sat Jun  1 18:44:23 2013
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 1 Jun 2013 12:44:23 -0400
Subject: [R] measuring distances between colours?
In-Reply-To: <A8E5759F-C0BC-4033-B4F3-A327554B7CEA@inserm.fr>
References: <4382_1369916184_r4UCGK5j024861_web-459777071@cgpsrv2.cis.mcmaster.ca>	<004601ce5d7a$9f16fc00$dd44f400$@mcmaster.ca>	<51A8B263.8040905@yorku.ca>	<32399_1370100869_51AA1485_32399_14449_1_000e01ce5edd$0a2e4170$1e8ac450$@mcmaster.ca>
	<A8E5759F-C0BC-4033-B4F3-A327554B7CEA@inserm.fr>
Message-ID: <001001ce5ee7$463492f0$d29db8d0$@mcmaster.ca>

Hi Ken,

I just tried that, and with a distance of 15 as the criterion, which seemed to work well for Lav distances, I get fewer matches for the following example that we've been using:

> cols <- c("#010101", "#EEEEEE", "#AA0000", "#00AA00", "#0000AA", "#AAAA00", "#AA00AA", "#00AAAA")
> (nms <- rgb2col(cols, near=15))
[1] "black"         "gray93"        "firebrick"     "#00AA00"      
[5] "#0000AA"       "#AAAA00"       "#AA00AA"       "lightseagreen"

Do you know what a JND is supposed to be on the Luv distance scale? The Wikipedia article on CIELUV colours doesn't say.

Best,
 John

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Ken Knoblauch
> Sent: Saturday, June 01, 2013 12:18 PM
> To: John Fox
> Cc: <r-help at r-project.org>; Michael Friendly; Martin Maechler
> Subject: Re: [R] measuring distances between colours?
> 
> Hi John,
> 
> Out of curiosity and if it is not much trouble, I would be curious if
> Luv worked any better than Lab. I think that Luv is supposed to be
> preferred for monitors and Lab for surfaces but they are generally
> pretty similar.
> 
> Best,
> 
> Ken
> 
> Sent from my iPhone
> 
> ___
> Ken Knoblauch
> Inserm U846
> Stem-Cell and Brain Research Institute
> 18 av du Doyen L?pine
> 69500 Bron France
> Tel : 04 72 91 34 77
> Fax :  04 72 91 34 61
> portable : 06 84 10 64 10
> http://www.sbri.fr/members/kenneth-knoblauch.html
> 
> On 1 juin 2013, at 17:31, "John Fox" <jfox at mcmaster.ca> wrote:
> 
> > Hi Michael,
> >
> > Thanks for the Wikipedia tip -- I'd looked there but didn't find this
> > article. The article explains that the Lab colour space was
> formulated to
> > provide uniform perceptual differences between colours, with a JND of
> > approximately of 2.3. Ken Knoblauch made a similar point. The article
> goes
> > on to describe relatively complicated adjustments meant to improve
> the LAV
> > distance metric, which are probably overkill for my application.
> >
> > I've programmed Lab colour matching as follows, using Euclidean
> distances
> > and adapting Kevin Wright's modification of my original code. I used
> > convertColor(), which Martin Maechler pointed out to me.
> >
> > ----------- snip --------------
> >
> > r2c <- function(){
> >    all.names <- colors()
> >    all.lab <- t(convertColor(t(col2rgb(all.names)), from="sRGB",
> to="Lab",
> > scale.in=255))
> >    find.near <- function(x.lab) {
> >        sq.dist <- colSums((all.lab - x.lab)^2)
> >        rbind(all.names[which.min(sq.dist)], min(sq.dist))
> >    }
> >    function(cols.hex, near=2.3){
> >        cols.lab <- t(convertColor(t(col2rgb(cols.hex)), from="sRGB",
> > to="Lab", scale.in=255))
> >        cols.near <- apply(cols.lab, 2, find.near)
> >        ifelse(cols.near[2, ] < near^2, cols.near[1, ], cols.hex)
> >    }
> > }
> >
> > rgb2col <- r2c()
> >
> > ----------- snip --------------
> >
> > A bit of experimentation suggests that this works better than using
> (as I
> > did previously) direct RGB distances, matching more colours to names
> and
> > providing (to my eye, with my monitor) perceptually closer matches,
> though
> > sometimes with (again to my eye) perceptible differences. Here's an
> > illustration, adapting one of Kevin's examples:
> >
> > ----------- snip --------------
> >
> > cols <- c("#010101", "#EEEEEE", "#AA0000", "#00AA00", "#0000AA",
> "#AAAA00",
> > "#AA00AA", "#00AAAA")
> > (nms <- rgb2col(cols))
> > pie(rep(1, 2*length(cols)), labels=c(cols, nms), col=c(cols, nms))
> >
> > ----------- snip --------------
> >
> > Thanks again to everyone who responded to my original, na?ve,
> question.
> >
> > Best,
> > John
> >
> >> -----Original Message-----
> >> From: Michael Friendly [mailto:friendly at yorku.ca]
> >> Sent: Friday, May 31, 2013 10:24 AM
> >> To: John Fox
> >> Cc: r-help at r-project.org; 'Martin Maechler'
> >> Subject: Re: measuring distances between colours?
> >>
> >> Hi John
> >> This has been an interesting discussion.
> >> Though you have a solution for your needs, you might be interested
> in
> >> this javascript implementation that allows you to visually compare
> >> color
> >> distances in various color spaces
> >>
> >> http://stevehanov.ca/blog/index.php?id=116
> >>
> >> And, all the theory of color distance is described in
> >> http://en.wikipedia.org/wiki/Color_difference
> >>
> >> PS: This is a very handy function.  When I last tried
> >> aplpack::bagplot(), it was annoying that the colors could *only*
> >> be specified in hex.
> >>
> >> -Michael
> >>
> >>
> >>
> >> On 5/30/2013 5:14 PM, John Fox wrote:
> >>> Dear all,
> >>>
> >>> My thanks to everyone who addressed my question. I've incorporated
> >> Eik
> >>> Vettorazzi's suggestion for improved conversion of hexadecimal RGB
> >> colours
> >>> to decimal numbers, and Martin Maechler's hint to look at
> >> demo(colors). I've
> >>> loosened the default definition of "close enough" from the latter,
> >> since the
> >>> following seems to work well for my purposes.
> >>>
> >>> r2c <- function(){
> >>>     hex2dec <- function(hexnums) {
> >>>         # suggestion of Eik Vettorazzi
> >>>         sapply(strtoi(hexnums, 16L), function(x) x %/% 256^(2:0) %%
> >> 256)
> >>>     }
> >>>     findMatch <- function(dec.col) {
> >>>         sq.dist <- colSums((hsv - dec.col)^2)
> >>>         rbind(which.min(sq.dist), min(sq.dist))
> >>>     }
> >>>     colors <- colors()
> >>>     hsv <- rgb2hsv(col2rgb(colors))
> >>>     function(cols, near=0.25){
> >>>         cols <- sub("^#", "", toupper(cols))
> >>>         dec.cols <- rgb2hsv(hex2dec(cols))
> >>>         which.col <- apply(dec.cols, 2, findMatch)
> >>>         matches <- colors[which.col[1, ]]
> >>>         unmatched <- which.col[2, ] > near^2
> >>>         matches[unmatched] <- paste("#", cols[unmatched], sep="")
> >>>         matches
> >>>     }
> >>> }
> >>>
> >>> rgb2col <- r2c()
> >>>
> >>> For example,
> >>>
> >>>> rgb2col(c("010101", "EEEEEE", "AA0000", "00AA00", "0000AA",
> >> "AAAA00",
> >>> "AA00AA", "00AAAA"))
> >>> [1] "black"         "gray93"        "darkred"       "green4"
> >>> [5] "blue4"         "darkgoldenrod" "darkmagenta"   "cyan4"
> >>>
> >>>> rgb2col(c("010101", "090909", "090000", "000900", "000009",
> >> "090900",
> >>> "090009", "000909"))
> >>> [1] "black"   "gray3"   "#090000" "#000900" "#000009" "#090900"
> >>> [7] "#090009" "#000909"
> >>>
> >>> Thanks again,
> >>>  John
> >>
> >>
> >> --
> >> Michael Friendly     Email: friendly AT yorku DOT ca
> >> Professor, Psychology Dept. & Chair, Quantitative Methods
> >> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> >> 4700 Keele Street    Web:   http://www.datavis.ca
> >> Toronto, ONT  M3J 1P3 CANADA
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From friendly at yorku.ca  Sat Jun  1 19:33:42 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Sat, 01 Jun 2013 13:33:42 -0400
Subject: [R] measuring distances between colours?
In-Reply-To: <000e01ce5edd$0a2e4170$1e8ac450$@mcmaster.ca>
References: <4382_1369916184_r4UCGK5j024861_web-459777071@cgpsrv2.cis.mcmaster.ca>
	<004601ce5d7a$9f16fc00$dd44f400$@mcmaster.ca>
	<51A8B263.8040905@yorku.ca>
	<000e01ce5edd$0a2e4170$1e8ac450$@mcmaster.ca>
Message-ID: <51AA3076.2030008@yorku.ca>

Hi John
I agree that the Lab representation is the best so far for the goal of 
perceptually
similar colors, and the approximate JND of
2.3 on the distance scale in this space is a useful, non-arbitrary 
criterion.

FWIW, your demo might better show the hex and color names adjacently, 
for direct
comparison.

cols <- c("#010101", "#EEEEEE", "#AA0000", "#00AA00", "#0000AA", "#AAAA00",
"#AA00AA", "#00AAAA")
(nms <- rgb2col(cols))
pie(rep(1, 2*length(cols)), labels=c(rbind(cols, nms)), 
col=c(rbind(cols, nms)))

-Michael

On 6/1/2013 11:31 AM, John Fox wrote:
> Hi Michael,
>
> Thanks for the Wikipedia tip -- I'd looked there but didn't find this
> article. The article explains that the Lab colour space was formulated to
> provide uniform perceptual differences between colours, with a JND of
> approximately of 2.3. Ken Knoblauch made a similar point. The article goes
> on to describe relatively complicated adjustments meant to improve the LAV
> distance metric, which are probably overkill for my application.
>
> I've programmed Lab colour matching as follows, using Euclidean distances
> and adapting Kevin Wright's modification of my original code. I used
> convertColor(), which Martin Maechler pointed out to me.
>
> ----------- snip --------------
>
> r2c <- function(){
>      all.names <- colors()
>      all.lab <- t(convertColor(t(col2rgb(all.names)), from="sRGB", to="Lab",
> scale.in=255))
>      find.near <- function(x.lab) {
>          sq.dist <- colSums((all.lab - x.lab)^2)
>          rbind(all.names[which.min(sq.dist)], min(sq.dist))
>      }
>      function(cols.hex, near=2.3){
>          cols.lab <- t(convertColor(t(col2rgb(cols.hex)), from="sRGB",
> to="Lab", scale.in=255))
>          cols.near <- apply(cols.lab, 2, find.near)
>          ifelse(cols.near[2, ] < near^2, cols.near[1, ], cols.hex)
>      }
> }
>
> rgb2col <- r2c()
>
> ----------- snip --------------
>
> A bit of experimentation suggests that this works better than using (as I
> did previously) direct RGB distances, matching more colours to names and
> providing (to my eye, with my monitor) perceptually closer matches, though
> sometimes with (again to my eye) perceptible differences. Here's an
> illustration, adapting one of Kevin's examples:
>
> ----------- snip --------------
>
> cols <- c("#010101", "#EEEEEE", "#AA0000", "#00AA00", "#0000AA", "#AAAA00",
> "#AA00AA", "#00AAAA")
> (nms <- rgb2col(cols))
> pie(rep(1, 2*length(cols)), labels=c(cols, nms), col=c(cols, nms))
>
> ----------- snip --------------
>
> Thanks again to everyone who responded to my original, na?ve, question.
>
> Best,
>   John
>
>> -----Original Message-----
>> From: Michael Friendly [mailto:friendly at yorku.ca]
>> Sent: Friday, May 31, 2013 10:24 AM
>> To: John Fox
>> Cc: r-help at r-project.org; 'Martin Maechler'
>> Subject: Re: measuring distances between colours?
>>
>> Hi John
>> This has been an interesting discussion.
>> Though you have a solution for your needs, you might be interested in
>> this javascript implementation that allows you to visually compare
>> color
>> distances in various color spaces
>>
>> http://stevehanov.ca/blog/index.php?id=116
>>
>> And, all the theory of color distance is described in
>> http://en.wikipedia.org/wiki/Color_difference
>>
>> PS: This is a very handy function.  When I last tried
>> aplpack::bagplot(), it was annoying that the colors could *only*
>> be specified in hex.
>>
>> -Michael
>>
>>
>>
>> On 5/30/2013 5:14 PM, John Fox wrote:
>>> Dear all,
>>>
>>> My thanks to everyone who addressed my question. I've incorporated
>> Eik
>>> Vettorazzi's suggestion for improved conversion of hexadecimal RGB
>> colours
>>> to decimal numbers, and Martin Maechler's hint to look at
>> demo(colors). I've
>>> loosened the default definition of "close enough" from the latter,
>> since the
>>> following seems to work well for my purposes.
>>>
>>> r2c <- function(){
>>>       hex2dec <- function(hexnums) {
>>>           # suggestion of Eik Vettorazzi
>>>           sapply(strtoi(hexnums, 16L), function(x) x %/% 256^(2:0) %%
>> 256)
>>>       }
>>>       findMatch <- function(dec.col) {
>>>           sq.dist <- colSums((hsv - dec.col)^2)
>>>           rbind(which.min(sq.dist), min(sq.dist))
>>>       }
>>>       colors <- colors()
>>>       hsv <- rgb2hsv(col2rgb(colors))
>>>       function(cols, near=0.25){
>>>           cols <- sub("^#", "", toupper(cols))
>>>           dec.cols <- rgb2hsv(hex2dec(cols))
>>>           which.col <- apply(dec.cols, 2, findMatch)
>>>           matches <- colors[which.col[1, ]]
>>>           unmatched <- which.col[2, ] > near^2
>>>           matches[unmatched] <- paste("#", cols[unmatched], sep="")
>>>           matches
>>>       }
>>> }
>>>
>>> rgb2col <- r2c()
>>>
>>> For example,
>>>
>>>> rgb2col(c("010101", "EEEEEE", "AA0000", "00AA00", "0000AA",
>> "AAAA00",
>>> "AA00AA", "00AAAA"))
>>> [1] "black"         "gray93"        "darkred"       "green4"
>>> [5] "blue4"         "darkgoldenrod" "darkmagenta"   "cyan4"
>>>
>>>> rgb2col(c("010101", "090909", "090000", "000900", "000009",
>> "090900",
>>> "090009", "000909"))
>>> [1] "black"   "gray3"   "#090000" "#000900" "#000009" "#090900"
>>> [7] "#090009" "#000909"
>>>
>>> Thanks again,
>>>    John
>>
>> --
>> Michael Friendly     Email: friendly AT yorku DOT ca
>> Professor, Psychology Dept. & Chair, Quantitative Methods
>> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
>> 4700 Keele Street    Web:   http://www.datavis.ca
>> Toronto, ONT  M3J 1P3 CANADA
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From ken.knoblauch at inserm.fr  Sat Jun  1 19:42:34 2013
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Sat, 1 Jun 2013 19:42:34 +0200
Subject: [R] measuring distances between colours?
In-Reply-To: <32399_1370105184_51AA2560_32399_15724_1_001001ce5ee7$463492f0$d29db8d0$@mcmaster.ca>
References: <4382_1369916184_r4UCGK5j024861_web-459777071@cgpsrv2.cis.mcmaster.ca>
	<004601ce5d7a$9f16fc00$dd44f400$@mcmaster.ca>
	<51A8B263.8040905@yorku.ca>
	<32399_1370100869_51AA1485_32399_14449_1_000e01ce5edd$0a2e4170$1e8ac450$@mcmaster.ca>
	<A8E5759F-C0BC-4033-B4F3-A327554B7CEA@inserm.fr>
	<32399_1370105184_51AA2560_32399_15724_1_001001ce5ee7$463492f0$d29db8d0$@mcmaster.ca>
Message-ID: <E49A41BF-3B85-469D-8A0F-1E3CF976DC27@inserm.fr>

I'd have to look it up and I'm not home at the moment. Can see later on. I would have thought that it would be normalized to have a jnd equal to 1 but I'm not sure. 

Ken

Sent from my iPhone

___
Ken Knoblauch
Inserm U846
Stem-Cell and Brain Research Institute
18 av du Doyen L?pine
69500 Bron France
Tel : 04 72 91 34 77
Fax :  04 72 91 34 61
portable : 06 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html

On 1 juin 2013, at 18:44, "John Fox" <jfox at mcmaster.ca> wrote:

> Hi Ken,
> 
> I just tried that, and with a distance of 15 as the criterion, which seemed to work well for Lav distances, I get fewer matches for the following example that we've been using:
> 
>> cols <- c("#010101", "#EEEEEE", "#AA0000", "#00AA00", "#0000AA", "#AAAA00", "#AA00AA", "#00AAAA")
>> (nms <- rgb2col(cols, near=15))
> [1] "black"         "gray93"        "firebrick"     "#00AA00"      
> [5] "#0000AA"       "#AAAA00"       "#AA00AA"       "lightseagreen"
> 
> Do you know what a JND is supposed to be on the Luv distance scale? The Wikipedia article on CIELUV colours doesn't say.
> 
> Best,
> John
> 
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Ken Knoblauch
>> Sent: Saturday, June 01, 2013 12:18 PM
>> To: John Fox
>> Cc: <r-help at r-project.org>; Michael Friendly; Martin Maechler
>> Subject: Re: [R] measuring distances between colours?
>> 
>> Hi John,
>> 
>> Out of curiosity and if it is not much trouble, I would be curious if
>> Luv worked any better than Lab. I think that Luv is supposed to be
>> preferred for monitors and Lab for surfaces but they are generally
>> pretty similar.
>> 
>> Best,
>> 
>> Ken
>> 
>> Sent from my iPhone
>> 
>> ___


From annijanh at gmail.com  Sat Jun  1 19:52:01 2013
From: annijanh at gmail.com (Janh Anni)
Date: Sat, 1 Jun 2013 13:52:01 -0400
Subject: [R] Fwd: Your message to R-help awaits moderator approval
In-Reply-To: <mailman.6550.1370108896.4595.r-help@r-project.org>
References: <mailman.6550.1370108896.4595.r-help@r-project.org>
Message-ID: <CAFCoDdCr2KsXZFYNNWkO3+JiSj8hz7dQFXJ27P39ZMRxPi1rhw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130601/f1a126f8/attachment.pl>

From ruipbarradas at sapo.pt  Sat Jun  1 20:41:52 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 01 Jun 2013 19:41:52 +0100
Subject: [R] How to compute a P-value for a complex mixture of
 chi-squared distributions in R
In-Reply-To: <1CAE97A5-0B40-49CA-AC3F-D387D5EBA8EA@gmail.com>
References: <54649.201.81.178.2.1370061142.squirrel@webmail.mbe.bio.br>
	<1CAE97A5-0B40-49CA-AC3F-D387D5EBA8EA@gmail.com>
Message-ID: <51AA4070.90502@sapo.pt>

Hello,

No, nothing wrong. (I feel silly for not having noticed it.) In fact not 
only it's much simpler but it's also more accurate than the use of 
accurate with the default rel.tol.
It should be better, however, to use lower.tail = FALSE, since the op 
wants p-values.

0.5 * pchisq(x^2, 1, lower.tail = FALSE) + 0.5 * pchisq(x^2, 2, 
lower.tail = FALSE)

Rui Barradas

Em 01-06-2013 14:57, peter dalgaard escreveu:
>
> On Jun 1, 2013, at 06:32 , Tiago V. Pereira wrote:
>
>> Hello, R users!
>>
>> I am struggling with the following problem:
>>
>> I need to compute a P-value for a mixture of two chi-squared
>> distributions. My P-value is given by:
>>
>> P = 0.5*prob(sqrt(chi2(1)) <= x) + 0.5*prob(sqrt(chi2(2)) <= x)
>>
>> In words, I need to compute the p-value for 50?50 mixture of the square
>> root of a chi-squared random variable with 1 degree of freedom and the
>> square root of a chi-squared with two degrees of freedom.
>>
>> Although I can quickly simulate data, the P-values I am looking for are at
>> the tail of the distribution, that is, alpha levels below 10^-7. Hence,
>> simulation is not efficient.
>>
>> Are you aware of smart approach?
>
> Er,...
>
> Anything wrong with
>
> 0.5 * pchisq(x^2, 1) + 0.5 * pchisq(x^2, 2)
>
> ???
>
> -pd
>
>
>>
>>
>> All the best,
>>
>> Tiago
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From tiago.pereira at mbe.bio.br  Sat Jun  1 20:52:45 2013
From: tiago.pereira at mbe.bio.br (Tiago V. Pereira)
Date: Sat, 1 Jun 2013 15:52:45 -0300 (BRT)
Subject: [R] How to compute a P-value for a complex mixture of
 chi-squared distributions in R
In-Reply-To: <51AA4070.90502@sapo.pt>
References: <54649.201.81.178.2.1370061142.squirrel@webmail.mbe.bio.br>
	<1CAE97A5-0B40-49CA-AC3F-D387D5EBA8EA@gmail.com>
	<51AA4070.90502@sapo.pt>
Message-ID: <39468.201.81.178.2.1370112765.squirrel@webmail.mbe.bio.br>

Thank you very much, Rui and Peter, for you detailed and helpful tips!

It worked like a charm! I would spend more two weeks (or more) to figure
out that by myself.

Cheers!

Tiago

> Hello,
>
> No, nothing wrong. (I feel silly for not having noticed it.) In fact not
> only it's much simpler but it's also more accurate than the use of
> accurate with the default rel.tol.
> It should be better, however, to use lower.tail = FALSE, since the op
> wants p-values.
>
> 0.5 * pchisq(x^2, 1, lower.tail = FALSE) + 0.5 * pchisq(x^2, 2,
> lower.tail = FALSE)
>
> Rui Barradas
>
> Em 01-06-2013 14:57, peter dalgaard escreveu:
>>
>> On Jun 1, 2013, at 06:32 , Tiago V. Pereira wrote:
>>
>>> Hello, R users!
>>>
>>> I am struggling with the following problem:
>>>
>>> I need to compute a P-value for a mixture of two chi-squared
>>> distributions. My P-value is given by:
>>>
>>> P = 0.5*prob(sqrt(chi2(1)) <= x) + 0.5*prob(sqrt(chi2(2)) <= x)
>>>
>>> In words, I need to compute the p-value for 50?50 mixture of the square
>>> root of a chi-squared random variable with 1 degree of freedom and the
>>> square root of a chi-squared with two degrees of freedom.
>>>
>>> Although I can quickly simulate data, the P-values I am looking for are
>>> at
>>> the tail of the distribution, that is, alpha levels below 10^-7. Hence,
>>> simulation is not efficient.
>>>
>>> Are you aware of smart approach?
>>
>> Er,...
>>
>> Anything wrong with
>>
>> 0.5 * pchisq(x^2, 1) + 0.5 * pchisq(x^2, 2)
>>
>> ???
>>
>> -pd
>>
>>
>>>
>>>
>>> All the best,
>>>
>>> Tiago
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From Ted.Harding at wlandres.net  Sat Jun  1 21:11:05 2013
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Sat, 01 Jun 2013 20:11:05 +0100 (BST)
Subject: [R] Fwd: Your message to R-help awaits moderator approval
In-Reply-To: <CAFCoDdCr2KsXZFYNNWkO3+JiSj8hz7dQFXJ27P39ZMRxPi1rhw@mail.gmail.com>
Message-ID: <XFMail.20130601201105.Ted.Harding@wlandres.net>

[See at end]

On 01-Jun-2013 17:52:01 Janh Anni wrote:
> Hello,
> 
> I don't understand why my mails are being held up.  What could be the
> problem?
> 
> Thanks
> Janh
> ---------- Forwarded message ----------
> From: <r-help-bounces at r-project.org>
> Date: Sat, Jun 1, 2013 at 1:48 PM
> Subject: Your message to R-help awaits moderator approval
> To: annijanh at gmail.com
> 
> 
> Your mail to 'R-help' with the subject
> 
>     Re: [R] wilcox_test function in coin package
> 
> Is being held until the list moderator can review it for approval.
> 
> The reason it is being held:
> 
>     The message headers matched a filter rule
> 
> Either the message will get posted to the list, or you will receive
> notification of the moderator's decision.  If you would like to cancel
> this posting, please visit the following URL:
> 
> https://stat.ethz.ch/mailman/confirm/r-help/067afe28f7ead30dfea844b8a34449526c
> d665d8

This can happen to anyone, depending on the current sensitivity
of the mail-server's spam-detection filter to potential
"triggers" in the message.

It is particularly likely to arise with mails posted from a gmail
account, as your was. This is because gmail is a major source of
spam emails, and the spam filter is alert to these.

I have had a look at your message (which was duly approved), and
I see that it is in reply to a message which itself is in a thread
that includes several messages sent via gmail. From the headers
of your message:

In-Reply-To: <51A9291C.70509 at ucalgary.ca>
References:
<CAFCoDdDp64MFyvTTB6b_O6KgoTKYR41mCB2sPCC4c6ANQyWx1Q at mail.gmail.com>
<CAFEqCdy6+NhK2hgcWQALYmYXx1a0tRqJTHYBXx-FUb9OYfFUKA at mail.gmail.com>
 <CAFCoDdBcm4B1tVW7BarkHXAgpqMpTCimmjhrLc3N7=yvSSEbbw at mail.gmail.com>
 <CAFEqCdz_=YBeeDYLfpDYyTAwjr6a4n2OKTbQaBsb9UC=G9sAag at mail.gmail.com>
 <CAFCoDdC1asW6JGK5huY_kLgCQQCduw8s=YjhHDP0ptA_9YAhhw at mail.gmail.com>
 <51A9291C.70509 at ucalgary.ca>

so that's a total of 6 references to gmail (including your own message)
which is probably why the spam filter felt a bit twitchy!

Don't worry about it. As I say, it can happen to anyone (though more
often to some than to others). If it is a proper message to R-help,
one of the moderators will approve it (though quite possible not
immediately).

Hoping this helps,
Ted (one of the moderators)

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 01-Jun-2013  Time: 20:11:00
This message was sent by XFMail


From jgrn at illinois.edu  Sat Jun  1 22:01:19 2013
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Sat, 1 Jun 2013 15:01:19 -0500
Subject: [R] Official way to set/retrieve options in packages?
Message-ID: <CABG0rfskpFF8T+i9OKCBNRGyCS_rn7L1PVO4RO0NivWo0a7jGQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130601/62dc43a2/attachment.pl>

From ron_michael70 at yahoo.com  Sat Jun  1 22:14:58 2013
From: ron_michael70 at yahoo.com (Ron Michael)
Date: Sun, 2 Jun 2013 04:14:58 +0800 (SGT)
Subject: [R] Need to download data from internet
Message-ID: <1370117698.36063.YahooMailNeo@web190506.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130602/387a9838/attachment.pl>

From gunter.berton at gene.com  Sat Jun  1 22:21:39 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 1 Jun 2013 13:21:39 -0700
Subject: [R] Need to download data from internet
In-Reply-To: <1370117698.36063.YahooMailNeo@web190506.mail.sg3.yahoo.com>
References: <1370117698.36063.YahooMailNeo@web190506.mail.sg3.yahoo.com>
Message-ID: <CACk-te1GFEmQnSuqFaL1s7AQsw_0VEs5z8i4bJCjRGLtxVyQ+A@mail.gmail.com>

Google is your friend!

A google search on "download internet data in R" brought up this:

http://www.slideshare.net/schamber/web-data-from-r

-- Bert

On Sat, Jun 1, 2013 at 1:14 PM, Ron Michael <ron_michael70 at yahoo.com> wrote:
> Hi,
>
> I need to dowload a time series with arbitray start date and end date, from this site:
>
> http://www.mcxindia.com/sitepages/SpotMarketHistory.aspx?sLinkPage=Y
>
> While I can download my required data manually, I would like R to do that for me. I have tried 'quandl' package, however could not find any such data available to download. Can somebody point me some R function which can help me to download that data automatically?
>
> Regards,
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From annijanh at gmail.com  Sat Jun  1 22:22:13 2013
From: annijanh at gmail.com (Janh Anni)
Date: Sat, 1 Jun 2013 16:22:13 -0400
Subject: [R] Fwd: Your message to R-help awaits moderator approval
In-Reply-To: <XFMail.20130601201105.Ted.Harding@wlandres.net>
References: <CAFCoDdCr2KsXZFYNNWkO3+JiSj8hz7dQFXJ27P39ZMRxPi1rhw@mail.gmail.com>
	<XFMail.20130601201105.Ted.Harding@wlandres.net>
Message-ID: <CAFCoDdANGJLxFxdwjZgd9jvs5RE24zmDWTAFKdq4uRsi_5tMYg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130601/137a2b1a/attachment.pl>

From ruipbarradas at sapo.pt  Sat Jun  1 23:21:44 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 01 Jun 2013 22:21:44 +0100
Subject: [R] How to compute a P-value for a complex mixture of
 chi-squared distributions in R
In-Reply-To: <51AA4070.90502@sapo.pt>
References: <54649.201.81.178.2.1370061142.squirrel@webmail.mbe.bio.br>
	<1CAE97A5-0B40-49CA-AC3F-D387D5EBA8EA@gmail.com>
	<51AA4070.90502@sapo.pt>
Message-ID: <51AA65E8.1070905@sapo.pt>

Inline.

Em 01-06-2013 19:41, Rui Barradas escreveu:
> Hello,
>
> No, nothing wrong. (I feel silly for not having noticed it.) In fact not
> only it's much simpler but it's also more accurate than the use of
> accurate with the default rel.tol.

Correction: "...than the use of _integrate()_ with the default rel.tol."

Rui Barradas

> It should be better, however, to use lower.tail = FALSE, since the op
> wants p-values.
>
> 0.5 * pchisq(x^2, 1, lower.tail = FALSE) + 0.5 * pchisq(x^2, 2,
> lower.tail = FALSE)
>
> Rui Barradas
>
> Em 01-06-2013 14:57, peter dalgaard escreveu:
>>
>> On Jun 1, 2013, at 06:32 , Tiago V. Pereira wrote:
>>
>>> Hello, R users!
>>>
>>> I am struggling with the following problem:
>>>
>>> I need to compute a P-value for a mixture of two chi-squared
>>> distributions. My P-value is given by:
>>>
>>> P = 0.5*prob(sqrt(chi2(1)) <= x) + 0.5*prob(sqrt(chi2(2)) <= x)
>>>
>>> In words, I need to compute the p-value for 50?50 mixture of the square
>>> root of a chi-squared random variable with 1 degree of freedom and the
>>> square root of a chi-squared with two degrees of freedom.
>>>
>>> Although I can quickly simulate data, the P-values I am looking for
>>> are at
>>> the tail of the distribution, that is, alpha levels below 10^-7. Hence,
>>> simulation is not efficient.
>>>
>>> Are you aware of smart approach?
>>
>> Er,...
>>
>> Anything wrong with
>>
>> 0.5 * pchisq(x^2, 1) + 0.5 * pchisq(x^2, 2)
>>
>> ???
>>
>> -pd
>>
>>
>>>
>>>
>>> All the best,
>>>
>>> Tiago
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ajdamico at gmail.com  Sat Jun  1 23:44:04 2013
From: ajdamico at gmail.com (Anthony Damico)
Date: Sat, 1 Jun 2013 17:44:04 -0400
Subject: [R] Official way to set/retrieve options in packages?
In-Reply-To: <CABG0rfskpFF8T+i9OKCBNRGyCS_rn7L1PVO4RO0NivWo0a7jGQ@mail.gmail.com>
References: <CABG0rfskpFF8T+i9OKCBNRGyCS_rn7L1PVO4RO0NivWo0a7jGQ@mail.gmail.com>
Message-ID: <CAOwvMDz0kzspV8se-gB+7u2WAUghNi99fONcvEofPiVjfEjQng@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130601/ccfb2ed5/attachment.pl>

From ripley at stats.ox.ac.uk  Sat Jun  1 23:57:38 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 01 Jun 2013 22:57:38 +0100
Subject: [R] Official way to set/retrieve options in packages?
In-Reply-To: <CAOwvMDz0kzspV8se-gB+7u2WAUghNi99fONcvEofPiVjfEjQng@mail.gmail.com>
References: <CABG0rfskpFF8T+i9OKCBNRGyCS_rn7L1PVO4RO0NivWo0a7jGQ@mail.gmail.com>
	<CAOwvMDz0kzspV8se-gB+7u2WAUghNi99fONcvEofPiVjfEjQng@mail.gmail.com>
Message-ID: <51AA6E52.2060402@stats.ox.ac.uk>

On 01/06/2013 22:44, Anthony Damico wrote:
> hope this helps..  :)
>
>      # define an object `x`
>      x <- list( "any value here" , 10 )
>
>      # set `myoption` to that object
>      options( "myoption" = x )
>
>      # retrieve it later (perhaps within a function elsewhere in the package)
>      ( y <- getOption( myoption ) )
>
>
> it's nice to name your options `mypackage.myoption` so users know what
> package the option is associated with in case they type `options()`
>
>
> here's the `.onLoad` function in the R survey package.  notice how the
> options are only set *if* they don't already exist--

But a nicer convention is that used by most packages in R itself: if the 
option is not set, the function using it assumes a suitable default. 
That would make sense for all the FALSE defaults below.

Note though that this is not 'persistent': users have to set options in 
their startup files (see ?Startup).   There is no official location to 
store package configurations.  Users generally dislike software saving 
settings in their own file space so it seems very much preferable to use 
the standard R mechanisms (.Rprofile etc).

>
>> survey:::.onLoad
>
> function (...)
> {
>      if (is.null(getOption("survey.lonely.psu")))
> options(survey.lonely.psu = "fail")
>      if (is.null(getOption("survey.ultimate.cluster")))
> options(survey.ultimate.cluster = FALSE)
>      if (is.null(getOption("survey.want.obsolete")))
> options(survey.want.obsolete = FALSE)
>      if (is.null(getOption("survey.adjust.domain.lonely")))
> options(survey.adjust.domain.lonely = FALSE)
>      if (is.null(getOption("survey.drop.replicates")))
> options(survey.drop.replicates = TRUE)
>      if (is.null(getOption("survey.multicore")))
> options(survey.multicore = FALSE)
>      if (is.null(getOption("survey.replicates.mse")))
> options(survey.replicates.mse = FALSE)
> }
> <environment: namespace:survey>
>
>
>
>
> On Sat, Jun 1, 2013 at 4:01 PM, Jonathan Greenberg <jgrn at illinois.edu>wrote:
>
>> R-helpers:
>>
>> Say I'm developing a package that has a set of user-definable options that
>> I would like to be persistent across R-invocations (they are saved
>> someplace).  Of course, I can create a little text file to be written/read,
>> but I was wondering if there is an "officially sanctioned" way to do this?
>>   I see there is an options() and getOptions() function, but I'm unclear how
>> I would use this in my own package to create/save new options for my
>> particular package.  Cheers!
>>
>> --j
>>
>> --
>> Jonathan A. Greenberg, PhD
>> Assistant Professor
>> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>> Department of Geography and Geographic Information Science
>> University of Illinois at Urbana-Champaign
>> 607 South Mathews Avenue, MC 150
>> Urbana, IL 61801
>> Phone: 217-300-1924
>> http://www.geog.illinois.edu/~jgrn/
>> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jannetta at henning.org  Sun Jun  2 02:50:28 2013
From: jannetta at henning.org (Jannetta Steyn)
Date: Sun, 2 Jun 2013 01:50:28 +0100
Subject: [R] object not found
Message-ID: <CAGR4ry4+vxeZh2=q7Zbh+SCgcvbf7mcSasMTKu0z+ecuTypi4g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130602/7af36105/attachment.pl>

From jholtman at gmail.com  Sun Jun  2 03:14:25 2013
From: jholtman at gmail.com (jim holtman)
Date: Sat, 1 Jun 2013 21:14:25 -0400
Subject: [R] object not found
In-Reply-To: <CAGR4ry4+vxeZh2=q7Zbh+SCgcvbf7mcSasMTKu0z+ecuTypi4g@mail.gmail.com>
References: <CAGR4ry4+vxeZh2=q7Zbh+SCgcvbf7mcSasMTKu0z+ecuTypi4g@mail.gmail.com>
Message-ID: <CAAxdm-6StMeT73usaW8UNbQQR2CmGH942ofMTjt4K_KGZXYO5Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130601/7bf5de66/attachment.pl>

From emhanlon at go.olemiss.edu  Sat Jun  1 23:12:21 2013
From: emhanlon at go.olemiss.edu (emhanlon)
Date: Sat, 1 Jun 2013 14:12:21 -0700 (PDT)
Subject: [R] metafor mixed-effect models: testing different predictor
 combinations for lowest AIC
Message-ID: <1370121141774-4668486.post@n4.nabble.com>

Good afternoon,


I am trying to use a mixed-effect model to find the best predictors of
wildlife response (fledgling success, offspring growth rate, etc...) to
human disturbance. I am using a Log Response Ratio as my measure of effect
size along with study variance, and testing to see how: habitat, diet, mass,
generation time, sociality, etc... influence how a species responds to
disturbance. I have 9 total predictors, but a sample size that would only
allow for 3, at most, in a model. Does anyone know of any code that could
allow me to automatically test all combinations of 1,2, or 3 predictors to
get the model with the lowest overall AIC?

#Code I had been using in different combinations manually:
> res <- rma(LRR, est_var, mods = cbind(Gentime, Sociality, Season), data =
> data)

#Also, if the best model has more than one predictor, how can you get
specific mean effect sizes for different levels of the #variable, especially
if it is categorical (non-ranked)?


Thank you so much for your help,

Edward  



--
View this message in context: http://r.789695.n4.nabble.com/metafor-mixed-effect-models-testing-different-predictor-combinations-for-lowest-AIC-tp4668486.html
Sent from the R help mailing list archive at Nabble.com.


From nilsson.henric at gmail.com  Sat Jun  1 14:41:59 2013
From: nilsson.henric at gmail.com (Henric Winell)
Date: Sat, 01 Jun 2013 14:41:59 +0200
Subject: [R] wilcox_test function in coin package
In-Reply-To: <CAFCoDdAOHSKSTTD8o+gkdoMppuMW_XhX63zoh-eveBcnE1HVHQ@mail.gmail.com>
References: <CAFCoDdDp64MFyvTTB6b_O6KgoTKYR41mCB2sPCC4c6ANQyWx1Q@mail.gmail.com>
	<CAFEqCdy6+NhK2hgcWQALYmYXx1a0tRqJTHYBXx-FUb9OYfFUKA@mail.gmail.com>
	<CAFCoDdBcm4B1tVW7BarkHXAgpqMpTCimmjhrLc3N7=yvSSEbbw@mail.gmail.com>
	<CAFEqCdz_=YBeeDYLfpDYyTAwjr6a4n2OKTbQaBsb9UC=G9sAag@mail.gmail.com>
	<CAFCoDdC1asW6JGK5huY_kLgCQQCduw8s=YjhHDP0ptA_9YAhhw@mail.gmail.com>
	<51A9291C.70509@ucalgary.ca>
	<CAFCoDdAOHSKSTTD8o+gkdoMppuMW_XhX63zoh-eveBcnE1HVHQ@mail.gmail.com>
Message-ID: <51A9EC17.2000907@gmail.com>

Janh,

Janh Anni skrev 2013-06-01 04:27:
> Hello peter,
>
> Thanks for the comment.  wilcox.exact is simpler as you pointed out but the
> fact that it is no longer being developed is somewhat concerning.

Admittedly, 'coin' is being actively developed and has a lot more bells 
and whistles.  But for something as simple as this, that wouldn't bother 
me at all.  In any case, the 'exactRankTests' package still gets bug 
fixes and the algorithm used in the Wilcoxon case is exactly the same 
for both packages.

However, if you want to stay with 'coin' you can just wrap up Greg's 
proposal in a function:

wilcox_test.default <- function(x, y, ...) {
     data <-
         data.frame(values = c(x, y),
                    group = rep(c("x", "y"), c(length(x), length(y))))
     wilcox_test(values ~ group, data = data, ...)
}

Assuming that both 'coin' and 'exactRankTests are loaded, we can now 
check that it works:

 > set.seed(123)
 > x <- rpois(10, 3)
 > y <- rpois(11, 3.1)
 >
 > wilcox_test(x, y, alternative = "less", distribution = "exact")

         Exact Wilcoxon-Mann-Whitney Test

data:  values by group (x, y)
Z = -0.0715, p-value = 0.4844
alternative hypothesis: true mu is less than 0

 > wilcox.exact(x, y, alternative = "less")

         Exact Wilcoxon rank sum test

data:  x and y
W = 54, p-value = 0.4844
alternative hypothesis: true mu is less than 0


HTH,
Henric



>
> Regards
> Janh
>
>
> On Fri, May 31, 2013 at 6:50 PM, Peter Ehlers <ehlers at ucalgary.ca> wrote:
>
>> On 2013-05-30 20:20, Janh Anni wrote:
>>
>>> Hello Greg,
>>>
>>> Thank you so much for your kind assistance.  It looks like there's no way
>>> around using the formula format.  I longed in vain for a simpler script
>>> more like the wilcox.test format.  Thanks again.
>>>
>>> Janh
>>>
>>
>> I don't see why the formula syntax would be a problem, but to avoid it
>> you could use exactRankTests::wilcox.exact() which, I believe, was
>> written by the same author. It uses the same syntax as wilcox.test().
>> Note, though, that the package is no longer
>> being developed.
>>
>> Peter Ehlers
>>
>>
>>
>>>
>>> On Thu, May 30, 2013 at 6:21 PM, Greg Snow <538280 at gmail.com> wrote:
>>>
>>>   Ok, it looks like the function mainly works through the formula syntax.
>>>>    It still would have been nice to have a reproducible example of what
>>>> your
>>>> data may look like, but I can show an example with simulated x and y:
>>>>
>>>>   x <- rpois(10, 3)
>>>>> y <- rpois(11, 3.1)
>>>>> mydf <- data.frame( vals = c(x,y),
>>>>>
>>>> +   group=rep( c('x','y'), c( length(x), length(y) ) ) )
>>>>
>>>>> wilcox_test( vals ~ group, data=mydf )
>>>>>
>>>>
>>>>           Asymptotic Wilcoxon-Mann-Whitney Test
>>>>
>>>> data:  vals by group (x, y)
>>>> Z = -1.3718, p-value = 0.1701
>>>> alternative hypothesis: true mu is not equal to 0
>>>>
>>>> Does that help?  (maybe I am the heedlessness theorist after all)
>>>>
>>>>
>>>>
>>>> On Thu, May 30, 2013 at 4:14 PM, Janh Anni <annijanh at gmail.com> wrote:
>>>>
>>>>   I thought (hoped) wilcox_test(x,y) would do it but it doesn't and the
>>>>> package maintainer says the data have to be rearranged but does not
>>>>> specify
>>>>> how.  Thanks
>>>>>
>>>>> Janh
>>>>>
>>>>>
>>>>>
>>>>> On Thu, May 30, 2013 at 6:05 PM, Greg Snow <538280 at gmail.com> wrote:
>>>>>
>>>>>   What have you tried so far?  Have you read the help page? have you run
>>>>>> the examples on that page?
>>>>>>
>>>>>> I would expect that it is something as simple as
>>>>>>
>>>>>> library(coin)
>>>>>> wilcox_test(x,y)
>>>>>>
>>>>>> or
>>>>>>
>>>>>> wilcox_test( y ~ group )
>>>>>>
>>>>>> But you should trust the help page more than the expectations of
>>>>>> someone
>>>>>> who has not read it recently (see fortune(14)).
>>>>>>
>>>>>> If that does not answer your question then give us more detail on what
>>>>>> you tried, what you expected the results to be, what the results
>>>>>> actually
>>>>>> were, and how they differed.  Without that information we have to
>>>>>> resort to
>>>>>> mind reading and the current implementation of the esp package is still
>>>>>> very pre-alpha, it suggests that the answer to your question is:
>>>>>>
>>>>>>   esp()
>>>>>>>
>>>>>> [1] "selflessly vigilantly pigeon theorist heedlessness"
>>>>>>
>>>>>> Which is either much to profound for the likes of me to understand or
>>>>>> is
>>>>>> complete gibberish (which is only slightly less helpful than an overly
>>>>>> general question without a reproducible example).
>>>>>>
>>>>>>
>>>>>> On Thu, May 30, 2013 at 2:07 PM, Janh Anni <annijanh at gmail.com> wrote:
>>>>>>
>>>>>>   Dear All,
>>>>>>>
>>>>>>> I have two simple data samples (no groups or factors, etc.) and would
>>>>>>> just
>>>>>>> like to compute the two-sample Wilcoxon Rank Sum test using the
>>>>>>> wilcox_test
>>>>>>> function contained in the coin package, which is reportedly better
>>>>>>> than
>>>>>>> the
>>>>>>> regular wilcox.test function because it performs some adjustment for
>>>>>>> ties.
>>>>>>> Would anyone know how to craft a script to perform this task?  Much
>>>>>>> appreciated.
>>>>>>>
>>>>>>> Janh
>>>>>>>
>>>>>>>           [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> ______________________________**________________
>>>>>>> R-help at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/**posting-guide.html<http://www.R-project.org/posting-guide.html>
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>>>
>>>>>>
>>>>>>
>>>>>> --
>>>>>> Gregory (Greg) L. Snow Ph.D.
>>>>>> 538280 at gmail.com
>>>>>>
>>>>>>
>>>>>
>>>>>
>>>>
>>>> --
>>>> Gregory (Greg) L. Snow Ph.D.
>>>> 538280 at gmail.com
>>>>
>>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________**________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>>> PLEASE do read the posting guide http://www.R-project.org/**
>>> posting-guide.html <http://www.R-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From laomeng_3 at 163.com  Sat Jun  1 17:03:09 2013
From: laomeng_3 at 163.com (meng)
Date: Sat, 1 Jun 2013 23:03:09 +0800 (CST)
Subject: [R] error about MCA
Message-ID: <437ecacf.7226.13f00437ae1.Coremail.laomeng_3@163.com>

Hi,all:
I want to perform multiple correspondance analysis via MCA{FactoMineR}.
The data is in the attachment.

My code:
dat<-read.delim("e:\\mydata.txt",header=T)
MCA(dat,quanti.sup=7,quali.sup=1:6)
Error in `[.data.frame`(tab, , i) : undefined columns selected
 
My question:
Why does the error happen?
 
Many thanks.

Best.
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: mydata.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130601/c5b1f272/attachment.txt>

From annijanh at gmail.com  Sat Jun  1 19:47:59 2013
From: annijanh at gmail.com (Janh Anni)
Date: Sat, 1 Jun 2013 13:47:59 -0400
Subject: [R] wilcox_test function in coin package
In-Reply-To: <51A9EC17.2000907@gmail.com>
References: <CAFCoDdDp64MFyvTTB6b_O6KgoTKYR41mCB2sPCC4c6ANQyWx1Q@mail.gmail.com>
	<CAFEqCdy6+NhK2hgcWQALYmYXx1a0tRqJTHYBXx-FUb9OYfFUKA@mail.gmail.com>
	<CAFCoDdBcm4B1tVW7BarkHXAgpqMpTCimmjhrLc3N7=yvSSEbbw@mail.gmail.com>
	<CAFEqCdz_=YBeeDYLfpDYyTAwjr6a4n2OKTbQaBsb9UC=G9sAag@mail.gmail.com>
	<CAFCoDdC1asW6JGK5huY_kLgCQQCduw8s=YjhHDP0ptA_9YAhhw@mail.gmail.com>
	<51A9291C.70509@ucalgary.ca>
	<CAFCoDdAOHSKSTTD8o+gkdoMppuMW_XhX63zoh-eveBcnE1HVHQ@mail.gmail.com>
	<51A9EC17.2000907@gmail.com>
Message-ID: <CAFCoDdByrDLZgffzqBEog1GZCY3bQ=mnfb-r_yASssTm3NxfxA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130601/6678eafa/attachment.pl>

From jsdroyster at bellsouth.net  Sat Jun  1 21:28:18 2013
From: jsdroyster at bellsouth.net (Julie Royster)
Date: Sat, 1 Jun 2013 15:28:18 -0400
Subject: [R] Windows Vista computer will not use changes I made to R console
	file
Message-ID: <001901ce5efe$2c32e480$8498ad80$@net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130601/2e1e50b1/attachment.pl>

From sridiyer at gmail.com  Sat Jun  1 23:56:55 2013
From: sridiyer at gmail.com (Sridhar Iyer)
Date: Sat, 1 Jun 2013 16:56:55 -0500
Subject: [R] Frequency count of Boolean pattern in 4 vectors.
Message-ID: <CACYyDbiAKe7Jjve7w+3MbMW4RiPzSuDR=sY7bqE5ACdW+vdZtA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130601/911b178d/attachment.pl>

From mef2153 at columbia.edu  Sun Jun  2 05:01:45 2013
From: mef2153 at columbia.edu (Matthew Fagan)
Date: Sat, 01 Jun 2013 23:01:45 -0400
Subject: [R] Regularized Discriminant Analysis scores, anyone?
Message-ID: <51AAB599.9090109@columbia.edu>

Hi all,

I am attempting to do Regularized Discriminant Analysis (RDA) on a large 
dataset, and I want to extract the RDA  discriminant score matrix.  But 
the predict function in the "klaR" package, unlike the predict function 
for LDA in the "MASS" package, doesn't seem to give me an option to 
extract the scores.  Any suggestions?

i have already tried (and failed; ran out of 16 GB of memory) to do this 
with the "rda" package: don't know why, but the klaR package seems to be 
much more efficient with memory.  I have included an example below:

library(klaR)
library(MASS)

data(iris)

x <- rda(Species ~ ., data = iris, gamma = 0.05, lambda = 0.2)
rda1<-predict(x, iris[, 1:4])
str(rda1)

#  This gets you an object with posterior probabilities and classes, but 
no discriminant scores!

#  if you run lda

y <- lda(Species ~ ., data = iris)
lda1<-predict(y, iris[, 1:4])
str(lda1)

head(lda1$x)  #  gets you the discriminant scores for the LDA.  But how 
to do this for RDA?

#  curiously, the QDA function in MASS has this same problem, although 
you can get around it using the rrcov package.

Regards, and thank very much for any help,
Matt


From bagchias at gmail.com  Sun Jun  2 05:30:05 2013
From: bagchias at gmail.com (Aishwarya S. Bagchi)
Date: Sun, 2 Jun 2013 15:30:05 +1200
Subject: [R] plot.gam
Message-ID: <B7E32BBE-2A33-49E6-B39F-A596BC82B042@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130602/74d1c0f1/attachment.pl>

From wdunlap at tibco.com  Sun Jun  2 06:37:09 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 2 Jun 2013 04:37:09 +0000
Subject: [R] Frequency count of Boolean pattern in 4 vectors.
In-Reply-To: <CACYyDbiAKe7Jjve7w+3MbMW4RiPzSuDR=sY7bqE5ACdW+vdZtA@mail.gmail.com>
References: <CACYyDbiAKe7Jjve7w+3MbMW4RiPzSuDR=sY7bqE5ACdW+vdZtA@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C2FC439@PA-MBX01.na.tibco.com>

For 10 million data points
   table(interaction(vec_D, vec_C, vec_B, vec_A))
took my laptop 11.45 seconds and the following function required 0.18 seconds
   f0 <- function (vec_A, vec_B, vec_C, vec_D) 
  {
      x <- 1 + vec_A + 2 * (vec_B + 2 * (vec_C + 2 * vec_D))
      tab <- tabulate(x, nbins = 16)
      names(tab) <- do.call(paste0, rev(expand.grid(0:1, 0:1, 0:1, 
          0:1)))
      tab
  }
Aside from the order of the entries in the output tables, they gave the same results.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Sridhar Iyer
> Sent: Saturday, June 01, 2013 2:57 PM
> To: r-help at r-project.org
> Subject: [R] Frequency count of Boolean pattern in 4 vectors.
> 
> I need to do this on very large datasets ( > a few million data points). So
> seeking help in figuring out an implementation of the task.
> 
> Input 4 vectors which contain values as 0 or 1. (as integers, not boolean
> bits)
> vec_A = ( 0, 1, 0, 0, ...... 1, 0, 1, 0)   etc
> vec_B = (0,0,1,1.....)
> vec_C, vec_D  (similar to above)
> All four vectors are same length.
> 
> I need to compute frequency count of the boolean literals for DCBA,
> DCBA
> 0000
> 0001
> 0010
> 0011
> ..
> ..
> 1111
> 
> Questions:
> a) Is there a mechanism for combining the 4 vectors (in integer formats)
> into 4 bits of a new vector or some other
> type? (or treat them as boolean values true/false instead of 0 or 1
> integers).
> b) what is the most efficient mechanism for obtaining the frequency count of
> each of the sixteen Boolean
> combinations?
> 
> I need to do this frequently on large datasets. So am trying to get an
> efficient implementation (instead of
> a quick and dirty scheme). Thank you very very much in advance.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mattstati at yahoo.com  Sun Jun  2 08:08:24 2013
From: mattstati at yahoo.com (Matt Stati)
Date: Sat, 1 Jun 2013 23:08:24 -0700 (PDT)
Subject: [R] Computing Median for Subset of Data
Message-ID: <1370153304.23685.YahooMailNeo@web162605.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130601/c3afb129/attachment.pl>

From pdalgd at gmail.com  Sun Jun  2 09:48:48 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 2 Jun 2013 09:48:48 +0200
Subject: [R] Computing Median for Subset of Data
In-Reply-To: <1370153304.23685.YahooMailNeo@web162605.mail.bf1.yahoo.com>
References: <1370153304.23685.YahooMailNeo@web162605.mail.bf1.yahoo.com>
Message-ID: <DACA6B43-213D-4D13-87B5-2FCA350D2F76@gmail.com>


On Jun 2, 2013, at 08:08 , Matt Stati wrote:

>> From my larger data set I created a subset of it by using: 
> 
> subset_1 <- subset(timeuse, IndepTrans = 1, Physical = 1)

That's not going to work. Try

subset(timeuse, (IndepTrans == 1) & (Physical == 1))

(Whenever you do things like this, run summary(subset_1) to check.)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bhh at xs4all.nl  Sun Jun  2 09:50:09 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 2 Jun 2013 09:50:09 +0200
Subject: [R] Computing Median for Subset of Data
In-Reply-To: <1370153304.23685.YahooMailNeo@web162605.mail.bf1.yahoo.com>
References: <1370153304.23685.YahooMailNeo@web162605.mail.bf1.yahoo.com>
Message-ID: <7D5BDFEE-36BB-4B85-9CFD-07494D733053@xs4all.nl>


On 02-06-2013, at 08:08, Matt Stati <mattstati at yahoo.com> wrote:

>> From my larger data set I created a subset of it by using: 
> 
> subset_1 <- subset(timeuse, IndepTrans = 1, Physical = 1)
> 
> where my larger data set is "timeuse" and the smaller subset is "subset_1". The subset was conditioned on "IndepTrans" equaling "1" in the data and "Physical" equaling "1" as well. I want to be able to compute the median of a variable first for the larger data set "timeuse" then for the subset file "subset_1". How do I identify to R which data set I'm wanting the median computed for? I've tried many possibilities but for some reason can't figure it out. 


?with

with(timeuse, median(?))
with(subset_1, median(?))

Berend


From jannetta at henning.org  Sun Jun  2 10:12:19 2013
From: jannetta at henning.org (Jannetta Steyn)
Date: Sun, 2 Jun 2013 09:12:19 +0100
Subject: [R] object not found
In-Reply-To: <CAAxdm-6StMeT73usaW8UNbQQR2CmGH942ofMTjt4K_KGZXYO5Q@mail.gmail.com>
References: <CAGR4ry4+vxeZh2=q7Zbh+SCgcvbf7mcSasMTKu0z+ecuTypi4g@mail.gmail.com>
	<CAAxdm-6StMeT73usaW8UNbQQR2CmGH942ofMTjt4K_KGZXYO5Q@mail.gmail.com>
Message-ID: <CAGR4ry42S_9_izC7YG8gUtUgU6wiWTSomWMjdp+wCFp5ZBKrtA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130602/15fa48bd/attachment.pl>

From jholtman at gmail.com  Sun Jun  2 10:15:09 2013
From: jholtman at gmail.com (Jim Holtman)
Date: Sun, 2 Jun 2013 04:15:09 -0400
Subject: [R] object not found
In-Reply-To: <CAGR4ry42S_9_izC7YG8gUtUgU6wiWTSomWMjdp+wCFp5ZBKrtA@mail.gmail.com>
References: <CAGR4ry4+vxeZh2=q7Zbh+SCgcvbf7mcSasMTKu0z+ecuTypi4g@mail.gmail.com>
	<CAAxdm-6StMeT73usaW8UNbQQR2CmGH942ofMTjt4K_KGZXYO5Q@mail.gmail.com>
	<CAGR4ry42S_9_izC7YG8gUtUgU6wiWTSomWMjdp+wCFp5ZBKrtA@mail.gmail.com>
Message-ID: <3AC3CFA5-60A6-45AE-9969-7C6A8983FD4F@gmail.com>

but that is not the variable that is not found. "mCaT_soma_AB"

Sent from my iPad

On Jun 2, 2013, at 4:12, Jannetta Steyn <jannetta at henning.org> wrote:

> mCaT_soma_AB


From info at aghmed.fsnet.co.uk  Sun Jun  2 13:27:08 2013
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Sun, 02 Jun 2013 12:27:08 +0100
Subject: [R] metafor mixed-effect models: testing different predictor
 combinations for lowest AIC
In-Reply-To: <1370121141774-4668486.post@n4.nabble.com>
References: <1370121141774-4668486.post@n4.nabble.com>
Message-ID: <Zen-1Uj6RQ-0002My-KG@smarthost04.mail.zen.net.uk>

At 22:12 01/06/2013, emhanlon wrote:
>Good afternoon,
>
>
>I am trying to use a mixed-effect model to find the best predictors of
>wildlife response (fledgling success, offspring growth rate, etc...) to
>human disturbance. I am using a Log Response Ratio as my measure of effect
>size along with study variance, and testing to see how: habitat, diet, mass,
>generation time, sociality, etc... influence how a species responds to
>disturbance. I have 9 total predictors, but a sample size that would only
>allow for 3, at most, in a model. Does anyone know of any code that could
>allow me to automatically test all combinations of 1,2, or 3 predictors to
>get the model with the lowest overall AIC?

You could use the facility that mods can be a matrix and use combn to 
generate all the possible combinations of 9 taken 1, 2, 3 at a time. 
Each time you call ram.uni just save whatever you want to use as your 
criterion.

I am not sure how good an idea that is and I would advise looking at 
all the solutions near (for some meaning of near) the apparently best 
one. You might be surprised how close they are which rather casts 
doubt on the wisdom of selecting variables.


>#Code I had been using in different combinations manually:
> > res <- rma(LRR, est_var, mods = cbind(Gentime, Sociality, Season), data =
> > data)
>
>#Also, if the best model has more than one predictor, how can you get
>specific mean effect sizes for different levels of the #variable, especially
>if it is categorical (non-ranked)?
>
>
>Thank you so much for your help,
>
>Edward
>
>
>
>--
>View this message in context: 
>http://r.789695.n4.nabble.com/metafor-mixed-effect-models-testing-different-predictor-combinations-for-lowest-AIC-tp4668486.html
>Sent from the R help mailing list archive at Nabble.com.

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html


From nalimilan at club.fr  Sun Jun  2 13:49:20 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Sun, 02 Jun 2013 13:49:20 +0200
Subject: [R] Windows Vista computer will not use changes I made to R
 console file
In-Reply-To: <001901ce5efe$2c32e480$8498ad80$@net>
References: <001901ce5efe$2c32e480$8498ad80$@net>
Message-ID: <1370173760.6693.12.camel@milan>

Le samedi 01 juin 2013 ? 15:28 -0400, Julie Royster a ?crit :
> My newer laptop died so I installed R on an older Vista laptop.
> I did follow the online instructions about giving myself full control under
> the R properties security tab.
> I made changes in the R console file under the etc folder to use bold type
> in color Black, but it is not doing what I ask.
> I am still getting blue type that is not bold.
> This previously worked great on the other computers I have used.
> Can anyone tell me what to do?  THANKS!!!
> Julie in Raleigh NC
Maybe you have changes saved to a Rconsole file in your home folder?
What happens if you make changes from Rgui and save them?


Regards

> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From neumancohu at gmail.com  Sun Jun  2 15:17:57 2013
From: neumancohu at gmail.com (Neuman Co)
Date: Sun, 2 Jun 2013 15:17:57 +0200
Subject: [R] Multivariate EWMA covariance estimator?
Message-ID: <CADih64QyTxh7hAOfeKz=MLg35N8RHhyS39mEddDepSKh3rbqaQ@mail.gmail.com>

Hi,
since I want to calculate the VaR of a portfolio consiting of 4 assets
(returns saved into "eonreturn","henkelreturn" and so on) I have to
estimate the covariance matrix. I do not want to take the rectangular
version with equal weights, but the exponentially weighted moving
average in a multivariate version. I want to estimate a covariance
matrix at every time point t. Then I want to comput the VaR at this
time point t. Afterwards, I will look at the exceedances and do a
backtest.

I tried to implement it as follows (data attached):

lambda<-0.9

summe2<-0
dummy2<-0
covestiexpo<-list(NA)
meanvalues<-NA
for(i in 101:length(eonreturn)){
meanvalues<-matrix(c(mean(eonreturn[(i-100):(i-1)]),mean(henkelreturn[(i-100):(i-1)]),mean(siemensreturn[(i-100):(i-1)]),mean(adidasreturn[(i-100):(i-1)])),4)
for(a in 1:100){
dummy2<-lambda^(a-1)*t(datamatrix[(i-a),]-t(meanvalues))%*%(datamatrix[(i-a),]-t(meanvalues))
summe2<-summe2+dummy2
}
covestiexpo[[i]]<-(1-lambda)*summe2
}


So the covestieexpo[[101]] would be the covariance estimate for the
101th day, taking into account the last 100 observations. Now, the
problem is, that there seems to be something wrong, since the
covariance estimates are cleraly wrong, they seem to be too big. At
the beginning, compared to the normal covariance estimate the
difference is as follows:

covestiexpo[[101]]
            [,1]        [,2]        [,3]        [,4]
[1,] 0.004559042 0.002346775 0.004379735 0.003068916
[2,] 0.002346775 0.001978469 0.002536891 0.001909276
[3,] 0.004379735 0.002536891 0.005531590 0.003259803
[4,] 0.003068916 0.001909276 0.003259803 0.003140198



compared to cov(datamatrix[1:100,])
             [,1]         [,2]         [,3]        [,4]
[1,] 0.0018118239 0.0007432779 0.0015301070 0.001119120
[2,] 0.0007432779 0.0008355960 0.0009281029 0.000754449
[3,] 0.0015301070 0.0009281029 0.0021073171 0.001269626
[4,] 0.0011191199 0.0007544490 0.0012696257 0.001325716

So already here, it is obvious, that something is not correct, if I
look at a period far ahead:

covestiexpo[[1200]]

          [,1]      [,2]      [,3]      [,4]
[1,] 0.5312575 0.1939061 0.3419379 0.2475233
[2,] 0.1939061 0.3204951 0.2303478 0.2022423
[3,] 0.3419379 0.2303478 0.5288435 0.2943051
[4,] 0.2475233 0.2022423 0.2943051 0.4599648


you can see, that the values are way too large, so where is my mistake?



Thanks a lot for your help!
--
Neumann, Conrad

From cgiannoul at gmail.com  Sun Jun  2 16:05:46 2013
From: cgiannoul at gmail.com (Christos Giannoulis)
Date: Sun, 2 Jun 2013 10:05:46 -0400
Subject: [R] Robust GAM that covers Gaussian Distributions
Message-ID: <CAMmHnJ0FvntaEy-XyUQJRv-M6j8tXhNbeCqKxTuq60qp9_xZtw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130602/c62e039f/attachment.pl>

From ligges at statistik.tu-dortmund.de  Sun Jun  2 16:31:34 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 02 Jun 2013 16:31:34 +0200
Subject: [R] Windows Vista computer will not use changes I made to R
 console file
In-Reply-To: <1370173760.6693.12.camel@milan>
References: <001901ce5efe$2c32e480$8498ad80$@net>
	<1370173760.6693.12.camel@milan>
Message-ID: <51AB5746.3050007@statistik.tu-dortmund.de>



On 02.06.2013 13:49, Milan Bouchet-Valat wrote:
> Le samedi 01 juin 2013 ? 15:28 -0400, Julie Royster a ?crit :
>> My newer laptop died so I installed R on an older Vista laptop.
>> I did follow the online instructions about giving myself full control under
>> the R properties security tab.
>> I made changes in the R console file under the etc folder to use bold type
>> in color Black, but it is not doing what I ask.
>> I am still getting blue type that is not bold.
>> This previously worked great on the other computers I have used.
>> Can anyone tell me what to do?  THANKS!!!
>> Julie in Raleigh NC
> Maybe you have changes saved to a Rconsole file in your home folder?
> What happens if you make changes from Rgui and save them?

Right, if there is a user level file, it will take precedence. See ?Startup

There was a bug in an older version of R (cannot remember which one) not 
respecting all the setting. So as always, we also need the R version you 
are talking about.

Best,
UWe Ligges



>
>
> Regards
>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bhh at xs4all.nl  Sun Jun  2 16:35:43 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 2 Jun 2013 16:35:43 +0200
Subject: [R] Multivariate EWMA covariance estimator?
In-Reply-To: <CADih64QyTxh7hAOfeKz=MLg35N8RHhyS39mEddDepSKh3rbqaQ@mail.gmail.com>
References: <CADih64QyTxh7hAOfeKz=MLg35N8RHhyS39mEddDepSKh3rbqaQ@mail.gmail.com>
Message-ID: <0E3FA5A0-C12C-4183-8050-B0F768892988@xs4all.nl>


On 02-06-2013, at 15:17, Neuman Co <neumancohu at gmail.com> wrote:

> Hi,
> since I want to calculate the VaR of a portfolio consiting of 4 assets
> (returns saved into "eonreturn","henkelreturn" and so on) I have to
> estimate the covariance matrix. I do not want to take the rectangular
> version with equal weights, but the exponentially weighted moving
> average in a multivariate version. I want to estimate a covariance
> matrix at every time point t. Then I want to comput the VaR at this
> time point t. Afterwards, I will look at the exceedances and do a
> backtest.
> 
> I tried to implement it as follows (data attached):
> 
> lambda<-0.9
> 
> summe2<-0
> dummy2<-0
> covestiexpo<-list(NA)
> meanvalues<-NA
> for(i in 101:length(eonreturn)){
> meanvalues<-matrix(c(mean(eonreturn[(i-100):(i-1)]),mean(henkelreturn[(i-100):(i-1)]),mean(siemensreturn[(i-100):(i-1)]),mean(adidasreturn[(i-100):(i-1)])),4)
> for(a in 1:100){
> dummy2<-lambda^(a-1)*t(datamatrix[(i-a),]-t(meanvalues))%*%(datamatrix[(i-a),]-t(meanvalues))
> summe2<-summe2+dummy2
> }
> covestiexpo[[i]]<-(1-lambda)*summe2
> }
> 
> 
> So the covestieexpo[[101]] would be the covariance estimate for the
> 101th day, taking into account the last 100 observations. Now, the
> problem is, that there seems to be something wrong, since the
> covariance estimates are cleraly wrong, they seem to be too big. At
> the beginning, compared to the normal covariance estimate the
> difference is as follows:
> 
> covestiexpo[[101]]
>            [,1]        [,2]        [,3]        [,4]
> [1,] 0.004559042 0.002346775 0.004379735 0.003068916
> [2,] 0.002346775 0.001978469 0.002536891 0.001909276
> [3,] 0.004379735 0.002536891 0.005531590 0.003259803
> [4,] 0.003068916 0.001909276 0.003259803 0.003140198
> 
> 
> 
> compared to cov(datamatrix[1:100,])
>             [,1]         [,2]         [,3]        [,4]
> [1,] 0.0018118239 0.0007432779 0.0015301070 0.001119120
> [2,] 0.0007432779 0.0008355960 0.0009281029 0.000754449
> [3,] 0.0015301070 0.0009281029 0.0021073171 0.001269626
> [4,] 0.0011191199 0.0007544490 0.0012696257 0.001325716
> 
> So already here, it is obvious, that something is not correct, if I
> look at a period far ahead:
> 
> covestiexpo[[1200]]
> 
>          [,1]      [,2]      [,3]      [,4]
> [1,] 0.5312575 0.1939061 0.3419379 0.2475233
> [2,] 0.1939061 0.3204951 0.2303478 0.2022423
> [3,] 0.3419379 0.2303478 0.5288435 0.2943051
> [4,] 0.2475233 0.2022423 0.2943051 0.4599648
> 
> 
> you can see, that the values are way too large, so where is my mistake?

Without actual data this is an unverifiable statement.
But you probably have to move the statement

summe2 <- 0

to inside the i-forloop just before the a-forloop.

summe2 <- 0
for(a in 1:100){
?

so that summe2 is initialized to 0 every time you use it as an accumulator in the a-forloop.
Furthermore there is no need to initialize dummy2. It gets overwritten continuously.

Berend


From ligges at statistik.tu-dortmund.de  Sun Jun  2 16:39:30 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 02 Jun 2013 16:39:30 +0200
Subject: [R] Regularized Discriminant Analysis scores, anyone?
In-Reply-To: <51AAB599.9090109@columbia.edu>
References: <51AAB599.9090109@columbia.edu>
Message-ID: <51AB5922.9070703@statistik.tu-dortmund.de>



On 02.06.2013 05:01, Matthew Fagan wrote:
> Hi all,
>
> I am attempting to do Regularized Discriminant Analysis (RDA) on a large
> dataset, and I want to extract the RDA  discriminant score matrix.  But
> the predict function in the "klaR" package, unlike the predict function
> for LDA in the "MASS" package, doesn't seem to give me an option to
> extract the scores.  Any suggestions?

There are no such scores:

same as for qda, you do not follow the Fisher idea of the linear 
discriminant components any more: Your space is now partitioned by 
ellipsoid like structures based on the estimation of the inner-class 
covariance matrices.

rda as implemented in klaR (see the reference given on the help page) is 
a regularization that helps to overcome problems when estimating 
non-singular covariance matrices for the separate classes.


> i have already tried (and failed; ran out of 16 GB of memory) to do this
> with the "rda" package: don't know why, but the klaR package seems to be
> much more efficient with memory.  I have included an example below:

The rda package provides a completely different regularization 
technique, see the reference given on the help page.

Best,
Uwe Ligges




> library(klaR)
> library(MASS)
>
> data(iris)
>
> x <- rda(Species ~ ., data = iris, gamma = 0.05, lambda = 0.2)
> rda1<-predict(x, iris[, 1:4])
> str(rda1)
>
> #  This gets you an object with posterior probabilities and classes, but
> no discriminant scores!
>
> #  if you run lda
>
> y <- lda(Species ~ ., data = iris)
> lda1<-predict(y, iris[, 1:4])
> str(lda1)
>
> head(lda1$x)  #  gets you the discriminant scores for the LDA.  But how
> to do this for RDA?
>
> #  curiously, the QDA function in MASS has this same problem, although
> you can get around it using the rrcov package.
>
> Regards, and thank very much for any help,
> Matt
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kw.stat at gmail.com  Sun Jun  2 16:43:23 2013
From: kw.stat at gmail.com (Kevin Wright)
Date: Sun, 2 Jun 2013 09:43:23 -0500
Subject: [R] measuring distances between colours?
In-Reply-To: <000f01ce5ee5$46b1c420$d4154c60$@mcmaster.ca>
References: <4382_1369916184_r4UCGK5j024861_web-459777071@cgpsrv2.cis.mcmaster.ca>
	<004601ce5d7a$9f16fc00$dd44f400$@mcmaster.ca>
	<20904.20143.918220.744897@stat.math.ethz.ch>
	<CAKFxdiSHPCgsVCaaJDfedX8b2ZAHbTdNNYktjHzUk=0XtG=ayA@mail.gmail.com>
	<007001ce5e58$7776a400$6663ec00$@mcmaster.ca>
	<51AA1436.2020909@yorku.ca>
	<000f01ce5ee5$46b1c420$d4154c60$@mcmaster.ca>
Message-ID: <CAKFxdiSywvZEbuOurrP+K8xDZMZR3napE4XWEttRJOuUH=tc3w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130602/2bf1cdbf/attachment.pl>

From jgrn at illinois.edu  Sun Jun  2 18:06:14 2013
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Sun, 2 Jun 2013 11:06:14 -0500
Subject: [R] Official way to set/retrieve options in packages?
In-Reply-To: <9ac4a7ea5b424580ba3c71d96dee61b7@CITESHT1.ad.uillinois.edu>
References: <CABG0rfskpFF8T+i9OKCBNRGyCS_rn7L1PVO4RO0NivWo0a7jGQ@mail.gmail.com>
	<CAOwvMDz0kzspV8se-gB+7u2WAUghNi99fONcvEofPiVjfEjQng@mail.gmail.com>
	<9ac4a7ea5b424580ba3c71d96dee61b7@CITESHT1.ad.uillinois.edu>
Message-ID: <CABG0rft95zMfCuC09M5HQSKEdcrj=6+bDRbprQNWy5e5fkYgiQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130602/14bc1e7d/attachment.pl>

From gunter.berton at gene.com  Sun Jun  2 18:38:16 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 2 Jun 2013 09:38:16 -0700
Subject: [R] Official way to set/retrieve options in packages?
In-Reply-To: <CABG0rft95zMfCuC09M5HQSKEdcrj=6+bDRbprQNWy5e5fkYgiQ@mail.gmail.com>
References: <CABG0rfskpFF8T+i9OKCBNRGyCS_rn7L1PVO4RO0NivWo0a7jGQ@mail.gmail.com>
	<CAOwvMDz0kzspV8se-gB+7u2WAUghNi99fONcvEofPiVjfEjQng@mail.gmail.com>
	<9ac4a7ea5b424580ba3c71d96dee61b7@CITESHT1.ad.uillinois.edu>
	<CABG0rft95zMfCuC09M5HQSKEdcrj=6+bDRbprQNWy5e5fkYgiQ@mail.gmail.com>
Message-ID: <CACk-te3SatYvs-_sqewFSdEotTZWL+_hRH5LcPa-xwtbNBEbTQ@mail.gmail.com>

Have you read

?Startup

which explains startup procedures, including reading of .Rprofile.

I cannot speak for Brian Ripley, but I can tell you that I would
prefer that packages did not mess with my .Rprofile files.

OTOH, I have no objections if packages suggest that I set certain
options in them or even give me lines of code that I can add if I
choose ( or give me an option to call a function to do so).

I understand that this is not the automatic procedure you seem to be seeking...

Cheers,
Bert

On Sun, Jun 2, 2013 at 9:06 AM, Jonathan Greenberg <jgrn at illinois.edu> wrote:
> What would be an example of setting, saving, and re-loading an option to a
> user's .Rprofile -- and would this be a no-no in a CRAN package?
>
> --j
>
>
> On Sat, Jun 1, 2013 at 4:57 PM, Prof Brian Ripley <ripley at stats.ox.ac.uk>wrote:
>
>> On 01/06/2013 22:44, Anthony Damico wrote:
>> > hope this helps..  :)
>> >
>> >      # define an object `x`
>> >      x <- list( "any value here" , 10 )
>> >
>> >      # set `myoption` to that object
>> >      options( "myoption" = x )
>> >
>> >      # retrieve it later (perhaps within a function elsewhere in the
>> package)
>> >      ( y <- getOption( myoption ) )
>> >
>> >
>> > it's nice to name your options `mypackage.myoption` so users know what
>> > package the option is associated with in case they type `options()`
>> >
>> >
>> > here's the `.onLoad` function in the R survey package.  notice how the
>> > options are only set *if* they don't already exist--
>>
>> But a nicer convention is that used by most packages in R itself: if the
>> option is not set, the function using it assumes a suitable default.
>> That would make sense for all the FALSE defaults below.
>>
>> Note though that this is not 'persistent': users have to set options in
>> their startup files (see ?Startup).   There is no official location to
>> store package configurations.  Users generally dislike software saving
>> settings in their own file space so it seems very much preferable to use
>> the standard R mechanisms (.Rprofile etc).
>>
>> >
>> >> survey:::.onLoad
>> >
>> > function (...)
>> > {
>> >      if (is.null(getOption("survey.lonely.psu")))
>> > options(survey.lonely.psu = "fail")
>> >      if (is.null(getOption("survey.ultimate.cluster")))
>> > options(survey.ultimate.cluster = FALSE)
>> >      if (is.null(getOption("survey.want.obsolete")))
>> > options(survey.want.obsolete = FALSE)
>> >      if (is.null(getOption("survey.adjust.domain.lonely")))
>> > options(survey.adjust.domain.lonely = FALSE)
>> >      if (is.null(getOption("survey.drop.replicates")))
>> > options(survey.drop.replicates = TRUE)
>> >      if (is.null(getOption("survey.multicore")))
>> > options(survey.multicore = FALSE)
>> >      if (is.null(getOption("survey.replicates.mse")))
>> > options(survey.replicates.mse = FALSE)
>> > }
>> > <environment: namespace:survey>
>> >
>> >
>> >
>> >
>> > On Sat, Jun 1, 2013 at 4:01 PM, Jonathan Greenberg <jgrn at illinois.edu
>> >wrote:
>> >
>> >> R-helpers:
>> >>
>> >> Say I'm developing a package that has a set of user-definable options
>> that
>> >> I would like to be persistent across R-invocations (they are saved
>> >> someplace).  Of course, I can create a little text file to be
>> written/read,
>> >> but I was wondering if there is an "officially sanctioned" way to do
>> this?
>> >>   I see there is an options() and getOptions() function, but I'm
>> unclear how
>> >> I would use this in my own package to create/save new options for my
>> >> particular package.  Cheers!
>> >>
>> >> --j
>> >>
>> >> --
>> >> Jonathan A. Greenberg, PhD
>> >> Assistant Professor
>> >> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>> >> Department of Geography and Geographic Information Science
>> >> University of Illinois at Urbana-Champaign
>> >> 607 South Mathews Avenue, MC 150
>> >> Urbana, IL 61801
>> >> Phone: 217-300-1924
>> >> http://www.geog.illinois.edu/~jgrn/
>> >> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>> >>
>> >>          [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>
>
>
> --
> Jonathan A. Greenberg, PhD
> Assistant Professor
> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> Department of Geography and Geographic Information Science
> University of Illinois at Urbana-Champaign
> 607 South Mathews Avenue, MC 150
> Urbana, IL 61801
> Phone: 217-300-1924
> http://www.geog.illinois.edu/~jgrn/
> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From neumancohu at gmail.com  Sun Jun  2 19:03:29 2013
From: neumancohu at gmail.com (Neuman Co)
Date: Sun, 2 Jun 2013 19:03:29 +0200
Subject: [R] Multivariate EWMA covariance estimator?
In-Reply-To: <0E3FA5A0-C12C-4183-8050-B0F768892988@xs4all.nl>
References: <CADih64QyTxh7hAOfeKz=MLg35N8RHhyS39mEddDepSKh3rbqaQ@mail.gmail.com>
	<0E3FA5A0-C12C-4183-8050-B0F768892988@xs4all.nl>
Message-ID: <CADih64QbAuJyf7aHj9vD6_yD+poFfLHraQwOBfbA4SL1UUguig@mail.gmail.com>

Thanks a lot for your answer, one more question:
I now use 100 values, so not infinity values. That means I cut some
values off, so the weights will not sum up to one. With which factor
do I have to multiply the (1-lambda)*summe2 to rescale it? So that I
do not always underestimate the variance anymore?

2013/6/2 Berend Hasselman <bhh at xs4all.nl>:
>
> On 02-06-2013, at 15:17, Neuman Co <neumancohu at gmail.com> wrote:
>
>> Hi,
>> since I want to calculate the VaR of a portfolio consiting of 4 assets
>> (returns saved into "eonreturn","henkelreturn" and so on) I have to
>> estimate the covariance matrix. I do not want to take the rectangular
>> version with equal weights, but the exponentially weighted moving
>> average in a multivariate version. I want to estimate a covariance
>> matrix at every time point t. Then I want to comput the VaR at this
>> time point t. Afterwards, I will look at the exceedances and do a
>> backtest.
>>
>> I tried to implement it as follows (data attached):
>>
>> lambda<-0.9
>>
>> summe2<-0
>> dummy2<-0
>> covestiexpo<-list(NA)
>> meanvalues<-NA
>> for(i in 101:length(eonreturn)){
>> meanvalues<-matrix(c(mean(eonreturn[(i-100):(i-1)]),mean(henkelreturn[(i-100):(i-1)]),mean(siemensreturn[(i-100):(i-1)]),mean(adidasreturn[(i-100):(i-1)])),4)
>> for(a in 1:100){
>> dummy2<-lambda^(a-1)*t(datamatrix[(i-a),]-t(meanvalues))%*%(datamatrix[(i-a),]-t(meanvalues))
>> summe2<-summe2+dummy2
>> }
>> covestiexpo[[i]]<-(1-lambda)*summe2
>> }
>>
>>
>> So the covestieexpo[[101]] would be the covariance estimate for the
>> 101th day, taking into account the last 100 observations. Now, the
>> problem is, that there seems to be something wrong, since the
>> covariance estimates are cleraly wrong, they seem to be too big. At
>> the beginning, compared to the normal covariance estimate the
>> difference is as follows:
>>
>> covestiexpo[[101]]
>>            [,1]        [,2]        [,3]        [,4]
>> [1,] 0.004559042 0.002346775 0.004379735 0.003068916
>> [2,] 0.002346775 0.001978469 0.002536891 0.001909276
>> [3,] 0.004379735 0.002536891 0.005531590 0.003259803
>> [4,] 0.003068916 0.001909276 0.003259803 0.003140198
>>
>>
>>
>> compared to cov(datamatrix[1:100,])
>>             [,1]         [,2]         [,3]        [,4]
>> [1,] 0.0018118239 0.0007432779 0.0015301070 0.001119120
>> [2,] 0.0007432779 0.0008355960 0.0009281029 0.000754449
>> [3,] 0.0015301070 0.0009281029 0.0021073171 0.001269626
>> [4,] 0.0011191199 0.0007544490 0.0012696257 0.001325716
>>
>> So already here, it is obvious, that something is not correct, if I
>> look at a period far ahead:
>>
>> covestiexpo[[1200]]
>>
>>          [,1]      [,2]      [,3]      [,4]
>> [1,] 0.5312575 0.1939061 0.3419379 0.2475233
>> [2,] 0.1939061 0.3204951 0.2303478 0.2022423
>> [3,] 0.3419379 0.2303478 0.5288435 0.2943051
>> [4,] 0.2475233 0.2022423 0.2943051 0.4599648
>>
>>
>> you can see, that the values are way too large, so where is my mistake?
>
> Without actual data this is an unverifiable statement.
> But you probably have to move the statement
>
> summe2 <- 0
>
> to inside the i-forloop just before the a-forloop.
>
> summe2 <- 0
> for(a in 1:100){
> ?
>
> so that summe2 is initialized to 0 every time you use it as an accumulator in the a-forloop.
> Furthermore there is no need to initialize dummy2. It gets overwritten continuously.
>
> Berend
>
>



-- 
Neumann, Conrad


From bhh at xs4all.nl  Sun Jun  2 19:38:34 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 2 Jun 2013 19:38:34 +0200
Subject: [R] Multivariate EWMA covariance estimator?
In-Reply-To: <CADih64QbAuJyf7aHj9vD6_yD+poFfLHraQwOBfbA4SL1UUguig@mail.gmail.com>
References: <CADih64QyTxh7hAOfeKz=MLg35N8RHhyS39mEddDepSKh3rbqaQ@mail.gmail.com>
	<0E3FA5A0-C12C-4183-8050-B0F768892988@xs4all.nl>
	<CADih64QbAuJyf7aHj9vD6_yD+poFfLHraQwOBfbA4SL1UUguig@mail.gmail.com>
Message-ID: <44EF9921-A4DA-4DE4-ADC6-CF1488E1D6B5@xs4all.nl>


On 02-06-2013, at 19:03, Neuman Co <neumancohu at gmail.com> wrote:

> Thanks a lot for your answer, one more question:
> I now use 100 values, so not infinity values. That means I cut some
> values off, so the weights will not sum up to one. With which factor
> do I have to multiply the (1-lambda)*summe2 to rescale it? So that I
> do not always underestimate the variance anymore?
> 

I don't know but maybe something like this

1/sum(lambda^((1:100)-1))/(1-lambda)

which in your case is 1.000027

Berend

> 2013/6/2 Berend Hasselman <bhh at xs4all.nl>:
>> 
>> On 02-06-2013, at 15:17, Neuman Co <neumancohu at gmail.com> wrote:
>> 
>>> Hi,
>>> since I want to calculate the VaR of a portfolio consiting of 4 assets
>>> (returns saved into "eonreturn","henkelreturn" and so on) I have to
>>> estimate the covariance matrix. I do not want to take the rectangular
>>> version with equal weights, but the exponentially weighted moving
>>> average in a multivariate version. I want to estimate a covariance
>>> matrix at every time point t. Then I want to comput the VaR at this
>>> time point t. Afterwards, I will look at the exceedances and do a
>>> backtest.
>>> 
>>> I tried to implement it as follows (data attached):
>>> 
>>> lambda<-0.9
>>> 
>>> summe2<-0
>>> dummy2<-0
>>> covestiexpo<-list(NA)
>>> meanvalues<-NA
>>> for(i in 101:length(eonreturn)){
>>> meanvalues<-matrix(c(mean(eonreturn[(i-100):(i-1)]),mean(henkelreturn[(i-100):(i-1)]),mean(siemensreturn[(i-100):(i-1)]),mean(adidasreturn[(i-100):(i-1)])),4)
>>> for(a in 1:100){
>>> dummy2<-lambda^(a-1)*t(datamatrix[(i-a),]-t(meanvalues))%*%(datamatrix[(i-a),]-t(meanvalues))
>>> summe2<-summe2+dummy2
>>> }
>>> covestiexpo[[i]]<-(1-lambda)*summe2
>>> }
>>> 
>>> 
>>> So the covestieexpo[[101]] would be the covariance estimate for the
>>> 101th day, taking into account the last 100 observations. Now, the
>>> problem is, that there seems to be something wrong, since the
>>> covariance estimates are cleraly wrong, they seem to be too big. At
>>> the beginning, compared to the normal covariance estimate the
>>> difference is as follows:
>>> 
>>> covestiexpo[[101]]
>>>           [,1]        [,2]        [,3]        [,4]
>>> [1,] 0.004559042 0.002346775 0.004379735 0.003068916
>>> [2,] 0.002346775 0.001978469 0.002536891 0.001909276
>>> [3,] 0.004379735 0.002536891 0.005531590 0.003259803
>>> [4,] 0.003068916 0.001909276 0.003259803 0.003140198
>>> 
>>> 
>>> 
>>> compared to cov(datamatrix[1:100,])
>>>            [,1]         [,2]         [,3]        [,4]
>>> [1,] 0.0018118239 0.0007432779 0.0015301070 0.001119120
>>> [2,] 0.0007432779 0.0008355960 0.0009281029 0.000754449
>>> [3,] 0.0015301070 0.0009281029 0.0021073171 0.001269626
>>> [4,] 0.0011191199 0.0007544490 0.0012696257 0.001325716
>>> 
>>> So already here, it is obvious, that something is not correct, if I
>>> look at a period far ahead:
>>> 
>>> covestiexpo[[1200]]
>>> 
>>>         [,1]      [,2]      [,3]      [,4]
>>> [1,] 0.5312575 0.1939061 0.3419379 0.2475233
>>> [2,] 0.1939061 0.3204951 0.2303478 0.2022423
>>> [3,] 0.3419379 0.2303478 0.5288435 0.2943051
>>> [4,] 0.2475233 0.2022423 0.2943051 0.4599648
>>> 
>>> 
>>> you can see, that the values are way too large, so where is my mistake?
>> 
>> Without actual data this is an unverifiable statement.
>> But you probably have to move the statement
>> 
>> summe2 <- 0
>> 
>> to inside the i-forloop just before the a-forloop.
>> 
>> summe2 <- 0
>> for(a in 1:100){
>> ?
>> 
>> so that summe2 is initialized to 0 every time you use it as an accumulator in the a-forloop.
>> Furthermore there is no need to initialize dummy2. It gets overwritten continuously.
>> 
>> Berend
>> 
>> 
> 
> 
> 
> -- 
> Neumann, Conrad


From neumancohu at gmail.com  Sun Jun  2 19:45:55 2013
From: neumancohu at gmail.com (Neuman Co)
Date: Sun, 2 Jun 2013 19:45:55 +0200
Subject: [R] Multivariate EWMA covariance estimator?
In-Reply-To: <44EF9921-A4DA-4DE4-ADC6-CF1488E1D6B5@xs4all.nl>
References: <CADih64QyTxh7hAOfeKz=MLg35N8RHhyS39mEddDepSKh3rbqaQ@mail.gmail.com>
	<0E3FA5A0-C12C-4183-8050-B0F768892988@xs4all.nl>
	<CADih64QbAuJyf7aHj9vD6_yD+poFfLHraQwOBfbA4SL1UUguig@mail.gmail.com>
	<44EF9921-A4DA-4DE4-ADC6-CF1488E1D6B5@xs4all.nl>
Message-ID: <CADih64T7rVUFZe1scTAhJpsyrj6pAcm5r5m_yeOiQCUq3GDjOA@mail.gmail.com>

Again, a big thanks for your answer.

On this webpage:
http://financetrainingcourse.com/education/2010/03/master-class-calculating-value-at-risk-var-final-steps/

I found, that I have to rescale by dividing the weights calculated in
Step B2 by 1-?n

The "?" is the lambda, since the webpage cannot display it, I also
found it on another webpage, therefore, I changed my code to the
following:

dummy2<-lambda^(a-1)/(1-lambda^100)*t(datamatrix[(i-a),]-t(meanvalues))%*%(datamatrix[(i-a),]-t(meanvalues))


Do you think this is correct?

One further question: You also told me, that I do not have to
initialize my dummy2, what does this mean? I wrote dummy2<-0 because I
have to create this variable before using it for the loop?

2013/6/2 Berend Hasselman <bhh at xs4all.nl>:
>
> On 02-06-2013, at 19:03, Neuman Co <neumancohu at gmail.com> wrote:
>
>> Thanks a lot for your answer, one more question:
>> I now use 100 values, so not infinity values. That means I cut some
>> values off, so the weights will not sum up to one. With which factor
>> do I have to multiply the (1-lambda)*summe2 to rescale it? So that I
>> do not always underestimate the variance anymore?
>>
>
> I don't know but maybe something like this
>
> 1/sum(lambda^((1:100)-1))/(1-lambda)
>
> which in your case is 1.000027
>
> Berend
>
>> 2013/6/2 Berend Hasselman <bhh at xs4all.nl>:
>>>
>>> On 02-06-2013, at 15:17, Neuman Co <neumancohu at gmail.com> wrote:
>>>
>>>> Hi,
>>>> since I want to calculate the VaR of a portfolio consiting of 4 assets
>>>> (returns saved into "eonreturn","henkelreturn" and so on) I have to
>>>> estimate the covariance matrix. I do not want to take the rectangular
>>>> version with equal weights, but the exponentially weighted moving
>>>> average in a multivariate version. I want to estimate a covariance
>>>> matrix at every time point t. Then I want to comput the VaR at this
>>>> time point t. Afterwards, I will look at the exceedances and do a
>>>> backtest.
>>>>
>>>> I tried to implement it as follows (data attached):
>>>>
>>>> lambda<-0.9
>>>>
>>>> summe2<-0
>>>> dummy2<-0
>>>> covestiexpo<-list(NA)
>>>> meanvalues<-NA
>>>> for(i in 101:length(eonreturn)){
>>>> meanvalues<-matrix(c(mean(eonreturn[(i-100):(i-1)]),mean(henkelreturn[(i-100):(i-1)]),mean(siemensreturn[(i-100):(i-1)]),mean(adidasreturn[(i-100):(i-1)])),4)
>>>> for(a in 1:100){
>>>> dummy2<-lambda^(a-1)*t(datamatrix[(i-a),]-t(meanvalues))%*%(datamatrix[(i-a),]-t(meanvalues))
>>>> summe2<-summe2+dummy2
>>>> }
>>>> covestiexpo[[i]]<-(1-lambda)*summe2
>>>> }
>>>>
>>>>
>>>> So the covestieexpo[[101]] would be the covariance estimate for the
>>>> 101th day, taking into account the last 100 observations. Now, the
>>>> problem is, that there seems to be something wrong, since the
>>>> covariance estimates are cleraly wrong, they seem to be too big. At
>>>> the beginning, compared to the normal covariance estimate the
>>>> difference is as follows:
>>>>
>>>> covestiexpo[[101]]
>>>>           [,1]        [,2]        [,3]        [,4]
>>>> [1,] 0.004559042 0.002346775 0.004379735 0.003068916
>>>> [2,] 0.002346775 0.001978469 0.002536891 0.001909276
>>>> [3,] 0.004379735 0.002536891 0.005531590 0.003259803
>>>> [4,] 0.003068916 0.001909276 0.003259803 0.003140198
>>>>
>>>>
>>>>
>>>> compared to cov(datamatrix[1:100,])
>>>>            [,1]         [,2]         [,3]        [,4]
>>>> [1,] 0.0018118239 0.0007432779 0.0015301070 0.001119120
>>>> [2,] 0.0007432779 0.0008355960 0.0009281029 0.000754449
>>>> [3,] 0.0015301070 0.0009281029 0.0021073171 0.001269626
>>>> [4,] 0.0011191199 0.0007544490 0.0012696257 0.001325716
>>>>
>>>> So already here, it is obvious, that something is not correct, if I
>>>> look at a period far ahead:
>>>>
>>>> covestiexpo[[1200]]
>>>>
>>>>         [,1]      [,2]      [,3]      [,4]
>>>> [1,] 0.5312575 0.1939061 0.3419379 0.2475233
>>>> [2,] 0.1939061 0.3204951 0.2303478 0.2022423
>>>> [3,] 0.3419379 0.2303478 0.5288435 0.2943051
>>>> [4,] 0.2475233 0.2022423 0.2943051 0.4599648
>>>>
>>>>
>>>> you can see, that the values are way too large, so where is my mistake?
>>>
>>> Without actual data this is an unverifiable statement.
>>> But you probably have to move the statement
>>>
>>> summe2 <- 0
>>>
>>> to inside the i-forloop just before the a-forloop.
>>>
>>> summe2 <- 0
>>> for(a in 1:100){
>>> ?
>>>
>>> so that summe2 is initialized to 0 every time you use it as an accumulator in the a-forloop.
>>> Furthermore there is no need to initialize dummy2. It gets overwritten continuously.
>>>
>>> Berend
>>>
>>>
>>
>>
>>
>> --
>> Neumann, Conrad
>



-- 
Neumann, Conrad


From bhh at xs4all.nl  Sun Jun  2 19:57:37 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 2 Jun 2013 19:57:37 +0200
Subject: [R] Multivariate EWMA covariance estimator?
In-Reply-To: <CADih64T7rVUFZe1scTAhJpsyrj6pAcm5r5m_yeOiQCUq3GDjOA@mail.gmail.com>
References: <CADih64QyTxh7hAOfeKz=MLg35N8RHhyS39mEddDepSKh3rbqaQ@mail.gmail.com>
	<0E3FA5A0-C12C-4183-8050-B0F768892988@xs4all.nl>
	<CADih64QbAuJyf7aHj9vD6_yD+poFfLHraQwOBfbA4SL1UUguig@mail.gmail.com>
	<44EF9921-A4DA-4DE4-ADC6-CF1488E1D6B5@xs4all.nl>
	<CADih64T7rVUFZe1scTAhJpsyrj6pAcm5r5m_yeOiQCUq3GDjOA@mail.gmail.com>
Message-ID: <15A9D348-0D0C-469B-931A-96B2CBD4AA16@xs4all.nl>


On 02-06-2013, at 19:45, Neuman Co <neumancohu at gmail.com> wrote:

> Again, a big thanks for your answer.
> 
> On this webpage:
> http://financetrainingcourse.com/education/2010/03/master-class-calculating-value-at-risk-var-final-steps/
> 
> I found, that I have to rescale by dividing the weights calculated in
> Step B2 by 1-?n
> 
> The "?" is the lambda, since the webpage cannot display it, I also
> found it on another webpage, therefore, I changed my code to the
> following:
> 
> dummy2<-lambda^(a-1)/(1-lambda^100)*t(datamatrix[(i-a),]-t(meanvalues))%*%(datamatrix[(i-a),]-t(meanvalues))
> 
> 
> Do you think this is correct?
> 

I'm not going to do homework.
You have to scale the weights. So you need to scale lambda^(a-1) by their sum for a=1:100 if I understand correctly.

> One further question: You also told me, that I do not have to
> initialize my dummy2, what does this mean?

Exactly that: you don't have to initialize dummy2.
You are assigning a value to dummy2 for each value of a.
You are thus either creating a new object dummy2  or overwriting any existing object dummy2 and thus destroying a previous value.

> I wrote dummy2<-0 because I
> have to create this variable before using it for the loop?
> 

You are not using it on the righthand side of an expression. You are assigning to it.
You only need to initialize dummy2 if you have an expression involving dummy2 on the righthand side e.g.  dummy2 <- dummy2 + ??

Berend

> 2013/6/2 Berend Hasselman <bhh at xs4all.nl>:
>> 
>> On 02-06-2013, at 19:03, Neuman Co <neumancohu at gmail.com> wrote:
>> 
>>> Thanks a lot for your answer, one more question:
>>> I now use 100 values, so not infinity values. That means I cut some
>>> values off, so the weights will not sum up to one. With which factor
>>> do I have to multiply the (1-lambda)*summe2 to rescale it? So that I
>>> do not always underestimate the variance anymore?
>>> 
>> 
>> I don't know but maybe something like this
>> 
>> 1/sum(lambda^((1:100)-1))/(1-lambda)
>> 
>> which in your case is 1.000027
>> 
>> Berend
>> 
>>> 2013/6/2 Berend Hasselman <bhh at xs4all.nl>:
>>>> 
>>>> On 02-06-2013, at 15:17, Neuman Co <neumancohu at gmail.com> wrote:
>>>> 
>>>>> Hi,
>>>>> since I want to calculate the VaR of a portfolio consiting of 4 assets
>>>>> (returns saved into "eonreturn","henkelreturn" and so on) I have to
>>>>> estimate the covariance matrix. I do not want to take the rectangular
>>>>> version with equal weights, but the exponentially weighted moving
>>>>> average in a multivariate version. I want to estimate a covariance
>>>>> matrix at every time point t. Then I want to comput the VaR at this
>>>>> time point t. Afterwards, I will look at the exceedances and do a
>>>>> backtest.
>>>>> 
>>>>> I tried to implement it as follows (data attached):
>>>>> 
>>>>> lambda<-0.9
>>>>> 
>>>>> summe2<-0
>>>>> dummy2<-0
>>>>> covestiexpo<-list(NA)
>>>>> meanvalues<-NA
>>>>> for(i in 101:length(eonreturn)){
>>>>> meanvalues<-matrix(c(mean(eonreturn[(i-100):(i-1)]),mean(henkelreturn[(i-100):(i-1)]),mean(siemensreturn[(i-100):(i-1)]),mean(adidasreturn[(i-100):(i-1)])),4)
>>>>> for(a in 1:100){
>>>>> dummy2<-lambda^(a-1)*t(datamatrix[(i-a),]-t(meanvalues))%*%(datamatrix[(i-a),]-t(meanvalues))
>>>>> summe2<-summe2+dummy2
>>>>> }
>>>>> covestiexpo[[i]]<-(1-lambda)*summe2
>>>>> }
>>>>> 
>>>>> 
>>>>> So the covestieexpo[[101]] would be the covariance estimate for the
>>>>> 101th day, taking into account the last 100 observations. Now, the
>>>>> problem is, that there seems to be something wrong, since the
>>>>> covariance estimates are cleraly wrong, they seem to be too big. At
>>>>> the beginning, compared to the normal covariance estimate the
>>>>> difference is as follows:
>>>>> 
>>>>> covestiexpo[[101]]
>>>>>          [,1]        [,2]        [,3]        [,4]
>>>>> [1,] 0.004559042 0.002346775 0.004379735 0.003068916
>>>>> [2,] 0.002346775 0.001978469 0.002536891 0.001909276
>>>>> [3,] 0.004379735 0.002536891 0.005531590 0.003259803
>>>>> [4,] 0.003068916 0.001909276 0.003259803 0.003140198
>>>>> 
>>>>> 
>>>>> 
>>>>> compared to cov(datamatrix[1:100,])
>>>>>           [,1]         [,2]         [,3]        [,4]
>>>>> [1,] 0.0018118239 0.0007432779 0.0015301070 0.001119120
>>>>> [2,] 0.0007432779 0.0008355960 0.0009281029 0.000754449
>>>>> [3,] 0.0015301070 0.0009281029 0.0021073171 0.001269626
>>>>> [4,] 0.0011191199 0.0007544490 0.0012696257 0.001325716
>>>>> 
>>>>> So already here, it is obvious, that something is not correct, if I
>>>>> look at a period far ahead:
>>>>> 
>>>>> covestiexpo[[1200]]
>>>>> 
>>>>>        [,1]      [,2]      [,3]      [,4]
>>>>> [1,] 0.5312575 0.1939061 0.3419379 0.2475233
>>>>> [2,] 0.1939061 0.3204951 0.2303478 0.2022423
>>>>> [3,] 0.3419379 0.2303478 0.5288435 0.2943051
>>>>> [4,] 0.2475233 0.2022423 0.2943051 0.4599648
>>>>> 
>>>>> 
>>>>> you can see, that the values are way too large, so where is my mistake?
>>>> 
>>>> Without actual data this is an unverifiable statement.
>>>> But you probably have to move the statement
>>>> 
>>>> summe2 <- 0
>>>> 
>>>> to inside the i-forloop just before the a-forloop.
>>>> 
>>>> summe2 <- 0
>>>> for(a in 1:100){
>>>> ?
>>>> 
>>>> so that summe2 is initialized to 0 every time you use it as an accumulator in the a-forloop.
>>>> Furthermore there is no need to initialize dummy2. It gets overwritten continuously.
>>>> 
>>>> Berend
>>>> 
>>>> 
>>> 
>>> 
>>> 
>>> --
>>> Neumann, Conrad
>> 
> 
> 
> 
> -- 
> Neumann, Conrad


From jfox at mcmaster.ca  Sun Jun  2 20:03:29 2013
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 2 Jun 2013 14:03:29 -0400
Subject: [R] measuring distances between colours?
In-Reply-To: <CAKFxdiSywvZEbuOurrP+K8xDZMZR3napE4XWEttRJOuUH=tc3w@mail.gmail.com>
References: <4382_1369916184_r4UCGK5j024861_web-459777071@cgpsrv2.cis.mcmaster.ca>	<004601ce5d7a$9f16fc00$dd44f400$@mcmaster.ca>	<20904.20143.918220.744897@stat.math.ethz.ch>	<CAKFxdiSHPCgsVCaaJDfedX8b2ZAHbTdNNYktjHzUk=0XtG=ayA@mail.gmail.com>	<007001ce5e58$7776a400$6663ec00$@mcmaster.ca>	<51AA1436.2020909@yorku.ca>	<000f01ce5ee5$46b1c420$d4154c60$@mcmaster.ca>
	<CAKFxdiSywvZEbuOurrP+K8xDZMZR3napE4XWEttRJOuUH=tc3w@mail.gmail.com>
Message-ID: <000a01ce5fbb$7d5ca630$7815f290$@mcmaster.ca>

Dear Kevin,

When computer code is bug free, we'll probably all be out of business. Thank
you for improving my original code.

Best,
 John

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Kevin Wright
> Sent: Sunday, June 02, 2013 10:43 AM
> To: John Fox
> Cc: r-help; Michael Friendly; Martin Maechler
> Subject: Re: [R] measuring distances between colours?
> 
> Sorry about the bug. How embarrassing. Especially because I've learned
> over
> the years to trust my gut feelings when something doesn't feel quite
> right,
> and when I was testing the function, I remember thinking "surely there
> a
> better matching named color than 'magenta'".
> 
> Thanks for the fix.
> 
> Kevin
> 
> 
> 
> On Sat, Jun 1, 2013 at 11:30 AM, John Fox <jfox at mcmaster.ca> wrote:
> 
> > Hi Michael,
> >
> > This has become a bit of a comedy of errors.
> >
> > The bug is in Kevin Wright's code, which I adapted, and you too in
> your
> > version, which uses local() rather than function() to produce the
> closure.
> > The matrix which.col contains character data, as a consequence of
> binding
> > the minimum squared distances to colour names, and thus the
> comparison
> > cols.near[2,] < near^2 doesn't work properly when, ironically, the
> distance
> > is small enough so that it's rendered in scientific notation.
> >
> > Converting to numeric appears to work:
> >
> > > rgb2col2 <- local({
> > +     all.names <- colors()
> > +     all.hsv <- rgb2hsv(col2rgb(all.names))
> > +     find.near <- function(x.hsv) {
> > +         # return the nearest R color name and distance
> > +         sq.dist <- colSums((all.hsv - x.hsv)^2)
> > +         rbind(all.names[which.min(sq.dist)], min(sq.dist))
> > +     }
> > +     function(cols.hex, near=.25){
> > +         cols.hsv <- rgb2hsv(col2rgb(cols.hex))
> > +         cols.near <- apply(cols.hsv, 2, find.near)
> > +         ifelse(as.numeric(cols.near[2,]) <= near^2, cols.near[1,],
> > cols.hex)
> > +     }
> > + })
> >
> > > rgb2col2(c("#010101", "#EEEEEE", "#AA0000", "#00AA00", "#0000AA",
> > +     "#AAAA00", "#AA00AA", "#00AAAA"))
> >
> > [1] "black"         "gray93"        "darkred"       "green4"
> "blue4"
> > "darkgoldenrod"
> > [7] "darkmagenta"   "cyan4"
> >
> > The same bug is in the code that I just posted using Lab colours, so
> (for
> > posterity) here's a fixed version of that, using local():
> >
> > > rgb2col <- local({
> > +     all.names <- colors()
> > +     all.lab <- t(convertColor(t(col2rgb(all.names)), from = "sRGB",
> > +         to = "Lab", scale.in = 255))
> > +     find.near <- function(x.lab) {
> > +         sq.dist <- colSums((all.lab - x.lab)^2)
> > +         rbind(all.names[which.min(sq.dist)], min(sq.dist))
> > +     }
> > +     function(cols.hex, near = 2.3) {
> > +         cols.lab <- t(convertColor(t(col2rgb(cols.hex)), from =
> "sRGB",
> > +             to = "Lab", scale.in = 255))
> > +         cols.near <- apply(cols.lab, 2, find.near)
> > +         ifelse(as.numeric(cols.near[2, ]) < near^2, cols.near[1, ],
> > toupper(cols.hex))
> > +     }
> > + })
> >
> > > rgb2col(c("#010101", "#EEEEEE", "#AA0000", "#00AA00", "#0000AA",
> > "#AAAA00", "#AA00AA", "#00AAAA"))
> >
> > [1] "black"   "gray93"  "#AA0000" "#00AA00" "#0000AA" "#AAAA00"
> > [7] "#AA00AA" "#00AAAA"
> >
> > > rgb2col(c("#010101", "#EEEEEE", "#AA0000", "#00AA00", "#0000AA",
> > "#AAAA00", "#AA00AA", "#00AAAA"), near=15)
> >
> > [1] "black"         "gray93"        "firebrick3"    "limegreen"
> > [5] "blue4"         "#AAAA00"       "darkmagenta"   "lightseagreen"
> >
> > So with Lab colours, setting near to the JND of 2.3 leaves many of
> these
> > colours unmatched. I experimented a bit, and using 15 (as above)
> produces
> > matches that appear reasonably "close" to me.
> >
> > I used squared distances to avoid taking the square-roots of all the
> > distances. Since the criterion for "near" colours, which is on the
> distance
> > scale, is squared to make the comparison, this shouldn't be
> problematic.
> >
> > I hope that finally this will be a satisfactory solution.
> >
> > Best,
> >  John
> >
> > > -----Original Message-----
> > > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> > > project.org] On Behalf Of Michael Friendly
> > > Sent: Saturday, June 01, 2013 11:33 AM
> > > To: John Fox
> > > Cc: 'r-help'; 'Martin Maechler'
> > > Subject: Re: [R] measuring distances between colours?
> > >
> > > Just a quick note:  The following two versions of your function
> don't
> > > give the same results.  I'm not sure why, and also not sure why the
> > > criterion for 'near' should be expressed in squared distance.
> > >
> > > # version 1
> > > rgb2col <- local({
> > >      hex2dec <- function(hexnums) {
> > >          # suggestion of Eik Vettorazzi
> > >          sapply(strtoi(hexnums, 16L), function(x) x %/% 256^(2:0)
> %%
> > > 256)
> > >      }
> > >      findMatch <- function(dec.col) {
> > >          sq.dist <- colSums((hsv - dec.col)^2)
> > >          rbind(which.min(sq.dist), min(sq.dist))
> > >      }
> > >      colors <- colors()
> > >      hsv <- rgb2hsv(col2rgb(colors))
> > >
> > >      function(cols, near=0.25) {
> > >          cols <- sub("^#", "", toupper(cols))
> > >          dec.cols <- rgb2hsv(hex2dec(cols))
> > >          which.col <- apply(dec.cols, 2, findMatch)
> > >          matches <- colors[which.col[1, ]]
> > >          unmatched <- which.col[2, ] > near^2
> > >          matches[unmatched] <- paste("#", cols[unmatched], sep="")
> > >          matches
> > >      }
> > > })
> > >
> > > # version 2
> > > rgb2col2 <- local({
> > >        all.names <- colors()
> > >        all.hsv <- rgb2hsv(col2rgb(all.names))
> > >        find.near <- function(x.hsv) {
> > >            # return the nearest R color name and distance
> > >            sq.dist <- colSums((all.hsv - x.hsv)^2)
> > >            rbind(all.names[which.min(sq.dist)], min(sq.dist))
> > >        }
> > >        function(cols.hex, near=.25){
> > >            cols.hsv <- rgb2hsv(col2rgb(cols.hex))
> > >            cols.near <- apply(cols.hsv, 2, find.near)
> > >            ifelse(cols.near[2,] < near^2, cols.near[1,], cols.hex)
> > >        }
> > > })
> > >
> > > # tests
> > >  > rgb2col(c("#010101", "#EEEEEE", "#AA0000", "#00AA00", "#0000AA",
> > > "#AAAA00", "#AA00AA", "#00AAAA"))
> > > [1] "black"         "gray93"        "darkred"       "green4"
> > > [5] "blue4"         "darkgoldenrod" "darkmagenta"   "cyan4"
> > >  > rgb2col2(c("#010101", "#EEEEEE", "#AA0000", "#00AA00",
> "#0000AA",
> > > "#AAAA00", "#AA00AA", "#00AAAA"))
> > > [1] "#010101"       "#EEEEEE"       "darkred"       "green4"
> > > [5] "blue4"         "darkgoldenrod" "darkmagenta"   "cyan4"
> > >  >
> > >
> > >
> > > On 5/31/2013 7:42 PM, John Fox wrote:
> > > > Dear Kevin,
> > > >
> > > > I generally prefer your solution. I didn't realize that col2rgb()
> > > worked
> > > > with hex-colour input (as opposed to named colours), so my code
> > > converting
> > > > hex numbers to decimal is unnecessary; and using ifelse() is
> clearer
> > > than
> > > > replacing the non-matches.
> > > >
> > > > I'm not so sure about avoiding the closure, since for converting
> > > small
> > > > numbers of colours, your function will spend most of its time
> > > constructing
> > > > the local function find.near() and building all.hsv. Here's an
> > > example,
> > > > using your rgb2col() and a comparable function employing a
> closure,
> > > with one
> > > > of your examples executed 100 times:
> > > >
> > > >> r2c <- function(){
> > > > +     all.names <- colors()
> > > > +     all.hsv <- rgb2hsv(col2rgb(all.names))
> > > > +     find.near <- function(x.hsv) {
> > > > +         # return the nearest R color name and distance
> > > > +         sq.dist <- colSums((all.hsv - x.hsv)^2)
> > > > +         rbind(all.names[which.min(sq.dist)], min(sq.dist))
> > > > +     }
> > > > +     function(cols.hex, near=.25){
> > > > +         cols.hsv <- rgb2hsv(col2rgb(cols.hex))
> > > > +         cols.near <- apply(cols.hsv, 2, find.near)
> > > > +         ifelse(cols.near[2,] < near^2, cols.near[1,], cols.hex)
> > > > +     }
> > > > + }
> > > >
> > > >> mycols <- c("#010101", "#EEEEEE", "#AA0000", "#00AA00",
> "#0000AA",
> > > > +     "#AAAA00", "#AA00AA", "#00AAAA")
> > > >
> > > >> system.time(for (i in 1:100) oldnew <- c(mycols, rgb2col(mycols,
> > > > near=.25)))
> > > >     user  system elapsed
> > > >     1.97    0.00    1.97
> > > >
> > > >> system.time({rgb2col2 <- r2c()
> > > > +     for (i in 1:100) oldnew2 <- c(mycols, rgb2col2(mycols,
> > > near=.25))
> > > > +     })
> > > >     user  system elapsed
> > > >     0.08    0.00    0.08
> > > >
> > > >> rbind(oldnew, oldnew2)
> > > >          [,1]      [,2]      [,3]      [,4]      [,5]      [,6]
> > > > oldnew  "#010101" "#EEEEEE" "#AA0000" "#00AA00" "#0000AA"
> "#AAAA00"
> > > > oldnew2 "#010101" "#EEEEEE" "#AA0000" "#00AA00" "#0000AA"
> "#AAAA00"
> > > >          [,7]      [,8]      [,9]      [,10]     [,11]     [,12]
> > > > oldnew  "#AA00AA" "#00AAAA" "#010101" "#EEEEEE" "darkred"
> "green4"
> > > > oldnew2 "#AA00AA" "#00AAAA" "#010101" "#EEEEEE" "darkred"
> "green4"
> > > >          [,13]   [,14]           [,15]         [,16]
> > > > oldnew  "blue4" "darkgoldenrod" "darkmagenta" "cyan4"
> > > > oldnew2 "blue4" "darkgoldenrod" "darkmagenta" "cyan4"
> > > >
> > > > Does this really make a difference? Frankly, it wouldn't for my
> > > application
> > > > (for colour selection in the Rcmdr) where a user is likely to
> perform
> > > at
> > > > most one or two conversions of a small number of colours in a
> > > session. The
> > > > time advantage of the second approach will depend upon the number
> of
> > > times
> > > > the function is invoked and the number of colours converted each
> > > time.
> > > >
> > > > Best,
> > > >   John
> > > >
> > > >> -----Original Message-----
> > > >> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> > > >> project.org] On Behalf Of Kevin Wright
> > > >> Sent: Friday, May 31, 2013 3:39 PM
> > > >> To: Martin Maechler
> > > >> Cc: r-help; John Fox
> > > >> Subject: Re: [R] measuring distances between colours?
> > > >>
> > > >> Thanks for the discussion.  I've also wanted to be able to find
> > > nearest
> > > >> colors.  I took the code and comments in this thread and
> simplified
> > > the
> > > >> function even further.  (Personally, I think using closures
> results
> > > in
> > > >> Rube-Goldberg code.  YMMV.)  The first example below is what I
> use
> > > for
> > > >> 'group' colors in lattice.
> > > >>
> > > >> Kevin Wright
> > > >>
> > > >> rgb2col <- function(cols.hex, near=.25){
> > > >>    # Given a vector of hex colors, find the nearest 'named' R
> colors
> > > >>    # If no color closer than 'near' is found, return the hex
> color
> > > >>    # Authors: John Fox, Martin Maechler, Kevin Wright
> > > >>    # From r-help discussion 5.30.13
> > > >>
> > > >>    find.near <- function(x.hsv) {
> > > >>      # return the nearest R color name and distance
> > > >>      sq.dist <- colSums((all.hsv - x.hsv)^2)
> > > >>      rbind(all.names[which.min(sq.dist)], min(sq.dist))
> > > >>    }
> > > >>    all.names <- colors()
> > > >>    all.hsv <- rgb2hsv(col2rgb(all.names))
> > > >>    cols.hsv <- rgb2hsv(col2rgb(cols.hex))
> > > >>    cols.near <- apply(cols.hsv, 2, find.near)
> > > >>    ifelse(cols.near[2,] < near^2, cols.near[1,], cols.hex)
> > > >> }
> > > >>
> > > >> mycols <- c("royalblue", "red", "#009900", "dark orange",
> "#999999",
> > > >> "#a6761d", "#aa00da")
> > > >> mycols <- c("#010101", "#EEEEEE", "#AA0000", "#00AA00",
> "#0000AA",
> > > >> "#AAAA00", "#AA00AA", "#00AAAA")
> > > >> mycols <- c("#010101", "#090909", "#090000", "#000900",
> "#000009",
> > > >> "#090900", "#090009", "#000909")
> > > >> oldnew <- c(mycols, rgb2col(mycols, near=.25)) # Also try
> near=10
> > > >> pie(rep(1,2*length(mycols)), labels=oldnew, col=oldnew)
> > > >>
> > > >>    [[alternative HTML version deleted]]
> > > >>
> > > >> ______________________________________________
> > > >> R-help at r-project.org mailing list
> > > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > > >> PLEASE do read the posting guide http://www.R-
> project.org/posting-
> > > >> guide.html
> > > >> and provide commented, minimal, self-contained, reproducible
> code.
> > > >
> > >
> > >
> > > --
> > > Michael Friendly     Email: friendly AT yorku DOT ca
> > > Professor, Psychology Dept. & Chair, Quantitative Methods
> > > York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> > > 4700 Keele Street    Web:   http://www.datavis.ca
> > > Toronto, ONT  M3J 1P3 CANADA
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-
> > > guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> 
> 
> --
> Kevin Wright
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From MSchmidberger at freenet.de  Sun Jun  2 20:54:32 2013
From: MSchmidberger at freenet.de (Markus Schmidberger)
Date: Sun, 2 Jun 2013 20:54:32 +0200
Subject: [R] useR meetup group in Munich,
	Friday 7th: Web Service Frameworks with R
In-Reply-To: <D67C25C2-0B0F-42BA-9830-AA43F2F27E2B@freenet.de>
References: <D67C25C2-0B0F-42BA-9830-AA43F2F27E2B@freenet.de>
Message-ID: <8953C000-77A6-4289-9191-8F8557C7C518@freenet.de>

Dear all,

I would like to invite Munich (Germany) area R users for our second meeting: 7th June 2013. The group is aimed to bring together practitioners from industry and academia in order to exchange knowledge and experience in solving data analysis & statistical problems by using R. More information about the group at: http://www.meetup.com/munich-useR-group/

Our second meeting will host two talks about Web Service Frameworks with R (shiny and RevolutionDeployR).

Meet you in Munich
Markus

From jrkrideau at inbox.com  Sun Jun  2 21:44:42 2013
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 2 Jun 2013 11:44:42 -0800
Subject: [R] Scale package change comma defaults?
Message-ID: <D9DB4E3005E.000004A4jrkrideau@inbox.com>

I was using the comma() funtion in the scales page and was wondering how to chage a  the defaults.  comm(1000) gives me 1,000 which is what I usually want but how would I change the output to 1.000.  

I had thought that I could simply do
comm(1000, big.mark = ".")
but I am getting 
Error in format.default(x, ..., big.mark = ",", scientific = FALSE, trim = TRUE) : 
  formal argument "big.mark" matched by multiple actual arguments

And since I'm here I might as well ask if there is a way to keep a couple fo decemal points rather than rounding to the first integer.

Thanks
John Kane
Kingston ON Canada

sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: i686-pc-linux-gnu (32-bit)

locale:
 [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C               LC_TIME=en_CA.UTF-8       
 [4] LC_COLLATE=en_CA.UTF-8     LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8   
 [7] LC_PAPER=C                 LC_NAME=C                  LC_ADDRESS=C              
[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] scales_0.2.3

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From bbolker at gmail.com  Sun Jun  2 22:57:58 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 2 Jun 2013 20:57:58 +0000
Subject: [R] Scale package change comma defaults?
References: <D9DB4E3005E.000004A4jrkrideau@inbox.com>
Message-ID: <loom.20130602T225338-972@post.gmane.org>

John Kane <jrkrideau <at> inbox.com> writes:

>  I was using the comma() funtion in the scales page and was
> wondering how to chage a the defaults.  comm(1000) gives me 1,000
> which is what I usually want but how would I change the output to
> 1.000.

 Since the comma() function is just a wrapper for format():

> scales::comma
function (x, ...) 
{
    format(x, ..., big.mark = ",", scientific = FALSE, trim = TRUE)
}

Why not just define your own function that does what you want?

myComma <- function (x, big.mark=",", ...) 
{
    format(x, ..., big.mark = big.mark, scientific = FALSE, trim = TRUE)
}

myComma(1000,".")

> I had thought that I could simply do
> comm(1000, big.mark = ".")
> but I am getting 
> Error in format.default(x, ..., big.mark = ",", scientific = FALSE, trim =
TRUE) : 
>   formal argument "big.mark" matched by multiple actual arguments

> And since I'm here I might as well ask if there is a way
> to keep a couple fo decemal points rather than rounding to the first integer.

 Not quite sure what you mean here; see ?format for more details.

format(1200,big.mark=".",nsmall=2)

might be what you want, but if you're going to use "." for big.mark
then you might want:
    
options(OutDec=",")

[1] "1.200,00"


From kpmainali at gmail.com  Sun Jun  2 23:01:05 2013
From: kpmainali at gmail.com (Kumar Mainali)
Date: Sun, 2 Jun 2013 16:01:05 -0500
Subject: [R] X-axis in meandist {vegan}
Message-ID: <CABK368gDN-J0sUnG44nRoOvex=8dDr8S3XHCUd1gpFm0oZpbpA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130602/15603334/attachment.pl>

From mef2153 at columbia.edu  Sun Jun  2 17:57:41 2013
From: mef2153 at columbia.edu (Matthew Fagan)
Date: Sun, 02 Jun 2013 11:57:41 -0400
Subject: [R] Regularized Discriminant Analysis scores, anyone?
In-Reply-To: <51AB5922.9070703@statistik.tu-dortmund.de>
References: <51AAB599.9090109@columbia.edu>
	<51AB5922.9070703@statistik.tu-dortmund.de>
Message-ID: <51AB6B75.5030007@columbia.edu>

Thank you Dr. Ligges, i very much appreciate the quick reply.  i 
wondered if that was the case, based on the math as I (poorly) 
understood it.  However i remain confused.   page 107 from the "rrcov" 
package PDF makes me think I can derive LDA-style discriminant scores 
for a QDA:

library(rrcov)
data(iris)
qda1<-QdaClassic(x=iris[,1:4], grouping=iris[,5])
pred_qda<-predict(qda1, iris[,1:4])
head(pred_qda at x)
plotdat<-pred_qda at x
plot(plotdat[,1], plotdat[,2])
plot(plotdat[,2], plotdat[,3])

pred_qda$x looks like QDA discriminant scores.   No doubt you are right, 
but if you have a moment, I'd love to know what these scores are and 
what they summarize.

In addition, I have run into this nice set of lengthy R code to manually 
calculate discriminant scores for a QDA:
https://cs.uwaterloo.ca/~a2curtis/courses/2005/ML-classification.pdf

None of this means i can calculate discriminant scores for a RDA, of 
course, but QDA is my back-up choice.

Bottom line: am i am completely misinterpreting what I am seeing here, 
mathematically?  Or is this just the result of different ways of 
implementing QDA in R?

Regards, and thanks again,
Matt


On 6/2/2013 10:39 AM, Uwe Ligges wrote:
>
>
> On 02.06.2013 05:01, Matthew Fagan wrote:
>> Hi all,
>>
>> I am attempting to do Regularized Discriminant Analysis (RDA) on a large
>> dataset, and I want to extract the RDA  discriminant score matrix.  But
>> the predict function in the "klaR" package, unlike the predict function
>> for LDA in the "MASS" package, doesn't seem to give me an option to
>> extract the scores.  Any suggestions?
>
> There are no such scores:
>
> same as for qda, you do not follow the Fisher idea of the linear 
> discriminant components any more: Your space is now partitioned by 
> ellipsoid like structures based on the estimation of the inner-class 
> covariance matrices.
>
> rda as implemented in klaR (see the reference given on the help page) 
> is a regularization that helps to overcome problems when estimating 
> non-singular covariance matrices for the separate classes.
>
>
>> i have already tried (and failed; ran out of 16 GB of memory) to do this
>> with the "rda" package: don't know why, but the klaR package seems to be
>> much more efficient with memory.  I have included an example below:
>
> The rda package provides a completely different regularization 
> technique, see the reference given on the help page.
>
> Best,
> Uwe Ligges
>
>
>
>
>> library(klaR)
>> library(MASS)
>>
>> data(iris)
>>
>> x <- rda(Species ~ ., data = iris, gamma = 0.05, lambda = 0.2)
>> rda1<-predict(x, iris[, 1:4])
>> str(rda1)
>>
>> #  This gets you an object with posterior probabilities and classes, but
>> no discriminant scores!
>>
>> #  if you run lda
>>
>> y <- lda(Species ~ ., data = iris)
>> lda1<-predict(y, iris[, 1:4])
>> str(lda1)
>>
>> head(lda1$x)  #  gets you the discriminant scores for the LDA. But how
>> to do this for RDA?
>>
>> #  curiously, the QDA function in MASS has this same problem, although
>> you can get around it using the rrcov package.
>>
>> Regards, and thank very much for any help,
>> Matt
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Matthew Fagan
Columbia University
Department of Ecology, Evolution, and Environmental Biology
512-569-1417 (cell/home)
(212) 854-9987 (office)
(212) 854-8188 (fax)


From sascha.sandragesan at stud.unibas.ch  Sun Jun  2 17:09:47 2013
From: sascha.sandragesan at stud.unibas.ch (Sascha Sandragesan)
Date: Sun, 2 Jun 2013 15:09:47 +0000
Subject: [R] Problem with package 'mi' for multiple imputation
Message-ID: <0F22FB3FD1560E42BD99848C0689A4BA628F2AED@urz-mbx-4.urz.unibas.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130602/61b12b5b/attachment.pl>

From erling.froysa at gmail.com  Sun Jun  2 19:15:42 2013
From: erling.froysa at gmail.com (=?ISO-8859-1?Q?Erling_Johan_Fr=F8ysa?=)
Date: Sun, 2 Jun 2013 19:15:42 +0200
Subject: [R] Strange behaviour of R graphics copied to PowerPoint
Message-ID: <CAJSLS6UVLAp1AtH-u6XebB+qfgvddsgLvApCJYqkQ8Q69qw7Ew@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130602/c94625d9/attachment.pl>

From kuma0177 at gmail.com  Sun Jun  2 23:16:10 2013
From: kuma0177 at gmail.com (Piyush Kumar)
Date: Sun, 2 Jun 2013 14:16:10 -0700
Subject: [R] Plot 2 different time series data with 2 y axes
Message-ID: <CAGAqBuxtP_-kteDqjbRiHLJNJZoTFF2asOgAcw2XCz3p2gSvKA@mail.gmail.com>

Hello

I am new to R and I have been trying to plot 2 different time series with 2
y axes. I have been able to plot it so far with 2 y axis but the x axis is
not shifted. I mean, the x range for data1 from day1 and xrange for data2
is from day2, however my plot overlaps the 2 x-axis. Below is the code with
comments.

Rplot_x_over_y = function( df1, df2, left_data_type, right_data_type){

#df1 contains data from day1, and its in POSIX time,
eg: [1] "2013-04-03 00:00:00 UTC" "2013-04-03 00:01:00 UTC"
  [3] "2013-04-03 00:02:00 UTC" "2013-04-03 00:03:00 UTC"
   [5] "2013-04-03 00:04:00 UTC" "2013-04-03 00:05:00 UTC"

#df2 contains data from day2 and is in posix time
[1] "2013-04-04 00:00:00 UTC" "2013-04-04 00:01:00 UTC"
[3] "2013-04-04 00:02:00 UTC" "2013-04-04 00:03:00 UTC"
[5] "2013-04-04 00:04:00 UTC" "2013-04-04 00:05:00 UTC"

  time<-df1[[1]]
  time2<-df2[[1]]
  y1<-df1[[2]]
  y2<-df2[[2]]
  xleft_limit_min = min(time)
  x_left_limit_max = max(time)
  y_left_limit_max = min(time)
  xright_limit_max = max(time2)

  x_range<-c(xleft_limit, xright_limit)
  print(x_range)
  par(mar=c(5,4,4,5)+.1)
  plot(time ,y1,type="l",col="red", ylab=left_data_type)
  par(new=TRUE)
  plot(time2, y2,,type="l",col="blue", xaxt="n" , yaxt="n",xlab="",ylab="")
  axis(4)
  mtext(right_data_type,side=4,line=3)
  legend("topright",col=c("red","blue"),lty=1,legend=c(left_data_type,
right_data_type))
  grid (10,10, lty = 6, col = "cornsilk2")
}

I would expect the plots to have different starting points for  x values
but it seems its unable to understand the dates are different.  A
screenshot is attached. How can I fix it ?

Thanks
-P
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screen Shot 2013-06-02 at 1.55.49 PM.png
Type: image/png
Size: 262139 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130602/0d2dcaab/attachment.png>

From zodiacpc at gmail.com  Mon Jun  3 01:37:29 2013
From: zodiacpc at gmail.com (Devin Moore)
Date: Sun, 2 Jun 2013 18:37:29 -0500
Subject: [R] Conditional Forecast with MSBVAR
Message-ID: <B5800FAB-38BA-4710-BA1D-FE3743CD3F2B@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130602/7a99f072/attachment.pl>

From jari.oksanen at oulu.fi  Mon Jun  3 06:02:21 2013
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Mon, 3 Jun 2013 04:02:21 +0000
Subject: [R] X-axis in meandist {vegan}
In-Reply-To: <CABK368gDN-J0sUnG44nRoOvex=8dDr8S3XHCUd1gpFm0oZpbpA@mail.gmail.com>
References: <CABK368gDN-J0sUnG44nRoOvex=8dDr8S3XHCUd1gpFm0oZpbpA@mail.gmail.com>
Message-ID: <B02549AF-8215-4DCC-9DFC-32E2E4171B3A@oulu.fi>

Dear Kumar Mainali, 

On 03/06/2013, at 00:01 AM, Kumar Mainali wrote:

> I am using vegan package for estimating dissimilarity within and between clusters, and plotting them. The following code gives me a dendrogram without X-axis. How would I add X axis to the plot? Below "dataEnv" is a matrix of my environmental variables. dataFact$Source_by_Type has the levels that delineate clusters.
> 
> dataEnvDist <- vegdist(dataEnv, method="bray") ## bray curtis dissimilarity
> meanDist <- meandist(dataEnvDist, dataFact$Source_by_Type)
> plot(meanDist, ylab="Mean dissimilarity")
> 

What should the X-axis show? 

You can add X-axis with command axis(1), but it hardly shows anything useful.

Cheers, Jari Oksanen

--
Jari Oksanen, Dept Biology, Univ Oulu, 90014 Finland


From christoph.knapp01 at gmail.com  Mon Jun  3 06:05:21 2013
From: christoph.knapp01 at gmail.com (Christoph Knapp)
Date: Mon, 03 Jun 2013 16:05:21 +1200
Subject: [R] 3.0.1 update and compiler package
In-Reply-To: <51A80BDE.9090007@gmail.com>
References: <51A80BDE.9090007@gmail.com>
Message-ID: <51AC1601.4010106@gmail.com>

Hello,
would it be possible to make a decision whether this forwarded to the 
list or declined. Its now 2 days.

Thanks

Christoph

On 31/05/13 14:33, Christoph Knapp wrote:
> Hi,
> I recently updated to R 3.0.1. I'm running linux ubuntu 12.04. I 
> realized that I have to update all the installed packages so I run > 
> update.packages(checkBuilt=TRUE)
> as described here 
> http://www.r-bloggers.com/r-3-0-0-is-released-whats-new-and-how-to-upgrade/ 
> . The first thing it did was telling me that it will not update 
> several packages. When it was finished I used the warnings function to 
> have a look at what did not work. See the list below.
>
> > warnings()
> Warning messages:
> 1: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?boot? had non-zero exit status
> 2: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?cluster? had non-zero exit status
> 3: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?foreign? had non-zero exit status
> 4: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?KernSmooth? had non-zero exit status
> 5: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?MASS? had non-zero exit status
> 6: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?Matrix? had non-zero exit status
> 7: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?nlme? had non-zero exit status
> 8: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?nnet? had non-zero exit status
> 9: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?rpart? had non-zero exit status
> 10: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?spatial? had non-zero exit status
> 11: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?survival? had non-zero exit status
> 12: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?class? had non-zero exit status
> 13: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?epiR? had non-zero exit status
> 14: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?gmodels? had non-zero exit status
> 15: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?gplots? had non-zero exit status
> 16: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?mgcv? had non-zero exit status
> 17: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?gregmisc? had non-zero exit status
>
> I tried to reinstall them manually but this always failed because of a 
> package dependency to the "compiler" package. Now, if I try to install 
> the compiler package it tells me.
>
> > install.packages("compiler")
> Installing package into 
> ?/home/christoph/R/x86_64-pc-linux-gnu-library/3.0?
> (as ?lib? is unspecified)
> Warning message:
> package ?compiler? is not available (for R version 3.0.1)
>
> The last line also came up all the time when the packages were updated
>
> Doing a bit of research does not deliver much only that the compiler 
> package was included into R at version 2.13.0 
> (http://dirk.eddelbuettel.com/blog/2011/04/12/).
>
> Most of those packages which do not work any more are pretty important 
> for some of my scripts and I would not even know what packages replace 
> the packages above.
>
> Would anyone know how to fix this?
>
> Regards
>


From kridox at ymail.com  Mon Jun  3 07:19:12 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Mon, 03 Jun 2013 14:19:12 +0900
Subject: [R] 3.0.1 update and compiler package
In-Reply-To: <51A80BDE.9090007@gmail.com>
References: <51A80BDE.9090007@gmail.com>
Message-ID: <51AC2750.3020503@ymail.com>

Hi,

How did you upgraded your version of R? From source or from a Linux package?

Regards,
Pascal


On 05/31/2013 11:33 AM, Christoph Knapp wrote:
> Hi,
> I recently updated to R 3.0.1. I'm running linux ubuntu 12.04. I
> realized that I have to update all the installed packages so I run >
> update.packages(checkBuilt=TRUE)
> as described here
> http://www.r-bloggers.com/r-3-0-0-is-released-whats-new-and-how-to-upgrade/
> . The first thing it did was telling me that it will not update several
> packages. When it was finished I used the warnings function to have a
> look at what did not work. See the list below.
>
>  > warnings()
> Warning messages:
> 1: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?boot? had non-zero exit status
> 2: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?cluster? had non-zero exit status
> 3: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?foreign? had non-zero exit status
> 4: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?KernSmooth? had non-zero exit status
> 5: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?MASS? had non-zero exit status
> 6: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?Matrix? had non-zero exit status
> 7: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?nlme? had non-zero exit status
> 8: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?nnet? had non-zero exit status
> 9: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?rpart? had non-zero exit status
> 10: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?spatial? had non-zero exit status
> 11: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?survival? had non-zero exit status
> 12: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?class? had non-zero exit status
> 13: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?epiR? had non-zero exit status
> 14: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?gmodels? had non-zero exit status
> 15: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?gplots? had non-zero exit status
> 16: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?mgcv? had non-zero exit status
> 17: In install.packages(update[instlib == l, "Package"], l, ... :
> installation of package ?gregmisc? had non-zero exit status
>
> I tried to reinstall them manually but this always failed because of a
> package dependency to the "compiler" package. Now, if I try to install
> the compiler package it tells me.
>
>  > install.packages("compiler")
> Installing package into ?/home/christoph/R/x86_64-pc-linux-gnu-library/3.0?
> (as ?lib? is unspecified)
> Warning message:
> package ?compiler? is not available (for R version 3.0.1)
>
> The last line also came up all the time when the packages were updated
>
> Doing a bit of research does not deliver much only that the compiler
> package was included into R at version 2.13.0
> (http://dirk.eddelbuettel.com/blog/2011/04/12/).
>
> Most of those packages which do not work any more are pretty important
> for some of my scripts and I would not even know what packages replace
> the packages above.
>
> Would anyone know how to fix this?
>
> Regards
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From es at enricoschumann.net  Mon Jun  3 08:56:10 2013
From: es at enricoschumann.net (Enrico Schumann)
Date: Mon, 03 Jun 2013 08:56:10 +0200
Subject: [R] Plot 2 different time series data with 2 y axes
In-Reply-To: <CAGAqBuxtP_-kteDqjbRiHLJNJZoTFF2asOgAcw2XCz3p2gSvKA@mail.gmail.com>
	(Piyush Kumar's message of "Sun, 2 Jun 2013 14:16:10 -0700")
References: <CAGAqBuxtP_-kteDqjbRiHLJNJZoTFF2asOgAcw2XCz3p2gSvKA@mail.gmail.com>
Message-ID: <87ip1vk7hx.fsf@enricoschumann.net>

On Sun, 02 Jun 2013, Piyush Kumar <kuma0177 at gmail.com> writes:

> Hello
>
> I am new to R and I have been trying to plot 2 different time series with 2
> y axes. I have been able to plot it so far with 2 y axis but the x axis is
> not shifted. I mean, the x range for data1 from day1 and xrange for data2
> is from day2, however my plot overlaps the 2 x-axis. Below is the code with
> comments.
>
> Rplot_x_over_y = function( df1, df2, left_data_type, right_data_type){
>
> #df1 contains data from day1, and its in POSIX time,
> eg: [1] "2013-04-03 00:00:00 UTC" "2013-04-03 00:01:00 UTC"
>   [3] "2013-04-03 00:02:00 UTC" "2013-04-03 00:03:00 UTC"
>    [5] "2013-04-03 00:04:00 UTC" "2013-04-03 00:05:00 UTC"
>
> #df2 contains data from day2 and is in posix time
> [1] "2013-04-04 00:00:00 UTC" "2013-04-04 00:01:00 UTC"
> [3] "2013-04-04 00:02:00 UTC" "2013-04-04 00:03:00 UTC"
> [5] "2013-04-04 00:04:00 UTC" "2013-04-04 00:05:00 UTC"
>
>   time<-df1[[1]]
>   time2<-df2[[1]]
>   y1<-df1[[2]]
>   y2<-df2[[2]]
>   xleft_limit_min = min(time)
>   x_left_limit_max = max(time)
>   y_left_limit_max = min(time)
>   xright_limit_max = max(time2)
>
>   x_range<-c(xleft_limit, xright_limit)
>   print(x_range)
>   par(mar=c(5,4,4,5)+.1)
>   plot(time ,y1,type="l",col="red", ylab=left_data_type)
>   par(new=TRUE)
>   plot(time2, y2,,type="l",col="blue", xaxt="n" , yaxt="n",xlab="",ylab="")
>   axis(4)
>   mtext(right_data_type,side=4,line=3)
>   legend("topright",col=c("red","blue"),lty=1,legend=c(left_data_type,
> right_data_type))
>   grid (10,10, lty = 6, col = "cornsilk2")
> }
>
> I would expect the plots to have different starting points for  x values
> but it seems its unable to understand the dates are different.  A
> screenshot is attached. How can I fix it ?
>
> Thanks
> -P
>

Have a look at the zoo-FAQ in package 'zoo': if you have the package
installed, just type 

  vignette("zoo-faq", package = "zoo")

There you find an example how to plot two y-axis.


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From ligges at statistik.tu-dortmund.de  Mon Jun  3 09:37:08 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 03 Jun 2013 09:37:08 +0200
Subject: [R] 3.0.1 update and compiler package
In-Reply-To: <51AC2750.3020503@ymail.com>
References: <51A80BDE.9090007@gmail.com> <51AC2750.3020503@ymail.com>
Message-ID: <51AC47A4.7080603@statistik.tu-dortmund.de>



On 03.06.2013 07:19, Pascal Oettli wrote:
> Hi,
>
> How did you upgraded your version of R? From source or from a Linux
> package?

Actually the new R installation is just broken. It simply has to be 
reinstalled carefully (watch for errors).

Best,
Uwe Ligges






>
> Regards,
> Pascal
>
>
> On 05/31/2013 11:33 AM, Christoph Knapp wrote:
>> Hi,
>> I recently updated to R 3.0.1. I'm running linux ubuntu 12.04. I
>> realized that I have to update all the installed packages so I run >
>> update.packages(checkBuilt=TRUE)
>> as described here
>> http://www.r-bloggers.com/r-3-0-0-is-released-whats-new-and-how-to-upgrade/
>>
>> . The first thing it did was telling me that it will not update several
>> packages. When it was finished I used the warnings function to have a
>> look at what did not work. See the list below.
>>
>>  > warnings()
>> Warning messages:
>> 1: In install.packages(update[instlib == l, "Package"], l, ... :
>> installation of package ?boot? had non-zero exit status
>> 2: In install.packages(update[instlib == l, "Package"], l, ... :
>> installation of package ?cluster? had non-zero exit status
>> 3: In install.packages(update[instlib == l, "Package"], l, ... :
>> installation of package ?foreign? had non-zero exit status
>> 4: In install.packages(update[instlib == l, "Package"], l, ... :
>> installation of package ?KernSmooth? had non-zero exit status
>> 5: In install.packages(update[instlib == l, "Package"], l, ... :
>> installation of package ?MASS? had non-zero exit status
>> 6: In install.packages(update[instlib == l, "Package"], l, ... :
>> installation of package ?Matrix? had non-zero exit status
>> 7: In install.packages(update[instlib == l, "Package"], l, ... :
>> installation of package ?nlme? had non-zero exit status
>> 8: In install.packages(update[instlib == l, "Package"], l, ... :
>> installation of package ?nnet? had non-zero exit status
>> 9: In install.packages(update[instlib == l, "Package"], l, ... :
>> installation of package ?rpart? had non-zero exit status
>> 10: In install.packages(update[instlib == l, "Package"], l, ... :
>> installation of package ?spatial? had non-zero exit status
>> 11: In install.packages(update[instlib == l, "Package"], l, ... :
>> installation of package ?survival? had non-zero exit status
>> 12: In install.packages(update[instlib == l, "Package"], l, ... :
>> installation of package ?class? had non-zero exit status
>> 13: In install.packages(update[instlib == l, "Package"], l, ... :
>> installation of package ?epiR? had non-zero exit status
>> 14: In install.packages(update[instlib == l, "Package"], l, ... :
>> installation of package ?gmodels? had non-zero exit status
>> 15: In install.packages(update[instlib == l, "Package"], l, ... :
>> installation of package ?gplots? had non-zero exit status
>> 16: In install.packages(update[instlib == l, "Package"], l, ... :
>> installation of package ?mgcv? had non-zero exit status
>> 17: In install.packages(update[instlib == l, "Package"], l, ... :
>> installation of package ?gregmisc? had non-zero exit status
>>
>> I tried to reinstall them manually but this always failed because of a
>> package dependency to the "compiler" package. Now, if I try to install
>> the compiler package it tells me.
>>
>>  > install.packages("compiler")
>> Installing package into
>> ?/home/christoph/R/x86_64-pc-linux-gnu-library/3.0?
>> (as ?lib? is unspecified)
>> Warning message:
>> package ?compiler? is not available (for R version 3.0.1)
>>
>> The last line also came up all the time when the packages were updated
>>
>> Doing a bit of research does not deliver much only that the compiler
>> package was included into R at version 2.13.0
>> (http://dirk.eddelbuettel.com/blog/2011/04/12/).
>>
>> Most of those packages which do not work any more are pretty important
>> for some of my scripts and I would not even know what packages replace
>> the packages above.
>>
>> Would anyone know how to fix this?
>>
>> Regards
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kridox at ymail.com  Mon Jun  3 10:32:05 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Mon, 03 Jun 2013 17:32:05 +0900
Subject: [R] 3.0.1 update and compiler package
In-Reply-To: <51AC47A4.7080603@statistik.tu-dortmund.de>
References: <51A80BDE.9090007@gmail.com> <51AC2750.3020503@ymail.com>
	<51AC47A4.7080603@statistik.tu-dortmund.de>
Message-ID: <51AC5485.7040601@ymail.com>

My mistake,

Regards,
Pascal

On 06/03/2013 04:37 PM, Uwe Ligges wrote:
>
>
> On 03.06.2013 07:19, Pascal Oettli wrote:
>> Hi,
>>
>> How did you upgraded your version of R? From source or from a Linux
>> package?
>
> Actually the new R installation is just broken. It simply has to be
> reinstalled carefully (watch for errors).
>
> Best,
> Uwe Ligges
>
>
>
>
>
>
>>
>> Regards,
>> Pascal
>>
>>
>> On 05/31/2013 11:33 AM, Christoph Knapp wrote:
>>> Hi,
>>> I recently updated to R 3.0.1. I'm running linux ubuntu 12.04. I
>>> realized that I have to update all the installed packages so I run >
>>> update.packages(checkBuilt=TRUE)
>>> as described here
>>> http://www.r-bloggers.com/r-3-0-0-is-released-whats-new-and-how-to-upgrade/
>>>
>>>
>>> . The first thing it did was telling me that it will not update several
>>> packages. When it was finished I used the warnings function to have a
>>> look at what did not work. See the list below.
>>>
>>>  > warnings()
>>> Warning messages:
>>> 1: In install.packages(update[instlib == l, "Package"], l, ... :
>>> installation of package ?boot? had non-zero exit status
>>> 2: In install.packages(update[instlib == l, "Package"], l, ... :
>>> installation of package ?cluster? had non-zero exit status
>>> 3: In install.packages(update[instlib == l, "Package"], l, ... :
>>> installation of package ?foreign? had non-zero exit status
>>> 4: In install.packages(update[instlib == l, "Package"], l, ... :
>>> installation of package ?KernSmooth? had non-zero exit status
>>> 5: In install.packages(update[instlib == l, "Package"], l, ... :
>>> installation of package ?MASS? had non-zero exit status
>>> 6: In install.packages(update[instlib == l, "Package"], l, ... :
>>> installation of package ?Matrix? had non-zero exit status
>>> 7: In install.packages(update[instlib == l, "Package"], l, ... :
>>> installation of package ?nlme? had non-zero exit status
>>> 8: In install.packages(update[instlib == l, "Package"], l, ... :
>>> installation of package ?nnet? had non-zero exit status
>>> 9: In install.packages(update[instlib == l, "Package"], l, ... :
>>> installation of package ?rpart? had non-zero exit status
>>> 10: In install.packages(update[instlib == l, "Package"], l, ... :
>>> installation of package ?spatial? had non-zero exit status
>>> 11: In install.packages(update[instlib == l, "Package"], l, ... :
>>> installation of package ?survival? had non-zero exit status
>>> 12: In install.packages(update[instlib == l, "Package"], l, ... :
>>> installation of package ?class? had non-zero exit status
>>> 13: In install.packages(update[instlib == l, "Package"], l, ... :
>>> installation of package ?epiR? had non-zero exit status
>>> 14: In install.packages(update[instlib == l, "Package"], l, ... :
>>> installation of package ?gmodels? had non-zero exit status
>>> 15: In install.packages(update[instlib == l, "Package"], l, ... :
>>> installation of package ?gplots? had non-zero exit status
>>> 16: In install.packages(update[instlib == l, "Package"], l, ... :
>>> installation of package ?mgcv? had non-zero exit status
>>> 17: In install.packages(update[instlib == l, "Package"], l, ... :
>>> installation of package ?gregmisc? had non-zero exit status
>>>
>>> I tried to reinstall them manually but this always failed because of a
>>> package dependency to the "compiler" package. Now, if I try to install
>>> the compiler package it tells me.
>>>
>>>  > install.packages("compiler")
>>> Installing package into
>>> ?/home/christoph/R/x86_64-pc-linux-gnu-library/3.0?
>>> (as ?lib? is unspecified)
>>> Warning message:
>>> package ?compiler? is not available (for R version 3.0.1)
>>>
>>> The last line also came up all the time when the packages were updated
>>>
>>> Doing a bit of research does not deliver much only that the compiler
>>> package was included into R at version 2.13.0
>>> (http://dirk.eddelbuettel.com/blog/2011/04/12/).
>>>
>>> Most of those packages which do not work any more are pretty important
>>> for some of my scripts and I would not even know what packages replace
>>> the packages above.
>>>
>>> Would anyone know how to fix this?
>>>
>>> Regards
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From skagandbonegirl at hotmail.com  Mon Jun  3 11:15:37 2013
From: skagandbonegirl at hotmail.com (Laura Thomas)
Date: Mon, 3 Jun 2013 10:15:37 +0100
Subject: [R] Calculating Mean
Message-ID: <BLU0-SMTP21565D30AFBFF7FF3838D9AC9D0@phx.gbl>

Hi All,

Sorry about this quite basic, but I am very new to R.

I have a data file which has a dependent variable (reaction time) and a couple of independent variables, one of which is coded 1-8; I want to calculate the reaction time for each of the 8 codes of the independent variable.

Thanks for any help,

Laura


From ivan.calandra at u-bourgogne.fr  Mon Jun  3 11:31:20 2013
From: ivan.calandra at u-bourgogne.fr (Ivan Calandra)
Date: Mon, 03 Jun 2013 11:31:20 +0200
Subject: [R] Calculating Mean
In-Reply-To: <BLU0-SMTP21565D30AFBFF7FF3838D9AC9D0@phx.gbl>
References: <BLU0-SMTP21565D30AFBFF7FF3838D9AC9D0@phx.gbl>
Message-ID: <51AC6268.8020008@u-bourgogne.fr>

Hi Laura,

I think you're looking for aggregate()
See ?aggregate

If you had posted a reproducible example, I could have given you a more 
detailed answer. Learn to use the dput() function to do so.
If you're very new to R, maybe this could help you get started: 
http://www.burns-stat.com/documents/tutorials/impatient-r/

HTH,
Ivan

--
Ivan CALANDRA
Universit? de Bourgogne
UMR CNRS/uB 6282 Biog?osciences
6 Boulevard Gabriel
21000 Dijon, FRANCE
ivan.calandra at u-bourgogne.fr
http://biogeosciences.u-bourgogne.fr/calandra

Le 03/06/13 11:15, Laura Thomas a ?crit :
> Hi All,
>
> Sorry about this quite basic, but I am very new to R.
>
> I have a data file which has a dependent variable (reaction time) and a couple of independent variables, one of which is coded 1-8; I want to calculate the reaction time for each of the 8 codes of the independent variable.
>
> Thanks for any help,
>
> Laura
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ruipbarradas at sapo.pt  Mon Jun  3 12:20:16 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 03 Jun 2013 11:20:16 +0100
Subject: [R] Calculating Mean
In-Reply-To: <BLU0-SMTP21565D30AFBFF7FF3838D9AC9D0@phx.gbl>
References: <BLU0-SMTP21565D30AFBFF7FF3838D9AC9D0@phx.gbl>
Message-ID: <51AC6DE0.8070402@sapo.pt>

Hello,

Like Ivan said, you should give us a data example, the best way is to do 
it is to paste the output of ?dput in a post. If your data frame is 
named 'dat' use the following.

dput(head(dat, 50))  # paste the output of this in a post

As for the question, here is an example using ?aggregate, with fake data.


dat <- data.frame(X = rnorm(100), A = sample(8, 100, TRUE))

aggregate(X ~ A, data = dat, FUN = mean)


Hope this helps,

Rui Barradas

Em 03-06-2013 10:15, Laura Thomas escreveu:
> Hi All,
>
> Sorry about this quite basic, but I am very new to R.
>
> I have a data file which has a dependent variable (reaction time) and a couple of independent variables, one of which is coded 1-8; I want to calculate the reaction time for each of the 8 codes of the independent variable.
>
> Thanks for any help,
>
> Laura
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Mon Jun  3 13:24:45 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 3 Jun 2013 04:24:45 -0700 (PDT)
Subject: [R] Calculating Mean
In-Reply-To: <BLU0-SMTP21565D30AFBFF7FF3838D9AC9D0@phx.gbl>
References: <BLU0-SMTP21565D30AFBFF7FF3838D9AC9D0@phx.gbl>
Message-ID: <1370258685.78014.YahooMailNeo@web142602.mail.bf1.yahoo.com>

HI,You could also try:

set.seed(24)
dat1<- data.frame(Reaction_time=sample(24:60,80,replace=TRUE),Categ=rep(1:8,each=10))
with(dat1,tapply(Reaction_time,list(Categ),FUN=mean))
#?? 1??? 2??? 3??? 4??? 5??? 6??? 7??? 8 
#43.7 39.8 37.5 42.7 33.9 42.3 43.2 40.0 
#or
library(plyr)
?ddply(dat1,.(Categ),summarize, RTMean=mean(Reaction_time))
#? Categ RTMean
#1???? 1?? 43.7
#2???? 2?? 39.8
#3???? 3?? 37.5
#4???? 4?? 42.7
#5???? 5?? 33.9
#6???? 6?? 42.3
#7???? 7?? 43.2
#8???? 8?? 40.0
A.K.

----- Original Message -----
From: Laura Thomas <skagandbonegirl at hotmail.com>
To: r-help at r-project.org
Cc: 
Sent: Monday, June 3, 2013 5:15 AM
Subject: [R] Calculating Mean

Hi All,

Sorry about this quite basic, but I am very new to R.

I have a data file which has a dependent variable (reaction time) and a couple of independent variables, one of which is coded 1-8; I want to calculate the reaction time for each of the 8 codes of the independent variable.

Thanks for any help,

Laura

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From skagandbonegirl at hotmail.com  Mon Jun  3 13:29:28 2013
From: skagandbonegirl at hotmail.com (Laura Thomas)
Date: Mon, 3 Jun 2013 12:29:28 +0100
Subject: [R] Calculating Mean
In-Reply-To: <51AC6DE0.8070402@sapo.pt>
References: <BLU0-SMTP21565D30AFBFF7FF3838D9AC9D0@phx.gbl>
	<51AC6DE0.8070402@sapo.pt>
Message-ID: <BLU0-SMTP12312E36CE31B24B9544B36AC9D0@phx.gbl>

Hi,

Thanks all for the help. I have used the dput function which I have posted below. What I am trying to do is calculate the mean latency for each state(1-8), in each condition (1-10), for each participant (n=13). I know for this to be most efficient I would need some form of loop, but this is a bit about my R abilities at the moment, I am quite happy to run the code a few times to get the information that I would need.

Thanks a lot for any help,

Laura

structure(list(subject = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L), conditionNo = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L
), state = c(5L, 8L, 7L, 8L, 1L, 7L, 8L, 8L, 8L, 7L, 1L, 1L, 
5L, 7L, 1L, 4L, 3L, 2L, 8L, 3L, 7L, 6L, 6L, 4L, 2L, 5L, 1L, 5L, 
2L, 2L, 8L, 7L, 5L, 7L, 3L, 1L, 7L, 5L, 7L, 8L, 8L, 6L, 7L, 5L, 
5L, 1L, 4L, 3L, 6L, 2L, 4L, 5L, 8L, 2L, 8L, 5L, 7L, 2L, 4L, 1L, 
3L, 8L, 6L, 4L, 3L, 6L, 2L, 3L, 5L, 6L, 7L, 4L, 4L, 8L, 4L, 8L, 
1L, 3L, 1L, 1L, 7L, 6L, 3L, 1L, 7L, 1L, 2L, 2L, 2L, 8L, 6L, 8L, 
5L, 8L, 3L, 2L, 4L, 4L, 6L, 3L, 7L, 4L, 4L, 8L, 3L, 5L, 5L, 2L, 
4L, 2L, 1L, 7L, 2L, 5L, 1L, 5L, 1L, 3L, 4L, 3L, 6L, 5L, 6L, 7L, 
2L, 3L, 8L, 4L, 6L, 1L, 4L, 3L, 6L, 1L, 8L, 1L, 3L, 2L, 4L, 7L, 
5L, 6L, 2L, 7L, 3L, 6L, 4L, 3L, 2L, 5L, 6L, 4L, 5L, 2L, 6L, 6L, 
7L, 3L, 4L, 3L, 1L, 8L, 5L, 5L, 5L, 4L, 2L, 1L, 5L, 2L), latency = c(869L, 
864L, 1004L, 801L, 611L, 679L, 649L, 603L, 677L, 614L, 619L, 
542L, 613L, 746L, 713L, 714L, 586L, 542L, 613L, 585L, 799L, 807L, 
868L, 670L, 672L, 706L, 739L, 546L, 681L, 683L, 604L, 608L, 773L, 
643L, 743L, 524L, 579L, 617L, 604L, 609L, 967L, 540L, 514L, 651L, 
508L, 548L, 506L, 578L, 763L, 585L, 1088L, 609L, 549L, 603L, 
582L, 764L, 618L, 606L, 918L, 959L, 775L, 676L, 678L, 584L, 611L, 
583L, 614L, 747L, 618L, 702L, 800L, 709L, 742L, 645L, 648L, 747L, 
650L, 669L, 703L, 704L, 544L, 550L, 508L, 869L, 680L, 843L, 839L, 
578L, 776L, 678L, 519L, 606L, 578L, 648L, 602L, 865L, 803L, 639L, 
610L, 614L, 747L, 715L, 587L, 672L, 674L, 579L, 713L, 617L, 637L, 
613L, 810L, 646L, 585L, 541L, 644L, 583L, 571L, 738L, 609L, 613L, 
617L, 604L, 576L, 646L, 488L, 512L, 584L, 637L, 511L, 551L, 583L, 
572L, 738L, 609L, 709L, 614L, 690L, 708L, 580L, 687L, 575L, 709L, 
581L, 651L, 1009L, 646L, 649L, 764L, 843L, 697L, 746L, 649L, 
870L, 511L, 583L, 604L, 629L, 893L, 518L, 1023L, 675L, 838L, 
673L, 739L, 578L, 647L, 650L, 829L, 746L, 649L)), .Names = c("subject", 
"conditionNo", "state", "latency"), row.names = c(3L, 4L, 5L, 
6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 
32L, 33L, 34L, 35L, 36L, 37L, 38L, 39L, 40L, 41L, 42L, 43L, 44L, 
45L, 46L, 47L, 48L, 49L, 50L, 51L, 52L, 53L, 54L, 55L, 56L, 57L, 
58L, 59L, 60L, 61L, 62L, 63L, 64L, 65L, 66L, 67L, 68L, 69L, 70L, 
71L, 72L, 73L, 74L, 75L, 76L, 77L, 78L, 79L, 80L, 81L, 82L, 83L, 
84L, 85L, 86L, 87L, 88L, 89L, 90L, 91L, 92L, 93L, 94L, 95L, 96L, 
97L, 99L, 100L, 101L, 102L, 103L, 104L, 105L, 106L, 107L, 108L, 
109L, 110L, 111L, 112L, 113L, 114L, 115L, 116L, 117L, 118L, 119L, 
120L, 121L, 122L, 123L, 124L, 125L, 126L, 127L, 128L, 129L, 130L, 
131L, 132L, 133L, 134L, 135L, 136L, 137L, 138L, 139L, 140L, 141L, 
142L, 143L, 144L, 145L, 146L, 147L, 148L, 149L, 150L, 151L, 152L, 
153L, 154L, 155L, 157L, 158L, 159L, 160L, 162L, 164L, 165L, 166L, 
167L, 168L, 169L, 170L, 171L, 172L, 173L, 174L, 175L, 176L), class = "data.frame")

On 3 Jun 2013, at 11:20, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
> 
> Like Ivan said, you should give us a data example, the best way is to do it is to paste the output of ?dput in a post. If your data frame is named 'dat' use the following.
> 
> dput(head(dat, 50))  # paste the output of this in a post
> 
> As for the question, here is an example using ?aggregate, with fake data.
> 
> 
> dat <- data.frame(X = rnorm(100), A = sample(8, 100, TRUE))
> 
> aggregate(X ~ A, data = dat, FUN = mean)
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> Em 03-06-2013 10:15, Laura Thomas escreveu:
>> Hi All,
>> 
>> Sorry about this quite basic, but I am very new to R.
>> 
>> I have a data file which has a dependent variable (reaction time) and a couple of independent variables, one of which is coded 1-8; I want to calculate the reaction time for each of the 8 codes of the independent variable.
>> 
>> Thanks for any help,
>> 
>> Laura
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 


From smartpink111 at yahoo.com  Mon Jun  3 13:45:33 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 3 Jun 2013 04:45:33 -0700 (PDT)
Subject: [R] Calculating Mean
In-Reply-To: <BLU0-SMTP12312E36CE31B24B9544B36AC9D0@phx.gbl>
References: <BLU0-SMTP21565D30AFBFF7FF3838D9AC9D0@phx.gbl>
	<51AC6DE0.8070402@sapo.pt>
	<BLU0-SMTP12312E36CE31B24B9544B36AC9D0@phx.gbl>
Message-ID: <1370259933.38752.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
May be this is what you wanted:
dat2: dataset
library(plyr)

res1<-ddply(dat2,.(subject,conditionNo,state),summarize,MLat=mean(latency))
res1? 

#subject conditionNo state???? MLat
#1??????? 1?????????? 1???? 1 674.8947
#2??????? 1?????????? 1???? 2 649.5000
#3??????? 1?????????? 1???? 3 662.6316
#4??????? 1?????????? 1???? 4 683.3500
#5??????? 1?????????? 1???? 5 650.7000
#6??????? 1?????????? 1???? 6 650.0000
#7??????? 1?????????? 1???? 7 674.1579
#8??????? 1?????????? 1???? 8 674.1500
#9??????? 1?????????? 2???? 1 752.0000
#10?????? 1?????????? 2???? 2 649.5000
#11?????? 1?????????? 2???? 3 958.0000
#12?????? 1?????????? 2???? 4 582.5000
#13?????? 1?????????? 2???? 5 684.0000
#14?????? 1?????????? 2???? 7 629.0000
#15?????? 1?????????? 2???? 8 838.0000
#or 

res2<-aggregate(latency~.,data=dat2,mean)
?res2<-res2[order(res2[,1],res2[,2],res2[,3]),]
?colnames(res2)<-colnames(res1)
?row.names(res2)<-1:nrow(res2)
?identical(res1,res2)
#[1] TRUE
A.K.



----- Original Message -----
From: Laura Thomas <skagandbonegirl at hotmail.com>
To: Rui Barradas <ruipbarradas at sapo.pt>
Cc: r-help at r-project.org
Sent: Monday, June 3, 2013 7:29 AM
Subject: Re: [R] Calculating Mean

Hi,

Thanks all for the help. I have used the dput function which I have posted below. What I am trying to do is calculate the mean latency for each state(1-8), in each condition (1-10), for each participant (n=13). I know for this to be most efficient I would need some form of loop, but this is a bit about my R abilities at the moment, I am quite happy to run the code a few times to get the information that I would need.

Thanks a lot for any help,

Laura

structure(list(subject = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L), conditionNo = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L
), state = c(5L, 8L, 7L, 8L, 1L, 7L, 8L, 8L, 8L, 7L, 1L, 1L, 
5L, 7L, 1L, 4L, 3L, 2L, 8L, 3L, 7L, 6L, 6L, 4L, 2L, 5L, 1L, 5L, 
2L, 2L, 8L, 7L, 5L, 7L, 3L, 1L, 7L, 5L, 7L, 8L, 8L, 6L, 7L, 5L, 
5L, 1L, 4L, 3L, 6L, 2L, 4L, 5L, 8L, 2L, 8L, 5L, 7L, 2L, 4L, 1L, 
3L, 8L, 6L, 4L, 3L, 6L, 2L, 3L, 5L, 6L, 7L, 4L, 4L, 8L, 4L, 8L, 
1L, 3L, 1L, 1L, 7L, 6L, 3L, 1L, 7L, 1L, 2L, 2L, 2L, 8L, 6L, 8L, 
5L, 8L, 3L, 2L, 4L, 4L, 6L, 3L, 7L, 4L, 4L, 8L, 3L, 5L, 5L, 2L, 
4L, 2L, 1L, 7L, 2L, 5L, 1L, 5L, 1L, 3L, 4L, 3L, 6L, 5L, 6L, 7L, 
2L, 3L, 8L, 4L, 6L, 1L, 4L, 3L, 6L, 1L, 8L, 1L, 3L, 2L, 4L, 7L, 
5L, 6L, 2L, 7L, 3L, 6L, 4L, 3L, 2L, 5L, 6L, 4L, 5L, 2L, 6L, 6L, 
7L, 3L, 4L, 3L, 1L, 8L, 5L, 5L, 5L, 4L, 2L, 1L, 5L, 2L), latency = c(869L, 
864L, 1004L, 801L, 611L, 679L, 649L, 603L, 677L, 614L, 619L, 
542L, 613L, 746L, 713L, 714L, 586L, 542L, 613L, 585L, 799L, 807L, 
868L, 670L, 672L, 706L, 739L, 546L, 681L, 683L, 604L, 608L, 773L, 
643L, 743L, 524L, 579L, 617L, 604L, 609L, 967L, 540L, 514L, 651L, 
508L, 548L, 506L, 578L, 763L, 585L, 1088L, 609L, 549L, 603L, 
582L, 764L, 618L, 606L, 918L, 959L, 775L, 676L, 678L, 584L, 611L, 
583L, 614L, 747L, 618L, 702L, 800L, 709L, 742L, 645L, 648L, 747L, 
650L, 669L, 703L, 704L, 544L, 550L, 508L, 869L, 680L, 843L, 839L, 
578L, 776L, 678L, 519L, 606L, 578L, 648L, 602L, 865L, 803L, 639L, 
610L, 614L, 747L, 715L, 587L, 672L, 674L, 579L, 713L, 617L, 637L, 
613L, 810L, 646L, 585L, 541L, 644L, 583L, 571L, 738L, 609L, 613L, 
617L, 604L, 576L, 646L, 488L, 512L, 584L, 637L, 511L, 551L, 583L, 
572L, 738L, 609L, 709L, 614L, 690L, 708L, 580L, 687L, 575L, 709L, 
581L, 651L, 1009L, 646L, 649L, 764L, 843L, 697L, 746L, 649L, 
870L, 511L, 583L, 604L, 629L, 893L, 518L, 1023L, 675L, 838L, 
673L, 739L, 578L, 647L, 650L, 829L, 746L, 649L)), .Names = c("subject", 
"conditionNo", "state", "latency"), row.names = c(3L, 4L, 5L, 
6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 
32L, 33L, 34L, 35L, 36L, 37L, 38L, 39L, 40L, 41L, 42L, 43L, 44L, 
45L, 46L, 47L, 48L, 49L, 50L, 51L, 52L, 53L, 54L, 55L, 56L, 57L, 
58L, 59L, 60L, 61L, 62L, 63L, 64L, 65L, 66L, 67L, 68L, 69L, 70L, 
71L, 72L, 73L, 74L, 75L, 76L, 77L, 78L, 79L, 80L, 81L, 82L, 83L, 
84L, 85L, 86L, 87L, 88L, 89L, 90L, 91L, 92L, 93L, 94L, 95L, 96L, 
97L, 99L, 100L, 101L, 102L, 103L, 104L, 105L, 106L, 107L, 108L, 
109L, 110L, 111L, 112L, 113L, 114L, 115L, 116L, 117L, 118L, 119L, 
120L, 121L, 122L, 123L, 124L, 125L, 126L, 127L, 128L, 129L, 130L, 
131L, 132L, 133L, 134L, 135L, 136L, 137L, 138L, 139L, 140L, 141L, 
142L, 143L, 144L, 145L, 146L, 147L, 148L, 149L, 150L, 151L, 152L, 
153L, 154L, 155L, 157L, 158L, 159L, 160L, 162L, 164L, 165L, 166L, 
167L, 168L, 169L, 170L, 171L, 172L, 173L, 174L, 175L, 176L), class = "data.frame")

On 3 Jun 2013, at 11:20, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
> 
> Like Ivan said, you should give us a data example, the best way is to do it is to paste the output of ?dput in a post. If your data frame is named 'dat' use the following.
> 
> dput(head(dat, 50))? # paste the output of this in a post
> 
> As for the question, here is an example using ?aggregate, with fake data.
> 
> 
> dat <- data.frame(X = rnorm(100), A = sample(8, 100, TRUE))
> 
> aggregate(X ~ A, data = dat, FUN = mean)
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> Em 03-06-2013 10:15, Laura Thomas escreveu:
>> Hi All,
>> 
>> Sorry about this quite basic, but I am very new to R.
>> 
>> I have a data file which has a dependent variable (reaction time) and a couple of independent variables, one of which is coded 1-8; I want to calculate the reaction time for each of the 8 codes of the independent variable.
>> 
>> Thanks for any help,
>> 
>> Laura
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From kw.stat at gmail.com  Mon Jun  3 13:55:56 2013
From: kw.stat at gmail.com (Kevin Wright)
Date: Mon, 3 Jun 2013 06:55:56 -0500
Subject: [R] Strange behaviour of R graphics copied to PowerPoint
In-Reply-To: <CAJSLS6UVLAp1AtH-u6XebB+qfgvddsgLvApCJYqkQ8Q69qw7Ew@mail.gmail.com>
References: <CAJSLS6UVLAp1AtH-u6XebB+qfgvddsgLvApCJYqkQ8Q69qw7Ew@mail.gmail.com>
Message-ID: <CAKFxdiSjJb7WwX5t2_cbebnSy+gR4XgtOm9_GY9WbMJj6MzU3w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130603/d655e03e/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Mon Jun  3 13:58:29 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 03 Jun 2013 04:58:29 -0700
Subject: [R] Strange behaviour of R graphics copied to PowerPoint
In-Reply-To: <CAJSLS6UVLAp1AtH-u6XebB+qfgvddsgLvApCJYqkQ8Q69qw7Ew@mail.gmail.com>
References: <CAJSLS6UVLAp1AtH-u6XebB+qfgvddsgLvApCJYqkQ8Q69qw7Ew@mail.gmail.com>
Message-ID: <261d774a-5258-41ba-8ea5-795f0db6a474@email.android.com>

I have not seen this particular problem, but I have seen other problems and I tend to export bitmaps or pdf files as a result.

Note that a reproducible example is usually required to to obtain help on this list, and posting in HTML format is bad because it mutilates example code, so fix your email client. Please read the Posting Guide for more etiquette tips.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

"Erling Johan Fr?ysa" <erling.froysa at gmail.com> wrote:

>Hello,
>
>I am using R to create graphics, especially to plot time series charts.
>These charts are then copied as metafiles (for best quality) to a
>PowerPoint
>presentation and then saved to PDF (via the "Save As" dialog").
>
>Attached is two pictures. The first picture shows how my chart looks
>like in
>the R Graphics window, and the second picture shows how the chart
>becomes
>after saving it to PDF.
>
>< http://r.789695.n4.nabble.com/file/n4668522/R.png>
>
>< http://r.789695.n4.nabble.com/file/n4668522/Rppt.png>
>
>As you can see. After saving the metafile to PDF via PowerPoint, some
>straight lines appears (it seems like all of the lines has the same
>origin
>in the upper left corner and ends somewhere on the times series line).
>This
>happens in both plot() and ggplot(). The problem appears more often
>when
>using daily data in my time series. With monthly data the problem don't
>exist.
>
>Have anyone experienced this before? Do you think the problem is
>related to
>R or to Powerpoint?
>
>Thanks all,
>
>E
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From therneau at mayo.edu  Mon Jun  3 14:11:27 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 03 Jun 2013 07:11:27 -0500
Subject: [R] How to compute a P-value for a complex mixture
 of	chi-squared distributions in R
In-Reply-To: <mailman.17.1370167206.28860.r-help@r-project.org>
References: <mailman.17.1370167206.28860.r-help@r-project.org>
Message-ID: <51AC87EF.4030604@mayo.edu>

You need to be more explicit about what you are doing.
For this problem:
     y = (x1 + x2)/2
where x1 and x2 are chi-square random variables, you want to use the pchisqsum() routine 
found in the survey package.  This is not a trivial computation.

For the alternate problem where y is a random choice of either x1 or x2
     y = ifelse(z, x1, x2)
z is binomial and x1, x2 are chisq, then the suggestion by Peter Dalgaard is correct.

Which of these two are you trying to solve?

Terry Therneau


On 06/02/2013 05:00 AM, r-help-request at r-project.org wrote:
> Em 01-06-2013 05:26, Tiago V. Pereira escreveu:
>> >  Hello, R users!
>> >
>> >  I am struggling with the following problem:
>> >
>> >  I need to compute a P-value for a mixture of two chi-squared
>> >  distributions. My P-value is given by:
>> >
>> >  P = 0.5*prob(sqrt(chi2(1))<= x) + 0.5*prob(sqrt(chi2(2))<= x)
>> >
>> >  In words, I need to compute the p-value for 50?50 mixture of the square
>> >  root of a chi-squared random variable with 1 degree of freedom and the
>> >  square root of a chi-squared with two degrees of freedom.
>> >
>> >  Although I can quickly simulate data, the P-values I am looking for are at
>> >  the tail of the distribution, that is, alpha levels below 10^-7. Hence,
>> >  simulation is not efficient.
>> >
>> >  Are you aware of smart approach?
>> >
>> >
>> >  All the best,
>> >
>> >  Tiago
>> >


From jrkrideau at inbox.com  Mon Jun  3 14:36:00 2013
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 3 Jun 2013 04:36:00 -0800
Subject: [R] Scale package change comma defaults?
In-Reply-To: <loom.20130602T225338-972@post.gmane.org>
References: <d9db4e3005e.000004a4jrkrideau@inbox.com>
Message-ID: <E2AFB8354E8.00000233jrkrideau@inbox.com>

Thanks Ben,
I did just that after getting Duncan's reply. I should have seen it myself but for some reason thought I could treat it as an option.  Myopia at its best.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: bbolker at gmail.com
> Sent: Sun, 2 Jun 2013 20:57:58 +0000
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] Scale package change comma defaults?
> 
> John Kane <jrkrideau <at> inbox.com> writes:
> 
>>  I was using the comma() funtion in the scales page and was
>> wondering how to chage a the defaults.  comm(1000) gives me 1,000
>> which is what I usually want but how would I change the output to
>> 1.000.
> 
>  Since the comma() function is just a wrapper for format():
> 
>> scales::comma
> function (x, ...)
> {
>     format(x, ..., big.mark = ",", scientific = FALSE, trim = TRUE)
> }
> 
> Why not just define your own function that does what you want?
> 
> myComma <- function (x, big.mark=",", ...)
> {
>     format(x, ..., big.mark = big.mark, scientific = FALSE, trim = TRUE)
> }
> 
> myComma(1000,".")
> 
>> I had thought that I could simply do
>> comm(1000, big.mark = ".")
>> but I am getting
>> Error in format.default(x, ..., big.mark = ",", scientific = FALSE, trim
>> =
> TRUE) :
>>   formal argument "big.mark" matched by multiple actual arguments
> 
>> And since I'm here I might as well ask if there is a way
>> to keep a couple fo decemal points rather than rounding to the first
>> integer.
> 
>  Not quite sure what you mean here; see ?format for more details.
> 
> format(1200,big.mark=".",nsmall=2)
> 
> might be what you want, but if you're going to use "." for big.mark
> then you might want:
> 
> options(OutDec=",")
> 
> [1] "1.200,00"
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Receive Notifications of Incoming Messages
Easily monitor multiple email accounts & access them with a click.
Visit http://www.inbox.com/notifier and check it out!


From tal.galili at gmail.com  Mon Jun  3 15:15:56 2013
From: tal.galili at gmail.com (Tal Galili)
Date: Mon, 3 Jun 2013 16:15:56 +0300
Subject: [R] Why do tabs disappear when pasted into the R console?
Message-ID: <CANdJ3dWgo5YwMW0MBTdQSr7awK5LPG7yNgALpJF-R730+cm5UQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130603/8a7233e3/attachment.pl>

From sarah.goslee at gmail.com  Mon Jun  3 15:22:34 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 3 Jun 2013 09:22:34 -0400
Subject: [R] Why do tabs disappear when pasted into the R console?
In-Reply-To: <CANdJ3dWgo5YwMW0MBTdQSr7awK5LPG7yNgALpJF-R730+cm5UQ@mail.gmail.com>
References: <CANdJ3dWgo5YwMW0MBTdQSr7awK5LPG7yNgALpJF-R730+cm5UQ@mail.gmail.com>
Message-ID: <CAM_vjuk4zBSnG6FFi47-k5pPY=doz1MKgaJ6prYAskQgVvmzwg@mail.gmail.com>

Pasting tabs into the console works for me on linux, which suggests
that you need to provide more information about your OS and all the
other usual things.

Sarah

On Mon, Jun 3, 2013 at 9:15 AM, Tal Galili <tal.galili at gmail.com> wrote:
> Hello Dear R-help Members,
>
> I have noticed that when pasting text with "tab" in it to the R console it
> eliminates the tab. Whereas, when pasted into the R Editor, the tab is
> preserved.
> For example, pasting this:
> "1997 7680"
> In the R Console will result in:
> "19977680"
>
> Is there a way to preserve the tab?
> This would allow (for example) to use read.table with a table copied from
> website/libre-office/excel such as:
>
> a = read.table( text=
> "
> 1 2
> 3 4
> ")
> a
>
> I understand I can use readClipboard directly, but I wonder if there is a
> way to use it while the text is kept in the R Editor.
>
>
> With regards,
> Tal


-- 
Sarah Goslee
http://www.functionaldiversity.org


From tal.galili at gmail.com  Mon Jun  3 15:24:42 2013
From: tal.galili at gmail.com (Tal Galili)
Date: Mon, 3 Jun 2013 16:24:42 +0300
Subject: [R] Why do tabs disappear when pasted into the R console?
In-Reply-To: <CAM_vjuk4zBSnG6FFi47-k5pPY=doz1MKgaJ6prYAskQgVvmzwg@mail.gmail.com>
References: <CANdJ3dWgo5YwMW0MBTdQSr7awK5LPG7yNgALpJF-R730+cm5UQ@mail.gmail.com>
	<CAM_vjuk4zBSnG6FFi47-k5pPY=doz1MKgaJ6prYAskQgVvmzwg@mail.gmail.com>
Message-ID: <CANdJ3dXsqG+tLdV8Q-u1w-L9C3o5w84+xAEPNrEqNmq9aXaSYg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130603/103dd4c0/attachment.pl>

From ivan.calandra at u-bourgogne.fr  Mon Jun  3 15:26:29 2013
From: ivan.calandra at u-bourgogne.fr (Ivan Calandra)
Date: Mon, 03 Jun 2013 15:26:29 +0200
Subject: [R] Calculating Mean
In-Reply-To: <BLU0-SMTP12312E36CE31B24B9544B36AC9D0@phx.gbl>
References: <BLU0-SMTP21565D30AFBFF7FF3838D9AC9D0@phx.gbl>
	<51AC6DE0.8070402@sapo.pt>
	<BLU0-SMTP12312E36CE31B24B9544B36AC9D0@phx.gbl>
Message-ID: <51AC9985.5050703@u-bourgogne.fr>

Hi again Laura,

Let's say your data.frame is called df, just run this:
aggregate(latency~subject+conditionNo+state, data=df, FUN=mean)

I think this is what you're looking for.
For help, check ?aggregate and ?formula.

HTH,
Ivan

--
Ivan CALANDRA
Universit? de Bourgogne
UMR CNRS/uB 6282 Biog?osciences
6 Boulevard Gabriel
21000 Dijon, FRANCE
ivan.calandra at u-bourgogne.fr
http://biogeosciences.u-bourgogne.fr/calandra

Le 03/06/13 13:29, Laura Thomas a ?crit :
> structure(list(subject = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L), conditionNo = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L
> ), state = c(5L, 8L, 7L, 8L, 1L, 7L, 8L, 8L, 8L, 7L, 1L, 1L,
> 5L, 7L, 1L, 4L, 3L, 2L, 8L, 3L, 7L, 6L, 6L, 4L, 2L, 5L, 1L, 5L,
> 2L, 2L, 8L, 7L, 5L, 7L, 3L, 1L, 7L, 5L, 7L, 8L, 8L, 6L, 7L, 5L,
> 5L, 1L, 4L, 3L, 6L, 2L, 4L, 5L, 8L, 2L, 8L, 5L, 7L, 2L, 4L, 1L,
> 3L, 8L, 6L, 4L, 3L, 6L, 2L, 3L, 5L, 6L, 7L, 4L, 4L, 8L, 4L, 8L,
> 1L, 3L, 1L, 1L, 7L, 6L, 3L, 1L, 7L, 1L, 2L, 2L, 2L, 8L, 6L, 8L,
> 5L, 8L, 3L, 2L, 4L, 4L, 6L, 3L, 7L, 4L, 4L, 8L, 3L, 5L, 5L, 2L,
> 4L, 2L, 1L, 7L, 2L, 5L, 1L, 5L, 1L, 3L, 4L, 3L, 6L, 5L, 6L, 7L,
> 2L, 3L, 8L, 4L, 6L, 1L, 4L, 3L, 6L, 1L, 8L, 1L, 3L, 2L, 4L, 7L,
> 5L, 6L, 2L, 7L, 3L, 6L, 4L, 3L, 2L, 5L, 6L, 4L, 5L, 2L, 6L, 6L,
> 7L, 3L, 4L, 3L, 1L, 8L, 5L, 5L, 5L, 4L, 2L, 1L, 5L, 2L), latency = c(869L,
> 864L, 1004L, 801L, 611L, 679L, 649L, 603L, 677L, 614L, 619L,
> 542L, 613L, 746L, 713L, 714L, 586L, 542L, 613L, 585L, 799L, 807L,
> 868L, 670L, 672L, 706L, 739L, 546L, 681L, 683L, 604L, 608L, 773L,
> 643L, 743L, 524L, 579L, 617L, 604L, 609L, 967L, 540L, 514L, 651L,
> 508L, 548L, 506L, 578L, 763L, 585L, 1088L, 609L, 549L, 603L,
> 582L, 764L, 618L, 606L, 918L, 959L, 775L, 676L, 678L, 584L, 611L,
> 583L, 614L, 747L, 618L, 702L, 800L, 709L, 742L, 645L, 648L, 747L,
> 650L, 669L, 703L, 704L, 544L, 550L, 508L, 869L, 680L, 843L, 839L,
> 578L, 776L, 678L, 519L, 606L, 578L, 648L, 602L, 865L, 803L, 639L,
> 610L, 614L, 747L, 715L, 587L, 672L, 674L, 579L, 713L, 617L, 637L,
> 613L, 810L, 646L, 585L, 541L, 644L, 583L, 571L, 738L, 609L, 613L,
> 617L, 604L, 576L, 646L, 488L, 512L, 584L, 637L, 511L, 551L, 583L,
> 572L, 738L, 609L, 709L, 614L, 690L, 708L, 580L, 687L, 575L, 709L,
> 581L, 651L, 1009L, 646L, 649L, 764L, 843L, 697L, 746L, 649L,
> 870L, 511L, 583L, 604L, 629L, 893L, 518L, 1023L, 675L, 838L,
> 673L, 739L, 578L, 647L, 650L, 829L, 746L, 649L)), .Names = c("subject",
> "conditionNo", "state", "latency"), row.names = c(3L, 4L, 5L,
> 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L,
> 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L,
> 32L, 33L, 34L, 35L, 36L, 37L, 38L, 39L, 40L, 41L, 42L, 43L, 44L,
> 45L, 46L, 47L, 48L, 49L, 50L, 51L, 52L, 53L, 54L, 55L, 56L, 57L,
> 58L, 59L, 60L, 61L, 62L, 63L, 64L, 65L, 66L, 67L, 68L, 69L, 70L,
> 71L, 72L, 73L, 74L, 75L, 76L, 77L, 78L, 79L, 80L, 81L, 82L, 83L,
> 84L, 85L, 86L, 87L, 88L, 89L, 90L, 91L, 92L, 93L, 94L, 95L, 96L,
> 97L, 99L, 100L, 101L, 102L, 103L, 104L, 105L, 106L, 107L, 108L,
> 109L, 110L, 111L, 112L, 113L, 114L, 115L, 116L, 117L, 118L, 119L,
> 120L, 121L, 122L, 123L, 124L, 125L, 126L, 127L, 128L, 129L, 130L,
> 131L, 132L, 133L, 134L, 135L, 136L, 137L, 138L, 139L, 140L, 141L,
> 142L, 143L, 144L, 145L, 146L, 147L, 148L, 149L, 150L, 151L, 152L,
> 153L, 154L, 155L, 157L, 158L, 159L, 160L, 162L, 164L, 165L, 166L,
> 167L, 168L, 169L, 170L, 171L, 172L, 173L, 174L, 175L, 176L), class = "data.frame")


From ruipbarradas at sapo.pt  Mon Jun  3 15:33:46 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 03 Jun 2013 14:33:46 +0100
Subject: [R] Calculating Mean
In-Reply-To: <BLU0-SMTP12312E36CE31B24B9544B36AC9D0@phx.gbl>
References: <BLU0-SMTP21565D30AFBFF7FF3838D9AC9D0@phx.gbl>
	<51AC6DE0.8070402@sapo.pt>
	<BLU0-SMTP12312E36CE31B24B9544B36AC9D0@phx.gbl>
Message-ID: <51AC9B3A.70302@sapo.pt>

Hello,

Try

aggregate(latency ~ state + conditionNo + subject, data = dat, FUN = mean)


Rui Barradas

Em 03-06-2013 12:29, Laura Thomas escreveu:
> Hi,
>
> Thanks all for the help. I have used the dput function which I have posted below. What I am trying to do is calculate the mean latency for each state(1-8), in each condition (1-10), for each participant (n=13). I know for this to be most efficient I would need some form of loop, but this is a bit about my R abilities at the moment, I am quite happy to run the code a few times to get the information that I would need.
>
> Thanks a lot for any help,
>
> Laura
>
> structure(list(subject = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L), conditionNo = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L
> ), state = c(5L, 8L, 7L, 8L, 1L, 7L, 8L, 8L, 8L, 7L, 1L, 1L,
> 5L, 7L, 1L, 4L, 3L, 2L, 8L, 3L, 7L, 6L, 6L, 4L, 2L, 5L, 1L, 5L,
> 2L, 2L, 8L, 7L, 5L, 7L, 3L, 1L, 7L, 5L, 7L, 8L, 8L, 6L, 7L, 5L,
> 5L, 1L, 4L, 3L, 6L, 2L, 4L, 5L, 8L, 2L, 8L, 5L, 7L, 2L, 4L, 1L,
> 3L, 8L, 6L, 4L, 3L, 6L, 2L, 3L, 5L, 6L, 7L, 4L, 4L, 8L, 4L, 8L,
> 1L, 3L, 1L, 1L, 7L, 6L, 3L, 1L, 7L, 1L, 2L, 2L, 2L, 8L, 6L, 8L,
> 5L, 8L, 3L, 2L, 4L, 4L, 6L, 3L, 7L, 4L, 4L, 8L, 3L, 5L, 5L, 2L,
> 4L, 2L, 1L, 7L, 2L, 5L, 1L, 5L, 1L, 3L, 4L, 3L, 6L, 5L, 6L, 7L,
> 2L, 3L, 8L, 4L, 6L, 1L, 4L, 3L, 6L, 1L, 8L, 1L, 3L, 2L, 4L, 7L,
> 5L, 6L, 2L, 7L, 3L, 6L, 4L, 3L, 2L, 5L, 6L, 4L, 5L, 2L, 6L, 6L,
> 7L, 3L, 4L, 3L, 1L, 8L, 5L, 5L, 5L, 4L, 2L, 1L, 5L, 2L), latency = c(869L,
> 864L, 1004L, 801L, 611L, 679L, 649L, 603L, 677L, 614L, 619L,
> 542L, 613L, 746L, 713L, 714L, 586L, 542L, 613L, 585L, 799L, 807L,
> 868L, 670L, 672L, 706L, 739L, 546L, 681L, 683L, 604L, 608L, 773L,
> 643L, 743L, 524L, 579L, 617L, 604L, 609L, 967L, 540L, 514L, 651L,
> 508L, 548L, 506L, 578L, 763L, 585L, 1088L, 609L, 549L, 603L,
> 582L, 764L, 618L, 606L, 918L, 959L, 775L, 676L, 678L, 584L, 611L,
> 583L, 614L, 747L, 618L, 702L, 800L, 709L, 742L, 645L, 648L, 747L,
> 650L, 669L, 703L, 704L, 544L, 550L, 508L, 869L, 680L, 843L, 839L,
> 578L, 776L, 678L, 519L, 606L, 578L, 648L, 602L, 865L, 803L, 639L,
> 610L, 614L, 747L, 715L, 587L, 672L, 674L, 579L, 713L, 617L, 637L,
> 613L, 810L, 646L, 585L, 541L, 644L, 583L, 571L, 738L, 609L, 613L,
> 617L, 604L, 576L, 646L, 488L, 512L, 584L, 637L, 511L, 551L, 583L,
> 572L, 738L, 609L, 709L, 614L, 690L, 708L, 580L, 687L, 575L, 709L,
> 581L, 651L, 1009L, 646L, 649L, 764L, 843L, 697L, 746L, 649L,
> 870L, 511L, 583L, 604L, 629L, 893L, 518L, 1023L, 675L, 838L,
> 673L, 739L, 578L, 647L, 650L, 829L, 746L, 649L)), .Names = c("subject",
> "conditionNo", "state", "latency"), row.names = c(3L, 4L, 5L,
> 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L,
> 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L,
> 32L, 33L, 34L, 35L, 36L, 37L, 38L, 39L, 40L, 41L, 42L, 43L, 44L,
> 45L, 46L, 47L, 48L, 49L, 50L, 51L, 52L, 53L, 54L, 55L, 56L, 57L,
> 58L, 59L, 60L, 61L, 62L, 63L, 64L, 65L, 66L, 67L, 68L, 69L, 70L,
> 71L, 72L, 73L, 74L, 75L, 76L, 77L, 78L, 79L, 80L, 81L, 82L, 83L,
> 84L, 85L, 86L, 87L, 88L, 89L, 90L, 91L, 92L, 93L, 94L, 95L, 96L,
> 97L, 99L, 100L, 101L, 102L, 103L, 104L, 105L, 106L, 107L, 108L,
> 109L, 110L, 111L, 112L, 113L, 114L, 115L, 116L, 117L, 118L, 119L,
> 120L, 121L, 122L, 123L, 124L, 125L, 126L, 127L, 128L, 129L, 130L,
> 131L, 132L, 133L, 134L, 135L, 136L, 137L, 138L, 139L, 140L, 141L,
> 142L, 143L, 144L, 145L, 146L, 147L, 148L, 149L, 150L, 151L, 152L,
> 153L, 154L, 155L, 157L, 158L, 159L, 160L, 162L, 164L, 165L, 166L,
> 167L, 168L, 169L, 170L, 171L, 172L, 173L, 174L, 175L, 176L), class = "data.frame")
>
> On 3 Jun 2013, at 11:20, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
>> Hello,
>>
>> Like Ivan said, you should give us a data example, the best way is to do it is to paste the output of ?dput in a post. If your data frame is named 'dat' use the following.
>>
>> dput(head(dat, 50))  # paste the output of this in a post
>>
>> As for the question, here is an example using ?aggregate, with fake data.
>>
>>
>> dat <- data.frame(X = rnorm(100), A = sample(8, 100, TRUE))
>>
>> aggregate(X ~ A, data = dat, FUN = mean)
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Em 03-06-2013 10:15, Laura Thomas escreveu:
>>> Hi All,
>>>
>>> Sorry about this quite basic, but I am very new to R.
>>>
>>> I have a data file which has a dependent variable (reaction time) and a couple of independent variables, one of which is coded 1-8; I want to calculate the reaction time for each of the 8 codes of the independent variable.
>>>
>>> Thanks for any help,
>>>
>>> Laura
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>


From ggrothendieck at gmail.com  Mon Jun  3 15:38:39 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 3 Jun 2013 09:38:39 -0400
Subject: [R] Why do tabs disappear when pasted into the R console?
In-Reply-To: <CANdJ3dXsqG+tLdV8Q-u1w-L9C3o5w84+xAEPNrEqNmq9aXaSYg@mail.gmail.com>
References: <CANdJ3dWgo5YwMW0MBTdQSr7awK5LPG7yNgALpJF-R730+cm5UQ@mail.gmail.com>
	<CAM_vjuk4zBSnG6FFi47-k5pPY=doz1MKgaJ6prYAskQgVvmzwg@mail.gmail.com>
	<CANdJ3dXsqG+tLdV8Q-u1w-L9C3o5w84+xAEPNrEqNmq9aXaSYg@mail.gmail.com>
Message-ID: <CAP01uRm1-8A8o+kckgY+d3WR3eEd0Nc5sYuaTAd+tOBUTz8e2w@mail.gmail.com>

On Mon, Jun 3, 2013 at 9:24 AM, Tal Galili <tal.galili at gmail.com> wrote:
> My apologies Sarah, you are right, here:
>
>
>  sessionInfo()
> R version 3.0.0 (2013-04-03)
> Platform: i386-w64-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=Hebrew_Israel.1255  LC_CTYPE=Hebrew_Israel.1255
>  LC_MONETARY=Hebrew_Israel.1255
> [4] LC_NUMERIC=C                   LC_TIME=Hebrew_Israel.1255
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] plyr_1.8   jpeg_0.1-4
>
> loaded via a namespace (and not attached):
> [1] tools_3.0.0


Try this:

read.delim("clipboard")


From nicomet80 at gmail.com  Mon Jun  3 15:41:44 2013
From: nicomet80 at gmail.com (Nico Met)
Date: Mon, 3 Jun 2013 15:41:44 +0200
Subject: [R] split and common variables
Message-ID: <CAMMD=S4TzsJx3kjmZTG1rWc34oAarYKga=Q=L3PLcvzaWSzo4g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130603/e2bd5aec/attachment.pl>

From pdalgd at gmail.com  Mon Jun  3 15:48:48 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 3 Jun 2013 15:48:48 +0200
Subject: [R] Why do tabs disappear when pasted into the R console?
In-Reply-To: <CAM_vjuk4zBSnG6FFi47-k5pPY=doz1MKgaJ6prYAskQgVvmzwg@mail.gmail.com>
References: <CANdJ3dWgo5YwMW0MBTdQSr7awK5LPG7yNgALpJF-R730+cm5UQ@mail.gmail.com>
	<CAM_vjuk4zBSnG6FFi47-k5pPY=doz1MKgaJ6prYAskQgVvmzwg@mail.gmail.com>
Message-ID: <778A1E90-A94B-498B-9E1E-221082A09B3A@gmail.com>


On Jun 3, 2013, at 15:22 , Sarah Goslee wrote:

> Pasting tabs into the console works for me on linux, which suggests
> that you need to provide more information about your OS and all the
> other usual things.

Which console and which Linux?

Anyways, the thing that usually gets in the way is tab-completion. If you expect pasting to work exactly as if the same characters were typed at the keyboard, you can't really expect that TAB will not try to autocomplete commands and filenames. I don't know whether there's a way to temporarily disable completion.

-pf

> 
> Sarah
> 
> On Mon, Jun 3, 2013 at 9:15 AM, Tal Galili <tal.galili at gmail.com> wrote:
>> Hello Dear R-help Members,
>> 
>> I have noticed that when pasting text with "tab" in it to the R console it
>> eliminates the tab. Whereas, when pasted into the R Editor, the tab is
>> preserved.
>> For example, pasting this:
>> "1997 7680"
>> In the R Console will result in:
>> "19977680"
>> 
>> Is there a way to preserve the tab?
>> This would allow (for example) to use read.table with a table copied from
>> website/libre-office/excel such as:
>> 
>> a = read.table( text=
>> "
>> 1 2
>> 3 4
>> ")
>> a
>> 
>> I understand I can use readClipboard directly, but I wonder if there is a
>> way to use it while the text is kept in the R Editor.
>> 
>> 
>> With regards,
>> Tal
> 
> 
> -- 
> Sarah Goslee
> http://www.functionaldiversity.org
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dcarlson at tamu.edu  Mon Jun  3 15:54:59 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 3 Jun 2013 08:54:59 -0500
Subject: [R] error about MCA
In-Reply-To: <437ecacf.7226.13f00437ae1.Coremail.laomeng_3@163.com>
References: <437ecacf.7226.13f00437ae1.Coremail.laomeng_3@163.com>
Message-ID: <011501ce6061$efba47e0$cf2ed7a0$@tamu.edu>

Probably because you have defined all of the variables as
supplemental. These will then be estimated from the other variables,
but there are no other variables.

-----------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of meng
Sent: Saturday, June 1, 2013 10:03 AM
To: R help
Subject: [R] error about MCA

Hi,all:
I want to perform multiple correspondance analysis via
MCA{FactoMineR}.
The data is in the attachment.

My code:
dat<-read.delim("e:\\mydata.txt",header=T)
MCA(dat,quanti.sup=7,quali.sup=1:6)
Error in `[.data.frame`(tab, , i) : undefined columns selected
 
My question:
Why does the error happen?
 
Many thanks.

Best.


From wolfgang.viechtbauer at maastrichtuniversity.nl  Mon Jun  3 16:08:43 2013
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Mon, 3 Jun 2013 16:08:43 +0200
Subject: [R] Strange behaviour of R graphics copied to PowerPoint
In-Reply-To: <261d774a-5258-41ba-8ea5-795f0db6a474@email.android.com>
References: <CAJSLS6UVLAp1AtH-u6XebB+qfgvddsgLvApCJYqkQ8Q69qw7Ew@mail.gmail.com>
	<261d774a-5258-41ba-8ea5-795f0db6a474@email.android.com>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730D7B6A30F1@UM-MAIL4112.unimaas.nl>

I have come across this issue many times. I have yet to find a pattern in what causes this.

At least I can offer a workaround. Instead of using "Save As" to create the pdf, what I do is "Print" with "Adobe PDF" as the printer. This gets rid of those lines and the resulting pdf looks just as nice.

There is one slight disadvantage to this. Hyperlinks in your Powerpoint presentation that are not directly given as a URL (with no line breaks) will no longer work. So, if you have:

http://www.r-project.org/

in your slide, then this will be "clickable". However, if the hyperlink is a property of the object (e.g., text, button) in the slide, then it won't be anymore clickable when you "print" it (while "Save As" does preserve those links).

Best,
Wolfgang

--   
Wolfgang Viechtbauer, Ph.D., Statistician   
Department of Psychiatry and Psychology   
School for Mental Health and Neuroscience   
Faculty of Health, Medicine, and Life Sciences   
Maastricht University, P.O. Box 616 (VIJV1)   
6200 MD Maastricht, The Netherlands   
+31 (43) 388-4170 | http://www.wvbauer.com   


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Jeff Newmiller
> Sent: Monday, June 03, 2013 13:58
> To: Erling Johan Fr?ysa; r-help at r-project.org
> Subject: Re: [R] Strange behaviour of R graphics copied to PowerPoint
> 
> I have not seen this particular problem, but I have seen other problems
> and I tend to export bitmaps or pdf files as a result.
> 
> Note that a reproducible example is usually required to to obtain help on
> this list, and posting in HTML format is bad because it mutilates example
> code, so fix your email client. Please read the Posting Guide for more
> etiquette tips.
> --------------------------------------------------------------------------
> -
> Jeff Newmiller                        The     .....       .....  Go
> Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> --------------------------------------------------------------------------
> -
> Sent from my phone. Please excuse my brevity.
> 
> "Erling Johan Fr?ysa" <erling.froysa at gmail.com> wrote:
> 
> >Hello,
> >
> >I am using R to create graphics, especially to plot time series charts.
> >These charts are then copied as metafiles (for best quality) to a
> >PowerPoint
> >presentation and then saved to PDF (via the "Save As" dialog").
> >
> >Attached is two pictures. The first picture shows how my chart looks
> >like in
> >the R Graphics window, and the second picture shows how the chart
> >becomes
> >after saving it to PDF.
> >
> >< http://r.789695.n4.nabble.com/file/n4668522/R.png>
> >
> >< http://r.789695.n4.nabble.com/file/n4668522/Rppt.png>
> >
> >As you can see. After saving the metafile to PDF via PowerPoint, some
> >straight lines appears (it seems like all of the lines has the same
> >origin
> >in the upper left corner and ends somewhere on the times series line).
> >This
> >happens in both plot() and ggplot(). The problem appears more often
> >when
> >using daily data in my time series. With monthly data the problem don't
> >exist.
> >
> >Have anyone experienced this before? Do you think the problem is
> >related to
> >R or to Powerpoint?
> >
> >Thanks all,
> >
> >E
> >
> >	[[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.

From ripley at stats.ox.ac.uk  Mon Jun  3 16:11:51 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 03 Jun 2013 15:11:51 +0100
Subject: [R] Why do tabs disappear when pasted into the R console?
In-Reply-To: <778A1E90-A94B-498B-9E1E-221082A09B3A@gmail.com>
References: <CANdJ3dWgo5YwMW0MBTdQSr7awK5LPG7yNgALpJF-R730+cm5UQ@mail.gmail.com>
	<CAM_vjuk4zBSnG6FFi47-k5pPY=doz1MKgaJ6prYAskQgVvmzwg@mail.gmail.com>
	<778A1E90-A94B-498B-9E1E-221082A09B3A@gmail.com>
Message-ID: <51ACA427.3020308@stats.ox.ac.uk>

On 03/06/2013 14:48, peter dalgaard wrote:
>
> On Jun 3, 2013, at 15:22 , Sarah Goslee wrote:
>
>> Pasting tabs into the console works for me on linux, which suggests
>> that you need to provide more information about your OS and all the
>> other usual things.
>
> Which console and which Linux?
>
> Anyways, the thing that usually gets in the way is tab-completion. If you expect pasting to work exactly as if the same characters were typed at the keyboard, you can't really expect that TAB will not try to autocomplete commands and filenames. I don't know whether there's a way to temporarily disable completion.

There are lots of consoles and completion mechanisms.  But on RGui (at 
least this seems to be Windows), this is controlled by the environment 
variable R_COMPLETION and that can be set during a session.  Its help says

      ?R_COMPLETION?: Optional.  If set to ?FALSE?, command-line
           completion is not used.  (Not used by Mac OS GUI.)

and ??completion gets you there.


> -pf
>
>>
>> Sarah
>>
>> On Mon, Jun 3, 2013 at 9:15 AM, Tal Galili <tal.galili at gmail.com> wrote:
>>> Hello Dear R-help Members,
>>>
>>> I have noticed that when pasting text with "tab" in it to the R console it
>>> eliminates the tab. Whereas, when pasted into the R Editor, the tab is
>>> preserved.
>>> For example, pasting this:
>>> "1997 7680"
>>> In the R Console will result in:
>>> "19977680"
>>>
>>> Is there a way to preserve the tab?
>>> This would allow (for example) to use read.table with a table copied from
>>> website/libre-office/excel such as:
>>>
>>> a = read.table( text=
>>> "
>>> 1 2
>>> 3 4
>>> ")
>>> a
>>>
>>> I understand I can use readClipboard directly, but I wonder if there is a
>>> way to use it while the text is kept in the R Editor.
>>>
>>>
>>> With regards,
>>> Tal
>>
>>
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From marc_schwartz at me.com  Mon Jun  3 16:18:32 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 03 Jun 2013 09:18:32 -0500
Subject: [R] Strange behaviour of R graphics copied to PowerPoint
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730D7B6A30F1@UM-MAIL4112.unimaas.nl>
References: <CAJSLS6UVLAp1AtH-u6XebB+qfgvddsgLvApCJYqkQ8Q69qw7Ew@mail.gmail.com>
	<261d774a-5258-41ba-8ea5-795f0db6a474@email.android.com>
	<077E31A57DA26E46AB0D493C9966AC730D7B6A30F1@UM-MAIL4112.unimaas.nl>
Message-ID: <76B74E49-CF55-44AB-A3F3-0CDB5A02FB20@me.com>

In addition to the manner in which the PDF files are generated, you might want to consider the possibility that the lines are artifacts created by your PDF viewer.

See:

  http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-are-there-unwanted-borders


Regards,

Marc Schwartz


On Jun 3, 2013, at 9:08 AM, Viechtbauer Wolfgang (STAT) <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:

> I have come across this issue many times. I have yet to find a pattern in what causes this.
> 
> At least I can offer a workaround. Instead of using "Save As" to create the pdf, what I do is "Print" with "Adobe PDF" as the printer. This gets rid of those lines and the resulting pdf looks just as nice.
> 
> There is one slight disadvantage to this. Hyperlinks in your Powerpoint presentation that are not directly given as a URL (with no line breaks) will no longer work. So, if you have:
> 
> http://www.r-project.org/
> 
> in your slide, then this will be "clickable". However, if the hyperlink is a property of the object (e.g., text, button) in the slide, then it won't be anymore clickable when you "print" it (while "Save As" does preserve those links).
> 
> Best,
> Wolfgang
> 
> --   
> Wolfgang Viechtbauer, Ph.D., Statistician   
> Department of Psychiatry and Psychology   
> School for Mental Health and Neuroscience   
> Faculty of Health, Medicine, and Life Sciences   
> Maastricht University, P.O. Box 616 (VIJV1)   
> 6200 MD Maastricht, The Netherlands   
> +31 (43) 388-4170 | http://www.wvbauer.com   
> 
> 
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On Behalf Of Jeff Newmiller
>> Sent: Monday, June 03, 2013 13:58
>> To: Erling Johan Fr?ysa; r-help at r-project.org
>> Subject: Re: [R] Strange behaviour of R graphics copied to PowerPoint
>> 
>> I have not seen this particular problem, but I have seen other problems
>> and I tend to export bitmaps or pdf files as a result.
>> 
>> Note that a reproducible example is usually required to to obtain help on
>> this list, and posting in HTML format is bad because it mutilates example
>> code, so fix your email client. Please read the Posting Guide for more
>> etiquette tips.
>> --------------------------------------------------------------------------
>> -
>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                      Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>> --------------------------------------------------------------------------
>> -
>> Sent from my phone. Please excuse my brevity.
>> 
>> "Erling Johan Fr?ysa" <erling.froysa at gmail.com> wrote:
>> 
>>> Hello,
>>> 
>>> I am using R to create graphics, especially to plot time series charts.
>>> These charts are then copied as metafiles (for best quality) to a
>>> PowerPoint
>>> presentation and then saved to PDF (via the "Save As" dialog").
>>> 
>>> Attached is two pictures. The first picture shows how my chart looks
>>> like in
>>> the R Graphics window, and the second picture shows how the chart
>>> becomes
>>> after saving it to PDF.
>>> 
>>> < http://r.789695.n4.nabble.com/file/n4668522/R.png>
>>> 
>>> < http://r.789695.n4.nabble.com/file/n4668522/Rppt.png>
>>> 
>>> As you can see. After saving the metafile to PDF via PowerPoint, some
>>> straight lines appears (it seems like all of the lines has the same
>>> origin
>>> in the upper left corner and ends somewhere on the times series line).
>>> This
>>> happens in both plot() and ggplot(). The problem appears more often
>>> when
>>> using daily data in my time series. With monthly data the problem don't
>>> exist.
>>> 
>>> Have anyone experienced this before? Do you think the problem is
>>> related to
>>> R or to Powerpoint?
>>> 
>>> Thanks all,
>>> 
>>> E


From jvadams at usgs.gov  Mon Jun  3 16:47:23 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 3 Jun 2013 09:47:23 -0500
Subject: [R] Y-lim minimum overrun in barplot
In-Reply-To: <CAHskT4rx2gBADoyoh8Z=kL=Aveo8EVYaA5mOrb56A8J2+MXEJQ@mail.gmail.com>
References: <CAHskT4rx2gBADoyoh8Z=kL=Aveo8EVYaA5mOrb56A8J2+MXEJQ@mail.gmail.com>
Message-ID: <CAN5YmCGAy+u2jUF_i4JwA6o_O14pvkE8ETdJaWsKOG7kKKKwpQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130603/b3a60ec2/attachment.pl>

From jvadams at usgs.gov  Mon Jun  3 16:55:40 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 3 Jun 2013 09:55:40 -0500
Subject: [R] split and common variables
In-Reply-To: <CAMMD=S4TzsJx3kjmZTG1rWc34oAarYKga=Q=L3PLcvzaWSzo4g@mail.gmail.com>
References: <CAMMD=S4TzsJx3kjmZTG1rWc34oAarYKga=Q=L3PLcvzaWSzo4g@mail.gmail.com>
Message-ID: <CAN5YmCEKQBNxZ7u9nnQbCHEPUmr64cK1nCRf=CSVxEwkiMMHPw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130603/2e7001e6/attachment.pl>

From smartpink111 at yahoo.com  Mon Jun  3 17:09:27 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 3 Jun 2013 08:09:27 -0700 (PDT)
Subject: [R] split and common variables
In-Reply-To: <CAMMD=S4TzsJx3kjmZTG1rWc34oAarYKga=Q=L3PLcvzaWSzo4g@mail.gmail.com>
References: <CAMMD=S4TzsJx3kjmZTG1rWc34oAarYKga=Q=L3PLcvzaWSzo4g@mail.gmail.com>
Message-ID: <1370272167.62329.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,

It is not clear.
dta1<-do.call(data.frame,dta)
dta2<-dta1[complete.cases(dta1),]
dta2[,-3]<-lapply(dta2[,-3],as.character)
lstdta2<-split(dta2,dta2$place)
library(plyr)
join_all(lapply(lstdta2,`[`,-1),by="name",type="inner") #none of them are common
#[1] name? value value value value value
#<0 rows> (or 0-length row.names)


A.K.


----- Original Message -----
From: Nico Met <nicomet80 at gmail.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Monday, June 3, 2013 9:41 AM
Subject: [R] split and common variables

Dear all,

I would like to split the data based on the "place" and then would like to
see how many "names" were common in place with corresponding "value" .

Please find a demo file.

Thanks for your expert comment

best

Nico

> dput(dta)
structure(list(place = structure(c(3L, 2L, 5L, 6L, 4L, 3L, 2L,
5L, 6L, 4L, 2L, 5L, 6L, 4L, 2L, 5L, 6L, 4L, 2L, 3L, 2L, 5L, 6L,
4L, 3L, 2L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 1L), .Label = c("",
"GCKT", "IKLI", "KLOI", "PLRT", "POIV"), class = "factor"), name = structure
(c(2L,
3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 2L, 3L, 4L, 5L, 6L,
7L, 8L, 9L, 10L, 11L, 12L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
11L, 12L, 12L, 1L), .Label = c("", "P_CK23", "P_CK24", "P_CK25",
"P_CK26", "P_CK27", "P_CK28", "P_CK29", "P_CK30", "P_CK31", "P_CK32",
"P_CK33"), class = "factor"), value = c(5.9464, 6.0786, -4.5155,
15.0241, -38.1847, -0.0861, 1.2757, -23.9914, 9.5951, -11.128,
6.2826, 23.5218, 20.862, 3.1626, 6.242, -20.5348, -14.0126, -13.796,
15.3869, -15.7409, -8.1963, -14.4522, 3.2117, -1.2738, 14.3556,
-12.5337, 20.4308, -3.3227, -34.802, -11.1103, -9.7146, -35.9044,
-9.4303, -28.1949, NA)), .Names = c("place", "name", "value"), class = "data
.frame", row.names = c(NA,
35L))
>

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From dcarlson at tamu.edu  Mon Jun  3 17:20:22 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 3 Jun 2013 10:20:22 -0500
Subject: [R] split and common variables
In-Reply-To: <CAMMD=S4TzsJx3kjmZTG1rWc34oAarYKga=Q=L3PLcvzaWSzo4g@mail.gmail.com>
References: <CAMMD=S4TzsJx3kjmZTG1rWc34oAarYKga=Q=L3PLcvzaWSzo4g@mail.gmail.com>
Message-ID: <015801ce606d$dd637e70$982a7b50$@tamu.edu>

It may be easier if you convert the list you provided to a
data.frame:

> dta.df <- data.frame(place=dta$place, name=dta$name,
value=dta$value)
> dta.df

Note that the last line is blank so you probably want to remove that
and remove the blank factor levels:

> dta.df <- dta.df[-nrow(dta.df),]
> dta.df$place <- factor(dta.df$place)
> dta.df$name <- factor(dta.df$name)
> dta.df

Now you can make a list containing separate data.frames by place 

> dta.df.sp <- split(dta.df, dta.df$place)
> dta.df.sp

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Nico Met
Sent: Monday, June 3, 2013 8:42 AM
To: R help
Subject: [R] split and common variables

Dear all,

I would like to split the data based on the "place" and then would
like to
see how many "names" were common in place with corresponding "value"
.

Please find a demo file.

Thanks for your expert comment

best

Nico

> dput(dta)
structure(list(place = structure(c(3L, 2L, 5L, 6L, 4L, 3L, 2L,
5L, 6L, 4L, 2L, 5L, 6L, 4L, 2L, 5L, 6L, 4L, 2L, 3L, 2L, 5L, 6L,
4L, 3L, 2L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 1L), .Label = c("",
"GCKT", "IKLI", "KLOI", "PLRT", "POIV"), class = "factor"), name =
structure
(c(2L,
3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 2L, 3L, 4L, 5L, 6L,
7L, 8L, 9L, 10L, 11L, 12L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
11L, 12L, 12L, 1L), .Label = c("", "P_CK23", "P_CK24", "P_CK25",
"P_CK26", "P_CK27", "P_CK28", "P_CK29", "P_CK30", "P_CK31",
"P_CK32",
"P_CK33"), class = "factor"), value = c(5.9464, 6.0786, -4.5155,
15.0241, -38.1847, -0.0861, 1.2757, -23.9914, 9.5951, -11.128,
6.2826, 23.5218, 20.862, 3.1626, 6.242, -20.5348, -14.0126, -13.796,
15.3869, -15.7409, -8.1963, -14.4522, 3.2117, -1.2738, 14.3556,
-12.5337, 20.4308, -3.3227, -34.802, -11.1103, -9.7146, -35.9044,
-9.4303, -28.1949, NA)), .Names = c("place", "name", "value"), class
= "data
.frame", row.names = c(NA,
35L))
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From yelin at lbl.gov  Mon Jun  3 17:25:59 2013
From: yelin at lbl.gov (Ye Lin)
Date: Mon, 3 Jun 2013 08:25:59 -0700
Subject: [R] delete active dataset
Message-ID: <CAAvu=bkrunnwnsJzE9ypC9LpiXVqaW3zmi4Gxvds6T-37ghgQw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130603/dab0ed6f/attachment.pl>

From jrkrideau at inbox.com  Mon Jun  3 17:33:49 2013
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 3 Jun 2013 07:33:49 -0800
Subject: [R] delete active dataset
In-Reply-To: <CAAvu=bkrunnwnsJzE9ypC9LpiXVqaW3zmi4Gxvds6T-37ghgQw@mail.gmail.com>
Message-ID: <E43D31A30B3.000004C3jrkrideau@inbox.com>

It sounds like you inadvertently saved a workspace file.  Have a look in your current directory and see if there is an .RDATA file there that you don't recognize. If so, delete it.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: yelin at lbl.gov
> Sent: Mon, 3 Jun 2013 08:25:59 -0700
> To: r-help at r-project.org
> Subject: [R] delete active dataset
> 
> Hi All, whenever I open R using the shortcut on desktop, there are 2
> active
> datasets in the workspace, I tried to start the program from Start menu,
> same thing!! How can I delete these two active datasets and make sure
> whenever I restart the program, they wont appear?
> 
> Thanks!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at http://www.inbox.com/smileys
Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk? and most webmails


From Avraham.Adler at guycarp.com  Mon Jun  3 18:36:20 2013
From: Avraham.Adler at guycarp.com (Adler, Avraham)
Date: Mon, 3 Jun 2013 11:36:20 -0500
Subject: [R] Error code from optim - "NEW_X" what does it mean?
Message-ID: <93A2161604A30C4ABE14AC35CAFC8422DE7315B4@USDFW11XM32.mercer.com>

Hello.

Does anyone know what the error code "NEW_X" means in optim? Here is what the return looks like:

		$counts
		function gradient
			 302      302

		$convergence
		[1] 1

		$message
		[1] "NEW_X"

I have searched and found a couple of mentions without responses:

<https://stat.ethz.ch/pipermail/r-help/2011-September/290722.html>   September 2011
<https://stat.ethz.ch/pipermail/r-devel/2013-May/066731.html>        Full disclosure, this is my (unanswered) question on R-devel


I can only find one instance of the call in `optim.c` and I don't understand what it is doing.

Thank you,

Avraham Adler




 


From murdoch.duncan at gmail.com  Mon Jun  3 18:46:27 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 03 Jun 2013 12:46:27 -0400
Subject: [R] Strange behaviour of R graphics copied to PowerPoint
In-Reply-To: <CAJSLS6UVLAp1AtH-u6XebB+qfgvddsgLvApCJYqkQ8Q69qw7Ew@mail.gmail.com>
References: <CAJSLS6UVLAp1AtH-u6XebB+qfgvddsgLvApCJYqkQ8Q69qw7Ew@mail.gmail.com>
Message-ID: <51ACC863.7030303@gmail.com>

On 02/06/2013 1:15 PM, Erling Johan Fr?ysa wrote:
> Hello,
>
> I am using R to create graphics, especially to plot time series charts.
> These charts are then copied as metafiles (for best quality) to a PowerPoint
> presentation and then saved to PDF (via the "Save As" dialog").
>
> Attached is two pictures. The first picture shows how my chart looks like in
> the R Graphics window, and the second picture shows how the chart becomes
> after saving it to PDF.
>
> < http://r.789695.n4.nabble.com/file/n4668522/R.png>
>
> < http://r.789695.n4.nabble.com/file/n4668522/Rppt.png>
>
> As you can see. After saving the metafile to PDF via PowerPoint, some
> straight lines appears (it seems like all of the lines has the same origin
> in the upper left corner and ends somewhere on the times series line). This
> happens in both plot() and ggplot(). The problem appears more often when
> using daily data in my time series. With monthly data the problem don't
> exist.
>
> Have anyone experienced this before? Do you think the problem is related to
> R or to Powerpoint?

This has come up before, and it does appear to be a problem in 
Powerpoint: it doesn't export to PDF very well.  It is possible that the 
metafiles that R produces could be changed so as not to trigger this 
bug, but that would really need input from Microsoft on what changes are 
needed, and as far as I've heard, they've never made any comment or 
acknowledgment of the problem.

My advice would be to contact them; if they're unresponsive, try some 
other software (OpenOffice, LibreOffice, LaTeX+Beamer, ...).

Duncan Murdoch


From jdnewmil at dcn.davis.CA.us  Mon Jun  3 19:03:00 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 03 Jun 2013 10:03:00 -0700
Subject: [R] Error code from optim - "NEW_X" what does it mean?
In-Reply-To: <93A2161604A30C4ABE14AC35CAFC8422DE7315B4@USDFW11XM32.mercer.com>
References: <93A2161604A30C4ABE14AC35CAFC8422DE7315B4@USDFW11XM32.mercer.com>
Message-ID: <b02b5fad-b2fd-44c3-9bdf-eb383e04a3d6@email.android.com>

Your email Is missing a reproducible example... very sub-optimal, likely to be ignored.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

"Adler, Avraham" <Avraham.Adler at guycarp.com> wrote:

>Hello.
>
>Does anyone know what the error code "NEW_X" means in optim? Here is
>what the return looks like:
>
>		$counts
>		function gradient
>			 302      302
>
>		$convergence
>		[1] 1
>
>		$message
>		[1] "NEW_X"
>
>I have searched and found a couple of mentions without responses:
>
><https://stat.ethz.ch/pipermail/r-help/2011-September/290722.html>  
>September 2011
><https://stat.ethz.ch/pipermail/r-devel/2013-May/066731.html>       
>Full disclosure, this is my (unanswered) question on R-devel
>
>
>I can only find one instance of the call in `optim.c` and I don't
>understand what it is doing.
>
>Thank you,
>
>Avraham Adler
>
>
>
>
> 
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Avraham.Adler at guycarp.com  Mon Jun  3 19:40:15 2013
From: Avraham.Adler at guycarp.com (Adler, Avraham)
Date: Mon, 3 Jun 2013 12:40:15 -0500
Subject: [R] Error code from optim - "NEW_X" what does it mean?
In-Reply-To: <b02b5fad-b2fd-44c3-9bdf-eb383e04a3d6@email.android.com>
References: <93A2161604A30C4ABE14AC35CAFC8422DE7315B4@USDFW11XM32.mercer.com>
	<b02b5fad-b2fd-44c3-9bdf-eb383e04a3d6@email.android.com>
Message-ID: <93A2161604A30C4ABE14AC35CAFC8422DE7316A9@USDFW11XM32.mercer.com>

Hello, Jeff.

Thank you for your quick response. Unfortunately, a reproducible example will be difficult, if not impossible, as it depends on a particular compilation of both 'R' and 'Rblas.dll' as described in <https://stat.ethz.ch/pipermail/r-devel/2013-May/066731.html>. I therefore was hoping that someone would recognize the error code having seen it before, know what it means or what could cause it, and could help direct me towards a solution.


If you, or someone, has a Nehelem (corei7) or SandyBridge (corei7-avx) processor running Windows 64-bit, I can describe (off-line) step-by-step as to how to generate the necessary files, or I'd be happy to e-mail the flawed Rblas.dll if you or anyone has access to the above kinds of machines and OS, and are interested.


To address the request for a little more information, inside `factanal`, there is a call to optim. Using the reference BLAS, `fa <- factanal( ~., 2, data = swiss)` works fine. Using a specific compiled BLAS it returns "unable to optimize". Breaking it down further (by running the procedures in factanal.R manually) the error comes from an optim call in `factanal.mle.fit` that does not converge, but returns an ever-so-slightly different set of numbers and the "NEW_X" error code. Running the code with the reference BLAS will return the PASS version below, running the code with the flawed BLAS returns the FAIL version. The code is just running the subprocedures in `factanal.R` using "data=swiss" and factors=2:


PASS
		> nfit

		Call:
		NULL

		Uniquenesses:
			   Fertility      Agriculture      Examination        Education
				   0.420            0.492            0.270            0.005
				Catholic Infant.Mortality
				   0.061            0.960

		Loadings:
						 Factor1 Factor2
		Fertility        -0.674   0.356
		Agriculture      -0.648   0.297
		Examination       0.713  -0.471
		Education         0.997
		Catholic         -0.178   0.953
		Infant.Mortality -0.104   0.169

					   Factor1 Factor2
		SS loadings      2.419   1.373
		Proportion Var   0.403   0.229
		Cumulative Var   0.403   0.632

		The degrees of freedom for the model is 4 and the fit was 0.5017
		> nfit$converged
		[1] TRUE

FAIL

		> nfit

		Call:
		NULL

		Uniquenesses:
			   Fertility      Agriculture      Examination        Education
				   0.417            0.487            0.258            0.012
				Catholic Infant.Mortality
				   0.097            0.951

		Loadings:
						 Factor1 Factor2
		Fertility        -0.683   0.340
		Agriculture      -0.658   0.282
		Examination       0.728  -0.461
		Education         0.993
		Catholic         -0.203   0.929
		Infant.Mortality -0.110   0.171

					   Factor1 Factor2
		SS loadings      2.469   1.302
		Proportion Var   0.411   0.217
		Cumulative Var   0.411   0.628

		The degrees of freedom for the model is 4 and the fit was 0.5042
		> nfit$converged
		[1] FALSE



Thank you,

Avraham Adler


-----Original Message-----
From: Jeff Newmiller
Sent: Monday, June 03, 2013 1:03 PM
To: Adler, Avraham; r-help at r-project.org
Subject: Re: [R] Error code from optim - "NEW_X" what does it mean?

Your email Is missing a reproducible example... very sub-optimal, likely to be ignored.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.

"Adler, Avraham" <Avraham.Adler at guycarp.com> wrote:

>Hello.
>
>Does anyone know what the error code "NEW_X" means in optim? Here is 
>what the return looks like:
>
>		$counts
>		function gradient
>			 302      302
>
>		$convergence
>		[1] 1
>
>		$message
>		[1] "NEW_X"
>
>I have searched and found a couple of mentions without responses:
>
><https://stat.ethz.ch/pipermail/r-help/2011-September/290722.html>
>September 2011
><https://stat.ethz.ch/pipermail/r-devel/2013-May/066731.html>       
>Full disclosure, this is my (unanswered) question on R-devel
>
>
>I can only find one instance of the call in `optim.c` and I don't
>understand what it is doing.
>
>Thank you,
>
>Avraham Adler
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From szehnder at uni-bonn.de  Mon Jun  3 19:37:59 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Mon, 3 Jun 2013 19:37:59 +0200
Subject: [R] Optim seems not to work properly in foreach
Message-ID: <83F485E4-798D-404A-9912-0242E277DEE7@uni-bonn.de>

Hi guys,

I am working now for several years in R and I would say I manage things pretty easily, but with the foreach loop I have my problems. I call for a simulation a double foreach loop and this works fine. Inside the second loop (which I plan to parallelize later on) I call Rs optim-function:
                                                                                               
"simulateML" <- function(sim.it = 250, input.path,
                        output.path, T = 390, ncore = 2) {

        ## load packages ##
        library("mmstruct")
        library("doMC")
        library("foreach")

        ## read input parameters ##
        input <- read.csv(input.path, header = FALSE)

        ## create container to store results ##
        results <- data.frame(NA, nrow = NROW(input) * sim.it, ncol = 12)

        ## initialize the parallel backend ##
        registerDoMC(ncore)

        result.list <- foreach(i = 1:2) %do% {
                input <- as.matrix(input)
                input.row <- input[i, ]
                list <- foreach(i = 1:2, .combine = rbind, .packages = c("mmstruct", "stats")) %do% {
                        data <- simulateEKOP(size = input.row[1], alpha = input.row[2],           
                                        epsilon = input.row[1], delta = input.row[4],
                                        mu = input.row[5], T = T)
                        data <- data[,4]
                        ## create start values ##
                        tmp <- mean(data)/T
                        startpar <- c(0, tmp * 0.75/2, tmp * 0.25/2)

                        ## set options for optimization ##
                        optim_fn        <- computeKokotLik
                        optim_method    <- "L-BFGS-B"
                        optim_lower     <- c(-1e+7, 0, 0)
                        optim_upper     <- rep(1e+7, 3)
                        optim_fnscale   <- -1
                        optim_maxit     <- 200
                        optim_ctrl      <- list(fnscale = optim_fnscale, maxit = optim_maxit)

                        ## start optimization ##
                        res <- optim(par = startpar, fn = optim_fn, data = data, T = T,
                                        methodLik = "approx", method = optim_method,
                                        lower = optim_lower, upper = optim_upper,
                                        control = optim_ctrl, hessian = TRUE)
                        res$par

                }
                print(list)
        }

}

Data simulation and thecreation of startpar works fine, but the parameters in res$par are always the start parameters. If I run the same commands directly on the shell I get in res$par the optimized parameters - only inside the foreach loop optim seems not to work. What could that be? 


Best 

Simon


From angel at mpi-marburg.mpg.de  Mon Jun  3 18:27:13 2013
From: angel at mpi-marburg.mpg.de (Roey Angel)
Date: Mon, 03 Jun 2013 18:27:13 +0200
Subject: [R] Mixed effects model with a phylogenetic tree/ distance matrix
 as a random effect
Message-ID: <51ACC3E1.2090107@mpi-marburg.mpg.de>

Hi,
I'm trying to build a mixed-effects model in which I'd like to include 
either a distance matrix or a phylogenetic tree as a random effect.
The troubles I've had are that:
1. Function lmer() in package lme4 only accepts a data frame column as a 
random factor and not a distance matrix.
2. Function MCMCglmm() in package MCMCglmm only accepts a rooted and 
ultrametric phylogenetic tree as a pedigree argument while my tree is 
neither (and for various reasons I cannot construct one or coerce mine 
to be a rooted, ultrametric tree).

Is there any way around it?
I'd appreciate mostly a solution to problem 1.

Roey

-- 
Dr. Roey Angel

Max-Planck-Institute for Terrestrial Microbiology
Karl-von-Frisch-Strasse 10
D-35043 Marburg, Germany

Office: +49 (0)6421/178-832
Mobile: +49 (0)176/612-785-88


From nprause at mednet.ucla.edu  Mon Jun  3 19:31:03 2013
From: nprause at mednet.ucla.edu (Nicole Prause)
Date: Mon, 3 Jun 2013 10:31:03 -0700
Subject: [R] Y-lim minimum overrun in barplot
In-Reply-To: <011701ce606a$66205d40$326117c0$@tamu.edu>
References: <CAHskT4rx2gBADoyoh8Z=kL=Aveo8EVYaA5mOrb56A8J2+MXEJQ@mail.gmail.com>
	<011701ce606a$66205d40$326117c0$@tamu.edu>
Message-ID: <CAHskT4r-gbAgL1FTgAP4_46EoYZ-TejmePKyYshaEmO4vk-UFg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130603/79352589/attachment.pl>

From mail at pmean.com  Mon Jun  3 19:37:17 2013
From: mail at pmean.com (Steve Simon, P.Mean Consulting)
Date: Mon, 3 Jun 2013 10:37:17 -0700 (PDT)
Subject: [R] Strange behaviour of R graphics copied to PowerPoint
In-Reply-To: <CAJSLS6UVLAp1AtH-u6XebB+qfgvddsgLvApCJYqkQ8Q69qw7Ew@mail.gmail.com>
References: <CAJSLS6UVLAp1AtH-u6XebB+qfgvddsgLvApCJYqkQ8Q69qw7Ew@mail.gmail.com>
Message-ID: <1370281037569-4668586.post@n4.nabble.com>

As I understand it, there are multiple competing standards for the Windows
Metafile (WMF) format. See
--> http://en.wikipedia.org/wiki/Windows_Metafile

I like WMF because it is vector based and thus scales nicely. But eventually
I gave up on it because the WMF format was unpredictable when exported to
other applications. I would encourage you to experiment with the bmp() and
png() functions. If you specify a large enough value for width and height so
that the don't get re-scaled, then they will look just as good as the WMF
format.

If you like to tinker with a graph onscreen and then save it, you need to
open the graphics window at the "right" size so that the saved BMP or PNG
file does not need rescaling in Powerpoint. I hope this makes sense.
Graphics are tricky in any package.

Steve Simon, www.pmean.com



--
View this message in context: http://r.789695.n4.nabble.com/Strange-behaviour-of-R-graphics-copied-to-PowerPoint-tp4668535p4668586.html
Sent from the R help mailing list archive at Nabble.com.


From nilsson.henric at gmail.com  Mon Jun  3 12:15:39 2013
From: nilsson.henric at gmail.com (Henric Winell)
Date: Mon, 03 Jun 2013 12:15:39 +0200
Subject: [R] wilcox_test function in coin package
In-Reply-To: <CAFCoDdByrDLZgffzqBEog1GZCY3bQ=mnfb-r_yASssTm3NxfxA@mail.gmail.com>
References: <CAFCoDdDp64MFyvTTB6b_O6KgoTKYR41mCB2sPCC4c6ANQyWx1Q@mail.gmail.com>
	<CAFEqCdy6+NhK2hgcWQALYmYXx1a0tRqJTHYBXx-FUb9OYfFUKA@mail.gmail.com>
	<CAFCoDdBcm4B1tVW7BarkHXAgpqMpTCimmjhrLc3N7=yvSSEbbw@mail.gmail.com>
	<CAFEqCdz_=YBeeDYLfpDYyTAwjr6a4n2OKTbQaBsb9UC=G9sAag@mail.gmail.com>
	<CAFCoDdC1asW6JGK5huY_kLgCQQCduw8s=YjhHDP0ptA_9YAhhw@mail.gmail.com>
	<51A9291C.70509@ucalgary.ca>
	<CAFCoDdAOHSKSTTD8o+gkdoMppuMW_XhX63zoh-eveBcnE1HVHQ@mail.gmail.com>
	<51A9EC17.2000907@gmail.com>
	<CAFCoDdByrDLZgffzqBEog1GZCY3bQ=mnfb-r_yASssTm3NxfxA@mail.gmail.com>
Message-ID: <51AC6CCB.7040207@gmail.com>

Janh,

Janh Anni skrev 2013-06-01 19:47:
> Hello All,
> Thanks a lot for the helpful suggestions.  I wonder how ties are handled
> for the rank sum test by wilcox_test and wilcox.exact?  For instance,

Ties handling was mainly a problem back in the day when recursion 
formulas were used for the computation of exact p-values.  (When no ties 
are present, the form of the exact null distribution of the Wilcoxon 
rank-sum statistic depends only on the total number of observations in 
the two groups.)

> other software such as Minitab correct for ties by adjusting the
> variance of the test statistic, and actually provide the p values before
> and after adjustment for ties.

Adjusting the variance only matters when approximating the exact 
distribution with its asymptotic Gaussian distribution.  And only when 
at least one tie is shared between the two groups.  And yes, the 
standardized statistic in 'coin' accounts for ties.  If ties are 
present, why would you want to know the unadjusted p-value?

> IIf neither wilcox_test nor wilcox.exact
> expressly corrects for ties in the Wilcoxon rank sum test, then perhaps
> one should just use the conventional wilcox.test which is the simplest
 > of them all?  Thanks again

If this was true, the 'wilcox.exact' function would be completely 
pointless since 'wilcox.test' just falls back on the asymptotic 
approximation when ties are present.

Software like 'StatXact', 'exactRankTests', and 'coin' use algorithms 
that compute the exact p-value for any ties configuration.  Take a look 
at Torsten Hothorn's "On Exact Rank Tests in R" article from the very 
first issue of R News http://www.r-project.org/doc/Rnews/Rnews_2001-1.pdf.


Henric



> Janh
>
>
> On Sat, Jun 1, 2013 at 8:41 AM, Henric Winell <nilsson.henric at gmail.com
> <mailto:nilsson.henric at gmail.com>> wrote:
>
>     Janh,
>
>     Janh Anni skrev 2013-06-01 04:27:
>
>         Hello peter,
>
>
>         Thanks for the comment.  wilcox.exact is simpler as you pointed
>         out but the
>         fact that it is no longer being developed is somewhat concerning.
>
>
>     Admittedly, 'coin' is being actively developed and has a lot more
>     bells and whistles.  But for something as simple as this, that
>     wouldn't bother me at all.  In any case, the 'exactRankTests'
>     package still gets bug fixes and the algorithm used in the Wilcoxon
>     case is exactly the same for both packages.
>
>     However, if you want to stay with 'coin' you can just wrap up Greg's
>     proposal in a function:
>
>     wilcox_test.default <- function(x, y, ...) {
>          data <-
>              data.frame(values = c(x, y),
>                         group = rep(c("x", "y"), c(length(x), length(y))))
>          wilcox_test(values ~ group, data = data, ...)
>     }
>
>     Assuming that both 'coin' and 'exactRankTests are loaded, we can now
>     check that it works:
>
>      > set.seed(123)
>      > x <- rpois(10, 3)
>      > y <- rpois(11, 3.1)
>      >
>      > wilcox_test(x, y, alternative = "less", distribution = "exact")
>
>              Exact Wilcoxon-Mann-Whitney Test
>
>     data:  values by group (x, y)
>     Z = -0.0715, p-value = 0.4844
>     alternative hypothesis: true mu is less than 0
>
>      > wilcox.exact(x, y, alternative = "less")
>
>              Exact Wilcoxon rank sum test
>
>     data:  x and y
>     W = 54, p-value = 0.4844
>     alternative hypothesis: true mu is less than 0
>
>
>     HTH,
>     Henric
>
>
>
>
>         Regards
>         Janh
>
>
>         On Fri, May 31, 2013 at 6:50 PM, Peter Ehlers
>         <ehlers at ucalgary.ca <mailto:ehlers at ucalgary.ca>> wrote:
>
>             On 2013-05-30 20:20, Janh Anni wrote:
>
>                 Hello Greg,
>
>                 Thank you so much for your kind assistance.  It looks
>                 like there's no way
>                 around using the formula format.  I longed in vain for a
>                 simpler script
>                 more like the wilcox.test format.  Thanks again.
>
>                 Janh
>
>
>             I don't see why the formula syntax would be a problem, but
>             to avoid it
>             you could use exactRankTests::wilcox.exact() which, I
>             believe, was
>             written by the same author. It uses the same syntax as
>             wilcox.test().
>             Note, though, that the package is no longer
>             being developed.
>
>             Peter Ehlers
>
>
>
>
>                 On Thu, May 30, 2013 at 6:21 PM, Greg Snow
>                 <538280 at gmail.com <mailto:538280 at gmail.com>> wrote:
>
>                    Ok, it looks like the function mainly works through
>                 the formula syntax.
>
>                         It still would have been nice to have a
>                     reproducible example of what
>                     your
>                     data may look like, but I can show an example with
>                     simulated x and y:
>
>                        x <- rpois(10, 3)
>
>                         y <- rpois(11, 3.1)
>                         mydf <- data.frame( vals = c(x,y),
>
>                     +   group=rep( c('x','y'), c( length(x), length(y) ) ) )
>
>                         wilcox_test( vals ~ group, data=mydf )
>
>
>                                Asymptotic Wilcoxon-Mann-Whitney Test
>
>                     data:  vals by group (x, y)
>                     Z = -1.3718, p-value = 0.1701
>                     alternative hypothesis: true mu is not equal to 0
>
>                     Does that help?  (maybe I am the heedlessness
>                     theorist after all)
>
>
>
>                     On Thu, May 30, 2013 at 4:14 PM, Janh Anni
>                     <annijanh at gmail.com <mailto:annijanh at gmail.com>> wrote:
>
>                        I thought (hoped) wilcox_test(x,y) would do it
>                     but it doesn't and the
>
>                         package maintainer says the data have to be
>                         rearranged but does not
>                         specify
>                         how.  Thanks
>
>                         Janh
>
>
>
>                         On Thu, May 30, 2013 at 6:05 PM, Greg Snow
>                         <538280 at gmail.com <mailto:538280 at gmail.com>> wrote:
>
>                            What have you tried so far?  Have you read
>                         the help page? have you run
>
>                             the examples on that page?
>
>                             I would expect that it is something as simple as
>
>                             library(coin)
>                             wilcox_test(x,y)
>
>                             or
>
>                             wilcox_test( y ~ group )
>
>                             But you should trust the help page more than
>                             the expectations of
>                             someone
>                             who has not read it recently (see fortune(14)).
>
>                             If that does not answer your question then
>                             give us more detail on what
>                             you tried, what you expected the results to
>                             be, what the results
>                             actually
>                             were, and how they differed.  Without that
>                             information we have to
>                             resort to
>                             mind reading and the current implementation
>                             of the esp package is still
>                             very pre-alpha, it suggests that the answer
>                             to your question is:
>
>                                esp()
>
>
>                             [1] "selflessly vigilantly pigeon theorist
>                             heedlessness"
>
>                             Which is either much to profound for the
>                             likes of me to understand or
>                             is
>                             complete gibberish (which is only slightly
>                             less helpful than an overly
>                             general question without a reproducible
>                             example).
>
>
>                             On Thu, May 30, 2013 at 2:07 PM, Janh Anni
>                             <annijanh at gmail.com
>                             <mailto:annijanh at gmail.com>> wrote:
>
>                                Dear All,
>
>
>                                 I have two simple data samples (no
>                                 groups or factors, etc.) and would
>                                 just
>                                 like to compute the two-sample Wilcoxon
>                                 Rank Sum test using the
>                                 wilcox_test
>                                 function contained in the coin package,
>                                 which is reportedly better
>                                 than
>                                 the
>                                 regular wilcox.test function because it
>                                 performs some adjustment for
>                                 ties.
>                                 Would anyone know how to craft a script
>                                 to perform this task?  Much
>                                 appreciated.
>
>                                 Janh
>
>                                            [[alternative HTML version
>                                 deleted]]
>
>                                 ________________________________**________________
>                                 R-help at r-project.org
>                                 <mailto:R-help at r-project.org> mailing list
>                                 https://stat.ethz.ch/mailman/*__*listinfo/r-help
>                                 <https://stat.ethz.ch/mailman/**listinfo/r-help><https://stat__ethz.ch/mailman/listinfo/r-__help
>                                 <https://stat.ethz.ch/mailman/listinfo/r-help>>
>
>                                 PLEASE do read the posting guide
>                                 http://www.R-project.org/**__posting-guide.html
>                                 <http://www.R-project.org/**posting-guide.html><http://www.__R-project.org/posting-guide.__html
>                                 <http://www.R-project.org/posting-guide.html>>
>
>                                 and provide commented, minimal,
>                                 self-contained, reproducible code.
>
>
>
>
>                             --
>                             Gregory (Greg) L. Snow Ph.D.
>                             538280 at gmail.com <mailto:538280 at gmail.com>
>
>
>
>
>
>                     --
>                     Gregory (Greg) L. Snow Ph.D.
>                     538280 at gmail.com <mailto:538280 at gmail.com>
>
>
>                           [[alternative HTML version deleted]]
>
>                 ________________________________**________________
>                 R-help at r-project.org <mailto:R-help at r-project.org>
>                 mailing list
>                 https://stat.ethz.ch/mailman/*__*listinfo/r-help
>                 <https://stat.ethz.ch/mailman/**listinfo/r-help><https://stat__ethz.ch/mailman/listinfo/r-__help
>                 <https://stat.ethz.ch/mailman/listinfo/r-help>>
>                 PLEASE do read the posting guide http://www.R-project.org/**
>                 posting-guide.html
>                 <http://www.R-project.org/__posting-guide.html
>                 <http://www.R-project.org/posting-guide.html>>
>
>                 and provide commented, minimal, self-contained,
>                 reproducible code.
>
>
>
>
>
>                  [[alternative HTML version deleted]]
>
>         ________________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         https://stat.ethz.ch/mailman/__listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/__posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>
>


From ilapro at ceh.ac.uk  Mon Jun  3 12:22:54 2013
From: ilapro at ceh.ac.uk (Ilaria Prosdocimi)
Date: Mon, 3 Jun 2013 10:22:54 +0000
Subject: [R] Robust GAM that covers Gaussian Distributions
References: <CAMmHnJ0FvntaEy-XyUQJRv-M6j8tXhNbeCqKxTuq60qp9_xZtw@mail.gmail.com>
Message-ID: <loom.20130603T121347-492@post.gmane.org>

Christos Giannoulis <cgiannoul <at> gmail.com> writes:

> 
> Dear All,
> 
> I was looking the r-archives and crantastic...for a package that has a
> robust approach to generalized additive models. I found two packages
> "robustgam" and "rgam" but their implemented functions
> cover only binomial and poisson distributions (pls correct me if I am
> wrong).
> 
> I would greatly appreciate if anyone could share with us other packages or
> robust approaches of general additive modeling that might have a better
> performance with small data sets (n = 50 -100 records).
> 
> Thank you very much all for reading this message. I am hoping and looking
> forward to receiving your reply.
> 
> Sincerely,
> 
> Christos Giannoulis
> 
> 	[[alternative HTML version deleted]]
> 
> 

Indeed, it seems that both the libraries do not allow normal data. I think
you could try to use the code in this page
(http://www.stat.ubc.ca/~matias/penalised/) for S-estimation. 
If you want the code for the Croux et al paper
(http://onlinelibrary.wiley.com/doi/10.1111/j.1541-0420.2011.01630.x/full)
just email me (ilapro + ceh.ac.uk) - it seems to be not available online
anymore. This also allow normal data. 

Best

Ilaria


From mksrivas at mtu.edu  Mon Jun  3 16:19:41 2013
From: mksrivas at mtu.edu (Manish K. Srivastava)
Date: Mon, 03 Jun 2013 10:19:41 -0400
Subject: [R] installing package 'rqpd' (Regression quantiles for panel data)
Message-ID: <51ACA5FD.5060404@mtu.edu>

Hello R community members,

I'm trying to install the 'rqpd' package which is developed by Roger 
Koenker and Stefan Bache. When I try to install the package using the 
command 'install.packages("rqpd",repos="http://R-Forge.R-project.org")' 
I'm getting the following two messages:

i) package ?rqpd? is available as a source package but not as a binary
ii) package ?rqpd? is not available (for R version 3.0.1)

On checking the Log of /pkg on the r-forge.r.project.org website, I find 
that the package was last modified on May 8,2012 and was made compatible 
with R>2.14.

"Quick fix to make it compile for R >= 2.14"


So, in another attempt, I downloaded the older version of R (2.14) to see if the 'rqpd' package could be installed using the older version, but still I had no luck.


Is there any way I could still use this package?


Thank you for your help.

Best regards,

Manish


-- 

-- 
*Manish K. Srivastava
Michigan Technological University
*


From dcarlson at tamu.edu  Mon Jun  3 16:55:33 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 3 Jun 2013 09:55:33 -0500
Subject: [R] Y-lim minimum overrun in barplot
In-Reply-To: <CAHskT4rx2gBADoyoh8Z=kL=Aveo8EVYaA5mOrb56A8J2+MXEJQ@mail.gmail.com>
References: <CAHskT4rx2gBADoyoh8Z=kL=Aveo8EVYaA5mOrb56A8J2+MXEJQ@mail.gmail.com>
Message-ID: <011701ce606a$66205d40$326117c0$@tamu.edu>

I believe you are looking for the offset= parameter. Consider the
following:

barplot(c(2, 3), ylim=c(1, 3))
barplot(c(2, 3), ylim=c(1, 3), offset=1)

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Nicole Prause
Sent: Friday, May 31, 2013 11:31 AM
To: r-help at r-project.org
Subject: [R] Y-lim minimum overrun in barplot

The code below produces the plot hosted here:
http://www.span-lab.com/ChartStop.jpeg

    error.bar <- function(x, y, upper, lower=upper, length=0.1,...){
    if(length(x) != length(y) | length(y) !=length(lower) |
length(lower) != length(upper))
    stop("vectors must be same length")
    arrows(x,y+upper, x, y-lower, angle=90, code=3, length=length,
...)
    }

Means<-tapply(data$IntercourseIntention,data$FilmAndOrder,mean)
SDs<-tapply(data$IntercourseIntention,data$FilmAndOrder,sd)
b<-barplot(Means,col=c("gray","tan1","blue","white"),axis.lty=1,ylim
=c(2,3),names.arg=c("","","",""),ylab="Intercourse
intention",xlab="Film and condition")
legend("topleft",c("Pre drink, Neutral","Post drink,
Neutral","Pre-drink, Sexual", "Post-drink,
Sexual"),col=c("gray","tan1","blue","white"),pch=15)
error.bar(b,Means, 1.96*SDs/10)

(I know it's not pretty yet. To be fixed after the initial display
is reasonable!) The y average value minimum truly is 1.2, but even
ylim=c(1,X) produces this behavior of the bars running over the
x-axis. I should be able to specify the starting value regardless of
the range. Does anyone see the code bit I'm missing here?

Much appreciated!

Nikky

****************************
Nicole Prause, PhD
Research faculty
Department of Psychiatry
760 Westwood Blvd
University of California
Los Angeles, CA 90024
nprause at mednet.ucla.edu<mailto:nprause at mednet.ucla.edu>
www.span-lab.com<http://www.span-lab.com>

________________________________

IMPORTANT WARNING: This email (and any attachments) is\ ...{{dropped:10}}


From saranlcarvalho at gmail.com  Mon Jun  3 19:55:11 2013
From: saranlcarvalho at gmail.com (Sara Carvalho)
Date: Mon, 3 Jun 2013 18:55:11 +0100
Subject: [R] interpretation of flexsurvreg output from flexsurv package
Message-ID: <CAAwavg+7xw6udQxTK5BtYO=n4zu0TffAgXz6PbmZgGdBg76YDQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130603/8565cb79/attachment.pl>

From gunter.berton at gene.com  Mon Jun  3 20:35:29 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 3 Jun 2013 11:35:29 -0700
Subject: [R] Mixed effects model with a phylogenetic tree/ distance
 matrix as a random effect
In-Reply-To: <51ACC3E1.2090107@mpi-marburg.mpg.de>
References: <51ACC3E1.2090107@mpi-marburg.mpg.de>
Message-ID: <CACk-te2-TLBuEaCa1cmMOtjsXCzdKZ2HPSFSsDRBBV6kXvxiAw@mail.gmail.com>

Recommendation: Post this to the R-sig-mixed-models  list, not here.

Cheers,
Bert

On Mon, Jun 3, 2013 at 9:27 AM, Roey Angel <angel at mpi-marburg.mpg.de> wrote:
> Hi,
> I'm trying to build a mixed-effects model in which I'd like to include
> either a distance matrix or a phylogenetic tree as a random effect.
> The troubles I've had are that:
> 1. Function lmer() in package lme4 only accepts a data frame column as a
> random factor and not a distance matrix.
> 2. Function MCMCglmm() in package MCMCglmm only accepts a rooted and
> ultrametric phylogenetic tree as a pedigree argument while my tree is
> neither (and for various reasons I cannot construct one or coerce mine to be
> a rooted, ultrametric tree).
>
> Is there any way around it?
> I'd appreciate mostly a solution to problem 1.
>
> Roey
>
> --
> Dr. Roey Angel
>
> Max-Planck-Institute for Terrestrial Microbiology
> Karl-von-Frisch-Strasse 10
> D-35043 Marburg, Germany
>
> Office: +49 (0)6421/178-832
> Mobile: +49 (0)176/612-785-88
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From tal.galili at gmail.com  Mon Jun  3 21:46:07 2013
From: tal.galili at gmail.com (Tal Galili)
Date: Mon, 3 Jun 2013 22:46:07 +0300
Subject: [R] Why do tabs disappear when pasted into the R console?
In-Reply-To: <51ACA427.3020308@stats.ox.ac.uk>
References: <CANdJ3dWgo5YwMW0MBTdQSr7awK5LPG7yNgALpJF-R730+cm5UQ@mail.gmail.com>
	<CAM_vjuk4zBSnG6FFi47-k5pPY=doz1MKgaJ6prYAskQgVvmzwg@mail.gmail.com>
	<778A1E90-A94B-498B-9E1E-221082A09B3A@gmail.com>
	<51ACA427.3020308@stats.ox.ac.uk>
Message-ID: <CANdJ3dW9EJuMmWUn2zOzfjesL0WzW1Uyqd08sRAA8rX3LavyhQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130603/5f8ae6c2/attachment.pl>

From bbolker at gmail.com  Mon Jun  3 22:22:45 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 3 Jun 2013 20:22:45 +0000
Subject: [R] Mixed effects model with a phylogenetic tree/ distance
	matrix as a random effect
References: <51ACC3E1.2090107@mpi-marburg.mpg.de>
	<CACk-te2-TLBuEaCa1cmMOtjsXCzdKZ2HPSFSsDRBBV6kXvxiAw@mail.gmail.com>
Message-ID: <loom.20130603T221826-336@post.gmane.org>

Bert Gunter <gunter.berton <at> gene.com> writes:

> 
> Recommendation: Post this to the R-sig-mixed-models  list, not here.
> 
> Cheers,
> Bert

  Seconded.  Alternatively you could try the r-sig-phylo at r-project.org
mailing list, although I think I would try R-s-m-m first.

> 
> On Mon, Jun 3, 2013 at 9:27 AM, Roey Angel 
>   <angel <at> mpi-marburg.mpg.de> wrote:
> > Hi,
> > I'm trying to build a mixed-effects model in which I'd like to include
> > either a distance matrix or a phylogenetic tree as a random effect.
> > The troubles I've had are that:
> > 1. Function lmer() in package lme4 only accepts a data frame column 
> as a
> > random factor and not a distance matrix.

  This is not going to change in the near future, although
there is a 'pedigreemm' package built on lme4 that 
might do what you want.

  You might be able to use MASS::glmmPQL in conjunction with
the corStruct structures from nlme (for classical geostatistical
correlation models); ape (for phylogenetic models); or ramps (other
choices).

  INLA might ??? allow tree correlation structures:
http://arxiv.org/abs/1210.4908

  Ives and Garland have some MATLAB code for phylogenetic 
logistic regression ...

> > 2. Function MCMCglmm() in package MCMCglmm only accepts a rooted and
> > ultrametric phylogenetic tree as a pedigree argument while my tree is
> > neither (and for various reasons I cannot construct one or 
> coerce mine to be
> > a rooted, ultrametric tree).
> >
> > Is there any way around it?
> > I'd appreciate mostly a solution to problem 1.
> >
> > Roey
> >
> > --
> > Dr. Roey Angel
> >
> > Max-Planck-Institute for Terrestrial Microbiology
> > Karl-von-Frisch-Strasse 10
> > D-35043 Marburg, Germany
> >
> > Office: +49 (0)6421/178-832
> > Mobile: +49 (0)176/612-785-88
> >
> >
> > ______________________________________________
> > R-help <at> r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>


From dwinsemius at comcast.net  Mon Jun  3 22:46:18 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 3 Jun 2013 13:46:18 -0700
Subject: [R] Why do tabs disappear when pasted into the R console?
In-Reply-To: <CANdJ3dW9EJuMmWUn2zOzfjesL0WzW1Uyqd08sRAA8rX3LavyhQ@mail.gmail.com>
References: <CANdJ3dWgo5YwMW0MBTdQSr7awK5LPG7yNgALpJF-R730+cm5UQ@mail.gmail.com>
	<CAM_vjuk4zBSnG6FFi47-k5pPY=doz1MKgaJ6prYAskQgVvmzwg@mail.gmail.com>
	<778A1E90-A94B-498B-9E1E-221082A09B3A@gmail.com>
	<51ACA427.3020308@stats.ox.ac.uk>
	<CANdJ3dW9EJuMmWUn2zOzfjesL0WzW1Uyqd08sRAA8rX3LavyhQ@mail.gmail.com>
Message-ID: <00FABE7B-02A7-430E-A0E4-C32AE8C5D824@comcast.net>


On Jun 3, 2013, at 12:46 PM, Tal Galili wrote:

> Very interesting, thank you.
> However, after disabling the tab completion, the RGUI still can't
> distinguish pasted tabs.  e.g:
> 
> # Running:
> 
> Sys.setenv(R_COMPLETION=FALSE)
> Sys.getenv("R_COMPLETION")
> 
> a = read.table( text=
> "
> 1 2
> 3 4
> ")
> a
> 
> # will result in: (instead of two columns)
>  V1
> 1 12
> 2 34

I get the same result pasting fromExcel into RGUI in WinXP with tab-completion disabled. 

But I hope it is not forgotten that?.

 ?? six hours ago Gabor Grothendieck suggested:

read.delim("clipboard")

I do agree that is is strange but I find that the using (R 2.15.1/WinXP in VMware Fusion virtual box) R GUI editor  will not pass the tabs it recognizes (as signified by the appearance of a 7 character wide gap and the cursor jumping back)  along with source()-ed text when used with the Edit/Run selection menu choice:

read.delim("1	2
3	4")

> read.table(text="12
+ 34
+ "read.delim("12
Error: unexpected symbol in:
"34
"read.delim"
> 34")
+ 
+ 
However with this in the GUI Editor:

test <- read.table(text="1	2
3	4")

Running this succeeds:

> source(file(description="clipboard"))
> test
  V1 V2
1  1  2
2  3  4

So in Windows whatever connection the GUI is using when text from the clipboard is pasted, it somehow removes the tabs it encounters, unlike the connection used by 'source()' when accessing the clipboard file.



-- 
David.

> 
> 
> 
> 
> 
> ----------------Contact
> Details:-------------------------------------------------------
> Contact me: Tal.Galili at gmail.com |
> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
> www.r-statistics.com (English)
> ----------------------------------------------------------------------------------------------
> 
> 
> 
> On Mon, Jun 3, 2013 at 5:11 PM, Prof Brian Ripley <ripley at stats.ox.ac.uk>wrote:
> 
>> On 03/06/2013 14:48, peter dalgaard wrote:
>> 
>>> 
>>> On Jun 3, 2013, at 15:22 , Sarah Goslee wrote:
>>> 
>>> Pasting tabs into the console works for me on linux, which suggests
>>>> that you need to provide more information about your OS and all the
>>>> other usual things.
>>>> 
>>> 
>>> Which console and which Linux?
>>> 
>>> Anyways, the thing that usually gets in the way is tab-completion. If you
>>> expect pasting to work exactly as if the same characters were typed at the
>>> keyboard, you can't really expect that TAB will not try to autocomplete
>>> commands and filenames. I don't know whether there's a way to temporarily
>>> disable completion.
>>> 
>> 
>> There are lots of consoles and completion mechanisms.  But on RGui (at
>> least this seems to be Windows), this is controlled by the environment
>> variable R_COMPLETION and that can be set during a session.  Its help says
>> 
>>     ?R_COMPLETION?: Optional.  If set to ?FALSE?, command-line
>>          completion is not used.  (Not used by Mac OS GUI.)
>> 
>> and ??completion gets you there.
>> 
>> 
>> 
>> -pf
>>> 
>>> 
>>>> Sarah
>>>> 
>>>> On Mon, Jun 3, 2013 at 9:15 AM, Tal Galili <tal.galili at gmail.com> wrote:
>>>> 
>>>>> Hello Dear R-help Members,
>>>>> 
>>>>> I have noticed that when pasting text with "tab" in it to the R console
>>>>> it
>>>>> eliminates the tab. Whereas, when pasted into the R Editor, the tab is
>>>>> preserved.
>>>>> For example, pasting this:
>>>>> "1997 7680"
>>>>> In the R Console will result in:
>>>>> "19977680"
>>>>> 
>>>>> Is there a way to preserve the tab?
>>>>> This would allow (for example) to use read.table with a table copied
>>>>> from
>>>>> website/libre-office/excel such as:
>>>>> 
>>>>> a = read.table( text=
>>>>> "
>>>>> 1 2
>>>>> 3 4
>>>>> ")
>>>>> a
>>>>> 
>>>>> I understand I can use readClipboard directly, but I wonder if there is
>>>>> a
>>>>> way to use it while the text is kept in the R Editor.
>>>>> 
>>>>> 
>>>>> With regards,
>>>>> Tal
>>>>> 
>>>> 

David Winsemius
Alameda, CA, USA


From keren at math.montana.edu  Mon Jun  3 22:53:59 2013
From: keren at math.montana.edu (ilai)
Date: Mon, 3 Jun 2013 14:53:59 -0600
Subject: [R] Optim seems not to work properly in foreach
In-Reply-To: <83F485E4-798D-404A-9912-0242E277DEE7@uni-bonn.de>
References: <83F485E4-798D-404A-9912-0242E277DEE7@uni-bonn.de>
Message-ID: <CAK4FJ1Bf-QVuQ6gH69N-sn8XFqTaR+B-KPpd=qXMjqJ=X28HbQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130603/c7c3fbaf/attachment.pl>

From ligges at statistik.tu-dortmund.de  Tue Jun  4 00:00:47 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 04 Jun 2013 00:00:47 +0200
Subject: [R] Regularized Discriminant Analysis scores, anyone?
In-Reply-To: <51AB6B75.5030007@columbia.edu>
References: <51AAB599.9090109@columbia.edu>
	<51AB5922.9070703@statistik.tu-dortmund.de>
	<51AB6B75.5030007@columbia.edu>
Message-ID: <51AD120F.4030509@statistik.tu-dortmund.de>

On 02.06.2013 17:57, Matthew Fagan wrote:
> Thank you Dr. Ligges, i very much appreciate the quick reply.  i
> wondered if that was the case, based on the math as I (poorly)
> understood it.  However i remain confused.   page 107 from the "rrcov"
> package PDF makes me think I can derive LDA-style discriminant scores
> for a QDA:
>
> library(rrcov)
> data(iris)
> qda1<-QdaClassic(x=iris[,1:4], grouping=iris[,5])
> pred_qda<-predict(qda1, iris[,1:4])
> head(pred_qda at x)
> plotdat<-pred_qda at x
> plot(plotdat[,1], plotdat[,2])
> plot(plotdat[,2], plotdat[,3])
>
> pred_qda$x looks like QDA discriminant scores.   No doubt you are right,
> but if you have a moment, I'd love to know what these scores are and
> what they summarize.
>
> In addition, I have run into this nice set of lengthy R code to manually
> calculate discriminant scores for a QDA:
> https://cs.uwaterloo.ca/~a2curtis/courses/2005/ML-classification.pdf
>
> None of this means i can calculate discriminant scores for a RDA, of
> course, but QDA is my back-up choice.
>
> Bottom line: am i am completely misinterpreting what I am seeing here,
> mathematically?  Or is this just the result of different ways of
> implementing QDA in R?

What you see in your code above is the result of the formula on page 2 
of the cited paper. And you need one vector for each class - choosing 
the max value or deciding on the classification.
This corresponds to the posterior probabilities.

You originally asked for the coefficients of the discriminant components 
(i.e. direction in the space that separates the classes according to 
Fisher's criterion in the best way) given in the output of lda() (and 
here you will have max(dimension, number of classes - 1) of them). These 
are very different from the scores you are talking about now and do not 
exists for neither QDA nor RDA.

Please carefully re-read about Fisher LDA and its discriminant components.

Best,
Uwe Ligges



> Regards, and thanks again,
> Matt
>
>
> On 6/2/2013 10:39 AM, Uwe Ligges wrote:
>>
>>
>> On 02.06.2013 05:01, Matthew Fagan wrote:
>>> Hi all,
>>>
>>> I am attempting to do Regularized Discriminant Analysis (RDA) on a large
>>> dataset, and I want to extract the RDA  discriminant score matrix.  But
>>> the predict function in the "klaR" package, unlike the predict function
>>> for LDA in the "MASS" package, doesn't seem to give me an option to
>>> extract the scores.  Any suggestions?
>>
>> There are no such scores:
>>
>> same as for qda, you do not follow the Fisher idea of the linear
>> discriminant components any more: Your space is now partitioned by
>> ellipsoid like structures based on the estimation of the inner-class
>> covariance matrices.
>>
>> rda as implemented in klaR (see the reference given on the help page)
>> is a regularization that helps to overcome problems when estimating
>> non-singular covariance matrices for the separate classes.
>>
>>
>>> i have already tried (and failed; ran out of 16 GB of memory) to do this
>>> with the "rda" package: don't know why, but the klaR package seems to be
>>> much more efficient with memory.  I have included an example below:
>>
>> The rda package provides a completely different regularization
>> technique, see the reference given on the help page.
>>
>> Best,
>> Uwe Ligges
>>
>>
>>
>>
>>> library(klaR)
>>> library(MASS)
>>>
>>> data(iris)
>>>
>>> x <- rda(Species ~ ., data = iris, gamma = 0.05, lambda = 0.2)
>>> rda1<-predict(x, iris[, 1:4])
>>> str(rda1)
>>>
>>> #  This gets you an object with posterior probabilities and classes, but
>>> no discriminant scores!
>>>
>>> #  if you run lda
>>>
>>> y <- lda(Species ~ ., data = iris)
>>> lda1<-predict(y, iris[, 1:4])
>>> str(lda1)
>>>
>>> head(lda1$x)  #  gets you the discriminant scores for the LDA. But how
>>> to do this for RDA?
>>>
>>> #  curiously, the QDA function in MASS has this same problem, although
>>> you can get around it using the rrcov package.
>>>
>>> Regards, and thank very much for any help,
>>> Matt
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From ivo.welch at anderson.ucla.edu  Tue Jun  4 00:59:03 2013
From: ivo.welch at anderson.ucla.edu (ivo welch)
Date: Mon, 3 Jun 2013 15:59:03 -0700
Subject: [R] read.csv and write.csv filtering for very big data ?
Message-ID: <CAPr7RtW3fX73N5NZRQbuN7M+PFJHzXo0L1VuMLih1P2Uz5Gx5g@mail.gmail.com>

dear R wizards---

I presume this is a common problem, so I thought I would ask whether
this solution already exists and if not, suggest it.  say, a user has
a data set of x GB, where x is very big---say, greater than RAM.
fortunately, data often come sequentially in groups, and there is a
need to process contiguous subsets of them and write the results to a
new file.  read.csv and write.csv only work on FULL data sets.
read.csv has the ability to skip n lines and read only m lines, but
this can cross the subsets.  the useful solution here would be a
"filter" function that understands about chunks:

   filter.csv <- function( in.csv, out.csv, chunk, FUNprocess ) ...

a chunk would not exactly be a factor, because normal R factors can be
non-sequential in the data frame.  the filter.csv makes it very simple
to work on large data sets...almost SAS simple:

   filter.csv( pipe('bzcat infile.csv.bz2'), "results.csv", "date",
function(d) colMeans(d))
or
   filter.csv( pipe('bzcat infile.csv.bz2'), pipe("bzip -c >
results.csv.bz2"), "date", function(d) d[ unique(d$date), ] )  ##
filter out obserations that have the same date again later

or some reasonable variant of this.

now that I can have many small chunks, it would be nice if this were
threadsafe, so

   mcfilter.csv <- function( in.csv, out.csv, chunk, FUNprocess ) ...

with 'library(parallel)' could feed multiple cores the FUNprocess, and
make sure that the processes don't step on one another.  (why did R
not use a dot after "mc" for parallel lapply?)  presumably, to keep it
simple, mcfilter.csv would keep a counter of read chunks and block
write chinks until the next sequential chunk in order arrives.

just a suggestion...

/iaw

----
Ivo Welch (ivo.welch at gmail.com)


From dwinsemius at comcast.net  Tue Jun  4 02:18:24 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 3 Jun 2013 17:18:24 -0700
Subject: [R] delete active dataset
In-Reply-To: <E43D31A30B3.000004C3jrkrideau@inbox.com>
References: <E43D31A30B3.000004C3jrkrideau@inbox.com>
Message-ID: <E44FEEB1-6C30-44EE-8AEE-AEDCC8DB2CEF@comcast.net>

This may not help if the OP is using  Mac or Windows since these hidden by default. Seek out OS info on how to show dot-files.

-- 
David

Sent from my iPhone

On Jun 3, 2013, at 8:33 AM, John Kane <jrkrideau at inbox.com> wrote:

> It sounds like you inadvertently saved a workspace file.  Have a look in your current directory and see if there is an .RDATA file there that you don't recognize. If so, delete it.
> 
> John Kane
> Kingston ON Canada
> 
> 
>> -----Original Message-----
>> From: yelin at lbl.gov
>> Sent: Mon, 3 Jun 2013 08:25:59 -0700
>> To: r-help at r-project.org
>> Subject: [R] delete active dataset
>> 
>> Hi All, whenever I open R using the shortcut on desktop, there are 2
>> active
>> datasets in the workspace, I tried to start the program from Start menu,
>> same thing!! How can I delete these two active datasets and make sure
>> whenever I restart the program, they wont appear?
>> 
>> Thanks!
>> 
>>    [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ____________________________________________________________
> GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at http://www.inbox.com/smileys
> Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk? and most webmails
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From annijanh at gmail.com  Tue Jun  4 03:51:15 2013
From: annijanh at gmail.com (Janh Anni)
Date: Mon, 3 Jun 2013 21:51:15 -0400
Subject: [R] wilcox_test function in coin package
In-Reply-To: <51AC6CCB.7040207@gmail.com>
References: <CAFCoDdDp64MFyvTTB6b_O6KgoTKYR41mCB2sPCC4c6ANQyWx1Q@mail.gmail.com>
	<CAFEqCdy6+NhK2hgcWQALYmYXx1a0tRqJTHYBXx-FUb9OYfFUKA@mail.gmail.com>
	<CAFCoDdBcm4B1tVW7BarkHXAgpqMpTCimmjhrLc3N7=yvSSEbbw@mail.gmail.com>
	<CAFEqCdz_=YBeeDYLfpDYyTAwjr6a4n2OKTbQaBsb9UC=G9sAag@mail.gmail.com>
	<CAFCoDdC1asW6JGK5huY_kLgCQQCduw8s=YjhHDP0ptA_9YAhhw@mail.gmail.com>
	<51A9291C.70509@ucalgary.ca>
	<CAFCoDdAOHSKSTTD8o+gkdoMppuMW_XhX63zoh-eveBcnE1HVHQ@mail.gmail.com>
	<51A9EC17.2000907@gmail.com>
	<CAFCoDdByrDLZgffzqBEog1GZCY3bQ=mnfb-r_yASssTm3NxfxA@mail.gmail.com>
	<51AC6CCB.7040207@gmail.com>
Message-ID: <CAFCoDdAnczogD5wvsZaCBOY1J5ZsrMAx558AZD_QmNU5sLXkHw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130603/5ebed468/attachment.pl>

From smartpink111 at yahoo.com  Tue Jun  4 04:10:25 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 3 Jun 2013 19:10:25 -0700 (PDT)
Subject: [R] Read 2 rows in 1 dataframe for diff - longitudinal data
Message-ID: <1370311825.22574.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
May be this helps:
res1<-df1[with(df1,unlist(tapply(var,list(subid),FUN=function(x) c(FALSE,diff(x)!=0)),use.names=FALSE)),]
?res1
#?? subid year var
#3???? 36 2003?? 3
#7???? 47 2001?? 3
#9???? 47 2005?? 1
#10??? 47 2007?? 3
#or
library(plyr)
?subset(ddply(df1,.(subid),mutate,delta=c(FALSE,diff(var)!=0)),delta)[,-4]
#?? subid year var
#3???? 36 2003?? 3
#7???? 47 2001?? 3
#9???? 47 2005?? 1
#10??? 47 2007?? 3
A.K.



I need to output a dataframe whenever var changes a value. 

df1 <- data.frame(subid=rep(c(36,47),each=5),year=rep(seq(1999,2007,2),2),var=c(1,1,3,3,3,1,3,3,1,3)) 
? ?subid year var 
1 ? ? 36 1999 ? 1 
2 ? ? 36 2001 ? 1 
3 ? ? 36 2003 ? 3 
4 ? ? 36 2005 ? 3 
5 ? ? 36 2007 ? 3 
6 ? ? 47 1999 ? 1 
7 ? ? 47 2001 ? 3 
8 ? ? 47 2003 ? 3 
9 ? ? 47 2005 ? 1 
10 ? ?47 2007 ? 3 
> 

I need: 
36 2003 ? 3 
47 2001 ? 3 
47 2005 ? 1 
47 2007 ? 3 

I am trying to use ddply over subid and use the diff function, but it is not working quiet right. 

> dd <- ddply(df1,.(subid),summarize,delta=diff(var) != 0) 
> dd 
? subid delta 
1 ? ?36 FALSE 
2 ? ?36 ?TRUE 
3 ? ?36 FALSE 
4 ? ?36 FALSE 
5 ? ?47 ?TRUE 
6 ? ?47 FALSE 
7 ? ?47 ?TRUE 
8 ? ?47 ?TRUE 

I would appreciate any help on this. 
Thank You! 
-ST


From dwinsemius at comcast.net  Tue Jun  4 06:37:50 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 3 Jun 2013 21:37:50 -0700
Subject: [R] Read 2 rows in 1 dataframe for diff - longitudinal data
In-Reply-To: <1370311825.22574.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1370311825.22574.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <A5470E89-5497-426F-B7E0-5D308419630E@comcast.net>


On Jun 3, 2013, at 7:10 PM, arun wrote:

> Hi,
> May be this helps:
> res1<-df1[with(df1,unlist(tapply(var,list(subid),FUN=function(x) c(FALSE,diff(x)!=0)),use.names=FALSE)),]
>  res1
> #   subid year var
> #3     36 2003   3
> #7     47 2001   3
> #9     47 2005   1
> #10    47 2007   3
> #or
> library(plyr)
>  subset(ddply(df1,.(subid),mutate,delta=c(FALSE,diff(var)!=0)),delta)[,-4]
> #   subid year var
> #3     36 2003   3
> #7     47 2001   3
> #9     47 2005   1
> #10    47 2007   3
> A.K.
> 
It's pretty simple with logical indexing:

> df1[ c(FALSE, df1$var[-1]!=df1$var[-length(df1$var)]), ]
   subid year var
3     36 2003   3
6     47 1999   1
7     47 2001   3
9     47 2005   1
10    47 2007   3


When I count the number of changes in value of var is give me 5. Not sure why you are both leaving out row 6.

-- 
David.
> 
> 
> I need to output a dataframe whenever var changes a value. 
> 
> df1 <- data.frame(subid=rep(c(36,47),each=5),year=rep(seq(1999,2007,2),2),var=c(1,1,3,3,3,1,3,3,1,3)) 
>    subid year var 
> 1     36 1999   1 
> 2     36 2001   1 
> 3     36 2003   3 
> 4     36 2005   3 
> 5     36 2007   3 
> 6     47 1999   1 
> 7     47 2001   3 
> 8     47 2003   3 
> 9     47 2005   1 
> 10    47 2007   3 
>> 
> 
> I need: 
> 36 2003   3 
> 47 2001   3 
> 47 2005   1 
> 47 2007   3 
> 
> I am trying to use ddply over subid and use the diff function, but it is not working quiet right. 
> 
>> dd <- ddply(df1,.(subid),summarize,delta=diff(var) != 0) 
>> dd 
>   subid delta 
> 1    36 FALSE 
> 2    36  TRUE 
> 3    36 FALSE 
> 4    36 FALSE 
> 5    47  TRUE 
> 6    47 FALSE 
> 7    47  TRUE 
> 8    47  TRUE 
> 
> I would appreciate any help on this. 
> Thank You! 
> -ST
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From robert.b.lynch at gmail.com  Mon Jun  3 22:23:31 2013
From: robert.b.lynch at gmail.com (Robert Lynch)
Date: Mon, 3 Jun 2013 13:23:31 -0700
Subject: [R] Multiple selection and normalization
Message-ID: <CACYeG1iFURLDF25H=Pa2Y4i+Y1q1URFxO4FgTjd2Vu3BGuNygA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130603/87a7ac52/attachment.pl>

From laomeng_3 at 163.com  Tue Jun  4 03:54:33 2013
From: laomeng_3 at 163.com (meng)
Date: Tue, 4 Jun 2013 09:54:33 +0800 (CST)
Subject: [R] error about MCA
In-Reply-To: <011501ce6061$efba47e0$cf2ed7a0$@tamu.edu>
References: <437ecacf.7226.13f00437ae1.Coremail.laomeng_3@163.com>
	<011501ce6061$efba47e0$cf2ed7a0$@tamu.edu>
Message-ID: <10b8e421.15187.13f0ce491cd.Coremail.laomeng_3@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130604/b828df22/attachment.pl>

From smartpink111 at yahoo.com  Tue Jun  4 06:51:11 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 3 Jun 2013 21:51:11 -0700 (PDT)
Subject: [R] Read 2 rows in 1 dataframe for diff - longitudinal data
In-Reply-To: <A5470E89-5497-426F-B7E0-5D308419630E@comcast.net>
References: <1370311825.22574.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<A5470E89-5497-426F-B7E0-5D308419630E@comcast.net>
Message-ID: <1370321471.5229.YahooMailNeo@web142602.mail.bf1.yahoo.com>

If it is grouped by "subid" (that would be the difference in the number of changes)

subset(ddply(df1,.(subid),mutate,delta=c(FALSE,var[-1]!=var[-length(var)])),delta)[,-4]
#?? subid year var
#3???? 36 2003?? 3
#7???? 47 2001?? 3
#9???? 47 2005?? 1
#10??? 47 2007?? 3
A.K.


----- Original Message -----
From: David Winsemius <dwinsemius at comcast.net>
To: arun <smartpink111 at yahoo.com>
Cc: R help <r-help at r-project.org>
Sent: Tuesday, June 4, 2013 12:37 AM
Subject: Re: [R] Read 2 rows in 1 dataframe for diff - longitudinal data


On Jun 3, 2013, at 7:10 PM, arun wrote:

> Hi,
> May be this helps:
> res1<-df1[with(df1,unlist(tapply(var,list(subid),FUN=function(x) c(FALSE,diff(x)!=0)),use.names=FALSE)),]
>? res1
> #?  subid year var
> #3? ?  36 2003?  3
> #7? ?  47 2001?  3
> #9? ?  47 2005?  1
> #10? ? 47 2007?  3
> #or
> library(plyr)
>? subset(ddply(df1,.(subid),mutate,delta=c(FALSE,diff(var)!=0)),delta)[,-4]
> #?  subid year var
> #3? ?  36 2003?  3
> #7? ?  47 2001?  3
> #9? ?  47 2005?  1
> #10? ? 47 2007?  3
> A.K.
> 
It's pretty simple with logical indexing:

> df1[ c(FALSE, df1$var[-1]!=df1$var[-length(df1$var)]), ]
?  subid year var
3? ?  36 2003?  3
6? ?  47 1999?  1
7? ?  47 2001?  3
9? ?  47 2005?  1
10? ? 47 2007?  3


When I count the number of changes in value of var is give me 5. Not sure why you are both leaving out row 6.

-- 
David.
> 
> 
> I need to output a dataframe whenever var changes a value. 
> 
> df1 <- data.frame(subid=rep(c(36,47),each=5),year=rep(seq(1999,2007,2),2),var=c(1,1,3,3,3,1,3,3,1,3)) 
>? ? subid year var 
> 1? ?  36 1999?  1 
> 2? ?  36 2001?  1 
> 3? ?  36 2003?  3 
> 4? ?  36 2005?  3 
> 5? ?  36 2007?  3 
> 6? ?  47 1999?  1 
> 7? ?  47 2001?  3 
> 8? ?  47 2003?  3 
> 9? ?  47 2005?  1 
> 10? ? 47 2007?  3 
>> 
> 
> I need: 
> 36 2003?  3 
> 47 2001?  3 
> 47 2005?  1 
> 47 2007?  3 
> 
> I am trying to use ddply over subid and use the diff function, but it is not working quiet right. 
> 
>> dd <- ddply(df1,.(subid),summarize,delta=diff(var) != 0) 
>> dd 
>?  subid delta 
> 1? ? 36 FALSE 
> 2? ? 36? TRUE 
> 3? ? 36 FALSE 
> 4? ? 36 FALSE 
> 5? ? 47? TRUE 
> 6? ? 47 FALSE 
> 7? ? 47? TRUE 
> 8? ? 47? TRUE 
> 
> I would appreciate any help on this. 
> Thank You! 
> -ST
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA



From christoph.knapp01 at gmail.com  Tue Jun  4 10:41:21 2013
From: christoph.knapp01 at gmail.com (Christoph Knapp)
Date: Tue, 04 Jun 2013 20:41:21 +1200
Subject: [R] 3.0.1 update and compiler package
In-Reply-To: <51AC5485.7040601@ymail.com>
References: <51A80BDE.9090007@gmail.com> <51AC2750.3020503@ymail.com>
	<51AC47A4.7080603@statistik.tu-dortmund.de>
	<51AC5485.7040601@ymail.com>
Message-ID: <51ADA831.9090102@gmail.com>

Hi,
reinstalling R did not help. It still will not update the same packages. 
I attached the terminal output. There were no errors while I was 
installing R again. I might have to remove all libraries and reinstall 
them all. Would you agree or do you think I should try something else 
first which is not as extreme.

Thanks for your help

Christoph

On 03/06/13 20:32, Pascal Oettli wrote:
> My mistake,
>
> Regards,
> Pascal
>
> On 06/03/2013 04:37 PM, Uwe Ligges wrote:
>>
>>
>> On 03.06.2013 07:19, Pascal Oettli wrote:
>>> Hi,
>>>
>>> How did you upgraded your version of R? From source or from a Linux
>>> package?
>>
>> Actually the new R installation is just broken. It simply has to be
>> reinstalled carefully (watch for errors).
>>
>> Best,
>> Uwe Ligges
>>
>>
>>
>>
>>
>>
>>>
>>> Regards,
>>> Pascal
>>>
>>>
>>> On 05/31/2013 11:33 AM, Christoph Knapp wrote:
>>>> Hi,
>>>> I recently updated to R 3.0.1. I'm running linux ubuntu 12.04. I
>>>> realized that I have to update all the installed packages so I run >
>>>> update.packages(checkBuilt=TRUE)
>>>> as described here
>>>> http://www.r-bloggers.com/r-3-0-0-is-released-whats-new-and-how-to-upgrade/ 
>>>>
>>>>
>>>>
>>>> . The first thing it did was telling me that it will not update 
>>>> several
>>>> packages. When it was finished I used the warnings function to have a
>>>> look at what did not work. See the list below.
>>>>
>>>>  > warnings()
>>>> Warning messages:
>>>> 1: In install.packages(update[instlib == l, "Package"], l, ... :
>>>> installation of package ?boot? had non-zero exit status
>>>> 2: In install.packages(update[instlib == l, "Package"], l, ... :
>>>> installation of package ?cluster? had non-zero exit status
>>>> 3: In install.packages(update[instlib == l, "Package"], l, ... :
>>>> installation of package ?foreign? had non-zero exit status
>>>> 4: In install.packages(update[instlib == l, "Package"], l, ... :
>>>> installation of package ?KernSmooth? had non-zero exit status
>>>> 5: In install.packages(update[instlib == l, "Package"], l, ... :
>>>> installation of package ?MASS? had non-zero exit status
>>>> 6: In install.packages(update[instlib == l, "Package"], l, ... :
>>>> installation of package ?Matrix? had non-zero exit status
>>>> 7: In install.packages(update[instlib == l, "Package"], l, ... :
>>>> installation of package ?nlme? had non-zero exit status
>>>> 8: In install.packages(update[instlib == l, "Package"], l, ... :
>>>> installation of package ?nnet? had non-zero exit status
>>>> 9: In install.packages(update[instlib == l, "Package"], l, ... :
>>>> installation of package ?rpart? had non-zero exit status
>>>> 10: In install.packages(update[instlib == l, "Package"], l, ... :
>>>> installation of package ?spatial? had non-zero exit status
>>>> 11: In install.packages(update[instlib == l, "Package"], l, ... :
>>>> installation of package ?survival? had non-zero exit status
>>>> 12: In install.packages(update[instlib == l, "Package"], l, ... :
>>>> installation of package ?class? had non-zero exit status
>>>> 13: In install.packages(update[instlib == l, "Package"], l, ... :
>>>> installation of package ?epiR? had non-zero exit status
>>>> 14: In install.packages(update[instlib == l, "Package"], l, ... :
>>>> installation of package ?gmodels? had non-zero exit status
>>>> 15: In install.packages(update[instlib == l, "Package"], l, ... :
>>>> installation of package ?gplots? had non-zero exit status
>>>> 16: In install.packages(update[instlib == l, "Package"], l, ... :
>>>> installation of package ?mgcv? had non-zero exit status
>>>> 17: In install.packages(update[instlib == l, "Package"], l, ... :
>>>> installation of package ?gregmisc? had non-zero exit status
>>>>
>>>> I tried to reinstall them manually but this always failed because of a
>>>> package dependency to the "compiler" package. Now, if I try to install
>>>> the compiler package it tells me.
>>>>
>>>>  > install.packages("compiler")
>>>> Installing package into
>>>> ?/home/christoph/R/x86_64-pc-linux-gnu-library/3.0?
>>>> (as ?lib? is unspecified)
>>>> Warning message:
>>>> package ?compiler? is not available (for R version 3.0.1)
>>>>
>>>> The last line also came up all the time when the packages were updated
>>>>
>>>> Doing a bit of research does not deliver much only that the compiler
>>>> package was included into R at version 2.13.0
>>>> (http://dirk.eddelbuettel.com/blog/2011/04/12/).
>>>>
>>>> Most of those packages which do not work any more are pretty important
>>>> for some of my scripts and I would not even know what packages replace
>>>> the packages above.
>>>>
>>>> Would anyone know how to fix this?
>>>>
>>>> Regards
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>

-------------- next part --------------
christoph at christoph-Latitude-E4300:~$ sudo apt-get --purge remove r-base-core
[sudo] password for christoph:
Reading package lists... Done
Building dependency tree      
Reading state information... Done
The following packages will be REMOVED
  r-base* r-base-core* r-base-dev* r-base-html* r-cran-boot* r-cran-class*
  r-cran-cluster* r-cran-codetools* r-cran-foreign* r-cran-kernsmooth*
  r-cran-lattice* r-cran-mass* r-cran-matrix* r-cran-mgcv* r-cran-nlme*
  r-cran-nnet* r-cran-rpart* r-cran-spatial* r-cran-survival* r-recommended*
0 upgraded, 0 newly installed, 20 to remove and 20 not upgraded.
After this operation, 51.5 MB disk space will be freed.
Do you want to continue [Y/n]? Y
(Reading database ... 429389 files and directories currently installed.)
Removing r-base ...
Removing r-recommended ...
Removing r-cran-boot ...
Removing r-cran-mgcv ...
Removing r-cran-matrix ...
Removing r-cran-rpart ...
Removing r-cran-survival ...
Removing r-cran-kernsmooth ...
Removing r-base-dev ...
Removing r-cran-spatial ...
Removing r-cran-cluster ...
Removing r-cran-class ...
Removing r-cran-foreign ...
Removing r-cran-nlme ...
Removing r-cran-nnet ...
Removing r-base-html ...
Removing r-cran-lattice ...
Removing r-cran-mass ...
Removing r-cran-codetools ...
Removing r-base-core ...
Purging configuration files for r-base-core ...
dpkg: warning: while removing r-base-core, directory '/usr/lib/R/library' not empty so not removed.
dpkg: warning: while removing r-base-core, directory '/usr/lib/R/site-library' not empty so not removed.
Processing triggers for man-db ...
Processing triggers for bamfdaemon ...
Rebuilding /usr/share/applications/bamf.index...
Processing triggers for desktop-file-utils ...
Processing triggers for gnome-menus ...
Processing triggers for hicolor-icon-theme ...
Processing triggers for install-info ...
christoph at christoph-Latitude-E4300:~$ R
The program 'R' is currently not installed.  You can install it by typing:
sudo apt-get install r-base-core
christoph at christoph-Latitude-E4300:~$ sudo apt-get install r-base-core
Reading package lists... Done
Building dependency tree      
Reading state information... Done
The following extra packages will be installed:
  r-base-dev r-cran-boot r-cran-class r-cran-cluster r-cran-codetools r-cran-foreign
  r-cran-kernsmooth r-cran-lattice r-cran-mass r-cran-matrix r-cran-mgcv r-cran-nlme
  r-cran-nnet r-cran-rpart r-cran-spatial r-cran-survival r-recommended
Suggested packages:
  ess r-doc-info r-doc-pdf r-mathlib r-base-html texinfo texi2html
The following NEW packages will be installed
  r-base-core r-base-dev r-cran-boot r-cran-class r-cran-cluster r-cran-codetools
  r-cran-foreign r-cran-kernsmooth r-cran-lattice r-cran-mass r-cran-matrix r-cran-mgcv
  r-cran-nlme r-cran-nnet r-cran-rpart r-cran-spatial r-cran-survival r-recommended
0 upgraded, 18 newly installed, 0 to remove and 20 not upgraded.
Need to get 0 B/35.6 MB of archives.
After this operation, 50.8 MB of additional disk space will be used.
Do you want to continue [Y/n]? y
Selecting previously unselected package r-base-core.
(Reading database ... 427503 files and directories currently installed.)
Unpacking r-base-core (from .../r-base-core_3.0.1-3precise_amd64.deb) ...
Selecting previously unselected package r-base-dev.
Unpacking r-base-dev (from .../r-base-dev_3.0.1-3precise_all.deb) ...
Selecting previously unselected package r-cran-boot.
Unpacking r-cran-boot (from .../r-cran-boot_1.3-9-1precise0_all.deb) ...
Selecting previously unselected package r-cran-mass.
Unpacking r-cran-mass (from .../r-cran-mass_7.3-26-1precise0_amd64.deb) ...
Selecting previously unselected package r-cran-class.
Unpacking r-cran-class (from .../r-cran-class_7.3-7-1precise0_amd64.deb) ...
Selecting previously unselected package r-cran-cluster.
Unpacking r-cran-cluster (from .../r-cran-cluster_1.14.4-1precise0_amd64.deb) ...
Selecting previously unselected package r-cran-codetools.
Unpacking r-cran-codetools (from .../r-cran-codetools_0.2-8-2precise0_all.deb) ...
Selecting previously unselected package r-cran-foreign.
Unpacking r-cran-foreign (from .../r-cran-foreign_0.8.54-1precise0_amd64.deb) ...
Selecting previously unselected package r-cran-kernsmooth.
Unpacking r-cran-kernsmooth (from .../r-cran-kernsmooth_2.23-10-2precise0_amd64.deb) ...
Selecting previously unselected package r-cran-lattice.
Unpacking r-cran-lattice (from .../r-cran-lattice_0.20-15-1precise0_amd64.deb) ...
Selecting previously unselected package r-cran-matrix.
Unpacking r-cran-matrix (from .../r-cran-matrix_1.0-12-1precise0_amd64.deb) ...
Selecting previously unselected package r-cran-nlme.
Unpacking r-cran-nlme (from .../r-cran-nlme_3.1.109-1precise0_amd64.deb) ...
Selecting previously unselected package r-cran-mgcv.
Unpacking r-cran-mgcv (from .../r-cran-mgcv_1.7-23-1precise0_amd64.deb) ...
Selecting previously unselected package r-cran-nnet.
Unpacking r-cran-nnet (from .../r-cran-nnet_7.3-6-2precise0_amd64.deb) ...
Selecting previously unselected package r-cran-survival.
Unpacking r-cran-survival (from .../r-cran-survival_2.37-4-2precise0_amd64.deb) ...
Selecting previously unselected package r-cran-rpart.
Unpacking r-cran-rpart (from .../r-cran-rpart_4.1-1-2precise0_amd64.deb) ...
Selecting previously unselected package r-cran-spatial.
Unpacking r-cran-spatial (from .../r-cran-spatial_7.3-6-1precise0_amd64.deb) ...
Selecting previously unselected package r-recommended.
Unpacking r-recommended (from .../r-recommended_3.0.1-3precise_all.deb) ...
Processing triggers for install-info ...
Processing triggers for hicolor-icon-theme ...
Processing triggers for bamfdaemon ...
Rebuilding /usr/share/applications/bamf.index...
Processing triggers for desktop-file-utils ...
Processing triggers for gnome-menus ...
Processing triggers for man-db ...
Setting up r-base-core (3.0.1-3precise) ...

Creating config file /etc/R/Renviron with new version
mktexlsr: Updating /var/lib/texmf/ls-R-TEXMFMAIN...
mktexlsr: Done.
Setting up r-base-dev (3.0.1-3precise) ...
Setting up r-cran-boot (1.3-9-1precise0) ...
Setting up r-cran-mass (7.3-26-1precise0) ...
Setting up r-cran-class (7.3-7-1precise0) ...
Setting up r-cran-cluster (1.14.4-1precise0) ...
Setting up r-cran-codetools (0.2-8-2precise0) ...
Setting up r-cran-foreign (0.8.54-1precise0) ...
Setting up r-cran-kernsmooth (2.23-10-2precise0) ...
Setting up r-cran-lattice (0.20-15-1precise0) ...
Setting up r-cran-matrix (1.0-12-1precise0) ...
Setting up r-cran-nlme (3.1.109-1precise0) ...
Setting up r-cran-mgcv (1.7-23-1precise0) ...
Setting up r-cran-nnet (7.3-6-2precise0) ...
Setting up r-cran-survival (2.37-4-2precise0) ...
Setting up r-cran-rpart (4.1-1-2precise0) ...
Setting up r-cran-spatial (7.3-6-1precise0) ...
Setting up r-recommended (3.0.1-3precise) ...
christoph at christoph-Latitude-E4300:~$
christoph at christoph-Latitude-E4300:~$ sudo R

R version 3.0.1 (2013-05-16) -- "Good Sport"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> update.packages(checkBuilt=TRUE)
> update.packages(checkBuilt=TRUE)
Warning: package 'codetools' in library '/usr/lib/R/site-library' will not be updated
Warning: package 'DBI' in library '/usr/lib/R/site-library' will not be updated
Warning: package 'lattice' in library '/usr/lib/R/site-library' will not be updated
Warning: package 'proxy' in library '/usr/lib/R/site-library' will not be updated
Warning: package 'RColorBrewer' in library '/usr/lib/R/site-library' will not be updated
Warning: package 'RMySQL' in library '/usr/lib/R/site-library' will not be updated
Warning: package 'RSQLite' in library '/usr/lib/R/site-library' will not be updated
Warning: package 'bitops' in library '/usr/lib/R/library' will not be updated
Warning: package 'caTools' in library '/usr/lib/R/library' will not be updated
Warning: package 'DBI' in library '/usr/lib/R/library' will not be updated
Warning: package 'epiR' in library '/usr/lib/R/library' will not be updated
Warning: package 'gdata' in library '/usr/lib/R/library' will not be updated
Warning: package 'gtools' in library '/usr/lib/R/library' will not be updated
Warning: package 'proxy' in library '/usr/lib/R/library' will not be updated
Warning: package 'RColorBrewer' in library '/usr/lib/R/library' will not be updated
Warning: package 'RMySQL' in library '/usr/lib/R/library' will not be updated
Warning: package 'RSQLite' in library '/usr/lib/R/library' will not be updated
boot :
 Version 1.3-7 installed in /usr/lib/R/site-library built under R 2.15.1 
 Version 1.3-9 available at http://cran.stat.auckland.ac.nz
Update (y/N/c)?  y
class :
 Version 7.3-5 installed in /usr/lib/R/site-library built under R 2.15.1 
 Version 7.3-7 available at http://cran.stat.auckland.ac.nz
Update (y/N/c)?  y
cluster :
 Version 1.14.3 installed in /usr/lib/R/site-library built under R 2.15.1 
 Version 1.14.4 available at http://cran.stat.auckland.ac.nz
Update (y/N/c)?  y
epiR :
 Version 0.9-48 installed in /usr/lib/R/site-library built under R 2.15.3 
 Version 0.9-48 available at http://cran.stat.auckland.ac.nz
Update (y/N/c)?  y
foreign :
 Version 0.8-53 installed in /usr/lib/R/site-library built under R 2.15.3 
 Version 0.8-54 available at http://cran.stat.auckland.ac.nz
Update (y/N/c)?  y
KernSmooth :
 Version 2.23-10 installed in /usr/lib/R/site-library built under R 2.15.3 
 Version 2.23-10 available at http://cran.stat.auckland.ac.nz
Update (y/N/c)?  y
MASS :
 Version 7.3-23 installed in /usr/lib/R/site-library built under R 2.15.2 
 Version 7.3-26 available at http://cran.stat.auckland.ac.nz
Update (y/N/c)?  y
Matrix :
 Version 1.0-11 installed in /usr/lib/R/site-library built under R 2.15.2 
 Version 1.0-12 available at http://cran.stat.auckland.ac.nz
Update (y/N/c)?  y
mgcv :
 Version 1.7-22 installed in /usr/lib/R/site-library built under R 2.15.1 
 Version 1.7-23 available at http://cran.stat.auckland.ac.nz
Update (y/N/c)?  y
nlme :
 Version 3.1-108 installed in /usr/lib/R/site-library built under R 2.15.2 
 Version 3.1-109 available at http://cran.stat.auckland.ac.nz
Update (y/N/c)?  y
nnet :
 Version 7.3-6 installed in /usr/lib/R/site-library built under R 2.15.3 
 Version 7.3-6 available at http://cran.stat.auckland.ac.nz
Update (y/N/c)?  y
rpart :
 Version 4.1-1 installed in /usr/lib/R/site-library built under R 2.15.3 
 Version 4.1-1 available at http://cran.stat.auckland.ac.nz
Update (y/N/c)?  y
spatial :
 Version 7.3-4 installed in /usr/lib/R/site-library built under R 2.15.1 
 Version 7.3-6 available at http://cran.stat.auckland.ac.nz
Update (y/N/c)?  y
survival :
 Version 2.36-14 installed in /usr/lib/R/site-library built under R 2.15.0 
 Version 2.37-4 available at http://cran.stat.auckland.ac.nz
Update (y/N/c)?  y
gmodels :
 Version 2.15.1 installed in /usr/lib/R/library built under R 2.12.1 
 Version 2.15.4 available at http://cran.stat.auckland.ac.nz
Update (y/N/c)?  y
gplots :
 Version 2.10.1 installed in /usr/lib/R/library built under R 2.13.1 
 Version 2.11.0.1 available at http://cran.stat.auckland.ac.nz
Update (y/N/c)?  y
gregmisc :
 Version 2.1.2 installed in /usr/lib/R/library built under R 2.14.1 
 Version 2.1.2 available at http://cran.stat.auckland.ac.nz
Update (y/N/c)?  y
trying URL 'http://cran.stat.auckland.ac.nz/src/contrib/boot_1.3-9.tar.gz'
Content type 'application/x-gzip' length 231614 bytes (226 Kb)
opened URL
==================================================
downloaded 226 Kb

trying URL 'http://cran.stat.auckland.ac.nz/src/contrib/class_7.3-7.tar.gz'
Content type 'application/x-gzip' length 24692 bytes (24 Kb)
opened URL
==================================================
downloaded 24 Kb

trying URL 'http://cran.stat.auckland.ac.nz/src/contrib/cluster_1.14.4.tar.gz'
Content type 'application/x-gzip' length 253036 bytes (247 Kb)
opened URL
==================================================
downloaded 247 Kb

trying URL 'http://cran.stat.auckland.ac.nz/src/contrib/epiR_0.9-48.tar.gz'
Content type 'application/x-gzip' length 375546 bytes (366 Kb)
opened URL
==================================================
downloaded 366 Kb

trying URL 'http://cran.stat.auckland.ac.nz/src/contrib/foreign_0.8-54.tar.gz'
Content type 'application/x-gzip' length 320608 bytes (313 Kb)
opened URL
==================================================
downloaded 313 Kb

trying URL 'http://cran.stat.auckland.ac.nz/src/contrib/KernSmooth_2.23-10.tar.gz'
Content type 'application/x-gzip' length 33334 bytes (32 Kb)
opened URL
==================================================
downloaded 32 Kb

trying URL 'http://cran.stat.auckland.ac.nz/src/contrib/MASS_7.3-26.tar.gz'
Content type 'application/x-gzip' length 481973 bytes (470 Kb)
opened URL
==================================================
downloaded 470 Kb

trying URL 'http://cran.stat.auckland.ac.nz/src/contrib/Matrix_1.0-12.tar.gz'
Content type 'application/x-gzip' length 1649142 bytes (1.6 Mb)
opened URL
==================================================
downloaded 1.6 Mb

trying URL 'http://cran.stat.auckland.ac.nz/src/contrib/mgcv_1.7-23.tar.gz'
Content type 'application/x-gzip' length 531246 bytes (518 Kb)
opened URL
==================================================
downloaded 518 Kb

trying URL 'http://cran.stat.auckland.ac.nz/src/contrib/nlme_3.1-109.tar.gz'
Content type 'application/x-gzip' length 700708 bytes (684 Kb)
opened URL
==================================================
downloaded 684 Kb

trying URL 'http://cran.stat.auckland.ac.nz/src/contrib/nnet_7.3-6.tar.gz'
Content type 'application/x-gzip' length 29530 bytes (28 Kb)
opened URL
==================================================
downloaded 28 Kb

trying URL 'http://cran.stat.auckland.ac.nz/src/contrib/rpart_4.1-1.tar.gz'
Content type 'application/x-gzip' length 813735 bytes (794 Kb)
opened URL
==================================================
downloaded 794 Kb

trying URL 'http://cran.stat.auckland.ac.nz/src/contrib/spatial_7.3-6.tar.gz'
Content type 'application/x-gzip' length 44062 bytes (43 Kb)
opened URL
==================================================
downloaded 43 Kb

trying URL 'http://cran.stat.auckland.ac.nz/src/contrib/survival_2.37-4.tar.gz'
Content type 'application/x-gzip' length 1619938 bytes (1.5 Mb)
opened URL
==================================================
downloaded 1.5 Mb

* installing *source* package ?boot? ...
** package ?boot? successfully unpacked and MD5 sums checked
** R
** data
*** moving datasets to lazyload DB
** inst
** byte-compile and prepare package for lazy loading
Error: package ?compiler? was built before R 3.0.0: please re-install it
* removing ?/usr/lib/R/site-library/boot?
* restoring previous ?/usr/lib/R/site-library/boot?
* installing *source* package ?cluster? ...
** package ?cluster? successfully unpacked and MD5 sums checked
** libs
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c clara.c -o clara.o
gfortran   -fpic  -O3 -pipe  -g  -c daisy.f -o daisy.o
gfortran   -fpic  -O3 -pipe  -g  -c dysta.f -o dysta.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c fanny.c -o fanny.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c init.c -o init.o
gfortran   -fpic  -O3 -pipe  -g  -c mona.f -o mona.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c pam.c -o pam.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c sildist.c -o sildist.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c spannel.c -o spannel.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c twins.c -o twins.o
gcc -std=gnu99 -shared -o cluster.so clara.o daisy.o dysta.o fanny.o init.o mona.o pam.o sildist.o spannel.o twins.o -lgfortran -lm -lquadmath -L/usr/lib/R/lib -lR
installing to /usr/lib/R/site-library/cluster/libs
** R
** data
*** moving datasets to lazyload DB
** inst
** byte-compile and prepare package for lazy loading
Error: package ?compiler? was built before R 3.0.0: please re-install it
* removing ?/usr/lib/R/site-library/cluster?
* restoring previous ?/usr/lib/R/site-library/cluster?
* installing *source* package ?foreign? ...
** package ?foreign? successfully unpacked and MD5 sums checked
** libs
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c R_systat.c -o R_systat.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c Rdbfread.c -o Rdbfread.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c Rdbfwrite.c -o Rdbfwrite.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c SASxport.c -o SASxport.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c avl.c -o avl.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c dbfopen.c -o dbfopen.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c file-handle.c -o file-handle.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c format.c -o format.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c init.c -o init.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c minitab.c -o minitab.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c pfm-read.c -o pfm-read.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c sfm-read.c -o sfm-read.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c spss.c -o spss.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c stataread.c -o stataread.o
gcc -std=gnu99 -shared -o foreign.so R_systat.o Rdbfread.o Rdbfwrite.o SASxport.o avl.o dbfopen.o file-handle.o format.o init.o minitab.o pfm-read.o sfm-read.o spss.o stataread.o -L/usr/lib/R/lib -lR
installing to /usr/lib/R/site-library/foreign/libs
** R
** inst
** byte-compile and prepare package for lazy loading
Error: package ?compiler? was built before R 3.0.0: please re-install it
* removing ?/usr/lib/R/site-library/foreign?
* restoring previous ?/usr/lib/R/site-library/foreign?
* installing *source* package ?KernSmooth? ...
** package ?KernSmooth? successfully unpacked and MD5 sums checked
** libs
gfortran   -fpic  -O3 -pipe  -g  -c blkest.f -o blkest.o
gfortran   -fpic  -O3 -pipe  -g  -c cp.f -o cp.o
gfortran   -fpic  -O3 -pipe  -g  -c dgedi.f -o dgedi.o
gfortran   -fpic  -O3 -pipe  -g  -c dgefa.f -o dgefa.o
gfortran   -fpic  -O3 -pipe  -g  -c dgesl.f -o dgesl.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c init.c -o init.o
gfortran   -fpic  -O3 -pipe  -g  -c linbin.f -o linbin.o
gfortran   -fpic  -O3 -pipe  -g  -c linbin2D.f -o linbin2D.o
gfortran   -fpic  -O3 -pipe  -g  -c locpoly.f -o locpoly.o
gfortran   -fpic  -O3 -pipe  -g  -c rlbin.f -o rlbin.o
gfortran   -fpic  -O3 -pipe  -g  -c sdiag.f -o sdiag.o
gfortran   -fpic  -O3 -pipe  -g  -c sstdiag.f -o sstdiag.o
gcc -std=gnu99 -shared -o KernSmooth.so blkest.o cp.o dgedi.o dgefa.o dgesl.o init.o linbin.o linbin2D.o locpoly.o rlbin.o sdiag.o sstdiag.o -lblas -lgfortran -lm -lquadmath -lgfortran -lm -lquadmath -L/usr/lib/R/lib -lR
installing to /usr/lib/R/site-library/KernSmooth/libs
** R
** inst
** byte-compile and prepare package for lazy loading
Error: package ?compiler? was built before R 3.0.0: please re-install it
* removing ?/usr/lib/R/site-library/KernSmooth?
* restoring previous ?/usr/lib/R/site-library/KernSmooth?
* installing *source* package ?MASS? ...
** package ?MASS? successfully unpacked and MD5 sums checked
** libs
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c MASS.c -o MASS.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c lqs.c -o lqs.o
gcc -std=gnu99 -shared -o MASS.so MASS.o lqs.o -L/usr/lib/R/lib -lR
installing to /usr/lib/R/site-library/MASS/libs
** R
** data
*** moving datasets to lazyload DB
** inst
** byte-compile and prepare package for lazy loading
Error: package ?compiler? was built before R 3.0.0: please re-install it
* removing ?/usr/lib/R/site-library/MASS?
* restoring previous ?/usr/lib/R/site-library/MASS?
* installing *source* package ?Matrix? ...
** package ?Matrix? successfully unpacked and MD5 sums checked
** libs
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c CHMfactor.c -o CHMfactor.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c Csparse.c -o Csparse.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c TMatrix_as.c -o TMatrix_as.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c Tsparse.c -o Tsparse.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c init.c -o init.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c Mutils.c -o Mutils.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c chm_common.c -o chm_common.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c cs.c -o cs.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c cs_utils.c -o cs_utils.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c dense.c -o dense.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c dgCMatrix.c -o dgCMatrix.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c dgTMatrix.c -o dgTMatrix.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c dgeMatrix.c -o dgeMatrix.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c dpoMatrix.c -o dpoMatrix.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c dppMatrix.c -o dppMatrix.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c dsCMatrix.c -o dsCMatrix.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c dsyMatrix.c -o dsyMatrix.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c dspMatrix.c -o dspMatrix.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c dtCMatrix.c -o dtCMatrix.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c dtTMatrix.c -o dtTMatrix.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c dtrMatrix.c -o dtrMatrix.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c dtpMatrix.c -o dtpMatrix.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c factorizations.c -o factorizations.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c ldense.c -o ldense.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c lgCMatrix.c -o lgCMatrix.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c sparseQR.c -o sparseQR.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER -I./SuiteSparse_config     -fpic  -O3 -pipe  -g  -c abIndex.c -o abIndex.o
make[1]: Entering directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/CHOLMOD'
( cd Lib ; make clean )
make[2]: Entering directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/CHOLMOD/Lib'
make[2]: Leaving directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/CHOLMOD/Lib'
make[1]: Leaving directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/CHOLMOD'
make[1]: Entering directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/COLAMD'
( cd Source ; make clean )
make[2]: Entering directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/COLAMD/Source'
make[2]: Leaving directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/COLAMD/Source'
make[1]: Leaving directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/COLAMD'
make[1]: Entering directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/AMD'
( cd Source ; make clean )
make[2]: Entering directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/AMD/Source'
make[2]: Leaving directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/AMD/Source'
make[1]: Leaving directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/AMD'
make[1]: Entering directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/SuiteSparse_config'
make[1]: Leaving directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/SuiteSparse_config'
make[1]: Entering directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/CHOLMOD'
( cd Lib ; make )
make[2]: Entering directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/CHOLMOD/Lib'
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Core/cholmod_aat.c -o cholmod_aat.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Core/cholmod_add.c -o cholmod_add.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Core/cholmod_band.c -o cholmod_band.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Core/cholmod_change_factor.c -o cholmod_change_factor.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Core/cholmod_common.c -o cholmod_common.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Core/cholmod_complex.c -o cholmod_complex.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Core/cholmod_copy.c -o cholmod_copy.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Core/cholmod_dense.c -o cholmod_dense.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Core/cholmod_error.c -o cholmod_error.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Core/cholmod_factor.c -o cholmod_factor.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Core/cholmod_memory.c -o cholmod_memory.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Core/cholmod_sparse.c -o cholmod_sparse.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Core/cholmod_transpose.c -o cholmod_transpose.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Core/cholmod_triplet.c -o cholmod_triplet.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Check/cholmod_check.c -o cholmod_check.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Check/cholmod_read.c -o cholmod_read.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Check/cholmod_write.c -o cholmod_write.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Cholesky/cholmod_amd.c -o cholmod_amd.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Cholesky/cholmod_analyze.c -o cholmod_analyze.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Cholesky/cholmod_colamd.c -o cholmod_colamd.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Cholesky/cholmod_etree.c -o cholmod_etree.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Cholesky/cholmod_factorize.c -o cholmod_factorize.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Cholesky/cholmod_postorder.c -o cholmod_postorder.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Cholesky/cholmod_rcond.c -o cholmod_rcond.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Cholesky/cholmod_resymbol.c -o cholmod_resymbol.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Cholesky/cholmod_rowcolcounts.c -o cholmod_rowcolcounts.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Cholesky/cholmod_rowfac.c -o cholmod_rowfac.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Cholesky/cholmod_solve.c -o cholmod_solve.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Cholesky/cholmod_spsolve.c -o cholmod_spsolve.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../MatrixOps/cholmod_drop.c -o cholmod_drop.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../MatrixOps/cholmod_horzcat.c -o cholmod_horzcat.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../MatrixOps/cholmod_norm.c -o cholmod_norm.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../MatrixOps/cholmod_scale.c -o cholmod_scale.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../MatrixOps/cholmod_sdmult.c -o cholmod_sdmult.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../MatrixOps/cholmod_ssmult.c -o cholmod_ssmult.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../MatrixOps/cholmod_submatrix.c -o cholmod_submatrix.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../MatrixOps/cholmod_vertcat.c -o cholmod_vertcat.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../MatrixOps/cholmod_symmetry.c -o cholmod_symmetry.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Modify/cholmod_rowadd.c -o cholmod_rowadd.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Modify/cholmod_rowdel.c -o cholmod_rowdel.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Modify/cholmod_updown.c -o cholmod_updown.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Supernodal/cholmod_super_numeric.c -o cholmod_super_numeric.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Supernodal/cholmod_super_solve.c -o cholmod_super_solve.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -c ../Supernodal/cholmod_super_symbolic.c -o cholmod_super_symbolic.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Core/cholmod_aat.c -o cholmod_l_aat.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Core/cholmod_add.c -o cholmod_l_add.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Core/cholmod_band.c -o cholmod_l_band.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Core/cholmod_change_factor.c -o cholmod_l_change_factor.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Core/cholmod_common.c -o cholmod_l_common.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Core/cholmod_complex.c -o cholmod_l_complex.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Core/cholmod_copy.c -o cholmod_l_copy.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Core/cholmod_dense.c -o cholmod_l_dense.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Core/cholmod_error.c -o cholmod_l_error.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Core/cholmod_factor.c -o cholmod_l_factor.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Core/cholmod_memory.c -o cholmod_l_memory.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Core/cholmod_sparse.c -o cholmod_l_sparse.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Core/cholmod_transpose.c -o cholmod_l_transpose.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Core/cholmod_triplet.c -o cholmod_l_triplet.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Check/cholmod_check.c -o cholmod_l_check.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Check/cholmod_read.c -o cholmod_l_read.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Check/cholmod_write.c -o cholmod_l_write.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Cholesky/cholmod_amd.c -o cholmod_l_amd.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Cholesky/cholmod_analyze.c -o cholmod_l_analyze.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Cholesky/cholmod_colamd.c -o cholmod_l_colamd.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Cholesky/cholmod_etree.c -o cholmod_l_etree.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Cholesky/cholmod_factorize.c -o cholmod_l_factorize.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Cholesky/cholmod_postorder.c -o cholmod_l_postorder.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Cholesky/cholmod_rcond.c -o cholmod_l_rcond.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Cholesky/cholmod_resymbol.c -o cholmod_l_resymbol.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Cholesky/cholmod_rowcolcounts.c -o cholmod_l_rowcolcounts.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Cholesky/cholmod_rowfac.c -o cholmod_l_rowfac.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Cholesky/cholmod_solve.c -o cholmod_l_solve.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Cholesky/cholmod_spsolve.c -o cholmod_l_spsolve.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../MatrixOps/cholmod_drop.c -o cholmod_l_drop.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../MatrixOps/cholmod_horzcat.c -o cholmod_l_horzcat.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../MatrixOps/cholmod_norm.c -o cholmod_l_norm.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../MatrixOps/cholmod_scale.c -o cholmod_l_scale.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../MatrixOps/cholmod_sdmult.c -o cholmod_l_sdmult.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../MatrixOps/cholmod_ssmult.c -o cholmod_l_ssmult.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../MatrixOps/cholmod_submatrix.c -o cholmod_l_submatrix.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../MatrixOps/cholmod_vertcat.c -o cholmod_l_vertcat.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../MatrixOps/cholmod_symmetry.c -o cholmod_l_symmetry.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Modify/cholmod_rowadd.c -o cholmod_l_rowadd.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Modify/cholmod_rowdel.c -o cholmod_l_rowdel.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Modify/cholmod_updown.c -o cholmod_l_updown.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Supernodal/cholmod_super_numeric.c -o cholmod_l_super_numeric.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Supernodal/cholmod_super_solve.c -o cholmod_l_super_solve.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../../AMD/Include -I../../AMD/Source -I../../COLAMD/Include -I../Include -I../../SuiteSparse_config -DNPARTITION -DNPRINT     -fpic  -O3 -pipe  -g  -DDLONG -c  ../Supernodal/cholmod_super_symbolic.c -o cholmod_l_super_symbolic.o
ar -rucs ../../CHOLMOD.a cholmod_aat.o cholmod_add.o cholmod_band.o cholmod_change_factor.o cholmod_common.o cholmod_complex.o cholmod_copy.o cholmod_dense.o cholmod_error.o cholmod_factor.o cholmod_memory.o cholmod_sparse.o cholmod_transpose.o cholmod_triplet.o cholmod_check.o cholmod_read.o cholmod_write.o cholmod_amd.o cholmod_analyze.o cholmod_colamd.o cholmod_etree.o cholmod_factorize.o cholmod_postorder.o cholmod_rcond.o cholmod_resymbol.o cholmod_rowcolcounts.o cholmod_rowfac.o cholmod_solve.o cholmod_spsolve.o cholmod_drop.o cholmod_horzcat.o cholmod_norm.o cholmod_scale.o cholmod_sdmult.o cholmod_ssmult.o cholmod_submatrix.o cholmod_vertcat.o cholmod_symmetry.o cholmod_rowadd.o cholmod_rowdel.o cholmod_updown.o cholmod_super_numeric.o cholmod_super_solve.o cholmod_super_symbolic.o  cholmod_l_aat.o cholmod_l_add.o cholmod_l_band.o cholmod_l_change_factor.o cholmod_l_common.o cholmod_l_complex.o cholmod_l_copy.o cholmod_l_dense.o cholmod_l_error.o cholmod_l_factor.o cholmod_l_memory.o cholmod_l_sparse.o cholmod_l_transpose.o cholmod_l_triplet.o cholmod_l_check.o cholmod_l_read.o cholmod_l_write.o cholmod_l_amd.o cholmod_l_analyze.o cholmod_l_colamd.o cholmod_l_etree.o cholmod_l_factorize.o cholmod_l_postorder.o cholmod_l_rcond.o cholmod_l_resymbol.o cholmod_l_rowcolcounts.o cholmod_l_rowfac.o cholmod_l_solve.o cholmod_l_spsolve.o cholmod_l_drop.o cholmod_l_horzcat.o cholmod_l_norm.o cholmod_l_scale.o cholmod_l_sdmult.o cholmod_l_ssmult.o cholmod_l_submatrix.o cholmod_l_vertcat.o cholmod_l_symmetry.o cholmod_l_rowadd.o cholmod_l_rowdel.o cholmod_l_updown.o cholmod_l_super_numeric.o cholmod_l_super_solve.o cholmod_l_super_symbolic.o 
make[2]: Leaving directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/CHOLMOD/Lib'
make[1]: Leaving directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/CHOLMOD'
make[1]: Entering directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/COLAMD'
( cd Source ; make lib )
make[2]: Entering directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/COLAMD/Source'
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -c colamd_global.c -o colamd_global.o
colamd_global.c:22:44: warning: initialisation from incompatible pointer type [enabled by default]
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -c colamd.c -o colamd.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDLONG -c colamd.c -o colamd_l.o
ar -rucs ../../COLAMD.a colamd_global.o colamd.o colamd_l.o
make[2]: Leaving directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/COLAMD/Source'
make[1]: Leaving directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/COLAMD'
make[1]: Entering directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/AMD'
( cd Source ; make lib )
make[2]: Entering directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/AMD/Source'
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDINT -c amd_aat.c -o amd_i_aat.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDLONG -c amd_aat.c -o amd_l_aat.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDINT -c amd_1.c -o amd_i_1.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDLONG -c amd_1.c -o amd_l_1.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDINT -c amd_2.c -o amd_i_2.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDLONG -c amd_2.c -o amd_l_2.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDINT -c amd_postorder.c -o amd_i_postorder.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDLONG -c amd_postorder.c -o amd_l_postorder.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDINT -c amd_post_tree.c -o amd_i_post_tree.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDLONG -c amd_post_tree.c -o amd_l_post_tree.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDINT -c amd_defaults.c -o amd_i_defaults.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDLONG -c amd_defaults.c -o amd_l_defaults.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDINT -c amd_order.c -o amd_i_order.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDLONG -c amd_order.c -o amd_l_order.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDINT -c amd_control.c -o amd_i_control.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDLONG -c amd_control.c -o amd_l_control.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDINT -c amd_info.c -o amd_i_info.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDLONG -c amd_info.c -o amd_l_info.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDINT -c amd_valid.c -o amd_i_valid.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDLONG -c amd_valid.c -o amd_l_valid.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDINT -c amd_preprocess.c -o amd_i_preprocess.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDLONG -c amd_preprocess.c -o amd_l_preprocess.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDINT -c amd_dump.c -o amd_i_dump.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDLONG -c amd_dump.c -o amd_l_dump.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDINT -c amd_global.c -o amd_i_global.o
amd_global.c:81:41: warning: initialisation from incompatible pointer type [enabled by default]
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -I../Include -I../../SuiteSparse_config     -fpic  -O3 -pipe  -g  -I../Include -DDLONG -c amd_global.c -o amd_l_global.o
amd_global.c:81:41: warning: initialisation from incompatible pointer type [enabled by default]
ar -rucs ../../AMD.a amd_i_aat.o amd_l_aat.o amd_i_1.o amd_l_1.o amd_i_2.o amd_l_2.o amd_i_postorder.o amd_l_postorder.o amd_i_post_tree.o amd_l_post_tree.o amd_i_defaults.o amd_l_defaults.o amd_i_order.o amd_l_order.o amd_i_control.o amd_l_control.o amd_i_info.o amd_l_info.o amd_i_valid.o amd_l_valid.o amd_i_preprocess.o amd_l_preprocess.o amd_i_dump.o amd_l_dump.o amd_i_global.o amd_l_global.o 
make[2]: Leaving directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/AMD/Source'
make[1]: Leaving directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/AMD'
make[1]: Entering directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/SuiteSparse_config'
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG -DNTIMER     -fpic  -O3 -pipe  -g  -c SuiteSparse_config.c -o SuiteSparse_config.o
ar -rucs ../SuiteSparse_config.a SuiteSparse_config.o
make[1]: Leaving directory `/tmp/RtmpjDFbwj/R.INSTALL10e2fab8ff2/Matrix/src/SuiteSparse_config'
gcc -std=gnu99 -shared -o Matrix.so CHMfactor.o Csparse.o TMatrix_as.o Tsparse.o init.o Mutils.o chm_common.o cs.o cs_utils.o dense.o dgCMatrix.o dgTMatrix.o dgeMatrix.o dpoMatrix.o dppMatrix.o dsCMatrix.o dsyMatrix.o dspMatrix.o dtCMatrix.o dtTMatrix.o dtrMatrix.o dtpMatrix.o factorizations.o ldense.o lgCMatrix.o sparseQR.o abIndex.o CHOLMOD.a COLAMD.a AMD.a SuiteSparse_config.a -llapack -lblas -lgfortran -lm -lquadmath -L/usr/lib/R/lib -lR
installing to /usr/lib/R/site-library/Matrix/libs
** R
** data
** inst
** byte-compile and prepare package for lazy loading
Error: package ?compiler? was built before R 3.0.0: please re-install it
* removing ?/usr/lib/R/site-library/Matrix?
* restoring previous ?/usr/lib/R/site-library/Matrix?
* installing *source* package ?nlme? ...
** package ?nlme? successfully unpacked and MD5 sums checked
** libs
gfortran   -fpic  -O3 -pipe  -g  -c chol.f -o chol.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG     -fvisibility=hidden -fpic  -O3 -pipe  -g  -c corStruct.c -o corStruct.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG     -fvisibility=hidden -fpic  -O3 -pipe  -g  -c gnls.c -o gnls.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG     -fvisibility=hidden -fpic  -O3 -pipe  -g  -c init.c -o init.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG     -fvisibility=hidden -fpic  -O3 -pipe  -g  -c matrix.c -o matrix.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG     -fvisibility=hidden -fpic  -O3 -pipe  -g  -c nlOptimizer.c -o nlOptimizer.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG     -fvisibility=hidden -fpic  -O3 -pipe  -g  -c nlme.c -o nlme.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG     -fvisibility=hidden -fpic  -O3 -pipe  -g  -c nlmefit.c -o nlmefit.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG     -fvisibility=hidden -fpic  -O3 -pipe  -g  -c nls.c -o nls.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG     -fvisibility=hidden -fpic  -O3 -pipe  -g  -c pdMat.c -o pdMat.o
gfortran   -fpic  -O3 -pipe  -g  -c rs.f -o rs.o
gcc -std=gnu99 -shared -o nlme.so chol.o corStruct.o gnls.o init.o matrix.o nlOptimizer.o nlme.o nlmefit.o nls.o pdMat.o rs.o -lgfortran -lm -lquadmath -L/usr/lib/R/lib -lR
installing to /usr/lib/R/site-library/nlme/libs
** R
** data
*** moving datasets to lazyload DB
** inst
** byte-compile and prepare package for lazy loading
Error: package ?compiler? was built before R 3.0.0: please re-install it
* removing ?/usr/lib/R/site-library/nlme?
* restoring previous ?/usr/lib/R/site-library/nlme?
* installing *source* package ?nnet? ...
** package ?nnet? successfully unpacked and MD5 sums checked
** libs
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c nnet.c -o nnet.o
gcc -std=gnu99 -shared -o nnet.so nnet.o -L/usr/lib/R/lib -lR
installing to /usr/lib/R/site-library/nnet/libs
** R
** inst
** byte-compile and prepare package for lazy loading
Error: package ?compiler? was built before R 3.0.0: please re-install it
* removing ?/usr/lib/R/site-library/nnet?
* restoring previous ?/usr/lib/R/site-library/nnet?
* installing *source* package ?rpart? ...
** package ?rpart? successfully unpacked and MD5 sums checked
** libs
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c anova.c -o anova.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c anovapred.c -o anovapred.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c branch.c -o branch.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c bsplit.c -o bsplit.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c choose_surg.c -o choose_surg.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c fix_cp.c -o fix_cp.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c free_tree.c -o free_tree.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c gini.c -o gini.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c graycode.c -o graycode.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c init.c -o init.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c insert_split.c -o insert_split.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c make_cp_list.c -o make_cp_list.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c make_cp_table.c -o make_cp_table.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c mysort.c -o mysort.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c nodesplit.c -o nodesplit.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c partition.c -o partition.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c poisson.c -o poisson.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c pred_rpart.c -o pred_rpart.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c print_tree.c -o print_tree.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c rpart.c -o rpart.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c rpart_callback.c -o rpart_callback.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c rpartexp.c -o rpartexp.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c rpartexp2.c -o rpartexp2.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c rpcountup.c -o rpcountup.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c rpmatrix.c -o rpmatrix.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c rundown.c -o rundown.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c rundown2.c -o rundown2.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c surrogate.c -o surrogate.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c usersplit.c -o usersplit.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c xpred.c -o xpred.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c xval.c -o xval.o
gcc -std=gnu99 -shared -o rpart.so anova.o anovapred.o branch.o bsplit.o choose_surg.o fix_cp.o free_tree.o gini.o graycode.o init.o insert_split.o make_cp_list.o make_cp_table.o mysort.o nodesplit.o partition.o poisson.o pred_rpart.o print_tree.o rpart.o rpart_callback.o rpartexp.o rpartexp2.o rpcountup.o rpmatrix.o rundown.o rundown2.o surrogate.o usersplit.o xpred.o xval.o -L/usr/lib/R/lib -lR
installing to /usr/lib/R/site-library/rpart/libs
** R
** data
*** moving datasets to lazyload DB
** inst
** byte-compile and prepare package for lazy loading
Error: package ?compiler? was built before R 3.0.0: please re-install it
* removing ?/usr/lib/R/site-library/rpart?
* restoring previous ?/usr/lib/R/site-library/rpart?
* installing *source* package ?spatial? ...
** package ?spatial? successfully unpacked and MD5 sums checked
** libs
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c init.c -o init.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c krc.c -o krc.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c pps.c -o pps.o
gcc -std=gnu99 -shared -o spatial.so init.o krc.o pps.o -L/usr/lib/R/lib -lR
installing to /usr/lib/R/site-library/spatial/libs
** R
** inst
** byte-compile and prepare package for lazy loading
Error: package ?compiler? was built before R 3.0.0: please re-install it
* removing ?/usr/lib/R/site-library/spatial?
* restoring previous ?/usr/lib/R/site-library/spatial?
* installing *source* package ?survival? ...
** package ?survival? successfully unpacked and MD5 sums checked
** libs
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c agexact.c -o agexact.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c agfit3.c -o agfit3.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c agfit5.c -o agfit5.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c agmart.c -o agmart.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c agmart2.c -o agmart2.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c agscore.c -o agscore.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c agsurv3.c -o agsurv3.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c agsurv4.c -o agsurv4.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c agsurv5.c -o agsurv5.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c chinv2.c -o chinv2.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c chinv3.c -o chinv3.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c cholesky2.c -o cholesky2.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c cholesky3.c -o cholesky3.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c chsolve2.c -o chsolve2.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c chsolve3.c -o chsolve3.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c concordance1.c -o concordance1.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c cox_Rcallback.c -o cox_Rcallback.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c coxcount1.c -o coxcount1.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c coxdetail.c -o coxdetail.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c coxexact.c -o coxexact.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c coxfit2.c -o coxfit2.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c coxfit5.c -o coxfit5.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c coxfit6.c -o coxfit6.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c coxmart.c -o coxmart.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c coxmart2.c -o coxmart2.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c coxph_wtest.c -o coxph_wtest.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c coxsafe.c -o coxsafe.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c coxscho.c -o coxscho.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c coxscore.c -o coxscore.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c dmatrix.c -o dmatrix.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c doloop.c -o doloop.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c init.c -o init.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c msurv.c -o msurv.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c pyears1.c -o pyears1.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c pyears2.c -o pyears2.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c pyears3b.c -o pyears3b.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c pystep.c -o pystep.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c survConcordance.c -o survConcordance.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c survdiff2.c -o survdiff2.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c survfit4.c -o survfit4.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c survfitci.c -o survfitci.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c survpenal.c -o survpenal.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c survreg6.c -o survreg6.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c survreg7.c -o survreg7.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c survregc1.c -o survregc1.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c survregc2.c -o survregc2.o
gcc -std=gnu99 -shared -o survival.so agexact.o agfit3.o agfit5.o agmart.o agmart2.o agscore.o agsurv3.o agsurv4.o agsurv5.o chinv2.o chinv3.o cholesky2.o cholesky3.o chsolve2.o chsolve3.o concordance1.o cox_Rcallback.o coxcount1.o coxdetail.o coxexact.o coxfit2.o coxfit5.o coxfit6.o coxmart.o coxmart2.o coxph_wtest.o coxsafe.o coxscho.o coxscore.o dmatrix.o doloop.o init.o msurv.o pyears1.o pyears2.o pyears3b.o pystep.o survConcordance.o survdiff2.o survfit4.o survfitci.o survpenal.o survreg6.o survreg7.o survregc1.o survregc2.o -L/usr/lib/R/lib -lR
installing to /usr/lib/R/site-library/survival/libs
** R
** data
*** moving datasets to lazyload DB
** inst
** byte-compile and prepare package for lazy loading
Error: package ?compiler? was built before R 3.0.0: please re-install it
* removing ?/usr/lib/R/site-library/survival?
* restoring previous ?/usr/lib/R/site-library/survival?
* installing *source* package ?class? ...
** package ?class? successfully unpacked and MD5 sums checked
** libs
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c class.c -o class.o
gcc -std=gnu99 -shared -o class.so class.o -L/usr/lib/R/lib -lR
installing to /usr/lib/R/site-library/class/libs
** R
** inst
** byte-compile and prepare package for lazy loading
Error: package ?compiler? was built before R 3.0.0: please re-install it
* removing ?/usr/lib/R/site-library/class?
* restoring previous ?/usr/lib/R/site-library/class?
* installing *source* package ?epiR? ...
** package ?epiR? successfully unpacked and MD5 sums checked
** R
** data
** preparing package for lazy loading
Error : package ?survival? was built before R 3.0.0: please re-install it
ERROR: lazy loading failed for package ?epiR?
* removing ?/usr/lib/R/site-library/epiR?
* restoring previous ?/usr/lib/R/site-library/epiR?
* installing *source* package ?mgcv? ...
** package ?mgcv? successfully unpacked and MD5 sums checked
** libs
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c gdi.c -o gdi.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c init.c -o init.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c magic.c -o magic.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c mat.c -o mat.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c matrix.c -o matrix.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c mgcv.c -o mgcv.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c misc.c -o misc.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c qp.c -o qp.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c soap.c -o soap.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c sparse-smooth.c -o sparse-smooth.o
gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG      -fpic  -O3 -pipe  -g  -c tprs.c -o tprs.o
gcc -std=gnu99 -shared -o mgcv.so gdi.o init.o magic.o mat.o matrix.o mgcv.o misc.o qp.o soap.o sparse-smooth.o tprs.o -llapack -lblas -lgfortran -lm -lquadmath -L/usr/lib/R/lib -lR
installing to /usr/lib/R/site-library/mgcv/libs
** R
** data
** inst
** byte-compile and prepare package for lazy loading
Error: package ?compiler? was built before R 3.0.0: please re-install it
* removing ?/usr/lib/R/site-library/mgcv?
* restoring previous ?/usr/lib/R/site-library/mgcv?

The downloaded source packages are in
	?/tmp/RtmpO2dLnD/downloaded_packages?
trying URL 'http://cran.stat.auckland.ac.nz/src/contrib/gmodels_2.15.4.tar.gz'
Content type 'application/x-gzip' length 38803 bytes (37 Kb)
opened URL
==================================================
downloaded 37 Kb

trying URL 'http://cran.stat.auckland.ac.nz/src/contrib/gplots_2.11.0.1.tar.gz'
Content type 'application/x-gzip' length 250489 bytes (244 Kb)
opened URL
==================================================
downloaded 244 Kb

trying URL 'http://cran.stat.auckland.ac.nz/src/contrib/gregmisc_2.1.2.tar.gz'
Content type 'application/x-gzip' length 13080 bytes (12 Kb)
opened URL
==================================================
downloaded 12 Kb

* installing *source* package ?gmodels? ...
** package ?gmodels? successfully unpacked and MD5 sums checked
** R
** inst
** preparing package for lazy loading
Error : package ?gdata? was built before R 3.0.0: please re-install it
ERROR: lazy loading failed for package ?gmodels?
* removing ?/usr/lib/R/library/gmodels?
* restoring previous ?/usr/lib/R/library/gmodels?
* installing *source* package ?gplots? ...
** package ?gplots? successfully unpacked and MD5 sums checked
** R
** data
** inst
** preparing package for lazy loading
Error : package ?gtools? was built before R 3.0.0: please re-install it
ERROR: lazy loading failed for package ?gplots?
* removing ?/usr/lib/R/library/gplots?
* restoring previous ?/usr/lib/R/library/gplots?
* installing *source* package ?gregmisc? ...
** package ?gregmisc? successfully unpacked and MD5 sums checked
** R
** inst
** preparing package for lazy loading
Error : package ?gdata? was built before R 3.0.0: please re-install it
ERROR: lazy loading failed for package ?gregmisc?
* removing ?/usr/lib/R/library/gregmisc?
* restoring previous ?/usr/lib/R/library/gregmisc?

The downloaded source packages are in
	?/tmp/RtmpO2dLnD/downloaded_packages?
Updating HTML index of packages in '.Library'
Making 'packages.html' ... done
There were 17 warnings (use warnings() to see them)
> warnings()
Warning messages:
1: In install.packages(update[instlib == l, "Package"], l,  ... :
  installation of package ?boot? had non-zero exit status
2: In install.packages(update[instlib == l, "Package"], l,  ... :
  installation of package ?cluster? had non-zero exit status
3: In install.packages(update[instlib == l, "Package"], l,  ... :
  installation of package ?foreign? had non-zero exit status
4: In install.packages(update[instlib == l, "Package"], l,  ... :
  installation of package ?KernSmooth? had non-zero exit status
5: In install.packages(update[instlib == l, "Package"], l,  ... :
  installation of package ?MASS? had non-zero exit status
6: In install.packages(update[instlib == l, "Package"], l,  ... :
  installation of package ?Matrix? had non-zero exit status
7: In install.packages(update[instlib == l, "Package"], l,  ... :
  installation of package ?nlme? had non-zero exit status
8: In install.packages(update[instlib == l, "Package"], l,  ... :
  installation of package ?nnet? had non-zero exit status
9: In install.packages(update[instlib == l, "Package"], l,  ... :
  installation of package ?rpart? had non-zero exit status
10: In install.packages(update[instlib == l, "Package"], l,  ... :
  installation of package ?spatial? had non-zero exit status
11: In install.packages(update[instlib == l, "Package"], l,  ... :
  installation of package ?survival? had non-zero exit status
12: In install.packages(update[instlib == l, "Package"], l,  ... :
  installation of package ?class? had non-zero exit status
13: In install.packages(update[instlib == l, "Package"], l,  ... :
  installation of package ?epiR? had non-zero exit status
14: In install.packages(update[instlib == l, "Package"], l,  ... :
  installation of package ?mgcv? had non-zero exit status
15: In install.packages(update[instlib == l, "Package"], l,  ... :
  installation of package ?gmodels? had non-zero exit status
16: In install.packages(update[instlib == l, "Package"], l,  ... :
  installation of package ?gplots? had non-zero exit status
17: In install.packages(update[instlib == l, "Package"], l,  ... :
  installation of package ?gregmisc? had non-zero exit status
> 




From szehnder at uni-bonn.de  Tue Jun  4 11:13:27 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Tue, 4 Jun 2013 11:13:27 +0200
Subject: [R] 3.0.1 update and compiler package
In-Reply-To: <51ADA831.9090102@gmail.com>
References: <51A80BDE.9090007@gmail.com> <51AC2750.3020503@ymail.com>
	<51AC47A4.7080603@statistik.tu-dortmund.de>
	<51AC5485.7040601@ymail.com> <51ADA831.9090102@gmail.com>
Message-ID: <64939DB5-D1A8-469C-B753-DEE3877BD9FC@uni-bonn.de>

Hi Christoph,

do you install from sources? 

Best 

Simon

On Jun 4, 2013, at 10:41 AM, Christoph Knapp <christoph.knapp01 at gmail.com> wrote:

> Hi,
> reinstalling R did not help. It still will not update the same packages. I attached the terminal output. There were no errors while I was installing R again. I might have to remove all libraries and reinstall them all. Would you agree or do you think I should try something else first which is not as extreme.
> 
> Thanks for your help
> 
> Christoph
> 
> On 03/06/13 20:32, Pascal Oettli wrote:
>> My mistake,
>> 
>> Regards,
>> Pascal
>> 
>> On 06/03/2013 04:37 PM, Uwe Ligges wrote:
>>> 
>>> 
>>> On 03.06.2013 07:19, Pascal Oettli wrote:
>>>> Hi,
>>>> 
>>>> How did you upgraded your version of R? From source or from a Linux
>>>> package?
>>> 
>>> Actually the new R installation is just broken. It simply has to be
>>> reinstalled carefully (watch for errors).
>>> 
>>> Best,
>>> Uwe Ligges
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>>> 
>>>> Regards,
>>>> Pascal
>>>> 
>>>> 
>>>> On 05/31/2013 11:33 AM, Christoph Knapp wrote:
>>>>> Hi,
>>>>> I recently updated to R 3.0.1. I'm running linux ubuntu 12.04. I
>>>>> realized that I have to update all the installed packages so I run >
>>>>> update.packages(checkBuilt=TRUE)
>>>>> as described here
>>>>> http://www.r-bloggers.com/r-3-0-0-is-released-whats-new-and-how-to-upgrade/ 
>>>>> 
>>>>> 
>>>>> . The first thing it did was telling me that it will not update several
>>>>> packages. When it was finished I used the warnings function to have a
>>>>> look at what did not work. See the list below.
>>>>> 
>>>>> > warnings()
>>>>> Warning messages:
>>>>> 1: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>> installation of package ?boot? had non-zero exit status
>>>>> 2: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>> installation of package ?cluster? had non-zero exit status
>>>>> 3: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>> installation of package ?foreign? had non-zero exit status
>>>>> 4: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>> installation of package ?KernSmooth? had non-zero exit status
>>>>> 5: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>> installation of package ?MASS? had non-zero exit status
>>>>> 6: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>> installation of package ?Matrix? had non-zero exit status
>>>>> 7: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>> installation of package ?nlme? had non-zero exit status
>>>>> 8: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>> installation of package ?nnet? had non-zero exit status
>>>>> 9: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>> installation of package ?rpart? had non-zero exit status
>>>>> 10: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>> installation of package ?spatial? had non-zero exit status
>>>>> 11: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>> installation of package ?survival? had non-zero exit status
>>>>> 12: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>> installation of package ?class? had non-zero exit status
>>>>> 13: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>> installation of package ?epiR? had non-zero exit status
>>>>> 14: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>> installation of package ?gmodels? had non-zero exit status
>>>>> 15: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>> installation of package ?gplots? had non-zero exit status
>>>>> 16: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>> installation of package ?mgcv? had non-zero exit status
>>>>> 17: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>> installation of package ?gregmisc? had non-zero exit status
>>>>> 
>>>>> I tried to reinstall them manually but this always failed because of a
>>>>> package dependency to the "compiler" package. Now, if I try to install
>>>>> the compiler package it tells me.
>>>>> 
>>>>> > install.packages("compiler")
>>>>> Installing package into
>>>>> ?/home/christoph/R/x86_64-pc-linux-gnu-library/3.0?
>>>>> (as ?lib? is unspecified)
>>>>> Warning message:
>>>>> package ?compiler? is not available (for R version 3.0.1)
>>>>> 
>>>>> The last line also came up all the time when the packages were updated
>>>>> 
>>>>> Doing a bit of research does not deliver much only that the compiler
>>>>> package was included into R at version 2.13.0
>>>>> (http://dirk.eddelbuettel.com/blog/2011/04/12/).
>>>>> 
>>>>> Most of those packages which do not work any more are pretty important
>>>>> for some of my scripts and I would not even know what packages replace
>>>>> the packages above.
>>>>> 
>>>>> Would anyone know how to fix this?
>>>>> 
>>>>> Regards
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
> 
> <email.txt>______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From katherine_gobin at yahoo.com  Tue Jun  4 11:15:41 2013
From: katherine_gobin at yahoo.com (Katherine Gobin)
Date: Tue, 4 Jun 2013 17:15:41 +0800 (SGT)
Subject: [R] Finding Beta
Message-ID: <1370337341.84416.YahooMailClassic@web193205.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130604/541cc12e/attachment.pl>

From michael.weylandt at gmail.com  Tue Jun  4 11:38:12 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Tue, 4 Jun 2013 10:38:12 +0100
Subject: [R] Finding Beta
In-Reply-To: <1370337341.84416.YahooMailClassic@web193205.mail.sg3.yahoo.com>
References: <1370337341.84416.YahooMailClassic@web193205.mail.sg3.yahoo.com>
Message-ID: <CAAmySGNdL867tFOr4ckjrd=QH7mrcD_o8bw9WJQOmOrzt3QvOg@mail.gmail.com>

Put your data in a real time series (xts) object and use the CAPM.*
functions from the PerformanceAnalytics package.

MW

On Tue, Jun 4, 2013 at 10:15 AM, Katherine Gobin
<katherine_gobin at yahoo.com> wrote:
> Dear R forum
>
> I have a dataframe (of prices) as given below -
>
> dat
>  = data.frame(company = rep(c("A", "B", "C", "D", "index"), each = 5),
> prices = c(runif(5, 10, 12), runif(5, 108, 112), runif(5, 500, 510),
> runif(5, 40, 50), runif(5, 1000, 1020)))
>
>    company     prices
> 1        A   10.61727
> 2        A   10.51892
> 3        A   11.80495
> 4        A   11.15243
> 5        A   10.77543
> 6        B  111.23817
> 7        B  109.19825
> 8        B
>  108.80053
> 9        B  110.79876
> 10       B  108.84385
> 11       C  504.71801
> 12       C  504.11778
> 13       C  502.89416
> 14       C  500.65996
> 15       C  502.26748
> 16       D   42.35901
> 17       D   43.71947
> 18       D   46.46092
> 19       D   43.62220
> 20       D   48.47480
> 21   index 1017.24476
> 22   index 1002.88139
> 23   index 1005.16148
> 24   index 1014.54480
> 25   index 1014.12103
>
> I need to find the beta
>  of A, B, C and D w.r.t index.
>
> Beta between two variables X and Y (where Y is dependent) is given by,
>
> beta = coef(lm(Y ~ X))[2]
>
> Any guidance is appreciated.
>
> With regards
>
> Katherine
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From christoph.knapp01 at gmail.com  Tue Jun  4 11:50:18 2013
From: christoph.knapp01 at gmail.com (Christoph Knapp)
Date: Tue, 04 Jun 2013 21:50:18 +1200
Subject: [R] 3.0.1 update and compiler package
In-Reply-To: <64939DB5-D1A8-469C-B753-DEE3877BD9FC@uni-bonn.de>
References: <51A80BDE.9090007@gmail.com> <51AC2750.3020503@ymail.com>
	<51AC47A4.7080603@statistik.tu-dortmund.de>
	<51AC5485.7040601@ymail.com> <51ADA831.9090102@gmail.com>
	<64939DB5-D1A8-469C-B753-DEE3877BD9FC@uni-bonn.de>
Message-ID: <51ADB85A.70005@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130604/f8970d32/attachment.pl>

From ripley at stats.ox.ac.uk  Tue Jun  4 12:40:05 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 04 Jun 2013 11:40:05 +0100
Subject: [R] 3.0.1 update and compiler package
In-Reply-To: <51ADB85A.70005@gmail.com>
References: <51A80BDE.9090007@gmail.com> <51AC2750.3020503@ymail.com>
	<51AC47A4.7080603@statistik.tu-dortmund.de>
	<51AC5485.7040601@ymail.com> <51ADA831.9090102@gmail.com>
	<64939DB5-D1A8-469C-B753-DEE3877BD9FC@uni-bonn.de>
	<51ADB85A.70005@gmail.com>
Message-ID: <51ADC405.5010902@stats.ox.ac.uk>

On 04/06/2013 10:50, Christoph Knapp wrote:
> Usually sudo apt-get install ... Sometimes synaptic package manager. I'm
> using the

So you really do need to discuss this on R-sig-debian, as those OSes 
have their own non-R package layout.

Do not expect the R manuals to cover the changes made by third-party 
re-distributors, nor advice by general R users nor R bloggers.

> /http://cran.ma.imperial.ac.uk/bin/linux/ubuntu/precise/
> http://cran.stat.ucla.edu/bin/linux/ubuntu/precise
>
> repositories. Not sure what the differences are. I had some problems
> before when I installed packages from within Rstudio. It would install
> them in a different directory than apt-get would and it would tell me
> that those packages were not installed when I used the terminal to start
> R. Drove me crazy for a while because I could use them in Rstudio so I
> was sure they were installed. Do you think this could also cause this?
>
> Christoph
>
> /
> On 04/06/13 21:13, Simon Zehnder wrote:
>> Hi Christoph,
>>
>> do you install from sources?
>>
>> Best
>>
>> Simon
>>
>> On Jun 4, 2013, at 10:41 AM, Christoph Knapp <christoph.knapp01 at gmail.com> wrote:
>>
>>> Hi,
>>> reinstalling R did not help. It still will not update the same packages. I attached the terminal output. There were no errors while I was installing R again. I might have to remove all libraries and reinstall them all. Would you agree or do you think I should try something else first which is not as extreme.
>>>
>>> Thanks for your help
>>>
>>> Christoph
>>>
>>> On 03/06/13 20:32, Pascal Oettli wrote:
>>>> My mistake,
>>>>
>>>> Regards,
>>>> Pascal
>>>>
>>>> On 06/03/2013 04:37 PM, Uwe Ligges wrote:
>>>>>
>>>>> On 03.06.2013 07:19, Pascal Oettli wrote:
>>>>>> Hi,
>>>>>>
>>>>>> How did you upgraded your version of R? From source or from a Linux
>>>>>> package?
>>>>> Actually the new R installation is just broken. It simply has to be
>>>>> reinstalled carefully (watch for errors).
>>>>>
>>>>> Best,
>>>>> Uwe Ligges
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>> Regards,
>>>>>> Pascal
>>>>>>
>>>>>>
>>>>>> On 05/31/2013 11:33 AM, Christoph Knapp wrote:
>>>>>>> Hi,
>>>>>>> I recently updated to R 3.0.1. I'm running linux ubuntu 12.04. I
>>>>>>> realized that I have to update all the installed packages so I run >
>>>>>>> update.packages(checkBuilt=TRUE)
>>>>>>> as described here
>>>>>>> http://www.r-bloggers.com/r-3-0-0-is-released-whats-new-and-how-to-upgrade/
>>>>>>>
>>>>>>>
>>>>>>> . The first thing it did was telling me that it will not update several
>>>>>>> packages. When it was finished I used the warnings function to have a
>>>>>>> look at what did not work. See the list below.
>>>>>>>
>>>>>>>> warnings()
>>>>>>> Warning messages:
>>>>>>> 1: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>>>> installation of package ?boot? had non-zero exit status
>>>>>>> 2: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>>>> installation of package ?cluster? had non-zero exit status
>>>>>>> 3: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>>>> installation of package ?foreign? had non-zero exit status
>>>>>>> 4: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>>>> installation of package ?KernSmooth? had non-zero exit status
>>>>>>> 5: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>>>> installation of package ?MASS? had non-zero exit status
>>>>>>> 6: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>>>> installation of package ?Matrix? had non-zero exit status
>>>>>>> 7: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>>>> installation of package ?nlme? had non-zero exit status
>>>>>>> 8: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>>>> installation of package ?nnet? had non-zero exit status
>>>>>>> 9: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>>>> installation of package ?rpart? had non-zero exit status
>>>>>>> 10: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>>>> installation of package ?spatial? had non-zero exit status
>>>>>>> 11: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>>>> installation of package ?survival? had non-zero exit status
>>>>>>> 12: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>>>> installation of package ?class? had non-zero exit status
>>>>>>> 13: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>>>> installation of package ?epiR? had non-zero exit status
>>>>>>> 14: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>>>> installation of package ?gmodels? had non-zero exit status
>>>>>>> 15: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>>>> installation of package ?gplots? had non-zero exit status
>>>>>>> 16: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>>>> installation of package ?mgcv? had non-zero exit status
>>>>>>> 17: In install.packages(update[instlib == l, "Package"], l, ... :
>>>>>>> installation of package ?gregmisc? had non-zero exit status
>>>>>>>
>>>>>>> I tried to reinstall them manually but this always failed because of a
>>>>>>> package dependency to the "compiler" package. Now, if I try to install
>>>>>>> the compiler package it tells me.
>>>>>>>
>>>>>>>> install.packages("compiler")
>>>>>>> Installing package into
>>>>>>> ?/home/christoph/R/x86_64-pc-linux-gnu-library/3.0?
>>>>>>> (as ?lib? is unspecified)
>>>>>>> Warning message:
>>>>>>> package ?compiler? is not available (for R version 3.0.1)
>>>>>>>
>>>>>>> The last line also came up all the time when the packages were updated
>>>>>>>
>>>>>>> Doing a bit of research does not deliver much only that the compiler
>>>>>>> package was included into R at version 2.13.0
>>>>>>> (http://dirk.eddelbuettel.com/blog/2011/04/12/).
>>>>>>>
>>>>>>> Most of those packages which do not work any more are pretty important
>>>>>>> for some of my scripts and I would not even know what packages replace
>>>>>>> the packages above.
>>>>>>>
>>>>>>> Would anyone know how to fix this?
>>>>>>>
>>>>>>> Regards
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>> <email.txt>______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ruipbarradas at sapo.pt  Tue Jun  4 13:21:00 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 04 Jun 2013 12:21:00 +0100
Subject: [R] Multiple selection and normalization
In-Reply-To: <CACYeG1iFURLDF25H=Pa2Y4i+Y1q1URFxO4FgTjd2Vu3BGuNygA@mail.gmail.com>
References: <CACYeG1iFURLDF25H=Pa2Y4i+Y1q1URFxO4FgTjd2Vu3BGuNygA@mail.gmail.com>
Message-ID: <51ADCD9C.9030300@sapo.pt>

Hello,

A data example would be great. Try the following.

set.seed(71926)  # make up some data
dat <- data.frame(SIDN = 1:100,
		TERM = factor(sample(4, 100, TRUE)),
		GRADE = runif(100),
		INST = factor(sample(5, 100, TRUE)))

head(dat)

with(dat, ave(GRADE, list(TERM, INST), FUN = scale))


Hope this helps,

Rui Barradas

Em 03-06-2013 21:23, Robert Lynch escreveu:
> Hi--
>
> I am trying to normalize course grades for each instance of a course, e.g.
> Stats 1 Fall2009 J. Smith.
>
> I have a frame for all instances of a course, e.g. stats 1 in the last 5
> years, that looks like
>
> SIDN  TERM  GRADE  INST
>
> where SIDN is a Student ID Number, TERM is a factor that gives the quarter
> and year a course was offered, GRADE is a 0-4.3 grade and INST is the
> instructor, again as a factor.
>
> Course offerings are determined by the TERM and INST.  That is one inst.
> assigned grades to all the students they were responsible for that term.
>   Multiple instructors may have taught the same term.
>
> For every course offering I would like to normalize the GRADE:  Z<- (GRADE
> - mean)/SD  where the mean and SD are over a single course offering.
>
> Thanks!
> RBL
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From szehnder at uni-bonn.de  Tue Jun  4 13:39:14 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Tue, 4 Jun 2013 13:39:14 +0200
Subject: [R] 3.0.1 update and compiler package
In-Reply-To: <51ADB85A.70005@gmail.com>
References: <51A80BDE.9090007@gmail.com> <51AC2750.3020503@ymail.com>
	<51AC47A4.7080603@statistik.tu-dortmund.de>
	<51AC5485.7040601@ymail.com> <51ADA831.9090102@gmail.com>
	<64939DB5-D1A8-469C-B753-DEE3877BD9FC@uni-bonn.de>
	<51ADB85A.70005@gmail.com>
Message-ID: <49973B36-CFB4-4549-AE9E-8750DE87945B@uni-bonn.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130604/3bde3442/attachment.pl>

From richard.asturia at gmail.com  Tue Jun  4 14:48:23 2013
From: richard.asturia at gmail.com (Richard Asturia)
Date: Tue, 4 Jun 2013 09:48:23 -0300
Subject: [R] delete active dataset
In-Reply-To: <E44FEEB1-6C30-44EE-8AEE-AEDCC8DB2CEF@comcast.net>
References: <E43D31A30B3.000004C3jrkrideau@inbox.com>
	<E44FEEB1-6C30-44EE-8AEE-AEDCC8DB2CEF@comcast.net>
Message-ID: <CA+xNL7r3crqSEtRp2i6oU=5d9JT6CPPJ-zavr0RUBanrH6wLOw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130604/42dba58e/attachment.pl>

From maitra.mbox.ignored at inbox.com  Tue Jun  4 15:12:09 2013
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Tue, 4 Jun 2013 08:12:09 -0500
Subject: [R] 3.0.1 update and compiler package
In-Reply-To: <51ADA831.9090102@gmail.com>
References: <51A80BDE.9090007@gmail.com> <51AC2750.3020503@ymail.com>
	<51AC47A4.7080603@statistik.tu-dortmund.de>
	<51AC5485.7040601@ymail.com> <51ADA831.9090102@gmail.com>
Message-ID: <20130604081209.0c48540ed1b77f2515cc5fea@inbox.com>

Hi,

Did you try:

update.packages(installed.packages()[,1])

or 

install.packages(installed.packages()[,1])

This will reinstall the packages you have on your system and for which
updates for 3.0.1 exist.

In my experience, as recounted here earlier, update.packages()
does not always work: it breaks because it fails to also recognize the
need to update some dependencies.

If reducing bandwidth is your concern, you can update the ones that
did not update manually, but note that this is a long drawn process
with one dependency leading to another in many cases.

All this is from my experience of updating R 2.15.2 to R 3.0.0 and
later R 3.0.1: of course YMMV.

HTH,
Ranjan


On Tue, 4 Jun 2013 20:41:21 +1200 Christoph Knapp
<christoph.knapp01 at gmail.com> wrote:

> Hi,
> reinstalling R did not help. It still will not update the same packages. 
> I attached the terminal output. There were no errors while I was 
> installing R again. I might have to remove all libraries and reinstall 
> them all. Would you agree or do you think I should try something else 
> first which is not as extreme.
> 
> Thanks for your help
> 
> Christoph
> 
> On 03/06/13 20:32, Pascal Oettli wrote:
> > My mistake,
> >
> > Regards,
> > Pascal
> >
> > On 06/03/2013 04:37 PM, Uwe Ligges wrote:
> >>
> >>
> >> On 03.06.2013 07:19, Pascal Oettli wrote:
> >>> Hi,
> >>>
> >>> How did you upgraded your version of R? From source or from a Linux
> >>> package?
> >>
> >> Actually the new R installation is just broken. It simply has to be
> >> reinstalled carefully (watch for errors).
> >>
> >> Best,
> >> Uwe Ligges
> >>
> >>
> >>
> >>
> >>
> >>
> >>>
> >>> Regards,
> >>> Pascal
> >>>
> >>>
> >>> On 05/31/2013 11:33 AM, Christoph Knapp wrote:
> >>>> Hi,
> >>>> I recently updated to R 3.0.1. I'm running linux ubuntu 12.04. I
> >>>> realized that I have to update all the installed packages so I run >
> >>>> update.packages(checkBuilt=TRUE)
> >>>> as described here
> >>>> http://www.r-bloggers.com/r-3-0-0-is-released-whats-new-and-how-to-upgrade/ 
> >>>>
> >>>>
> >>>>
> >>>> . The first thing it did was telling me that it will not update 
> >>>> several
> >>>> packages. When it was finished I used the warnings function to have a
> >>>> look at what did not work. See the list below.
> >>>>
> >>>>  > warnings()
> >>>> Warning messages:
> >>>> 1: In install.packages(update[instlib == l, "Package"], l, ... :
> >>>> installation of package ?boot? had non-zero exit status
> >>>> 2: In install.packages(update[instlib == l, "Package"], l, ... :
> >>>> installation of package ?cluster? had non-zero exit status
> >>>> 3: In install.packages(update[instlib == l, "Package"], l, ... :
> >>>> installation of package ?foreign? had non-zero exit status
> >>>> 4: In install.packages(update[instlib == l, "Package"], l, ... :
> >>>> installation of package ?KernSmooth? had non-zero exit status
> >>>> 5: In install.packages(update[instlib == l, "Package"], l, ... :
> >>>> installation of package ?MASS? had non-zero exit status
> >>>> 6: In install.packages(update[instlib == l, "Package"], l, ... :
> >>>> installation of package ?Matrix? had non-zero exit status
> >>>> 7: In install.packages(update[instlib == l, "Package"], l, ... :
> >>>> installation of package ?nlme? had non-zero exit status
> >>>> 8: In install.packages(update[instlib == l, "Package"], l, ... :
> >>>> installation of package ?nnet? had non-zero exit status
> >>>> 9: In install.packages(update[instlib == l, "Package"], l, ... :
> >>>> installation of package ?rpart? had non-zero exit status
> >>>> 10: In install.packages(update[instlib == l, "Package"], l, ... :
> >>>> installation of package ?spatial? had non-zero exit status
> >>>> 11: In install.packages(update[instlib == l, "Package"], l, ... :
> >>>> installation of package ?survival? had non-zero exit status
> >>>> 12: In install.packages(update[instlib == l, "Package"], l, ... :
> >>>> installation of package ?class? had non-zero exit status
> >>>> 13: In install.packages(update[instlib == l, "Package"], l, ... :
> >>>> installation of package ?epiR? had non-zero exit status
> >>>> 14: In install.packages(update[instlib == l, "Package"], l, ... :
> >>>> installation of package ?gmodels? had non-zero exit status
> >>>> 15: In install.packages(update[instlib == l, "Package"], l, ... :
> >>>> installation of package ?gplots? had non-zero exit status
> >>>> 16: In install.packages(update[instlib == l, "Package"], l, ... :
> >>>> installation of package ?mgcv? had non-zero exit status
> >>>> 17: In install.packages(update[instlib == l, "Package"], l, ... :
> >>>> installation of package ?gregmisc? had non-zero exit status
> >>>>
> >>>> I tried to reinstall them manually but this always failed because of a
> >>>> package dependency to the "compiler" package. Now, if I try to install
> >>>> the compiler package it tells me.
> >>>>
> >>>>  > install.packages("compiler")
> >>>> Installing package into
> >>>> ?/home/christoph/R/x86_64-pc-linux-gnu-library/3.0?
> >>>> (as ?lib? is unspecified)
> >>>> Warning message:
> >>>> package ?compiler? is not available (for R version 3.0.1)
> >>>>
> >>>> The last line also came up all the time when the packages were updated
> >>>>
> >>>> Doing a bit of research does not deliver much only that the compiler
> >>>> package was included into R at version 2.13.0
> >>>> (http://dirk.eddelbuettel.com/blog/2011/04/12/).
> >>>>
> >>>> Most of those packages which do not work any more are pretty important
> >>>> for some of my scripts and I would not even know what packages replace
> >>>> the packages above.
> >>>>
> >>>> Would anyone know how to fix this?
> >>>>
> >>>> Regards
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be
deleted on receipt. For those needing to send personal or professional
e-mail, please use appropriate addresses.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From jrkrideau at inbox.com  Tue Jun  4 15:33:05 2013
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 4 Jun 2013 05:33:05 -0800
Subject: [R] delete active dataset
In-Reply-To: <E44FEEB1-6C30-44EE-8AEE-AEDCC8DB2CEF@comcast.net>
References: <e43d31a30b3.000004c3jrkrideau@inbox.com>
Message-ID: <EFC1F876B35.000000A3jrkrideau@inbox.com>

Thanks David. I totally forgot that and I had that problem on Windows 3-4 years ago before moving to linux.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: dwinsemius at comcast.net
> Sent: Mon, 3 Jun 2013 17:18:24 -0700
> To: jrkrideau at inbox.com
> Subject: Re: [R] delete active dataset
> 
> This may not help if the OP is using  Mac or Windows since these hidden
> by default. Seek out OS info on how to show dot-files.
> 
> --
> David
> 
> Sent from my iPhone
> 
> On Jun 3, 2013, at 8:33 AM, John Kane <jrkrideau at inbox.com> wrote:
> 
>> It sounds like you inadvertently saved a workspace file.  Have a look in
>> your current directory and see if there is an .RDATA file there that you
>> don't recognize. If so, delete it.
>> 
>> John Kane
>> Kingston ON Canada
>> 
>> 
>>> -----Original Message-----
>>> From: yelin at lbl.gov
>>> Sent: Mon, 3 Jun 2013 08:25:59 -0700
>>> To: r-help at r-project.org
>>> Subject: [R] delete active dataset
>>> 
>>> Hi All, whenever I open R using the shortcut on desktop, there are 2
>>> active
>>> datasets in the workspace, I tried to start the program from Start
>>> menu,
>>> same thing!! How can I delete these two active datasets and make sure
>>> whenever I restart the program, they wont appear?
>>> 
>>> Thanks!
>>> 
>>>    [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ____________________________________________________________
>> GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at
>> http://www.inbox.com/smileys
>> Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk?
>> and most webmails
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From Bernhard_Pfaff at fra.invesco.com  Tue Jun  4 15:42:53 2013
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Tue, 4 Jun 2013 13:42:53 +0000
Subject: [R] The weak exogeneity test in R for the Error Correction
 Model?
In-Reply-To: <419EED2318C2164DB95FBB20AA8810D8A57D55@smtp_mail.bankofamerica.com>
Message-ID: <FCD9A33C859ACC469587CB09DD5C6C717D7E15@GBLONXMB11.corp.amvescap.net>

Hello Rebecca,

Set up your your model as a bivariate VECM (use ca.jo() and create a matrix of your x and y variables) and invoke alrtest() on the returned object as already mentioned by you. See the example section of alrtest for how accomplishing this.

Best,
Bernhard
Dr. Bernhard Pfaff
Director
Global Asset Allocation

Invesco Asset Management Deutschland GmbH
An der Welle 5
D-60322 Frankfurt am Main

Tel: +49 (0)69 29807 230
Fax: +49 (0)69 29807 178
www.institutional.invesco.com
Email: bernhard_pfaff at fra.invesco.com

Gesch?ftsf?hrer: Karl Georg Bayer, Bernhard Langer, Dr. Jens Langewand, Alexander Lehmann, Christian Puschmann
Handelsregister: Frankfurt am Main, HRB 28469
Sitz der Gesellschaft: Frankfurt am Main




----- Originalnachricht -----
Von: Yuan, Rebecca [mailto:rebecca.yuan at bankofamerica.com]
Gesendet: Tuesday, May 28, 2013 05:16 PM
An: R help <r-help at r-project.org>
Betreff: [R] The weak exogeneity test in R for the Error Correction Model?

Hello all,

I would like to carry out a single-equation approach of the Error Correction Model such as

Delta_y(t) = a + b*y(t-1) + c*x1(t-1) + d*x2(t-1) + e*delta_x1(t) + f*delta_x2(t) + epsilon(t)

Where, a, b, c, d, e, f are coefficients to be estimated, y is the dependent variable, and x1, x2 are independent variables.

For the single equation approach of ECM, there is a requirement of the weak exogeneity. How could I carry out the test to see if there is weak exogeneity in the above system?

I read the book "Bernhard-Analysis of Integrated and Cointegrated Time Series" where in section 8.1.3 it uses alrtest() for the weak exogeneity test. But that is for the vector ECM, where y is of five components, where in my example, y is a scalar, only one component. What would be the best way for me to test the weak exogeneity for the above approach ECM?

http://books.google.com/books?id=ca5MkRbF3fYC

Thanks very much!

Cheers,

Rebecca

----------------------------------------------------------------------
This message, and any attachments, is for the intended r...{{dropped:18}}


From therneau at mayo.edu  Tue Jun  4 15:51:54 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Tue, 04 Jun 2013 08:51:54 -0500
Subject: [R] Mixed effects model with a phylogenetic tree/ distance,
 matrix as a random effect
In-Reply-To: <mailman.25.1370340008.4302.r-help@r-project.org>
References: <mailman.25.1370340008.4302.r-help@r-project.org>
Message-ID: <51ADF0FA.9030402@mayo.edu>

Take a look at lmekin() in the coxme package.  The motivating data set for my development 
of coxme was the Minnesota Family Breast Cancer project: 24050 subjects in 462 families.  
The random effect is an intercept per subject with sigma^2 K as its variance where K is 
the kinship matrix (1 for self-self, .5 for parent-child or sib-sib, .25 for uncle-neice, 
etc).  lmekin is a linear models front end to the same underlying routines.

    I think you want lmekin(y ~ x1 + x2 + (1| subject), data=yourdata, varlist= D)
or some such, where D is the similarity or "correlation" form of you distance matrix.

    A downside is that lmekin is sort of the poor cousin to comxe -- with finite time I've 
never gotton around to writing predict, residuals, plot, ... methods for it.  The basic 
fit is fine though.

Terry Therneau

(In general I agree with Bert & Ben to try the other list, but I don't happen to read it.)

On 06/04/2013 05:00 AM, r-help-request at r-project.org wrote:
> Hi,
> I'm trying to build a mixed-effects model in which I'd like to include
> either a distance matrix or a phylogenetic tree as a random effect.
> The troubles I've had are that:
> 1. Function lmer() in package lme4 only accepts a data frame column as a
> random factor and not a distance matrix.
> 2. Function MCMCglmm() in package MCMCglmm only accepts a rooted and
> ultrametric phylogenetic tree as a pedigree argument while my tree is
> neither (and for various reasons I cannot construct one or coerce mine
> to be a rooted, ultrametric tree).
>
> Is there any way around it?
> I'd appreciate mostly a solution to problem 1.
>
> Roey


From dcarlson at tamu.edu  Tue Jun  4 16:26:24 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Tue, 4 Jun 2013 09:26:24 -0500
Subject: [R] error about MCA
In-Reply-To: <10b8e421.15187.13f0ce491cd.Coremail.laomeng_3@163.com>
References: <437ecacf.7226.13f00437ae1.Coremail.laomeng_3@163.com>
	<011501ce6061$efba47e0$cf2ed7a0$@tamu.edu>
	<10b8e421.15187.13f0ce491cd.Coremail.laomeng_3@163.com>
Message-ID: <024c01ce612f$7de65f90$79b31eb0$@tamu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130604/b95ea9e7/attachment.pl>

From jspark4 at uic.edu  Tue Jun  4 16:33:25 2013
From: jspark4 at uic.edu (Sparks, John James)
Date: Tue, 4 Jun 2013 09:33:25 -0500
Subject: [R] Refer to Data Frame Name Inside a List
Message-ID: <20eddd63cdc733bfb65205d5930867da.squirrel@webmail.uic.edu>

Dear R Helpers,

I have a fairly complicated list of data frames.  To give you an idea of
the structure, the top of the str output is shown below.

How do I refer to the data.frame name for each data.frame in the list? 
That is, how can I pull the terms Advertising2007, AirFreightDelivery2007,
Apparel2007 etc. out of the list?  I need them to keep track of
correlations that I am doing inside each data frame of the list.

Apologies for not sending a reproducible example.  I am hoping that
someone knows this off the top of their head.

--John Sparks

> str(ResList)
List of 60
 $ Advertising2007         :'data.frame':       21 obs. of  10 variables:
  ..$ RFPred       : num [1:21] -0.01749 -0.00801 -0.01155 -0.01494
-0.03715 ...
  ..$ marsPred     : num [1:21] 0.0901 0.0127 0.0616 0.0618 -0.0559 ...
  ..$ GainRepAft3  : num [1:21] -0.0673 -0.0183 -0.2353 0.0294 -0.059 ...
  ..$ Industry     : chr [1:21] "Advertising2007" "Advertising2007"
"Advertising2007" "Advertising2007" ...
  ..$ dateavail    : Factor w/ 346 levels "2008-02-01","2008-02-13",..: 18
4 14 12 13 19 1 15 17 8 ...
  ..$ FinYearEnd   : Factor w/ 12 levels "2007-12-01","2007-03-01",..: 1 1
1 1 1 1 1 1 1 1 ...
  ..$ GainAft1Aft30: num [1:21] -0.2376 -0.1384 -0.1176 0.0145 0.0527 ...
  ..$ GainAft1Aft60: num [1:21] -0.36212 -0.17801 -0.23529 -0.00501
-0.27414 ...
  ..$ GainAft1Aft90: num [1:21] -0.516 -0.203 -0.176 0.024 -0.241 ...
  ..$ groups       : Factor w/ 40 levels "-0.04013239",..: 4 11 8 6 1 1 10
13 2 5 ...
 $ AirFreightDelivery2007  :'data.frame':       20 obs. of  10 variables:
  ..$ RFPred       : num [1:20] 0.00322 -0.00351 0.034 0.01095 0.02237 ...
  ..$ marsPred     : num [1:20] -0.013 -0.109 0.0662 0.0353 0.0662 ...
  ..$ GainRepAft3  : num [1:20] 0.0344 -0.0659 0.054 0.045 0.0266 ...
  ..$ Industry     : chr [1:20] "AirFreightDelivery2007"
"AirFreightDelivery2007" "AirFreightDelivery2007"
"AirFreightDelivery2007" ...
  ..$ dateavail    : Factor w/ 346 levels "2008-02-01","2008-02-13",..: 22
10 26 33 35 32 25 23 31 10 ...
  ..$ FinYearEnd   : Factor w/ 12 levels "2007-12-01","2007-03-01",..: 2 1
1 1 1 1 1 3 1 1 ...
  ..$ GainAft1Aft30: num [1:20] -0.0656 -0.1539 -0.1002 -0.0694 -0.4101 ...
  ..$ GainAft1Aft60: num [1:20] -0.133 -0.141 -0.242 -0.691 -0.212 ...
  ..$ GainAft1Aft90: num [1:20] -0.0523 -0.0673 -0.1793 -0.6875 -0.187 ...
  ..$ groups       : Factor w/ 40 levels "-0.04013239",..: 24 16 39 32 37
21 17 30 35 37 ...
 $ Apparel2007             :'data.frame':       28 obs. of  10 variables:
  ..$ RFPred       : num [1:28] 0.011439 0.021311 0.014564 0.018168
-0.000892 ...
  ..$ marsPred     : num [1:28] -0.001463 0.0345 0.027227 -0.000129
-0.006483 ...


From jorgeivanvelez at gmail.com  Tue Jun  4 16:37:48 2013
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Wed, 5 Jun 2013 00:37:48 +1000
Subject: [R] Refer to Data Frame Name Inside a List
In-Reply-To: <20eddd63cdc733bfb65205d5930867da.squirrel@webmail.uic.edu>
References: <20eddd63cdc733bfb65205d5930867da.squirrel@webmail.uic.edu>
Message-ID: <-9002825958105953022@unknownmsgid>

Try

names(ResList)

HTH,
Jorge.-

Sent from my phone. Please excuse my brevity and misspelling.

On Jun 5, 2013, at 12:34 AM, "Sparks, John James" <jspark4 at uic.edu> wrote:

> Dear R Helpers,
>
> I have a fairly complicated list of data frames.  To give you an idea of
> the structure, the top of the str output is shown below.
>
> How do I refer to the data.frame name for each data.frame in the list?
> That is, how can I pull the terms Advertising2007, AirFreightDelivery2007,
> Apparel2007 etc. out of the list?  I need them to keep track of
> correlations that I am doing inside each data frame of the list.
>
> Apologies for not sending a reproducible example.  I am hoping that
> someone knows this off the top of their head.
>
> --John Sparks
>
>> str(ResList)
> List of 60
> $ Advertising2007         :'data.frame':       21 obs. of  10 variables:
>  ..$ RFPred       : num [1:21] -0.01749 -0.00801 -0.01155 -0.01494
> -0.03715 ...
>  ..$ marsPred     : num [1:21] 0.0901 0.0127 0.0616 0.0618 -0.0559 ...
>  ..$ GainRepAft3  : num [1:21] -0.0673 -0.0183 -0.2353 0.0294 -0.059 ...
>  ..$ Industry     : chr [1:21] "Advertising2007" "Advertising2007"
> "Advertising2007" "Advertising2007" ...
>  ..$ dateavail    : Factor w/ 346 levels "2008-02-01","2008-02-13",..: 18
> 4 14 12 13 19 1 15 17 8 ...
>  ..$ FinYearEnd   : Factor w/ 12 levels "2007-12-01","2007-03-01",..: 1 1
> 1 1 1 1 1 1 1 1 ...
>  ..$ GainAft1Aft30: num [1:21] -0.2376 -0.1384 -0.1176 0.0145 0.0527 ...
>  ..$ GainAft1Aft60: num [1:21] -0.36212 -0.17801 -0.23529 -0.00501
> -0.27414 ...
>  ..$ GainAft1Aft90: num [1:21] -0.516 -0.203 -0.176 0.024 -0.241 ...
>  ..$ groups       : Factor w/ 40 levels "-0.04013239",..: 4 11 8 6 1 1 10
> 13 2 5 ...
> $ AirFreightDelivery2007  :'data.frame':       20 obs. of  10 variables:
>  ..$ RFPred       : num [1:20] 0.00322 -0.00351 0.034 0.01095 0.02237 ...
>  ..$ marsPred     : num [1:20] -0.013 -0.109 0.0662 0.0353 0.0662 ...
>  ..$ GainRepAft3  : num [1:20] 0.0344 -0.0659 0.054 0.045 0.0266 ...
>  ..$ Industry     : chr [1:20] "AirFreightDelivery2007"
> "AirFreightDelivery2007" "AirFreightDelivery2007"
> "AirFreightDelivery2007" ...
>  ..$ dateavail    : Factor w/ 346 levels "2008-02-01","2008-02-13",..: 22
> 10 26 33 35 32 25 23 31 10 ...
>  ..$ FinYearEnd   : Factor w/ 12 levels "2007-12-01","2007-03-01",..: 2 1
> 1 1 1 1 1 3 1 1 ...
>  ..$ GainAft1Aft30: num [1:20] -0.0656 -0.1539 -0.1002 -0.0694 -0.4101 ...
>  ..$ GainAft1Aft60: num [1:20] -0.133 -0.141 -0.242 -0.691 -0.212 ...
>  ..$ GainAft1Aft90: num [1:20] -0.0523 -0.0673 -0.1793 -0.6875 -0.187 ...
>  ..$ groups       : Factor w/ 40 levels "-0.04013239",..: 24 16 39 32 37
> 21 17 30 35 37 ...
> $ Apparel2007             :'data.frame':       28 obs. of  10 variables:
>  ..$ RFPred       : num [1:28] 0.011439 0.021311 0.014564 0.018168
> -0.000892 ...
>  ..$ marsPred     : num [1:28] -0.001463 0.0345 0.027227 -0.000129
> -0.006483 ...
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Tue Jun  4 17:02:19 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 4 Jun 2013 11:02:19 -0400
Subject: [R] Refer to Data Frame Name Inside a List
In-Reply-To: <20eddd63cdc733bfb65205d5930867da.squirrel@webmail.uic.edu>
References: <20eddd63cdc733bfb65205d5930867da.squirrel@webmail.uic.edu>
Message-ID: <CAM_vjukkse23QFektbufBTNkpr8Oni1u9j=PeqrdzkT4ppExTQ@mail.gmail.com>

On Tue, Jun 4, 2013 at 10:33 AM, Sparks, John James <jspark4 at uic.edu> wrote:
> Dear R Helpers,
>
> I have a fairly complicated list of data frames.  To give you an idea of
> the structure, the top of the str output is shown below.
>
> How do I refer to the data.frame name for each data.frame in the list?
> That is, how can I pull the terms Advertising2007, AirFreightDelivery2007,
> Apparel2007 etc. out of the list?  I need them to keep track of
> correlations that I am doing inside each data frame of the list.

The same way you'd access any named list component:
resList[["Advertising2007"]]

Sarah

-- 
Sarah Goslee
http://www.functionaldiversity.org


From dwinsemius at comcast.net  Tue Jun  4 17:10:03 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 4 Jun 2013 08:10:03 -0700
Subject: [R] Read 2 rows in 1 dataframe for diff - longitudinal data
In-Reply-To: <1370321471.5229.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1370311825.22574.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<A5470E89-5497-426F-B7E0-5D308419630E@comcast.net>
	<1370321471.5229.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <5FFE290B-4819-41D5-91E5-EA72952C57EA@comcast.net>


On Jun 3, 2013, at 9:51 PM, arun wrote:

> If it is grouped by "subid" (that would be the difference in the number of changes)
> 
> subset(ddply(df1,.(subid),mutate,delta=c(FALSE,var[-1]!=var[-length(var)])),delta)[,-4]
> #   subid year var
> #3     36 2003   3
> #7     47 2001   3
> #9     47 2005   1
> #10    47 2007   3
> A.K.
> 

Ah. I see. Then this looks simpler to my eyes:

df1[ ave( df1$var, df1$subid, FUN=function(x) c( FALSE, x[-1] != x[-length(x)]) ) , ]

-- 
David.


> 
> ----- Original Message -----
> From: David Winsemius <dwinsemius at comcast.net>
> To: arun <smartpink111 at yahoo.com>
> Cc: R help <r-help at r-project.org>
> Sent: Tuesday, June 4, 2013 12:37 AM
> Subject: Re: [R] Read 2 rows in 1 dataframe for diff - longitudinal data
> 
> 
> On Jun 3, 2013, at 7:10 PM, arun wrote:
> 
>> Hi,
>> May be this helps:
>> res1<-df1[with(df1,unlist(tapply(var,list(subid),FUN=function(x) c(FALSE,diff(x)!=0)),use.names=FALSE)),]
>>   res1
>> #   subid year var
>> #3     36 2003   3
>> #7     47 2001   3
>> #9     47 2005   1
>> #10    47 2007   3
>> #or
>> library(plyr)
>>   subset(ddply(df1,.(subid),mutate,delta=c(FALSE,diff(var)!=0)),delta)[,-4]
>> #   subid year var
>> #3     36 2003   3
>> #7     47 2001   3
>> #9     47 2005   1
>> #10    47 2007   3
>> A.K.
>> 
> It's pretty simple with logical indexing:
> 
>> df1[ c(FALSE, df1$var[-1]!=df1$var[-length(df1$var)]), ]
>    subid year var
> 3     36 2003   3
> 6     47 1999   1
> 7     47 2001   3
> 9     47 2005   1
> 10    47 2007   3
> 
> 
> When I count the number of changes in value of var is give me 5. Not sure why you are both leaving out row 6.
> 
> -- 
> David.
>> 
>> 
>> I need to output a dataframe whenever var changes a value. 
>> 
>> df1 <- data.frame(subid=rep(c(36,47),each=5),year=rep(seq(1999,2007,2),2),var=c(1,1,3,3,3,1,3,3,1,3)) 
>>     subid year var 
>> 1     36 1999   1 
>> 2     36 2001   1 
>> 3     36 2003   3 
>> 4     36 2005   3 
>> 5     36 2007   3 
>> 6     47 1999   1 
>> 7     47 2001   3 
>> 8     47 2003   3 
>> 9     47 2005   1 
>> 10    47 2007   3 
>>> 
>> 
>> I need: 
>> 36 2003   3 
>> 47 2001   3 
>> 47 2005   1 
>> 47 2007   3 
>> 
>> I am trying to use ddply over subid and use the diff function, but it is not working quiet right. 
>> 
>>> dd <- ddply(df1,.(subid),summarize,delta=diff(var) != 0) 
>>> dd 
>>    subid delta 
>> 1    36 FALSE 
>> 2    36  TRUE 
>> 3    36 FALSE 
>> 4    36 FALSE 
>> 5    47  TRUE 
>> 6    47 FALSE 
>> 7    47  TRUE 
>> 8    47  TRUE 
>> 
>> I would appreciate any help on this. 
>> Thank You! 
>> -ST
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Tue Jun  4 17:13:57 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 4 Jun 2013 08:13:57 -0700
Subject: [R] Read 2 rows in 1 dataframe for diff - longitudinal data
In-Reply-To: <1370321471.5229.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1370311825.22574.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<A5470E89-5497-426F-B7E0-5D308419630E@comcast.net>
	<1370321471.5229.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <851EB2B7-699F-441A-98D1-BFA7D5552060@comcast.net>


On Jun 3, 2013, at 9:51 PM, arun wrote:

> If it is grouped by "subid" (that would be the difference in the number of changes)
> 
> subset(ddply(df1,.(subid),mutate,delta=c(FALSE,var[-1]!=var[-length(var)])),delta)[,-4]
> #   subid year var
> #3     36 2003   3
> #7     47 2001   3
> #9     47 2005   1
> #10    47 2007   3
> A.K.

I'm not sure why the first one retruns integer values from the ave() call but the second version works:

> df1[ ave( df1$var, df1$subid, FUN=function(x) c( FALSE, x[-1] != x[-length(x)]) ), ]
    subid year var
1      36 1999   1
1.1    36 1999   1
1.2    36 1999   1
1.3    36 1999   1

ave( df1$var, df1$subid, FUN=function(x) c( FALSE, x[-1] != x[-length(x)]))
 [1] 0 0 1 0 0 0 1 0 1 1

Perhaps one of the single item groups sabotaged my simple function.


> df1[ as.logical( ave( df1$var, df1$subid, FUN=function(x) c( FALSE, x[-1] != x[-length(x)]) ) ), ]
   subid year var
3     36 2003   3
7     47 2001   3
9     47 2005   1
10    47 2007   3

-- 
David.
> 
> 
> ----- Original Message -----
> From: David Winsemius <dwinsemius at comcast.net>
> To: arun <smartpink111 at yahoo.com>
> Cc: R help <r-help at r-project.org>
> Sent: Tuesday, June 4, 2013 12:37 AM
> Subject: Re: [R] Read 2 rows in 1 dataframe for diff - longitudinal data
> 
> 
> On Jun 3, 2013, at 7:10 PM, arun wrote:
> 
>> Hi,
>> May be this helps:
>> res1<-df1[with(df1,unlist(tapply(var,list(subid),FUN=function(x) c(FALSE,diff(x)!=0)),use.names=FALSE)),]
>>   res1
>> #   subid year var
>> #3     36 2003   3
>> #7     47 2001   3
>> #9     47 2005   1
>> #10    47 2007   3
>> #or
>> library(plyr)
>>   subset(ddply(df1,.(subid),mutate,delta=c(FALSE,diff(var)!=0)),delta)[,-4]
>> #   subid year var
>> #3     36 2003   3
>> #7     47 2001   3
>> #9     47 2005   1
>> #10    47 2007   3
>> A.K.
>> 
> It's pretty simple with logical indexing:
> 
>> df1[ c(FALSE, df1$var[-1]!=df1$var[-length(df1$var)]), ]
>    subid year var
> 3     36 2003   3
> 6     47 1999   1
> 7     47 2001   3
> 9     47 2005   1
> 10    47 2007   3
> 
> 
> When I count the number of changes in value of var is give me 5. Not sure why you are both leaving out row 6.
> 
> -- 
> David.
>> 
>> 
>> I need to output a dataframe whenever var changes a value. 
>> 
>> df1 <- data.frame(subid=rep(c(36,47),each=5),year=rep(seq(1999,2007,2),2),var=c(1,1,3,3,3,1,3,3,1,3)) 
>>     subid year var 
>> 1     36 1999   1 
>> 2     36 2001   1 
>> 3     36 2003   3 
>> 4     36 2005   3 
>> 5     36 2007   3 
>> 6     47 1999   1 
>> 7     47 2001   3 
>> 8     47 2003   3 
>> 9     47 2005   1 
>> 10    47 2007   3 
>>> 
>> 
>> I need: 
>> 36 2003   3 
>> 47 2001   3 
>> 47 2005   1 
>> 47 2007   3 
>> 
>> I am trying to use ddply over subid and use the diff function, but it is not working quiet right. 
>> 
>>> dd <- ddply(df1,.(subid),summarize,delta=diff(var) != 0) 
>>> dd 
>>    subid delta 
>> 1    36 FALSE 
>> 2    36  TRUE 
>> 3    36 FALSE 
>> 4    36 FALSE 
>> 5    47  TRUE 
>> 6    47 FALSE 
>> 7    47  TRUE 
>> 8    47  TRUE 
>> 
>> I would appreciate any help on this. 
>> Thank You! 
>> -ST
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 

David Winsemius
Alameda, CA, USA


From smartpink111 at yahoo.com  Tue Jun  4 17:37:32 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 4 Jun 2013 08:37:32 -0700 (PDT)
Subject: [R] choose the lines2
In-Reply-To: <CAMiZAipnz9UXhUimh+ejGJTiyb8nGaTH4zPtBsiFAPoaGR61hw@mail.gmail.com>
References: <CAMiZAipnz9UXhUimh+ejGJTiyb8nGaTH4zPtBsiFAPoaGR61hw@mail.gmail.com>
Message-ID: <1370360252.30823.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
May be this helps:
dat1<- read.csv("dat7.csv",header=TRUE,stringsAsFactors=FALSE,sep="\t")
dat.bru<- dat1[!is.na(dat1$evnmt_brutal),]

fun2<- function(dat){?? 
????? lst1<- split(dat,dat$patient_id)
??? lst2<- lapply(lst1,function(x) x[cumsum(x$evnmt_brutal==0)>0,])
??? lst3<- lapply(lst2,function(x) x[!(all(x$evnmt_brutal==1)|all(x$evnmt_brutal==0)),])
??? lst4<- lst3[lapply(lst3,nrow)!=0]
??? lst5<- lapply(seq_along(lst4),function(i){
??? ??? ??? ??? ???? do.call(rbind,lapply(which(lst4[[i]]$evnmt_brutal==1),function(x) {
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? x1<-c(x-2,x-1,x)
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? x2<-x1[!any(x1==0)]
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? x3<-lst4[[i]][x2,]
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? x4<-x3[!is.na(match(paste(x3$evnmt_brutal,collapse=""),"001")),]
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? x4[!any(duplicated(x4$number))]
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? }
??? ??? ??? ??? ??? ??? ??? ??? ??? ??? ))
??? ??? ??? ??? ??? ??? ??? ??? ??? })
?? lst6<-lst5[lapply(lst5,nrow)!=0]
?? names(lst6)<- unlist(lapply(lst6,function(x) unique(x$patient_id)))
?? Mean0bet_01<- do.call(rbind,lapply(lst6,function(x) mean(x[seq(nrow(x))%%3==2,"basdai_d"])))
?? lst7<-list(lst6,Mean0bet_01)
?? lst7
?? #lapply(lst7,head,2)??? 
?? }?? ??? ??? ??? ??? 

fun2(dat.bru)

##output from first 2 patients


#[[1]]
#[[1]]$`2`
?# ? X patient_id number responsed_at? t basdai_d evnmt_brutal
#13 13????????? 2???? 12?? 2011-07-05 12???? -1.0??????????? 0
#14 14????????? 2???? 13?? 2011-08-07 13????? 0.9??????????? 0
#15 15????????? 2???? 14?? 2011-09-11 14???? -0.8??????????? 1
#
#[[1]]$`5`
#??? X patient_id number responsed_at t basdai_d evnmt_brutal
#52 52????????? 5????? 8?? 2011-01-11 7???? -2.8??????????? 0
#53 53????????? 5????? 9?? 2011-02-13 8????? 0.0??????????? 0
#54 54????????? 5???? 10?? 2011-03-19 9???? -1.2??????????? 1
#

#[[2]]
?# [,1]
#2? 0.9
#5? 0.0

A.K.





________________________________
From: GUANGUAN LUO <guanguanluo at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Tuesday, June 4, 2013 3:54 AM
Subject: choose the lines2



Hello, Arun,?
now it is nearly the same problem.
I want to know if I want to choose three period : one line with evnmt_brutal ==0 , one line with evnmt_brutal==0 and one line with evnmt_brutal==1, then I want to choose the second and third period for each patient, so that i can calculate the average of scores of basdai when evnmt_brutal==0 (in condition that the precedent line with evnmt_brutal==0) and evnmt_brutal==1.
In writing with the phrase "if", if i have two conditions, i don't know how can i write that.

This is when i want to choose the period with evnmt_brutal ==0 et evnmt_brutal==1 for each patient, you have written this code. If i want to add one condition that before the line evnmt_brutal==0, evnmt_brutal of that line equal to 0 too.?
The result i want to get is just the two last lines.

Do you know how can i realize that?

dat1<- read.csv("dat7.csv",header=TRUE,stringsAsFactors=FALSE,sep="\t")
dat.bru<- dat1[!is.na(dat1$evnmt_brutal),]

fun1<- function(dat){???
? ??? lst1<- split(dat,dat$patient_id)
??? lst2<- lapply(lst1,function(x) x[cumsum(x$evnmt_brutal==0)>0,])
??? lst3<- lapply(lst2,function(x) x[!(all(x$evnmt_brutal==1)|all(x$evnmt_brutal==0)),])
??? lst4<-lapply(lst3,function(x) {vect.brutal=c()
??? ??? ??? ??? for(line in which(x$evnmt_brutal==1)){
??? ??? ??? ??? ?? if(x$evnmt_brutal[line-1]==0){
??? ??? ??? ??? ? vect.brutal=c(vect.brutal,line)
??? ??? ??? ??? ??? }
??? ??? ??? ??? ??? ?? }
??? ??? ??? ????? vect.brutal1<- sort(c(vect.brutal,vect.brutal-1))
??? ??? ??? ???? x[vect.brutal1,]
??? ??? ??? ??? ??? ?? }
??? ??? ??? ??? ??? ?? )
??? res<- do.call(rbind,lst4)
??? row.names(res)<- 1:nrow(res)
??? res
??? }


fun1(dat.bru)head(fun1(dat.bru),10)
#??? X patient_id number responsed_at? t basdai_d evnmt_brutal
#1? 14????????? 2???? 13?? 2011-08-07 13??? 0.900??????????? 0
#2? 15????????? 2???? 14?? 2011-09-11 14?? -0.800??????????? 1
#3? 22????????? 3????? 2?? 2010-06-29? 1?? -0.800??????????? 0
#4? 23????????? 3????? 3?? 2010-08-05? 2??? 0.000??????????? 1
#5? 24????????? 3????? 4?? 2010-09-05? 3??? 1.200??????????? 0
#6? 25????????? 3????? 5?? 2010-10-13? 4??? 1.925??????????? 1
#7? 26????????? 3????? 6?? 2010-11-15? 5?? -2.525??????????? 0
#8? 27????????? 3????? 7?? 2010-12-18? 6?? -0.200??????????? 1
#9? 53????????? 5????? 9?? 2011-02-13? 8??? 0.000??????????? 0
#10 54????????? 5???? 10?? 2011-03-19? 9?? -1.200??????????? 1


From carlybobak at hotmail.com  Tue Jun  4 17:47:32 2013
From: carlybobak at hotmail.com (Carly Bobak)
Date: Tue, 4 Jun 2013 12:47:32 -0300
Subject: [R] Zero-Inflated Negative Binomial Regression
Message-ID: <BAY174-W4B2C4C2713E51EA040128CF9E0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130604/4bd518b1/attachment.pl>

From dcarlson at tamu.edu  Tue Jun  4 16:47:10 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Tue, 4 Jun 2013 09:47:10 -0500
Subject: [R] Y-lim minimum overrun in barplot
In-Reply-To: <CAHskT4r-gbAgL1FTgAP4_46EoYZ-TejmePKyYshaEmO4vk-UFg@mail.gmail.com>
References: <CAHskT4rx2gBADoyoh8Z=kL=Aveo8EVYaA5mOrb56A8J2+MXEJQ@mail.gmail.com>
	<011701ce606a$66205d40$326117c0$@tamu.edu>
	<CAHskT4r-gbAgL1FTgAP4_46EoYZ-TejmePKyYshaEmO4vk-UFg@mail.gmail.com>
Message-ID: <02e201ce6132$64bfbef0$2e3f3cd0$@tamu.edu>

The barp() function in plotrix seems to handle base substraction:

> library(plotrix)
> barp(c(2, 3), ylim=c(1, 3.25))

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352


From: Nicole Prause [mailto:nprause at mednet.ucla.edu] 
Sent: Monday, June 3, 2013 12:31 PM
To: dcarlson at tamu.edu
Cc: r-help at r-project.org
Subject: Re: [R] Y-lim minimum overrun in barplot

Thank you for the three (!) solutions suggested. I found that the
base subtraction trick worked well, but I investigated all three:
offset, I found, referred to moving bars on the x-axis. Great for
line plot jitter when they're overlapping, but not the problem I was
trying to solve here. Sorry if it was my lack of clarity.
ggplot...I have used that package, but could not find a ggplot or
ggplot2 command in the CRAN reference manual. I tweaked a bit and
will benefit from some of the specifications you happen to make in
there that will pretty-fy the chart, but the other solution was just
too easy in comparison.
Another option I had not thought of was to make one of these broken
y charts (e.g., http://community.qlikview.com/ideas/1912) that
better discloses the true range while still magnifying the
otherwise-difficult-to-see effect. Not that I figured out that one
either, mind you, but it occurred to me later!
Thanks all for the many ideas. I'll include a data matrix if there
is a next round as well.
Best,
Nikky

On Mon, Jun 3, 2013 at 7:55 AM, David Carlson <dcarlson at tamu.edu>
wrote:
I believe you are looking for the offset= parameter. Consider the
following:

barplot(c(2, 3), ylim=c(1, 3))
barplot(c(2, 3), ylim=c(1, 3), offset=1)

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Nicole Prause
Sent: Friday, May 31, 2013 11:31 AM
To: r-help at r-project.org
Subject: [R] Y-lim minimum overrun in barplot
The code below produces the plot hosted here:
http://www.span-lab.com/ChartStop.jpeg

? ? error.bar <- function(x, y, upper, lower=upper, length=0.1,...){
? ? if(length(x) != length(y) | length(y) !=length(lower) |
length(lower) != length(upper))
? ? stop("vectors must be same length")
? ? arrows(x,y+upper, x, y-lower, angle=90, code=3, length=length,
...)
? ? }

Means<-tapply(data$IntercourseIntention,data$FilmAndOrder,mean)
SDs<-tapply(data$IntercourseIntention,data$FilmAndOrder,sd)
b<-barplot(Means,col=c("gray","tan1","blue","white"),axis.lty=1,ylim
=c(2,3),names.arg=c("","","",""),ylab="Intercourse
intention",xlab="Film and condition")
legend("topleft",c("Pre drink, Neutral","Post drink,
Neutral","Pre-drink, Sexual", "Post-drink,
Sexual"),col=c("gray","tan1","blue","white"),pch=15)
error.bar(b,Means, 1.96*SDs/10)

(I know it's not pretty yet. To be fixed after the initial display
is reasonable!) The y average value minimum truly is 1.2, but even
ylim=c(1,X) produces this behavior of the bars running over the
x-axis. I should be able to specify the starting value regardless of
the range. Does anyone see the code bit I'm missing here?

Much appreciated!

Nikky

****************************
Nicole Prause, PhD
Research faculty
Department of Psychiatry
760 Westwood Blvd
University of California
Los Angeles, CA 90024
nprause at mednet.ucla.edu<mailto:nprause at mednet.ucla.edu>
www.span-lab.com<http://www.span-lab.com>

________________________________

IMPORTANT WARNING: This email (and any attachments) is
o...{{dropped:12}}

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



-- 
****************************
Nicole Prause, PhD
Research faculty
Department of Psychiatry
760 Westwood Blvd
University of California
Los Angeles, CA 90024
nprause at mednet.ucla.edu
www.span-lab.com 

________________________________________

IMPORTANT WARNING: This email (and any attachments) is only intended
for the use of the person or entity to which it is addressed, and
may contain information that is privileged and confidential. You,
the recipient, are obligated to maintain it in a safe, secure and
confidential manner. Unauthorized redisclosure or failure to
maintain confidentiality may subject you to federal and state
penalties. If you are not the intended recipient, please immediately
notify us by return email, and delete this message from your
computer.


From Stephen.Bond at cibc.com  Tue Jun  4 18:35:23 2013
From: Stephen.Bond at cibc.com (Bond, Stephen)
Date: Tue, 4 Jun 2013 12:35:23 -0400
Subject: [R] odfWeave on WinXP
Message-ID: <3D9EA53CDE9BBF40ADB2096F4784910F22805E2890@CBMCC-X7-MBX02.ad.cibc.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130604/1633b7ed/attachment.pl>

From k.zhong at erasmusmc.nl  Tue Jun  4 18:37:53 2013
From: k.zhong at erasmusmc.nl (Kaiyin Zhong (Victor Chung))
Date: Tue, 4 Jun 2013 18:37:53 +0200
Subject: [R] hclust segfault when using rpuDist
Message-ID: <CAOHtMfVQhtbTLoKWmY64agiotge-9-z6eJE=Axk2CT7wjOugZw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130604/04e7b40c/attachment.pl>

From Achim.Zeileis at uibk.ac.at  Tue Jun  4 18:40:22 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Tue, 4 Jun 2013 18:40:22 +0200 (CEST)
Subject: [R] Zero-Inflated Negative Binomial Regression
In-Reply-To: <BAY174-W4B2C4C2713E51EA040128CF9E0@phx.gbl>
References: <BAY174-W4B2C4C2713E51EA040128CF9E0@phx.gbl>
Message-ID: <alpine.DEB.2.02.1306041833080.19236@paninaro.uibk.ac.at>

On Tue, 4 Jun 2013, Carly Bobak wrote:

> Hi!
>
> I'm running a zero-inflated negative binomial regression on a large (n=54822) set of confidential data. I'm using the code:
> ZerNegBinRegress<-zeroinfl(Paper~.|., data=OvsP, dist="negbin", EM=TRUE)
>
> And keep getting the error:
>
> Warning message:
> glm.fit: fitted probabilities numerically 0 or 1 occurred
>
> I've done enough reading about this error to realize that I have a 
> linear separation issue, for which the solution seems to be eliminating 
> variables. However, elminating via trial and error isn't getting me 
> anywhere, especially since the regression takes about 10 minutes to run 
> every time.

In many cases, separation issues are apparent from simple explorative 
analysis. If you have categorical covariates x, say, then you could look 
at xtabs(~ factor(Paper > 0) + x, data = OvsP). For numeric x, you could 
cut() it first.

Or you could look at the visualization (which does the cut() internally 
if necessary): plot(factor(Paper > 0) ~ x, data = OvsP)

Then the variables with separation issues should be easy to find (or at 
least to narrow it down).

> I tried to identify the issue using the xtab function and 
> received this error:
>
> Error: cannot allocate vector of size 1.4 Gb

Hard to say what goes wrong here. Possibly, the variables are numeric or 
you have specified the formula incorrectly.

> Is there an easier way to identify the covariate that is causing me 
> problems here? Also, am I right in assuming that the count regression 
> should be fine, while its just the logit regression that is causing me 
> the issue (I've never done a zero-inflated regression before).

In the zero-inflation formulation you can't separate the binary part from 
the count part of the model. However, for the hurdle specification, you 
can estimate the models separately.

If necessary, the truncated count part of the _hurdle_ model can be 
estimated with the zerotrunc() function from the "countreg" package on 
R-Forge. That is exactly the same code as in "pscl". But there are also 
other implementations of zero-truncated models in R, e.g., in "VGAM".

hth,
Z

> Thanks!!
>
> Carly
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From hejiaxiu at gmail.com  Tue Jun  4 18:57:12 2013
From: hejiaxiu at gmail.com (Jiaxiu He)
Date: Tue, 4 Jun 2013 11:57:12 -0500
Subject: [R] High volume plot using log(local density)
Message-ID: <CAJdZ_fkf6TnRT+Yj=XRO-Eb9CusYEOFuHna4SrULj8m98pcXaA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130604/3c468520/attachment.pl>

From j.lenkeit at uva.nl  Tue Jun  4 18:13:31 2013
From: j.lenkeit at uva.nl (j.lenkeit)
Date: Tue, 4 Jun 2013 09:13:31 -0700 (PDT)
Subject: [R] probability weights in multilevel models
Message-ID: <1370362411836-4668645.post@n4.nabble.com>

Hello, 
I am new in R and would be glad for any help.

My question is: Is there any available package to run a multilevel model
(random/fixed effects) with probability weights in R?

I have read an older post from 2011 but thought that perhaps there have been
new developments. 

Thank you!
Best, 
Jenny



--
View this message in context: http://r.789695.n4.nabble.com/probability-weights-in-multilevel-models-tp4668645.html
Sent from the R help mailing list archive at Nabble.com.


From k.zhong at erasmusmc.nl  Tue Jun  4 19:08:46 2013
From: k.zhong at erasmusmc.nl (Kaiyin Zhong (Victor Chung))
Date: Tue, 4 Jun 2013 19:08:46 +0200
Subject: [R] gpuHclust slower than hclust
Message-ID: <CAOHtMfVHmzFsETUTmztrJqWYyEX4U3W4UKWp1wRkjgtMHQxkSQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130604/edf18b2d/attachment.pl>

From smartpink111 at yahoo.com  Tue Jun  4 19:18:35 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 4 Jun 2013 10:18:35 -0700 (PDT)
Subject: [R] Read 2 rows in 1 dataframe for diff - longitudinal data
In-Reply-To: <851EB2B7-699F-441A-98D1-BFA7D5552060@comcast.net>
References: <1370311825.22574.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<A5470E89-5497-426F-B7E0-5D308419630E@comcast.net>
	<1370321471.5229.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<851EB2B7-699F-441A-98D1-BFA7D5552060@comcast.net>
Message-ID: <1370366315.67454.YahooMailNeo@web142601.mail.bf1.yahoo.com>



Hi,

By comparing some of the solutions:
?set.seed(25)
?subid<- sample(30:50,22e5,replace=TRUE)
set.seed(27)
year<- sample(1990:2012,22e5,replace=TRUE)
set.seed(35)
?var1<- sample(c(1,3,5,7),22e5,replace=TRUE)
df2<- data.frame(subid,year,var1)
df2<- df2[order(df2$subid,df2$year),]
system.time(res<-subset(ddply(df2,.(subid),mutate,delta=c(FALSE,var1[-1]!=var1[-length(var1)])),delta)[,-4]) 
#? user? system elapsed 
?# 8.036?? 0.132?? 8.188 

system.time(res2<-df2[ as.logical( ave( df2$var1, df2$subid, FUN=function(x) c( FALSE, x[-1] != x[-length(x)]) ) ), ])
#? user? system elapsed 
?# 1.220?? 0.000?? 1.222 
system.time(res3<-df2[with(df2,unlist(tapply(var1,list(subid),FUN=function(x) c(FALSE,diff(x)!=0)),use.names=FALSE)),])
#? user? system elapsed 
?# 1.729?? 0.000?? 1.730 
identical(res2,res3)
#[1] TRUE

row.names(res)<-1:nrow(res)
?row.names(res2)<-1:nrow(res)
?identical(res,res2)
#[1] TRUE

I found half an hour a bit too extreme by comparing the above numbers.


A.K.


David: 

6 ? ? 47 1999 ? 1 

should not be included in the output list because, we are trying
 to detect changes within the subid's. ?1999 was the first year for 
subject 47 and changes have to be detected after that year - hence we 
were using ddply to group. Your solution ran very fast as expected. 

AK- I have a large dataset and your solution is taking too long -
 as a matter of fact i had to kill it afte 1/2 hr on a 22K row dataset. 

Thanks for the suggestions. 

-ST 


----- Original Message -----
From: David Winsemius <dwinsemius at comcast.net>
To: arun <smartpink111 at yahoo.com>
Cc: R help <r-help at r-project.org>
Sent: Tuesday, June 4, 2013 11:13 AM
Subject: Re: [R] Read 2 rows in 1 dataframe for diff - longitudinal data


On Jun 3, 2013, at 9:51 PM, arun wrote:

> If it is grouped by "subid" (that would be the difference in the number of changes)
> 
> subset(ddply(df1,.(subid),mutate,delta=c(FALSE,var[-1]!=var[-length(var)])),delta)[,-4]
> #?  subid year var
> #3? ?  36 2003?  3
> #7? ?  47 2001?  3
> #9? ?  47 2005?  1
> #10? ? 47 2007?  3
> A.K.

I'm not sure why the first one retruns integer values from the ave() call but the second version works:

> df1[ ave( df1$var, df1$subid, FUN=function(x) c( FALSE, x[-1] != x[-length(x)]) ), ]
? ? subid year var
1? ? ? 36 1999?  1
1.1? ? 36 1999?  1
1.2? ? 36 1999?  1
1.3? ? 36 1999?  1

ave( df1$var, df1$subid, FUN=function(x) c( FALSE, x[-1] != x[-length(x)]))
[1] 0 0 1 0 0 0 1 0 1 1

Perhaps one of the single item groups sabotaged my simple function.


> df1[ as.logical( ave( df1$var, df1$subid, FUN=function(x) c( FALSE, x[-1] != x[-length(x)]) ) ), ]
?  subid year var
3? ?  36 2003?  3
7? ?  47 2001?  3
9? ?  47 2005?  1
10? ? 47 2007?  3

-- 
David.
> 
> 
> ----- Original Message -----
> From: David Winsemius <dwinsemius at comcast.net>
> To: arun <smartpink111 at yahoo.com>
> Cc: R help <r-help at r-project.org>
> Sent: Tuesday, June 4, 2013 12:37 AM
> Subject: Re: [R] Read 2 rows in 1 dataframe for diff - longitudinal data
> 
> 
> On Jun 3, 2013, at 7:10 PM, arun wrote:
> 
>> Hi,
>> May be this helps:
>> res1<-df1[with(df1,unlist(tapply(var,list(subid),FUN=function(x) c(FALSE,diff(x)!=0)),use.names=FALSE)),]
>>?  res1
>> #?  subid year var
>> #3? ?  36 2003?  3
>> #7? ?  47 2001?  3
>> #9? ?  47 2005?  1
>> #10? ? 47 2007?  3
>> #or
>> library(plyr)
>>?  subset(ddply(df1,.(subid),mutate,delta=c(FALSE,diff(var)!=0)),delta)[,-4]
>> #?  subid year var
>> #3? ?  36 2003?  3
>> #7? ?  47 2001?  3
>> #9? ?  47 2005?  1
>> #10? ? 47 2007?  3
>> A.K.
>> 
> It's pretty simple with logical indexing:
> 
>> df1[ c(FALSE, df1$var[-1]!=df1$var[-length(df1$var)]), ]
>? ? subid year var
> 3? ?  36 2003?  3
> 6? ?  47 1999?  1
> 7? ?  47 2001?  3
> 9? ?  47 2005?  1
> 10? ? 47 2007?  3
> 
> 
> When I count the number of changes in value of var is give me 5. Not sure why you are both leaving out row 6.
> 
> -- 
> David.
>> 
>> 
>> I need to output a dataframe whenever var changes a value. 
>> 
>> df1 <- data.frame(subid=rep(c(36,47),each=5),year=rep(seq(1999,2007,2),2),var=c(1,1,3,3,3,1,3,3,1,3)) 
>>? ?  subid year var 
>> 1? ?  36 1999?  1 
>> 2? ?  36 2001?  1 
>> 3? ?  36 2003?  3 
>> 4? ?  36 2005?  3 
>> 5? ?  36 2007?  3 
>> 6? ?  47 1999?  1 
>> 7? ?  47 2001?  3 
>> 8? ?  47 2003?  3 
>> 9? ?  47 2005?  1 
>> 10? ? 47 2007?  3 
>>> 
>> 
>> I need: 
>> 36 2003?  3 
>> 47 2001?  3 
>> 47 2005?  1 
>> 47 2007?  3 
>> 
>> I am trying to use ddply over subid and use the diff function, but it is not working quiet right. 
>> 
>>> dd <- ddply(df1,.(subid),summarize,delta=diff(var) != 0) 
>>> dd 
>>? ? subid delta 
>> 1? ? 36 FALSE 
>> 2? ? 36? TRUE 
>> 3? ? 36 FALSE 
>> 4? ? 36 FALSE 
>> 5? ? 47? TRUE 
>> 6? ? 47 FALSE 
>> 7? ? 47? TRUE 
>> 8? ? 47? TRUE 
>> 
>> I would appreciate any help on this. 
>> Thank You! 
>> -ST
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 

David Winsemius
Alameda, CA, USA



From smartpink111 at yahoo.com  Tue Jun  4 20:45:27 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 4 Jun 2013 11:45:27 -0700 (PDT)
Subject: [R] choose the lines2
In-Reply-To: <CAMiZAioXr33PM2xXRu4krOac7+JJiRq4jsKm7PFJO5RJMgX_KA@mail.gmail.com>
References: <CAMiZAioXr33PM2xXRu4krOac7+JJiRq4jsKm7PFJO5RJMgX_KA@mail.gmail.com>
Message-ID: <1370371527.43283.YahooMailNeo@web142606.mail.bf1.yahoo.com>

HI,
You can do this:

dat1<- read.csv("dat7.csv",header=TRUE,stringsAsFactors=FALSE,sep="\t")
dat.bru<- dat1[!is.na(dat1$evnmt_brutal),]


fun2<- function(dat){? 
????? lst1<- split(dat,dat$patient_id)
??? lst2<- lapply(lst1,function(x) x[cumsum(x$evnmt_brutal==0)>0,])
??? lst3<- lapply(lst2,function(x) x[!(all(x$evnmt_brutal==1)|all(x$evnmt_brutal==0)),])
??? lst4<- lst3[lapply(lst3,nrow)!=0]
??? lst5<- lapply(seq_along(lst4),function(i){
???????????????????? do.call(rbind,lapply(which(lst4[[i]]$evnmt_brutal==1),function(x) {
??????????????????????????????????????? x1<-c(x-2,x-1,x)
??????????????????????????????????????? x2<-x1[!any(x1==0)]
??????????????????????????????????????? x3<-lst4[[i]][x2,]
??????????????????????????????????????? x4<-x3[!is.na(match(paste(x3$evnmt_brutal,collapse=""),"001")),]
??????????????????????????????????????? x4[!any(duplicated(x4$number))]
??????????????????????????????????????? }
??????????????????????????????????????? ))
??????????????????????????????????? })
?? lst6<-lst5[lapply(lst5,nrow)!=0]
?? names(lst6)<- unlist(lapply(lst6,function(x) unique(x$patient_id)))
?? Mean_01<-do.call(rbind,lapply(lst6,function(x) cbind(Mean_Middle0=mean(x[seq(nrow(x))%%3==2,"basdai_d"]),Mean_1=mean(x[seq(nrow(x))%%3==0,"basdai_d"]))))
rownames(Mean_01)<- names(lst6)

? ?? lst7<-list(lst6,Mean_01)
?? lst7
?? #lapply(lst7,head,2)?? 
?? }????????????????? 

fun2(dat.bru)
head(fun2(dat.bru)[[1]],3)
#$`2`
#??? X patient_id number responsed_at? t basdai_d evnmt_brutal
#13 13????????? 2???? 12?? 2011-07-05 12???? -1.0??????????? 0
#14 14????????? 2???? 13?? 2011-08-07 13????? 0.9??????????? 0
#15 15????????? 2???? 14?? 2011-09-11 14???? -0.8??????????? 1
#
#$`5`
?# ? X patient_id number responsed_at t basdai_d evnmt_brutal
#52 52????????? 5????? 8?? 2011-01-11 7???? -2.8??????????? 0
#53 53????????? 5????? 9?? 2011-02-13 8????? 0.0??????????? 0
#54 54????????? 5???? 10?? 2011-03-19 9???? -1.2??????????? 1
#
#$`6`
?# ? X patient_id number responsed_at? t basdai_d evnmt_brutal
#74 74????????? 6????? 9?? 2011-02-05? 8???? 0.80??????????? 0
#75 75????????? 6???? 10?? 2011-03-09? 9???? 0.15??????????? 0
#76 76????????? 6???? 11?? 2011-04-11 10??? -0.45??????????? 1


?head(fun2(dat.bru)[[2]],3)
# Mean_Middle0 Mean_1
#2???????? 0.90? -0.80
#5???????? 0.00? -1.20
#6???????? 0.15? -0.45

res1<- fun2(dat.bru)[[1]]

lapply(res1,function(x) tail(x,-1))[1:3]
#$`2`
?# ? X patient_id number responsed_at? t basdai_d evnmt_brutal
#14 14????????? 2???? 13?? 2011-08-07 13????? 0.9??????????? 0
#15 15????????? 2???? 14?? 2011-09-11 14???? -0.8??????????? 1
#
#$`5`
?# ? X patient_id number responsed_at t basdai_d evnmt_brutal
#53 53????????? 5????? 9?? 2011-02-13 8????? 0.0??????????? 0
#54 54????????? 5???? 10?? 2011-03-19 9???? -1.2??????????? 1
#
#$`6`
?# ? X patient_id number responsed_at? t basdai_d evnmt_brutal
#75 75????????? 6???? 10?? 2011-03-09? 9???? 0.15??????????? 0
#76 76????????? 6???? 11?? 2011-04-11 10??? -0.45??????????? 1

#or
res11<-do.call(rbind,lapply(res1,function(x) tail(x,-1)))
row.names(res11)<-1:nrow(res11)

A.K.
________________________________
From: GUANGUAN LUO <guanguanluo at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Tuesday, June 4, 2013 2:10 PM
Subject: choose the lines2



13 2 12 2011/7/5 12 -1 0 
14 2 13 2011/8/7 13 0.9 0 
15 2 14 2011/9/11 14 -0.8 1 
52 5 8 2011/1/11 7 -2.8 0 
53 5 9 2011/2/13 8 0 0 
54 5 10 2011/3/19 9 -1.2 1 
74 6 9 2011/2/5 8 0.8 0 
75 6 10 2011/3/9 9 0.15 0 
76 6 11 2011/4/11 10 -0.45 1 

those are the result which i want, and then i want to choose like this










14 2 13 2011/8/7 13 0.9 0 
15 2 14 2011/9/11 14 -0.8 1 








53 5 9 2011/2/13 8 0 0 
54 5 10 2011/3/19 9 -1.2 1 








75 6 10 2011/3/9 9 0.15 0 
76 6 11 2011/4/11 10 -0.45 1






















so that i can calculate the mean of the lines with evnmt_brutal ==0 and compare with the lines with evnmt_brutal==1


From smartpink111 at yahoo.com  Tue Jun  4 21:06:01 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 4 Jun 2013 12:06:01 -0700 (PDT)
Subject: [R] return p-value in a t.test function
Message-ID: <1370372761.32581.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Try this:
set.seed(24)
?b1<- sample(1:40,20,replace=TRUE)
?set.seed(28)
?a1<- sample(30:50,20,replace=TRUE)
t_test_apparie <- function(x,y)
{
t.test(x,y,paired=TRUE,alternative = "greater")$p.value
} 

t_test_apparie(a1,b1)
#[1] 6.571404e-08
A.K.



>Hi, 
>
>I have written this function : 
>
>t_test_apparie <- function(x,y) 
>{ 
>t.test(x,y,paired=TRUE,alternative = "greater") 
>} 
>
>I would like that ONLY the p-value gets returned. How would I do that? 
>
>Thanks.


From smartpink111 at yahoo.com  Tue Jun  4 21:25:15 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 4 Jun 2013 12:25:15 -0700 (PDT)
Subject: [R] Read 2 rows in 1 dataframe for diff - longitudinal data
In-Reply-To: <1370366315.67454.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1370311825.22574.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<A5470E89-5497-426F-B7E0-5D308419630E@comcast.net>
	<1370321471.5229.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<851EB2B7-699F-441A-98D1-BFA7D5552060@comcast.net>
	<1370366315.67454.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1370373915.98379.YahooMailNeo@web142605.mail.bf1.yahoo.com>

HI ST,

In case, you wanted to further decrease the time:
library(data.table)
dt1<- data.table(df2) #using the same example as below
system.time({
?dt1<-dt1[,indx:=c(FALSE,diff(var1)!=0),by=subid]
res3<-subset(dt1,indx,select=1:3)
})
# user? system elapsed 
#?? 0.32??? 0.00??? 0.32 
?head(res3)
#?? subid year var1
#1:??? 30 1990??? 7
#2:??? 30 1990??? 1
#3:??? 30 1990??? 5
#4:??? 30 1990??? 7
#5:??? 30 1990??? 5
#6:??? 30 1990??? 7
?head(res2)
#? subid year var1
#1??? 30 1990??? 7
#2??? 30 1990??? 1
#3??? 30 1990??? 5
#4??? 30 1990??? 7
#5??? 30 1990??? 5
#6??? 30 1990??? 7


Since you mentioned this > half-hour running time, it would be good to check your data.? 

?str()
A.K.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: David Winsemius <dwinsemius at comcast.net>
Sent: Tuesday, June 4, 2013 1:18 PM
Subject: Re: [R] Read 2 rows in 1 dataframe for diff - longitudinal data



Hi,

By comparing some of the solutions:
?set.seed(25)
?subid<- sample(30:50,22e5,replace=TRUE)
set.seed(27)
year<- sample(1990:2012,22e5,replace=TRUE)
set.seed(35)
?var1<- sample(c(1,3,5,7),22e5,replace=TRUE)
df2<- data.frame(subid,year,var1)
df2<- df2[order(df2$subid,df2$year),]
system.time(res<-subset(ddply(df2,.(subid),mutate,delta=c(FALSE,var1[-1]!=var1[-length(var1)])),delta)[,-4]) 
#? user? system elapsed 
?# 8.036?? 0.132?? 8.188 

system.time(res2<-df2[ as.logical( ave( df2$var1, df2$subid, FUN=function(x) c( FALSE, x[-1] != x[-length(x)]) ) ), ])
#? user? system elapsed 
?# 1.220?? 0.000?? 1.222 
system.time(res3<-df2[with(df2,unlist(tapply(var1,list(subid),FUN=function(x) c(FALSE,diff(x)!=0)),use.names=FALSE)),])
#? user? system elapsed 
?# 1.729?? 0.000?? 1.730 
identical(res2,res3)
#[1] TRUE

row.names(res)<-1:nrow(res)
?row.names(res2)<-1:nrow(res)
?identical(res,res2)
#[1] TRUE

I found half an hour a bit too extreme by comparing the above numbers.


A.K.


David: 

6 ? ? 47 1999 ? 1 

should not be included in the output list because, we are trying
to detect changes within the subid's. ?1999 was the first year for 
subject 47 and changes have to be detected after that year - hence we 
were using ddply to group. Your solution ran very fast as expected. 

AK- I have a large dataset and your solution is taking too long -
as a matter of fact i had to kill it afte 1/2 hr on a 22K row dataset. 

Thanks for the suggestions. 

-ST 


----- Original Message -----
From: David Winsemius <dwinsemius at comcast.net>
To: arun <smartpink111 at yahoo.com>
Cc: R help <r-help at r-project.org>
Sent: Tuesday, June 4, 2013 11:13 AM
Subject: Re: [R] Read 2 rows in 1 dataframe for diff - longitudinal data


On Jun 3, 2013, at 9:51 PM, arun wrote:

> If it is grouped by "subid" (that would be the difference in the number of changes)
> 
> subset(ddply(df1,.(subid),mutate,delta=c(FALSE,var[-1]!=var[-length(var)])),delta)[,-4]
> #?? subid year var
> #3? ?? 36 2003?? 3
> #7? ?? 47 2001?? 3
> #9? ?? 47 2005?? 1
> #10? ? 47 2007?? 3
> A.K.

I'm not sure why the first one retruns integer values from the ave() call but the second version works:

> df1[ ave( df1$var, df1$subid, FUN=function(x) c( FALSE, x[-1] != x[-length(x)]) ), ]
? ? subid year var
1? ? ? 36 1999?? 1
1.1? ? 36 1999?? 1
1.2? ? 36 1999?? 1
1.3? ? 36 1999?? 1

ave( df1$var, df1$subid, FUN=function(x) c( FALSE, x[-1] != x[-length(x)]))
[1] 0 0 1 0 0 0 1 0 1 1

Perhaps one of the single item groups sabotaged my simple function.


> df1[ as.logical( ave( df1$var, df1$subid, FUN=function(x) c( FALSE, x[-1] != x[-length(x)]) ) ), ]
?? subid year var
3? ?? 36 2003?? 3
7? ?? 47 2001?? 3
9? ?? 47 2005?? 1
10? ? 47 2007?? 3

-- 
David.
> 
> 
> ----- Original Message -----
> From: David Winsemius <dwinsemius at comcast.net>
> To: arun <smartpink111 at yahoo.com>
> Cc: R help <r-help at r-project.org>
> Sent: Tuesday, June 4, 2013 12:37 AM
> Subject: Re: [R] Read 2 rows in 1 dataframe for diff - longitudinal data
> 
> 
> On Jun 3, 2013, at 7:10 PM, arun wrote:
> 
>> Hi,
>> May be this helps:
>> res1<-df1[with(df1,unlist(tapply(var,list(subid),FUN=function(x) c(FALSE,diff(x)!=0)),use.names=FALSE)),]
>>?? res1
>> #?? subid year var
>> #3? ?? 36 2003?? 3
>> #7? ?? 47 2001?? 3
>> #9? ?? 47 2005?? 1
>> #10? ? 47 2007?? 3
>> #or
>> library(plyr)
>>?? subset(ddply(df1,.(subid),mutate,delta=c(FALSE,diff(var)!=0)),delta)[,-4]
>> #?? subid year var
>> #3? ?? 36 2003?? 3
>> #7? ?? 47 2001?? 3
>> #9? ?? 47 2005?? 1
>> #10? ? 47 2007?? 3
>> A.K.
>> 
> It's pretty simple with logical indexing:
> 
>> df1[ c(FALSE, df1$var[-1]!=df1$var[-length(df1$var)]), ]
>? ? subid year var
> 3? ?? 36 2003?? 3
> 6? ?? 47 1999?? 1
> 7? ?? 47 2001?? 3
> 9? ?? 47 2005?? 1
> 10? ? 47 2007?? 3
> 
> 
> When I count the number of changes in value of var is give me 5. Not sure why you are both leaving out row 6.
> 
> -- 
> David.
>> 
>> 
>> I need to output a dataframe whenever var changes a value. 
>> 
>> df1 <- data.frame(subid=rep(c(36,47),each=5),year=rep(seq(1999,2007,2),2),var=c(1,1,3,3,3,1,3,3,1,3)) 
>>? ?? subid year var 
>> 1? ?? 36 1999?? 1 
>> 2? ?? 36 2001?? 1 
>> 3? ?? 36 2003?? 3 
>> 4? ?? 36 2005?? 3 
>> 5? ?? 36 2007?? 3 
>> 6? ?? 47 1999?? 1 
>> 7? ?? 47 2001?? 3 
>> 8? ?? 47 2003?? 3 
>> 9? ?? 47 2005?? 1 
>> 10? ? 47 2007?? 3 
>>> 
>> 
>> I need: 
>> 36 2003?? 3 
>> 47 2001?? 3 
>> 47 2005?? 1 
>> 47 2007?? 3 
>> 
>> I am trying to use ddply over subid and use the diff function, but it is not working quiet right. 
>> 
>>> dd <- ddply(df1,.(subid),summarize,delta=diff(var) != 0) 
>>> dd 
>>? ? subid delta 
>> 1? ? 36 FALSE 
>> 2? ? 36? TRUE 
>> 3? ? 36 FALSE 
>> 4? ? 36 FALSE 
>> 5? ? 47? TRUE 
>> 6? ? 47 FALSE 
>> 7? ? 47? TRUE 
>> 8? ? 47? TRUE 
>> 
>> I would appreciate any help on this. 
>> Thank You! 
>> -ST
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 

David Winsemius
Alameda, CA, USA



From wdunlap at tibco.com  Tue Jun  4 21:25:47 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 4 Jun 2013 19:25:47 +0000
Subject: [R] Read 2 rows in 1 dataframe for diff - longitudinal data
In-Reply-To: <1370366315.67454.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1370311825.22574.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<A5470E89-5497-426F-B7E0-5D308419630E@comcast.net>
	<1370321471.5229.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<851EB2B7-699F-441A-98D1-BFA7D5552060@comcast.net>
	<1370366315.67454.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C2FCF8F@PA-MBX01.na.tibco.com>

Since you have sorted the data.frame by 'subid', breaking ties with 'year',
doesn't the following do the same thing as the other solutions.
  f4 <- function(df) df[ c(TRUE,diff(df$var1)!=0) & c(FALSE,diff(df$subid)==0), ]
It gives the same answer for your df2 and is quicker than the others.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of arun
> Sent: Tuesday, June 04, 2013 10:19 AM
> To: R help
> Subject: Re: [R] Read 2 rows in 1 dataframe for diff - longitudinal data
> 
> 
> 
> Hi,
> 
> By comparing some of the solutions:
> ?set.seed(25)
> ?subid<- sample(30:50,22e5,replace=TRUE)
> set.seed(27)
> year<- sample(1990:2012,22e5,replace=TRUE)
> set.seed(35)
> ?var1<- sample(c(1,3,5,7),22e5,replace=TRUE)
> df2<- data.frame(subid,year,var1)
> df2<- df2[order(df2$subid,df2$year),]
> system.time(res<-subset(ddply(df2,.(subid),mutate,delta=c(FALSE,var1[-1]!=var1[-
> length(var1)])),delta)[,-4])
> #? user? system elapsed
> ?# 8.036?? 0.132?? 8.188
> 
> system.time(res2<-df2[ as.logical( ave( df2$var1, df2$subid, FUN=function(x) c( FALSE,
> x[-1] != x[-length(x)]) ) ), ])
> #? user? system elapsed
> ?# 1.220?? 0.000?? 1.222
> system.time(res3<-df2[with(df2,unlist(tapply(var1,list(subid),FUN=function(x)
> c(FALSE,diff(x)!=0)),use.names=FALSE)),])
> #? user? system elapsed
> ?# 1.729?? 0.000?? 1.730
> identical(res2,res3)
> #[1] TRUE
> 
> row.names(res)<-1:nrow(res)
> ?row.names(res2)<-1:nrow(res)
> ?identical(res,res2)
> #[1] TRUE
> 
> I found half an hour a bit too extreme by comparing the above numbers.
> 
> 
> A.K.
> 
> 
> David:
> 
> 6 ? ? 47 1999 ? 1
> 
> should not be included in the output list because, we are trying
>  to detect changes within the subid's. ?1999 was the first year for
> subject 47 and changes have to be detected after that year - hence we
> were using ddply to group. Your solution ran very fast as expected.
> 
> AK- I have a large dataset and your solution is taking too long -
>  as a matter of fact i had to kill it afte 1/2 hr on a 22K row dataset.
> 
> Thanks for the suggestions.
> 
> -ST
> 
> 
> ----- Original Message -----
> From: David Winsemius <dwinsemius at comcast.net>
> To: arun <smartpink111 at yahoo.com>
> Cc: R help <r-help at r-project.org>
> Sent: Tuesday, June 4, 2013 11:13 AM
> Subject: Re: [R] Read 2 rows in 1 dataframe for diff - longitudinal data
> 
> 
> On Jun 3, 2013, at 9:51 PM, arun wrote:
> 
> > If it is grouped by "subid" (that would be the difference in the number of changes)
> >
> > subset(ddply(df1,.(subid),mutate,delta=c(FALSE,var[-1]!=var[-length(var)])),delta)[,-4]
> > #?  subid year var
> > #3? ?  36 2003?  3
> > #7? ?  47 2001?  3
> > #9? ?  47 2005?  1
> > #10? ? 47 2007?  3
> > A.K.
> 
> I'm not sure why the first one retruns integer values from the ave() call but the second
> version works:
> 
> > df1[ ave( df1$var, df1$subid, FUN=function(x) c( FALSE, x[-1] != x[-length(x)]) ), ]
> ? ? subid year var
> 1? ? ? 36 1999?  1
> 1.1? ? 36 1999?  1
> 1.2? ? 36 1999?  1
> 1.3? ? 36 1999?  1
> 
> ave( df1$var, df1$subid, FUN=function(x) c( FALSE, x[-1] != x[-length(x)]))
> [1] 0 0 1 0 0 0 1 0 1 1
> 
> Perhaps one of the single item groups sabotaged my simple function.
> 
> 
> > df1[ as.logical( ave( df1$var, df1$subid, FUN=function(x) c( FALSE, x[-1] != x[-length(x)])
> ) ), ]
> ?  subid year var
> 3? ?  36 2003?  3
> 7? ?  47 2001?  3
> 9? ?  47 2005?  1
> 10? ? 47 2007?  3
> 
> --
> David.
> >
> >
> > ----- Original Message -----
> > From: David Winsemius <dwinsemius at comcast.net>
> > To: arun <smartpink111 at yahoo.com>
> > Cc: R help <r-help at r-project.org>
> > Sent: Tuesday, June 4, 2013 12:37 AM
> > Subject: Re: [R] Read 2 rows in 1 dataframe for diff - longitudinal data
> >
> >
> > On Jun 3, 2013, at 7:10 PM, arun wrote:
> >
> >> Hi,
> >> May be this helps:
> >> res1<-df1[with(df1,unlist(tapply(var,list(subid),FUN=function(x)
> c(FALSE,diff(x)!=0)),use.names=FALSE)),]
> >>?  res1
> >> #?  subid year var
> >> #3? ?  36 2003?  3
> >> #7? ?  47 2001?  3
> >> #9? ?  47 2005?  1
> >> #10? ? 47 2007?  3
> >> #or
> >> library(plyr)
> >>?  subset(ddply(df1,.(subid),mutate,delta=c(FALSE,diff(var)!=0)),delta)[,-4]
> >> #?  subid year var
> >> #3? ?  36 2003?  3
> >> #7? ?  47 2001?  3
> >> #9? ?  47 2005?  1
> >> #10? ? 47 2007?  3
> >> A.K.
> >>
> > It's pretty simple with logical indexing:
> >
> >> df1[ c(FALSE, df1$var[-1]!=df1$var[-length(df1$var)]), ]
> >? ? subid year var
> > 3? ?  36 2003?  3
> > 6? ?  47 1999?  1
> > 7? ?  47 2001?  3
> > 9? ?  47 2005?  1
> > 10? ? 47 2007?  3
> >
> >
> > When I count the number of changes in value of var is give me 5. Not sure why you are
> both leaving out row 6.
> >
> > --
> > David.
> >>
> >>
> >> I need to output a dataframe whenever var changes a value.
> >>
> >> df1 <-
> data.frame(subid=rep(c(36,47),each=5),year=rep(seq(1999,2007,2),2),var=c(1,1,3,3,3,1,3
> ,3,1,3))
> >>? ?  subid year var
> >> 1? ?  36 1999?  1
> >> 2? ?  36 2001?  1
> >> 3? ?  36 2003?  3
> >> 4? ?  36 2005?  3
> >> 5? ?  36 2007?  3
> >> 6? ?  47 1999?  1
> >> 7? ?  47 2001?  3
> >> 8? ?  47 2003?  3
> >> 9? ?  47 2005?  1
> >> 10? ? 47 2007?  3
> >>>
> >>
> >> I need:
> >> 36 2003?  3
> >> 47 2001?  3
> >> 47 2005?  1
> >> 47 2007?  3
> >>
> >> I am trying to use ddply over subid and use the diff function, but it is not working quiet
> right.
> >>
> >>> dd <- ddply(df1,.(subid),summarize,delta=diff(var) != 0)
> >>> dd
> >>? ? subid delta
> >> 1? ? 36 FALSE
> >> 2? ? 36? TRUE
> >> 3? ? 36 FALSE
> >> 4? ? 36 FALSE
> >> 5? ? 47? TRUE
> >> 6? ? 47 FALSE
> >> 7? ? 47? TRUE
> >> 8? ? 47? TRUE
> >>
> >> I would appreciate any help on this.
> >> Thank You!
> >> -ST
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> 
> David Winsemius
> Alameda, CA, USA
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From joeclark77 at hotmail.com  Tue Jun  4 22:32:07 2013
From: joeclark77 at hotmail.com (Joseph Clark)
Date: Tue, 4 Jun 2013 13:32:07 -0700
Subject: [R] how to compute maximum of fitted polynomial?
Message-ID: <BLU171-W3008743CA8E23E4C29E050D89E0@phx.gbl>

My script fits a third-order polynomial to my data with something like this:

model <- lm( y ~ poly(x, 3) )

What I'd like to do is find the theoretical maximum of the polynomial (i.e. the x at which "model" predicts the highest y).  Specifically, I'd like to predict the maximum between 0 <= x <= 1.

What's the best way to accomplish that in R?

Bonus question: can R give me the derivative or 2nd derivative of the polynomial?  I'd like to be able to compute these at that maximum point.

Thanks in advance!


// joseph w. clark , phd , visiting research associate
\\ university of nebraska at omaha - college of IS&T 		 	   		  

From tring at gvdnet.dk  Tue Jun  4 22:36:01 2013
From: tring at gvdnet.dk (Troels Ring)
Date: Tue, 04 Jun 2013 22:36:01 +0200
Subject: [R] survival aareg plot problem
Message-ID: <51AE4FB1.5060008@gvdnet.dk>

Dear friends - I'm on windows 7, R 2.15.2

when I run the example for aareg in survival package I see this:

  plot(lfit[4], ylim=c(-4,4))
error in xy.coords(x, y, xlabel, ylabel, log) :
   'x' is a list, but does not have components 'x' and 'y'

Is that a matter of an old R?

Best wishes

Troels Ring, MD
Aalborg, Denmark


From dwinsemius at comcast.net  Tue Jun  4 23:38:36 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 4 Jun 2013 14:38:36 -0700
Subject: [R] survival aareg plot problem
In-Reply-To: <51AE4FB1.5060008@gvdnet.dk>
References: <51AE4FB1.5060008@gvdnet.dk>
Message-ID: <1DBAE090-9E1D-4244-B810-57D188DC9314@comcast.net>


On Jun 4, 2013, at 1:36 PM, Troels Ring wrote:

> Dear friends - I'm on windows 7, R 2.15.2
>
> when I run the example for aareg in survival package I see this:
>
> plot(lfit[4], ylim=c(-4,4))
> error in xy.coords(x, y, xlabel, ylabel, log) :
>  'x' is a list, but does not have components 'x' and 'y'
>
> Is that a matter of an old R?

Difficult to ascertain or investigate. At the moment only you are able  
to do so with:

str( lfit[4] )

--

David Winsemius, MD
Alameda, CA, USA


From ruipbarradas at sapo.pt  Tue Jun  4 23:51:48 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 04 Jun 2013 22:51:48 +0100
Subject: [R] how to compute maximum of fitted polynomial?
In-Reply-To: <BLU171-W3008743CA8E23E4C29E050D89E0@phx.gbl>
References: <BLU171-W3008743CA8E23E4C29E050D89E0@phx.gbl>
Message-ID: <51AE6174.30103@sapo.pt>

Hello,

As for the first question, you can use ?optim to compute the maximum of 
a function. Note that by default optim minimizes, to maximize you must 
set the parameter control$fnscale to a negative value.

fit <- lm(y ~ poly(x, 3))

fn <- function(x, coefs) as.numeric(c(1, x, x^2, x^3) %*% coefs)

sol <- optim(0, fn, gr = NULL, coef(fit), control = list(fnscale = -1),
	method = "L-BFGS-B", lower = 0, upper = 1)


As for the second question, I believe you can do something like

dfdx <- D( expression(a + b*x + c*x^2 + d*x^3), "x")

a <- coef(fit)[1]
b <- coef(fit)[2]
c <- coef(fit)[3]
d <- coef(fit)[4]
x <- sol$par
eval(dfdx)


See the help page for ?D


Hope this helps,

Rui Barradas

Em 04-06-2013 21:32, Joseph Clark escreveu:
> My script fits a third-order polynomial to my data with something like this:
>
> model <- lm( y ~ poly(x, 3) )
>
> What I'd like to do is find the theoretical maximum of the polynomial (i.e. the x at which "model" predicts the highest y).  Specifically, I'd like to predict the maximum between 0 <= x <= 1.
>
> What's the best way to accomplish that in R?
>
> Bonus question: can R give me the derivative or 2nd derivative of the polynomial?  I'd like to be able to compute these at that maximum point.
>
> Thanks in advance!
>
>
> // joseph w. clark , phd , visiting research associate
> \\ university of nebraska at omaha - college of IS&T 		 	   		
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From 538280 at gmail.com  Tue Jun  4 23:56:49 2013
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 4 Jun 2013 15:56:49 -0600
Subject: [R] read.csv and write.csv filtering for very big data ?
In-Reply-To: <CAPr7RtW3fX73N5NZRQbuN7M+PFJHzXo0L1VuMLih1P2Uz5Gx5g@mail.gmail.com>
References: <CAPr7RtW3fX73N5NZRQbuN7M+PFJHzXo0L1VuMLih1P2Uz5Gx5g@mail.gmail.com>
Message-ID: <CAFEqCdy7tYgY_DYtovOewfFXzuRWH2XxKYyuqf8BMAzdWOwDqw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130604/50333efe/attachment.pl>

From gunter.berton at gene.com  Wed Jun  5 01:20:05 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 4 Jun 2013 16:20:05 -0700
Subject: [R] how to compute maximum of fitted polynomial?
In-Reply-To: <51AE6174.30103@sapo.pt>
References: <BLU171-W3008743CA8E23E4C29E050D89E0@phx.gbl>
	<51AE6174.30103@sapo.pt>
Message-ID: <CACk-te16ReaLbN5amRL63tbn=3DBgbEZwBNMHa7TANPveY4HWQ@mail.gmail.com>

1. This looks like a homework question. We should not do homework here.

2. optim() will only approximate the max.

3. optim() is not the right numerical tool for this anyway. optimize() is.

4. There is never a guarantee numerical methods will find the max.

5. This can (and should?) be done exactly using elementary math rather
than numerical methods.

Cheers,
Bert

On Tue, Jun 4, 2013 at 2:51 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> As for the first question, you can use ?optim to compute the maximum of a
> function. Note that by default optim minimizes, to maximize you must set the
> parameter control$fnscale to a negative value.
>
> fit <- lm(y ~ poly(x, 3))
>
> fn <- function(x, coefs) as.numeric(c(1, x, x^2, x^3) %*% coefs)
>
> sol <- optim(0, fn, gr = NULL, coef(fit), control = list(fnscale = -1),
>         method = "L-BFGS-B", lower = 0, upper = 1)
>
>
> As for the second question, I believe you can do something like
>
> dfdx <- D( expression(a + b*x + c*x^2 + d*x^3), "x")
>
> a <- coef(fit)[1]
> b <- coef(fit)[2]
> c <- coef(fit)[3]
> d <- coef(fit)[4]
> x <- sol$par
> eval(dfdx)
>
>
> See the help page for ?D
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 04-06-2013 21:32, Joseph Clark escreveu:
>>
>> My script fits a third-order polynomial to my data with something like
>> this:
>>
>> model <- lm( y ~ poly(x, 3) )
>>
>> What I'd like to do is find the theoretical maximum of the polynomial
>> (i.e. the x at which "model" predicts the highest y).  Specifically, I'd
>> like to predict the maximum between 0 <= x <= 1.
>>
>> What's the best way to accomplish that in R?
>>
>> Bonus question: can R give me the derivative or 2nd derivative of the
>> polynomial?  I'd like to be able to compute these at that maximum point.
>>
>> Thanks in advance!
>>
>>
>> // joseph w. clark , phd , visiting research associate
>> \\ university of nebraska at omaha - college of IS&T
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From paxkn at nottingham.ac.uk  Wed Jun  5 01:44:12 2013
From: paxkn at nottingham.ac.uk (beginner)
Date: Tue, 4 Jun 2013 16:44:12 -0700 (PDT)
Subject: [R] How to write a loop in R to select multiple regression model
 and validate it ?
Message-ID: <1370389452097-4668668.post@n4.nabble.com>

I would like to run a loop in R. I have never done this before, so I would be
very grateful for your help !

1. I have a sample set: 25 objects. I would like to draw 1 object from it
and use it as a test set for my future external validation. The remaining 24
objects I would like to use as a training set (to select a model). I would
like to repeat this process until all 25 objects are used as a test set. 

2. For each of the training sets I would like to run the following code:


library(leaps)
forward <- regsubsets(Y ~.,data = training, method = "forward", nbest=1) 
backward <- regsubsets(Y ~.,data = training, method = "backward", nbest=1)
stepwise <- regsubsets(Y ~., data = training, method = "seqrep", nbest=1)
exhaustive <- regsubsets(Y ~.,data = training, method = "forward", nbest=1)
summary(forward)
summary(backward)
summary(stepwise)
summary(exhaustive)

I would like R programme to select the best model (with the highest adjusted
R2) using each of the selection methods, so there are 4 final best models
(e.g. the best model selected with forward selection, the best model
selected with backward selection and so on...). 

 
Afterwards I would like to perform internal cross validation of all 4
selected models and choose 1 out of 4 which has the lowest average mean
squared error (MSE). I used to do it using the code below:

library(DAAG)
val.daag<-CVlm(df=training, m=1, form.lm=formula(Y ~ X1+X2+X3))
val.daag<-CVlm(df=training, m=1, form.lm=formula(Y ~ X1+X2+X4))
val.daag<-CVlm(df=training, m=1, form.lm=formula(Y ~ X3+X4+X5))
val.daag<-CVlm(df=training, m=1, form.lm=formula(Y ~ X4+X5+X7))

For the best selected model (the lowest MSE) I would like to perform an
external validation on 1 object left on the site at the beginning of the
study (please refer to point 1.).

3. And loop again using different training and test set ....


I hope that you could help me with this. 

If you have any suggestions how to select the best model and perform
validation more efficiently, I would be happy to hear about that.

Thank you !




--
View this message in context: http://r.789695.n4.nabble.com/How-to-write-a-loop-in-R-to-select-multiple-regression-model-and-validate-it-tp4668668.html
Sent from the R help mailing list archive at Nabble.com.


From paxkn at nottingham.ac.uk  Wed Jun  5 01:45:31 2013
From: paxkn at nottingham.ac.uk (beginner)
Date: Tue, 4 Jun 2013 16:45:31 -0700 (PDT)
Subject: [R] How to write a loop in R to select multiple regression model
 and validate it ?
Message-ID: <1370389531950-4668669.post@n4.nabble.com>

I would like to run a loop in R. I have never done this before, so I would be
very grateful for your help !

1. I have a sample set: 25 objects. I would like to draw 1 object from it
and use it as a test set for my future external validation. The remaining 24
objects I would like to use as a training set (to select a model). I would
like to repeat this process until all 25 objects are used as a test set. 

2. For each of the training sets I would like to run the following code:


library(leaps)
forward <- regsubsets(Y ~.,data = training, method = "forward", nbest=1) 
backward <- regsubsets(Y ~.,data = training, method = "backward", nbest=1)
stepwise <- regsubsets(Y ~., data = training, method = "seqrep", nbest=1)
exhaustive <- regsubsets(Y ~.,data = training, method = "forward", nbest=1)
summary(forward)
summary(backward)
summary(stepwise)
summary(exhaustive)

I would like R programme to select the best model (with the highest adjusted
R2) using each of the selection methods, so there are 4 final best models
(e.g. the best model selected with forward selection, the best model
selected with backward selection and so on...). 

 
Afterwards I would like to perform internal cross validation of all 4
selected models and choose 1 out of 4 which has the lowest average mean
squared error (MSE). I used to do it using the code below:

library(DAAG)
val.daag<-CVlm(df=training, m=1, form.lm=formula(Y ~ X1+X2+X3))
val.daag<-CVlm(df=training, m=1, form.lm=formula(Y ~ X1+X2+X4))
val.daag<-CVlm(df=training, m=1, form.lm=formula(Y ~ X3+X4+X5))
val.daag<-CVlm(df=training, m=1, form.lm=formula(Y ~ X4+X5+X7))

For the best selected model (the lowest MSE) I would like to perform an
external validation on 1 object left on the site at the beginning of the
study (please refer to point 1.).

3. And loop again using different training and test set ....


I hope that you could help me with this. 

If you have any suggestions how to select the best model and perform
validation more efficiently, I would be happy to hear about that.

Thank you !



--
View this message in context: http://r.789695.n4.nabble.com/How-to-write-a-loop-in-R-to-select-multiple-regression-model-and-validate-it-tp4668669.html
Sent from the R help mailing list archive at Nabble.com.


From jdnewmil at dcn.davis.CA.us  Wed Jun  5 02:12:00 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 04 Jun 2013 17:12:00 -0700
Subject: [R] How to write a loop in R to select multiple regression
	model and validate it ?
In-Reply-To: <1370389531950-4668669.post@n4.nabble.com>
References: <1370389531950-4668669.post@n4.nabble.com>
Message-ID: <397397cd-29d2-41e6-a9b4-aed842473850@email.android.com>

This doesn't look like a task you have acquired through a real-life problem... it looks like homework. There is a stated no-homework policy in the Posting Guide (please read it), since you should be using the resources provided along with your educational environment (teaching assistants, tutors, office hours...), and we don't know whether the help we provide would be considered "cheating".
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

beginner <paxkn at nottingham.ac.uk> wrote:

>I would like to run a loop in R. I have never done this before, so I
>would be
>very grateful for your help !
>
>1. I have a sample set: 25 objects. I would like to draw 1 object from
>it
>and use it as a test set for my future external validation. The
>remaining 24
>objects I would like to use as a training set (to select a model). I
>would
>like to repeat this process until all 25 objects are used as a test
>set. 
>
>2. For each of the training sets I would like to run the following
>code:
>
>
>library(leaps)
>forward <- regsubsets(Y ~.,data = training, method = "forward",
>nbest=1) 
>backward <- regsubsets(Y ~.,data = training, method = "backward",
>nbest=1)
>stepwise <- regsubsets(Y ~., data = training, method = "seqrep",
>nbest=1)
>exhaustive <- regsubsets(Y ~.,data = training, method = "forward",
>nbest=1)
>summary(forward)
>summary(backward)
>summary(stepwise)
>summary(exhaustive)
>
>I would like R programme to select the best model (with the highest
>adjusted
>R2) using each of the selection methods, so there are 4 final best
>models
>(e.g. the best model selected with forward selection, the best model
>selected with backward selection and so on...). 
>
> 
>Afterwards I would like to perform internal cross validation of all 4
>selected models and choose 1 out of 4 which has the lowest average mean
>squared error (MSE). I used to do it using the code below:
>
>library(DAAG)
>val.daag<-CVlm(df=training, m=1, form.lm=formula(Y ~ X1+X2+X3))
>val.daag<-CVlm(df=training, m=1, form.lm=formula(Y ~ X1+X2+X4))
>val.daag<-CVlm(df=training, m=1, form.lm=formula(Y ~ X3+X4+X5))
>val.daag<-CVlm(df=training, m=1, form.lm=formula(Y ~ X4+X5+X7))
>
>For the best selected model (the lowest MSE) I would like to perform an
>external validation on 1 object left on the site at the beginning of
>the
>study (please refer to point 1.).
>
>3. And loop again using different training and test set ....
>
>
>I hope that you could help me with this. 
>
>If you have any suggestions how to select the best model and perform
>validation more efficiently, I would be happy to hear about that.
>
>Thank you !
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/How-to-write-a-loop-in-R-to-select-multiple-regression-model-and-validate-it-tp4668669.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Wed Jun  5 02:14:32 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 4 Jun 2013 17:14:32 -0700 (PDT)
Subject: [R] dates and time series management
In-Reply-To: <1370384616.88390.YahooMailNeo@web160601.mail.bf1.yahoo.com>
References: <1370384616.88390.YahooMailNeo@web160601.mail.bf1.yahoo.com>
Message-ID: <1370391272.9589.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
May be this helps:
I duplicated your dataset (only one was attached) and changed the dates.


lstf1<- list.files(pattern=".txt")
lstf1
#[1] "dt3031093-1.txt" "dt3031093-2.txt" "dt3031093-3.txt"

#3rd one has less number of observations.


fun1<- function(lstf){
??? ?lst1<-lapply(lstf,function(x) read.table(x,sep="",header=TRUE,stringsAsFactors=FALSE))
??? ?lst2<- lapply(lst1,function(x) x[x$V1>=1961 & x$V1<=2005,])
??? ?lst3<- lapply(lst2,function(x) {
??? ??? ??? ??? ???? if((min(x$V1)>1961)|(max(x$V1)<2005)){
??? ??? ??? ??? ??? ??? ?n1<- (min(x$V1)-1961)*12
??? ??? ??? ??? ??? ??? ?x1<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n1))
??? ??? ??? ??? ??? ??? ?n2<- (2005-max(x$V1))*12
??? ??? ??? ??? ??? ??? ?x2<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n2))
??? ??? ??? ??? ??? ??? ?x3<- rbind(x1,x,x2)
??? ??? ??? ??? ??? ??? }
??? ??? ??? ????????????? else {
??? ??? ??? ??? ??? x
??? ??? ??? ??? ??? } })
??? ?lst4<- lapply(lst3,function(x) data.frame(col1=unlist(x[,-c(1:2)])))
??? ?lst5<- lapply(seq_along(lst4),function(i){
??? ??? ??? ??? ??? ??? x<- lst4[[i]]
??? ??? ??? ??? ??? ??? colnames(x)<- lstf[i]
??? ??? ??? ??? ??? ??? row.names(x)<- 1:nrow(x)
??? ??? ??? ??? ??? ??? x
??? ??? ??? ??? ??? ??? })
??????? lst5}
res<-fun1(lstf1)
?lapply(res,head,3)
#[[1]]
#? dt3031093-1.txt
#1??????????? 0.21
#2??????????? 0.00
#3??????????? 0.21
#
#[[2]]
#? dt3031093-2.txt
#1??????????? 0.21
#2??????????? 0.00
#3??????????? 0.21
#
#[[3]]
#? dt3031093-3.txt
#1????????????? NA
#2????????????? NA
#3????????????? NA

sapply(res,nrow)
#[1] 16740 16740 16740

A.K.


________________________________
From: Zilefac Elvis <zilefacelvis at yahoo.com>
To: "r-help at r-project.org" <r-help at r-project.org> 
Cc: "smartpink111 at yahoo.com" <smartpink111 at yahoo.com> 
Sent: Tuesday, June 4, 2013 6:23 PM
Subject: dates and time series management



Hi,
I have 100 files (4 attached for your reference) with different file names,
different start and end dates. Years and months occupy 1st and 2nd columns while days occupy the rest of the 33 columns in each file.

If date starts before 1961 and ends after 2005, extract all rows between 1961 to 2005 in all 100 files,
else, if date starts after 1961 and does not go up till 2005,?retain?the values as they are, then generate a date vector "%Y-%m" from 1961 to 2005 and fill spaces without values using 'NA'. For example, in one file I have data from 1970 to 2000. I would like to generate dates from 1961 to 2005, fill 1961-1966, and 2001-2005 with 'NA'. Do same for all 100 files.

After doing the extracting and replacing, all files will have a common date window (1961-2005).
Now, delete year and month from each file (i.e. first two columns in each file) and convert each file to as.vector (column vector. i.e take column 4 and place under column 3 etc). My expected output would then be 100 files each having a column vector.

Finally, I would like to use the original file names as the resulting column names for each file. Then combine all 100 files in a data.frame

Using 4 files, final output should be 'equal rows * 4 columns', e.g 16354 rows * 4 columns, say.

Thanks so much.

Atem?


From smartpink111 at yahoo.com  Wed Jun  5 03:57:00 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 4 Jun 2013 18:57:00 -0700 (PDT)
Subject: [R] dates and time series management
In-Reply-To: <1370391272.9589.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1370384616.88390.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1370391272.9589.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <1370397420.70765.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Forgot that you wanted the result in a data.frame
fun1<- function(lstf){
???? lst1<-lapply(lstf,function(x) read.table(x,sep="",header=TRUE,stringsAsFactors=FALSE))
???? lst2<- lapply(lst1,function(x) x[x$V1>=1961 & x$V1<=2005,])
???? lst3<- lapply(lst2,function(x) {
???????????????????? if((min(x$V1)>1961)|(max(x$V1)<2005)){
???????????????????????? n1<- (min(x$V1)-1961)*12
???????????????????????? x1<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n1))
???????????????????????? n2<- (2005-max(x$V1))*12
???????????????????????? x2<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n2))
???????????????????????? x3<- rbind(x1,x,x2)
??????????????????????? }
????????????????????????? else {
??????????????????? x
??????????????????? } })
???? lst4<- lapply(lst3,function(x) data.frame(col1=unlist(x[,-c(1:2)])))
???? lst5<- lapply(seq_along(lst4),function(i){
??????????????????????? x<- lst4[[i]]
??????????????????????? colnames(x)<- lstf[i]
??????????????????????? row.names(x)<- 1:nrow(x)
??????????????????????? x
??????????????????????? })
??????? do.call(cbind,lst5)}
res<-fun1(lstf1)
?head(res)
#? dt3031093-1.txt dt3031093-2.txt dt3031093-3.txt
#1??????????? 0.21??????????? 0.21????????????? NA
#2??????????? 0.00??????????? 0.00????????????? NA
#3??????????? 0.21??????????? 0.21????????????? NA
#4??????????? 0.00??????????? 0.00????????????? NA
#5??????????? 0.00??????????? 0.00????????????? NA
#6??????????? 0.00??????????? 0.00????????????? NA
?dim(res)
#[1] 16740???? 3
(2005-1960)*12*31
#[1] 16740

A.K.




----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Zilefac Elvis <zilefacelvis at yahoo.com>
Cc: R help <r-help at r-project.org>
Sent: Tuesday, June 4, 2013 8:14 PM
Subject: Re: dates and time series management

Hi,
May be this helps:
I duplicated your dataset (only one was attached) and changed the dates.


lstf1<- list.files(pattern=".txt")
lstf1
#[1] "dt3031093-1.txt" "dt3031093-2.txt" "dt3031093-3.txt"

#3rd one has less number of observations.


fun1<- function(lstf){
??? ?lst1<-lapply(lstf,function(x) read.table(x,sep="",header=TRUE,stringsAsFactors=FALSE))
??? ?lst2<- lapply(lst1,function(x) x[x$V1>=1961 & x$V1<=2005,])
??? ?lst3<- lapply(lst2,function(x) {
??? ??? ??? ??? ???? if((min(x$V1)>1961)|(max(x$V1)<2005)){
??? ??? ??? ??? ??? ??? ?n1<- (min(x$V1)-1961)*12
??? ??? ??? ??? ??? ??? ?x1<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n1))
??? ??? ??? ??? ??? ??? ?n2<- (2005-max(x$V1))*12
??? ??? ??? ??? ??? ??? ?x2<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n2))
??? ??? ??? ??? ??? ??? ?x3<- rbind(x1,x,x2)
??? ??? ??? ??? ??? ??? }
??? ??? ??? ????????????? else {
??? ??? ??? ??? ??? x
??? ??? ??? ??? ??? } })
??? ?lst4<- lapply(lst3,function(x) data.frame(col1=unlist(x[,-c(1:2)])))
??? ?lst5<- lapply(seq_along(lst4),function(i){
??? ??? ??? ??? ??? ??? x<- lst4[[i]]
??? ??? ??? ??? ??? ??? colnames(x)<- lstf[i]
??? ??? ??? ??? ??? ??? row.names(x)<- 1:nrow(x)
??? ??? ??? ??? ??? ??? x
??? ??? ??? ??? ??? ??? })
??????? lst5}
res<-fun1(lstf1)
?lapply(res,head,3)
#[[1]]
#? dt3031093-1.txt
#1??????????? 0.21
#2??????????? 0.00
#3??????????? 0.21
#
#[[2]]
#? dt3031093-2.txt
#1??????????? 0.21
#2??????????? 0.00
#3??????????? 0.21
#
#[[3]]
#? dt3031093-3.txt
#1????????????? NA
#2????????????? NA
#3????????????? NA

sapply(res,nrow)
#[1] 16740 16740 16740

A.K.


________________________________
From: Zilefac Elvis <zilefacelvis at yahoo.com>
To: "r-help at r-project.org" <r-help at r-project.org> 
Cc: "smartpink111 at yahoo.com" <smartpink111 at yahoo.com> 
Sent: Tuesday, June 4, 2013 6:23 PM
Subject: dates and time series management



Hi,
I have 100 files (4 attached for your reference) with different file names,
different start and end dates. Years and months occupy 1st and 2nd columns while days occupy the rest of the 33 columns in each file.

If date starts before 1961 and ends after 2005, extract all rows between 1961 to 2005 in all 100 files,
else, if date starts after 1961 and does not go up till 2005,?retain?the values as they are, then generate a date vector "%Y-%m" from 1961 to 2005 and fill spaces without values using 'NA'. For example, in one file I have data from 1970 to 2000. I would like to generate dates from 1961 to 2005, fill 1961-1966, and 2001-2005 with 'NA'. Do same for all 100 files.

After doing the extracting and replacing, all files will have a common date window (1961-2005).
Now, delete year and month from each file (i.e. first two columns in each file) and convert each file to as.vector (column vector. i.e take column 4 and place under column 3 etc). My expected output would then be 100 files each having a column vector.

Finally, I would like to use the original file names as the resulting column names for each file. Then combine all 100 files in a data.frame

Using 4 files, final output should be 'equal rows * 4 columns', e.g 16354 rows * 4 columns, say.

Thanks so much.

Atem?


From santosh2005 at gmail.com  Wed Jun  5 04:39:05 2013
From: santosh2005 at gmail.com (Santosh)
Date: Tue, 4 Jun 2013 19:39:05 -0700
Subject: [R] Expression evaluation of Plotting labels containing spaces
Message-ID: <CAN_e6Xsb_WBW=yOAs+Zf=TnziCSOiFbGh2nk4bZ=8_m6cv=hnw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130604/2ff373c8/attachment.pl>

From kridox at ymail.com  Wed Jun  5 04:48:49 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Wed, 05 Jun 2013 11:48:49 +0900
Subject: [R] Expression evaluation of Plotting labels containing spaces
In-Reply-To: <CAN_e6Xsb_WBW=yOAs+Zf=TnziCSOiFbGh2nk4bZ=8_m6cv=hnw@mail.gmail.com>
References: <CAN_e6Xsb_WBW=yOAs+Zf=TnziCSOiFbGh2nk4bZ=8_m6cv=hnw@mail.gmail.com>
Message-ID: <51AEA711.1080109@ymail.com>

Hello,

Example not reproducible:

 > exc <- list(units=list( c(m^2)) ,vars= list(c('asb')), ,label= 
list(c('abs surf body')))

Error: object 'm' not found

Regards,
Pascal


On 05/06/13 11:39, Santosh wrote:
> Dear Rxperts,
> How do I overcome the anomaly as in the second case of examples below?
>
> exc <- list(units=list( c(m^2)) ,vars= list(c('asb')), ,label= list(c('abs
> surf body')))
>
> plot(1:10,1:10, ylab=parse(text= paste(exc$vars[1],'
> (',exc$units[1],')',sep='')))
>
> plot(1:10,1:10, ylab=parse(text= paste(exc$label[1],'
> (',exc$units[1],')',sep='')))
>
> Thanks so much!
>
> Santosh
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From juliosergio at gmail.com  Wed Jun  5 04:53:11 2013
From: juliosergio at gmail.com (Julio Sergio)
Date: Wed, 5 Jun 2013 02:53:11 +0000
Subject: [R] Trying to build up functions with its names by means of lapply
Message-ID: <loom.20130605T043218-210@post.gmane.org>

I want to generate specific gamma distribution functions, given fixed 
parameters. 
This is I have k, and theta, say

   k <- 32.2549       # shape
   theta <- 26.32809  # scale


   # I have an auxiliary function that produces funcions according to 
   # a given character (this is to have either dgamma, pgamma or qgamma)
   # for the specific parameters given above:

   faux <- function(c) {
     function (x) get(paste0(c,"gamma"))(x,k,scale=theta)
   }

   # So I can have, for instance, dgamma, and pgamma with

   dff <- faux("d")
   pff <- faux("p")

   dff(1000)
   ## [1] 0.001433138

   pff(1000)
   ## [1] 0.844305

Now, if I try to produce both functions in one shot with lapply, the thing 
doesn't work, see

   ffs <- lapply(c("d", "p"), faux)

   ffs[[1]](1000)
   ## [1] 0.844305 

   ffs[[2]](1000)
   ## [1] 0.844305 
 
The two produced functions are the very same and correspond to pgamma!!
Maybe I'm missing something. Do you have any idea?

Thanks,

  -Sergio.


From zilefacelvis at yahoo.com  Wed Jun  5 05:03:43 2013
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Tue, 4 Jun 2013 20:03:43 -0700 (PDT)
Subject: [R] dates and time series management
In-Reply-To: <1370397420.70765.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1370384616.88390.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1370391272.9589.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1370397420.70765.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1370401423.51446.YahooMailNeo@web160601.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130604/eb5dddf1/attachment.pl>

From ivo.welch at gmail.com  Wed Jun  5 06:08:18 2013
From: ivo.welch at gmail.com (ivo welch)
Date: Tue, 4 Jun 2013 21:08:18 -0700
Subject: [R] read.csv and write.csv filtering for very big data ?
In-Reply-To: <CAFEqCdy7tYgY_DYtovOewfFXzuRWH2XxKYyuqf8BMAzdWOwDqw@mail.gmail.com>
References: <CAPr7RtW3fX73N5NZRQbuN7M+PFJHzXo0L1VuMLih1P2Uz5Gx5g@mail.gmail.com>
	<CAFEqCdy7tYgY_DYtovOewfFXzuRWH2XxKYyuqf8BMAzdWOwDqw@mail.gmail.com>
Message-ID: <CAPr7RtVYb-FFNDv4=JA+RP5XNor4Tg_6jLf5hY44NfUuAVyZ5w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130604/8049b6ad/attachment.pl>

From kridox at ymail.com  Wed Jun  5 06:08:48 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Wed, 05 Jun 2013 13:08:48 +0900
Subject: [R] Expression evaluation of Plotting labels containing spaces
In-Reply-To: <CAN_e6Xsb_WBW=yOAs+Zf=TnziCSOiFbGh2nk4bZ=8_m6cv=hnw@mail.gmail.com>
References: <CAN_e6Xsb_WBW=yOAs+Zf=TnziCSOiFbGh2nk4bZ=8_m6cv=hnw@mail.gmail.com>
Message-ID: <51AEB9D0.5010008@ymail.com>

Hi,

On possibility is:

par(mfrow=c(2,1), mar=c(5.1,5.1,4.1,2.1))
plot(1,1, ylab=expression(a.s.b.~(m^2)))
plot(1,1, ylab=expression(abs~surf~body~(m^2)))

Regards,
Pascal

On 05/06/13 11:39, Santosh wrote:
> Dear Rxperts,
> How do I overcome the anomaly as in the second case of examples below?
>
> exc <- list(units=list( c(m^2)) ,vars= list(c('asb')), ,label= list(c('abs
> surf body')))
>
> plot(1:10,1:10, ylab=parse(text= paste(exc$vars[1],'
> (',exc$units[1],')',sep='')))
>
> plot(1:10,1:10, ylab=parse(text= paste(exc$label[1],'
> (',exc$units[1],')',sep='')))
>
> Thanks so much!
>
> Santosh
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Wed Jun  5 06:13:50 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 4 Jun 2013 22:13:50 -0600
Subject: [R] Expression evaluation of Plotting labels containing spaces
In-Reply-To: <CAN_e6Xsb_WBW=yOAs+Zf=TnziCSOiFbGh2nk4bZ=8_m6cv=hnw@mail.gmail.com>
References: <CAN_e6Xsb_WBW=yOAs+Zf=TnziCSOiFbGh2nk4bZ=8_m6cv=hnw@mail.gmail.com>
Message-ID: <61223B18-5722-400C-A44D-3236D112F649@comcast.net>


On Jun 4, 2013, at 8:39 PM, Santosh wrote:

> Dear Rxperts,
> How do I overcome the anomaly as in the second case of examples below?
>
> exc <- list(units=list( c(m^2)) ,vars= list(c('asb')), ,label=  
> list(c('abs
> surf body')))
>
> plot(1:10,1:10, ylab=parse(text= paste(exc$vars[1],'
> (',exc$units[1],')',sep='')))
>
> plot(1:10,1:10, ylab=parse(text= paste(exc$label[1],'
> (',exc$units[1],')',sep='')))

Mail client mangled this due entirely to your improper use HTML. You  
have been posting to Rhelp long enough to have had plenty of  
opportunity to read the Posting Guide. And I know for a fact that it  
is quite easy to send plain text using gmail. You have no legitimate  
excuse for continuing this deprecated practice.

Anyway,  running this code:

exc <- list(units=list( c("m^2")) ,vars= list(c('asb')), label=  
list(c('abs surf body')))
# Notice that I quoted the 'units' value
plot(1:10,1:10, ylab=parse(text= paste(exc$vars[1],'(',exc 
$units[1],')',sep='')))
# Also note that plotmath cannot handle embedded carriage returns
plot(1:10,1:10, ylab=parse(text= paste(exc$label[1],'(',exc 
$units[1],')',sep='')))

Produces this error:

Error in parse(text = paste(exc$label[1], "(", exc$units[1], ")", sep  
= "")) :
   <text>:1:5: unexpected symbol
1: abs surf
        ^
(You are asked in the Posting Guide exactly your code and also to post  
your error messages.)

So you are trying to parse an expression and the parser is expecting a  
comma or a tilde or  .... something other than the beginning of  
another token. You never said what you actually wanted (also a request  
in the Posting Guide),  but try adding tilde's:

exc <- list(units=list( c("m^2")) ,vars= list(c('asb')), label=  
list(c('abs~surf~body')))

plot(1:10,1:10, ylab=parse(text= paste(exc$vars[1],'(',exc 
$units[1],')',sep='')))

plot(1:10,1:10, ylab=parse(text= paste(exc$label[1],'(',exc 
$units[1],')',sep='')))

I know that the plotmath help page is not exactly the most expansive  
regarding how to form proper expressions for R but at least review it  
and run the examples:

?plotmath

-- 
David.

>
> Thanks so much!
>
> Santosh
>
> 	[[alternative HTML version deleted]]

Sigh.
>
>
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
^ 
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> and provide commented, minimal, self-contained, reproducible code.


---
David Winsemius, MD
Alameda, CA, USA


From hwborchers at googlemail.com  Wed Jun  5 06:15:41 2013
From: hwborchers at googlemail.com (Hans W Borchers)
Date: Wed, 5 Jun 2013 04:15:41 +0000
Subject: [R] how to compute maximum of fitted polynomial?
References: <BLU171-W3008743CA8E23E4C29E050D89E0@phx.gbl>
	<51AE6174.30103@sapo.pt>
	<CACk-te16ReaLbN5amRL63tbn=3DBgbEZwBNMHa7TANPveY4HWQ@mail.gmail.com>
Message-ID: <loom.20130605T060711-422@post.gmane.org>

Bert Gunter <gunter.berton <at> gene.com> writes:
> 
> 1. This looks like a homework question. We should not do homework here.
> 2. optim() will only approximate the max.
> 3. optim() is not the right numerical tool for this anyway. optimize() is.
> 4. There is never a guarantee numerical methods will find the max.
> 5. This can (and should?) be done exactly using elementary math rather
> than numerical methods.
> 
> Cheers,
> Bert

In the case of polynomials, "elementary math ... methods" can actually be
executed with R:

    library(polynomial)                 # -6 + 11*x - 6*x^2 + x^3
    p0 <- polynomial(c(-6, 11, -6, 1))  # has zeros at 1, 2, and 3
    p1 <- deriv(p0); p2 <- deriv(p1)    # first and second derivative
    xm <- solve(p1)                     # maxima and minima of p0
    xmax = xm[predict(p2, xm) < 0]      # select the maxima
    xmax                                # [1] 1.42265

Obviously, the same procedure will work for polynomials p0 of higher orders.

Hans Werner


> > Em 04-06-2013 21:32, Joseph Clark escreveu:
> >>
> >> My script fits a third-order polynomial to my data with something like
> >> this:
> >>
> >> model <- lm( y ~ poly(x, 3) )
> >>
> >> What I'd like to do is find the theoretical maximum of the polynomial
> >> (i.e. the x at which "model" predicts the highest y).  Specifically, I'd
> >> like to predict the maximum between 0 <= x <= 1.
> >>
> >> What's the best way to accomplish that in R?
> >>
> >> Bonus question: can R give me the derivative or 2nd derivative of the
> >> polynomial?  I'd like to be able to compute these at that maximum point.
> >>
> >> Thanks in advance!
> >>
> >>
> >> // joseph w. clark , phd , visiting research associate
> >> \\ university of nebraska at omaha - college of IS&T


From kota.hattori at canterbury.ac.nz  Wed Jun  5 00:46:16 2013
From: kota.hattori at canterbury.ac.nz (Kota Hattori)
Date: Wed, 05 Jun 2013 10:46:16 +1200
Subject: [R] Post hoc power analysis for mixed-effects models
Message-ID: <482B1843EE6C72459D3BD633C43679EA04447F54@ucexchange2.canterbury.ac.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130605/ed707ecc/attachment.pl>

From nilsson.henric at gmail.com  Tue Jun  4 21:54:13 2013
From: nilsson.henric at gmail.com (Henric Winell)
Date: Tue, 04 Jun 2013 21:54:13 +0200
Subject: [R] installing package 'rqpd' (Regression quantiles for panel
 data)
In-Reply-To: <51ACA5FD.5060404@mtu.edu>
References: <51ACA5FD.5060404@mtu.edu>
Message-ID: <51AE45E5.3060301@gmail.com>

Manish,

Manish K. Srivastava skrev 2013-06-03 16:19:
> Hello R community members,
>
> I'm trying to install the 'rqpd' package which is developed by Roger
> Koenker and Stefan Bache. When I try to install the package using the
> command 'install.packages("rqpd",repos="http://R-Forge.R-project.org")'
> I'm getting the following two messages:
>
> i) package ?rqpd? is available as a source package but not as a binary
> ii) package ?rqpd? is not available (for R version 3.0.1)

Are you using Windows or OS X?  R-Forge doesn't currently provide 
binaries for OS X.

> On checking the Log of /pkg on the r-forge.r.project.org website, I find
> that the package was last modified on May 8,2012 and was made compatible
> with R>2.14.
>
> "Quick fix to make it compile for R >= 2.14"
>
>
> So, in another attempt, I downloaded the older version of R (2.14) to
> see if the 'rqpd' package could be installed using the older version,
> but still I had no luck.

That's because R-Forge no longer provide binaries for 2.14.x.

>
>
> Is there any way I could still use this package?

Binaries seem to be available for 2.15.x.  Alternatively, you can always 
build from source and that'll work for 3.0.x.


HTH,
Henric



>
>
> Thank you for your help.
>
> Best regards,
>
> Manish
>
>


From armel.kaptue at sdstate.edu  Tue Jun  4 23:05:45 2013
From: armel.kaptue at sdstate.edu (Kaptue Tchuente, Armel)
Date: Tue, 4 Jun 2013 21:05:45 +0000
Subject: [R] How to display multiples lines with different color on the same
 plot?
Message-ID: <9879AF1F439EF943BDEE22D3AAA5C3F683FBD675@sdsu-ex01.jacks.local>

Hi all,

I'm struggling with the display of several regression lines (with different colors) on the same plot.

I manually drew what I'm trying to do with 8 lines (see attached).

Any thoughts for a code will be very much appreciated.

Thanks

Armel

-------------- next part --------------
A non-text attachment was scrubbed...
Name: multiple_lines_graph.png
Type: image/png
Size: 15005 bytes
Desc: multiple_lines_graph.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130604/3ebaad2c/attachment.png>

From zilefacelvis at yahoo.com  Wed Jun  5 00:23:36 2013
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Tue, 4 Jun 2013 15:23:36 -0700 (PDT)
Subject: [R] dates and time series management
Message-ID: <1370384616.88390.YahooMailNeo@web160601.mail.bf1.yahoo.com>

Hi,
I have 100 files (4 attached for your reference) with different file names,
different start and end dates. Years and months occupy 1st and 2nd columns while days occupy the rest of the 33 columns in each file.

If date starts before 1961 and ends after 2005, extract all rows between 1961 to 2005 in all 100 files,
else, if date starts after 1961 and does not go up till 2005,?retain?the values as they are, then generate a date vector "%Y-%m" from 1961 to 2005 and fill spaces without values using 'NA'. For example, in one file I have data from 1970 to 2000. I would like to generate dates from 1961 to 2005, fill 1961-1966, and 2001-2005 with 'NA'. Do same for all 100 files.

After doing the extracting and replacing, all files will have a common date window (1961-2005).
Now, delete year and month from each file (i.e. first two columns in each file) and convert each file to as.vector (column vector. i.e take column 4 and place under column 3 etc). My expected output would then be 100 files each having a column vector.

Finally, I would like to use the original file names as the resulting column names for each file. Then combine all 100 files in a data.frame

Using 4 files, final output should be 'equal rows * 4 columns', e.g 16354 rows * 4 columns, say.

Thanks so much.
?
Atem
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: dt3031093.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130604/b1496dc3/attachment.txt>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: dt3031400.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130604/b1496dc3/attachment-0001.txt>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: dt3032800.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130604/b1496dc3/attachment-0002.txt>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: dt3033880.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130604/b1496dc3/attachment-0003.txt>

From laomeng_3 at 163.com  Wed Jun  5 03:26:12 2013
From: laomeng_3 at 163.com (meng)
Date: Wed, 5 Jun 2013 09:26:12 +0800 (CST)
Subject: [R] error about MCA
In-Reply-To: <024c01ce612f$7de65f90$79b31eb0$@tamu.edu>
References: <437ecacf.7226.13f00437ae1.Coremail.laomeng_3@163.com>
	<011501ce6061$efba47e0$cf2ed7a0$@tamu.edu>
	<10b8e421.15187.13f0ce491cd.Coremail.laomeng_3@163.com>
	<024c01ce612f$7de65f90$79b31eb0$@tamu.edu>
Message-ID: <4719e995.2ce2.13f11f0f88f.Coremail.laomeng_3@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130605/0398ef84/attachment.pl>

From mmuurr at gmail.com  Wed Jun  5 07:33:07 2013
From: mmuurr at gmail.com (Murat Tasan)
Date: Wed, 5 Jun 2013 01:33:07 -0400
Subject: [R] plyr _aply simplifying return-value dimensions
Message-ID: <CA+YV+Hw8BokEV88q6m=aht8HgLpszcQ1tEE9vHZSqRRREZwAbA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130605/0c580757/attachment.pl>

From santosh2005 at gmail.com  Wed Jun  5 08:00:06 2013
From: santosh2005 at gmail.com (Santosh)
Date: Tue, 4 Jun 2013 23:00:06 -0700
Subject: [R] Expression evaluation of Plotting labels containing spaces
In-Reply-To: <61223B18-5722-400C-A44D-3236D112F649@comcast.net>
References: <CAN_e6Xsb_WBW=yOAs+Zf=TnziCSOiFbGh2nk4bZ=8_m6cv=hnw@mail.gmail.com>
	<61223B18-5722-400C-A44D-3236D112F649@comcast.net>
Message-ID: <CAN_e6XufOZBsBPVNKWLGg7pWKyyzRf5Cs=L+YXHPF+POQXK=KQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130604/0c151830/attachment.pl>

From michael.weylandt at gmail.com  Wed Jun  5 08:13:23 2013
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Wed, 5 Jun 2013 07:13:23 +0100
Subject: [R] Trying to build up functions with its names by means of
	lapply
In-Reply-To: <loom.20130605T043218-210@post.gmane.org>
References: <loom.20130605T043218-210@post.gmane.org>
Message-ID: <250F03A2-77CE-4FAC-B1C9-6754567A3F6A@gmail.com>



On Jun 5, 2013, at 3:53, Julio Sergio <juliosergio at gmail.com> wrote:

> I want to generate specific gamma distribution functions, given fixed 
> parameters. 
> This is I have k, and theta, say
> 
>   k <- 32.2549       # shape
>   theta <- 26.32809  # scale
> 
> 
>   # I have an auxiliary function that produces funcions according to 
>   # a given character (this is to have either dgamma, pgamma or qgamma)
>   # for the specific parameters given above:
> 
>   faux <- function(c) {
>     function (x) get(paste0(c,"gamma"))(x,k,scale=theta)
>   }
> 
>   # So I can have, for instance, dgamma, and pgamma with
> 
>   dff <- faux("d")
>   pff <- faux("p")
> 
>   dff(1000)
>   ## [1] 0.001433138
> 
>   pff(1000)
>   ## [1] 0.844305
> 
> Now, if I try to produce both functions in one shot with lapply, the thing 
> doesn't work, see
> 
>   ffs <- lapply(c("d", "p"), faux)
> 
>   ffs[[1]](1000)
>   ## [1] 0.844305 
> 
>   ffs[[2]](1000)
>   ## [1] 0.844305 
> 
> The two produced functions are the very same and correspond to pgamma!!
> Maybe I'm missing something. Do you have any idea?

I think you are hitting a bit of strangeness R generously calls 'lazy evaluation'.  I'm afraid I don't have a reference at hand, but search the archives for mention of the promise mechanism. 

MW

> 
> Thanks,
> 
>  -Sergio.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kridox at ymail.com  Wed Jun  5 08:14:47 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Wed, 05 Jun 2013 15:14:47 +0900
Subject: [R] Expression evaluation of Plotting labels containing spaces
In-Reply-To: <CAN_e6XufOZBsBPVNKWLGg7pWKyyzRf5Cs=L+YXHPF+POQXK=KQ@mail.gmail.com>
References: <CAN_e6Xsb_WBW=yOAs+Zf=TnziCSOiFbGh2nk4bZ=8_m6cv=hnw@mail.gmail.com>
	<61223B18-5722-400C-A44D-3236D112F649@comcast.net>
	<CAN_e6XufOZBsBPVNKWLGg7pWKyyzRf5Cs=L+YXHPF+POQXK=KQ@mail.gmail.com>
Message-ID: <51AED757.1010503@ymail.com>

Hello,

?plotmath -> See Also
demo(plotmath)

Regards,
Pascal


On 05/06/13 15:00, Santosh wrote:
> Thanks so much!!
> Would be it be better if in vignette of plotmath, x %~% y and x~~y;
> likewise, other operations (.e.g.,
>   x %*% y, x * y) may be grouped, so that are not missed by a layman like
> me! - just a thought...
>
> Thanks,
> Santosh
>
>
>
>
> On Tue, Jun 4, 2013 at 9:13 PM, David Winsemius <dwinsemius at comcast.net>wrote:
>
>>
>> On Jun 4, 2013, at 8:39 PM, Santosh wrote:
>>
>>   Dear Rxperts,
>>> How do I overcome the anomaly as in the second case of examples below?
>>>
>>> exc <- list(units=list( c(m^2)) ,vars= list(c('asb')), ,label= list(c('abs
>>> surf body')))
>>>
>>> plot(1:10,1:10, ylab=parse(text= paste(exc$vars[1],'
>>> (',exc$units[1],')',sep='')))
>>>
>>> plot(1:10,1:10, ylab=parse(text= paste(exc$label[1],'
>>> (',exc$units[1],')',sep='')))
>>>
>>
>> Mail client mangled this due entirely to your improper use HTML. You have
>> been posting to Rhelp long enough to have had plenty of opportunity to read
>> the Posting Guide. And I know for a fact that it is quite easy to send
>> plain text using gmail. You have no legitimate excuse for continuing this
>> deprecated practice.
>>
>> Anyway,  running this code:
>>
>> exc <- list(units=list( c("m^2")) ,vars= list(c('asb')), label=
>> list(c('abs surf body')))
>> # Notice that I quoted the 'units' value
>>
>> plot(1:10,1:10, ylab=parse(text= paste(exc$vars[1],'(',exc$**
>> units[1],')',sep='')))
>> # Also note that plotmath cannot handle embedded carriage returns
>>
>> plot(1:10,1:10, ylab=parse(text= paste(exc$label[1],'(',exc$**
>> units[1],')',sep='')))
>>
>> Produces this error:
>>
>> Error in parse(text = paste(exc$label[1], "(", exc$units[1], ")", sep =
>> "")) :
>>    <text>:1:5: unexpected symbol
>> 1: abs surf
>>         ^
>> (You are asked in the Posting Guide exactly your code and also to post
>> your error messages.)
>>
>> So you are trying to parse an expression and the parser is expecting a
>> comma or a tilde or  .... something other than the beginning of another
>> token. You never said what you actually wanted (also a request in the
>> Posting Guide),  but try adding tilde's:
>>
>> exc <- list(units=list( c("m^2")) ,vars= list(c('asb')), label=
>> list(c('abs~surf~body')))
>>
>>
>> plot(1:10,1:10, ylab=parse(text= paste(exc$vars[1],'(',exc$**
>> units[1],')',sep='')))
>>
>> plot(1:10,1:10, ylab=parse(text= paste(exc$label[1],'(',exc$**
>> units[1],')',sep='')))
>>
>> I know that the plotmath help page is not exactly the most expansive
>> regarding how to form proper expressions for R but at least review it and
>> run the examples:
>>
>> ?plotmath
>>
>> --
>> David.
>>
>>
>>
>>> Thanks so much!
>>>
>>> Santosh
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>
>> Sigh.
>>
>>
>>>
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>>> PLEASE do read the posting guide http://www.R-project.org/**
>>> posting-guide.html <http://www.R-project.org/posting-guide.html>
>>>
>> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^**^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^**
>> ^^^^^^^^^^^^^
>>
>>   and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>> ---
>> David Winsemius, MD
>> Alameda, CA, USA
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Xochitl.Cormon at ifremer.fr  Wed Jun  5 10:37:16 2013
From: Xochitl.Cormon at ifremer.fr (Xochitl CORMON)
Date: Wed, 05 Jun 2013 10:37:16 +0200
Subject: [R] Loop FOR with histogram()  from lattice
In-Reply-To: <CAJdZ_fkf6TnRT+Yj=XRO-Eb9CusYEOFuHna4SrULj8m98pcXaA@mail.gmail.com>
References: <CAJdZ_fkf6TnRT+Yj=XRO-Eb9CusYEOFuHna4SrULj8m98pcXaA@mail.gmail.com>
Message-ID: <51AEF8BC.3060003@ifremer.fr>

Hi all,

I'm encountering a problem I do not understand on my data:

library (lattice)

Mpool1 <- Table[Table$Subarea %in% c("52E9", "51E9"),]
Mpool2 <- Table[Table$Subarea %in% c("53F0", "52F0"),]
Mpool3 <- Table[Table$Subarea %in% c("51F0", "50F0"),]
Mpool4 <- Table[Table$Subarea %in% c("51F1", "52F1"),]

Mpool <- list(Mpool1, Mpool2, Mpool3, Mpool4)


histogram(~ Mpool[[2]]$LngtClas | Mpool[[2]]$SpCode, type = "count", col 
= "lightgrey", xlab= "LngtClas", main = paste("Length distribution per 
species for Mpool", "2", sep = "_"))

#### This part works perfectly and I obtain the graph reprensenting 
Mpool2 length class count per species.
#### Now when I want to automatize this with a "for" loop nothing is 
plotted.

for (i in c(2)){
windows()
histogram(~ Mpool[[i]]$LngtClas | Mpool[[i]]$SpCode, type = "count", col 
= "lightgrey", xlab= "LngtClas", main = paste("Length distribution per 
species for Mpool", i, sep = "_"))
print (i)
}

### Running this loop I obtained  windows filled grey (no plot drawn at 
all) but the print (i) print a "2" as expected. I really dont understand 
what's wrong with the loop. There is no error message and no 
notification in R. You can find enclosed my data in txt file.

Thank you very much for any help,

Xochitl C.

<>< <>< <>< <><

Xochitl CORMON
+33 (0)3 21 99 56 84

Doctorante en sciences halieutiques
PhD student in fishery sciences

<>< <>< <>< <><

IFREMER
Centre Manche Mer du Nord
150 quai Gambetta
62200 Boulogne-sur-Mer

<>< <>< <>< <><

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Table.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130605/4df6b793/attachment.txt>

From Gerrit.Eichner at math.uni-giessen.de  Wed Jun  5 10:52:42 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Wed, 5 Jun 2013 10:52:42 +0200 (MEST)
Subject: [R] Loop FOR with histogram() from lattice
In-Reply-To: <51AEF8BC.3060003@ifremer.fr>
References: <CAJdZ_fkf6TnRT+Yj=XRO-Eb9CusYEOFuHna4SrULj8m98pcXaA@mail.gmail.com>
	<51AEF8BC.3060003@ifremer.fr>
Message-ID: <Pine.SOC.4.64.1306051051020.17608@solcom.hrz.uni-giessen.de>

Hi, Xochitl,

wrapping the call to histogram() inside your loop in a call to print() 
should solve your problem:

print( histogram( .....))


  Regards --  Gerrit


On Wed, 5 Jun 2013, Xochitl CORMON wrote:

> Hi all,
>
> I'm encountering a problem I do not understand on my data:
>
> library (lattice)
>
> Mpool1 <- Table[Table$Subarea %in% c("52E9", "51E9"),]
> Mpool2 <- Table[Table$Subarea %in% c("53F0", "52F0"),]
> Mpool3 <- Table[Table$Subarea %in% c("51F0", "50F0"),]
> Mpool4 <- Table[Table$Subarea %in% c("51F1", "52F1"),]
>
> Mpool <- list(Mpool1, Mpool2, Mpool3, Mpool4)
>
>
> histogram(~ Mpool[[2]]$LngtClas | Mpool[[2]]$SpCode, type = "count", col = 
> "lightgrey", xlab= "LngtClas", main = paste("Length distribution per species 
> for Mpool", "2", sep = "_"))
>
> #### This part works perfectly and I obtain the graph reprensenting Mpool2 
> length class count per species.
> #### Now when I want to automatize this with a "for" loop nothing is plotted.
>
> for (i in c(2)){
> windows()
> histogram(~ Mpool[[i]]$LngtClas | Mpool[[i]]$SpCode, type = "count", col = 
> "lightgrey", xlab= "LngtClas", main = paste("Length distribution per species 
> for Mpool", i, sep = "_"))
> print (i)
> }
>
> ### Running this loop I obtained  windows filled grey (no plot drawn at all) 
> but the print (i) print a "2" as expected. I really dont understand what's 
> wrong with the loop. There is no error message and no notification in R. You 
> can find enclosed my data in txt file.
>
> Thank you very much for any help,
>
> Xochitl C.
>
> <>< <>< <>< <><
>
> Xochitl CORMON
> +33 (0)3 21 99 56 84
>
> Doctorante en sciences halieutiques
> PhD student in fishery sciences
>
> <>< <>< <>< <><
>
> IFREMER
> Centre Manche Mer du Nord
> 150 quai Gambetta
> 62200 Boulogne-sur-Mer
>
> <>< <>< <>< <><
>


From jholtman at gmail.com  Wed Jun  5 10:55:23 2013
From: jholtman at gmail.com (Jim Holtman)
Date: Wed, 5 Jun 2013 04:55:23 -0400
Subject: [R] Loop FOR with histogram()  from lattice
In-Reply-To: <51AEF8BC.3060003@ifremer.fr>
References: <CAJdZ_fkf6TnRT+Yj=XRO-Eb9CusYEOFuHna4SrULj8m98pcXaA@mail.gmail.com>
	<51AEF8BC.3060003@ifremer.fr>
Message-ID: <DF250247-D09F-45B3-8C05-815543B2734E@gmail.com>

This is an FAQ.  you have to explicitly 'print' the histogram:

print(histogram(~ Mpool[[2]]$LngtClas | Mpool[[2]]$SpCode, type = "count", col = "lightgrey", xlab= "LngtClas", main = paste("Length distribution per species for Mpool", "2", sep = "_")))

Sent from my iPad

On Jun 5, 2013, at 4:37, Xochitl CORMON <Xochitl.Cormon at ifremer.fr> wrote:

> Hi all,
> 
> I'm encountering a problem I do not understand on my data:
> 
> library (lattice)
> 
> Mpool1 <- Table[Table$Subarea %in% c("52E9", "51E9"),]
> Mpool2 <- Table[Table$Subarea %in% c("53F0", "52F0"),]
> Mpool3 <- Table[Table$Subarea %in% c("51F0", "50F0"),]
> Mpool4 <- Table[Table$Subarea %in% c("51F1", "52F1"),]
> 
> Mpool <- list(Mpool1, Mpool2, Mpool3, Mpool4)
> 
> 
> histogram(~ Mpool[[2]]$LngtClas | Mpool[[2]]$SpCode, type = "count", col = "lightgrey", xlab= "LngtClas", main = paste("Length distribution per species for Mpool", "2", sep = "_"))
> 
> #### This part works perfectly and I obtain the graph reprensenting Mpool2 length class count per species.
> #### Now when I want to automatize this with a "for" loop nothing is plotted.
> 
> for (i in c(2)){
> windows()
> histogram(~ Mpool[[i]]$LngtClas | Mpool[[i]]$SpCode, type = "count", col = "lightgrey", xlab= "LngtClas", main = paste("Length distribution per species for Mpool", i, sep = "_"))
> print (i)
> }
> 
> ### Running this loop I obtained  windows filled grey (no plot drawn at all) but the print (i) print a "2" as expected. I really dont understand what's wrong with the loop. There is no error message and no notification in R. You can find enclosed my data in txt file.
> 
> Thank you very much for any help,
> 
> Xochitl C.
> 
> <>< <>< <>< <><
> 
> Xochitl CORMON
> +33 (0)3 21 99 56 84
> 
> Doctorante en sciences halieutiques
> PhD student in fishery sciences
> 
> <>< <>< <>< <><
> 
> IFREMER
> Centre Manche Mer du Nord
> 150 quai Gambetta
> 62200 Boulogne-sur-Mer
> 
> <>< <>< <>< <><
> 
> <Table.txt>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Xochitl.Cormon at ifremer.fr  Wed Jun  5 11:06:50 2013
From: Xochitl.Cormon at ifremer.fr (Xochitl CORMON)
Date: Wed, 05 Jun 2013 11:06:50 +0200
Subject: [R] Loop FOR with histogram()  from lattice
In-Reply-To: <DF250247-D09F-45B3-8C05-815543B2734E@gmail.com>
References: <CAJdZ_fkf6TnRT+Yj=XRO-Eb9CusYEOFuHna4SrULj8m98pcXaA@mail.gmail.com>
	<51AEF8BC.3060003@ifremer.fr>
	<DF250247-D09F-45B3-8C05-815543B2734E@gmail.com>
Message-ID: <51AEFFAA.2060908@ifremer.fr>

Hi Jim,

Thank you a lot. Is it a FAQ concerning lattice or FOR loop in general?

Regards,

Xochitl C.


Le 05/06/2013 10:55, Jim Holtman a ?crit :
> This is an FAQ.  you have to explicitly 'print' the histogram:
>
> print(histogram(~ Mpool[[2]]$LngtClas | Mpool[[2]]$SpCode, type = "count", col = "lightgrey", xlab= "LngtClas", main = paste("Length distribution per species for Mpool", "2", sep = "_")))
>
> Sent from my iPad
>
> On Jun 5, 2013, at 4:37, Xochitl CORMON<Xochitl.Cormon at ifremer.fr>  wrote:
>
>> Hi all,
>>
>> I'm encountering a problem I do not understand on my data:
>>
>> library (lattice)
>>
>> Mpool1<- Table[Table$Subarea %in% c("52E9", "51E9"),]
>> Mpool2<- Table[Table$Subarea %in% c("53F0", "52F0"),]
>> Mpool3<- Table[Table$Subarea %in% c("51F0", "50F0"),]
>> Mpool4<- Table[Table$Subarea %in% c("51F1", "52F1"),]
>>
>> Mpool<- list(Mpool1, Mpool2, Mpool3, Mpool4)
>>
>>
>> histogram(~ Mpool[[2]]$LngtClas | Mpool[[2]]$SpCode, type = "count", col = "lightgrey", xlab= "LngtClas", main = paste("Length distribution per species for Mpool", "2", sep = "_"))
>>
>> #### This part works perfectly and I obtain the graph reprensenting Mpool2 length class count per species.
>> #### Now when I want to automatize this with a "for" loop nothing is plotted.
>>
>> for (i in c(2)){
>> windows()
>> histogram(~ Mpool[[i]]$LngtClas | Mpool[[i]]$SpCode, type = "count", col = "lightgrey", xlab= "LngtClas", main = paste("Length distribution per species for Mpool", i, sep = "_"))
>> print (i)
>> }
>>
>> ### Running this loop I obtained  windows filled grey (no plot drawn at all) but the print (i) print a "2" as expected. I really dont understand what's wrong with the loop. There is no error message and no notification in R. You can find enclosed my data in txt file.
>>
>> Thank you very much for any help,
>>
>> Xochitl C.
>>
>> <><  <><  <><  <><
>>
>> Xochitl CORMON
>> +33 (0)3 21 99 56 84
>>
>> Doctorante en sciences halieutiques
>> PhD student in fishery sciences
>>
>> <><  <><  <><  <><
>>
>> IFREMER
>> Centre Manche Mer du Nord
>> 150 quai Gambetta
>> 62200 Boulogne-sur-Mer
>>
>> <><  <><  <><  <><
>>
>> <Table.txt>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Wed Jun  5 11:49:25 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 5 Jun 2013 10:49:25 +0100
Subject: [R] Trying to build up functions with its names by means of
	lapply
In-Reply-To: <250F03A2-77CE-4FAC-B1C9-6754567A3F6A@gmail.com>
References: <loom.20130605T043218-210@post.gmane.org>
	<250F03A2-77CE-4FAC-B1C9-6754567A3F6A@gmail.com>
Message-ID: <51AF09A5.4080700@sapo.pt>

Hello,

If in faux we ?force the return value, the bug is gone.


faux <- function(c) {
	f <- function (x) get(paste0(c,"gamma"))(x,k,scale=theta)
	force(f)
	f
}

Hope this helps,

Rui Barradas

Em 05-06-2013 07:13, Michael Weylandt escreveu:
>
>
> On Jun 5, 2013, at 3:53, Julio Sergio <juliosergio at gmail.com> wrote:
>
>> I want to generate specific gamma distribution functions, given fixed
>> parameters.
>> This is I have k, and theta, say
>>
>>    k <- 32.2549       # shape
>>    theta <- 26.32809  # scale
>>
>>
>>    # I have an auxiliary function that produces funcions according to
>>    # a given character (this is to have either dgamma, pgamma or qgamma)
>>    # for the specific parameters given above:
>>
>>    faux <- function(c) {
>>      function (x) get(paste0(c,"gamma"))(x,k,scale=theta)
>>    }
>>
>>    # So I can have, for instance, dgamma, and pgamma with
>>
>>    dff <- faux("d")
>>    pff <- faux("p")
>>
>>    dff(1000)
>>    ## [1] 0.001433138
>>
>>    pff(1000)
>>    ## [1] 0.844305
>>
>> Now, if I try to produce both functions in one shot with lapply, the thing
>> doesn't work, see
>>
>>    ffs <- lapply(c("d", "p"), faux)
>>
>>    ffs[[1]](1000)
>>    ## [1] 0.844305
>>
>>    ffs[[2]](1000)
>>    ## [1] 0.844305
>>
>> The two produced functions are the very same and correspond to pgamma!!
>> Maybe I'm missing something. Do you have any idea?
>
> I think you are hitting a bit of strangeness R generously calls 'lazy evaluation'.  I'm afraid I don't have a reference at hand, but search the archives for mention of the promise mechanism.
>
> MW
>
>>
>> Thanks,
>>
>>   -Sergio.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From david.vicary at talbotuw.com  Wed Jun  5 11:56:03 2013
From: david.vicary at talbotuw.com (TwistedSkies)
Date: Wed, 5 Jun 2013 02:56:03 -0700 (PDT)
Subject: [R] Send Mail R and Socket Connections
Message-ID: <1370426163450-4668699.post@n4.nabble.com>

Good Afternoon All, 

I am attempting to use the SendMailR function, I have checked with our I.T.
department that I am using the correct server and I have the right
permissions to connect and they have sent emails via this server but not
through R and I have also checked that the port should be 25. 

The code: 

/

# E-Mail # 

library(sendmailR) 

from <- "david at work.com" 
to <- "adam at work.com" 
subject <- "Send Mail R- Test" 
body <- "TESTING TESTING TESTING"                     
mailControl=list(smtpServer="uksmtp.global.local") 

sendmail(from=from,to=to,subject=subject,msg=body,control=mailControl) 
/



I receive the below error: 

/
function (host = "localhost", port, server = FALSE, blocking = FALSE, 
open = "a+", encoding = getOption("encoding"), timeout =
getOption("timeout")) 
.Internal(socketConnection(host, port, server, blocking, open, 
encoding, timeout)) 
<bytecode: 0x00000000071beb18>
<environment: namespace:base>
/


So I figured its an error with or I needed to define a new socket
connection, is this where the problem lies? Could anyone give me any
pointers on where to go next with this to get it working? 

Many Thanks in Advance! 




--
View this message in context: http://r.789695.n4.nabble.com/Send-Mail-R-and-Socket-Connections-tp4668699.html
Sent from the R help mailing list archive at Nabble.com.


From ruipbarradas at sapo.pt  Wed Jun  5 11:58:59 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 5 Jun 2013 10:58:59 +0100
Subject: [R] Trying to build up functions with its names by means of
	lapply
In-Reply-To: <51AF09A5.4080700@sapo.pt>
References: <loom.20130605T043218-210@post.gmane.org>
	<250F03A2-77CE-4FAC-B1C9-6754567A3F6A@gmail.com>
	<51AF09A5.4080700@sapo.pt>
Message-ID: <51AF0BE3.3050500@sapo.pt>

Hello,

My solution works but it is incorrect. We should force the argument 'c', 
not the return value. Like said in the help page for force. Which I've 
only read after my first post. The following way makes much more sense 
and is a bit shorter.

faux <- function(c) {
	force(c)
	function (x) get(paste0(c,"gamma"))(x,k,scale=theta)
}

Rui Barradas

Em 05-06-2013 10:49, Rui Barradas escreveu:
> Hello,
>
> If in faux we ?force the return value, the bug is gone.
>
>
> faux <- function(c) {
>      f <- function (x) get(paste0(c,"gamma"))(x,k,scale=theta)
>      force(f)
>      f
> }
>
> Hope this helps,
>
> Rui Barradas
>
> Em 05-06-2013 07:13, Michael Weylandt escreveu:
>>
>>
>> On Jun 5, 2013, at 3:53, Julio Sergio <juliosergio at gmail.com> wrote:
>>
>>> I want to generate specific gamma distribution functions, given fixed
>>> parameters.
>>> This is I have k, and theta, say
>>>
>>>    k <- 32.2549       # shape
>>>    theta <- 26.32809  # scale
>>>
>>>
>>>    # I have an auxiliary function that produces funcions according to
>>>    # a given character (this is to have either dgamma, pgamma or qgamma)
>>>    # for the specific parameters given above:
>>>
>>>    faux <- function(c) {
>>>      function (x) get(paste0(c,"gamma"))(x,k,scale=theta)
>>>    }
>>>
>>>    # So I can have, for instance, dgamma, and pgamma with
>>>
>>>    dff <- faux("d")
>>>    pff <- faux("p")
>>>
>>>    dff(1000)
>>>    ## [1] 0.001433138
>>>
>>>    pff(1000)
>>>    ## [1] 0.844305
>>>
>>> Now, if I try to produce both functions in one shot with lapply, the
>>> thing
>>> doesn't work, see
>>>
>>>    ffs <- lapply(c("d", "p"), faux)
>>>
>>>    ffs[[1]](1000)
>>>    ## [1] 0.844305
>>>
>>>    ffs[[2]](1000)
>>>    ## [1] 0.844305
>>>
>>> The two produced functions are the very same and correspond to pgamma!!
>>> Maybe I'm missing something. Do you have any idea?
>>
>> I think you are hitting a bit of strangeness R generously calls 'lazy
>> evaluation'.  I'm afraid I don't have a reference at hand, but search
>> the archives for mention of the promise mechanism.
>>
>> MW
>>
>>>
>>> Thanks,
>>>
>>>   -Sergio.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Wed Jun  5 12:01:43 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 05 Jun 2013 11:01:43 +0100
Subject: [R] How to display multiples lines with different color on the
 same plot?
In-Reply-To: <9879AF1F439EF943BDEE22D3AAA5C3F683FBD675@sdsu-ex01.jacks.local>
References: <9879AF1F439EF943BDEE22D3AAA5C3F683FBD675@sdsu-ex01.jacks.local>
Message-ID: <51AF0C87.80107@sapo.pt>

Hello,

See the help pages for

?abline
?par  # parameter 'col'

Hope this helps,

Rui Barradas

Em 04-06-2013 22:05, Kaptue Tchuente, Armel escreveu:
> Hi all,
>
> I'm struggling with the display of several regression lines (with different colors) on the same plot.
>
> I manually drew what I'm trying to do with 8 lines (see attached).
>
> Any thoughts for a code will be very much appreciated.
>
> Thanks
>
> Armel
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Wed Jun  5 13:10:45 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 5 Jun 2013 05:10:45 -0600
Subject: [R] Post hoc power analysis for mixed-effects models
In-Reply-To: <482B1843EE6C72459D3BD633C43679EA04447F54@ucexchange2.canterbury.ac.nz>
References: <482B1843EE6C72459D3BD633C43679EA04447F54@ucexchange2.canterbury.ac.nz>
Message-ID: <C1688010-B655-493F-8D5F-B6F5F47C07C8@comcast.net>


On Jun 4, 2013, at 4:46 PM, Kota Hattori wrote:

> Dear all,
>
> I have been searching ways to run power analysis for mixed-effects  
> models. However, I have not been successful
> in the research. Today I would like to ask your help. As long as I  
> see from my search, Martin Julien wrote a package
> called pamm for the power analysis. One of the limitations in the  
> current version is that pamm cannot handle
> categorical fixed variables. Todd Jobes introduced his script to run  
> power analysis for mixed-effects models
> (http://toddjobe.blogspot.co.nz/2009/09/power-analysis-for-mixed-effect-models.html 
> ). However, some parts of
> the script is beyond my knowledge. I am not sure if I can run power  
> analysis with categorical variables either. Is there
> anybody who has run post hoc power analysis for mixed-effects  
> models? If you have experiences, I would like to
> ask your help. Thank you very much for taking your time.

Can you provide a sensible justification for "post hoc power analysis?  
I know the terminology has crept into widespread use due to its  
existence in either SAS or SPSS (I forget which), but I have doubts  
about its validity. It mixes up the order of statistical testing  
logic. Power analysis is something done _before_ the study. If a  
statistical procedure is done after a study's data is collected with  
the very dubious assumption that the sample statistics are the  
population statistics, it's not a power analysis.

-- 
David Winsemius, MD
Alameda, CA, USA


From dwinsemius at comcast.net  Wed Jun  5 13:32:03 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 5 Jun 2013 05:32:03 -0600
Subject: [R] how to compute maximum of fitted polynomial?
In-Reply-To: <loom.20130605T060711-422@post.gmane.org>
References: <BLU171-W3008743CA8E23E4C29E050D89E0@phx.gbl>
	<51AE6174.30103@sapo.pt>
	<CACk-te16ReaLbN5amRL63tbn=3DBgbEZwBNMHa7TANPveY4HWQ@mail.gmail.com>
	<loom.20130605T060711-422@post.gmane.org>
Message-ID: <38595B76-E9C2-4596-B41F-C4FB84575FAD@comcast.net>


On Jun 4, 2013, at 10:15 PM, Hans W Borchers wrote:

> Bert Gunter <gunter.berton <at> gene.com> writes:
>>
>> 1. This looks like a homework question. We should not do homework  
>> here.
>> 2. optim() will only approximate the max.
>> 3. optim() is not the right numerical tool for this anyway.  
>> optimize() is.
>> 4. There is never a guarantee numerical methods will find the max.
>> 5. This can (and should?) be done exactly using elementary math  
>> rather
>> than numerical methods.
>>
>> Cheers,
>> Bert
>
> In the case of polynomials, "elementary math ... methods" can  
> actually be
> executed with R:
>
>    library(polynomial)                 # -6 + 11*x - 6*x^2 + x^3
>    p0 <- polynomial(c(-6, 11, -6, 1))  # has zeros at 1, 2, and 3
>    p1 <- deriv(p0); p2 <- deriv(p1)    # first and second derivative
>    xm <- solve(p1)                     # maxima and minima of p0
>    xmax = xm[predict(p2, xm) < 0]      # select the maxima
>    xmax                                # [1] 1.42265
>
> Obviously, the same procedure will work for polynomials p0 of higher  
> orders.

These look like the functions present in the 'polynom' package  
authored by Bill Venables [aut] (S original), Kurt Hornik [aut, cre]  
(R port), Martin Maechler. I wasn't able to find a 'polynomial'  
package on CRAN. The 'mpoly' package by David Kahle offers  
multivariate symbolic operations as well.

-- 
David.

>
> Hans Werner
>
>
>>> Em 04-06-2013 21:32, Joseph Clark escreveu:
>>>>
>>>> My script fits a third-order polynomial to my data with something  
>>>> like
>>>> this:
>>>>
>>>> model <- lm( y ~ poly(x, 3) )
>>>>
>>>> What I'd like to do is find the theoretical maximum of the  
>>>> polynomial
>>>> (i.e. the x at which "model" predicts the highest y).   
>>>> Specifically, I'd
>>>> like to predict the maximum between 0 <= x <= 1.
>>>>
>>>> What's the best way to accomplish that in R?
>>>>
>>>> Bonus question: can R give me the derivative or 2nd derivative of  
>>>> the
>>>> polynomial?  I'd like to be able to compute these at that maximum  
>>>> point.
>>>>
>>>> Thanks in advance!

--

David Winsemius, MD
Alameda, CA, USA


From hwborchers at googlemail.com  Wed Jun  5 13:41:53 2013
From: hwborchers at googlemail.com (Hans W Borchers)
Date: Wed, 5 Jun 2013 11:41:53 +0000
Subject: [R] how to compute maximum of fitted polynomial?
References: <BLU171-W3008743CA8E23E4C29E050D89E0@phx.gbl>
	<51AE6174.30103@sapo.pt>
	<CACk-te16ReaLbN5amRL63tbn=3DBgbEZwBNMHa7TANPveY4HWQ@mail.gmail.com>
	<loom.20130605T060711-422@post.gmane.org>
	<38595B76-E9C2-4596-B41F-C4FB84575FAD@comcast.net>
Message-ID: <loom.20130605T133634-68@post.gmane.org>

David Winsemius <dwinsemius <at> comcast.net> writes:

> [...]
> 
> On Jun 4, 2013, at 10:15 PM, Hans W Borchers wrote:
> 
> > In the case of polynomials, "elementary math ... methods" can  
> > actually be
> > executed with R:

    library(polynomial)                 # -6 + 11*x - 6*x^2 + x^3
    p0 <- polynomial(c(-6, 11, -6, 1))  # has zeros at 1, 2, and 3
    p1 <- deriv(p0); p2 <- deriv(p1)    # first and second derivative
    xm <- solve(p1)                     # maxima and minima of p0
    xmax = xm[predict(p2, xm) < 0]      # select the maxima
    xmax                                # [1] 1.42265

> These look like the functions present in the 'polynom' package  
> authored by Bill Venables [aut] (S original), Kurt Hornik [aut, cre]  
> (R port), Martin Maechler. I wasn't able to find a 'polynomial'  
> package on CRAN. The 'mpoly' package by David Kahle offers  
> multivariate symbolic operations as well.
> 

Sorry, yes of course, it should be `library(polynom)`.
Somehow I'm making this mistake again and again.
And one has to be a bit careful about complex roots.


Hans Werner


From dwinsemius at comcast.net  Wed Jun  5 13:53:23 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 5 Jun 2013 05:53:23 -0600
Subject: [R] How to display multiples lines with different color on the
	same plot?
In-Reply-To: <9879AF1F439EF943BDEE22D3AAA5C3F683FBD675@sdsu-ex01.jacks.local>
References: <9879AF1F439EF943BDEE22D3AAA5C3F683FBD675@sdsu-ex01.jacks.local>
Message-ID: <1984C4B9-CF64-4E4F-A126-25F35212C3B1@comcast.net>


On Jun 4, 2013, at 3:05 PM, Kaptue Tchuente, Armel wrote:

> Hi all,
>
> I'm struggling with the display of several regression lines (with  
> different colors) on the same plot.
>
> I manually drew what I'm trying to do with 8 lines (see attached).

If you want lines that only span a portion of a plot area, then you  
should be looking at the segments function.

-- 

David Winsemius, MD
Alameda, CA, USA


From murdoch.duncan at gmail.com  Wed Jun  5 14:06:36 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 5 Jun 2013 08:06:36 -0400
Subject: [R] read.csv and write.csv filtering for very big data ?
In-Reply-To: <CAPr7RtVYb-FFNDv4=JA+RP5XNor4Tg_6jLf5hY44NfUuAVyZ5w@mail.gmail.com>
References: <CAPr7RtW3fX73N5NZRQbuN7M+PFJHzXo0L1VuMLih1P2Uz5Gx5g@mail.gmail.com>
	<CAFEqCdy7tYgY_DYtovOewfFXzuRWH2XxKYyuqf8BMAzdWOwDqw@mail.gmail.com>
	<CAPr7RtVYb-FFNDv4=JA+RP5XNor4Tg_6jLf5hY44NfUuAVyZ5w@mail.gmail.com>
Message-ID: <51AF29CC.2010807@gmail.com>

On 13-06-05 12:08 AM, ivo welch wrote:
> thx, greg.
>
> chunk boundaries have meanings.  the reader needs to stop, and buffer one
> line when it has crossed to the first line beyond the boundary.  it is also
> problem that read.csv no longer works with files---readLines then has to do
> the processing.  (starting read.csv over and over again with different
> skip.lines is probably not a good idea for big files.)  it needs a lot of
> smarts to intelligently append to a data frame.  (if the input is a data
> matrix, this is much simpler, of course.)

As Greg said, you don't need to use skip.lines:  just don't close the 
file, and continue reading from where you stopped on the previous run.

If you don't know the size of blocks in advance this is harder, but it's 
not really all that hard.  The logic would be something like this:

open the file
read the first block including the header
while not done:
    if you have a complete block with some extra lines at the end,
    extract them and save them, then process the complete block.
    Initialize the next block with the extra lines.

    if the block is incomplete, read some more and append it
    to what you saved.
end while
close the file

Duncan Murdoch

>
> exporting large input files to sqlite data bases makes sense when the same
> file is used again and again, but probably not when it is a staged one-time
> processor.  the disk consumption is too big.
>
> the writer could become quasi-threaded by writing to multiple temp files
> and then concatenating at the end, but this would be a nasty
> solution...nothing like the parsimonious elegance and generality that a
> built-in R filter function could provide.
>
> ----
> Ivo Welch (ivo.welch at gmail.com)
>
>
>
> On Tue, Jun 4, 2013 at 2:56 PM, Greg Snow <538280 at gmail.com> wrote:
>
>> Some possibilities using existing tools.
>>
>> If you create a file connection and open it before reading from it (or
>> writing to it), then functions like read.table and read.csv ( and
>> write.table for a writable connection) will read from the connection, but
>> not close and reset it.  This means that you could open 2 files, one for
>> reading and one for writing, then read in a chunk, process it, write it
>> out, then read in the next chunk, etc.
>>
>> Another option would be to read the data into an ff object (ff package) or
>> into a database (SQLite for one) which could have the data accessed in
>> chunks, possibly even in parallel.
>>
>>
>> On Mon, Jun 3, 2013 at 4:59 PM, ivo welch <ivo.welch at anderson.ucla.edu>wrote:
>>
>>> dear R wizards---
>>>
>>> I presume this is a common problem, so I thought I would ask whether
>>> this solution already exists and if not, suggest it.  say, a user has
>>> a data set of x GB, where x is very big---say, greater than RAM.
>>> fortunately, data often come sequentially in groups, and there is a
>>> need to process contiguous subsets of them and write the results to a
>>> new file.  read.csv and write.csv only work on FULL data sets.
>>> read.csv has the ability to skip n lines and read only m lines, but
>>> this can cross the subsets.  the useful solution here would be a
>>> "filter" function that understands about chunks:
>>>
>>>     filter.csv <- function( in.csv, out.csv, chunk, FUNprocess ) ...
>>>
>>> a chunk would not exactly be a factor, because normal R factors can be
>>> non-sequential in the data frame.  the filter.csv makes it very simple
>>> to work on large data sets...almost SAS simple:
>>>
>>>     filter.csv( pipe('bzcat infile.csv.bz2'), "results.csv", "date",
>>> function(d) colMeans(d))
>>> or
>>>     filter.csv( pipe('bzcat infile.csv.bz2'), pipe("bzip -c >
>>> results.csv.bz2"), "date", function(d) d[ unique(d$date), ] )  ##
>>> filter out obserations that have the same date again later
>>>
>>> or some reasonable variant of this.
>>>
>>> now that I can have many small chunks, it would be nice if this were
>>> threadsafe, so
>>>
>>>     mcfilter.csv <- function( in.csv, out.csv, chunk, FUNprocess ) ...
>>>
>>> with 'library(parallel)' could feed multiple cores the FUNprocess, and
>>> make sure that the processes don't step on one another.  (why did R
>>> not use a dot after "mc" for parallel lapply?)  presumably, to keep it
>>> simple, mcfilter.csv would keep a counter of read chunks and block
>>> write chinks until the next sequential chunk in order arrives.
>>>
>>> just a suggestion...
>>>
>>> /iaw
>>>
>>> ----
>>> Ivo Welch (ivo.welch at gmail.com)
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>>
>> --
>> Gregory (Greg) L. Snow Ph.D.
>> 538280 at gmail.com
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From therneau at mayo.edu  Wed Jun  5 14:12:56 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Wed, 05 Jun 2013 07:12:56 -0500
Subject: [R] Survival aareg problem
In-Reply-To: <mailman.6905.1370410398.4595.r-help@r-project.org>
References: <mailman.6905.1370410398.4595.r-help@r-project.org>
Message-ID: <51AF2B48.6000708@mayo.edu>



On 06/05/2013 12:33 AM, r-help-request at r-project.org wrote:
> Dear friends - I'm on windows 7, R 2.15.2
>
> when I run the example for aareg in survival package I see this:
>
>    plot(lfit[4], ylim=c(-4,4))
> error in xy.coords(x, y, xlabel, ylabel, log) :
>     'x' is a list, but does not have components 'x' and 'y'
>
> Is that a matter of an old R?
>
> Best wishes
>
> Troels Ring, MD
> Aalborg, Denmark

It's an error in the survival package: the line "S3method('[', aareg)" was missing from 
the NAMESPACE file.
Without it R doesn't find the correct code to perform the subscripting.  (In earlier 
versions of R a declaration of every S3 method was not necessary.)  You are the first to 
run into this.

   This will be fixed in the next (soon) release.  In the meantime, simply read in a copy 
of the subscripting code into your session, either with source() or cut and paste.   The 
code is below.

    Terry Therneau

"[.aareg" <- function(x, ..., drop=FALSE) {
     if (!inherits(x, 'aareg')) stop ("Must be an aareg object")
     i <- ..1
     if (is.matrix(x$coefficient)) {
         x$coefficient <- x$coefficient[,i, drop=drop]
         x$tweight <- x$tweight[,i,drop=drop]
     }
     else stop("Subsripting impossible, coefficient component not a matrix")

     if (!is.null(x$dfbeta)){
         x$dfbeta <- x$dfbeta[,i,,drop=drop]
         x$test.var2 <- x$test.var2[i,i,drop=drop]
     }
     x$test.statistic <- x$test.statistic[i, drop=drop]
     x$test.var <- x$test.var[i,i,drop=drop]
     x
     }


From bbolker at gmail.com  Wed Jun  5 14:41:27 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 5 Jun 2013 12:41:27 +0000
Subject: [R] Post hoc power analysis for mixed-effects models
References: <482B1843EE6C72459D3BD633C43679EA04447F54@ucexchange2.canterbury.ac.nz>
Message-ID: <loom.20130605T143312-245@post.gmane.org>

Kota Hattori <kota.hattori <at> canterbury.ac.nz> writes:

>  Dear all, I have been searching ways to run power analysis for
> mixed-effects models. However, I have not been successful in the
> research. Today I would like to ask your help. As long as I see from
> my search, Martin Julien wrote a package called pamm for the power
> analysis. One of the limitations in the current version is that pamm
> cannot handle categorical fixed variables. Todd Jobes introduced his
> script to run power analysis for mixed-effects models
> (http://toddjobe.blogspot.co.nz/2009/09/
    power-analysis-for-mixed-effect-models.html).
> However, some parts of the script is beyond my knowledge. I am not
> sure if I can run power analysis with categorical variables
> either. Is there anybody who has run post hoc power analysis for
> mixed-effects models? If you have experiences, I would like to ask
> your help. Thank you very much for taking your time.

  I share David Winsemius's concerns about post hoc power analysis:
this thread from 2008 gives some important reading.
<http://comments.gmane.org/gmane.comp.lang.r.ecology/472>

  The script you reference is a pretty generic introduction
to simulating data corresponding to a fixed + random effects
structure, so it should certainly be adaptable to categorical
variables.  

  This doesn't immediately solve your problem, but you might
work through chapter 5 of
http://www.math.mcmaster.ca/~bolker/emdbook/book.pdf
to strengthen your background knowledge ...

  Further mixed-model-relevant questions should probably
go to r-sig-mixed-models at r-project.org.

  Ben Bolker


From scott.raynaud at yahoo.com  Wed Jun  5 15:20:35 2013
From: scott.raynaud at yahoo.com (Scott Raynaud)
Date: Wed, 5 Jun 2013 06:20:35 -0700 (PDT)
Subject: [R] SPlus script
Message-ID: <1370438435.93923.YahooMailNeo@web142703.mail.bf1.yahoo.com>

This?originally was?an SPlus script that I modifeid about a year-and-a-half ago.? It worked perfectly then.? Now I can't get any output despite not receiving an error message.? I'm providing the SPLUS script as a reference.? I'm running R15.2.2.? Any help appreciated.? 
?
************************************MY MODIFICATION*********************************************************************
## sshc.ssc: sample size calculation for historical control studies
## J. Jack Lee (jjlee at mdanderson.org) and Chi-hong Tseng
## Department of Biostatistics, Univ. of Texas M.D. Anderson Cancer Center
##
## 3/1/99
## updated 6/7/00: add loess
##------------------------------------------------------------------
######## Required Input:
#
# rc???? number of response in historical control group
# nc???? sample size in historical control
# d????? target improvement = Pe - Pc
# method 1=method based on the randomized design
#??????? 2=Makuch & Simon method (Makuch RW, Simon RM. Sample size considerations 
#????????? for non-randomized comparative studies. J of Chron Dis 1980; 3:175-181.
#??????? 3=uniform power method
######## optional Input:
#
# alpha? size of the test
# power? desired power of the test
# tol??? convergence criterion for methods 1 & 2 in terms of sample size
# tol1?? convergence criterion for method 3 at any given obs Rc in terms of difference
#????????? of expected power from target
# tol2?? overall convergence criterion for method 3 as the max absolute deviation
#????????? of expected power from target for all Rc
# cc???? range of multiplicative constant applied to the initial values ne
# l.span smoothing constant for loess
#
# Note:? rc is required for methods 1 and 2 but not 3
#??????? method 3 return the sample size need for rc=0 to (1-d)*nc
#
######## Output
# for methdos 1 & 2: return the sample size needed for the experimental group (1 number)
#??????????????????? for given rc, nc, d, alpha, and power
# for method 3:????? return the profile of sample size needed for given nc, d, alpha, and power
#??????????????????? vector $ne contains the sample size corresponding to rc=0, 1, 2, ... nc*(1-d)
#??????????????????? vector $Ep contains the expected power corresponding to 
#????????????????????? the true pc = (0, 1, 2, ..., nc*(1-d)) / nc
#????????????????????????????????????????????????? 
#------------------------------------------------------------------
sshc<-function(rc, nc=1092, d=.085779816, method=3, alpha=0.05, power=0.8,
????????????? tol=0.01, tol1=.0001, tol2=.005, cc=c(.1,2), l.span=.5)
{
### for method 1
if (method==1) {
?ne1<-ss.rand(rc,nc,d,alpha=.05,power=.8,tol=.01)
?return(ne=ne1)?
?????????????? }
### for method 2
if (method==2) {
ne<-nc
ne1<-nc+50
while(abs(ne-ne1)>tol & ne1<100000){
ne<-ne1
pe<-d+rc/nc
ne1<-nef(rc,nc,pe*ne,ne,alpha,power)
## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
}
if (ne1>100000) return(NA)
else return(ne=ne1)
}
### for method 3
if (method==3) {
if (tol1 > tol2/10) tol1<-tol2/10
ncstar<-(1-d)*nc
pc<-(0:ncstar)/nc
ne<-rep(NA,ncstar + 1)
for (i in (0:ncstar))
{ ne[i+1]<-ss.rand(i,nc,d,alpha=.05,power=.8,tol=.01)
}
plot(pc,ne,type='l',ylim=c(0,max(ne)*1.5))
ans<-c.searchd(nc, d, ne, alpha, power, cc, tol1)
### check overall absolute deviance
old.abs.dev<-sum(abs(ans$Ep-power))
##bad<-0
print(round(ans$Ep,4))
print(round(ans$ne,2))
lines(pc,ans$ne,lty=1,col=8)
old.ne<-ans$ne
##while(max(abs(ans$Ep-power))>tol2 & bad==0){? #### unnecessary ##
while(max(abs(ans$Ep-power))>tol2){
ans<-c.searchd(nc, d, ans$ne, alpha, power, cc, tol1)
abs.dev<-sum(abs(ans$Ep-power))
print(paste(" old.abs.dev=",old.abs.dev))
print(paste("???? abs.dev=",abs.dev))
##if (abs.dev > old.abs.dev) { bad<-1}
old.abs.dev<-abs.dev
print(round(ans$Ep,4))
print(round(ans$ne,2))
lines(pc,old.ne,lty=1,col=1)
lines(pc,ans$ne,lty=1,col=8)
### add convex
ans$ne<-convex(pc,ans$ne)$wy
### add loess
###old.ne<-ans$ne
loess.ne<-loess(ans$ne ~ pc, span=l.span)
lines(pc,loess.ne$fit,lty=1,col=4)
old.ne<-loess.ne$fit
###readline()
}
return(list(ne=ans$ne, Ep=ans$Ep))?
?????????????? }
}
## needed for method 1
nef2<-function(rc,nc,re,ne,alpha,power){
za<-qnorm(1-alpha)
zb<-qnorm(power)
xe<-asin(sqrt((re+0.375)/(ne+0.75)))
xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
ans<- 1/(4*(xc-xe)^2/(za+zb)^2-1/(nc+0.5)) - 0.5
return(ans)
}
## needed for method 2
nef<-function(rc,nc,re,ne,alpha,power){
za<-qnorm(1-alpha)
zb<-qnorm(power)
xe<-asin(sqrt((re+0.375)/(ne+0.75)))
xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
ans<-(za*sqrt(1+(ne+0.5)/(nc+0.5))+zb)^2/(2*(xe-xc))^2-0.5
return(ans)
}
## needed for method 3
c.searchd<-function(nc, d, ne, alpha=0.05, power=0.8, cc=c(0.1,2),tol1=0.0001){
#---------------------------
# nc???? sample size of control group
# d????? the differece to detect between control and experiment
# ne???? vector of starting sample size of experiment group 
#????? corresonding to rc of 0 to nc*(1-d)
# alpha? size of test
# power? target power
# cc?? pre-screen vector of constant c, the range should cover the 
#????? the value of cc that has expected power?? 
# tol1?? the allowance between the expceted power and target power
#--------------------------- 
pc<-(0:((1-d)*nc))/nc
ncl<-length(pc)
ne.old<-ne
ne.old1<-ne.old
### sweeping forward
for(i in 1:ncl){
?cmin<-cc[1]
?cmax<-cc[2]
### fixed cci<-cmax bug?
?cci <-1
?lhood<-dbinom((i:ncl)-1,nc,pc[i])
?ne[i:ncl]<-(1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
?Ep0 <-Epower(nc, d, ne, pc, alpha)
?while(abs(Ep0[i]-power)>tol1){
??if(Ep0[i]<power) cmin<-cci
??else cmax<-cci
??cci<-(cmax+cmin)/2??
??ne[i:ncl]<-(1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
??Ep0<-Epower(nc, d, ne, pc, alpha)
?}
??ne.old1<-ne
}
ne1<-ne
### sweeping backward -- ncl:i
ne.old2<-ne.old
ne???? <-ne.old
for(i in ncl:1){
?cmin<-cc[1]
?cmax<-cc[2]
### fixed cci<-cmax bug?
?cci <-1
?lhood<-dbinom((ncl:i)-1,nc,pc[i])
?lenl <-length(lhood)
?ne[ncl:i]<-(1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
?Ep0 <-Epower(nc, d, cci*ne, pc, alpha)
?while(abs(Ep0[i]-power)>tol1){
??if(Ep0[i]<power) cmin<-cci
??else cmax<-cci
??cci<-(cmax+cmin)/2
??ne[ncl:i]<-(1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
??Ep0<-Epower(nc, d, ne, pc, alpha)
?}
??ne.old2<-ne
}
ne2<-ne
ne<-(ne1+ne2)/2
#cat(ccc*ne)
Ep1<-Epower(nc, d, ne, pc, alpha)
return(list(ne=ne, Ep=Ep1))
}
###
vertex<-function(x,y)
{ ?n<-length(x)
?vx<-x[1]
?vy<-y[1]
?vp<-1?
?up<-T
?for (i in (2:n))
?{ if (up)
??{ ?if (y[i-1] > y[i])
???{vx<-c(vx,x[i-1])
??? vy<-c(vy,y[i-1])
??? vp<-c(vp,i-1)
??? up<-F
???}
??}
??else
??{ ?if (y[i-1] < y[i]) up<-T
??}
?}
?vx<-c(vx,x[n])
?vy<-c(vy,y[n])
?vp<-c(vp,n)
?return(list(vx=vx,vy=vy,vp=vp))
}
###
convex<-function(x,y)
{ 
?n<-length(x)
?ans<-vertex(x,y)
?len<-length(ans$vx)
?while (len>3)
?{ ?
#??cat("x=",x,"\n")
#??cat("y=",y,"\n")
??newx<-x[1:(ans$vp[2]-1)]
??newy<-y[1:(ans$vp[2]-1)]
??for (i in (2:(len-1)))
??{
?? ?newx<-c(newx,x[ans$vp[i]])
???newy<-c(newy,y[ans$vp[i]])
??}
??newx<-c(newx,x[(ans$vp[len-1]+1):n])
??newy<-c(newy,y[(ans$vp[len-1]+1):n])
??y<-approx(newx,newy,xout=x)$y
#??cat("new y=",y,"\n")
??ans<-vertex(x,y)
??len<-length(ans$vx)
#??cat("vx=",ans$vx,"\n")
#??cat("vy=",ans$vy,"\n")
}
?return(list(wx=x,wy=y))}
###?
Epower<-function(nc, d, ne, pc = (0:((1 - d) * nc))/nc, alpha = 0.05)
{
#-------------------------------------
# nc???? sample size in historical control
# d????? the increase of response rate between historical and experiment
# ne???? sample size of corresonding rc of 0 to nc*(1-d)
# pc???? the response rate of control group, where we compute the 
#??????? expected power
# alpha? the size of test
#-------------------------------------
?kk <- length(pc)
?rc <- 0:(nc * (1 - d))
?pp <- rep(NA, kk)
?ppp <- rep(NA, kk)
?for(i in 1:(kk)) {
??pe <- pc[i] + d
??lhood <- dbinom(rc, nc, pc[i])
??pp <- power1.f(rc, nc, ne, pe, alpha)
??ppp[i] <- sum(pp * lhood)/sum(lhood)
?}
?return(ppp)
}
# adapted from the old biss2
ss.rand<-function(rc,nc,d,alpha=.05,power=.8,tol=.01)
{
ne<-nc
ne1<-nc+50
while(abs(ne-ne1)>tol & ne1<100000){
ne<-ne1
pe<-d+rc/nc
ne1<-nef2(rc,nc,pe*ne,ne,alpha,power)
## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
}
if (ne1>100000) return(NA)
else return(ne1)
}
###
power1.f<-function(rc,nc,ne,pie,alpha=0.05){
#-------------------------------------
# rc?number of response in historical control
# nc?sample size in historical control
# ne??? sample size in experitment group
# pie?true response rate for experiment group
# alpha?size of the test
#-------------------------------------
za<-qnorm(1-alpha)
re<-ne*pie
xe<-asin(sqrt((re+0.375)/(ne+0.75)))
xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
ans<-za*sqrt(1+(ne+0.5)/(nc+0.5))-(xe-xc)/sqrt(1/(4*(ne+0.5)))
return(1-pnorm(ans))
}

?
?
*************************************ORIGINAL SPLUS SCRIPT************************************************************
## sshc.ssc: sample size calculation for historical control studies
## J. Jack Lee (jjlee at mdanderson.org) and Chi-hong Tseng
## Department of Biostatistics, Univ. of Texas M.D. Anderson Cancer Center
##
## 3/1/99
## updated 6/7/00: add loess
##------------------------------------------------------------------
######## Required Input:
#
# rc     number of response in historical control group
# nc     sample size in historical control
# d      target improvement = Pe - Pc
# method 1=method based on the randomized design
#        2=Makuch & Simon method (Makuch RW, Simon RM. Sample size considerations 
#          for non-randomized comparative studies. J of Chron Dis 1980; 3:175-181.
#        3=uniform power method
######## optional Input:
#
# alpha  size of the test
# power  desired power of the test
# tol    convergence criterion for methods 1 & 2 in terms of sample size
# tol1   convergence criterion for method 3 at any given obs Rc in terms of
 difference
#          of expected power from target
# tol2   overall convergence criterion for method 3 as the max absolute deviation
#          of expected power from target for all Rc
# cc     range of multiplicative constant applied to the initial values ne
# l.span smoothing constant for loess
#
# Note:  rc is required for methods 1 and 2 but not 3
#        method 3 return the sample size need for rc=0 to (1-d)*nc
#
######## Output
# for methdos 1 & 2: return the sample size needed for the experimental group (1 number)
#                    for given rc, nc, d, alpha, and power
# for method 3:      return the profile of sample size needed for given nc, d, alpha, and power
#                    vector $ne contains the sample size corresponding to rc=0, 1, 2, ... nc*(1-d)
#                    vector $Ep contains the expected power corresponding to 
#                      the true pc = (0, 1, 2, ..., nc*(1-d)) / nc
#                                      
            
#------------------------------------------------------------------
sshc _ function(rc, nc, d, method, alpha=0.05, power=0.8,
	             tol=0.01, tol1=.0001, tol2=.005, cc=c(.1,2), l.span=.5)
{
### for method 1
if (method==1) {
	ne1 _ ss.rand(rc,nc,d,alpha=.05,power=.8,tol=.01)
	return(ne=ne1)	
               }
### for method 2
if (method==2) {
ne_nc
ne1_nc+50
while(abs(ne-ne1)>tol & ne1<100000){
ne_ne1
pe_d+rc/nc
ne1_nef(rc,nc,pe*ne,ne,alpha,power)
## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
}
if (ne1>100000) return(NA)
else return(ne=ne1)
}
### for method 3
if (method==3) {
if (tol1 > tol2/10) tol1_tol2/10
ncstar _ (1-d)*nc
pc_(0:ncstar)/nc
ne _ rep(NA,ncstar + 1)
for (i in (0:ncstar))
{ ne[i+1] _ ss.rand(i,nc,d,alpha=.05,power=.8,tol=.01)
}
plot(pc,ne,type='l',ylim=c(0,max(ne)*1.5))
ans_c.searchd(nc, d, ne, alpha, power, cc, tol1)
### check overall absolute deviance
old.abs.dev _ sum(abs(ans$Ep-power))
##bad
 _ 0
print(round(ans$Ep,4))
print(round(ans$ne,2))
lines(pc,ans$ne,lty=1,col=8)
old.ne _ ans$ne
##while(max(abs(ans$Ep-power))>tol2 & bad==0){  #### unnecessary ##
while(max(abs(ans$Ep-power))>tol2){
ans_c.searchd(nc, d, ans$ne, alpha, power, cc, tol1)
abs.dev _ sum(abs(ans$Ep-power))
print(paste(" old.abs.dev=",old.abs.dev))
print(paste("     abs.dev=",abs.dev))
##if (abs.dev > old.abs.dev) { bad _ 1}
old.abs.dev _ abs.dev
print(round(ans$Ep,4))
print(round(ans$ne,2))
lines(pc,old.ne,lty=1,col=1)
lines(pc,ans$ne,lty=1,col=8)
### add convex
ans$ne _ convex(pc,ans$ne)$wy
### add loess
###old.ne _ ans$ne
loess.ne _ loess(ans$ne ~ pc, span=l.span)
lines(pc,loess.ne$fit,lty=1,col=4)
old.ne _ loess.ne$fit
###readline()
}
return(ne=ans$ne, Ep=ans$Ep)	
               }
}

## needed for method 1
nef2_function(rc,nc,re,ne,alpha,power){
za_qnorm(1-alpha)
zb_qnorm(power)
xe_asin(sqrt((re+0.375)/(ne+0.75)))
xc_asin(sqrt((rc+0.375)/(nc+0.75)))
ans_
 1/(4*(xc-xe)^2/(za+zb)^2-1/(nc+0.5)) - 0.5
return(ans)
}
## needed for method 2
nef_function(rc,nc,re,ne,alpha,power){
za_qnorm(1-alpha)
zb_qnorm(power)
xe_asin(sqrt((re+0.375)/(ne+0.75)))
xc_asin(sqrt((rc+0.375)/(nc+0.75)))
ans_(za*sqrt(1+(ne+0.5)/(nc+0.5))+zb)^2/(2*(xe-xc))^2-0.5
return(ans)
}
## needed for method 3
c.searchd_function(nc, d, ne, alpha=0.05, power=0.8, cc=c(0.1,2),tol1=0.0001){
#---------------------------
# nc     sample size of control group
# d      the differece to detect between control and experiment
# ne     vector of starting sample size of experiment group 
#		    corresonding to rc of 0 to nc*(1-d)
# alpha  size of test
# power  target power
# cc	  pre-screen vector of constant c, the range should cover the 
#		    the value of cc that has expected power		 
# tol1   the allowance between the expceted power and target power
#--------------------------- 
pc_(0:((1-d)*nc))/nc
ncl _ length(pc)
ne.old _ ne
ne.old1 _ ne.old
###
 sweeping forward
for(i in 1:ncl){
	cmin _ cc[1]
	cmax _ cc[2]
### fixed cci_cmax bug	
	cci  _ 1
	lhood _ dbinom((i:ncl)-1,nc,pc[i])
	ne[i:ncl] _ (1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
	Ep0  _ Epower(nc, d, ne, pc, alpha)
	while(abs(Ep0[i]-power)>tol1){
		if(Ep0[i]<power) cmin_cci
		else cmax_cci
		cci_(cmax+cmin)/2		
		ne[i:ncl] _ (1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
		Ep0_Epower(nc, d, ne, pc, alpha)
	}
 	ne.old1 _ ne
}
ne1 _ ne
### sweeping backward -- ncl:i
ne.old2 _ ne.old
ne      _ ne.old
for(i in ncl:1){
	cmin _ cc[1]
	cmax _ cc[2]
### fixed cci_cmax bug	
	cci  _ 1
	lhood _ dbinom((ncl:i)-1,nc,pc[i])
	lenl  _ length(lhood)
	ne[ncl:i] _ (1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
	Ep0  _ Epower(nc, d, cci*ne, pc, alpha)
	while(abs(Ep0[i]-power)>tol1){
		if(Ep0[i]<power) cmin_cci
		else cmax_cci
		cci_(cmax+cmin)/2
		ne[ncl:i] _ (1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
		Ep0_Epower(nc, d, ne, pc, alpha)
	}
 	ne.old2 _ ne
}

ne2 _ ne
ne _ (ne1+ne2)/2
#cat(ccc*ne)
Ep1_Epower(nc, d, ne, pc, alpha)
return(ne=ne, Ep=Ep1)
}
###
vertex _ function(x,y)
{ 	n _ length(x)
	vx _ x[1]
	vy _ y[1]
	vp _ 1	
	up _ T
	for (i in (2:n))
	{ if (up)
		{ 	if (y[i-1] > y[i])
			{vx _ c(vx,x[i-1])
			 vy _ c(vy,y[i-1])
			 vp _ c(vp,i-1)
			 up _ F
			}
		}
		else
		{ 	if (y[i-1] < y[i]) up _ T
		}
	}
	vx _ c(vx,x[n])
	vy _ c(vy,y[n])
	vp _ c(vp,n)
	return(vx=vx,vy=vy,vp=vp)
}
###
convex _ function(x,y)
{ 
	n _ length(x)
	ans _ vertex(x,y)
	len _ length(ans$vx)
	while (len>3)
	{ 	
#		cat("x=",x,"\n")
#		cat("y=",y,"\n")
		newx _ x[1:(ans$vp[2]-1)]
		newy _ y[1:(ans$vp[2]-1)]
		for (i in (2:(len-1)))
		{
		 	newx _ c(newx,x[ans$vp[i]])
			newy _ c(newy,y[ans$vp[i]])
		}
		newx _ c(newx,x[(ans$vp[len-1]+1):n])
		newy _ c(newy,y[(ans$vp[len-1]+1):n])
		y _ approx(newx,newy,xout=x)$y
#		cat("new y=",y,"\n")
		ans _ vertex(x,y)
		len _ length(ans$vx)
#		cat("vx=",ans$vx,"\n")
#		cat("vy=",ans$vy,"\n")

}
	return(wx=x,wy=y)}
###	
Epower _ function(nc, d, ne, pc = (0:((1 - d) * nc))/nc, alpha = 0.05)
{
#-------------------------------------
# nc     sample size in historical control
# d      the increase of response rate between historical and experiment
# ne     sample size of corresonding rc of 0 to nc*(1-d)
# pc     the response rate of control group, where we compute the 
#        expected power
# alpha  the size of test
#-------------------------------------
	kk <- length(pc)
	rc <- 0:(nc * (1 - d))
	pp <- rep(NA, kk)
	ppp <- rep(NA, kk)
	for(i in 1:(kk)) {
		pe <- pc[i] + d
		lhood <- dbinom(rc, nc, pc[i])
		pp <- power1.f(rc, nc, ne, pe, alpha)
		ppp[i] <- sum(pp * lhood)/sum(lhood)
	}
	return(ppp)
}

# adapted from the old biss2
ss.rand _ function(rc,nc,d,alpha=.05,power=.8,tol=.01)
{
ne_nc
ne1_nc+50
while(abs(ne-ne1)>tol & ne1<100000){
ne_ne1
pe_d+rc/nc
ne1_nef2(rc,nc,pe*ne,ne,alpha,power)

## if(is.na(ne1))
 print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
}
if (ne1>100000) return(NA)
else return(ne1)
}
###
power1.f_function(rc,nc,ne,pie,alpha=0.05){
#-------------------------------------
# rc	number of response in historical control
# nc	sample size in historical control
# ne    sample size in experitment group
# pie	true response rate for experiment group
# alpha	size of the test
#-------------------------------------

za_qnorm(1-alpha)
re_ne*pie
xe_asin(sqrt((re+0.375)/(ne+0.75)))
xc_asin(sqrt((rc+0.375)/(nc+0.75)))
ans_za*sqrt(1+(ne+0.5)/(nc+0.5))-(xe-xc)/sqrt(1/(4*(ne+0.5)))
return(1-pnorm(ans))
}


From smartpink111 at yahoo.com  Wed Jun  5 15:44:41 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 5 Jun 2013 06:44:41 -0700 (PDT)
Subject: [R] dates and time series management
In-Reply-To: <1370412356.2514.YahooMailNeo@web160604.mail.bf1.yahoo.com>
References: <1370384616.88390.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1370391272.9589.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1370397420.70765.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1370401423.51446.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1370402738.70484.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1370403455.40198.YahooMailNeo@web160602.mail.bf1.yahoo.com>
	<1370403750.12728.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1370404333.84419.YahooMailNeo@web160605.mail.bf1.yahoo.com>
	<1370404682.21912.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1370406335.8400.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<1370406649.16477.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1370412356.2514.YahooMailNeo@web160604.mail.bf1.yahoo.com>
Message-ID: <1370439881.75797.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
Try this:
lstf1<- list.files(pattern=".txt")
length(lstf1)
#[1] 119
fun2<- function(lstf){
?lst1<-lapply(lstf,function(x) readLines(x))
?lst2<-lapply(lst1,function(x) {gsub("(\\d+)(-9999.99)","\\1 \\2",x)})
?lst3<-lapply(lst2,function(x) {x<-gsub("(\\d+)(-9999.99)","\\1 \\2",x)})
?lst4<- lapply(lst3,function(x) read.table(text=x,header=TRUE,stringsAsFactors=FALSE,sep="",fill=TRUE))
?lst5<- lapply(lst4,function(x) x[x$V1>=1961 & x$V1<=2005,])
?lst6<- lapply(lst5,function(x) x[!is.na(x$V1),])
?lst7<- lapply(lst6,function(x) {
???????????????????? if((min(x$V1)>1961)|(max(x$V1)<2005)){
???????????????????????? n1<- (min(x$V1)-1961)*12
???????????????????????? x1<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n1))
???????????????????????? n2<- (2005-max(x$V1))*12
???????????????????????? x2<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n2))
???????????????????????? x3<- rbind(x1,x,x2)
??????????????????????? }
????????????????????????? else {
??????????????????? x
??????????????????? } })

lst8<- lapply(lst7,function(x) data.frame(col1=unlist(x[,-c(1:2)])))
???? lst9<- lapply(seq_along(lst8),function(i){
??????????????????????? x<- lst8[[i]]
??????????????????????? colnames(x)<- lstf1[i]
??????????????????????? row.names(x)<- 1:nrow(x)
??????????????????????? x
??????????????????????? })
?do.call(cbind,lst9)}
res<-fun2(lstf1)
dim(res)
#[1] 16740?? 119
res[1:5,1:3]
?# dt3011120.txt dt3011240.txt dt3011887.txt
#1????????? 1.67??????????? NA????????? 0.17
#2????????? 0.00??????????? NA????????? 0.28
#3????????? 0.00??????????? NA????????? 0.00
#4????????? 0.00??????????? NA????????? 0.30
#5????????? 0.00??????????? NA????????? 0.00


########################################

There are some formatting issues in your files:
For eg. If I run the function line by line:

?lst1<-lapply(lstf1,function(x) readLines(x))
sapply(lst1,function(x) any(grepl("\\d+-9999.99",x)))
? [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[37]? TRUE FALSE? TRUE FALSE FALSE? TRUE FALSE FALSE FALSE FALSE FALSE FALSE
?[49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[73] FALSE FALSE FALSE FALSE FALSE? TRUE FALSE FALSE FALSE FALSE? TRUE FALSE
?[85] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE? TRUE
?[97] FALSE FALSE FALSE FALSE FALSE FALSE? TRUE? TRUE FALSE FALSE FALSE FALSE
[109] FALSE FALSE FALSE FALSE? TRUE FALSE FALSE FALSE FALSE FALSE? TRUE


###means some rows in the a few files have:
#-9999.99 0 0 0 0.00-9999.99 0 0.00-9999.99 0 0 0 0.00-9999.99 (no space before -9999.99)


?lst2<-lapply(lst1,function(x) {gsub("(\\d+)(-9999.99)","\\1 \\2",x)})
sapply(lst2,function(x) any(grepl("\\d+-9999.99",x))) #still a few files had the problem
? [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[73] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE? TRUE FALSE
?[85] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE? TRUE
?[97] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
[109] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
lst3<-lapply(lst2,function(x) {x<-gsub("(\\d+)(-9999.99)","\\1 \\2",x)})
any(sapply(lst3,function(x) any(grepl("\\d+-9999.99",x))))
#[1] FALSE
lst4<- lapply(lst3,function(x) read.table(text=x,header=TRUE,stringsAsFactors=FALSE,sep="",fill=TRUE))


any(sapply(lst4,function(x) any(sapply(x,is.character))))
#[1] FALSE

?lst5<- lapply(lst4,function(x) x[x$V1>=1961 & x$V1<=2005,])
lst6<- lapply(lst5,function(x) x[!is.na(x$V1),])
sapply(lst6,nrow)
?# [1] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [19] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [37] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [55] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [73] 540 540 540 540 528 492 528 540 348 540 540 480 540 540 540 540 540 540
# [91] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 528 540 540 540
#[109] 540 540 540 540 540 540 540 540 540 468 540

???? lst7<- lapply(lst6,function(x) {
???????????????????? if((min(x$V1)>1961)|(max(x$V1)<2005)){
???????????????????????? n1<- (min(x$V1)-1961)*12
???????????????????????? x1<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n1))
???????????????????????? n2<- (2005-max(x$V1))*12
???????????????????????? x2<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n2))
???????????????????????? x3<- rbind(x1,x,x2)
??????????????????????? }
????????????????????????? else {
??????????????????? x
??????????????????? } })

?sapply(lst7,nrow)
#? [1] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [19] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [37] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [55] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [73] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [91] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
#[109] 540 540 540 540 540 540 540 540 540 540 540


Hope this helps.
A.K.

________________________________
From: Zilefac Elvis <zilefacelvis at yahoo.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Wednesday, June 5, 2013 2:05 AM
Subject: Re: dates and time series management



Hi A.K,
Sorry my internet connection was so bad last evening.

I have attached all the files as .zip.
Below is the output you requested.
As I explained, the start date in 'res' should be 1961 and end date should be 2005 in all 119 files.

Thanks A.K

> lapply(lst1,head,3)
[[1]]
? V1.V2.V3.V4.V5.V6.V7.V8.V9.V10.V11.V12.V13.V14.V15.V16.V17.V18.V19.V20.V21.V22.V23.V24.V25.V26.V27.V28.V29.V30.V31.V32.V33
1 ? ? ? ? ? ? ? ? ? ? ? ?1915 1 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
2 ? ? ? ? ? ? ? ? ? ? ? ?1915 2 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
3 ? ? ? ? ? ? ? ? ? ? ? ?1915 3 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA

[


From jdnewmil at dcn.davis.CA.us  Wed Jun  5 16:01:58 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 05 Jun 2013 07:01:58 -0700
Subject: [R] Loop FOR with histogram()  from lattice
In-Reply-To: <51AEFFAA.2060908@ifremer.fr>
References: <CAJdZ_fkf6TnRT+Yj=XRO-Eb9CusYEOFuHna4SrULj8m98pcXaA@mail.gmail.com>
	<51AEF8BC.3060003@ifremer.fr>
	<DF250247-D09F-45B3-8C05-815543B2734E@gmail.com>
	<51AEFFAA.2060908@ifremer.fr>
Message-ID: <03e25fad-d538-475c-b204-0369502d8f83@email.android.com>

If you have read the Posting Guide, you will know that you should have read ALL the FAQs before posting your question.

http://cran.r-project.org/doc/FAQ/R-FAQ.html

That said, this particular FAQ applies to any library that depends on grid graphics, including lattice and ggplot2.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Xochitl CORMON <Xochitl.Cormon at ifremer.fr> wrote:

>Hi Jim,
>
>Thank you a lot. Is it a FAQ concerning lattice or FOR loop in general?
>
>Regards,
>
>Xochitl C.
>
>
>Le 05/06/2013 10:55, Jim Holtman a ?crit :
>> This is an FAQ.  you have to explicitly 'print' the histogram:
>>
>> print(histogram(~ Mpool[[2]]$LngtClas | Mpool[[2]]$SpCode, type =
>"count", col = "lightgrey", xlab= "LngtClas", main = paste("Length
>distribution per species for Mpool", "2", sep = "_")))
>>
>> Sent from my iPad
>>
>> On Jun 5, 2013, at 4:37, Xochitl CORMON<Xochitl.Cormon at ifremer.fr> 
>wrote:
>>
>>> Hi all,
>>>
>>> I'm encountering a problem I do not understand on my data:
>>>
>>> library (lattice)
>>>
>>> Mpool1<- Table[Table$Subarea %in% c("52E9", "51E9"),]
>>> Mpool2<- Table[Table$Subarea %in% c("53F0", "52F0"),]
>>> Mpool3<- Table[Table$Subarea %in% c("51F0", "50F0"),]
>>> Mpool4<- Table[Table$Subarea %in% c("51F1", "52F1"),]
>>>
>>> Mpool<- list(Mpool1, Mpool2, Mpool3, Mpool4)
>>>
>>>
>>> histogram(~ Mpool[[2]]$LngtClas | Mpool[[2]]$SpCode, type = "count",
>col = "lightgrey", xlab= "LngtClas", main = paste("Length distribution
>per species for Mpool", "2", sep = "_"))
>>>
>>> #### This part works perfectly and I obtain the graph reprensenting
>Mpool2 length class count per species.
>>> #### Now when I want to automatize this with a "for" loop nothing is
>plotted.
>>>
>>> for (i in c(2)){
>>> windows()
>>> histogram(~ Mpool[[i]]$LngtClas | Mpool[[i]]$SpCode, type = "count",
>col = "lightgrey", xlab= "LngtClas", main = paste("Length distribution
>per species for Mpool", i, sep = "_"))
>>> print (i)
>>> }
>>>
>>> ### Running this loop I obtained  windows filled grey (no plot drawn
>at all) but the print (i) print a "2" as expected. I really dont
>understand what's wrong with the loop. There is no error message and no
>notification in R. You can find enclosed my data in txt file.
>>>
>>> Thank you very much for any help,
>>>
>>> Xochitl C.
>>>
>>> <><  <><  <><  <><
>>>
>>> Xochitl CORMON
>>> +33 (0)3 21 99 56 84
>>>
>>> Doctorante en sciences halieutiques
>>> PhD student in fishery sciences
>>>
>>> <><  <><  <><  <><
>>>
>>> IFREMER
>>> Centre Manche Mer du Nord
>>> 150 quai Gambetta
>>> 62200 Boulogne-sur-Mer
>>>
>>> <><  <><  <><  <><
>>>
>>> <Table.txt>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From deepayan.sarkar at r-project.org  Wed Jun  5 16:07:04 2013
From: deepayan.sarkar at r-project.org (Deepayan Sarkar)
Date: Wed, 5 Jun 2013 19:37:04 +0530
Subject: [R] Lattice, ggplot, and pointsize
In-Reply-To: <1369509438.20032.163.camel@milan>
References: <1369135114.20032.58.camel@milan>
	<201305211330.r4LDU9eK025410@mail15.tpg.com.au>
	<1369144480.20032.63.camel@milan>
	<ad7504fc-3f32-4da7-a190-cc9239252c85@email.android.com>
	<1369163829.20032.79.camel@milan>
	<CACk-te0=1068zyxve7eWAJ=q87PR8Ye0Ntd7GXRGRCCSChMBtA@mail.gmail.com>
	<519BDB6A.2020008@stats.ox.ac.uk>
	<1369509438.20032.163.camel@milan>
Message-ID: <CADfFDC5tYQ2f-GNLGbBb-OZn-ys_q9ct=NETn6hiQrhW2zaEVQ@mail.gmail.com>

On Sun, May 26, 2013 at 12:47 AM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
> Le mardi 21 mai 2013 ? 21:39 +0100, Prof Brian Ripley a ?crit :
>> On 21/05/2013 21:24, Bert Gunter wrote:
>> > At the risk of misunderstanding... (inline)
>> >
>> > On Tue, May 21, 2013 at 12:17 PM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
>> >> Le mardi 21 mai 2013 ? 08:17 -0700, Jeff Newmiller a ?crit :
>> >>> That is like complaining that your hammer does not fit these
>> >>> newfangled Philips screws.
>> >>>
>> >>> These are different tools. Do not expect them to interoperate.
>> >> I understand that Lattice and ggplot2 do not use settings from par().
>> >> I'm fine with this, as these packages are different from base graphics
>> >> and have they own equivalent to tweak settings.
>> >>
>> >> What I do not understand is that one argument passed to output devices,
>> >> which are _not_ provided by package graphics, is ignored by these two
>> >> packages. Lattice and ggplot2 do not provide an alternative output
>> >> system,
>> >
>> > False, I believe, depending on what you mean by "output system". They
>> > both use grid graphics, not base graphics and with lattice, anyway,
>>
>> Indeed.  The issue is a design difference between the base and grid
>> graphics subsystems.  See the 'R Internals' manual for more details.
>
> Thanks for the pointers. Indeed there is some interesting documentation
> there. I've also had a deeper look at the code, and I've traced
> pointsize (called ps) back to the R_GE_gcontext struct in
> src/include/R_ext/GraphicsEngine.h.
>
> If I understand correctly, base graphics draw text using GText() in
> src/library/graphics/src/graphics.c, which in turn calls GEText() in
> src/main/engine.c. GEText() does take into account the pointsize.
>
> On the other hand, grid graphics draw text using gridText() from
> src/library/grid/src/grid.c. This function uses gcontextFromgpar() to
> get its R_GE_gcontext object. gcontextFromgpar() (defined in gpar.c)
> computes the pointsize from the fontsize gpar setting and a general
> scaling of the output:
>     /*
>      * Scale by GSS_SCALE (a "zoom" factor)
>      */
>     gc->ps = gpFontSize(gp, i) * REAL(gridStateElement(dd, GSS_SCALE))[0];
>
> What is interesting is that when a new device gets initialized by grid
> (initGPar() atin gpar.c), the fontsize gpar settings is set to the
> device starting pointsize:
>     REAL(gpfs)[0] = dev->startps;
>
> And indeed this works with svg():
>> svg("test.svg", pointsize=5)
>> get.gpar("fontsize")
> $fontsize
> [1] 5
>
> ...but not with Lattice:
>> trellis.par.get("fontsize")
> $text
> [1] 12
>
> $points
> [1] 8
>
>
> So the problem does not appear to be a base vs. grid graphics issue, but
> rather something specific to Lattice and ggplot2. And indeed, when
> looking at Lattice's sources, canonical.theme() in settings.R does:
>              fontsize         = list(text = 12, points = 8),
>
> As simple as that! I didn't need to look so deep into the code... :-/
>
>
> ?trellis.par.set says:
>      The initial settings for each device defaults to values
>      appropriate for that device. In practice, this boils down to three
>      distinct settings, one for screen devices like ?x11? and
>      ?windows?, one for black and white plots (mostly useful for
>      ?postscript?) and one for color printers (color ?postcript?,
>      ?pdf?). [This may not be up-to-date, though...]
>
> So it does not appear completely absurd to try to adjust to the device
> settings where appropriate. Pointsize seems such a case to me.
> canonical.theme() could set the text font size to get.gpar("fontsize").
> Since the default value is 12 for most devices, this would not change
> anything by default. (ggplot2 could probably benefit from a similar
> change.)

If I remember correctly (it was a long time ago), I had nothing in
particular against the default text fontsize. The default symbol size
in grid was larger than I liked, and so fontsize$points was set to
something more reasonable, and fontsize$text just seemed natural to
add. It is only ever used in a single call to gpar() inside
print.trellis. So it seems perfectly reasonable to take the default of
fontsize$text from grid instead.

I don't like the idea of making the default
'get.gpar("fontsize")$fontsize' though, because that requires a device
to be active, which canonical.theme() doesn't by design. Instead I
have changed the default to NULL, and the fontsize is now set from (in
order of priority)

1. trellis.par.get("fontsize")$text  # NULL by default
2. trellis.par.get("grid.pars")$fontsize # NULL by default
3. get.gpars()$fontsize # approximately device pointsize by default

Hopefully this works for you. You can test using the r-forge version.

-Deepayan

> I realize this is no longer a discussion relevant for R as a whole, but
> I am posting it here nevertheless in case somebody was interested. Maybe
> we should discuss this offlist with Deepayan.

[...]


From joeclark77 at hotmail.com  Wed Jun  5 16:11:30 2013
From: joeclark77 at hotmail.com (Joseph Clark)
Date: Wed, 5 Jun 2013 07:11:30 -0700
Subject: [R] how to compute maximum of fitted polynomial?
In-Reply-To: <loom.20130605T133634-68@post.gmane.org>
References: <BLU171-W3008743CA8E23E4C29E050D89E0@phx.gbl>,
	<51AE6174.30103@sapo.pt>,
	<CACk-te16ReaLbN5amRL63tbn=3DBgbEZwBNMHa7TANPveY4HWQ@mail.gmail.com>,
	<loom.20130605T060711-422@post.gmane.org>,
	<38595B76-E9C2-4596-B41F-C4FB84575FAD@comcast.net>,
	<loom.20130605T133634-68@post.gmane.org>
Message-ID: <BLU171-W40B9CFB4E145E77050B33FD89F0@phx.gbl>

Thank you all!  This approach, using the 'polynom' library, did the trick.

> library(polynom) # -6 + 11*x - 6*x^2 + x^3
> p0 <- polynomial(c(-6, 11, -6, 1)) # has zeros at 1, 2, and 3
> p1 <- deriv(p0); p2 <- deriv(p1) # first and second derivative
> xm <- solve(p1) # maxima and minima of p0
> xmax = xm[predict(p2, xm) < 0] # select the maxima
> xmax # [1] 1.42265

With these tweaks:

In fitting the model to the data I had to use raw=TRUE:
model <- lm( y ~ poly(x, 3, raw=TRUE) )
 
Then I could generate p0 directly from my lm:
p0 <- polynomial( coef(model) )

And I answered my second question by using the obvious:
predict(p2,xmax)

I don't know what I would have done if the optima weren't between x=0 and x=1, which was my constraint.  In that case the "maximum" would have been one of the endpoints rather than a zero of p1.  I suppose I could just have checked for it with some if/then code.  Fortunately it didn't turn out to be an issue with my data.

And no, this wasn't a homework problem.  I didn't do the math by hand because I needed to automate this process for several subsets of my data and several fitted models. 		 	   		  

From paxkn at nottingham.ac.uk  Wed Jun  5 16:17:50 2013
From: paxkn at nottingham.ac.uk (beginner)
Date: Wed, 5 Jun 2013 07:17:50 -0700 (PDT)
Subject: [R] How to write a loop in R to select multiple regression
 model and validate it ?
In-Reply-To: <397397cd-29d2-41e6-a9b4-aed842473850@email.android.com>
References: <1370389531950-4668669.post@n4.nabble.com>
	<397397cd-29d2-41e6-a9b4-aed842473850@email.android.com>
Message-ID: <1370441870545-4668720.post@n4.nabble.com>

This is not a homework but part of my research. 



--
View this message in context: http://r.789695.n4.nabble.com/How-to-write-a-loop-in-R-to-select-multiple-regression-model-and-validate-it-tp4668669p4668720.html
Sent from the R help mailing list archive at Nabble.com.


From paxkn at nottingham.ac.uk  Wed Jun  5 16:22:50 2013
From: paxkn at nottingham.ac.uk (beginner)
Date: Wed, 5 Jun 2013 07:22:50 -0700 (PDT)
Subject: [R] Coefficients paths - comparison of ridge,
 lasso and elastic net regression
Message-ID: <1370442170146-4668722.post@n4.nabble.com>

I would like to compare models selected with ridge, lasso and elastic net.
Fig. below shows coefficients paths using all 3 methods: ridge (Fig A,
alpha=0), lasso (Fig B; alpha=1) and elastic net (Fig C; alpha=0.5). The
optimal solution depends on the selected value of lambda, which is chosen
based on cross validation.

<http://r.789695.n4.nabble.com/file/n4668722/regularization.jpg> 

When looking at these plots, I would expect the elastic net (Fig C) to
exhibit a grouping effect. However it is not clear in the presented case.
The coefficients path for lasso and elastic net are very similar. What could
be the reason for this ? Is it just a coding mistake ? I used the following
code in R:


library(glmnet)
X<- as.matrix(mydata[,2:22])
Y<- mydata[,23]
par(mfrow=c(1,3))
ans1<-cv.glmnet(X, Y, alpha=0) # ridge
plot(ans1$glmnet.fit, "lambda", label=FALSE)
    text (6, 0.4, "A", cex=1.8, font=1)
    ans2<-cv.glmnet(X, Y, alpha=1) # lasso
    plot(ans2$glmnet.fit, "lambda", label=FALSE)
text (-0.8, 0.48, "B", cex=1.8, font=1)
ans3<-cv.glmnet(X, Y, alpha=0.5) # elastic net 
plot(ans3$glmnet.fit, "lambda", label=FALSE)
text (0, 0.62, "C", cex=1.8, font=1)


The code used to plot elastic net coefficients paths is exactly the same as
for ridge and lasso. The only difference is in the value of alpha. Alpha
parameter for elastic net regression was selected based on the lowest MSE
(mean squared error) for corresponding lambda values.

Thank you for your help !



--
View this message in context: http://r.789695.n4.nabble.com/Coefficients-paths-comparison-of-ridge-lasso-and-elastic-net-regression-tp4668722.html
Sent from the R help mailing list archive at Nabble.com.


From Xochitl.Cormon at ifremer.fr  Wed Jun  5 16:27:44 2013
From: Xochitl.Cormon at ifremer.fr (Xochitl CORMON)
Date: Wed, 05 Jun 2013 16:27:44 +0200
Subject: [R] sample {base}
In-Reply-To: <1370439881.75797.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1370384616.88390.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1370391272.9589.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1370397420.70765.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1370401423.51446.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1370402738.70484.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1370403455.40198.YahooMailNeo@web160602.mail.bf1.yahoo.com>
	<1370403750.12728.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1370404333.84419.YahooMailNeo@web160605.mail.bf1.yahoo.com>
	<1370404682.21912.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1370406335.8400.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<1370406649.16477.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1370412356.2514.YahooMailNeo@web160604.mail.bf1.yahoo.com>
	<1370439881.75797.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <51AF4AE0.7050205@ifremer.fr>

Hi all,

I'm trying to randomly select sample numbers for length class groups (5 
per length class).

For this I'm using a loop FOR and the function sample () and specified a 
size for the sampling of 5. Unfortunately, one of the length class group 
does not contain 5 individuals. For me is not a big deal as I have 
others groups to complete. However it bothers me that the sampling 
function does not select any individuals in this group generating the 
error below :

Error in sample(Gpool2$SampleNb[Gpool2$LngtClas == LngtClas[[i]] & 
Gpool2$SpCode ==  : can not take a sample larger than the population 
when 'replace = FALSE'.

I understand why this error message appears but I was wondering if there 
is a way to select all the items present in the group even if it's not 5 
(something like size =< 5).

LngtClas <- list( "40_49", "50_59", "60_69", "70_")
SpCode <- list ("POLLVIR ", "MERLMER")

a <- as.character(sample(Gpool$SampleNb[Gpool$LngtClas == LngtClas[[4]] 
& Gpool$SpCode == SpCode[[2]]], size = 5, replace = FALSE))

You can find enclosed my dataset,

Thank you for the help,

Xochitl C.

<>< <>< <>< <><

Xochitl CORMON
+33 (0)3 21 99 56 84

Doctorante en sciences halieutiques
PhD student in fishery sciences

<>< <>< <>< <><

IFREMER
Centre Manche Mer du Nord
150 quai Gambetta
62200 Boulogne-sur-Mer

<>< <>< <>< <><

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: ex.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130605/415f9d74/attachment.txt>

From nicomet80 at gmail.com  Wed Jun  5 16:30:17 2013
From: nicomet80 at gmail.com (Nico Met)
Date: Wed, 5 Jun 2013 16:30:17 +0200
Subject: [R] split and common variables
In-Reply-To: <015801ce606d$dd637e70$982a7b50$@tamu.edu>
References: <CAMMD=S4TzsJx3kjmZTG1rWc34oAarYKga=Q=L3PLcvzaWSzo4g@mail.gmail.com>
	<015801ce606d$dd637e70$982a7b50$@tamu.edu>
Message-ID: <CAMMD=S587oU0SngM3DYdPst=3mGOAPFDCWR--vm=YoQ=0He9YA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130605/0f2c2980/attachment.pl>

From juliosergio at gmail.com  Wed Jun  5 16:39:10 2013
From: juliosergio at gmail.com (Julio Sergio)
Date: Wed, 5 Jun 2013 14:39:10 +0000
Subject: [R]
	=?utf-8?q?Trying_to_build_up_functions_with_its_names_by_mean?=
	=?utf-8?q?s_of=09lapply?=
References: <loom.20130605T043218-210@post.gmane.org>
	<250F03A2-77CE-4FAC-B1C9-6754567A3F6A@gmail.com>
	<51AF09A5.4080700@sapo.pt> <51AF0BE3.3050500@sapo.pt>
Message-ID: <loom.20130605T161738-505@post.gmane.org>

Rui Barradas <ruipbarradas <at> sapo.pt> writes:

> My solution works but it is incorrect. We should force the argument 'c', 
> 
> faux <- function(c) {
> 	force(c)
> 	function (x) get(paste0(c,"gamma"))(x,k,scale=theta)
> }

Thanks a lot, Rul. I think I have to learn a bit more about lazy evaluation 
of arguments, as someone else told me at the beginning of this discussion.


  -Sergio.


From murdoch.duncan at gmail.com  Wed Jun  5 16:40:28 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 5 Jun 2013 10:40:28 -0400
Subject: [R] read.csv and write.csv filtering for very big data ?
In-Reply-To: <CAPr7RtXNdfxW1o5S3pwd6Z9y+EQEsWObNn0niKSspRS69da52w@mail.gmail.com>
References: <CAPr7RtW3fX73N5NZRQbuN7M+PFJHzXo0L1VuMLih1P2Uz5Gx5g@mail.gmail.com>
	<CAFEqCdy7tYgY_DYtovOewfFXzuRWH2XxKYyuqf8BMAzdWOwDqw@mail.gmail.com>
	<CAPr7RtVYb-FFNDv4=JA+RP5XNor4Tg_6jLf5hY44NfUuAVyZ5w@mail.gmail.com>
	<51AF29CC.2010807@gmail.com>
	<CAPr7RtXNdfxW1o5S3pwd6Z9y+EQEsWObNn0niKSspRS69da52w@mail.gmail.com>
Message-ID: <51AF4DDC.30505@gmail.com>

On 05/06/2013 10:32 AM, ivo welch wrote:
>
> I just tested read.csv with files...it still works.  it can read one 
> line at a time (without col.names and with nrows).  nice.  it loses 
> its type memory across reinvokcations, but this is usually not a 
> problem if one reads a few thousand lines inside a buffer function. 
>  this sort of function is useful only for big files anyway.

Surely you know the types of the columns?  If you specify it in advance, 
read.table and relatives will be much faster.

Duncan Murdoch

>
> is it possible to block write.csv across multiple threads in mclapply? 
>  or hook a single-thread function into the mclapply collector?
>
> /iaw
>
>
>
> On Wed, Jun 5, 2013 at 5:06 AM, Duncan Murdoch 
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>
>     On 13-06-05 12:08 AM, ivo welch wrote:
>
>         thx, greg.
>
>         chunk boundaries have meanings.  the reader needs to stop, and
>         buffer one
>         line when it has crossed to the first line beyond the
>         boundary.  it is also
>         problem that read.csv no longer works with files---readLines
>         then has to do
>         the processing.  (starting read.csv over and over again with
>         different
>         skip.lines is probably not a good idea for big files.)  it
>         needs a lot of
>         smarts to intelligently append to a data frame.  (if the input
>         is a data
>         matrix, this is much simpler, of course.)
>
>
>     As Greg said, you don't need to use skip.lines:  just don't close
>     the file, and continue reading from where you stopped on the
>     previous run.
>
>     If you don't know the size of blocks in advance this is harder,
>     but it's not really all that hard.  The logic would be something
>     like this:
>
>     open the file
>     read the first block including the header
>     while not done:
>        if you have a complete block with some extra lines at the end,
>        extract them and save them, then process the complete block.
>        Initialize the next block with the extra lines.
>
>        if the block is incomplete, read some more and append it
>        to what you saved.
>     end while
>     close the file
>
>     Duncan Murdoch
>
>
>         exporting large input files to sqlite data bases makes sense
>         when the same
>         file is used again and again, but probably not when it is a
>         staged one-time
>         processor.  the disk consumption is too big.
>
>         the writer could become quasi-threaded by writing to multiple
>         temp files
>         and then concatenating at the end, but this would be a nasty
>         solution...nothing like the parsimonious elegance and
>         generality that a
>         built-in R filter function could provide.
>
>         ----
>         Ivo Welch (ivo.welch at gmail.com <mailto:ivo.welch at gmail.com>)
>
>
>
>         On Tue, Jun 4, 2013 at 2:56 PM, Greg Snow <538280 at gmail.com
>         <mailto:538280 at gmail.com>> wrote:
>
>             Some possibilities using existing tools.
>
>             If you create a file connection and open it before reading
>             from it (or
>             writing to it), then functions like read.table and
>             read.csv ( and
>             write.table for a writable connection) will read from the
>             connection, but
>             not close and reset it.  This means that you could open 2
>             files, one for
>             reading and one for writing, then read in a chunk, process
>             it, write it
>             out, then read in the next chunk, etc.
>
>             Another option would be to read the data into an ff object
>             (ff package) or
>             into a database (SQLite for one) which could have the data
>             accessed in
>             chunks, possibly even in parallel.
>
>
>             On Mon, Jun 3, 2013 at 4:59 PM, ivo welch
>             <ivo.welch at anderson.ucla.edu
>             <mailto:ivo.welch at anderson.ucla.edu>>wrote:
>
>                 dear R wizards---
>
>                 I presume this is a common problem, so I thought I
>                 would ask whether
>                 this solution already exists and if not, suggest it.
>                  say, a user has
>                 a data set of x GB, where x is very big---say, greater
>                 than RAM.
>                 fortunately, data often come sequentially in groups,
>                 and there is a
>                 need to process contiguous subsets of them and write
>                 the results to a
>                 new file.  read.csv and write.csv only work on FULL
>                 data sets.
>                 read.csv has the ability to skip n lines and read only
>                 m lines, but
>                 this can cross the subsets.  the useful solution here
>                 would be a
>                 "filter" function that understands about chunks:
>
>                     filter.csv <- function( in.csv, out.csv, chunk,
>                 FUNprocess ) ...
>
>                 a chunk would not exactly be a factor, because normal
>                 R factors can be
>                 non-sequential in the data frame.  the filter.csv
>                 makes it very simple
>                 to work on large data sets...almost SAS simple:
>
>                     filter.csv( pipe('bzcat infile.csv.bz2'),
>                 "results.csv", "date",
>                 function(d) colMeans(d))
>                 or
>                     filter.csv( pipe('bzcat infile.csv.bz2'),
>                 pipe("bzip -c >
>                 results.csv.bz2"), "date", function(d) d[
>                 unique(d$date), ] )  ##
>                 filter out obserations that have the same date again later
>
>                 or some reasonable variant of this.
>
>                 now that I can have many small chunks, it would be
>                 nice if this were
>                 threadsafe, so
>
>                     mcfilter.csv <- function( in.csv, out.csv, chunk,
>                 FUNprocess ) ...
>
>                 with 'library(parallel)' could feed multiple cores the
>                 FUNprocess, and
>                 make sure that the processes don't step on one
>                 another.  (why did R
>                 not use a dot after "mc" for parallel lapply?)
>                  presumably, to keep it
>                 simple, mcfilter.csv would keep a counter of read
>                 chunks and block
>                 write chinks until the next sequential chunk in order
>                 arrives.
>
>                 just a suggestion...
>
>                 /iaw
>
>                 ----
>                 Ivo Welch (ivo.welch at gmail.com
>                 <mailto:ivo.welch at gmail.com>)
>
>                 ______________________________________________
>                 R-help at r-project.org <mailto:R-help at r-project.org>
>                 mailing list
>                 https://stat.ethz.ch/mailman/listinfo/r-help
>                 PLEASE do read the posting guide
>                 http://www.R-project.org/posting-guide.html
>                 and provide commented, minimal, self-contained,
>                 reproducible code.
>
>
>
>
>             --
>             Gregory (Greg) L. Snow Ph.D.
>             538280 at gmail.com <mailto:538280 at gmail.com>
>
>
>                 [[alternative HTML version deleted]]
>
>
>         ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         and provide commented, minimal, self-contained, reproducible code.
>
>
>


From neotropical.bats at gmail.com  Wed Jun  5 16:43:01 2013
From: neotropical.bats at gmail.com (Neotropical bat risk assessments)
Date: Wed, 05 Jun 2013 10:43:01 -0400
Subject: [R] reshape2 issue
Message-ID: <51AF4E75.1050500@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130605/49e8018f/attachment.pl>

From sarah.goslee at gmail.com  Wed Jun  5 16:49:22 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 5 Jun 2013 10:49:22 -0400
Subject: [R] sample {base}
In-Reply-To: <51AF4AE0.7050205@ifremer.fr>
References: <1370384616.88390.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1370391272.9589.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1370397420.70765.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1370401423.51446.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1370402738.70484.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1370403455.40198.YahooMailNeo@web160602.mail.bf1.yahoo.com>
	<1370403750.12728.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1370404333.84419.YahooMailNeo@web160605.mail.bf1.yahoo.com>
	<1370404682.21912.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1370406335.8400.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<1370406649.16477.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1370412356.2514.YahooMailNeo@web160604.mail.bf1.yahoo.com>
	<1370439881.75797.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<51AF4AE0.7050205@ifremer.fr>
Message-ID: <CAM_vjunvgRXeK7Fxx+LHvZPQDz-S17PQAzBNcy4TnKGSs5EVrQ@mail.gmail.com>

What about using instead
size = min(5, length(Gpool$SampleNb[Gpool$LngtClas == LngtClas[[4]] &
Gpool$SpCode == SpCode[[2]]])

that would make sure your sample is either the size of the data or 5.

Sarah

On Wed, Jun 5, 2013 at 10:27 AM, Xochitl CORMON
<Xochitl.Cormon at ifremer.fr> wrote:
> Hi all,
>
> I'm trying to randomly select sample numbers for length class groups (5 per
> length class).
>
> For this I'm using a loop FOR and the function sample () and specified a
> size for the sampling of 5. Unfortunately, one of the length class group
> does not contain 5 individuals. For me is not a big deal as I have others
> groups to complete. However it bothers me that the sampling function does
> not select any individuals in this group generating the error below :
>
> Error in sample(Gpool2$SampleNb[Gpool2$LngtClas == LngtClas[[i]] &
> Gpool2$SpCode ==  : can not take a sample larger than the population when
> 'replace = FALSE'.
>
> I understand why this error message appears but I was wondering if there is
> a way to select all the items present in the group even if it's not 5
> (something like size =< 5).
>
> LngtClas <- list( "40_49", "50_59", "60_69", "70_")
> SpCode <- list ("POLLVIR ", "MERLMER")
>
> a <- as.character(sample(Gpool$SampleNb[Gpool$LngtClas == LngtClas[[4]] &
> Gpool$SpCode == SpCode[[2]]], size = 5, replace = FALSE))
>
> You can find enclosed my dataset,
>
> Thank you for the help,
>
> Xochitl C.

-- 
Sarah Goslee
http://www.functionaldiversity.org


From dcarlson at tamu.edu  Wed Jun  5 16:57:35 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Wed, 5 Jun 2013 09:57:35 -0500
Subject: [R] sample {base}
In-Reply-To: <51AF4AE0.7050205@ifremer.fr>
References: <1370384616.88390.YahooMailNeo@web160601.mail.bf1.yahoo.com>	<1370391272.9589.YahooMailNeo@web142604.mail.bf1.yahoo.com>	<1370397420.70765.YahooMailNeo@web142602.mail.bf1.yahoo.com>	<1370401423.51446.YahooMailNeo@web160601.mail.bf1.yahoo.com>	<1370402738.70484.YahooMailNeo@web142602.mail.bf1.yahoo.com>	<1370403455.40198.YahooMailNeo@web160602.mail.bf1.yahoo.com>	<1370403750.12728.YahooMailNeo@web142606.mail.bf1.yahoo.com>	<1370404333.84419.YahooMailNeo@web160605.mail.bf1.yahoo.com>	<1370404682.21912.YahooMailNeo@web142606.mail.bf1.yahoo.com>	<1370406335.8400.YahooMailNeo@web160606.mail.bf1.yahoo.com>	<1370406649.16477.YahooMailNeo@web142604.mail.bf1.yahoo.com>	<1370412356.2514.YahooMailNeo@web160604.mail.bf1.yahoo.com>	<1370439881.75797.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<51AF4AE0.7050205@ifremer.fr>
Message-ID: <03f201ce61fd$03d5da90$0b818fb0$@tamu.edu>

Something like this?

> set.seed(42)
> a <- sample.int(10)
> b <- sample.int(5)
> c <- sample.int(3)
> smpl <- function(x) sample(x, ifelse(length(x)<5, length(x), 5))
> smpl(a)
[1]  4  8  1 10  2
> smpl(b)
[1] 2 3 5 1 4
> smpl(c)
[1] 2 1 3

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352





-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Xochitl CORMON
Sent: Wednesday, June 5, 2013 9:28 AM
To: r-help at r-project.org
Subject: [R] sample {base}

Hi all,

I'm trying to randomly select sample numbers for length class groups
(5 
per length class).

For this I'm using a loop FOR and the function sample () and
specified a 
size for the sampling of 5. Unfortunately, one of the length class
group 
does not contain 5 individuals. For me is not a big deal as I have 
others groups to complete. However it bothers me that the sampling 
function does not select any individuals in this group generating
the 
error below :

Error in sample(Gpool2$SampleNb[Gpool2$LngtClas == LngtClas[[i]] & 
Gpool2$SpCode ==  : can not take a sample larger than the population

when 'replace = FALSE'.

I understand why this error message appears but I was wondering if
there 
is a way to select all the items present in the group even if it's
not 5 
(something like size =< 5).

LngtClas <- list( "40_49", "50_59", "60_69", "70_")
SpCode <- list ("POLLVIR ", "MERLMER")

a <- as.character(sample(Gpool$SampleNb[Gpool$LngtClas ==
LngtClas[[4]] 
& Gpool$SpCode == SpCode[[2]]], size = 5, replace = FALSE))

You can find enclosed my dataset,

Thank you for the help,

Xochitl C.

<>< <>< <>< <><

Xochitl CORMON
+33 (0)3 21 99 56 84

Doctorante en sciences halieutiques
PhD student in fishery sciences

<>< <>< <>< <><

IFREMER
Centre Manche Mer du Nord
150 quai Gambetta
62200 Boulogne-sur-Mer

<>< <>< <>< <><


From kridox at ymail.com  Wed Jun  5 17:10:06 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 6 Jun 2013 00:10:06 +0900
Subject: [R] SPlus script
In-Reply-To: <1370438435.93923.YahooMailNeo@web142703.mail.bf1.yahoo.com>
References: <1370438435.93923.YahooMailNeo@web142703.mail.bf1.yahoo.com>
Message-ID: <CAAcyNCy9VND-pDfwqG6j3TnW_oTGp=6mYui7AkRZo+HePaegLQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130606/a370a358/attachment.pl>

From kridox at ymail.com  Wed Jun  5 17:10:46 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 6 Jun 2013 00:10:46 +0900
Subject: [R] reshape2 issue
In-Reply-To: <51AF4E75.1050500@gmail.com>
References: <51AF4E75.1050500@gmail.com>
Message-ID: <CAAcyNCxhhre+4zipy-on9OgXiKE1vS21ruWE6EStgeaA7CtLTA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130606/4a48c74b/attachment.pl>

From smartpink111 at yahoo.com  Wed Jun  5 17:36:39 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 5 Jun 2013 08:36:39 -0700 (PDT)
Subject: [R] split and common variables
In-Reply-To: <CAMMD=S587oU0SngM3DYdPst=3mGOAPFDCWR--vm=YoQ=0He9YA@mail.gmail.com>
References: <CAMMD=S4TzsJx3kjmZTG1rWc34oAarYKga=Q=L3PLcvzaWSzo4g@mail.gmail.com>
	<015801ce606d$dd637e70$982a7b50$@tamu.edu>
	<CAMMD=S587oU0SngM3DYdPst=3mGOAPFDCWR--vm=YoQ=0He9YA@mail.gmail.com>
Message-ID: <1370446599.36963.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hello,
May be this helps:
dta1<-do.call(data.frame,dta)
dta2<-dta1[complete.cases(dta1),]
dta2[,-3]<-lapply(dta2[,-3],as.character)
lstdta2<-split(dta2,dta2$place)
library(plyr)
#Some names are common in a few, but not in all the places. If you are looking for names common in 2 places, 3, places, etc...
lstNew<-lapply(2:5,function(i){x1<- combn(names(lstdta2),i);lapply(split(x1,col(x1)),function(x){x2<-paste(x,collapse="_");lst1<-lapply(lstdta2[x],`[`,-1);lst2<-join_all(lst1,by="name",type="inner");names(lst2)<-x2; colnames(lst2)[-1]<-paste("value",1:(ncol(lst2)-1),sep="");lst2}) })

?lstNew1<-lapply(lstNew,function(x) x[lapply(x,nrow)!=0])
?lstNew2<-lstNew1[lapply(lstNew1,length)!=0]
?lstNew2[[1]][1:2]
#$`2`
#? GCKT_KLOI? value1?? value2
#1??? P_CK24? 6.0786? -1.2738
#2??? P_CK29? 1.2757 -13.7960
#3??? P_CK29? 1.2757 -34.8020
#4??? P_CK32 -8.1963 -11.1280
#5??? P_CK32 -8.1963 -35.9044
#
#$`3`
#? GCKT_PLRT? value1?? value2
#1??? P_CK33? 6.2826 -14.4522
#2??? P_CK33? 6.2826? -9.4303
#3??? P_CK30 15.3869 -23.9914
#4??? P_CK30 15.3869 -11.1103
A.K.






----- Original Message -----
From: Nico Met <nicomet80 at gmail.com>
To: dcarlson at tamu.edu
Cc: R help <r-help at r-project.org>
Sent: Wednesday, June 5, 2013 10:30 AM
Subject: Re: [R] split and common variables

Dear Dr. David,

Many thanks for your answer.

Now, if I want to see if there are common "name"in those "places" , how can
I do it? So, by common I mean, it might be compared with 2, 3, 4 .... all
of them. All possible combinations

Many thanks

regards

Nico


On Mon, Jun 3, 2013 at 5:20 PM, David Carlson <dcarlson at tamu.edu> wrote:

> It may be easier if you convert the list you provided to a
> data.frame:
>
> > dta.df <- data.frame(place=dta$place, name=dta$name,
> value=dta$value)
> > dta.df
>
> Note that the last line is blank so you probably want to remove that
> and remove the blank factor levels:
>
> > dta.df <- dta.df[-nrow(dta.df),]
> > dta.df$place <- factor(dta.df$place)
> > dta.df$name <- factor(dta.df$name)
> > dta.df
>
> Now you can make a list containing separate data.frames by place
>
> > dta.df.sp <- split(dta.df, dta.df$place)
> > dta.df.sp
>
> -------------------------------------
> David L Carlson
> Associate Professor of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
> -----Original Message-----
> From: r-help-bounces at r-project.org
> [mailto:r-help-bounces at r-project.org] On Behalf Of Nico Met
> Sent: Monday, June 3, 2013 8:42 AM
> To: R help
> Subject: [R] split and common variables
>
> Dear all,
>
> I would like to split the data based on the "place" and then would
> like to
> see how many "names" were common in place with corresponding "value"
> .
>
> Please find a demo file.
>
> Thanks for your expert comment
>
> best
>
> Nico
>
> > dput(dta)
> structure(list(place = structure(c(3L, 2L, 5L, 6L, 4L, 3L, 2L,
> 5L, 6L, 4L, 2L, 5L, 6L, 4L, 2L, 5L, 6L, 4L, 2L, 3L, 2L, 5L, 6L,
> 4L, 3L, 2L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 1L), .Label = c("",
> "GCKT", "IKLI", "KLOI", "PLRT", "POIV"), class = "factor"), name =
> structure
> (c(2L,
> 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 2L, 3L, 4L, 5L, 6L,
> 7L, 8L, 9L, 10L, 11L, 12L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
> 11L, 12L, 12L, 1L), .Label = c("", "P_CK23", "P_CK24", "P_CK25",
> "P_CK26", "P_CK27", "P_CK28", "P_CK29", "P_CK30", "P_CK31",
> "P_CK32",
> "P_CK33"), class = "factor"), value = c(5.9464, 6.0786, -4.5155,
> 15.0241, -38.1847, -0.0861, 1.2757, -23.9914, 9.5951, -11.128,
> 6.2826, 23.5218, 20.862, 3.1626, 6.242, -20.5348, -14.0126, -13.796,
> 15.3869, -15.7409, -8.1963, -14.4522, 3.2117, -1.2738, 14.3556,
> -12.5337, 20.4308, -3.3227, -34.802, -11.1103, -9.7146, -35.9044,
> -9.4303, -28.1949, NA)), .Names = c("place", "name", "value"), class
> = "data
> .frame", row.names = c(NA,
> 35L))
> >
>
>? ? ? ?  [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From Xochitl.Cormon at ifremer.fr  Wed Jun  5 17:40:01 2013
From: Xochitl.Cormon at ifremer.fr (Xochitl CORMON)
Date: Wed, 05 Jun 2013 17:40:01 +0200
Subject: [R] sample {base}
In-Reply-To: <CAM_vjunvgRXeK7Fxx+LHvZPQDz-S17PQAzBNcy4TnKGSs5EVrQ@mail.gmail.com>
References: <1370384616.88390.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1370391272.9589.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1370397420.70765.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1370401423.51446.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1370402738.70484.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1370403455.40198.YahooMailNeo@web160602.mail.bf1.yahoo.com>
	<1370403750.12728.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1370404333.84419.YahooMailNeo@web160605.mail.bf1.yahoo.com>
	<1370404682.21912.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1370406335.8400.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<1370406649.16477.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1370412356.2514.YahooMailNeo@web160604.mail.bf1.yahoo.com>
	<1370439881.75797.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<51AF4AE0.7050205@ifremer.fr>
	<CAM_vjunvgRXeK7Fxx+LHvZPQDz-S17PQAzBNcy4TnKGSs5EVrQ@mail.gmail.com>
Message-ID: <51AF5BD1.70704@ifremer.fr>



Thank you Sarah for this code, it's exactly what I wanted to reach.


Le 05/06/2013 16:49, Sarah Goslee a ?crit :
> What about using instead
> size = min(5, length(Gpool$SampleNb[Gpool$LngtClas == LngtClas[[4]]&
> Gpool$SpCode == SpCode[[2]]])
>
> that would make sure your sample is either the size of the data or 5.
>
> Sarah
>
> On Wed, Jun 5, 2013 at 10:27 AM, Xochitl CORMON
> <Xochitl.Cormon at ifremer.fr>  wrote:
>> Hi all,
>>
>> I'm trying to randomly select sample numbers for length class groups (5 per
>> length class).
>>
>> For this I'm using a loop FOR and the function sample () and specified a
>> size for the sampling of 5. Unfortunately, one of the length class group
>> does not contain 5 individuals. For me is not a big deal as I have others
>> groups to complete. However it bothers me that the sampling function does
>> not select any individuals in this group generating the error below :
>>
>> Error in sample(Gpool2$SampleNb[Gpool2$LngtClas == LngtClas[[i]]&
>> Gpool2$SpCode ==  : can not take a sample larger than the population when
>> 'replace = FALSE'.
>>
>> I understand why this error message appears but I was wondering if there is
>> a way to select all the items present in the group even if it's not 5
>> (something like size =<  5).
>>
>> LngtClas<- list( "40_49", "50_59", "60_69", "70_")
>> SpCode<- list ("POLLVIR ", "MERLMER")
>>
>> a<- as.character(sample(Gpool$SampleNb[Gpool$LngtClas == LngtClas[[4]]&
>> Gpool$SpCode == SpCode[[2]]], size = 5, replace = FALSE))
>>
>> You can find enclosed my dataset,
>>
>> Thank you for the help,
>>
>> Xochitl C.
>


From neotropical.bats at gmail.com  Wed Jun  5 17:42:11 2013
From: neotropical.bats at gmail.com (Neotropical bat risk assessments)
Date: Wed, 05 Jun 2013 11:42:11 -0400
Subject: [R] reshape2 issue continued
Message-ID: <51AF5C53.1090900@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130605/4f4e2e67/attachment.pl>

From smartpink111 at yahoo.com  Wed Jun  5 17:44:57 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 5 Jun 2013 08:44:57 -0700 (PDT)
Subject: [R] dates and time series management
In-Reply-To: <1370444162.39307.YahooMailNeo@web160601.mail.bf1.yahoo.com>
References: <1370384616.88390.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1370391272.9589.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1370397420.70765.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1370401423.51446.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1370402738.70484.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1370403455.40198.YahooMailNeo@web160602.mail.bf1.yahoo.com>
	<1370403750.12728.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1370404333.84419.YahooMailNeo@web160605.mail.bf1.yahoo.com>
	<1370404682.21912.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1370406335.8400.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<1370406649.16477.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1370412356.2514.YahooMailNeo@web160604.mail.bf1.yahoo.com>
	<1370439881.75797.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1370444162.39307.YahooMailNeo@web160601.mail.bf1.yahoo.com>
Message-ID: <1370447097.93721.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi Atem,
No problem.


?which(res==-9999.99)
# [1]?? 18246? 397379? 420059? 426569? 427109? 603659? 604199? 662518? 664678
#[10]? 698982? 699522? 700062? 701142? 754745 1289823 1500490 1589487 1716011
#[19] 1837083
?which(res==-9999.99,arr.ind=TRUE)
#??????? row col
#1506?? 1506?? 2
#12359 12359? 24
#1559?? 1559? 26
#8069?? 8069? 26

#----------------------
res[ which(res==-9999.99,arr.ind=TRUE)]<-NA
#or

res[res==-9999.99]<-NA
?which(res==-9999.99)
#integer(0)
A.K.




________________________________
From: Zilefac Elvis <zilefacelvis at yahoo.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Wednesday, June 5, 2013 10:56 AM
Subject: Re: dates and time series management



Hi A.K,

It works as expected. You are too smart.
Can you find all -9999.99 and replace with NA, if only it exists?

lst2<-lapply(lst1,function(x) {gsub("(\\d+)(-9999.99)","\\1 \\2",x)})
?lst3<-lapply(lst2,function(x) {x<-gsub("(\\d+)(-9999.99)","\\1 \\2",x)})?


Thanks so much A.K.



________________________________
From: arun <smartpink111 at yahoo.com>
To: Zilefac Elvis <zilefacelvis at yahoo.com> 
Cc: R help <r-help at r-project.org> 
Sent: Wednesday, June 5, 2013 7:44 AM
Subject: Re: dates and time series management


Hi,
Try this:
lstf1<- list.files(pattern=".txt")
length(lstf1)
#[1] 119
fun2<- function(lstf){
?lst1<-lapply(lstf,function(x) readLines(x))
?lst2<-lapply(lst1,function(x) {gsub("(\\d+)(-9999.99)","\\1 \\2",x)})
?lst3<-lapply(lst2,function(x) {x<-gsub("(\\d+)(-9999.99)","\\1
\\2",x)})
?lst4<- lapply(lst3,function(x) read.table(text=x,header=TRUE,stringsAsFactors=FALSE,sep="",fill=TRUE))
?lst5<- lapply(lst4,function(x) x[x$V1>=1961 & x$V1<=2005,])
?lst6<- lapply(lst5,function(x) x[!is.na(x$V1),])
?lst7<- lapply(lst6,function(x) {
???????????????????? if((min(x$V1)>1961)|(max(x$V1)<2005)){
???????????????????????? n1<- (min(x$V1)-1961)*12
???????????????????????? x1<-
as.data.frame(matrix(NA,ncol=ncol(x),nrow=n1))
???????????????????????? n2<- (2005-max(x$V1))*12
???????????????????????? x2<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n2))
???????????????????????? x3<- rbind(x1,x,x2)
??????????????????????? }
????????????????????????? else
{
??????????????????? x
??????????????????? } })

lst8<- lapply(lst7,function(x) data.frame(col1=unlist(x[,-c(1:2)])))
???? lst9<- lapply(seq_along(lst8),function(i){
??????????????????????? x<- lst8[[i]]
??????????????????????? colnames(x)<- lstf1[i]
??????????????????????? row.names(x)<-
1:nrow(x)
??????????????????????? x
??????????????????????? })
?do.call(cbind,lst9)}
res<-fun2(lstf1)
dim(res)
#[1] 16740?? 119
res[1:5,1:3]
?# dt3011120.txt dt3011240.txt dt3011887.txt
#1????????? 1.67??????????? NA????????? 0.17
#2????????? 0.00??????????? NA????????? 0.28
#3?????????
0.00??????????? NA????????? 0.00
#4????????? 0.00??????????? NA????????? 0.30
#5????????? 0.00??????????? NA????????? 0.00


########################################

There are some formatting issues in your files:
For eg. If I run the function line by line:

?lst1<-lapply(lstf1,function(x) readLines(x))
sapply(lst1,function(x) any(grepl("\\d+-9999.99",x)))
? [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
FALSE
?[25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[37]? TRUE FALSE? TRUE FALSE FALSE? TRUE FALSE FALSE FALSE FALSE FALSE FALSE
?[49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[73] FALSE FALSE FALSE FALSE FALSE? TRUE FALSE FALSE FALSE FALSE? TRUE FALSE
?[85] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE? TRUE
?[97] FALSE FALSE FALSE FALSE FALSE FALSE? TRUE? TRUE FALSE FALSE FALSE FALSE
[109] FALSE FALSE FALSE FALSE? TRUE FALSE FALSE FALSE FALSE FALSE? TRUE


###means some rows in the a few files have:
#-9999.99 0 0 0 0.00-9999.99 0 0.00-9999.99 0 0 0 0.00-9999.99 (no space before -9999.99)


?lst2<-lapply(lst1,function(x) {gsub("(\\d+)(-9999.99)","\\1
\\2",x)})
sapply(lst2,function(x) any(grepl("\\d+-9999.99",x))) #still a few files had the problem
? [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[73] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE? TRUE FALSE
?[85] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE? TRUE
?[97] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
[109] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
FALSE
lst3<-lapply(lst2,function(x) {x<-gsub("(\\d+)(-9999.99)","\\1 \\2",x)})
any(sapply(lst3,function(x) any(grepl("\\d+-9999.99",x))))
#[1] FALSE
lst4<- lapply(lst3,function(x) read.table(text=x,header=TRUE,stringsAsFactors=FALSE,sep="",fill=TRUE))


any(sapply(lst4,function(x) any(sapply(x,is.character))))
#[1] FALSE

?lst5<- lapply(lst4,function(x) x[x$V1>=1961 & x$V1<=2005,])
lst6<- lapply(lst5,function(x) x[!is.na(x$V1),])
sapply(lst6,nrow)
?# [1] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [19] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [37] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [55] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [73] 540 540 540 540 528 492 528 540 348 540 540 480 540 540 540 540 540 540
# [91] 540 540 540 540 540 540
540 540 540 540 540 540 540 540 528 540 540 540
#[109] 540 540 540 540 540 540 540 540 540 468 540

???? lst7<- lapply(lst6,function(x) {
???????????????????? if((min(x$V1)>1961)|(max(x$V1)<2005)){
???????????????????????? n1<- (min(x$V1)-1961)*12
???????????????????????? x1<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n1))
???????????????????????? n2<-
(2005-max(x$V1))*12
???????????????????????? x2<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n2))
???????????????????????? x3<- rbind(x1,x,x2)
??????????????????????? }
????????????????????????? else {
??????????????????? x
??????????????????? }
})

?sapply(lst7,nrow)
#? [1] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [19] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [37] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [55] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [73] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [91] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
#[109] 540 540 540 540 540 540 540 540 540 540 540


Hope this helps.
A.K.

________________________________
From: Zilefac Elvis <zilefacelvis at yahoo.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Wednesday, June 5, 2013 2:05
AM
Subject: Re: dates and time series management



Hi A.K,
Sorry my internet connection was so bad last evening.

I have attached all the files as .zip.
Below is the output you requested.
As I explained, the start date in 'res' should be 1961 and end date should be 2005 in all 119 files.

Thanks A.K

> lapply(lst1,head,3)
[[1]]
? V1.V2.V3.V4.V5.V6.V7.V8.V9.V10.V11.V12.V13.V14.V15.V16.V17.V18.V19.V20.V21.V22.V23.V24.V25.V26.V27.V28.V29.V30.V31.V32.V33
1 ? ? ? ? ? ? ? ? ? ? ? ?1915 1 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
2 ? ? ? ? ? ? ? ? ? ? ? ?1915 2 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
3 ? ? ? ? ? ? ? ? ? ?
? ?1915 3 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA

[


From dcarlson at tamu.edu  Wed Jun  5 17:46:07 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Wed, 5 Jun 2013 10:46:07 -0500
Subject: [R] split and common variables
In-Reply-To: <1370446599.36963.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <CAMMD=S4TzsJx3kjmZTG1rWc34oAarYKga=Q=L3PLcvzaWSzo4g@mail.gmail.com>	<015801ce606d$dd637e70$982a7b50$@tamu.edu>
	<CAMMD=S587oU0SngM3DYdPst=3mGOAPFDCWR--vm=YoQ=0He9YA@mail.gmail.com>
	<1370446599.36963.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <043601ce6203$cb899b20$629cd160$@tamu.edu>

Your request is still vague. Arun has given you one approach. This
will tell you which names are found in pairs of places:

> ndf <- length(names(dta.df.sp))
> results <- vector("list")
> for (i in 1:(ndf-1)) {
+ for (j in (i+1):ndf) {
+ pair <- paste(names(dta.df.sp)[i], names(dta.df.sp)[j])
+ results[[pair]] <- intersect(dta.df.sp[[i]]$name,
dta.df.sp[[j]]$name)
+ k <- k+1
+ }
+ }
> results
$`GCKT IKLI`
character(0)

$`GCKT KLOI`
[1] "P_CK24" "P_CK29" "P_CK32"

$`GCKT PLRT`
[1] "P_CK33" "P_CK30"

$`GCKT POIV`
[1] "P_CK24" "P_CK33" "P_CK26"

$`IKLI KLOI`
[1] "P_CK25"

$`IKLI PLRT`
[1] "P_CK23" "P_CK25"

$`IKLI POIV`
[1] "P_CK23" "P_CK28" "P_CK31"

$`KLOI PLRT`
[1] "P_CK27" "P_CK25"

$`KLOI POIV`
[1] "P_CK24"

$`PLRT POIV`
[1] "P_CK23" "P_CK33"

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: arun [mailto:smartpink111 at yahoo.com] 
Sent: Wednesday, June 5, 2013 10:37 AM
To: Nico Met
Cc: dcarlson at tamu.edu; R help
Subject: Re: [R] split and common variables

Hello,
May be this helps:
dta1<-do.call(data.frame,dta)
dta2<-dta1[complete.cases(dta1),]
dta2[,-3]<-lapply(dta2[,-3],as.character)
lstdta2<-split(dta2,dta2$place)
library(plyr)
#Some names are common in a few, but not in all the places. If you
are looking for names common in 2 places, 3, places, etc...
lstNew<-lapply(2:5,function(i){x1<-
combn(names(lstdta2),i);lapply(split(x1,col(x1)),function(x){x2<-pas
te(x,collapse="_");lst1<-lapply(lstdta2[x],`[`,-1);lst2<-join_all(ls
t1,by="name",type="inner");names(lst2)<-x2;
colnames(lst2)[-1]<-paste("value",1:(ncol(lst2)-1),sep="");lst2}) })

?lstNew1<-lapply(lstNew,function(x) x[lapply(x,nrow)!=0])
?lstNew2<-lstNew1[lapply(lstNew1,length)!=0]
?lstNew2[[1]][1:2]
#$`2`
#? GCKT_KLOI? value1?? value2
#1??? P_CK24? 6.0786? -1.2738
#2??? P_CK29? 1.2757 -13.7960
#3??? P_CK29? 1.2757 -34.8020
#4??? P_CK32 -8.1963 -11.1280
#5??? P_CK32 -8.1963 -35.9044
#
#$`3`
#? GCKT_PLRT? value1?? value2
#1??? P_CK33? 6.2826 -14.4522
#2??? P_CK33? 6.2826? -9.4303
#3??? P_CK30 15.3869 -23.9914
#4??? P_CK30 15.3869 -11.1103
A.K.






----- Original Message -----
From: Nico Met <nicomet80 at gmail.com>
To: dcarlson at tamu.edu
Cc: R help <r-help at r-project.org>
Sent: Wednesday, June 5, 2013 10:30 AM
Subject: Re: [R] split and common variables

Dear Dr. David,

Many thanks for your answer.

Now, if I want to see if there are common "name"in those "places" ,
how can
I do it? So, by common I mean, it might be compared with 2, 3, 4
.... all
of them. All possible combinations

Many thanks

regards

Nico


On Mon, Jun 3, 2013 at 5:20 PM, David Carlson <dcarlson at tamu.edu>
wrote:

> It may be easier if you convert the list you provided to a
> data.frame:
>
> > dta.df <- data.frame(place=dta$place, name=dta$name,
> value=dta$value)
> > dta.df
>
> Note that the last line is blank so you probably want to remove
that
> and remove the blank factor levels:
>
> > dta.df <- dta.df[-nrow(dta.df),]
> > dta.df$place <- factor(dta.df$place)
> > dta.df$name <- factor(dta.df$name)
> > dta.df
>
> Now you can make a list containing separate data.frames by place
>
> > dta.df.sp <- split(dta.df, dta.df$place)
> > dta.df.sp
>
> -------------------------------------
> David L Carlson
> Associate Professor of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
> -----Original Message-----
> From: r-help-bounces at r-project.org
> [mailto:r-help-bounces at r-project.org] On Behalf Of Nico Met
> Sent: Monday, June 3, 2013 8:42 AM
> To: R help
> Subject: [R] split and common variables
>
> Dear all,
>
> I would like to split the data based on the "place" and then would
> like to
> see how many "names" were common in place with corresponding
"value"
> .
>
> Please find a demo file.
>
> Thanks for your expert comment
>
> best
>
> Nico
>
> > dput(dta)
> structure(list(place = structure(c(3L, 2L, 5L, 6L, 4L, 3L, 2L,
> 5L, 6L, 4L, 2L, 5L, 6L, 4L, 2L, 5L, 6L, 4L, 2L, 3L, 2L, 5L, 6L,
> 4L, 3L, 2L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 1L), .Label = c("",
> "GCKT", "IKLI", "KLOI", "PLRT", "POIV"), class = "factor"), name =
> structure
> (c(2L,
> 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 2L, 3L, 4L, 5L, 6L,
> 7L, 8L, 9L, 10L, 11L, 12L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
> 11L, 12L, 12L, 1L), .Label = c("", "P_CK23", "P_CK24", "P_CK25",
> "P_CK26", "P_CK27", "P_CK28", "P_CK29", "P_CK30", "P_CK31",
> "P_CK32",
> "P_CK33"), class = "factor"), value = c(5.9464, 6.0786, -4.5155,
> 15.0241, -38.1847, -0.0861, 1.2757, -23.9914, 9.5951, -11.128,
> 6.2826, 23.5218, 20.862, 3.1626, 6.242, -20.5348, -14.0126,
-13.796,
> 15.3869, -15.7409, -8.1963, -14.4522, 3.2117, -1.2738, 14.3556,
> -12.5337, 20.4308, -3.3227, -34.802, -11.1103, -9.7146, -35.9044,
> -9.4303, -28.1949, NA)), .Names = c("place", "name", "value"),
class
> = "data
> .frame", row.names = c(NA,
> 35L))
> >
>
>? ? ? ?  [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From tea3rd at gmail.com  Wed Jun  5 17:55:43 2013
From: tea3rd at gmail.com (Thomas Adams)
Date: Wed, 5 Jun 2013 11:55:43 -0400
Subject: [R] reshape2 issue continued
In-Reply-To: <51AF5C53.1090900@gmail.com>
References: <51AF5C53.1090900@gmail.com>
Message-ID: <CAGxgkWgJs3yAg8jxePKqz3cCA-o9tacQmG9VqOBKBvynhH6Kqw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130605/3592a811/attachment.pl>

From istazahn at gmail.com  Wed Jun  5 19:29:43 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 5 Jun 2013 13:29:43 -0400
Subject: [R] reshape2 issue continued
In-Reply-To: <CAGxgkWgJs3yAg8jxePKqz3cCA-o9tacQmG9VqOBKBvynhH6Kqw@mail.gmail.com>
References: <51AF5C53.1090900@gmail.com>
	<CAGxgkWgJs3yAg8jxePKqz3cCA-o9tacQmG9VqOBKBvynhH6Kqw@mail.gmail.com>
Message-ID: <CA+vqiLFnoXULKvaXY6YugoY7Zp47dGTLetBmgJ--bzLzCBkOXw@mail.gmail.com>

There is indeed a ?cast help topic in reshape2, but there is no cast
function. Instead there is dcast (returns a data.frame) and
acast(returns an array).

Bruce, you can try your original example with

input.cast <- dcast(input.melt, Species ~ Date, fun.aggregate = sum)

Best,
Ista

On Wed, Jun 5, 2013 at 11:55 AM, Thomas Adams <tea3rd at gmail.com> wrote:
> Bruce,
>
> I'm not sure what's going on since I tried this on my Linux system running
> R 3.0.0 and just did:
>
> library(reshape2)
> help(cast)
>
> and the help for 'cast' came up. There was no indication to me that
> 'reshape' was needed and I can not see a dependency in CRAN for 'reshape'.
> But I built R from source when installing R 3.0.0 and all the packages I
> use had to be reinstalled...
>
> Great research, BTW!
>
> Tom
>
>
> On Wed, Jun 5, 2013 at 11:42 AM, Neotropical bat risk assessments <
> neotropical.bats at gmail.com> wrote:
>
>> Hi again all,
>> Several replied ASAP that I also needed reshape loaded and not just
>> reshape2.
>> Hmmm tried that and I had some output but not the correct format.
>>
>> What I need is to run simulations of time overlap between species as per
>> the simulation program data input constraints:
>>
>> The basis for the simulations is a species by _time-use matrix in which
>> species are arranged in rows, and time intervals are arranged
>> chronologically in columns.___ TimeOverlap only uses text tab-delimited
>> files with no headings for columns or rows.Empirical data must be
>> specified in proportional abundances (0 to 100) and totals for each
>> species should be the same (100%).
>>
>> With the existing code the result was rows were correct for species but
>> dates were used for columns rather than the times.
>>
>> The input file read has long format 4 columns - species; location; date;
>> time.
>>
>> It dawns on me I may need to have a sub sample of the main data set by
>> Location ID first then have the code run but for time values and not dates.
>>
>> I need to tweak this a bit more to see if I can figure that out as well.
>>
>> I will have many repetitions of this dat reformatting so it is important
>> I get the code correct one time so I can run this on the gazillion or so
>> data sets accumulated.
>>
>> Rather than use reshape can I use _recast_ in place of cast and stick
>> with reshape2?
>>
>> Bruce
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Wed Jun  5 19:51:10 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 5 Jun 2013 10:51:10 -0700
Subject: [R] Trying to build up functions with its names by means of
	lapply
In-Reply-To: <51AF0BE3.3050500@sapo.pt>
References: <loom.20130605T043218-210@post.gmane.org>
	<250F03A2-77CE-4FAC-B1C9-6754567A3F6A@gmail.com>
	<51AF09A5.4080700@sapo.pt> <51AF0BE3.3050500@sapo.pt>
Message-ID: <CACk-te21kO0xP+4RpvJrLVxoUZjbAVh_h6RbL0JxSwoBH2YwPg@mail.gmail.com>

Rui et al.

Certainly correct.

However, I think the use of force() and similar should be avoided if
possible, as computing on the language can be tricky. So here is an
alternative formulation that avoids it:

faux <- function(c){
  f <- get(paste0(c,"gamma")) ## evaluation of c is forced here
  function(x)f(x,k,scale=theta)
}

Now another way to do this is:

faux <- function(c, nm = paste0(c,"gamma")){
     f <- get(nm)
      function(x)nm(x,k,scale=theta)}

This, in turn, suggests a more flexible function that would work for
any  distribution, using ... to pass in the arguments needed

faux <- function(c, nm = "gamma",...){
     f <- get(paste0(c,nm))
      function(x)f(x,...)
    }

This could be called with:

> xgam <- lapply(c("p","d"), faux, shape=k, scale=theta)
> xgam[[1]](1000)
[1] 0.8710477
> xgam[[2]](1000)
[1] 0.001265311


But it would also work for, e.g. "norm"

> xnorm <- lapply(c("p","d"), faux, nm="norm", mean=5)
> xnorm[[1]](6)
[1] 0.8413447
> xnorm[[2]](6)
[1] 0.2419707

Cheers,
Bert

P.S. Bill Dunlap might have something to say about this. I think there
may be better ways to approach this whole business, but I prefer such
insight from real experts.

-- Bert

On Wed, Jun 5, 2013 at 2:58 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> My solution works but it is incorrect. We should force the argument 'c', not
> the return value. Like said in the help page for force. Which I've only read
> after my first post. The following way makes much more sense and is a bit
> shorter.
>
> faux <- function(c) {
>         force(c)
>         function (x) get(paste0(c,"gamma"))(x,k,scale=theta)
> }
>
> Rui Barradas
>
> Em 05-06-2013 10:49, Rui Barradas escreveu:
>>
>> Hello,
>>
>> If in faux we ?force the return value, the bug is gone.
>>
>>
>> faux <- function(c) {
>>      f <- function (x) get(paste0(c,"gamma"))(x,k,scale=theta)
>>      force(f)
>>      f
>> }
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Em 05-06-2013 07:13, Michael Weylandt escreveu:
>>>
>>>
>>>
>>> On Jun 5, 2013, at 3:53, Julio Sergio <juliosergio at gmail.com> wrote:
>>>
>>>> I want to generate specific gamma distribution functions, given fixed
>>>> parameters.
>>>> This is I have k, and theta, say
>>>>
>>>>    k <- 32.2549       # shape
>>>>    theta <- 26.32809  # scale
>>>>
>>>>
>>>>    # I have an auxiliary function that produces funcions according to
>>>>    # a given character (this is to have either dgamma, pgamma or qgamma)
>>>>    # for the specific parameters given above:
>>>>
>>>>    faux <- function(c) {
>>>>      function (x) get(paste0(c,"gamma"))(x,k,scale=theta)
>>>>    }
>>>>
>>>>    # So I can have, for instance, dgamma, and pgamma with
>>>>
>>>>    dff <- faux("d")
>>>>    pff <- faux("p")
>>>>
>>>>    dff(1000)
>>>>    ## [1] 0.001433138
>>>>
>>>>    pff(1000)
>>>>    ## [1] 0.844305
>>>>
>>>> Now, if I try to produce both functions in one shot with lapply, the
>>>> thing
>>>> doesn't work, see
>>>>
>>>>    ffs <- lapply(c("d", "p"), faux)
>>>>
>>>>    ffs[[1]](1000)
>>>>    ## [1] 0.844305
>>>>
>>>>    ffs[[2]](1000)
>>>>    ## [1] 0.844305
>>>>
>>>> The two produced functions are the very same and correspond to pgamma!!
>>>> Maybe I'm missing something. Do you have any idea?
>>>
>>>
>>> I think you are hitting a bit of strangeness R generously calls 'lazy
>>> evaluation'.  I'm afraid I don't have a reference at hand, but search
>>> the archives for mention of the promise mechanism.
>>>
>>> MW
>>>
>>>>
>>>> Thanks,
>>>>
>>>>   -Sergio.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From jvadams at usgs.gov  Wed Jun  5 20:02:18 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 5 Jun 2013 13:02:18 -0500
Subject: [R] plyr _aply simplifying return-value dimensions
In-Reply-To: <CA+YV+Hw8BokEV88q6m=aht8HgLpszcQ1tEE9vHZSqRRREZwAbA@mail.gmail.com>
References: <CA+YV+Hw8BokEV88q6m=aht8HgLpszcQ1tEE9vHZSqRRREZwAbA@mail.gmail.com>
Message-ID: <CAN5YmCEpz3JymOtRiohJ0F-1T+3SNp30GzjFQ_kGkKNbFExGaQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130605/3a68202c/attachment.pl>

From smartpink111 at yahoo.com  Wed Jun  5 20:34:58 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 5 Jun 2013 11:34:58 -0700 (PDT)
Subject: [R] sample {base}
In-Reply-To: <51AF4AE0.7050205@ifremer.fr>
References: <1370384616.88390.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1370391272.9589.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1370397420.70765.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1370401423.51446.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1370402738.70484.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1370403455.40198.YahooMailNeo@web160602.mail.bf1.yahoo.com>
	<1370403750.12728.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1370404333.84419.YahooMailNeo@web160605.mail.bf1.yahoo.com>
	<1370404682.21912.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1370406335.8400.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<1370406649.16477.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1370412356.2514.YahooMailNeo@web160604.mail.bf1.yahoo.com>
	<1370439881.75797.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<51AF4AE0.7050205@ifremer.fr>
Message-ID: <1370457298.78975.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
Try:
?fun1<- function(dat,Col1,Col2,number){
?lst1<- split(dat,list(dat[,Col1],dat[,Col2]))
?lst2<- lst1[lapply(lst1,nrow)>0]
?res<- lapply(lst2,function(x) sample(x[,1],if(nrow(x)< number) nrow(x) else number,replace=FALSE))
?res}
head(fun1(Gpool,"LngtClas","SpCode",5),4)
#$`40_49.MERLMER`
#[1]? 34? 38 143?? 3? 19
#
#$`50_59.MERLMER`
#[1]? 20 112 115 104? 77
#
#$`60_69.MERLMER`
#[1] 130 136? 40 128? 32
#
#$`70_.MERLMER`
#[1] 44 63 96



A.K.



----- Original Message -----
From: Xochitl CORMON <Xochitl.Cormon at ifremer.fr>
To: r-help at r-project.org
Cc: 
Sent: Wednesday, June 5, 2013 10:27 AM
Subject: [R] sample {base}

Hi all,

I'm trying to randomly select sample numbers for length class groups (5 
per length class).

For this I'm using a loop FOR and the function sample () and specified a 
size for the sampling of 5. Unfortunately, one of the length class group 
does not contain 5 individuals. For me is not a big deal as I have 
others groups to complete. However it bothers me that the sampling 
function does not select any individuals in this group generating the 
error below :

Error in sample(Gpool2$SampleNb[Gpool2$LngtClas == LngtClas[[i]] & 
Gpool2$SpCode ==? : can not take a sample larger than the population 
when 'replace = FALSE'.

I understand why this error message appears but I was wondering if there 
is a way to select all the items present in the group even if it's not 5 
(something like size =< 5).

LngtClas <- list( "40_49", "50_59", "60_69", "70_")
SpCode <- list ("POLLVIR ", "MERLMER")

a <- as.character(sample(Gpool$SampleNb[Gpool$LngtClas == LngtClas[[4]] 
& Gpool$SpCode == SpCode[[2]]], size = 5, replace = FALSE))

You can find enclosed my dataset,

Thank you for the help,

Xochitl C.

<>< <>< <>< <><

Xochitl CORMON
+33 (0)3 21 99 56 84

Doctorante en sciences halieutiques
PhD student in fishery sciences

<>< <>< <>< <><

IFREMER
Centre Manche Mer du Nord
150 quai Gambetta
62200 Boulogne-sur-Mer

<>< <>< <>< <><


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From scott.raynaud at yahoo.com  Wed Jun  5 20:58:20 2013
From: scott.raynaud at yahoo.com (Scott Raynaud)
Date: Wed, 5 Jun 2013 11:58:20 -0700 (PDT)
Subject: [R] SPlus script
In-Reply-To: <CAAcyNCzF-0orndB+0L55onfnhRHUV6+aDTLbe+fVz+RRwJdhcA@mail.gmail.com>
References: <1370438435.93923.YahooMailNeo@web142703.mail.bf1.yahoo.com>
	<CAAcyNCzF-0orndB+0L55onfnhRHUV6+aDTLbe+fVz+RRwJdhcA@mail.gmail.com>
Message-ID: <1370458700.49159.YahooMailNeo@web142702.mail.bf1.yahoo.com>

See my comments below.
________________________________
From: Pascal Oettli <kridox at ymail.com>
To: Scott Raynaud <scott.raynaud at yahoo.com> 
Sent: Wednesday, June 5, 2013 10:02 AM
Subject: Re: [R] SPlus script



Hello,

1) It is always nice to say something as "Hello", Tried, but could make it come out in anything other than four letters.
2) What do you want us to do with that script, without the required "commented, minimal, self-contained, reproducible code"? I want it to run as it did before.? I cannot explain why the exact same code used to run and now doesn't.? I've tried everything I can think of, so maybe brighter minds than mine can shed some light.
3) The lastest version of R is 3.0.1. Yes, I know.? I was trying to keep things as constant as possible.? Besides, do you really think the version wouold make a difference?? The code runs without error.? It just doesn't produce output.? 

Regards,
Pascal



2013/6/5 Scott Raynaud <scott.raynaud at yahoo.com>

This?originally was?an SPlus script that I modifeid about a year-and-a-half ago.? It worked perfectly then.? Now I can't get any output despite not receiving an error message.? I'm providing the SPLUS script as a reference.? I'm running R15.2.2.? Any help appreciated.?
>?
>************************************MY MODIFICATION*********************************************************************
>## sshc.ssc: sample size calculation for historical control studies
>## J. Jack Lee (jjlee at mdanderson.org) and Chi-hong Tseng
>## Department of Biostatistics, Univ. of Texas M.D. Anderson Cancer Center
>##
>## 3/1/99
>## updated 6/7/00: add loess
>##------------------------------------------------------------------
>######## Required Input:
>#
># rc???? number of response in historical control group
># nc???? sample size in historical control
># d????? target improvement = Pe - Pc
># method 1=method based on the randomized design
>#??????? 2=Makuch & Simon method (Makuch RW, Simon RM. Sample size considerations
>#????????? for non-randomized comparative studies. J of Chron Dis 1980; 3:175-181.
>#??????? 3=uniform power method
>######## optional Input:
>#
># alpha? size of the test
># power? desired power of the test
># tol??? convergence criterion for methods 1 & 2 in terms of sample size
># tol1?? convergence criterion for method 3 at any given obs Rc in terms of difference
>#????????? of expected power from target
># tol2?? overall convergence criterion for method 3 as the max absolute deviation
>#????????? of expected power from target for all Rc
># cc???? range of multiplicative constant applied to the initial values ne
># l.span smoothing constant for loess
>#
># Note:? rc is required for methods 1 and 2 but not 3
>#??????? method 3 return the sample size need for rc=0 to (1-d)*nc
>#
>######## Output
># for methdos 1 & 2: return the sample size needed for the experimental group (1 number)
>#??????????????????? for given rc, nc, d, alpha, and power
># for method 3:????? return the profile of sample size needed for given nc, d, alpha, and power
>#??????????????????? vector $ne contains the sample size corresponding to rc=0, 1, 2, ... nc*(1-d)
>#??????????????????? vector $Ep contains the expected power corresponding to
>#????????????????????? the true pc = (0, 1, 2, ..., nc*(1-d)) / nc
>#?????????????????????????????????????????????????
>#------------------------------------------------------------------
>sshc<-function(rc, nc=1092, d=.085779816, method=3, alpha=0.05, power=0.8,
>????????????? tol=0.01, tol1=.0001, tol2=.005, cc=c(.1,2), l.span=.5)
>{
>### for method 1
>if (method==1) {
>?ne1<-ss.rand(rc,nc,d,alpha=.05,power=.8,tol=.01)
>?return(ne=ne1)?
>?????????????? }
>### for method 2
>if (method==2) {
>ne<-nc
>ne1<-nc+50
>while(abs(ne-ne1)>tol & ne1<100000){
>ne<-ne1
>pe<-d+rc/nc
>ne1<-nef(rc,nc,pe*ne,ne,alpha,power)
>## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
>}
>if (ne1>100000) return(NA)
>else return(ne=ne1)
>}
>### for method 3
>if (method==3) {
>if (tol1 > tol2/10) tol1<-tol2/10
>ncstar<-(1-d)*nc
>pc<-(0:ncstar)/nc
>ne<-rep(NA,ncstar + 1)
>for (i in (0:ncstar))
>{ ne[i+1]<-ss.rand(i,nc,d,alpha=.05,power=.8,tol=.01)
>}
>plot(pc,ne,type='l',ylim=c(0,max(ne)*1.5))
>ans<-c.searchd(nc, d, ne, alpha, power, cc, tol1)
>### check overall absolute deviance
>old.abs.dev<-sum(abs(ans$Ep-power))
>##bad<-0
>print(round(ans$Ep,4))
>print(round(ans$ne,2))
>lines(pc,ans$ne,lty=1,col=8)
>old.ne<-ans$ne
>##while(max(abs(ans$Ep-power))>tol2 & bad==0){? #### unnecessary ##
>while(max(abs(ans$Ep-power))>tol2){
>ans<-c.searchd(nc, d, ans$ne, alpha, power, cc, tol1)
>abs.dev<-sum(abs(ans$Ep-power))
>print(paste(" old.abs.dev=",old.abs.dev))
>print(paste("???? abs.dev=",abs.dev))
>##if (abs.dev > old.abs.dev) { bad<-1}
>old.abs.dev<-abs.dev
>print(round(ans$Ep,4))
>print(round(ans$ne,2))
>lines(pc,old.ne,lty=1,col=1)
>lines(pc,ans$ne,lty=1,col=8)
>### add convex
>ans$ne<-convex(pc,ans$ne)$wy
>### add loess
>###old.ne<-ans$ne
>loess.ne<-loess(ans$ne ~ pc, span=l.span)
>lines(pc,loess.ne$fit,lty=1,col=4)
>old.ne<-loess.ne$fit
>###readline()
>}
>return(list(ne=ans$ne, Ep=ans$Ep))?
>?????????????? }
>}
>## needed for method 1
>nef2<-function(rc,nc,re,ne,alpha,power){
>za<-qnorm(1-alpha)
>zb<-qnorm(power)
>xe<-asin(sqrt((re+0.375)/(ne+0.75)))
>xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
>ans<- 1/(4*(xc-xe)^2/(za+zb)^2-1/(nc+0.5)) - 0.5
>return(ans)
>}
>## needed for method 2
>nef<-function(rc,nc,re,ne,alpha,power){
>za<-qnorm(1-alpha)
>zb<-qnorm(power)
>xe<-asin(sqrt((re+0.375)/(ne+0.75)))
>xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
>ans<-(za*sqrt(1+(ne+0.5)/(nc+0.5))+zb)^2/(2*(xe-xc))^2-0.5
>return(ans)
>}
>## needed for method 3
>c.searchd<-function(nc, d, ne, alpha=0.05, power=0.8, cc=c(0.1,2),tol1=0.0001){
>#---------------------------
># nc???? sample size of control group
># d????? the differece to detect between control and experiment
># ne???? vector of starting sample size of experiment group
>#????? corresonding to rc of 0 to nc*(1-d)
># alpha? size of test
># power? target power
># cc?? pre-screen vector of constant c, the range should cover the
>#????? the value of cc that has expected power??
># tol1?? the allowance between the expceted power and target power
>#---------------------------
>pc<-(0:((1-d)*nc))/nc
>ncl<-length(pc)
>ne.old<-ne
>ne.old1<-ne.old
>### sweeping forward
>for(i in 1:ncl){
>?cmin<-cc[1]
>?cmax<-cc[2]
>### fixed cci<-cmax bug?
>?cci <-1
>?lhood<-dbinom((i:ncl)-1,nc,pc[i])
>?ne[i:ncl]<-(1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
>?Ep0 <-Epower(nc, d, ne, pc, alpha)
>?while(abs(Ep0[i]-power)>tol1){
>??if(Ep0[i]<power) cmin<-cci
>??else cmax<-cci
>??cci<-(cmax+cmin)/2??
>??ne[i:ncl]<-(1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
>??Ep0<-Epower(nc, d, ne, pc, alpha)
>?}
>??ne.old1<-ne
>}
>ne1<-ne
>### sweeping backward -- ncl:i
>ne.old2<-ne.old
>ne???? <-ne.old
>for(i in ncl:1){
>?cmin<-cc[1]
>?cmax<-cc[2]
>### fixed cci<-cmax bug?
>?cci <-1
>?lhood<-dbinom((ncl:i)-1,nc,pc[i])
>?lenl <-length(lhood)
>?ne[ncl:i]<-(1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
>?Ep0 <-Epower(nc, d, cci*ne, pc, alpha)
>?while(abs(Ep0[i]-power)>tol1){
>??if(Ep0[i]<power) cmin<-cci
>??else cmax<-cci
>??cci<-(cmax+cmin)/2
>??ne[ncl:i]<-(1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
>??Ep0<-Epower(nc, d, ne, pc, alpha)
>?}
>??ne.old2<-ne
>}
>ne2<-ne
>ne<-(ne1+ne2)/2
>#cat(ccc*ne)
>Ep1<-Epower(nc, d, ne, pc, alpha)
>return(list(ne=ne, Ep=Ep1))
>}
>###
>vertex<-function(x,y)
>{ ?n<-length(x)
>?vx<-x[1]
>?vy<-y[1]
>?vp<-1?
>?up<-T
>?for (i in (2:n))
>?{ if (up)
>??{ ?if (y[i-1] > y[i])
>???{vx<-c(vx,x[i-1])
>??? vy<-c(vy,y[i-1])
>??? vp<-c(vp,i-1)
>??? up<-F
>???}
>??}
>??else
>??{ ?if (y[i-1] < y[i]) up<-T
>??}
>?}
>?vx<-c(vx,x[n])
>?vy<-c(vy,y[n])
>?vp<-c(vp,n)
>?return(list(vx=vx,vy=vy,vp=vp))
>}
>###
>convex<-function(x,y)
>{
>?n<-length(x)
>?ans<-vertex(x,y)
>?len<-length(ans$vx)
>?while (len>3)
>?{ ?
>#??cat("x=",x,"\n")
>#??cat("y=",y,"\n")
>??newx<-x[1:(ans$vp[2]-1)]
>??newy<-y[1:(ans$vp[2]-1)]
>??for (i in (2:(len-1)))
>??{
>?? ?newx<-c(newx,x[ans$vp[i]])
>???newy<-c(newy,y[ans$vp[i]])
>??}
>??newx<-c(newx,x[(ans$vp[len-1]+1):n])
>??newy<-c(newy,y[(ans$vp[len-1]+1):n])
>??y<-approx(newx,newy,xout=x)$y
>#??cat("new y=",y,"\n")
>??ans<-vertex(x,y)
>??len<-length(ans$vx)
>#??cat("vx=",ans$vx,"\n")
>#??cat("vy=",ans$vy,"\n")
>}
>?return(list(wx=x,wy=y))}
>###?
>Epower<-function(nc, d, ne, pc = (0:((1 - d) * nc))/nc, alpha = 0.05)
>{
>#-------------------------------------
># nc???? sample size in historical control
># d????? the increase of response rate between historical and experiment
># ne???? sample size of corresonding rc of 0 to nc*(1-d)
># pc???? the response rate of control group, where we compute the
>#??????? expected power
># alpha? the size of test
>#-------------------------------------
>?kk <- length(pc)
>?rc <- 0:(nc * (1 - d))
>?pp <- rep(NA, kk)
>?ppp <- rep(NA, kk)
>?for(i in 1:(kk)) {
>??pe <- pc[i] + d
>??lhood <- dbinom(rc, nc, pc[i])
>??pp <- power1.f(rc, nc, ne, pe, alpha)
>??ppp[i] <- sum(pp * lhood)/sum(lhood)
>?}
>?return(ppp)
>}
># adapted from the old biss2
>ss.rand<-function(rc,nc,d,alpha=.05,power=.8,tol=.01)
>{
>ne<-nc
>ne1<-nc+50
>while(abs(ne-ne1)>tol & ne1<100000){
>ne<-ne1
>pe<-d+rc/nc
>ne1<-nef2(rc,nc,pe*ne,ne,alpha,power)
>## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
>}
>if (ne1>100000) return(NA)
>else return(ne1)
>}
>###
>power1.f<-function(rc,nc,ne,pie,alpha=0.05){
>#-------------------------------------
># rc?number of response in historical control
># nc?sample size in historical control
># ne??? sample size in experitment group
># pie?true response rate for experiment group
># alpha?size of the test
>#-------------------------------------
>za<-qnorm(1-alpha)
>re<-ne*pie
>xe<-asin(sqrt((re+0.375)/(ne+0.75)))
>xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
>ans<-za*sqrt(1+(ne+0.5)/(nc+0.5))-(xe-xc)/sqrt(1/(4*(ne+0.5)))
>return(1-pnorm(ans))
>}
>
>?
>?
>*************************************ORIGINAL SPLUS SCRIPT************************************************************
>## sshc.ssc: sample size calculation for historical control studies
>## J. Jack Lee (jjlee at mdanderson.org) and Chi-hong Tseng
>## Department of Biostatistics, Univ. of Texas M.D. Anderson Cancer Center
>##
>## 3/1/99
>## updated 6/7/00: add loess
>##------------------------------------------------------------------
>######## Required Input:
>#
># rc ? ? number of response in historical control group
># nc ? ? sample size in historical control
># d ? ? ?target improvement = Pe - Pc
># method 1=method based on the randomized design
># ? ? ? ?2=Makuch & Simon method (Makuch RW, Simon RM. Sample size considerations
># ? ? ? ? ?for non-randomized comparative studies. J of Chron Dis 1980; 3:175-181.
># ? ? ? ?3=uniform power method
>######## optional Input:
>#
># alpha ?size of the test
># power ?desired power of the test
># tol ? ?convergence criterion for methods 1 & 2 in terms of sample size
># tol1 ? convergence criterion for method 3 at any given obs Rc in terms of
>?difference
># ? ? ? ? ?of expected power from target
># tol2 ? overall convergence criterion for method 3 as the max absolute deviation
># ? ? ? ? ?of expected power from target for all Rc
># cc ? ? range of multiplicative constant applied to the initial values ne
># l.span smoothing constant for loess
>#
># Note: ?rc is required for methods 1 and 2 but not 3
># ? ? ? ?method 3 return the sample size need for rc=0 to (1-d)*nc
>#
>######## Output
># for methdos 1 & 2: return the sample size needed for the experimental group (1 number)
># ? ? ? ? ? ? ? ? ? ?for given rc, nc, d, alpha, and power
># for method 3: ? ? ?return the profile of sample size needed for given nc, d, alpha, and power
># ? ? ? ? ? ? ? ? ? ?vector $ne contains the sample size corresponding to rc=0, 1, 2, ... nc*(1-d)
># ? ? ? ? ? ? ? ? ? ?vector $Ep contains the expected power corresponding to
># ? ? ? ? ? ? ? ? ? ? ?the true pc = (0, 1, 2, ..., nc*(1-d)) / nc
>#
>
>#------------------------------------------------------------------
>sshc _ function(rc, nc, d, method, alpha=0.05, power=0.8,
>? ? ? ? ? ? ? ? ? ? ?tol=0.01, tol1=.0001, tol2=.005, cc=c(.1,2), l.span=.5)
>{
>### for method 1
>if (method==1) {
>? ? ? ? ne1 _ ss.rand(rc,nc,d,alpha=.05,power=.8,tol=.01)
>? ? ? ? return(ne=ne1)
>? ? ? ? ? ? ? ?}
>### for method 2
>if (method==2) {
>ne_nc
>ne1_nc+50
>while(abs(ne-ne1)>tol & ne1<100000){
>ne_ne1
>pe_d+rc/nc
>ne1_nef(rc,nc,pe*ne,ne,alpha,power)
>## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
>}
>if (ne1>100000) return(NA)
>else return(ne=ne1)
>}
>### for method 3
>if (method==3) {
>if (tol1 > tol2/10) tol1_tol2/10
>ncstar _ (1-d)*nc
>pc_(0:ncstar)/nc
>ne _ rep(NA,ncstar + 1)
>for (i in (0:ncstar))
>{ ne[i+1] _ ss.rand(i,nc,d,alpha=.05,power=.8,tol=.01)
>}
>plot(pc,ne,type='l',ylim=c(0,max(ne)*1.5))
>ans_c.searchd(nc, d, ne, alpha, power, cc, tol1)
>### check overall absolute deviance
>old.abs.dev _ sum(abs(ans$Ep-power))
>##bad
>?_ 0
>print(round(ans$Ep,4))
>print(round(ans$ne,2))
>lines(pc,ans$ne,lty=1,col=8)
>old.ne _ ans$ne
>##while(max(abs(ans$Ep-power))>tol2 & bad==0){ ?#### unnecessary ##
>while(max(abs(ans$Ep-power))>tol2){
>ans_c.searchd(nc, d, ans$ne, alpha, power, cc, tol1)
>abs.dev _ sum(abs(ans$Ep-power))
>print(paste(" old.abs.dev=",old.abs.dev))
>print(paste(" ? ? abs.dev=",abs.dev))
>##if (abs.dev > old.abs.dev) { bad _ 1}
>old.abs.dev _ abs.dev
>print(round(ans$Ep,4))
>print(round(ans$ne,2))
>lines(pc,old.ne,lty=1,col=1)
>lines(pc,ans$ne,lty=1,col=8)
>### add convex
>ans$ne _ convex(pc,ans$ne)$wy
>### add loess
>###old.ne _ ans$ne
>loess.ne _ loess(ans$ne ~ pc, span=l.span)
>lines(pc,loess.ne$fit,lty=1,col=4)
>old.ne _ loess.ne$fit
>###readline()
>}
>return(ne=ans$ne, Ep=ans$Ep)
>? ? ? ? ? ? ? ?}
>}
>
>## needed for method 1
>nef2_function(rc,nc,re,ne,alpha,power){
>za_qnorm(1-alpha)
>zb_qnorm(power)
>xe_asin(sqrt((re+0.375)/(ne+0.75)))
>xc_asin(sqrt((rc+0.375)/(nc+0.75)))
>ans_
>?1/(4*(xc-xe)^2/(za+zb)^2-1/(nc+0.5)) - 0.5
>return(ans)
>}
>## needed for method 2
>nef_function(rc,nc,re,ne,alpha,power){
>za_qnorm(1-alpha)
>zb_qnorm(power)
>xe_asin(sqrt((re+0.375)/(ne+0.75)))
>xc_asin(sqrt((rc+0.375)/(nc+0.75)))
>ans_(za*sqrt(1+(ne+0.5)/(nc+0.5))+zb)^2/(2*(xe-xc))^2-0.5
>return(ans)
>}
>## needed for method 3
>c.searchd_function(nc, d, ne, alpha=0.05, power=0.8, cc=c(0.1,2),tol1=0.0001){
>#---------------------------
># nc ? ? sample size of control group
># d ? ? ?the differece to detect between control and experiment
># ne ? ? vector of starting sample size of experiment group
># ? ? ? ? ? ? ? ? ? corresonding to rc of 0 to nc*(1-d)
># alpha ?size of test
># power ?target power
># cc ? ? ?pre-screen vector of constant c, the range should cover the
># ? ? ? ? ? ? ? ? ? the value of cc that has expected power
># tol1 ? the allowance between the expceted power and target power
>#---------------------------
>pc_(0:((1-d)*nc))/nc
>ncl _ length(pc)
>ne.old _ ne
>ne.old1 _ ne.old
>###
>?sweeping forward
>for(i in 1:ncl){
>? ? ? ? cmin _ cc[1]
>? ? ? ? cmax _ cc[2]
>### fixed cci_cmax bug
>? ? ? ? cci ?_ 1
>? ? ? ? lhood _ dbinom((i:ncl)-1,nc,pc[i])
>? ? ? ? ne[i:ncl] _ (1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
>? ? ? ? Ep0 ?_ Epower(nc, d, ne, pc, alpha)
>? ? ? ? while(abs(Ep0[i]-power)>tol1){
>? ? ? ? ? ? ? ? if(Ep0[i]<power) cmin_cci
>? ? ? ? ? ? ? ? else cmax_cci
>? ? ? ? ? ? ? ? cci_(cmax+cmin)/2
>? ? ? ? ? ? ? ? ne[i:ncl] _ (1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
>? ? ? ? ? ? ? ? Ep0_Epower(nc, d, ne, pc, alpha)
>? ? ? ? }
>? ? ? ? ne.old1 _ ne
>}
>ne1 _ ne
>### sweeping backward -- ncl:i
>ne.old2 _ ne.old
>ne ? ? ?_ ne.old
>for(i in ncl:1){
>? ? ? ? cmin _ cc[1]
>? ? ? ? cmax _ cc[2]
>### fixed cci_cmax bug
>? ? ? ? cci ?_ 1
>? ? ? ? lhood _ dbinom((ncl:i)-1,nc,pc[i])
>? ? ? ? lenl ?_ length(lhood)
>? ? ? ? ne[ncl:i] _ (1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
>? ? ? ? Ep0 ?_ Epower(nc, d, cci*ne, pc, alpha)
>? ? ? ? while(abs(Ep0[i]-power)>tol1){
>? ? ? ? ? ? ? ? if(Ep0[i]<power) cmin_cci
>? ? ? ? ? ? ? ? else cmax_cci
>? ? ? ? ? ? ? ? cci_(cmax+cmin)/2
>? ? ? ? ? ? ? ? ne[ncl:i] _ (1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
>? ? ? ? ? ? ? ? Ep0_Epower(nc, d, ne, pc, alpha)
>? ? ? ? }
>? ? ? ? ne.old2 _ ne
>}
>
>ne2 _ ne
>ne _ (ne1+ne2)/2
>#cat(ccc*ne)
>Ep1_Epower(nc, d, ne, pc, alpha)
>return(ne=ne, Ep=Ep1)
>}
>###
>vertex _ function(x,y)
>{ ? ? ? n _ length(x)
>? ? ? ? vx _ x[1]
>? ? ? ? vy _ y[1]
>? ? ? ? vp _ 1
>? ? ? ? up _ T
>? ? ? ? for (i in (2:n))
>? ? ? ? { if (up)
>? ? ? ? ? ? ? ? { ? ? ? if (y[i-1] > y[i])
>? ? ? ? ? ? ? ? ? ? ? ? {vx _ c(vx,x[i-1])
>? ? ? ? ? ? ? ? ? ? ? ? ?vy _ c(vy,y[i-1])
>? ? ? ? ? ? ? ? ? ? ? ? ?vp _ c(vp,i-1)
>? ? ? ? ? ? ? ? ? ? ? ? ?up _ F
>? ? ? ? ? ? ? ? ? ? ? ? }
>? ? ? ? ? ? ? ? }
>? ? ? ? ? ? ? ? else
>? ? ? ? ? ? ? ? { ? ? ? if (y[i-1] < y[i]) up _ T
>? ? ? ? ? ? ? ? }
>? ? ? ? }
>? ? ? ? vx _ c(vx,x[n])
>? ? ? ? vy _ c(vy,y[n])
>? ? ? ? vp _ c(vp,n)
>? ? ? ? return(vx=vx,vy=vy,vp=vp)
>}
>###
>convex _ function(x,y)
>{
>? ? ? ? n _ length(x)
>? ? ? ? ans _ vertex(x,y)
>? ? ? ? len _ length(ans$vx)
>? ? ? ? while (len>3)
>? ? ? ? {
># ? ? ? ? ? ? ? cat("x=",x,"\n")
># ? ? ? ? ? ? ? cat("y=",y,"\n")
>? ? ? ? ? ? ? ? newx _ x[1:(ans$vp[2]-1)]
>? ? ? ? ? ? ? ? newy _ y[1:(ans$vp[2]-1)]
>? ? ? ? ? ? ? ? for (i in (2:(len-1)))
>? ? ? ? ? ? ? ? {
>? ? ? ? ? ? ? ? ? ? ? ? newx _ c(newx,x[ans$vp[i]])
>? ? ? ? ? ? ? ? ? ? ? ? newy _ c(newy,y[ans$vp[i]])
>? ? ? ? ? ? ? ? }
>? ? ? ? ? ? ? ? newx _ c(newx,x[(ans$vp[len-1]+1):n])
>? ? ? ? ? ? ? ? newy _ c(newy,y[(ans$vp[len-1]+1):n])
>? ? ? ? ? ? ? ? y _ approx(newx,newy,xout=x)$y
># ? ? ? ? ? ? ? cat("new y=",y,"\n")
>? ? ? ? ? ? ? ? ans _ vertex(x,y)
>? ? ? ? ? ? ? ? len _ length(ans$vx)
># ? ? ? ? ? ? ? cat("vx=",ans$vx,"\n")
># ? ? ? ? ? ? ? cat("vy=",ans$vy,"\n")
>
>}
>? ? ? ? return(wx=x,wy=y)}
>###
>Epower _ function(nc, d, ne, pc = (0:((1 - d) * nc))/nc, alpha = 0.05)
>{
>#-------------------------------------
># nc ? ? sample size in historical control
># d ? ? ?the increase of response rate between historical and experiment
># ne ? ? sample size of corresonding rc of 0 to nc*(1-d)
># pc ? ? the response rate of control group, where we compute the
># ? ? ? ?expected power
># alpha ?the size of test
>#-------------------------------------
>? ? ? ? kk <- length(pc)
>? ? ? ? rc <- 0:(nc * (1 - d))
>? ? ? ? pp <- rep(NA, kk)
>? ? ? ? ppp <- rep(NA, kk)
>? ? ? ? for(i in 1:(kk)) {
>? ? ? ? ? ? ? ? pe <- pc[i] + d
>? ? ? ? ? ? ? ? lhood <- dbinom(rc, nc, pc[i])
>? ? ? ? ? ? ? ? pp <- power1.f(rc, nc, ne, pe, alpha)
>? ? ? ? ? ? ? ? ppp[i] <- sum(pp * lhood)/sum(lhood)
>? ? ? ? }
>? ? ? ? return(ppp)
>}
>
># adapted from the old biss2
>ss.rand _ function(rc,nc,d,alpha=.05,power=.8,tol=.01)
>{
>ne_nc
>ne1_nc+50
>while(abs(ne-ne1)>tol & ne1<100000){
>ne_ne1
>pe_d+rc/nc
>ne1_nef2(rc,nc,pe*ne,ne,alpha,power)
>
>## if(is.na(ne1))
>?print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
>}
>if (ne1>100000) return(NA)
>else return(ne1)
>}
>###
>power1.f_function(rc,nc,ne,pie,alpha=0.05){
>#-------------------------------------
># rc ? ?number of response in historical control
># nc ? ?sample size in historical control
># ne ? ?sample size in experitment group
># pie ? true response rate for experiment group
># alpha size of the test
>#-------------------------------------
>
>za_qnorm(1-alpha)
>re_ne*pie
>xe_asin(sqrt((re+0.375)/(ne+0.75)))
>xc_asin(sqrt((rc+0.375)/(nc+0.75)))
>ans_za*sqrt(1+(ne+0.5)/(nc+0.5))-(xe-xc)/sqrt(1/(4*(ne+0.5)))
>return(1-pnorm(ans))
>}
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


From jrkrideau at inbox.com  Wed Jun  5 21:04:21 2013
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 5 Jun 2013 11:04:21 -0800
Subject: [R] reshape2 issue continued
In-Reply-To: <CAGxgkWgJs3yAg8jxePKqz3cCA-o9tacQmG9VqOBKBvynhH6Kqw@mail.gmail.com>
References: <51af5c53.1090900@gmail.com>
Message-ID: <FF39131AE4D.000000D1jrkrideau@inbox.com>

Interestingly enoughhelp(cast) did not work but ?cast does

As Ista says, there is no cast() in reshape2 

John Kane
Kingston ON Canada


> -----Original Message-----
> From: tea3rd at gmail.com
> Sent: Wed, 5 Jun 2013 11:55:43 -0400
> To: neotropical.bats at gmail.com
> Subject: Re: [R] reshape2 issue continued
> 
> Bruce,
> 
> I'm not sure what's going on since I tried this on my Linux system
> running
> R 3.0.0 and just did:
> 
> library(reshape2)
> help(cast)
> 
> and the help for 'cast' came up. There was no indication to me that
> 'reshape' was needed and I can not see a dependency in CRAN for
> 'reshape'.
> But I built R from source when installing R 3.0.0 and all the packages I
> use had to be reinstalled...
> 
> Great research, BTW!
> 
> Tom
> 
> 
> On Wed, Jun 5, 2013 at 11:42 AM, Neotropical bat risk assessments <
> neotropical.bats at gmail.com> wrote:
> 
>> Hi again all,
>> Several replied ASAP that I also needed reshape loaded and not just
>> reshape2.
>> Hmmm tried that and I had some output but not the correct format.
>> 
>> What I need is to run simulations of time overlap between species as per
>> the simulation program data input constraints:
>> 
>> The basis for the simulations is a species by _time-use matrix in which
>> species are arranged in rows, and time intervals are arranged
>> chronologically in columns.___ TimeOverlap only uses text tab-delimited
>> files with no headings for columns or rows.Empirical data must be
>> specified in proportional abundances (0 to 100) and totals for each
>> species should be the same (100%).
>> 
>> With the existing code the result was rows were correct for species but
>> dates were used for columns rather than the times.
>> 
>> The input file read has long format 4 columns - species; location; date;
>> time.
>> 
>> It dawns on me I may need to have a sub sample of the main data set by
>> Location ID first then have the code run but for time values and not
>> dates.
>> 
>> I need to tweak this a bit more to see if I can figure that out as well.
>> 
>> I will have many repetitions of this dat reformatting so it is important
>> I get the code correct one time so I can run this on the gazillion or so
>> data sets accumulated.
>> 
>> Rather than use reshape can I use _recast_ in place of cast and stick
>> with reshape2?
>> 
>> Bruce
>> 
>>         [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From pdalgd at gmail.com  Wed Jun  5 21:10:17 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 5 Jun 2013 21:10:17 +0200
Subject: [R] SPlus script
In-Reply-To: <1370458700.49159.YahooMailNeo@web142702.mail.bf1.yahoo.com>
References: <1370438435.93923.YahooMailNeo@web142703.mail.bf1.yahoo.com>
	<CAAcyNCzF-0orndB+0L55onfnhRHUV6+aDTLbe+fVz+RRwJdhcA@mail.gmail.com>
	<1370458700.49159.YahooMailNeo@web142702.mail.bf1.yahoo.com>
Message-ID: <78E4D6D9-4578-4181-9BD5-FAEAAF851E66@gmail.com>


On Jun 5, 2013, at 20:58 , Scott Raynaud wrote:

> See my comments below.
> ________________________________
> From: Pascal Oettli <kridox at ymail.com>
> To: Scott Raynaud <scott.raynaud at yahoo.com> 
> Sent: Wednesday, June 5, 2013 10:02 AM
> Subject: Re: [R] SPlus script
> 
> 
> 
> Hello,
> 
> 1) It is always nice to say something as "Hello", Tried, but could make it come out in anything other than four letters.

Well, hello to you too, then.

> 2) What do you want us to do with that script, without the required "commented, minimal, self-contained, reproducible code"? I want it to run as it did before.  I cannot explain why the exact same code used to run and now doesn't.  I've tried everything I can think of, so maybe brighter minds than mine can shed some light.

It's using "_" for assignment, and that hasn't worked in R for a decade or so...

> 3) The lastest version of R is 3.0.1. Yes, I know.  I was trying to keep things as constant as possible.  Besides, do you really think the version wouold make a difference?  The code runs without error.  It just doesn't produce output.  
> 
> Regards,
> Pascal
> 
> 
> 
> 2013/6/5 Scott Raynaud <scott.raynaud at yahoo.com>
> 
> This originally was an SPlus script that I modifeid about a year-and-a-half ago.  It worked perfectly then.  Now I can't get any output despite not receiving an error message.  I'm providing the SPLUS script as a reference.  I'm running R15.2.2.  Any help appreciated. 
>>  
>> ************************************MY MODIFICATION*********************************************************************
>> ## sshc.ssc: sample size calculation for historical control studies
>> ## J. Jack Lee (jjlee at mdanderson.org) and Chi-hong Tseng
>> ## Department of Biostatistics, Univ. of Texas M.D. Anderson Cancer Center
>> ##
>> ## 3/1/99
>> ## updated 6/7/00: add loess
>> ##------------------------------------------------------------------
>> ######## Required Input:
>> #
>> # rc     number of response in historical control group
>> # nc     sample size in historical control
>> # d      target improvement = Pe - Pc
>> # method 1=method based on the randomized design
>> #        2=Makuch & Simon method (Makuch RW, Simon RM. Sample size considerations
>> #          for non-randomized comparative studies. J of Chron Dis 1980; 3:175-181.
>> #        3=uniform power method
>> ######## optional Input:
>> #
>> # alpha  size of the test
>> # power  desired power of the test
>> # tol    convergence criterion for methods 1 & 2 in terms of sample size
>> # tol1   convergence criterion for method 3 at any given obs Rc in terms of difference
>> #          of expected power from target
>> # tol2   overall convergence criterion for method 3 as the max absolute deviation
>> #          of expected power from target for all Rc
>> # cc     range of multiplicative constant applied to the initial values ne
>> # l.span smoothing constant for loess
>> #
>> # Note:  rc is required for methods 1 and 2 but not 3
>> #        method 3 return the sample size need for rc=0 to (1-d)*nc
>> #
>> ######## Output
>> # for methdos 1 & 2: return the sample size needed for the experimental group (1 number)
>> #                    for given rc, nc, d, alpha, and power
>> # for method 3:      return the profile of sample size needed for given nc, d, alpha, and power
>> #                    vector $ne contains the sample size corresponding to rc=0, 1, 2, ... nc*(1-d)
>> #                    vector $Ep contains the expected power corresponding to
>> #                      the true pc = (0, 1, 2, ..., nc*(1-d)) / nc
>> #                                                 
>> #------------------------------------------------------------------
>> sshc<-function(rc, nc=1092, d=.085779816, method=3, alpha=0.05, power=0.8,
>>               tol=0.01, tol1=.0001, tol2=.005, cc=c(.1,2), l.span=.5)
>> {
>> ### for method 1
>> if (method==1) {
>>  ne1<-ss.rand(rc,nc,d,alpha=.05,power=.8,tol=.01)
>>  return(ne=ne1) 
>>                }
>> ### for method 2
>> if (method==2) {
>> ne<-nc
>> ne1<-nc+50
>> while(abs(ne-ne1)>tol & ne1<100000){
>> ne<-ne1
>> pe<-d+rc/nc
>> ne1<-nef(rc,nc,pe*ne,ne,alpha,power)
>> ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
>> }
>> if (ne1>100000) return(NA)
>> else return(ne=ne1)
>> }
>> ### for method 3
>> if (method==3) {
>> if (tol1 > tol2/10) tol1<-tol2/10
>> ncstar<-(1-d)*nc
>> pc<-(0:ncstar)/nc
>> ne<-rep(NA,ncstar + 1)
>> for (i in (0:ncstar))
>> { ne[i+1]<-ss.rand(i,nc,d,alpha=.05,power=.8,tol=.01)
>> }
>> plot(pc,ne,type='l',ylim=c(0,max(ne)*1.5))
>> ans<-c.searchd(nc, d, ne, alpha, power, cc, tol1)
>> ### check overall absolute deviance
>> old.abs.dev<-sum(abs(ans$Ep-power))
>> ##bad<-0
>> print(round(ans$Ep,4))
>> print(round(ans$ne,2))
>> lines(pc,ans$ne,lty=1,col=8)
>> old.ne<-ans$ne
>> ##while(max(abs(ans$Ep-power))>tol2 & bad==0){  #### unnecessary ##
>> while(max(abs(ans$Ep-power))>tol2){
>> ans<-c.searchd(nc, d, ans$ne, alpha, power, cc, tol1)
>> abs.dev<-sum(abs(ans$Ep-power))
>> print(paste(" old.abs.dev=",old.abs.dev))
>> print(paste("     abs.dev=",abs.dev))
>> ##if (abs.dev > old.abs.dev) { bad<-1}
>> old.abs.dev<-abs.dev
>> print(round(ans$Ep,4))
>> print(round(ans$ne,2))
>> lines(pc,old.ne,lty=1,col=1)
>> lines(pc,ans$ne,lty=1,col=8)
>> ### add convex
>> ans$ne<-convex(pc,ans$ne)$wy
>> ### add loess
>> ###old.ne<-ans$ne
>> loess.ne<-loess(ans$ne ~ pc, span=l.span)
>> lines(pc,loess.ne$fit,lty=1,col=4)
>> old.ne<-loess.ne$fit
>> ###readline()
>> }
>> return(list(ne=ans$ne, Ep=ans$Ep)) 
>>                }
>> }
>> ## needed for method 1
>> nef2<-function(rc,nc,re,ne,alpha,power){
>> za<-qnorm(1-alpha)
>> zb<-qnorm(power)
>> xe<-asin(sqrt((re+0.375)/(ne+0.75)))
>> xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
>> ans<- 1/(4*(xc-xe)^2/(za+zb)^2-1/(nc+0.5)) - 0.5
>> return(ans)
>> }
>> ## needed for method 2
>> nef<-function(rc,nc,re,ne,alpha,power){
>> za<-qnorm(1-alpha)
>> zb<-qnorm(power)
>> xe<-asin(sqrt((re+0.375)/(ne+0.75)))
>> xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
>> ans<-(za*sqrt(1+(ne+0.5)/(nc+0.5))+zb)^2/(2*(xe-xc))^2-0.5
>> return(ans)
>> }
>> ## needed for method 3
>> c.searchd<-function(nc, d, ne, alpha=0.05, power=0.8, cc=c(0.1,2),tol1=0.0001){
>> #---------------------------
>> # nc     sample size of control group
>> # d      the differece to detect between control and experiment
>> # ne     vector of starting sample size of experiment group
>> #      corresonding to rc of 0 to nc*(1-d)
>> # alpha  size of test
>> # power  target power
>> # cc   pre-screen vector of constant c, the range should cover the
>> #      the value of cc that has expected power  
>> # tol1   the allowance between the expceted power and target power
>> #---------------------------
>> pc<-(0:((1-d)*nc))/nc
>> ncl<-length(pc)
>> ne.old<-ne
>> ne.old1<-ne.old
>> ### sweeping forward
>> for(i in 1:ncl){
>>  cmin<-cc[1]
>>  cmax<-cc[2]
>> ### fixed cci<-cmax bug 
>>  cci <-1
>>  lhood<-dbinom((i:ncl)-1,nc,pc[i])
>>  ne[i:ncl]<-(1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
>>  Ep0 <-Epower(nc, d, ne, pc, alpha)
>>  while(abs(Ep0[i]-power)>tol1){
>>   if(Ep0[i]<power) cmin<-cci
>>   else cmax<-cci
>>   cci<-(cmax+cmin)/2  
>>   ne[i:ncl]<-(1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
>>   Ep0<-Epower(nc, d, ne, pc, alpha)
>>  }
>>   ne.old1<-ne
>> }
>> ne1<-ne
>> ### sweeping backward -- ncl:i
>> ne.old2<-ne.old
>> ne     <-ne.old
>> for(i in ncl:1){
>>  cmin<-cc[1]
>>  cmax<-cc[2]
>> ### fixed cci<-cmax bug 
>>  cci <-1
>>  lhood<-dbinom((ncl:i)-1,nc,pc[i])
>>  lenl <-length(lhood)
>>  ne[ncl:i]<-(1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
>>  Ep0 <-Epower(nc, d, cci*ne, pc, alpha)
>>  while(abs(Ep0[i]-power)>tol1){
>>   if(Ep0[i]<power) cmin<-cci
>>   else cmax<-cci
>>   cci<-(cmax+cmin)/2
>>   ne[ncl:i]<-(1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
>>   Ep0<-Epower(nc, d, ne, pc, alpha)
>>  }
>>   ne.old2<-ne
>> }
>> ne2<-ne
>> ne<-(ne1+ne2)/2
>> #cat(ccc*ne)
>> Ep1<-Epower(nc, d, ne, pc, alpha)
>> return(list(ne=ne, Ep=Ep1))
>> }
>> ###
>> vertex<-function(x,y)
>> {  n<-length(x)
>>  vx<-x[1]
>>  vy<-y[1]
>>  vp<-1 
>>  up<-T
>>  for (i in (2:n))
>>  { if (up)
>>   {  if (y[i-1] > y[i])
>>    {vx<-c(vx,x[i-1])
>>     vy<-c(vy,y[i-1])
>>     vp<-c(vp,i-1)
>>     up<-F
>>    }
>>   }
>>   else
>>   {  if (y[i-1] < y[i]) up<-T
>>   }
>>  }
>>  vx<-c(vx,x[n])
>>  vy<-c(vy,y[n])
>>  vp<-c(vp,n)
>>  return(list(vx=vx,vy=vy,vp=vp))
>> }
>> ###
>> convex<-function(x,y)
>> {
>>  n<-length(x)
>>  ans<-vertex(x,y)
>>  len<-length(ans$vx)
>>  while (len>3)
>>  {  
>> #  cat("x=",x,"\n")
>> #  cat("y=",y,"\n")
>>   newx<-x[1:(ans$vp[2]-1)]
>>   newy<-y[1:(ans$vp[2]-1)]
>>   for (i in (2:(len-1)))
>>   {
>>     newx<-c(newx,x[ans$vp[i]])
>>    newy<-c(newy,y[ans$vp[i]])
>>   }
>>   newx<-c(newx,x[(ans$vp[len-1]+1):n])
>>   newy<-c(newy,y[(ans$vp[len-1]+1):n])
>>   y<-approx(newx,newy,xout=x)$y
>> #  cat("new y=",y,"\n")
>>   ans<-vertex(x,y)
>>   len<-length(ans$vx)
>> #  cat("vx=",ans$vx,"\n")
>> #  cat("vy=",ans$vy,"\n")
>> }
>>  return(list(wx=x,wy=y))}
>> ### 
>> Epower<-function(nc, d, ne, pc = (0:((1 - d) * nc))/nc, alpha = 0.05)
>> {
>> #-------------------------------------
>> # nc     sample size in historical control
>> # d      the increase of response rate between historical and experiment
>> # ne     sample size of corresonding rc of 0 to nc*(1-d)
>> # pc     the response rate of control group, where we compute the
>> #        expected power
>> # alpha  the size of test
>> #-------------------------------------
>>  kk <- length(pc)
>>  rc <- 0:(nc * (1 - d))
>>  pp <- rep(NA, kk)
>>  ppp <- rep(NA, kk)
>>  for(i in 1:(kk)) {
>>   pe <- pc[i] + d
>>   lhood <- dbinom(rc, nc, pc[i])
>>   pp <- power1.f(rc, nc, ne, pe, alpha)
>>   ppp[i] <- sum(pp * lhood)/sum(lhood)
>>  }
>>  return(ppp)
>> }
>> # adapted from the old biss2
>> ss.rand<-function(rc,nc,d,alpha=.05,power=.8,tol=.01)
>> {
>> ne<-nc
>> ne1<-nc+50
>> while(abs(ne-ne1)>tol & ne1<100000){
>> ne<-ne1
>> pe<-d+rc/nc
>> ne1<-nef2(rc,nc,pe*ne,ne,alpha,power)
>> ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
>> }
>> if (ne1>100000) return(NA)
>> else return(ne1)
>> }
>> ###
>> power1.f<-function(rc,nc,ne,pie,alpha=0.05){
>> #-------------------------------------
>> # rc number of response in historical control
>> # nc sample size in historical control
>> # ne    sample size in experitment group
>> # pie true response rate for experiment group
>> # alpha size of the test
>> #-------------------------------------
>> za<-qnorm(1-alpha)
>> re<-ne*pie
>> xe<-asin(sqrt((re+0.375)/(ne+0.75)))
>> xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
>> ans<-za*sqrt(1+(ne+0.5)/(nc+0.5))-(xe-xc)/sqrt(1/(4*(ne+0.5)))
>> return(1-pnorm(ans))
>> }
>> 
>>  
>>  
>> *************************************ORIGINAL SPLUS SCRIPT************************************************************
>> ## sshc.ssc: sample size calculation for historical control studies
>> ## J. Jack Lee (jjlee at mdanderson.org) and Chi-hong Tseng
>> ## Department of Biostatistics, Univ. of Texas M.D. Anderson Cancer Center
>> ##
>> ## 3/1/99
>> ## updated 6/7/00: add loess
>> ##------------------------------------------------------------------
>> ######## Required Input:
>> #
>> # rc     number of response in historical control group
>> # nc     sample size in historical control
>> # d      target improvement = Pe - Pc
>> # method 1=method based on the randomized design
>> #        2=Makuch & Simon method (Makuch RW, Simon RM. Sample size considerations
>> #          for non-randomized comparative studies. J of Chron Dis 1980; 3:175-181.
>> #        3=uniform power method
>> ######## optional Input:
>> #
>> # alpha  size of the test
>> # power  desired power of the test
>> # tol    convergence criterion for methods 1 & 2 in terms of sample size
>> # tol1   convergence criterion for method 3 at any given obs Rc in terms of
>>  difference
>> #          of expected power from target
>> # tol2   overall convergence criterion for method 3 as the max absolute deviation
>> #          of expected power from target for all Rc
>> # cc     range of multiplicative constant applied to the initial values ne
>> # l.span smoothing constant for loess
>> #
>> # Note:  rc is required for methods 1 and 2 but not 3
>> #        method 3 return the sample size need for rc=0 to (1-d)*nc
>> #
>> ######## Output
>> # for methdos 1 & 2: return the sample size needed for the experimental group (1 number)
>> #                    for given rc, nc, d, alpha, and power
>> # for method 3:      return the profile of sample size needed for given nc, d, alpha, and power
>> #                    vector $ne contains the sample size corresponding to rc=0, 1, 2, ... nc*(1-d)
>> #                    vector $Ep contains the expected power corresponding to
>> #                      the true pc = (0, 1, 2, ..., nc*(1-d)) / nc
>> #
>> 
>> #------------------------------------------------------------------
>> sshc _ function(rc, nc, d, method, alpha=0.05, power=0.8,
>>                      tol=0.01, tol1=.0001, tol2=.005, cc=c(.1,2), l.span=.5)
>> {
>> ### for method 1
>> if (method==1) {
>>         ne1 _ ss.rand(rc,nc,d,alpha=.05,power=.8,tol=.01)
>>         return(ne=ne1)
>>                }
>> ### for method 2
>> if (method==2) {
>> ne_nc
>> ne1_nc+50
>> while(abs(ne-ne1)>tol & ne1<100000){
>> ne_ne1
>> pe_d+rc/nc
>> ne1_nef(rc,nc,pe*ne,ne,alpha,power)
>> ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
>> }
>> if (ne1>100000) return(NA)
>> else return(ne=ne1)
>> }
>> ### for method 3
>> if (method==3) {
>> if (tol1 > tol2/10) tol1_tol2/10
>> ncstar _ (1-d)*nc
>> pc_(0:ncstar)/nc
>> ne _ rep(NA,ncstar + 1)
>> for (i in (0:ncstar))
>> { ne[i+1] _ ss.rand(i,nc,d,alpha=.05,power=.8,tol=.01)
>> }
>> plot(pc,ne,type='l',ylim=c(0,max(ne)*1.5))
>> ans_c.searchd(nc, d, ne, alpha, power, cc, tol1)
>> ### check overall absolute deviance
>> old.abs.dev _ sum(abs(ans$Ep-power))
>> ##bad
>>  _ 0
>> print(round(ans$Ep,4))
>> print(round(ans$ne,2))
>> lines(pc,ans$ne,lty=1,col=8)
>> old.ne _ ans$ne
>> ##while(max(abs(ans$Ep-power))>tol2 & bad==0){  #### unnecessary ##
>> while(max(abs(ans$Ep-power))>tol2){
>> ans_c.searchd(nc, d, ans$ne, alpha, power, cc, tol1)
>> abs.dev _ sum(abs(ans$Ep-power))
>> print(paste(" old.abs.dev=",old.abs.dev))
>> print(paste("     abs.dev=",abs.dev))
>> ##if (abs.dev > old.abs.dev) { bad _ 1}
>> old.abs.dev _ abs.dev
>> print(round(ans$Ep,4))
>> print(round(ans$ne,2))
>> lines(pc,old.ne,lty=1,col=1)
>> lines(pc,ans$ne,lty=1,col=8)
>> ### add convex
>> ans$ne _ convex(pc,ans$ne)$wy
>> ### add loess
>> ###old.ne _ ans$ne
>> loess.ne _ loess(ans$ne ~ pc, span=l.span)
>> lines(pc,loess.ne$fit,lty=1,col=4)
>> old.ne _ loess.ne$fit
>> ###readline()
>> }
>> return(ne=ans$ne, Ep=ans$Ep)
>>                }
>> }
>> 
>> ## needed for method 1
>> nef2_function(rc,nc,re,ne,alpha,power){
>> za_qnorm(1-alpha)
>> zb_qnorm(power)
>> xe_asin(sqrt((re+0.375)/(ne+0.75)))
>> xc_asin(sqrt((rc+0.375)/(nc+0.75)))
>> ans_
>>  1/(4*(xc-xe)^2/(za+zb)^2-1/(nc+0.5)) - 0.5
>> return(ans)
>> }
>> ## needed for method 2
>> nef_function(rc,nc,re,ne,alpha,power){
>> za_qnorm(1-alpha)
>> zb_qnorm(power)
>> xe_asin(sqrt((re+0.375)/(ne+0.75)))
>> xc_asin(sqrt((rc+0.375)/(nc+0.75)))
>> ans_(za*sqrt(1+(ne+0.5)/(nc+0.5))+zb)^2/(2*(xe-xc))^2-0.5
>> return(ans)
>> }
>> ## needed for method 3
>> c.searchd_function(nc, d, ne, alpha=0.05, power=0.8, cc=c(0.1,2),tol1=0.0001){
>> #---------------------------
>> # nc     sample size of control group
>> # d      the differece to detect between control and experiment
>> # ne     vector of starting sample size of experiment group
>> #                   corresonding to rc of 0 to nc*(1-d)
>> # alpha  size of test
>> # power  target power
>> # cc      pre-screen vector of constant c, the range should cover the
>> #                   the value of cc that has expected power
>> # tol1   the allowance between the expceted power and target power
>> #---------------------------
>> pc_(0:((1-d)*nc))/nc
>> ncl _ length(pc)
>> ne.old _ ne
>> ne.old1 _ ne.old
>> ###
>>  sweeping forward
>> for(i in 1:ncl){
>>         cmin _ cc[1]
>>         cmax _ cc[2]
>> ### fixed cci_cmax bug
>>         cci  _ 1
>>         lhood _ dbinom((i:ncl)-1,nc,pc[i])
>>         ne[i:ncl] _ (1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
>>         Ep0  _ Epower(nc, d, ne, pc, alpha)
>>         while(abs(Ep0[i]-power)>tol1){
>>                 if(Ep0[i]<power) cmin_cci
>>                 else cmax_cci
>>                 cci_(cmax+cmin)/2
>>                 ne[i:ncl] _ (1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
>>                 Ep0_Epower(nc, d, ne, pc, alpha)
>>         }
>>         ne.old1 _ ne
>> }
>> ne1 _ ne
>> ### sweeping backward -- ncl:i
>> ne.old2 _ ne.old
>> ne      _ ne.old
>> for(i in ncl:1){
>>         cmin _ cc[1]
>>         cmax _ cc[2]
>> ### fixed cci_cmax bug
>>         cci  _ 1
>>         lhood _ dbinom((ncl:i)-1,nc,pc[i])
>>         lenl  _ length(lhood)
>>         ne[ncl:i] _ (1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
>>         Ep0  _ Epower(nc, d, cci*ne, pc, alpha)
>>         while(abs(Ep0[i]-power)>tol1){
>>                 if(Ep0[i]<power) cmin_cci
>>                 else cmax_cci
>>                 cci_(cmax+cmin)/2
>>                 ne[ncl:i] _ (1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
>>                 Ep0_Epower(nc, d, ne, pc, alpha)
>>         }
>>         ne.old2 _ ne
>> }
>> 
>> ne2 _ ne
>> ne _ (ne1+ne2)/2
>> #cat(ccc*ne)
>> Ep1_Epower(nc, d, ne, pc, alpha)
>> return(ne=ne, Ep=Ep1)
>> }
>> ###
>> vertex _ function(x,y)
>> {       n _ length(x)
>>         vx _ x[1]
>>         vy _ y[1]
>>         vp _ 1
>>         up _ T
>>         for (i in (2:n))
>>         { if (up)
>>                 {       if (y[i-1] > y[i])
>>                         {vx _ c(vx,x[i-1])
>>                          vy _ c(vy,y[i-1])
>>                          vp _ c(vp,i-1)
>>                          up _ F
>>                         }
>>                 }
>>                 else
>>                 {       if (y[i-1] < y[i]) up _ T
>>                 }
>>         }
>>         vx _ c(vx,x[n])
>>         vy _ c(vy,y[n])
>>         vp _ c(vp,n)
>>         return(vx=vx,vy=vy,vp=vp)
>> }
>> ###
>> convex _ function(x,y)
>> {
>>         n _ length(x)
>>         ans _ vertex(x,y)
>>         len _ length(ans$vx)
>>         while (len>3)
>>         {
>> #               cat("x=",x,"\n")
>> #               cat("y=",y,"\n")
>>                 newx _ x[1:(ans$vp[2]-1)]
>>                 newy _ y[1:(ans$vp[2]-1)]
>>                 for (i in (2:(len-1)))
>>                 {
>>                         newx _ c(newx,x[ans$vp[i]])
>>                         newy _ c(newy,y[ans$vp[i]])
>>                 }
>>                 newx _ c(newx,x[(ans$vp[len-1]+1):n])
>>                 newy _ c(newy,y[(ans$vp[len-1]+1):n])
>>                 y _ approx(newx,newy,xout=x)$y
>> #               cat("new y=",y,"\n")
>>                 ans _ vertex(x,y)
>>                 len _ length(ans$vx)
>> #               cat("vx=",ans$vx,"\n")
>> #               cat("vy=",ans$vy,"\n")
>> 
>> }
>>         return(wx=x,wy=y)}
>> ###
>> Epower _ function(nc, d, ne, pc = (0:((1 - d) * nc))/nc, alpha = 0.05)
>> {
>> #-------------------------------------
>> # nc     sample size in historical control
>> # d      the increase of response rate between historical and experiment
>> # ne     sample size of corresonding rc of 0 to nc*(1-d)
>> # pc     the response rate of control group, where we compute the
>> #        expected power
>> # alpha  the size of test
>> #-------------------------------------
>>         kk <- length(pc)
>>         rc <- 0:(nc * (1 - d))
>>         pp <- rep(NA, kk)
>>         ppp <- rep(NA, kk)
>>         for(i in 1:(kk)) {
>>                 pe <- pc[i] + d
>>                 lhood <- dbinom(rc, nc, pc[i])
>>                 pp <- power1.f(rc, nc, ne, pe, alpha)
>>                 ppp[i] <- sum(pp * lhood)/sum(lhood)
>>         }
>>         return(ppp)
>> }
>> 
>> # adapted from the old biss2
>> ss.rand _ function(rc,nc,d,alpha=.05,power=.8,tol=.01)
>> {
>> ne_nc
>> ne1_nc+50
>> while(abs(ne-ne1)>tol & ne1<100000){
>> ne_ne1
>> pe_d+rc/nc
>> ne1_nef2(rc,nc,pe*ne,ne,alpha,power)
>> 
>> ## if(is.na(ne1))
>>  print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
>> }
>> if (ne1>100000) return(NA)
>> else return(ne1)
>> }
>> ###
>> power1.f_function(rc,nc,ne,pie,alpha=0.05){
>> #-------------------------------------
>> # rc    number of response in historical control
>> # nc    sample size in historical control
>> # ne    sample size in experitment group
>> # pie   true response rate for experiment group
>> # alpha size of the test
>> #-------------------------------------
>> 
>> za_qnorm(1-alpha)
>> re_ne*pie
>> xe_asin(sqrt((re+0.375)/(ne+0.75)))
>> xc_asin(sqrt((rc+0.375)/(nc+0.75)))
>> ans_za*sqrt(1+(ne+0.5)/(nc+0.5))-(xe-xc)/sqrt(1/(4*(ne+0.5)))
>> return(1-pnorm(ans))
>> }
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From wdunlap at tibco.com  Wed Jun  5 21:17:10 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 5 Jun 2013 19:17:10 +0000
Subject: [R] SPlus script
In-Reply-To: <1370438435.93923.YahooMailNeo@web142703.mail.bf1.yahoo.com>
References: <1370438435.93923.YahooMailNeo@web142703.mail.bf1.yahoo.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C2FD5C4@PA-MBX01.na.tibco.com>

Both the R and S+ versions (which seem to differ only in the use of _ for assignment
in the S+ version) do nothing but define some functions.  You would not expect any
printed output unless you used those functions on some data.  Is there another script
that does that?

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Scott Raynaud
> Sent: Wednesday, June 05, 2013 6:21 AM
> To: r-help at r-project.org
> Subject: [R] SPlus script
> 
> This?originally was?an SPlus script that I modifeid about a year-and-a-half ago.? It worked
> perfectly then.? Now I can't get any output despite not receiving an error message.? I'm
> providing the SPLUS script as a reference.? I'm running R15.2.2.? Any help appreciated.
> 
> ************************************MY
> MODIFICATION***********************************************************
> **********
> ## sshc.ssc: sample size calculation for historical control studies
> ## J. Jack Lee (jjlee at mdanderson.org) and Chi-hong Tseng
> ## Department of Biostatistics, Univ. of Texas M.D. Anderson Cancer Center
> ##
> ## 3/1/99
> ## updated 6/7/00: add loess
> ##------------------------------------------------------------------
> ######## Required Input:
> #
> # rc???? number of response in historical control group
> # nc???? sample size in historical control
> # d????? target improvement = Pe - Pc
> # method 1=method based on the randomized design
> #??????? 2=Makuch & Simon method (Makuch RW, Simon RM. Sample size considerations
> #????????? for non-randomized comparative studies. J of Chron Dis 1980; 3:175-181.
> #??????? 3=uniform power method
> ######## optional Input:
> #
> # alpha? size of the test
> # power? desired power of the test
> # tol??? convergence criterion for methods 1 & 2 in terms of sample size
> # tol1?? convergence criterion for method 3 at any given obs Rc in terms of difference
> #????????? of expected power from target
> # tol2?? overall convergence criterion for method 3 as the max absolute deviation
> #????????? of expected power from target for all Rc
> # cc???? range of multiplicative constant applied to the initial values ne
> # l.span smoothing constant for loess
> #
> # Note:? rc is required for methods 1 and 2 but not 3
> #??????? method 3 return the sample size need for rc=0 to (1-d)*nc
> #
> ######## Output
> # for methdos 1 & 2: return the sample size needed for the experimental group (1
> number)
> #??????????????????? for given rc, nc, d, alpha, and power
> # for method 3:????? return the profile of sample size needed for given nc, d, alpha, and
> power
> #??????????????????? vector $ne contains the sample size corresponding to rc=0, 1, 2, ... nc*(1-d)
> #??????????????????? vector $Ep contains the expected power corresponding to
> #????????????????????? the true pc = (0, 1, 2, ..., nc*(1-d)) / nc
> #
> #------------------------------------------------------------------
> sshc<-function(rc, nc=1092, d=.085779816, method=3, alpha=0.05, power=0.8,
> ????????????? tol=0.01, tol1=.0001, tol2=.005, cc=c(.1,2), l.span=.5)
> {
> ### for method 1
> if (method==1) {
> ?ne1<-ss.rand(rc,nc,d,alpha=.05,power=.8,tol=.01)
> ?return(ne=ne1)
> ?????????????? }
> ### for method 2
> if (method==2) {
> ne<-nc
> ne1<-nc+50
> while(abs(ne-ne1)>tol & ne1<100000){
> ne<-ne1
> pe<-d+rc/nc
> ne1<-nef(rc,nc,pe*ne,ne,alpha,power)
> ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
> }
> if (ne1>100000) return(NA)
> else return(ne=ne1)
> }
> ### for method 3
> if (method==3) {
> if (tol1 > tol2/10) tol1<-tol2/10
> ncstar<-(1-d)*nc
> pc<-(0:ncstar)/nc
> ne<-rep(NA,ncstar + 1)
> for (i in (0:ncstar))
> { ne[i+1]<-ss.rand(i,nc,d,alpha=.05,power=.8,tol=.01)
> }
> plot(pc,ne,type='l',ylim=c(0,max(ne)*1.5))
> ans<-c.searchd(nc, d, ne, alpha, power, cc, tol1)
> ### check overall absolute deviance
> old.abs.dev<-sum(abs(ans$Ep-power))
> ##bad<-0
> print(round(ans$Ep,4))
> print(round(ans$ne,2))
> lines(pc,ans$ne,lty=1,col=8)
> old.ne<-ans$ne
> ##while(max(abs(ans$Ep-power))>tol2 & bad==0){? #### unnecessary ##
> while(max(abs(ans$Ep-power))>tol2){
> ans<-c.searchd(nc, d, ans$ne, alpha, power, cc, tol1)
> abs.dev<-sum(abs(ans$Ep-power))
> print(paste(" old.abs.dev=",old.abs.dev))
> print(paste("???? abs.dev=",abs.dev))
> ##if (abs.dev > old.abs.dev) { bad<-1}
> old.abs.dev<-abs.dev
> print(round(ans$Ep,4))
> print(round(ans$ne,2))
> lines(pc,old.ne,lty=1,col=1)
> lines(pc,ans$ne,lty=1,col=8)
> ### add convex
> ans$ne<-convex(pc,ans$ne)$wy
> ### add loess
> ###old.ne<-ans$ne
> loess.ne<-loess(ans$ne ~ pc, span=l.span)
> lines(pc,loess.ne$fit,lty=1,col=4)
> old.ne<-loess.ne$fit
> ###readline()
> }
> return(list(ne=ans$ne, Ep=ans$Ep))
> ?????????????? }
> }
> ## needed for method 1
> nef2<-function(rc,nc,re,ne,alpha,power){
> za<-qnorm(1-alpha)
> zb<-qnorm(power)
> xe<-asin(sqrt((re+0.375)/(ne+0.75)))
> xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
> ans<- 1/(4*(xc-xe)^2/(za+zb)^2-1/(nc+0.5)) - 0.5
> return(ans)
> }
> ## needed for method 2
> nef<-function(rc,nc,re,ne,alpha,power){
> za<-qnorm(1-alpha)
> zb<-qnorm(power)
> xe<-asin(sqrt((re+0.375)/(ne+0.75)))
> xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
> ans<-(za*sqrt(1+(ne+0.5)/(nc+0.5))+zb)^2/(2*(xe-xc))^2-0.5
> return(ans)
> }
> ## needed for method 3
> c.searchd<-function(nc, d, ne, alpha=0.05, power=0.8, cc=c(0.1,2),tol1=0.0001){
> #---------------------------
> # nc???? sample size of control group
> # d????? the differece to detect between control and experiment
> # ne???? vector of starting sample size of experiment group
> #????? corresonding to rc of 0 to nc*(1-d)
> # alpha? size of test
> # power? target power
> # cc?? pre-screen vector of constant c, the range should cover the
> #????? the value of cc that has expected power
> # tol1?? the allowance between the expceted power and target power
> #---------------------------
> pc<-(0:((1-d)*nc))/nc
> ncl<-length(pc)
> ne.old<-ne
> ne.old1<-ne.old
> ### sweeping forward
> for(i in 1:ncl){
> ?cmin<-cc[1]
> ?cmax<-cc[2]
> ### fixed cci<-cmax bug
> ?cci <-1
> ?lhood<-dbinom((i:ncl)-1,nc,pc[i])
> ?ne[i:ncl]<-(1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
> ?Ep0 <-Epower(nc, d, ne, pc, alpha)
> ?while(abs(Ep0[i]-power)>tol1){
> ??if(Ep0[i]<power) cmin<-cci
> ??else cmax<-cci
> ??cci<-(cmax+cmin)/2
> ??ne[i:ncl]<-(1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
> ??Ep0<-Epower(nc, d, ne, pc, alpha)
> ?}
> ??ne.old1<-ne
> }
> ne1<-ne
> ### sweeping backward -- ncl:i
> ne.old2<-ne.old
> ne???? <-ne.old
> for(i in ncl:1){
> ?cmin<-cc[1]
> ?cmax<-cc[2]
> ### fixed cci<-cmax bug
> ?cci <-1
> ?lhood<-dbinom((ncl:i)-1,nc,pc[i])
> ?lenl <-length(lhood)
> ?ne[ncl:i]<-(1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
> ?Ep0 <-Epower(nc, d, cci*ne, pc, alpha)
> ?while(abs(Ep0[i]-power)>tol1){
> ??if(Ep0[i]<power) cmin<-cci
> ??else cmax<-cci
> ??cci<-(cmax+cmin)/2
> ??ne[ncl:i]<-(1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
> ??Ep0<-Epower(nc, d, ne, pc, alpha)
> ?}
> ??ne.old2<-ne
> }
> ne2<-ne
> ne<-(ne1+ne2)/2
> #cat(ccc*ne)
> Ep1<-Epower(nc, d, ne, pc, alpha)
> return(list(ne=ne, Ep=Ep1))
> }
> ###
> vertex<-function(x,y)
> { ?n<-length(x)
> ?vx<-x[1]
> ?vy<-y[1]
> ?vp<-1
> ?up<-T
> ?for (i in (2:n))
> ?{ if (up)
> ??{ ?if (y[i-1] > y[i])
> ???{vx<-c(vx,x[i-1])
> ??? vy<-c(vy,y[i-1])
> ??? vp<-c(vp,i-1)
> ??? up<-F
> ???}
> ??}
> ??else
> ??{ ?if (y[i-1] < y[i]) up<-T
> ??}
> ?}
> ?vx<-c(vx,x[n])
> ?vy<-c(vy,y[n])
> ?vp<-c(vp,n)
> ?return(list(vx=vx,vy=vy,vp=vp))
> }
> ###
> convex<-function(x,y)
> {
> ?n<-length(x)
> ?ans<-vertex(x,y)
> ?len<-length(ans$vx)
> ?while (len>3)
> ?{
> #??cat("x=",x,"\n")
> #??cat("y=",y,"\n")
> ??newx<-x[1:(ans$vp[2]-1)]
> ??newy<-y[1:(ans$vp[2]-1)]
> ??for (i in (2:(len-1)))
> ??{
> ?? ?newx<-c(newx,x[ans$vp[i]])
> ???newy<-c(newy,y[ans$vp[i]])
> ??}
> ??newx<-c(newx,x[(ans$vp[len-1]+1):n])
> ??newy<-c(newy,y[(ans$vp[len-1]+1):n])
> ??y<-approx(newx,newy,xout=x)$y
> #??cat("new y=",y,"\n")
> ??ans<-vertex(x,y)
> ??len<-length(ans$vx)
> #??cat("vx=",ans$vx,"\n")
> #??cat("vy=",ans$vy,"\n")
> }
> ?return(list(wx=x,wy=y))}
> ###
> Epower<-function(nc, d, ne, pc = (0:((1 - d) * nc))/nc, alpha = 0.05)
> {
> #-------------------------------------
> # nc???? sample size in historical control
> # d????? the increase of response rate between historical and experiment
> # ne???? sample size of corresonding rc of 0 to nc*(1-d)
> # pc???? the response rate of control group, where we compute the
> #??????? expected power
> # alpha? the size of test
> #-------------------------------------
> ?kk <- length(pc)
> ?rc <- 0:(nc * (1 - d))
> ?pp <- rep(NA, kk)
> ?ppp <- rep(NA, kk)
> ?for(i in 1:(kk)) {
> ??pe <- pc[i] + d
> ??lhood <- dbinom(rc, nc, pc[i])
> ??pp <- power1.f(rc, nc, ne, pe, alpha)
> ??ppp[i] <- sum(pp * lhood)/sum(lhood)
> ?}
> ?return(ppp)
> }
> # adapted from the old biss2
> ss.rand<-function(rc,nc,d,alpha=.05,power=.8,tol=.01)
> {
> ne<-nc
> ne1<-nc+50
> while(abs(ne-ne1)>tol & ne1<100000){
> ne<-ne1
> pe<-d+rc/nc
> ne1<-nef2(rc,nc,pe*ne,ne,alpha,power)
> ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
> }
> if (ne1>100000) return(NA)
> else return(ne1)
> }
> ###
> power1.f<-function(rc,nc,ne,pie,alpha=0.05){
> #-------------------------------------
> # rc?number of response in historical control
> # nc?sample size in historical control
> # ne??? sample size in experitment group
> # pie?true response rate for experiment group
> # alpha?size of the test
> #-------------------------------------
> za<-qnorm(1-alpha)
> re<-ne*pie
> xe<-asin(sqrt((re+0.375)/(ne+0.75)))
> xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
> ans<-za*sqrt(1+(ne+0.5)/(nc+0.5))-(xe-xc)/sqrt(1/(4*(ne+0.5)))
> return(1-pnorm(ans))
> }
> 
> 
> 
> *************************************ORIGINAL SPLUS
> SCRIPT************************************************************
> ## sshc.ssc: sample size calculation for historical control studies
> ## J. Jack Lee (jjlee at mdanderson.org) and Chi-hong Tseng
> ## Department of Biostatistics, Univ. of Texas M.D. Anderson Cancer Center
> ##
> ## 3/1/99
> ## updated 6/7/00: add loess
> ##------------------------------------------------------------------
> ######## Required Input:
> #
> # rc     number of response in historical control group
> # nc     sample size in historical control
> # d      target improvement = Pe - Pc
> # method 1=method based on the randomized design
> #        2=Makuch & Simon method (Makuch RW, Simon RM. Sample size considerations
> #          for non-randomized comparative studies. J of Chron Dis 1980; 3:175-181.
> #        3=uniform power method
> ######## optional Input:
> #
> # alpha  size of the test
> # power  desired power of the test
> # tol    convergence criterion for methods 1 & 2 in terms of sample size
> # tol1   convergence criterion for method 3 at any given obs Rc in terms of
>  difference
> #          of expected power from target
> # tol2   overall convergence criterion for method 3 as the max absolute deviation
> #          of expected power from target for all Rc
> # cc     range of multiplicative constant applied to the initial values ne
> # l.span smoothing constant for loess
> #
> # Note:  rc is required for methods 1 and 2 but not 3
> #        method 3 return the sample size need for rc=0 to (1-d)*nc
> #
> ######## Output
> # for methdos 1 & 2: return the sample size needed for the experimental group (1
> number)
> #                    for given rc, nc, d, alpha, and power
> # for method 3:      return the profile of sample size needed for given nc, d, alpha, and
> power
> #                    vector $ne contains the sample size corresponding to rc=0, 1, 2, ... nc*(1-d)
> #                    vector $Ep contains the expected power corresponding to
> #                      the true pc = (0, 1, 2, ..., nc*(1-d)) / nc
> #
> 
> #------------------------------------------------------------------
> sshc _ function(rc, nc, d, method, alpha=0.05, power=0.8,
> 	             tol=0.01, tol1=.0001, tol2=.005, cc=c(.1,2), l.span=.5)
> {
> ### for method 1
> if (method==1) {
> 	ne1 _ ss.rand(rc,nc,d,alpha=.05,power=.8,tol=.01)
> 	return(ne=ne1)
>                }
> ### for method 2
> if (method==2) {
> ne_nc
> ne1_nc+50
> while(abs(ne-ne1)>tol & ne1<100000){
> ne_ne1
> pe_d+rc/nc
> ne1_nef(rc,nc,pe*ne,ne,alpha,power)
> ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
> }
> if (ne1>100000) return(NA)
> else return(ne=ne1)
> }
> ### for method 3
> if (method==3) {
> if (tol1 > tol2/10) tol1_tol2/10
> ncstar _ (1-d)*nc
> pc_(0:ncstar)/nc
> ne _ rep(NA,ncstar + 1)
> for (i in (0:ncstar))
> { ne[i+1] _ ss.rand(i,nc,d,alpha=.05,power=.8,tol=.01)
> }
> plot(pc,ne,type='l',ylim=c(0,max(ne)*1.5))
> ans_c.searchd(nc, d, ne, alpha, power, cc, tol1)
> ### check overall absolute deviance
> old.abs.dev _ sum(abs(ans$Ep-power))
> ##bad
>  _ 0
> print(round(ans$Ep,4))
> print(round(ans$ne,2))
> lines(pc,ans$ne,lty=1,col=8)
> old.ne _ ans$ne
> ##while(max(abs(ans$Ep-power))>tol2 & bad==0){  #### unnecessary ##
> while(max(abs(ans$Ep-power))>tol2){
> ans_c.searchd(nc, d, ans$ne, alpha, power, cc, tol1)
> abs.dev _ sum(abs(ans$Ep-power))
> print(paste(" old.abs.dev=",old.abs.dev))
> print(paste("     abs.dev=",abs.dev))
> ##if (abs.dev > old.abs.dev) { bad _ 1}
> old.abs.dev _ abs.dev
> print(round(ans$Ep,4))
> print(round(ans$ne,2))
> lines(pc,old.ne,lty=1,col=1)
> lines(pc,ans$ne,lty=1,col=8)
> ### add convex
> ans$ne _ convex(pc,ans$ne)$wy
> ### add loess
> ###old.ne _ ans$ne
> loess.ne _ loess(ans$ne ~ pc, span=l.span)
> lines(pc,loess.ne$fit,lty=1,col=4)
> old.ne _ loess.ne$fit
> ###readline()
> }
> return(ne=ans$ne, Ep=ans$Ep)
>                }
> }
> 
> ## needed for method 1
> nef2_function(rc,nc,re,ne,alpha,power){
> za_qnorm(1-alpha)
> zb_qnorm(power)
> xe_asin(sqrt((re+0.375)/(ne+0.75)))
> xc_asin(sqrt((rc+0.375)/(nc+0.75)))
> ans_
>  1/(4*(xc-xe)^2/(za+zb)^2-1/(nc+0.5)) - 0.5
> return(ans)
> }
> ## needed for method 2
> nef_function(rc,nc,re,ne,alpha,power){
> za_qnorm(1-alpha)
> zb_qnorm(power)
> xe_asin(sqrt((re+0.375)/(ne+0.75)))
> xc_asin(sqrt((rc+0.375)/(nc+0.75)))
> ans_(za*sqrt(1+(ne+0.5)/(nc+0.5))+zb)^2/(2*(xe-xc))^2-0.5
> return(ans)
> }
> ## needed for method 3
> c.searchd_function(nc, d, ne, alpha=0.05, power=0.8, cc=c(0.1,2),tol1=0.0001){
> #---------------------------
> # nc     sample size of control group
> # d      the differece to detect between control and experiment
> # ne     vector of starting sample size of experiment group
> #		    corresonding to rc of 0 to nc*(1-d)
> # alpha  size of test
> # power  target power
> # cc	  pre-screen vector of constant c, the range should cover the
> #		    the value of cc that has expected power
> # tol1   the allowance between the expceted power and target power
> #---------------------------
> pc_(0:((1-d)*nc))/nc
> ncl _ length(pc)
> ne.old _ ne
> ne.old1 _ ne.old
> ###
>  sweeping forward
> for(i in 1:ncl){
> 	cmin _ cc[1]
> 	cmax _ cc[2]
> ### fixed cci_cmax bug
> 	cci  _ 1
> 	lhood _ dbinom((i:ncl)-1,nc,pc[i])
> 	ne[i:ncl] _ (1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
> 	Ep0  _ Epower(nc, d, ne, pc, alpha)
> 	while(abs(Ep0[i]-power)>tol1){
> 		if(Ep0[i]<power) cmin_cci
> 		else cmax_cci
> 		cci_(cmax+cmin)/2
> 		ne[i:ncl] _ (1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
> 		Ep0_Epower(nc, d, ne, pc, alpha)
> 	}
>  	ne.old1 _ ne
> }
> ne1 _ ne
> ### sweeping backward -- ncl:i
> ne.old2 _ ne.old
> ne      _ ne.old
> for(i in ncl:1){
> 	cmin _ cc[1]
> 	cmax _ cc[2]
> ### fixed cci_cmax bug
> 	cci  _ 1
> 	lhood _ dbinom((ncl:i)-1,nc,pc[i])
> 	lenl  _ length(lhood)
> 	ne[ncl:i] _ (1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
> 	Ep0  _ Epower(nc, d, cci*ne, pc, alpha)
> 	while(abs(Ep0[i]-power)>tol1){
> 		if(Ep0[i]<power) cmin_cci
> 		else cmax_cci
> 		cci_(cmax+cmin)/2
> 		ne[ncl:i] _ (1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
> 		Ep0_Epower(nc, d, ne, pc, alpha)
> 	}
>  	ne.old2 _ ne
> }
> 
> ne2 _ ne
> ne _ (ne1+ne2)/2
> #cat(ccc*ne)
> Ep1_Epower(nc, d, ne, pc, alpha)
> return(ne=ne, Ep=Ep1)
> }
> ###
> vertex _ function(x,y)
> { 	n _ length(x)
> 	vx _ x[1]
> 	vy _ y[1]
> 	vp _ 1
> 	up _ T
> 	for (i in (2:n))
> 	{ if (up)
> 		{ 	if (y[i-1] > y[i])
> 			{vx _ c(vx,x[i-1])
> 			 vy _ c(vy,y[i-1])
> 			 vp _ c(vp,i-1)
> 			 up _ F
> 			}
> 		}
> 		else
> 		{ 	if (y[i-1] < y[i]) up _ T
> 		}
> 	}
> 	vx _ c(vx,x[n])
> 	vy _ c(vy,y[n])
> 	vp _ c(vp,n)
> 	return(vx=vx,vy=vy,vp=vp)
> }
> ###
> convex _ function(x,y)
> {
> 	n _ length(x)
> 	ans _ vertex(x,y)
> 	len _ length(ans$vx)
> 	while (len>3)
> 	{
> #		cat("x=",x,"\n")
> #		cat("y=",y,"\n")
> 		newx _ x[1:(ans$vp[2]-1)]
> 		newy _ y[1:(ans$vp[2]-1)]
> 		for (i in (2:(len-1)))
> 		{
> 		 	newx _ c(newx,x[ans$vp[i]])
> 			newy _ c(newy,y[ans$vp[i]])
> 		}
> 		newx _ c(newx,x[(ans$vp[len-1]+1):n])
> 		newy _ c(newy,y[(ans$vp[len-1]+1):n])
> 		y _ approx(newx,newy,xout=x)$y
> #		cat("new y=",y,"\n")
> 		ans _ vertex(x,y)
> 		len _ length(ans$vx)
> #		cat("vx=",ans$vx,"\n")
> #		cat("vy=",ans$vy,"\n")
> 
> }
> 	return(wx=x,wy=y)}
> ###
> Epower _ function(nc, d, ne, pc = (0:((1 - d) * nc))/nc, alpha = 0.05)
> {
> #-------------------------------------
> # nc     sample size in historical control
> # d      the increase of response rate between historical and experiment
> # ne     sample size of corresonding rc of 0 to nc*(1-d)
> # pc     the response rate of control group, where we compute the
> #        expected power
> # alpha  the size of test
> #-------------------------------------
> 	kk <- length(pc)
> 	rc <- 0:(nc * (1 - d))
> 	pp <- rep(NA, kk)
> 	ppp <- rep(NA, kk)
> 	for(i in 1:(kk)) {
> 		pe <- pc[i] + d
> 		lhood <- dbinom(rc, nc, pc[i])
> 		pp <- power1.f(rc, nc, ne, pe, alpha)
> 		ppp[i] <- sum(pp * lhood)/sum(lhood)
> 	}
> 	return(ppp)
> }
> 
> # adapted from the old biss2
> ss.rand _ function(rc,nc,d,alpha=.05,power=.8,tol=.01)
> {
> ne_nc
> ne1_nc+50
> while(abs(ne-ne1)>tol & ne1<100000){
> ne_ne1
> pe_d+rc/nc
> ne1_nef2(rc,nc,pe*ne,ne,alpha,power)
> 
> ## if(is.na(ne1))
>  print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
> }
> if (ne1>100000) return(NA)
> else return(ne1)
> }
> ###
> power1.f_function(rc,nc,ne,pie,alpha=0.05){
> #-------------------------------------
> # rc	number of response in historical control
> # nc	sample size in historical control
> # ne    sample size in experitment group
> # pie	true response rate for experiment group
> # alpha	size of the test
> #-------------------------------------
> 
> za_qnorm(1-alpha)
> re_ne*pie
> xe_asin(sqrt((re+0.375)/(ne+0.75)))
> xc_asin(sqrt((rc+0.375)/(nc+0.75)))
> ans_za*sqrt(1+(ne+0.5)/(nc+0.5))-(xe-xc)/sqrt(1/(4*(ne+0.5)))
> return(1-pnorm(ans))
> }
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From neotropical.bats at gmail.com  Wed Jun  5 21:26:25 2013
From: neotropical.bats at gmail.com (Neotropical bat risk assessments)
Date: Wed, 05 Jun 2013 15:26:25 -0400
Subject: [R] reshape2 issue solved Tnx!
Message-ID: <51AF90E1.9060101@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130605/a5935f49/attachment.pl>

From jrkrideau at inbox.com  Wed Jun  5 21:28:49 2013
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 5 Jun 2013 11:28:49 -0800
Subject: [R] How to display multiples lines with different color on the
 same plot?
In-Reply-To: <9879AF1F439EF943BDEE22D3AAA5C3F683FBD675@sdsu-ex01.jacks.local>
Message-ID: <FF6FC0FD832.00000122jrkrideau@inbox.com>

Try:
library(ggplot2)
ggplot(mtcars, aes(mpg, qsec, colour = as.factor(gear))) +
  geom_point() + geom_smooth(method = lm, se = FALSE)

You probably will have to melt your data to get into the right format. 

John Kane
Kingston ON Canada

> -----Original Message-----
> From: armel.kaptue at sdstate.edu
> Sent: Tue, 4 Jun 2013 21:05:45 +0000
> To: r-help at r-project.org
> Subject: [R] How to display multiples lines with different color on the
> same plot?
> 
> Hi all,
> 
> I'm struggling with the display of several regression lines (with
> different colors) on the same plot.
> 
> I manually drew what I'm trying to do with 8 lines (see attached).
> 
> Any thoughts for a code will be very much appreciated.
> 
> Thanks
> 
> Armel
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at http://www.inbox.com/smileys
Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk? and most webmails


From jrkrideau at inbox.com  Wed Jun  5 21:29:44 2013
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 5 Jun 2013 11:29:44 -0800
Subject: [R] reshape2 issue solved Tnx!
In-Reply-To: <51AF90E1.9060101@gmail.com>
Message-ID: <FF71CDCE4A4.00000126jrkrideau@inbox.com>

Yes , I think it was only a year or two ago that the change occured.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: neotropical.bats at gmail.com
> Sent: Wed, 05 Jun 2013 15:26:25 -0400
> To: r-help at r-project.org
> Subject: [R] reshape2 issue solved Tnx!
> 
> Hi again all,
> 
> As the original code lines I had dated back to 2007 that may have
> predated reshape2?
> 
> In any case the use of *dcast *rather than /*cast*/ solved the issue.
> 
> Then with 3 steps:
> Stop
> read
> Think
> 
> I saw I just needed to change the line
> input.cast <- cast(input.melt, Species ~ *Date*, fun.aggregate = sum)
> to
> input.cast <- cast(input.melt, Species ~ *Time*, fun.aggregate = sum)
> 
> ...and it all works as expected and needed.
> 
> Thanks again all who replied.
> 
> 
> Bruce
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at http://www.inbox.com/smileys
Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk? and most webmails


From juliosergio at gmail.com  Wed Jun  5 22:26:26 2013
From: juliosergio at gmail.com (Julio Sergio)
Date: Wed, 5 Jun 2013 20:26:26 +0000
Subject: [R]
	=?utf-8?q?Trying_to_build_up_functions_with_its_names_by_mean?=
	=?utf-8?q?s_of=09lapply?=
References: <loom.20130605T043218-210@post.gmane.org>
	<250F03A2-77CE-4FAC-B1C9-6754567A3F6A@gmail.com>
	<51AF09A5.4080700@sapo.pt> <51AF0BE3.3050500@sapo.pt>
	<CACk-te21kO0xP+4RpvJrLVxoUZjbAVh_h6RbL0JxSwoBH2YwPg@mail.gmail.com>
Message-ID: <loom.20130605T215734-601@post.gmane.org>

Bert Gunter <gunter.berton <at> gene.com> writes:

> 
> faux <- function(c, nm = "gamma",...){
>      f <- get(paste0(c,nm))
>       function(x)f(x,...)
>     }
> 
> This could be called with:
> 
> > xgam <- lapply(c("p","d"), faux, shape=k, scale=theta)
> > xgam[[1]](1000)
> [1] 0.8710477
> > xgam[[2]](1000)
> [1] 0.001265311
> 

Excellent, Bert, and thanks a lot for your contribution! In fact, I was 
planning to write a separate functions producer for each distribution. This 
really saves me a lot of work!


  -Sergio


From wdunlap at tibco.com  Wed Jun  5 22:46:18 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 5 Jun 2013 20:46:18 +0000
Subject: [R] Trying to build up functions with its names by means
	of	lapply
In-Reply-To: <loom.20130605T215734-601@post.gmane.org>
References: <loom.20130605T043218-210@post.gmane.org>
	<250F03A2-77CE-4FAC-B1C9-6754567A3F6A@gmail.com>	<51AF09A5.4080700@sapo.pt>
	<51AF0BE3.3050500@sapo.pt>
	<CACk-te21kO0xP+4RpvJrLVxoUZjbAVh_h6RbL0JxSwoBH2YwPg@mail.gmail.com>
	<loom.20130605T215734-601@post.gmane.org>
Message-ID: <E66794E69CFDE04D9A70842786030B931C2FD621@PA-MBX01.na.tibco.com>

You will want to force the evaluation of the ... arguments, just as you are already
forcing the evaluation of 'c', before returning your function.  E.g., compare the
following two:

# your 'faux', renamed and enhanced a bit
f0 <- function (c, nm = "gamma", ...)
{
    probFunc <- getFunction(paste0(c, nm))
    function(x) probFunc(x, ...)
}
# the above but adding a call to force the evaluation of the ... argument before returning the function
f1 <- function (c, nm = "gamma", ...)
{
    probFunc <- getFunction(paste0(c, nm))
    force(list(...))
    function(x) probFunc(x, ...)
}
# Now use mapply to make a list of functions with various parameters
z0 <-  mapply(c=c("p","d"), nm="norm", mean=c(1,-1), FUN=f0)
z1 <-  mapply(c=c("p","d"), nm="norm", mean=c(1,-1), FUN=f1)
z0[[1]](0.1) # expect same result as pnorm(0.1, mean=1)
# [1] 0.8643339 # bad
z1[[1]](0.1) # expect same result as pnorm(0.1, mean=1)
# [1] 0.1840601 # good
# for reference:
pnorm(0.1, mean=1)
# [1] 0.1840601
pnorm(0.1, mean=-1)
# [1] 0.8643339

You don't have to say 'force(list(...))' to force their evaluation.  You could use
'junk <- list(...)' or 'junk <- c(...)', but using the force function should indicate
that you are only doing this to force the evaluation of the argument at this point,
not because you intend to use the result of list(...) or c(...).

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Julio Sergio
> Sent: Wednesday, June 05, 2013 1:26 PM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] Trying to build up functions with its names by means of lapply
> 
> Bert Gunter <gunter.berton <at> gene.com> writes:
> 
> >
> > faux <- function(c, nm = "gamma",...){
> >      f <- get(paste0(c,nm))
> >       function(x)f(x,...)
> >     }
> >
> > This could be called with:
> >
> > > xgam <- lapply(c("p","d"), faux, shape=k, scale=theta)
> > > xgam[[1]](1000)
> > [1] 0.8710477
> > > xgam[[2]](1000)
> > [1] 0.001265311
> >
> 
> Excellent, Bert, and thanks a lot for your contribution! In fact, I was
> planning to write a separate functions producer for each distribution. This
> really saves me a lot of work!
> 
> 
>   -Sergio
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nalimilan at club.fr  Wed Jun  5 22:53:23 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Wed, 05 Jun 2013 22:53:23 +0200
Subject: [R] Lattice, ggplot, and pointsize
In-Reply-To: <CADfFDC5tYQ2f-GNLGbBb-OZn-ys_q9ct=NETn6hiQrhW2zaEVQ@mail.gmail.com>
References: <1369135114.20032.58.camel@milan>
	<201305211330.r4LDU9eK025410@mail15.tpg.com.au>
	<1369144480.20032.63.camel@milan>
	<ad7504fc-3f32-4da7-a190-cc9239252c85@email.android.com>
	<1369163829.20032.79.camel@milan>
	<CACk-te0=1068zyxve7eWAJ=q87PR8Ye0Ntd7GXRGRCCSChMBtA@mail.gmail.com>
	<519BDB6A.2020008@stats.ox.ac.uk> <1369509438.20032.163.camel@milan>
	<CADfFDC5tYQ2f-GNLGbBb-OZn-ys_q9ct=NETn6hiQrhW2zaEVQ@mail.gmail.com>
Message-ID: <1370465603.18223.20.camel@milan>

Le mercredi 05 juin 2013 ? 19:37 +0530, Deepayan Sarkar a ?crit :
> On Sun, May 26, 2013 at 12:47 AM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
> > Le mardi 21 mai 2013 ? 21:39 +0100, Prof Brian Ripley a ?crit :
> >> On 21/05/2013 21:24, Bert Gunter wrote:
> >> > At the risk of misunderstanding... (inline)
> >> >
> >> > On Tue, May 21, 2013 at 12:17 PM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
> >> >> Le mardi 21 mai 2013 ? 08:17 -0700, Jeff Newmiller a ?crit :
> >> >>> That is like complaining that your hammer does not fit these
> >> >>> newfangled Philips screws.
> >> >>>
> >> >>> These are different tools. Do not expect them to interoperate.
> >> >> I understand that Lattice and ggplot2 do not use settings from par().
> >> >> I'm fine with this, as these packages are different from base graphics
> >> >> and have they own equivalent to tweak settings.
> >> >>
> >> >> What I do not understand is that one argument passed to output devices,
> >> >> which are _not_ provided by package graphics, is ignored by these two
> >> >> packages. Lattice and ggplot2 do not provide an alternative output
> >> >> system,
> >> >
> >> > False, I believe, depending on what you mean by "output system". They
> >> > both use grid graphics, not base graphics and with lattice, anyway,
> >>
> >> Indeed.  The issue is a design difference between the base and grid
> >> graphics subsystems.  See the 'R Internals' manual for more details.
> >
> > Thanks for the pointers. Indeed there is some interesting documentation
> > there. I've also had a deeper look at the code, and I've traced
> > pointsize (called ps) back to the R_GE_gcontext struct in
> > src/include/R_ext/GraphicsEngine.h.
> >
> > If I understand correctly, base graphics draw text using GText() in
> > src/library/graphics/src/graphics.c, which in turn calls GEText() in
> > src/main/engine.c. GEText() does take into account the pointsize.
> >
> > On the other hand, grid graphics draw text using gridText() from
> > src/library/grid/src/grid.c. This function uses gcontextFromgpar() to
> > get its R_GE_gcontext object. gcontextFromgpar() (defined in gpar.c)
> > computes the pointsize from the fontsize gpar setting and a general
> > scaling of the output:
> >     /*
> >      * Scale by GSS_SCALE (a "zoom" factor)
> >      */
> >     gc->ps = gpFontSize(gp, i) * REAL(gridStateElement(dd, GSS_SCALE))[0];
> >
> > What is interesting is that when a new device gets initialized by grid
> > (initGPar() atin gpar.c), the fontsize gpar settings is set to the
> > device starting pointsize:
> >     REAL(gpfs)[0] = dev->startps;
> >
> > And indeed this works with svg():
> >> svg("test.svg", pointsize=5)
> >> get.gpar("fontsize")
> > $fontsize
> > [1] 5
> >
> > ...but not with Lattice:
> >> trellis.par.get("fontsize")
> > $text
> > [1] 12
> >
> > $points
> > [1] 8
> >
> >
> > So the problem does not appear to be a base vs. grid graphics issue, but
> > rather something specific to Lattice and ggplot2. And indeed, when
> > looking at Lattice's sources, canonical.theme() in settings.R does:
> >              fontsize         = list(text = 12, points = 8),
> >
> > As simple as that! I didn't need to look so deep into the code... :-/
> >
> >
> > ?trellis.par.set says:
> >      The initial settings for each device defaults to values
> >      appropriate for that device. In practice, this boils down to three
> >      distinct settings, one for screen devices like ?x11? and
> >      ?windows?, one for black and white plots (mostly useful for
> >      ?postscript?) and one for color printers (color ?postcript?,
> >      ?pdf?). [This may not be up-to-date, though...]
> >
> > So it does not appear completely absurd to try to adjust to the device
> > settings where appropriate. Pointsize seems such a case to me.
> > canonical.theme() could set the text font size to get.gpar("fontsize").
> > Since the default value is 12 for most devices, this would not change
> > anything by default. (ggplot2 could probably benefit from a similar
> > change.)
> 
> If I remember correctly (it was a long time ago), I had nothing in
> particular against the default text fontsize. The default symbol size
> in grid was larger than I liked, and so fontsize$points was set to
> something more reasonable, and fontsize$text just seemed natural to
> add. It is only ever used in a single call to gpar() inside
> print.trellis. So it seems perfectly reasonable to take the default of
> fontsize$text from grid instead.
> 
> I don't like the idea of making the default
> 'get.gpar("fontsize")$fontsize' though, because that requires a device
> to be active, which canonical.theme() doesn't by design. Instead I
> have changed the default to NULL, and the fontsize is now set from (in
> order of priority)
> 
> 1. trellis.par.get("fontsize")$text  # NULL by default
> 2. trellis.par.get("grid.pars")$fontsize # NULL by default
> 3. get.gpars()$fontsize # approximately device pointsize by default
> 
> Hopefully this works for you. You can test using the r-forge version.
Thanks! I've just tested it and it seems to fix the problem. Your
solution indeed makes more sense. This nicely proves that grid graphics
can perfectly cooperate with output devices.

Do you think that symbol size could also adapt in the same way? It
sounds natural that the default the ratio between symbol size and text
size is constant disregarding the device's pointsize. To retain the
current default, it would mean that
points = 8/12 * text


Regards

> -Deepayan
> 
> > I realize this is no longer a discussion relevant for R as a whole, but
> > I am posting it here nevertheless in case somebody was interested. Maybe
> > we should discuss this offlist with Deepayan.
> 
> [...]


From scott.raynaud at yahoo.com  Wed Jun  5 22:55:18 2013
From: scott.raynaud at yahoo.com (Scott Raynaud)
Date: Wed, 5 Jun 2013 13:55:18 -0700 (PDT)
Subject: [R] SPlus script
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C2FD5C4@PA-MBX01.na.tibco.com>
References: <1370438435.93923.YahooMailNeo@web142703.mail.bf1.yahoo.com>
	<E66794E69CFDE04D9A70842786030B931C2FD5C4@PA-MBX01.na.tibco.com>
Message-ID: <1370465718.71929.YahooMailNeo@web142702.mail.bf1.yahoo.com>

As you can see, my original modification was to replace all _ with <-.? It worked after I
did that.? This is a simulation that generates its own data based on the given parameters.? 
I should obtain a plot of the number of experimental subjects as a function of the repsonse 
rate in the historical group.? Maybe I'm forgetting something here...? It's been a while since I 
ran this.? Thanks for your help.


----- Original Message -----
From: William Dunlap <wdunlap at tibco.com>
To: Scott Raynaud <scott.raynaud at yahoo.com>; "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Wednesday, June 5, 2013 2:17 PM
Subject: RE: [R] SPlus script

Both the R and S+ versions (which seem to differ only in the use of _ for assignment
in the S+ version) do nothing but define some functions.? You would not expect any
printed output unless you used those functions on some data.? Is there another script
that does that?

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Scott Raynaud
> Sent: Wednesday, June 05, 2013 6:21 AM
> To: r-help at r-project.org
> Subject: [R] SPlus script
> 
> This?originally was?an SPlus script that I modifeid about a year-and-a-half ago.? It worked
> perfectly then.? Now I can't get any output despite not receiving an error message.? I'm
> providing the SPLUS script as a reference.? I'm running R15.2.2.? Any help appreciated.
> 
> ************************************MY
> MODIFICATION***********************************************************
> **********
> ## sshc.ssc: sample size calculation for historical control studies
> ## J. Jack Lee (jjlee at mdanderson.org) and Chi-hong Tseng
> ## Department of Biostatistics, Univ. of Texas M.D. Anderson Cancer Center
> ##
> ## 3/1/99
> ## updated 6/7/00: add loess
> ##------------------------------------------------------------------
> ######## Required Input:
> #
> # rc???? number of response in historical control group
> # nc???? sample size in historical control
> # d????? target improvement = Pe - Pc
> # method 1=method based on the randomized design
> #??????? 2=Makuch & Simon method (Makuch RW, Simon RM. Sample size considerations
> #????????? for non-randomized comparative studies. J of Chron Dis 1980; 3:175-181.
> #??????? 3=uniform power method
> ######## optional Input:
> #
> # alpha? size of the test
> # power? desired power of the test
> # tol??? convergence criterion for methods 1 & 2 in terms of sample size
> # tol1?? convergence criterion for method 3 at any given obs Rc in terms of difference
> #????????? of expected power from target
> # tol2?? overall convergence criterion for method 3 as the max absolute deviation
> #????????? of expected power from target for all Rc
> # cc???? range of multiplicative constant applied to the initial values ne
> # l.span smoothing constant for loess
> #
> # Note:? rc is required for methods 1 and 2 but not 3
> #??????? method 3 return the sample size need for rc=0 to (1-d)*nc
> #
> ######## Output
> # for methdos 1 & 2: return the sample size needed for the experimental group (1
> number)
> #??????????????????? for given rc, nc, d, alpha, and power
> # for method 3:????? return the profile of sample size needed for given nc, d, alpha, and
> power
> #??????????????????? vector $ne contains the sample size corresponding to rc=0, 1, 2, ... nc*(1-d)
> #??????????????????? vector $Ep contains the expected power corresponding to
> #????????????????????? the true pc = (0, 1, 2, ..., nc*(1-d)) / nc
> #
> #------------------------------------------------------------------
> sshc<-function(rc, nc=1092, d=.085779816, method=3, alpha=0.05, power=0.8,
> ????????????? tol=0.01, tol1=.0001, tol2=.005, cc=c(.1,2), l.span=.5)
> {
> ### for method 1
> if (method==1) {
> ?ne1<-ss.rand(rc,nc,d,alpha=.05,power=.8,tol=.01)
> ?return(ne=ne1)
> ?????????????? }
> ### for method 2
> if (method==2) {
> ne<-nc
> ne1<-nc+50
> while(abs(ne-ne1)>tol & ne1<100000){
> ne<-ne1
> pe<-d+rc/nc
> ne1<-nef(rc,nc,pe*ne,ne,alpha,power)
> ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
> }
> if (ne1>100000) return(NA)
> else return(ne=ne1)
> }
> ### for method 3
> if (method==3) {
> if (tol1 > tol2/10) tol1<-tol2/10
> ncstar<-(1-d)*nc
> pc<-(0:ncstar)/nc
> ne<-rep(NA,ncstar + 1)
> for (i in (0:ncstar))
> { ne[i+1]<-ss.rand(i,nc,d,alpha=.05,power=.8,tol=.01)
> }
> plot(pc,ne,type='l',ylim=c(0,max(ne)*1.5))
> ans<-c.searchd(nc, d, ne, alpha, power, cc, tol1)
> ### check overall absolute deviance
> old.abs.dev<-sum(abs(ans$Ep-power))
> ##bad<-0
> print(round(ans$Ep,4))
> print(round(ans$ne,2))
> lines(pc,ans$ne,lty=1,col=8)
> old.ne<-ans$ne
> ##while(max(abs(ans$Ep-power))>tol2 & bad==0){? #### unnecessary ##
> while(max(abs(ans$Ep-power))>tol2){
> ans<-c.searchd(nc, d, ans$ne, alpha, power, cc, tol1)
> abs.dev<-sum(abs(ans$Ep-power))
> print(paste(" old.abs.dev=",old.abs.dev))
> print(paste("???? abs.dev=",abs.dev))
> ##if (abs.dev > old.abs.dev) { bad<-1}
> old.abs.dev<-abs.dev
> print(round(ans$Ep,4))
> print(round(ans$ne,2))
> lines(pc,old.ne,lty=1,col=1)
> lines(pc,ans$ne,lty=1,col=8)
> ### add convex
> ans$ne<-convex(pc,ans$ne)$wy
> ### add loess
> ###old.ne<-ans$ne
> loess.ne<-loess(ans$ne ~ pc, span=l.span)
> lines(pc,loess.ne$fit,lty=1,col=4)
> old.ne<-loess.ne$fit
> ###readline()
> }
> return(list(ne=ans$ne, Ep=ans$Ep))
> ?????????????? }
> }
> ## needed for method 1
> nef2<-function(rc,nc,re,ne,alpha,power){
> za<-qnorm(1-alpha)
> zb<-qnorm(power)
> xe<-asin(sqrt((re+0.375)/(ne+0.75)))
> xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
> ans<- 1/(4*(xc-xe)^2/(za+zb)^2-1/(nc+0.5)) - 0.5
> return(ans)
> }
> ## needed for method 2
> nef<-function(rc,nc,re,ne,alpha,power){
> za<-qnorm(1-alpha)
> zb<-qnorm(power)
> xe<-asin(sqrt((re+0.375)/(ne+0.75)))
> xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
> ans<-(za*sqrt(1+(ne+0.5)/(nc+0.5))+zb)^2/(2*(xe-xc))^2-0.5
> return(ans)
> }
> ## needed for method 3
> c.searchd<-function(nc, d, ne, alpha=0.05, power=0.8, cc=c(0.1,2),tol1=0.0001){
> #---------------------------
> # nc???? sample size of control group
> # d????? the differece to detect between control and experiment
> # ne???? vector of starting sample size of experiment group
> #????? corresonding to rc of 0 to nc*(1-d)
> # alpha? size of test
> # power? target power
> # cc?? pre-screen vector of constant c, the range should cover the
> #????? the value of cc that has expected power
> # tol1?? the allowance between the expceted power and target power
> #---------------------------
> pc<-(0:((1-d)*nc))/nc
> ncl<-length(pc)
> ne.old<-ne
> ne.old1<-ne.old
> ### sweeping forward
> for(i in 1:ncl){
> ?cmin<-cc[1]
> ?cmax<-cc[2]
> ### fixed cci<-cmax bug
> ?cci <-1
> ?lhood<-dbinom((i:ncl)-1,nc,pc[i])
> ?ne[i:ncl]<-(1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
> ?Ep0 <-Epower(nc, d, ne, pc, alpha)
> ?while(abs(Ep0[i]-power)>tol1){
> ??if(Ep0[i]<power) cmin<-cci
> ??else cmax<-cci
> ??cci<-(cmax+cmin)/2
> ??ne[i:ncl]<-(1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
> ??Ep0<-Epower(nc, d, ne, pc, alpha)
> ?}
> ??ne.old1<-ne
> }
> ne1<-ne
> ### sweeping backward -- ncl:i
> ne.old2<-ne.old
> ne???? <-ne.old
> for(i in ncl:1){
> ?cmin<-cc[1]
> ?cmax<-cc[2]
> ### fixed cci<-cmax bug
> ?cci <-1
> ?lhood<-dbinom((ncl:i)-1,nc,pc[i])
> ?lenl <-length(lhood)
> ?ne[ncl:i]<-(1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
> ?Ep0 <-Epower(nc, d, cci*ne, pc, alpha)
> ?while(abs(Ep0[i]-power)>tol1){
> ??if(Ep0[i]<power) cmin<-cci
> ??else cmax<-cci
> ??cci<-(cmax+cmin)/2
> ??ne[ncl:i]<-(1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
> ??Ep0<-Epower(nc, d, ne, pc, alpha)
> ?}
> ??ne.old2<-ne
> }
> ne2<-ne
> ne<-(ne1+ne2)/2
> #cat(ccc*ne)
> Ep1<-Epower(nc, d, ne, pc, alpha)
> return(list(ne=ne, Ep=Ep1))
> }
> ###
> vertex<-function(x,y)
> { ?n<-length(x)
> ?vx<-x[1]
> ?vy<-y[1]
> ?vp<-1
> ?up<-T
> ?for (i in (2:n))
> ?{ if (up)
> ??{ ?if (y[i-1] > y[i])
> ???{vx<-c(vx,x[i-1])
> ??? vy<-c(vy,y[i-1])
> ??? vp<-c(vp,i-1)
> ??? up<-F
> ???}
> ??}
> ??else
> ??{ ?if (y[i-1] < y[i]) up<-T
> ??}
> ?}
> ?vx<-c(vx,x[n])
> ?vy<-c(vy,y[n])
> ?vp<-c(vp,n)
> ?return(list(vx=vx,vy=vy,vp=vp))
> }
> ###
> convex<-function(x,y)
> {
> ?n<-length(x)
> ?ans<-vertex(x,y)
> ?len<-length(ans$vx)
> ?while (len>3)
> ?{
> #??cat("x=",x,"\n")
> #??cat("y=",y,"\n")
> ??newx<-x[1:(ans$vp[2]-1)]
> ??newy<-y[1:(ans$vp[2]-1)]
> ??for (i in (2:(len-1)))
> ??{
> ?? ?newx<-c(newx,x[ans$vp[i]])
> ???newy<-c(newy,y[ans$vp[i]])
> ??}
> ??newx<-c(newx,x[(ans$vp[len-1]+1):n])
> ??newy<-c(newy,y[(ans$vp[len-1]+1):n])
> ??y<-approx(newx,newy,xout=x)$y
> #??cat("new y=",y,"\n")
> ??ans<-vertex(x,y)
> ??len<-length(ans$vx)
> #??cat("vx=",ans$vx,"\n")
> #??cat("vy=",ans$vy,"\n")
> }
> ?return(list(wx=x,wy=y))}
> ###
> Epower<-function(nc, d, ne, pc = (0:((1 - d) * nc))/nc, alpha = 0.05)
> {
> #-------------------------------------
> # nc???? sample size in historical control
> # d????? the increase of response rate between historical and experiment
> # ne???? sample size of corresonding rc of 0 to nc*(1-d)
> # pc???? the response rate of control group, where we compute the
> #??????? expected power
> # alpha? the size of test
> #-------------------------------------
> ?kk <- length(pc)
> ?rc <- 0:(nc * (1 - d))
> ?pp <- rep(NA, kk)
> ?ppp <- rep(NA, kk)
> ?for(i in 1:(kk)) {
> ??pe <- pc[i] + d
> ??lhood <- dbinom(rc, nc, pc[i])
> ??pp <- power1.f(rc, nc, ne, pe, alpha)
> ??ppp[i] <- sum(pp * lhood)/sum(lhood)
> ?}
> ?return(ppp)
> }
> # adapted from the old biss2
> ss.rand<-function(rc,nc,d,alpha=.05,power=.8,tol=.01)
> {
> ne<-nc
> ne1<-nc+50
> while(abs(ne-ne1)>tol & ne1<100000){
> ne<-ne1
> pe<-d+rc/nc
> ne1<-nef2(rc,nc,pe*ne,ne,alpha,power)
> ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
> }
> if (ne1>100000) return(NA)
> else return(ne1)
> }
> ###
> power1.f<-function(rc,nc,ne,pie,alpha=0.05){
> #-------------------------------------
> # rc?number of response in historical control
> # nc?sample size in historical control
> # ne??? sample size in experitment group
> # pie?true response rate for experiment group
> # alpha?size of the test
> #-------------------------------------
> za<-qnorm(1-alpha)
> re<-ne*pie
> xe<-asin(sqrt((re+0.375)/(ne+0.75)))
> xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
> ans<-za*sqrt(1+(ne+0.5)/(nc+0.5))-(xe-xc)/sqrt(1/(4*(ne+0.5)))
> return(1-pnorm(ans))
> }
> 
> 
> 
> *************************************ORIGINAL SPLUS
> SCRIPT************************************************************
> ## sshc.ssc: sample size calculation for historical control studies
> ## J. Jack Lee (jjlee at mdanderson.org) and Chi-hong Tseng
> ## Department of Biostatistics, Univ. of Texas M.D. Anderson Cancer Center
> ##
> ## 3/1/99
> ## updated 6/7/00: add loess
> ##------------------------------------------------------------------
> ######## Required Input:
> #
> # rc? ? number of response in historical control group
> # nc? ? sample size in historical control
> # d? ? ? target improvement = Pe - Pc
> # method 1=method based on the randomized design
> #? ? ? ? 2=Makuch & Simon method (Makuch RW, Simon RM. Sample size considerations
> #? ? ? ? ? for non-randomized comparative studies. J of Chron Dis 1980; 3:175-181.
> #? ? ? ? 3=uniform power method
> ######## optional Input:
> #
> # alpha? size of the test
> # power? desired power of the test
> # tol? ? convergence criterion for methods 1 & 2 in terms of sample size
> # tol1? convergence criterion for method 3 at any given obs Rc in terms of
>? difference
> #? ? ? ? ? of expected power from target
> # tol2? overall convergence criterion for method 3 as the max absolute deviation
> #? ? ? ? ? of expected power from target for all Rc
> # cc? ? range of multiplicative constant applied to the initial values ne
> # l.span smoothing constant for loess
> #
> # Note:? rc is required for methods 1 and 2 but not 3
> #? ? ? ? method 3 return the sample size need for rc=0 to (1-d)*nc
> #
> ######## Output
> # for methdos 1 & 2: return the sample size needed for the experimental group (1
> number)
> #? ? ? ? ? ? ? ? ? ? for given rc, nc, d, alpha, and power
> # for method 3:? ? ? return the profile of sample size needed for given nc, d, alpha, and
> power
> #? ? ? ? ? ? ? ? ? ? vector $ne contains the sample size corresponding to rc=0, 1, 2, ... nc*(1-d)
> #? ? ? ? ? ? ? ? ? ? vector $Ep contains the expected power corresponding to
> #? ? ? ? ? ? ? ? ? ? ? the true pc = (0, 1, 2, ..., nc*(1-d)) / nc
> #
> 
> #------------------------------------------------------------------
> sshc _ function(rc, nc, d, method, alpha=0.05, power=0.8,
> ??? ? ? ? ? ? ? tol=0.01, tol1=.0001, tol2=.005, cc=c(.1,2), l.span=.5)
> {
> ### for method 1
> if (method==1) {
> ??? ne1 _ ss.rand(rc,nc,d,alpha=.05,power=.8,tol=.01)
> ??? return(ne=ne1)
>? ? ? ? ? ? ? ? }
> ### for method 2
> if (method==2) {
> ne_nc
> ne1_nc+50
> while(abs(ne-ne1)>tol & ne1<100000){
> ne_ne1
> pe_d+rc/nc
> ne1_nef(rc,nc,pe*ne,ne,alpha,power)
> ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
> }
> if (ne1>100000) return(NA)
> else return(ne=ne1)
> }
> ### for method 3
> if (method==3) {
> if (tol1 > tol2/10) tol1_tol2/10
> ncstar _ (1-d)*nc
> pc_(0:ncstar)/nc
> ne _ rep(NA,ncstar + 1)
> for (i in (0:ncstar))
> { ne[i+1] _ ss.rand(i,nc,d,alpha=.05,power=.8,tol=.01)
> }
> plot(pc,ne,type='l',ylim=c(0,max(ne)*1.5))
> ans_c.searchd(nc, d, ne, alpha, power, cc, tol1)
> ### check overall absolute deviance
> old.abs.dev _ sum(abs(ans$Ep-power))
> ##bad
>? _ 0
> print(round(ans$Ep,4))
> print(round(ans$ne,2))
> lines(pc,ans$ne,lty=1,col=8)
> old.ne _ ans$ne
> ##while(max(abs(ans$Ep-power))>tol2 & bad==0){? #### unnecessary ##
> while(max(abs(ans$Ep-power))>tol2){
> ans_c.searchd(nc, d, ans$ne, alpha, power, cc, tol1)
> abs.dev _ sum(abs(ans$Ep-power))
> print(paste(" old.abs.dev=",old.abs.dev))
> print(paste("? ? abs.dev=",abs.dev))
> ##if (abs.dev > old.abs.dev) { bad _ 1}
> old.abs.dev _ abs.dev
> print(round(ans$Ep,4))
> print(round(ans$ne,2))
> lines(pc,old.ne,lty=1,col=1)
> lines(pc,ans$ne,lty=1,col=8)
> ### add convex
> ans$ne _ convex(pc,ans$ne)$wy
> ### add loess
> ###old.ne _ ans$ne
> loess.ne _ loess(ans$ne ~ pc, span=l.span)
> lines(pc,loess.ne$fit,lty=1,col=4)
> old.ne _ loess.ne$fit
> ###readline()
> }
> return(ne=ans$ne, Ep=ans$Ep)
>? ? ? ? ? ? ? ? }
> }
> 
> ## needed for method 1
> nef2_function(rc,nc,re,ne,alpha,power){
> za_qnorm(1-alpha)
> zb_qnorm(power)
> xe_asin(sqrt((re+0.375)/(ne+0.75)))
> xc_asin(sqrt((rc+0.375)/(nc+0.75)))
> ans_
>? 1/(4*(xc-xe)^2/(za+zb)^2-1/(nc+0.5)) - 0.5
> return(ans)
> }
> ## needed for method 2
> nef_function(rc,nc,re,ne,alpha,power){
> za_qnorm(1-alpha)
> zb_qnorm(power)
> xe_asin(sqrt((re+0.375)/(ne+0.75)))
> xc_asin(sqrt((rc+0.375)/(nc+0.75)))
> ans_(za*sqrt(1+(ne+0.5)/(nc+0.5))+zb)^2/(2*(xe-xc))^2-0.5
> return(ans)
> }
> ## needed for method 3
> c.searchd_function(nc, d, ne, alpha=0.05, power=0.8, cc=c(0.1,2),tol1=0.0001){
> #---------------------------
> # nc? ? sample size of control group
> # d? ? ? the differece to detect between control and experiment
> # ne? ? vector of starting sample size of experiment group
> #??? ??? ? ? corresonding to rc of 0 to nc*(1-d)
> # alpha? size of test
> # power? target power
> # cc??? ? pre-screen vector of constant c, the range should cover the
> #??? ??? ? ? the value of cc that has expected power
> # tol1? the allowance between the expceted power and target power
> #---------------------------
> pc_(0:((1-d)*nc))/nc
> ncl _ length(pc)
> ne.old _ ne
> ne.old1 _ ne.old
> ###
>? sweeping forward
> for(i in 1:ncl){
> ??? cmin _ cc[1]
> ??? cmax _ cc[2]
> ### fixed cci_cmax bug
> ??? cci? _ 1
> ??? lhood _ dbinom((i:ncl)-1,nc,pc[i])
> ??? ne[i:ncl] _ (1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
> ??? Ep0? _ Epower(nc, d, ne, pc, alpha)
> ??? while(abs(Ep0[i]-power)>tol1){
> ??? ??? if(Ep0[i]<power) cmin_cci
> ??? ??? else cmax_cci
> ??? ??? cci_(cmax+cmin)/2
> ??? ??? ne[i:ncl] _ (1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
> ??? ??? Ep0_Epower(nc, d, ne, pc, alpha)
> ??? }
>? ??? ne.old1 _ ne
> }
> ne1 _ ne
> ### sweeping backward -- ncl:i
> ne.old2 _ ne.old
> ne? ? ? _ ne.old
> for(i in ncl:1){
> ??? cmin _ cc[1]
> ??? cmax _ cc[2]
> ### fixed cci_cmax bug
> ??? cci? _ 1
> ??? lhood _ dbinom((ncl:i)-1,nc,pc[i])
> ??? lenl? _ length(lhood)
> ??? ne[ncl:i] _ (1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
> ??? Ep0? _ Epower(nc, d, cci*ne, pc, alpha)
> ??? while(abs(Ep0[i]-power)>tol1){
> ??? ??? if(Ep0[i]<power) cmin_cci
> ??? ??? else cmax_cci
> ??? ??? cci_(cmax+cmin)/2
> ??? ??? ne[ncl:i] _ (1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
> ??? ??? Ep0_Epower(nc, d, ne, pc, alpha)
> ??? }
>? ??? ne.old2 _ ne
> }
> 
> ne2 _ ne
> ne _ (ne1+ne2)/2
> #cat(ccc*ne)
> Ep1_Epower(nc, d, ne, pc, alpha)
> return(ne=ne, Ep=Ep1)
> }
> ###
> vertex _ function(x,y)
> { ??? n _ length(x)
> ??? vx _ x[1]
> ??? vy _ y[1]
> ??? vp _ 1
> ??? up _ T
> ??? for (i in (2:n))
> ??? { if (up)
> ??? ??? { ??? if (y[i-1] > y[i])
> ??? ??? ??? {vx _ c(vx,x[i-1])
> ??? ??? ??? vy _ c(vy,y[i-1])
> ??? ??? ??? vp _ c(vp,i-1)
> ??? ??? ??? up _ F
> ??? ??? ??? }
> ??? ??? }
> ??? ??? else
> ??? ??? { ??? if (y[i-1] < y[i]) up _ T
> ??? ??? }
> ??? }
> ??? vx _ c(vx,x[n])
> ??? vy _ c(vy,y[n])
> ??? vp _ c(vp,n)
> ??? return(vx=vx,vy=vy,vp=vp)
> }
> ###
> convex _ function(x,y)
> {
> ??? n _ length(x)
> ??? ans _ vertex(x,y)
> ??? len _ length(ans$vx)
> ??? while (len>3)
> ??? {
> #??? ??? cat("x=",x,"\n")
> #??? ??? cat("y=",y,"\n")
> ??? ??? newx _ x[1:(ans$vp[2]-1)]
> ??? ??? newy _ y[1:(ans$vp[2]-1)]
> ??? ??? for (i in (2:(len-1)))
> ??? ??? {
> ??? ??? ??? newx _ c(newx,x[ans$vp[i]])
> ??? ??? ??? newy _ c(newy,y[ans$vp[i]])
> ??? ??? }
> ??? ??? newx _ c(newx,x[(ans$vp[len-1]+1):n])
> ??? ??? newy _ c(newy,y[(ans$vp[len-1]+1):n])
> ??? ??? y _ approx(newx,newy,xout=x)$y
> #??? ??? cat("new y=",y,"\n")
> ??? ??? ans _ vertex(x,y)
> ??? ??? len _ length(ans$vx)
> #??? ??? cat("vx=",ans$vx,"\n")
> #??? ??? cat("vy=",ans$vy,"\n")
> 
> }
> ??? return(wx=x,wy=y)}
> ###
> Epower _ function(nc, d, ne, pc = (0:((1 - d) * nc))/nc, alpha = 0.05)
> {
> #-------------------------------------
> # nc? ? sample size in historical control
> # d? ? ? the increase of response rate between historical and experiment
> # ne? ? sample size of corresonding rc of 0 to nc*(1-d)
> # pc? ? the response rate of control group, where we compute the
> #? ? ? ? expected power
> # alpha? the size of test
> #-------------------------------------
> ??? kk <- length(pc)
> ??? rc <- 0:(nc * (1 - d))
> ??? pp <- rep(NA, kk)
> ??? ppp <- rep(NA, kk)
> ??? for(i in 1:(kk)) {
> ??? ??? pe <- pc[i] + d
> ??? ??? lhood <- dbinom(rc, nc, pc[i])
> ??? ??? pp <- power1.f(rc, nc, ne, pe, alpha)
> ??? ??? ppp[i] <- sum(pp * lhood)/sum(lhood)
> ??? }
> ??? return(ppp)
> }
> 
> # adapted from the old biss2
> ss.rand _ function(rc,nc,d,alpha=.05,power=.8,tol=.01)
> {
> ne_nc
> ne1_nc+50
> while(abs(ne-ne1)>tol & ne1<100000){
> ne_ne1
> pe_d+rc/nc
> ne1_nef2(rc,nc,pe*ne,ne,alpha,power)
> 
> ## if(is.na(ne1))
>? print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
> }
> if (ne1>100000) return(NA)
> else return(ne1)
> }
> ###
> power1.f_function(rc,nc,ne,pie,alpha=0.05){
> #-------------------------------------
> # rc??? number of response in historical control
> # nc??? sample size in historical control
> # ne? ? sample size in experitment group
> # pie??? true response rate for experiment group
> # alpha??? size of the test
> #-------------------------------------
> 
> za_qnorm(1-alpha)
> re_ne*pie
> xe_asin(sqrt((re+0.375)/(ne+0.75)))
> xc_asin(sqrt((rc+0.375)/(nc+0.75)))
> ans_za*sqrt(1+(ne+0.5)/(nc+0.5))-(xe-xc)/sqrt(1/(4*(ne+0.5)))
> return(1-pnorm(ans))
> }
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From juliosergio at gmail.com  Wed Jun  5 23:11:05 2013
From: juliosergio at gmail.com (Julio Sergio)
Date: Wed, 5 Jun 2013 21:11:05 +0000
Subject: [R]
	=?utf-8?q?Trying_to_build_up_functions_with_its_names_by_mean?=
	=?utf-8?q?s=09of=09lapply?=
References: <loom.20130605T043218-210@post.gmane.org>
	<250F03A2-77CE-4FAC-B1C9-6754567A3F6A@gmail.com>	<51AF09A5.4080700@sapo.pt>
	<51AF0BE3.3050500@sapo.pt>
	<CACk-te21kO0xP+4RpvJrLVxoUZjbAVh_h6RbL0JxSwoBH2YwPg@mail.gmail.com>
	<loom.20130605T215734-601@post.gmane.org>
	<E66794E69CFDE04D9A70842786030B931C2FD621@PA-MBX01.na.tibco.com>
Message-ID: <loom.20130605T230722-349@post.gmane.org>

William Dunlap <wdunlap <at> tibco.com> writes:

> f1 <- function (c, nm = "gamma", ...)
> {
>     probFunc <- getFunction(paste0(c, nm))
>     force(list(...))
>     function(x) probFunc(x, ...)
> }
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
> 

Thanks a lot William!, this really enhances my knowledge of the language.

 -Sergio.


From tlumley at uw.edu  Wed Jun  5 23:15:24 2013
From: tlumley at uw.edu (Thomas Lumley)
Date: Thu, 6 Jun 2013 09:15:24 +1200
Subject: [R] probability weights in multilevel models
In-Reply-To: <1370362411836-4668645.post@n4.nabble.com>
References: <1370362411836-4668645.post@n4.nabble.com>
Message-ID: <CAJ55+d+Tm01h=2RWEzvE2RCtt8T_xjmbdXS-fou7td4WK-gY+Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130606/136d4c5a/attachment.pl>

From wdunlap at tibco.com  Wed Jun  5 23:26:37 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 5 Jun 2013 21:26:37 +0000
Subject: [R] Trying to build up functions with its names by
	means	of	lapply
In-Reply-To: <loom.20130605T230722-349@post.gmane.org>
References: <loom.20130605T043218-210@post.gmane.org>
	<250F03A2-77CE-4FAC-B1C9-6754567A3F6A@gmail.com>	<51AF09A5.4080700@sapo.pt>
	<51AF0BE3.3050500@sapo.pt>
	<CACk-te21kO0xP+4RpvJrLVxoUZjbAVh_h6RbL0JxSwoBH2YwPg@mail.gmail.com>
	<loom.20130605T215734-601@post.gmane.org>
	<E66794E69CFDE04D9A70842786030B931C2FD621@PA-MBX01.na.tibco.com>
	<loom.20130605T230722-349@post.gmane.org>
Message-ID: <E66794E69CFDE04D9A70842786030B931C2FD67E@PA-MBX01.na.tibco.com>

You can put print statements into the arguments given to a function to more directly
see when they get evaluated.  E.g., 

> z <- f0(c={ cat("Evaluating 'c' argument\n"); "p"}, nm="norm", mean={ cat("Evaluating 'mean' argument\n"); 1.2 })
Evaluating 'c' argument
> z(1:5)
Evaluating 'mean' argument
[1] 0.4207403 0.7881446 0.9640697 0.9974449 0.9999277
>
> z <- f1(c={ cat("Evaluating 'c' argument\n"); "p"}, nm="norm", mean={ cat("Evaluating 'mean' argument\n"); 1.2 })
Evaluating 'c' argument
Evaluating 'mean' argument
> z(1:5)
[1] 0.4207403 0.7881446 0.9640697 0.9974449 0.9999277
> pnorm(1:5, mean=1.2)
[1] 0.4207403 0.7881446 0.9640697 0.9974449 0.9999277

where f0 does not call force(list(...)) and f1 does.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Julio Sergio
> Sent: Wednesday, June 05, 2013 2:11 PM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] Trying to build up functions with its names by means of lapply
> 
> William Dunlap <wdunlap <at> tibco.com> writes:
> 
> > f1 <- function (c, nm = "gamma", ...)
> > {
> >     probFunc <- getFunction(paste0(c, nm))
> >     force(list(...))
> >     function(x) probFunc(x, ...)
> > }
> >
> > Bill Dunlap
> > Spotfire, TIBCO Software
> > wdunlap tibco.com
> >
> 
> Thanks a lot William!, this really enhances my knowledge of the language.
> 
>  -Sergio.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From junxu.r at gmail.com  Thu Jun  6 00:13:16 2013
From: junxu.r at gmail.com (Xu Jun)
Date: Wed, 5 Jun 2013 18:13:16 -0400
Subject: [R] multilevel binary and ordered regression models
Message-ID: <CADe_g+W+1cZOoGFquWxc7xt9qUoBLKQU43ApGVrRbrkEk3PdTg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130605/97417842/attachment.pl>

From smartpink111 at yahoo.com  Thu Jun  6 01:16:43 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 5 Jun 2013 16:16:43 -0700 (PDT)
Subject: [R] dates and time series management
In-Reply-To: <1370467035.61051.YahooMailNeo@web160603.mail.bf1.yahoo.com>
References: <1370384616.88390.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1370391272.9589.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1370397420.70765.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1370401423.51446.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1370402738.70484.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1370403455.40198.YahooMailNeo@web160602.mail.bf1.yahoo.com>
	<1370403750.12728.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1370404333.84419.YahooMailNeo@web160605.mail.bf1.yahoo.com>
	<1370404682.21912.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1370406335.8400.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<1370406649.16477.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1370412356.2514.YahooMailNeo@web160604.mail.bf1.yahoo.com>
	<1370439881.75797.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1370444162.39307.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1370447097.93721.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1370467035.61051.YahooMailNeo@web160603.mail.bf1.yahoo.com>
Message-ID: <1370474203.51290.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Try this:
lstf1<- list.files(pattern=".txt")
length(lstf1)
#[1] 119
#I changed the function a little bit to unlist by rows to match the dates column I created.

fun2<- function(lstf){
?lst1<-lapply(lstf,function(x) readLines(x))
?lst2<-lapply(lst1,function(x) {gsub("(\\d+)(-9999.99)","\\1 \\2",x)})
?lst3<-lapply(lst2,function(x) {x<-gsub("(\\d+)(-9999.99)","\\1 \\2",x)})
?lst4<- lapply(lst3,function(x) read.table(text=x,header=TRUE,stringsAsFactors=FALSE,sep="",fill=TRUE))
?lst5<- lapply(lst4,function(x) x[x$V1>=1961 & x$V1<=2005,])
?lst6<- lapply(lst5,function(x) x[!is.na(x$V1),])
?lst7<- lapply(lst6,function(x) {
???????????????????? if((min(x$V1)>1961)|(max(x$V1)<2005)){
???????????????????????? n1<- (min(x$V1)-1961)*12
???????????????????????? x1<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n1))
???????????????????????? n2<- (2005-max(x$V1))*12
???????????????????????? x2<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n2))
???????????????????????? x3<- rbind(x1,x,x2)
??????????????????????? }
????????????????????????? else {
??????????????????? x
??????????????????? } })
??? lst8<-lapply(lst7,function(x) data.frame(col1=unlist(data.frame(t(x)[-c(1:2),]),use.names=FALSE))) ####changed
???? lst9<- lapply(seq_along(lst8),function(i){
??????????????????????? x<- lst8[[i]]
??????????????????????? colnames(x)<- lstf1[i]
??????????????????????? row.names(x)<- 1:nrow(x)
??????????????????????? x
??????????????????????? })
?do.call(cbind,lst9)}
res<-fun2(lstf1)
dim(res)
#[1] 16740?? 119
?res[res==-9999.99]<-NA
which(res==-9999.99)
#integer(0)

dates1<-seq.Date(as.Date('1Jan1961',format="%d%b%Y"),as.Date('31Dec2005',format="%d%b%Y"),by="day")
dates2<- as.character(dates1)
sldat<- split(dates2,list(gsub("-.*","",dates2)))
?lst11<-lapply(sldat,function(x) lapply(split(x,gsub(".*-(.*)-.*","\\1",x)), function(y){x1<-as.numeric(gsub(".*-.*-(.*)","\\1",y));if((31-max(x1))>0) {x2<-seq(max(x1)+1,31,1);x3<-paste0(unique(gsub("(.*-.*-).*","\\1",y)),x2);c(y,x3)} else y} ))
any(sapply(lst1,function(x) any(lapply(x,length)!=31)))
#[1] FALSE
lst22<-lapply(lst11,function(x) unlist(x,use.names=FALSE))
sapply(lst22,length)
#1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 
# 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372 
#1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 
# 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372 
#1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 
# 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372 

?dates3<-unlist(lst22,use.names=FALSE)
?length(dates3)
#[1] 16740
res1<- data.frame(dates=dates3,res,stringsAsFactors=FALSE)
str(res1)
'data.frame':??? 16740 obs. of? 120 variables:
?$ dates??????? : chr? "1961-01-01" "1961-01-02" "1961-01-03" "1961-01-04" ...
?$ dt3011120.txt: num? 1.67 0 0 0 0 0 4.17 0 0 0 ...
?$ dt3011240.txt: num? NA NA NA NA NA NA NA NA NA NA ...
?$ dt3011887.txt: num? 0.17 0.28 0 0.3 0 0 1.78 0 0.3 0 ...
?$ dt3012205.txt: num? 0.34 0.21 0 0.51 0 0 2.82 0 0.3 0 ...
-----------------------------------------------------------
res1$dates<-as.Date(res1$dates)
?res2<-res1[!is.na(res1$dates),]
res2[1:3,1:3]
#?????? dates dt3011120.txt dt3011240.txt
#1 1961-01-01????????? 1.67??????????? NA
#2 1961-01-02????????? 0.00??????????? NA
#3 1961-01-03????????? 0.00??????????? NA
?dim(res2)
#[1] 16436?? 120

Now, you can try the reshape() and the zoo().
Hope it helps.
A.K.








________________________________
From: Zilefac Elvis <zilefacelvis at yahoo.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Wednesday, June 5, 2013 5:17 PM
Subject: Re: dates and time series management



Hi A.K,
I am gradually improving my R skills thanks to your support.
I have this code for the attached data.
********************************************************************************************************
library(hydroTSM)

# Reading the data with 21 daily simulations, from 1961-01-01 up to 2005-12-31
x <- read.csv("data2.csv")

# Creating a single variable with all the dates
dates <- as.Date(paste0(x$year, "-", x$month, "-", x$day), format="%Y-%m-%d")

# Creating a data.frame with 3 columns: simulation number, Date, Rainfall values
x.new <- data.frame(s.num=x[,1], Date=dates, Rainfall=x[,5])

# Creating a data.frame with 22 columns: Dates + Rainfall values for21 simulations
x.wide <- reshape(x.new, idvar = "Date", timevar = "s.num", direction = "wide")
# Creating a zoo variable
z <- zoo(x.wide[,-1], order.by=x.wide[,1])
# 5-day total rainfall for each one of the simulations

z.5tot <- rollapply(data=z, width=5, FUN=sum, fill=NA, partial= TRUE,
? ? ? ? ? ? ? ? ? ? align="center")# to get the total of 5-day precipitation
# Maximum value per year of 5-day total rainfall for each one of the simulations
z.5max.annual <- daily2annual(z.5max, dates=1, FUN=max)
*********************************************************************************************************

Problem: I am trying to do a similar thing with 'res' from our previous problem (see below). However, instead of width=5, I need something like?
Max.Daily<-rollapply(data=z, width=372, FUN=max, by.column = TRUE, partial= TRUE, align="center")
# width=1961 to 2005=45years, 16740/45=372

To do this, I need a date column vector just as I did above. Can you show me how to generate daily dates with??format="%Y-%m-%d"??
Days range from 1 to 31 for all months since we filled for example February having 28/29 days with NA.?
Months from 1 to 12 and years from 1961 to 2005.

If column 1 of 'res' contains dates, then we can use parts of the code above to extract the Maximum value for each year and for each column.
So, my final output will be 45 * 119.?

Thanks so much A.K. I keep learning hard though slowly. ?

________________________________
From: arun 
: R help <r-help at r-project.org> 
Sent: Wednesday, June 5, 2013 9:44 AM
Subject: Re: dates and time series management


Hi Atem,
No problem.


?which(res==-9999.99)
# [1]?? 18246? 397379? 420059? 426569? 427109? 603659? 604199? 662518? 664678
#[10]? 698982? 699522? 700062? 701142? 754745 1289823 1500490 1589487 1716011
#[19] 1837083
?which(res==-9999.99,arr.ind=TRUE)
#??????? row col
#1506?? 1506?? 2
#12359 12359? 24
#1559?? 1559? 26
#8069?? 8069? 26

#----------------------
res[ which(res==-9999.99,arr.ind=TRUE)]<-NA
#or

res[res==-9999.99]<-NA
?which(res==-9999.99)
#integer(0)
A.K.




________________________________
From: Zilefac Elvis <zilefacelv
5, 2013 10:56 AM
Subject: Re: dates and time series management



Hi A.K,

It works as expected. You are too smart.
Can you find all -9999.99 and replace with NA, if only it exists?

lst2<-lapply(lst1,function(x) {gsub("(\\d+)(-9999.99)","\\1 \\2",x)})
?lst3<-lapply(lst2,function(x) {x<-gsub("(\\d+)(-9999.99)","\\1 \\2",x)})?


Thanks so much A.K.



________________________________
From: arun <smartpin
<r-help at r-project.org> 
Sent: Wednesday, June 5, 2013 7:44 AM
Subject: Re: dates and time series management


Hi,
Try this:
lstf1<- list.files(pattern=".txt")
length(lstf1)
#[1] 119
fun2<- function(lstf){
?lst1<-lapply(lstf,function(x) readLines(x))
?lst2<-lapply(lst1,function(x) {gsub("(\\d+)(-9999.99)","\\1 \\2",x)})
?lst3<-lapply(lst2,function(x) {x<-gsub("(\\d+)(-9999.99)","\\1
\\2",x)})
?lst4<- lapply(lst3,function(x) read.table(text=x,header=TRUE,stringsAsFactors=FALSE,sep="",fill=TRUE))
?lst5<- lapply(lst4,function(x) x[x$V1>=1961 & x$V1<=2005,])
?lst6<- lapply(lst5,function(x) x[!is.na(x$V1),])
?lst7<- lapply(lst6,function(x) {

if((min(x$V1)>1961)|(max(x$V1)<2005)){
???????????????????????? n1<- (min(x$V1)-1961)*12
???????????????????????? x1<-
as.data.frame(matrix(NA,ncol=ncol(x),nrow=n1))
???????????????????????? n2<- (2005-max(x$V1))*12
???????????????????????? x2<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n2))
???????????????????????? x3<-
rbind(x1,x,x2)
??????????????????????? }
????????????????????????? else
{
??????????????????? x
??????????????????? } })

lst8<- lapply(lst7,function(x) data.frame(col1=unlist(x[,-c(1:2)])))
???? lst9<- lapply(seq_along(lst8),function(i){
??????????????????????? x<-
lst8[[i]]
??????????????????????? colnames(x)<- lstf1[i]
??????????????????????? row.names(x)<-
1:nrow(x)
??????????????????????? x
??????????????????????? })
?do.call(cbind,lst9)}
res<-fun2(lstf1)
dim(res)
#[1] 16740?? 119
res[1:5,1:3]
?# dt3011120.txt dt3011240.txt dt3011887.txt
#1????????? 1.67???????????
NA????????? 0.17
#2????????? 0.00??????????? NA????????? 0.28
#3?????????
0.00??????????? NA????????? 0.00
#4????????? 0.00??????????? NA????????? 0.30
#5????????? 0.00??????????? NA????????? 0.00


########################################

There are some formatting issues in your files:
For eg. If I run the
function line by line:

?lst1<-lapply(lstf1,function(x) readLines(x))
sapply(lst1,function(x) any(grepl("\\d+-9999.99",x)))
? [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
FALSE
?[25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[37]? TRUE FALSE? TRUE FALSE FALSE? TRUE FALSE FALSE FALSE FALSE FALSE FALSE
?[49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[73] FALSE FALSE FALSE FALSE FALSE? TRUE FALSE FALSE FALSE FALSE? TRUE FALSE
?[85] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE? TRUE
?[97] FALSE FALSE FALSE FALSE FALSE FALSE? TRUE? TRUE FALSE FALSE FALSE FALSE
[109]
FALSE FALSE FALSE FALSE? TRUE FALSE FALSE FALSE FALSE FALSE? TRUE


###means some rows in the a few files have:
#-9999.99 0 0 0 0.00-9999.99 0 0.00-9999.99 0 0 0 0.00-9999.99 (no space before -9999.99)


?lst2<-lapply(lst1,function(x) {gsub("(\\d+)(-9999.99)","\\1
\\2",x)})
sapply(lst2,function(x) any(grepl("\\d+-9999.99",x))) #still a few files had the problem
? [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[73] FALSE FALSE FALSE FALSE
FALSE FALSE FALSE FALSE FALSE FALSE? TRUE FALSE
?[85] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE? TRUE
?[97] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
[109] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
FALSE
lst3<-lapply(lst2,function(x) {x<-gsub("(\\d+)(-9999.99)","\\1 \\2",x)})
any(sapply(lst3,function(x) any(grepl("\\d+-9999.99",x))))
#[1] FALSE
lst4<- lapply(lst3,function(x) read.table(text=x,header=TRUE,stringsAsFactors=FALSE,sep="",fill=TRUE))


any(sapply(lst4,function(x) any(sapply(x,is.character))))
#[1] FALSE

?lst5<- lapply(lst4,function(x) x[x$V1>=1961 & x$V1<=2005,])
lst6<- lapply(lst5,function(x) x[!is.na(x$V1),])
sapply(lst6,nrow)
?# [1] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [19] 540 540 540 540 540 540 540 540 540 540 540 540
540 540 540 540 540 540
# [37] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [55] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [73] 540 540 540 540 528 492 528 540 348 540 540 480 540 540 540 540 540 540
# [91] 540 540 540 540 540 540
540 540 540 540 540 540 540 540 528 540 540 540
#[109] 540 540 540 540 540 540 540 540 540 468 540

???? lst7<- lapply(lst6,function(x) {
???????????????????? if((min(x$V1)>1961)|(max(x$V1)<2005)){
???????????????????????? n1<-
(min(x$V1)-1961)*12
???????????????????????? x1<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n1))
???????????????????????? n2<-
(2005-max(x$V1))*12
???????????????????????? x2<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n2))
???????????????????????? x3<- rbind(x1,x,x2)

}
????????????????????????? else {
??????????????????? x
??????????????????? }
})

?sapply(lst7,nrow)
#? [1] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [19] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [37] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [55] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [73] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [91] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
#[109] 540 540 540 540 540
540 540 540 540 540 540


Hope this helps.
A.K.

________________________________
Fr
om> 
Sent: Wednesday, June 5, 2013 2:05
AM
Subject: Re: dates and time series management



Hi A.K,
Sorry my internet connection was so bad last evening.

I have attached all the files as .zip.
Below is the output you requested.
As I explained, the start date in 'res' should be 1961 and end date should be 2005 in all 119 files.

Thanks A.K

> lapply(lst1,head,3)
[[1]]
? V1.V2.V3.V4.V5.V6.V7.V8.V9.V10.V11.V12.V13.V14.V15.V16.V17.V18.V19.V20.V21.V22.V23.V24.V25.V26.V27.V28.V29.V30.V31.V32.V33
1 ? ? ? ? ? ?
? ? ? ? ? ?1915 1 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
2 ? ? ? ? ? ? ? ? ? ? ? ?1915 2 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
3 ? ? ? ? ? ? ? ? ? ?
? ?1915 3 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA

[???????????????????????????????????????????


From dimitri.liakhovitski at gmail.com  Thu Jun  6 01:38:05 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Wed, 5 Jun 2013 19:38:05 -0400
Subject: [R] rJava is not loading
Message-ID: <CAN2xGJbUNA25+e9fR6NWo+HaYES1w3j_KMRpPY73cRDvA37uog@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130605/20b6bbba/attachment.pl>

From ejb274 at psu.edu  Wed Jun  5 15:00:34 2013
From: ejb274 at psu.edu (ejb)
Date: Wed, 5 Jun 2013 06:00:34 -0700 (PDT)
Subject: [R] Map Antarctica
Message-ID: <1370437234111-4668713.post@n4.nabble.com>

Hey, I'm new with R and I'm attempting to map and then plot points on a map
of Antarctica with help from some code at the following link.  Link
<http://www.molecularecologist.com/2012/09/making-maps-with-r/>  

After downloading the packages here is the code I used. I feel like the
problem has to do with the coordinates since I get a very small image that
appears to be only a small portion of the continent (I want the whole
thing). Thanks in advance!

library(maps)
library(mapdata)
map("worldHires","Antarctica",xlim=c(-90,-60),ylim=c(-180,180),col="gray90",fill=TRUE)



 



--
View this message in context: http://r.789695.n4.nabble.com/Map-Antarctica-tp4668713.html
Sent from the R help mailing list archive at Nabble.com.


From andreas1tr at web.de  Wed Jun  5 10:49:55 2013
From: andreas1tr at web.de (Andtrei89)
Date: Wed, 5 Jun 2013 01:49:55 -0700 (PDT)
Subject: [R] List into table
Message-ID: <1370422195429-4668693.post@n4.nabble.com>

Hi everyone,

I want to open an XML file in R and it also works.
But then I get a list of all numbers but it isn't in the type of "numeric".

I tried this:

exampleData <-
"C:/Users/Andreas/Desktop/Thesis/Interzeptionsmodell/Daten/Karlsruhe/Windgeschwindigkeit/1948.xml"

F <- system.file("exampleData", "1948.xml", package = "XML")
f <- xmlToDataFrame(exampleData, colClasses = NULL, homogeneous = TRUE,
collectNames = TRUE,
                    stringsAsFactors = default.stringsAsFactors())


I got this:

1 4.9 5.0 5.3 4.4 2.9 1.9 1.1 1.5 1.6 1.2 0.7 0.8 2.5 2.3 1.6 0.6 1.3 0.8
1.3 1.2 3.9 5.0 6.4 6.3 8.4
   NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
NA  NA  NA  NA  NA  NA  NA
1 8.4 8.3 8.3 9.1 8.3 7.7 6.8 5.4 4.8 3.6 3.6 3.5 2.6 3.5 3.0 3.1 2.4 3.4
3.3 4.8 6.1 5.1 4.2 4.5 4.5
   NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
NA  NA  NA  NA  NA  NA  NA
1 5.4 4.7 4.6 3.8 4.0 1.5 0.0 1.1 0.7 0.0 0.0 1.3 1.5 1.6 0.0 0.7 0.6 0.5
1.8 1.5 1.6 1.5 1.9 2.5 2.5

I only want the numbers out of it as numeric ... if I try as.numeric() I got
a list looking like that:

1 1 1 1 1 1 1 1 1  1  1 1 1 1 1 1 ..........

I would be very thankful for your answer

Andy
  



--
View this message in context: http://r.789695.n4.nabble.com/List-into-table-tp4668693.html
Sent from the R help mailing list archive at Nabble.com.


From isabelp at iseg.utl.pt  Wed Jun  5 13:01:55 2013
From: isabelp at iseg.utl.pt (=?iso-8859-1?Q?Isabel_Proen=E7a?=)
Date: Wed, 5 Jun 2013 12:01:55 +0100
Subject: [R] sandwich matrix in gamm
Message-ID: <007301ce61dc$17b1f100$4715d300$@iseg.utl.pt>

Hello, 

I need to calculate a sandwich covariance matrix in gamm. The package
sandwich does not work because:
Error in UseMethod("vcov") : no applicable method for 'vcov' applied to an
object of class "c('gamm', 'list')"

Does anyone knows how to overcome this problem? Thanks in advance.

Regards,
Isabel Proen?a
Dep. of Mathematics
ISEG ? UTL (Technical University)


From sandro.magalhaes at presentvalue.pt  Wed Jun  5 13:07:22 2013
From: sandro.magalhaes at presentvalue.pt (=?iso-8859-1?Q?Sandro_Magalh=E3es?=)
Date: Wed, 5 Jun 2013 12:07:22 +0100
Subject: [R]  R error- "more columns than column names"
Message-ID: <51af1bf3.05fb0e0a.3659.0baf@mx.google.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130605/415d7ac4/attachment.pl>

From daniel.tucker at rochester.edu  Wed Jun  5 15:33:58 2013
From: daniel.tucker at rochester.edu (Daniel Tucker)
Date: Wed, 5 Jun 2013 09:33:58 -0400
Subject: [R] Subsetting out missing values for a certain variable
Message-ID: <CAO=keJyL26Hwo=NtABm60fdzm2Y0Q1+anXeCYeBqmTYMGC1WPA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130605/33cad290/attachment.pl>

From dtucker9 at u.rochester.edu  Wed Jun  5 15:54:50 2013
From: dtucker9 at u.rochester.edu (Daniel Tucker)
Date: Wed, 5 Jun 2013 09:54:50 -0400
Subject: [R] Subsetting out missing values for a certain variable
In-Reply-To: <CAO=keJyL26Hwo=NtABm60fdzm2Y0Q1+anXeCYeBqmTYMGC1WPA@mail.gmail.com>
References: <CAO=keJyL26Hwo=NtABm60fdzm2Y0Q1+anXeCYeBqmTYMGC1WPA@mail.gmail.com>
Message-ID: <CAO=keJyu_8wRpgz2yYr_YC1HzsAUPwhp8Wd0wvPW-ifK78QPqQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130605/9d9fc16b/attachment.pl>

From dtucker9 at u.rochester.edu  Wed Jun  5 15:58:44 2013
From: dtucker9 at u.rochester.edu (Daniel Tucker)
Date: Wed, 5 Jun 2013 09:58:44 -0400
Subject: [R] Subsetting out missing values for a certain variable
In-Reply-To: <CAO=keJyu_8wRpgz2yYr_YC1HzsAUPwhp8Wd0wvPW-ifK78QPqQ@mail.gmail.com>
References: <CAO=keJyL26Hwo=NtABm60fdzm2Y0Q1+anXeCYeBqmTYMGC1WPA@mail.gmail.com>
	<CAO=keJyu_8wRpgz2yYr_YC1HzsAUPwhp8Wd0wvPW-ifK78QPqQ@mail.gmail.com>
Message-ID: <CAO=keJwzmac3BB_2XmpAfksX4o04uEXcs+51ui9QoGC3vabJJA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130605/35b4c889/attachment.pl>

From ivo.welch at gmail.com  Wed Jun  5 16:32:34 2013
From: ivo.welch at gmail.com (ivo welch)
Date: Wed, 5 Jun 2013 07:32:34 -0700
Subject: [R] read.csv and write.csv filtering for very big data ?
In-Reply-To: <51AF29CC.2010807@gmail.com>
References: <CAPr7RtW3fX73N5NZRQbuN7M+PFJHzXo0L1VuMLih1P2Uz5Gx5g@mail.gmail.com>
	<CAFEqCdy7tYgY_DYtovOewfFXzuRWH2XxKYyuqf8BMAzdWOwDqw@mail.gmail.com>
	<CAPr7RtVYb-FFNDv4=JA+RP5XNor4Tg_6jLf5hY44NfUuAVyZ5w@mail.gmail.com>
	<51AF29CC.2010807@gmail.com>
Message-ID: <CAPr7RtXNdfxW1o5S3pwd6Z9y+EQEsWObNn0niKSspRS69da52w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130605/e2733c9a/attachment.pl>

From batsncats at gmail.com  Wed Jun  5 16:35:54 2013
From: batsncats at gmail.com (Bruce Miller)
Date: Wed, 05 Jun 2013 10:35:54 -0400
Subject: [R] reshape2 issue
Message-ID: <51AF4CCA.10104@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130605/5aa442b5/attachment.pl>

From mksrivas at mtu.edu  Wed Jun  5 17:45:13 2013
From: mksrivas at mtu.edu (Manish K. Srivastava)
Date: Wed, 05 Jun 2013 11:45:13 -0400
Subject: [R] installing package 'rqpd' (Regression quantiles for panel
 data)
In-Reply-To: <51AE45E5.3060301@gmail.com>
References: <51ACA5FD.5060404@mtu.edu> <51AE45E5.3060301@gmail.com>
Message-ID: <51AF5D09.3020900@mtu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130605/5a270cba/attachment.pl>

From swanson.ali at gmail.com  Wed Jun  5 17:54:46 2013
From: swanson.ali at gmail.com (Ali Swanson)
Date: Wed, 5 Jun 2013 10:54:46 -0500
Subject: [R] Temporally autocorrelated Poisson data
Message-ID: <CAAXPCyi9Qmek50TF-0Tq1Vhb=k6HxXT70ZWe0=55fdHOR2BSkg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130605/8e2a8219/attachment.pl>

From danielle.edwards at yale.edu  Wed Jun  5 23:49:33 2013
From: danielle.edwards at yale.edu (Edwards, Danielle)
Date: Wed, 5 Jun 2013 21:49:33 +0000
Subject: [R] Error in anova.cca by="axis" after Vegan update
Message-ID: <CDD52AAC.7E0D%danielle.edwards@yale.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130605/d26f04fa/attachment.pl>

From thomas.hufnagel1 at gmx.de  Wed Jun  5 23:56:16 2013
From: thomas.hufnagel1 at gmx.de (ThomasH)
Date: Wed, 5 Jun 2013 14:56:16 -0700 (PDT)
Subject: [R] combining two different matrizes
Message-ID: <1370469376981-4668766.post@n4.nabble.com>


Hello together,

this is ma first post, so please aplogize me if post this in the wrong
section.

I have problem concerning ma two matrizes.

After a regressione and so on, I got two matrizes

Matrixres contains the results of ma calculation.

Matrixr contains my detiene, which where Aldo used for the regression.

Please ser the following code:

#Datei einlesen
residual = read.csv2("E:***Input-R_Renditen.csv",header=TRUE, sep=";")


#Aktientitel
alist <- list()
for (a in 2:11){


#Regression
? ?#L?nge Gesamtzeit
? ?t <- 243
? ?tx <- t-59

? ?#L?nge Regression
? ?reglist <- list()
? ?for (i in 1:tx){
? ?j <- i+59

? ?#RegressionsVariable
? ?x = residual[i:j,a]
? ?rm = residual[i:j,12]
? ?smb = residual[i:j,13]
? ?hml = residual[i:j,14]
? ?rf = residual[i:j,15]

? ?#?berschussrenditen
? ?ex=x-rf
? ?erm=rm-rf

? ?#Regression
? ?reg <- lm(ex~erm+smb+hml)
? ?reglist[[i]] <- coef(reg)
? ?

#Berechnung Residuum
? ?? ?#Residual Berechnung
? ?? ?rx = residual[(j-5):j,a]
? ?? ?rrm = residual[(j-5):j,12]
? ?? ?rsmb = residual[(j-5):j,13]
? ?? ?rhml = residual[(j-5):j,14]
? ?? ?rrf = residual[(j-5):j,15]

? ?? ?rex = rx-rrf
? ?? ?rerm = rrm-rrf

? ?? ?#Berechnung
? ?? ?res <-
sum(rex-(reglist[[i]][2]*rerm+reglist[[i]][3]*rsmb+reglist[[i]][4]*rhml))/sd(rex-(reglist[[i]][2]*rerm+reglist[[i]][3]*rsmb+reglist[[i]][4]*rhml))
? ?? ?reglist[[i]] <- res
}? ?
? ?

#Residuen auf alle Aktien
? ?alist[[a]] <- reglist
}
? ?
#Matrix mit Residuen
? ?matrixres <- do.call(cbind,alist)

#Spaltennamen/Zeilennamen
s<- names(residual)[2:11]
colnames(matrixres)<-s

#RenditeMatrix
matrixr <- do.call(cbind,residual[60:243,2:11])


Now I want to combines  the two matrizes in the following way:

Under every row of matrixres should stand the row of matrixr for excample:

Matrixres row1
Matrixr row1
Matrixres row2
Matrixr row 2

Can anybody help me? I was working on this problem the whole day, but have
no idea.

Thanks alot
Thomash




--
View this message in context: http://r.789695.n4.nabble.com/combining-two-different-matrizes-tp4668766.html
Sent from the R help mailing list archive at Nabble.com.


From jorgeivanvelez at gmail.com  Thu Jun  6 02:37:41 2013
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Thu, 6 Jun 2013 10:37:41 +1000
Subject: [R] Subsetting out missing values for a certain variable
In-Reply-To: <CAO=keJyu_8wRpgz2yYr_YC1HzsAUPwhp8Wd0wvPW-ifK78QPqQ@mail.gmail.com>
References: <CAO=keJyL26Hwo=NtABm60fdzm2Y0Q1+anXeCYeBqmTYMGC1WPA@mail.gmail.com>
	<CAO=keJyu_8wRpgz2yYr_YC1HzsAUPwhp8Wd0wvPW-ifK78QPqQ@mail.gmail.com>
Message-ID: <1889709742138422586@unknownmsgid>

Daniel,
You need "==" instead of "=".
HTH,
Jorge.-

Sent from my phone. Please excuse my brevity and misspelling.

On Jun 6, 2013, at 10:36 AM, Daniel Tucker <dtucker9 at u.rochester.edu> wrote:

> Also tried this but results werent any different
>
> subset1<- subset(dframe, glb_ind="Y" | sample==1 | !is.na(glb_ind))
> subset2<-subset(dframe, cwar_ind="Y" |sample==2 | !is.na(cwar_ind))
> subset3<-subset(dframe, reg_ind="Y" | sample==3 | !is.na(reg_ind))
>
>
> On Wed, Jun 5, 2013 at 9:33 AM, Daniel Tucker
> <daniel.tucker at rochester.edu>wrote:
>
>> I am trying to create a new datafarme using the subset function given 2
>> conditions
>>
>> subset1<- subset(dframe, glb_ind="Y" | sample==1)
>> subset2<-subset(dframe, cwar_ind="Y" | sample==2)
>> subset3<-subset(dframe, reg_ind="Y" | sample==3)
>>
>> However, my first conditions (glb_ind,cwar_ind, and reg_ind) all have
>> missing values (they are either Y, N, or no value. In subsetting my data, I
>> am looking to not only get rid of the "N" in the new dataframes, but also
>> the NA's. I don't want to na.omit the entire data frame; I only want to get
>> rid of missing values (and non Y values) for a certain variable (glb_ind,
>> cwar_ind, reg_ind) for each subset. Is there anyway I can do this?
>>
>> Thanks,
>> Dan
>
>    [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mdsumner at gmail.com  Thu Jun  6 02:57:26 2013
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 6 Jun 2013 10:57:26 +1000
Subject: [R] Map Antarctica
In-Reply-To: <1370437234111-4668713.post@n4.nabble.com>
References: <1370437234111-4668713.post@n4.nabble.com>
Message-ID: <CAAcGz9-teUakOig15a7FhM1ZwMu7izvrxNEwxyh9MO3s1rWw8A@mail.gmail.com>

You have mixed your x with your y, try this:

 map("worldHires","Antarctica",ylim=c(-90,-60),xlim=c(-180,180),col="gray90",fill=TRUE)

I tend not to use maps/mapdata if I can help it (there are problems as
you can see, though there is support for projections with mapproject,
see ?map), if you want to use an alternative try this.

library(maptools)
data(wrld_simpl)
## select out just the continent
antarctica <-  wrld_simpl[wrld_simpl$NAME == "Antarctica", ]
plot(antarctica)
degAxis(1)
degAxis(2)

For a better display of this part of the world

library(rgdal)
## define a sensible projection
pr <- "+proj=laea +lat_0=-90 +ellps=WGS84 +datum=WGS84 +no_defs +towgs84=0,0,0"
antarctica.laea <- spTransform(antarctica, CRS(pr))


plot(antarctica.laea)

Removing the dud coordinates at -90 is a bit more difficult, but can
be done (the first plot by map() has a similar problem).

There is a mailing list R-Sig-Geo which is more topical for questions
like this if you want to explore further.

Cheers, Mike.

On Wed, Jun 5, 2013 at 11:00 PM, ejb <ejb274 at psu.edu> wrote:
> Hey, I'm new with R and I'm attempting to map and then plot points on a map
> of Antarctica with help from some code at the following link.  Link
> <http://www.molecularecologist.com/2012/09/making-maps-with-r/>
>
> After downloading the packages here is the code I used. I feel like the
> problem has to do with the coordinates since I get a very small image that
> appears to be only a small portion of the continent (I want the whole
> thing). Thanks in advance!
>
> library(maps)
> library(mapdata)
> map("worldHires","Antarctica",xlim=c(-90,-60),ylim=c(-180,180),col="gray90",fill=TRUE)
>
>
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Map-Antarctica-tp4668713.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Michael Sumner
Hobart, Australia
e-mail: mdsumner at gmail.com


From kridox at ymail.com  Thu Jun  6 03:24:02 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 06 Jun 2013 10:24:02 +0900
Subject: [R] Map Antarctica
In-Reply-To: <1370437234111-4668713.post@n4.nabble.com>
References: <1370437234111-4668713.post@n4.nabble.com>
Message-ID: <51AFE4B2.1040907@ymail.com>

Hi,

There is a problem with xlim and ylim.

map("worldHires","Antarctica",xlim=c(-180,180),ylim=c(-90,-60),col="gray90",fill=TRUE)


You also might have a look at "ggplot2"

library(ggplot2)
world <- map_data("world")
worldmap <- ggplot(world, aes(x=long, y=lat, group=group)) +
   geom_path() +
   scale_y_continuous(breaks=(-2:2) * 30) +
   scale_x_continuous(breaks=(-4:4) * 45)

worldmap + coord_map("ortho", orientation=c(-90, 0, 0))

Regards,
Pascal


On 05/06/13 22:00, ejb wrote:
> Hey, I'm new with R and I'm attempting to map and then plot points on a map
> of Antarctica with help from some code at the following link.  Link
> <http://www.molecularecologist.com/2012/09/making-maps-with-r/>
>
> After downloading the packages here is the code I used. I feel like the
> problem has to do with the coordinates since I get a very small image that
> appears to be only a small portion of the continent (I want the whole
> thing). Thanks in advance!
>
> library(maps)
> library(mapdata)
> map("worldHires","Antarctica",xlim=c(-90,-60),ylim=c(-180,180),col="gray90",fill=TRUE)
>
>
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Map-Antarctica-tp4668713.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mackay at northnet.com.au  Thu Jun  6 03:26:38 2013
From: mackay at northnet.com.au (Duncan Mackay)
Date: Thu, 06 Jun 2013 11:26:38 +1000
Subject: [R] SPlus script
In-Reply-To: <1370465718.71929.YahooMailNeo@web142702.mail.bf1.yahoo.com
 >
References: <1370438435.93923.YahooMailNeo@web142703.mail.bf1.yahoo.com>
	<E66794E69CFDE04D9A70842786030B931C2FD5C4@PA-MBX01.na.tibco.com>
	<1370465718.71929.YahooMailNeo@web142702.mail.bf1.yahoo.com>
Message-ID: <201306060126.r561Qg5b019081@mail15.tpg.com.au>

Hi Scott

I converted the _ to <- and ran it in 3.01

Ran about half way and then could not find nl? and others so may be 
some scoping problems? or other problems

Duncan


Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au



At 06:55 6/06/2013, you wrote:
>As you can see, my original modification was to replace all _ with 
><-.  It worked after I
>did that.  This is a simulation that generates its own data based on 
>the given parameters.
>I should obtain a plot of the number of experimental subjects as a 
>function of the repsonse
>rate in the historical group.  Maybe I'm forgetting something 
>here...  It's been a while since I
>ran this.  Thanks for your help.
>
>
>----- Original Message -----
>From: William Dunlap <wdunlap at tibco.com>
>To: Scott Raynaud <scott.raynaud at yahoo.com>; "r-help at r-project.org" 
><r-help at r-project.org>
>Cc:
>Sent: Wednesday, June 5, 2013 2:17 PM
>Subject: RE: [R] SPlus script
>
>Both the R and S+ versions (which seem to differ only in the use of 
>_ for assignment
>in the S+ version) do nothing but define some functions.  You would 
>not expect any
>printed output unless you used those functions on some data.  Is 
>there another script
>that does that?
>
>Bill Dunlap
>Spotfire, TIBCO Software
>wdunlap tibco.com
>
>
> > -----Original Message-----
> > From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf
> > Of Scott Raynaud
> > Sent: Wednesday, June 05, 2013 6:21 AM
> > To: r-help at r-project.org
> > Subject: [R] SPlus script
> >
> > This originally was an SPlus script that I modifeid about a 
> year-and-a-half ago.  It worked
> > perfectly then.  Now I can't get any output despite not receiving 
> an error message.  I'm
> > providing the SPLUS script as a reference.  I'm running 
> R15.2.2.  Any help appreciated.
> >
> > ************************************MY
> > MODIFICATION***********************************************************
> > **********
> > ## sshc.ssc: sample size calculation for historical control studies
> > ## J. Jack Lee (jjlee at mdanderson.org) and Chi-hong Tseng
> > ## Department of Biostatistics, Univ. of Texas M.D. Anderson Cancer Center
> > ##
> > ## 3/1/99
> > ## updated 6/7/00: add loess
> > ##------------------------------------------------------------------
> > ######## Required Input:
> > #
> > # rc     number of response in historical control group
> > # nc     sample size in historical control
> > # d      target improvement = Pe - Pc
> > # method 1=method based on the randomized design
> > #        2=Makuch & Simon method (Makuch RW, Simon RM. Sample 
> size considerations
> > #          for non-randomized comparative studies. J of Chron Dis 
> 1980; 3:175-181.
> > #        3=uniform power method
> > ######## optional Input:
> > #
> > # alpha  size of the test
> > # power  desired power of the test
> > # tol    convergence criterion for methods 1 & 2 in terms of sample size
> > # tol1   convergence criterion for method 3 at any given obs Rc 
> in terms of difference
> > #          of expected power from target
> > # tol2   overall convergence criterion for method 3 as the max 
> absolute deviation
> > #          of expected power from target for all Rc
> > # cc     range of multiplicative constant applied to the initial values ne
> > # l.span smoothing constant for loess
> > #
> > # Note:  rc is required for methods 1 and 2 but not 3
> > #        method 3 return the sample size need for rc=0 to (1-d)*nc
> > #
> > ######## Output
> > # for methdos 1 & 2: return the sample size needed for the 
> experimental group (1
> > number)
> > #                    for given rc, nc, d, alpha, and power
> > # for method 3:      return the profile of sample size needed for 
> given nc, d, alpha, and
> > power
> > #                    vector $ne contains the sample size 
> corresponding to rc=0, 1, 2, ... nc*(1-d)
> > #                    vector $Ep contains the expected power 
> corresponding to
> > #                      the true pc = (0, 1, 2, ..., nc*(1-d)) / nc
> > #
> > #------------------------------------------------------------------
> > sshc<-function(rc, nc=1092, d=.085779816, method=3, alpha=0.05, power=0.8,
> >               tol=0.01, tol1=.0001, tol2=.005, cc=c(.1,2), l.span=.5)
> > {
> > ### for method 1
> > if (method==1) {
> >  ne1<-ss.rand(rc,nc,d,alpha=.05,power=.8,tol=.01)
> >  return(ne=ne1)
> >                }
> > ### for method 2
> > if (method==2) {
> > ne<-nc
> > ne1<-nc+50
> > while(abs(ne-ne1)>tol & ne1<100000){
> > ne<-ne1
> > pe<-d+rc/nc
> > ne1<-nef(rc,nc,pe*ne,ne,alpha,power)
> > ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
> > }
> > if (ne1>100000) return(NA)
> > else return(ne=ne1)
> > }
> > ### for method 3
> > if (method==3) {
> > if (tol1 > tol2/10) tol1<-tol2/10
> > ncstar<-(1-d)*nc
> > pc<-(0:ncstar)/nc
> > ne<-rep(NA,ncstar + 1)
> > for (i in (0:ncstar))
> > { ne[i+1]<-ss.rand(i,nc,d,alpha=.05,power=.8,tol=.01)
> > }
> > plot(pc,ne,type='l',ylim=c(0,max(ne)*1.5))
> > ans<-c.searchd(nc, d, ne, alpha, power, cc, tol1)
> > ### check overall absolute deviance
> > old.abs.dev<-sum(abs(ans$Ep-power))
> > ##bad<-0
> > print(round(ans$Ep,4))
> > print(round(ans$ne,2))
> > lines(pc,ans$ne,lty=1,col=8)
> > old.ne<-ans$ne
> > ##while(max(abs(ans$Ep-power))>tol2 & bad==0){  #### unnecessary ##
> > while(max(abs(ans$Ep-power))>tol2){
> > ans<-c.searchd(nc, d, ans$ne, alpha, power, cc, tol1)
> > abs.dev<-sum(abs(ans$Ep-power))
> > print(paste(" old.abs.dev=",old.abs.dev))
> > print(paste("     abs.dev=",abs.dev))
> > ##if (abs.dev > old.abs.dev) { bad<-1}
> > old.abs.dev<-abs.dev
> > print(round(ans$Ep,4))
> > print(round(ans$ne,2))
> > lines(pc,old.ne,lty=1,col=1)
> > lines(pc,ans$ne,lty=1,col=8)
> > ### add convex
> > ans$ne<-convex(pc,ans$ne)$wy
> > ### add loess
> > ###old.ne<-ans$ne
> > loess.ne<-loess(ans$ne ~ pc, span=l.span)
> > lines(pc,loess.ne$fit,lty=1,col=4)
> > old.ne<-loess.ne$fit
> > ###readline()
> > }
> > return(list(ne=ans$ne, Ep=ans$Ep))
> >                }
> > }
> > ## needed for method 1
> > nef2<-function(rc,nc,re,ne,alpha,power){
> > za<-qnorm(1-alpha)
> > zb<-qnorm(power)
> > xe<-asin(sqrt((re+0.375)/(ne+0.75)))
> > xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
> > ans<- 1/(4*(xc-xe)^2/(za+zb)^2-1/(nc+0.5)) - 0.5
> > return(ans)
> > }
> > ## needed for method 2
> > nef<-function(rc,nc,re,ne,alpha,power){
> > za<-qnorm(1-alpha)
> > zb<-qnorm(power)
> > xe<-asin(sqrt((re+0.375)/(ne+0.75)))
> > xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
> > ans<-(za*sqrt(1+(ne+0.5)/(nc+0.5))+zb)^2/(2*(xe-xc))^2-0.5
> > return(ans)
> > }
> > ## needed for method 3
> > c.searchd<-function(nc, d, ne, alpha=0.05, power=0.8, 
> cc=c(0.1,2),tol1=0.0001){
> > #---------------------------
> > # nc     sample size of control group
> > # d      the differece to detect between control and experiment
> > # ne     vector of starting sample size of experiment group
> > #      corresonding to rc of 0 to nc*(1-d)
> > # alpha  size of test
> > # power  target power
> > # cc   pre-screen vector of constant c, the range should cover the
> > #      the value of cc that has expected power
> > # tol1   the allowance between the expceted power and target power
> > #---------------------------
> > pc<-(0:((1-d)*nc))/nc
> > ncl<-length(pc)
> > ne.old<-ne
> > ne.old1<-ne.old
> > ### sweeping forward
> > for(i in 1:ncl){
> >  cmin<-cc[1]
> >  cmax<-cc[2]
> > ### fixed cci<-cmax bug
> >  cci <-1
> >  lhood<-dbinom((i:ncl)-1,nc,pc[i])
> >  ne[i:ncl]<-(1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
> >  Ep0 <-Epower(nc, d, ne, pc, alpha)
> >  while(abs(Ep0[i]-power)>tol1){
> >   if(Ep0[i]<power) cmin<-cci
> >   else cmax<-cci
> >   cci<-(cmax+cmin)/2
> >   ne[i:ncl]<-(1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
> >   Ep0<-Epower(nc, d, ne, pc, alpha)
> >  }
> >   ne.old1<-ne
> > }
> > ne1<-ne
> > ### sweeping backward -- ncl:i
> > ne.old2<-ne.old
> > ne     <-ne.old
> > for(i in ncl:1){
> >  cmin<-cc[1]
> >  cmax<-cc[2]
> > ### fixed cci<-cmax bug
> >  cci <-1
> >  lhood<-dbinom((ncl:i)-1,nc,pc[i])
> >  lenl <-length(lhood)
> >  ne[ncl:i]<-(1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
> >  Ep0 <-Epower(nc, d, cci*ne, pc, alpha)
> >  while(abs(Ep0[i]-power)>tol1){
> >   if(Ep0[i]<power) cmin<-cci
> >   else cmax<-cci
> >   cci<-(cmax+cmin)/2
> >   ne[ncl:i]<-(1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
> >   Ep0<-Epower(nc, d, ne, pc, alpha)
> >  }
> >   ne.old2<-ne
> > }
> > ne2<-ne
> > ne<-(ne1+ne2)/2
> > #cat(ccc*ne)
> > Ep1<-Epower(nc, d, ne, pc, alpha)
> > return(list(ne=ne, Ep=Ep1))
> > }
> > ###
> > vertex<-function(x,y)
> > {  n<-length(x)
> >  vx<-x[1]
> >  vy<-y[1]
> >  vp<-1
> >  up<-T
> >  for (i in (2:n))
> >  { if (up)
> >   {  if (y[i-1] > y[i])
> >    {vx<-c(vx,x[i-1])
> >     vy<-c(vy,y[i-1])
> >     vp<-c(vp,i-1)
> >     up<-F
> >    }
> >   }
> >   else
> >   {  if (y[i-1] < y[i]) up<-T
> >   }
> >  }
> >  vx<-c(vx,x[n])
> >  vy<-c(vy,y[n])
> >  vp<-c(vp,n)
> >  return(list(vx=vx,vy=vy,vp=vp))
> > }
> > ###
> > convex<-function(x,y)
> > {
> >  n<-length(x)
> >  ans<-vertex(x,y)
> >  len<-length(ans$vx)
> >  while (len>3)
> >  {
> > #  cat("x=",x,"\n")
> > #  cat("y=",y,"\n")
> >   newx<-x[1:(ans$vp[2]-1)]
> >   newy<-y[1:(ans$vp[2]-1)]
> >   for (i in (2:(len-1)))
> >   {
> >     newx<-c(newx,x[ans$vp[i]])
> >    newy<-c(newy,y[ans$vp[i]])
> >   }
> >   newx<-c(newx,x[(ans$vp[len-1]+1):n])
> >   newy<-c(newy,y[(ans$vp[len-1]+1):n])
> >   y<-approx(newx,newy,xout=x)$y
> > #  cat("new y=",y,"\n")
> >   ans<-vertex(x,y)
> >   len<-length(ans$vx)
> > #  cat("vx=",ans$vx,"\n")
> > #  cat("vy=",ans$vy,"\n")
> > }
> >  return(list(wx=x,wy=y))}
> > ###
> > Epower<-function(nc, d, ne, pc = (0:((1 - d) * nc))/nc, alpha = 0.05)
> > {
> > #-------------------------------------
> > # nc     sample size in historical control
> > # d      the increase of response rate between historical and experiment
> > # ne     sample size of corresonding rc of 0 to nc*(1-d)
> > # pc     the response rate of control group, where we compute the
> > #        expected power
> > # alpha  the size of test
> > #-------------------------------------
> >  kk <- length(pc)
> >  rc <- 0:(nc * (1 - d))
> >  pp <- rep(NA, kk)
> >  ppp <- rep(NA, kk)
> >  for(i in 1:(kk)) {
> >   pe <- pc[i] + d
> >   lhood <- dbinom(rc, nc, pc[i])
> >   pp <- power1.f(rc, nc, ne, pe, alpha)
> >   ppp[i] <- sum(pp * lhood)/sum(lhood)
> >  }
> >  return(ppp)
> > }
> > # adapted from the old biss2
> > ss.rand<-function(rc,nc,d,alpha=.05,power=.8,tol=.01)
> > {
> > ne<-nc
> > ne1<-nc+50
> > while(abs(ne-ne1)>tol & ne1<100000){
> > ne<-ne1
> > pe<-d+rc/nc
> > ne1<-nef2(rc,nc,pe*ne,ne,alpha,power)
> > ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
> > }
> > if (ne1>100000) return(NA)
> > else return(ne1)
> > }
> > ###
> > power1.f<-function(rc,nc,ne,pie,alpha=0.05){
> > #-------------------------------------
> > # rc number of response in historical control
> > # nc sample size in historical control
> > # ne    sample size in experitment group
> > # pie true response rate for experiment group
> > # alpha size of the test
> > #-------------------------------------
> > za<-qnorm(1-alpha)
> > re<-ne*pie
> > xe<-asin(sqrt((re+0.375)/(ne+0.75)))
> > xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
> > ans<-za*sqrt(1+(ne+0.5)/(nc+0.5))-(xe-xc)/sqrt(1/(4*(ne+0.5)))
> > return(1-pnorm(ans))
> > }
> >
> >
> >
> > *************************************ORIGINAL SPLUS
> > SCRIPT************************************************************
> > ## sshc.ssc: sample size calculation for historical control studies
> > ## J. Jack Lee (jjlee at mdanderson.org) and Chi-hong Tseng
> > ## Department of Biostatistics, Univ. of Texas M.D. Anderson Cancer Center
> > ##
> > ## 3/1/99
> > ## updated 6/7/00: add loess
> > ##------------------------------------------------------------------
> > ######## Required Input:
> > #
> > # rc    number of response in historical control group
> > # nc    sample size in historical control
> > # d      target improvement = Pe - Pc
> > # method 1=method based on the randomized design
> > #        2=Makuch & Simon method (Makuch RW, Simon RM. Sample 
> size considerations
> > #          for non-randomized comparative studies. J of Chron Dis 
> 1980; 3:175-181.
> > #        3=uniform power method
> > ######## optional Input:
> > #
> > # alpha  size of the test
> > # power  desired power of the test
> > # tol    convergence criterion for methods 1 & 2 in terms of sample size
> > # tol1  convergence criterion for method 3 at any given obs Rc in terms of
> >  difference
> > #          of expected power from target
> > # tol2  overall convergence criterion for method 3 as the max 
> absolute deviation
> > #          of expected power from target for all Rc
> > # cc    range of multiplicative constant applied to the initial values ne
> > # l.span smoothing constant for loess
> > #
> > # Note:  rc is required for methods 1 and 2 but not 3
> > #        method 3 return the sample size need for rc=0 to (1-d)*nc
> > #
> > ######## Output
> > # for methdos 1 & 2: return the sample size needed for the 
> experimental group (1
> > number)
> > #                    for given rc, nc, d, alpha, and power
> > # for method 3:      return the profile of sample size needed for 
> given nc, d, alpha, and
> > power
> > #                    vector $ne contains the sample size 
> corresponding to rc=0, 1, 2, ... nc*(1-d)
> > #                    vector $Ep contains the expected power 
> corresponding to
> > #                      the true pc = (0, 1, 2, ..., nc*(1-d)) / nc
> > #
> >
> > #------------------------------------------------------------------
> > sshc _ function(rc, nc, d, method, alpha=0.05, power=0.8,
> >                 tol=0.01, tol1=.0001, tol2=.005, cc=c(.1,2), l.span=.5)
> > {
> > ### for method 1
> > if (method==1) {
> >     ne1 _ ss.rand(rc,nc,d,alpha=.05,power=.8,tol=.01)
> >     return(ne=ne1)
> >                }
> > ### for method 2
> > if (method==2) {
> > ne_nc
> > ne1_nc+50
> > while(abs(ne-ne1)>tol & ne1<100000){
> > ne_ne1
> > pe_d+rc/nc
> > ne1_nef(rc,nc,pe*ne,ne,alpha,power)
> > ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
> > }
> > if (ne1>100000) return(NA)
> > else return(ne=ne1)
> > }
> > ### for method 3
> > if (method==3) {
> > if (tol1 > tol2/10) tol1_tol2/10
> > ncstar _ (1-d)*nc
> > pc_(0:ncstar)/nc
> > ne _ rep(NA,ncstar + 1)
> > for (i in (0:ncstar))
> > { ne[i+1] _ ss.rand(i,nc,d,alpha=.05,power=.8,tol=.01)
> > }
> > plot(pc,ne,type='l',ylim=c(0,max(ne)*1.5))
> > ans_c.searchd(nc, d, ne, alpha, power, cc, tol1)
> > ### check overall absolute deviance
> > old.abs.dev _ sum(abs(ans$Ep-power))
> > ##bad
> >  _ 0
> > print(round(ans$Ep,4))
> > print(round(ans$ne,2))
> > lines(pc,ans$ne,lty=1,col=8)
> > old.ne _ ans$ne
> > ##while(max(abs(ans$Ep-power))>tol2 & bad==0){  #### unnecessary ##
> > while(max(abs(ans$Ep-power))>tol2){
> > ans_c.searchd(nc, d, ans$ne, alpha, power, cc, tol1)
> > abs.dev _ sum(abs(ans$Ep-power))
> > print(paste(" old.abs.dev=",old.abs.dev))
> > print(paste("    abs.dev=",abs.dev))
> > ##if (abs.dev > old.abs.dev) { bad _ 1}
> > old.abs.dev _ abs.dev
> > print(round(ans$Ep,4))
> > print(round(ans$ne,2))
> > lines(pc,old.ne,lty=1,col=1)
> > lines(pc,ans$ne,lty=1,col=8)
> > ### add convex
> > ans$ne _ convex(pc,ans$ne)$wy
> > ### add loess
> > ###old.ne _ ans$ne
> > loess.ne _ loess(ans$ne ~ pc, span=l.span)
> > lines(pc,loess.ne$fit,lty=1,col=4)
> > old.ne _ loess.ne$fit
> > ###readline()
> > }
> > return(ne=ans$ne, Ep=ans$Ep)
> >                }
> > }
> >
> > ## needed for method 1
> > nef2_function(rc,nc,re,ne,alpha,power){
> > za_qnorm(1-alpha)
> > zb_qnorm(power)
> > xe_asin(sqrt((re+0.375)/(ne+0.75)))
> > xc_asin(sqrt((rc+0.375)/(nc+0.75)))
> > ans_
> >  1/(4*(xc-xe)^2/(za+zb)^2-1/(nc+0.5)) - 0.5
> > return(ans)
> > }
> > ## needed for method 2
> > nef_function(rc,nc,re,ne,alpha,power){
> > za_qnorm(1-alpha)
> > zb_qnorm(power)
> > xe_asin(sqrt((re+0.375)/(ne+0.75)))
> > xc_asin(sqrt((rc+0.375)/(nc+0.75)))
> > ans_(za*sqrt(1+(ne+0.5)/(nc+0.5))+zb)^2/(2*(xe-xc))^2-0.5
> > return(ans)
> > }
> > ## needed for method 3
> > c.searchd_function(nc, d, ne, alpha=0.05, power=0.8, 
> cc=c(0.1,2),tol1=0.0001){
> > #---------------------------
> > # nc    sample size of control group
> > # d      the differece to detect between control and experiment
> > # ne    vector of starting sample size of experiment group
> > #            corresonding to rc of 0 to nc*(1-d)
> > # alpha  size of test
> > # power  target power
> > # cc      pre-screen vector of constant c, the range should cover the
> > #            the value of cc that has expected power
> > # tol1  the allowance between the expceted power and target power
> > #---------------------------
> > pc_(0:((1-d)*nc))/nc
> > ncl _ length(pc)
> > ne.old _ ne
> > ne.old1 _ ne.old
> > ###
> >  sweeping forward
> > for(i in 1:ncl){
> >     cmin _ cc[1]
> >     cmax _ cc[2]
> > ### fixed cci_cmax bug
> >     cci  _ 1
> >     lhood _ dbinom((i:ncl)-1,nc,pc[i])
> >     ne[i:ncl] _ (1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
> >     Ep0  _ Epower(nc, d, ne, pc, alpha)
> >     while(abs(Ep0[i]-power)>tol1){
> >         if(Ep0[i]<power) cmin_cci
> >         else cmax_cci
> >         cci_(cmax+cmin)/2
> >         ne[i:ncl] _ (1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
> >         Ep0_Epower(nc, d, ne, pc, alpha)
> >     }
> >      ne.old1 _ ne
> > }
> > ne1 _ ne
> > ### sweeping backward -- ncl:i
> > ne.old2 _ ne.old
> > ne      _ ne.old
> > for(i in ncl:1){
> >     cmin _ cc[1]
> >     cmax _ cc[2]
> > ### fixed cci_cmax bug
> >     cci  _ 1
> >     lhood _ dbinom((ncl:i)-1,nc,pc[i])
> >     lenl  _ length(lhood)
> >     ne[ncl:i] _ (1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
> >     Ep0  _ Epower(nc, d, cci*ne, pc, alpha)
> >     while(abs(Ep0[i]-power)>tol1){
> >         if(Ep0[i]<power) cmin_cci
> >         else cmax_cci
> >         cci_(cmax+cmin)/2
> >         ne[ncl:i] _ (1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
> >         Ep0_Epower(nc, d, ne, pc, alpha)
> >     }
> >      ne.old2 _ ne
> > }
> >
> > ne2 _ ne
> > ne _ (ne1+ne2)/2
> > #cat(ccc*ne)
> > Ep1_Epower(nc, d, ne, pc, alpha)
> > return(ne=ne, Ep=Ep1)
> > }
> > ###
> > vertex _ function(x,y)
> > {     n _ length(x)
> >     vx _ x[1]
> >     vy _ y[1]
> >     vp _ 1
> >     up _ T
> >     for (i in (2:n))
> >     { if (up)
> >         {     if (y[i-1] > y[i])
> >             {vx _ c(vx,x[i-1])
> >             vy _ c(vy,y[i-1])
> >             vp _ c(vp,i-1)
> >             up _ F
> >             }
> >         }
> >         else
> >         {     if (y[i-1] < y[i]) up _ T
> >         }
> >     }
> >     vx _ c(vx,x[n])
> >     vy _ c(vy,y[n])
> >     vp _ c(vp,n)
> >     return(vx=vx,vy=vy,vp=vp)
> > }
> > ###
> > convex _ function(x,y)
> > {
> >     n _ length(x)
> >     ans _ vertex(x,y)
> >     len _ length(ans$vx)
> >     while (len>3)
> >     {
> > #        cat("x=",x,"\n")
> > #        cat("y=",y,"\n")
> >         newx _ x[1:(ans$vp[2]-1)]
> >         newy _ y[1:(ans$vp[2]-1)]
> >         for (i in (2:(len-1)))
> >         {
> >             newx _ c(newx,x[ans$vp[i]])
> >             newy _ c(newy,y[ans$vp[i]])
> >         }
> >         newx _ c(newx,x[(ans$vp[len-1]+1):n])
> >         newy _ c(newy,y[(ans$vp[len-1]+1):n])
> >         y _ approx(newx,newy,xout=x)$y
> > #        cat("new y=",y,"\n")
> >         ans _ vertex(x,y)
> >         len _ length(ans$vx)
> > #        cat("vx=",ans$vx,"\n")
> > #        cat("vy=",ans$vy,"\n")
> >
> > }
> >     return(wx=x,wy=y)}
> > ###
> > Epower _ function(nc, d, ne, pc = (0:((1 - d) * nc))/nc, alpha = 0.05)
> > {
> > #-------------------------------------
> > # nc    sample size in historical control
> > # d      the increase of response rate between historical and experiment
> > # ne    sample size of corresonding rc of 0 to nc*(1-d)
> > # pc    the response rate of control group, where we compute the
> > #        expected power
> > # alpha  the size of test
> > #-------------------------------------
> >     kk <- length(pc)
> >     rc <- 0:(nc * (1 - d))
> >     pp <- rep(NA, kk)
> >     ppp <- rep(NA, kk)
> >     for(i in 1:(kk)) {
> >         pe <- pc[i] + d
> >         lhood <- dbinom(rc, nc, pc[i])
> >         pp <- power1.f(rc, nc, ne, pe, alpha)
> >         ppp[i] <- sum(pp * lhood)/sum(lhood)
> >     }
> >     return(ppp)
> > }
> >
> > # adapted from the old biss2
> > ss.rand _ function(rc,nc,d,alpha=.05,power=.8,tol=.01)
> > {
> > ne_nc
> > ne1_nc+50
> > while(abs(ne-ne1)>tol & ne1<100000){
> > ne_ne1
> > pe_d+rc/nc
> > ne1_nef2(rc,nc,pe*ne,ne,alpha,power)
> >
> > ## if(is.na(ne1))
> >  print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
> > }
> > if (ne1>100000) return(NA)
> > else return(ne1)
> > }
> > ###
> > power1.f_function(rc,nc,ne,pie,alpha=0.05){
> > #-------------------------------------
> > # rc    number of response in historical control
> > # nc    sample size in historical control
> > # ne    sample size in experitment group
> > # pie    true response rate for experiment group
> > # alpha    size of the test
> > #-------------------------------------
> >
> > za_qnorm(1-alpha)
> > re_ne*pie
> > xe_asin(sqrt((re+0.375)/(ne+0.75)))
> > xc_asin(sqrt((rc+0.375)/(nc+0.75)))
> > ans_za*sqrt(1+(ne+0.5)/(nc+0.5))-(xe-xc)/sqrt(1/(4*(ne+0.5)))
> > return(1-pnorm(ans))
> > }
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pfeiffss at miamioh.edu  Thu Jun  6 03:20:02 2013
From: pfeiffss at miamioh.edu (Pfeiffer, Steven)
Date: Wed, 5 Jun 2013 21:20:02 -0400
Subject: [R] lme function cannot find object
Message-ID: <CAJjjYOnJnTj2frJ8_O5g+h8sYmkjCL3Zgj1F=OvgNYjxz11J8A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130605/25388c00/attachment.pl>

From smartpink111 at yahoo.com  Thu Jun  6 06:13:16 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 5 Jun 2013 21:13:16 -0700 (PDT)
Subject: [R] dates and time series management
In-Reply-To: <1370487887.8599.YahooMailNeo@web160601.mail.bf1.yahoo.com>
References: <1370384616.88390.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1370391272.9589.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1370397420.70765.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1370401423.51446.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1370402738.70484.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1370403455.40198.YahooMailNeo@web160602.mail.bf1.yahoo.com>
	<1370403750.12728.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1370404333.84419.YahooMailNeo@web160605.mail.bf1.yahoo.com>
	<1370404682.21912.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1370406335.8400.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<1370406649.16477.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1370412356.2514.YahooMailNeo@web160604.mail.bf1.yahoo.com>
	<1370439881.75797.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1370444162.39307.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1370447097.93721.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1370467035.61051.YahooMailNeo@web160603.mail.bf1.yahoo.com>
	<1370474203.51290.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1370487887.8599.YahooMailNeo@web160601.mail.bf1.yahoo.com>
Message-ID: <1370491996.19954.YahooMailNeo@web142604.mail.bf1.yahoo.com>



Hi,
I think it is due to the missing values:
I get warnings()
?z.5.annualMax<- daily2annual(z, FUN=max, na.rm=TRUE,dates=1)
#There were 50 or more warnings (use warnings() to see the first 50)
write.csv(z.5max.annual, file = "Stations.csv")
Just to validate? the result:


I tried this:
res3<- lapply(seq_len(ncol(res1[,-1])),function(i) {x<-data.frame(res1[,1],res1[,i+1]); names(x)<- c(names(res1)[1],names(res1)[i+1]);x})
res4<-lapply(res3,function(x) {x1<-x[!is.na(x$dates),]; na.omit(x1)})
library(zoo)
zl<- lapply(res4,function(x) zoo(x[,-1],order.by=x[,1]))
zl.max.annual<- lapply(zl,function(x) daily2annual(x,FUN=max,na.rm=TRUE)) #no warnings()
#na.rm=TRUE inside the daily2annual() didn't show any effect.

?sapply(zl.max.annual,length)
#? [1] 45 42 44 45 37 45 44 44 41 45 25 45 45 45 45 45 45 45 45 45 45 41 40 41 45
?#[26] 44 45 45 45 45 44 42 45 38 45 45 45 38 44 31 45 45 45 42 45 36 42 45 42 45
?#[51] 45 45 44 45 40 41 45 45 45 45 34 45 34 45 45 41 41 45 45 45 45 45 45 45 45
?#[76] 45 43 40 29 44 29 42 45 40 44 33 45 45 43 40 45 45 45 45 43 45 34 45 44 45
#[101] 45 44 30 44 44 42 45 45 43 42 44 45 45 45 45 42 45 39 39
library(xts)
zl.max.annual1<-lapply(zl.max.annual, as.xts)
?zl.merge<- Reduce(function(...) merge(...),zl.max.annual1))
?zl.merge[1:3,1:8]
#???????????? ..1?? ..2? ..2.1 ..2.2 ..2.3 ..2.4? ..2.5 ..2.6
#1961-01-01 35.37??? NA? 13.43 40.88 17.69 38.44? 50.56 36.93
#1962-01-01 34.54 34.85 102.97 39.84 73.43 68.88? 63.88 22.89
#1963-01-01 18.32??? NA? 64.18 51.49 14.61 40.79 127.74 25.07
?z.5.annualMax[1:3,1:8]
?# ???????? dt3011120.txt dt3011240.txt dt3011887.txt dt3012205.txt
#1961-01-01???????? 35.37??????????? NA???????? 13.43???????? 40.88
#1962-01-01???????? 34.54???????? 34.85??????? 102.97???????? 39.84
#1963-01-01???????? 18.32??????????? NA???????? 64.18???????? 51.49
?# ???????? dt3012280.txt dt3015405.txt dt3015523.txt dt3015960.txt
#1961-01-01???????? 17.69???????? 38.44???????? 50.56???????? 36.93
#1962-01-01???????? 73.43???????? 68.88???????? 63.88???????? 22.89
#1963-01-01???????? 14.61???????? 40.79??????? 127.74???????? 25.07

Looks like this is the same result as above.
A.K.


________________________________
From: Zilefac Elvis <zilefacelvis at yahoo.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Wednesday, June 5, 2013 11:04 PM
Subject: Re: dates and time series management





Hi A.K,

Here is the final code:
*******************************************************************
lstf1<- list.files(pattern=".txt")
length(lstf1)
#[1] 119
fun2<- function(lstf){
? lst1<-lapply(lstf,function(x) readLines(x))
? lst2<-lapply(lst1,function(x) {gsub("(\\d+)(-9999.99)","\\1 \\2",x)})
? lst3<-lapply(lst2,function(x) {x<-gsub("(\\d+)(-9999.99)","\\1 \\2",x)})
? lst4<- lapply(lst3,function(x) read.table(text=x,header=TRUE,stringsAsFactors=FALSE,sep="",fill=TRUE))
? lst5<- lapply(lst4,function(x) x[x$V1>=1961 & x$V1<=2005,])
? lst6<- lapply(lst5,function(x) x[!is.na(x$V1),])
? lst7<- lapply(lst6,function(x) {
? ? if((min(x$V1)>1961)|(max(x$V1)<2005)){
? ? ? n1<- (min(x$V1)-1961)*12
? ? ? x1<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n1))
? ? ? n2<- (2005-max(x$V1))*12
? ? ? x2<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n2))
? ? ? x3<- rbind(x1,x,x2)
? ? }
? ? else {
? ? ? x
? ? } })
? lst8<-lapply(lst7,function(x) data.frame(col1=unlist(data.frame(t(x)[-c(1:2),]),use.names=FALSE))) ####changed
? lst9<- lapply(seq_along(lst8),function(i){
? ? x<- lst8[[i]]
? ? colnames(x)<- lstf1[i]
? ? row.names(x)<- 1:nrow(x)
? ? x
? })
? do.call(cbind,lst9)}
res<-fun2(lstf1)
dim(res)
res[res==-9999.99]<-NA
which(res==-9999.99)

dates1<-seq.Date(as.Date('1Jan1961',format="%d%b%Y"),as.Date('31Dec2005',format="%d%b%Y"),by="day")
dates2<- as.character(dates1)
sldat<- split(dates2,list(gsub("-.*","",dates2)))
lst11<-lapply(sldat,function(x) lapply(split(x,gsub(".*-(.*)-.*","\\1",x)), function(y){x1<-as.numeric(gsub(".*-.*-(.*)","\\1",y));if((31-max(x1))>0) {x2<-seq(max(x1)+1,31,1);x3<-paste0(unique(gsub("(.*-.*-).*","\\1",y)),x2);c(y,x3)} else y} ))
any(sapply(lst1,function(x) any(lapply(x,length)!=31)))
lst22<-lapply(lst11,function(x) unlist(x,use.names=FALSE))
sapply(lst22,length)
dates3<-unlist(lst22,use.names=FALSE)
length(dates3)
res1<- data.frame(dates=dates3,res,stringsAsFactors=FALSE)
str(res1)
res1$dates<-as.Date(res1$dates)
res2<-res1[!is.na(res1$dates),]
res2[1:3,1:3]
dim(res2)
z <- zoo(res2[,-1], order.by=res2[,1])
library(hydroTSM)
z.5max.annual <- daily2annual(z, dates=1, FUN=max) # dates=1 refers to year-month-day format
write.table(z.5max.annual, file = "Stations.csv", sep = ",")# write results file to current directory

At the second before the last line of the code, I transform from daily to annual values and keep only the maximum value in each year. i.e max value in 365 days.

MINOR PROBLEM: My output does contains some 'NA'. Does it mean that for that station, for that year, all data was NA or missing??

Thanks so much.
Atem.


________________________________
From: arun <smartpink111 at yahoo.com>
To: Zilefac Elvis <zilefacelvis at yahoo.com> 
Cc: R help <r-help at r-project.org> 
Sent: Wednesday, June 5, 2013 5:16 PM
Subject: Re: dates and time series management


Hi,
Try this:
lstf1<- list.files(pattern=".txt")
length(lstf1)
#[1] 119
#I changed the function a little bit to unlist by rows to match the dates column I created.

fun2<- function(lstf){
?lst1<-lapply(lstf,function(x) readLines(x))
?lst2<-lapply(lst1,function(x) {gsub("(\\d+)(-9999.99)","\\1 \\2",x)})
?lst3<-lapply(lst2,function(x) {x<-gsub("(\\d+)(-9999.99)","\\1 \\2",x)})
?lst4<- lapply(lst3,function(x) read.table(text=x,header=TRUE,stringsAsFactors=FALSE,sep="",fill=TRUE))
?lst5<- lapply(lst4,function(x) x[x$V1>=1961 & x$V1<=2005,])
?lst6<-
lapply(lst5,function(x) x[!is.na(x$V1),])
?lst7<- lapply(lst6,function(x) {
???????????????????? if((min(x$V1)>1961)|(max(x$V1)<2005)){
???????????????????????? n1<- (min(x$V1)-1961)*12
???????????????????????? x1<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n1))
???????????????????????? n2<- (2005-max(x$V1))*12
???????????????????????? x2<-
as.data.frame(matrix(NA,ncol=ncol(x),nrow=n2))
???????????????????????? x3<- rbind(x1,x,x2)
??????????????????????? }
????????????????????????? else {
??????????????????? x
??????????????????? } })
??? lst8<-lapply(lst7,function(x) data.frame(col1=unlist(data.frame(t(x)[-c(1:2),]),use.names=FALSE))) ####changed
???? lst9<-
lapply(seq_along(lst8),function(i){
??????????????????????? x<- lst8[[i]]
??????????????????????? colnames(x)<- lstf1[i]
??????????????????????? row.names(x)<- 1:nrow(x)
??????????????????????? x
??????????????????????? })
?do.call(cbind,lst9)}
res<-fun2(lstf1)
dim(res)
#[1] 16740??
119
?res[res==-9999.99]<-NA
which(res==-9999.99)
#integer(0)

dates1<-seq.Date(as.Date('1Jan1961',format="%d%b%Y"),as.Date('31Dec2005',format="%d%b%Y"),by="day")
dates2<- as.character(dates1)
sldat<- split(dates2,list(gsub("-.*","",dates2)))
?lst11<-lapply(sldat,function(x) lapply(split(x,gsub(".*-(.*)-.*","\\1",x)), function(y){x1<-as.numeric(gsub(".*-.*-(.*)","\\1",y));if((31-max(x1))>0) {x2<-seq(max(x1)+1,31,1);x3<-paste0(unique(gsub("(.*-.*-).*","\\1",y)),x2);c(y,x3)} else y} ))
any(sapply(lst1,function(x) any(lapply(x,length)!=31)))
#[1] FALSE
lst22<-lapply(lst11,function(x) unlist(x,use.names=FALSE))
sapply(lst22,length)
#1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 
# 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372 
#1977
1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 
# 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372 
#1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 
# 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372? 372 

?dates3<-unlist(lst22,use.names=FALSE)
?length(dates3)
#[1] 16740
res1<- data.frame(dates=dates3,res,stringsAsFactors=FALSE)
str(res1)
'data.frame':??? 16740 obs. of? 120 variables:
?$ dates??????? : chr? "1961-01-01" "1961-01-02" "1961-01-03" "1961-01-04" ...
?$ dt3011120.txt: num? 1.67 0 0 0 0 0 4.17 0 0 0 ...
?$ dt3011240.txt: num? NA NA NA NA NA NA NA NA NA NA ...
?$ dt3011887.txt:
num? 0.17 0.28 0 0.3 0 0 1.78 0 0.3 0 ...
?$ dt3012205.txt: num? 0.34 0.21 0 0.51 0 0 2.82 0 0.3 0 ...
-----------------------------------------------------------
res1$dates<-as.Date(res1$dates)
?res2<-res1[!is.na(res1$dates),]
res2[1:3,1:3]
#?????? dates dt3011120.txt dt3011240.txt
#1 1961-01-01????????? 1.67??????????? NA
#2 1961-01-02????????? 0.00??????????? NA
#3 1961-01-03????????? 0.00??????????? NA
?dim(res2)
#[1] 16436?? 120

Now, you can try the reshape() and the zoo().
Hope it
helps.
A.K.








________________________________
From: Zilefac Elvis <zilefacelvis at yahoo.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Wednesday, June 5, 2013 5:17 PM
Subject: Re: dates and time series management



Hi A.K,
I am gradually improving my R skills thanks to your support.
I have this code for the attached data.
********************************************************************************************************
library(hydroTSM)

# Reading the data with 21 daily simulations, from 1961-01-01 up to 2005-12-31
x <- read.csv("data2.csv")

# Creating a single variable with all the dates
dates <- as.Date(paste0(x$year, "-", x$month, "-", x$day), format="%Y-%m-%d")

#
Creating a data.frame with 3 columns: simulation number, Date, Rainfall values
x.new <- data.frame(s.num=x[,1], Date=dates, Rainfall=x[,5])

# Creating a data.frame with 22 columns: Dates + Rainfall values for21 simulations
x.wide <- reshape(x.new, idvar = "Date", timevar = "s.num", direction = "wide")
# Creating a zoo variable
z <- zoo(x.wide[,-1], order.by=x.wide[,1])
# 5-day total rainfall for each one of the simulations

z.5tot <- rollapply(data=z, width=5, FUN=sum, fill=NA, partial= TRUE,
? ? ? ? ? ? ? ? ? ? align="center")# to get the total of 5-day precipitation
# Maximum value per year of 5-day total rainfall for each one of the simulations
z.5max.annual <- daily2annual(z.5max, dates=1, FUN=max)
*********************************************************************************************************

Problem: I am trying to do a similar
thing with 'res' from our previous problem (see below). However, instead of width=5, I need something like?
Max.Daily<-rollapply(data=z, width=372, FUN=max, by.column = TRUE, partial= TRUE, align="center")
# width=1961 to 2005=45years, 16740/45=372

To do this, I need a date column vector just as I did above. Can you show me how to generate daily dates with??format="%Y-%m-%d"??
Days range from 1 to 31 for all months since we filled for example February having 28/29 days with NA.?
Months from 1 to 12 and years from 1961 to 2005.

If column 1 of 'res' contains dates, then we can use parts of the code above to extract the Maximum value for each year and for each column.
So, my final output will be 45 * 119.?

Thanks so much A.K. I keep learning hard though slowly. ?

________________________________
From: arun <smartpink111 at yahoo.com>
To: Zilefac Elvis <zilefacelvis at yahoo.com> 
Cc: R help <r-help at r-project.org> 
Sent: Wednesday, June 5, 2013 9:44 AM
Subject: Re: dates and time series management


Hi Atem,
No problem.


?which(res==-9999.99)
# [1]?? 18246? 397379? 420059? 426569? 427109? 603659? 604199? 662518? 664678
#[10]? 698982? 699522? 700062? 701142? 754745 1289823 1500490 1589487 1716011
#[19] 1837083
?which(res==-9999.99,arr.ind=TRUE)
#??????? row col
#1506?? 1506?? 2
#12359 12359? 24
#1559?? 1559? 26
#8069??
8069? 26

#----------------------
res[ which(res==-9999.99,arr.ind=TRUE)]<-NA
#or

res[res==-9999.99]<-NA
?which(res==-9999.99)
#integer(0)
A.K.




________________________________
From: Zilefac Elvis <zilefacelvis at yahoo.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Wednesday, June 5, 2013 10:56 AM
Subject: Re: dates and time series management



Hi A.K,

It works as expected. You are too smart.
Can you find all -9999.99 and replace with NA, if only it exists?

lst2<-lapply(lst1,function(x) {gsub("(\\d+)(-9999.99)","\\1 \\2",x)})
?lst3<-lapply(lst2,function(x) {x<-gsub("(\\d+)(-9999.99)","\\1 \\2",x)})?


Thanks so much
A.K.



________________________________
From: arun <smartpink111 at yahoo.com>
To: Zilefac Elvis <zilefacelvis at yahoo.com> 
Cc: R help <r-help at r-project.org> 
Sent: Wednesday, June 5, 2013 7:44 AM
Subject: Re: dates and time series management


Hi,
Try this:
lstf1<- list.files(pattern=".txt")
length(lstf1)
#[1] 119
fun2<- function(lstf){
?lst1<-lapply(lstf,function(x) readLines(x))
?lst2<-lapply(lst1,function(x) {gsub("(\\d+)(-9999.99)","\\1 \\2",x)})
?lst3<-lapply(lst2,function(x) {x<-gsub("(\\d+)(-9999.99)","\\1
\\2",x)})
?lst4<- lapply(lst3,function(x)
read.table(text=x,header=TRUE,stringsAsFactors=FALSE,sep="",fill=TRUE))
?lst5<- lapply(lst4,function(x) x[x$V1>=1961 & x$V1<=2005,])
?lst6<- lapply(lst5,function(x) x[!is.na(x$V1),])
?lst7<- lapply(lst6,function(x) {

if((min(x$V1)>1961)|(max(x$V1)<2005)){
???????????????????????? n1<- (min(x$V1)-1961)*12
???????????????????????? x1<-
as.data.frame(matrix(NA,ncol=ncol(x),nrow=n1))
???????????????????????? n2<-
(2005-max(x$V1))*12
???????????????????????? x2<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n2))
???????????????????????? x3<-
rbind(x1,x,x2)
??????????????????????? }
????????????????????????? else
{
??????????????????? x
??????????????????? } })

lst8<-
lapply(lst7,function(x) data.frame(col1=unlist(x[,-c(1:2)])))
???? lst9<- lapply(seq_along(lst8),function(i){
??????????????????????? x<-
lst8[[i]]
??????????????????????? colnames(x)<- lstf1[i]
??????????????????????? row.names(x)<-
1:nrow(x)
??????????????????????? x

})
?do.call(cbind,lst9)}
res<-fun2(lstf1)
dim(res)
#[1] 16740?? 119
res[1:5,1:3]
?# dt3011120.txt dt3011240.txt dt3011887.txt
#1????????? 1.67???????????
NA????????? 0.17
#2????????? 0.00??????????? NA????????? 0.28
#3?????????
0.00??????????? NA????????? 0.00
#4????????? 0.00??????????? NA?????????
0.30
#5????????? 0.00??????????? NA????????? 0.00


########################################

There are some formatting issues in your files:
For eg. If I run the
function line by line:

?lst1<-lapply(lstf1,function(x) readLines(x))
sapply(lst1,function(x) any(grepl("\\d+-9999.99",x)))
? [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
FALSE
?[25] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[37]? TRUE FALSE? TRUE FALSE FALSE? TRUE FALSE FALSE FALSE FALSE FALSE FALSE
?[49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[61] FALSE FALSE FALSE FALSE FALSE
FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[73] FALSE FALSE FALSE FALSE FALSE? TRUE FALSE FALSE FALSE FALSE? TRUE FALSE
?[85] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE? TRUE
?[97] FALSE FALSE FALSE FALSE FALSE FALSE? TRUE? TRUE FALSE FALSE FALSE FALSE
[109]
FALSE FALSE FALSE FALSE? TRUE FALSE FALSE FALSE FALSE FALSE? TRUE


###means some rows in the a few files have:
#-9999.99 0 0 0 0.00-9999.99 0 0.00-9999.99 0 0 0 0.00-9999.99 (no space before -9999.99)


?lst2<-lapply(lst1,function(x) {gsub("(\\d+)(-9999.99)","\\1
\\2",x)})
sapply(lst2,function(x) any(grepl("\\d+-9999.99",x))) #still a few files had the problem
? [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[25] FALSE FALSE FALSE FALSE FALSE FALSE
FALSE FALSE FALSE FALSE FALSE FALSE
?[37] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
?[73] FALSE FALSE FALSE FALSE
FALSE FALSE FALSE FALSE FALSE FALSE? TRUE FALSE
?[85] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE? TRUE
?[97] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
[109] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
FALSE
lst3<-lapply(lst2,function(x) {x<-gsub("(\\d+)(-9999.99)","\\1 \\2",x)})
any(sapply(lst3,function(x) any(grepl("\\d+-9999.99",x))))
#[1] FALSE
lst4<- lapply(lst3,function(x) read.table(text=x,header=TRUE,stringsAsFactors=FALSE,sep="",fill=TRUE))


any(sapply(lst4,function(x)
any(sapply(x,is.character))))
#[1] FALSE

?lst5<- lapply(lst4,function(x) x[x$V1>=1961 & x$V1<=2005,])
lst6<- lapply(lst5,function(x) x[!is.na(x$V1),])
sapply(lst6,nrow)
?# [1] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [19] 540 540 540 540 540 540 540 540 540 540 540 540
540 540 540 540 540 540
# [37] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [55] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [73] 540 540 540 540 528 492 528 540 348 540 540 480 540 540 540 540 540 540
# [91] 540 540 540 540 540 540
540 540 540 540 540 540 540 540 528 540 540 540
#[109] 540 540 540 540 540 540 540 540 540 468 540

???? lst7<- lapply(lst6,function(x) {

if((min(x$V1)>1961)|(max(x$V1)<2005)){
???????????????????????? n1<-
(min(x$V1)-1961)*12
???????????????????????? x1<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n1))
???????????????????????? n2<-
(2005-max(x$V1))*12
???????????????????????? x2<- as.data.frame(matrix(NA,ncol=ncol(x),nrow=n2))
???????????????????????? x3<-
rbind(x1,x,x2)

}
????????????????????????? else {
??????????????????? x
??????????????????? }
})

?sapply(lst7,nrow)
#? [1] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [19] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [37] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [55] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [73] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
# [91] 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540 540
540
#[109] 540 540 540 540 540
540 540 540 540 540 540


Hope this helps.
A.K.

________________________________
From: Zilefac Elvis <zilefacelvis at yahoo.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Wednesday, June 5, 2013 2:05
AM
Subject: Re: dates and time series management



Hi A.K,
Sorry my internet connection was so bad last evening.

I have attached all the files as .zip.
Below is the output you requested.
As I explained, the start date in 'res' should be 1961 and end date should be 2005 in all 119 files.

Thanks A.K

> lapply(lst1,head,3)
[[1]]
? V1.V2.V3.V4.V5.V6.V7.V8.V9.V10.V11.V12.V13.V14.V15.V16.V17.V18.V19.V20.V21.V22.V23.V24.V25.V26.V27.V28.V29.V30.V31.V32.V33
1 ?

? ? ? ? ? ?1915 1 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
2 ? ? ? ? ? ? ? ? ? ? ? ?1915 2 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
3 ? ? ? ? ? ? ? ? ? ?
? ?1915 3 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA

[?????????????????????????????????????????????????????????????????????????????????????? ? ? ? ? ?


From gunter.berton at gene.com  Thu Jun  6 07:28:12 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 5 Jun 2013 22:28:12 -0700
Subject: [R] Trying to build up functions with its names by means of
	lapply
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C2FD621@PA-MBX01.na.tibco.com>
References: <loom.20130605T043218-210@post.gmane.org>
	<250F03A2-77CE-4FAC-B1C9-6754567A3F6A@gmail.com>
	<51AF09A5.4080700@sapo.pt> <51AF0BE3.3050500@sapo.pt>
	<CACk-te21kO0xP+4RpvJrLVxoUZjbAVh_h6RbL0JxSwoBH2YwPg@mail.gmail.com>
	<loom.20130605T215734-601@post.gmane.org>
	<E66794E69CFDE04D9A70842786030B931C2FD621@PA-MBX01.na.tibco.com>
Message-ID: <CACk-te1burUA2mSPDVjN_ZdB6iEkUhtUt3-jLBP0+rtWzYocCw@mail.gmail.com>

Thanks, Bill. Clearly something I missed. I appreciate your filling in
that crack.

Another equivalent way to do it?

f2 <- function(c,nm = "gamma",...)
{
  probFunc <- paste0(c,nm)
  more <- list(...)
  function(x)do.call(probFunc,c(x,more))
}

This avoids the explicit use of get() and force(), I believe, but are
there problems here I'm missing?


-- Cheers,
Bert

On Wed, Jun 5, 2013 at 1:46 PM, William Dunlap <wdunlap at tibco.com> wrote:
> You will want to force the evaluation of the ... arguments, just as you are already
> forcing the evaluation of 'c', before returning your function.  E.g., compare the
> following two:
>
> # your 'faux', renamed and enhanced a bit
> f0 <- function (c, nm = "gamma", ...)
> {
>     probFunc <- getFunction(paste0(c, nm))
>     function(x) probFunc(x, ...)
> }
> # the above but adding a call to force the evaluation of the ... argument before returning the function
> f1 <- function (c, nm = "gamma", ...)
> {
>     probFunc <- getFunction(paste0(c, nm))
>     force(list(...))
>     function(x) probFunc(x, ...)
> }
> # Now use mapply to make a list of functions with various parameters
> z0 <-  mapply(c=c("p","d"), nm="norm", mean=c(1,-1), FUN=f0)
> z1 <-  mapply(c=c("p","d"), nm="norm", mean=c(1,-1), FUN=f1)
> z0[[1]](0.1) # expect same result as pnorm(0.1, mean=1)
> # [1] 0.8643339 # bad
> z1[[1]](0.1) # expect same result as pnorm(0.1, mean=1)
> # [1] 0.1840601 # good
> # for reference:
> pnorm(0.1, mean=1)
> # [1] 0.1840601
> pnorm(0.1, mean=-1)
> # [1] 0.8643339
>
> You don't have to say 'force(list(...))' to force their evaluation.  You could use
> 'junk <- list(...)' or 'junk <- c(...)', but using the force function should indicate
> that you are only doing this to force the evaluation of the argument at this point,
> not because you intend to use the result of list(...) or c(...).
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
>> Of Julio Sergio
>> Sent: Wednesday, June 05, 2013 1:26 PM
>> To: r-help at stat.math.ethz.ch
>> Subject: Re: [R] Trying to build up functions with its names by means of lapply
>>
>> Bert Gunter <gunter.berton <at> gene.com> writes:
>>
>> >
>> > faux <- function(c, nm = "gamma",...){
>> >      f <- get(paste0(c,nm))
>> >       function(x)f(x,...)
>> >     }
>> >
>> > This could be called with:
>> >
>> > > xgam <- lapply(c("p","d"), faux, shape=k, scale=theta)
>> > > xgam[[1]](1000)
>> > [1] 0.8710477
>> > > xgam[[2]](1000)
>> > [1] 0.001265311
>> >
>>
>> Excellent, Bert, and thanks a lot for your contribution! In fact, I was
>> planning to write a separate functions producer for each distribution. This
>> really saves me a lot of work!
>>
>>
>>   -Sergio
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From elham_h763 at yahoo.com  Thu Jun  6 07:36:27 2013
From: elham_h763 at yahoo.com (Patty Haaem)
Date: Wed, 5 Jun 2013 22:36:27 -0700 (PDT)
Subject: [R] multivariate multilevel model
Message-ID: <1370496987.56754.YahooMailClassic@web141105.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130605/fa7e82e0/attachment.pl>

From yelin at lbl.gov  Thu Jun  6 07:43:39 2013
From: yelin at lbl.gov (Ye Lin)
Date: Wed, 5 Jun 2013 22:43:39 -0700
Subject: [R] highlighted a certain time period on multiple plots
Message-ID: <CAAvu=b=weMhB0DnRQBDSmtrq-ryENgsUq0XdDWz5+TKAmNAstA@mail.gmail.com>

Hey All,

I have a dataset like this:

DatedayVar1Var2Var3Obs1/1/2013Tue23411/2/2013Wed23521/3/2013Thu24631/4/2013
Fri24741/5/2013Sat24.5851/6/2013Sun24.9961/7/2013Mon25.31071/8/2013Tue25.711
81/9/2013Wed26.11291/10/2013Thu26.513101/11/2013Fri26.914111/12/2013Sat27.3
15121/13/2013Sun27.716131/14/2013Mon28.117141/15/2013Tue28.518151/16/2013Wed
28.919161/17/2013Thu29.320171/18/2013Fri29.721181/19/2013Sat210.12219
1/20/2013Sun210.523201/21/2013Mon210.924211/22/2013Tue211.325221/23/2013Wed2
11.726231/24/2013Thu212.127241/25/2013Fri212.528251/26/2013Sat212.92926
1/27/2013Sun213.330271/28/2013Mon213.731281/29/2013Tue214.132291/30/2013Wed2
14.533301/31/2013Thu214.93431
Here is the code I use to plot:

par(mar=c(10, 0.5, 0.5, 0.5))
par(mfrow=c(3,1))
plot(Var1~Obs,data=dat,xaxt="n",xlab="")
plot(Var2~Obs,data=dat,xaxt="n",xlab="")
plot(Var3~Obs,data=dat,xaxt="n",xlab="")
axis(1,at=dat$Obs,label=dat$Date)
mtext(1,text="Date",line=2.5)
axis(1,at=dat$Obs,label=dat$day,line=4)
mtext(1,text="Day of week",line=7)

How can I remove the extra white space between plots and emphasize time
periods=weekend with dashed area?? I have attached original output and
ideal output I am looking for.

Any suggestion to emphasize/highlight weekend periods is really appreciate!

Thanks!
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 16505 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130605/accd27cd/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image (1).png
Type: image/png
Size: 67240 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130605/accd27cd/attachment-0001.png>

From ripley at stats.ox.ac.uk  Thu Jun  6 08:19:50 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 06 Jun 2013 07:19:50 +0100
Subject: [R] rJava is not loading
In-Reply-To: <CAN2xGJbUNA25+e9fR6NWo+HaYES1w3j_KMRpPY73cRDvA37uog@mail.gmail.com>
References: <CAN2xGJbUNA25+e9fR6NWo+HaYES1w3j_KMRpPY73cRDvA37uog@mail.gmail.com>
Message-ID: <51B02A06.50903@stats.ox.ac.uk>

On 06/06/2013 00:38, Dimitri Liakhovitski wrote:
> Hello!
> I installed rJava and am trying to load it.
>
> library(rJava)
>
> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>    call: fun(libname, pkgname)
>    error: No CurrentVersion entry in Software/JavaSoft registry! Try
> re-installing Java and make sure R and Java have matching architectures.
> Error: package or namespace load failed for ?rJava?
>
> Any idea why?
> Background info:

But the posting guide asked for the output from sessionInfo(): we want 
to know what R knows it is running as, not why you think.

> Windows 7, 64-bit
> R version 3.0.1 (for 64-bit)
> I just installed the lastest Java: Java 7 Update 21

For the right architecture?

The message is crystal clear: you do not have a Java installed matching 
your R.  Most likely your Java is 32-bit and your R 64-bit or v.v.



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Jose.Iparraguirre at ageuk.org.uk  Thu Jun  6 10:54:19 2013
From: Jose.Iparraguirre at ageuk.org.uk (Jose Iparraguirre)
Date: Thu, 6 Jun 2013 09:54:19 +0100
Subject: [R] multivariate multilevel model
In-Reply-To: <1370496987.56754.YahooMailClassic@web141105.mail.bf1.yahoo.com>
References: <1370496987.56754.YahooMailClassic@web141105.mail.bf1.yahoo.com>
Message-ID: <E0807BF04F0D0C419BF2B39803E98582010E3BB3BCD5@AGEPXCH002C.uk.age.local>

Dear Patty,

I would leave others to point you to the right packages, but I'd suggest you read this excellent R-based book: "Data Analysis Using Regression and Multilevel/Hierarchical Models", by Andrew Gelman and Jennifer Hill (Cambridge University Press, 2006).
Kind regards,

Jos?


Prof. Jos? Iparraguirre
Chief Economist
Age UK

Age UK
Tavis House, 1- 6 Tavistock Square
London, WC1H 9NB

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Patty Haaem
Sent: 06 June 2013 06:36
To: r-help at r-project.org
Subject: [R] multivariate multilevel model

Hi
I want to fit a multivariate multilevel model for a longitudinal data set. can you introduce me a package or some function to fit this model?
Thanks in advance.
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

Age UK Improving later life

www.ageuk.org.uk


 
-------------------------------
Age UK is a registered charity and company limited by guarantee, (registered charity number 1128267, registered company number 6825798). 
Registered office: Tavis House, 1-6 Tavistock Square, London WC1H 9NA.

For the purposes of promoting Age UK Insurance, Age UK is an Appointed Representative of Age UK Enterprises Limited, Age UK is an Introducer 
Appointed Representative of JLT Benefit Solutions Limited and Simplyhealth Access for the purposes of introducing potential annuity and health 
cash plans customers respectively.  Age UK Enterprises Limited, JLT Benefit Solutions Limited and Simplyhealth Access are all authorised and 
regulated by the Financial Services Authority. 
------------------------------

This email and any files transmitted with it are confidential and intended solely for the use of the individual or entity to whom they are 
addressed. If you receive a message in error, please advise the sender and delete immediately.

Except where this email is sent in the usual course of our business, any opinions expressed in this email are those of the author and do not 
necessarily reflect the opinions of Age UK or its subsidiaries and associated companies. Age UK monitors all e-mail transmissions passing 
through its network and may block or modify mails which are deemed to be unsuitable.

Age Concern England (charity number 261794) and Help the Aged (charity number 272786) and their trading and other associated companies merged 
on 1st April 2009.  Together they have formed the Age UK Group, dedicated to improving the lives of people in later life.  The three national 
Age Concerns in Scotland, Northern Ireland and Wales have also merged with Help the Aged in these nations to form three registered charities: 
Age Scotland, Age NI, Age Cymru.





From ligges at statistik.tu-dortmund.de  Thu Jun  6 11:01:29 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 06 Jun 2013 11:01:29 +0200
Subject: [R] Send Mail R and Socket Connections
In-Reply-To: <1370426163450-4668699.post@n4.nabble.com>
References: <1370426163450-4668699.post@n4.nabble.com>
Message-ID: <51B04FE9.1070604@statistik.tu-dortmund.de>



On 05.06.2013 11:56, TwistedSkies wrote:
> Good Afternoon All,
>
> I am attempting to use the SendMailR function, I have checked with our I.T.
> department that I am using the correct server and I have the right
> permissions to connect and they have sent emails via this server but not
> through R and I have also checked that the port should be 25.
>
> The code:
>
> /
>
> # E-Mail #
>
> library(sendmailR)
>
> from <- "david at work.com"
> to <- "adam at work.com"
> subject <- "Send Mail R- Test"
> body <- "TESTING TESTING TESTING"
> mailControl=list(smtpServer="uksmtp.global.local")
>
> sendmail(from=from,to=to,subject=subject,msg=body,control=mailControl)
> /
>
>
>
> I receive the below error:
>
> /
> function (host = "localhost", port, server = FALSE, blocking = FALSE,
> open = "a+", encoding = getOption("encoding"), timeout =
> getOption("timeout"))
> .Internal(socketConnection(host, port, server, blocking, open,
> encoding, timeout))
> <bytecode: 0x00000000071beb18>
> <environment: namespace:base>
> /
>


This is not an error but the definition of the socketConnection() function.

If this is really the result, please contact the package maintainer 
(CCIng) for details, assuming you have the most recent versions of R and 
that package.

Best,
Uwe Ligges



>
> So I figured its an error with or I needed to define a new socket
> connection, is this where the problem lies? Could anyone give me any
> pointers on where to go next with this to get it working?
>
> Many Thanks in Advance!
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Send-Mail-R-and-Socket-Connections-tp4668699.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From scott.raynaud at yahoo.com  Thu Jun  6 13:24:37 2013
From: scott.raynaud at yahoo.com (Scott Raynaud)
Date: Thu, 6 Jun 2013 04:24:37 -0700 (PDT)
Subject: [R] SPlus script
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C2FD5C4@PA-MBX01.na.tibco.com>
References: <1370438435.93923.YahooMailNeo@web142703.mail.bf1.yahoo.com>
	<E66794E69CFDE04D9A70842786030B931C2FD5C4@PA-MBX01.na.tibco.com>
Message-ID: <1370517877.96887.YahooMailNeo@web142701.mail.bf1.yahoo.com>

Ok. I tried copying the original program, changing all _ to <- and running in 3.0.1.? Still no error 
message or output.? It's a mystery to me.

----- Original Message -----
From: William Dunlap <wdunlap at tibco.com>
To: Scott Raynaud <scott.raynaud at yahoo.com>; "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Wednesday, June 5, 2013 2:17 PM
Subject: RE: [R] SPlus script

Both the R and S+ versions (which seem to differ only in the use of _ for assignment
in the S+ version) do nothing but define some functions.? You would not expect any
printed output unless you used those functions on some data.? Is there another script
that does that?

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Scott Raynaud
> Sent: Wednesday, June 05, 2013 6:21 AM
> To: r-help at r-project.org
> Subject: [R] SPlus script
> 
> This?originally was?an SPlus script that I modifeid about a year-and-a-half ago.? It worked
> perfectly then.? Now I can't get any output despite not receiving an error message.? I'm
> providing the SPLUS script as a reference.? I'm running R15.2.2.? Any help appreciated.
> 
> ************************************MY
> MODIFICATION***********************************************************
> **********
> ## sshc.ssc: sample size calculation for historical control studies
> ## J. Jack Lee (jjlee at mdanderson.org) and Chi-hong Tseng
> ## Department of Biostatistics, Univ. of Texas M.D. Anderson Cancer Center
> ##
> ## 3/1/99
> ## updated 6/7/00: add loess
> ##------------------------------------------------------------------
> ######## Required Input:
> #
> # rc???? number of response in historical control group
> # nc???? sample size in historical control
> # d????? target improvement = Pe - Pc
> # method 1=method based on the randomized design
> #??????? 2=Makuch & Simon method (Makuch RW, Simon RM. Sample size considerations
> #????????? for non-randomized comparative studies. J of Chron Dis 1980; 3:175-181.
> #??????? 3=uniform power method
> ######## optional Input:
> #
> # alpha? size of the test
> # power? desired power of the test
> # tol??? convergence criterion for methods 1 & 2 in terms of sample size
> # tol1?? convergence criterion for method 3 at any given obs Rc in terms of difference
> #????????? of expected power from target
> # tol2?? overall convergence criterion for method 3 as the max absolute deviation
> #????????? of expected power from target for all Rc
> # cc???? range of multiplicative constant applied to the initial values ne
> # l.span smoothing constant for loess
> #
> # Note:? rc is required for methods 1 and 2 but not 3
> #??????? method 3 return the sample size need for rc=0 to (1-d)*nc
> #
> ######## Output
> # for methdos 1 & 2: return the sample size needed for the experimental group (1
> number)
> #??????????????????? for given rc, nc, d, alpha, and power
> # for method 3:????? return the profile of sample size needed for given nc, d, alpha, and
> power
> #??????????????????? vector $ne contains the sample size corresponding to rc=0, 1, 2, ... nc*(1-d)
> #??????????????????? vector $Ep contains the expected power corresponding to
> #????????????????????? the true pc = (0, 1, 2, ..., nc*(1-d)) / nc
> #
> #------------------------------------------------------------------
> sshc<-function(rc, nc=1092, d=.085779816, method=3, alpha=0.05, power=0.8,
> ????????????? tol=0.01, tol1=.0001, tol2=.005, cc=c(.1,2), l.span=.5)
> {
> ### for method 1
> if (method==1) {
> ?ne1<-ss.rand(rc,nc,d,alpha=.05,power=.8,tol=.01)
> ?return(ne=ne1)
> ?????????????? }
> ### for method 2
> if (method==2) {
> ne<-nc
> ne1<-nc+50
> while(abs(ne-ne1)>tol & ne1<100000){
> ne<-ne1
> pe<-d+rc/nc
> ne1<-nef(rc,nc,pe*ne,ne,alpha,power)
> ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
> }
> if (ne1>100000) return(NA)
> else return(ne=ne1)
> }
> ### for method 3
> if (method==3) {
> if (tol1 > tol2/10) tol1<-tol2/10
> ncstar<-(1-d)*nc
> pc<-(0:ncstar)/nc
> ne<-rep(NA,ncstar + 1)
> for (i in (0:ncstar))
> { ne[i+1]<-ss.rand(i,nc,d,alpha=.05,power=.8,tol=.01)
> }
> plot(pc,ne,type='l',ylim=c(0,max(ne)*1.5))
> ans<-c.searchd(nc, d, ne, alpha, power, cc, tol1)
> ### check overall absolute deviance
> old.abs.dev<-sum(abs(ans$Ep-power))
> ##bad<-0
> print(round(ans$Ep,4))
> print(round(ans$ne,2))
> lines(pc,ans$ne,lty=1,col=8)
> old.ne<-ans$ne
> ##while(max(abs(ans$Ep-power))>tol2 & bad==0){? #### unnecessary ##
> while(max(abs(ans$Ep-power))>tol2){
> ans<-c.searchd(nc, d, ans$ne, alpha, power, cc, tol1)
> abs.dev<-sum(abs(ans$Ep-power))
> print(paste(" old.abs.dev=",old.abs.dev))
> print(paste("???? abs.dev=",abs.dev))
> ##if (abs.dev > old.abs.dev) { bad<-1}
> old.abs.dev<-abs.dev
> print(round(ans$Ep,4))
> print(round(ans$ne,2))
> lines(pc,old.ne,lty=1,col=1)
> lines(pc,ans$ne,lty=1,col=8)
> ### add convex
> ans$ne<-convex(pc,ans$ne)$wy
> ### add loess
> ###old.ne<-ans$ne
> loess.ne<-loess(ans$ne ~ pc, span=l.span)
> lines(pc,loess.ne$fit,lty=1,col=4)
> old.ne<-loess.ne$fit
> ###readline()
> }
> return(list(ne=ans$ne, Ep=ans$Ep))
> ?????????????? }
> }
> ## needed for method 1
> nef2<-function(rc,nc,re,ne,alpha,power){
> za<-qnorm(1-alpha)
> zb<-qnorm(power)
> xe<-asin(sqrt((re+0.375)/(ne+0.75)))
> xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
> ans<- 1/(4*(xc-xe)^2/(za+zb)^2-1/(nc+0.5)) - 0.5
> return(ans)
> }
> ## needed for method 2
> nef<-function(rc,nc,re,ne,alpha,power){
> za<-qnorm(1-alpha)
> zb<-qnorm(power)
> xe<-asin(sqrt((re+0.375)/(ne+0.75)))
> xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
> ans<-(za*sqrt(1+(ne+0.5)/(nc+0.5))+zb)^2/(2*(xe-xc))^2-0.5
> return(ans)
> }
> ## needed for method 3
> c.searchd<-function(nc, d, ne, alpha=0.05, power=0.8, cc=c(0.1,2),tol1=0.0001){
> #---------------------------
> # nc???? sample size of control group
> # d????? the differece to detect between control and experiment
> # ne???? vector of starting sample size of experiment group
> #????? corresonding to rc of 0 to nc*(1-d)
> # alpha? size of test
> # power? target power
> # cc?? pre-screen vector of constant c, the range should cover the
> #????? the value of cc that has expected power
> # tol1?? the allowance between the expceted power and target power
> #---------------------------
> pc<-(0:((1-d)*nc))/nc
> ncl<-length(pc)
> ne.old<-ne
> ne.old1<-ne.old
> ### sweeping forward
> for(i in 1:ncl){
> ?cmin<-cc[1]
> ?cmax<-cc[2]
> ### fixed cci<-cmax bug
> ?cci <-1
> ?lhood<-dbinom((i:ncl)-1,nc,pc[i])
> ?ne[i:ncl]<-(1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
> ?Ep0 <-Epower(nc, d, ne, pc, alpha)
> ?while(abs(Ep0[i]-power)>tol1){
> ??if(Ep0[i]<power) cmin<-cci
> ??else cmax<-cci
> ??cci<-(cmax+cmin)/2
> ??ne[i:ncl]<-(1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
> ??Ep0<-Epower(nc, d, ne, pc, alpha)
> ?}
> ??ne.old1<-ne
> }
> ne1<-ne
> ### sweeping backward -- ncl:i
> ne.old2<-ne.old
> ne???? <-ne.old
> for(i in ncl:1){
> ?cmin<-cc[1]
> ?cmax<-cc[2]
> ### fixed cci<-cmax bug
> ?cci <-1
> ?lhood<-dbinom((ncl:i)-1,nc,pc[i])
> ?lenl <-length(lhood)
> ?ne[ncl:i]<-(1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
> ?Ep0 <-Epower(nc, d, cci*ne, pc, alpha)
> ?while(abs(Ep0[i]-power)>tol1){
> ??if(Ep0[i]<power) cmin<-cci
> ??else cmax<-cci
> ??cci<-(cmax+cmin)/2
> ??ne[ncl:i]<-(1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
> ??Ep0<-Epower(nc, d, ne, pc, alpha)
> ?}
> ??ne.old2<-ne
> }
> ne2<-ne
> ne<-(ne1+ne2)/2
> #cat(ccc*ne)
> Ep1<-Epower(nc, d, ne, pc, alpha)
> return(list(ne=ne, Ep=Ep1))
> }
> ###
> vertex<-function(x,y)
> { ?n<-length(x)
> ?vx<-x[1]
> ?vy<-y[1]
> ?vp<-1
> ?up<-T
> ?for (i in (2:n))
> ?{ if (up)
> ??{ ?if (y[i-1] > y[i])
> ???{vx<-c(vx,x[i-1])
> ??? vy<-c(vy,y[i-1])
> ??? vp<-c(vp,i-1)
> ??? up<-F
> ???}
> ??}
> ??else
> ??{ ?if (y[i-1] < y[i]) up<-T
> ??}
> ?}
> ?vx<-c(vx,x[n])
> ?vy<-c(vy,y[n])
> ?vp<-c(vp,n)
> ?return(list(vx=vx,vy=vy,vp=vp))
> }
> ###
> convex<-function(x,y)
> {
> ?n<-length(x)
> ?ans<-vertex(x,y)
> ?len<-length(ans$vx)
> ?while (len>3)
> ?{
> #??cat("x=",x,"\n")
> #??cat("y=",y,"\n")
> ??newx<-x[1:(ans$vp[2]-1)]
> ??newy<-y[1:(ans$vp[2]-1)]
> ??for (i in (2:(len-1)))
> ??{
> ?? ?newx<-c(newx,x[ans$vp[i]])
> ???newy<-c(newy,y[ans$vp[i]])
> ??}
> ??newx<-c(newx,x[(ans$vp[len-1]+1):n])
> ??newy<-c(newy,y[(ans$vp[len-1]+1):n])
> ??y<-approx(newx,newy,xout=x)$y
> #??cat("new y=",y,"\n")
> ??ans<-vertex(x,y)
> ??len<-length(ans$vx)
> #??cat("vx=",ans$vx,"\n")
> #??cat("vy=",ans$vy,"\n")
> }
> ?return(list(wx=x,wy=y))}
> ###
> Epower<-function(nc, d, ne, pc = (0:((1 - d) * nc))/nc, alpha = 0.05)
> {
> #-------------------------------------
> # nc???? sample size in historical control
> # d????? the increase of response rate between historical and experiment
> # ne???? sample size of corresonding rc of 0 to nc*(1-d)
> # pc???? the response rate of control group, where we compute the
> #??????? expected power
> # alpha? the size of test
> #-------------------------------------
> ?kk <- length(pc)
> ?rc <- 0:(nc * (1 - d))
> ?pp <- rep(NA, kk)
> ?ppp <- rep(NA, kk)
> ?for(i in 1:(kk)) {
> ??pe <- pc[i] + d
> ??lhood <- dbinom(rc, nc, pc[i])
> ??pp <- power1.f(rc, nc, ne, pe, alpha)
> ??ppp[i] <- sum(pp * lhood)/sum(lhood)
> ?}
> ?return(ppp)
> }
> # adapted from the old biss2
> ss.rand<-function(rc,nc,d,alpha=.05,power=.8,tol=.01)
> {
> ne<-nc
> ne1<-nc+50
> while(abs(ne-ne1)>tol & ne1<100000){
> ne<-ne1
> pe<-d+rc/nc
> ne1<-nef2(rc,nc,pe*ne,ne,alpha,power)
> ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
> }
> if (ne1>100000) return(NA)
> else return(ne1)
> }
> ###
> power1.f<-function(rc,nc,ne,pie,alpha=0.05){
> #-------------------------------------
> # rc?number of response in historical control
> # nc?sample size in historical control
> # ne??? sample size in experitment group
> # pie?true response rate for experiment group
> # alpha?size of the test
> #-------------------------------------
> za<-qnorm(1-alpha)
> re<-ne*pie
> xe<-asin(sqrt((re+0.375)/(ne+0.75)))
> xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
> ans<-za*sqrt(1+(ne+0.5)/(nc+0.5))-(xe-xc)/sqrt(1/(4*(ne+0.5)))
> return(1-pnorm(ans))
> }
> 
> 
> 
> *************************************ORIGINAL SPLUS
> SCRIPT************************************************************
> ## sshc.ssc: sample size calculation for historical control studies
> ## J. Jack Lee (jjlee at mdanderson.org) and Chi-hong Tseng
> ## Department of Biostatistics, Univ. of Texas M.D. Anderson Cancer Center
> ##
> ## 3/1/99
> ## updated 6/7/00: add loess
> ##------------------------------------------------------------------
> ######## Required Input:
> #
> # rc? ? number of response in historical control group
> # nc? ? sample size in historical control
> # d? ? ? target improvement = Pe - Pc
> # method 1=method based on the randomized design
> #? ? ? ? 2=Makuch & Simon method (Makuch RW, Simon RM. Sample size considerations
> #? ? ? ? ? for non-randomized comparative studies. J of Chron Dis 1980; 3:175-181.
> #? ? ? ? 3=uniform power method
> ######## optional Input:
> #
> # alpha? size of the test
> # power? desired power of the test
> # tol? ? convergence criterion for methods 1 & 2 in terms of sample size
> # tol1? convergence criterion for method 3 at any given obs Rc in terms of
>? difference
> #? ? ? ? ? of expected power from target
> # tol2? overall convergence criterion for method 3 as the max absolute deviation
> #? ? ? ? ? of expected power from target for all Rc
> # cc? ? range of multiplicative constant applied to the initial values ne
> # l.span smoothing constant for loess
> #
> # Note:? rc is required for methods 1 and 2 but not 3
> #? ? ? ? method 3 return the sample size need for rc=0 to (1-d)*nc
> #
> ######## Output
> # for methdos 1 & 2: return the sample size needed for the experimental group (1
> number)
> #? ? ? ? ? ? ? ? ? ? for given rc, nc, d, alpha, and power
> # for method 3:? ? ? return the profile of sample size needed for given nc, d, alpha, and
> power
> #? ? ? ? ? ? ? ? ? ? vector $ne contains the sample size corresponding to rc=0, 1, 2, ... nc*(1-d)
> #? ? ? ? ? ? ? ? ? ? vector $Ep contains the expected power corresponding to
> #? ? ? ? ? ? ? ? ? ? ? the true pc = (0, 1, 2, ..., nc*(1-d)) / nc
> #
> 
> #------------------------------------------------------------------
> sshc _ function(rc, nc, d, method, alpha=0.05, power=0.8,
> ??? ? ? ? ? ? ? tol=0.01, tol1=.0001, tol2=.005, cc=c(.1,2), l.span=.5)
> {
> ### for method 1
> if (method==1) {
> ??? ne1 _ ss.rand(rc,nc,d,alpha=.05,power=.8,tol=.01)
> ??? return(ne=ne1)
>? ? ? ? ? ? ? ? }
> ### for method 2
> if (method==2) {
> ne_nc
> ne1_nc+50
> while(abs(ne-ne1)>tol & ne1<100000){
> ne_ne1
> pe_d+rc/nc
> ne1_nef(rc,nc,pe*ne,ne,alpha,power)
> ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
> }
> if (ne1>100000) return(NA)
> else return(ne=ne1)
> }
> ### for method 3
> if (method==3) {
> if (tol1 > tol2/10) tol1_tol2/10
> ncstar _ (1-d)*nc
> pc_(0:ncstar)/nc
> ne _ rep(NA,ncstar + 1)
> for (i in (0:ncstar))
> { ne[i+1] _ ss.rand(i,nc,d,alpha=.05,power=.8,tol=.01)
> }
> plot(pc,ne,type='l',ylim=c(0,max(ne)*1.5))
> ans_c.searchd(nc, d, ne, alpha, power, cc, tol1)
> ### check overall absolute deviance
> old.abs.dev _ sum(abs(ans$Ep-power))
> ##bad
>? _ 0
> print(round(ans$Ep,4))
> print(round(ans$ne,2))
> lines(pc,ans$ne,lty=1,col=8)
> old.ne _ ans$ne
> ##while(max(abs(ans$Ep-power))>tol2 & bad==0){? #### unnecessary ##
> while(max(abs(ans$Ep-power))>tol2){
> ans_c.searchd(nc, d, ans$ne, alpha, power, cc, tol1)
> abs.dev _ sum(abs(ans$Ep-power))
> print(paste(" old.abs.dev=",old.abs.dev))
> print(paste("? ? abs.dev=",abs.dev))
> ##if (abs.dev > old.abs.dev) { bad _ 1}
> old.abs.dev _ abs.dev
> print(round(ans$Ep,4))
> print(round(ans$ne,2))
> lines(pc,old.ne,lty=1,col=1)
> lines(pc,ans$ne,lty=1,col=8)
> ### add convex
> ans$ne _ convex(pc,ans$ne)$wy
> ### add loess
> ###old.ne _ ans$ne
> loess.ne _ loess(ans$ne ~ pc, span=l.span)
> lines(pc,loess.ne$fit,lty=1,col=4)
> old.ne _ loess.ne$fit
> ###readline()
> }
> return(ne=ans$ne, Ep=ans$Ep)
>? ? ? ? ? ? ? ? }
> }
> 
> ## needed for method 1
> nef2_function(rc,nc,re,ne,alpha,power){
> za_qnorm(1-alpha)
> zb_qnorm(power)
> xe_asin(sqrt((re+0.375)/(ne+0.75)))
> xc_asin(sqrt((rc+0.375)/(nc+0.75)))
> ans_
>? 1/(4*(xc-xe)^2/(za+zb)^2-1/(nc+0.5)) - 0.5
> return(ans)
> }
> ## needed for method 2
> nef_function(rc,nc,re,ne,alpha,power){
> za_qnorm(1-alpha)
> zb_qnorm(power)
> xe_asin(sqrt((re+0.375)/(ne+0.75)))
> xc_asin(sqrt((rc+0.375)/(nc+0.75)))
> ans_(za*sqrt(1+(ne+0.5)/(nc+0.5))+zb)^2/(2*(xe-xc))^2-0.5
> return(ans)
> }
> ## needed for method 3
> c.searchd_function(nc, d, ne, alpha=0.05, power=0.8, cc=c(0.1,2),tol1=0.0001){
> #---------------------------
> # nc? ? sample size of control group
> # d? ? ? the differece to detect between control and experiment
> # ne? ? vector of starting sample size of experiment group
> #??? ??? ? ? corresonding to rc of 0 to nc*(1-d)
> # alpha? size of test
> # power? target power
> # cc??? ? pre-screen vector of constant c, the range should cover the
> #??? ??? ? ? the value of cc that has expected power
> # tol1? the allowance between the expceted power and target power
> #---------------------------
> pc_(0:((1-d)*nc))/nc
> ncl _ length(pc)
> ne.old _ ne
> ne.old1 _ ne.old
> ###
>? sweeping forward
> for(i in 1:ncl){
> ??? cmin _ cc[1]
> ??? cmax _ cc[2]
> ### fixed cci_cmax bug
> ??? cci? _ 1
> ??? lhood _ dbinom((i:ncl)-1,nc,pc[i])
> ??? ne[i:ncl] _ (1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
> ??? Ep0? _ Epower(nc, d, ne, pc, alpha)
> ??? while(abs(Ep0[i]-power)>tol1){
> ??? ??? if(Ep0[i]<power) cmin_cci
> ??? ??? else cmax_cci
> ??? ??? cci_(cmax+cmin)/2
> ??? ??? ne[i:ncl] _ (1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
> ??? ??? Ep0_Epower(nc, d, ne, pc, alpha)
> ??? }
>? ??? ne.old1 _ ne
> }
> ne1 _ ne
> ### sweeping backward -- ncl:i
> ne.old2 _ ne.old
> ne? ? ? _ ne.old
> for(i in ncl:1){
> ??? cmin _ cc[1]
> ??? cmax _ cc[2]
> ### fixed cci_cmax bug
> ??? cci? _ 1
> ??? lhood _ dbinom((ncl:i)-1,nc,pc[i])
> ??? lenl? _ length(lhood)
> ??? ne[ncl:i] _ (1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
> ??? Ep0? _ Epower(nc, d, cci*ne, pc, alpha)
> ??? while(abs(Ep0[i]-power)>tol1){
> ??? ??? if(Ep0[i]<power) cmin_cci
> ??? ??? else cmax_cci
> ??? ??? cci_(cmax+cmin)/2
> ??? ??? ne[ncl:i] _ (1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
> ??? ??? Ep0_Epower(nc, d, ne, pc, alpha)
> ??? }
>? ??? ne.old2 _ ne
> }
> 
> ne2 _ ne
> ne _ (ne1+ne2)/2
> #cat(ccc*ne)
> Ep1_Epower(nc, d, ne, pc, alpha)
> return(ne=ne, Ep=Ep1)
> }
> ###
> vertex _ function(x,y)
> { ??? n _ length(x)
> ??? vx _ x[1]
> ??? vy _ y[1]
> ??? vp _ 1
> ??? up _ T
> ??? for (i in (2:n))
> ??? { if (up)
> ??? ??? { ??? if (y[i-1] > y[i])
> ??? ??? ??? {vx _ c(vx,x[i-1])
> ??? ??? ??? vy _ c(vy,y[i-1])
> ??? ??? ??? vp _ c(vp,i-1)
> ??? ??? ??? up _ F
> ??? ??? ??? }
> ??? ??? }
> ??? ??? else
> ??? ??? { ??? if (y[i-1] < y[i]) up _ T
> ??? ??? }
> ??? }
> ??? vx _ c(vx,x[n])
> ??? vy _ c(vy,y[n])
> ??? vp _ c(vp,n)
> ??? return(vx=vx,vy=vy,vp=vp)
> }
> ###
> convex _ function(x,y)
> {
> ??? n _ length(x)
> ??? ans _ vertex(x,y)
> ??? len _ length(ans$vx)
> ??? while (len>3)
> ??? {
> #??? ??? cat("x=",x,"\n")
> #??? ??? cat("y=",y,"\n")
> ??? ??? newx _ x[1:(ans$vp[2]-1)]
> ??? ??? newy _ y[1:(ans$vp[2]-1)]
> ??? ??? for (i in (2:(len-1)))
> ??? ??? {
> ??? ??? ??? newx _ c(newx,x[ans$vp[i]])
> ??? ??? ??? newy _ c(newy,y[ans$vp[i]])
> ??? ??? }
> ??? ??? newx _ c(newx,x[(ans$vp[len-1]+1):n])
> ??? ??? newy _ c(newy,y[(ans$vp[len-1]+1):n])
> ??? ??? y _ approx(newx,newy,xout=x)$y
> #??? ??? cat("new y=",y,"\n")
> ??? ??? ans _ vertex(x,y)
> ??? ??? len _ length(ans$vx)
> #??? ??? cat("vx=",ans$vx,"\n")
> #??? ??? cat("vy=",ans$vy,"\n")
> 
> }
> ??? return(wx=x,wy=y)}
> ###
> Epower _ function(nc, d, ne, pc = (0:((1 - d) * nc))/nc, alpha = 0.05)
> {
> #-------------------------------------
> # nc? ? sample size in historical control
> # d? ? ? the increase of response rate between historical and experiment
> # ne? ? sample size of corresonding rc of 0 to nc*(1-d)
> # pc? ? the response rate of control group, where we compute the
> #? ? ? ? expected power
> # alpha? the size of test
> #-------------------------------------
> ??? kk <- length(pc)
> ??? rc <- 0:(nc * (1 - d))
> ??? pp <- rep(NA, kk)
> ??? ppp <- rep(NA, kk)
> ??? for(i in 1:(kk)) {
> ??? ??? pe <- pc[i] + d
> ??? ??? lhood <- dbinom(rc, nc, pc[i])
> ??? ??? pp <- power1.f(rc, nc, ne, pe, alpha)
> ??? ??? ppp[i] <- sum(pp * lhood)/sum(lhood)
> ??? }
> ??? return(ppp)
> }
> 
> # adapted from the old biss2
> ss.rand _ function(rc,nc,d,alpha=.05,power=.8,tol=.01)
> {
> ne_nc
> ne1_nc+50
> while(abs(ne-ne1)>tol & ne1<100000){
> ne_ne1
> pe_d+rc/nc
> ne1_nef2(rc,nc,pe*ne,ne,alpha,power)
> 
> ## if(is.na(ne1))
>? print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
> }
> if (ne1>100000) return(NA)
> else return(ne1)
> }
> ###
> power1.f_function(rc,nc,ne,pie,alpha=0.05){
> #-------------------------------------
> # rc??? number of response in historical control
> # nc??? sample size in historical control
> # ne? ? sample size in experitment group
> # pie??? true response rate for experiment group
> # alpha??? size of the test
> #-------------------------------------
> 
> za_qnorm(1-alpha)
> re_ne*pie
> xe_asin(sqrt((re+0.375)/(ne+0.75)))
> xc_asin(sqrt((rc+0.375)/(nc+0.75)))
> ans_za*sqrt(1+(ne+0.5)/(nc+0.5))-(xe-xc)/sqrt(1/(4*(ne+0.5)))
> return(1-pnorm(ans))
> }
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Thu Jun  6 13:46:41 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 6 Jun 2013 07:46:41 -0400
Subject: [R] SPlus script
In-Reply-To: <1370517877.96887.YahooMailNeo@web142701.mail.bf1.yahoo.com>
References: <1370438435.93923.YahooMailNeo@web142703.mail.bf1.yahoo.com>
	<E66794E69CFDE04D9A70842786030B931C2FD5C4@PA-MBX01.na.tibco.com>
	<1370517877.96887.YahooMailNeo@web142701.mail.bf1.yahoo.com>
Message-ID: <CA+vqiLEGQH+A5wwXh8+3Wb_Vi+gSGh13xCSdFmktVtEsTYAsAQ@mail.gmail.com>

Hi Scott,

As others have pointed out, all your script does is define functions.
It doesn't generate "output" because those functions are never called.
Basically you are missing part of the program--possibly in another
file--that actually calls the sshc function.

Best,
Ista

On Thu, Jun 6, 2013 at 7:24 AM, Scott Raynaud <scott.raynaud at yahoo.com> wrote:
> Ok. I tried copying the original program, changing all _ to <- and running in 3.0.1.  Still no error
> message or output.  It's a mystery to me.
>
> ----- Original Message -----
> From: William Dunlap <wdunlap at tibco.com>
> To: Scott Raynaud <scott.raynaud at yahoo.com>; "r-help at r-project.org" <r-help at r-project.org>
> Cc:
> Sent: Wednesday, June 5, 2013 2:17 PM
> Subject: RE: [R] SPlus script
>
> Both the R and S+ versions (which seem to differ only in the use of _ for assignment
> in the S+ version) do nothing but define some functions.  You would not expect any
> printed output unless you used those functions on some data.  Is there another script
> that does that?
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
>> Of Scott Raynaud
>> Sent: Wednesday, June 05, 2013 6:21 AM
>> To: r-help at r-project.org
>> Subject: [R] SPlus script
>>
>> This originally was an SPlus script that I modifeid about a year-and-a-half ago.  It worked
>> perfectly then.  Now I can't get any output despite not receiving an error message.  I'm
>> providing the SPLUS script as a reference.  I'm running R15.2.2.  Any help appreciated.
>>
>> ************************************MY
>> MODIFICATION***********************************************************
>> **********
>> ## sshc.ssc: sample size calculation for historical control studies
>> ## J. Jack Lee (jjlee at mdanderson.org) and Chi-hong Tseng
>> ## Department of Biostatistics, Univ. of Texas M.D. Anderson Cancer Center
>> ##
>> ## 3/1/99
>> ## updated 6/7/00: add loess
>> ##------------------------------------------------------------------
>> ######## Required Input:
>> #
>> # rc     number of response in historical control group
>> # nc     sample size in historical control
>> # d      target improvement = Pe - Pc
>> # method 1=method based on the randomized design
>> #        2=Makuch & Simon method (Makuch RW, Simon RM. Sample size considerations
>> #          for non-randomized comparative studies. J of Chron Dis 1980; 3:175-181.
>> #        3=uniform power method
>> ######## optional Input:
>> #
>> # alpha  size of the test
>> # power  desired power of the test
>> # tol    convergence criterion for methods 1 & 2 in terms of sample size
>> # tol1   convergence criterion for method 3 at any given obs Rc in terms of difference
>> #          of expected power from target
>> # tol2   overall convergence criterion for method 3 as the max absolute deviation
>> #          of expected power from target for all Rc
>> # cc     range of multiplicative constant applied to the initial values ne
>> # l.span smoothing constant for loess
>> #
>> # Note:  rc is required for methods 1 and 2 but not 3
>> #        method 3 return the sample size need for rc=0 to (1-d)*nc
>> #
>> ######## Output
>> # for methdos 1 & 2: return the sample size needed for the experimental group (1
>> number)
>> #                    for given rc, nc, d, alpha, and power
>> # for method 3:      return the profile of sample size needed for given nc, d, alpha, and
>> power
>> #                    vector $ne contains the sample size corresponding to rc=0, 1, 2, ... nc*(1-d)
>> #                    vector $Ep contains the expected power corresponding to
>> #                      the true pc = (0, 1, 2, ..., nc*(1-d)) / nc
>> #
>> #------------------------------------------------------------------
>> sshc<-function(rc, nc=1092, d=.085779816, method=3, alpha=0.05, power=0.8,
>>               tol=0.01, tol1=.0001, tol2=.005, cc=c(.1,2), l.span=.5)
>> {
>> ### for method 1
>> if (method==1) {
>>  ne1<-ss.rand(rc,nc,d,alpha=.05,power=.8,tol=.01)
>>  return(ne=ne1)
>>                }
>> ### for method 2
>> if (method==2) {
>> ne<-nc
>> ne1<-nc+50
>> while(abs(ne-ne1)>tol & ne1<100000){
>> ne<-ne1
>> pe<-d+rc/nc
>> ne1<-nef(rc,nc,pe*ne,ne,alpha,power)
>> ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
>> }
>> if (ne1>100000) return(NA)
>> else return(ne=ne1)
>> }
>> ### for method 3
>> if (method==3) {
>> if (tol1 > tol2/10) tol1<-tol2/10
>> ncstar<-(1-d)*nc
>> pc<-(0:ncstar)/nc
>> ne<-rep(NA,ncstar + 1)
>> for (i in (0:ncstar))
>> { ne[i+1]<-ss.rand(i,nc,d,alpha=.05,power=.8,tol=.01)
>> }
>> plot(pc,ne,type='l',ylim=c(0,max(ne)*1.5))
>> ans<-c.searchd(nc, d, ne, alpha, power, cc, tol1)
>> ### check overall absolute deviance
>> old.abs.dev<-sum(abs(ans$Ep-power))
>> ##bad<-0
>> print(round(ans$Ep,4))
>> print(round(ans$ne,2))
>> lines(pc,ans$ne,lty=1,col=8)
>> old.ne<-ans$ne
>> ##while(max(abs(ans$Ep-power))>tol2 & bad==0){  #### unnecessary ##
>> while(max(abs(ans$Ep-power))>tol2){
>> ans<-c.searchd(nc, d, ans$ne, alpha, power, cc, tol1)
>> abs.dev<-sum(abs(ans$Ep-power))
>> print(paste(" old.abs.dev=",old.abs.dev))
>> print(paste("     abs.dev=",abs.dev))
>> ##if (abs.dev > old.abs.dev) { bad<-1}
>> old.abs.dev<-abs.dev
>> print(round(ans$Ep,4))
>> print(round(ans$ne,2))
>> lines(pc,old.ne,lty=1,col=1)
>> lines(pc,ans$ne,lty=1,col=8)
>> ### add convex
>> ans$ne<-convex(pc,ans$ne)$wy
>> ### add loess
>> ###old.ne<-ans$ne
>> loess.ne<-loess(ans$ne ~ pc, span=l.span)
>> lines(pc,loess.ne$fit,lty=1,col=4)
>> old.ne<-loess.ne$fit
>> ###readline()
>> }
>> return(list(ne=ans$ne, Ep=ans$Ep))
>>                }
>> }
>> ## needed for method 1
>> nef2<-function(rc,nc,re,ne,alpha,power){
>> za<-qnorm(1-alpha)
>> zb<-qnorm(power)
>> xe<-asin(sqrt((re+0.375)/(ne+0.75)))
>> xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
>> ans<- 1/(4*(xc-xe)^2/(za+zb)^2-1/(nc+0.5)) - 0.5
>> return(ans)
>> }
>> ## needed for method 2
>> nef<-function(rc,nc,re,ne,alpha,power){
>> za<-qnorm(1-alpha)
>> zb<-qnorm(power)
>> xe<-asin(sqrt((re+0.375)/(ne+0.75)))
>> xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
>> ans<-(za*sqrt(1+(ne+0.5)/(nc+0.5))+zb)^2/(2*(xe-xc))^2-0.5
>> return(ans)
>> }
>> ## needed for method 3
>> c.searchd<-function(nc, d, ne, alpha=0.05, power=0.8, cc=c(0.1,2),tol1=0.0001){
>> #---------------------------
>> # nc     sample size of control group
>> # d      the differece to detect between control and experiment
>> # ne     vector of starting sample size of experiment group
>> #      corresonding to rc of 0 to nc*(1-d)
>> # alpha  size of test
>> # power  target power
>> # cc   pre-screen vector of constant c, the range should cover the
>> #      the value of cc that has expected power
>> # tol1   the allowance between the expceted power and target power
>> #---------------------------
>> pc<-(0:((1-d)*nc))/nc
>> ncl<-length(pc)
>> ne.old<-ne
>> ne.old1<-ne.old
>> ### sweeping forward
>> for(i in 1:ncl){
>>  cmin<-cc[1]
>>  cmax<-cc[2]
>> ### fixed cci<-cmax bug
>>  cci <-1
>>  lhood<-dbinom((i:ncl)-1,nc,pc[i])
>>  ne[i:ncl]<-(1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
>>  Ep0 <-Epower(nc, d, ne, pc, alpha)
>>  while(abs(Ep0[i]-power)>tol1){
>>   if(Ep0[i]<power) cmin<-cci
>>   else cmax<-cci
>>   cci<-(cmax+cmin)/2
>>   ne[i:ncl]<-(1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
>>   Ep0<-Epower(nc, d, ne, pc, alpha)
>>  }
>>   ne.old1<-ne
>> }
>> ne1<-ne
>> ### sweeping backward -- ncl:i
>> ne.old2<-ne.old
>> ne     <-ne.old
>> for(i in ncl:1){
>>  cmin<-cc[1]
>>  cmax<-cc[2]
>> ### fixed cci<-cmax bug
>>  cci <-1
>>  lhood<-dbinom((ncl:i)-1,nc,pc[i])
>>  lenl <-length(lhood)
>>  ne[ncl:i]<-(1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
>>  Ep0 <-Epower(nc, d, cci*ne, pc, alpha)
>>  while(abs(Ep0[i]-power)>tol1){
>>   if(Ep0[i]<power) cmin<-cci
>>   else cmax<-cci
>>   cci<-(cmax+cmin)/2
>>   ne[ncl:i]<-(1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
>>   Ep0<-Epower(nc, d, ne, pc, alpha)
>>  }
>>   ne.old2<-ne
>> }
>> ne2<-ne
>> ne<-(ne1+ne2)/2
>> #cat(ccc*ne)
>> Ep1<-Epower(nc, d, ne, pc, alpha)
>> return(list(ne=ne, Ep=Ep1))
>> }
>> ###
>> vertex<-function(x,y)
>> {  n<-length(x)
>>  vx<-x[1]
>>  vy<-y[1]
>>  vp<-1
>>  up<-T
>>  for (i in (2:n))
>>  { if (up)
>>   {  if (y[i-1] > y[i])
>>    {vx<-c(vx,x[i-1])
>>     vy<-c(vy,y[i-1])
>>     vp<-c(vp,i-1)
>>     up<-F
>>    }
>>   }
>>   else
>>   {  if (y[i-1] < y[i]) up<-T
>>   }
>>  }
>>  vx<-c(vx,x[n])
>>  vy<-c(vy,y[n])
>>  vp<-c(vp,n)
>>  return(list(vx=vx,vy=vy,vp=vp))
>> }
>> ###
>> convex<-function(x,y)
>> {
>>  n<-length(x)
>>  ans<-vertex(x,y)
>>  len<-length(ans$vx)
>>  while (len>3)
>>  {
>> #  cat("x=",x,"\n")
>> #  cat("y=",y,"\n")
>>   newx<-x[1:(ans$vp[2]-1)]
>>   newy<-y[1:(ans$vp[2]-1)]
>>   for (i in (2:(len-1)))
>>   {
>>     newx<-c(newx,x[ans$vp[i]])
>>    newy<-c(newy,y[ans$vp[i]])
>>   }
>>   newx<-c(newx,x[(ans$vp[len-1]+1):n])
>>   newy<-c(newy,y[(ans$vp[len-1]+1):n])
>>   y<-approx(newx,newy,xout=x)$y
>> #  cat("new y=",y,"\n")
>>   ans<-vertex(x,y)
>>   len<-length(ans$vx)
>> #  cat("vx=",ans$vx,"\n")
>> #  cat("vy=",ans$vy,"\n")
>> }
>>  return(list(wx=x,wy=y))}
>> ###
>> Epower<-function(nc, d, ne, pc = (0:((1 - d) * nc))/nc, alpha = 0.05)
>> {
>> #-------------------------------------
>> # nc     sample size in historical control
>> # d      the increase of response rate between historical and experiment
>> # ne     sample size of corresonding rc of 0 to nc*(1-d)
>> # pc     the response rate of control group, where we compute the
>> #        expected power
>> # alpha  the size of test
>> #-------------------------------------
>>  kk <- length(pc)
>>  rc <- 0:(nc * (1 - d))
>>  pp <- rep(NA, kk)
>>  ppp <- rep(NA, kk)
>>  for(i in 1:(kk)) {
>>   pe <- pc[i] + d
>>   lhood <- dbinom(rc, nc, pc[i])
>>   pp <- power1.f(rc, nc, ne, pe, alpha)
>>   ppp[i] <- sum(pp * lhood)/sum(lhood)
>>  }
>>  return(ppp)
>> }
>> # adapted from the old biss2
>> ss.rand<-function(rc,nc,d,alpha=.05,power=.8,tol=.01)
>> {
>> ne<-nc
>> ne1<-nc+50
>> while(abs(ne-ne1)>tol & ne1<100000){
>> ne<-ne1
>> pe<-d+rc/nc
>> ne1<-nef2(rc,nc,pe*ne,ne,alpha,power)
>> ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
>> }
>> if (ne1>100000) return(NA)
>> else return(ne1)
>> }
>> ###
>> power1.f<-function(rc,nc,ne,pie,alpha=0.05){
>> #-------------------------------------
>> # rc number of response in historical control
>> # nc sample size in historical control
>> # ne    sample size in experitment group
>> # pie true response rate for experiment group
>> # alpha size of the test
>> #-------------------------------------
>> za<-qnorm(1-alpha)
>> re<-ne*pie
>> xe<-asin(sqrt((re+0.375)/(ne+0.75)))
>> xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
>> ans<-za*sqrt(1+(ne+0.5)/(nc+0.5))-(xe-xc)/sqrt(1/(4*(ne+0.5)))
>> return(1-pnorm(ans))
>> }
>>
>>
>>
>> *************************************ORIGINAL SPLUS
>> SCRIPT************************************************************
>> ## sshc.ssc: sample size calculation for historical control studies
>> ## J. Jack Lee (jjlee at mdanderson.org) and Chi-hong Tseng
>> ## Department of Biostatistics, Univ. of Texas M.D. Anderson Cancer Center
>> ##
>> ## 3/1/99
>> ## updated 6/7/00: add loess
>> ##------------------------------------------------------------------
>> ######## Required Input:
>> #
>> # rc    number of response in historical control group
>> # nc    sample size in historical control
>> # d      target improvement = Pe - Pc
>> # method 1=method based on the randomized design
>> #        2=Makuch & Simon method (Makuch RW, Simon RM. Sample size considerations
>> #          for non-randomized comparative studies. J of Chron Dis 1980; 3:175-181.
>> #        3=uniform power method
>> ######## optional Input:
>> #
>> # alpha  size of the test
>> # power  desired power of the test
>> # tol    convergence criterion for methods 1 & 2 in terms of sample size
>> # tol1  convergence criterion for method 3 at any given obs Rc in terms of
>>  difference
>> #          of expected power from target
>> # tol2  overall convergence criterion for method 3 as the max absolute deviation
>> #          of expected power from target for all Rc
>> # cc    range of multiplicative constant applied to the initial values ne
>> # l.span smoothing constant for loess
>> #
>> # Note:  rc is required for methods 1 and 2 but not 3
>> #        method 3 return the sample size need for rc=0 to (1-d)*nc
>> #
>> ######## Output
>> # for methdos 1 & 2: return the sample size needed for the experimental group (1
>> number)
>> #                    for given rc, nc, d, alpha, and power
>> # for method 3:      return the profile of sample size needed for given nc, d, alpha, and
>> power
>> #                    vector $ne contains the sample size corresponding to rc=0, 1, 2, ... nc*(1-d)
>> #                    vector $Ep contains the expected power corresponding to
>> #                      the true pc = (0, 1, 2, ..., nc*(1-d)) / nc
>> #
>>
>> #------------------------------------------------------------------
>> sshc _ function(rc, nc, d, method, alpha=0.05, power=0.8,
>>                 tol=0.01, tol1=.0001, tol2=.005, cc=c(.1,2), l.span=.5)
>> {
>> ### for method 1
>> if (method==1) {
>>     ne1 _ ss.rand(rc,nc,d,alpha=.05,power=.8,tol=.01)
>>     return(ne=ne1)
>>                }
>> ### for method 2
>> if (method==2) {
>> ne_nc
>> ne1_nc+50
>> while(abs(ne-ne1)>tol & ne1<100000){
>> ne_ne1
>> pe_d+rc/nc
>> ne1_nef(rc,nc,pe*ne,ne,alpha,power)
>> ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
>> }
>> if (ne1>100000) return(NA)
>> else return(ne=ne1)
>> }
>> ### for method 3
>> if (method==3) {
>> if (tol1 > tol2/10) tol1_tol2/10
>> ncstar _ (1-d)*nc
>> pc_(0:ncstar)/nc
>> ne _ rep(NA,ncstar + 1)
>> for (i in (0:ncstar))
>> { ne[i+1] _ ss.rand(i,nc,d,alpha=.05,power=.8,tol=.01)
>> }
>> plot(pc,ne,type='l',ylim=c(0,max(ne)*1.5))
>> ans_c.searchd(nc, d, ne, alpha, power, cc, tol1)
>> ### check overall absolute deviance
>> old.abs.dev _ sum(abs(ans$Ep-power))
>> ##bad
>>  _ 0
>> print(round(ans$Ep,4))
>> print(round(ans$ne,2))
>> lines(pc,ans$ne,lty=1,col=8)
>> old.ne _ ans$ne
>> ##while(max(abs(ans$Ep-power))>tol2 & bad==0){  #### unnecessary ##
>> while(max(abs(ans$Ep-power))>tol2){
>> ans_c.searchd(nc, d, ans$ne, alpha, power, cc, tol1)
>> abs.dev _ sum(abs(ans$Ep-power))
>> print(paste(" old.abs.dev=",old.abs.dev))
>> print(paste("    abs.dev=",abs.dev))
>> ##if (abs.dev > old.abs.dev) { bad _ 1}
>> old.abs.dev _ abs.dev
>> print(round(ans$Ep,4))
>> print(round(ans$ne,2))
>> lines(pc,old.ne,lty=1,col=1)
>> lines(pc,ans$ne,lty=1,col=8)
>> ### add convex
>> ans$ne _ convex(pc,ans$ne)$wy
>> ### add loess
>> ###old.ne _ ans$ne
>> loess.ne _ loess(ans$ne ~ pc, span=l.span)
>> lines(pc,loess.ne$fit,lty=1,col=4)
>> old.ne _ loess.ne$fit
>> ###readline()
>> }
>> return(ne=ans$ne, Ep=ans$Ep)
>>                }
>> }
>>
>> ## needed for method 1
>> nef2_function(rc,nc,re,ne,alpha,power){
>> za_qnorm(1-alpha)
>> zb_qnorm(power)
>> xe_asin(sqrt((re+0.375)/(ne+0.75)))
>> xc_asin(sqrt((rc+0.375)/(nc+0.75)))
>> ans_
>>  1/(4*(xc-xe)^2/(za+zb)^2-1/(nc+0.5)) - 0.5
>> return(ans)
>> }
>> ## needed for method 2
>> nef_function(rc,nc,re,ne,alpha,power){
>> za_qnorm(1-alpha)
>> zb_qnorm(power)
>> xe_asin(sqrt((re+0.375)/(ne+0.75)))
>> xc_asin(sqrt((rc+0.375)/(nc+0.75)))
>> ans_(za*sqrt(1+(ne+0.5)/(nc+0.5))+zb)^2/(2*(xe-xc))^2-0.5
>> return(ans)
>> }
>> ## needed for method 3
>> c.searchd_function(nc, d, ne, alpha=0.05, power=0.8, cc=c(0.1,2),tol1=0.0001){
>> #---------------------------
>> # nc    sample size of control group
>> # d      the differece to detect between control and experiment
>> # ne    vector of starting sample size of experiment group
>> #            corresonding to rc of 0 to nc*(1-d)
>> # alpha  size of test
>> # power  target power
>> # cc      pre-screen vector of constant c, the range should cover the
>> #            the value of cc that has expected power
>> # tol1  the allowance between the expceted power and target power
>> #---------------------------
>> pc_(0:((1-d)*nc))/nc
>> ncl _ length(pc)
>> ne.old _ ne
>> ne.old1 _ ne.old
>> ###
>>  sweeping forward
>> for(i in 1:ncl){
>>     cmin _ cc[1]
>>     cmax _ cc[2]
>> ### fixed cci_cmax bug
>>     cci  _ 1
>>     lhood _ dbinom((i:ncl)-1,nc,pc[i])
>>     ne[i:ncl] _ (1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
>>     Ep0  _ Epower(nc, d, ne, pc, alpha)
>>     while(abs(Ep0[i]-power)>tol1){
>>         if(Ep0[i]<power) cmin_cci
>>         else cmax_cci
>>         cci_(cmax+cmin)/2
>>         ne[i:ncl] _ (1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
>>         Ep0_Epower(nc, d, ne, pc, alpha)
>>     }
>>      ne.old1 _ ne
>> }
>> ne1 _ ne
>> ### sweeping backward -- ncl:i
>> ne.old2 _ ne.old
>> ne      _ ne.old
>> for(i in ncl:1){
>>     cmin _ cc[1]
>>     cmax _ cc[2]
>> ### fixed cci_cmax bug
>>     cci  _ 1
>>     lhood _ dbinom((ncl:i)-1,nc,pc[i])
>>     lenl  _ length(lhood)
>>     ne[ncl:i] _ (1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
>>     Ep0  _ Epower(nc, d, cci*ne, pc, alpha)
>>     while(abs(Ep0[i]-power)>tol1){
>>         if(Ep0[i]<power) cmin_cci
>>         else cmax_cci
>>         cci_(cmax+cmin)/2
>>         ne[ncl:i] _ (1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
>>         Ep0_Epower(nc, d, ne, pc, alpha)
>>     }
>>      ne.old2 _ ne
>> }
>>
>> ne2 _ ne
>> ne _ (ne1+ne2)/2
>> #cat(ccc*ne)
>> Ep1_Epower(nc, d, ne, pc, alpha)
>> return(ne=ne, Ep=Ep1)
>> }
>> ###
>> vertex _ function(x,y)
>> {     n _ length(x)
>>     vx _ x[1]
>>     vy _ y[1]
>>     vp _ 1
>>     up _ T
>>     for (i in (2:n))
>>     { if (up)
>>         {     if (y[i-1] > y[i])
>>             {vx _ c(vx,x[i-1])
>>             vy _ c(vy,y[i-1])
>>             vp _ c(vp,i-1)
>>             up _ F
>>             }
>>         }
>>         else
>>         {     if (y[i-1] < y[i]) up _ T
>>         }
>>     }
>>     vx _ c(vx,x[n])
>>     vy _ c(vy,y[n])
>>     vp _ c(vp,n)
>>     return(vx=vx,vy=vy,vp=vp)
>> }
>> ###
>> convex _ function(x,y)
>> {
>>     n _ length(x)
>>     ans _ vertex(x,y)
>>     len _ length(ans$vx)
>>     while (len>3)
>>     {
>> #        cat("x=",x,"\n")
>> #        cat("y=",y,"\n")
>>         newx _ x[1:(ans$vp[2]-1)]
>>         newy _ y[1:(ans$vp[2]-1)]
>>         for (i in (2:(len-1)))
>>         {
>>             newx _ c(newx,x[ans$vp[i]])
>>             newy _ c(newy,y[ans$vp[i]])
>>         }
>>         newx _ c(newx,x[(ans$vp[len-1]+1):n])
>>         newy _ c(newy,y[(ans$vp[len-1]+1):n])
>>         y _ approx(newx,newy,xout=x)$y
>> #        cat("new y=",y,"\n")
>>         ans _ vertex(x,y)
>>         len _ length(ans$vx)
>> #        cat("vx=",ans$vx,"\n")
>> #        cat("vy=",ans$vy,"\n")
>>
>> }
>>     return(wx=x,wy=y)}
>> ###
>> Epower _ function(nc, d, ne, pc = (0:((1 - d) * nc))/nc, alpha = 0.05)
>> {
>> #-------------------------------------
>> # nc    sample size in historical control
>> # d      the increase of response rate between historical and experiment
>> # ne    sample size of corresonding rc of 0 to nc*(1-d)
>> # pc    the response rate of control group, where we compute the
>> #        expected power
>> # alpha  the size of test
>> #-------------------------------------
>>     kk <- length(pc)
>>     rc <- 0:(nc * (1 - d))
>>     pp <- rep(NA, kk)
>>     ppp <- rep(NA, kk)
>>     for(i in 1:(kk)) {
>>         pe <- pc[i] + d
>>         lhood <- dbinom(rc, nc, pc[i])
>>         pp <- power1.f(rc, nc, ne, pe, alpha)
>>         ppp[i] <- sum(pp * lhood)/sum(lhood)
>>     }
>>     return(ppp)
>> }
>>
>> # adapted from the old biss2
>> ss.rand _ function(rc,nc,d,alpha=.05,power=.8,tol=.01)
>> {
>> ne_nc
>> ne1_nc+50
>> while(abs(ne-ne1)>tol & ne1<100000){
>> ne_ne1
>> pe_d+rc/nc
>> ne1_nef2(rc,nc,pe*ne,ne,alpha,power)
>>
>> ## if(is.na(ne1))
>>  print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
>> }
>> if (ne1>100000) return(NA)
>> else return(ne1)
>> }
>> ###
>> power1.f_function(rc,nc,ne,pie,alpha=0.05){
>> #-------------------------------------
>> # rc    number of response in historical control
>> # nc    sample size in historical control
>> # ne    sample size in experitment group
>> # pie    true response rate for experiment group
>> # alpha    size of the test
>> #-------------------------------------
>>
>> za_qnorm(1-alpha)
>> re_ne*pie
>> xe_asin(sqrt((re+0.375)/(ne+0.75)))
>> xc_asin(sqrt((rc+0.375)/(nc+0.75)))
>> ans_za*sqrt(1+(ne+0.5)/(nc+0.5))-(xe-xc)/sqrt(1/(4*(ne+0.5)))
>> return(1-pnorm(ans))
>> }
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bbolker at gmail.com  Thu Jun  6 14:35:54 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 6 Jun 2013 12:35:54 +0000
Subject: [R] lme function cannot find object
References: <CAJjjYOnJnTj2frJ8_O5g+h8sYmkjCL3Zgj1F=OvgNYjxz11J8A@mail.gmail.com>
Message-ID: <loom.20130606T141928-414@post.gmane.org>

Pfeiffer, Steven <pfeiffss <at> miamioh.edu> writes:


> I have been using the function lme() from package 'nlme' for several months
> now without any problems.  Suddenly, it cannot find a factor in my data.
> Is this a new bug of some kind?  My code and output are below.
> Thanks for your help!
> -Steve Pfeiffer

  You have an extra comma at the end of the first line of
your lme code (indicated with ^^^), so R thinks your interaction term is a
separate argument and tries to intepret it outside the context
of the formula ...

library("nlme")
fit.1<-lme(soil.moisture ~ Trenching + DaysSinceEvent,
                                                   ^^^^^
                                         + Trenching:DaysSinceEvent,
                 random = ~ DaysSinceEvent | Plot,
                 data=Dat.middle,
                 method="ML"
                )


From scott.raynaud at yahoo.com  Thu Jun  6 15:02:19 2013
From: scott.raynaud at yahoo.com (Scott Raynaud)
Date: Thu, 6 Jun 2013 06:02:19 -0700 (PDT)
Subject: [R] SPlus script
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C2FD5C4@PA-MBX01.na.tibco.com>
References: <1370438435.93923.YahooMailNeo@web142703.mail.bf1.yahoo.com>
	<E66794E69CFDE04D9A70842786030B931C2FD5C4@PA-MBX01.na.tibco.com>
Message-ID: <1370523739.92423.YahooMailNeo@web142703.mail.bf1.yahoo.com>

Ok.? Now I see that the sshc function is not being called.? Thanks for pointing that out.? 
I'm not certain about the solution, however.? I tried putting call("sshc") at the end of the 
program, but nothing happened.? My memory about all of this is fuzzy.? Suggestions 
on how to call the function appreciated.

----- Original Message -----
From: William Dunlap <wdunlap at tibco.com>
To: Scott Raynaud <scott.raynaud at yahoo.com>; "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Wednesday, June 5, 2013 2:17 PM
Subject: RE: [R] SPlus script

Both the R and S+ versions (which seem to differ only in the use of _ for assignment
in the S+ version) do nothing but define some functions.? You would not expect any
printed output unless you used those functions on some data.? Is there another script
that does that?

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Scott Raynaud
> Sent: Wednesday, June 05, 2013 6:21 AM
> To: r-help at r-project.org
> Subject: [R] SPlus script
> 
> This?originally was?an SPlus script that I modifeid about a year-and-a-half ago.? It worked
> perfectly then.? Now I can't get any output despite not receiving an error message.? I'm
> providing the SPLUS script as a reference.? I'm running R15.2.2.? Any help appreciated.
> 
> ************************************MY
> MODIFICATION***********************************************************
> **********
> ## sshc.ssc: sample size calculation for historical control studies
> ## J. Jack Lee (jjlee at mdanderson.org) and Chi-hong Tseng
> ## Department of Biostatistics, Univ. of Texas M.D. Anderson Cancer Center
> ##
> ## 3/1/99
> ## updated 6/7/00: add loess
> ##------------------------------------------------------------------
> ######## Required Input:
> #
> # rc???? number of response in historical control group
> # nc???? sample size in historical control
> # d????? target improvement = Pe - Pc
> # method 1=method based on the randomized design
> #??????? 2=Makuch & Simon method (Makuch RW, Simon RM. Sample size considerations
> #????????? for non-randomized comparative studies. J of Chron Dis 1980; 3:175-181.
> #??????? 3=uniform power method
> ######## optional Input:
> #
> # alpha? size of the test
> # power? desired power of the test
> # tol??? convergence criterion for methods 1 & 2 in terms of sample size
> # tol1?? convergence criterion for method 3 at any given obs Rc in terms of difference
> #????????? of expected power from target
> # tol2?? overall convergence criterion for method 3 as the max absolute deviation
> #????????? of expected power from target for all Rc
> # cc???? range of multiplicative constant applied to the initial values ne
> # l.span smoothing constant for loess
> #
> # Note:? rc is required for methods 1 and 2 but not 3
> #??????? method 3 return the sample size need for rc=0 to (1-d)*nc
> #
> ######## Output
> # for methdos 1 & 2: return the sample size needed for the experimental group (1
> number)
> #??????????????????? for given rc, nc, d, alpha, and power
> # for method 3:????? return the profile of sample size needed for given nc, d, alpha, and
> power
> #??????????????????? vector $ne contains the sample size corresponding to rc=0, 1, 2, ... nc*(1-d)
> #??????????????????? vector $Ep contains the expected power corresponding to
> #????????????????????? the true pc = (0, 1, 2, ..., nc*(1-d)) / nc
> #
> #------------------------------------------------------------------
> sshc<-function(rc, nc=1092, d=.085779816, method=3, alpha=0.05, power=0.8,
> ????????????? tol=0.01, tol1=.0001, tol2=.005, cc=c(.1,2), l.span=.5)
> {
> ### for method 1
> if (method==1) {
> ?ne1<-ss.rand(rc,nc,d,alpha=.05,power=.8,tol=.01)
> ?return(ne=ne1)
> ?????????????? }
> ### for method 2
> if (method==2) {
> ne<-nc
> ne1<-nc+50
> while(abs(ne-ne1)>tol & ne1<100000){
> ne<-ne1
> pe<-d+rc/nc
> ne1<-nef(rc,nc,pe*ne,ne,alpha,power)
> ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
> }
> if (ne1>100000) return(NA)
> else return(ne=ne1)
> }
> ### for method 3
> if (method==3) {
> if (tol1 > tol2/10) tol1<-tol2/10
> ncstar<-(1-d)*nc
> pc<-(0:ncstar)/nc
> ne<-rep(NA,ncstar + 1)
> for (i in (0:ncstar))
> { ne[i+1]<-ss.rand(i,nc,d,alpha=.05,power=.8,tol=.01)
> }
> plot(pc,ne,type='l',ylim=c(0,max(ne)*1.5))
> ans<-c.searchd(nc, d, ne, alpha, power, cc, tol1)
> ### check overall absolute deviance
> old.abs.dev<-sum(abs(ans$Ep-power))
> ##bad<-0
> print(round(ans$Ep,4))
> print(round(ans$ne,2))
> lines(pc,ans$ne,lty=1,col=8)
> old.ne<-ans$ne
> ##while(max(abs(ans$Ep-power))>tol2 & bad==0){? #### unnecessary ##
> while(max(abs(ans$Ep-power))>tol2){
> ans<-c.searchd(nc, d, ans$ne, alpha, power, cc, tol1)
> abs.dev<-sum(abs(ans$Ep-power))
> print(paste(" old.abs.dev=",old.abs.dev))
> print(paste("???? abs.dev=",abs.dev))
> ##if (abs.dev > old.abs.dev) { bad<-1}
> old.abs.dev<-abs.dev
> print(round(ans$Ep,4))
> print(round(ans$ne,2))
> lines(pc,old.ne,lty=1,col=1)
> lines(pc,ans$ne,lty=1,col=8)
> ### add convex
> ans$ne<-convex(pc,ans$ne)$wy
> ### add loess
> ###old.ne<-ans$ne
> loess.ne<-loess(ans$ne ~ pc, span=l.span)
> lines(pc,loess.ne$fit,lty=1,col=4)
> old.ne<-loess.ne$fit
> ###readline()
> }
> return(list(ne=ans$ne, Ep=ans$Ep))
> ?????????????? }
> }
> ## needed for method 1
> nef2<-function(rc,nc,re,ne,alpha,power){
> za<-qnorm(1-alpha)
> zb<-qnorm(power)
> xe<-asin(sqrt((re+0.375)/(ne+0.75)))
> xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
> ans<- 1/(4*(xc-xe)^2/(za+zb)^2-1/(nc+0.5)) - 0.5
> return(ans)
> }
> ## needed for method 2
> nef<-function(rc,nc,re,ne,alpha,power){
> za<-qnorm(1-alpha)
> zb<-qnorm(power)
> xe<-asin(sqrt((re+0.375)/(ne+0.75)))
> xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
> ans<-(za*sqrt(1+(ne+0.5)/(nc+0.5))+zb)^2/(2*(xe-xc))^2-0.5
> return(ans)
> }
> ## needed for method 3
> c.searchd<-function(nc, d, ne, alpha=0.05, power=0.8, cc=c(0.1,2),tol1=0.0001){
> #---------------------------
> # nc???? sample size of control group
> # d????? the differece to detect between control and experiment
> # ne???? vector of starting sample size of experiment group
> #????? corresonding to rc of 0 to nc*(1-d)
> # alpha? size of test
> # power? target power
> # cc?? pre-screen vector of constant c, the range should cover the
> #????? the value of cc that has expected power
> # tol1?? the allowance between the expceted power and target power
> #---------------------------
> pc<-(0:((1-d)*nc))/nc
> ncl<-length(pc)
> ne.old<-ne
> ne.old1<-ne.old
> ### sweeping forward
> for(i in 1:ncl){
> ?cmin<-cc[1]
> ?cmax<-cc[2]
> ### fixed cci<-cmax bug
> ?cci <-1
> ?lhood<-dbinom((i:ncl)-1,nc,pc[i])
> ?ne[i:ncl]<-(1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
> ?Ep0 <-Epower(nc, d, ne, pc, alpha)
> ?while(abs(Ep0[i]-power)>tol1){
> ??if(Ep0[i]<power) cmin<-cci
> ??else cmax<-cci
> ??cci<-(cmax+cmin)/2
> ??ne[i:ncl]<-(1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
> ??Ep0<-Epower(nc, d, ne, pc, alpha)
> ?}
> ??ne.old1<-ne
> }
> ne1<-ne
> ### sweeping backward -- ncl:i
> ne.old2<-ne.old
> ne???? <-ne.old
> for(i in ncl:1){
> ?cmin<-cc[1]
> ?cmax<-cc[2]
> ### fixed cci<-cmax bug
> ?cci <-1
> ?lhood<-dbinom((ncl:i)-1,nc,pc[i])
> ?lenl <-length(lhood)
> ?ne[ncl:i]<-(1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
> ?Ep0 <-Epower(nc, d, cci*ne, pc, alpha)
> ?while(abs(Ep0[i]-power)>tol1){
> ??if(Ep0[i]<power) cmin<-cci
> ??else cmax<-cci
> ??cci<-(cmax+cmin)/2
> ??ne[ncl:i]<-(1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
> ??Ep0<-Epower(nc, d, ne, pc, alpha)
> ?}
> ??ne.old2<-ne
> }
> ne2<-ne
> ne<-(ne1+ne2)/2
> #cat(ccc*ne)
> Ep1<-Epower(nc, d, ne, pc, alpha)
> return(list(ne=ne, Ep=Ep1))
> }
> ###
> vertex<-function(x,y)
> { ?n<-length(x)
> ?vx<-x[1]
> ?vy<-y[1]
> ?vp<-1
> ?up<-T
> ?for (i in (2:n))
> ?{ if (up)
> ??{ ?if (y[i-1] > y[i])
> ???{vx<-c(vx,x[i-1])
> ??? vy<-c(vy,y[i-1])
> ??? vp<-c(vp,i-1)
> ??? up<-F
> ???}
> ??}
> ??else
> ??{ ?if (y[i-1] < y[i]) up<-T
> ??}
> ?}
> ?vx<-c(vx,x[n])
> ?vy<-c(vy,y[n])
> ?vp<-c(vp,n)
> ?return(list(vx=vx,vy=vy,vp=vp))
> }
> ###
> convex<-function(x,y)
> {
> ?n<-length(x)
> ?ans<-vertex(x,y)
> ?len<-length(ans$vx)
> ?while (len>3)
> ?{
> #??cat("x=",x,"\n")
> #??cat("y=",y,"\n")
> ??newx<-x[1:(ans$vp[2]-1)]
> ??newy<-y[1:(ans$vp[2]-1)]
> ??for (i in (2:(len-1)))
> ??{
> ?? ?newx<-c(newx,x[ans$vp[i]])
> ???newy<-c(newy,y[ans$vp[i]])
> ??}
> ??newx<-c(newx,x[(ans$vp[len-1]+1):n])
> ??newy<-c(newy,y[(ans$vp[len-1]+1):n])
> ??y<-approx(newx,newy,xout=x)$y
> #??cat("new y=",y,"\n")
> ??ans<-vertex(x,y)
> ??len<-length(ans$vx)
> #??cat("vx=",ans$vx,"\n")
> #??cat("vy=",ans$vy,"\n")
> }
> ?return(list(wx=x,wy=y))}
> ###
> Epower<-function(nc, d, ne, pc = (0:((1 - d) * nc))/nc, alpha = 0.05)
> {
> #-------------------------------------
> # nc???? sample size in historical control
> # d????? the increase of response rate between historical and experiment
> # ne???? sample size of corresonding rc of 0 to nc*(1-d)
> # pc???? the response rate of control group, where we compute the
> #??????? expected power
> # alpha? the size of test
> #-------------------------------------
> ?kk <- length(pc)
> ?rc <- 0:(nc * (1 - d))
> ?pp <- rep(NA, kk)
> ?ppp <- rep(NA, kk)
> ?for(i in 1:(kk)) {
> ??pe <- pc[i] + d
> ??lhood <- dbinom(rc, nc, pc[i])
> ??pp <- power1.f(rc, nc, ne, pe, alpha)
> ??ppp[i] <- sum(pp * lhood)/sum(lhood)
> ?}
> ?return(ppp)
> }
> # adapted from the old biss2
> ss.rand<-function(rc,nc,d,alpha=.05,power=.8,tol=.01)
> {
> ne<-nc
> ne1<-nc+50
> while(abs(ne-ne1)>tol & ne1<100000){
> ne<-ne1
> pe<-d+rc/nc
> ne1<-nef2(rc,nc,pe*ne,ne,alpha,power)
> ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
> }
> if (ne1>100000) return(NA)
> else return(ne1)
> }
> ###
> power1.f<-function(rc,nc,ne,pie,alpha=0.05){
> #-------------------------------------
> # rc?number of response in historical control
> # nc?sample size in historical control
> # ne??? sample size in experitment group
> # pie?true response rate for experiment group
> # alpha?size of the test
> #-------------------------------------
> za<-qnorm(1-alpha)
> re<-ne*pie
> xe<-asin(sqrt((re+0.375)/(ne+0.75)))
> xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
> ans<-za*sqrt(1+(ne+0.5)/(nc+0.5))-(xe-xc)/sqrt(1/(4*(ne+0.5)))
> return(1-pnorm(ans))
> }
> 
> 
> 
> *************************************ORIGINAL SPLUS
> SCRIPT************************************************************
> ## sshc.ssc: sample size calculation for historical control studies
> ## J. Jack Lee (jjlee at mdanderson.org) and Chi-hong Tseng
> ## Department of Biostatistics, Univ. of Texas M.D. Anderson Cancer Center
> ##
> ## 3/1/99
> ## updated 6/7/00: add loess
> ##------------------------------------------------------------------
> ######## Required Input:
> #
> # rc? ? number of response in historical control group
> # nc? ? sample size in historical control
> # d? ? ? target improvement = Pe - Pc
> # method 1=method based on the randomized design
> #? ? ? ? 2=Makuch & Simon method (Makuch RW, Simon RM. Sample size considerations
> #? ? ? ? ? for non-randomized comparative studies. J of Chron Dis 1980; 3:175-181.
> #? ? ? ? 3=uniform power method
> ######## optional Input:
> #
> # alpha? size of the test
> # power? desired power of the test
> # tol? ? convergence criterion for methods 1 & 2 in terms of sample size
> # tol1? convergence criterion for method 3 at any given obs Rc in terms of
>? difference
> #? ? ? ? ? of expected power from target
> # tol2? overall convergence criterion for method 3 as the max absolute deviation
> #? ? ? ? ? of expected power from target for all Rc
> # cc? ? range of multiplicative constant applied to the initial values ne
> # l.span smoothing constant for loess
> #
> # Note:? rc is required for methods 1 and 2 but not 3
> #? ? ? ? method 3 return the sample size need for rc=0 to (1-d)*nc
> #
> ######## Output
> # for methdos 1 & 2: return the sample size needed for the experimental group (1
> number)
> #? ? ? ? ? ? ? ? ? ? for given rc, nc, d, alpha, and power
> # for method 3:? ? ? return the profile of sample size needed for given nc, d, alpha, and
> power
> #? ? ? ? ? ? ? ? ? ? vector $ne contains the sample size corresponding to rc=0, 1, 2, ... nc*(1-d)
> #? ? ? ? ? ? ? ? ? ? vector $Ep contains the expected power corresponding to
> #? ? ? ? ? ? ? ? ? ? ? the true pc = (0, 1, 2, ..., nc*(1-d)) / nc
> #
> 
> #------------------------------------------------------------------
> sshc _ function(rc, nc, d, method, alpha=0.05, power=0.8,
> ??? ? ? ? ? ? ? tol=0.01, tol1=.0001, tol2=.005, cc=c(.1,2), l.span=.5)
> {
> ### for method 1
> if (method==1) {
> ??? ne1 _ ss.rand(rc,nc,d,alpha=.05,power=.8,tol=.01)
> ??? return(ne=ne1)
>? ? ? ? ? ? ? ? }
> ### for method 2
> if (method==2) {
> ne_nc
> ne1_nc+50
> while(abs(ne-ne1)>tol & ne1<100000){
> ne_ne1
> pe_d+rc/nc
> ne1_nef(rc,nc,pe*ne,ne,alpha,power)
> ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
> }
> if (ne1>100000) return(NA)
> else return(ne=ne1)
> }
> ### for method 3
> if (method==3) {
> if (tol1 > tol2/10) tol1_tol2/10
> ncstar _ (1-d)*nc
> pc_(0:ncstar)/nc
> ne _ rep(NA,ncstar + 1)
> for (i in (0:ncstar))
> { ne[i+1] _ ss.rand(i,nc,d,alpha=.05,power=.8,tol=.01)
> }
> plot(pc,ne,type='l',ylim=c(0,max(ne)*1.5))
> ans_c.searchd(nc, d, ne, alpha, power, cc, tol1)
> ### check overall absolute deviance
> old.abs.dev _ sum(abs(ans$Ep-power))
> ##bad
>? _ 0
> print(round(ans$Ep,4))
> print(round(ans$ne,2))
> lines(pc,ans$ne,lty=1,col=8)
> old.ne _ ans$ne
> ##while(max(abs(ans$Ep-power))>tol2 & bad==0){? #### unnecessary ##
> while(max(abs(ans$Ep-power))>tol2){
> ans_c.searchd(nc, d, ans$ne, alpha, power, cc, tol1)
> abs.dev _ sum(abs(ans$Ep-power))
> print(paste(" old.abs.dev=",old.abs.dev))
> print(paste("? ? abs.dev=",abs.dev))
> ##if (abs.dev > old.abs.dev) { bad _ 1}
> old.abs.dev _ abs.dev
> print(round(ans$Ep,4))
> print(round(ans$ne,2))
> lines(pc,old.ne,lty=1,col=1)
> lines(pc,ans$ne,lty=1,col=8)
> ### add convex
> ans$ne _ convex(pc,ans$ne)$wy
> ### add loess
> ###old.ne _ ans$ne
> loess.ne _ loess(ans$ne ~ pc, span=l.span)
> lines(pc,loess.ne$fit,lty=1,col=4)
> old.ne _ loess.ne$fit
> ###readline()
> }
> return(ne=ans$ne, Ep=ans$Ep)
>? ? ? ? ? ? ? ? }
> }
> 
> ## needed for method 1
> nef2_function(rc,nc,re,ne,alpha,power){
> za_qnorm(1-alpha)
> zb_qnorm(power)
> xe_asin(sqrt((re+0.375)/(ne+0.75)))
> xc_asin(sqrt((rc+0.375)/(nc+0.75)))
> ans_
>? 1/(4*(xc-xe)^2/(za+zb)^2-1/(nc+0.5)) - 0.5
> return(ans)
> }
> ## needed for method 2
> nef_function(rc,nc,re,ne,alpha,power){
> za_qnorm(1-alpha)
> zb_qnorm(power)
> xe_asin(sqrt((re+0.375)/(ne+0.75)))
> xc_asin(sqrt((rc+0.375)/(nc+0.75)))
> ans_(za*sqrt(1+(ne+0.5)/(nc+0.5))+zb)^2/(2*(xe-xc))^2-0.5
> return(ans)
> }
> ## needed for method 3
> c.searchd_function(nc, d, ne, alpha=0.05, power=0.8, cc=c(0.1,2),tol1=0.0001){
> #---------------------------
> # nc? ? sample size of control group
> # d? ? ? the differece to detect between control and experiment
> # ne? ? vector of starting sample size of experiment group
> #??? ??? ? ? corresonding to rc of 0 to nc*(1-d)
> # alpha? size of test
> # power? target power
> # cc??? ? pre-screen vector of constant c, the range should cover the
> #??? ??? ? ? the value of cc that has expected power
> # tol1? the allowance between the expceted power and target power
> #---------------------------
> pc_(0:((1-d)*nc))/nc
> ncl _ length(pc)
> ne.old _ ne
> ne.old1 _ ne.old
> ###
>? sweeping forward
> for(i in 1:ncl){
> ??? cmin _ cc[1]
> ??? cmax _ cc[2]
> ### fixed cci_cmax bug
> ??? cci? _ 1
> ??? lhood _ dbinom((i:ncl)-1,nc,pc[i])
> ??? ne[i:ncl] _ (1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
> ??? Ep0? _ Epower(nc, d, ne, pc, alpha)
> ??? while(abs(Ep0[i]-power)>tol1){
> ??? ??? if(Ep0[i]<power) cmin_cci
> ??? ??? else cmax_cci
> ??? ??? cci_(cmax+cmin)/2
> ??? ??? ne[i:ncl] _ (1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
> ??? ??? Ep0_Epower(nc, d, ne, pc, alpha)
> ??? }
>? ??? ne.old1 _ ne
> }
> ne1 _ ne
> ### sweeping backward -- ncl:i
> ne.old2 _ ne.old
> ne? ? ? _ ne.old
> for(i in ncl:1){
> ??? cmin _ cc[1]
> ??? cmax _ cc[2]
> ### fixed cci_cmax bug
> ??? cci? _ 1
> ??? lhood _ dbinom((ncl:i)-1,nc,pc[i])
> ??? lenl? _ length(lhood)
> ??? ne[ncl:i] _ (1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
> ??? Ep0? _ Epower(nc, d, cci*ne, pc, alpha)
> ??? while(abs(Ep0[i]-power)>tol1){
> ??? ??? if(Ep0[i]<power) cmin_cci
> ??? ??? else cmax_cci
> ??? ??? cci_(cmax+cmin)/2
> ??? ??? ne[ncl:i] _ (1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
> ??? ??? Ep0_Epower(nc, d, ne, pc, alpha)
> ??? }
>? ??? ne.old2 _ ne
> }
> 
> ne2 _ ne
> ne _ (ne1+ne2)/2
> #cat(ccc*ne)
> Ep1_Epower(nc, d, ne, pc, alpha)
> return(ne=ne, Ep=Ep1)
> }
> ###
> vertex _ function(x,y)
> { ??? n _ length(x)
> ??? vx _ x[1]
> ??? vy _ y[1]
> ??? vp _ 1
> ??? up _ T
> ??? for (i in (2:n))
> ??? { if (up)
> ??? ??? { ??? if (y[i-1] > y[i])
> ??? ??? ??? {vx _ c(vx,x[i-1])
> ??? ??? ??? vy _ c(vy,y[i-1])
> ??? ??? ??? vp _ c(vp,i-1)
> ??? ??? ??? up _ F
> ??? ??? ??? }
> ??? ??? }
> ??? ??? else
> ??? ??? { ??? if (y[i-1] < y[i]) up _ T
> ??? ??? }
> ??? }
> ??? vx _ c(vx,x[n])
> ??? vy _ c(vy,y[n])
> ??? vp _ c(vp,n)
> ??? return(vx=vx,vy=vy,vp=vp)
> }
> ###
> convex _ function(x,y)
> {
> ??? n _ length(x)
> ??? ans _ vertex(x,y)
> ??? len _ length(ans$vx)
> ??? while (len>3)
> ??? {
> #??? ??? cat("x=",x,"\n")
> #??? ??? cat("y=",y,"\n")
> ??? ??? newx _ x[1:(ans$vp[2]-1)]
> ??? ??? newy _ y[1:(ans$vp[2]-1)]
> ??? ??? for (i in (2:(len-1)))
> ??? ??? {
> ??? ??? ??? newx _ c(newx,x[ans$vp[i]])
> ??? ??? ??? newy _ c(newy,y[ans$vp[i]])
> ??? ??? }
> ??? ??? newx _ c(newx,x[(ans$vp[len-1]+1):n])
> ??? ??? newy _ c(newy,y[(ans$vp[len-1]+1):n])
> ??? ??? y _ approx(newx,newy,xout=x)$y
> #??? ??? cat("new y=",y,"\n")
> ??? ??? ans _ vertex(x,y)
> ??? ??? len _ length(ans$vx)
> #??? ??? cat("vx=",ans$vx,"\n")
> #??? ??? cat("vy=",ans$vy,"\n")
> 
> }
> ??? return(wx=x,wy=y)}
> ###
> Epower _ function(nc, d, ne, pc = (0:((1 - d) * nc))/nc, alpha = 0.05)
> {
> #-------------------------------------
> # nc? ? sample size in historical control
> # d? ? ? the increase of response rate between historical and experiment
> # ne? ? sample size of corresonding rc of 0 to nc*(1-d)
> # pc? ? the response rate of control group, where we compute the
> #? ? ? ? expected power
> # alpha? the size of test
> #-------------------------------------
> ??? kk <- length(pc)
> ??? rc <- 0:(nc * (1 - d))
> ??? pp <- rep(NA, kk)
> ??? ppp <- rep(NA, kk)
> ??? for(i in 1:(kk)) {
> ??? ??? pe <- pc[i] + d
> ??? ??? lhood <- dbinom(rc, nc, pc[i])
> ??? ??? pp <- power1.f(rc, nc, ne, pe, alpha)
> ??? ??? ppp[i] <- sum(pp * lhood)/sum(lhood)
> ??? }
> ??? return(ppp)
> }
> 
> # adapted from the old biss2
> ss.rand _ function(rc,nc,d,alpha=.05,power=.8,tol=.01)
> {
> ne_nc
> ne1_nc+50
> while(abs(ne-ne1)>tol & ne1<100000){
> ne_ne1
> pe_d+rc/nc
> ne1_nef2(rc,nc,pe*ne,ne,alpha,power)
> 
> ## if(is.na(ne1))
>? print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
> }
> if (ne1>100000) return(NA)
> else return(ne1)
> }
> ###
> power1.f_function(rc,nc,ne,pie,alpha=0.05){
> #-------------------------------------
> # rc??? number of response in historical control
> # nc??? sample size in historical control
> # ne? ? sample size in experitment group
> # pie??? true response rate for experiment group
> # alpha??? size of the test
> #-------------------------------------
> 
> za_qnorm(1-alpha)
> re_ne*pie
> xe_asin(sqrt((re+0.375)/(ne+0.75)))
> xc_asin(sqrt((rc+0.375)/(nc+0.75)))
> ans_za*sqrt(1+(ne+0.5)/(nc+0.5))-(xe-xc)/sqrt(1/(4*(ne+0.5)))
> return(1-pnorm(ans))
> }
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Sudha.Krishnan at marlabs.com  Thu Jun  6 08:37:41 2013
From: Sudha.Krishnan at marlabs.com (Sudha Krishnan)
Date: Thu, 6 Jun 2013 06:37:41 +0000
Subject: [R]  generating a bar chart with two axis for co-linear variable
Message-ID: <EB2D2D799706D645AA4808B7CB24D41A315BA864@MLBMBX4.marlabs.com>



Hello Dimitris,



I was goggling for some help on Sensitivity vs 1-specificity and saw your link.



I hope you can be of help to me in one of the issue that I am facing in generating combo chart(bar chart and plot). I am a novice and have some difficulty in getting this logic correct.





I am give a dataset (I am attaching a sample dataset).



I am using a barplot() and passing values for percentage frequency and the corresponding variables. I am struck here, what my function does is only calculate the frequency for the listed variables and not the frequency percentage. Is there a method or a script with which I can pass the frequency percent and the related values as category columns for x axis?



I will attach the graphs that I have generated so that you can suggest the better way.



Sampledata - Sampledata.txt

What my function does to calculate the frequency with category names in X axis - 1.png

My requirement is to generate percentage frequency of the variable in y1 and not the frequency itself. 2.png (where x categories are missing)





Thanks,

Sudha Krishnan


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: sampledata.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130606/b6e65804/attachment.txt>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 1.png
Type: image/png
Size: 3263 bytes
Desc: 1.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130606/b6e65804/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 2.png
Type: image/png
Size: 4135 bytes
Desc: 2.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130606/b6e65804/attachment-0001.png>

From mfay at niaid.nih.gov  Wed Jun  5 17:43:45 2013
From: mfay at niaid.nih.gov (Fay, Michael (NIH/NIAID) [E])
Date: Wed, 5 Jun 2013 15:43:45 +0000
Subject: [R] [R-pkgs] update to interval package
Message-ID: <F064307CEF0BC64593398B58FBE7EC66536C57@MLBXV06.nih.gov>

Hi all,

I just uploaded an update to the interval package that does NPMLE estimates of survival distribution and weighted logrank tests for interval censored data.

The update now includes a confidence interval method for the survival that uses a modified bootstrap method.

Mike

******************************************************************
Michael P. Fay, PhD
Mathematical Statistician
National Institute of Allergy and Infectious Diseases
Tel: 301-451-5124               Fax:301-480-0912
(U.S. postal mail address)
6700B Rockledge Drive MSC 7609
Bethesda, MD 20892-7609
(Overnight mail address)
6700-A Rockledge Drive, Room 5133
Bethesda, MD 20817
http://www3.niaid.nih.gov/about/organization/dcr/BRB/staff/michael.htm
**********************************************************************
Disclaimer:
The information in this e-mail and any of its attachment...{{dropped:7}}


From mfay at niaid.nih.gov  Wed Jun  5 17:39:52 2013
From: mfay at niaid.nih.gov (Fay, Michael (NIH/NIAID) [E])
Date: Wed, 5 Jun 2013 15:39:52 +0000
Subject: [R] [R-pkgs] bpcp package for pointwise confidence intervals for a
 survival distribution
Message-ID: <F064307CEF0BC64593398B58FBE7EC66536C3F@MLBXV06.nih.gov>

Hi all,

I just uploaded a new version of the bpcp package.  It calculates confidence intervals for a survival distribution for right-censored data using the newly developed beta product confidence procedure.  Previously developed methods can have substantial error rate inflation for the lower limit, especially at the right end of the curves when there are small numbers of events.  The bpcp method guarantees coverage when there is no censoring (when it reduces to the exact Clopper-Pearson intervals for binomial data at each time) or when there is progressive type II censoring.  Simulations show at least nominal  coverage for independent censoring.  Also, it is fast so it can be used routinely.

For a complete description of the new method see

Fay, Brittain, and Proschan (2013). Pointwise confidence intervals for a survival distribution with small samples or heavy censoring. Biostatistics doi:10.1093/biostatistics/kxt016 (available at http://www.niaid.nih.gov/about/organization/dcr/brb/staff/Pages/michael.aspx ).


Mike

******************************************************************
Michael P. Fay, PhD
Mathematical Statistician
National Institute of Allergy and Infectious Diseases
Tel: 301-451-5124               Fax:301-480-0912
(U.S. postal mail address)
6700B Rockledge Drive MSC 7609
Bethesda, MD 20892-7609
(Overnight mail address)
6700-A Rockledge Drive, Room 5133
Bethesda, MD 20817
http://www3.niaid.nih.gov/about/organization/dcr/BRB/staff/michael.htm
**********************************************************************
Disclaimer:
The information in this e-mail and any of its attachment...{{dropped:7}}


From lgh0504 at gmail.com  Thu Jun  6 10:27:56 2013
From: lgh0504 at gmail.com (Michael Liu)
Date: Thu, 6 Jun 2013 16:27:56 +0800
Subject: [R] basic sweave question
In-Reply-To: <514C38FA.4030803@statistik.tu-dortmund.de>
References: <1252600554.47755951231819157630.JavaMail.javamailuser@localhost>
	<1359035322178-4656512.post@n4.nabble.com>
	<1363193716416-4661220.post@n4.nabble.com>
	<CA+xG9521dH99FCgec-sy8aQKcKi58cSJBta5ARTcYc=gi13bQQ@mail.gmail.com>
	<514C38FA.4030803@statistik.tu-dortmund.de>
Message-ID: <CA+xG9528B2-sJCqxmhJRnv1BehrZ-FB272N9X7_xKqS+yX2Q8g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130606/7173ff65/attachment.pl>

From leonard.moulin at gmail.com  Thu Jun  6 12:51:47 2013
From: leonard.moulin at gmail.com (Leonard Moulin)
Date: Thu, 6 Jun 2013 12:51:47 +0200
Subject: [R] Problem with marginal effects of a multinomial logistic
	regression
Message-ID: <CA8712BF-B415-4A66-8F4D-48AEE13355C9@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130606/6c47cd38/attachment.pl>

From daniel.ws at gmx.at  Thu Jun  6 13:17:51 2013
From: daniel.ws at gmx.at (danielw7)
Date: Thu, 6 Jun 2013 04:17:51 -0700 (PDT)
Subject: [R] Error invalid graphics state using text()
Message-ID: <1370517471571-4668809.post@n4.nabble.com>

I'm using ssplot for drawing a map of Austria and colour the nine provinces
regarding their share of employment. Now I wanted to add the figures in each
province and failed miserably. Using the locator() and text() function
caused the error message "invalid graphics state". I try to show you what I
have done below, maybe you can find a general fault in my codes. I know that
it's probably not the shortest way to the finishing line, but I'm a starter
and happy about every finish. ;) I'm really hoping for some helpful
comments!

library(maptools)
library(fields)
library(raster)
library(rgdal)
library(RColorBrewer)
library(rgeos)
library(pixmap)
library(classInt)
library(sp)
NUTS2<-readShapePoly("xxx.shp")
shareub2012 <- read.csv("xxx.csv", header=TRUE, sep = ";", dec =
",",stringsAsFactors=F)
mergeshareub2012 <- merge(shareub2012, NUTS2, by.x = "Bundesland", by.y =
"NAME" )
sortmergeshare2012 <- mergeshareub2012[order(mergeshareub2012$ID),]
col_no <- as.factor(as.numeric(cut(sortmergeshare2012$x, c(0, .075, .125,
.25, .50))))
levels(col_no) <- c("< 7,5%", "7,5-12,5%", "12,5-25%","> 25%")
sortmergeshare2012$col_no <- col_no
NUTS2$col_no <- col_no
myPalette<-brewer.pal(4,"Blues")
shareplot2012 <- spplot(NUTS2, "col_no", col="black", col.regions=myPalette,
                    par.settings=list(axis.line=list(col="transparent")))
shareplot2012
plot.new()
locator()
text(0.82421448,0.3897917,"12,41", cex=0.7)



--
View this message in context: http://r.789695.n4.nabble.com/Error-invalid-graphics-state-using-text-tp4668809.html
Sent from the R help mailing list archive at Nabble.com.


From njc72 at cam.ac.uk  Thu Jun  6 13:32:12 2013
From: njc72 at cam.ac.uk (nickDIL)
Date: Thu, 6 Jun 2013 04:32:12 -0700 (PDT)
Subject: [R] SnpMatrix super slow to access cells when large
Message-ID: <1370518332190-4668812.post@n4.nabble.com>

Dear snpStats users,

I'm working with a large SnpMatrix object (roughly 5000 samples x 200K snps)
and I've noticed using numerical accessors is extremely slow, e.g, see times
below, takes over 1.5 seconds to retrieve a single cell in SnpMatrix format
[1,1], versus 0.0 seconds to access the same datapoint in RAW format. It
also takes no longer (still 1.5s) to access an entire row or column [1,] or
[,1].

Is snpStats::SnpMatrix doing something unnecessary prior to returning the
matrix entry? [NB: 'chopsticks' seems to give the same slow result]

Is there any way around this delay other than copying the entire SnpMatrix
into RAW format? I want to access specific cell ranges many times in an
algorithm i'm writing and this would be excessively slow with access times
of 1.5s.

Code to show this below.

Many thanks,

N.

# generate raw matrix
rawd <- as.raw(sample(0:3,(10^9),replace=T)); dim(rawd) <- c(5000,200000)

# copy to a SnpMatrix object
snpd <- new("SnpMatrix",rawd)


# show class details
> class(snpd)
[1] "SnpMatrix"
attr(,"package")
[1] "snpStats"


# access times in SnpMatrix format

> system.time(snpd[1,])
   user  system elapsed 
  0.876   0.681   1.554 
> system.time(snpd[1,1])
   user  system elapsed 
  0.872   0.668   1.538 
> system.time(snpd[,1])
   user  system elapsed 
  0.896   0.644   1.540 



# access times in raw format

> system.time(rawd[1,])
   user  system elapsed 
  0.012   0.004   0.011 
> system.time(rawd[,1])
   user  system elapsed 
      0       0       0 
> system.time(rawd[1,1])
   user  system elapsed 
      0       0       0 





--
View this message in context: http://r.789695.n4.nabble.com/SnpMatrix-super-slow-to-access-cells-when-large-tp4668812.html
Sent from the R help mailing list archive at Nabble.com.


From daniel.ws at gmx.at  Thu Jun  6 13:36:40 2013
From: daniel.ws at gmx.at (Daniel Wagner)
Date: Thu, 6 Jun 2013 13:36:40 +0200 (CEST)
Subject: [R] Error invalid graphics state using text()
Message-ID: <trinity-34a71ef2-1526-436c-bc92-45345c401c2e-1370518600241@3capp-gmx-bs16>


   Hi all!

   I'm using ssplot for drawing a map of Austria and colour the nine provinces
   regarding their share of employment. Now I wanted to add the figures in each
   province and failed miserably. Using the locator() and text() function
   caused the error message "invalid graphics state". I try to show you what I
   have done below, maybe you can find a general fault in my codes. I know that
   it's probably not the shortest way to the finishing line, but I'm a starter
   and  happy  about  every finish. ;) I'm really hoping for some helpful
   comments!

library(maptools)
library(fields)
library(raster)
library(rgdal)
library(RColorBrewer)
library(rgeos)
library(pixmap)
library(classInt)
library(sp)
NUTS2<-readShapePoly("xxx.shp")
shareub2012 <- read.csv("xxx.csv", header=TRUE, sep = ";", dec = ",",stringsAsF
actors=F)
mergeshareub2012 <- merge(shareub2012, NUTS2, by.x = "Bundesland", by.y = "NAME
" )
sortmergeshare2012 <- mergeshareub2012[order(mergeshareub2012$ID),]
col_no <- as.factor(as.numeric(cut(sortmergeshare2012$x, c(0, .075, .125, .25, 
.50))))
levels(col_no) <- c("< 7,5%", "7,5-12,5%", "12,5-25%","> 25%")
sortmergeshare2012$col_no <- col_no
NUTS2$col_no <- col_no
myPalette<-brewer.pal(4,"Blues")
shareplot2012 <- spplot(NUTS2, "col_no", col="black", col.regions=myPalette,
                    par.settings=list(axis.line=list(col="transparent")))
shareplot2012
plot.new()
locator()
text(0.82421448,0.3897917,"12,41", cex=0.7)

From kota.hattori at canterbury.ac.nz  Thu Jun  6 13:59:30 2013
From: kota.hattori at canterbury.ac.nz (Kota Hattori)
Date: Thu, 06 Jun 2013 23:59:30 +1200
Subject: [R] Post hoc power analysis for mixed-effects models
References: <482B1843EE6C72459D3BD633C43679EA04447F54@ucexchange2.canterbury.ac.nz>
	<C1688010-B655-493F-8D5F-B6F5F47C07C8@comcast.net>
Message-ID: <482B1843EE6C72459D3BD633C43679EA04447F59@ucexchange2.canterbury.ac.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130606/2eaeefd1/attachment.pl>

From smartpink111 at yahoo.com  Thu Jun  6 15:41:33 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 6 Jun 2013 06:41:33 -0700 (PDT)
Subject: [R] Loop through variables and estimate effects on several
	outcomes
Message-ID: <1370526093.8373.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
Try:
hsb2 <- read.csv("http://www.ats.ucla.edu/stat/data/hsb2.csv")

varlist<-names(hsb2)[8:10]
fun2<- function(varName){
??? res<- sapply(varName,function(x){
??? ??? ??? ? model1<- lm(substitute(cbind(female,race,ses)~i,list(i=as.name(x))),data=hsb2)
??? ??? ????????? sM<- summary(model1)
??? ??? ??? ? sapply(sM,function(x) x$coef[2,1])??? ??? ?? 
??? ??? ??? ?})
??? ??? ??? res 
??????????????????????? }??? ???? 

?fun2(varlist)
#???????????????????? write???????? math????? science
#Response female 0.01350896 -0.001563341 -0.006441112
#Response race?? 0.02412624? 0.022474213? 0.033622966
#Response ses??? 0.01585530? 0.021064315? 0.020692042

A.K.

>This post has NOT been accepted by the mailing list yet. 
>I want to estimate the effects of an exposure on several outcomes. The example in this link provides how to loop though variables which are 
>explanatory variables. ?http://www.ats.ucla.edu/stat/r/pages/looping_strings.htm
>The
 example below estimates the effects of several variables on read. ?But I
 want to estimate the effect of ?"female" , "race" ?, ?"ses" ?on 
?"write" ,? >"math" ? ?"science" ? one at a time using the hsb data set. 
?How can I loop through these outcomes? 
>varlist <- names(hsb2)[8:11] 
>models <- lapply(varlist, function(x) { 
?> lm(substitute(read ~ i, list(i = as.name(x))), data = hsb2) 
>})


From bhh at xs4all.nl  Thu Jun  6 16:04:00 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 6 Jun 2013 16:04:00 +0200
Subject: [R] combining two different matrizes
In-Reply-To: <1370469376981-4668766.post@n4.nabble.com>
References: <1370469376981-4668766.post@n4.nabble.com>
Message-ID: <9887E730-C27B-468E-AF83-8713F4E5C3F5@xs4all.nl>


On 05-06-2013, at 23:56, ThomasH <thomas.hufnagel1 at gmx.de> wrote:

> 
> Hello together,
> 
> this is ma first post, so please aplogize me if post this in the wrong
> section.
> 
> I have problem concerning ma two matrizes.
> 
> After a regressione and so on, I got two matrizes
> 
> Matrixres contains the results of ma calculation.
> 
> Matrixr contains my detiene, which where Aldo used for the regression.
> 
> Please ser the following code:
> 
> #Datei einlesen
> residual = read.csv2("E:***Input-R_Renditen.csv",header=TRUE, sep=";")
> 
> 
> #Aktientitel
> alist <- list()
> for (a in 2:11){
> 
> 
> #Regression
>    #L?nge Gesamtzeit
>    t <- 243
>    tx <- t-59
> 
>    #L?nge Regression
>    reglist <- list()
>    for (i in 1:tx){
>    j <- i+59
> 
>    #RegressionsVariable
>    x = residual[i:j,a]
>    rm = residual[i:j,12]
>    smb = residual[i:j,13]
>    hml = residual[i:j,14]
>    rf = residual[i:j,15]
> 
>    #?berschussrenditen
>    ex=x-rf
>    erm=rm-rf
> 
>    #Regression
>    reg <- lm(ex~erm+smb+hml)
>    reglist[[i]] <- coef(reg)
>    
> 
> #Berechnung Residuum
>       #Residual Berechnung
>       rx = residual[(j-5):j,a]
>       rrm = residual[(j-5):j,12]
>       rsmb = residual[(j-5):j,13]
>       rhml = residual[(j-5):j,14]
>       rrf = residual[(j-5):j,15]
> 
>       rex = rx-rrf
>       rerm = rrm-rrf
> 
>       #Berechnung
>       res <-
> sum(rex-(reglist[[i]][2]*rerm+reglist[[i]][3]*rsmb+reglist[[i]][4]*rhml))/sd(rex-(reglist[[i]][2]*rerm+reglist[[i]][3]*rsmb+reglist[[i]][4]*rhml))
>       reglist[[i]] <- res
> }   
>    
> 
> #Residuen auf alle Aktien
>    alist[[a]] <- reglist
> }
>    
> #Matrix mit Residuen
>    matrixres <- do.call(cbind,alist)
> 
> #Spaltennamen/Zeilennamen
> s<- names(residual)[2:11]
> colnames(matrixres)<-s
> 
> #RenditeMatrix
> matrixr <- do.call(cbind,residual[60:243,2:11])
> 
> 
> Now I want to combines  the two matrizes in the following way:
> 
> Under every row of matrixres should stand the row of matrixr for excample:
> 
> Matrixres row1
> Matrixr row1
> Matrixres row2
> Matrixr row 2
> 
> Can anybody help me? I was working on this problem the whole day, but have
> no idea.

Something like this (assuming A and B have the same dimensions)

set.seed(11)
A <- matrix(round(rnorm(25),3),nrow=5)
B <- matrix(1:25,nrow=5)

C <- matrix(0,nrow=2*nrow(A),ncol=ncol(A))

crows <- seq.int(from=1,to=2*nrow(A),by=2)
C[crows,] <- A
C[crows+1,] <- B

Some friendly advice: get someone to check your English before sending a mail to the list.

Berend


From hoferr at ee.ethz.ch  Thu Jun  6 16:12:54 2013
From: hoferr at ee.ethz.ch (Ramon Hofer)
Date: Thu, 6 Jun 2013 16:12:54 +0200
Subject: [R] Autocorrelation and normal distribution of gaps for ping
 requests in an unstable network
Message-ID: <20130606161254.1c1b7c35@rhofer-debian-7-64>

Hi all

I have a powerline network connection which I'm investigating.
The test network contains some nodes to which I ping from one host.
The source host is always the same and I split the data to get files
for each connection.
A lot of ping requests get lost and I'm trying to plot an
autocorrelation of the data.

Here's an example log:
http://people.ee.ethz.ch/~hoferr/download/data-20130603-192.168.72.33.csv

I tried to plot the autocorrelation graph:
 acf(A$pingRTT.ms.)
which didn't work because of missing ping values. I found a post at
stackoverflow [1] where they suggest to use coredata which didn't work
for me. They also suggest to use "na.action = na.omit" or "na.action =
na.pass". The second option works for me.

With these two commands I can draw an autocorrelation graph.
 A <- read.csv('data-20130603-192.168.72.33.csv')
 acf(A$pingRTT.ms., na.action = na.pass)

But they also warn that:
"acf works on regularly spaced data so acf first expands the time
series to a regularly spaced one inserting NAs as needed to make it
regularly spaced."
This seems to me as if it introduces new periods of time where there's
no ping value and thus no connection which means the autocorrelation
graph I get is nonsense.
Is my fear for no reason or is there a way to get a meaningful plot?


I'd also like to plot a histogram with normal curve like the example
from statmethods [2].
In their example they have the data directly available.
In my case I need to prepare my data to get a list of gaps. E.g.

 TimestampStart,GapLength
 2013-06-03_15:20:25.374096766,16.2s
 2013-06-03_15:22:13.944293504,37.5s
 ...

My plan is to program a loop like

 A$Timestamp <- strptime(as.character(A$Timestamp), "%Y-%m-%d_%H:%M:%S")
 B <- matrix(nrow = 0, ncol = 2)
 colnames(B) <- c("TimestampStart","GapLength[s]")
 j <- 1
 gap.start <- A$Timestamp[0]
 for(i in 2:length(A$Timestamp)) 
 { #For all rows
  if(is.na(A$pingRTT.ms.[i]))
  { #Currently no connection
   if(!is.na(A$pingRTT.ms.[i-1]))
   { #Connection lost now
    gap.start <- i
   } 
   else if(!is.na(A$pingRTT.ms.[i+1])) 
   { # Connection restores next time
    gap.end <- i+1
    B <-
     rbind( B,
      c(
       A$Timestamp[gap.start],
       A$Timestamp[gap.end]-A$Timestamp[gap.start]
      ) 
     ) 
   }
  } 
 }
 x <- B$GapLength
 h<-hist(x, xlab="Gap Length [s?]", 

There's a problem with the rbind function which I'm using wrong.
Is this the right approach and could you please give me a hint on how
to add the line?
Or is there a better way to achieve this?


Best
Ramon


[1]
http://stackoverflow.com/questions/7309411/how-to-calculate-autocorrelation-in-r-zoo-object

[2]
http://www.statmethods.net/graphs/images/histogram3.jpg


From istazahn at gmail.com  Thu Jun  6 16:15:45 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 6 Jun 2013 10:15:45 -0400
Subject: [R] SPlus script
In-Reply-To: <1370523739.92423.YahooMailNeo@web142703.mail.bf1.yahoo.com>
References: <1370438435.93923.YahooMailNeo@web142703.mail.bf1.yahoo.com>
	<E66794E69CFDE04D9A70842786030B931C2FD5C4@PA-MBX01.na.tibco.com>
	<1370523739.92423.YahooMailNeo@web142703.mail.bf1.yahoo.com>
Message-ID: <CA+vqiLGCTXQDEzzbeZDf-_EddiGQ=xx4P9n_3EJ2HkN1-qTMQg@mail.gmail.com>

Presumably something like

r <- sshc(50)
print(r)

But if you were getting output before than you already have a script
that does something like this. It would be better to find it...

Best,
Ista

On Thu, Jun 6, 2013 at 9:02 AM, Scott Raynaud <scott.raynaud at yahoo.com> wrote:
> Ok.  Now I see that the sshc function is not being called.  Thanks for pointing that out.
> I'm not certain about the solution, however.  I tried putting call("sshc") at the end of the
> program, but nothing happened.  My memory about all of this is fuzzy.  Suggestions
> on how to call the function appreciated.
>
> ----- Original Message -----
> From: William Dunlap <wdunlap at tibco.com>
> To: Scott Raynaud <scott.raynaud at yahoo.com>; "r-help at r-project.org" <r-help at r-project.org>
> Cc:
> Sent: Wednesday, June 5, 2013 2:17 PM
> Subject: RE: [R] SPlus script
>
> Both the R and S+ versions (which seem to differ only in the use of _ for assignment
> in the S+ version) do nothing but define some functions.  You would not expect any
> printed output unless you used those functions on some data.  Is there another script
> that does that?
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
>> Of Scott Raynaud
>> Sent: Wednesday, June 05, 2013 6:21 AM
>> To: r-help at r-project.org
>> Subject: [R] SPlus script
>>
>> This originally was an SPlus script that I modifeid about a year-and-a-half ago.  It worked
>> perfectly then.  Now I can't get any output despite not receiving an error message.  I'm
>> providing the SPLUS script as a reference.  I'm running R15.2.2.  Any help appreciated.
>>
>> ************************************MY
>> MODIFICATION***********************************************************
>> **********
>> ## sshc.ssc: sample size calculation for historical control studies
>> ## J. Jack Lee (jjlee at mdanderson.org) and Chi-hong Tseng
>> ## Department of Biostatistics, Univ. of Texas M.D. Anderson Cancer Center
>> ##
>> ## 3/1/99
>> ## updated 6/7/00: add loess
>> ##------------------------------------------------------------------
>> ######## Required Input:
>> #
>> # rc     number of response in historical control group
>> # nc     sample size in historical control
>> # d      target improvement = Pe - Pc
>> # method 1=method based on the randomized design
>> #        2=Makuch & Simon method (Makuch RW, Simon RM. Sample size considerations
>> #          for non-randomized comparative studies. J of Chron Dis 1980; 3:175-181.
>> #        3=uniform power method
>> ######## optional Input:
>> #
>> # alpha  size of the test
>> # power  desired power of the test
>> # tol    convergence criterion for methods 1 & 2 in terms of sample size
>> # tol1   convergence criterion for method 3 at any given obs Rc in terms of difference
>> #          of expected power from target
>> # tol2   overall convergence criterion for method 3 as the max absolute deviation
>> #          of expected power from target for all Rc
>> # cc     range of multiplicative constant applied to the initial values ne
>> # l.span smoothing constant for loess
>> #
>> # Note:  rc is required for methods 1 and 2 but not 3
>> #        method 3 return the sample size need for rc=0 to (1-d)*nc
>> #
>> ######## Output
>> # for methdos 1 & 2: return the sample size needed for the experimental group (1
>> number)
>> #                    for given rc, nc, d, alpha, and power
>> # for method 3:      return the profile of sample size needed for given nc, d, alpha, and
>> power
>> #                    vector $ne contains the sample size corresponding to rc=0, 1, 2, ... nc*(1-d)
>> #                    vector $Ep contains the expected power corresponding to
>> #                      the true pc = (0, 1, 2, ..., nc*(1-d)) / nc
>> #
>> #------------------------------------------------------------------
>> sshc<-function(rc, nc=1092, d=.085779816, method=3, alpha=0.05, power=0.8,
>>               tol=0.01, tol1=.0001, tol2=.005, cc=c(.1,2), l.span=.5)
>> {
>> ### for method 1
>> if (method==1) {
>>  ne1<-ss.rand(rc,nc,d,alpha=.05,power=.8,tol=.01)
>>  return(ne=ne1)
>>                }
>> ### for method 2
>> if (method==2) {
>> ne<-nc
>> ne1<-nc+50
>> while(abs(ne-ne1)>tol & ne1<100000){
>> ne<-ne1
>> pe<-d+rc/nc
>> ne1<-nef(rc,nc,pe*ne,ne,alpha,power)
>> ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
>> }
>> if (ne1>100000) return(NA)
>> else return(ne=ne1)
>> }
>> ### for method 3
>> if (method==3) {
>> if (tol1 > tol2/10) tol1<-tol2/10
>> ncstar<-(1-d)*nc
>> pc<-(0:ncstar)/nc
>> ne<-rep(NA,ncstar + 1)
>> for (i in (0:ncstar))
>> { ne[i+1]<-ss.rand(i,nc,d,alpha=.05,power=.8,tol=.01)
>> }
>> plot(pc,ne,type='l',ylim=c(0,max(ne)*1.5))
>> ans<-c.searchd(nc, d, ne, alpha, power, cc, tol1)
>> ### check overall absolute deviance
>> old.abs.dev<-sum(abs(ans$Ep-power))
>> ##bad<-0
>> print(round(ans$Ep,4))
>> print(round(ans$ne,2))
>> lines(pc,ans$ne,lty=1,col=8)
>> old.ne<-ans$ne
>> ##while(max(abs(ans$Ep-power))>tol2 & bad==0){  #### unnecessary ##
>> while(max(abs(ans$Ep-power))>tol2){
>> ans<-c.searchd(nc, d, ans$ne, alpha, power, cc, tol1)
>> abs.dev<-sum(abs(ans$Ep-power))
>> print(paste(" old.abs.dev=",old.abs.dev))
>> print(paste("     abs.dev=",abs.dev))
>> ##if (abs.dev > old.abs.dev) { bad<-1}
>> old.abs.dev<-abs.dev
>> print(round(ans$Ep,4))
>> print(round(ans$ne,2))
>> lines(pc,old.ne,lty=1,col=1)
>> lines(pc,ans$ne,lty=1,col=8)
>> ### add convex
>> ans$ne<-convex(pc,ans$ne)$wy
>> ### add loess
>> ###old.ne<-ans$ne
>> loess.ne<-loess(ans$ne ~ pc, span=l.span)
>> lines(pc,loess.ne$fit,lty=1,col=4)
>> old.ne<-loess.ne$fit
>> ###readline()
>> }
>> return(list(ne=ans$ne, Ep=ans$Ep))
>>                }
>> }
>> ## needed for method 1
>> nef2<-function(rc,nc,re,ne,alpha,power){
>> za<-qnorm(1-alpha)
>> zb<-qnorm(power)
>> xe<-asin(sqrt((re+0.375)/(ne+0.75)))
>> xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
>> ans<- 1/(4*(xc-xe)^2/(za+zb)^2-1/(nc+0.5)) - 0.5
>> return(ans)
>> }
>> ## needed for method 2
>> nef<-function(rc,nc,re,ne,alpha,power){
>> za<-qnorm(1-alpha)
>> zb<-qnorm(power)
>> xe<-asin(sqrt((re+0.375)/(ne+0.75)))
>> xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
>> ans<-(za*sqrt(1+(ne+0.5)/(nc+0.5))+zb)^2/(2*(xe-xc))^2-0.5
>> return(ans)
>> }
>> ## needed for method 3
>> c.searchd<-function(nc, d, ne, alpha=0.05, power=0.8, cc=c(0.1,2),tol1=0.0001){
>> #---------------------------
>> # nc     sample size of control group
>> # d      the differece to detect between control and experiment
>> # ne     vector of starting sample size of experiment group
>> #      corresonding to rc of 0 to nc*(1-d)
>> # alpha  size of test
>> # power  target power
>> # cc   pre-screen vector of constant c, the range should cover the
>> #      the value of cc that has expected power
>> # tol1   the allowance between the expceted power and target power
>> #---------------------------
>> pc<-(0:((1-d)*nc))/nc
>> ncl<-length(pc)
>> ne.old<-ne
>> ne.old1<-ne.old
>> ### sweeping forward
>> for(i in 1:ncl){
>>  cmin<-cc[1]
>>  cmax<-cc[2]
>> ### fixed cci<-cmax bug
>>  cci <-1
>>  lhood<-dbinom((i:ncl)-1,nc,pc[i])
>>  ne[i:ncl]<-(1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
>>  Ep0 <-Epower(nc, d, ne, pc, alpha)
>>  while(abs(Ep0[i]-power)>tol1){
>>   if(Ep0[i]<power) cmin<-cci
>>   else cmax<-cci
>>   cci<-(cmax+cmin)/2
>>   ne[i:ncl]<-(1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
>>   Ep0<-Epower(nc, d, ne, pc, alpha)
>>  }
>>   ne.old1<-ne
>> }
>> ne1<-ne
>> ### sweeping backward -- ncl:i
>> ne.old2<-ne.old
>> ne     <-ne.old
>> for(i in ncl:1){
>>  cmin<-cc[1]
>>  cmax<-cc[2]
>> ### fixed cci<-cmax bug
>>  cci <-1
>>  lhood<-dbinom((ncl:i)-1,nc,pc[i])
>>  lenl <-length(lhood)
>>  ne[ncl:i]<-(1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
>>  Ep0 <-Epower(nc, d, cci*ne, pc, alpha)
>>  while(abs(Ep0[i]-power)>tol1){
>>   if(Ep0[i]<power) cmin<-cci
>>   else cmax<-cci
>>   cci<-(cmax+cmin)/2
>>   ne[ncl:i]<-(1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
>>   Ep0<-Epower(nc, d, ne, pc, alpha)
>>  }
>>   ne.old2<-ne
>> }
>> ne2<-ne
>> ne<-(ne1+ne2)/2
>> #cat(ccc*ne)
>> Ep1<-Epower(nc, d, ne, pc, alpha)
>> return(list(ne=ne, Ep=Ep1))
>> }
>> ###
>> vertex<-function(x,y)
>> {  n<-length(x)
>>  vx<-x[1]
>>  vy<-y[1]
>>  vp<-1
>>  up<-T
>>  for (i in (2:n))
>>  { if (up)
>>   {  if (y[i-1] > y[i])
>>    {vx<-c(vx,x[i-1])
>>     vy<-c(vy,y[i-1])
>>     vp<-c(vp,i-1)
>>     up<-F
>>    }
>>   }
>>   else
>>   {  if (y[i-1] < y[i]) up<-T
>>   }
>>  }
>>  vx<-c(vx,x[n])
>>  vy<-c(vy,y[n])
>>  vp<-c(vp,n)
>>  return(list(vx=vx,vy=vy,vp=vp))
>> }
>> ###
>> convex<-function(x,y)
>> {
>>  n<-length(x)
>>  ans<-vertex(x,y)
>>  len<-length(ans$vx)
>>  while (len>3)
>>  {
>> #  cat("x=",x,"\n")
>> #  cat("y=",y,"\n")
>>   newx<-x[1:(ans$vp[2]-1)]
>>   newy<-y[1:(ans$vp[2]-1)]
>>   for (i in (2:(len-1)))
>>   {
>>     newx<-c(newx,x[ans$vp[i]])
>>    newy<-c(newy,y[ans$vp[i]])
>>   }
>>   newx<-c(newx,x[(ans$vp[len-1]+1):n])
>>   newy<-c(newy,y[(ans$vp[len-1]+1):n])
>>   y<-approx(newx,newy,xout=x)$y
>> #  cat("new y=",y,"\n")
>>   ans<-vertex(x,y)
>>   len<-length(ans$vx)
>> #  cat("vx=",ans$vx,"\n")
>> #  cat("vy=",ans$vy,"\n")
>> }
>>  return(list(wx=x,wy=y))}
>> ###
>> Epower<-function(nc, d, ne, pc = (0:((1 - d) * nc))/nc, alpha = 0.05)
>> {
>> #-------------------------------------
>> # nc     sample size in historical control
>> # d      the increase of response rate between historical and experiment
>> # ne     sample size of corresonding rc of 0 to nc*(1-d)
>> # pc     the response rate of control group, where we compute the
>> #        expected power
>> # alpha  the size of test
>> #-------------------------------------
>>  kk <- length(pc)
>>  rc <- 0:(nc * (1 - d))
>>  pp <- rep(NA, kk)
>>  ppp <- rep(NA, kk)
>>  for(i in 1:(kk)) {
>>   pe <- pc[i] + d
>>   lhood <- dbinom(rc, nc, pc[i])
>>   pp <- power1.f(rc, nc, ne, pe, alpha)
>>   ppp[i] <- sum(pp * lhood)/sum(lhood)
>>  }
>>  return(ppp)
>> }
>> # adapted from the old biss2
>> ss.rand<-function(rc,nc,d,alpha=.05,power=.8,tol=.01)
>> {
>> ne<-nc
>> ne1<-nc+50
>> while(abs(ne-ne1)>tol & ne1<100000){
>> ne<-ne1
>> pe<-d+rc/nc
>> ne1<-nef2(rc,nc,pe*ne,ne,alpha,power)
>> ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
>> }
>> if (ne1>100000) return(NA)
>> else return(ne1)
>> }
>> ###
>> power1.f<-function(rc,nc,ne,pie,alpha=0.05){
>> #-------------------------------------
>> # rc number of response in historical control
>> # nc sample size in historical control
>> # ne    sample size in experitment group
>> # pie true response rate for experiment group
>> # alpha size of the test
>> #-------------------------------------
>> za<-qnorm(1-alpha)
>> re<-ne*pie
>> xe<-asin(sqrt((re+0.375)/(ne+0.75)))
>> xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
>> ans<-za*sqrt(1+(ne+0.5)/(nc+0.5))-(xe-xc)/sqrt(1/(4*(ne+0.5)))
>> return(1-pnorm(ans))
>> }
>>
>>
>>
>> *************************************ORIGINAL SPLUS
>> SCRIPT************************************************************
>> ## sshc.ssc: sample size calculation for historical control studies
>> ## J. Jack Lee (jjlee at mdanderson.org) and Chi-hong Tseng
>> ## Department of Biostatistics, Univ. of Texas M.D. Anderson Cancer Center
>> ##
>> ## 3/1/99
>> ## updated 6/7/00: add loess
>> ##------------------------------------------------------------------
>> ######## Required Input:
>> #
>> # rc    number of response in historical control group
>> # nc    sample size in historical control
>> # d      target improvement = Pe - Pc
>> # method 1=method based on the randomized design
>> #        2=Makuch & Simon method (Makuch RW, Simon RM. Sample size considerations
>> #          for non-randomized comparative studies. J of Chron Dis 1980; 3:175-181.
>> #        3=uniform power method
>> ######## optional Input:
>> #
>> # alpha  size of the test
>> # power  desired power of the test
>> # tol    convergence criterion for methods 1 & 2 in terms of sample size
>> # tol1  convergence criterion for method 3 at any given obs Rc in terms of
>>  difference
>> #          of expected power from target
>> # tol2  overall convergence criterion for method 3 as the max absolute deviation
>> #          of expected power from target for all Rc
>> # cc    range of multiplicative constant applied to the initial values ne
>> # l.span smoothing constant for loess
>> #
>> # Note:  rc is required for methods 1 and 2 but not 3
>> #        method 3 return the sample size need for rc=0 to (1-d)*nc
>> #
>> ######## Output
>> # for methdos 1 & 2: return the sample size needed for the experimental group (1
>> number)
>> #                    for given rc, nc, d, alpha, and power
>> # for method 3:      return the profile of sample size needed for given nc, d, alpha, and
>> power
>> #                    vector $ne contains the sample size corresponding to rc=0, 1, 2, ... nc*(1-d)
>> #                    vector $Ep contains the expected power corresponding to
>> #                      the true pc = (0, 1, 2, ..., nc*(1-d)) / nc
>> #
>>
>> #------------------------------------------------------------------
>> sshc _ function(rc, nc, d, method, alpha=0.05, power=0.8,
>>                 tol=0.01, tol1=.0001, tol2=.005, cc=c(.1,2), l.span=.5)
>> {
>> ### for method 1
>> if (method==1) {
>>     ne1 _ ss.rand(rc,nc,d,alpha=.05,power=.8,tol=.01)
>>     return(ne=ne1)
>>                }
>> ### for method 2
>> if (method==2) {
>> ne_nc
>> ne1_nc+50
>> while(abs(ne-ne1)>tol & ne1<100000){
>> ne_ne1
>> pe_d+rc/nc
>> ne1_nef(rc,nc,pe*ne,ne,alpha,power)
>> ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
>> }
>> if (ne1>100000) return(NA)
>> else return(ne=ne1)
>> }
>> ### for method 3
>> if (method==3) {
>> if (tol1 > tol2/10) tol1_tol2/10
>> ncstar _ (1-d)*nc
>> pc_(0:ncstar)/nc
>> ne _ rep(NA,ncstar + 1)
>> for (i in (0:ncstar))
>> { ne[i+1] _ ss.rand(i,nc,d,alpha=.05,power=.8,tol=.01)
>> }
>> plot(pc,ne,type='l',ylim=c(0,max(ne)*1.5))
>> ans_c.searchd(nc, d, ne, alpha, power, cc, tol1)
>> ### check overall absolute deviance
>> old.abs.dev _ sum(abs(ans$Ep-power))
>> ##bad
>>  _ 0
>> print(round(ans$Ep,4))
>> print(round(ans$ne,2))
>> lines(pc,ans$ne,lty=1,col=8)
>> old.ne _ ans$ne
>> ##while(max(abs(ans$Ep-power))>tol2 & bad==0){  #### unnecessary ##
>> while(max(abs(ans$Ep-power))>tol2){
>> ans_c.searchd(nc, d, ans$ne, alpha, power, cc, tol1)
>> abs.dev _ sum(abs(ans$Ep-power))
>> print(paste(" old.abs.dev=",old.abs.dev))
>> print(paste("    abs.dev=",abs.dev))
>> ##if (abs.dev > old.abs.dev) { bad _ 1}
>> old.abs.dev _ abs.dev
>> print(round(ans$Ep,4))
>> print(round(ans$ne,2))
>> lines(pc,old.ne,lty=1,col=1)
>> lines(pc,ans$ne,lty=1,col=8)
>> ### add convex
>> ans$ne _ convex(pc,ans$ne)$wy
>> ### add loess
>> ###old.ne _ ans$ne
>> loess.ne _ loess(ans$ne ~ pc, span=l.span)
>> lines(pc,loess.ne$fit,lty=1,col=4)
>> old.ne _ loess.ne$fit
>> ###readline()
>> }
>> return(ne=ans$ne, Ep=ans$Ep)
>>                }
>> }
>>
>> ## needed for method 1
>> nef2_function(rc,nc,re,ne,alpha,power){
>> za_qnorm(1-alpha)
>> zb_qnorm(power)
>> xe_asin(sqrt((re+0.375)/(ne+0.75)))
>> xc_asin(sqrt((rc+0.375)/(nc+0.75)))
>> ans_
>>  1/(4*(xc-xe)^2/(za+zb)^2-1/(nc+0.5)) - 0.5
>> return(ans)
>> }
>> ## needed for method 2
>> nef_function(rc,nc,re,ne,alpha,power){
>> za_qnorm(1-alpha)
>> zb_qnorm(power)
>> xe_asin(sqrt((re+0.375)/(ne+0.75)))
>> xc_asin(sqrt((rc+0.375)/(nc+0.75)))
>> ans_(za*sqrt(1+(ne+0.5)/(nc+0.5))+zb)^2/(2*(xe-xc))^2-0.5
>> return(ans)
>> }
>> ## needed for method 3
>> c.searchd_function(nc, d, ne, alpha=0.05, power=0.8, cc=c(0.1,2),tol1=0.0001){
>> #---------------------------
>> # nc    sample size of control group
>> # d      the differece to detect between control and experiment
>> # ne    vector of starting sample size of experiment group
>> #            corresonding to rc of 0 to nc*(1-d)
>> # alpha  size of test
>> # power  target power
>> # cc      pre-screen vector of constant c, the range should cover the
>> #            the value of cc that has expected power
>> # tol1  the allowance between the expceted power and target power
>> #---------------------------
>> pc_(0:((1-d)*nc))/nc
>> ncl _ length(pc)
>> ne.old _ ne
>> ne.old1 _ ne.old
>> ###
>>  sweeping forward
>> for(i in 1:ncl){
>>     cmin _ cc[1]
>>     cmax _ cc[2]
>> ### fixed cci_cmax bug
>>     cci  _ 1
>>     lhood _ dbinom((i:ncl)-1,nc,pc[i])
>>     ne[i:ncl] _ (1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
>>     Ep0  _ Epower(nc, d, ne, pc, alpha)
>>     while(abs(Ep0[i]-power)>tol1){
>>         if(Ep0[i]<power) cmin_cci
>>         else cmax_cci
>>         cci_(cmax+cmin)/2
>>         ne[i:ncl] _ (1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
>>         Ep0_Epower(nc, d, ne, pc, alpha)
>>     }
>>      ne.old1 _ ne
>> }
>> ne1 _ ne
>> ### sweeping backward -- ncl:i
>> ne.old2 _ ne.old
>> ne      _ ne.old
>> for(i in ncl:1){
>>     cmin _ cc[1]
>>     cmax _ cc[2]
>> ### fixed cci_cmax bug
>>     cci  _ 1
>>     lhood _ dbinom((ncl:i)-1,nc,pc[i])
>>     lenl  _ length(lhood)
>>     ne[ncl:i] _ (1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
>>     Ep0  _ Epower(nc, d, cci*ne, pc, alpha)
>>     while(abs(Ep0[i]-power)>tol1){
>>         if(Ep0[i]<power) cmin_cci
>>         else cmax_cci
>>         cci_(cmax+cmin)/2
>>         ne[ncl:i] _ (1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
>>         Ep0_Epower(nc, d, ne, pc, alpha)
>>     }
>>      ne.old2 _ ne
>> }
>>
>> ne2 _ ne
>> ne _ (ne1+ne2)/2
>> #cat(ccc*ne)
>> Ep1_Epower(nc, d, ne, pc, alpha)
>> return(ne=ne, Ep=Ep1)
>> }
>> ###
>> vertex _ function(x,y)
>> {     n _ length(x)
>>     vx _ x[1]
>>     vy _ y[1]
>>     vp _ 1
>>     up _ T
>>     for (i in (2:n))
>>     { if (up)
>>         {     if (y[i-1] > y[i])
>>             {vx _ c(vx,x[i-1])
>>             vy _ c(vy,y[i-1])
>>             vp _ c(vp,i-1)
>>             up _ F
>>             }
>>         }
>>         else
>>         {     if (y[i-1] < y[i]) up _ T
>>         }
>>     }
>>     vx _ c(vx,x[n])
>>     vy _ c(vy,y[n])
>>     vp _ c(vp,n)
>>     return(vx=vx,vy=vy,vp=vp)
>> }
>> ###
>> convex _ function(x,y)
>> {
>>     n _ length(x)
>>     ans _ vertex(x,y)
>>     len _ length(ans$vx)
>>     while (len>3)
>>     {
>> #        cat("x=",x,"\n")
>> #        cat("y=",y,"\n")
>>         newx _ x[1:(ans$vp[2]-1)]
>>         newy _ y[1:(ans$vp[2]-1)]
>>         for (i in (2:(len-1)))
>>         {
>>             newx _ c(newx,x[ans$vp[i]])
>>             newy _ c(newy,y[ans$vp[i]])
>>         }
>>         newx _ c(newx,x[(ans$vp[len-1]+1):n])
>>         newy _ c(newy,y[(ans$vp[len-1]+1):n])
>>         y _ approx(newx,newy,xout=x)$y
>> #        cat("new y=",y,"\n")
>>         ans _ vertex(x,y)
>>         len _ length(ans$vx)
>> #        cat("vx=",ans$vx,"\n")
>> #        cat("vy=",ans$vy,"\n")
>>
>> }
>>     return(wx=x,wy=y)}
>> ###
>> Epower _ function(nc, d, ne, pc = (0:((1 - d) * nc))/nc, alpha = 0.05)
>> {
>> #-------------------------------------
>> # nc    sample size in historical control
>> # d      the increase of response rate between historical and experiment
>> # ne    sample size of corresonding rc of 0 to nc*(1-d)
>> # pc    the response rate of control group, where we compute the
>> #        expected power
>> # alpha  the size of test
>> #-------------------------------------
>>     kk <- length(pc)
>>     rc <- 0:(nc * (1 - d))
>>     pp <- rep(NA, kk)
>>     ppp <- rep(NA, kk)
>>     for(i in 1:(kk)) {
>>         pe <- pc[i] + d
>>         lhood <- dbinom(rc, nc, pc[i])
>>         pp <- power1.f(rc, nc, ne, pe, alpha)
>>         ppp[i] <- sum(pp * lhood)/sum(lhood)
>>     }
>>     return(ppp)
>> }
>>
>> # adapted from the old biss2
>> ss.rand _ function(rc,nc,d,alpha=.05,power=.8,tol=.01)
>> {
>> ne_nc
>> ne1_nc+50
>> while(abs(ne-ne1)>tol & ne1<100000){
>> ne_ne1
>> pe_d+rc/nc
>> ne1_nef2(rc,nc,pe*ne,ne,alpha,power)
>>
>> ## if(is.na(ne1))
>>  print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
>> }
>> if (ne1>100000) return(NA)
>> else return(ne1)
>> }
>> ###
>> power1.f_function(rc,nc,ne,pie,alpha=0.05){
>> #-------------------------------------
>> # rc    number of response in historical control
>> # nc    sample size in historical control
>> # ne    sample size in experitment group
>> # pie    true response rate for experiment group
>> # alpha    size of the test
>> #-------------------------------------
>>
>> za_qnorm(1-alpha)
>> re_ne*pie
>> xe_asin(sqrt((re+0.375)/(ne+0.75)))
>> xc_asin(sqrt((rc+0.375)/(nc+0.75)))
>> ans_za*sqrt(1+(ne+0.5)/(nc+0.5))-(xe-xc)/sqrt(1/(4*(ne+0.5)))
>> return(1-pnorm(ans))
>> }
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From landronimirc at gmail.com  Thu Jun  6 16:48:27 2013
From: landronimirc at gmail.com (Liviu Andronic)
Date: Thu, 6 Jun 2013 16:48:27 +0200
Subject: [R] generate simple function with pre-defined constants
Message-ID: <CABxs9V=DcRW_CbwMy6DBt41wgqVo=E36Ep2EsCpSFFtkN=XgLg@mail.gmail.com>

Dear all,
Given:
a <- 2
b <- 3

I'd like to obtain the following function:
f <- function(x) 2 + 3*x

but when I do this:
f <- function(x) a + b*x
##f
##function(x) a + b*x

the 'a' and 'b' objects do not get evaluated to their constants. How
could I do that?

Thanks,
Liviu


-- 
Do you know how to read?
http://www.alienetworks.com/srtest.cfm
http://goodies.xfce.org/projects/applications/xfce4-dict#speed-reader
Do you know how to write?
http://garbl.home.comcast.net/~garbl/stylemanual/e.htm#e-mail


From dimitri.liakhovitski at gmail.com  Thu Jun  6 16:52:35 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 6 Jun 2013 10:52:35 -0400
Subject: [R] rJava is not loading
In-Reply-To: <51B02A06.50903@stats.ox.ac.uk>
References: <CAN2xGJbUNA25+e9fR6NWo+HaYES1w3j_KMRpPY73cRDvA37uog@mail.gmail.com>
	<51B02A06.50903@stats.ox.ac.uk>
Message-ID: <CAN2xGJZ5kQecuqn5toYgTPwUjWQp4Ca7efjN56t7djWrO+VYow@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130606/127b8d0a/attachment.pl>

From ripley at stats.ox.ac.uk  Thu Jun  6 16:58:16 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 06 Jun 2013 15:58:16 +0100
Subject: [R] rJava is not loading
In-Reply-To: <CAN2xGJZ5kQecuqn5toYgTPwUjWQp4Ca7efjN56t7djWrO+VYow@mail.gmail.com>
References: <CAN2xGJbUNA25+e9fR6NWo+HaYES1w3j_KMRpPY73cRDvA37uog@mail.gmail.com>
	<51B02A06.50903@stats.ox.ac.uk>
	<CAN2xGJZ5kQecuqn5toYgTPwUjWQp4Ca7efjN56t7djWrO+VYow@mail.gmail.com>
Message-ID: <51B0A388.4050303@stats.ox.ac.uk>

On 06/06/2013 15:52, Dimitri Liakhovitski wrote:
> Thank you very much, Brian.
> It's clearly christal clear - but one needs a christal ball to realize
> that! :-)
> So I learned: architecture = bitness

On current Windows, yes.
But not on OS X nor Linux nor Solaris nor FreeBSD ....

It indicates the type of CPU, or more precisely the instruction set the 
CPU is running.  x86_64 CPUs (as used by most current Windows boxes) can 
emulate i386 CPUs.  So the architectures for R on Windows are

i386 (32-bit)
x64 (64-bit, the Windows name for x86_64).

> Dimitri
>
>
> On Thu, Jun 6, 2013 at 2:19 AM, Prof Brian Ripley <ripley at stats.ox.ac.uk
> <mailto:ripley at stats.ox.ac.uk>> wrote:
>
>     On 06/06/2013 00:38, Dimitri Liakhovitski wrote:
>
>         Hello!
>         I installed rJava and am trying to load it.
>
>         library(rJava)
>
>         Error : .onLoad failed in loadNamespace() for 'rJava', details:
>             call: fun(libname, pkgname)
>             error: No CurrentVersion entry in Software/JavaSoft
>         registry! Try
>         re-installing Java and make sure R and Java have matching
>         architectures.
>         Error: package or namespace load failed for ?rJava?
>
>         Any idea why?
>         Background info:
>
>
>     But the posting guide asked for the output from sessionInfo(): we
>     want to know what R knows it is running as, not why you think.
>
>
>         Windows 7, 64-bit
>         R version 3.0.1 (for 64-bit)
>         I just installed the lastest Java: Java 7 Update 21
>
>
>     For the right architecture?
>
>     The message is crystal clear: you do not have a Java installed
>     matching your R.  Most likely your Java is 32-bit and your R 64-bit
>     or v.v.
>
>
>
>     --
>     Brian D. Ripley, ripley at stats.ox.ac.uk <mailto:ripley at stats.ox.ac.uk>
>     Professor of Applied Statistics,
>     http://www.stats.ox.ac.uk/~__ripley/
>     <http://www.stats.ox.ac.uk/~ripley/>
>     University of Oxford,             Tel: +44 1865 272861
>     <tel:%2B44%201865%20272861> (self)
>     1 South Parks Road, +44 1865 272866 <tel:%2B44%201865%20272866> (PA)
>     Oxford OX1 3TG, UK                Fax: +44 1865 272595
>     <tel:%2B44%201865%20272595>
>
>
>
>
> --
> Dimitri Liakhovitski


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From landronimirc at gmail.com  Thu Jun  6 17:00:27 2013
From: landronimirc at gmail.com (Liviu Andronic)
Date: Thu, 6 Jun 2013 17:00:27 +0200
Subject: [R] generate simple function with pre-defined constants
In-Reply-To: <CABxs9V=DcRW_CbwMy6DBt41wgqVo=E36Ep2EsCpSFFtkN=XgLg@mail.gmail.com>
References: <CABxs9V=DcRW_CbwMy6DBt41wgqVo=E36Ep2EsCpSFFtkN=XgLg@mail.gmail.com>
Message-ID: <CABxs9VnCDNt4pcty-1BQnr3UbEDx+WdKPO-08NTj4ud6U_CzTQ@mail.gmail.com>

On Thu, Jun 6, 2013 at 4:48 PM, Liviu Andronic <landronimirc at gmail.com> wrote:
> Dear all,
> Given:
> a <- 2
> b <- 3
>
> I'd like to obtain the following function:
> f <- function(x) 2 + 3*x
>
> but when I do this:
> f <- function(x) a + b*x
> ##f
> ##function(x) a + b*x
>
> the 'a' and 'b' objects do not get evaluated to their constants. How
> could I do that?
>
I found one solution:
a <- 2
b <- 3
f <- eval(parse(text=paste("function(z)", a, "+ z * ", b)))
f
##function(z) 2 + z *  3

but I still have nightmares from:
> fortune("parse")

If the answer is parse() you should usually rethink the question.
   -- Thomas Lumley
      R-help (February 2005)

Is there a nicer way to approach this? Thanks,
Liviu


> Thanks,
> Liviu
>
>
> --
> Do you know how to read?
> http://www.alienetworks.com/srtest.cfm
> http://goodies.xfce.org/projects/applications/xfce4-dict#speed-reader
> Do you know how to write?
> http://garbl.home.comcast.net/~garbl/stylemanual/e.htm#e-mail



-- 
Do you know how to read?
http://www.alienetworks.com/srtest.cfm
http://goodies.xfce.org/projects/applications/xfce4-dict#speed-reader
Do you know how to write?
http://garbl.home.comcast.net/~garbl/stylemanual/e.htm#e-mail


From calum.polwart at nhs.net  Thu Jun  6 17:03:16 2013
From: calum.polwart at nhs.net (Polwart Calum (COUNTY DURHAM AND DARLINGTON NHS FOUNDATION TRUST))
Date: Thu, 6 Jun 2013 16:03:16 +0100
Subject: [R] Not sure this is something R could do but it feels like it
 should be.
Message-ID: <20130606150318.57E504483A7@nhs-pd1e-esg101.ad1.nhs.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130606/3af2455c/attachment.pl>

From smartpink111 at yahoo.com  Thu Jun  6 17:03:31 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 6 Jun 2013 08:03:31 -0700 (PDT)
Subject: [R] generate simple function with pre-defined constants
In-Reply-To: <CABxs9V=DcRW_CbwMy6DBt41wgqVo=E36Ep2EsCpSFFtkN=XgLg@mail.gmail.com>
References: <CABxs9V=DcRW_CbwMy6DBt41wgqVo=E36Ep2EsCpSFFtkN=XgLg@mail.gmail.com>
Message-ID: <1370531011.91968.YahooMailNeo@web142606.mail.bf1.yahoo.com>

HI,
Not sure I understand your question:
?a <- 2
?b <- 3
?f1<- function(x) a+b*x
?f1(2)
#[1] 8
?f1(3)
#[1] 11
?f<- function(x) 2+3*x
?f(2)
#[1] 8
?f(3)
#[1] 11


A.K.

? sessionInfo()
R version 3.0.0 (2013-04-03)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
?[1] LC_CTYPE=en_CA.UTF-8?????? LC_NUMERIC=C????????????? 
?[3] LC_TIME=en_CA.UTF-8??????? LC_COLLATE=en_CA.UTF-8??? 
?[5] LC_MONETARY=en_CA.UTF-8??? LC_MESSAGES=en_CA.UTF-8?? 
?[7] LC_PAPER=C???????????????? LC_NAME=C???????????????? 
?[9] LC_ADDRESS=C?????????????? LC_TELEPHONE=C??????????? 
[11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C?????? 

attached base packages:
[1] stats???? graphics? grDevices utils???? datasets? methods?? base???? 

other attached packages:
[1] arrayhelpers_0.76-20120816 abind_1.4-0?????????????? 
[3] plyr_1.8?????????????????? stringr_0.6.2???????????? 
[5] reshape2_1.2.2??????????? 

loaded via a namespace (and not attached):
[1] tools_3.0.0


----- Original Message -----
From: Liviu Andronic <landronimirc at gmail.com>
To: "r-help at r-project.org Help" <r-help at r-project.org>
Cc: 
Sent: Thursday, June 6, 2013 10:48 AM
Subject: [R] generate simple function with pre-defined constants

Dear all,
Given:
a <- 2
b <- 3

I'd like to obtain the following function:
f <- function(x) 2 + 3*x

but when I do this:
f <- function(x) a + b*x
##f
##function(x) a + b*x

the 'a' and 'b' objects do not get evaluated to their constants. How
could I do that?

Thanks,
Liviu


-- 
Do you know how to read?
http://www.alienetworks.com/srtest.cfm
http://goodies.xfce.org/projects/applications/xfce4-dict#speed-reader
Do you know how to write?
http://garbl.home.comcast.net/~garbl/stylemanual/e.htm#e-mail

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From dcarlson at tamu.edu  Thu Jun  6 17:04:42 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Thu, 6 Jun 2013 10:04:42 -0500
Subject: [R] combining two different matrizes
In-Reply-To: <1370469376981-4668766.post@n4.nabble.com>
References: <1370469376981-4668766.post@n4.nabble.com>
Message-ID: <053601ce62c7$2c3cf750$84b6e5f0$@tamu.edu>

You didn't give us data, but this may give you enough to solve your problem:

> set.seed(42)
> nrows <- 6
> ncols <- 5
> mat1 <- matrix(sample.int(100, 30), nrows, ncols)
> mat1
     [,1] [,2] [,3] [,4] [,5]
[1,]   92   70   83   39    7
[2,]   93   13   23   46   82
[3,]   29   61   40   73   98
[4,]   81   65   80   11   67
[5,]   62   42   88   78   33
[6,]   50   91   10   85   60
> mat2 <- round(prop.table(mat1)*100, 2)
> mat2
     [,1] [,2] [,3] [,4] [,5]
[1,] 5.25 4.00 4.74 2.23 0.40
[2,] 5.31 0.74 1.31 2.63 4.68
[3,] 1.66 3.48 2.28 4.17 5.59
[4,] 4.62 3.71 4.57 0.63 3.82
[5,] 3.54 2.40 5.02 4.45 1.88
[6,] 2.85 5.19 0.57 4.85 3.42
> newmat <- matrix(rbind(as.vector(mat1), as.vector(mat2)), nrows*2, ncols)
> newmat
       [,1]  [,2]  [,3]  [,4]  [,5]
 [1,] 92.00 70.00 83.00 39.00  7.00
 [2,]  5.25  4.00  4.74  2.23  0.40
 [3,] 93.00 13.00 23.00 46.00 82.00
 [4,]  5.31  0.74  1.31  2.63  4.68
 [5,] 29.00 61.00 40.00 73.00 98.00
 [6,]  1.66  3.48  2.28  4.17  5.59
 [7,] 81.00 65.00 80.00 11.00 67.00
 [8,]  4.62  3.71  4.57  0.63  3.82
 [9,] 62.00 42.00 88.00 78.00 33.00
[10,]  3.54  2.40  5.02  4.45  1.88
[11,] 50.00 91.00 10.00 85.00 60.00
[12,]  2.85  5.19  0.57  4.85  3.42

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of ThomasH
Sent: Wednesday, June 5, 2013 4:56 PM
To: r-help at r-project.org
Subject: [R] combining two different matrizes


Hello together,

this is ma first post, so please aplogize me if post this in the wrong
section.

I have problem concerning ma two matrizes.

After a regressione and so on, I got two matrizes

Matrixres contains the results of ma calculation.

Matrixr contains my detiene, which where Aldo used for the regression.

Please ser the following code:

#Datei einlesen
residual = read.csv2("E:***Input-R_Renditen.csv",header=TRUE, sep=";")


#Aktientitel
alist <- list()
for (a in 2:11){


#Regression
   #L?nge Gesamtzeit
   t <- 243
   tx <- t-59

   #L?nge Regression
   reglist <- list()
   for (i in 1:tx){
   j <- i+59

   #RegressionsVariable
   x = residual[i:j,a]
   rm = residual[i:j,12]
   smb = residual[i:j,13]
   hml = residual[i:j,14]
   rf = residual[i:j,15]

   #?berschussrenditen
   ex=x-rf
   erm=rm-rf

   #Regression
   reg <- lm(ex~erm+smb+hml)
   reglist[[i]] <- coef(reg)
   

#Berechnung Residuum
      #Residual Berechnung
      rx = residual[(j-5):j,a]
      rrm = residual[(j-5):j,12]
      rsmb = residual[(j-5):j,13]
      rhml = residual[(j-5):j,14]
      rrf = residual[(j-5):j,15]

      rex = rx-rrf
      rerm = rrm-rrf

      #Berechnung
      res <-
sum(rex-(reglist[[i]][2]*rerm+reglist[[i]][3]*rsmb+reglist[[i]][4]*rhml))/sd(rex-(reglist[[i]][2]*rerm+reglist[[i]][3]*rsmb+reglist[[i]][4]*rhml))
      reglist[[i]] <- res
}   
   

#Residuen auf alle Aktien
   alist[[a]] <- reglist
}
   
#Matrix mit Residuen
   matrixres <- do.call(cbind,alist)

#Spaltennamen/Zeilennamen
s<- names(residual)[2:11]
colnames(matrixres)<-s

#RenditeMatrix
matrixr <- do.call(cbind,residual[60:243,2:11])


Now I want to combines  the two matrizes in the following way:

Under every row of matrixres should stand the row of matrixr for excample:

Matrixres row1
Matrixr row1
Matrixres row2
Matrixr row 2

Can anybody help me? I was working on this problem the whole day, but have
no idea.

Thanks alot
Thomash




--
View this message in context: http://r.789695.n4.nabble.com/combining-two-different-matrizes-tp4668766.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Thu Jun  6 17:17:37 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 06 Jun 2013 10:17:37 -0500
Subject: [R] Not sure this is something R could do but it feels like it
 should be.
In-Reply-To: <20130606150318.57E504483A7@nhs-pd1e-esg101.ad1.nhs.net>
References: <20130606150318.57E504483A7@nhs-pd1e-esg101.ad1.nhs.net>
Message-ID: <A043AE2B-69A5-4670-B3F2-5A65F61A5181@me.com>


On Jun 6, 2013, at 10:03 AM, Polwart Calum (COUNTY DURHAM AND DARLINGTON NHS FOUNDATION TRUST) <calum.polwart at nhs.net> wrote:

> Some colleagues nationally have developed a system which means they can pick the optimal sets of doses for a drug.  The system could apply to a number of drugs.  But the actual doses might vary.  To try and explain this in terms that the average Joe on the street might understand if you have some amoxicillin antibiotic for a chest infection the normal dose for an adult is 250 to 500mg increased to maybe 1000mg in severe cases.
> 
> For a child it is dosed from a liquid and people usually go from 62.5mg, 125mg to 250mg although you could measure any volume you wanted.
> 
> What this new method has developed is a means to pick the "right" standard doses so what above is 62.5, 125, 250, 500, 1000.  However the method they've used is really engineered about ensure the jump between doses is correct - you'll notice that the list above is a doubling up method.
> 
> But you can also have a doubling up method that went 50, 100, 200, 400, 800, 1600  and pretty much as many as you can think of depending on your starting point and there is no scientific means to pick that starting point.  So colleagues have developed their rather more complex equivalent of the doubling method to determine the doses they need but they need to know if they should start at 40, 50, 62.5 or some other number.
> 
> Once they have the starting number they can calculate all the other doses.  I realise R can do that, and I realise using a loop of possible starting numbers it can build all those options.
> 
> Each patient then has a theoretical dose they should get lets say that's 10mg/kg and you might treat patients from 5 to 120kg.  They are then looking to calculate the variance for each dose range so if we take the 50, 100, 200, 400 model and said you'd give 50mg to anyone needing 0?? to 75mg 100mg to anyone needing 76 - 150mg etc... from there they are taking that range and saying that's a 31% overdose to a 33% underdose.  Then they want to find if there is a starting number which minimises the extent of under and overdosing...
> 
> Anyone know of an existing stats function in R that can easily do that and almost then report from some inputs a single number that is the "best fit"?
> 
> Calum


The first place I would start is with the two relevant CRAN Task Views:

  http://cran.r-project.org/web/views/ClinicalTrials.html

and

  http://cran.r-project.org/web/views/Pharmacokinetics.html


There is also another package not listed above that might be relevant:

  http://cran.r-project.org/web/packages/scaRabee/


Regards,

Marc Schwartz


From landronimirc at gmail.com  Thu Jun  6 17:18:07 2013
From: landronimirc at gmail.com (Liviu Andronic)
Date: Thu, 6 Jun 2013 17:18:07 +0200
Subject: [R] generate simple function with pre-defined constants
In-Reply-To: <1370531011.91968.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <CABxs9V=DcRW_CbwMy6DBt41wgqVo=E36Ep2EsCpSFFtkN=XgLg@mail.gmail.com>
	<1370531011.91968.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <CABxs9Vkcty7pvSjnhE33upJ_0-MHYe3UqpuqADEeof7U8UfLBg@mail.gmail.com>

On Thu, Jun 6, 2013 at 5:03 PM, arun <smartpink111 at yahoo.com> wrote:
> HI,
> Not sure I understand your question:
>  a <- 2
>  b <- 3
>  f1<- function(x) a+b*x
>
I don't want the function to depend on the objects a and b, but
instead use the values of those objects (I do this within a function).

Liviu


>  f1(2)
> #[1] 8
>  f1(3)
> #[1] 11
>  f<- function(x) 2+3*x
>  f(2)
> #[1] 8
>  f(3)
> #[1] 11
>
>
> A.K.
>
>   sessionInfo()
> R version 3.0.0 (2013-04-03)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>  [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
>  [7] LC_PAPER=C                 LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] arrayhelpers_0.76-20120816 abind_1.4-0
> [3] plyr_1.8                   stringr_0.6.2
> [5] reshape2_1.2.2
>
> loaded via a namespace (and not attached):
> [1] tools_3.0.0
>
>
> ----- Original Message -----
> From: Liviu Andronic <landronimirc at gmail.com>
> To: "r-help at r-project.org Help" <r-help at r-project.org>
> Cc:
> Sent: Thursday, June 6, 2013 10:48 AM
> Subject: [R] generate simple function with pre-defined constants
>
> Dear all,
> Given:
> a <- 2
> b <- 3
>
> I'd like to obtain the following function:
> f <- function(x) 2 + 3*x
>
> but when I do this:
> f <- function(x) a + b*x
> ##f
> ##function(x) a + b*x
>
> the 'a' and 'b' objects do not get evaluated to their constants. How
> could I do that?
>
> Thanks,
> Liviu
>
>
> --
> Do you know how to read?
> http://www.alienetworks.com/srtest.cfm
> http://goodies.xfce.org/projects/applications/xfce4-dict#speed-reader
> Do you know how to write?
> http://garbl.home.comcast.net/~garbl/stylemanual/e.htm#e-mail
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Do you know how to read?
http://www.alienetworks.com/srtest.cfm
http://goodies.xfce.org/projects/applications/xfce4-dict#speed-reader
Do you know how to write?
http://garbl.home.comcast.net/~garbl/stylemanual/e.htm#e-mail


From scott.raynaud at yahoo.com  Thu Jun  6 17:19:29 2013
From: scott.raynaud at yahoo.com (Scott Raynaud)
Date: Thu, 6 Jun 2013 08:19:29 -0700 (PDT)
Subject: [R] SPlus script
In-Reply-To: <CA+vqiLGCTXQDEzzbeZDf-_EddiGQ=xx4P9n_3EJ2HkN1-qTMQg@mail.gmail.com>
References: <1370438435.93923.YahooMailNeo@web142703.mail.bf1.yahoo.com>
	<E66794E69CFDE04D9A70842786030B931C2FD5C4@PA-MBX01.na.tibco.com>
	<1370523739.92423.YahooMailNeo@web142703.mail.bf1.yahoo.com>
	<CA+vqiLGCTXQDEzzbeZDf-_EddiGQ=xx4P9n_3EJ2HkN1-qTMQg@mail.gmail.com>
Message-ID: <1370531969.88020.YahooMailNeo@web142705.mail.bf1.yahoo.com>

I actually had tried placing arguments in the call but it didn't work.?? However, I did 
not think about writing it to a variable and printing.? That seems to have done the 
trick.? Funny, I don't remember having to do that before, but that's not surprising.

Anyway, thanks for helping to diagnose and fix the problem.

----- Original Message -----
From: Ista Zahn <istazahn at gmail.com>
To: Scott Raynaud <scott.raynaud at yahoo.com>
Cc: William Dunlap <wdunlap at tibco.com>; "r-help at r-project.org" <r-help at r-project.org>
Sent: Thursday, June 6, 2013 9:15 AM
Subject: Re: [R] SPlus script

Presumably something like

r <- sshc(50)
print(r)

But if you were getting output before than you already have a script
that does something like this. It would be better to find it...

Best,
Ista

On Thu, Jun 6, 2013 at 9:02 AM, Scott Raynaud <scott.raynaud at yahoo.com> wrote:
> Ok.? Now I see that the sshc function is not being called.? Thanks for pointing that out.
> I'm not certain about the solution, however.? I tried putting call("sshc") at the end of the
> program, but nothing happened.? My memory about all of this is fuzzy.? Suggestions
> on how to call the function appreciated.
>
> ----- Original Message -----
> From: William Dunlap <wdunlap at tibco.com>
> To: Scott Raynaud <scott.raynaud at yahoo.com>; "r-help at r-project.org" <r-help at r-project.org>
> Cc:
> Sent: Wednesday, June 5, 2013 2:17 PM
> Subject: RE: [R] SPlus script
>
> Both the R and S+ versions (which seem to differ only in the use of _ for assignment
> in the S+ version) do nothing but define some functions.? You would not expect any
> printed output unless you used those functions on some data.? Is there another script
> that does that?
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
>> Of Scott Raynaud
>> Sent: Wednesday, June 05, 2013 6:21 AM
>> To: r-help at r-project.org
>> Subject: [R] SPlus script
>>
>> This originally was an SPlus script that I modifeid about a year-and-a-half ago.? It worked
>> perfectly then.? Now I can't get any output despite not receiving an error message.? I'm
>> providing the SPLUS script as a reference.? I'm running R15.2.2.? Any help appreciated.
>>
>> ************************************MY
>> MODIFICATION***********************************************************
>> **********
>> ## sshc.ssc: sample size calculation for historical control studies
>> ## J. Jack Lee (jjlee at mdanderson.org) and Chi-hong Tseng
>> ## Department of Biostatistics, Univ. of Texas M.D. Anderson Cancer Center
>> ##
>> ## 3/1/99
>> ## updated 6/7/00: add loess
>> ##------------------------------------------------------------------
>> ######## Required Input:
>> #
>> # rc? ? number of response in historical control group
>> # nc? ? sample size in historical control
>> # d? ? ? target improvement = Pe - Pc
>> # method 1=method based on the randomized design
>> #? ? ? ? 2=Makuch & Simon method (Makuch RW, Simon RM. Sample size considerations
>> #? ? ? ? ? for non-randomized comparative studies. J of Chron Dis 1980; 3:175-181.
>> #? ? ? ? 3=uniform power method
>> ######## optional Input:
>> #
>> # alpha? size of the test
>> # power? desired power of the test
>> # tol? ? convergence criterion for methods 1 & 2 in terms of sample size
>> # tol1? convergence criterion for method 3 at any given obs Rc in terms of difference
>> #? ? ? ? ? of expected power from target
>> # tol2? overall convergence criterion for method 3 as the max absolute deviation
>> #? ? ? ? ? of expected power from target for all Rc
>> # cc? ? range of multiplicative constant applied to the initial values ne
>> # l.span smoothing constant for loess
>> #
>> # Note:? rc is required for methods 1 and 2 but not 3
>> #? ? ? ? method 3 return the sample size need for rc=0 to (1-d)*nc
>> #
>> ######## Output
>> # for methdos 1 & 2: return the sample size needed for the experimental group (1
>> number)
>> #? ? ? ? ? ? ? ? ? ? for given rc, nc, d, alpha, and power
>> # for method 3:? ? ? return the profile of sample size needed for given nc, d, alpha, and
>> power
>> #? ? ? ? ? ? ? ? ? ? vector $ne contains the sample size corresponding to rc=0, 1, 2, ... nc*(1-d)
>> #? ? ? ? ? ? ? ? ? ? vector $Ep contains the expected power corresponding to
>> #? ? ? ? ? ? ? ? ? ? ? the true pc = (0, 1, 2, ..., nc*(1-d)) / nc
>> #
>> #------------------------------------------------------------------
>> sshc<-function(rc, nc=1092, d=.085779816, method=3, alpha=0.05, power=0.8,
>>? ? ? ? ? ? ? tol=0.01, tol1=.0001, tol2=.005, cc=c(.1,2), l.span=.5)
>> {
>> ### for method 1
>> if (method==1) {
>>? ne1<-ss.rand(rc,nc,d,alpha=.05,power=.8,tol=.01)
>>? return(ne=ne1)
>>? ? ? ? ? ? ? ? }
>> ### for method 2
>> if (method==2) {
>> ne<-nc
>> ne1<-nc+50
>> while(abs(ne-ne1)>tol & ne1<100000){
>> ne<-ne1
>> pe<-d+rc/nc
>> ne1<-nef(rc,nc,pe*ne,ne,alpha,power)
>> ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
>> }
>> if (ne1>100000) return(NA)
>> else return(ne=ne1)
>> }
>> ### for method 3
>> if (method==3) {
>> if (tol1 > tol2/10) tol1<-tol2/10
>> ncstar<-(1-d)*nc
>> pc<-(0:ncstar)/nc
>> ne<-rep(NA,ncstar + 1)
>> for (i in (0:ncstar))
>> { ne[i+1]<-ss.rand(i,nc,d,alpha=.05,power=.8,tol=.01)
>> }
>> plot(pc,ne,type='l',ylim=c(0,max(ne)*1.5))
>> ans<-c.searchd(nc, d, ne, alpha, power, cc, tol1)
>> ### check overall absolute deviance
>> old.abs.dev<-sum(abs(ans$Ep-power))
>> ##bad<-0
>> print(round(ans$Ep,4))
>> print(round(ans$ne,2))
>> lines(pc,ans$ne,lty=1,col=8)
>> old.ne<-ans$ne
>> ##while(max(abs(ans$Ep-power))>tol2 & bad==0){? #### unnecessary ##
>> while(max(abs(ans$Ep-power))>tol2){
>> ans<-c.searchd(nc, d, ans$ne, alpha, power, cc, tol1)
>> abs.dev<-sum(abs(ans$Ep-power))
>> print(paste(" old.abs.dev=",old.abs.dev))
>> print(paste("? ? abs.dev=",abs.dev))
>> ##if (abs.dev > old.abs.dev) { bad<-1}
>> old.abs.dev<-abs.dev
>> print(round(ans$Ep,4))
>> print(round(ans$ne,2))
>> lines(pc,old.ne,lty=1,col=1)
>> lines(pc,ans$ne,lty=1,col=8)
>> ### add convex
>> ans$ne<-convex(pc,ans$ne)$wy
>> ### add loess
>> ###old.ne<-ans$ne
>> loess.ne<-loess(ans$ne ~ pc, span=l.span)
>> lines(pc,loess.ne$fit,lty=1,col=4)
>> old.ne<-loess.ne$fit
>> ###readline()
>> }
>> return(list(ne=ans$ne, Ep=ans$Ep))
>>? ? ? ? ? ? ? ? }
>> }
>> ## needed for method 1
>> nef2<-function(rc,nc,re,ne,alpha,power){
>> za<-qnorm(1-alpha)
>> zb<-qnorm(power)
>> xe<-asin(sqrt((re+0.375)/(ne+0.75)))
>> xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
>> ans<- 1/(4*(xc-xe)^2/(za+zb)^2-1/(nc+0.5)) - 0.5
>> return(ans)
>> }
>> ## needed for method 2
>> nef<-function(rc,nc,re,ne,alpha,power){
>> za<-qnorm(1-alpha)
>> zb<-qnorm(power)
>> xe<-asin(sqrt((re+0.375)/(ne+0.75)))
>> xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
>> ans<-(za*sqrt(1+(ne+0.5)/(nc+0.5))+zb)^2/(2*(xe-xc))^2-0.5
>> return(ans)
>> }
>> ## needed for method 3
>> c.searchd<-function(nc, d, ne, alpha=0.05, power=0.8, cc=c(0.1,2),tol1=0.0001){
>> #---------------------------
>> # nc? ? sample size of control group
>> # d? ? ? the differece to detect between control and experiment
>> # ne? ? vector of starting sample size of experiment group
>> #? ? ? corresonding to rc of 0 to nc*(1-d)
>> # alpha? size of test
>> # power? target power
>> # cc? pre-screen vector of constant c, the range should cover the
>> #? ? ? the value of cc that has expected power
>> # tol1? the allowance between the expceted power and target power
>> #---------------------------
>> pc<-(0:((1-d)*nc))/nc
>> ncl<-length(pc)
>> ne.old<-ne
>> ne.old1<-ne.old
>> ### sweeping forward
>> for(i in 1:ncl){
>>? cmin<-cc[1]
>>? cmax<-cc[2]
>> ### fixed cci<-cmax bug
>>? cci <-1
>>? lhood<-dbinom((i:ncl)-1,nc,pc[i])
>>? ne[i:ncl]<-(1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
>>? Ep0 <-Epower(nc, d, ne, pc, alpha)
>>? while(abs(Ep0[i]-power)>tol1){
>>? if(Ep0[i]<power) cmin<-cci
>>? else cmax<-cci
>>? cci<-(cmax+cmin)/2
>>? ne[i:ncl]<-(1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
>>? Ep0<-Epower(nc, d, ne, pc, alpha)
>>? }
>>? ne.old1<-ne
>> }
>> ne1<-ne
>> ### sweeping backward -- ncl:i
>> ne.old2<-ne.old
>> ne? ? <-ne.old
>> for(i in ncl:1){
>>? cmin<-cc[1]
>>? cmax<-cc[2]
>> ### fixed cci<-cmax bug
>>? cci <-1
>>? lhood<-dbinom((ncl:i)-1,nc,pc[i])
>>? lenl <-length(lhood)
>>? ne[ncl:i]<-(1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
>>? Ep0 <-Epower(nc, d, cci*ne, pc, alpha)
>>? while(abs(Ep0[i]-power)>tol1){
>>? if(Ep0[i]<power) cmin<-cci
>>? else cmax<-cci
>>? cci<-(cmax+cmin)/2
>>? ne[ncl:i]<-(1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
>>? Ep0<-Epower(nc, d, ne, pc, alpha)
>>? }
>>? ne.old2<-ne
>> }
>> ne2<-ne
>> ne<-(ne1+ne2)/2
>> #cat(ccc*ne)
>> Ep1<-Epower(nc, d, ne, pc, alpha)
>> return(list(ne=ne, Ep=Ep1))
>> }
>> ###
>> vertex<-function(x,y)
>> {? n<-length(x)
>>? vx<-x[1]
>>? vy<-y[1]
>>? vp<-1
>>? up<-T
>>? for (i in (2:n))
>>? { if (up)
>>? {? if (y[i-1] > y[i])
>>? ? {vx<-c(vx,x[i-1])
>>? ? vy<-c(vy,y[i-1])
>>? ? vp<-c(vp,i-1)
>>? ? up<-F
>>? ? }
>>? }
>>? else
>>? {? if (y[i-1] < y[i]) up<-T
>>? }
>>? }
>>? vx<-c(vx,x[n])
>>? vy<-c(vy,y[n])
>>? vp<-c(vp,n)
>>? return(list(vx=vx,vy=vy,vp=vp))
>> }
>> ###
>> convex<-function(x,y)
>> {
>>? n<-length(x)
>>? ans<-vertex(x,y)
>>? len<-length(ans$vx)
>>? while (len>3)
>>? {
>> #? cat("x=",x,"\n")
>> #? cat("y=",y,"\n")
>>? newx<-x[1:(ans$vp[2]-1)]
>>? newy<-y[1:(ans$vp[2]-1)]
>>? for (i in (2:(len-1)))
>>? {
>>? ? newx<-c(newx,x[ans$vp[i]])
>>? ? newy<-c(newy,y[ans$vp[i]])
>>? }
>>? newx<-c(newx,x[(ans$vp[len-1]+1):n])
>>? newy<-c(newy,y[(ans$vp[len-1]+1):n])
>>? y<-approx(newx,newy,xout=x)$y
>> #? cat("new y=",y,"\n")
>>? ans<-vertex(x,y)
>>? len<-length(ans$vx)
>> #? cat("vx=",ans$vx,"\n")
>> #? cat("vy=",ans$vy,"\n")
>> }
>>? return(list(wx=x,wy=y))}
>> ###
>> Epower<-function(nc, d, ne, pc = (0:((1 - d) * nc))/nc, alpha = 0.05)
>> {
>> #-------------------------------------
>> # nc? ? sample size in historical control
>> # d? ? ? the increase of response rate between historical and experiment
>> # ne? ? sample size of corresonding rc of 0 to nc*(1-d)
>> # pc? ? the response rate of control group, where we compute the
>> #? ? ? ? expected power
>> # alpha? the size of test
>> #-------------------------------------
>>? kk <- length(pc)
>>? rc <- 0:(nc * (1 - d))
>>? pp <- rep(NA, kk)
>>? ppp <- rep(NA, kk)
>>? for(i in 1:(kk)) {
>>? pe <- pc[i] + d
>>? lhood <- dbinom(rc, nc, pc[i])
>>? pp <- power1.f(rc, nc, ne, pe, alpha)
>>? ppp[i] <- sum(pp * lhood)/sum(lhood)
>>? }
>>? return(ppp)
>> }
>> # adapted from the old biss2
>> ss.rand<-function(rc,nc,d,alpha=.05,power=.8,tol=.01)
>> {
>> ne<-nc
>> ne1<-nc+50
>> while(abs(ne-ne1)>tol & ne1<100000){
>> ne<-ne1
>> pe<-d+rc/nc
>> ne1<-nef2(rc,nc,pe*ne,ne,alpha,power)
>> ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
>> }
>> if (ne1>100000) return(NA)
>> else return(ne1)
>> }
>> ###
>> power1.f<-function(rc,nc,ne,pie,alpha=0.05){
>> #-------------------------------------
>> # rc number of response in historical control
>> # nc sample size in historical control
>> # ne? ? sample size in experitment group
>> # pie true response rate for experiment group
>> # alpha size of the test
>> #-------------------------------------
>> za<-qnorm(1-alpha)
>> re<-ne*pie
>> xe<-asin(sqrt((re+0.375)/(ne+0.75)))
>> xc<-asin(sqrt((rc+0.375)/(nc+0.75)))
>> ans<-za*sqrt(1+(ne+0.5)/(nc+0.5))-(xe-xc)/sqrt(1/(4*(ne+0.5)))
>> return(1-pnorm(ans))
>> }
>>
>>
>>
>> *************************************ORIGINAL SPLUS
>> SCRIPT************************************************************
>> ## sshc.ssc: sample size calculation for historical control studies
>> ## J. Jack Lee (jjlee at mdanderson.org) and Chi-hong Tseng
>> ## Department of Biostatistics, Univ. of Texas M.D. Anderson Cancer Center
>> ##
>> ## 3/1/99
>> ## updated 6/7/00: add loess
>> ##------------------------------------------------------------------
>> ######## Required Input:
>> #
>> # rc? ? number of response in historical control group
>> # nc? ? sample size in historical control
>> # d? ? ? target improvement = Pe - Pc
>> # method 1=method based on the randomized design
>> #? ? ? ? 2=Makuch & Simon method (Makuch RW, Simon RM. Sample size considerations
>> #? ? ? ? ? for non-randomized comparative studies. J of Chron Dis 1980; 3:175-181.
>> #? ? ? ? 3=uniform power method
>> ######## optional Input:
>> #
>> # alpha? size of the test
>> # power? desired power of the test
>> # tol? ? convergence criterion for methods 1 & 2 in terms of sample size
>> # tol1? convergence criterion for method 3 at any given obs Rc in terms of
>>? difference
>> #? ? ? ? ? of expected power from target
>> # tol2? overall convergence criterion for method 3 as the max absolute deviation
>> #? ? ? ? ? of expected power from target for all Rc
>> # cc? ? range of multiplicative constant applied to the initial values ne
>> # l.span smoothing constant for loess
>> #
>> # Note:? rc is required for methods 1 and 2 but not 3
>> #? ? ? ? method 3 return the sample size need for rc=0 to (1-d)*nc
>> #
>> ######## Output
>> # for methdos 1 & 2: return the sample size needed for the experimental group (1
>> number)
>> #? ? ? ? ? ? ? ? ? ? for given rc, nc, d, alpha, and power
>> # for method 3:? ? ? return the profile of sample size needed for given nc, d, alpha, and
>> power
>> #? ? ? ? ? ? ? ? ? ? vector $ne contains the sample size corresponding to rc=0, 1, 2, ... nc*(1-d)
>> #? ? ? ? ? ? ? ? ? ? vector $Ep contains the expected power corresponding to
>> #? ? ? ? ? ? ? ? ? ? ? the true pc = (0, 1, 2, ..., nc*(1-d)) / nc
>> #
>>
>> #------------------------------------------------------------------
>> sshc _ function(rc, nc, d, method, alpha=0.05, power=0.8,
>>? ? ? ? ? ? ? ? tol=0.01, tol1=.0001, tol2=.005, cc=c(.1,2), l.span=.5)
>> {
>> ### for method 1
>> if (method==1) {
>>? ? ne1 _ ss.rand(rc,nc,d,alpha=.05,power=.8,tol=.01)
>>? ? return(ne=ne1)
>>? ? ? ? ? ? ? ? }
>> ### for method 2
>> if (method==2) {
>> ne_nc
>> ne1_nc+50
>> while(abs(ne-ne1)>tol & ne1<100000){
>> ne_ne1
>> pe_d+rc/nc
>> ne1_nef(rc,nc,pe*ne,ne,alpha,power)
>> ## if(is.na(ne1)) print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
>> }
>> if (ne1>100000) return(NA)
>> else return(ne=ne1)
>> }
>> ### for method 3
>> if (method==3) {
>> if (tol1 > tol2/10) tol1_tol2/10
>> ncstar _ (1-d)*nc
>> pc_(0:ncstar)/nc
>> ne _ rep(NA,ncstar + 1)
>> for (i in (0:ncstar))
>> { ne[i+1] _ ss.rand(i,nc,d,alpha=.05,power=.8,tol=.01)
>> }
>> plot(pc,ne,type='l',ylim=c(0,max(ne)*1.5))
>> ans_c.searchd(nc, d, ne, alpha, power, cc, tol1)
>> ### check overall absolute deviance
>> old.abs.dev _ sum(abs(ans$Ep-power))
>> ##bad
>>? _ 0
>> print(round(ans$Ep,4))
>> print(round(ans$ne,2))
>> lines(pc,ans$ne,lty=1,col=8)
>> old.ne _ ans$ne
>> ##while(max(abs(ans$Ep-power))>tol2 & bad==0){? #### unnecessary ##
>> while(max(abs(ans$Ep-power))>tol2){
>> ans_c.searchd(nc, d, ans$ne, alpha, power, cc, tol1)
>> abs.dev _ sum(abs(ans$Ep-power))
>> print(paste(" old.abs.dev=",old.abs.dev))
>> print(paste("? ? abs.dev=",abs.dev))
>> ##if (abs.dev > old.abs.dev) { bad _ 1}
>> old.abs.dev _ abs.dev
>> print(round(ans$Ep,4))
>> print(round(ans$ne,2))
>> lines(pc,old.ne,lty=1,col=1)
>> lines(pc,ans$ne,lty=1,col=8)
>> ### add convex
>> ans$ne _ convex(pc,ans$ne)$wy
>> ### add loess
>> ###old.ne _ ans$ne
>> loess.ne _ loess(ans$ne ~ pc, span=l.span)
>> lines(pc,loess.ne$fit,lty=1,col=4)
>> old.ne _ loess.ne$fit
>> ###readline()
>> }
>> return(ne=ans$ne, Ep=ans$Ep)
>>? ? ? ? ? ? ? ? }
>> }
>>
>> ## needed for method 1
>> nef2_function(rc,nc,re,ne,alpha,power){
>> za_qnorm(1-alpha)
>> zb_qnorm(power)
>> xe_asin(sqrt((re+0.375)/(ne+0.75)))
>> xc_asin(sqrt((rc+0.375)/(nc+0.75)))
>> ans_
>>? 1/(4*(xc-xe)^2/(za+zb)^2-1/(nc+0.5)) - 0.5
>> return(ans)
>> }
>> ## needed for method 2
>> nef_function(rc,nc,re,ne,alpha,power){
>> za_qnorm(1-alpha)
>> zb_qnorm(power)
>> xe_asin(sqrt((re+0.375)/(ne+0.75)))
>> xc_asin(sqrt((rc+0.375)/(nc+0.75)))
>> ans_(za*sqrt(1+(ne+0.5)/(nc+0.5))+zb)^2/(2*(xe-xc))^2-0.5
>> return(ans)
>> }
>> ## needed for method 3
>> c.searchd_function(nc, d, ne, alpha=0.05, power=0.8, cc=c(0.1,2),tol1=0.0001){
>> #---------------------------
>> # nc? ? sample size of control group
>> # d? ? ? the differece to detect between control and experiment
>> # ne? ? vector of starting sample size of experiment group
>> #? ? ? ? ? ? corresonding to rc of 0 to nc*(1-d)
>> # alpha? size of test
>> # power? target power
>> # cc? ? ? pre-screen vector of constant c, the range should cover the
>> #? ? ? ? ? ? the value of cc that has expected power
>> # tol1? the allowance between the expceted power and target power
>> #---------------------------
>> pc_(0:((1-d)*nc))/nc
>> ncl _ length(pc)
>> ne.old _ ne
>> ne.old1 _ ne.old
>> ###
>>? sweeping forward
>> for(i in 1:ncl){
>>? ? cmin _ cc[1]
>>? ? cmax _ cc[2]
>> ### fixed cci_cmax bug
>>? ? cci? _ 1
>>? ? lhood _ dbinom((i:ncl)-1,nc,pc[i])
>>? ? ne[i:ncl] _ (1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
>>? ? Ep0? _ Epower(nc, d, ne, pc, alpha)
>>? ? while(abs(Ep0[i]-power)>tol1){
>>? ? ? ? if(Ep0[i]<power) cmin_cci
>>? ? ? ? else cmax_cci
>>? ? ? ? cci_(cmax+cmin)/2
>>? ? ? ? ne[i:ncl] _ (1+(cci-1)*(lhood/lhood[1])) * ne.old1[i:ncl]
>>? ? ? ? Ep0_Epower(nc, d, ne, pc, alpha)
>>? ? }
>>? ? ? ne.old1 _ ne
>> }
>> ne1 _ ne
>> ### sweeping backward -- ncl:i
>> ne.old2 _ ne.old
>> ne? ? ? _ ne.old
>> for(i in ncl:1){
>>? ? cmin _ cc[1]
>>? ? cmax _ cc[2]
>> ### fixed cci_cmax bug
>>? ? cci? _ 1
>>? ? lhood _ dbinom((ncl:i)-1,nc,pc[i])
>>? ? lenl? _ length(lhood)
>>? ? ne[ncl:i] _ (1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
>>? ? Ep0? _ Epower(nc, d, cci*ne, pc, alpha)
>>? ? while(abs(Ep0[i]-power)>tol1){
>>? ? ? ? if(Ep0[i]<power) cmin_cci
>>? ? ? ? else cmax_cci
>>? ? ? ? cci_(cmax+cmin)/2
>>? ? ? ? ne[ncl:i] _ (1+(cci-1)*(lhood/lhood[lenl]))*ne.old2[ncl:i]
>>? ? ? ? Ep0_Epower(nc, d, ne, pc, alpha)
>>? ? }
>>? ? ? ne.old2 _ ne
>> }
>>
>> ne2 _ ne
>> ne _ (ne1+ne2)/2
>> #cat(ccc*ne)
>> Ep1_Epower(nc, d, ne, pc, alpha)
>> return(ne=ne, Ep=Ep1)
>> }
>> ###
>> vertex _ function(x,y)
>> {? ? n _ length(x)
>>? ? vx _ x[1]
>>? ? vy _ y[1]
>>? ? vp _ 1
>>? ? up _ T
>>? ? for (i in (2:n))
>>? ? { if (up)
>>? ? ? ? {? ? if (y[i-1] > y[i])
>>? ? ? ? ? ? {vx _ c(vx,x[i-1])
>>? ? ? ? ? ? vy _ c(vy,y[i-1])
>>? ? ? ? ? ? vp _ c(vp,i-1)
>>? ? ? ? ? ? up _ F
>>? ? ? ? ? ? }
>>? ? ? ? }
>>? ? ? ? else
>>? ? ? ? {? ? if (y[i-1] < y[i]) up _ T
>>? ? ? ? }
>>? ? }
>>? ? vx _ c(vx,x[n])
>>? ? vy _ c(vy,y[n])
>>? ? vp _ c(vp,n)
>>? ? return(vx=vx,vy=vy,vp=vp)
>> }
>> ###
>> convex _ function(x,y)
>> {
>>? ? n _ length(x)
>>? ? ans _ vertex(x,y)
>>? ? len _ length(ans$vx)
>>? ? while (len>3)
>>? ? {
>> #? ? ? ? cat("x=",x,"\n")
>> #? ? ? ? cat("y=",y,"\n")
>>? ? ? ? newx _ x[1:(ans$vp[2]-1)]
>>? ? ? ? newy _ y[1:(ans$vp[2]-1)]
>>? ? ? ? for (i in (2:(len-1)))
>>? ? ? ? {
>>? ? ? ? ? ? newx _ c(newx,x[ans$vp[i]])
>>? ? ? ? ? ? newy _ c(newy,y[ans$vp[i]])
>>? ? ? ? }
>>? ? ? ? newx _ c(newx,x[(ans$vp[len-1]+1):n])
>>? ? ? ? newy _ c(newy,y[(ans$vp[len-1]+1):n])
>>? ? ? ? y _ approx(newx,newy,xout=x)$y
>> #? ? ? ? cat("new y=",y,"\n")
>>? ? ? ? ans _ vertex(x,y)
>>? ? ? ? len _ length(ans$vx)
>> #? ? ? ? cat("vx=",ans$vx,"\n")
>> #? ? ? ? cat("vy=",ans$vy,"\n")
>>
>> }
>>? ? return(wx=x,wy=y)}
>> ###
>> Epower _ function(nc, d, ne, pc = (0:((1 - d) * nc))/nc, alpha = 0.05)
>> {
>> #-------------------------------------
>> # nc? ? sample size in historical control
>> # d? ? ? the increase of response rate between historical and experiment
>> # ne? ? sample size of corresonding rc of 0 to nc*(1-d)
>> # pc? ? the response rate of control group, where we compute the
>> #? ? ? ? expected power
>> # alpha? the size of test
>> #-------------------------------------
>>? ? kk <- length(pc)
>>? ? rc <- 0:(nc * (1 - d))
>>? ? pp <- rep(NA, kk)
>>? ? ppp <- rep(NA, kk)
>>? ? for(i in 1:(kk)) {
>>? ? ? ? pe <- pc[i] + d
>>? ? ? ? lhood <- dbinom(rc, nc, pc[i])
>>? ? ? ? pp <- power1.f(rc, nc, ne, pe, alpha)
>>? ? ? ? ppp[i] <- sum(pp * lhood)/sum(lhood)
>>? ? }
>>? ? return(ppp)
>> }
>>
>> # adapted from the old biss2
>> ss.rand _ function(rc,nc,d,alpha=.05,power=.8,tol=.01)
>> {
>> ne_nc
>> ne1_nc+50
>> while(abs(ne-ne1)>tol & ne1<100000){
>> ne_ne1
>> pe_d+rc/nc
>> ne1_nef2(rc,nc,pe*ne,ne,alpha,power)
>>
>> ## if(is.na(ne1))
>>? print(paste('rc=',rc,',nc=',nc,',pe=',pe,',ne=',ne))
>> }
>> if (ne1>100000) return(NA)
>> else return(ne1)
>> }
>> ###
>> power1.f_function(rc,nc,ne,pie,alpha=0.05){
>> #-------------------------------------
>> # rc? ? number of response in historical control
>> # nc? ? sample size in historical control
>> # ne? ? sample size in experitment group
>> # pie? ? true response rate for experiment group
>> # alpha? ? size of the test
>> #-------------------------------------
>>
>> za_qnorm(1-alpha)
>> re_ne*pie
>> xe_asin(sqrt((re+0.375)/(ne+0.75)))
>> xc_asin(sqrt((rc+0.375)/(nc+0.75)))
>> ans_za*sqrt(1+(ne+0.5)/(nc+0.5))-(xe-xc)/sqrt(1/(4*(ne+0.5)))
>> return(1-pnorm(ans))
>> }
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From bhh at xs4all.nl  Thu Jun  6 17:20:41 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 6 Jun 2013 17:20:41 +0200
Subject: [R] combining two different matrizes
In-Reply-To: <053601ce62c7$2c3cf750$84b6e5f0$@tamu.edu>
References: <1370469376981-4668766.post@n4.nabble.com>
	<053601ce62c7$2c3cf750$84b6e5f0$@tamu.edu>
Message-ID: <26BC1C7E-AB5B-4E18-BED1-FE62F44EB120@xs4all.nl>


On 06-06-2013, at 17:04, David Carlson <dcarlson at tamu.edu> wrote:

> You didn't give us data, but this may give you enough to solve your problem:
> 
>> set.seed(42)
>> nrows <- 6
>> ncols <- 5
>> mat1 <- matrix(sample.int(100, 30), nrows, ncols)
>> mat1
> ?..
>> newmat <- matrix(rbind(as.vector(mat1), as.vector(mat2)), nrows*2, ncols)

Nice.

Berend


From juliosergio at gmail.com  Thu Jun  6 17:28:36 2013
From: juliosergio at gmail.com (Julio Sergio)
Date: Thu, 6 Jun 2013 15:28:36 +0000
Subject: [R]
	=?utf-8?q?Trying_to_build_up_functions_with_its_names_by_mean?=
	=?utf-8?q?s_of=09lapply?=
References: <loom.20130605T043218-210@post.gmane.org>
	<250F03A2-77CE-4FAC-B1C9-6754567A3F6A@gmail.com>
	<51AF09A5.4080700@sapo.pt> <51AF0BE3.3050500@sapo.pt>
	<CACk-te21kO0xP+4RpvJrLVxoUZjbAVh_h6RbL0JxSwoBH2YwPg@mail.gmail.com>
	<loom.20130605T215734-601@post.gmane.org>
	<E66794E69CFDE04D9A70842786030B931C2FD621@PA-MBX01.na.tibco.com>
	<CACk-te1burUA2mSPDVjN_ZdB6iEkUhtUt3-jLBP0+rtWzYocCw@mail.gmail.com>
Message-ID: <loom.20130606T171909-431@post.gmane.org>

Bert Gunter <gunter.berton <at> gene.com> writes:

> Another equivalent way to do it?
> 
> f2 <- function(c,nm = "gamma",...)
> {
>   probFunc <- paste0(c,nm)
>   more <- list(...)
>   function(x)do.call(probFunc,c(x,more))
> }
> 
> This avoids the explicit use of get() and force(), I believe, but are
> there problems here I'm missing?
> 

Thanks Bert. Since I'm relatively new in using this language, a question 
arises in my mind: why should the use of get() and force() be avoided? Is it 
just for syntactic clarity or is there another computational reason?

Best regards,

  -Sergio.


From smartpink111 at yahoo.com  Thu Jun  6 17:29:22 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 6 Jun 2013 08:29:22 -0700 (PDT)
Subject: [R] combining two different matrizes
In-Reply-To: <9887E730-C27B-468E-AF83-8713F4E5C3F5@xs4all.nl>
References: <1370469376981-4668766.post@n4.nabble.com>
	<9887E730-C27B-468E-AF83-8713F4E5C3F5@xs4all.nl>
Message-ID: <1370532562.64144.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Perhaps this also helps:
library(plyr)

?do.call(rbind,alply(aperm(laply(list(A,B),as.matrix),c(1,3,2)),3)) #Using Berend's example
?????????? 1????? 2????? 3????? 4????? 5
# [1,] -0.591 -0.934 -0.828? 0.012 -0.683
?#[2,]? 1.000? 6.000 11.000 16.000 21.000
?#[3,]? 0.027? 1.324 -0.348 -0.223 -0.016
?#[4,]? 2.000? 7.000 12.000 17.000 22.000
?#[5,] -1.517? 0.625 -1.538? 0.888 -0.443
?#[6,]? 3.000? 8.000 13.000 18.000 23.000
?#[7,] -1.363 -0.046 -0.256 -0.592? 0.353
?#[8,]? 4.000? 9.000 14.000 19.000 24.000
?#[9,]? 1.178 -1.004 -1.150 -0.656? 0.073
#[10,]? 5.000 10.000 15.000 20.000 25.000


A.K.

----- Original Message -----
From: Berend Hasselman <bhh at xs4all.nl>
To: ThomasH <thomas.hufnagel1 at gmx.de>
Cc: r-help at r-project.org
Sent: Thursday, June 6, 2013 10:04 AM
Subject: Re: [R] combining two different matrizes


On 05-06-2013, at 23:56, ThomasH <thomas.hufnagel1 at gmx.de> wrote:

> 
> Hello together,
> 
> this is ma first post, so please aplogize me if post this in the wrong
> section.
> 
> I have problem concerning ma two matrizes.
> 
> After a regressione and so on, I got two matrizes
> 
> Matrixres contains the results of ma calculation.
> 
> Matrixr contains my detiene, which where Aldo used for the regression.
> 
> Please ser the following code:
> 
> #Datei einlesen
> residual = read.csv2("E:***Input-R_Renditen.csv",header=TRUE, sep=";")
> 
> 
> #Aktientitel
> alist <- list()
> for (a in 2:11){
> 
> 
> #Regression
>? ? #L?nge Gesamtzeit
>? ? t <- 243
>? ? tx <- t-59
> 
>? ? #L?nge Regression
>? ? reglist <- list()
>? ? for (i in 1:tx){
>? ? j <- i+59
> 
>? ? #RegressionsVariable
>? ? x = residual[i:j,a]
>? ? rm = residual[i:j,12]
>? ? smb = residual[i:j,13]
>? ? hml = residual[i:j,14]
>? ? rf = residual[i:j,15]
> 
>? ? #?berschussrenditen
>? ? ex=x-rf
>? ? erm=rm-rf
> 
>? ? #Regression
>? ? reg <- lm(ex~erm+smb+hml)
>? ? reglist[[i]] <- coef(reg)
>? ? 
> 
> #Berechnung Residuum
>? ? ?  #Residual Berechnung
>? ? ?  rx = residual[(j-5):j,a]
>? ? ?  rrm = residual[(j-5):j,12]
>? ? ?  rsmb = residual[(j-5):j,13]
>? ? ?  rhml = residual[(j-5):j,14]
>? ? ?  rrf = residual[(j-5):j,15]
> 
>? ? ?  rex = rx-rrf
>? ? ?  rerm = rrm-rrf
> 
>? ? ?  #Berechnung
>? ? ?  res <-
> sum(rex-(reglist[[i]][2]*rerm+reglist[[i]][3]*rsmb+reglist[[i]][4]*rhml))/sd(rex-(reglist[[i]][2]*rerm+reglist[[i]][3]*rsmb+reglist[[i]][4]*rhml))
>? ? ?  reglist[[i]] <- res
> }? 
>? ? 
> 
> #Residuen auf alle Aktien
>? ? alist[[a]] <- reglist
> }
>? ? 
> #Matrix mit Residuen
>? ? matrixres <- do.call(cbind,alist)
> 
> #Spaltennamen/Zeilennamen
> s<- names(residual)[2:11]
> colnames(matrixres)<-s
> 
> #RenditeMatrix
> matrixr <- do.call(cbind,residual[60:243,2:11])
> 
> 
> Now I want to combines? the two matrizes in the following way:
> 
> Under every row of matrixres should stand the row of matrixr for excample:
> 
> Matrixres row1
> Matrixr row1
> Matrixres row2
> Matrixr row 2
> 
> Can anybody help me? I was working on this problem the whole day, but have
> no idea.

Something like this (assuming A and B have the same dimensions)

set.seed(11)
A <- matrix(round(rnorm(25),3),nrow=5)
B <- matrix(1:25,nrow=5)

C <- matrix(0,nrow=2*nrow(A),ncol=ncol(A))

crows <- seq.int(from=1,to=2*nrow(A),by=2)
C[crows,] <- A
C[crows+1,] <- B

Some friendly advice: get someone to check your English before sending a mail to the list.

Berend

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Jun  6 17:30:50 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 6 Jun 2013 08:30:50 -0700
Subject: [R] List into table
In-Reply-To: <1370422195429-4668693.post@n4.nabble.com>
References: <1370422195429-4668693.post@n4.nabble.com>
Message-ID: <031E355A-B2FE-4C53-A72D-E49A9C0487E9@comcast.net>


On Jun 5, 2013, at 1:49 AM, Andtrei89 wrote:

> Hi everyone,
> 
> I want to open an XML file in R and it also works.
> But then I get a list of all numbers but it isn't in the type of "numeric".
> 
> I tried this:
> 
> exampleData <-
> "C:/Users/Andreas/Desktop/Thesis/Interzeptionsmodell/Daten/Karlsruhe/Windgeschwindigkeit/1948.xml"
> 
> F <- system.file("exampleData", "1948.xml", package = "XML")
> f <- xmlToDataFrame(exampleData, colClasses = NULL, homogeneous = TRUE,
> collectNames = TRUE,
>                    stringsAsFactors = default.stringsAsFactors())
> 
> 
> I got this:
> 

You got that when you did ? what?

> 1 4.9 5.0 5.3 4.4 2.9 1.9 1.1 1.5 1.6 1.2 0.7 0.8 2.5 2.3 1.6 0.6 1.3 0.8
> 1.3 1.2 3.9 5.0 6.4 6.3 8.4
>   NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
> NA  NA  NA  NA  NA  NA  NA
> 1 8.4 8.3 8.3 9.1 8.3 7.7 6.8 5.4 4.8 3.6 3.6 3.5 2.6 3.5 3.0 3.1 2.4 3.4
> 3.3 4.8 6.1 5.1 4.2 4.5 4.5
>   NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA 
> NA  NA  NA  NA  NA  NA  NA
> 1 5.4 4.7 4.6 3.8 4.0 1.5 0.0 1.1 0.7 0.0 0.0 1.3 1.5 1.6 0.0 0.7 0.6 0.5
> 1.8 1.5 1.6 1.5 1.9 2.5 2.5
> 
> I only want the numbers out of it as numeric ... if I try as.numeric() I got
> a list looking like that:
> 
Probably not a "list". Probably a vector of indexes into a set of factor levels.

> 1 1 1 1 1 1 1 1 1  1  1 1 1 1 1 1 ..........
> 
> I would be very thankful for your answer

Hard to know for sure, but try reading the FAQ regarding proper conversion of factor varibles to numeric and following its advice.


> --
> View this message in context: http://r.789695.n4.nabble.com/List-into-table-tp4668693.html

Posting from Nabble is likely to cause you problems at some point or another due to the tightened spam filters.

> Sent from the R help mailing list archive at Nabble.com.

Nabble is not an archive and it is not the R mailing list.

-- 

David Winsemius
Alameda, CA, USA


From kridox at ymail.com  Thu Jun  6 17:34:29 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Fri, 7 Jun 2013 00:34:29 +0900
Subject: [R] generate simple function with pre-defined constants
In-Reply-To: <CABxs9V=DcRW_CbwMy6DBt41wgqVo=E36Ep2EsCpSFFtkN=XgLg@mail.gmail.com>
References: <CABxs9V=DcRW_CbwMy6DBt41wgqVo=E36Ep2EsCpSFFtkN=XgLg@mail.gmail.com>
Message-ID: <CAAcyNCwrfv-Hd7YPYWGiJQkfY=Y0Zuw1W5z5kafFGti_9Axp6w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/d29caf86/attachment.pl>

From wdunlap at tibco.com  Thu Jun  6 17:36:32 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 6 Jun 2013 15:36:32 +0000
Subject: [R] generate simple function with pre-defined constants
In-Reply-To: <CABxs9VnCDNt4pcty-1BQnr3UbEDx+WdKPO-08NTj4ud6U_CzTQ@mail.gmail.com>
References: <CABxs9V=DcRW_CbwMy6DBt41wgqVo=E36Ep2EsCpSFFtkN=XgLg@mail.gmail.com>
	<CABxs9VnCDNt4pcty-1BQnr3UbEDx+WdKPO-08NTj4ud6U_CzTQ@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C2FF771@PA-MBX01.na.tibco.com>

Try the following:
   generateABFunction <- function(a, b) {
      force(a)
      force(b)
      function(x) a*x + b
   }
   f12 <- generateABFunction(1, 2)
   f53 <- generateABFunction(5,6)
   f12(10:12) # get 12, 13, 14
   f53(10:12) # get 56, 61, 66

See, e.g., yesterday's discussion under the subject
"Trying to build up functions with its names by means of lapply"
on why the force() calls are required.  Read up on R's environments
to see why f12 and f53 look the same but act differently (hint:
look at ls.str(environment(f12))).

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Liviu Andronic
> Sent: Thursday, June 06, 2013 8:00 AM
> To: r-help at r-project.org Help
> Subject: Re: [R] generate simple function with pre-defined constants
> 
> On Thu, Jun 6, 2013 at 4:48 PM, Liviu Andronic <landronimirc at gmail.com> wrote:
> > Dear all,
> > Given:
> > a <- 2
> > b <- 3
> >
> > I'd like to obtain the following function:
> > f <- function(x) 2 + 3*x
> >
> > but when I do this:
> > f <- function(x) a + b*x
> > ##f
> > ##function(x) a + b*x
> >
> > the 'a' and 'b' objects do not get evaluated to their constants. How
> > could I do that?
> >
> I found one solution:
> a <- 2
> b <- 3
> f <- eval(parse(text=paste("function(z)", a, "+ z * ", b)))
> f
> ##function(z) 2 + z *  3
> 
> but I still have nightmares from:
> > fortune("parse")
> 
> If the answer is parse() you should usually rethink the question.
>    -- Thomas Lumley
>       R-help (February 2005)
> 
> Is there a nicer way to approach this? Thanks,
> Liviu
> 
> 
> > Thanks,
> > Liviu
> >
> >
> > --
> > Do you know how to read?
> > http://www.alienetworks.com/srtest.cfm
> > http://goodies.xfce.org/projects/applications/xfce4-dict#speed-reader
> > Do you know how to write?
> > http://garbl.home.comcast.net/~garbl/stylemanual/e.htm#e-mail
> 
> 
> 
> --
> Do you know how to read?
> http://www.alienetworks.com/srtest.cfm
> http://goodies.xfce.org/projects/applications/xfce4-dict#speed-reader
> Do you know how to write?
> http://garbl.home.comcast.net/~garbl/stylemanual/e.htm#e-mail
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From leonard.moulin at gmail.com  Thu Jun  6 15:51:01 2013
From: leonard.moulin at gmail.com (Leonard Moulin)
Date: Thu, 6 Jun 2013 15:51:01 +0200
Subject: [R] Problem with marginal effects of a multinomial logistic
	regression
Message-ID: <22BDCB12-9006-4839-987D-8AEEEEA480CC@me.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130606/5f4b9d4b/attachment.pl>

From roland.pape at uni-oldenburg.de  Thu Jun  6 16:41:24 2013
From: roland.pape at uni-oldenburg.de (Roland Pape)
Date: Thu, 6 Jun 2013 14:41:24 +0000
Subject: [R] Conditional coloring of area between curves
Message-ID: <4780FC16AA89574CA36BB63C15DF63A1014CA4EA@mbx02.w2kroot.uni-oldenburg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130606/bf6e72df/attachment.pl>

From jrkrideau at inbox.com  Thu Jun  6 17:48:29 2013
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 6 Jun 2013 07:48:29 -0800
Subject: [R] generating a bar chart with two axis for co-linear variable
In-Reply-To: <EB2D2D799706D645AA4808B7CB24D41A315BA864@MLBMBX4.marlabs.com>
Message-ID: <0A15E871AE8.00000B5Fjrkrideau@inbox.com>

I think we really need to see the code.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: sudha.krishnan at marlabs.com
> Sent: Thu, 6 Jun 2013 06:37:41 +0000
> To: r-help at r-project.org
> Subject: [R] generating a bar chart with two axis for co-linear variable
> 
> 
> 
> Hello Dimitris,
> 
> 
> 
> I was goggling for some help on Sensitivity vs 1-specificity and saw your
> link.
> 
> 
> 
> I hope you can be of help to me in one of the issue that I am facing in
> generating combo chart(bar chart and plot). I am a novice and have some
> difficulty in getting this logic correct.
> 
> 
> 
> 
> 
> I am give a dataset (I am attaching a sample dataset).
> 
> 
> 
> I am using a barplot() and passing values for percentage frequency and
> the corresponding variables. I am struck here, what my function does is
> only calculate the frequency for the listed variables and not the
> frequency percentage. Is there a method or a script with which I can pass
> the frequency percent and the related values as category columns for x
> axis?
> 
> 
> 
> I will attach the graphs that I have generated so that you can suggest
> the better way.
> 
> 
> 
> Sampledata - Sampledata.txt
> 
> What my function does to calculate the frequency with category names in X
> axis - 1.png
> 
> My requirement is to generate percentage frequency of the variable in y1
> and not the frequency itself. 2.png (where x categories are missing)
> 
> 
> 
> 
> 
> Thanks,
> 
> Sudha Krishnan
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From gunter.berton at gene.com  Thu Jun  6 17:48:36 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 6 Jun 2013 08:48:36 -0700
Subject: [R] Trying to build up functions with its names by means of
	lapply
In-Reply-To: <loom.20130606T171909-431@post.gmane.org>
References: <loom.20130605T043218-210@post.gmane.org>
	<250F03A2-77CE-4FAC-B1C9-6754567A3F6A@gmail.com>
	<51AF09A5.4080700@sapo.pt> <51AF0BE3.3050500@sapo.pt>
	<CACk-te21kO0xP+4RpvJrLVxoUZjbAVh_h6RbL0JxSwoBH2YwPg@mail.gmail.com>
	<loom.20130605T215734-601@post.gmane.org>
	<E66794E69CFDE04D9A70842786030B931C2FD621@PA-MBX01.na.tibco.com>
	<CACk-te1burUA2mSPDVjN_ZdB6iEkUhtUt3-jLBP0+rtWzYocCw@mail.gmail.com>
	<loom.20130606T171909-431@post.gmane.org>
Message-ID: <CACk-te39V25v_X=tki--Zay1CnD5dmVKLJ+JoD7n-fEdofbUCw@mail.gmail.com>

Sergio:

Fair question.

Unfair answer: My personal hangup. To my taste, get() makes R like a
macro language instead of doing functional programming. force() makes
me nervous about how I'm passing arguments. I won't attempt to defend
either of these claims, so feel free to dismiss.

Cheers,
Bert

On Thu, Jun 6, 2013 at 8:28 AM, Julio Sergio <juliosergio at gmail.com> wrote:
> Bert Gunter <gunter.berton <at> gene.com> writes:
>
>> Another equivalent way to do it?
>>
>> f2 <- function(c,nm = "gamma",...)
>> {
>>   probFunc <- paste0(c,nm)
>>   more <- list(...)
>>   function(x)do.call(probFunc,c(x,more))
>> }
>>
>> This avoids the explicit use of get() and force(), I believe, but are
>> there problems here I'm missing?
>>
>
> Thanks Bert. Since I'm relatively new in using this language, a question
> arises in my mind: why should the use of get() and force() be avoided? Is it
> just for syntactic clarity or is there another computational reason?
>
> Best regards,
>
>   -Sergio.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From markleeds2 at gmail.com  Thu Jun  6 17:56:56 2013
From: markleeds2 at gmail.com (Mark Leeds)
Date: Thu, 6 Jun 2013 11:56:56 -0400
Subject: [R] generate simple function with pre-defined constants
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C2FF771@PA-MBX01.na.tibco.com>
References: <CABxs9V=DcRW_CbwMy6DBt41wgqVo=E36Ep2EsCpSFFtkN=XgLg@mail.gmail.com>
	<CABxs9VnCDNt4pcty-1BQnr3UbEDx+WdKPO-08NTj4ud6U_CzTQ@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C2FF771@PA-MBX01.na.tibco.com>
Message-ID: <CAHz+bWbaeteqaK8Uac=qqXRoy+q+b7kgzzHx-gfMSyaPo=_o6A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130606/c2c32a2c/attachment.pl>

From wdunlap at tibco.com  Thu Jun  6 18:05:22 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 6 Jun 2013 16:05:22 +0000
Subject: [R] generate simple function with pre-defined constants
In-Reply-To: <CAHz+bWbaeteqaK8Uac=qqXRoy+q+b7kgzzHx-gfMSyaPo=_o6A@mail.gmail.com>
References: <CABxs9V=DcRW_CbwMy6DBt41wgqVo=E36Ep2EsCpSFFtkN=XgLg@mail.gmail.com>
	<CABxs9VnCDNt4pcty-1BQnr3UbEDx+WdKPO-08NTj4ud6U_CzTQ@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C2FF771@PA-MBX01.na.tibco.com>
	<CAHz+bWbaeteqaK8Uac=qqXRoy+q+b7kgzzHx-gfMSyaPo=_o6A@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C2FF7BE@PA-MBX01.na.tibco.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130606/5e4f046a/attachment.pl>

From markleeds2 at gmail.com  Thu Jun  6 18:09:18 2013
From: markleeds2 at gmail.com (Mark Leeds)
Date: Thu, 6 Jun 2013 12:09:18 -0400
Subject: [R] generate simple function with pre-defined constants
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C2FF7BE@PA-MBX01.na.tibco.com>
References: <CABxs9V=DcRW_CbwMy6DBt41wgqVo=E36Ep2EsCpSFFtkN=XgLg@mail.gmail.com>
	<CABxs9VnCDNt4pcty-1BQnr3UbEDx+WdKPO-08NTj4ud6U_CzTQ@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C2FF771@PA-MBX01.na.tibco.com>
	<CAHz+bWbaeteqaK8Uac=qqXRoy+q+b7kgzzHx-gfMSyaPo=_o6A@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C2FF7BE@PA-MBX01.na.tibco.com>
Message-ID: <CAHz+bWY=RCaTs9OBy8UU6ZPvSqya_SdZQgyUE2zYbFxmqWQwyA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130606/76dc10f4/attachment.pl>

From jwiley.psych at gmail.com  Thu Jun  6 18:15:26 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 6 Jun 2013 09:15:26 -0700
Subject: [R] generate simple function with pre-defined constants
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C2FF7BE@PA-MBX01.na.tibco.com>
References: <CABxs9V=DcRW_CbwMy6DBt41wgqVo=E36Ep2EsCpSFFtkN=XgLg@mail.gmail.com>
	<CABxs9VnCDNt4pcty-1BQnr3UbEDx+WdKPO-08NTj4ud6U_CzTQ@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C2FF771@PA-MBX01.na.tibco.com>
	<CAHz+bWbaeteqaK8Uac=qqXRoy+q+b7kgzzHx-gfMSyaPo=_o6A@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C2FF7BE@PA-MBX01.na.tibco.com>
Message-ID: <CANz9Z_+LDbOtjjFDCTTvkPBiXyFBkttXQBKp9jLmPq0aJr4vPQ@mail.gmail.com>

On Thu, Jun 6, 2013 at 9:05 AM, William Dunlap <wdunlap at tibco.com> wrote:
>
> I said the force was 'required' in the sense that without it
> the function will fail to do what you want in some situations.

With the Force on your side, functions always do what you want.

>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com


From szehnder at uni-bonn.de  Thu Jun  6 18:18:14 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Thu, 6 Jun 2013 18:18:14 +0200
Subject: [R] Optim seems not to work properly in foreach
In-Reply-To: <CAK4FJ1Bf-QVuQ6gH69N-sn8XFqTaR+B-KPpd=qXMjqJ=X28HbQ@mail.gmail.com>
References: <83F485E4-798D-404A-9912-0242E277DEE7@uni-bonn.de>
	<CAK4FJ1Bf-QVuQ6gH69N-sn8XFqTaR+B-KPpd=qXMjqJ=X28HbQ@mail.gmail.com>
Message-ID: <87D2004A-9BF1-4E3C-819B-093B25C9DBF6@uni-bonn.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130606/4d3ca5d4/attachment.pl>

From murdoch.duncan at gmail.com  Thu Jun  6 18:45:15 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 06 Jun 2013 12:45:15 -0400
Subject: [R] Conditional coloring of area between curves
In-Reply-To: <4780FC16AA89574CA36BB63C15DF63A1014CA4EA@mbx02.w2kroot.uni-oldenburg.de>
References: <4780FC16AA89574CA36BB63C15DF63A1014CA4EA@mbx02.w2kroot.uni-oldenburg.de>
Message-ID: <51B0BC9B.9020104@gmail.com>

On 06/06/2013 10:41 AM, Roland Pape wrote:
> Dear list,
>
> I have two time series of temperatures from different sites plotted in the same diagram and would like to color the area between the curves differently, dependent on whether site 1 is cooler than site 2 (colored let's say in blue) or warmer (red). While polygone() works fine to color the enclosed area in general, I'm struggling with this conditional coloring. Any help is greatly appreciated!

Suppose the series are named "site1" and "site2", and they have common 
times in a variable "times".  Then the following should do what you want:

smaller <- pmin(site1, site2)
plot(x, site1, ylim = range(c(site1, site2)), type="n")
polygon(c(x, rev(x)), c(smaller, rev(site1)), col="red")
polygon(c(x, rev(x)), c(smaller, rev(site2)), col="blue")

If the times for the two series are different it's a little harder; 
first you need to give them common times, and that will depend on how 
you decide to evaluate the values between observations. Probably linear 
interpolation (using approx()) is fine, but it's up to you.

Duncan Murdoch


From chirag.maru at ironfinancial.com  Thu Jun  6 17:49:56 2013
From: chirag.maru at ironfinancial.com (Chirag Maru)
Date: Thu, 6 Jun 2013 11:49:56 -0400
Subject: [R] RBloomberg: unable to use 'Corp' to fetch data
Message-ID: <531BA6749E246144AE2B081744F6F22F177EC491AC@pit-exmbx-13.smarshexchange.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130606/735b9e26/attachment.pl>

From sarah.goslee at gmail.com  Thu Jun  6 19:01:26 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 6 Jun 2013 13:01:26 -0400
Subject: [R] OT: FAQ 7.31
Message-ID: <CAM_vjumNDLC2=8yp3M52YBhyum0jjgdjP3_gL_9h0T1hoX514Q@mail.gmail.com>

Or, how to tell thinking like humans from thinking like computers:

www.smbc-comics.com/index.php?db=comics&id=2999


-- 
Sarah Goslee
http://www.functionaldiversity.org


From jvadams at usgs.gov  Thu Jun  6 20:29:00 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 6 Jun 2013 13:29:00 -0500
Subject: [R] reshape2 issue
In-Reply-To: <51AF4CCA.10104@gmail.com>
References: <51AF4CCA.10104@gmail.com>
Message-ID: <CAN5YmCFi8vcQQvurij5hb29NWiONX7Kv_5NdxW=Jc=S0dALJ9Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130606/92aa0cc7/attachment.pl>

From bernd.weiss at uni-koeln.de  Thu Jun  6 20:34:57 2013
From: bernd.weiss at uni-koeln.de (Bernd Weiss)
Date: Thu, 06 Jun 2013 20:34:57 +0200
Subject: [R] Add prediction interval forest plot (package "meta")
Message-ID: <51B0D651.6080900@uni-koeln.de>

Dear all,

I am struggling to add a prediction interval to a forest plot that was
created with forest.meta(), package "meta".

I checked the source of forest.meta() and realized that it is heavily
relying on grid. I am lacking any experience with grid graphics. So, I
am having difficulties to find out where the random effects estimate is
actually plotted in order to add prediction intervals.

Any help is much appreciated!

Bernd


R version 3.0.1 Patched (2013-05-28 r62825)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
LC_MONETARY=German_Germany.1252
[4] LC_NUMERIC=C                    LC_TIME=German_Germany.1252

attached base packages:
[1] grid      stats     graphics  grDevices utils     datasets  methods
  base

other attached packages:
[1] meta_2.3-0

loaded via a namespace (and not attached):
[1] tools_3.0.1


From smartpink111 at yahoo.com  Thu Jun  6 20:44:27 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 6 Jun 2013 11:44:27 -0700 (PDT)
Subject: [R] generating a bar chart with two axis for co-linear variable
In-Reply-To: <EB2D2D799706D645AA4808B7CB24D41A315BA864@MLBMBX4.marlabs.com>
References: <EB2D2D799706D645AA4808B7CB24D41A315BA864@MLBMBX4.marlabs.com>
Message-ID: <1370544267.26595.YahooMailNeo@web142601.mail.bf1.yahoo.com>

HI,

May be this helps:
dat1<- read.table("sampledata.txt",header=TRUE,sep=",",stringsAsFactors=FALSE)
pdf("Barplots.pdf")
?lst1<-lapply(seq_len(ncol(dat1)),function(i) {Ctdat<- table(dat1[,i]);Ctdat1<-(Ctdat/sum(Ctdat))*100;barplot(Ctdat1,ylim=c(0,100),xlab=colnames(dat1)[i],ylab="Relative Frequency",main=paste("Barplot:",colnames(dat1)[i],sep=" "))})
dev.off()
A.K.




----- Original Message -----
From: Sudha Krishnan <Sudha.Krishnan at marlabs.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Thursday, June 6, 2013 2:37 AM
Subject: [R]  generating a bar chart with two axis for co-linear variable



Hello Dimitris,



I was goggling for some help on Sensitivity vs 1-specificity and saw your link.



I hope you can be of help to me in one of the issue that I am facing in generating combo chart(bar chart and plot). I am a novice and have some difficulty in getting this logic correct.





I am give a dataset (I am attaching a sample dataset).



I am using a barplot() and passing values for percentage frequency and the corresponding variables. I am struck here, what my function does is only calculate the frequency for the listed variables and not the frequency percentage. Is there a method or a script with which I can pass the frequency percent and the related values as category columns for x axis?



I will attach the graphs that I have generated so that you can suggest the better way.



Sampledata - Sampledata.txt

What my function does to calculate the frequency with category names in X axis - 1.png

My requirement is to generate percentage frequency of the variable in y1 and not the frequency itself. 2.png (where x categories are missing)





Thanks,

Sudha Krishnan



______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jvadams at usgs.gov  Thu Jun  6 20:55:54 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 6 Jun 2013 13:55:54 -0500
Subject: [R] highlighted a certain time period on multiple plots
In-Reply-To: <CAAvu=b=weMhB0DnRQBDSmtrq-ryENgsUq0XdDWz5+TKAmNAstA@mail.gmail.com>
References: <CAAvu=b=weMhB0DnRQBDSmtrq-ryENgsUq0XdDWz5+TKAmNAstA@mail.gmail.com>
Message-ID: <CAN5YmCGA831HXfbnCJWC89kaUHnuLCYmZ6xichdoVjAo=Btcgw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130606/014113a9/attachment.pl>

From jluo.rhelp at gmail.com  Thu Jun  6 21:52:43 2013
From: jluo.rhelp at gmail.com (Jack Luo)
Date: Thu, 6 Jun 2013 15:52:43 -0400
Subject: [R] how to fit a glm model with all possible interactions between
 explanatory variables
Message-ID: <CAD-E8+62Cp7415YqFM2iEh1ZVkXPNzXU9kMhKmrGtVe2xyT9vA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130606/01c07224/attachment.pl>

From dwinsemius at comcast.net  Thu Jun  6 22:01:31 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 6 Jun 2013 13:01:31 -0700
Subject: [R] how to fit a glm model with all possible interactions
	between explanatory variables
In-Reply-To: <CAD-E8+62Cp7415YqFM2iEh1ZVkXPNzXU9kMhKmrGtVe2xyT9vA@mail.gmail.com>
References: <CAD-E8+62Cp7415YqFM2iEh1ZVkXPNzXU9kMhKmrGtVe2xyT9vA@mail.gmail.com>
Message-ID: <8D9C8B03-9F2C-49BA-A37D-17D3E674DBDB@comcast.net>


On Jun 6, 2013, at 12:52 PM, Jack Luo wrote:

> Hi,
> 
> I am trying to find a way to fit a glm model with all the possible
> interaction terms between different variables, without typing all the
> X1:X2, X1:X3,  in the formula, is there a way in R to do that?

The "*" operator does that:

  ~ X1 * X2 * X3

-- 
David Winsemius
Alameda, CA, USA


From gunter.berton at gene.com  Thu Jun  6 22:03:40 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 6 Jun 2013 13:03:40 -0700
Subject: [R] how to fit a glm model with all possible interactions
 between explanatory variables
In-Reply-To: <CAD-E8+62Cp7415YqFM2iEh1ZVkXPNzXU9kMhKmrGtVe2xyT9vA@mail.gmail.com>
References: <CAD-E8+62Cp7415YqFM2iEh1ZVkXPNzXU9kMhKmrGtVe2xyT9vA@mail.gmail.com>
Message-ID: <CACk-te3b9MNHidX9ErZovSc9tK3rUyo89aZAtVzqzpAg8EX96A@mail.gmail.com>

?formula

-- Bert

On Thu, Jun 6, 2013 at 12:52 PM, Jack Luo <jluo.rhelp at gmail.com> wrote:
> Hi,
>
> I am trying to find a way to fit a glm model with all the possible
> interaction terms between different variables, without typing all the
> X1:X2, X1:X3,  in the formula, is there a way in R to do that?
>
> Thanks,
>
> -Jack
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From david at revolutionanalytics.com  Thu Jun  6 22:14:53 2013
From: david at revolutionanalytics.com (David Smith)
Date: Thu, 6 Jun 2013 13:14:53 -0700
Subject: [R] Revolutions Blog: May Roundup
Message-ID: <CABgvEC_bEoYPD64xVKxjR3y5sBw0DMQdTAj36eyubSe-RwUebQ@mail.gmail.com>

Revolution Analytics staff write about R every weekday at the Revolutions blog:
 http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month
of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of May:

Billions of geotagged Tweets create a beautiful map of the world when
plotted with the ggmap package: http://bit.ly/111ZQq4

A review of Ryan Sheftel's talk at R/Finance, on how he uses R on the
trading desk at Credit Suisse: http://bit.ly/111ZQq5 . Also, a quick
take on some other talks at the meeting: http://bit.ly/111ZQq6

Two new R books to be published in July: Applied Predictive Modeling
(Kuhn and Johnson), and Dynamic Documents with R and knitr (Xie)
http://bit.ly/111ZQq3

Some organizations using R in 2013: Google, The New York Times,
Facebook, FourSquare, Twitter, John Deere, Zillow, FDA, NOAA and CFPB:
http://bit.ly/111ZOOX

Sentiment analysis on the Enron emails using R and Infinit.e used to
reveal signs of employee anxiety: http://bit.ly/111ZOOW

The 7th R/Rmetrics workshop will take place in Switzerland June
30-July 4: http://bit.ly/111ZOOY

Highlights from the Milwaukee Workshop on R and Bioinformatics:
http://bit.ly/111ZOOZ

An R script to simulate and animate an escape from a Zombie horde:
http://bit.ly/111ZQq7

R 3.0.1 has been released: http://bit.ly/111ZOP1

The May edition of the Revolution Analytics newsletter, including R
training courses and a new gaming webinar on June 13:
http://bit.ly/111ZQq8

Social network analysis in R, presented at the New Frontiers in
Computing Conference: http://bit.ly/111ZOP0

My somewhat controversial comparison of the terms "Statistics", "Data
Science" and "Business Intelligence" (with video for context):
http://bit.ly/111ZOP3

An updated list of resources for R users, including the top 3
resources for R beginners: http://bit.ly/111ZOP2

Noam Ross's useful guide to speeding up R code: http://bit.ly/111ZQqc

Trevor Hastie presents on lasso and elastic-net regularization with
the glmnet package at the Orange County R User Group:
http://bit.ly/111ZQqb

Video replay of the "What's new in Revolution R Enterprise 6.2"
webinar: http://bit.ly/111ZOP4

Further critiques of a SAS white paper benchmarking SAS and R:
http://bit.ly/111ZQqd

Video replay of my Strata presentation, "Real-time Big Data Analytics:
>From Deployment to Production": http://bit.ly/111ZOP5

Naive Bayes modeling for big data with the RevoScaleR package:
http://bit.ly/111ZQqe

An analysis of CRAN package updates and the most prolific package
maintainers: http://bit.ly/111ZQqf

The New York Times again uses R to develop an on-line data
visualization, this time on NFL draft data: http://bit.ly/111ZOP6

Some non-R stories in the past month included: chaotic double
pendulums (http://bit.ly/111ZQqg), Game of Thrones family trees
(http://bit.ly/111ZOP7), top Big Data accounts on Twitter
(http://bit.ly/111ZOP8), StackExchange for Open Data
(http://bit.ly/111ZOP9), logical fallacies (http://bit.ly/111ZOPa), an
animation of every known meteorite (http://bit.ly/111ZQqh) and places
singles meet (http://bit.ly/111ZOPb).

Meeting times for local R user groups (http://bit.ly/eC5YQe) can be
found on the updated R Community Calendar at: http://bit.ly/bb3naW

If you're looking for more articles about R, you can find summaries
from previous months at http://blog.revolutionanalytics.com/roundups/.
Join the Revolution mailing list at
http://revolutionanalytics.com/newsletter to be alerted to new
articles on a monthly basis.

As always, thanks for the comments and please keep sending suggestions
to me at david at revolutionanalytics.com . Don't forget you can also
follow the blog using an RSS reader, or by following me on Twitter
(I'm @revodavid).

Cheers,
# David

--
David M Smith <david at revolutionanalytics.com>
VP of Marketing, Revolution Analytics  http://blog.revolutionanalytics.com
Tel: +1 (650) 646-9523 (Seattle WA, USA)
Twitter: @revodavid
We're hiring! www.revolutionanalytics.com/careers


From michael.weylandt at gmail.com  Thu Jun  6 22:34:48 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Thu, 6 Jun 2013 21:34:48 +0100
Subject: [R] highlighted a certain time period on multiple plots
In-Reply-To: <CAAvu=b=weMhB0DnRQBDSmtrq-ryENgsUq0XdDWz5+TKAmNAstA@mail.gmail.com>
References: <CAAvu=b=weMhB0DnRQBDSmtrq-ryENgsUq0XdDWz5+TKAmNAstA@mail.gmail.com>
Message-ID: <CAAmySGMxHeHgOmdqH9j8LRPJqSLZdW=Qk=wH1gxBLF7UDgupsA@mail.gmail.com>

On Thu, Jun 6, 2013 at 6:43 AM, Ye Lin <yelin at lbl.gov> wrote:
> Hey All,
>
> I have a dataset like this:
>
> DatedayVar1Var2Var3Obs1/1/2013Tue23411/2/2013Wed23521/3/2013Thu24631/4/2013
> Fri24741/5/2013Sat24.5851/6/2013Sun24.9961/7/2013Mon25.31071/8/2013Tue25.711
> 81/9/2013Wed26.11291/10/2013Thu26.513101/11/2013Fri26.914111/12/2013Sat27.3
> 15121/13/2013Sun27.716131/14/2013Mon28.117141/15/2013Tue28.518151/16/2013Wed
> 28.919161/17/2013Thu29.320171/18/2013Fri29.721181/19/2013Sat210.12219
> 1/20/2013Sun210.523201/21/2013Mon210.924211/22/2013Tue211.325221/23/2013Wed2
> 11.726231/24/2013Thu212.127241/25/2013Fri212.528251/26/2013Sat212.92926
> 1/27/2013Sun213.330271/28/2013Mon213.731281/29/2013Tue214.132291/30/2013Wed2
> 14.533301/31/2013Thu214.93431
> Here is the code I use to plot:
>
> par(mar=c(10, 0.5, 0.5, 0.5))
> par(mfrow=c(3,1))
> plot(Var1~Obs,data=dat,xaxt="n",xlab="")
> plot(Var2~Obs,data=dat,xaxt="n",xlab="")
> plot(Var3~Obs,data=dat,xaxt="n",xlab="")
> axis(1,at=dat$Obs,label=dat$Date)
> mtext(1,text="Date",line=2.5)
> axis(1,at=dat$Obs,label=dat$day,line=4)
> mtext(1,text="Day of week",line=7)
>
> How can I remove the extra white space between plots and emphasize time
> periods=weekend with dashed area?? I have attached original output and
> ideal output I am looking for.

Take a look at my "xtsExtra" package off of R-forge:

## Using your data as Jean arranged it.
library(xtsExtra)

dat2 <- xts(dat[,c(3,4,5)], as.Date(dat[,1], format = "%m/%d/%Y"))

plot(dat2, yax.loc = "left")

and look at

example(plot.xts)

for how to do shading / lines as desired.

Cheers,
MW

>
> Any suggestion to emphasize/highlight weekend periods is really appreciate!
>
> Thanks!
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Thu Jun  6 23:06:06 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 6 Jun 2013 14:06:06 -0700 (PDT)
Subject: [R] generating a bar chart with two axis for co-linear variable
In-Reply-To: <1370544267.26595.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <EB2D2D799706D645AA4808B7CB24D41A315BA864@MLBMBX4.marlabs.com>
	<1370544267.26595.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1370552766.76220.YahooMailNeo@web142601.mail.bf1.yahoo.com>

HI,
Not sure if this is what you wanted.

pdf("BarplotsNew.pdf")
library(plotrix)
lst2<-lapply(seq_len(ncol(dat1)),function(i){
??? ??? ??? ??? ??? Ctdat<- table(dat1[,i])
??? ??? ??? ??? ??? Ctdat1<-(Ctdat/sum(Ctdat))*100
??? ??? ??? ??? ??? dat2<-data.frame(Ctdat,Ctdat1,stringsAsFactors=FALSE)[,-3]
??? ??? ??? ??? ??? colnames(dat2)[3]<-"Rel.Freq"
??? ??? ??? ??? ??? dat2[,1]<- as.numeric(as.character(dat2[,1]))
??? ??? ??? ??? ??? with(dat2,twoord.plot(Var1,Rel.Freq,Freq,
??? ??? ??? ??? ??? ??? lylim=c(0,100),rylim=c(0,1000),
??? ??? ??? ??? ??? ??? ylab="Relative Frequency",
??? ??? ??? ??? ??? ??? rylab="Frequency",main=paste("Bar plot:",colnames(dat1)[i],sep=" "),
??? ??? ??? ??? ??? ??? type=c("bar","l"),lcol=2,rcol=4,xtickpos=Var1,xticklab=Var1))
??? ??? ??? ??? ??? ??? })
?dev.off()

A.K.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Sudha Krishnan <Sudha.Krishnan at marlabs.com>
Cc: R help <r-help at r-project.org>
Sent: Thursday, June 6, 2013 2:44 PM
Subject: Re: [R]  generating a bar chart with two axis for co-linear variable

HI,

May be this helps:
dat1<- read.table("sampledata.txt",header=TRUE,sep=",",stringsAsFactors=FALSE)
pdf("Barplots.pdf")
?lst1<-lapply(seq_len(ncol(dat1)),function(i) {Ctdat<- table(dat1[,i]);Ctdat1<-(Ctdat/sum(Ctdat))*100;barplot(Ctdat1,ylim=c(0,100),xlab=colnames(dat1)[i],ylab="Relative Frequency",main=paste("Barplot:",colnames(dat1)[i],sep=" "))})
dev.off()
A.K.




----- Original Message -----
From: Sudha Krishnan <Sudha.Krishnan at marlabs.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Thursday, June 6, 2013 2:37 AM
Subject: [R]? generating a bar chart with two axis for co-linear variable



Hello Dimitris,



I was goggling for some help on Sensitivity vs 1-specificity and saw your link.



I hope you can be of help to me in one of the issue that I am facing in generating combo chart(bar chart and plot). I am a novice and have some difficulty in getting this logic correct.





I am give a dataset (I am attaching a sample dataset).



I am using a barplot() and passing values for percentage frequency and the corresponding variables. I am struck here, what my function does is only calculate the frequency for the listed variables and not the frequency percentage. Is there a method or a script with which I can pass the frequency percent and the related values as category columns for x axis?



I will attach the graphs that I have generated so that you can suggest the better way.



Sampledata - Sampledata.txt

What my function does to calculate the frequency with category names in X axis - 1.png

My requirement is to generate percentage frequency of the variable in y1 and not the frequency itself. 2.png (where x categories are missing)





Thanks,

Sudha Krishnan



______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: BarplotsNew.pdf
Type: application/pdf
Size: 29361 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130606/4a9a0aae/attachment.pdf>

From rolf.turner at xtra.co.nz  Fri Jun  7 00:22:18 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Fri, 07 Jun 2013 10:22:18 +1200
Subject: [R] SPlus script
In-Reply-To: <1370531969.88020.YahooMailNeo@web142705.mail.bf1.yahoo.com>
References: <1370438435.93923.YahooMailNeo@web142703.mail.bf1.yahoo.com>
	<E66794E69CFDE04D9A70842786030B931C2FD5C4@PA-MBX01.na.tibco.com>
	<1370523739.92423.YahooMailNeo@web142703.mail.bf1.yahoo.com>
	<CA+vqiLGCTXQDEzzbeZDf-_EddiGQ=xx4P9n_3EJ2HkN1-qTMQg@mail.gmail.com>
	<1370531969.88020.YahooMailNeo@web142705.mail.bf1.yahoo.com>
Message-ID: <51B10B9A.5060406@xtra.co.nz>

On 07/06/13 03:19, Scott Raynaud wrote:
> I actually had tried placing arguments in the call but it didn't work.   However, I did
> not think about writing it to a variable and printing.  That seems to have done the
> trick.  Funny, I don't remember having to do that before, but that's not surprising.
>

If I remember correctly --- haven't used Splus for decades --- this is a 
difference
between Splus and R.

In R the output of a function is returned *invisibly* if that function 
is called
from within another function.  And source() is one such other function.

So if you have a script, say "melvin" with the single line:

     sin(42)

and in R you execute

     source("melvin")

you will see no output.  If in another script, say "clyde" you have the
single line

     print(sin(42))

and in R you execute

     source("clyde")

you will see

     [1] -0.9165215

In Splus, IIRC, the print() call is unnecessary.  I.e. you would get the 
same
result by sourcing "melvin" and "clyde".

Current Splus users may correct me if I am wrong about this.

     cheers,

         Rolf Turner


From jim at bitwrit.com.au  Fri Jun  7 01:59:19 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 07 Jun 2013 09:59:19 +1000
Subject: [R] Not sure this is something R could do but it feels like it
 should be.
In-Reply-To: <20130606150318.57E504483A7@nhs-pd1e-esg101.ad1.nhs.net>
References: <20130606150318.57E504483A7@nhs-pd1e-esg101.ad1.nhs.net>
Message-ID: <51B12257.1010602@bitwrit.com.au>

On 06/07/2013 01:03 AM, Polwart Calum (COUNTY DURHAM AND DARLINGTON NHS 
FOUNDATION TRUST) wrote:
> Some colleagues nationally have developed a system which means they can pick the optimal sets of doses for a drug.  The system could apply to a number of drugs.  But the actual doses might vary.  To try and explain this in terms that the average Joe on the street might understand if you have some amoxicillin antibiotic for a chest infection the normal dose for an adult is 250 to 500mg increased to maybe 1000mg in severe cases.
>
> For a child it is dosed from a liquid and people usually go from 62.5mg, 125mg to 250mg although you could measure any volume you wanted.
>
> What this new method has developed is a means to pick the "right" standard doses so what above is 62.5, 125, 250, 500, 1000.  However the method they've used is really engineered about ensure the jump between doses is correct - you'll notice that the list above is a doubling up method.
>
> But you can also have a doubling up method that went 50, 100, 200, 400, 800, 1600  and pretty much as many as you can think of depending on your starting point and there is no scientific means to pick that starting point.  So colleagues have developed their rather more complex equivalent of the doubling method to determine the doses they need but they need to know if they should start at 40, 50, 62.5 or some other number.
>
> Once they have the starting number they can calculate all the other doses.  I realise R can do that, and I realise using a loop of possible starting numbers it can build all those options.
>
> Each patient then has a theoretical dose they should get lets say that's 10mg/kg and you might treat patients from 5 to 120kg.  They are then looking to calculate the variance for each dose range so if we take the 50, 100, 200, 400 model and said you'd give 50mg to anyone needing 0?? to 75mg 100mg to anyone needing 76 - 150mg etc... from there they are taking that range and saying that's a 31% overdose to a 33% underdose.  Then they want to find if there is a starting number which minimises the extent of under and overdosing...
>
> Anyone know of an existing stats function in R that can easily do that and almost then report from some inputs a single number that is the "best fit"?
>
> Calum
>
Hi Calum,
I can only answer from the perspective of someone who calculated doses 
of alcohol for experimental subjects many years ago. It was not possible 
to apply a linear function across the range due to a number of factors. 
One is that BAC, which was the target value, is dependent upon the 
proportion of the weight that represents the water compartment of the 
body. This varies with both weight (heavier people typically have a 
higher proportion of fat) and sex (women also tend to have slightly more 
fat). The real monkey wrench in the works was absorption rate, which 
often made nonsense of my calculations. This may not be as important in 
therapeutic drugs, for we were aiming at a specified BAC at a certain 
time after dosing rather than an average level. However, I suspect that 
many therapeutic drugs have a different dose by weight for children (we 
weren't dosing children) and choosing a starting point at the bottom of 
the range would almost certainly introduce a systematic error. My 
intuition would be to anchor the dosage rate in the middle of the scale 
and then extrapolate in both directions (adults only, of course).

Jim


From rebecca.greenblatt at gmail.com  Thu Jun  6 21:58:18 2013
From: rebecca.greenblatt at gmail.com (Rebecca Greenblatt)
Date: Thu, 6 Jun 2013 15:58:18 -0400
Subject: [R] sample size determination - comparing means for different size
	samples
Message-ID: <CAHd-2N452L=1d6R2LwGoUO_7QVj7UyNT-NX_20kE8V+5+RSHTQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130606/19fc887e/attachment.pl>

From mikeumo at gmail.com  Thu Jun  6 22:34:53 2013
From: mikeumo at gmail.com (Mikhail Umorin)
Date: Thu, 06 Jun 2013 15:34:53 -0500
Subject: [R] Distance-based non-parametric ANOVA
Message-ID: <2093686.8QetdgVmrY@localhost>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130606/1d0b23c0/attachment.pl>

From andres.holz at utas.edu.au  Fri Jun  7 05:19:36 2013
From: andres.holz at utas.edu.au (andres.holz)
Date: Thu, 6 Jun 2013 20:19:36 -0700 (PDT)
Subject: [R] error running mvabund package
Message-ID: <1370575176124-4668879.post@n4.nabble.com>

Dear All,

This is my first post, and probably (and hence apologies that) my question
is very silly!
 
I'm having issues with a the mvabund package
(http://cran.r-project.org/web/packages/mvabund/index.html), 
and would be great to get some help!

Here is the code (and files are attached):

library(mvabund)
##visualizing data
florabund <- read.csv("CPL_floristics_abund_v1d.csv", header=TRUE)
vegtype <- read.csv("CPL_vegtype_all_v1b.csv", header=TRUE)
transect <- read.csv("CPL_transect_all_v1b.csv", header=TRUE)

cplflorabund <-mvabund(florabund, check.rows=FALSE, check.names=TRUE)
vegtype=as.factor(vegtype$vegtype)
plot(cplflorabund~vegtype) #there is a column called "treatment", and
another called "block"
plot.mvabund(cplflorabund)

##Fitting predictive models
transect=as.factor(transect$transect)
flormat=as.matrix(florabund)
abund.nb <-manyglm(flormat~transect*vegtype, family="nagative.binomial") 

predict(abund.nb, type= "response") 

##Checking Model Assumptions
plot(abund.nb) 

meanvar.plot(flormat~transect, col=as.numeric (vegtype)) #direct plot of
mean-variace relationship

anova(abund.nb, p.uni="adjusted") 

It's after running the last code line  [>anova(abund.nb, p.uni="adjusted")],
when I get thiis error:

Error in XvarIn[nterms - i, varseq > i + minterm] <- 0 : 
  (subscript) logical subscript too long

Any idea what I'm doing wrong?  I've tried shortening the length of all
files, but didn't matter. 

Thanks so much for your time!!

Cheers,
Andr?s 

errorrunningmvabund.zip
<http://r.789695.n4.nabble.com/file/n4668879/errorrunningmvabund.zip>  



--
View this message in context: http://r.789695.n4.nabble.com/error-running-mvabund-package-tp4668879.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Fri Jun  7 06:10:32 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 6 Jun 2013 21:10:32 -0700
Subject: [R] sample size determination - comparing means for different
	size samples
In-Reply-To: <CAHd-2N452L=1d6R2LwGoUO_7QVj7UyNT-NX_20kE8V+5+RSHTQ@mail.gmail.com>
References: <CAHd-2N452L=1d6R2LwGoUO_7QVj7UyNT-NX_20kE8V+5+RSHTQ@mail.gmail.com>
Message-ID: <4E03CAFC-A353-4909-8F8E-C6A1B1E538E3@comcast.net>

This is a duplicate question, right?

On Jun 6, 2013, at 12:58 PM, Rebecca Greenblatt wrote:

> Looking to determine sample sizes for both my experimental and control
> groups (I want only a small portion of my participants in my experimental
> condition) in order to compare population means. I would be able to
> estimate standard deviation beforehand.
> 
> I'm using the bpower function from the Hmisc R package, specifically
> bsamsize to compare population proportions, but was wondering if there was
> an equivalent function for comparing means.
> 
> -- 
> Rebecca Greenblatt
> 
> 	[[alternative HTML version deleted]]
> 

David Winsemius
Alameda, CA, USA


From kpmainali at gmail.com  Fri Jun  7 06:46:00 2013
From: kpmainali at gmail.com (Kumar Mainali)
Date: Thu, 6 Jun 2013 23:46:00 -0500
Subject: [R] lineplot.ci{sciplot}: Split x.factor label in two lines
Message-ID: <CABK368hOjVv5gkN7pOc7G7Qf3B1jC-RkeXmYzFVxGZ6YXcQzeA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130606/9bf0a2e5/attachment.pl>

From rune.haubo at gmail.com  Fri Jun  7 07:04:46 2013
From: rune.haubo at gmail.com (Rune Haubo)
Date: Fri, 7 Jun 2013 07:04:46 +0200
Subject: [R] multilevel binary and ordered regression models
In-Reply-To: <CADe_g+W+1cZOoGFquWxc7xt9qUoBLKQU43ApGVrRbrkEk3PdTg@mail.gmail.com>
References: <CADe_g+W+1cZOoGFquWxc7xt9qUoBLKQU43ApGVrRbrkEk3PdTg@mail.gmail.com>
Message-ID: <CAG_uk918pXxQcj4H1bsLz56BXJU7APaKm45MKVMRrXVUMKBC+w@mail.gmail.com>

On 6 June 2013 00:13, Xu Jun <junxu.r at gmail.com> wrote:
> Dear r-helpers,
>
> I have two questions on multilevel binary and ordered regression models,
> respectively:
>
> 1. Is there any r function (like lmer or glmer) to run multilevel ordered
> regression models?

Yes, package ordinal will fit such models.

Cheers,
Rune


From highstat at highstat.com  Fri Jun  7 10:28:12 2013
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Fri, 07 Jun 2013 09:28:12 +0100
Subject: [R] 5 remaining places on stats course in Edmonton
Message-ID: <51B1999C.1060702@highstat.com>

There are 5 remaining places on the following course:


Data exploration, regression, GLM & GAM. With introduction to R

When: 26 - 30 August 2013.
Where: Edmonton, Canada

For details, see: http://www.highstat.com/statscourse.htm
Course flyer: http://www.highstat.com/Courses/Flyer2013_09Canada.pdf



Kind regards,

Alain Zuur



-- 

Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007).
Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
URL: www.springer.com/0-387-45967-7


2. Mixed effects models and extensions in ecology with R. (2009).
Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9


3. A Beginner's Guide to R (2009).
Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
http://www.springer.com/statistics/computational/book/978-0-387-93836-3


4. Zero Inflated Models and Generalized Linear Mixed Models with R. (2012) Zuur, Saveliev, Ieno.
http://www.highstat.com/book4.htm

Other books: http://www.highstat.com/books.htm


Statistical consultancy, courses, data analysis and software
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com


From ruipbarradas at sapo.pt  Fri Jun  7 10:50:53 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 07 Jun 2013 09:50:53 +0100
Subject: [R] sample size determination - comparing means for different
 size samples
In-Reply-To: <CAHd-2N452L=1d6R2LwGoUO_7QVj7UyNT-NX_20kE8V+5+RSHTQ@mail.gmail.com>
References: <CAHd-2N452L=1d6R2LwGoUO_7QVj7UyNT-NX_20kE8V+5+RSHTQ@mail.gmail.com>
Message-ID: <51B19EED.9000709@sapo.pt>

Hello,

At an R prompt, type

?power.t.test

Hope this helps,

Rui Barradas

Em 06-06-2013 20:58, Rebecca Greenblatt escreveu:
> Looking to determine sample sizes for both my experimental and control
> groups (I want only a small portion of my participants in my experimental
> condition) in order to compare population means. I would be able to
> estimate standard deviation beforehand.
>
> I'm using the bpower function from the Hmisc R package, specifically
> bsamsize to compare population proportions, but was wondering if there was
> an equivalent function for comparing means.
>


From dchristop at econ.uoa.gr  Fri Jun  7 09:08:07 2013
From: dchristop at econ.uoa.gr (dchristop)
Date: Fri, 7 Jun 2013 00:08:07 -0700 (PDT)
Subject: [R] Identifying breakpoints/inflection points?
In-Reply-To: <q2i35fefd7e1004261506g8df50co8302f04380ed57be@mail.gmail.com>
References: <q2i35fefd7e1004261506g8df50co8302f04380ed57be@mail.gmail.com>
Message-ID: <1370588887318-4668889.post@n4.nabble.com>

You can try this:

library(inflection)
#you have to instsall package inflection first
a<-findiplist(cbind(year),cbind(piproute),1)
a

The answer:
     [,1] [,2]   [,3]
[1,]    5   35 1986.0
[2,]    5   30 1983.5

shows that the total inflection point is between 1983 and 1986, if we treat
data as first concave and then convex, as it can be found from a simple
graph.



--
View this message in context: http://r.789695.n4.nabble.com/Identifying-breakpoints-inflection-points-tp2065886p4668889.html
Sent from the R help mailing list archive at Nabble.com.


From gpagnoni at gmail.com  Fri Jun  7 10:51:32 2013
From: gpagnoni at gmail.com (Giuseppe Pagnoni)
Date: Fri, 7 Jun 2013 10:51:32 +0200
Subject: [R] Function nlme::lme in Ubuntu (but not Win or OS X):
 "Non-positive definite approximate variance-covariance"
Message-ID: <CAAdktEy=tWmoVe5vF56hZMcRgMHEgn61HXi98mG0R+2L9ApEBA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/21d478f3/attachment.pl>

From lmramba at ufl.edu  Fri Jun  7 10:59:55 2013
From: lmramba at ufl.edu (Laz)
Date: Fri, 07 Jun 2013 04:59:55 -0400
Subject: [R] R help on loops
In-Reply-To: <CAAxdm-6=KLifDLfD=ZTxn8Mu7c0nPpuKUAf6BN6_Uh_jQqURTQ@mail.gmail.com>
References: <51A8E5C7.1010306@ufl.edu>
	<CAAxdm-6=KLifDLfD=ZTxn8Mu7c0nPpuKUAf6BN6_Uh_jQqURTQ@mail.gmail.com>
Message-ID: <51B1A10B.4060006@ufl.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/33659483/attachment.pl>

From rguy at 123mail.org  Fri Jun  7 10:03:24 2013
From: rguy at 123mail.org (Rguy)
Date: Fri, 7 Jun 2013 09:03:24 +0100
Subject: [R] boot, what am I doing wrong?
Message-ID: <CAEorq2ONrHdCPgmDad_bTYBo-AdWmGy3G6USOmKPpZ1DMYO6Lg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/f3caf307/attachment.pl>

From jorgeivanvelez at gmail.com  Fri Jun  7 11:13:51 2013
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Fri, 7 Jun 2013 19:13:51 +1000
Subject: [R] boot, what am I doing wrong?
In-Reply-To: <CAEorq2ONrHdCPgmDad_bTYBo-AdWmGy3G6USOmKPpZ1DMYO6Lg@mail.gmail.com>
References: <CAEorq2ONrHdCPgmDad_bTYBo-AdWmGy3G6USOmKPpZ1DMYO6Lg@mail.gmail.com>
Message-ID: <CAKL8G3G+ZhZPv_+OMKZOnkZQMMH3FTUNR_f=tbuj+jrEUbsGZA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/74dd54d9/attachment.pl>

From bhh at xs4all.nl  Fri Jun  7 11:24:36 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 7 Jun 2013 11:24:36 +0200
Subject: [R] R help on loops
In-Reply-To: <51B1A10B.4060006@ufl.edu>
References: <51A8E5C7.1010306@ufl.edu>
	<CAAxdm-6=KLifDLfD=ZTxn8Mu7c0nPpuKUAf6BN6_Uh_jQqURTQ@mail.gmail.com>
	<51B1A10B.4060006@ufl.edu>
Message-ID: <9886C555-B547-4E8B-923C-12A916B54913@xs4all.nl>


On 07-06-2013, at 10:59, Laz <lmramba at ufl.edu> wrote:

> Dear R users,
> 
> I am stuck here: My first function returns a vector of 5 values.
> In my second function, I want to repeat this, a number of times, say 10 
> so that I have 10 rows and five columns but I keep on getting errors.
> 
> See the code and results below:
> 
> optm <-function(perm, verbose = FALSE)
> {
>   trace<-c()
>   for (k in 1:perm){
> trace[k]<-Rspatswap(rhox=0.6,rhoy=0.6,sigmasqG=0.081,SsqR=1)[1]
>     perm[k]<-k
>     mat<-cbind(trace, perm = seq(perm))
>   }
>   if (verbose){
>     cat("***starting matrix\n")
>     print(mat)
>   }
>   # iterate till done
>   while(nrow(mat) > 1){
>     high <- diff(mat[, 'trace']) > 0
>     if (!any(high)) break  # done
>     # find which one to delete
>     delete <- which.max(high) + 1L
>     mat <- mat[-delete, ]
>     newmat<-apply(mat,2,mean)[1]
>     sdm<-sd(mat[,1])
>     sem<-sdm/sqrt(nrow(mat))
>     maxv<-mat[1,1]
>     minv<-mat[nrow(mat),1]
>       }
>   stats<-cbind(average=newmat,sd=sdm,se=sem,min=minv,max=maxv)
>   stats
> }
> 
>> test<-optm(perm=20)
>> test
>         average           sd           se       min      max
> trace 0.8880286 0.0009178193 0.0004589096 0.8870152 0.889241
> 
> 
> itn<-function(it){
> siml<-matrix(NA,ncol=5,nrow=length(it))
>   for(g in 1:it){
>    siml[g]<-optm(perm=20)
>   }
> siml<-cbind(siml=siml)
> siml
> }
> 
>> ans<-itn(5)
> Warning messages:
> 1: In siml[g] <- optm(perm = 20) :
>   number of items to replace is not a multiple of replacement length
> 2: In siml[g] <- optm(perm = 20) :
>   number of items to replace is not a multiple of replacement length
> 3: In siml[g] <- optm(perm = 20) :
>   number of items to replace is not a multiple of replacement length
> 4: In siml[g] <- optm(perm = 20) :
>   number of items to replace is not a multiple of replacement length
> 5: In siml[g] <- optm(perm = 20) :
>   number of items to replace is not a multiple of replacement length
>> ans
>           [,1]      [,2]      [,3]      [,4]      [,5]
> [1,] 0.8874234 0.8861666 0.8880521 0.8870958 0.8876469
> 


1. Not reproducible code. Where does function Rspatswap come from?

2. You have several errors in function itn:
    Argument it is a scalar: length(it) is 1. You need to do siml <- matrix(NA,ncol=5,nrow=it)
Next in the g-loop you want to fill row g so do: siml[g,] <- ?..

Finally why are you doing siml <- cbind(siml=siml)?
Seems superfluous to me. Delete the line.

Berend


From cecilia.carmo at ua.pt  Fri Jun  7 11:37:49 2013
From: cecilia.carmo at ua.pt (Cecilia Carmo)
Date: Fri, 7 Jun 2013 09:37:49 +0000
Subject: [R] matched samples, dataframe, panel data
Message-ID: <104083AE5AAA634C993249DFCCE4C203064395C6@CIPRESTE.ua.pt>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/d09c5ce9/attachment.pl>

From lmramba at ufl.edu  Fri Jun  7 11:39:36 2013
From: lmramba at ufl.edu (Laz)
Date: Fri, 07 Jun 2013 05:39:36 -0400
Subject: [R] R help on loops
In-Reply-To: <9886C555-B547-4E8B-923C-12A916B54913@xs4all.nl>
References: <51A8E5C7.1010306@ufl.edu>
	<CAAxdm-6=KLifDLfD=ZTxn8Mu7c0nPpuKUAf6BN6_Uh_jQqURTQ@mail.gmail.com>
	<51B1A10B.4060006@ufl.edu>
	<9886C555-B547-4E8B-923C-12A916B54913@xs4all.nl>
Message-ID: <51B1AA58.6070000@ufl.edu>

Dear Berend,

For reproducibility,
Rspatswap() is a function which originally returns a single value. For 
example Rspatswap(...)  and you get 0.8

So, run Rspatswap() 20 times and store all the values.
Then from these 20 values, calculate the calculate average, 
sd,se,min,max to get something similar to:

         average           sd           se       min      max
trace 0.8880286 0.0009178193 0.0004589096 0.8870152 0.889241

If we repeat the function 10 times, then I expect 10 rows with 5 columns but it does not work ?

I hope I am now clearer...







On 6/7/2013 5:24 AM, Berend Hasselman wrote:
> On 07-06-2013, at 10:59, Laz <lmramba at ufl.edu> wrote:
>
>> Dear R users,
>>
>> I am stuck here: My first function returns a vector of 5 values.
>> In my second function, I want to repeat this, a number of times, say 10
>> so that I have 10 rows and five columns but I keep on getting errors.
>>
>> See the code and results below:
>>
>> optm <-function(perm, verbose = FALSE)
>> {
>>    trace<-c()
>>    for (k in 1:perm){
>> trace[k]<-Rspatswap(rhox=0.6,rhoy=0.6,sigmasqG=0.081,SsqR=1)[1]
>>      perm[k]<-k
>>      mat<-cbind(trace, perm = seq(perm))
>>    }
>>    if (verbose){
>>      cat("***starting matrix\n")
>>      print(mat)
>>    }
>>    # iterate till done
>>    while(nrow(mat) > 1){
>>      high <- diff(mat[, 'trace']) > 0
>>      if (!any(high)) break  # done
>>      # find which one to delete
>>      delete <- which.max(high) + 1L
>>      mat <- mat[-delete, ]
>>      newmat<-apply(mat,2,mean)[1]
>>      sdm<-sd(mat[,1])
>>      sem<-sdm/sqrt(nrow(mat))
>>      maxv<-mat[1,1]
>>      minv<-mat[nrow(mat),1]
>>        }
>>    stats<-cbind(average=newmat,sd=sdm,se=sem,min=minv,max=maxv)
>>    stats
>> }
>>
>>> test<-optm(perm=20)
>>> test
>>          average           sd           se       min      max
>> trace 0.8880286 0.0009178193 0.0004589096 0.8870152 0.889241
>>
>>
>> itn<-function(it){
>> siml<-matrix(NA,ncol=5,nrow=length(it))
>>    for(g in 1:it){
>>     siml[g]<-optm(perm=20)
>>    }
>> siml<-cbind(siml=siml)
>> siml
>> }
>>
>>> ans<-itn(5)
>> Warning messages:
>> 1: In siml[g] <- optm(perm = 20) :
>>    number of items to replace is not a multiple of replacement length
>> 2: In siml[g] <- optm(perm = 20) :
>>    number of items to replace is not a multiple of replacement length
>> 3: In siml[g] <- optm(perm = 20) :
>>    number of items to replace is not a multiple of replacement length
>> 4: In siml[g] <- optm(perm = 20) :
>>    number of items to replace is not a multiple of replacement length
>> 5: In siml[g] <- optm(perm = 20) :
>>    number of items to replace is not a multiple of replacement length
>>> ans
>>            [,1]      [,2]      [,3]      [,4]      [,5]
>> [1,] 0.8874234 0.8861666 0.8880521 0.8870958 0.8876469
>>
>
> 1. Not reproducible code. Where does function Rspatswap come from?
>
> 2. You have several errors in function itn:
>      Argument it is a scalar: length(it) is 1. You need to do siml <- matrix(NA,ncol=5,nrow=it)
> Next in the g-loop you want to fill row g so do: siml[g,] <- ?..
>
> Finally why are you doing siml <- cbind(siml=siml)?
> Seems superfluous to me. Delete the line.
>
> Berend
>
>


From roland.pape at uni-oldenburg.de  Fri Jun  7 11:51:10 2013
From: roland.pape at uni-oldenburg.de (Roland Pape)
Date: Fri, 7 Jun 2013 09:51:10 +0000
Subject: [R] Conditional coloring of area between curves
In-Reply-To: <51B0BC9B.9020104@gmail.com>
References: <4780FC16AA89574CA36BB63C15DF63A1014CA4EA@mbx02.w2kroot.uni-oldenburg.de>,
	<51B0BC9B.9020104@gmail.com>
Message-ID: <4780FC16AA89574CA36BB63C15DF63A1014CA54D@mbx02.w2kroot.uni-oldenburg.de>

Hi Duncan,

that's exactly what I was looking for! The series have common times, so that's no problem. Thanks a lot!

Roland
________________________________________
Von: Duncan Murdoch [murdoch.duncan at gmail.com]
Gesendet: Donnerstag, 6. Juni 2013 18:45
An: Roland Pape
Cc: r-help at r-project.org
Betreff: Re: [R] Conditional coloring of area between curves

On 06/06/2013 10:41 AM, Roland Pape wrote:
> Dear list,
>
> I have two time series of temperatures from different sites plotted in the same diagram and would like to color the area between the curves differently, dependent on whether site 1 is cooler than site 2 (colored let's say in blue) or warmer (red). While polygone() works fine to color the enclosed area in general, I'm struggling with this conditional coloring. Any help is greatly appreciated!

Suppose the series are named "site1" and "site2", and they have common
times in a variable "times".  Then the following should do what you want:

smaller <- pmin(site1, site2)
plot(x, site1, ylim = range(c(site1, site2)), type="n")
polygon(c(x, rev(x)), c(smaller, rev(site1)), col="red")
polygon(c(x, rev(x)), c(smaller, rev(site2)), col="blue")

If the times for the two series are different it's a little harder;
first you need to give them common times, and that will depend on how
you decide to evaluate the values between observations. Probably linear
interpolation (using approx()) is fine, but it's up to you.

Duncan Murdoch


From Jose.Iparraguirre at ageuk.org.uk  Fri Jun  7 11:52:02 2013
From: Jose.Iparraguirre at ageuk.org.uk (Jose Iparraguirre)
Date: Fri, 7 Jun 2013 10:52:02 +0100
Subject: [R] Distance-based non-parametric ANOVA
In-Reply-To: <2093686.8QetdgVmrY@localhost>
References: <2093686.8QetdgVmrY@localhost>
Message-ID: <E0807BF04F0D0C419BF2B39803E98582010E3BB3BCFA@AGEPXCH002C.uk.age.local>

Hi Mikhail,

After a cursory online search using simply " A new method for non-parametric multivariate analysis" + CRAN + R, I got the following three packages which include this paper in their references: vegan, mefa, and TraMineR. I don't know whether they deal with the procedure you are after, but it would be worth having a look.
Regards,
Jos?

Prof. Jos? Iparraguirre
Chief Economist
Age UK

Age UK
Tavis House, 1- 6 Tavistock Square
London, WC1H 9NB

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Mikhail Umorin
Sent: 06 June 2013 21:35
To: r-help at r-project.org
Subject: [R] Distance-based non-parametric ANOVA

Hello, 

I am comparing treatments by comparing within group to between group distances like described in 

MJ Anderson. 2001. A new method for non-parametric multivariate analysis of variance. 
Austral Ecology 26: 32 -- 46.

The idea is to find the ratio of within group sum of distance^2 to between group sum of distance^2. Then find the distribution of the statistic by permuting the sample.

Has anyone done this before in R code? Are there any packages (I did checked on CRAN - none). Code?

I want to make sure I won't be inventing a bicycle before I write my own package.

Comments? Suggestions? (I have never written an R package before)

Thank you for your time, 

Mikhail.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

Age UK Improving later life

www.ageuk.org.uk


 
-------------------------------
Age UK is a registered charity and company limited by guarantee, (registered charity number 1128267, registered company number 6825798). 
Registered office: Tavis House, 1-6 Tavistock Square, London WC1H 9NA.

For the purposes of promoting Age UK Insurance, Age UK is an Appointed Representative of Age UK Enterprises Limited, Age UK is an Introducer 
Appointed Representative of JLT Benefit Solutions Limited and Simplyhealth Access for the purposes of introducing potential annuity and health 
cash plans customers respectively.  Age UK Enterprises Limited, JLT Benefit Solutions Limited and Simplyhealth Access are all authorised and 
regulated by the Financial Services Authority. 
------------------------------

This email and any files transmitted with it are confidential and intended solely for the use of the individual or entity to whom they are 
addressed. If you receive a message in error, please advise the sender and delete immediately.

Except where this email is sent in the usual course of our business, any opinions expressed in this email are those of the author and do not 
necessarily reflect the opinions of Age UK or its subsidiaries and associated companies. Age UK monitors all e-mail transmissions passing 
through its network and may block or modify mails which are deemed to be unsuitable.

Age Concern England (charity number 261794) and Help the Aged (charity number 272786) and their trading and other associated companies merged 
on 1st April 2009.  Together they have formed the Age UK Group, dedicated to improving the lives of people in later life.  The three national 
Age Concerns in Scotland, Northern Ireland and Wales have also merged with Help the Aged in these nations to form three registered charities: 
Age Scotland, Age NI, Age Cymru.





From lmramba at ufl.edu  Fri Jun  7 12:15:30 2013
From: lmramba at ufl.edu (Laz)
Date: Fri, 07 Jun 2013 06:15:30 -0400
Subject: [R] R help on loops
In-Reply-To: <9886C555-B547-4E8B-923C-12A916B54913@xs4all.nl>
References: <51A8E5C7.1010306@ufl.edu>
	<CAAxdm-6=KLifDLfD=ZTxn8Mu7c0nPpuKUAf6BN6_Uh_jQqURTQ@mail.gmail.com>
	<51B1A10B.4060006@ufl.edu>
	<9886C555-B547-4E8B-923C-12A916B54913@xs4all.nl>
Message-ID: <51B1B2C2.8070709@ufl.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/19c64f42/attachment.pl>

From kridox at ymail.com  Fri Jun  7 12:19:55 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Fri, 7 Jun 2013 19:19:55 +0900
Subject: [R] Distance-based non-parametric ANOVA
In-Reply-To: <2093686.8QetdgVmrY@localhost>
References: <2093686.8QetdgVmrY@localhost>
Message-ID: <CAAcyNCzPdP-gLyvN5qrqjP+htvtPL_gr0mexuvjrG0LhHHnjAg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/5bb77e77/attachment.pl>

From bhh at xs4all.nl  Fri Jun  7 12:25:49 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 7 Jun 2013 12:25:49 +0200
Subject: [R] R help on loops
In-Reply-To: <51B1AEA5.4050908@ufl.edu>
References: <51A8E5C7.1010306@ufl.edu>
	<CAAxdm-6=KLifDLfD=ZTxn8Mu7c0nPpuKUAf6BN6_Uh_jQqURTQ@mail.gmail.com>
	<51B1A10B.4060006@ufl.edu>
	<9886C555-B547-4E8B-923C-12A916B54913@xs4all.nl>
	<51B1AEA5.4050908@ufl.edu>
Message-ID: <9BA8401A-8739-4EB4-9B79-13ECAF44B99D@xs4all.nl>


On 07-06-2013, at 11:57, Laz <lmramba at ufl.edu> wrote:

> Dear Berend,
> 
> I have made some changes but I still get errors:
> 
> For reproducibility, 
> Rspatswap() is a function which originally returns a single value. For example Rspatswap(...)  and you get 0.8 
> 
> So, run Rspatswap() 20 times and store all the values. 
> Then from these 20 values, calculate the calculate average, sd,se,min,max to get something similar to: 
> 
>         average           sd           se       min      max 
> trace 0.8880286 0.0009178193 0.0004589096 0.8870152 0.889241 
> 
> If we repeat the function 10 times, then I expect 10 rows with 5 columns but it does not work ? 
> 

Replacing Rspatswap(?)[1] with runif(1) (you could/should have done that to provide reproducible code) and the modifications I suggested you make in your function itn() like this

itn<-function(it){
siml<-matrix(NA,ncol=5,nrow=it)
  for(g in 1:it){
   siml[g,]<-optm(perm=20)
  }
siml
}

running itn(10) I get a matrix with 10 rows and 5 columns.

So what do you mean by "it does not work"?
You sometimes get an error message from apply due to a bad dim() like this

Error in apply(mat, 2, mean) : dim(X) must have a positive length

When the result of mat[-delete,] is a matrix with a single row the result is simplified to a vector. See ?"[" in particular the drop argument.
So this should work in function optm()

    mat <- mat[-delete,, drop=FALSE] 

Berend


From bhh at xs4all.nl  Fri Jun  7 12:32:01 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 7 Jun 2013 12:32:01 +0200
Subject: [R] R help on loops
In-Reply-To: <51B1B2C2.8070709@ufl.edu>
References: <51A8E5C7.1010306@ufl.edu>
	<CAAxdm-6=KLifDLfD=ZTxn8Mu7c0nPpuKUAf6BN6_Uh_jQqURTQ@mail.gmail.com>
	<51B1A10B.4060006@ufl.edu>
	<9886C555-B547-4E8B-923C-12A916B54913@xs4all.nl>
	<51B1B2C2.8070709@ufl.edu>
Message-ID: <802D7B41-B846-4BC2-B072-23D07F480634@xs4all.nl>



Please, please do not use html formatted mail.
It is clearly requested by the mailing list
The code of your last mail is a mess and when replying it becomes even more of a mess.

I told you to do 

siml[g,] <- optm(perm=20)

See the comma after g.

and not what you are now doing with siml[g]<-optm(perm=20)[g]

I'm giving up.

Berend


On 07-06-2013, at 12:15, Laz <lmramba at ufl.edu> wrote:

> Hi,
> 
> I am almost getting there, but still have errors. Thanks for your help. I have tried improving but I get the following errors below:
> 
> 
>         
> 
> > 
> itn<-function(it){
> 
> + 
> siml<-matrix(NA,ncol=5,nrow=it)
> 
> + 
> for(g in 1:it){
> 
> + 
> siml[g]<-optm(perm=20)[g]
> 
> + 
> }
> 
> + 
> siml
> 
> + 
> }
> 
> > 
> itn(3)
> 
>              [,1] [,2] [,3] [,4] [,5]
> [1,] 0.8873775898   NA   NA   NA   NA
> [2,] 0.0015584824   NA   NA   NA   NA
> [3,] 0.0001414317   NA   NA   NA   NA
> 
> 
> 
> > 
> itn<-function(it){
> 
> + 
> siml<-matrix(NA,ncol=5,nrow=it)
> 
> + 
> for(g in 1:it){
> 
> + 
> siml[g]<-optm(perm=20)
> 
> + 
> }
> 
> + 
> siml
> 
> + 
> }
> 
> > 
> itn(3)
> 
>           [,1] [,2] [,3] [,4] [,5]
> [1,] 0.8880941   NA   NA   NA   NA
> [2,] 0.8869727   NA   NA   NA   NA
> [3,] 0.8877045   NA   NA   NA   NA
> 
> Warning messages:
> 
> 1: In siml[g] <- optm(perm = 20) :
>   number of items to replace is not a multiple of replacement length
> 
> 2: In siml[g] <- optm(perm = 20) :
>   number of items to replace is not a multiple of replacement length
> 
> 3: In siml[g] <- optm(perm = 20) :
>   number of items to replace is not a multiple of replacement length
> 
> 
> I expect something close to
> 
> 
>         average           sd          se       min       max
>         0.8881969 0.0008215379 0.000410769 0.8873842 0.8890167
> 
> 	0.884659 0.0004215379 0.000410769 0.2342 0.676307
> 
> 	0.8885839 0.0001215379 0.0002112 0.000082752992 0.8836337
> 
> 
> 
> 
>       
> Thanks fpr you help.
> 
> 
> On 6/7/2013 5:24 AM, Berend Hasselman wrote:
>> On 07-06-2013, at 10:59, Laz <lmramba at ufl.edu>
>>  wrote:
>> 
>> 
>>> Dear R users,
>>> 
>>> I am stuck here: My first function returns a vector of 5 values.
>>> In my second function, I want to repeat this, a number of times, say 10 
>>> so that I have 10 rows and five columns but I keep on getting errors.
>>> 
>>> See the code and results below:
>>> 
>>> optm <-function(perm, verbose = FALSE)
>>> {
>>>   trace<-c()
>>>   for (k in 1:perm){
>>> trace[k]<-Rspatswap(rhox=0.6,rhoy=0.6,sigmasqG=0.081,SsqR=1)[1]
>>>     perm[k]<-k
>>>     mat<-cbind(trace, perm = seq(perm))
>>>   }
>>>   if (verbose){
>>>     cat("***starting matrix\n")
>>>     print(mat)
>>>   }
>>>   # iterate till done
>>>   while(nrow(mat) > 1){
>>>     high <- diff(mat[, 'trace']) > 0
>>>     if (!any(high)) break  # done
>>>     # find which one to delete
>>>     delete <- which.max(high) + 1L
>>>     mat <- mat[-delete, ]
>>>     newmat<-apply(mat,2,mean)[1]
>>>     sdm<-sd(mat[,1])
>>>     sem<-sdm/sqrt(nrow(mat))
>>>     maxv<-mat[1,1]
>>>     minv<-mat[nrow(mat),1]
>>>       }
>>>   stats<-cbind(average=newmat,sd=sdm,se=sem,min=minv,max=maxv)
>>>   stats
>>> }
>>> 
>>> 
>>>> test<-optm(perm=20)
>>>> test
>>>> 
>>>         average           sd           se       min      max
>>> trace 0.8880286 0.0009178193 0.0004589096 0.8870152 0.889241
>>> 
>>> 
>>> itn<-function(it){
>>> siml<-matrix(NA,ncol=5,nrow=length(it))
>>>   for(g in 1:it){
>>>    siml[g]<-optm(perm=20)
>>>   }
>>> siml<-cbind(siml=siml)
>>> siml
>>> }
>>> 
>>> 
>>>> ans<-itn(5)
>>>> 
>>> Warning messages:
>>> 1: In siml[g] <- optm(perm = 20) :
>>>   number of items to replace is not a multiple of replacement length
>>> 2: In siml[g] <- optm(perm = 20) :
>>>   number of items to replace is not a multiple of replacement length
>>> 3: In siml[g] <- optm(perm = 20) :
>>>   number of items to replace is not a multiple of replacement length
>>> 4: In siml[g] <- optm(perm = 20) :
>>>   number of items to replace is not a multiple of replacement length
>>> 5: In siml[g] <- optm(perm = 20) :
>>>   number of items to replace is not a multiple of replacement length
>>> 
>>>> ans
>>>> 
>>>           [,1]      [,2]      [,3]      [,4]      [,5]
>>> [1,] 0.8874234 0.8861666 0.8880521 0.8870958 0.8876469
>>> 
>>> 
>> 
>> 1. Not reproducible code. Where does function Rspatswap come from?
>> 
>> 2. You have several errors in function itn:
>>     Argument it is a scalar: length(it) is 1. You need to do siml <- matrix(NA,ncol=5,nrow=it)
>> Next in the g-loop you want to fill row g so do: siml[g,] <- ?..
>> 
>> Finally why are you doing siml <- cbind(siml=siml)?
>> Seems superfluous to me. Delete the line.
>> 
>> Berend
>> 
>> 
>> 
> 


From murdoch.duncan at gmail.com  Fri Jun  7 13:05:59 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 07 Jun 2013 07:05:59 -0400
Subject: [R] SPlus script
In-Reply-To: <51B10B9A.5060406@xtra.co.nz>
References: <1370438435.93923.YahooMailNeo@web142703.mail.bf1.yahoo.com>
	<E66794E69CFDE04D9A70842786030B931C2FD5C4@PA-MBX01.na.tibco.com>
	<1370523739.92423.YahooMailNeo@web142703.mail.bf1.yahoo.com>
	<CA+vqiLGCTXQDEzzbeZDf-_EddiGQ=xx4P9n_3EJ2HkN1-qTMQg@mail.gmail.com>
	<1370531969.88020.YahooMailNeo@web142705.mail.bf1.yahoo.com>
	<51B10B9A.5060406@xtra.co.nz>
Message-ID: <51B1BE97.7090006@gmail.com>

On 13-06-06 6:22 PM, Rolf Turner wrote:
> On 07/06/13 03:19, Scott Raynaud wrote:
>> I actually had tried placing arguments in the call but it didn't work.   However, I did
>> not think about writing it to a variable and printing.  That seems to have done the
>> trick.  Funny, I don't remember having to do that before, but that's not surprising.
>>
>
> If I remember correctly --- haven't used Splus for decades --- this is a
> difference
> between Splus and R.
>
> In R the output of a function is returned *invisibly* if that function
> is called
> from within another function.  And source() is one such other function.

Actually this depends on the caller.  source() does return its results 
invisibly, but many other functions don't.

source() is unusual in another way that came up recently (on R-devel, I 
think):  it calls withVisible() on the code that it evaluates, which 
means that instead of a simple value it will return a list containing 
the value and an indicator about whether it should be displayed. It 
returns this list invisibly, leaving it up to whoever called source() to 
decide whether to display the value or not.

Duncan Murdoch

>
> So if you have a script, say "melvin" with the single line:
>
>       sin(42)
>
> and in R you execute
>
>       source("melvin")
>
> you will see no output.  If in another script, say "clyde" you have the
> single line
>
>       print(sin(42))
>
> and in R you execute
>
>       source("clyde")
>
> you will see
>
>       [1] -0.9165215
>
> In Splus, IIRC, the print() call is unnecessary.  I.e. you would get the
> same
> result by sourcing "melvin" and "clyde".
>
> Current Splus users may correct me if I am wrong about this.
>
>       cheers,
>
>           Rolf Turner
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From info at aghmed.fsnet.co.uk  Fri Jun  7 13:17:08 2013
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Fri, 07 Jun 2013 12:17:08 +0100
Subject: [R] Add prediction interval forest plot (package "meta")
In-Reply-To: <51B0D651.6080900@uni-koeln.de>
References: <51B0D651.6080900@uni-koeln.de>
Message-ID: <Zen-1UkufU-00084i-Cz@smarthost03.mail.zen.net.uk>

At 19:34 06/06/2013, Bernd Weiss wrote:
>Dear all,
>
>I am struggling to add a prediction interval to a forest plot that was
>created with forest.meta(), package "meta".
>
>I checked the source of forest.meta() and realized that it is heavily
>relying on grid. I am lacking any experience with grid graphics. So, I
>am having difficulties to find out where the random effects estimate is
>actually plotted in order to add prediction intervals.

I appreciate this is not a direct answer to your question but the 
equivalent function in metafor (available from CRAN) does this and it 
might be easier to use that.


>Any help is much appreciated!
>
>Bernd
>
>
>R version 3.0.1 Patched (2013-05-28 r62825)
>Platform: x86_64-w64-mingw32/x64 (64-bit)
>
>locale:
>[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
>LC_MONETARY=German_Germany.1252
>[4] LC_NUMERIC=C                    LC_TIME=German_Germany.1252
>
>attached base packages:
>[1] grid      stats     graphics  grDevices utils     datasets  methods
>   base
>
>other attached packages:
>[1] meta_2.3-0
>
>loaded via a namespace (and not attached):
>[1] tools_3.0.1

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html


From Aakanksha_Dahiya01 at infosys.com  Fri Jun  7 13:21:02 2013
From: Aakanksha_Dahiya01 at infosys.com (Aakanksha Dahiya01)
Date: Fri, 7 Jun 2013 11:21:02 +0000
Subject: [R] arima time series in R
Message-ID: <A70E6C8815CB614D92A3AAD769261E8101E54CFB@BLRKECMBX12.ad.infosys.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/a742dc66/attachment.pl>

From bernd.weiss at uni-koeln.de  Fri Jun  7 13:39:39 2013
From: bernd.weiss at uni-koeln.de (=?ISO-8859-1?Q?Bernd_Wei=DF?=)
Date: Fri, 07 Jun 2013 13:39:39 +0200
Subject: [R] Add prediction interval forest plot (package "meta")
In-Reply-To: <Zen-1UkufU-00084i-Cz@smarthost03.mail.zen.net.uk>
References: <51B0D651.6080900@uni-koeln.de>
	<Zen-1UkufU-00084i-Cz@smarthost03.mail.zen.net.uk>
Message-ID: <51B1C67B.1050801@uni-koeln.de>

Am 07.06.2013 13:17, schrieb Michael Dewey:
> At 19:34 06/06/2013, Bernd Weiss wrote:
>> Dear all,
>>
>> I am struggling to add a prediction interval to a forest plot that was
>> created with forest.meta(), package "meta".
>>
>> I checked the source of forest.meta() and realized that it is heavily
>> relying on grid. I am lacking any experience with grid graphics. So, I
>> am having difficulties to find out where the random effects estimate is
>> actually plotted in order to add prediction intervals.
>
> I appreciate this is not a direct answer to your question but the
> equivalent function in metafor (available from CRAN) does this and it
> might be easier to use that.

Thanks, Michael!

Yes, I vaguely remember that the metafor package can calculate the PIs 
but most of our analyses rely on the meta package. On the other hand, 
this might be a good reason to finally switch to metafor.

You probably refer to the function addpoly() which can be used for that. 
I will check it out.

Again, thanks for your help,

Bernd


From ripley at stats.ox.ac.uk  Fri Jun  7 13:59:01 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 07 Jun 2013 12:59:01 +0100
Subject: [R] arima time series in R
In-Reply-To: <A70E6C8815CB614D92A3AAD769261E8101E54CFB@BLRKECMBX12.ad.infosys.com>
References: <A70E6C8815CB614D92A3AAD769261E8101E54CFB@BLRKECMBX12.ad.infosys.com>
Message-ID: <51B1CB05.1020908@stats.ox.ac.uk>

On 07/06/2013 12:21, Aakanksha Dahiya01 wrote:
>
> Hi
>
> Could just anyone explain me the coefficients in the output of arima model

The person who wrote the help page already did, but that is hardly 'just 
anyone'.

> timeseriesarima <- arima(series, order=c(1,1,2))
>> timeseriesarima
> Series: series
> ARIMA(1,1,2)
>
> Coefficients:
>           ar1      ma1     ma2
>        0.9744  -1.7695  0.7873
> s.e.  0.0310   0.0481  0.0426
>
> sigma^2 estimated as 337.4:  log likelihood=-1096.03
> AIC=2200.07   AICc=2200.23   BIC=2214.2

That is not from arima in package stats, so you need to follow the 
posting guide to tell us whose wrapper it is and hence which help page 
to read.  (Possibly package TSA.)

>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

That does mean you.



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From smartpink111 at yahoo.com  Fri Jun  7 15:21:42 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 7 Jun 2013 06:21:42 -0700 (PDT)
Subject: [R] subset with non logical rules
Message-ID: <1370611302.80316.YahooMailNeo@web142606.mail.bf1.yahoo.com>

HI,
Try:
?split()

source("http://www.openintro.org/stat/data/cdc.R")
?str(cdc)
#'data.frame':?? ?20000 obs. of? 9 variables:
# $ genhlth : Factor w/ 5 levels "excellent","very good",..: 3 3 3 3 2 2 2 2 3 3 ...
# $ exerany : num? 0 0 1 1 0 1 1 0 0 1 ...
# $ hlthplan: num? 1 1 1 1 1 1 1 1 1 1 ...
# $ smoke100: num? 0 1 1 0 0 0 0 0 1 0 ...
# $ height? : num? 70 64 60 66 61 64 71 67 65 70 ...
# $ weight? : int? 175 125 105 132 150 114 194 170 150 180 ...
# $ wtdesire: int? 175 115 105 124 130 114 185 160 130 170 ...
# $ age???? : int? 77 33 49 42 55 55 31 45 27 44 ...
# $ gender? : Factor w/ 2 levels "m","f": 1 2 2 2 2 2 1 1 2 1 ...
cdc$genhlth<- as.character(cdc$genhlth)
cdclst1<- split(cdc,cdc$genhlth)
lapply(cdclst1,head,2)
#$excellent
#???? genhlth exerany hlthplan smoke100 height weight wtdesire age gender
#11 excellent?????? 1??????? 1??????? 1???? 69??? 186????? 175? 46????? m
#13 excellent?????? 1??????? 0??????? 1???? 66??? 185????? 220? 21????? m
#
#$fair
#?? genhlth exerany hlthplan smoke100 height weight wtdesire age gender
#12??? fair?????? 1??????? 1??????? 1???? 69??? 168????? 148? 62????? m
#15??? fair?????? 1??????? 0??????? 0???? 69??? 170????? 170? 23????? m
#
#$good
#? genhlth exerany hlthplan smoke100 height weight wtdesire age gender
#1??? good?????? 0??????? 1??????? 0???? 70??? 175????? 175? 77????? m
#2??? good?????? 0??????? 1??????? 1???? 64??? 125????? 115? 33????? f
#
#$poor
#?? genhlth exerany hlthplan smoke100 height weight wtdesire age gender
#53??? poor?????? 1??????? 1??????? 1???? 62??? 140????? 130? 64????? f
#79??? poor?????? 1??????? 1??????? 0???? 63??? 142????? 120? 52????? f

#$`very good`
#??? genhlth exerany hlthplan smoke100 height weight wtdesire age gender
#5 very good?????? 0??????? 1??????? 0???? 61??? 150????? 130? 55????? f
#6 very good?????? 1??????? 1??????? 0???? 64??? 114????? 114? 55????? f


sapply(cdclst1,nrow)
#excellent????? fair????? good????? poor very good 
#???? 4657????? 2019????? 5675?????? 677????? 6972 

cdcGood<-cdclst1[["good"]]
? str(cdcGood)
#'data.frame':?? ?5675 obs. of? 9 variables:
# $ genhlth : chr? "good" "good" "good" "good" ...
# $ exerany : num? 0 0 1 1 0 1 1 0 1 1 ...
# $ hlthplan: num? 1 1 1 1 1 1 1 0 1 1 ...
# $ smoke100: num? 0 1 1 0 1 0 1 1 1 1 ...
# $ height? : num? 70 64 60 66 65 70 73 67 75 65 ...
# $ weight? : int? 175 125 105 132 150 180 185 156 200 160 ...
# $ wtdesire: int? 175 115 105 124 130 170 175 150 190 140 ...
# $ age???? : int? 77 33 49 42 27 44 79 47 43 54 ...
# $ gender? : Factor w/ 2 levels "m","f": 1 2 2 2 2 1 1 1 1 2 ...
?

A.K.


>Hi I am trying to figure out how to subset a bunch of data. As an example I am using the cdc data from openintro.org. 
>
>In the first column with the name "genhlth" there are various 
options that the persons could respond. For exmaple "good" "very good" 
and "poor". Now >what i would like to do is to seperate the data so that 
everyone who answered good are stored in one variable and everyone who 
answered poor are in >another variable. 
>
>Now I know i could just do subset(cdc, cdc$genhlth == "poor") to
 get the poor, but would really like for a code that would seperate data
 into each >group, regardless of what the text or the number of groups 
are. 
>
>Can anyone give me a hint?


From gunter.berton at gene.com  Fri Jun  7 15:49:10 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 7 Jun 2013 06:49:10 -0700
Subject: [R] Evaluation of function names...
Message-ID: <CACk-te2oXnKtBaWON=j05kU83ehRtPSPSBOxJHOhv5sG1LG44g@mail.gmail.com>

Folks:

Feel free to provide me a link or reference instead of an answer.

Preamble:

f <- function() function(x)rnorm(x)
g <- f()
g(3)
## [1] -0.4448492 -0.2379978 -0.4537394

## But
rnorm <- function()1  ## nasty nasty
g(3)
## Error in rnorm(x) : unused argument(s) (x)

## of course f <- function()function(x)stats:::rnorm(x)
## would fix this.

Question 1:
Suppose I defined f() as at top in a package namespace and exported it.
Would a user see this same error defining g() and with rnorm redefined
as above? (Assume stats is attached as usual).  I presume so, but ...

Question 2:
If the answer to Q1 is yes, (how) can this be avoided without using fully
qualified function names?

Again, a quick reference to relevant docs would suffice.

Thanks.

-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From smartpink111 at yahoo.com  Fri Jun  7 15:54:11 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 7 Jun 2013 06:54:11 -0700 (PDT)
Subject: [R] Get count by day for particular coulmn
Message-ID: <1370613251.70353.YahooMailNeo@web142602.mail.bf1.yahoo.com>

HI,
Please dput() the example data.
"""

Could anyone give a help ASAP ?"""""

You have been posting for long time and your many posts show this "ASAP". I know that you got comments to that and also advised to dput() the data.? Formatting your data took some time.? Would it be better to follow the posting guidelines and then use "ASAP"?

dat1<- read.table(text="
DATETIME,COL_A,COL_B,COL_C,COL_D
1/1/2007 0:01,0,3,0,0
1/1/2007 0:02,0,0,3,0
1/1/2007 0:03,0,3,0,0
1/2/2007 0,0,3,0,0
1/2/2007 0:01,0,3,4,0
1/2/2007 0:02,0,3,0,0
1/3/2007 0,0,0,0,0
1/3/2007 0:01,0,0,4,0
1/3/2007 0:02,0,3,0,0
",sep=",",header=TRUE,stringsAsFactors=FALSE)
dat1$DATETIME[!grepl("\\:",dat1$DATETIME)]<-paste0(dat1$DATETIME[!grepl("\\:",dat1$DATETIME)],":00")
res<-aggregate(.~gsub("\\s+.*","",dat1$DATETIME),data=dat1[,-1],function(x) length(x[x==3]))
?colnames(res)[1]<- colnames(dat1)[1]
colnames(res)[-1]<-paste0("COUNT(",colnames(res)[-1],"=3)")
?res
#? DATETIME COUNT(COL_A=3) COUNT(COL_B=3) COUNT(COL_C=3) COUNT(COL_D=3)
#1 1/1/2007????????????? 0????????????? 2????????????? 1????????????? 0
#2 1/2/2007????????????? 0????????????? 3????????????? 0????????????? 0
#3 1/3/2007????????????? 0????????????? 1????????????? 0????????????? 0
A.K.

?? 



here i have a dataframe 

for eg:- 
DATETIME	COL_A	COL_B	COL_C	COL_D 
1/1/2007 0:01	0	3	0	0 
1/1/2007 0:02	0	0	3	0 
1/1/2007 0:03	0	3	0	0 
....................... ? ? ? ..... ? ? ? ? ? ? ... ? ? ? ? ? ? ... ? ? ? ? ? ? ?.... 
1/2/2007	0	0	3	0 
1/2/2007 0:01	0	3	4	0 
1/2/2007 0:02	0	3	0	0 
....................... ? ? ? ..... ? ? ? ? ? ? ... ? ? ? ? ? ? ... ? ? ? ? ? ? ?.... 
1/3/2007	0	0	0	0 
1/3/2007 0:01	0	0	4	0 
1/3/2007 0:02	0	3	0	0 
....................... ? ? ? ..... ? ? ? ? ? ? ... ? ? ? ? ? ? ... ? ? ? ? ? ? ?.... 

My requirement what is, i have to get the count for each "day " where COL_B = 3 

For eg:- here i need to get like 
DATETIME ? ? ? ? ? COUNT(COL_B=3) 
------------ ? ? ? ? ? ?------------ 
1/1/2007 ? ? ? ? ? ? ? 2 
1/2/2007 ? ? ? ? ? ? ? 3 
1/3/2007 ? ? ? ? ? ? ? 1 

============================= 
============================= 

and this way i tried to get, 
MyDF[MyDF["DATETIME"]=="1/2/2007"] ?---> here this only select the row where DATETIME - column coming as 
"1/2/2007" - date and not selecting other rows where same date is 
coming (eg:- 1/1/2007 0:01). And here i need to get the complete records
 for that particular day, when i give date without giving timestamp. 

- Could anyone give a help ASAP ? 

- Thanks 
Antony. 



From cecilia.carmo at ua.pt  Fri Jun  7 15:56:25 2013
From: cecilia.carmo at ua.pt (Cecilia Carmo)
Date: Fri, 7 Jun 2013 13:56:25 +0000
Subject: [R] matched samples, dataframe, panel data
Message-ID: <104083AE5AAA634C993249DFCCE4C20306439641@CIPRESTE.ua.pt>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/fa45ed5e/attachment.pl>

From info at aghmed.fsnet.co.uk  Fri Jun  7 16:02:36 2013
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Fri, 07 Jun 2013 15:02:36 +0100
Subject: [R] Add prediction interval forest plot (package "meta")
In-Reply-To: <51B1C67B.1050801@uni-koeln.de>
References: <51B0D651.6080900@uni-koeln.de>
	<Zen-1UkufU-00084i-Cz@smarthost03.mail.zen.net.uk>
	<51B1C67B.1050801@uni-koeln.de>
Message-ID: <Zen-1UkxFT-00029X-Ax@smarthost04.mail.zen.net.uk>

At 12:39 07/06/2013, Bernd Wei? wrote:
>Am 07.06.2013 13:17, schrieb Michael Dewey:
>>At 19:34 06/06/2013, Bernd Weiss wrote:
>>>Dear all,
>>>
>>>I am struggling to add a prediction interval to a forest plot that was
>>>created with forest.meta(), package "meta".
>>>
>>>I checked the source of forest.meta() and realized that it is heavily
>>>relying on grid. I am lacking any experience with grid graphics. So, I
>>>am having difficulties to find out where the random effects estimate is
>>>actually plotted in order to add prediction intervals.
>>
>>I appreciate this is not a direct answer to your question but the
>>equivalent function in metafor (available from CRAN) does this and it
>>might be easier to use that.
>
>Thanks, Michael!
>
>Yes, I vaguely remember that the metafor package 
>can calculate the PIs but most of our analyses 
>rely on the meta package. On the other hand, 
>this might be a good reason to finally switch to metafor.
>
>You probably refer to the function addpoly() 
>which can be used for that. I will check it out.

I was thinking of the addcred parameter to 
forest.rma.uni in fact, although you could roll your own.


>Again, thanks for your help,
>
>Bernd

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html


From hertzogg at student.ethz.ch  Fri Jun  7 14:00:17 2013
From: hertzogg at student.ethz.ch (Hertzog  Gladys)
Date: Fri, 7 Jun 2013 12:00:17 +0000
Subject: [R] estimation of covariance matrix of a bivariate normal
 distribution using maximization of the log-likelihood
Message-ID: <E71E7032F00FCA4AA40DC7943D3DB10E24D0BFFF@MBX12.d.ethz.ch>

Dear all,
I?m new in R and I?m trying to estimate the covariance matrix of a bivariate normal distribution by maximizing the log-likelihood. The maximization really has to be performed with the non-linear minimization routine (nlm). The 2 means of the distribution are known and equal to 1.
I?ve already tried 2 different ways to compute this covariance but for each of them I obtained a lot of warnings and illogical values for the covariance matrix.
 
In the first one, I defined the bivariate normal distribution with the command dmvnorm:
 
x<-rnorm(6000, 2.4, 0.6)
x <- matrix(c(x), ncol=1)
y<-rlnorm(6000, 1.3,0.1)
y <- matrix(c(y), ncol=1)
XY <- cbind(x,y) 
 
L <- function(par,x,y) {
return (-sum(log(par[4]*dmvnorm(XY, mean=c(1,1), sigma= matrix(c(par[1], par[1]*par[2]*par[3],par[1]*par[2]*par[3], par[2] ),nrow=2, ncol=2))            )))
}
par.start<- c(0.5, 0.5 ,0.5 ,0.5)
result<-nlm(L,par.start,y=y,x=x, hessian=TRUE)
par.hat <- result$estimate
 
par.hatIl y a eu 32 avis (utilisez warnings() pour les visionner)
> par.hat <- result$estimate
> par.hat
[1] 5.149919e+01 2.520721e+02 8.734212e-03 3.996771e+02
> warnings()
Messages d'avis :
1: In log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values) :
  production de NaN
2: In nlm(L, par.start, y = y, x = x, hessian = TRUE) :
  NA/Inf replaced by maximum positive value
3: In log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values) :
  production de NaN
4: In nlm(L, par.start, y = y, x = x, hessian = TRUE) :
  NA/Inf replaced by maximum positive value
5: In log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values) :
  production de NaN
6: In nlm(L, par.start, y = y, x = x, hessian = TRUE) :
  NA/Inf replaced by maximum positive value
7: In log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values) :
  production de NaN
8: In nlm(L, par.start, y = y, x = x, hessian = TRUE) :
  NA/Inf replaced by maximum positive value
9: In log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values) :
  production de NaN
10: In nlm(L, par.start, y = y, x = x, hessian = TRUE) :
  NA/Inf replaced by maximum positive value
11: In log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values) :
  production de NaN
12: In nlm(L, par.start, y = y, x = x, hessian = TRUE) :
  NA/Inf replaced by maximum positive value
13: In log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values) :
  production de NaN
 
In the second one, I wrote step by step the bivariate normal distribution in order to have each parameter separately (not in a matrix) but it didn?t work as well:
 
x<-rnorm(6000, 2.4, 0.6)
y<-rlnorm(6000, 1.3,0.1)
L <- function(par,x,y) {
return (-sum(log((1-par[4])*( (1/(2*pi*par[1]*par[2]*sqrt(1-par[3])))*exp(   (-1/2*(1-par[3]^2))* ((y-1)/par[2])^2 +((x-1)/par[1])^2 - 2*(y-1)*(x-1)/(par[2]*par[1])   )) )))
}
#par [1]= sigma_x , par [2]= sigma_y  par [3]= rho_xy  par[4] is a mixing parameter. The final step of my calculation will be to have a mixture of bivariate normal and log-normal distributions.
par.start<- c(0.5, 0.5 ,0.5 ,0.5)
result<-nlm(L,par.start,y=y,x=x, hessian=T)
par.hat <- result$estimate
par.ha
 
When I run this script, I get always 50 advices like those below:
Messages d'avis :
1: In sqrt(1 - par[3]) : production de NaN
2: In nlm(L, par.start, y = y, x = x, hessian = T) :
  NA/Inf replaced by maximum positive value
3: In sqrt(1 - par[3]) : production de NaN
4: In nlm(L, par.start, y = y, x = x, hessian = T) :
  NA/Inf replaced by maximum positive value
5: In sqrt(1 - par[3]) : production de NaN
6: In nlm(L, par.start, y = y, x = x, hessian = T) :
  NA/Inf replaced by maximum positive value
7: In log((1 - par[4]) * ((1/(2 * pi * par[1] * par[2] *  ... : production de NaN
8: In nlm(L, par.start, y = y, x = x, hessian = T) :
  NA/Inf replaced by maximum positive value
9: In log((1 - par[4]) * ((1/(2 * pi * par[1] * par[2] *  ... : production de NaN
10: In nlm(L, par.start, y = y, x = x, hessian = T) :
  NA/Inf replaced by maximum positive value
11: In log((1 - par[4]) * ((1/(2 * pi * par[1] * par[2] *  ... : production de NaN
12: In nlm(L, par.start, y = y, x = x, hessian = T) :
  NA/Inf replaced by maximum positive value
??
Does one of you know how to use the nlm method to estimate the covariance matrix (and mixing parameter ) of a bivariate normal distribution?
 
Thank you in advance for your help and answers.
 
Best regards,
 
Gladys Hertzog
Master student in environmental engineering at ETH Zurich
-------------- next part --------------
A non-text attachment was scrubbed...
Name: message_to_mailing_list.pdf
Type: application/pdf
Size: 200565 bytes
Desc: message_to_mailing_list.pdf
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/3fcf8ef9/attachment.pdf>

From rbeckett81 at yahoo.com  Fri Jun  7 15:34:33 2013
From: rbeckett81 at yahoo.com (Richard Beckett)
Date: Fri, 7 Jun 2013 06:34:33 -0700 (PDT)
Subject: [R] Clogit R and Stata
Message-ID: <1370612073.93488.YahooMailNeo@web163803.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/5dda9833/attachment.pl>

From payal.urs at gmail.com  Fri Jun  7 12:12:53 2013
From: payal.urs at gmail.com (Payal Urs)
Date: Fri, 7 Jun 2013 11:12:53 +0100
Subject: [R] Bionconductor help
Message-ID: <CAPmHZoG1j1ZZ0VL9g+KTH3G-_rVMUoW5Xqg7DBawNNNxzOKeLg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/173ed166/attachment.pl>

From Sudha.Krishnan at marlabs.com  Fri Jun  7 12:57:47 2013
From: Sudha.Krishnan at marlabs.com (Sudha Krishnan)
Date: Fri, 7 Jun 2013 10:57:47 +0000
Subject: [R] generating a bar chart with two axis for co-linear variable
In-Reply-To: <1370552766.76220.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <EB2D2D799706D645AA4808B7CB24D41A315BA864@MLBMBX4.marlabs.com>
	<1370544267.26595.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1370552766.76220.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <EB2D2D799706D645AA4808B7CB24D41A315BA9B3@MLBMBX4.marlabs.com>

Arun, 

Perfect, this is what I was looking for. 

Thanks,
Sudha Krishnan

-----Original Message-----
From: arun [mailto:smartpink111 at yahoo.com] 
Sent: Friday, June 07, 2013 2:36 AM
To: Sudha Krishnan
Cc: R help
Subject: Re: [R] generating a bar chart with two axis for co-linear variable

HI,
Not sure if this is what you wanted.

pdf("BarplotsNew.pdf")
library(plotrix)
lst2<-lapply(seq_len(ncol(dat1)),function(i){
??? ??? ??? ??? ??? Ctdat<- table(dat1[,i])
??? ??? ??? ??? ??? Ctdat1<-(Ctdat/sum(Ctdat))*100
??? ??? ??? ??? ??? dat2<-data.frame(Ctdat,Ctdat1,stringsAsFactors=FALSE)[,-3]
??? ??? ??? ??? ??? colnames(dat2)[3]<-"Rel.Freq"
??? ??? ??? ??? ??? dat2[,1]<- as.numeric(as.character(dat2[,1]))
??? ??? ??? ??? ??? with(dat2,twoord.plot(Var1,Rel.Freq,Freq,
??? ??? ??? ??? ??? ??? lylim=c(0,100),rylim=c(0,1000),
??? ??? ??? ??? ??? ??? ylab="Relative Frequency",
??? ??? ??? ??? ??? ??? rylab="Frequency",main=paste("Bar plot:",colnames(dat1)[i],sep=" "),
??? ??? ??? ??? ??? ??? type=c("bar","l"),lcol=2,rcol=4,xtickpos=Var1,xticklab=Var1))
??? ??? ??? ??? ??? ??? })
?dev.off()

A.K.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Sudha Krishnan <Sudha.Krishnan at marlabs.com>
Cc: R help <r-help at r-project.org>
Sent: Thursday, June 6, 2013 2:44 PM
Subject: Re: [R]  generating a bar chart with two axis for co-linear variable

HI,

May be this helps:
dat1<- read.table("sampledata.txt",header=TRUE,sep=",",stringsAsFactors=FALSE)
pdf("Barplots.pdf")
?lst1<-lapply(seq_len(ncol(dat1)),function(i) {Ctdat<- table(dat1[,i]);Ctdat1<-(Ctdat/sum(Ctdat))*100;barplot(Ctdat1,ylim=c(0,100),xlab=colnames(dat1)[i],ylab="Relative Frequency",main=paste("Barplot:",colnames(dat1)[i],sep=" "))})
dev.off()
A.K.




----- Original Message -----
From: Sudha Krishnan <Sudha.Krishnan at marlabs.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Thursday, June 6, 2013 2:37 AM
Subject: [R]? generating a bar chart with two axis for co-linear variable



Hello Dimitris,



I was goggling for some help on Sensitivity vs 1-specificity and saw your link.



I hope you can be of help to me in one of the issue that I am facing in generating combo chart(bar chart and plot). I am a novice and have some difficulty in getting this logic correct.





I am give a dataset (I am attaching a sample dataset).



I am using a barplot() and passing values for percentage frequency and the corresponding variables. I am struck here, what my function does is only calculate the frequency for the listed variables and not the frequency percentage. Is there a method or a script with which I can pass the frequency percent and the related values as category columns for x axis?



I will attach the graphs that I have generated so that you can suggest the better way.



Sampledata - Sampledata.txt

What my function does to calculate the frequency with category names in X axis - 1.png

My requirement is to generate percentage frequency of the variable in y1 and not the frequency itself. 2.png (where x categories are missing)





Thanks,

Sudha Krishnan



______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bogaso.christofer at gmail.com  Fri Jun  7 13:01:36 2013
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Fri, 7 Jun 2013 16:31:36 +0530
Subject: [R] Problem with ODBC connection
Message-ID: <CA+dpOJ=gLQyZmniVkrd+gKzjThe_y+dJ5fGBeGw1q6fm_rXCyQ@mail.gmail.com>

Hello again,

I am having problem with ODBC connection using the RODBC package.

I am basically trying to read the attached Excel-2003 file using RODBC
package. Here is my code:

> head(sqlFetch(odbcConnectExcel("d:/ssss1.xls"), "aaaa"), 30); odbcCloseAll()
   Criteria  s  d fd  f                        fd1
    f1                        fd2    f2 fd3 f3 F12 F13 F14 F15 F16 F17
F18 F19 F20
1         a NA NA NA NA 0.000000000000000000000000
0.000000000000000027755576 -0.00000000000000040332321    NA  NA NA  NA
 NA  NA  NA  NA  NA  NA  NA  NA
2         s NA  0 NA NA 0.000000000000000000000000
0.000000000000000000000000  0.00000000000000000000000    NA  NA NA  NA
 NA  NA  NA  NA  NA  NA  NA  NA
3         d NA  0 NA NA 0.000000000000000001734723
0.000000000000000006938894  0.00000000000000002775558  5.00  NA NA  NA
 NA  NA  NA  NA  NA  NA  NA  NA
4         f NA NA NA NA                         NA
    NA                         NA -4.25  NA NA  NA  NA  NA  NA  NA  NA
 NA  NA  NA
5         f NA  0 NA NA 0.000000000000000000000000
0.000000000000000000000000  0.00000000000000000000000 -1.53  NA NA  NA
 NA  NA  NA  NA  NA  NA  NA  NA
6         f NA NA NA NA                         NA
    NA  0.00000000000000000000000  0.00  NA NA  NA  NA  NA  NA  NA  NA
 NA  NA  NA
7         f NA NA NA NA                         NA
    NA  0.00000000000000000000000    NA  NA NA  NA  NA  NA  NA  NA  NA
 NA  NA  NA
8         f NA  0 NA NA                         NA
    NA                         NA    NA  NA NA  NA  NA  NA  NA  NA  NA
 NA  NA  NA
9         f NA  0 NA NA                         NA
    NA                         NA    NA  NA NA  NA  NA  NA  NA  NA  NA
 NA  NA  NA
10        f NA NA NA NA                         NA
    NA                         NA    NA  NA NA  NA  NA  NA  NA  NA  NA
 NA  NA  NA
11        f NA NA NA NA                         NA
    NA                         NA    NA  NA NA  NA  NA  NA  NA  NA  NA
 NA  NA  NA
12        f NA NA NA NA                         NA
    NA                         NA    NA  NA NA  NA  NA  NA  NA  NA  NA
 NA  NA  NA
13        f NA NA NA NA                         NA
    NA                         NA    NA  NA NA  NA  NA  NA  NA  NA  NA
 NA  NA  NA

Here you see the data in second column could not read at all.

Can somebody point me if I did something wrong?

Thanks and regards,

From antony.akkara at ge.com  Fri Jun  7 13:38:36 2013
From: antony.akkara at ge.com (R_Antony)
Date: Fri, 7 Jun 2013 04:38:36 -0700 (PDT)
Subject: [R] Get count by day for particular coulmn
Message-ID: <1370605116158-4668915.post@n4.nabble.com>

here i have a dataframe 

for eg:-
DATETIME	COL_A	COL_B	COL_C	COL_D
1/1/2007 0:01	0	3	0	0
1/1/2007 0:02	0	0	3	0
1/1/2007 0:03	0	3	0	0
.......................       .....             ...             ...             
....				
1/2/2007	0	0	3	0
1/2/2007 0:01	0	3	4	0
1/2/2007 0:02	0	3	0	0
.......................       .....             ...             ...             
....
1/3/2007	0	0	0	0
1/3/2007 0:01	0	0	4	0
1/3/2007 0:02	0	3	0	0
.......................       .....             ...             ...             
....

My requirement what is, i have to get the count for each "day " where COL_B
= 3

For eg:- here i need to get like
DATETIME           COUNT(COL_B=3)
------------            ------------
1/1/2007               2
1/2/2007               3
1/3/2007               1

=============================
=============================

and this way i tried to get,
MyDF[MyDF["DATETIME"]=="1/2/2007"]  ---> here this only select the row where
DATETIME - column coming as
"1/2/2007" - date and not selecting other rows where same date is coming
(eg:- 1/1/2007 0:01). And here i need to get the complete records for that
particular day, when i give date without giving timestamp. 

- Could anyone give a help ASAP ?

- Thanks
Antony.





--
View this message in context: http://r.789695.n4.nabble.com/Get-count-by-day-for-particular-coulmn-tp4668915.html
Sent from the R help mailing list archive at Nabble.com.


From antoine.migeon at u-bourgogne.fr  Fri Jun  7 14:42:36 2013
From: antoine.migeon at u-bourgogne.fr (Antoine Migeon)
Date: Fri, 07 Jun 2013 14:42:36 +0200
Subject: [R] cannot load pbdMPI package after compilation
Message-ID: <51B1D53C.1090305@u-bourgogne.fr>

Hello,

I try to install pbdMPI.
Compilation successful, but load fails with segfault.

Is anyone can help me?

R version 3.0.0
pbdMPI version 0.1-6
Intel compiler version 13.1.1
OpenMPI version 1.6.4-1
CPU Intel x86_64

# R CMD INSTALL pbdMPI_0.1-6.tar.gz
..
....
checking for gcc... icc -std=gnu99
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables...
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether icc -std=gnu99 accepts -g... yes
checking for icc -std=gnu99 option to accept ISO C89... none needed
checking for mpirun... mpirun
checking for mpiexec... mpiexec
checking for orterun... orterun
checking for sed... /bin/sed
checking for mpicc... mpicc
checking for ompi_info... ompi_info
checking for mpich2version... F
found sed, mpicc, and ompi_info ...
>> TMP_INC_DIRS = /opt/openmpi/1.6.4-1/intel-13.1.1/include
checking /opt/openmpi/1.6.4-1/intel-13.1.1/include ...
found /opt/openmpi/1.6.4-1/intel-13.1.1/include/mpi.h ...
>> TMP_LIB_DIRS = /opt/openmpi/1.6.4-1/intel-13.1.1/lib64
checking /opt/openmpi/1.6.4-1/intel-13.1.1/lib64 ...
found /opt/openmpi/1.6.4-1/intel-13.1.1/lib64/libmpi.so ...
found mpi.h and libmpi.so ...
>> TMP_INC = /opt/openmpi/1.6.4-1/intel-13.1.1/include
>> TMP_LIB = /opt/openmpi/1.6.4-1/intel-13.1.1/lib64
checking for openpty in -lutil... yes
checking for main in -lpthread... yes

******************* Results of pbdMPI package configure *****************

>> TMP_INC = /opt/openmpi/1.6.4-1/intel-13.1.1/include
>> TMP_LIB = /opt/openmpi/1.6.4-1/intel-13.1.1/lib64
>> MPI_ROOT =
>> MPITYPE = OPENMPI
>> MPI_INCLUDE_PATH = /opt/openmpi/1.6.4-1/intel-13.1.1/include
>> MPI_LIBPATH = /opt/openmpi/1.6.4-1/intel-13.1.1/lib64
>> MPI_LIBS =  -lutil -lpthread
>> MPI_DEFS = -DMPI2
>> MPI_INCL2 =
>> PKG_CPPFLAGS = -I/opt/openmpi/1.6.4-1/intel-13.1.1/include  -DMPI2
-DOPENMPI
>> PKG_LIBS = -L/opt/openmpi/1.6.4-1/intel-13.1.1/lib64 -lmpi  -lutil
-lpthread
*************************************************************************
..
icc -std=gnu99 -I/usr/local/R/3.0.0/intel13/lib64/R/include -DNDEBUG
-I/opt/openmpi/1.6.4-1/intel-13.1.1/include  -DMPI2 -DOPENMPI -O3
-fp-model precise -pc 64 -axAVX    -fpic  -O3 -fp-model precise  -pc 64
-axAVX  -c comm_errors.c -o comm_errors.o
icc -std=gnu99 -I/usr/local/R/3.0.0/intel13/lib64/R/include -DNDEBUG
-I/opt/openmpi/1.6.4-1/intel-13.1.1/include  -DMPI2 -DOPENMPI -O3
-fp-model precise -pc 64 -axAVX    -fpic  -O3 -fp-model precise  -pc 64
-axAVX  -c comm_sort_double.c -o comm_sort_double.o
.
..
....
** testing if installed package can be loaded
sh: line 1:  2905 Segmentation fault     
'/usr/local/R/3.0.0/intel13/lib64/R/bin/R' --no-save --slave 2>&1 <
/tmp/RtmpGkncGK/file1e541c57190
ERROR: loading failed

 *** caught segfault ***
address (nil), cause 'unknown'

Traceback:
 1: .Call("spmd_initialize", PACKAGE = "pbdMPI")
 2: fun(libname, pkgname)
 3: doTryCatch(return(expr), name, parentenv, handler)
 4: tryCatchOne(expr, names, parentenv, handlers[[1L]])
 5: tryCatchList(expr, classes, parentenv, handlers)
 6: tryCatch(fun(libname, pkgname), error = identity)
 7: runHook(".onLoad", env, package.lib, package)
 8: loadNamespace(package, c(which.lib.loc, lib.loc))
 9: doTryCatch(return(expr), name, parentenv, handler)
10: tryCatchOne(expr, names, parentenv, handlers[[1L]])
11: tryCatchList(expr, classes, parentenv, handlers)
12: tryCatch(expr, error = function(e) {    call <- conditionCall(e)   
if (!is.null(call)) {        if (identical(call[[1L]],
quote(doTryCatch)))             call <- sys.call(-4L)        dcall <-
deparse(call)[1L]        prefix <- paste("Error in", dcall, ": ")       
LONG <- 75L        msg <- conditionMessage(e)        sm <- strsplit(msg,
"\n")[[1L]]        w <- 14L + nchar(dcall, type = "w") + nchar(sm[1L],
type = "w")        if (is.na(w))             w <- 14L + nchar(dcall,
type = "b") + nchar(sm[1L],                 type = "b")        if (w >
LONG)             prefix <- paste0(prefix, "\n  ")    }    else prefix
<- "Error : "    msg <- paste0(prefix, conditionMessage(e), "\n")   
.Internal(seterrmessage(msg[1L]))    if (!silent &&
identical(getOption("show.error.messages"),         TRUE)) {       
cat(msg, file = stderr())        .Internal(printDeferredWarnings())   
}    invisible(structure(msg, class = "try-error", condition = e))})
13: try({    ns <- loadNamespace(package, c(which.lib.loc, lib.loc))   
env <- attachNamespace(ns, pos = pos, deps)})
14: library(pkg_name, lib.loc = lib, character.only = TRUE,
logical.return = TRUE)
15: withCallingHandlers(expr, packageStartupMessage = function(c)
invokeRestart("muffleMessage"))
16: suppressPackageStartupMessages(library(pkg_name, lib.loc = lib,    
character.only = TRUE, logical.return = TRUE))
17: doTryCatch(return(expr), name, parentenv, handler)
18: tryCatchOne(expr, names, parentenv, handlers[[1L]])
19: tryCatchList(expr, classes, parentenv, handlers)
20: tryCatch(expr, error = function(e) {    call <- conditionCall(e)   
if (!is.null(call)) {        if (identical(call[[1L]],
quote(doTryCatch)))             call <- sys.call(-4L)        dcall <-
deparse(call)[1L]        prefix <- paste("Error in", dcall, ": ")       
LONG <- 75L        msg <- conditionMessage(e)        sm <- strsplit(msg,
"\n")[[1L]]        w <- 14L + nchar(dcall, type = "w") + nchar(sm[1L],
type = "w")        if (is.na(w))             w <- 14L + nchar(dcall,
type = "b") + nchar(sm[1L],                 type = "b")        if (w >
LONG)             prefix <- paste0(prefix, "\n  ")    }    else prefix
<- "Error : "    msg <- paste0(prefix, conditionMessage(e), "\n")   
.Internal(seterrmessage(msg[1L]))    if (!silent &&
identical(getOption("show.error.messages"),         TRUE)) {       
cat(msg, file = stderr())        .Internal(printDeferredWarnings())   
}    invisible(structure(msg, class = "try-error", condition = e))})
21: try(suppressPackageStartupMessages(library(pkg_name, lib.loc =
lib,     character.only = TRUE, logical.return = TRUE)))
22: tools:::.test_load_package("pbdMPI",
"/usr/local/R/3.0.0/intel13/lib64/R/library")
aborting ...


-- 
Antoine Migeon
Universit? de Bourgogne
Centre de Calcul et Messagerie
Direction des Syst?mes d'Information

tel : 03 80 39 52 70
Site du CCUB : http://www.u-bourgogne.fr/dsi-ccub


From sisseck.net at gmail.com  Fri Jun  7 15:44:27 2013
From: sisseck.net at gmail.com (sisseck.net)
Date: Fri, 7 Jun 2013 06:44:27 -0700 (PDT)
Subject: [R] subset with non logical rules
In-Reply-To: <1370611302.80316.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1370599375332-4668906.post@n4.nabble.com>
	<1370611302.80316.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <CAA0sKrJMoAj6fdmxF7HtjMwMqx=WX7bEbZ4yv0WPjN=U4d+udQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/e76d1513/attachment.pl>

From ripley at stats.ox.ac.uk  Fri Jun  7 16:09:45 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 07 Jun 2013 15:09:45 +0100
Subject: [R] Evaluation of function names...
In-Reply-To: <CACk-te2oXnKtBaWON=j05kU83ehRtPSPSBOxJHOhv5sG1LG44g@mail.gmail.com>
References: <CACk-te2oXnKtBaWON=j05kU83ehRtPSPSBOxJHOhv5sG1LG44g@mail.gmail.com>
Message-ID: <51B1E9A9.4090002@stats.ox.ac.uk>

On 07/06/2013 14:49, Bert Gunter wrote:
> Folks:
>
> Feel free to provide me a link or reference instead of an answer.
>
> Preamble:
>
> f <- function() function(x)rnorm(x)
> g <- f()
> g(3)
> ## [1] -0.4448492 -0.2379978 -0.4537394
>
> ## But
> rnorm <- function()1  ## nasty nasty
> g(3)
> ## Error in rnorm(x) : unused argument(s) (x)
>
> ## of course f <- function()function(x)stats:::rnorm(x)
> ## would fix this.
>
> Question 1:
> Suppose I defined f() as at top in a package namespace and exported it.
> Would a user see this same error defining g() and with rnorm redefined
> as above? (Assume stats is attached as usual).  I presume so, but ...

Not if done right.  The package should importFrom(stats, rnorm).

> Question 2:
> If the answer to Q1 is yes, (how) can this be avoided without using fully
> qualified function names?
>
> Again, a quick reference to relevant docs would suffice.

'Writing R Extensions' says

'The namespace controls the search strategy for variables used by 
functions in the package. If not found locally, R searches the package 
namespace first, then the imports, then the base namespace and then the 
normal search path.'

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From gunter.berton at gene.com  Fri Jun  7 16:14:09 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 7 Jun 2013 07:14:09 -0700
Subject: [R] Evaluation of function names...
In-Reply-To: <51B1E9A9.4090002@stats.ox.ac.uk>
References: <CACk-te2oXnKtBaWON=j05kU83ehRtPSPSBOxJHOhv5sG1LG44g@mail.gmail.com>
	<51B1E9A9.4090002@stats.ox.ac.uk>
Message-ID: <CACk-te2M+05QuBSiJnboo5DN2jZoTn73690ZUTRi+Kd32wT29g@mail.gmail.com>

Thank you. That answers my question.

-- Bert

On Fri, Jun 7, 2013 at 7:09 AM, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On 07/06/2013 14:49, Bert Gunter wrote:
>>
>> Folks:
>>
>> Feel free to provide me a link or reference instead of an answer.
>>
>> Preamble:
>>
>> f <- function() function(x)rnorm(x)
>> g <- f()
>> g(3)
>> ## [1] -0.4448492 -0.2379978 -0.4537394
>>
>> ## But
>> rnorm <- function()1  ## nasty nasty
>> g(3)
>> ## Error in rnorm(x) : unused argument(s) (x)
>>
>> ## of course f <- function()function(x)stats:::rnorm(x)
>> ## would fix this.
>>
>> Question 1:
>> Suppose I defined f() as at top in a package namespace and exported it.
>> Would a user see this same error defining g() and with rnorm redefined
>> as above? (Assume stats is attached as usual).  I presume so, but ...
>
>
> Not if done right.  The package should importFrom(stats, rnorm).
>
>> Question 2:
>> If the answer to Q1 is yes, (how) can this be avoided without using fully
>> qualified function names?
>>
>> Again, a quick reference to relevant docs would suffice.
>
>
> 'Writing R Extensions' says
>
> 'The namespace controls the search strategy for variables used by functions
> in the package. If not found locally, R searches the package namespace
> first, then the imports, then the base namespace and then the normal search
> path.'
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From smartpink111 at yahoo.com  Fri Jun  7 16:16:17 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 7 Jun 2013 07:16:17 -0700 (PDT)
Subject: [R] Bionconductor help
In-Reply-To: <CAPmHZoG1j1ZZ0VL9g+KTH3G-_rVMUoW5Xqg7DBawNNNxzOKeLg@mail.gmail.com>
References: <CAPmHZoG1j1ZZ0VL9g+KTH3G-_rVMUoW5Xqg7DBawNNNxzOKeLg@mail.gmail.com>
Message-ID: <1370614577.98981.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,

You would get better response if you post at Bioconductor mailing list.
http://www.bioconductor.org/help/mailing-list/

A.K.

----- Original Message -----
From: Payal Urs <payal.urs at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Friday, June 7, 2013 6:12 AM
Subject: [R] Bionconductor help

Hi

I am trying to do some data analysis using R and Bioconductor.? I have a
function to read my data called "ReadAffyData" and a function to plot the
data called "preqc".? I want to know if there is any way I can extract
information (read: Data) from the ReadAffyData function into preqc in order
to produce plots? I have not completely understood the inheritance in R and
I am getting errors similar to the one below. I am new to R and could do
with any help in this aspect!

ReadAffyData <- function( filename ) {

? ? ? ? require(affy)
? ? ? ? require(annotate)

? ? ? ? Cov <- read.table( filename, sep="\t", header=1, quote="",
comment="" )
? ? if( ! all( c( "Filename", "Label", "Repl", "Trt" ) %in% colnames( Cov )
) )
? ? ? ? {
? ? ? ? stop( "Missing mandatory column" )
? ? }

? ? ? ? Cov <- Cov[order(Cov$Trt),]
? ? ? ? i <- table(Cov$Trt)
? ? ? ? Cov$Repl <- unlist( lapply( i, function( j ) 1:j ) )
? ? ? ? Cov$Label <- paste( as.character( Cov$Trt ), Cov$Repl, sep=":" )
? ? ? ? rownames(Cov) <- as.character(Cov$Label)

? ? ? ? tmp1 <- colnames( Cov )
? ? tmp2 <- rep( "", length( Cov ) )

? ? ? ? for( i in 1:length( tmp2 ) )
? ? ? ? {
? ? ? ? tmp2[i] <- paste( sort( unique( as.character( Cov[,i] ) ) ),
collapse="/" )
? ? }

? ? ? ? labelDescription <- data.frame( labelDescription=tmp2 )

? ? rownames( labelDescription ) <- tmp1
? ? tmp <- new( "AnnotatedDataFrame", data=Cov,
varMetadata=labelDescription)

? ? ? ? Data <- ReadAffy( sampleNames=as.character( Cov$Label
),phenoData=tmp, verbose=TRUE )
}

preQC <- function(name){
ReadAffyData(name)
plotDensity( log2( pm( Data ) ), xlab="Log2( Intensity )", ylab="Density",
main="Raw(PM)")
}

preQC("cov.txt")
1 reading C:/CEL/GSM311471.CEL ...instantiating an AffyBatch (intensity a
506944x24 matrix)...done.
Reading in : C:/CEL/GSM311471.CEL
Reading in : C:/CEL/GSM311472.CEL
Reading in : C:/CEL/GSM311473.CEL
Reading in : C:/CEL/GSM311474.CEL
Reading in : C:/CEL/GSM311475.CEL
.
.
.
Error in pm(Data) :
? error in evaluating the argument 'object' in selecting a method for
function 'pm': Error: object 'Data' not found

sessionInf()
R version 3.0.1 (2013-05-16)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_India.1252? LC_CTYPE=English_India.1252
LC_MONETARY=English_India.1252
[4] LC_NUMERIC=C? ? ? ? ? ? ? ? ?  LC_TIME=English_India.1252

attached base packages:
[1] parallel? stats? ?  graphics? grDevices utils? ?  datasets? methods
base

other attached packages:
[1] annotate_1.38.0? ? ? AnnotationDbi_1.22.6 affy_1.38.1
Biobase_2.20.0? ? ?  BiocGenerics_0.6.0

loaded via a namespace (and not attached):
[1] affyio_1.28.0? ? ? ?  BiocInstaller_1.10.1? DBI_0.2-7
IRanges_1.18.1? ? ? ? preprocessCore_1.22.0
[6] RSQLite_0.11.4? ? ? ? stats4_3.0.1? ? ? ? ? tools_3.0.1
XML_3.96-1.1? ? ? ? ? xtable_1.7-1
[11] zlibbioc_1.6.0



Thanking you,
Ipsitha
Graduate Student
London

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From sarah.goslee at gmail.com  Fri Jun  7 16:30:34 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 7 Jun 2013 10:30:34 -0400
Subject: [R] Get count by day for particular coulmn
In-Reply-To: <1370605116158-4668915.post@n4.nabble.com>
References: <1370605116158-4668915.post@n4.nabble.com>
Message-ID: <CAM_vjumQn+AvYmABQQFyvptpSAunPwoT+uMzg+ZmfLmfOuzh0w@mail.gmail.com>

Hi,

On Fri, Jun 7, 2013 at 7:38 AM, R_Antony <antony.akkara at ge.com> wrote:
> here i have a dataframe
>
> for eg:-
> DATETIME        COL_A   COL_B   COL_C   COL_D
> 1/1/2007 0:01   0       3       0       0
> 1/1/2007 0:02   0       0       3       0
> 1/1/2007 0:03   0       3       0       0
> .......................       .....             ...             ...
> ....
> 1/2/2007        0       0       3       0
> 1/2/2007 0:01   0       3       4       0
> 1/2/2007 0:02   0       3       0       0
> .......................       .....             ...             ...
> ....
> 1/3/2007        0       0       0       0
> 1/3/2007 0:01   0       0       4       0
> 1/3/2007 0:02   0       3       0       0
> .......................       .....             ...             ...
> ....
>
> My requirement what is, i have to get the count for each "day " where COL_B
> = 3
>
> For eg:- here i need to get like
> DATETIME           COUNT(COL_B=3)
> ------------            ------------
> 1/1/2007               2
> 1/2/2007               3
> 1/3/2007               1
>
> =============================
> =============================

Since you didn't provide reproducible data (dput() is great for that),
here's an example with fake data:


MyDF <- data.frame(DATETIME = c("1/1/2007", "1/1/2007", "1/1/2007",
"1/2/2007", "1/2/2007", "1/2/2007", "1/3/2007", "1/3/2007",
"1/3/2007"),
COL_A = c(0, 0, 0, 1, 0, 1, 2, 3, 1),
COL_B = c(0, 3, 0, 3, 3, 1, 0, 1, 2),
COL_C = c(1, 2, 3, 1, 2, 3, 1, 2, 3), stringsAsFactors=FALSE)

aggregate(COL_B ~ DATETIME, data=MyDF, FUN=function(x)sum(x == 3))


> and this way i tried to get,
> MyDF[MyDF["DATETIME"]=="1/2/2007"]  ---> here this only select the row where
> DATETIME - column coming as
> "1/2/2007" - date and not selecting other rows where same date is coming
> (eg:- 1/1/2007 0:01). And here i need to get the complete records for that
> particular day, when i give date without giving timestamp.

You omitted a comma:
MyDF[MyDF["DATETIME"]=="1/2/2007", ]


You might prefer:
subset(MyDF, DATETIME == "1/2/2007")

Sarah

-- 
Sarah Goslee
http://www.functionaldiversity.org


From careyshan at gmail.com  Fri Jun  7 16:36:52 2013
From: careyshan at gmail.com (Shane Carey)
Date: Fri, 7 Jun 2013 15:36:52 +0100
Subject: [R] increase outlier size on boxplot
Message-ID: <CA+jRDxCG7GeBdZug6zixQgdP4VqGVBBNaswHnOdRWYTf5Q=uxQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/1d6322d7/attachment.pl>

From sarah.goslee at gmail.com  Fri Jun  7 16:46:36 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 7 Jun 2013 10:46:36 -0400
Subject: [R] increase outlier size on boxplot
In-Reply-To: <CA+jRDxCG7GeBdZug6zixQgdP4VqGVBBNaswHnOdRWYTf5Q=uxQ@mail.gmail.com>
References: <CA+jRDxCG7GeBdZug6zixQgdP4VqGVBBNaswHnOdRWYTf5Q=uxQ@mail.gmail.com>
Message-ID: <CAM_vju=PmRaHN78HXnhwHMVFbbwEGexB5imD_=hTiaL6oM2g+A@mail.gmail.com>

Hi Shane,

On Fri, Jun 7, 2013 at 10:36 AM, Shane Carey <careyshan at gmail.com> wrote:
> Hi,
>
> Does anybody know how to increase boxplot outlier symbol size? And also the
> line from min/max to outlier

If you read the help for boxplot, it will send you to the help for bxp
for more information on custom plotting. ?bxp will offer you a vast
array of possibilities, including:

          whisklty, whisklwd, whiskcol: whisker line type (default:
              ?"dashed"?), width, and color.

          outlty, outlwd, outpch, outcex, outcol, outbg: outlier line
              type, line width, point character, point size expansion,
              color, and background color.

accompanied by reproducible examples.

Sarah

-- 
Sarah Goslee
http://www.functionaldiversity.org


From careyshan at gmail.com  Fri Jun  7 16:49:39 2013
From: careyshan at gmail.com (Shane Carey)
Date: Fri, 7 Jun 2013 15:49:39 +0100
Subject: [R] increase outlier size on boxplot
In-Reply-To: <CAM_vju=PmRaHN78HXnhwHMVFbbwEGexB5imD_=hTiaL6oM2g+A@mail.gmail.com>
References: <CA+jRDxCG7GeBdZug6zixQgdP4VqGVBBNaswHnOdRWYTf5Q=uxQ@mail.gmail.com>
	<CAM_vju=PmRaHN78HXnhwHMVFbbwEGexB5imD_=hTiaL6oM2g+A@mail.gmail.com>
Message-ID: <CA+jRDxBR_mRxscww3T2mh9WE=mkiH=HZZW_FbdtAWnKE9UPBRw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/a6dd1191/attachment.pl>

From smartpink111 at yahoo.com  Fri Jun  7 16:53:02 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 7 Jun 2013 07:53:02 -0700 (PDT)
Subject: [R] How to get a subscript of a vector?
Message-ID: <1370616782.28486.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
?which()
?which(A==2)
#[1]? 3? 7 10
A.K.

Suppose there is a vector 
A <- c(1,3,2,6,7,8,2,1,3,2). 

Now, I want to get the subscript of elements of A which equal 2. 

How can I do it ?


From rbeckett81 at yahoo.com  Fri Jun  7 17:03:12 2013
From: rbeckett81 at yahoo.com (Richard Beckett)
Date: Fri, 7 Jun 2013 08:03:12 -0700 (PDT)
Subject: [R] ROC Curves for Neural Networks
Message-ID: <1370617392.63133.YahooMailNeo@web163802.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/397a7af8/attachment.pl>

From mtmorgan at fhcrc.org  Fri Jun  7 17:03:16 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 07 Jun 2013 08:03:16 -0700
Subject: [R] Bionconductor help
In-Reply-To: <1370614577.98981.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <CAPmHZoG1j1ZZ0VL9g+KTH3G-_rVMUoW5Xqg7DBawNNNxzOKeLg@mail.gmail.com>
	<1370614577.98981.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <51B1F634.8010202@fhcrc.org>

On 06/07/2013 07:16 AM, arun wrote:
> Hi,
>
> You would get better response if you post at Bioconductor mailing list.
> http://www.bioconductor.org/help/mailing-list/

Agreed, though in this case I think

> ReadAffyData <- function( filename ) {
...
>     Data <- ReadAffy( sampleNames=as.character( Cov$Label),
>                      phenoData=tmp, verbose=TRUE )
> }
>
> preQC <- function(name){
>     ReadAffyData(name)

what needs to happen here is that the return value needs to be assigned to a 
variable,

     Data <- ReadAffyData(name)

Martin

>
>
>     plotDensity( log2( pm( Data ) ), xlab="Log2( Intensity )", ylab="Density",
>                 main="Raw(PM)")
> }

>
> A.K.
>
> ----- Original Message -----
> From: Payal Urs <payal.urs at gmail.com>
> To: r-help at r-project.org
> Cc:
> Sent: Friday, June 7, 2013 6:12 AM
> Subject: [R] Bionconductor help
>
> Hi
>
> I am trying to do some data analysis using R and Bioconductor.  I have a
> function to read my data called "ReadAffyData" and a function to plot the
> data called "preqc".  I want to know if there is any way I can extract
> information (read: Data) from the ReadAffyData function into preqc in order
> to produce plots? I have not completely understood the inheritance in R and
> I am getting errors similar to the one below. I am new to R and could do
> with any help in this aspect!
>
> ReadAffyData <- function( filename ) {
...
>    Data <- ReadAffy( sampleNames=as.character( Cov$Label ),phenoData=tmp, verbose=TRUE )
> }
>
> preQC <- function(name){
>     ReadAffyData(name)
> plotDensity( log2( pm( Data ) ), xlab="Log2( Intensity )", ylab="Density",
> main="Raw(PM)")
> }
>
> preQC("cov.txt")
> 1 reading C:/CEL/GSM311471.CEL ...instantiating an AffyBatch (intensity a
> 506944x24 matrix)...done.
> Reading in : C:/CEL/GSM311471.CEL
> Reading in : C:/CEL/GSM311472.CEL
> Reading in : C:/CEL/GSM311473.CEL
> Reading in : C:/CEL/GSM311474.CEL
> Reading in : C:/CEL/GSM311475.CEL
> .
> .
> .
> Error in pm(Data) :
>    error in evaluating the argument 'object' in selecting a method for
> function 'pm': Error: object 'Data' not found
>
> sessionInf()
> R version 3.0.1 (2013-05-16)
> Platform: i386-w64-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=English_India.1252  LC_CTYPE=English_India.1252
> LC_MONETARY=English_India.1252
> [4] LC_NUMERIC=C                   LC_TIME=English_India.1252
>
> attached base packages:
> [1] parallel  stats     graphics  grDevices utils     datasets  methods
> base
>
> other attached packages:
> [1] annotate_1.38.0      AnnotationDbi_1.22.6 affy_1.38.1
> Biobase_2.20.0       BiocGenerics_0.6.0
>
> loaded via a namespace (and not attached):
> [1] affyio_1.28.0         BiocInstaller_1.10.1  DBI_0.2-7
> IRanges_1.18.1        preprocessCore_1.22.0
> [6] RSQLite_0.11.4        stats4_3.0.1          tools_3.0.1
> XML_3.96-1.1          xtable_1.7-1
> [11] zlibbioc_1.6.0
>
>
>
> Thanking you,
> Ipsitha
> Graduate Student
> London
>
>      [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From lidaof at gmail.com  Fri Jun  7 16:44:18 2013
From: lidaof at gmail.com (Daofeng Li)
Date: Fri, 7 Jun 2013 09:44:18 -0500
Subject: [R] glm.nb error
Message-ID: <CAGSXrvEuLUR2pfMQazxPomeRPYCrShmxiL52tHXxobkJzEkuuA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/ac36e952/attachment.pl>

From pdalgd at gmail.com  Fri Jun  7 17:12:30 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 7 Jun 2013 17:12:30 +0200
Subject: [R] Clogit R and Stata
In-Reply-To: <1370612073.93488.YahooMailNeo@web163803.mail.gq1.yahoo.com>
References: <1370612073.93488.YahooMailNeo@web163803.mail.gq1.yahoo.com>
Message-ID: <3ABD3D67-B7E7-4E7E-9128-413F1D0967B4@gmail.com>


On Jun 7, 2013, at 15:34 , Richard Beckett wrote:

> Sorry to once again write a message but I'm once again stumped and am having no luck finding a solution anywhere else.
> 
> 
> This question requires some finesse in both R and STATA so hopefully I will be able to get an answer here. I am much more adept in R and am trying to replicate the results of a STATA file in R. Hopefully this is a proper forum for such questions. 
> 
> 
> This is the code for the clogit in STATA
> clogit sftpcons sftptv2a3 sftptv2a4 sftptv2a5 sftptv2a2 sftptv2a6 logim maccat disp4cat if sample==1 & glb_ind=="Y", group(stratida)
> and I tried to replicate it using
> clogit1<-clogit(sftpcons~sftptv2a3+sftptv2a4+sftptv2a5+sftptv2a2+sftptv2a6+logim+maccat+disp4cat+strata(stratida), dframe, sample==1 | glb_ind=="Y")
> but got different results
> What did I do wrong here? I interpreted the STATA clogit as run this logit as long as the sample is 1 and glb_ind="Y" What should I be doing instead?


An "&" rather than "|" in the R version might help. Other than that, we're a bit short on clues unless you provide some output.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From sarah.goslee at gmail.com  Fri Jun  7 17:13:40 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 7 Jun 2013 11:13:40 -0400
Subject: [R] glm.nb error
In-Reply-To: <CAGSXrvEuLUR2pfMQazxPomeRPYCrShmxiL52tHXxobkJzEkuuA@mail.gmail.com>
References: <CAGSXrvEuLUR2pfMQazxPomeRPYCrShmxiL52tHXxobkJzEkuuA@mail.gmail.com>
Message-ID: <CAM_vju=cMykOUVBQV5smrVVZsKah4m2px1_7h5gjkSACi2aqPg@mail.gmail.com>

Hi,

On Fri, Jun 7, 2013 at 10:44 AM, Daofeng Li <lidaof at gmail.com> wrote:
> Dear R Community,
>
> I have encountered a problem while using the R function glm.nb.
> The code that produce the error was following two lines:
>
> group=c(1,1,1,1,0,0,0,0)
> fit=glm.nb(y~group)
>
> While the y contains 8 sets of number like:
> gene275        0       1       0       0       1       5       1       0
>
> Error message:
>
> Error in while ((it <- it + 1) < limit && abs(del) > eps) { :
>   missing value where TRUE/FALSE needed
> Calls: glm.nb -> as.vector -> theta.ml
> In addition: There were 50 or more warnings (use warnings() to see the
> first 50)
> Execution halted

I'd assume there is a missing value somewhere.

But we really need a reproducible example to be certain. You could use
dput(head(yourdata, 20)) to give us something to work with (as long as
that much of your data throws the error).

At the very least, we probably also need
str(y)
str(group)

Are you certain there are no missing values in your data? The problem
may not be that obvious, but that's an easy place to start.

Sarah

>
> Information of my system:
>> sessionInfo()
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=C                 LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> Does anyone happen to have some hit on how to solve this?
> Appreciate for any response.
>
> Thanks in advance,
>
> Daofeng
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From marc_schwartz at me.com  Fri Jun  7 17:15:43 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 07 Jun 2013 10:15:43 -0500
Subject: [R] glm.nb error
In-Reply-To: <CAGSXrvEuLUR2pfMQazxPomeRPYCrShmxiL52tHXxobkJzEkuuA@mail.gmail.com>
References: <CAGSXrvEuLUR2pfMQazxPomeRPYCrShmxiL52tHXxobkJzEkuuA@mail.gmail.com>
Message-ID: <C5A273CE-DEAF-40E8-A96F-6D9C3A1A151E@me.com>


On Jun 7, 2013, at 9:44 AM, Daofeng Li <lidaof at gmail.com> wrote:

> Dear R Community,
> 
> I have encountered a problem while using the R function glm.nb.
> The code that produce the error was following two lines:
> 
> group=c(1,1,1,1,0,0,0,0)
> fit=glm.nb(y~group)
> 
> While the y contains 8 sets of number like:
> gene275        0       1       0       0       1       5       1       0
> 
> Error message:
> 
> Error in while ((it <- it + 1) < limit && abs(del) > eps) { :
>  missing value where TRUE/FALSE needed
> Calls: glm.nb -> as.vector -> theta.ml
> In addition: There were 50 or more warnings (use warnings() to see the
> first 50)
> Execution halted
> 
> 
> Information of my system:
>> sessionInfo()
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-unknown-linux-gnu (64-bit)
> 
> locale:
> [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> [7] LC_PAPER=C                 LC_NAME=C
> [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> Does anyone happen to have some hit on how to solve this?
> Appreciate for any response.
> 
> Thanks in advance,
> 
> Daofeng


There is something wrong with your actual 'y' or 'group' that is not evident from the above info:


group <- c(1, 1, 1, 1, 0, 0, 0, 0)
y <- c(0, 1, 0, 0, 1, 5, 1, 0)

> require(MASS)
Loading required package: MASS

> glm.nb(y ~ group)

Call:  glm.nb(formula = y ~ group, init.theta = 1.711564307, link = log)

Coefficients:
(Intercept)        group  
     0.5596      -1.9459  

Degrees of Freedom: 7 Total (i.e. Null);  6 Residual
Null Deviance:	    10.23 
Residual Deviance: 6.848 	AIC: 25.25


Check str(y) and str(group)

You should also be sure to note in your posts when you are using a function from a non-base package, in this case MASS, which is not indicated in your sessionInfo() above, so something is amiss there as well.

Regards,

Marc Schwartz


From smartpink111 at yahoo.com  Fri Jun  7 17:25:41 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 7 Jun 2013 08:25:41 -0700 (PDT)
Subject: [R] matched samples, dataframe, panel data
In-Reply-To: <104083AE5AAA634C993249DFCCE4C20306439641@CIPRESTE.ua.pt>
References: <104083AE5AAA634C993249DFCCE4C20306439641@CIPRESTE.ua.pt>
Message-ID: <1370618741.16808.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
May be this helps:
?lst1<-split(final3,list(final3$year,final3$industry))
lst2<-lst1[lapply(lst1,nrow)>0]
lst3<-lapply(lst2,function(x) lapply(x$dimension,function(y) x[(y< (x$dimension+x$dimension*0.1)) & (y> (x$dimension-x$dimension*0.1)),]))
lst4<-lapply(lst3,function(x) x[lapply(x,nrow)==2])
lst5<-lapply(lst4,function(x)x[!duplicated(x)])
lst6<-lst5[lapply(lst5,length)>0]

names(lst6)
# [1] "2000.20" "2001.20" "2002.20" "2003.20" "2004.20" "2001.30" "2002.30"
?#[8] "2001.40" "2002.40" "2003.40" "2004.40"


lst6["2000.20"]
#$`2000.20`
#$`2000.20`[[1]]
?#? firm year industry dummy dimension
#1???? 1 2000?????? 20???? 0????? 2120
#21??? 5 2000?????? 20???? 1????? 2189
#
#$`2000.20`[[2]]
?#? firm year industry dummy dimension
#16??? 4 2000?????? 20???? 0????? 3178
#31??? 7 2000?????? 20???? 1????? 3245
#
#$`2000.20`[[3]]
?#? firm year industry dummy dimension
#11??? 3 2000?????? 20???? 1????? 4532
#6???? 2 2000?????? 20???? 0????? 4890
A.K.





________________________________
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: "r-help at r-project.org" <r-help at r-project.org> 
Cc: "smartpink111 at yahoo.com" <smartpink111 at yahoo.com> 
Sent: Friday, June 7, 2013 9:56 AM
Subject: Re: [R] matched samples, dataframe, panel data




Again my problem, better explained.

#I have a data panel of thousands of firms, by year and industry and 
#one dummy variable that identifies one kind of firms (1 if the firm have an auditor; 0 if not)
#and another variable the represents the firm dimension (total assets in thousand of euros)
#I need to create two separated samples with the same number os firms where 
#one firm in the first have a corresponding firm in the second with the same 
#year, industry and dimension (the dimension doesn't need to be exatly the
#same, it could vary in an interval of +/- 10%, for example)

#My reproducible example
firm1<-sort(rep(1:10,5),decreasing=F)
year1<-rep(2000:2004,10)
industry1<-rep(20,50)
dummy1<-c(0,0,1,1,0,0,1,1,0,1,1,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,1,0,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,1,1,1)
dimension1<-c(2120,345,2341,5678,10900,4890,2789,3412,9500,8765,4532,6593,12900,123,2345,3178,2678,6666,647,23789,
2189,4289,8543,637,23456,781,35489,2345,5754,8976,3245,1234,25,1200,2345,2765,389,23456,2367,3892,5438,37824,
23,2897,3456,7690,6022,3678,9431,2890)
data1<-data.frame(firm1,year1,industry1,dummy1,dimension1)
data1
colnames(data1)<-c("firm","year","industry","dummy","dimension")

firm2<-sort(rep(11:15,3),decreasing=F)
year2<-rep(2001:2003,5)
industry2<-rep(30,15)
dummy2<-c(0,0,0,0,0,0,1,1,1,1,1,1,1,0,1)
dimension2<-c(12456,781,32489,2345,5754,8976,3245,2120,345,2341,5678,10900,12900,123,2345)
data2<-data.frame(firm2,year2,industry2,dummy2,dimension2)
data2
colnames(data2)<-c("firm","year","industry","dummy","dimension")
firm3<-sort(rep(16:20,4),decreasing=F)
year3<-rep(2001:2004,5)
industry3<-rep(40,20)
dummy3<-c(0,0,1,0,1,0,1,0,1,1,1,1,1,0,0,0,0,1,0,0)
dimension3<-c(23456,1181,32489,2345,6754,8976,3245,1234,1288,1200,2345,2765,389,23456,2367,3892,6438,24824,
23,2897)
data3<-data.frame(firm3,year3,industry3,dummy3,dimension3)
data3
colnames(data3)<-c("firm","year","industry","dummy","dimension")

final1<-rbind(data1,data2)
final2<-rbind(final1,data3)
final2
final3<-final2[order(final2$year,final2$industry,final2$dimension),]
final3


#So my data is final3 is?like this: 
?? firm year industry dummy dimension
26??? 6 2000?????? 20???? 0?????? 781
1???? 1 2000?????? 20???? 0????? 2120
21??? 5 2000?????? 20???? 1????? 2189
36??? 8 2000?????? 20???? 1????? 2765
16??? 4 2000?????? 20???? 0????? 3178
31??? 7 2000?????? 20???? 1????? 3245
11??? 3 2000?????? 20???? 1????? 4532
6???? 2 2000?????? 20???? 0????? 4890
41??? 9 2000?????? 20???? 0????? 5438
46?? 10 2000?????? 20???? 0????? 7690
2???? 1 2001?????? 20???? 0?????? 345
37??? 8 2001?????? 20???? 1?????? 389
32??? 7 2001?????? 20???? 0????? 1234
17??? 4 2001?????? 20???? 0????? 2678
7???? 2 2001?????? 20???? 1????? 2789
22??? 5 2001?????? 20???? 1????? 4289
47?? 10 2001?????? 20???? 0????? 6022
12??? 3 2001?????? 20???? 1????? 6593
27??? 6 2001?????? 20???? 0???? 35489
42??? 9 2001?????? 20???? 1???? 37824
60?? 14 2001?????? 30???? 1????? 2341
54?? 12 2001?????? 30???? 0????? 2345
57?? 13 2001?????? 30???? 1????? 3245
51?? 11 2001?????? 30???? 0???? 12456
63?? 15 2001?????? 30???? 1???? 12900
78?? 19 2001?????? 40???? 1?????? 389
74?? 18 2001?????? 40???? 1????? 1288
82?? 20 2001?????? 40???? 0????? 6438
70?? 17 2001?????? 40???? 1????? 6754
66?? 16 2001?????? 40???? 0???? 23456
43??? 9 2002?????? 20???? 0??????? 23
33??? 7 2002?????? 20???? 1??????? 25
3???? 1 2002?????? 20???? 1????? 2341
28??? 6 2002?????? 20???? 0????? 2345
8???? 2 2002?????? 20???? 1????? 3412
48?? 10 2002?????? 20???? 1????? 3678
18??? 4 2002?????? 20???? 0????? 6666
23??? 5 2002?????? 20???? 0????? 8543
13??? 3 2002?????? 20???? 0???? 12900
38??? 8 2002?????? 20???? 1???? 23456
64?? 15 2002?????? 30???? 0?????? 123
52?? 11 2002?????? 30???? 0?????? 781
58?? 13 2002?????? 30???? 1????? 2120
61?? 14 2002?????? 30???? 1????? 5678
55?? 12 2002?????? 30???? 0????? 5754
67?? 16 2002?????? 40???? 0????? 1181
75?? 18 2002?????? 40???? 1????? 1200
71?? 17 2002?????? 40???? 0????? 8976
79?? 19 2002?????? 40???? 0???? 23456
83?? 20 2002?????? 40???? 1???? 24824
14??? 3 2003?????? 20???? 0?????? 123
24??? 5 2003?????? 20???? 0?????? 637
19??? 4 2003?????? 20???? 1?????? 647
34??? 7 2003?????? 20???? 0????? 1200
39??? 8 2003?????? 20???? 1????? 2367
44??? 9 2003?????? 20???? 0????? 2897
4???? 1 2003?????? 20???? 1????? 5678
29??? 6 2003?????? 20???? 0????? 5754
49?? 10 2003?????? 20???? 1????? 9431
9???? 2 2003?????? 20???? 0????? 9500
59?? 13 2003?????? 30???? 1?????? 345
65?? 15 2003?????? 30???? 1????? 2345
56?? 12 2003?????? 30???? 0????? 8976
62?? 14 2003?????? 30???? 1???? 10900
53?? 11 2003?????? 30???? 0???? 32489
84?? 20 2003?????? 40???? 0??????? 23
76?? 18 2003?????? 40???? 1????? 2345
80?? 19 2003?????? 40???? 0????? 2367
72?? 17 2003?????? 40???? 1????? 3245
68?? 16 2003?????? 40???? 1???? 32489
15??? 3 2004?????? 20???? 0????? 2345
35??? 7 2004?????? 20???? 1????? 2345
50?? 10 2004?????? 20???? 1????? 2890
45??? 9 2004?????? 20???? 0????? 3456
40??? 8 2004?????? 20???? 0????? 3892
10??? 2 2004?????? 20???? 1????? 8765
30??? 6 2004?????? 20???? 0????? 8976
5???? 1 2004?????? 20???? 0???? 10900
25??? 5 2004?????? 20???? 0???? 23456
20??? 4 2004?????? 20???? 1???? 23789
73?? 17 2004?????? 40???? 0????? 1234
69?? 16 2004?????? 40???? 0????? 2345
77?? 18 2004?????? 40???? 1????? 2765
85?? 20 2004?????? 40???? 0????? 2897
81?? 19 2004?????? 40???? 0????? 3892

I want to keep couples of firms one with dummy=1 and other with dummy=0 that matchs in industry, firm and dimension.

But dimension doesn't need to be exactly the same, it is why I refer an interval of + or - 10%.

For example firm 1 matchs with firm 5, because they have the same year, industry, dimension (10% x 2120 = 212 and 2189-2120<212)
and firm 1 is dummy=0 and firm 5 is dummy=1.

So I want to delete firm 6 because it doesn't macth with any firm, and keep firm 1 and 5.

???? firm year industry dummy dimension
26??? 6 2000?????? 20???? 0?????? 781
1???? 1 2000?????? 20???? 0????? 2120
21??? 5 2000?????? 20???? 1????? 2189

Next,

Now I can match firm 4 with firm 7 and delete firm 8.
36??? 8 2000?????? 20???? 1????? 2765
16??? 4 2000?????? 20???? 0????? 3178
31??? 7 2000?????? 20???? 1????? 3245

And so on...

At the end I want to keep only pairs of firms, matched by year, industry and dimension.

If I separate firms with dummy=1 from firms with?dummy=0 in two separated dataframes, I have two matched samples
with the same number of observations. That's what I want.

Thank you,
Cec?lia Carmo 
Universidade de Aveiro - Portugal?????????


From careyshan at gmail.com  Fri Jun  7 17:38:44 2013
From: careyshan at gmail.com (Shane Carey)
Date: Fri, 7 Jun 2013 16:38:44 +0100
Subject: [R] Horizontal labels on a plot
Message-ID: <CA+jRDxAzS4fteUaYOWnch7yDTnbLNxcM6yOxy9U_D+qR22RLxA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/1f99ea76/attachment.pl>

From smartpink111 at yahoo.com  Fri Jun  7 17:43:13 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 7 Jun 2013 08:43:13 -0700 (PDT)
Subject: [R] matched samples, dataframe, panel data
In-Reply-To: <104083AE5AAA634C993249DFCCE4C20306439664@CIPRESTE.ua.pt>
References: <104083AE5AAA634C993249DFCCE4C20306439641@CIPRESTE.ua.pt>
	<1370618741.16808.YahooMailNeo@web142605.mail.bf1.yahoo.com>,
	<1370618875.52646.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<104083AE5AAA634C993249DFCCE4C20306439664@CIPRESTE.ua.pt>
Message-ID: <1370619793.18982.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
Not sure if this is what you wanted.

?res<-do.call(rbind,lapply(lst6,function(x) do.call(rbind,x)))
?row.names(res)<-1:nrow(res)

# this combines the list of lists to a data.frame
res[1:4,]
#? firm year industry dummy dimension
#1??? 1 2000?????? 20???? 0????? 2120
#2??? 5 2000?????? 20???? 1????? 2189
#3??? 4 2000?????? 20???? 0????? 3178
#4??? 7 2000?????? 20???? 1????? 3245


#or
?res<-do.call(rbind,lapply(lst6,function(x) do.call(rbind,x)))
?res$group<-gsub("(.*\\..*)\\..*$","\\1",rownames(res))
?row.names(res)<-1:nrow(res)
?res[1:4,]
#? firm year industry dummy dimension?? group
#1??? 1 2000?????? 20???? 0????? 2120 2000.20?? #1 group
#2??? 5 2000?????? 20???? 1????? 2189 2000.20?? #1
#3??? 4 2000?????? 20???? 0????? 3178 2000.20?? #2
#4??? 7 2000?????? 20???? 1????? 3245 2000.20?? #2
A.K.


----- Original Message -----
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Cc: 
Sent: Friday, June 7, 2013 11:33 AM
Subject: RE: [R] matched samples, dataframe, panel data

Thank you very much. 
Just a little thing: how can I put it like a dataframe?

Thanks,

Cec?lia

________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: sexta-feira, 7 de Junho de 2013 16:27
Para: Cecilia Carmo
Assunto: Re: [R] matched samples, dataframe, panel data

Hi,
There could be easier ways...? I am a bit busy now to try other ways.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Cecilia Carmo <cecilia.carmo at ua.pt>
Cc: R help <r-help at r-project.org>
Sent: Friday, June 7, 2013 11:25 AM
Subject: Re: [R] matched samples, dataframe, panel data

Hi,
May be this helps:
lst1<-split(final3,list(final3$year,final3$industry))
lst2<-lst1[lapply(lst1,nrow)>0]
lst3<-lapply(lst2,function(x) lapply(x$dimension,function(y) x[(y< (x$dimension+x$dimension*0.1)) & (y> (x$dimension-x$dimension*0.1)),]))
lst4<-lapply(lst3,function(x) x[lapply(x,nrow)==2])
lst5<-lapply(lst4,function(x)x[!duplicated(x)])
lst6<-lst5[lapply(lst5,length)>0]

names(lst6)
# [1] "2000.20" "2001.20" "2002.20" "2003.20" "2004.20" "2001.30" "2002.30"
#[8] "2001.40" "2002.40" "2003.40" "2004.40"


lst6["2000.20"]
#$`2000.20`
#$`2000.20`[[1]]
#? firm year industry dummy dimension
#1? ?  1 2000? ? ?  20? ?  0? ? ? 2120
#21? ? 5 2000? ? ?  20? ?  1? ? ? 2189
#
#$`2000.20`[[2]]
#? firm year industry dummy dimension
#16? ? 4 2000? ? ?  20? ?  0? ? ? 3178
#31? ? 7 2000? ? ?  20? ?  1? ? ? 3245
#
#$`2000.20`[[3]]
#? firm year industry dummy dimension
#11? ? 3 2000? ? ?  20? ?  1? ? ? 4532
#6? ?  2 2000? ? ?  20? ?  0? ? ? 4890
A.K.





________________________________
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: "smartpink111 at yahoo.com" <smartpink111 at yahoo.com>
Sent: Friday, June 7, 2013 9:56 AM
Subject: Re: [R] matched samples, dataframe, panel data




Again my problem, better explained.

#I have a data panel of thousands of firms, by year and industry and
#one dummy variable that identifies one kind of firms (1 if the firm have an auditor; 0 if not)
#and another variable the represents the firm dimension (total assets in thousand of euros)
#I need to create two separated samples with the same number os firms where
#one firm in the first have a corresponding firm in the second with the same
#year, industry and dimension (the dimension doesn't need to be exatly the
#same, it could vary in an interval of +/- 10%, for example)

#My reproducible example
firm1<-sort(rep(1:10,5),decreasing=F)
year1<-rep(2000:2004,10)
industry1<-rep(20,50)
dummy1<-c(0,0,1,1,0,0,1,1,0,1,1,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,1,0,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,1,1,1)
dimension1<-c(2120,345,2341,5678,10900,4890,2789,3412,9500,8765,4532,6593,12900,123,2345,3178,2678,6666,647,23789,
2189,4289,8543,637,23456,781,35489,2345,5754,8976,3245,1234,25,1200,2345,2765,389,23456,2367,3892,5438,37824,
23,2897,3456,7690,6022,3678,9431,2890)
data1<-data.frame(firm1,year1,industry1,dummy1,dimension1)
data1
colnames(data1)<-c("firm","year","industry","dummy","dimension")

firm2<-sort(rep(11:15,3),decreasing=F)
year2<-rep(2001:2003,5)
industry2<-rep(30,15)
dummy2<-c(0,0,0,0,0,0,1,1,1,1,1,1,1,0,1)
dimension2<-c(12456,781,32489,2345,5754,8976,3245,2120,345,2341,5678,10900,12900,123,2345)
data2<-data.frame(firm2,year2,industry2,dummy2,dimension2)
data2
colnames(data2)<-c("firm","year","industry","dummy","dimension")
firm3<-sort(rep(16:20,4),decreasing=F)
year3<-rep(2001:2004,5)
industry3<-rep(40,20)
dummy3<-c(0,0,1,0,1,0,1,0,1,1,1,1,1,0,0,0,0,1,0,0)
dimension3<-c(23456,1181,32489,2345,6754,8976,3245,1234,1288,1200,2345,2765,389,23456,2367,3892,6438,24824,
23,2897)
data3<-data.frame(firm3,year3,industry3,dummy3,dimension3)
data3
colnames(data3)<-c("firm","year","industry","dummy","dimension")

final1<-rbind(data1,data2)
final2<-rbind(final1,data3)
final2
final3<-final2[order(final2$year,final2$industry,final2$dimension),]
final3


#So my data is final3 is like this:
?  firm year industry dummy dimension
26? ? 6 2000? ? ?  20? ?  0? ? ?  781
1? ?  1 2000? ? ?  20? ?  0? ? ? 2120
21? ? 5 2000? ? ?  20? ?  1? ? ? 2189
36? ? 8 2000? ? ?  20? ?  1? ? ? 2765
16? ? 4 2000? ? ?  20? ?  0? ? ? 3178
31? ? 7 2000? ? ?  20? ?  1? ? ? 3245
11? ? 3 2000? ? ?  20? ?  1? ? ? 4532
6? ?  2 2000? ? ?  20? ?  0? ? ? 4890
41? ? 9 2000? ? ?  20? ?  0? ? ? 5438
46?  10 2000? ? ?  20? ?  0? ? ? 7690
2? ?  1 2001? ? ?  20? ?  0? ? ?  345
37? ? 8 2001? ? ?  20? ?  1? ? ?  389
32? ? 7 2001? ? ?  20? ?  0? ? ? 1234
17? ? 4 2001? ? ?  20? ?  0? ? ? 2678
7? ?  2 2001? ? ?  20? ?  1? ? ? 2789
22? ? 5 2001? ? ?  20? ?  1? ? ? 4289
47?  10 2001? ? ?  20? ?  0? ? ? 6022
12? ? 3 2001? ? ?  20? ?  1? ? ? 6593
27? ? 6 2001? ? ?  20? ?  0? ?  35489
42? ? 9 2001? ? ?  20? ?  1? ?  37824
60?  14 2001? ? ?  30? ?  1? ? ? 2341
54?  12 2001? ? ?  30? ?  0? ? ? 2345
57?  13 2001? ? ?  30? ?  1? ? ? 3245
51?  11 2001? ? ?  30? ?  0? ?  12456
63?  15 2001? ? ?  30? ?  1? ?  12900
78?  19 2001? ? ?  40? ?  1? ? ?  389
74?  18 2001? ? ?  40? ?  1? ? ? 1288
82?  20 2001? ? ?  40? ?  0? ? ? 6438
70?  17 2001? ? ?  40? ?  1? ? ? 6754
66?  16 2001? ? ?  40? ?  0? ?  23456
43? ? 9 2002? ? ?  20? ?  0? ? ? ? 23
33? ? 7 2002? ? ?  20? ?  1? ? ? ? 25
3? ?  1 2002? ? ?  20? ?  1? ? ? 2341
28? ? 6 2002? ? ?  20? ?  0? ? ? 2345
8? ?  2 2002? ? ?  20? ?  1? ? ? 3412
48?  10 2002? ? ?  20? ?  1? ? ? 3678
18? ? 4 2002? ? ?  20? ?  0? ? ? 6666
23? ? 5 2002? ? ?  20? ?  0? ? ? 8543
13? ? 3 2002? ? ?  20? ?  0? ?  12900
38? ? 8 2002? ? ?  20? ?  1? ?  23456
64?  15 2002? ? ?  30? ?  0? ? ?  123
52?  11 2002? ? ?  30? ?  0? ? ?  781
58?  13 2002? ? ?  30? ?  1? ? ? 2120
61?  14 2002? ? ?  30? ?  1? ? ? 5678
55?  12 2002? ? ?  30? ?  0? ? ? 5754
67?  16 2002? ? ?  40? ?  0? ? ? 1181
75?  18 2002? ? ?  40? ?  1? ? ? 1200
71?  17 2002? ? ?  40? ?  0? ? ? 8976
79?  19 2002? ? ?  40? ?  0? ?  23456
83?  20 2002? ? ?  40? ?  1? ?  24824
14? ? 3 2003? ? ?  20? ?  0? ? ?  123
24? ? 5 2003? ? ?  20? ?  0? ? ?  637
19? ? 4 2003? ? ?  20? ?  1? ? ?  647
34? ? 7 2003? ? ?  20? ?  0? ? ? 1200
39? ? 8 2003? ? ?  20? ?  1? ? ? 2367
44? ? 9 2003? ? ?  20? ?  0? ? ? 2897
4? ?  1 2003? ? ?  20? ?  1? ? ? 5678
29? ? 6 2003? ? ?  20? ?  0? ? ? 5754
49?  10 2003? ? ?  20? ?  1? ? ? 9431
9? ?  2 2003? ? ?  20? ?  0? ? ? 9500
59?  13 2003? ? ?  30? ?  1? ? ?  345
65?  15 2003? ? ?  30? ?  1? ? ? 2345
56?  12 2003? ? ?  30? ?  0? ? ? 8976
62?  14 2003? ? ?  30? ?  1? ?  10900
53?  11 2003? ? ?  30? ?  0? ?  32489
84?  20 2003? ? ?  40? ?  0? ? ? ? 23
76?  18 2003? ? ?  40? ?  1? ? ? 2345
80?  19 2003? ? ?  40? ?  0? ? ? 2367
72?  17 2003? ? ?  40? ?  1? ? ? 3245
68?  16 2003? ? ?  40? ?  1? ?  32489
15? ? 3 2004? ? ?  20? ?  0? ? ? 2345
35? ? 7 2004? ? ?  20? ?  1? ? ? 2345
50?  10 2004? ? ?  20? ?  1? ? ? 2890
45? ? 9 2004? ? ?  20? ?  0? ? ? 3456
40? ? 8 2004? ? ?  20? ?  0? ? ? 3892
10? ? 2 2004? ? ?  20? ?  1? ? ? 8765
30? ? 6 2004? ? ?  20? ?  0? ? ? 8976
5? ?  1 2004? ? ?  20? ?  0? ?  10900
25? ? 5 2004? ? ?  20? ?  0? ?  23456
20? ? 4 2004? ? ?  20? ?  1? ?  23789
73?  17 2004? ? ?  40? ?  0? ? ? 1234
69?  16 2004? ? ?  40? ?  0? ? ? 2345
77?  18 2004? ? ?  40? ?  1? ? ? 2765
85?  20 2004? ? ?  40? ?  0? ? ? 2897
81?  19 2004? ? ?  40? ?  0? ? ? 3892

I want to keep couples of firms one with dummy=1 and other with dummy=0 that matchs in industry, firm and dimension.

But dimension doesn't need to be exactly the same, it is why I refer an interval of + or - 10%.

For example firm 1 matchs with firm 5, because they have the same year, industry, dimension (10% x 2120 = 212 and 2189-2120<212)
and firm 1 is dummy=0 and firm 5 is dummy=1.

So I want to delete firm 6 because it doesn't macth with any firm, and keep firm 1 and 5.

? ?  firm year industry dummy dimension
26? ? 6 2000? ? ?  20? ?  0? ? ?  781
1? ?  1 2000? ? ?  20? ?  0? ? ? 2120
21? ? 5 2000? ? ?  20? ?  1? ? ? 2189

Next,

Now I can match firm 4 with firm 7 and delete firm 8.
36? ? 8 2000? ? ?  20? ?  1? ? ? 2765
16? ? 4 2000? ? ?  20? ?  0? ? ? 3178
31? ? 7 2000? ? ?  20? ?  1? ? ? 3245

And so on...

At the end I want to keep only pairs of firms, matched by year, industry and dimension.

If I separate firms with dummy=1 from firms with dummy=0 in two separated dataframes, I have two matched samples
with the same number of observations. That's what I want.

Thank you,
Cec?lia Carmo
Universidade de Aveiro - Portugal


From cecilia.carmo at ua.pt  Fri Jun  7 17:45:35 2013
From: cecilia.carmo at ua.pt (Cecilia Carmo)
Date: Fri, 7 Jun 2013 15:45:35 +0000
Subject: [R] matched samples, dataframe, panel data
In-Reply-To: <1370619793.18982.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <104083AE5AAA634C993249DFCCE4C20306439641@CIPRESTE.ua.pt>
	<1370618741.16808.YahooMailNeo@web142605.mail.bf1.yahoo.com>,
	<1370618875.52646.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<104083AE5AAA634C993249DFCCE4C20306439664@CIPRESTE.ua.pt>,
	<1370619793.18982.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <104083AE5AAA634C993249DFCCE4C20306439688@CIPRESTE.ua.pt>

That's it, the first one!

Thank you very much,

Cec?lia Carmo


________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: sexta-feira, 7 de Junho de 2013 16:43
Para: Cecilia Carmo
Cc: R help
Assunto: Re: [R] matched samples, dataframe, panel data

Hi,
Not sure if this is what you wanted.

 res<-do.call(rbind,lapply(lst6,function(x) do.call(rbind,x)))
 row.names(res)<-1:nrow(res)

# this combines the list of lists to a data.frame
res[1:4,]
#  firm year industry dummy dimension
#1    1 2000       20     0      2120
#2    5 2000       20     1      2189
#3    4 2000       20     0      3178
#4    7 2000       20     1      3245


#or
 res<-do.call(rbind,lapply(lst6,function(x) do.call(rbind,x)))
 res$group<-gsub("(.*\\..*)\\..*$","\\1",rownames(res))
 row.names(res)<-1:nrow(res)
 res[1:4,]
#  firm year industry dummy dimension   group
#1    1 2000       20     0      2120 2000.20   #1 group
#2    5 2000       20     1      2189 2000.20   #1
#3    4 2000       20     0      3178 2000.20   #2
#4    7 2000       20     1      3245 2000.20   #2
A.K.


----- Original Message -----
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Cc:
Sent: Friday, June 7, 2013 11:33 AM
Subject: RE: [R] matched samples, dataframe, panel data

Thank you very much.
Just a little thing: how can I put it like a dataframe?

Thanks,

Cec?lia

________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: sexta-feira, 7 de Junho de 2013 16:27
Para: Cecilia Carmo
Assunto: Re: [R] matched samples, dataframe, panel data

Hi,
There could be easier ways...  I am a bit busy now to try other ways.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Cecilia Carmo <cecilia.carmo at ua.pt>
Cc: R help <r-help at r-project.org>
Sent: Friday, June 7, 2013 11:25 AM
Subject: Re: [R] matched samples, dataframe, panel data

Hi,
May be this helps:
lst1<-split(final3,list(final3$year,final3$industry))
lst2<-lst1[lapply(lst1,nrow)>0]
lst3<-lapply(lst2,function(x) lapply(x$dimension,function(y) x[(y< (x$dimension+x$dimension*0.1)) & (y> (x$dimension-x$dimension*0.1)),]))
lst4<-lapply(lst3,function(x) x[lapply(x,nrow)==2])
lst5<-lapply(lst4,function(x)x[!duplicated(x)])
lst6<-lst5[lapply(lst5,length)>0]

names(lst6)
# [1] "2000.20" "2001.20" "2002.20" "2003.20" "2004.20" "2001.30" "2002.30"
#[8] "2001.40" "2002.40" "2003.40" "2004.40"


lst6["2000.20"]
#$`2000.20`
#$`2000.20`[[1]]
#  firm year industry dummy dimension
#1     1 2000       20     0      2120
#21    5 2000       20     1      2189
#
#$`2000.20`[[2]]
#  firm year industry dummy dimension
#16    4 2000       20     0      3178
#31    7 2000       20     1      3245
#
#$`2000.20`[[3]]
#  firm year industry dummy dimension
#11    3 2000       20     1      4532
#6     2 2000       20     0      4890
A.K.





________________________________
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: "r-help at r-project.org" <r-help at r-project.org>

Sent: Friday, June 7, 2013 9:56 AM
Subject: Re: [R] matched samples, dataframe, panel data




Again my problem, better explained.

#I have a data panel of thousands of firms, by year and industry and
#one dummy variable that identifies one kind of firms (1 if the firm have an auditor; 0 if not)
#and another variable the represents the firm dimension (total assets in thousand of euros)
#I need to create two separated samples with the same number os firms where
#one firm in the first have a corresponding firm in the second with the same
#year, industry and dimension (the dimension doesn't need to be exatly the
#same, it could vary in an interval of +/- 10%, for example)

#My reproducible example
firm1<-sort(rep(1:10,5),decreasing=F)
year1<-rep(2000:2004,10)
industry1<-rep(20,50)
dummy1<-c(0,0,1,1,0,0,1,1,0,1,1,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,1,0,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,1,1,1)
dimension1<-c(2120,345,2341,5678,10900,4890,2789,3412,9500,8765,4532,6593,12900,123,2345,3178,2678,6666,647,23789,
2189,4289,8543,637,23456,781,35489,2345,5754,8976,3245,1234,25,1200,2345,2765,389,23456,2367,3892,5438,37824,
23,2897,3456,7690,6022,3678,9431,2890)
data1<-data.frame(firm1,year1,industry1,dummy1,dimension1)
data1
colnames(data1)<-c("firm","year","industry","dummy","dimension")

firm2<-sort(rep(11:15,3),decreasing=F)
year2<-rep(2001:2003,5)
industry2<-rep(30,15)
dummy2<-c(0,0,0,0,0,0,1,1,1,1,1,1,1,0,1)
dimension2<-c(12456,781,32489,2345,5754,8976,3245,2120,345,2341,5678,10900,12900,123,2345)
data2<-data.frame(firm2,year2,industry2,dummy2,dimension2)
data2
colnames(data2)<-c("firm","year","industry","dummy","dimension")
firm3<-sort(rep(16:20,4),decreasing=F)
year3<-rep(2001:2004,5)
industry3<-rep(40,20)
dummy3<-c(0,0,1,0,1,0,1,0,1,1,1,1,1,0,0,0,0,1,0,0)
dimension3<-c(23456,1181,32489,2345,6754,8976,3245,1234,1288,1200,2345,2765,389,23456,2367,3892,6438,24824,
23,2897)
data3<-data.frame(firm3,year3,industry3,dummy3,dimension3)
data3
colnames(data3)<-c("firm","year","industry","dummy","dimension")

final1<-rbind(data1,data2)
final2<-rbind(final1,data3)
final2
final3<-final2[order(final2$year,final2$industry,final2$dimension),]
final3


#So my data is final3 is like this:
   firm year industry dummy dimension
26    6 2000       20     0       781
1     1 2000       20     0      2120
21    5 2000       20     1      2189
36    8 2000       20     1      2765
16    4 2000       20     0      3178
31    7 2000       20     1      3245
11    3 2000       20     1      4532
6     2 2000       20     0      4890
41    9 2000       20     0      5438
46   10 2000       20     0      7690
2     1 2001       20     0       345
37    8 2001       20     1       389
32    7 2001       20     0      1234
17    4 2001       20     0      2678
7     2 2001       20     1      2789
22    5 2001       20     1      4289
47   10 2001       20     0      6022
12    3 2001       20     1      6593
27    6 2001       20     0     35489
42    9 2001       20     1     37824
60   14 2001       30     1      2341
54   12 2001       30     0      2345
57   13 2001       30     1      3245
51   11 2001       30     0     12456
63   15 2001       30     1     12900
78   19 2001       40     1       389
74   18 2001       40     1      1288
82   20 2001       40     0      6438
70   17 2001       40     1      6754
66   16 2001       40     0     23456
43    9 2002       20     0        23
33    7 2002       20     1        25
3     1 2002       20     1      2341
28    6 2002       20     0      2345
8     2 2002       20     1      3412
48   10 2002       20     1      3678
18    4 2002       20     0      6666
23    5 2002       20     0      8543
13    3 2002       20     0     12900
38    8 2002       20     1     23456
64   15 2002       30     0       123
52   11 2002       30     0       781
58   13 2002       30     1      2120
61   14 2002       30     1      5678
55   12 2002       30     0      5754
67   16 2002       40     0      1181
75   18 2002       40     1      1200
71   17 2002       40     0      8976
79   19 2002       40     0     23456
83   20 2002       40     1     24824
14    3 2003       20     0       123
24    5 2003       20     0       637
19    4 2003       20     1       647
34    7 2003       20     0      1200
39    8 2003       20     1      2367
44    9 2003       20     0      2897
4     1 2003       20     1      5678
29    6 2003       20     0      5754
49   10 2003       20     1      9431
9     2 2003       20     0      9500
59   13 2003       30     1       345
65   15 2003       30     1      2345
56   12 2003       30     0      8976
62   14 2003       30     1     10900
53   11 2003       30     0     32489
84   20 2003       40     0        23
76   18 2003       40     1      2345
80   19 2003       40     0      2367
72   17 2003       40     1      3245
68   16 2003       40     1     32489
15    3 2004       20     0      2345
35    7 2004       20     1      2345
50   10 2004       20     1      2890
45    9 2004       20     0      3456
40    8 2004       20     0      3892
10    2 2004       20     1      8765
30    6 2004       20     0      8976
5     1 2004       20     0     10900
25    5 2004       20     0     23456
20    4 2004       20     1     23789
73   17 2004       40     0      1234
69   16 2004       40     0      2345
77   18 2004       40     1      2765
85   20 2004       40     0      2897
81   19 2004       40     0      3892

I want to keep couples of firms one with dummy=1 and other with dummy=0 that matchs in industry, firm and dimension.

But dimension doesn't need to be exactly the same, it is why I refer an interval of + or - 10%.

For example firm 1 matchs with firm 5, because they have the same year, industry, dimension (10% x 2120 = 212 and 2189-2120<212)
and firm 1 is dummy=0 and firm 5 is dummy=1.

So I want to delete firm 6 because it doesn't macth with any firm, and keep firm 1 and 5.

     firm year industry dummy dimension
26    6 2000       20     0       781
1     1 2000       20     0      2120
21    5 2000       20     1      2189

Next,

Now I can match firm 4 with firm 7 and delete firm 8.
36    8 2000       20     1      2765
16    4 2000       20     0      3178
31    7 2000       20     1      3245

And so on...

At the end I want to keep only pairs of firms, matched by year, industry and dimension.

If I separate firms with dummy=1 from firms with dummy=0 in two separated dataframes, I have two matched samples
with the same number of observations. That's what I want.

Thank you,
Cec?lia Carmo
Universidade de Aveiro - Portugal

From sarah.goslee at gmail.com  Fri Jun  7 17:47:08 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 7 Jun 2013 11:47:08 -0400
Subject: [R] glm.nb error
In-Reply-To: <CAGSXrvHKAM82x8g7KHQEKqEa2RdR5_HR6t+Gi-_sXLBdMgs82w@mail.gmail.com>
References: <CAGSXrvEuLUR2pfMQazxPomeRPYCrShmxiL52tHXxobkJzEkuuA@mail.gmail.com>
	<C5A273CE-DEAF-40E8-A96F-6D9C3A1A151E@me.com>
	<CAGSXrvHKAM82x8g7KHQEKqEa2RdR5_HR6t+Gi-_sXLBdMgs82w@mail.gmail.com>
Message-ID: <CAM_vju=1bpSoSjXpNEyRc78jXdUneusXzYSKjdxQsUEVN6af4g@mail.gmail.com>

Hi,

On Fri, Jun 7, 2013 at 11:36 AM, Daofeng Li <lidaof at gmail.com> wrote:
> Thank you Sarah and Marc for your fast and nice response.
> Apology for didn't include all information.
>
> I have a input file like following:
>
> gene1 18 15 13 13 16 9 20 24
> gene2 15 8 8 7 0 12 18 4
> gene3 10 9 8 12 9 11 12 12
> gene4 4 0 4 3 0 5 0 0
> gene5 0 1 0 0 1 5 1 0
> gene6 3 3 3 3 4 4 4 4
> gene7 0 4 0 2 2 2 0 0
> gene8 4 4 7 3 0 6 6 12
> gene9 11 6 13 10 13 7 12 9
> gene10 6 3 6 3 4 7 6 3

> dat =
> read.table("test",col.names=c("gene","b1","b2","b3","b4","c1","c2","c3","c4"))

Is this what's in the "test" file that your code reads in? We don't
have that file, so can't run your code.

If it is, then the output of

dput(dat)

would be enormously more useful than copy and pasting your data file
into your email.

And yes, the full code is very little like the pair of lines you
originally pasted in.

Sarah

> I am using following R code to compare the difference between the 1st 4
> numbers against 2nd 4 numbers:
>
> library(MASS)
> library(coin)
> suppressPackageStartupMessages(suppressWarnings(library(tcltk)))
> library(qvalue)
> library(plyr)
> dat =
> read.table("test",col.names=c("gene","b1","b2","b3","b4","c1","c2","c3","c4"))
> index=(apply(dat[,-1],1,sum)>0)
> data = dat[index,]
> group=c(1,1,1,1,0,0,0,0)
> n=nrow(data)
> result=NULL
> for (i in 1:n){
>   print(i)
>   y=as.numeric(data[i,-1])
>   if (all((y-mean(y))==0))
>     result=rbind(result,c(0,0,0,1))
>   else {
>     fit=glm.nb(y~group)
>     result=rbind(result,summary(fit)$coef[2,])
>   }
> }
> qval = qvalue(result[,4])
> fdr=0.1
> index=(qval$qvalues<fdr)
> dat.result = data[index,]
> write.table(dat.result,file="test_result",row.names=F,quote=F)
>
> If you use this input file and code, would reproduce the same error:
>
> Loading required package: methods
> Loading required package: survival
> Loading required package: splines
> Loading required package: mvtnorm
> Loading required package: modeltools
> Loading required package: stats4
>
> Attaching package: ?plyr?
>
> The following object is masked from ?package:modeltools?:
>
>     empty
>
> [1] 1
> [1] 2
> [1] 3
> [1] 4
> [1] 5
> [1] 6
> Error in while ((it <- it + 1) < limit && abs(del) > eps) { :
>   missing value where TRUE/FALSE needed
> Calls: glm.nb -> as.vector -> theta.ml
> In addition: Warning messages:
> 1: In theta.ml(Y, mu, sum(w), w, limit = control$maxit, trace =
> control$trace >  :
>   iteration limit reached
> 2: In theta.ml(Y, mu, sum(w), w, limit = control$maxit, trace =
> control$trace >  :
>   iteration limit reached
> Execution halted
>
> So might be the error was in 6th line, not the line I pasted before (5th
> line)? Sorry about that.
>
> Thanks.
>
> Daofeng
>
>
> On Fri, Jun 7, 2013 at 10:15 AM, Marc Schwartz <marc_schwartz at me.com> wrote:
>>
>>
>> On Jun 7, 2013, at 9:44 AM, Daofeng Li <lidaof at gmail.com> wrote:
>>
>> > Dear R Community,
>> >
>> > I have encountered a problem while using the R function glm.nb.
>> > The code that produce the error was following two lines:
>> >
>> > group=c(1,1,1,1,0,0,0,0)
>> > fit=glm.nb(y~group)
>> >
>> > While the y contains 8 sets of number like:
>> > gene275        0       1       0       0       1       5       1       0
>> >
>> > Error message:
>> >
>> > Error in while ((it <- it + 1) < limit && abs(del) > eps) { :
>> >  missing value where TRUE/FALSE needed
>> > Calls: glm.nb -> as.vector -> theta.ml
>> > In addition: There were 50 or more warnings (use warnings() to see the
>> > first 50)
>> > Execution halted
>> >
>> >
>> > Information of my system:
>> >> sessionInfo()
>> > R version 3.0.1 (2013-05-16)
>> > Platform: x86_64-unknown-linux-gnu (64-bit)
>> >
>> > locale:
>> > [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>> > [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>> > [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>> > [7] LC_PAPER=C                 LC_NAME=C
>> > [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> > [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>> >
>> > attached base packages:
>> > [1] stats     graphics  grDevices utils     datasets  methods   base
>> >
>> > Does anyone happen to have some hit on how to solve this?
>> > Appreciate for any response.
>> >
>> > Thanks in advance,
>> >
>> > Daofeng
>>
>>
>> There is something wrong with your actual 'y' or 'group' that is not
>> evident from the above info:
>>
>>
>> group <- c(1, 1, 1, 1, 0, 0, 0, 0)
>> y <- c(0, 1, 0, 0, 1, 5, 1, 0)
>>
>> > require(MASS)
>> Loading required package: MASS
>>
>> > glm.nb(y ~ group)
>>
>> Call:  glm.nb(formula = y ~ group, init.theta = 1.711564307, link = log)
>>
>> Coefficients:
>> (Intercept)        group
>>      0.5596      -1.9459
>>
>> Degrees of Freedom: 7 Total (i.e. Null);  6 Residual
>> Null Deviance:      10.23
>> Residual Deviance: 6.848        AIC: 25.25
>>
>>
>> Check str(y) and str(group)
>>
>> You should also be sure to note in your posts when you are using a
>> function from a non-base package, in this case MASS, which is not indicated
>> in your sessionInfo() above, so something is amiss there as well.
>>
>> Regards,
>>
>> Marc Schwartz
>>
>



-- 
Sarah Goslee
http://www.functionaldiversity.org


From marc_schwartz at me.com  Fri Jun  7 17:48:54 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 07 Jun 2013 10:48:54 -0500
Subject: [R] glm.nb error
In-Reply-To: <CAGSXrvHKAM82x8g7KHQEKqEa2RdR5_HR6t+Gi-_sXLBdMgs82w@mail.gmail.com>
References: <CAGSXrvEuLUR2pfMQazxPomeRPYCrShmxiL52tHXxobkJzEkuuA@mail.gmail.com>
	<C5A273CE-DEAF-40E8-A96F-6D9C3A1A151E@me.com>
	<CAGSXrvHKAM82x8g7KHQEKqEa2RdR5_HR6t+Gi-_sXLBdMgs82w@mail.gmail.com>
Message-ID: <D64D30D9-6ADA-4202-BCBB-FC69FBD0D6EA@me.com>


On Jun 7, 2013, at 10:36 AM, Daofeng Li <lidaof at gmail.com> wrote:

> Thank you Sarah and Marc for your fast and nice response.
> Apology for didn't include all information.
> 
> I have a input file like following:
> 
> gene1	18	15	13	13	16	9	20	24
> gene2	15	8	8	7	0	12	18	4
> gene3	10	9	8	12	9	11	12	12
> gene4	4	0	4	3	0	5	0	0
> gene5	0	1	0	0	1	5	1	0
> gene6	3	3	3	3	4	4	4	4
> gene7	0	4	0	2	2	2	0	0
> gene8	4	4	7	3	0	6	6	12
> gene9	11	6	13	10	13	7	12	9
> gene10	6	3	6	3	4	7	6	3
> 
> I am using following R code to compare the difference between the 1st 4 numbers against 2nd 4 numbers:
> 
> library(MASS)
> library(coin)
> suppressPackageStartupMessages(suppressWarnings(library(tcltk)))
> library(qvalue)
> library(plyr)
> dat = read.table("test",col.names=c("gene","b1","b2","b3","b4","c1","c2","c3","c4"))
> index=(apply(dat[,-1],1,sum)>0)
> data = dat[index,]
> group=c(1,1,1,1,0,0,0,0)
> n=nrow(data)
> result=NULL
> for (i in 1:n){
>   print(i)
>   y=as.numeric(data[i,-1])
>   if (all((y-mean(y))==0))
>     result=rbind(result,c(0,0,0,1))
>   else {
>     fit=glm.nb(y~group)
>     result=rbind(result,summary(fit)$coef[2,])
>   }
> }
> qval = qvalue(result[,4])
> fdr=0.1
> index=(qval$qvalues<fdr)
> dat.result = data[index,]
> write.table(dat.result,file="test_result",row.names=F,quote=F)
> 
> If you use this input file and code, would reproduce the same error:
> 
> Loading required package: methods
> Loading required package: survival
> Loading required package: splines
> Loading required package: mvtnorm
> Loading required package: modeltools
> Loading required package: stats4
> 
> Attaching package: ?plyr?
> 
> The following object is masked from ?package:modeltools?:
> 
>     empty
> 
> [1] 1
> [1] 2
> [1] 3
> [1] 4
> [1] 5
> [1] 6
> Error in while ((it <- it + 1) < limit && abs(del) > eps) { : 
>   missing value where TRUE/FALSE needed
> Calls: glm.nb -> as.vector -> theta.ml
> In addition: Warning messages:
> 1: In theta.ml(Y, mu, sum(w), w, limit = control$maxit, trace = control$trace >  :
>   iteration limit reached
> 2: In theta.ml(Y, mu, sum(w), w, limit = control$maxit, trace = control$trace >  :
>   iteration limit reached
> Execution halted
> 
> So might be the error was in 6th line, not the line I pasted before (5th line)? Sorry about that.
> 
> Thanks.
> 
> Daofeng


Your 'y' at that point in the loop is:
  
> y
[1] 3 3 3 3 4 4 4 4

and 'group' is:

> group
[1] 1 1 1 1 0 0 0 0


> glm.nb(y ~ group)
Error in while ((it <- it + 1) < limit && abs(del) > eps) { : 
  missing value where TRUE/FALSE needed


Think about it...  :-)

Regards,

Marc Schwartz


From wdunlap at tibco.com  Fri Jun  7 17:51:20 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 7 Jun 2013 15:51:20 +0000
Subject: [R] Conditional coloring of area between curves
In-Reply-To: <4780FC16AA89574CA36BB63C15DF63A1014CA54D@mbx02.w2kroot.uni-oldenburg.de>
References: <4780FC16AA89574CA36BB63C15DF63A1014CA4EA@mbx02.w2kroot.uni-oldenburg.de>,
	<51B0BC9B.9020104@gmail.com>
	<4780FC16AA89574CA36BB63C15DF63A1014CA54D@mbx02.w2kroot.uni-oldenburg.de>
Message-ID: <E66794E69CFDE04D9A70842786030B931C2FFC48@PA-MBX01.na.tibco.com>

> that's exactly what I was looking for!

That code has some problems if your time series do not cross at the time
points.  E.g., Duncan's code with some diagnostic plotting is:

  f0 <- function (site1, site2, x = time(site1), check = FALSE) 
  {
      stopifnot(length(x) == length(site1), length(x) == length(site2),  all(diff(x) > 0))
      if (check) {
          oldMfrow <- par(mfrow = c(2, 1))
          on.exit(par(oldMfrow))
          matplot(x, cbind(site1, site2), type = "b")
      }
      smaller <- pmin(site1, site2)
      plot(x, site1, ylim = range(c(site1, site2)), type = "n")
      polygon(c(x, rev(x)), c(smaller, rev(site1)), col = "red")
      polygon(c(x, rev(x)), c(smaller, rev(site2)), col = "blue")
  }
  # See how it messes the crossings in
  f0(c(0, 1, -1, 0), c(1, 0, -2, 1), check=TRUE)

The following is a quick and dirty way of adding all the crossing
points to the original data sets so the plot is right.
  addCrossingPoints <- function (y1, y2, x) 
  {
      stopifnot(length(y1)==length(x), length(y2)==length(x), all(diff(x)>0))
      # isCrossingSegment[i]==TRUE means that y1 and y2 cross between
      #    x[i] and x[i+1]  (strictly, not at x[i] or x[i+1]).
      i <- seq_len(length(y1) - 1)
      isCrossingSegment <- ((y1[i] < y2[i]) & (y1[i+1] > y2[i+1])) |
                           ((y1[i] > y2[i]) & (y1[i+1] < y2[i+1]))
      if (any(isCrossingSegment)) {
          i <- which(isCrossingSegment)
          dx <- x[i+1] - x[i]
          m1 <- (y1[i+1] - y1[i]) / dx
          m2 <- (y2[i+1] - y2[i]) / dx
          newDX <- (y1[i] - y2[i]) / (m2 - m1)
          newY <- y1[i] + newDX * m1 
          o <- order( x <- c(x, x[i] + newDX))
          x <- x[o]
          y1 <- c(y1, newY)[o]
          y2 <- c(y2, newY)[o]
      }
      list(y1=y1, y2=y2, x=x)
  }
  # Combine it with Duncan's code to get a better looking plot
  f1 <- function(site1, site2, x=time(site1), check = FALSE) {
      tmp <- addCrossingPoints(site1, site2, x)
      f0(tmp$y1, tmp$y2, tmp$x, check=check)
  }
  f1(c(0, 1, -1, 0), c(1, 0, -2, 1), check=TRUE)


Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Roland Pape
> Sent: Friday, June 07, 2013 2:51 AM
> To: Duncan Murdoch
> Cc: r-help at r-project.org
> Subject: Re: [R] Conditional coloring of area between curves
> 
> Hi Duncan,
> 
> that's exactly what I was looking for! The series have common times, so that's no
> problem. Thanks a lot!
> 
> Roland
> ________________________________________
> Von: Duncan Murdoch [murdoch.duncan at gmail.com]
> Gesendet: Donnerstag, 6. Juni 2013 18:45
> An: Roland Pape
> Cc: r-help at r-project.org
> Betreff: Re: [R] Conditional coloring of area between curves
> 
> On 06/06/2013 10:41 AM, Roland Pape wrote:
> > Dear list,
> >
> > I have two time series of temperatures from different sites plotted in the same diagram
> and would like to color the area between the curves differently, dependent on whether
> site 1 is cooler than site 2 (colored let's say in blue) or warmer (red). While polygone()
> works fine to color the enclosed area in general, I'm struggling with this conditional
> coloring. Any help is greatly appreciated!
> 
> Suppose the series are named "site1" and "site2", and they have common
> times in a variable "times".  Then the following should do what you want:
> 
> smaller <- pmin(site1, site2)
> plot(x, site1, ylim = range(c(site1, site2)), type="n")
> polygon(c(x, rev(x)), c(smaller, rev(site1)), col="red")
> polygon(c(x, rev(x)), c(smaller, rev(site2)), col="blue")
> 
> If the times for the two series are different it's a little harder;
> first you need to give them common times, and that will depend on how
> you decide to evaluate the values between observations. Probably linear
> interpolation (using approx()) is fine, but it's up to you.
> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cecilia.carmo at ua.pt  Fri Jun  7 18:03:24 2013
From: cecilia.carmo at ua.pt (Cecilia Carmo)
Date: Fri, 7 Jun 2013 16:03:24 +0000
Subject: [R] matched samples, dataframe, panel data
In-Reply-To: <1370619793.18982.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <104083AE5AAA634C993249DFCCE4C20306439641@CIPRESTE.ua.pt>
	<1370618741.16808.YahooMailNeo@web142605.mail.bf1.yahoo.com>,
	<1370618875.52646.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<104083AE5AAA634C993249DFCCE4C20306439664@CIPRESTE.ua.pt>,
	<1370619793.18982.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <104083AE5AAA634C993249DFCCE4C2030643969E@CIPRESTE.ua.pt>

Sorry,

Something is not ok, because when  I do

> nrow(subset(res,res$dummy==0))
[1] 22
> nrow(subset(res,res$dummy==1))
[1] 24

There the number  o observatios in the two subsets is not equal.


Thanks again,

Cec?lia


________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: sexta-feira, 7 de Junho de 2013 16:43
Para: Cecilia Carmo
Cc: R help
Assunto: Re: [R] matched samples, dataframe, panel data

Hi,
Not sure if this is what you wanted.

 res<-do.call(rbind,lapply(lst6,function(x) do.call(rbind,x)))
 row.names(res)<-1:nrow(res)

# this combines the list of lists to a data.frame
res[1:4,]
#  firm year industry dummy dimension
#1    1 2000       20     0      2120
#2    5 2000       20     1      2189
#3    4 2000       20     0      3178
#4    7 2000       20     1      3245


#or
 res<-do.call(rbind,lapply(lst6,function(x) do.call(rbind,x)))
 res$group<-gsub("(.*\\..*)\\..*$","\\1",rownames(res))
 row.names(res)<-1:nrow(res)
 res[1:4,]
#  firm year industry dummy dimension   group
#1    1 2000       20     0      2120 2000.20   #1 group
#2    5 2000       20     1      2189 2000.20   #1
#3    4 2000       20     0      3178 2000.20   #2
#4    7 2000       20     1      3245 2000.20   #2
A.K.


----- Original Message -----
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Cc:
Sent: Friday, June 7, 2013 11:33 AM
Subject: RE: [R] matched samples, dataframe, panel data

Thank you very much.
Just a little thing: how can I put it like a dataframe?

Thanks,

Cec?lia

________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: sexta-feira, 7 de Junho de 2013 16:27
Para: Cecilia Carmo
Assunto: Re: [R] matched samples, dataframe, panel data

Hi,
There could be easier ways...  I am a bit busy now to try other ways.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Cecilia Carmo <cecilia.carmo at ua.pt>
Cc: R help <r-help at r-project.org>
Sent: Friday, June 7, 2013 11:25 AM
Subject: Re: [R] matched samples, dataframe, panel data

Hi,
May be this helps:
lst1<-split(final3,list(final3$year,final3$industry))
lst2<-lst1[lapply(lst1,nrow)>0]
lst3<-lapply(lst2,function(x) lapply(x$dimension,function(y) x[(y< (x$dimension+x$dimension*0.1)) & (y> (x$dimension-x$dimension*0.1)),]))
lst4<-lapply(lst3,function(x) x[lapply(x,nrow)==2])
lst5<-lapply(lst4,function(x)x[!duplicated(x)])
lst6<-lst5[lapply(lst5,length)>0]

names(lst6)
# [1] "2000.20" "2001.20" "2002.20" "2003.20" "2004.20" "2001.30" "2002.30"
#[8] "2001.40" "2002.40" "2003.40" "2004.40"


lst6["2000.20"]
#$`2000.20`
#$`2000.20`[[1]]
#  firm year industry dummy dimension
#1     1 2000       20     0      2120
#21    5 2000       20     1      2189
#
#$`2000.20`[[2]]
#  firm year industry dummy dimension
#16    4 2000       20     0      3178
#31    7 2000       20     1      3245
#
#$`2000.20`[[3]]
#  firm year industry dummy dimension
#11    3 2000       20     1      4532
#6     2 2000       20     0      4890
A.K.





________________________________
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: "r-help at r-project.org" <r-help at r-project.org>

Sent: Friday, June 7, 2013 9:56 AM
Subject: Re: [R] matched samples, dataframe, panel data




Again my problem, better explained.

#I have a data panel of thousands of firms, by year and industry and
#one dummy variable that identifies one kind of firms (1 if the firm have an auditor; 0 if not)
#and another variable the represents the firm dimension (total assets in thousand of euros)
#I need to create two separated samples with the same number os firms where
#one firm in the first have a corresponding firm in the second with the same
#year, industry and dimension (the dimension doesn't need to be exatly the
#same, it could vary in an interval of +/- 10%, for example)

#My reproducible example
firm1<-sort(rep(1:10,5),decreasing=F)
year1<-rep(2000:2004,10)
industry1<-rep(20,50)
dummy1<-c(0,0,1,1,0,0,1,1,0,1,1,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,1,0,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,1,1,1)
dimension1<-c(2120,345,2341,5678,10900,4890,2789,3412,9500,8765,4532,6593,12900,123,2345,3178,2678,6666,647,23789,
2189,4289,8543,637,23456,781,35489,2345,5754,8976,3245,1234,25,1200,2345,2765,389,23456,2367,3892,5438,37824,
23,2897,3456,7690,6022,3678,9431,2890)
data1<-data.frame(firm1,year1,industry1,dummy1,dimension1)
data1
colnames(data1)<-c("firm","year","industry","dummy","dimension")

firm2<-sort(rep(11:15,3),decreasing=F)
year2<-rep(2001:2003,5)
industry2<-rep(30,15)
dummy2<-c(0,0,0,0,0,0,1,1,1,1,1,1,1,0,1)
dimension2<-c(12456,781,32489,2345,5754,8976,3245,2120,345,2341,5678,10900,12900,123,2345)
data2<-data.frame(firm2,year2,industry2,dummy2,dimension2)
data2
colnames(data2)<-c("firm","year","industry","dummy","dimension")
firm3<-sort(rep(16:20,4),decreasing=F)
year3<-rep(2001:2004,5)
industry3<-rep(40,20)
dummy3<-c(0,0,1,0,1,0,1,0,1,1,1,1,1,0,0,0,0,1,0,0)
dimension3<-c(23456,1181,32489,2345,6754,8976,3245,1234,1288,1200,2345,2765,389,23456,2367,3892,6438,24824,
23,2897)
data3<-data.frame(firm3,year3,industry3,dummy3,dimension3)
data3
colnames(data3)<-c("firm","year","industry","dummy","dimension")

final1<-rbind(data1,data2)
final2<-rbind(final1,data3)
final2
final3<-final2[order(final2$year,final2$industry,final2$dimension),]
final3


#So my data is final3 is like this:
   firm year industry dummy dimension
26    6 2000       20     0       781
1     1 2000       20     0      2120
21    5 2000       20     1      2189
36    8 2000       20     1      2765
16    4 2000       20     0      3178
31    7 2000       20     1      3245
11    3 2000       20     1      4532
6     2 2000       20     0      4890
41    9 2000       20     0      5438
46   10 2000       20     0      7690
2     1 2001       20     0       345
37    8 2001       20     1       389
32    7 2001       20     0      1234
17    4 2001       20     0      2678
7     2 2001       20     1      2789
22    5 2001       20     1      4289
47   10 2001       20     0      6022
12    3 2001       20     1      6593
27    6 2001       20     0     35489
42    9 2001       20     1     37824
60   14 2001       30     1      2341
54   12 2001       30     0      2345
57   13 2001       30     1      3245
51   11 2001       30     0     12456
63   15 2001       30     1     12900
78   19 2001       40     1       389
74   18 2001       40     1      1288
82   20 2001       40     0      6438
70   17 2001       40     1      6754
66   16 2001       40     0     23456
43    9 2002       20     0        23
33    7 2002       20     1        25
3     1 2002       20     1      2341
28    6 2002       20     0      2345
8     2 2002       20     1      3412
48   10 2002       20     1      3678
18    4 2002       20     0      6666
23    5 2002       20     0      8543
13    3 2002       20     0     12900
38    8 2002       20     1     23456
64   15 2002       30     0       123
52   11 2002       30     0       781
58   13 2002       30     1      2120
61   14 2002       30     1      5678
55   12 2002       30     0      5754
67   16 2002       40     0      1181
75   18 2002       40     1      1200
71   17 2002       40     0      8976
79   19 2002       40     0     23456
83   20 2002       40     1     24824
14    3 2003       20     0       123
24    5 2003       20     0       637
19    4 2003       20     1       647
34    7 2003       20     0      1200
39    8 2003       20     1      2367
44    9 2003       20     0      2897
4     1 2003       20     1      5678
29    6 2003       20     0      5754
49   10 2003       20     1      9431
9     2 2003       20     0      9500
59   13 2003       30     1       345
65   15 2003       30     1      2345
56   12 2003       30     0      8976
62   14 2003       30     1     10900
53   11 2003       30     0     32489
84   20 2003       40     0        23
76   18 2003       40     1      2345
80   19 2003       40     0      2367
72   17 2003       40     1      3245
68   16 2003       40     1     32489
15    3 2004       20     0      2345
35    7 2004       20     1      2345
50   10 2004       20     1      2890
45    9 2004       20     0      3456
40    8 2004       20     0      3892
10    2 2004       20     1      8765
30    6 2004       20     0      8976
5     1 2004       20     0     10900
25    5 2004       20     0     23456
20    4 2004       20     1     23789
73   17 2004       40     0      1234
69   16 2004       40     0      2345
77   18 2004       40     1      2765
85   20 2004       40     0      2897
81   19 2004       40     0      3892

I want to keep couples of firms one with dummy=1 and other with dummy=0 that matchs in industry, firm and dimension.

But dimension doesn't need to be exactly the same, it is why I refer an interval of + or - 10%.

For example firm 1 matchs with firm 5, because they have the same year, industry, dimension (10% x 2120 = 212 and 2189-2120<212)
and firm 1 is dummy=0 and firm 5 is dummy=1.

So I want to delete firm 6 because it doesn't macth with any firm, and keep firm 1 and 5.

     firm year industry dummy dimension
26    6 2000       20     0       781
1     1 2000       20     0      2120
21    5 2000       20     1      2189

Next,

Now I can match firm 4 with firm 7 and delete firm 8.
36    8 2000       20     1      2765
16    4 2000       20     0      3178
31    7 2000       20     1      3245

And so on...

At the end I want to keep only pairs of firms, matched by year, industry and dimension.

If I separate firms with dummy=1 from firms with dummy=0 in two separated dataframes, I have two matched samples
with the same number of observations. That's what I want.

Thank you,
Cec?lia Carmo
Universidade de Aveiro - Portugal

From sarah.goslee at gmail.com  Fri Jun  7 18:25:51 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 7 Jun 2013 12:25:51 -0400
Subject: [R] glm.nb error
In-Reply-To: <CAGSXrvFmBobz+j2D92RFN2h_xe6Mzexeexn2-CCBjMZOR-Hgxg@mail.gmail.com>
References: <CAGSXrvEuLUR2pfMQazxPomeRPYCrShmxiL52tHXxobkJzEkuuA@mail.gmail.com>
	<C5A273CE-DEAF-40E8-A96F-6D9C3A1A151E@me.com>
	<CAGSXrvHKAM82x8g7KHQEKqEa2RdR5_HR6t+Gi-_sXLBdMgs82w@mail.gmail.com>
	<CAM_vju=1bpSoSjXpNEyRc78jXdUneusXzYSKjdxQsUEVN6af4g@mail.gmail.com>
	<CAGSXrvFmBobz+j2D92RFN2h_xe6Mzexeexn2-CCBjMZOR-Hgxg@mail.gmail.com>
Message-ID: <CAM_vjukp00x+0KQvyxfFCwtgBg9=rN7HjcCz8pjiD5PTdZreGw@mail.gmail.com>

As Marc already pointed out, take a close look at this part of your loop:

R> i <- 6
R>
R> y <- as.numeric(data[i,-1])
R> y
[1] 3 3 3 3 4 4 4 4
R> group
[1] 1 1 1 1 0 0 0 0
R> fit <- glm.nb(y~group)
Error in while ((it <- it + 1) < limit && abs(del) > eps) { :
  missing value where TRUE/FALSE needed

What do you expect to happen there?

In general, it's a better practice to pre-specify the size of result
(eg matrix(NA, nrow=n, ncol=4) ) and fill it as you go, rather than
using rbind() within a loop. Much more memory-efficient.

Sarah

On Fri, Jun 7, 2013 at 11:58 AM, Daofeng Li <lidaof at gmail.com> wrote:
> Sorry Sarah.
>
>> dput(dat)
> structure(list(gene = structure(c(1L, 3L, 4L, 5L, 6L, 7L, 8L,
> 9L, 10L, 2L), .Label = c("gene1", "gene10", "gene2", "gene3",
> "gene4", "gene5", "gene6", "gene7", "gene8", "gene9"), class = "factor"),
>     b1 = c(18L, 15L, 10L, 4L, 0L, 3L, 0L, 4L, 11L, 6L), b2 = c(15L,
>     8L, 9L, 0L, 1L, 3L, 4L, 4L, 6L, 3L), b3 = c(13L, 8L, 8L,
>     4L, 0L, 3L, 0L, 7L, 13L, 6L), b4 = c(13L, 7L, 12L, 3L, 0L,
>     3L, 2L, 3L, 10L, 3L), c1 = c(16L, 0L, 9L, 0L, 1L, 4L, 2L,
>     0L, 13L, 4L), c2 = c(9L, 12L, 11L, 5L, 5L, 4L, 2L, 6L, 7L,
>     7L), c3 = c(20L, 18L, 12L, 0L, 1L, 4L, 0L, 6L, 12L, 6L),
>     c4 = c(24L, 4L, 12L, 0L, 0L, 4L, 0L, 12L, 9L, 3L)), .Names = c("gene",
> "b1", "b2", "b3", "b4", "c1", "c2", "c3", "c4"), class = "data.frame",
> row.names = c(NA,
> -10L))
>
> above was the dput(dat). Thanks.
>
> Daofeng
>
>
> On Fri, Jun 7, 2013 at 10:47 AM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>>
>> Hi,
>>
>> On Fri, Jun 7, 2013 at 11:36 AM, Daofeng Li <lidaof at gmail.com> wrote:
>> > Thank you Sarah and Marc for your fast and nice response.
>> > Apology for didn't include all information.
>> >
>> > I have a input file like following:
>> >
>> > gene1 18 15 13 13 16 9 20 24
>> > gene2 15 8 8 7 0 12 18 4
>> > gene3 10 9 8 12 9 11 12 12
>> > gene4 4 0 4 3 0 5 0 0
>> > gene5 0 1 0 0 1 5 1 0
>> > gene6 3 3 3 3 4 4 4 4
>> > gene7 0 4 0 2 2 2 0 0
>> > gene8 4 4 7 3 0 6 6 12
>> > gene9 11 6 13 10 13 7 12 9
>> > gene10 6 3 6 3 4 7 6 3
>>
>> > dat =
>> >
>> > read.table("test",col.names=c("gene","b1","b2","b3","b4","c1","c2","c3","c4"))
>>
>> Is this what's in the "test" file that your code reads in? We don't
>> have that file, so can't run your code.
>>
>> If it is, then the output of
>>
>> dput(dat)
>>
>> would be enormously more useful than copy and pasting your data file
>> into your email.
>>
>> And yes, the full code is very little like the pair of lines you
>> originally pasted in.
>>
>> Sarah
>>
>> > I am using following R code to compare the difference between the 1st 4
>> > numbers against 2nd 4 numbers:
>> >
>> > library(MASS)
>> > library(coin)
>> > suppressPackageStartupMessages(suppressWarnings(library(tcltk)))
>> > library(qvalue)
>> > library(plyr)
>> > dat =
>> >
>> > read.table("test",col.names=c("gene","b1","b2","b3","b4","c1","c2","c3","c4"))
>> > index=(apply(dat[,-1],1,sum)>0)
>> > data = dat[index,]
>> > group=c(1,1,1,1,0,0,0,0)
>> > n=nrow(data)
>> > result=NULL
>> > for (i in 1:n){
>> >   print(i)
>> >   y=as.numeric(data[i,-1])
>> >   if (all((y-mean(y))==0))
>> >     result=rbind(result,c(0,0,0,1))
>> >   else {
>> >     fit=glm.nb(y~group)
>> >     result=rbind(result,summary(fit)$coef[2,])
>> >   }
>> > }
>> > qval = qvalue(result[,4])
>> > fdr=0.1
>> > index=(qval$qvalues<fdr)
>> > dat.result = data[index,]
>> > write.table(dat.result,file="test_result",row.names=F,quote=F)
>> >
>> > If you use this input file and code, would reproduce the same error:
>> >
>> > Loading required package: methods
>> > Loading required package: survival
>> > Loading required package: splines
>> > Loading required package: mvtnorm
>> > Loading required package: modeltools
>> > Loading required package: stats4
>> >
>> > Attaching package: ?plyr?
>> >
>> > The following object is masked from ?package:modeltools?:
>> >
>> >     empty
>> >
>> > [1] 1
>> > [1] 2
>> > [1] 3
>> > [1] 4
>> > [1] 5
>> > [1] 6
>> > Error in while ((it <- it + 1) < limit && abs(del) > eps) { :
>> >   missing value where TRUE/FALSE needed
>> > Calls: glm.nb -> as.vector -> theta.ml
>> > In addition: Warning messages:
>> > 1: In theta.ml(Y, mu, sum(w), w, limit = control$maxit, trace =
>> > control$trace >  :
>> >   iteration limit reached
>> > 2: In theta.ml(Y, mu, sum(w), w, limit = control$maxit, trace =
>> > control$trace >  :
>> >   iteration limit reached
>> > Execution halted
>> >
>> > So might be the error was in 6th line, not the line I pasted before (5th
>> > line)? Sorry about that.
>> >
>> > Thanks.
>> >
>> > Daofeng
>> >
>> >
>> > On Fri, Jun 7, 2013 at 10:15 AM, Marc Schwartz <marc_schwartz at me.com>
>> > wrote:
>> >>
>> >>
>> >> On Jun 7, 2013, at 9:44 AM, Daofeng Li <lidaof at gmail.com> wrote:
>> >>
>> >> > Dear R Community,
>> >> >
>> >> > I have encountered a problem while using the R function glm.nb.
>> >> > The code that produce the error was following two lines:
>> >> >
>> >> > group=c(1,1,1,1,0,0,0,0)
>> >> > fit=glm.nb(y~group)
>> >> >
>> >> > While the y contains 8 sets of number like:
>> >> > gene275        0       1       0       0       1       5       1
>> >> > 0
>> >> >
>> >> > Error message:
>> >> >
>> >> > Error in while ((it <- it + 1) < limit && abs(del) > eps) { :
>> >> >  missing value where TRUE/FALSE needed
>> >> > Calls: glm.nb -> as.vector -> theta.ml
>> >> > In addition: There were 50 or more warnings (use warnings() to see
>> >> > the
>> >> > first 50)
>> >> > Execution halted
>> >> >
>> >> >
>> >> > Information of my system:
>> >> >> sessionInfo()
>> >> > R version 3.0.1 (2013-05-16)
>> >> > Platform: x86_64-unknown-linux-gnu (64-bit)
>> >> >
>> >> > locale:
>> >> > [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>> >> > [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>> >> > [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>> >> > [7] LC_PAPER=C                 LC_NAME=C
>> >> > [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> >> > [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>> >> >
>> >> > attached base packages:
>> >> > [1] stats     graphics  grDevices utils     datasets  methods   base
>> >> >
>> >> > Does anyone happen to have some hit on how to solve this?
>> >> > Appreciate for any response.
>> >> >
>> >> > Thanks in advance,
>> >> >
>> >> > Daofeng
>> >>
>> >>
>> >> There is something wrong with your actual 'y' or 'group' that is not
>> >> evident from the above info:
>> >>
>> >>
>> >> group <- c(1, 1, 1, 1, 0, 0, 0, 0)
>> >> y <- c(0, 1, 0, 0, 1, 5, 1, 0)
>> >>
>> >> > require(MASS)
>> >> Loading required package: MASS
>> >>
>> >> > glm.nb(y ~ group)
>> >>
>> >> Call:  glm.nb(formula = y ~ group, init.theta = 1.711564307, link =
>> >> log)
>> >>
>> >> Coefficients:
>> >> (Intercept)        group
>> >>      0.5596      -1.9459
>> >>
>> >> Degrees of Freedom: 7 Total (i.e. Null);  6 Residual
>> >> Null Deviance:      10.23
>> >> Residual Deviance: 6.848        AIC: 25.25
>> >>
>> >>
>> >> Check str(y) and str(group)
>> >>
>> >> You should also be sure to note in your posts when you are using a
>> >> function from a non-base package, in this case MASS, which is not
>> >> indicated
>> >> in your sessionInfo() above, so something is amiss there as well.
>> >>
>> >> Regards,
>> >>
>> >> Marc Schwartz
>> >>
>> >
>>
>>
>>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From smartpink111 at yahoo.com  Fri Jun  7 18:30:36 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 7 Jun 2013 09:30:36 -0700 (PDT)
Subject: [R] matched samples, dataframe, panel data
In-Reply-To: <104083AE5AAA634C993249DFCCE4C2030643969E@CIPRESTE.ua.pt>
References: <104083AE5AAA634C993249DFCCE4C20306439641@CIPRESTE.ua.pt>
	<1370618741.16808.YahooMailNeo@web142605.mail.bf1.yahoo.com>,
	<1370618875.52646.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<104083AE5AAA634C993249DFCCE4C20306439664@CIPRESTE.ua.pt>,
	<1370619793.18982.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<104083AE5AAA634C993249DFCCE4C2030643969E@CIPRESTE.ua.pt>
Message-ID: <1370622636.62630.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Sorry, it included a case with both values for dummy were 1.

lst7<-lapply(lst6,function(x) {lst<-lapply(x,function(y) y[sum(y$dummy)==1,]);lst[lapply(lst,nrow)>0]})

?res<-do.call(rbind,lapply(lst7,function(x) do.call(rbind,x)))
?row.names(res)<-1:nrow(res)
nrow(subset(res,dummy==0))
#[1] 22
?nrow(subset(res,dummy==1))
#[1] 22
A.K.



----- Original Message -----
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Cc: R help <r-help at r-project.org>
Sent: Friday, June 7, 2013 12:03 PM
Subject: RE: [R] matched samples, dataframe, panel data

Sorry,

Something is not ok, because when? I do

> nrow(subset(res,res$dummy==0))
[1] 22
> nrow(subset(res,res$dummy==1))
[1] 24

There the number? o observatios in the two subsets is not equal.


Thanks again,

Cec?lia


________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: sexta-feira, 7 de Junho de 2013 16:43
Para: Cecilia Carmo
Cc: R help
Assunto: Re: [R] matched samples, dataframe, panel data

Hi,
Not sure if this is what you wanted.

res<-do.call(rbind,lapply(lst6,function(x) do.call(rbind,x)))
row.names(res)<-1:nrow(res)

# this combines the list of lists to a data.frame
res[1:4,]
#? firm year industry dummy dimension
#1? ? 1 2000? ? ?  20? ?  0? ? ? 2120
#2? ? 5 2000? ? ?  20? ?  1? ? ? 2189
#3? ? 4 2000? ? ?  20? ?  0? ? ? 3178
#4? ? 7 2000? ? ?  20? ?  1? ? ? 3245


#or
res<-do.call(rbind,lapply(lst6,function(x) do.call(rbind,x)))
res$group<-gsub("(.*\\..*)\\..*$","\\1",rownames(res))
row.names(res)<-1:nrow(res)
res[1:4,]
#? firm year industry dummy dimension?  group
#1? ? 1 2000? ? ?  20? ?  0? ? ? 2120 2000.20?  #1 group
#2? ? 5 2000? ? ?  20? ?  1? ? ? 2189 2000.20?  #1
#3? ? 4 2000? ? ?  20? ?  0? ? ? 3178 2000.20?  #2
#4? ? 7 2000? ? ?  20? ?  1? ? ? 3245 2000.20?  #2
A.K.


----- Original Message -----
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Cc:
Sent: Friday, June 7, 2013 11:33 AM
Subject: RE: [R] matched samples, dataframe, panel data

Thank you very much.
Just a little thing: how can I put it like a dataframe?

Thanks,

Cec?lia

________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: sexta-feira, 7 de Junho de 2013 16:27
Para: Cecilia Carmo
Assunto: Re: [R] matched samples, dataframe, panel data

Hi,
There could be easier ways...? I am a bit busy now to try other ways.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Cecilia Carmo <cecilia.carmo at ua.pt>
Cc: R help <r-help at r-project.org>
Sent: Friday, June 7, 2013 11:25 AM
Subject: Re: [R] matched samples, dataframe, panel data

Hi,
May be this helps:
lst1<-split(final3,list(final3$year,final3$industry))
lst2<-lst1[lapply(lst1,nrow)>0]
lst3<-lapply(lst2,function(x) lapply(x$dimension,function(y) x[(y< (x$dimension+x$dimension*0.1)) & (y> (x$dimension-x$dimension*0.1)),]))
lst4<-lapply(lst3,function(x) x[lapply(x,nrow)==2])
lst5<-lapply(lst4,function(x)x[!duplicated(x)])
lst6<-lst5[lapply(lst5,length)>0]

names(lst6)
# [1] "2000.20" "2001.20" "2002.20" "2003.20" "2004.20" "2001.30" "2002.30"
#[8] "2001.40" "2002.40" "2003.40" "2004.40"


lst6["2000.20"]
#$`2000.20`
#$`2000.20`[[1]]
#? firm year industry dummy dimension
#1? ?  1 2000? ? ?  20? ?  0? ? ? 2120
#21? ? 5 2000? ? ?  20? ?  1? ? ? 2189
#
#$`2000.20`[[2]]
#? firm year industry dummy dimension
#16? ? 4 2000? ? ?  20? ?  0? ? ? 3178
#31? ? 7 2000? ? ?  20? ?  1? ? ? 3245
#
#$`2000.20`[[3]]
#? firm year industry dummy dimension
#11? ? 3 2000? ? ?  20? ?  1? ? ? 4532
#6? ?  2 2000? ? ?  20? ?  0? ? ? 4890
A.K.





________________________________
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: "smartpink111 at yahoo.com" <smartpink111 at yahoo.com>
Sent: Friday, June 7, 2013 9:56 AM
Subject: Re: [R] matched samples, dataframe, panel data




Again my problem, better explained.

#I have a data panel of thousands of firms, by year and industry and
#one dummy variable that identifies one kind of firms (1 if the firm have an auditor; 0 if not)
#and another variable the represents the firm dimension (total assets in thousand of euros)
#I need to create two separated samples with the same number os firms where
#one firm in the first have a corresponding firm in the second with the same
#year, industry and dimension (the dimension doesn't need to be exatly the
#same, it could vary in an interval of +/- 10%, for example)

#My reproducible example
firm1<-sort(rep(1:10,5),decreasing=F)
year1<-rep(2000:2004,10)
industry1<-rep(20,50)
dummy1<-c(0,0,1,1,0,0,1,1,0,1,1,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,1,0,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,1,1,1)
dimension1<-c(2120,345,2341,5678,10900,4890,2789,3412,9500,8765,4532,6593,12900,123,2345,3178,2678,6666,647,23789,
2189,4289,8543,637,23456,781,35489,2345,5754,8976,3245,1234,25,1200,2345,2765,389,23456,2367,3892,5438,37824,
23,2897,3456,7690,6022,3678,9431,2890)
data1<-data.frame(firm1,year1,industry1,dummy1,dimension1)
data1
colnames(data1)<-c("firm","year","industry","dummy","dimension")

firm2<-sort(rep(11:15,3),decreasing=F)
year2<-rep(2001:2003,5)
industry2<-rep(30,15)
dummy2<-c(0,0,0,0,0,0,1,1,1,1,1,1,1,0,1)
dimension2<-c(12456,781,32489,2345,5754,8976,3245,2120,345,2341,5678,10900,12900,123,2345)
data2<-data.frame(firm2,year2,industry2,dummy2,dimension2)
data2
colnames(data2)<-c("firm","year","industry","dummy","dimension")
firm3<-sort(rep(16:20,4),decreasing=F)
year3<-rep(2001:2004,5)
industry3<-rep(40,20)
dummy3<-c(0,0,1,0,1,0,1,0,1,1,1,1,1,0,0,0,0,1,0,0)
dimension3<-c(23456,1181,32489,2345,6754,8976,3245,1234,1288,1200,2345,2765,389,23456,2367,3892,6438,24824,
23,2897)
data3<-data.frame(firm3,year3,industry3,dummy3,dimension3)
data3
colnames(data3)<-c("firm","year","industry","dummy","dimension")

final1<-rbind(data1,data2)
final2<-rbind(final1,data3)
final2
final3<-final2[order(final2$year,final2$industry,final2$dimension),]
final3


#So my data is final3 is like this:
?  firm year industry dummy dimension
26? ? 6 2000? ? ?  20? ?  0? ? ?  781
1? ?  1 2000? ? ?  20? ?  0? ? ? 2120
21? ? 5 2000? ? ?  20? ?  1? ? ? 2189
36? ? 8 2000? ? ?  20? ?  1? ? ? 2765
16? ? 4 2000? ? ?  20? ?  0? ? ? 3178
31? ? 7 2000? ? ?  20? ?  1? ? ? 3245
11? ? 3 2000? ? ?  20? ?  1? ? ? 4532
6? ?  2 2000? ? ?  20? ?  0? ? ? 4890
41? ? 9 2000? ? ?  20? ?  0? ? ? 5438
46?  10 2000? ? ?  20? ?  0? ? ? 7690
2? ?  1 2001? ? ?  20? ?  0? ? ?  345
37? ? 8 2001? ? ?  20? ?  1? ? ?  389
32? ? 7 2001? ? ?  20? ?  0? ? ? 1234
17? ? 4 2001? ? ?  20? ?  0? ? ? 2678
7? ?  2 2001? ? ?  20? ?  1? ? ? 2789
22? ? 5 2001? ? ?  20? ?  1? ? ? 4289
47?  10 2001? ? ?  20? ?  0? ? ? 6022
12? ? 3 2001? ? ?  20? ?  1? ? ? 6593
27? ? 6 2001? ? ?  20? ?  0? ?  35489
42? ? 9 2001? ? ?  20? ?  1? ?  37824
60?  14 2001? ? ?  30? ?  1? ? ? 2341
54?  12 2001? ? ?  30? ?  0? ? ? 2345
57?  13 2001? ? ?  30? ?  1? ? ? 3245
51?  11 2001? ? ?  30? ?  0? ?  12456
63?  15 2001? ? ?  30? ?  1? ?  12900
78?  19 2001? ? ?  40? ?  1? ? ?  389
74?  18 2001? ? ?  40? ?  1? ? ? 1288
82?  20 2001? ? ?  40? ?  0? ? ? 6438
70?  17 2001? ? ?  40? ?  1? ? ? 6754
66?  16 2001? ? ?  40? ?  0? ?  23456
43? ? 9 2002? ? ?  20? ?  0? ? ? ? 23
33? ? 7 2002? ? ?  20? ?  1? ? ? ? 25
3? ?  1 2002? ? ?  20? ?  1? ? ? 2341
28? ? 6 2002? ? ?  20? ?  0? ? ? 2345
8? ?  2 2002? ? ?  20? ?  1? ? ? 3412
48?  10 2002? ? ?  20? ?  1? ? ? 3678
18? ? 4 2002? ? ?  20? ?  0? ? ? 6666
23? ? 5 2002? ? ?  20? ?  0? ? ? 8543
13? ? 3 2002? ? ?  20? ?  0? ?  12900
38? ? 8 2002? ? ?  20? ?  1? ?  23456
64?  15 2002? ? ?  30? ?  0? ? ?  123
52?  11 2002? ? ?  30? ?  0? ? ?  781
58?  13 2002? ? ?  30? ?  1? ? ? 2120
61?  14 2002? ? ?  30? ?  1? ? ? 5678
55?  12 2002? ? ?  30? ?  0? ? ? 5754
67?  16 2002? ? ?  40? ?  0? ? ? 1181
75?  18 2002? ? ?  40? ?  1? ? ? 1200
71?  17 2002? ? ?  40? ?  0? ? ? 8976
79?  19 2002? ? ?  40? ?  0? ?  23456
83?  20 2002? ? ?  40? ?  1? ?  24824
14? ? 3 2003? ? ?  20? ?  0? ? ?  123
24? ? 5 2003? ? ?  20? ?  0? ? ?  637
19? ? 4 2003? ? ?  20? ?  1? ? ?  647
34? ? 7 2003? ? ?  20? ?  0? ? ? 1200
39? ? 8 2003? ? ?  20? ?  1? ? ? 2367
44? ? 9 2003? ? ?  20? ?  0? ? ? 2897
4? ?  1 2003? ? ?  20? ?  1? ? ? 5678
29? ? 6 2003? ? ?  20? ?  0? ? ? 5754
49?  10 2003? ? ?  20? ?  1? ? ? 9431
9? ?  2 2003? ? ?  20? ?  0? ? ? 9500
59?  13 2003? ? ?  30? ?  1? ? ?  345
65?  15 2003? ? ?  30? ?  1? ? ? 2345
56?  12 2003? ? ?  30? ?  0? ? ? 8976
62?  14 2003? ? ?  30? ?  1? ?  10900
53?  11 2003? ? ?  30? ?  0? ?  32489
84?  20 2003? ? ?  40? ?  0? ? ? ? 23
76?  18 2003? ? ?  40? ?  1? ? ? 2345
80?  19 2003? ? ?  40? ?  0? ? ? 2367
72?  17 2003? ? ?  40? ?  1? ? ? 3245
68?  16 2003? ? ?  40? ?  1? ?  32489
15? ? 3 2004? ? ?  20? ?  0? ? ? 2345
35? ? 7 2004? ? ?  20? ?  1? ? ? 2345
50?  10 2004? ? ?  20? ?  1? ? ? 2890
45? ? 9 2004? ? ?  20? ?  0? ? ? 3456
40? ? 8 2004? ? ?  20? ?  0? ? ? 3892
10? ? 2 2004? ? ?  20? ?  1? ? ? 8765
30? ? 6 2004? ? ?  20? ?  0? ? ? 8976
5? ?  1 2004? ? ?  20? ?  0? ?  10900
25? ? 5 2004? ? ?  20? ?  0? ?  23456
20? ? 4 2004? ? ?  20? ?  1? ?  23789
73?  17 2004? ? ?  40? ?  0? ? ? 1234
69?  16 2004? ? ?  40? ?  0? ? ? 2345
77?  18 2004? ? ?  40? ?  1? ? ? 2765
85?  20 2004? ? ?  40? ?  0? ? ? 2897
81?  19 2004? ? ?  40? ?  0? ? ? 3892

I want to keep couples of firms one with dummy=1 and other with dummy=0 that matchs in industry, firm and dimension.

But dimension doesn't need to be exactly the same, it is why I refer an interval of + or - 10%.

For example firm 1 matchs with firm 5, because they have the same year, industry, dimension (10% x 2120 = 212 and 2189-2120<212)
and firm 1 is dummy=0 and firm 5 is dummy=1.

So I want to delete firm 6 because it doesn't macth with any firm, and keep firm 1 and 5.

? ?  firm year industry dummy dimension
26? ? 6 2000? ? ?  20? ?  0? ? ?  781
1? ?  1 2000? ? ?  20? ?  0? ? ? 2120
21? ? 5 2000? ? ?  20? ?  1? ? ? 2189

Next,

Now I can match firm 4 with firm 7 and delete firm 8.
36? ? 8 2000? ? ?  20? ?  1? ? ? 2765
16? ? 4 2000? ? ?  20? ?  0? ? ? 3178
31? ? 7 2000? ? ?  20? ?  1? ? ? 3245

And so on...

At the end I want to keep only pairs of firms, matched by year, industry and dimension.

If I separate firms with dummy=1 from firms with dummy=0 in two separated dataframes, I have two matched samples
with the same number of observations. That's what I want.

Thank you,
Cec?lia Carmo
Universidade de Aveiro - Portugal


From David.Costantini at glasgow.ac.uk  Fri Jun  7 19:16:36 2013
From: David.Costantini at glasgow.ac.uk (David Costantini)
Date: Fri, 7 Jun 2013 18:16:36 +0100
Subject: [R] coxme p-values
References: <mailman.29.1370512808.13234.r-help@r-project.org>
Message-ID: <CD5460DE8502AF4C9DE3C5C037E7051E0462DD52@exchange-be8.centre.ad.gla.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/5634aec7/attachment.pl>

From kydaviddoyle at gmail.com  Fri Jun  7 19:47:13 2013
From: kydaviddoyle at gmail.com (David Doyle)
Date: Fri, 7 Jun 2013 12:47:13 -0500
Subject: [R] Trying to install NADA in R 3.0.0
Message-ID: <CACftpvqOat_jqDZZYmrTESKzamATn6PcY-UhtaiJ91fiWAoEVA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/5507d11c/attachment.pl>

From mikeumo at gmail.com  Fri Jun  7 17:24:43 2013
From: mikeumo at gmail.com (Mikhail Umorin)
Date: Fri, 07 Jun 2013 10:24:43 -0500
Subject: [R] Distance-based non-parametric ANOVA
In-Reply-To: <E0807BF04F0D0C419BF2B39803E98582010E3BB3BCFA@AGEPXCH002C.uk.age.local>
References: <2093686.8QetdgVmrY@localhost>
	<E0807BF04F0D0C419BF2B39803E98582010E3BB3BCFA@AGEPXCH002C.uk.age.local>
Message-ID: <1460987.0dZ2JVbckk@localhost>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/de82e52b/attachment.pl>

From mikeumo at gmail.com  Fri Jun  7 17:28:28 2013
From: mikeumo at gmail.com (Mikhail Umorin)
Date: Fri, 07 Jun 2013 10:28:28 -0500
Subject: [R] Distance-based non-parametric ANOVA
In-Reply-To: <CAAcyNCzPdP-gLyvN5qrqjP+htvtPL_gr0mexuvjrG0LhHHnjAg@mail.gmail.com>
References: <2093686.8QetdgVmrY@localhost>
	<CAAcyNCzPdP-gLyvN5qrqjP+htvtPL_gr0mexuvjrG0LhHHnjAg@mail.gmail.com>
Message-ID: <5196170.q5OpiDbxA5@localhost>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/5eb1a340/attachment.pl>

From lidaof at gmail.com  Fri Jun  7 17:36:53 2013
From: lidaof at gmail.com (Daofeng Li)
Date: Fri, 7 Jun 2013 10:36:53 -0500
Subject: [R] glm.nb error
In-Reply-To: <C5A273CE-DEAF-40E8-A96F-6D9C3A1A151E@me.com>
References: <CAGSXrvEuLUR2pfMQazxPomeRPYCrShmxiL52tHXxobkJzEkuuA@mail.gmail.com>
	<C5A273CE-DEAF-40E8-A96F-6D9C3A1A151E@me.com>
Message-ID: <CAGSXrvHKAM82x8g7KHQEKqEa2RdR5_HR6t+Gi-_sXLBdMgs82w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/aa8a28cd/attachment.pl>

From lidaof at gmail.com  Fri Jun  7 17:58:16 2013
From: lidaof at gmail.com (Daofeng Li)
Date: Fri, 7 Jun 2013 10:58:16 -0500
Subject: [R] glm.nb error
In-Reply-To: <CAM_vju=1bpSoSjXpNEyRc78jXdUneusXzYSKjdxQsUEVN6af4g@mail.gmail.com>
References: <CAGSXrvEuLUR2pfMQazxPomeRPYCrShmxiL52tHXxobkJzEkuuA@mail.gmail.com>
	<C5A273CE-DEAF-40E8-A96F-6D9C3A1A151E@me.com>
	<CAGSXrvHKAM82x8g7KHQEKqEa2RdR5_HR6t+Gi-_sXLBdMgs82w@mail.gmail.com>
	<CAM_vju=1bpSoSjXpNEyRc78jXdUneusXzYSKjdxQsUEVN6af4g@mail.gmail.com>
Message-ID: <CAGSXrvFmBobz+j2D92RFN2h_xe6Mzexeexn2-CCBjMZOR-Hgxg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/751a4943/attachment.pl>

From lidaof at gmail.com  Fri Jun  7 18:02:16 2013
From: lidaof at gmail.com (Daofeng Li)
Date: Fri, 7 Jun 2013 11:02:16 -0500
Subject: [R] glm.nb error
In-Reply-To: <D64D30D9-6ADA-4202-BCBB-FC69FBD0D6EA@me.com>
References: <CAGSXrvEuLUR2pfMQazxPomeRPYCrShmxiL52tHXxobkJzEkuuA@mail.gmail.com>
	<C5A273CE-DEAF-40E8-A96F-6D9C3A1A151E@me.com>
	<CAGSXrvHKAM82x8g7KHQEKqEa2RdR5_HR6t+Gi-_sXLBdMgs82w@mail.gmail.com>
	<D64D30D9-6ADA-4202-BCBB-FC69FBD0D6EA@me.com>
Message-ID: <CAGSXrvGyPGdoXXT88ywMx4GYekOAz4Fyx7FY853LAMMmK4tb1w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/4fe8ee16/attachment.pl>

From rbeckett81 at yahoo.com  Fri Jun  7 18:51:20 2013
From: rbeckett81 at yahoo.com (Richard Beckett)
Date: Fri, 7 Jun 2013 09:51:20 -0700 (PDT)
Subject: [R] Clogit R and Stata
In-Reply-To: <3ABD3D67-B7E7-4E7E-9128-413F1D0967B4@gmail.com>
References: <1370612073.93488.YahooMailNeo@web163803.mail.gq1.yahoo.com>
	<3ABD3D67-B7E7-4E7E-9128-413F1D0967B4@gmail.com>
Message-ID: <1370623880.21636.YahooMailNeo@web163804.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/b76368fe/attachment.pl>

From lidaof at gmail.com  Fri Jun  7 19:05:53 2013
From: lidaof at gmail.com (Daofeng Li)
Date: Fri, 7 Jun 2013 12:05:53 -0500
Subject: [R] glm.nb error
In-Reply-To: <CAM_vjukp00x+0KQvyxfFCwtgBg9=rN7HjcCz8pjiD5PTdZreGw@mail.gmail.com>
References: <CAGSXrvEuLUR2pfMQazxPomeRPYCrShmxiL52tHXxobkJzEkuuA@mail.gmail.com>
	<C5A273CE-DEAF-40E8-A96F-6D9C3A1A151E@me.com>
	<CAGSXrvHKAM82x8g7KHQEKqEa2RdR5_HR6t+Gi-_sXLBdMgs82w@mail.gmail.com>
	<CAM_vju=1bpSoSjXpNEyRc78jXdUneusXzYSKjdxQsUEVN6af4g@mail.gmail.com>
	<CAGSXrvFmBobz+j2D92RFN2h_xe6Mzexeexn2-CCBjMZOR-Hgxg@mail.gmail.com>
	<CAM_vjukp00x+0KQvyxfFCwtgBg9=rN7HjcCz8pjiD5PTdZreGw@mail.gmail.com>
Message-ID: <CAGSXrvFaaiCT+UQ2vnRYzPHOoYLvKiWr6AzJ3f3PE2fmKP1RPg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/4f11905b/attachment.pl>

From sneha.bishnoi at gmail.com  Fri Jun  7 20:07:37 2013
From: sneha.bishnoi at gmail.com (Sneha Bishnoi)
Date: Fri, 7 Jun 2013 14:07:37 -0400
Subject: [R]  SQL queries in R
Message-ID: <CAOsJHwAJ7C6qdRCmq-SzFsPXAEcu9i_cNxcsrt+NbVGHyzZ+=w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/cc3f69e1/attachment.pl>

From mikeumo at gmail.com  Fri Jun  7 20:11:55 2013
From: mikeumo at gmail.com (Mikhail Umorin)
Date: Fri, 07 Jun 2013 13:11:55 -0500
Subject: [R] Distance-based non-parametric ANOVA
In-Reply-To: <8F4C481EBCA71E45845A4CD0778F60E4046136E4@exmbx2010-8.campus.MCGILL.CA>
References: <2093686.8QetdgVmrY@localhost>
	<8F4C481EBCA71E45845A4CD0778F60E4046136E4@exmbx2010-8.campus.MCGILL.CA>
Message-ID: <4542937.sQ3I1P1Pkq@localhost>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/ccb06862/attachment.pl>

From djandrija at gmail.com  Fri Jun  7 21:21:34 2013
From: djandrija at gmail.com (andrija djurovic)
Date: Fri, 7 Jun 2013 21:21:34 +0200
Subject: [R] SQL queries in R
In-Reply-To: <CAOsJHwAJ7C6qdRCmq-SzFsPXAEcu9i_cNxcsrt+NbVGHyzZ+=w@mail.gmail.com>
References: <CAOsJHwAJ7C6qdRCmq-SzFsPXAEcu9i_cNxcsrt+NbVGHyzZ+=w@mail.gmail.com>
Message-ID: <CABcwgRREZsGwMWXYaQ=dkG=u8-eSHBBPtPC5aKrRjM5EvBPQCQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/040b6902/attachment.pl>

From dimitri.liakhovitski at gmail.com  Fri Jun  7 21:25:11 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Fri, 7 Jun 2013 15:25:11 -0400
Subject: [R] Package 'ChoiceModelR' - Xbetas.csv? Rbetas.csv? betadraws?
Message-ID: <CAN2xGJa5PdhfggvX5sW3Xb8indvqucBoB2aM-Gy2mcgp0Kq=AA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/f7b33431/attachment.pl>

From dwinsemius at comcast.net  Fri Jun  7 21:37:29 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 7 Jun 2013 12:37:29 -0700
Subject: [R] Horizontal labels on a plot
In-Reply-To: <CA+jRDxAzS4fteUaYOWnch7yDTnbLNxcM6yOxy9U_D+qR22RLxA@mail.gmail.com>
References: <CA+jRDxAzS4fteUaYOWnch7yDTnbLNxcM6yOxy9U_D+qR22RLxA@mail.gmail.com>
Message-ID: <7274AA4D-2A30-4593-9AA2-B8067E5E861F@comcast.net>


On Jun 7, 2013, at 8:38 AM, Shane Carey wrote:

> Hi,
> 
> I have a plot with horizontal lables on the x-axis. For example:
> Devonian volcanic rocks
> n=2
> 
> with n=2 on a new line. How do I centre n=2 under the " Devonian volcanic
> rocks  "
> label?
> 
> This was my code: text(axis_text, par("usr")[three], labels = paste(LABELS,
> " \n ", " n =", t(t(name.count[,two]))), srt = txt_di,  adj = txtadj, xpd =
> TRUE, cex=txt_cex)
> 

Try: 

 ?, labels=bquote( atop(.(LABELS) , n==.(name.count[,two]) ) ), ?

(Unable to test with all those undefined parameters.)

?plotmath
# where one can read that "\n" is not honored by plotmath functions, including paste().
?bquote

-- 
David

> where LABELS=Devonian volcanic rocks
> and name.count[,two] =2
> 

David Winsemius
Alameda, CA, USA


From dimitri.liakhovitski at gmail.com  Fri Jun  7 21:58:09 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Fri, 7 Jun 2013 15:58:09 -0400
Subject: [R] rJava is not loading
In-Reply-To: <51B0A388.4050303@stats.ox.ac.uk>
References: <CAN2xGJbUNA25+e9fR6NWo+HaYES1w3j_KMRpPY73cRDvA37uog@mail.gmail.com>
	<51B02A06.50903@stats.ox.ac.uk>
	<CAN2xGJZ5kQecuqn5toYgTPwUjWQp4Ca7efjN56t7djWrO+VYow@mail.gmail.com>
	<51B0A388.4050303@stats.ox.ac.uk>
Message-ID: <CAN2xGJbjGs2S9+ZtkcPxKiaz+2c=t2E1-Uq3wkDamM_e-QAkkA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/1ae5ff03/attachment.pl>

From sneha.bishnoi at gmail.com  Fri Jun  7 21:58:17 2013
From: sneha.bishnoi at gmail.com (Sneha Bishnoi)
Date: Fri, 7 Jun 2013 15:58:17 -0400
Subject: [R] SQL queries in R
In-Reply-To: <CABcwgRREZsGwMWXYaQ=dkG=u8-eSHBBPtPC5aKrRjM5EvBPQCQ@mail.gmail.com>
References: <CAOsJHwAJ7C6qdRCmq-SzFsPXAEcu9i_cNxcsrt+NbVGHyzZ+=w@mail.gmail.com>
	<CABcwgRREZsGwMWXYaQ=dkG=u8-eSHBBPtPC5aKrRjM5EvBPQCQ@mail.gmail.com>
Message-ID: <CAOsJHwAicw-Bqs8F_BHPc7kyMuf4juD-Yg4=VahCj4VcVXXWKw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/f2d55e8b/attachment.pl>

From djandrija at gmail.com  Fri Jun  7 22:24:43 2013
From: djandrija at gmail.com (andrija djurovic)
Date: Fri, 7 Jun 2013 22:24:43 +0200
Subject: [R] SQL queries in R
In-Reply-To: <CAOsJHwAicw-Bqs8F_BHPc7kyMuf4juD-Yg4=VahCj4VcVXXWKw@mail.gmail.com>
References: <CAOsJHwAJ7C6qdRCmq-SzFsPXAEcu9i_cNxcsrt+NbVGHyzZ+=w@mail.gmail.com>
	<CABcwgRREZsGwMWXYaQ=dkG=u8-eSHBBPtPC5aKrRjM5EvBPQCQ@mail.gmail.com>
	<CAOsJHwAicw-Bqs8F_BHPc7kyMuf4juD-Yg4=VahCj4VcVXXWKw@mail.gmail.com>
Message-ID: <CABcwgRTuDH19isYHtO4xvm2NmUF6vjBwQEB8r0+R0DN-jAdckA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/686c48c9/attachment.pl>

From felix11_6 at gmx.de  Fri Jun  7 21:50:45 2013
From: felix11_6 at gmx.de (felice)
Date: Fri, 7 Jun 2013 12:50:45 -0700 (PDT)
Subject: [R] RCOde need urgent HELP
Message-ID: <1370634645144-4668981.post@n4.nabble.com>

hey i need help with a case in my R project.

i have a vector Rt with returns from day 1 till day t  now i want to form a
new vector r= which is rt = Xt ? Xt?1

then i want to definde positive and negative aggregates

r(n)+ _t= 1/n (rt +...+rt?n) I {(rt+...+ rt?n) ?0}
r(n)? _t= 1/n (rt +...+rt?n) I {(rt+...+ rt?n) <0}

thanks for the help 




--
View this message in context: http://r.789695.n4.nabble.com/RCOde-need-urgent-HELP-tp4668981.html
Sent from the R help mailing list archive at Nabble.com.


From wshadish at ucmerced.edu  Fri Jun  7 22:12:57 2013
From: wshadish at ucmerced.edu (William Shadish)
Date: Fri, 7 Jun 2013 13:12:57 -0700
Subject: [R] gamm in mgcv random effect significance
Message-ID: <51B23EC9.4090109@ucmerced.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/3c814311/attachment.pl>

From cecilia.carmo at ua.pt  Fri Jun  7 23:51:53 2013
From: cecilia.carmo at ua.pt (Cecilia Carmo)
Date: Fri, 7 Jun 2013 21:51:53 +0000
Subject: [R] matched samples, dataframe, panel data
In-Reply-To: <1370622636.62630.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <104083AE5AAA634C993249DFCCE4C20306439641@CIPRESTE.ua.pt>
	<1370618741.16808.YahooMailNeo@web142605.mail.bf1.yahoo.com>,
	<1370618875.52646.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<104083AE5AAA634C993249DFCCE4C20306439664@CIPRESTE.ua.pt>,
	<1370619793.18982.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<104083AE5AAA634C993249DFCCE4C2030643969E@CIPRESTE.ua.pt>,
	<1370622636.62630.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <104083AE5AAA634C993249DFCCE4C203064396BF@CIPRESTE.ua.pt>

Thank you very much.

I apologize but I want to ask only one more thing:

How to do if I want in addition to impose that the diffence between 
dimensions doesn't exced an absolute value, for example, 200.

Firm 1 continues matching with firm 5 in year 2000 because 
2189-2120=69, and 69 is < 10%x2120=212, and 69 is also < 200

But firm 20 doesn't match with firm 17 in year 2001
because 6754-6438=316, and 316 is < 10%x6438=643.8, but 316 is > 200


Thank you

Cec?lia

________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: sexta-feira, 7 de Junho de 2013 17:30
Para: Cecilia Carmo
Cc: R help
Assunto: Re: [R] matched samples, dataframe, panel data

Sorry, it included a case with both values for dummy were 1.

lst7<-lapply(lst6,function(x) {lst<-lapply(x,function(y) y[sum(y$dummy)==1,]);lst[lapply(lst,nrow)>0]})

 res<-do.call(rbind,lapply(lst7,function(x) do.call(rbind,x)))
 row.names(res)<-1:nrow(res)
nrow(subset(res,dummy==0))
#[1] 22
 nrow(subset(res,dummy==1))
#[1] 22
A.K.



----- Original Message -----
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Cc: R help <r-help at r-project.org>
Sent: Friday, June 7, 2013 12:03 PM
Subject: RE: [R] matched samples, dataframe, panel data

Sorry,

Something is not ok, because when  I do

> nrow(subset(res,res$dummy==0))
[1] 22
> nrow(subset(res,res$dummy==1))
[1] 24

There the number  o observatios in the two subsets is not equal.


Thanks again,

Cec?lia


________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: sexta-feira, 7 de Junho de 2013 16:43
Para: Cecilia Carmo
Cc: R help
Assunto: Re: [R] matched samples, dataframe, panel data

Hi,
Not sure if this is what you wanted.

res<-do.call(rbind,lapply(lst6,function(x) do.call(rbind,x)))
row.names(res)<-1:nrow(res)

# this combines the list of lists to a data.frame
res[1:4,]
#  firm year industry dummy dimension
#1    1 2000       20     0      2120
#2    5 2000       20     1      2189
#3    4 2000       20     0      3178
#4    7 2000       20     1      3245


#or
res<-do.call(rbind,lapply(lst6,function(x) do.call(rbind,x)))
res$group<-gsub("(.*\\..*)\\..*$","\\1",rownames(res))
row.names(res)<-1:nrow(res)
res[1:4,]
#  firm year industry dummy dimension   group
#1    1 2000       20     0      2120 2000.20   #1 group
#2    5 2000       20     1      2189 2000.20   #1
#3    4 2000       20     0      3178 2000.20   #2
#4    7 2000       20     1      3245 2000.20   #2
A.K.


----- Original Message -----
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Cc:
Sent: Friday, June 7, 2013 11:33 AM
Subject: RE: [R] matched samples, dataframe, panel data

Thank you very much.
Just a little thing: how can I put it like a dataframe?

Thanks,

Cec?lia

________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: sexta-feira, 7 de Junho de 2013 16:27
Para: Cecilia Carmo
Assunto: Re: [R] matched samples, dataframe, panel data

Hi,
There could be easier ways...  I am a bit busy now to try other ways.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Cecilia Carmo <cecilia.carmo at ua.pt>
Cc: R help <r-help at r-project.org>
Sent: Friday, June 7, 2013 11:25 AM
Subject: Re: [R] matched samples, dataframe, panel data

Hi,
May be this helps:
lst1<-split(final3,list(final3$year,final3$industry))
lst2<-lst1[lapply(lst1,nrow)>0]
lst3<-lapply(lst2,function(x) lapply(x$dimension,function(y) x[(y< (x$dimension+x$dimension*0.1)) & (y> (x$dimension-x$dimension*0.1)),]))
lst4<-lapply(lst3,function(x) x[lapply(x,nrow)==2])
lst5<-lapply(lst4,function(x)x[!duplicated(x)])
lst6<-lst5[lapply(lst5,length)>0]

names(lst6)
# [1] "2000.20" "2001.20" "2002.20" "2003.20" "2004.20" "2001.30" "2002.30"
#[8] "2001.40" "2002.40" "2003.40" "2004.40"


lst6["2000.20"]
#$`2000.20`
#$`2000.20`[[1]]
#  firm year industry dummy dimension
#1     1 2000       20     0      2120
#21    5 2000       20     1      2189
#
#$`2000.20`[[2]]
#  firm year industry dummy dimension
#16    4 2000       20     0      3178
#31    7 2000       20     1      3245
#
#$`2000.20`[[3]]
#  firm year industry dummy dimension
#11    3 2000       20     1      4532
#6     2 2000       20     0      4890
A.K.





________________________________
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: "r-help at r-project.org" <r-help at r-project.org>

Sent: Friday, June 7, 2013 9:56 AM
Subject: Re: [R] matched samples, dataframe, panel data




Again my problem, better explained.

#I have a data panel of thousands of firms, by year and industry and
#one dummy variable that identifies one kind of firms (1 if the firm have an auditor; 0 if not)
#and another variable the represents the firm dimension (total assets in thousand of euros)
#I need to create two separated samples with the same number os firms where
#one firm in the first have a corresponding firm in the second with the same
#year, industry and dimension (the dimension doesn't need to be exatly the
#same, it could vary in an interval of +/- 10%, for example)

#My reproducible example
firm1<-sort(rep(1:10,5),decreasing=F)
year1<-rep(2000:2004,10)
industry1<-rep(20,50)
dummy1<-c(0,0,1,1,0,0,1,1,0,1,1,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,1,0,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,1,1,1)
dimension1<-c(2120,345,2341,5678,10900,4890,2789,3412,9500,8765,4532,6593,12900,123,2345,3178,2678,6666,647,23789,
2189,4289,8543,637,23456,781,35489,2345,5754,8976,3245,1234,25,1200,2345,2765,389,23456,2367,3892,5438,37824,
23,2897,3456,7690,6022,3678,9431,2890)
data1<-data.frame(firm1,year1,industry1,dummy1,dimension1)
data1
colnames(data1)<-c("firm","year","industry","dummy","dimension")

firm2<-sort(rep(11:15,3),decreasing=F)
year2<-rep(2001:2003,5)
industry2<-rep(30,15)
dummy2<-c(0,0,0,0,0,0,1,1,1,1,1,1,1,0,1)
dimension2<-c(12456,781,32489,2345,5754,8976,3245,2120,345,2341,5678,10900,12900,123,2345)
data2<-data.frame(firm2,year2,industry2,dummy2,dimension2)
data2
colnames(data2)<-c("firm","year","industry","dummy","dimension")
firm3<-sort(rep(16:20,4),decreasing=F)
year3<-rep(2001:2004,5)
industry3<-rep(40,20)
dummy3<-c(0,0,1,0,1,0,1,0,1,1,1,1,1,0,0,0,0,1,0,0)
dimension3<-c(23456,1181,32489,2345,6754,8976,3245,1234,1288,1200,2345,2765,389,23456,2367,3892,6438,24824,
23,2897)
data3<-data.frame(firm3,year3,industry3,dummy3,dimension3)
data3
colnames(data3)<-c("firm","year","industry","dummy","dimension")

final1<-rbind(data1,data2)
final2<-rbind(final1,data3)
final2
final3<-final2[order(final2$year,final2$industry,final2$dimension),]
final3


#So my data is final3 is like this:
   firm year industry dummy dimension
26    6 2000       20     0       781
1     1 2000       20     0      2120
21    5 2000       20     1      2189
36    8 2000       20     1      2765
16    4 2000       20     0      3178
31    7 2000       20     1      3245
11    3 2000       20     1      4532
6     2 2000       20     0      4890
41    9 2000       20     0      5438
46   10 2000       20     0      7690
2     1 2001       20     0       345
37    8 2001       20     1       389
32    7 2001       20     0      1234
17    4 2001       20     0      2678
7     2 2001       20     1      2789
22    5 2001       20     1      4289
47   10 2001       20     0      6022
12    3 2001       20     1      6593
27    6 2001       20     0     35489
42    9 2001       20     1     37824
60   14 2001       30     1      2341
54   12 2001       30     0      2345
57   13 2001       30     1      3245
51   11 2001       30     0     12456
63   15 2001       30     1     12900
78   19 2001       40     1       389
74   18 2001       40     1      1288
82   20 2001       40     0      6438
70   17 2001       40     1      6754
66   16 2001       40     0     23456
43    9 2002       20     0        23
33    7 2002       20     1        25
3     1 2002       20     1      2341
28    6 2002       20     0      2345
8     2 2002       20     1      3412
48   10 2002       20     1      3678
18    4 2002       20     0      6666
23    5 2002       20     0      8543
13    3 2002       20     0     12900
38    8 2002       20     1     23456
64   15 2002       30     0       123
52   11 2002       30     0       781
58   13 2002       30     1      2120
61   14 2002       30     1      5678
55   12 2002       30     0      5754
67   16 2002       40     0      1181
75   18 2002       40     1      1200
71   17 2002       40     0      8976
79   19 2002       40     0     23456
83   20 2002       40     1     24824
14    3 2003       20     0       123
24    5 2003       20     0       637
19    4 2003       20     1       647
34    7 2003       20     0      1200
39    8 2003       20     1      2367
44    9 2003       20     0      2897
4     1 2003       20     1      5678
29    6 2003       20     0      5754
49   10 2003       20     1      9431
9     2 2003       20     0      9500
59   13 2003       30     1       345
65   15 2003       30     1      2345
56   12 2003       30     0      8976
62   14 2003       30     1     10900
53   11 2003       30     0     32489
84   20 2003       40     0        23
76   18 2003       40     1      2345
80   19 2003       40     0      2367
72   17 2003       40     1      3245
68   16 2003       40     1     32489
15    3 2004       20     0      2345
35    7 2004       20     1      2345
50   10 2004       20     1      2890
45    9 2004       20     0      3456
40    8 2004       20     0      3892
10    2 2004       20     1      8765
30    6 2004       20     0      8976
5     1 2004       20     0     10900
25    5 2004       20     0     23456
20    4 2004       20     1     23789
73   17 2004       40     0      1234
69   16 2004       40     0      2345
77   18 2004       40     1      2765
85   20 2004       40     0      2897
81   19 2004       40     0      3892

I want to keep couples of firms one with dummy=1 and other with dummy=0 that matchs in industry, firm and dimension.

But dimension doesn't need to be exactly the same, it is why I refer an interval of + or - 10%.

For example firm 1 matchs with firm 5, because they have the same year, industry, dimension (10% x 2120 = 212 and 2189-2120<212)
and firm 1 is dummy=0 and firm 5 is dummy=1.

So I want to delete firm 6 because it doesn't macth with any firm, and keep firm 1 and 5.

     firm year industry dummy dimension
26    6 2000       20     0       781
1     1 2000       20     0      2120
21    5 2000       20     1      2189

Next,

Now I can match firm 4 with firm 7 and delete firm 8.
36    8 2000       20     1      2765
16    4 2000       20     0      3178
31    7 2000       20     1      3245

And so on...

At the end I want to keep only pairs of firms, matched by year, industry and dimension.

If I separate firms with dummy=1 from firms with dummy=0 in two separated dataframes, I have two matched samples
with the same number of observations. That's what I want.

Thank you,
Cec?lia Carmo
Universidade de Aveiro - Portugal

From gavin.simpson at ucl.ac.uk  Sat Jun  8 00:02:29 2013
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 7 Jun 2013 16:02:29 -0600
Subject: [R] gamm in mgcv random effect significance
In-Reply-To: <51B23EC9.4090109@ucmerced.edu>
References: <51B23EC9.4090109@ucmerced.edu>
Message-ID: <1370642549.23179.17.camel@haul.biol.uregina.ca>

On Fri, 2013-06-07 at 13:12 -0700, William Shadish wrote:
> Dear R-helpers,
> 
> I'd like to understand how to test the statistical significance of a 
> random effect in gamm. I am using gamm because I want to test a model 
> with an AR(1) error structure, and it is my understanding neither gam 
> nor gamm4 will do the latter.

gamm4() can't yes and out of the box mgcv::gam can't either but
see ?magic for an example of correlated errors and how the fits can be
manipulated to take the AR(1) (or any structure really as far as I can
tell) into account.

You might like to look at mgcv::bam() which allows an known AR(1) term
but do check that it does what you think; with a random effect spline
I'm not at all certain that it will nest the AR(1) in the random effect
level.

<snip />
> Consider, for example, two models, both with AR(1) but one allowing a 
> random effect on xc:
> 
> g1 <- gamm(y ~ s(xc) +z+ int,family=binomial, weights=trial, 
> correlation=corAR1())
> g2 <- gamm(y ~ s(xc) +z+ int,family=binomial, weights=trial, random = 
> list(xc=~1),correlation=corAR1())

Shouldn't you specify how the AR(1) is nested in the hierarchy here,
i.e. AR(1) within xc? maybe I'm not following your data structure
correctly.

> I include the output for g1 and g2 below, but the question is how to 
> test the significance of the random effect on xc. I considered a test 
> comparing the Log-Likelihoods, but have no idea what the degrees of 
> freedom would be given that s(xc) is smoothed. I also tried:
> 
> anova(g1$gam, g2$gam)

gamm() fits via the lme() function of package nlme. To do what you want,
you need the anova() method for objects of class "lme", e.g.

anova(g1$lme, g2$lme)

Then I think you should check if the fits were done via REML and also be
aware of the issue of testing wether a variance term is 0.

> that did not seem to return anything useful for this question.
> 
> A related question is how to test the significance of adding a second 
> random effect to a model that already has a random effect, such as:
> 
> g3 <- gamm(y ~ xc +z+ s(int),family=binomial, weights=trial, random = 
> list(Case=~1, z=~1),correlation=corAR1())
> g4 <- gamm(y ~ xc +z+ s(int),family=binomial, weights=trial, random = 
> list(Case=~1, z=~1, int=~1),correlation=corAR1())

Again, I think you need anova() on the $lme components.

HTH

G

> Any help would be appreciated.
> 
> Thanks.
> 
> Will Shadish
> ********************************************
> g1
> $lme
> Linear mixed-effects model fit by maximum likelihood
>    Data: data
>    Log-likelihood: -437.696
>    Fixed: fixed
> X(Intercept)           Xz         Xint    Xs(xc)Fx1
>     0.6738466   -2.5688317    0.0137415   -0.1801294
> 
> Random effects:
>   Formula: ~Xr - 1 | g
>   Structure: pdIdnot
>                   Xr1          Xr2          Xr3 Xr4          
> Xr5          Xr6          Xr7          Xr8 Residual
> StdDev: 0.0004377781 0.0004377781 0.0004377781 0.0004377781 0.0004377781 
> 0.0004377781 0.0004377781 0.0004377781 1.693177
> 
> Correlation Structure: AR(1)
>   Formula: ~1 | g
>   Parameter estimate(s):
>        Phi
> 0.3110725
> Variance function:
>   Structure: fixed weights
>   Formula: ~invwt
> Number of Observations: 264
> Number of Groups: 1
> 
> $gam
> 
> Family: binomial
> Link function: logit
> 
> Formula:
> y ~ s(xc) + z + int
> 
> Estimated degrees of freedom:
> 1  total = 4
> 
> attr(,"class")
> [1] "gamm" "list"
> ****************************
>  > g2
> $lme
> Linear mixed-effects model fit by maximum likelihood
>    Data: data
>    Log-likelihood: -443.9495
>    Fixed: fixed
> X(Intercept)           Xz         Xint    Xs(xc)Fx1
>   0.720018143 -2.562155820  0.003457463 -0.045821030
> 
> Random effects:
>   Formula: ~Xr - 1 | g
>   Structure: pdIdnot
>                   Xr1          Xr2          Xr3 Xr4          
> Xr5          Xr6          Xr7          Xr8
> StdDev: 7.056078e-06 7.056078e-06 7.056078e-06 7.056078e-06 7.056078e-06 
> 7.056078e-06 7.056078e-06 7.056078e-06
> 
>   Formula: ~1 | xc %in% g
>           (Intercept) Residual
> StdDev: 6.277279e-05 1.683007
> 
> Correlation Structure: AR(1)
>   Formula: ~1 | g/xc
>   Parameter estimate(s):
>        Phi
> 0.1809409
> Variance function:
>   Structure: fixed weights
>   Formula: ~invwt
> Number of Observations: 264
> Number of Groups:
>          g xc %in% g
>          1        34
> 
> $gam
> 
> Family: binomial
> Link function: logit
> 
> Formula:
> y ~ s(xc) + z + int
> 
> Estimated degrees of freedom:
> 1  total = 4
> 
> attr(,"class")
> [1] "gamm" "list"
> 
> 

-- 
Gavin Simpson, PhD                          [t] +1 306 337 8863
Adjunct Professor, Department of Biology    [f] +1 306 337 2410
Institute of Environmental Change & Society [e] gavin.simpson at uregina.ca
523 Research and Innovation Centre          [tw] @ucfagls
University of Regina
Regina, SK S4S 0A2, Canada


From smartpink111 at yahoo.com  Sat Jun  8 00:04:33 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 7 Jun 2013 15:04:33 -0700 (PDT)
Subject: [R] matched samples, dataframe, panel data
In-Reply-To: <104083AE5AAA634C993249DFCCE4C203064396BF@CIPRESTE.ua.pt>
References: <104083AE5AAA634C993249DFCCE4C20306439641@CIPRESTE.ua.pt>
	<1370618741.16808.YahooMailNeo@web142605.mail.bf1.yahoo.com>,
	<1370618875.52646.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<104083AE5AAA634C993249DFCCE4C20306439664@CIPRESTE.ua.pt>,
	<1370619793.18982.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<104083AE5AAA634C993249DFCCE4C2030643969E@CIPRESTE.ua.pt>,
	<1370622636.62630.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<104083AE5AAA634C993249DFCCE4C203064396BF@CIPRESTE.ua.pt>
Message-ID: <1370642673.28997.YahooMailNeo@web142603.mail.bf1.yahoo.com>

HI,
Do you want to impose this on 'res' on 'final3'?
If it is on `res`:
res1<-do.call(rbind,lapply(split(res,(1:nrow(res)-1)%/%2+1),function(x) x[abs(diff(x$dimension))<200,]))
row.names(res1)<-1:nrow(res1)
nrow(subset(res1,dummy==0))
#[1] 14
?nrow(subset(res1,dummy==1))
#[1] 14

?head(res1)
#? firm year industry dummy dimension
#1??? 1 2000?????? 20???? 0????? 2120
#2??? 5 2000?????? 20???? 1????? 2189
#3??? 4 2000?????? 20???? 0????? 3178
#4??? 7 2000?????? 20???? 1????? 3245
#5??? 4 2001?????? 20???? 0????? 2678
#6 ?? 2 2001?????? 20???? 1????? 2789
A.K.



----- Original Message -----
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: R help <r-help at r-project.org>
Cc: arun <smartpink111 at yahoo.com>
Sent: Friday, June 7, 2013 5:51 PM
Subject: RE: [R] matched samples, dataframe, panel data

Thank you very much.

I apologize but I want to ask only one more thing:

How to do if I want in addition to impose that the diffence between 
dimensions doesn't exced an absolute value, for example, 200.

Firm 1 continues matching with firm 5 in year 2000 because 
2189-2120=69, and 69 is < 10%x2120=212, and 69 is also < 200

But firm 20 doesn't match with firm 17 in year 2001
because 6754-6438=316, and 316 is < 10%x6438=643.8, but 316 is > 200


Thank you

Cec?lia

________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: sexta-feira, 7 de Junho de 2013 17:30
Para: Cecilia Carmo
Cc: R help
Assunto: Re: [R] matched samples, dataframe, panel data

Sorry, it included a case with both values for dummy were 1.

lst7<-lapply(lst6,function(x) {lst<-lapply(x,function(y) y[sum(y$dummy)==1,]);lst[lapply(lst,nrow)>0]})

res<-do.call(rbind,lapply(lst7,function(x) do.call(rbind,x)))
row.names(res)<-1:nrow(res)
nrow(subset(res,dummy==0))
#[1] 22
nrow(subset(res,dummy==1))
#[1] 22
A.K.



----- Original Message -----
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Cc: R help <r-help at r-project.org>
Sent: Friday, June 7, 2013 12:03 PM
Subject: RE: [R] matched samples, dataframe, panel data

Sorry,

Something is not ok, because when? I do

> nrow(subset(res,res$dummy==0))
[1] 22
> nrow(subset(res,res$dummy==1))
[1] 24

There the number? o observatios in the two subsets is not equal.


Thanks again,

Cec?lia


________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: sexta-feira, 7 de Junho de 2013 16:43
Para: Cecilia Carmo
Cc: R help
Assunto: Re: [R] matched samples, dataframe, panel data

Hi,
Not sure if this is what you wanted.

res<-do.call(rbind,lapply(lst6,function(x) do.call(rbind,x)))
row.names(res)<-1:nrow(res)

# this combines the list of lists to a data.frame
res[1:4,]
#? firm year industry dummy dimension
#1? ? 1 2000? ? ?  20? ?  0? ? ? 2120
#2? ? 5 2000? ? ?  20? ?  1? ? ? 2189
#3? ? 4 2000? ? ?  20? ?  0? ? ? 3178
#4? ? 7 2000? ? ?  20? ?  1? ? ? 3245


#or
res<-do.call(rbind,lapply(lst6,function(x) do.call(rbind,x)))
res$group<-gsub("(.*\\..*)\\..*$","\\1",rownames(res))
row.names(res)<-1:nrow(res)
res[1:4,]
#? firm year industry dummy dimension?  group
#1? ? 1 2000? ? ?  20? ?  0? ? ? 2120 2000.20?  #1 group
#2? ? 5 2000? ? ?  20? ?  1? ? ? 2189 2000.20?  #1
#3? ? 4 2000? ? ?  20? ?  0? ? ? 3178 2000.20?  #2
#4? ? 7 2000? ? ?  20? ?  1? ? ? 3245 2000.20?  #2
A.K.


----- Original Message -----
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Cc:
Sent: Friday, June 7, 2013 11:33 AM
Subject: RE: [R] matched samples, dataframe, panel data

Thank you very much.
Just a little thing: how can I put it like a dataframe?

Thanks,

Cec?lia

________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: sexta-feira, 7 de Junho de 2013 16:27
Para: Cecilia Carmo
Assunto: Re: [R] matched samples, dataframe, panel data

Hi,
There could be easier ways...? I am a bit busy now to try other ways.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Cecilia Carmo <cecilia.carmo at ua.pt>
Cc: R help <r-help at r-project.org>
Sent: Friday, June 7, 2013 11:25 AM
Subject: Re: [R] matched samples, dataframe, panel data

Hi,
May be this helps:
lst1<-split(final3,list(final3$year,final3$industry))
lst2<-lst1[lapply(lst1,nrow)>0]
lst3<-lapply(lst2,function(x) lapply(x$dimension,function(y) x[(y< (x$dimension+x$dimension*0.1)) & (y> (x$dimension-x$dimension*0.1)),]))
lst4<-lapply(lst3,function(x) x[lapply(x,nrow)==2])
lst5<-lapply(lst4,function(x)x[!duplicated(x)])
lst6<-lst5[lapply(lst5,length)>0]

names(lst6)
# [1] "2000.20" "2001.20" "2002.20" "2003.20" "2004.20" "2001.30" "2002.30"
#[8] "2001.40" "2002.40" "2003.40" "2004.40"


lst6["2000.20"]
#$`2000.20`
#$`2000.20`[[1]]
#? firm year industry dummy dimension
#1? ?  1 2000? ? ?  20? ?  0? ? ? 2120
#21? ? 5 2000? ? ?  20? ?  1? ? ? 2189
#
#$`2000.20`[[2]]
#? firm year industry dummy dimension
#16? ? 4 2000? ? ?  20? ?  0? ? ? 3178
#31? ? 7 2000? ? ?  20? ?  1? ? ? 3245
#
#$`2000.20`[[3]]
#? firm year industry dummy dimension
#11? ? 3 2000? ? ?  20? ?  1? ? ? 4532
#6? ?  2 2000? ? ?  20? ?  0? ? ? 4890
A.K.





________________________________
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: "smartpink111 at yahoo.com" <smartpink111 at yahoo.com>
Sent: Friday, June 7, 2013 9:56 AM
Subject: Re: [R] matched samples, dataframe, panel data




Again my problem, better explained.

#I have a data panel of thousands of firms, by year and industry and
#one dummy variable that identifies one kind of firms (1 if the firm have an auditor; 0 if not)
#and another variable the represents the firm dimension (total assets in thousand of euros)
#I need to create two separated samples with the same number os firms where
#one firm in the first have a corresponding firm in the second with the same
#year, industry and dimension (the dimension doesn't need to be exatly the
#same, it could vary in an interval of +/- 10%, for example)

#My reproducible example
firm1<-sort(rep(1:10,5),decreasing=F)
year1<-rep(2000:2004,10)
industry1<-rep(20,50)
dummy1<-c(0,0,1,1,0,0,1,1,0,1,1,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,1,0,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,1,1,1)
dimension1<-c(2120,345,2341,5678,10900,4890,2789,3412,9500,8765,4532,6593,12900,123,2345,3178,2678,6666,647,23789,
2189,4289,8543,637,23456,781,35489,2345,5754,8976,3245,1234,25,1200,2345,2765,389,23456,2367,3892,5438,37824,
23,2897,3456,7690,6022,3678,9431,2890)
data1<-data.frame(firm1,year1,industry1,dummy1,dimension1)
data1
colnames(data1)<-c("firm","year","industry","dummy","dimension")

firm2<-sort(rep(11:15,3),decreasing=F)
year2<-rep(2001:2003,5)
industry2<-rep(30,15)
dummy2<-c(0,0,0,0,0,0,1,1,1,1,1,1,1,0,1)
dimension2<-c(12456,781,32489,2345,5754,8976,3245,2120,345,2341,5678,10900,12900,123,2345)
data2<-data.frame(firm2,year2,industry2,dummy2,dimension2)
data2
colnames(data2)<-c("firm","year","industry","dummy","dimension")
firm3<-sort(rep(16:20,4),decreasing=F)
year3<-rep(2001:2004,5)
industry3<-rep(40,20)
dummy3<-c(0,0,1,0,1,0,1,0,1,1,1,1,1,0,0,0,0,1,0,0)
dimension3<-c(23456,1181,32489,2345,6754,8976,3245,1234,1288,1200,2345,2765,389,23456,2367,3892,6438,24824,
23,2897)
data3<-data.frame(firm3,year3,industry3,dummy3,dimension3)
data3
colnames(data3)<-c("firm","year","industry","dummy","dimension")

final1<-rbind(data1,data2)
final2<-rbind(final1,data3)
final2
final3<-final2[order(final2$year,final2$industry,final2$dimension),]
final3


#So my data is final3 is like this:
?  firm year industry dummy dimension
26? ? 6 2000? ? ?  20? ?  0? ? ?  781
1? ?  1 2000? ? ?  20? ?  0? ? ? 2120
21? ? 5 2000? ? ?  20? ?  1? ? ? 2189
36? ? 8 2000? ? ?  20? ?  1? ? ? 2765
16? ? 4 2000? ? ?  20? ?  0? ? ? 3178
31? ? 7 2000? ? ?  20? ?  1? ? ? 3245
11? ? 3 2000? ? ?  20? ?  1? ? ? 4532
6? ?  2 2000? ? ?  20? ?  0? ? ? 4890
41? ? 9 2000? ? ?  20? ?  0? ? ? 5438
46?  10 2000? ? ?  20? ?  0? ? ? 7690
2? ?  1 2001? ? ?  20? ?  0? ? ?  345
37? ? 8 2001? ? ?  20? ?  1? ? ?  389
32? ? 7 2001? ? ?  20? ?  0? ? ? 1234
17? ? 4 2001? ? ?  20? ?  0? ? ? 2678
7? ?  2 2001? ? ?  20? ?  1? ? ? 2789
22? ? 5 2001? ? ?  20? ?  1? ? ? 4289
47?  10 2001? ? ?  20? ?  0? ? ? 6022
12? ? 3 2001? ? ?  20? ?  1? ? ? 6593
27? ? 6 2001? ? ?  20? ?  0? ?  35489
42? ? 9 2001? ? ?  20? ?  1? ?  37824
60?  14 2001? ? ?  30? ?  1? ? ? 2341
54?  12 2001? ? ?  30? ?  0? ? ? 2345
57?  13 2001? ? ?  30? ?  1? ? ? 3245
51?  11 2001? ? ?  30? ?  0? ?  12456
63?  15 2001? ? ?  30? ?  1? ?  12900
78?  19 2001? ? ?  40? ?  1? ? ?  389
74?  18 2001? ? ?  40? ?  1? ? ? 1288
82?  20 2001? ? ?  40? ?  0? ? ? 6438
70?  17 2001? ? ?  40? ?  1? ? ? 6754
66?  16 2001? ? ?  40? ?  0? ?  23456
43? ? 9 2002? ? ?  20? ?  0? ? ? ? 23
33? ? 7 2002? ? ?  20? ?  1? ? ? ? 25
3? ?  1 2002? ? ?  20? ?  1? ? ? 2341
28? ? 6 2002? ? ?  20? ?  0? ? ? 2345
8? ?  2 2002? ? ?  20? ?  1? ? ? 3412
48?  10 2002? ? ?  20? ?  1? ? ? 3678
18? ? 4 2002? ? ?  20? ?  0? ? ? 6666
23? ? 5 2002? ? ?  20? ?  0? ? ? 8543
13? ? 3 2002? ? ?  20? ?  0? ?  12900
38? ? 8 2002? ? ?  20? ?  1? ?  23456
64?  15 2002? ? ?  30? ?  0? ? ?  123
52?  11 2002? ? ?  30? ?  0? ? ?  781
58?  13 2002? ? ?  30? ?  1? ? ? 2120
61?  14 2002? ? ?  30? ?  1? ? ? 5678
55?  12 2002? ? ?  30? ?  0? ? ? 5754
67?  16 2002? ? ?  40? ?  0? ? ? 1181
75?  18 2002? ? ?  40? ?  1? ? ? 1200
71?  17 2002? ? ?  40? ?  0? ? ? 8976
79?  19 2002? ? ?  40? ?  0? ?  23456
83?  20 2002? ? ?  40? ?  1? ?  24824
14? ? 3 2003? ? ?  20? ?  0? ? ?  123
24? ? 5 2003? ? ?  20? ?  0? ? ?  637
19? ? 4 2003? ? ?  20? ?  1? ? ?  647
34? ? 7 2003? ? ?  20? ?  0? ? ? 1200
39? ? 8 2003? ? ?  20? ?  1? ? ? 2367
44? ? 9 2003? ? ?  20? ?  0? ? ? 2897
4? ?  1 2003? ? ?  20? ?  1? ? ? 5678
29? ? 6 2003? ? ?  20? ?  0? ? ? 5754
49?  10 2003? ? ?  20? ?  1? ? ? 9431
9? ?  2 2003? ? ?  20? ?  0? ? ? 9500
59?  13 2003? ? ?  30? ?  1? ? ?  345
65?  15 2003? ? ?  30? ?  1? ? ? 2345
56?  12 2003? ? ?  30? ?  0? ? ? 8976
62?  14 2003? ? ?  30? ?  1? ?  10900
53?  11 2003? ? ?  30? ?  0? ?  32489
84?  20 2003? ? ?  40? ?  0? ? ? ? 23
76?  18 2003? ? ?  40? ?  1? ? ? 2345
80?  19 2003? ? ?  40? ?  0? ? ? 2367
72?  17 2003? ? ?  40? ?  1? ? ? 3245
68?  16 2003? ? ?  40? ?  1? ?  32489
15? ? 3 2004? ? ?  20? ?  0? ? ? 2345
35? ? 7 2004? ? ?  20? ?  1? ? ? 2345
50?  10 2004? ? ?  20? ?  1? ? ? 2890
45? ? 9 2004? ? ?  20? ?  0? ? ? 3456
40? ? 8 2004? ? ?  20? ?  0? ? ? 3892
10? ? 2 2004? ? ?  20? ?  1? ? ? 8765
30? ? 6 2004? ? ?  20? ?  0? ? ? 8976
5? ?  1 2004? ? ?  20? ?  0? ?  10900
25? ? 5 2004? ? ?  20? ?  0? ?  23456
20? ? 4 2004? ? ?  20? ?  1? ?  23789
73?  17 2004? ? ?  40? ?  0? ? ? 1234
69?  16 2004? ? ?  40? ?  0? ? ? 2345
77?  18 2004? ? ?  40? ?  1? ? ? 2765
85?  20 2004? ? ?  40? ?  0? ? ? 2897
81?  19 2004? ? ?  40? ?  0? ? ? 3892

I want to keep couples of firms one with dummy=1 and other with dummy=0 that matchs in industry, firm and dimension.

But dimension doesn't need to be exactly the same, it is why I refer an interval of + or - 10%.

For example firm 1 matchs with firm 5, because they have the same year, industry, dimension (10% x 2120 = 212 and 2189-2120<212)
and firm 1 is dummy=0 and firm 5 is dummy=1.

So I want to delete firm 6 because it doesn't macth with any firm, and keep firm 1 and 5.

? ?  firm year industry dummy dimension
26? ? 6 2000? ? ?  20? ?  0? ? ?  781
1? ?  1 2000? ? ?  20? ?  0? ? ? 2120
21? ? 5 2000? ? ?  20? ?  1? ? ? 2189

Next,

Now I can match firm 4 with firm 7 and delete firm 8.
36? ? 8 2000? ? ?  20? ?  1? ? ? 2765
16? ? 4 2000? ? ?  20? ?  0? ? ? 3178
31? ? 7 2000? ? ?  20? ?  1? ? ? 3245

And so on...

At the end I want to keep only pairs of firms, matched by year, industry and dimension.

If I separate firms with dummy=1 from firms with dummy=0 in two separated dataframes, I have two matched samples
with the same number of observations. That's what I want.

Thank you,
Cec?lia Carmo
Universidade de Aveiro - Portugal


From cecilia.carmo at ua.pt  Sat Jun  8 00:10:04 2013
From: cecilia.carmo at ua.pt (Cecilia Carmo)
Date: Fri, 7 Jun 2013 22:10:04 +0000
Subject: [R] matched samples, dataframe, panel data
In-Reply-To: <1370642673.28997.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <104083AE5AAA634C993249DFCCE4C20306439641@CIPRESTE.ua.pt>
	<1370618741.16808.YahooMailNeo@web142605.mail.bf1.yahoo.com>,
	<1370618875.52646.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<104083AE5AAA634C993249DFCCE4C20306439664@CIPRESTE.ua.pt>,
	<1370619793.18982.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<104083AE5AAA634C993249DFCCE4C2030643969E@CIPRESTE.ua.pt>,
	<1370622636.62630.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<104083AE5AAA634C993249DFCCE4C203064396BF@CIPRESTE.ua.pt>,
	<1370642673.28997.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <104083AE5AAA634C993249DFCCE4C203064396CE@CIPRESTE.ua.pt>

Maybe the final result is the same, but I want to impose it on final3, when we are matching the firms.

Thanks,
Cec?lia



________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: sexta-feira, 7 de Junho de 2013 23:04
Para: Cecilia Carmo
Cc: R help
Assunto: Re: [R] matched samples, dataframe, panel data

HI,
Do you want to impose this on 'res' on 'final3'?
If it is on `res`:
res1<-do.call(rbind,lapply(split(res,(1:nrow(res)-1)%/%2+1),function(x) x[abs(diff(x$dimension))<200,]))
row.names(res1)<-1:nrow(res1)
nrow(subset(res1,dummy==0))
#[1] 14
 nrow(subset(res1,dummy==1))
#[1] 14

 head(res1)
#  firm year industry dummy dimension
#1    1 2000       20     0      2120
#2    5 2000       20     1      2189
#3    4 2000       20     0      3178
#4    7 2000       20     1      3245
#5    4 2001       20     0      2678
#6    2 2001       20     1      2789
A.K.



----- Original Message -----
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: R help <r-help at r-project.org>
Cc: arun <smartpink111 at yahoo.com>
Sent: Friday, June 7, 2013 5:51 PM
Subject: RE: [R] matched samples, dataframe, panel data

Thank you very much.

I apologize but I want to ask only one more thing:

How to do if I want in addition to impose that the diffence between
dimensions doesn't exced an absolute value, for example, 200.

Firm 1 continues matching with firm 5 in year 2000 because
2189-2120=69, and 69 is < 10%x2120=212, and 69 is also < 200

But firm 20 doesn't match with firm 17 in year 2001
because 6754-6438=316, and 316 is < 10%x6438=643.8, but 316 is > 200


Thank you

Cec?lia

________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: sexta-feira, 7 de Junho de 2013 17:30
Para: Cecilia Carmo
Cc: R help
Assunto: Re: [R] matched samples, dataframe, panel data

Sorry, it included a case with both values for dummy were 1.

lst7<-lapply(lst6,function(x) {lst<-lapply(x,function(y) y[sum(y$dummy)==1,]);lst[lapply(lst,nrow)>0]})

res<-do.call(rbind,lapply(lst7,function(x) do.call(rbind,x)))
row.names(res)<-1:nrow(res)
nrow(subset(res,dummy==0))
#[1] 22
nrow(subset(res,dummy==1))
#[1] 22
A.K.



----- Original Message -----
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Cc: R help <r-help at r-project.org>
Sent: Friday, June 7, 2013 12:03 PM
Subject: RE: [R] matched samples, dataframe, panel data

Sorry,

Something is not ok, because when  I do

> nrow(subset(res,res$dummy==0))
[1] 22
> nrow(subset(res,res$dummy==1))
[1] 24

There the number  o observatios in the two subsets is not equal.


Thanks again,

Cec?lia


________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: sexta-feira, 7 de Junho de 2013 16:43
Para: Cecilia Carmo
Cc: R help
Assunto: Re: [R] matched samples, dataframe, panel data

Hi,
Not sure if this is what you wanted.

res<-do.call(rbind,lapply(lst6,function(x) do.call(rbind,x)))
row.names(res)<-1:nrow(res)

# this combines the list of lists to a data.frame
res[1:4,]
#  firm year industry dummy dimension
#1    1 2000       20     0      2120
#2    5 2000       20     1      2189
#3    4 2000       20     0      3178
#4    7 2000       20     1      3245


#or
res<-do.call(rbind,lapply(lst6,function(x) do.call(rbind,x)))
res$group<-gsub("(.*\\..*)\\..*$","\\1",rownames(res))
row.names(res)<-1:nrow(res)
res[1:4,]
#  firm year industry dummy dimension   group
#1    1 2000       20     0      2120 2000.20   #1 group
#2    5 2000       20     1      2189 2000.20   #1
#3    4 2000       20     0      3178 2000.20   #2
#4    7 2000       20     1      3245 2000.20   #2
A.K.


----- Original Message -----
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Cc:
Sent: Friday, June 7, 2013 11:33 AM
Subject: RE: [R] matched samples, dataframe, panel data

Thank you very much.
Just a little thing: how can I put it like a dataframe?

Thanks,

Cec?lia

________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: sexta-feira, 7 de Junho de 2013 16:27
Para: Cecilia Carmo
Assunto: Re: [R] matched samples, dataframe, panel data

Hi,
There could be easier ways...  I am a bit busy now to try other ways.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Cecilia Carmo <cecilia.carmo at ua.pt>
Cc: R help <r-help at r-project.org>
Sent: Friday, June 7, 2013 11:25 AM
Subject: Re: [R] matched samples, dataframe, panel data

Hi,
May be this helps:
lst1<-split(final3,list(final3$year,final3$industry))
lst2<-lst1[lapply(lst1,nrow)>0]
lst3<-lapply(lst2,function(x) lapply(x$dimension,function(y) x[(y< (x$dimension+x$dimension*0.1)) & (y> (x$dimension-x$dimension*0.1)),]))
lst4<-lapply(lst3,function(x) x[lapply(x,nrow)==2])
lst5<-lapply(lst4,function(x)x[!duplicated(x)])
lst6<-lst5[lapply(lst5,length)>0]

names(lst6)
# [1] "2000.20" "2001.20" "2002.20" "2003.20" "2004.20" "2001.30" "2002.30"
#[8] "2001.40" "2002.40" "2003.40" "2004.40"


lst6["2000.20"]
#$`2000.20`
#$`2000.20`[[1]]
#  firm year industry dummy dimension
#1     1 2000       20     0      2120
#21    5 2000       20     1      2189
#
#$`2000.20`[[2]]
#  firm year industry dummy dimension
#16    4 2000       20     0      3178
#31    7 2000       20     1      3245
#
#$`2000.20`[[3]]
#  firm year industry dummy dimension
#11    3 2000       20     1      4532
#6     2 2000       20     0      4890
A.K.





________________________________
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: "r-help at r-project.org" <r-help at r-project.org>

Sent: Friday, June 7, 2013 9:56 AM
Subject: Re: [R] matched samples, dataframe, panel data




Again my problem, better explained.

#I have a data panel of thousands of firms, by year and industry and
#one dummy variable that identifies one kind of firms (1 if the firm have an auditor; 0 if not)
#and another variable the represents the firm dimension (total assets in thousand of euros)
#I need to create two separated samples with the same number os firms where
#one firm in the first have a corresponding firm in the second with the same
#year, industry and dimension (the dimension doesn't need to be exatly the
#same, it could vary in an interval of +/- 10%, for example)

#My reproducible example
firm1<-sort(rep(1:10,5),decreasing=F)
year1<-rep(2000:2004,10)
industry1<-rep(20,50)
dummy1<-c(0,0,1,1,0,0,1,1,0,1,1,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,1,0,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,1,1,1)
dimension1<-c(2120,345,2341,5678,10900,4890,2789,3412,9500,8765,4532,6593,12900,123,2345,3178,2678,6666,647,23789,
2189,4289,8543,637,23456,781,35489,2345,5754,8976,3245,1234,25,1200,2345,2765,389,23456,2367,3892,5438,37824,
23,2897,3456,7690,6022,3678,9431,2890)
data1<-data.frame(firm1,year1,industry1,dummy1,dimension1)
data1
colnames(data1)<-c("firm","year","industry","dummy","dimension")

firm2<-sort(rep(11:15,3),decreasing=F)
year2<-rep(2001:2003,5)
industry2<-rep(30,15)
dummy2<-c(0,0,0,0,0,0,1,1,1,1,1,1,1,0,1)
dimension2<-c(12456,781,32489,2345,5754,8976,3245,2120,345,2341,5678,10900,12900,123,2345)
data2<-data.frame(firm2,year2,industry2,dummy2,dimension2)
data2
colnames(data2)<-c("firm","year","industry","dummy","dimension")
firm3<-sort(rep(16:20,4),decreasing=F)
year3<-rep(2001:2004,5)
industry3<-rep(40,20)
dummy3<-c(0,0,1,0,1,0,1,0,1,1,1,1,1,0,0,0,0,1,0,0)
dimension3<-c(23456,1181,32489,2345,6754,8976,3245,1234,1288,1200,2345,2765,389,23456,2367,3892,6438,24824,
23,2897)
data3<-data.frame(firm3,year3,industry3,dummy3,dimension3)
data3
colnames(data3)<-c("firm","year","industry","dummy","dimension")

final1<-rbind(data1,data2)
final2<-rbind(final1,data3)
final2
final3<-final2[order(final2$year,final2$industry,final2$dimension),]
final3


#So my data is final3 is like this:
   firm year industry dummy dimension
26    6 2000       20     0       781
1     1 2000       20     0      2120
21    5 2000       20     1      2189
36    8 2000       20     1      2765
16    4 2000       20     0      3178
31    7 2000       20     1      3245
11    3 2000       20     1      4532
6     2 2000       20     0      4890
41    9 2000       20     0      5438
46   10 2000       20     0      7690
2     1 2001       20     0       345
37    8 2001       20     1       389
32    7 2001       20     0      1234
17    4 2001       20     0      2678
7     2 2001       20     1      2789
22    5 2001       20     1      4289
47   10 2001       20     0      6022
12    3 2001       20     1      6593
27    6 2001       20     0     35489
42    9 2001       20     1     37824
60   14 2001       30     1      2341
54   12 2001       30     0      2345
57   13 2001       30     1      3245
51   11 2001       30     0     12456
63   15 2001       30     1     12900
78   19 2001       40     1       389
74   18 2001       40     1      1288
82   20 2001       40     0      6438
70   17 2001       40     1      6754
66   16 2001       40     0     23456
43    9 2002       20     0        23
33    7 2002       20     1        25
3     1 2002       20     1      2341
28    6 2002       20     0      2345
8     2 2002       20     1      3412
48   10 2002       20     1      3678
18    4 2002       20     0      6666
23    5 2002       20     0      8543
13    3 2002       20     0     12900
38    8 2002       20     1     23456
64   15 2002       30     0       123
52   11 2002       30     0       781
58   13 2002       30     1      2120
61   14 2002       30     1      5678
55   12 2002       30     0      5754
67   16 2002       40     0      1181
75   18 2002       40     1      1200
71   17 2002       40     0      8976
79   19 2002       40     0     23456
83   20 2002       40     1     24824
14    3 2003       20     0       123
24    5 2003       20     0       637
19    4 2003       20     1       647
34    7 2003       20     0      1200
39    8 2003       20     1      2367
44    9 2003       20     0      2897
4     1 2003       20     1      5678
29    6 2003       20     0      5754
49   10 2003       20     1      9431
9     2 2003       20     0      9500
59   13 2003       30     1       345
65   15 2003       30     1      2345
56   12 2003       30     0      8976
62   14 2003       30     1     10900
53   11 2003       30     0     32489
84   20 2003       40     0        23
76   18 2003       40     1      2345
80   19 2003       40     0      2367
72   17 2003       40     1      3245
68   16 2003       40     1     32489
15    3 2004       20     0      2345
35    7 2004       20     1      2345
50   10 2004       20     1      2890
45    9 2004       20     0      3456
40    8 2004       20     0      3892
10    2 2004       20     1      8765
30    6 2004       20     0      8976
5     1 2004       20     0     10900
25    5 2004       20     0     23456
20    4 2004       20     1     23789
73   17 2004       40     0      1234
69   16 2004       40     0      2345
77   18 2004       40     1      2765
85   20 2004       40     0      2897
81   19 2004       40     0      3892

I want to keep couples of firms one with dummy=1 and other with dummy=0 that matchs in industry, firm and dimension.

But dimension doesn't need to be exactly the same, it is why I refer an interval of + or - 10%.

For example firm 1 matchs with firm 5, because they have the same year, industry, dimension (10% x 2120 = 212 and 2189-2120<212)
and firm 1 is dummy=0 and firm 5 is dummy=1.

So I want to delete firm 6 because it doesn't macth with any firm, and keep firm 1 and 5.

     firm year industry dummy dimension
26    6 2000       20     0       781
1     1 2000       20     0      2120
21    5 2000       20     1      2189

Next,

Now I can match firm 4 with firm 7 and delete firm 8.
36    8 2000       20     1      2765
16    4 2000       20     0      3178
31    7 2000       20     1      3245

And so on...

At the end I want to keep only pairs of firms, matched by year, industry and dimension.

If I separate firms with dummy=1 from firms with dummy=0 in two separated dataframes, I have two matched samples
with the same number of observations. That's what I want.

Thank you,
Cec?lia Carmo
Universidade de Aveiro - Portugal

From smartpink111 at yahoo.com  Sat Jun  8 00:29:55 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 7 Jun 2013 15:29:55 -0700 (PDT)
Subject: [R] matched samples, dataframe, panel data
In-Reply-To: <104083AE5AAA634C993249DFCCE4C203064396CE@CIPRESTE.ua.pt>
References: <104083AE5AAA634C993249DFCCE4C20306439641@CIPRESTE.ua.pt>
	<1370618741.16808.YahooMailNeo@web142605.mail.bf1.yahoo.com>,
	<1370618875.52646.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<104083AE5AAA634C993249DFCCE4C20306439664@CIPRESTE.ua.pt>,
	<1370619793.18982.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<104083AE5AAA634C993249DFCCE4C2030643969E@CIPRESTE.ua.pt>,
	<1370622636.62630.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<104083AE5AAA634C993249DFCCE4C203064396BF@CIPRESTE.ua.pt>,
	<1370642673.28997.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<104083AE5AAA634C993249DFCCE4C203064396CE@CIPRESTE.ua.pt>
Message-ID: <1370644195.96297.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
If i replace `lst3` with:

lst1<-split(final3,list(final3$year,final3$industry))
lst2<-lst1[lapply(lst1,nrow)>0]
lst3<-lapply(lst2,function(x) lapply(x$dimension,function(y) {x1<-x[(y< (x$dimension+x$dimension*0.1)) & (y> (x$dimension-x$dimension*0.1)),]; x1[abs(diff(x1$dimension))<200,]})) ###changed

lst4<-lapply(lst3,function(x) x[lapply(x,nrow)==2])
lst5<-lapply(lst4,function(x)x[!duplicated(x)])
lst6<-lst5[lapply(lst5,length)>0]
lst7<-lapply(lst6,function(x) {lst<-lapply(x,function(y) y[sum(y$dummy)==1,]);lst[lapply(lst,nrow)>0]})
res2<-do.call(rbind,lapply(lst7,function(x) do.call(rbind,x)))
?identical(res1,res2)
#[1] TRUE
A.K.



----- Original Message -----
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Cc: R help <r-help at r-project.org>
Sent: Friday, June 7, 2013 6:10 PM
Subject: RE: [R] matched samples, dataframe, panel data

Maybe the final result is the same, but I want to impose it on final3, when we are matching the firms.

Thanks,
Cec?lia



________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: sexta-feira, 7 de Junho de 2013 23:04
Para: Cecilia Carmo
Cc: R help
Assunto: Re: [R] matched samples, dataframe, panel data

HI,
Do you want to impose this on 'res' on 'final3'?
If it is on `res`:
res1<-do.call(rbind,lapply(split(res,(1:nrow(res)-1)%/%2+1),function(x) x[abs(diff(x$dimension))<200,]))
row.names(res1)<-1:nrow(res1)
nrow(subset(res1,dummy==0))
#[1] 14
nrow(subset(res1,dummy==1))
#[1] 14

head(res1)
#? firm year industry dummy dimension
#1? ? 1 2000? ? ?  20? ?  0? ? ? 2120
#2? ? 5 2000? ? ?  20? ?  1? ? ? 2189
#3? ? 4 2000? ? ?  20? ?  0? ? ? 3178
#4? ? 7 2000? ? ?  20? ?  1? ? ? 3245
#5? ? 4 2001? ? ?  20? ?  0? ? ? 2678
#6? ? 2 2001? ? ?  20? ?  1? ? ? 2789
A.K.



----- Original Message -----
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: R help <r-help at r-project.org>
Cc: arun <smartpink111 at yahoo.com>
Sent: Friday, June 7, 2013 5:51 PM
Subject: RE: [R] matched samples, dataframe, panel data

Thank you very much.

I apologize but I want to ask only one more thing:

How to do if I want in addition to impose that the diffence between
dimensions doesn't exced an absolute value, for example, 200.

Firm 1 continues matching with firm 5 in year 2000 because
2189-2120=69, and 69 is < 10%x2120=212, and 69 is also < 200

But firm 20 doesn't match with firm 17 in year 2001
because 6754-6438=316, and 316 is < 10%x6438=643.8, but 316 is > 200


Thank you

Cec?lia

________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: sexta-feira, 7 de Junho de 2013 17:30
Para: Cecilia Carmo
Cc: R help
Assunto: Re: [R] matched samples, dataframe, panel data

Sorry, it included a case with both values for dummy were 1.

lst7<-lapply(lst6,function(x) {lst<-lapply(x,function(y) y[sum(y$dummy)==1,]);lst[lapply(lst,nrow)>0]})

res<-do.call(rbind,lapply(lst7,function(x) do.call(rbind,x)))
row.names(res)<-1:nrow(res)
nrow(subset(res,dummy==0))
#[1] 22
nrow(subset(res,dummy==1))
#[1] 22
A.K.



----- Original Message -----
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Cc: R help <r-help at r-project.org>
Sent: Friday, June 7, 2013 12:03 PM
Subject: RE: [R] matched samples, dataframe, panel data

Sorry,

Something is not ok, because when? I do

> nrow(subset(res,res$dummy==0))
[1] 22
> nrow(subset(res,res$dummy==1))
[1] 24

There the number? o observatios in the two subsets is not equal.


Thanks again,

Cec?lia


________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: sexta-feira, 7 de Junho de 2013 16:43
Para: Cecilia Carmo
Cc: R help
Assunto: Re: [R] matched samples, dataframe, panel data

Hi,
Not sure if this is what you wanted.

res<-do.call(rbind,lapply(lst6,function(x) do.call(rbind,x)))
row.names(res)<-1:nrow(res)

# this combines the list of lists to a data.frame
res[1:4,]
#? firm year industry dummy dimension
#1? ? 1 2000? ? ?  20? ?  0? ? ? 2120
#2? ? 5 2000? ? ?  20? ?  1? ? ? 2189
#3? ? 4 2000? ? ?  20? ?  0? ? ? 3178
#4? ? 7 2000? ? ?  20? ?  1? ? ? 3245


#or
res<-do.call(rbind,lapply(lst6,function(x) do.call(rbind,x)))
res$group<-gsub("(.*\\..*)\\..*$","\\1",rownames(res))
row.names(res)<-1:nrow(res)
res[1:4,]
#? firm year industry dummy dimension?  group
#1? ? 1 2000? ? ?  20? ?  0? ? ? 2120 2000.20?  #1 group
#2? ? 5 2000? ? ?  20? ?  1? ? ? 2189 2000.20?  #1
#3? ? 4 2000? ? ?  20? ?  0? ? ? 3178 2000.20?  #2
#4? ? 7 2000? ? ?  20? ?  1? ? ? 3245 2000.20?  #2
A.K.


----- Original Message -----
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Cc:
Sent: Friday, June 7, 2013 11:33 AM
Subject: RE: [R] matched samples, dataframe, panel data

Thank you very much.
Just a little thing: how can I put it like a dataframe?

Thanks,

Cec?lia

________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: sexta-feira, 7 de Junho de 2013 16:27
Para: Cecilia Carmo
Assunto: Re: [R] matched samples, dataframe, panel data

Hi,
There could be easier ways...? I am a bit busy now to try other ways.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Cecilia Carmo <cecilia.carmo at ua.pt>
Cc: R help <r-help at r-project.org>
Sent: Friday, June 7, 2013 11:25 AM
Subject: Re: [R] matched samples, dataframe, panel data

Hi,
May be this helps:
lst1<-split(final3,list(final3$year,final3$industry))
lst2<-lst1[lapply(lst1,nrow)>0]
lst3<-lapply(lst2,function(x) lapply(x$dimension,function(y) x[(y< (x$dimension+x$dimension*0.1)) & (y> (x$dimension-x$dimension*0.1)),]))
lst4<-lapply(lst3,function(x) x[lapply(x,nrow)==2])
lst5<-lapply(lst4,function(x)x[!duplicated(x)])
lst6<-lst5[lapply(lst5,length)>0]

names(lst6)
# [1] "2000.20" "2001.20" "2002.20" "2003.20" "2004.20" "2001.30" "2002.30"
#[8] "2001.40" "2002.40" "2003.40" "2004.40"


lst6["2000.20"]
#$`2000.20`
#$`2000.20`[[1]]
#? firm year industry dummy dimension
#1? ?  1 2000? ? ?  20? ?  0? ? ? 2120
#21? ? 5 2000? ? ?  20? ?  1? ? ? 2189
#
#$`2000.20`[[2]]
#? firm year industry dummy dimension
#16? ? 4 2000? ? ?  20? ?  0? ? ? 3178
#31? ? 7 2000? ? ?  20? ?  1? ? ? 3245
#
#$`2000.20`[[3]]
#? firm year industry dummy dimension
#11? ? 3 2000? ? ?  20? ?  1? ? ? 4532
#6? ?  2 2000? ? ?  20? ?  0? ? ? 4890
A.K.





________________________________
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: "smartpink111 at yahoo.com" <smartpink111 at yahoo.com>
Sent: Friday, June 7, 2013 9:56 AM
Subject: Re: [R] matched samples, dataframe, panel data




Again my problem, better explained.

#I have a data panel of thousands of firms, by year and industry and
#one dummy variable that identifies one kind of firms (1 if the firm have an auditor; 0 if not)
#and another variable the represents the firm dimension (total assets in thousand of euros)
#I need to create two separated samples with the same number os firms where
#one firm in the first have a corresponding firm in the second with the same
#year, industry and dimension (the dimension doesn't need to be exatly the
#same, it could vary in an interval of +/- 10%, for example)

#My reproducible example
firm1<-sort(rep(1:10,5),decreasing=F)
year1<-rep(2000:2004,10)
industry1<-rep(20,50)
dummy1<-c(0,0,1,1,0,0,1,1,0,1,1,1,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,0,0,1,0,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,1,1,1)
dimension1<-c(2120,345,2341,5678,10900,4890,2789,3412,9500,8765,4532,6593,12900,123,2345,3178,2678,6666,647,23789,
2189,4289,8543,637,23456,781,35489,2345,5754,8976,3245,1234,25,1200,2345,2765,389,23456,2367,3892,5438,37824,
23,2897,3456,7690,6022,3678,9431,2890)
data1<-data.frame(firm1,year1,industry1,dummy1,dimension1)
data1
colnames(data1)<-c("firm","year","industry","dummy","dimension")

firm2<-sort(rep(11:15,3),decreasing=F)
year2<-rep(2001:2003,5)
industry2<-rep(30,15)
dummy2<-c(0,0,0,0,0,0,1,1,1,1,1,1,1,0,1)
dimension2<-c(12456,781,32489,2345,5754,8976,3245,2120,345,2341,5678,10900,12900,123,2345)
data2<-data.frame(firm2,year2,industry2,dummy2,dimension2)
data2
colnames(data2)<-c("firm","year","industry","dummy","dimension")
firm3<-sort(rep(16:20,4),decreasing=F)
year3<-rep(2001:2004,5)
industry3<-rep(40,20)
dummy3<-c(0,0,1,0,1,0,1,0,1,1,1,1,1,0,0,0,0,1,0,0)
dimension3<-c(23456,1181,32489,2345,6754,8976,3245,1234,1288,1200,2345,2765,389,23456,2367,3892,6438,24824,
23,2897)
data3<-data.frame(firm3,year3,industry3,dummy3,dimension3)
data3
colnames(data3)<-c("firm","year","industry","dummy","dimension")

final1<-rbind(data1,data2)
final2<-rbind(final1,data3)
final2
final3<-final2[order(final2$year,final2$industry,final2$dimension),]
final3


#So my data is final3 is like this:
?  firm year industry dummy dimension
26? ? 6 2000? ? ?  20? ?  0? ? ?  781
1? ?  1 2000? ? ?  20? ?  0? ? ? 2120
21? ? 5 2000? ? ?  20? ?  1? ? ? 2189
36? ? 8 2000? ? ?  20? ?  1? ? ? 2765
16? ? 4 2000? ? ?  20? ?  0? ? ? 3178
31? ? 7 2000? ? ?  20? ?  1? ? ? 3245
11? ? 3 2000? ? ?  20? ?  1? ? ? 4532
6? ?  2 2000? ? ?  20? ?  0? ? ? 4890
41? ? 9 2000? ? ?  20? ?  0? ? ? 5438
46?  10 2000? ? ?  20? ?  0? ? ? 7690
2? ?  1 2001? ? ?  20? ?  0? ? ?  345
37? ? 8 2001? ? ?  20? ?  1? ? ?  389
32? ? 7 2001? ? ?  20? ?  0? ? ? 1234
17? ? 4 2001? ? ?  20? ?  0? ? ? 2678
7? ?  2 2001? ? ?  20? ?  1? ? ? 2789
22? ? 5 2001? ? ?  20? ?  1? ? ? 4289
47?  10 2001? ? ?  20? ?  0? ? ? 6022
12? ? 3 2001? ? ?  20? ?  1? ? ? 6593
27? ? 6 2001? ? ?  20? ?  0? ?  35489
42? ? 9 2001? ? ?  20? ?  1? ?  37824
60?  14 2001? ? ?  30? ?  1? ? ? 2341
54?  12 2001? ? ?  30? ?  0? ? ? 2345
57?  13 2001? ? ?  30? ?  1? ? ? 3245
51?  11 2001? ? ?  30? ?  0? ?  12456
63?  15 2001? ? ?  30? ?  1? ?  12900
78?  19 2001? ? ?  40? ?  1? ? ?  389
74?  18 2001? ? ?  40? ?  1? ? ? 1288
82?  20 2001? ? ?  40? ?  0? ? ? 6438
70?  17 2001? ? ?  40? ?  1? ? ? 6754
66?  16 2001? ? ?  40? ?  0? ?  23456
43? ? 9 2002? ? ?  20? ?  0? ? ? ? 23
33? ? 7 2002? ? ?  20? ?  1? ? ? ? 25
3? ?  1 2002? ? ?  20? ?  1? ? ? 2341
28? ? 6 2002? ? ?  20? ?  0? ? ? 2345
8? ?  2 2002? ? ?  20? ?  1? ? ? 3412
48?  10 2002? ? ?  20? ?  1? ? ? 3678
18? ? 4 2002? ? ?  20? ?  0? ? ? 6666
23? ? 5 2002? ? ?  20? ?  0? ? ? 8543
13? ? 3 2002? ? ?  20? ?  0? ?  12900
38? ? 8 2002? ? ?  20? ?  1? ?  23456
64?  15 2002? ? ?  30? ?  0? ? ?  123
52?  11 2002? ? ?  30? ?  0? ? ?  781
58?  13 2002? ? ?  30? ?  1? ? ? 2120
61?  14 2002? ? ?  30? ?  1? ? ? 5678
55?  12 2002? ? ?  30? ?  0? ? ? 5754
67?  16 2002? ? ?  40? ?  0? ? ? 1181
75?  18 2002? ? ?  40? ?  1? ? ? 1200
71?  17 2002? ? ?  40? ?  0? ? ? 8976
79?  19 2002? ? ?  40? ?  0? ?  23456
83?  20 2002? ? ?  40? ?  1? ?  24824
14? ? 3 2003? ? ?  20? ?  0? ? ?  123
24? ? 5 2003? ? ?  20? ?  0? ? ?  637
19? ? 4 2003? ? ?  20? ?  1? ? ?  647
34? ? 7 2003? ? ?  20? ?  0? ? ? 1200
39? ? 8 2003? ? ?  20? ?  1? ? ? 2367
44? ? 9 2003? ? ?  20? ?  0? ? ? 2897
4? ?  1 2003? ? ?  20? ?  1? ? ? 5678
29? ? 6 2003? ? ?  20? ?  0? ? ? 5754
49?  10 2003? ? ?  20? ?  1? ? ? 9431
9? ?  2 2003? ? ?  20? ?  0? ? ? 9500
59?  13 2003? ? ?  30? ?  1? ? ?  345
65?  15 2003? ? ?  30? ?  1? ? ? 2345
56?  12 2003? ? ?  30? ?  0? ? ? 8976
62?  14 2003? ? ?  30? ?  1? ?  10900
53?  11 2003? ? ?  30? ?  0? ?  32489
84?  20 2003? ? ?  40? ?  0? ? ? ? 23
76?  18 2003? ? ?  40? ?  1? ? ? 2345
80?  19 2003? ? ?  40? ?  0? ? ? 2367
72?  17 2003? ? ?  40? ?  1? ? ? 3245
68?  16 2003? ? ?  40? ?  1? ?  32489
15? ? 3 2004? ? ?  20? ?  0? ? ? 2345
35? ? 7 2004? ? ?  20? ?  1? ? ? 2345
50?  10 2004? ? ?  20? ?  1? ? ? 2890
45? ? 9 2004? ? ?  20? ?  0? ? ? 3456
40? ? 8 2004? ? ?  20? ?  0? ? ? 3892
10? ? 2 2004? ? ?  20? ?  1? ? ? 8765
30? ? 6 2004? ? ?  20? ?  0? ? ? 8976
5? ?  1 2004? ? ?  20? ?  0? ?  10900
25? ? 5 2004? ? ?  20? ?  0? ?  23456
20? ? 4 2004? ? ?  20? ?  1? ?  23789
73?  17 2004? ? ?  40? ?  0? ? ? 1234
69?  16 2004? ? ?  40? ?  0? ? ? 2345
77?  18 2004? ? ?  40? ?  1? ? ? 2765
85?  20 2004? ? ?  40? ?  0? ? ? 2897
81?  19 2004? ? ?  40? ?  0? ? ? 3892

I want to keep couples of firms one with dummy=1 and other with dummy=0 that matchs in industry, firm and dimension.

But dimension doesn't need to be exactly the same, it is why I refer an interval of + or - 10%.

For example firm 1 matchs with firm 5, because they have the same year, industry, dimension (10% x 2120 = 212 and 2189-2120<212)
and firm 1 is dummy=0 and firm 5 is dummy=1.

So I want to delete firm 6 because it doesn't macth with any firm, and keep firm 1 and 5.

? ?  firm year industry dummy dimension
26? ? 6 2000? ? ?  20? ?  0? ? ?  781
1? ?  1 2000? ? ?  20? ?  0? ? ? 2120
21? ? 5 2000? ? ?  20? ?  1? ? ? 2189

Next,

Now I can match firm 4 with firm 7 and delete firm 8.
36? ? 8 2000? ? ?  20? ?  1? ? ? 2765
16? ? 4 2000? ? ?  20? ?  0? ? ? 3178
31? ? 7 2000? ? ?  20? ?  1? ? ? 3245

And so on...

At the end I want to keep only pairs of firms, matched by year, industry and dimension.

If I separate firms with dummy=1 from firms with dummy=0 in two separated dataframes, I have two matched samples
with the same number of observations. That's what I want.

Thank you,
Cec?lia Carmo
Universidade de Aveiro - Portugal


From davidmarino838 at gmail.com  Sat Jun  8 00:54:23 2013
From: davidmarino838 at gmail.com (Marino David)
Date: Sat, 8 Jun 2013 06:54:23 +0800
Subject: [R] It seams that fast99 function (sensitivity package) does not
 work out for norm distribution.
Message-ID: <CABmD0bFA0Q_HNQ-4+Z2rKftO=MYtEAjAz7qajKszJ2hK-TQBVA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130608/ff11b7f2/attachment.pl>

From annijanh at gmail.com  Sat Jun  8 01:15:00 2013
From: annijanh at gmail.com (Janh Anni)
Date: Fri, 7 Jun 2013 19:15:00 -0400
Subject: [R] Trying to install NADA in R 3.0.0
In-Reply-To: <CACftpvqOat_jqDZZYmrTESKzamATn6PcY-UhtaiJ91fiWAoEVA@mail.gmail.com>
References: <CACftpvqOat_jqDZZYmrTESKzamATn6PcY-UhtaiJ91fiWAoEVA@mail.gmail.com>
Message-ID: <CAFCoDdAe2vYvi5v9QGMLYsLoqu+qw+Rr0NR2pJxq5pde7zFiOw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/262004f0/attachment.pl>

From rolf.turner at xtra.co.nz  Sat Jun  8 01:17:25 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Sat, 08 Jun 2013 11:17:25 +1200
Subject: [R] SPlus script
In-Reply-To: <51B1BE97.7090006@gmail.com>
References: <1370438435.93923.YahooMailNeo@web142703.mail.bf1.yahoo.com>
	<E66794E69CFDE04D9A70842786030B931C2FD5C4@PA-MBX01.na.tibco.com>
	<1370523739.92423.YahooMailNeo@web142703.mail.bf1.yahoo.com>
	<CA+vqiLGCTXQDEzzbeZDf-_EddiGQ=xx4P9n_3EJ2HkN1-qTMQg@mail.gmail.com>
	<1370531969.88020.YahooMailNeo@web142705.mail.bf1.yahoo.com>
	<51B10B9A.5060406@xtra.co.nz> <51B1BE97.7090006@gmail.com>
Message-ID: <51B26A05.4010800@xtra.co.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130608/1ae8597b/attachment.pl>

From rshepard at appl-ecosys.com  Sat Jun  8 01:23:31 2013
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Fri, 7 Jun 2013 16:23:31 -0700 (PDT)
Subject: [R] Trying to install NADA in R 3.0.0
In-Reply-To: <CAFCoDdAe2vYvi5v9QGMLYsLoqu+qw+Rr0NR2pJxq5pde7zFiOw@mail.gmail.com>
References: <CACftpvqOat_jqDZZYmrTESKzamATn6PcY-UhtaiJ91fiWAoEVA@mail.gmail.com>
	<CAFCoDdAe2vYvi5v9QGMLYsLoqu+qw+Rr0NR2pJxq5pde7zFiOw@mail.gmail.com>
Message-ID: <alpine.LNX.2.00.1306071620090.9300@salmo.appl-ecosys.com>

On Fri, 7 Jun 2013, Janh Anni wrote:

> Try contacting Dr Dennis Helsel, the developer at
> dhelsel at practicalstats.com

   I don't know what OS David's using, nor if R-3.0.0 is an upgrade or a new
installation, but I had no issues when upgrading R from the last 2.x
version. The existing NADA in the system library works with 3.x. I'm running
Slackware-13.1 and -14.0.

   Iniially I ran install.packages("NADA"), selected the closest repository,
and had a working package available for use.

Rich

-- 
Richard B. Shepard, Ph.D.          |      Have knowledge, will travel.
Applied Ecosystem Services, Inc.   |
<http://www.appl-ecosys.com>     Voice: 503-667-4517      Fax: 503-667-8863


From wdunlap at tibco.com  Sat Jun  8 01:33:45 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 7 Jun 2013 23:33:45 +0000
Subject: [R] SPlus script
In-Reply-To: <51B26A05.4010800@xtra.co.nz>
References: <1370438435.93923.YahooMailNeo@web142703.mail.bf1.yahoo.com>
	<E66794E69CFDE04D9A70842786030B931C2FD5C4@PA-MBX01.na.tibco.com>
	<1370523739.92423.YahooMailNeo@web142703.mail.bf1.yahoo.com>
	<CA+vqiLGCTXQDEzzbeZDf-_EddiGQ=xx4P9n_3EJ2HkN1-qTMQg@mail.gmail.com>
	<1370531969.88020.YahooMailNeo@web142705.mail.bf1.yahoo.com>
	<51B10B9A.5060406@xtra.co.nz> <51B1BE97.7090006@gmail.com>
	<51B26A05.4010800@xtra.co.nz>
Message-ID: <E66794E69CFDE04D9A70842786030B931C300641@PA-MBX01.na.tibco.com>

>      foo <- function(x) {
>          sin(42)
>          x^2
>      }
> 
>      foo(3)
>      [1] 9
> 
> The value of sin(42) is never seen.

This is true in both R and S+.  Only the return value of a function is available
for autoprinting and sin(42) is not the return value.  Perhaps you are remembering
the case where the last subexpression in the function is an assignment, in which
case S+ autoprints its value but R does not.

  R> f <- function(x) { y <- x + 1 }
  R> f(10)
  R> .Last.value
  [1] 11

  S+> f <- function(x) { y <- x + 1 }
  Warning messages:
    Last expression in function is an assignment
                  (You probably wanted to return the left-hand side)
           in: y <- x + 1
  S+> f(10)
  [1] 11
  S+> .Last.value
  [1] 11

Autoprinting is implemented quite differently in R and S+.  I think R attaches
the autoprint flag to the returned object while S+ assigns .Auto.print<-TRUE
in the frame of the caller (yuck).  That leads to differences like the following

  R> f <- function(x) invisible(x+1)
  R> g <- function(x) 10 * x
  R> g(f(23)) # g() and f() are evaluated in same frame
  [1] 240
  R> .Last.value
  [1] 240

  S+> f <- function(x) invisible(x+1)
  S+> g <- function(x) 10 * x
  S+> g(f(23)) # g() and f() are evaluated in same frame
  S+> .Last.value
  [1] 240

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Rolf Turner
> Sent: Friday, June 07, 2013 4:17 PM
> To: Duncan Murdoch
> Cc: r-help at r-project.org; Scott Raynaud
> Subject: Re: [R] SPlus script
> 
> On 07/06/13 23:05, Duncan Murdoch wrote:
> > On 13-06-06 6:22 PM, Rolf Turner wrote:
> >> On 07/06/13 03:19, Scott Raynaud wrote:
> >>> I actually had tried placing arguments in the call but it didn't
> >>> work.   However, I did
> >>> not think about writing it to a variable and printing.  That seems
> >>> to have done the
> >>> trick.  Funny, I don't remember having to do that before, but that's
> >>> not surprising.
> >>>
> >>
> >> If I remember correctly --- haven't used Splus for decades --- this is a
> >> difference
> >> between Splus and R.
> >>
> >> In R the output of a function is returned *invisibly* if that function
> >> is called
> >> from within another function.  And source() is one such other function.
> >
> > Actually this depends on the caller.  source() does return its results
> > invisibly, but many other functions don't.
> 
>  From FAQ 7.16:
> > If you type '1+1' or 'summary(glm(y~x+z, family=binomial))' at the
> > command line the returned value is automatically printed (unless it is
> > |invisible()|), but in other circumstances, such as in a |source()|d
> > file or ***inside a function*** it isn't printed unless you
> > specifically print it.
> 
> (Emphasis added.)
> 
> I think that you have misinterpreted what I wrote.  Many (most?) functions
> *return* their results (values) visibly.  But if you put an expression
> into the code
> of that function (an expression which is not part of the returned value)
> you never
> see the result of evaluating that expression.
> 
> E.g.:
> 
>      foo <- function(x) {
>          sin(42)
>          x^2
>      }
> 
>      foo(3)
>      [1] 9
> 
> The value of sin(42) is never seen.
> 
> The main point however is that IIRC Splus is different from R in respect
> of whether the values of (un-assigned) expressions inside source are
> visible.  In R they are invisible; in Splus I *believe* (vaguely recall)
> that
> they are visible.  I cannot check this since I have no access to Splus.
> 
> I do wish someone would confirm (or deny, as the case may be) that
> my recollections about Splus are correct.
> 
>      cheers,
> 
>          Rolf
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rolf.turner at xtra.co.nz  Sat Jun  8 01:45:48 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Sat, 08 Jun 2013 11:45:48 +1200
Subject: [R] SPlus script
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C300641@PA-MBX01.na.tibco.com>
References: <1370438435.93923.YahooMailNeo@web142703.mail.bf1.yahoo.com>
	<E66794E69CFDE04D9A70842786030B931C2FD5C4@PA-MBX01.na.tibco.com>
	<1370523739.92423.YahooMailNeo@web142703.mail.bf1.yahoo.com>
	<CA+vqiLGCTXQDEzzbeZDf-_EddiGQ=xx4P9n_3EJ2HkN1-qTMQg@mail.gmail.com>
	<1370531969.88020.YahooMailNeo@web142705.mail.bf1.yahoo.com>
	<51B10B9A.5060406@xtra.co.nz> <51B1BE97.7090006@gmail.com>
	<51B26A05.4010800@xtra.co.nz>
	<E66794E69CFDE04D9A70842786030B931C300641@PA-MBX01.na.tibco.com>
Message-ID: <51B270AC.7080204@xtra.co.nz>


Very interesting.  But what explicitly happens with ***source()***
in Splus???

     cheers,

         Rolf

On 08/06/13 11:33, William Dunlap wrote:
>>       foo <- function(x) {
>>           sin(42)
>>           x^2
>>       }
>>
>>       foo(3)
>>       [1] 9
>>
>> The value of sin(42) is never seen.
> This is true in both R and S+.  Only the return value of a function is available
> for autoprinting and sin(42) is not the return value.  Perhaps you are remembering
> the case where the last subexpression in the function is an assignment, in which
> case S+ autoprints its value but R does not.
>
>    R> f <- function(x) { y <- x + 1 }
>    R> f(10)
>    R> .Last.value
>    [1] 11
>
>    S+> f <- function(x) { y <- x + 1 }
>    Warning messages:
>      Last expression in function is an assignment
>                    (You probably wanted to return the left-hand side)
>             in: y <- x + 1
>    S+> f(10)
>    [1] 11
>    S+> .Last.value
>    [1] 11
>
> Autoprinting is implemented quite differently in R and S+.  I think R attaches
> the autoprint flag to the returned object while S+ assigns .Auto.print<-TRUE
> in the frame of the caller (yuck).  That leads to differences like the following
>
>    R> f <- function(x) invisible(x+1)
>    R> g <- function(x) 10 * x
>    R> g(f(23)) # g() and f() are evaluated in same frame
>    [1] 240
>    R> .Last.value
>    [1] 240
>
>    S+> f <- function(x) invisible(x+1)
>    S+> g <- function(x) 10 * x
>    S+> g(f(23)) # g() and f() are evaluated in same frame
>    S+> .Last.value
>    [1] 240
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
>> Of Rolf Turner
>> Sent: Friday, June 07, 2013 4:17 PM
>> To: Duncan Murdoch
>> Cc: r-help at r-project.org; Scott Raynaud
>> Subject: Re: [R] SPlus script
>>
>> On 07/06/13 23:05, Duncan Murdoch wrote:
>>> On 13-06-06 6:22 PM, Rolf Turner wrote:
>>>> On 07/06/13 03:19, Scott Raynaud wrote:
>>>>> I actually had tried placing arguments in the call but it didn't
>>>>> work.   However, I did
>>>>> not think about writing it to a variable and printing.  That seems
>>>>> to have done the
>>>>> trick.  Funny, I don't remember having to do that before, but that's
>>>>> not surprising.
>>>>>
>>>> If I remember correctly --- haven't used Splus for decades --- this is a
>>>> difference
>>>> between Splus and R.
>>>>
>>>> In R the output of a function is returned *invisibly* if that function
>>>> is called
>>>> from within another function.  And source() is one such other function.
>>> Actually this depends on the caller.  source() does return its results
>>> invisibly, but many other functions don't.
>>   From FAQ 7.16:
>>> If you type '1+1' or 'summary(glm(y~x+z, family=binomial))' at the
>>> command line the returned value is automatically printed (unless it is
>>> |invisible()|), but in other circumstances, such as in a |source()|d
>>> file or ***inside a function*** it isn't printed unless you
>>> specifically print it.
>> (Emphasis added.)
>>
>> I think that you have misinterpreted what I wrote.  Many (most?) functions
>> *return* their results (values) visibly.  But if you put an expression
>> into the code
>> of that function (an expression which is not part of the returned value)
>> you never
>> see the result of evaluating that expression.
>>
>> E.g.:
>>
>>       foo <- function(x) {
>>           sin(42)
>>           x^2
>>       }
>>
>>       foo(3)
>>       [1] 9
>>
>> The value of sin(42) is never seen.
>>
>> The main point however is that IIRC Splus is different from R in respect
>> of whether the values of (un-assigned) expressions inside source are
>> visible.  In R they are invisible; in Splus I *believe* (vaguely recall)
>> that
>> they are visible.  I cannot check this since I have no access to Splus.
>>
>> I do wish someone would confirm (or deny, as the case may be) that
>> my recollections about Splus are correct.


From rolf.turner at xtra.co.nz  Sat Jun  8 02:21:27 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Sat, 08 Jun 2013 12:21:27 +1200
Subject: [R] estimation of covariance matrix of a bivariate normal
 distribution using maximization of the log-likelihood
In-Reply-To: <E71E7032F00FCA4AA40DC7943D3DB10E24D0BFFF@MBX12.d.ethz.ch>
References: <E71E7032F00FCA4AA40DC7943D3DB10E24D0BFFF@MBX12.d.ethz.ch>
Message-ID: <51B27907.502@xtra.co.nz>


See in line below.

On 08/06/13 00:00, Hertzog Gladys wrote:
> Dear all,
> I?m new in R and I?m trying to estimate the covariance matrix of a bivariate normal distribution by maximizing the log-likelihood. The maximization really has to be performed with the non-linear minimization routine (nlm).
Why?
> The 2 means of the distribution are known and equal to 1.
But you simulate your data using means 2.4 and 1.3.
> I?ve already tried 2 different ways to compute this covariance but for each of them I obtained a lot of warnings and illogical values for the covariance matrix.
>   
> In the first one, I defined the bivariate normal distribution with the command dmvnorm:
>   
> x<-rnorm(6000, 2.4, 0.6)
> x <- matrix(c(x), ncol=1)
Why do you use matrix() and c() here? Totally unnecessary
(and confusing).
> y<-rlnorm(6000, 1.3,0.1)
> y <- matrix(c(y), ncol=1)
> XY <- cbind(x,y)
To estimate the covariance matrix underlying the data XY you could
simply do:

M <- var(XY).

If you want to impose the constraint that the true mean vector is c(1,1)
you could do:

mu <- c(1,1)
xbar <- apply(XY,2,mean)
M <- (5999/6000)*var(XY) + (xbar-mu)%*%t(xbar-mu)

It would of course make more sense in terms of your simulated data
to use:

mu <- c(2.4,1.3)

I haven't looked at your code below any further. Too much of a mess.

cheers,

Rolf Turner
>   
> L <- function(par,x,y) {
> return (-sum(log(par[4]*dmvnorm(XY, mean=c(1,1), sigma= matrix(c(par[1], par[1]*par[2]*par[3],par[1]*par[2]*par[3], par[2] ),nrow=2, ncol=2))            )))
> }
> par.start<- c(0.5, 0.5 ,0.5 ,0.5)
> result<-nlm(L,par.start,y=y,x=x, hessian=TRUE)
> par.hat <- result$estimate
>   
> par.hatIl y a eu 32 avis (utilisez warnings() pour les visionner)
>> par.hat <- result$estimate
>> par.hat
> [1] 5.149919e+01 2.520721e+02 8.734212e-03 3.996771e+02
>> warnings()
> Messages d'avis :
> 1: In log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values) :
>    production de NaN
> 2: In nlm(L, par.start, y = y, x = x, hessian = TRUE) :
>    NA/Inf replaced by maximum positive value
> 3: In log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values) :
>    production de NaN
> 4: In nlm(L, par.start, y = y, x = x, hessian = TRUE) :
>    NA/Inf replaced by maximum positive value
> 5: In log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values) :
>    production de NaN
> 6: In nlm(L, par.start, y = y, x = x, hessian = TRUE) :
>    NA/Inf replaced by maximum positive value
> 7: In log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values) :
>    production de NaN
> 8: In nlm(L, par.start, y = y, x = x, hessian = TRUE) :
>    NA/Inf replaced by maximum positive value
> 9: In log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values) :
>    production de NaN
> 10: In nlm(L, par.start, y = y, x = x, hessian = TRUE) :
>    NA/Inf replaced by maximum positive value
> 11: In log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values) :
>    production de NaN
> 12: In nlm(L, par.start, y = y, x = x, hessian = TRUE) :
>    NA/Inf replaced by maximum positive value
> 13: In log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values) :
>    production de NaN
>   
> In the second one, I wrote step by step the bivariate normal distribution in order to have each parameter separately (not in a matrix) but it didn?t work as well:
>   
> x<-rnorm(6000, 2.4, 0.6)
> y<-rlnorm(6000, 1.3,0.1)
> L <- function(par,x,y) {
> return (-sum(log((1-par[4])*( (1/(2*pi*par[1]*par[2]*sqrt(1-par[3])))*exp(   (-1/2*(1-par[3]^2))* ((y-1)/par[2])^2 +((x-1)/par[1])^2 - 2*(y-1)*(x-1)/(par[2]*par[1])   )) )))
> }
> #par [1]= sigma_x , par [2]= sigma_y  par [3]= rho_xy  par[4] is a mixing parameter. The final step of my calculation will be to have a mixture of bivariate normal and log-normal distributions.
> par.start<- c(0.5, 0.5 ,0.5 ,0.5)
> result<-nlm(L,par.start,y=y,x=x, hessian=T)
> par.hat <- result$estimate
> par.ha
>   
> When I run this script, I get always 50 advices like those below:
> Messages d'avis :
> 1: In sqrt(1 - par[3]) : production de NaN
> 2: In nlm(L, par.start, y = y, x = x, hessian = T) :
>    NA/Inf replaced by maximum positive value
> 3: In sqrt(1 - par[3]) : production de NaN
> 4: In nlm(L, par.start, y = y, x = x, hessian = T) :
>    NA/Inf replaced by maximum positive value
> 5: In sqrt(1 - par[3]) : production de NaN
> 6: In nlm(L, par.start, y = y, x = x, hessian = T) :
>    NA/Inf replaced by maximum positive value
> 7: In log((1 - par[4]) * ((1/(2 * pi * par[1] * par[2] *  ... : production de NaN
> 8: In nlm(L, par.start, y = y, x = x, hessian = T) :
>    NA/Inf replaced by maximum positive value
> 9: In log((1 - par[4]) * ((1/(2 * pi * par[1] * par[2] *  ... : production de NaN
> 10: In nlm(L, par.start, y = y, x = x, hessian = T) :
>    NA/Inf replaced by maximum positive value
> 11: In log((1 - par[4]) * ((1/(2 * pi * par[1] * par[2] *  ... : production de NaN
> 12: In nlm(L, par.start, y = y, x = x, hessian = T) :
>    NA/Inf replaced by maximum positive value
> ??
> Does one of you know how to use the nlm method to estimate the covariance matrix (and mixing parameter ) of a bivariate normal distribution?
>   
> Thank you in advance for your help and answers.


From rtdew1 at gmail.com  Sat Jun  8 00:01:19 2013
From: rtdew1 at gmail.com (Ryan Dew)
Date: Fri, 7 Jun 2013 15:01:19 -0700
Subject: [R] optim() over bogus parameters
Message-ID: <CAEmQTHVqcJLhM7OX9EbApAof76rOW7v8CCr0fWwd43U1DMCgfA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/9b96e181/attachment.pl>

From wdunlap at tibco.com  Sat Jun  8 02:47:14 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 8 Jun 2013 00:47:14 +0000
Subject: [R] SPlus script
In-Reply-To: <51B270AC.7080204@xtra.co.nz>
References: <1370438435.93923.YahooMailNeo@web142703.mail.bf1.yahoo.com>
	<E66794E69CFDE04D9A70842786030B931C2FD5C4@PA-MBX01.na.tibco.com>
	<1370523739.92423.YahooMailNeo@web142703.mail.bf1.yahoo.com>
	<CA+vqiLGCTXQDEzzbeZDf-_EddiGQ=xx4P9n_3EJ2HkN1-qTMQg@mail.gmail.com>
	<1370531969.88020.YahooMailNeo@web142705.mail.bf1.yahoo.com>
	<51B10B9A.5060406@xtra.co.nz> <51B1BE97.7090006@gmail.com>
	<51B26A05.4010800@xtra.co.nz>
	<E66794E69CFDE04D9A70842786030B931C300641@PA-MBX01.na.tibco.com>
	<51B270AC.7080204@xtra.co.nz>
Message-ID: <E66794E69CFDE04D9A70842786030B931C300681@PA-MBX01.na.tibco.com>

> Very interesting.  But what explicitly happens with ***source()***
> in Splus???

Here are some examples where I use the exprs argument instead of making a
tempory file and source the file.  I don't know what you are looking for.
(The OP never showed any calls to the functions in defined in his script, so
I don't know what he was doing either.)

  S+>  source( exprs = expression( 12:15, invisible(1/9), log2(1:10)), auto.print=TRUE)
  S+> 12:15
  [1] 12 13 14 15
  S+> invisible(1/9)
  S+> log2(1:10)
   [1] 0.000000 1.000000 1.584963 2.000000 2.321928 2.584963 2.807355 3.000000
   [9] 3.169925 3.321928

  S+> source( exprs = expression( 12:15, invisible(1/9), log2(1:10)), auto.print=TRUE, echo=FALSE)
  [1] 12 13 14 15
   [1] 0.000000 1.000000 1.584963 2.000000 2.321928 2.584963 2.807355 3.000000
   [9] 3.169925 3.321928

  S+> source( exprs = expression( { 12:15 ; log2(1:10) } ), auto.print=TRUE)
  S+> {
          12:15
          log2(1:10)
  }
   [1] 0.000000 1.000000 1.584963 2.000000 2.321928 2.584963 2.807355 3.000000
   [9] 3.169925 3.321928

The next doesn't autoprint because invisible() sets the autprint flag to FALSE in the
caller's frame:
  S+> source( exprs = expression( { 12:15 ; invisible(1/9) ; log2(1:10) } ), auto.print=TRUE)
  S+> {
          12:15
          invisible(1/9)
          log2(1:10)
  }


Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: Rolf Turner [mailto:rolf.turner at xtra.co.nz]
> Sent: Friday, June 07, 2013 4:46 PM
> To: William Dunlap
> Cc: r-help at r-project.org
> Subject: Re: [R] SPlus script
> 
> 
> Very interesting.  But what explicitly happens with ***source()***
> in Splus???
> 
>      cheers,
> 
>          Rolf
> 
> On 08/06/13 11:33, William Dunlap wrote:
> >>       foo <- function(x) {
> >>           sin(42)
> >>           x^2
> >>       }
> >>
> >>       foo(3)
> >>       [1] 9
> >>
> >> The value of sin(42) is never seen.
> > This is true in both R and S+.  Only the return value of a function is available
> > for autoprinting and sin(42) is not the return value.  Perhaps you are remembering
> > the case where the last subexpression in the function is an assignment, in which
> > case S+ autoprints its value but R does not.
> >
> >    R> f <- function(x) { y <- x + 1 }
> >    R> f(10)
> >    R> .Last.value
> >    [1] 11
> >
> >    S+> f <- function(x) { y <- x + 1 }
> >    Warning messages:
> >      Last expression in function is an assignment
> >                    (You probably wanted to return the left-hand side)
> >             in: y <- x + 1
> >    S+> f(10)
> >    [1] 11
> >    S+> .Last.value
> >    [1] 11
> >
> > Autoprinting is implemented quite differently in R and S+.  I think R attaches
> > the autoprint flag to the returned object while S+ assigns .Auto.print<-TRUE
> > in the frame of the caller (yuck).  That leads to differences like the following
> >
> >    R> f <- function(x) invisible(x+1)
> >    R> g <- function(x) 10 * x
> >    R> g(f(23)) # g() and f() are evaluated in same frame
> >    [1] 240
> >    R> .Last.value
> >    [1] 240
> >
> >    S+> f <- function(x) invisible(x+1)
> >    S+> g <- function(x) 10 * x
> >    S+> g(f(23)) # g() and f() are evaluated in same frame
> >    S+> .Last.value
> >    [1] 240
> >
> > Bill Dunlap
> > Spotfire, TIBCO Software
> > wdunlap tibco.com
> >
> >
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
> Behalf
> >> Of Rolf Turner
> >> Sent: Friday, June 07, 2013 4:17 PM
> >> To: Duncan Murdoch
> >> Cc: r-help at r-project.org; Scott Raynaud
> >> Subject: Re: [R] SPlus script
> >>
> >> On 07/06/13 23:05, Duncan Murdoch wrote:
> >>> On 13-06-06 6:22 PM, Rolf Turner wrote:
> >>>> On 07/06/13 03:19, Scott Raynaud wrote:
> >>>>> I actually had tried placing arguments in the call but it didn't
> >>>>> work.   However, I did
> >>>>> not think about writing it to a variable and printing.  That seems
> >>>>> to have done the
> >>>>> trick.  Funny, I don't remember having to do that before, but that's
> >>>>> not surprising.
> >>>>>
> >>>> If I remember correctly --- haven't used Splus for decades --- this is a
> >>>> difference
> >>>> between Splus and R.
> >>>>
> >>>> In R the output of a function is returned *invisibly* if that function
> >>>> is called
> >>>> from within another function.  And source() is one such other function.
> >>> Actually this depends on the caller.  source() does return its results
> >>> invisibly, but many other functions don't.
> >>   From FAQ 7.16:
> >>> If you type '1+1' or 'summary(glm(y~x+z, family=binomial))' at the
> >>> command line the returned value is automatically printed (unless it is
> >>> |invisible()|), but in other circumstances, such as in a |source()|d
> >>> file or ***inside a function*** it isn't printed unless you
> >>> specifically print it.
> >> (Emphasis added.)
> >>
> >> I think that you have misinterpreted what I wrote.  Many (most?) functions
> >> *return* their results (values) visibly.  But if you put an expression
> >> into the code
> >> of that function (an expression which is not part of the returned value)
> >> you never
> >> see the result of evaluating that expression.
> >>
> >> E.g.:
> >>
> >>       foo <- function(x) {
> >>           sin(42)
> >>           x^2
> >>       }
> >>
> >>       foo(3)
> >>       [1] 9
> >>
> >> The value of sin(42) is never seen.
> >>
> >> The main point however is that IIRC Splus is different from R in respect
> >> of whether the values of (un-assigned) expressions inside source are
> >> visible.  In R they are invisible; in Splus I *believe* (vaguely recall)
> >> that
> >> they are visible.  I cannot check this since I have no access to Splus.
> >>
> >> I do wish someone would confirm (or deny, as the case may be) that
> >> my recollections about Splus are correct.


From pauljohn32 at gmail.com  Sat Jun  8 03:13:34 2013
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Fri, 7 Jun 2013 20:13:34 -0500
Subject: [R] recode: how to avoid nested ifelse
Message-ID: <CAErODj8Tr6KBNweyFy2kXYmqn-CEs=cDJJT0bwoaRc0Jxd-CMw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/6bb4d645/attachment.pl>

From jwiley.psych at gmail.com  Sat Jun  8 03:24:50 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Fri, 7 Jun 2013 18:24:50 -0700
Subject: [R] recode: how to avoid nested ifelse
In-Reply-To: <CAErODj8Tr6KBNweyFy2kXYmqn-CEs=cDJJT0bwoaRc0Jxd-CMw@mail.gmail.com>
References: <CAErODj8Tr6KBNweyFy2kXYmqn-CEs=cDJJT0bwoaRc0Jxd-CMw@mail.gmail.com>
Message-ID: <CANz9Z_LuJjikRcwyi2JF5byL9fbRPZ=kxD7Rq4q2GwX=ZCwMNQ@mail.gmail.com>

Hi Paul,

Unless you have truly offended the data generating oracle*, the
pattern: NA, 1, NA, should be a data entry error --- graduating HS
implies graduating ES, no?  I would argue fringe cases like that
should be corrected in the data, not through coding work arounds.
Then you can just do:

x <- do.call(paste0, list(es, hs, cg))

> table(factor(x, levels = c("000", "100", "110", "111"), labels = c("none", "es","hs", "cg")))
none   es   hs   cg
   4    1    1    2

Cheers,

Josh

*Drawn from comments by Judea Pearl one lively session.


On Fri, Jun 7, 2013 at 6:13 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> In our Summer Stats Institute, I was asked a question that amounts to
> reversing the effect of the contrasts function (reconstruct an ordinal
> predictor from a set of binary columns). The best I could think of was to
> link together several ifelse functions, and I don't think I want to do this
> if the example became any more complicated.
>
> I'm unable to remember a less error prone method :). But I expect you might.
>
> Here's my working example code
>
> ## Paul Johnson <pauljohn at ku.edu>
> ## 2013-06-07
>
> ## We need to create an ordinal factor from these indicators
> ## completed elementary school
> es <- c(0, 0, 1, 0, 1, 0, 1, 1)
> ## completed high school
> hs <- c(0, 0, 1, 0, 1, 0, 1, 0)
> ## completed college graduate
> cg <- c(0, 0, 0, 0, 1, 0, 1, 0)
>
> ed <- ifelse(cg == 1, 3,
>              ifelse(hs == 1, 2,
>                     ifelse(es == 1, 1, 0)))
>
> edf <- factor(ed, levels = 0:3,  labels = c("none", "es", "hs", "cg"))
> data.frame(es, hs, cg, ed, edf)
>
> ## Looks OK, but what if there are missings?
> es <- c(0, 0, 1, 0, 1, 0, 1, 1, NA, NA)
> hs <- c(0, 0, 1, 0, 1, 0, 1, 0, 1, NA)
> cg <- c(0, 0, 0, 0, 1, 0, 1, 0, NA, NA)
> ed <- ifelse(cg == 1, 3,
>              ifelse(hs == 1, 2,
>                     ifelse(es == 1, 1, 0)))
> cbind(es, hs, cg, ed)
>
> ## That's bad, ifelse returns NA too frequently.
> ## Revise (becoming tedious!)
>
> ed <- ifelse(!is.na(cg) & cg == 1, 3,
>              ifelse(!is.na(hs) & hs == 1, 2,
>                     ifelse(!is.na(es) & es == 1, 1,
>                            ifelse(is.na(es), NA, 0))))
> cbind(es, hs, cg, ed)
>
>
> ## Does the project director want us to worry about
> ## logical inconsistencies, such as es = 0 but cg = 1?
> ## I hope not.
>
> Thanks in advance, I hope you are having a nice summer.
>
> pj
>
> --
> Paul E. Johnson
> Professor, Political Science      Assoc. Director
> 1541 Lilac Lane, Room 504      Center for Research Methods
> University of Kansas                 University of Kansas
> http://pj.freefaculty.org               http://quant.ku.edu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com


From dimitri.liakhovitski at gmail.com  Sat Jun  8 03:24:48 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Fri, 7 Jun 2013 21:24:48 -0400
Subject: [R] splitting a string column into multiple columns faster
Message-ID: <CAN2xGJa2wfnk3bP0eyR4e1XOHqt8hcPaAgMaP9G+wByHpP511Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130607/b9a1eb30/attachment.pl>

From nfultz at gmail.com  Sat Jun  8 04:25:54 2013
From: nfultz at gmail.com (Neal Fultz)
Date: Fri, 7 Jun 2013 19:25:54 -0700
Subject: [R] recode: how to avoid nested ifelse
In-Reply-To: <CANz9Z_LuJjikRcwyi2JF5byL9fbRPZ=kxD7Rq4q2GwX=ZCwMNQ@mail.gmail.com>
References: <CAErODj8Tr6KBNweyFy2kXYmqn-CEs=cDJJT0bwoaRc0Jxd-CMw@mail.gmail.com>
	<CANz9Z_LuJjikRcwyi2JF5byL9fbRPZ=kxD7Rq4q2GwX=ZCwMNQ@mail.gmail.com>
Message-ID: <20130608022553.GY1685@neal-SP35>

I would do this to get the highest non-missing level:

x <- pmax(3*cg, 2*hs, es, 0, na.rm=TRUE)

rock chalk...

-nfultz

On Fri, Jun 07, 2013 at 06:24:50PM -0700, Joshua Wiley wrote:
> Hi Paul,
> 
> Unless you have truly offended the data generating oracle*, the
> pattern: NA, 1, NA, should be a data entry error --- graduating HS
> implies graduating ES, no?  I would argue fringe cases like that
> should be corrected in the data, not through coding work arounds.
> Then you can just do:
> 
> x <- do.call(paste0, list(es, hs, cg))
> 
> > table(factor(x, levels = c("000", "100", "110", "111"), labels = c("none", "es","hs", "cg")))
> none   es   hs   cg
>    4    1    1    2
> 
> Cheers,
> 
> Josh
> 
> *Drawn from comments by Judea Pearl one lively session.
> 
> 
> On Fri, Jun 7, 2013 at 6:13 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> > In our Summer Stats Institute, I was asked a question that amounts to
> > reversing the effect of the contrasts function (reconstruct an ordinal
> > predictor from a set of binary columns). The best I could think of was to
> > link together several ifelse functions, and I don't think I want to do this
> > if the example became any more complicated.
> >
> > I'm unable to remember a less error prone method :). But I expect you might.
> >
> > Here's my working example code
> >
> > ## Paul Johnson <pauljohn at ku.edu>
> > ## 2013-06-07
> >
> > ## We need to create an ordinal factor from these indicators
> > ## completed elementary school
> > es <- c(0, 0, 1, 0, 1, 0, 1, 1)
> > ## completed high school
> > hs <- c(0, 0, 1, 0, 1, 0, 1, 0)
> > ## completed college graduate
> > cg <- c(0, 0, 0, 0, 1, 0, 1, 0)
> >
> > ed <- ifelse(cg == 1, 3,
> >              ifelse(hs == 1, 2,
> >                     ifelse(es == 1, 1, 0)))
> >
> > edf <- factor(ed, levels = 0:3,  labels = c("none", "es", "hs", "cg"))
> > data.frame(es, hs, cg, ed, edf)
> >
> > ## Looks OK, but what if there are missings?
> > es <- c(0, 0, 1, 0, 1, 0, 1, 1, NA, NA)
> > hs <- c(0, 0, 1, 0, 1, 0, 1, 0, 1, NA)
> > cg <- c(0, 0, 0, 0, 1, 0, 1, 0, NA, NA)
> > ed <- ifelse(cg == 1, 3,
> >              ifelse(hs == 1, 2,
> >                     ifelse(es == 1, 1, 0)))
> > cbind(es, hs, cg, ed)
> >
> > ## That's bad, ifelse returns NA too frequently.
> > ## Revise (becoming tedious!)
> >
> > ed <- ifelse(!is.na(cg) & cg == 1, 3,
> >              ifelse(!is.na(hs) & hs == 1, 2,
> >                     ifelse(!is.na(es) & es == 1, 1,
> >                            ifelse(is.na(es), NA, 0))))
> > cbind(es, hs, cg, ed)
> >
> >
> > ## Does the project director want us to worry about
> > ## logical inconsistencies, such as es = 0 but cg = 1?
> > ## I hope not.
> >
> > Thanks in advance, I hope you are having a nice summer.
> >
> > pj
> >
> > --
> > Paul E. Johnson
> > Professor, Political Science      Assoc. Director
> > 1541 Lilac Lane, Room 504      Center for Research Methods
> > University of Kansas                 University of Kansas
> > http://pj.freefaculty.org               http://quant.ku.edu
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> Joshua Wiley
> Ph.D. Student, Health Psychology
> University of California, Los Angeles
> http://joshuawiley.com/
> Senior Analyst - Elkhart Group Ltd.
> http://elkhartgroup.com
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sat Jun  8 05:00:28 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 7 Jun 2013 20:00:28 -0700 (PDT)
Subject: [R] splitting a string column into multiple columns faster
In-Reply-To: <CAN2xGJa2wfnk3bP0eyR4e1XOHqt8hcPaAgMaP9G+wByHpP511Q@mail.gmail.com>
References: <CAN2xGJa2wfnk3bP0eyR4e1XOHqt8hcPaAgMaP9G+wByHpP511Q@mail.gmail.com>
Message-ID: <1370660428.56782.YahooMailNeo@web142603.mail.bf1.yahoo.com>

HI,
May be this helps:

res<-data.frame(x=x,read.table(text=gsub("[A-Za-z]","",x[,1]),sep="_",header=FALSE),stringsAsFactors=FALSE)
res
#?????????????? x V1 V2 V3
#1 aaa1_bbb1_ccc3? 1? 1? 3
#2 aaa2_bbb3_ccc2? 2? 3? 2
#3 aaa3_bbb2_ccc1? 3? 2? 1
A.K.

----- Original Message -----
From: Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com>
To: r-help <r-help at r-project.org>
Cc: 
Sent: Friday, June 7, 2013 9:24 PM
Subject: [R] splitting a string column into multiple columns faster

Hello!

I have a column in my data frame that I have to split: I have to distill
the numbers from the text. Below is my example and my solution.

x<-data.frame(x=c("aaa1_bbb1_ccc3","aaa2_bbb3_ccc2","aaa3_bbb2_ccc1"))
x
library(stringr)
out<-as.data.frame(str_split_fixed(x$x,"aaa",2))
out2<-as.data.frame(str_split_fixed(out$V2,"_bbb",2))
out3<-as.data.frame(str_split_fixed(out2$V2,"_ccc",2))
result<-cbind(x,out2[1],out3)
result
My problem is:
str_split.fixed is relatively slow. In my real data frame I have over
80,000 rows so that it takes almost 30 seconds to run just one line (like
out<-... above)
And it's even slower because I have to do it step-by-step many times.

Any way to do it by specifying all 3 delimiters at once
("aaa","_bbb","_ccc") and then split it in one swoop into a data frame with
several columns?

Thanks a lot for any pointers!

-- 
Dimitri Liakhovitski

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jwiley.psych at gmail.com  Sat Jun  8 05:03:26 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Fri, 7 Jun 2013 20:03:26 -0700
Subject: [R] recode: how to avoid nested ifelse
In-Reply-To: <20130608022553.GY1685@neal-SP35>
References: <CAErODj8Tr6KBNweyFy2kXYmqn-CEs=cDJJT0bwoaRc0Jxd-CMw@mail.gmail.com>
	<CANz9Z_LuJjikRcwyi2JF5byL9fbRPZ=kxD7Rq4q2GwX=ZCwMNQ@mail.gmail.com>
	<20130608022553.GY1685@neal-SP35>
Message-ID: <CANz9Z_J=x6NQHuhmkDxj=jV+K6u_8ZcwfZuBvEw5TfXV3NoUmQ@mail.gmail.com>

I still argue for na.rm=FALSE, but that is cute, also substantially faster

f1 <- function(x1, x2, x3) do.call(paste0, list(x1, x2, x3))
f2 <- function(x1, x2, x3) pmax(3*x3, 2*x2, es, 0, na.rm=FALSE)
f3 <- function(x1, x2, x3) Reduce(`+`, list(x1, x2, x3))
f4 <- function(x1, x2, x3) rowSums(cbind(x1, x2, x3))

es <- rep(c(0, 0, 1, 0, 1, 0, 1, 1, NA, NA), 1000)
hs <- rep(c(0, 0, 1, 0, 1, 0, 1, 0, 1, NA), 1000)
cg <- rep(c(0, 0, 0, 0, 1, 0, 1, 0, NA, NA), 1000)

system.time(replicate(1000, f1(cg, hs, es)))
system.time(replicate(1000, f2(cg, hs, es)))
system.time(replicate(1000, f3(cg, hs, es)))
system.time(replicate(1000, f4(cg, hs, es)))

> system.time(replicate(1000, f1(cg, hs, es)))
   user  system elapsed
  22.73    0.03   22.76
> system.time(replicate(1000, f2(cg, hs, es)))
   user  system elapsed
   0.92    0.04    0.95
> system.time(replicate(1000, f3(cg, hs, es)))
   user  system elapsed
   0.19    0.02    0.20
 > system.time(replicate(1000, f4(cg, hs, es)))
   user  system elapsed
   0.95    0.03    0.98


R version 3.0.0 (2013-04-03)
Platform: x86_64-w64-mingw32/x64 (64-bit)




On Fri, Jun 7, 2013 at 7:25 PM, Neal Fultz <nfultz at gmail.com> wrote:
> I would do this to get the highest non-missing level:
>
> x <- pmax(3*cg, 2*hs, es, 0, na.rm=TRUE)
>
> rock chalk...
>
> -nfultz
>
> On Fri, Jun 07, 2013 at 06:24:50PM -0700, Joshua Wiley wrote:
>> Hi Paul,
>>
>> Unless you have truly offended the data generating oracle*, the
>> pattern: NA, 1, NA, should be a data entry error --- graduating HS
>> implies graduating ES, no?  I would argue fringe cases like that
>> should be corrected in the data, not through coding work arounds.
>> Then you can just do:
>>
>> x <- do.call(paste0, list(es, hs, cg))
>>
>> > table(factor(x, levels = c("000", "100", "110", "111"), labels = c("none", "es","hs", "cg")))
>> none   es   hs   cg
>>    4    1    1    2
>>
>> Cheers,
>>
>> Josh
>>
>> *Drawn from comments by Judea Pearl one lively session.
>>
>>
>> On Fri, Jun 7, 2013 at 6:13 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
>> > In our Summer Stats Institute, I was asked a question that amounts to
>> > reversing the effect of the contrasts function (reconstruct an ordinal
>> > predictor from a set of binary columns). The best I could think of was to
>> > link together several ifelse functions, and I don't think I want to do this
>> > if the example became any more complicated.
>> >
>> > I'm unable to remember a less error prone method :). But I expect you might.
>> >
>> > Here's my working example code
>> >
>> > ## Paul Johnson <pauljohn at ku.edu>
>> > ## 2013-06-07
>> >
>> > ## We need to create an ordinal factor from these indicators
>> > ## completed elementary school
>> > es <- c(0, 0, 1, 0, 1, 0, 1, 1)
>> > ## completed high school
>> > hs <- c(0, 0, 1, 0, 1, 0, 1, 0)
>> > ## completed college graduate
>> > cg <- c(0, 0, 0, 0, 1, 0, 1, 0)
>> >
>> > ed <- ifelse(cg == 1, 3,
>> >              ifelse(hs == 1, 2,
>> >                     ifelse(es == 1, 1, 0)))
>> >
>> > edf <- factor(ed, levels = 0:3,  labels = c("none", "es", "hs", "cg"))
>> > data.frame(es, hs, cg, ed, edf)
>> >
>> > ## Looks OK, but what if there are missings?
>> > es <- c(0, 0, 1, 0, 1, 0, 1, 1, NA, NA)
>> > hs <- c(0, 0, 1, 0, 1, 0, 1, 0, 1, NA)
>> > cg <- c(0, 0, 0, 0, 1, 0, 1, 0, NA, NA)
>> > ed <- ifelse(cg == 1, 3,
>> >              ifelse(hs == 1, 2,
>> >                     ifelse(es == 1, 1, 0)))
>> > cbind(es, hs, cg, ed)
>> >
>> > ## That's bad, ifelse returns NA too frequently.
>> > ## Revise (becoming tedious!)
>> >
>> > ed <- ifelse(!is.na(cg) & cg == 1, 3,
>> >              ifelse(!is.na(hs) & hs == 1, 2,
>> >                     ifelse(!is.na(es) & es == 1, 1,
>> >                            ifelse(is.na(es), NA, 0))))
>> > cbind(es, hs, cg, ed)
>> >
>> >
>> > ## Does the project director want us to worry about
>> > ## logical inconsistencies, such as es = 0 but cg = 1?
>> > ## I hope not.
>> >
>> > Thanks in advance, I hope you are having a nice summer.
>> >
>> > pj
>> >
>> > --
>> > Paul E. Johnson
>> > Professor, Political Science      Assoc. Director
>> > 1541 Lilac Lane, Room 504      Center for Research Methods
>> > University of Kansas                 University of Kansas
>> > http://pj.freefaculty.org               http://quant.ku.edu
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Joshua Wiley
>> Ph.D. Student, Health Psychology
>> University of California, Los Angeles
>> http://joshuawiley.com/
>> Senior Analyst - Elkhart Group Ltd.
>> http://elkhartgroup.com
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com


From Pradip.Muhuri at samhsa.hhs.gov  Sat Jun  8 05:17:49 2013
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Sat, 8 Jun 2013 03:17:49 +0000
Subject: [R] Regression Tolerance Intervals - Dr. Young's Code
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C23331688@pl-emsmb11>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130608/0f02ccdb/attachment.pl>

From smartpink111 at yahoo.com  Sat Jun  8 05:27:10 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 7 Jun 2013 20:27:10 -0700 (PDT)
Subject: [R] splitting a string column into multiple columns faster
In-Reply-To: <1370660428.56782.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <CAN2xGJa2wfnk3bP0eyR4e1XOHqt8hcPaAgMaP9G+wByHpP511Q@mail.gmail.com>
	<1370660428.56782.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1370662030.9709.YahooMailNeo@web142601.mail.bf1.yahoo.com>

HI,
Tried it on 1e5 row dataset:

l1<- letters[1:10]
s1<-sapply(seq_along(l1),function(i) paste(rep(l1[i],3),collapse=""))
set.seed(24)
x1<-data.frame(x=paste(paste0(sample(s1,1e5,replace=TRUE),sample(1:15,1e5,replace=TRUE)),paste0(sample(s1,1e5,replace=TRUE),sample(1:15,1e5,replace=TRUE)),paste0(sample(s1,1e5,replace=TRUE),sample(1:15,1e5,replace=TRUE)),sep="_"),stringsAsFactors=FALSE)
system.time(resNew<-data.frame(x=x1,read.table(text=gsub("[A-Za-z]","",x1[,1]),sep="_",header=FALSE),stringsAsFactors=FALSE))
#?? user? system elapsed 
#? 2.712?? 0.016?? 2.732 

head(resNew)
#????????????????? x V1 V2 V3
#1? ccc12_ggg2_jjj14 12? 2 14
#2? ccc7_ddd15_aaa11? 7 15 11
#3 hhh12_ddd14_fff12 12 14 12
#4? fff11_bbb15_aaa6 11 15? 6
#5?? ggg12_ccc9_ggg8 12? 9? 8
#6?? jjj8_eee12_eee4? 8 12? 4

A.K.


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com>
Cc: R help <r-help at r-project.org>
Sent: Friday, June 7, 2013 11:00 PM
Subject: Re: [R] splitting a string column into multiple columns faster

HI,
May be this helps:

res<-data.frame(x=x,read.table(text=gsub("[A-Za-z]","",x[,1]),sep="_",header=FALSE),stringsAsFactors=FALSE)
res
#?????????????? x V1 V2 V3
#1 aaa1_bbb1_ccc3? 1? 1? 3
#2 aaa2_bbb3_ccc2? 2? 3? 2
#3 aaa3_bbb2_ccc1? 3? 2? 1
A.K.

----- Original Message -----
From: Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com>
To: r-help <r-help at r-project.org>
Cc: 
Sent: Friday, June 7, 2013 9:24 PM
Subject: [R] splitting a string column into multiple columns faster

Hello!

I have a column in my data frame that I have to split: I have to distill
the numbers from the text. Below is my example and my solution.

x<-data.frame(x=c("aaa1_bbb1_ccc3","aaa2_bbb3_ccc2","aaa3_bbb2_ccc1"))
x
library(stringr)
out<-as.data.frame(str_split_fixed(x$x,"aaa",2))
out2<-as.data.frame(str_split_fixed(out$V2,"_bbb",2))
out3<-as.data.frame(str_split_fixed(out2$V2,"_ccc",2))
result<-cbind(x,out2[1],out3)
result
My problem is:
str_split.fixed is relatively slow. In my real data frame I have over
80,000 rows so that it takes almost 30 seconds to run just one line (like
out<-... above)
And it's even slower because I have to do it step-by-step many times.

Any way to do it by specifying all 3 delimiters at once
("aaa","_bbb","_ccc") and then split it in one swoop into a data frame with
several columns?

Thanks a lot for any pointers!

-- 
Dimitri Liakhovitski

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Sat Jun  8 10:06:47 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 8 Jun 2013 01:06:47 -0700 (PDT)
Subject: [R] data
In-Reply-To: <104083AE5AAA634C993249DFCCE4C20306439744@CIPRESTE.ua.pt>
References: <104083AE5AAA634C993249DFCCE4C20306439744@CIPRESTE.ua.pt>
Message-ID: <1370678807.66022.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Try this:
final3New<-read.table(file="real_data_cecilia.txt",sep="\t")
dim(final3New)
#[1] 5369??? 5

#Inside the split within split, dummy==1 for the first row.? For lists that have many rows, I selected the row with dummy==0 (from the rest) using the #condition that the absolute difference between the dimensions of those rows and the first row dimension was minimum (after I applied the first #constraint).? I guess you wanted to select only a pair of rows (dummy=0 and dummy=1) for each lists.

fun1<- function(dat,percent,number){??? 
??? lst1<- split(dat,list(dat$year,dat$industry))
??? lst1New<- lapply(lst1,function(x) x[!(all(x$dummy==0)|all(x$dummy==1)),])
??? lst2<- lst1New[lapply(lst1New,nrow)>0]
??? lst3<- lapply(lst2,function(x){
??? ??? ??? ??? lapply(x$dimension,function(y){
??? ??? ??? ??? ? x1<- x[(y < (x$dimension+(x$dimension*percent))) & (y > (x$dimension-(x$dimension*percent))),]??? ??? 
??? ??? ??? ??? })??? 
??? ??? ??? ??? })
??? lst4<- lapply(lst3,function(x){
??? ??? ??? ???? ?? lst<- lapply(x,function(y){
??? ??? ??? ??? ??? ??? ??? y[!all(y$dummy==0),]
??? ??? ??? ??? ??? ??? ??? ???? })
??? ??? ??? ??? ?? lstNew<- lst[lapply(lst,nrow)>1]
??? ??? ??? ??? ?? lstNew1<- unique(lstNew)
??? ??? ??? ??? ?? })
???????? lst5<- lst4[lapply(lst4,length)>0]
??? ?lst6<- lapply(lst5,function(x) {
??? ??? ??? ??? ??? lst<- lapply(x,function(y){
??? ??? ??? ??? ??? ??? ? y[!all(y$dummy==1),]
??? ??? ??? ??? ??? ??? ?? })
??? ??? ??? ??? ??? lst[lapply(lst,nrow)>0]
??? ??? ??? ??? ??? })
???????? lst7<- lapply(lst6,function(x){
??? ??? ??? ??? ??? lst<- lapply(x,function(y) {
??? ??? ??? ??? ??? ??? x1<- y[1,]
??? ??? ??? ??? ??? ??? x2<- y[-1,]
??? ??? ??? ??? ??? ??? x3<- subset(x2,dummy==0)
??? ??? ??? ??? ??? ??? x4<- x3[which.min(abs(x1$dimension-x3$dimension)),]
??? ??? ??? ??? ??? ??? rbind(x1,x4)
??? ??? ??? ??? ??? ??? })
??? ??? ??? ??? ??? lstNew<-unique(lst)
??? ??? ??? ??? ??? lstNew1<- lapply(lstNew,function(x){
??? ??? ??? ??? ??? ??? x[abs(diff(x$dimension)) < number,] 
??? ??? ??? ??? ??? ??? })
??? ??? ??? ??? ??? ?lstNew1[lapply(lstNew1,nrow)>0]
??? ??? ??? ??? ??? ??? })
??? ?lst8<- lst7[lapply(lst7,length)>0]
??? ?res<- do.call(rbind,lapply(lst8,function(x){
??? ??? ??? ??? ??? ??? ?do.call(rbind,x)
??? ??? ??? ??? ??? ??? ??? })
??? ??? ??? ??? ??? ??? ??????? )
??? ?row.names(res)<- 1:nrow(res)
??? ?res}??? ??? ??? ??? ???? ??? ??? 

res10Percent<- fun1(final3New,0.1,200)
dim(res10Percent)
#[1] 508?? 5
?nrow(subset(res10Percent,dummy==0))
#[1] 254
?nrow(subset(res10Percent,dummy==1))
#[1] 254
?head(res10Percent)
#?????? firm year industry dummy dimension
#1 500622043 2004??????? 1???? 1????? 1198
#2 501611886 2004??????? 1???? 0????? 1208
#3 501164600 2005??????? 1???? 1????? 1332
#4 504243349 2005??????? 1???? 0????? 1455
#5 500862893 2006??????? 1???? 1????? 5324
#6 501744860 2006??????? 1???? 0????? 5453



res5Percent<- fun1(final3New,0.05,200)
?dim(res5Percent)
#[1] 548?? 5

?nrow(subset(res5Percent,dummy==0))
#[1] 274
? nrow(subset(res5Percent,dummy==1))
#[1] 274

res5percent1<-fun1(final3New,0.05,50)
?dim(res5percent1)
#[1] 302?? 5
?nrow(subset(res5percent1,dummy==0))
#[1] 151
?nrow(subset(res5percent1,dummy==1))
#[1] 151

Hope it helps.

A.K.



________________________________
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com> 
Sent: Friday, June 7, 2013 7:30 PM
Subject: data




I'm sending the data.
Thank you very much.
Cec?lia

The code

final3<-read.table(file="real data cecilia.txt",sep="\t")

lst1<-split(final3,list(final3$year,final3$industry))
lst2<-lst1[lapply(lst1,nrow)>0]
lst3<-lapply(lst2,function(x) lapply(x$dimension,function(y) x[(y< (x$dimension+x$dimension*0.10)) & (y> (x$dimension-x$dimension*0.10)),]))
lst4<-lapply(lst3,function(x) x[lapply(x,nrow)==2])
lst5<-lapply(lst4,function(x)x[!duplicated(x)])
lst6<-lst5[lapply(lst5,length)>0]
lst7<-lapply(lst6,function(x) {lst<-lapply(x,function(y) y[sum(y$dummy)==1,]);lst[lapply(lst,nrow)>0]})
res<-do.call(rbind,lapply(lst7,function(x) do.call(rbind,x)))
row.names(res)<-1:nrow(res)
nrow(subset(res,res$dummy==1))
nrow(subset(res,res$dummy==0))??


From pdalgd at gmail.com  Sat Jun  8 10:28:19 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 8 Jun 2013 10:28:19 +0200
Subject: [R] Clogit R and Stata
In-Reply-To: <1370623880.21636.YahooMailNeo@web163804.mail.gq1.yahoo.com>
References: <1370612073.93488.YahooMailNeo@web163803.mail.gq1.yahoo.com>
	<3ABD3D67-B7E7-4E7E-9128-413F1D0967B4@gmail.com>
	<1370623880.21636.YahooMailNeo@web163804.mail.gq1.yahoo.com>
Message-ID: <792B9F1B-451A-4406-95D0-2F4326B6158B@gmail.com>

The "n = 1404"  vs. "Number of obs   =        468" looks like the giveaway.

You are passing the subset selection logic as the 3rd positional argument, but according to the documentation, that is the weights argument.

So,  clogit(..., data = dframe, subset = sample==1 & glb_ind=="Y")


On Jun 7, 2013, at 18:51 , Richard Beckett wrote:

> 
> 
> From: peter dalgaard <pdalgd at gmail.com>
> To: Richard Beckett <rbeckett81 at yahoo.com> 
> Cc: "r-help at r-project.org" <r-help at r-project.org> 
> Sent: Friday, June 7, 2013 11:12 AM
> Subject: Re: [R] Clogit R and Stata
> 
> Here is the R output:
> 
> Call:
> coxph(formula = Surv(rep(1, 1404L), sftpcons) ~ sftptv2a3 + sftptv2a4 + 
>     sftptv2a5 + sftptv2a2 + sftptv2a6 + logim + maccat + disp4cat + 
>     strata(stratida), data = dframe, method = "exact")
> 
>   n= 1404, number of events= 351 
> 
>              coef           exp(coef) se(coef)      z Pr(>|z|)    
> sftptv2a3  1.4552    4.2852   0.2273  6.401 1.54e-10 ***
> sftptv2a4  3.1118   22.4609   0.2265 13.739  < 2e-16 ***
> sftptv2a5  1.0717    2.9204   0.2522  4.249 2.15e-05 ***
> sftptv2a2  0.7185    2.0514   0.3300  2.177   0.0295 *  
> sftptv2a6  2.7341   15.3965   0.5050  5.414 6.17e-08 ***
> logim      0.7579    2.1338   0.1347  5.625 1.85e-08 ***
> maccat     3.0809   21.7771   0.4005  7.693 1.43e-14 ***
> disp4cat   0.7061    2.0261   0.1524  4.634 3.59e-06 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 
> 
>                    exp(coef) exp(-coef) lower .95 upper .95
> sftptv2a3     4.285    0.23336     2.745     6.691
> sftptv2a4    22.461    0.04452    14.409    35.013
> sftptv2a5     2.920    0.34241     1.781     4.788
> sftptv2a2     2.051    0.48747     1.074     3.917
> sftptv2a6    15.397    0.06495     5.722    41.429
> logim         2.134    0.46866     1.639     2.779
> maccat       21.777    0.04592     9.934    47.739
> disp4cat      2.026    0.49355     1.503     2.731
> 
> Rsquare= 0.239   (max possible= 0.623 )
> Likelihood ratio test= 383.2  on 8 df,   p=0
> Wald test            = 264.7  on 8 df,   p=0
> Score (logrank) test = 396.2  on 8 df,   p=0
> 
> 
> And the STATA output:
> 
> Iteration 0:   log likelihood = -95.537697  
> Iteration 1:   log likelihood = -91.465581  
> Iteration 2:   log likelihood = -91.402366  
> Iteration 3:   log likelihood = -91.402264  
> Iteration 4:   log likelihood = -91.402264  
> 
> Conditional (fixed-effects) logistic regression   Number of obs   =        468
>                                                   LR chi2(8)      =     141.59
>                                                   Prob > chi2     =     0.0000
> Log likelihood = -91.402264                       Pseudo R2       =     0.4365
> 
> ------------------------------------------------------------------------------
>     sftpcons |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
> -------------+----------------------------------------------------------------
>    sftptv2a3 |   2.042827   .4741327     4.31   0.000     1.113544     2.97211
>    sftptv2a4 |    4.10828   .5593723     7.34   0.000      3.01193    5.204629
>    sftptv2a5 |   1.766492   .5585173     3.16   0.002     .6718177    2.861165
>    sftptv2a2 |   1.366568   .6540307     2.09   0.037      .084691    2.648444
>    sftptv2a6 |   2.307152   .8225835     2.80   0.005     .6949178    3.919386
>        logim |   1.404135   .3480976     4.03   0.000     .7218764    2.086394
>       maccat |     2.8423   .7008588     4.06   0.000     1.468642    4.215958
>     disp4cat |   .6347805   .2872258     2.21   0.027     .0718283    1.197733
> ------------------------------------------------------------------------------
> 
> Also tried changing method=approximate with no noticeable change 
> 
> On Jun 7, 2013, at 15:34 , Richard Beckett wrote:
> 
> > Sorry to once again write a message but I'm once again stumped and am having no luck finding a solution anywhere else.
> > 
> > 
> > This question requires some finesse in both R and STATA so hopefully I will be able to get an answer here. I am much more adept in R and am trying to replicate the results of a STATA file in R. Hopefully this is a proper forum for such questions. 
> > 
> > 
> > This is the code for the clogit in STATA
> > clogit sftpcons sftptv2a3 sftptv2a4 sftptv2a5 sftptv2a2 sftptv2a6 logim maccat disp4cat if sample==1 & glb_ind=="Y", group(stratida)
> > and I tried to replicate it using
> > clogit1<-clogit(sftpcons~sftptv2a3+sftptv2a4+sftptv2a5+sftptv2a2+sftptv2a6+logim+maccat+disp4cat+strata(stratida), dframe, sample==1 | glb_ind=="Y")
> > but got different results
> > What did I do wrong here? I interpreted the STATA clogit as run this logit as long as the sample is 1 and glb_ind="Y" What should I be doing instead?
> 
> 
> An "&" rather than "|" in the R version might help. Other than that, we're a bit short on clues unless you provide some output.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From sguallar at yahoo.com  Sat Jun  8 11:19:06 2013
From: sguallar at yahoo.com (Santiago Guallar)
Date: Sat, 8 Jun 2013 02:19:06 -0700 (PDT)
Subject: [R] modify and append new rows in a dataframe
Message-ID: <1370683146.3973.YahooMailNeo@web160806.mail.bf1.yahoo.com>

My data frame shows changes on the variable act which records the consecutive duration (in seconds) of two states (wet-dry) over a few days for several?individuals (identified by Ring). Since I want to work with daytime (i.e. from dawn till dusk) and night time (i.e. from dusk till next dawn), I have to split act in two: from time[i] till dusk and from dusk until time[i+1], and from time[k] till dawn and from dawn until time[k+1].
Example:

ith row: 01-01-2000 20:55:00 act= 360 seconds

i+1th row: 01-01-2000 21:01:00 act= 30 seconds # say that dusk= 21:00

i+2th row: 01-01-2000 21:01:30 act= 30 seconds

.

.
.
My goal is to get:

ith row: 01-01-2000 20:55:00 act= 300 seconds # modified row

i+1th row: 01-01-2000 21:00:00 act= 60 seconds # new row

i+2th row: 01-01-2000 00:01:00 act= 30 seconds # previously row i+1th

i+3th row: 01-01-2000 00:01:30 act= 30 seconds # previously row i+2th

.

.
.
I attach a dput with a selection of my data. Here's a piece of code that I am trying to run only for the daytime/night time change:

? xandn <- ddply( xan, .(Ring), function(df1){
? # ?ndex of daytime/night time changes
? ind <- c( FALSE,?diff( as.POSIXlt( df1$timepos, df1$dusk ) ) > 0?)
? add <- df1[ind,]
? add$timepos <- add$timepos - add$dusk
? # append and arrange rows
? df1 <- rbind( df1, add )
? df1 <- df1[order(df1$timepos),]
? # recalculation of act
? df1$act2 <- c( diff( as.numeric(df1$timepos) ), NA )
? df1} )

I get the following error message:
"Error in diff(as.POSIXlt(df1$timepos, df1$dusk)): error in evaluating the argument 'x' in selecting a method for function 'diff': Error in as.POSIXlt.POSIXct?(df1$timepos, df1$dusk): ? invalid 'tz' value"

Thank you for your hep,

Santi

From cecilia.carmo at ua.pt  Sat Jun  8 12:06:25 2013
From: cecilia.carmo at ua.pt (Cecilia Carmo)
Date: Sat, 8 Jun 2013 10:06:25 +0000
Subject: [R] data - matched samples, dataframes, panel data
Message-ID: <104083AE5AAA634C993249DFCCE4C2030643979D@CIPRESTE.ua.pt>


It seems to do all I want:
1. matchs the greatest  number of firms within an year and industry, by dimension
2. diferences between dimensions should not be more than 10% or/and 200 (if I want just the 10%
restrition I think I could substitute 200 for a big number that is impossible to exist)
3. if there are many cases that verif y 2. then it chooses the closest.

Thank you very much.

Cec?lia Carmo
Universidade de Aveiro - Portugal


________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: s?bado, 8 de Junho de 2013 9:06
Para: Cecilia Carmo
Cc: R help
Assunto: Re: data

Hi,
Try this:
final3New<-read.table(file="real_data_cecilia.txt",sep="\t")
dim(final3New)
#[1] 5369    5

#Inside the split within split, dummy==1 for the first row.  For lists that have many rows, I selected the row with dummy==0 (from the rest) using the #condition that the absolute difference between the dimensions of those rows and the first row dimension was minimum (after I applied the first #constraint).  I guess you wanted to select only a pair of rows (dummy=0 and dummy=1) for each lists.

fun1<- function(dat,percent,number){   
    lst1<- split(dat,list(dat$year,dat$industry))
    lst1New<- lapply(lst1,function(x) x[!(all(x$dummy==0)|all(x$dummy==1)),])
    lst2<- lst1New[lapply(lst1New,nrow)>0]
    lst3<- lapply(lst2,function(x){
                lapply(x$dimension,function(y){
                  x1<- x[(y < (x$dimension+(x$dimension*percent))) & (y > (x$dimension-(x$dimension*percent))),]   
                })
                })
    lst4<- lapply(lst3,function(x){
                    lst<- lapply(x,function(y){
                            y[!all(y$dummy==0),]
                                 })
                   lstNew<- lst[lapply(lst,nrow)>1]
                   lstNew1<- unique(lstNew)
                   })
         lst5<- lst4[lapply(lst4,length)>0]
     lst6<- lapply(lst5,function(x) {
                    lst<- lapply(x,function(y){
                          y[!all(y$dummy==1),]
                           })
                    lst[lapply(lst,nrow)>0]
                    })
         lst7<- lapply(lst6,function(x){
                    lst<- lapply(x,function(y) {
                        x1<- y[1,]
                        x2<- y[-1,]
                        x3<- subset(x2,dummy==0)
                        x4<- x3[which.min(abs(x1$dimension-x3$dimension)),]
                        rbind(x1,x4)
                        })
                    lstNew<-unique(lst)
                    lstNew1<- lapply(lstNew,function(x){
                        x[abs(diff(x$dimension)) < number,]
                        })
                     lstNew1[lapply(lstNew1,nrow)>0]
                        })
     lst8<- lst7[lapply(lst7,length)>0]
     res<- do.call(rbind,lapply(lst8,function(x){
                         do.call(rbind,x)
                            })
                                )
     row.names(res)<- 1:nrow(res)
     res}   

res10Percent<- fun1(final3New,0.1,200)
dim(res10Percent)
#[1] 508   5
 nrow(subset(res10Percent,dummy==0))
#[1] 254
 nrow(subset(res10Percent,dummy==1))
#[1] 254
 head(res10Percent)
#       firm year industry dummy dimension
#1 500622043 2004        1     1      1198
#2 501611886 2004        1     0      1208
#3 501164600 2005        1     1      1332
#4 504243349 2005        1     0      1455
#5 500862893 2006        1     1      5324
#6 501744860 2006        1     0      5453



res5Percent<- fun1(final3New,0.05,200)
 dim(res5Percent)
#[1] 548   5

 nrow(subset(res5Percent,dummy==0))
#[1] 274
  nrow(subset(res5Percent,dummy==1))
#[1] 274

res5percent1<-fun1(final3New,0.05,50)
 dim(res5percent1)
#[1] 302   5
 nrow(subset(res5percent1,dummy==0))
#[1] 151
 nrow(subset(res5percent1,dummy==1))
#[1] 151

Hope it helps.

A.K.



________________________________
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Sent: Friday, June 7, 2013 7:30 PM
Subject: data




I'm sending the data.
Thank you very much.
Cec?lia

The code

final3<-read.table(file="real data cecilia.txt",sep="\t")

lst1<-split(final3,list(final3$year,final3$industry))
lst2<-lst1[lapply(lst1,nrow)>0]
lst3<-lapply(lst2,function(x) lapply(x$dimension,function(y) x[(y< (x$dimension+x$dimension*0.10)) & (y> (x$dimension-x$dimension*0.10)),]))
lst4<-lapply(lst3,function(x) x[lapply(x,nrow)==2])
lst5<-lapply(lst4,function(x)x[!duplicated(x)])
lst6<-lst5[lapply(lst5,length)>0]
lst7<-lapply(lst6,function(x) {lst<-lapply(x,function(y) y[sum(y$dummy)==1,]);lst[lapply(lst,nrow)>0]})
res<-do.call(rbind,lapply(lst7,function(x) do.call(rbind,x)))
row.names(res)<-1:nrow(res)
nrow(subset(res,res$dummy==1))
nrow(subset(res,res$dummy==0))

From bert.jacobs at figurestofacts.be  Sat Jun  8 13:09:49 2013
From: bert.jacobs at figurestofacts.be (Bert Jacobs)
Date: Sat, 8 Jun 2013 13:09:49 +0200
Subject: [R] Add blank rows to a dataframe
Message-ID: <000601ce6438$b1a7e680$14f7b380$@jacobs@figurestofacts.be>

Hi,

I have a vector that looks like this:
RowSel <-c(0,1,0,1,2,3,0,5,5)

Now I want to select rows from a specific dataframe DF based on that vector
like this:
SubDF <- DF[RowSel,]

So this works fine, but I was wondering how I could add blank rows add the
locations in the vector where there is a zero:
So the final dataframe should look like this:

SubDF
[1] blank row
[2] row 1
[3] blank row
[4] row 1 
[5] row 2
[6] row 3
[7] blank row
[8] row 5
[9] row 5

Do I have to use a loop for this or does there exist a straight forward
function option.

Thx,
Bert


From murdoch.duncan at gmail.com  Sat Jun  8 13:29:03 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 08 Jun 2013 07:29:03 -0400
Subject: [R] Add blank rows to a dataframe
In-Reply-To: <51b30f1b.07ae0e0a.38a3.4ff9SMTPIN_ADDED_BROKEN@mx.google.com>
References: <51b30f1b.07ae0e0a.38a3.4ff9SMTPIN_ADDED_BROKEN@mx.google.com>
Message-ID: <51B3157F.1020407@gmail.com>

On 13-06-08 7:09 AM, Bert Jacobs wrote:
> Hi,
>
> I have a vector that looks like this:
> RowSel <-c(0,1,0,1,2,3,0,5,5)
>
> Now I want to select rows from a specific dataframe DF based on that vector
> like this:
> SubDF <- DF[RowSel,]
>
> So this works fine, but I was wondering how I could add blank rows add the
> locations in the vector where there is a zero:
> So the final dataframe should look like this:
>
> SubDF
> [1] blank row
> [2] row 1
> [3] blank row
> [4] row 1
> [5] row 2
> [6] row 3
> [7] blank row
> [8] row 5
> [9] row 5
>
> Do I have to use a loop for this or does there exist a straight forward
> function option.

You don't need a loop.  Do it in two steps:  add the blank row to the 
end of the original dataframe (or a copy of it), then replace your 0 
index with the row number of that row.

Duncan Murdoch


From dimitri.liakhovitski at gmail.com  Sat Jun  8 13:47:41 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Sat, 8 Jun 2013 07:47:41 -0400
Subject: [R] splitting a string column into multiple columns faster
In-Reply-To: <1370662030.9709.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <CAN2xGJa2wfnk3bP0eyR4e1XOHqt8hcPaAgMaP9G+wByHpP511Q@mail.gmail.com>
	<1370660428.56782.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1370662030.9709.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <CAN2xGJbTSicfCA4LyX2wNcerS=bTvJQ4LGLPrM05zB969f5vTQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130608/f10e73e7/attachment.pl>

From Pietro.Parodi at willis.com  Sat Jun  8 15:20:26 2013
From: Pietro.Parodi at willis.com (Parodi, Pietro)
Date: Sat, 8 Jun 2013 13:20:26 +0000
Subject: [R] Help with multiple use of "quantile"
In-Reply-To: <1370697489.17923.YahooMailNeo@web126201.mail.ne1.yahoo.com>
References: <1370697489.17923.YahooMailNeo@web126201.mail.ne1.yahoo.com>
Message-ID: <F3ACCAAB37ABEC4786A75A15276505A235F26348@GBIPS-I-XM2.int.dir.willis.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130608/9821715c/attachment.pl>

From kydaviddoyle at gmail.com  Sat Jun  8 15:46:46 2013
From: kydaviddoyle at gmail.com (David Doyle)
Date: Sat, 8 Jun 2013 08:46:46 -0500
Subject: [R] Trying to install NADA in R 3.0.0
In-Reply-To: <CAFCoDdAe2vYvi5v9QGMLYsLoqu+qw+Rr0NR2pJxq5pde7zFiOw@mail.gmail.com>
References: <CACftpvqOat_jqDZZYmrTESKzamATn6PcY-UhtaiJ91fiWAoEVA@mail.gmail.com>
	<CAFCoDdAe2vYvi5v9QGMLYsLoqu+qw+Rr0NR2pJxq5pde7zFiOw@mail.gmail.com>
Message-ID: <CACftpvrhpmyNwMpW+zBkP2_dm8DjG-B85UNdxhhu0zWcKBahXA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130608/c4be4ae0/attachment.pl>

From jvadams at usgs.gov  Sat Jun  8 15:49:24 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Sat, 8 Jun 2013 08:49:24 -0500
Subject: [R] Help with multiple use of "quantile"
In-Reply-To: <F3ACCAAB37ABEC4786A75A15276505A235F26348@GBIPS-I-XM2.int.dir.willis.com>
References: <1370697489.17923.YahooMailNeo@web126201.mail.ne1.yahoo.com>
	<F3ACCAAB37ABEC4786A75A15276505A235F26348@GBIPS-I-XM2.int.dir.willis.com>
Message-ID: <CAN5YmCG0bvqm-LR2c=5n5G5CUPgRnNeY-tJkz+NvxrnHEjn2YA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130608/55c5e73f/attachment.pl>

From dwinsemius at comcast.net  Sat Jun  8 16:36:27 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 8 Jun 2013 07:36:27 -0700
Subject: [R] Add blank rows to a dataframe
In-Reply-To: <000601ce6438$b1a7e680$14f7b380$@jacobs@figurestofacts.be>
References: <000601ce6438$b1a7e680$14f7b380$@jacobs@figurestofacts.be>
Message-ID: <CAAED183-4796-4A20-A660-DFECF34C6963@comcast.net>


On Jun 8, 2013, at 4:09 AM, Bert Jacobs wrote:

> Hi,
> 
> I have a vector that looks like this:
> RowSel <-c(0,1,0,1,2,3,0,5,5)
> 
> Now I want to select rows from a specific dataframe DF based on that vector
> like this:
> SubDF <- DF[RowSel,]
> 
> So this works fine, but I was wondering how I could add blank rows add the
> locations in the vector where there is a zero:
> So the final dataframe should look like this:
> 
> SubDF
> [1] blank row
> [2] row 1
> [3] blank row
> [4] row 1 
> [5] row 2
> [6] row 3
> [7] blank row
> [8] row 5
> [9] row 5
> 
> Do I have to use a loop for this or does there exist a straight forward
> function option.

NA's in the selection vector will retrun an NA row, so convert those zeros to NA's :

> str(df)
'data.frame':	9 obs. of  2 variables:
 $ A: num  0 3 9 0 2 0 1 0 1
 $ B: int  1 1 1 2 2 3 3 4 4
> RowSel <-c(0,1,0,1,2,3,0,5,5)
> df[RowSel,]
    A B
1   0 1
1.1 0 1
5   3 1
9   9 1
6   2 2
6.1 2 2
> is.na(RowSel) <- RowSel==0
> df[RowSel,]
      A  B
NA   NA NA
1     0  1
NA.1 NA NA
1.1   0  1
5     3  1
9     9  1
NA.2 NA NA
6     2  2
6.1   2  2

-- 
David Winsemius
Alameda, CA, USA


From bogaso.christofer at gmail.com  Sat Jun  8 17:54:16 2013
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Sat, 8 Jun 2013 21:39:16 +0545
Subject: [R] Problem with ODBC connection
In-Reply-To: <CA+dpOJ=gLQyZmniVkrd+gKzjThe_y+dJ5fGBeGw1q6fm_rXCyQ@mail.gmail.com>
References: <CA+dpOJ=gLQyZmniVkrd+gKzjThe_y+dJ5fGBeGw1q6fm_rXCyQ@mail.gmail.com>
Message-ID: <CA+dpOJnm7HXJPg-ReXb9SDKc3q7MeUqLtg+N0znbAhn0PhO9gw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130608/9593d955/attachment.pl>

From smartpink111 at yahoo.com  Sat Jun  8 19:11:42 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 8 Jun 2013 10:11:42 -0700 (PDT)
Subject: [R] Add blank rows to a dataframe
In-Reply-To: <000601ce6438$b1a7e680$14f7b380$@jacobs@figurestofacts.be>
References: <000601ce6438$b1a7e680$14f7b380$@jacobs@figurestofacts.be>
Message-ID: <1370711502.50764.YahooMailNeo@web142601.mail.bf1.yahoo.com>

RowSel <-c(0,1,0,1,2,3,0,5,5)
set.seed(24)
DF<- as.data.frame(matrix(sample(1:40,45,replace=TRUE),ncol=5))
RowSel[!as.logical(RowSel)]<-NA
DF[RowSel,]
#???? V1 V2 V3 V4 V5
#NA?? NA NA NA NA NA
#1??? 12 11 21 24 30
#NA.1 NA NA NA NA NA
#1.1? 12 11 21 24 30
#2???? 9 25? 6 26 26
#3??? 29 15? 4? 2 28
#NA.2 NA NA NA NA NA
#5??? 27 27 30 10 19
#5.1? 27 27 30 10 19


A.K.



----- Original Message -----
From: Bert Jacobs <bert.jacobs at figurestofacts.be>
To: r-help at r-project.org
Cc: 
Sent: Saturday, June 8, 2013 7:09 AM
Subject: [R] Add blank rows to a dataframe

Hi,

I have a vector that looks like this:
RowSel <-c(0,1,0,1,2,3,0,5,5)

Now I want to select rows from a specific dataframe DF based on that vector
like this:
SubDF <- DF[RowSel,]

So this works fine, but I was wondering how I could add blank rows add the
locations in the vector where there is a zero:
So the final dataframe should look like this:

SubDF
[1] blank row
[2] row 1
[3] blank row
[4] row 1 
[5] row 2
[6] row 3
[7] blank row
[8] row 5
[9] row 5

Do I have to use a loop for this or does there exist a straight forward
function option.

Thx,
Bert

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Sat Jun  8 19:28:13 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 8 Jun 2013 10:28:13 -0700 (PDT)
Subject: [R] Help with multiple use of "quantile"
In-Reply-To: <CAN5YmCG0bvqm-LR2c=5n5G5CUPgRnNeY-tJkz+NvxrnHEjn2YA@mail.gmail.com>
References: <1370697489.17923.YahooMailNeo@web126201.mail.ne1.yahoo.com>
	<F3ACCAAB37ABEC4786A75A15276505A235F26348@GBIPS-I-XM2.int.dir.willis.com>
	<CAN5YmCG0bvqm-LR2c=5n5G5CUPgRnNeY-tJkz+NvxrnHEjn2YA@mail.gmail.com>
Message-ID: <1370712493.2586.YahooMailNeo@web142603.mail.bf1.yahoo.com>

HI,
You could also use:

set.seed(24)
aaa <- matrix(rnorm(60), ncol=3)
bbb <- matrix(runif(15), ncol=3)
ccc1<- mapply(quantile,as.data.frame(aaa),as.data.frame(bbb))
ccc <- sapply(1:dim(aaa)[2], function(i) quantile(aaa[, i], bbb[, i])) #Jean's solution

colnames(ccc1)<-NULL

? identical(ccc,ccc1)
#[1] TRUE
A.K.



----- Original Message -----
From: "Adams, Jean" <jvadams at usgs.gov>
To: "Parodi, Pietro" <Pietro.Parodi at willis.com>
Cc: "r-help at r-project.org" <r-help at r-project.org>
Sent: Saturday, June 8, 2013 9:49 AM
Subject: Re: [R] Help with multiple use of "quantile"

Try this, Pietro ...

# example data
aaa <- matrix(rnorm(60), ncol=3)
bbb <- matrix(runif(15), ncol=3)

# calculate quantiles
ccc <- sapply(1:dim(aaa)[2], function(i) quantile(aaa[, i], bbb[, i]))
# change rownames
rownames(ccc) <- seq(dim(ccc)[1])

Jean


On Sat, Jun 8, 2013 at 8:20 AM, Parodi, Pietro <Pietro.Parodi at willis.com>wrote:

> Hello
>
> I have a matrix aaa like this:
>
>? ? ? ? ? ? aa1? ? ?  aa2? ? ?  aa3
> [1,]? 8371.417? 27613.57? 1170.466
> [2,] 14317.999? 42421.82? 3423.934
> [3,] 22026.466? 59874.14? 8103.084
> [4,] 33884.986? 84506.34 19176.764
> [5,] 57954.968 129824.30 56097.310
>
> where each column represents an empirical distribution of random variates
> (normally the number of rows would be, say, 10,000 or 100,000) and a matrix
> bbb of percentiles like this:
>
> bbb
>
>? ? ? ? ? ? [,1]? ? ? [,2]? ? ? [,3]
> [1,] 0.70092980 0.8144194 0.6200732
> [2,] 0.77968803 0.5804948 0.5463661
> [3,] 0.01509415 0.9313509 0.8611973
> [4,] 0.22654757 0.6183386 0.4962867
> [5,] 0.36548835 0.6608696 0.3062784
> What I'd like to do is to apply the quantiles in the three columns of bbb
> to the columns of aaa independently, so as to obtain a matrix ccc such
> that, for example, ccc[3,1]=quantile(aaa[,1],bbb[3,1]). THe complete matrix
> is:
>
>
> ccc =? ? quantile(aaa[,1],bbb[1,1]), quantile(aaa[,2],bbb[1,2]),
> quantile(aaa[,3],bbb[1,3])
>? ? ? ? ? ?  quantile(aaa[,1],bbb[2,1]), quantile(aaa[,2],bbb[2,2]),
> quantile(aaa[,3],bbb[2,3])
>? ? ? ? ? ?  quantile(aaa[,1],bbb[3,1]), quantile(aaa[,2],bbb[3,2]),
> quantile(aaa[,3],bbb[3,3])
>? ? ? ? ? ?  quantile(aaa[,1],bbb[4,1]), quantile(aaa[,2],bbb[4,2]),
> quantile(aaa[,3],bbb[4,3])
>? ? ? ? ? ?  quantile(aaa[,1],bbb[5,1]), quantile(aaa[,2],bbb[5,2]),
> quantile(aaa[,3],bbb[5,3])
>
>
>
> Now if I only two vectors, it would be enough for me to define
> ccc=quantile(aaa,bbb). However, if I do this when aaa and bbb are matrix,
> quantile(aaa,bbb) does something else -- it gives the percentiles bbb of
> the whole set of matrix elements rather than considering separately the
> quantiles of the different columns.
>
> I suspect I'll need to use "apply" in some form but have been able to come
> up with the correct form.
>
> As you might have imagined, this arises in the? context of simulating
> random variables from different distribution in empirical form that are
> correlated through a copula.
>
> Thanks in advance for your help!
>
> Pietro
> _
>
> ______________________________________________________________________
>
> For information pertaining to Willis' email confidentiality and monitoring
> policy, usage restrictions, or for specific company registration and
> regulatory status information, please visit
> http://www.willis.com/email_trailer.aspx
>
> We are now able to offer our clients an encrypted email capability for
> secure communication purposes. If you wish to take advantage of this
> service or learn more about it, please let me know or contact your Client
> Advocate for full details. ~W67897
> ______________________________________________________________________
>
>? ? ? ?  [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ruipbarradas at sapo.pt  Sat Jun  8 19:52:20 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 08 Jun 2013 18:52:20 +0100
Subject: [R] Help with multiple use of "quantile"
In-Reply-To: <1370712493.2586.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1370697489.17923.YahooMailNeo@web126201.mail.ne1.yahoo.com>
	<F3ACCAAB37ABEC4786A75A15276505A235F26348@GBIPS-I-XM2.int.dir.willis.com>
	<CAN5YmCG0bvqm-LR2c=5n5G5CUPgRnNeY-tJkz+NvxrnHEjn2YA@mail.gmail.com>
	<1370712493.2586.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <51B36F54.5040204@sapo.pt>

Hello,

And you really don't need colnames(ccc1) <- NULL, there's a USE.NAMES 
argument to mapply. Just set it to FALSE.

Rui Barradas

Em 08-06-2013 18:28, arun escreveu:
> HI,
> You could also use:
>
> set.seed(24)
> aaa <- matrix(rnorm(60), ncol=3)
> bbb <- matrix(runif(15), ncol=3)
> ccc1<- mapply(quantile,as.data.frame(aaa),as.data.frame(bbb))
> ccc <- sapply(1:dim(aaa)[2], function(i) quantile(aaa[, i], bbb[, i])) #Jean's solution
>
> colnames(ccc1)<-NULL
>
>    identical(ccc,ccc1)
> #[1] TRUE
> A.K.
>
>
>
> ----- Original Message -----
> From: "Adams, Jean" <jvadams at usgs.gov>
> To: "Parodi, Pietro" <Pietro.Parodi at willis.com>
> Cc: "r-help at r-project.org" <r-help at r-project.org>
> Sent: Saturday, June 8, 2013 9:49 AM
> Subject: Re: [R] Help with multiple use of "quantile"
>
> Try this, Pietro ...
>
> # example data
> aaa <- matrix(rnorm(60), ncol=3)
> bbb <- matrix(runif(15), ncol=3)
>
> # calculate quantiles
> ccc <- sapply(1:dim(aaa)[2], function(i) quantile(aaa[, i], bbb[, i]))
> # change rownames
> rownames(ccc) <- seq(dim(ccc)[1])
>
> Jean
>
>
> On Sat, Jun 8, 2013 at 8:20 AM, Parodi, Pietro <Pietro.Parodi at willis.com>wrote:
>
>> Hello
>>
>> I have a matrix aaa like this:
>>
>>              aa1       aa2       aa3
>> [1,]  8371.417  27613.57  1170.466
>> [2,] 14317.999  42421.82  3423.934
>> [3,] 22026.466  59874.14  8103.084
>> [4,] 33884.986  84506.34 19176.764
>> [5,] 57954.968 129824.30 56097.310
>>
>> where each column represents an empirical distribution of random variates
>> (normally the number of rows would be, say, 10,000 or 100,000) and a matrix
>> bbb of percentiles like this:
>>
>> bbb
>>
>>              [,1]      [,2]      [,3]
>> [1,] 0.70092980 0.8144194 0.6200732
>> [2,] 0.77968803 0.5804948 0.5463661
>> [3,] 0.01509415 0.9313509 0.8611973
>> [4,] 0.22654757 0.6183386 0.4962867
>> [5,] 0.36548835 0.6608696 0.3062784
>> What I'd like to do is to apply the quantiles in the three columns of bbb
>> to the columns of aaa independently, so as to obtain a matrix ccc such
>> that, for example, ccc[3,1]=quantile(aaa[,1],bbb[3,1]). THe complete matrix
>> is:
>>
>>
>> ccc =    quantile(aaa[,1],bbb[1,1]), quantile(aaa[,2],bbb[1,2]),
>> quantile(aaa[,3],bbb[1,3])
>>               quantile(aaa[,1],bbb[2,1]), quantile(aaa[,2],bbb[2,2]),
>> quantile(aaa[,3],bbb[2,3])
>>               quantile(aaa[,1],bbb[3,1]), quantile(aaa[,2],bbb[3,2]),
>> quantile(aaa[,3],bbb[3,3])
>>               quantile(aaa[,1],bbb[4,1]), quantile(aaa[,2],bbb[4,2]),
>> quantile(aaa[,3],bbb[4,3])
>>               quantile(aaa[,1],bbb[5,1]), quantile(aaa[,2],bbb[5,2]),
>> quantile(aaa[,3],bbb[5,3])
>>
>>
>>
>> Now if I only two vectors, it would be enough for me to define
>> ccc=quantile(aaa,bbb). However, if I do this when aaa and bbb are matrix,
>> quantile(aaa,bbb) does something else -- it gives the percentiles bbb of
>> the whole set of matrix elements rather than considering separately the
>> quantiles of the different columns.
>>
>> I suspect I'll need to use "apply" in some form but have been able to come
>> up with the correct form.
>>
>> As you might have imagined, this arises in the  context of simulating
>> random variables from different distribution in empirical form that are
>> correlated through a copula.
>>
>> Thanks in advance for your help!
>>
>> Pietro
>> _
>>
>> ______________________________________________________________________
>>
>> For information pertaining to Willis' email confidentiality and monitoring
>> policy, usage restrictions, or for specific company registration and
>> regulatory status information, please visit
>> http://www.willis.com/email_trailer.aspx
>>
>> We are now able to offer our clients an encrypted email capability for
>> secure communication purposes. If you wish to take advantage of this
>> service or learn more about it, please let me know or contact your Client
>> Advocate for full details. ~W67897
>> ______________________________________________________________________
>>
>>           [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>      [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From nfultz at gmail.com  Sat Jun  8 21:17:55 2013
From: nfultz at gmail.com (Neal Fultz)
Date: Sat, 8 Jun 2013 12:17:55 -0700
Subject: [R] recode: how to avoid nested ifelse
In-Reply-To: <CANz9Z_J=x6NQHuhmkDxj=jV+K6u_8ZcwfZuBvEw5TfXV3NoUmQ@mail.gmail.com>
References: <CAErODj8Tr6KBNweyFy2kXYmqn-CEs=cDJJT0bwoaRc0Jxd-CMw@mail.gmail.com>
	<CANz9Z_LuJjikRcwyi2JF5byL9fbRPZ=kxD7Rq4q2GwX=ZCwMNQ@mail.gmail.com>
	<20130608022553.GY1685@neal-SP35>
	<CANz9Z_J=x6NQHuhmkDxj=jV+K6u_8ZcwfZuBvEw5TfXV3NoUmQ@mail.gmail.com>
Message-ID: <20130608191755.GZ1685@neal-SP35>

rowSums and Reduce will have the same problems with bad data you alluded to earlier, eg
cg = 1, hs = 0

But that's something to check for with crosstabs anyway.


Side note: you should check out the microbenchmark pkg, it's quite handy.


R>require(microbenchmark)
R>microbenchmark(
+   f1(cg,hs,es),
+   f2(cg,hs,es),
+   f3(cg,hs,es),
+   f4(cg,hs,es)
+ )
Unit: microseconds
           expr       min         lq     median         uq       max neval
 f1(cg, hs, es) 23029.848 25279.9660 27024.9640 29996.6810 55444.112   100
 f2(cg, hs, es)   730.665   755.5750   811.7445   934.3320  6179.798   100
 f3(cg, hs, es)    85.029   101.6785   129.8605   196.2835  2820.187   100
 f4(cg, hs, es)   762.232   804.4850   843.7170  1079.0800 24869.548   100

On Fri, Jun 07, 2013 at 08:03:26PM -0700, Joshua Wiley wrote:
> I still argue for na.rm=FALSE, but that is cute, also substantially faster
> 
> f1 <- function(x1, x2, x3) do.call(paste0, list(x1, x2, x3))
> f2 <- function(x1, x2, x3) pmax(3*x3, 2*x2, es, 0, na.rm=FALSE)
> f3 <- function(x1, x2, x3) Reduce(`+`, list(x1, x2, x3))
> f4 <- function(x1, x2, x3) rowSums(cbind(x1, x2, x3))
> 
> es <- rep(c(0, 0, 1, 0, 1, 0, 1, 1, NA, NA), 1000)
> hs <- rep(c(0, 0, 1, 0, 1, 0, 1, 0, 1, NA), 1000)
> cg <- rep(c(0, 0, 0, 0, 1, 0, 1, 0, NA, NA), 1000)
> 
> system.time(replicate(1000, f1(cg, hs, es)))
> system.time(replicate(1000, f2(cg, hs, es)))
> system.time(replicate(1000, f3(cg, hs, es)))
> system.time(replicate(1000, f4(cg, hs, es)))
> 
> > system.time(replicate(1000, f1(cg, hs, es)))
>    user  system elapsed
>   22.73    0.03   22.76
> > system.time(replicate(1000, f2(cg, hs, es)))
>    user  system elapsed
>    0.92    0.04    0.95
> > system.time(replicate(1000, f3(cg, hs, es)))
>    user  system elapsed
>    0.19    0.02    0.20
>  > system.time(replicate(1000, f4(cg, hs, es)))
>    user  system elapsed
>    0.95    0.03    0.98
> 
> 
> R version 3.0.0 (2013-04-03)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> 
> 
> 
> 
> On Fri, Jun 7, 2013 at 7:25 PM, Neal Fultz <nfultz at gmail.com> wrote:
> > I would do this to get the highest non-missing level:
> >
> > x <- pmax(3*cg, 2*hs, es, 0, na.rm=TRUE)
> >
> > rock chalk...
> >
> > -nfultz
> >
> > On Fri, Jun 07, 2013 at 06:24:50PM -0700, Joshua Wiley wrote:
> >> Hi Paul,
> >>
> >> Unless you have truly offended the data generating oracle*, the
> >> pattern: NA, 1, NA, should be a data entry error --- graduating HS
> >> implies graduating ES, no?  I would argue fringe cases like that
> >> should be corrected in the data, not through coding work arounds.
> >> Then you can just do:
> >>
> >> x <- do.call(paste0, list(es, hs, cg))
> >>
> >> > table(factor(x, levels = c("000", "100", "110", "111"), labels = c("none", "es","hs", "cg")))
> >> none   es   hs   cg
> >>    4    1    1    2
> >>
> >> Cheers,
> >>
> >> Josh
> >>
> >> *Drawn from comments by Judea Pearl one lively session.
> >>
> >>
> >> On Fri, Jun 7, 2013 at 6:13 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> >> > In our Summer Stats Institute, I was asked a question that amounts to
> >> > reversing the effect of the contrasts function (reconstruct an ordinal
> >> > predictor from a set of binary columns). The best I could think of was to
> >> > link together several ifelse functions, and I don't think I want to do this
> >> > if the example became any more complicated.
> >> >
> >> > I'm unable to remember a less error prone method :). But I expect you might.
> >> >
> >> > Here's my working example code
> >> >
> >> > ## Paul Johnson <pauljohn at ku.edu>
> >> > ## 2013-06-07
> >> >
> >> > ## We need to create an ordinal factor from these indicators
> >> > ## completed elementary school
> >> > es <- c(0, 0, 1, 0, 1, 0, 1, 1)
> >> > ## completed high school
> >> > hs <- c(0, 0, 1, 0, 1, 0, 1, 0)
> >> > ## completed college graduate
> >> > cg <- c(0, 0, 0, 0, 1, 0, 1, 0)
> >> >
> >> > ed <- ifelse(cg == 1, 3,
> >> >              ifelse(hs == 1, 2,
> >> >                     ifelse(es == 1, 1, 0)))
> >> >
> >> > edf <- factor(ed, levels = 0:3,  labels = c("none", "es", "hs", "cg"))
> >> > data.frame(es, hs, cg, ed, edf)
> >> >
> >> > ## Looks OK, but what if there are missings?
> >> > es <- c(0, 0, 1, 0, 1, 0, 1, 1, NA, NA)
> >> > hs <- c(0, 0, 1, 0, 1, 0, 1, 0, 1, NA)
> >> > cg <- c(0, 0, 0, 0, 1, 0, 1, 0, NA, NA)
> >> > ed <- ifelse(cg == 1, 3,
> >> >              ifelse(hs == 1, 2,
> >> >                     ifelse(es == 1, 1, 0)))
> >> > cbind(es, hs, cg, ed)
> >> >
> >> > ## That's bad, ifelse returns NA too frequently.
> >> > ## Revise (becoming tedious!)
> >> >
> >> > ed <- ifelse(!is.na(cg) & cg == 1, 3,
> >> >              ifelse(!is.na(hs) & hs == 1, 2,
> >> >                     ifelse(!is.na(es) & es == 1, 1,
> >> >                            ifelse(is.na(es), NA, 0))))
> >> > cbind(es, hs, cg, ed)
> >> >
> >> >
> >> > ## Does the project director want us to worry about
> >> > ## logical inconsistencies, such as es = 0 but cg = 1?
> >> > ## I hope not.
> >> >
> >> > Thanks in advance, I hope you are having a nice summer.
> >> >
> >> > pj
> >> >
> >> > --
> >> > Paul E. Johnson
> >> > Professor, Political Science      Assoc. Director
> >> > 1541 Lilac Lane, Room 504      Center for Research Methods
> >> > University of Kansas                 University of Kansas
> >> > http://pj.freefaculty.org               http://quant.ku.edu
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >>
> >> --
> >> Joshua Wiley
> >> Ph.D. Student, Health Psychology
> >> University of California, Los Angeles
> >> http://joshuawiley.com/
> >> Senior Analyst - Elkhart Group Ltd.
> >> http://elkhartgroup.com
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> Joshua Wiley
> Ph.D. Student, Health Psychology
> University of California, Los Angeles
> http://joshuawiley.com/
> Senior Analyst - Elkhart Group Ltd.
> http://elkhartgroup.com


From friendly at yorku.ca  Sat Jun  8 22:31:57 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Sat, 08 Jun 2013 16:31:57 -0400
Subject: [R] reading a character translation table into R
Message-ID: <51B394BD.4050301@yorku.ca>

I have a txt file (attached) that defines equivalents among characters 
in latin1 (or iso-8859-1), numeric &#xxx; codes, HTML entities
and latex equivalents.  A portion of the file is shown inline below, but 
may not be rendered well in this email.

I'd like to read this into R to use as a character translation table, 
but am stuck on two things:
- The 5 fields in the file are column-aligned and are separated by 2+ 
white space characters.
In perl this is trivial to read and parse via something like
         @entries = split("\n", $charTable);
         foreach (@entries) {
                 ($desc, $char, $code, $html, $tex) = split(/\s\s+/);
         }
AFAIK, the only function for reading such data is utils::read.fwf, but I 
have to specify the field widths.
I don't know of any function that allows even a simple regrex like this 
as a sep= argument.

- The TeX field contains many backslashed codes that need to be escaped 
in R. Is it necessarty
to manually edit the file to change '\pounds' --> '\\pounds', '\S' --> 
'\\S', etc. or is there something
like raw mode input that would do this where necessary?

Description                         Char
  Code      HTML        TeX
double quote                         "    &#034; &quot;
ampersand                            &    &#038; &amp        \&
apostrophe                           '    &#039; &apos;
less than                            <    &#060; &lt;        $<$
greater than                         >    &#062; &gt;        $>$
non-breaking space                   .    &#160; &nbsp;      ~
inverted exclamation                 ?    &#161; &iexcl;     !'
cent sign                            ?    &#162; &cent;
pound sterling                       ?    &#163; &pound;     \pounds
general currency sign                ?    &#164; &curren;
yen sign                             ?    &#165; &yen;
broken vertical bar                  ?    &#166; &brvbar;
section sign                         ?    &#167; &sect;      \S
umlaut (dieresis)                    ?    &#168; &uml;       \"{}
copyright                            ?    &#169; &copy;      \copyright
feminine ordinal                     ?    &#170; &ordf;      $^a$
left angle quote, guillemotleft      ?    &#171; &laquo;     \guillemotleft
not sign                             ?    &#172; &not;
soft hyphen                          ?    &#173; &shy;
registered trademark                 ?    &#174; &reg;       \textregistered
macron accent                        ?    &#175; &macr;
degree sign                          ?    &#176; &deg;       $^o$
plus or minus                        ?    &#177; &plusmn;    $\pm$
superscript two                      ?    &#178; &sup2;      $^2$
superscript three                    ?    &#179; &sup3;      $^3$
acute accent                         ?    &#180; &acute;     \'{}
micro sign                           ?    &#181; &micro;     $\mu$
paragraph sign                       ?    &#182; &para;      \P
middle dot                           ?    &#183; &middot;    $\cdot$
cedilla                              ?    &#184; &cedil;     \c{}
superscript one                      ?    &#185; &sup1;      $^1$
masculine ordinal                    ?    &#186; &ordm;      $^o$
right angle quote, guillemotright    ?    &#187; &raquo;     \guillemotright
fraction one-fourth                  ?    &#188; &frac14;    $\frac14$
fraction one-half                    ?    &#189; &frac12;    $\frac12$
fraction three-fourths               ?    &#190; &frac34;    $\frac34$
inverted question mark               ?    &#191; &iquest;    ?'
capital A, grave accent              ?    &#192; &Agrave;    \`A
capital A, acute accent              ?    &#193; &Aacute;    \'A
capital A, circumflex accent         ?    &#194; &Acirc;     \^A
capital A, tilde                     ?    &#195; &Atilde;    \~A
capital A, dieresis or umlaut mark   ?    &#196; &Auml;      \"A
capital A, ring                      ?    &#197; &Aring;     \AA
capital AE diphthong (ligature)      ?    &#198; &AElig;     \AE

-- 
Michael Friendly     Email: friendly at yorku.ca
Professor, Psychology Dept.
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    http://datavis.ca
Toronto, ONT  M3J 1P3 CANADA

-------------- next part --------------
Description                          Char Code      HTML        TeX
double quote                         "    &#034;    &quot; 
ampersand                            &    &#038;    &amp        \&     
apostrophe                           '    &#039;    &apos;
less than                            <    &#060;    &lt;        $<$
greater than                         >    &#062;    &gt;        $>$  
non-breaking space                   .    &#160;    &nbsp;      ~
inverted exclamation                 ?    &#161;    &iexcl;     !'
cent sign                            ?    &#162;    &cent;
pound sterling                       ?    &#163;    &pound;     \pounds
general currency sign                ?    &#164;    &curren;
yen sign                             ?    &#165;    &yen;
broken vertical bar                  ?    &#166;    &brvbar;
section sign                         ?    &#167;    &sect;      \S
umlaut (dieresis)                    ?    &#168;    &uml;       \"{}
copyright                            ?    &#169;    &copy;      \copyright
feminine ordinal                     ?    &#170;    &ordf;      $^a$
left angle quote, guillemotleft      ?    &#171;    &laquo;     \guillemotleft
not sign                             ?    &#172;    &not;
soft hyphen                          ?    &#173;    &shy;
registered trademark                 ?    &#174;    &reg;       \textregistered
macron accent                        ?    &#175;    &macr;
degree sign                          ?    &#176;    &deg;       $^o$
plus or minus                        ?    &#177;    &plusmn;    $\pm$
superscript two                      ?    &#178;    &sup2;      $^2$
superscript three                    ?    &#179;    &sup3;      $^3$
acute accent                         ?    &#180;    &acute;     \'{}
micro sign                           ?    &#181;    &micro;     $\mu$
paragraph sign                       ?    &#182;    &para;      \P
middle dot                           ?    &#183;    &middot;    $\cdot$
cedilla                              ?    &#184;    &cedil;     \c{}
superscript one                      ?    &#185;    &sup1;      $^1$
masculine ordinal                    ?    &#186;    &ordm;      $^o$
right angle quote, guillemotright    ?    &#187;    &raquo;     \guillemotright
fraction one-fourth                  ?    &#188;    &frac14;    $\frac14$
fraction one-half                    ?    &#189;    &frac12;    $\frac12$
fraction three-fourths               ?    &#190;    &frac34;    $\frac34$
inverted question mark               ?    &#191;    &iquest;    ?'
capital A, grave accent              ?    &#192;    &Agrave;    \`A
capital A, acute accent              ?    &#193;    &Aacute;    \'A
capital A, circumflex accent         ?    &#194;    &Acirc;     \^A
capital A, tilde                     ?    &#195;    &Atilde;    \~A
capital A, dieresis or umlaut mark   ?    &#196;    &Auml;      \"A
capital A, ring                      ?    &#197;    &Aring;     \AA
capital AE diphthong (ligature)      ?    &#198;    &AElig;     \AE
capital C, cedilla                   ?    &#199;    &Ccedil;    \c{C}
capital E, grave accent              ?    &#200;    &Egrave;    \`E
capital E, acute accent              ?    &#201;    &Eacute;    \'E
capital E, circumflex accent         ?    &#202;    &Ecirc;     \^E
capital E, dieresis or umlaut mark   ?    &#203;    &Euml;      \"E
capital I, grave accent              ?    &#204;    &Igrave;    \`I
capital I, acute accent              ?    &#205;    &Iacute;    \'I
capital I, circumflex accent         ?    &#206;    &Icirc;     \^I
capital I, dieresis or umlaut mark   ?    &#207;    &Iuml;      \"I
capital Eth, Icelandic               ?    &#208;    &ETH;
capital N, tilde                     ?    &#209;    &Ntilde;    \~N
capital O, grave accent              ?    &#210;    &Ograve;    \`O
capital O, acute accent              ?    &#211;    &Oacute;    \'O
capital O, circumflex accent         ?    &#212;    &Ocirc;     \^O
capital O, tilde                     ?    &#213;    &Otilde;    \~O
capital O, dieresis or umlaut mark   ?    &#214;    &Ouml;      \"O
multiply sign                        ?    &#215;    &times;     $\times$
capital O, slash                     ?    &#216;    &Oslash;    {\O}
capital U, grave accent              ?    &#217;    &Ugrave;    \`U
capital U, acute accent              ?    &#218;    &Uacute;    \'U
capital U, circumflex accent         ?    &#219;    &Ucirc;     \^U
capital U, dieresis or umlaut mark   ?    &#220;    &Uuml;      \"A
capital Y, acute accent              ?    &#221;    &Yacute;    \'Y
capital THORN, Icelandic             ?    &#222;    &THORN;     \TH
small sharp s, German (sz ligature)  ?    &#223;    &szlig;     \ss
small a, grave accent                ?    &#224;    &agrave;    \`a
small a, acute accent                ?    &#225;    &aacute;    \'a
small a, circumflex accent           ?    &#226;    &acirc;     \^a
small a, tilde                       ?    &#227;    &atilde;    \~a
small a, dieresis or umlaut mark     ?    &#228;    &auml;      \"a
small a, ring                        ?    &#229;    &aring;     \aa
small ae diphthong (ligature)        ?    &#230;    &aelig;     \ae
small c, cedilla                     ?    &#231;    &ccedil;    \c{c}
small e, grave accent                ?    &#232;    &egrave;    \`e
small e, acute accent                ?    &#233;    &eacute;    \'e
small e, circumflex accent           ?    &#234;    &ecirc;     \^e
small e, dieresis or umlaut mark     ?    &#235;    &euml;      \"e
small i, grave accent                ?    &#236;    &igrave;    \`i
small i, acute accent                ?    &#237;    &iacute;    \'i
small i, circumflex accent           ?    &#238;    &icirc;     \^i
small i, dieresis or umlaut mark     ?    &#239;    &iuml;      \"i
small eth, Icelandic                 ?    &#240;    &eth;
small n, tilde                       ?    &#241;    &ntilde;    \~n
small o, grave accent                ?    &#242;    &ograve;    \`o
small o, acute accent                ?    &#243;    &oacute;    \'o
small o, circumflex accent           ?    &#244;    &ocirc;     \^o
small o, tilde                       ?    &#245;    &otilde;    \~o
small o, dieresis or umlaut mark     ?    &#246;    &ouml;      \"o
division sign                        ?    &#247;    &divide;    $\divide$
small o, slash                       ?    &#248;    &oslash;    {\o}
small u, grave accent                ?    &#249;    &ugrave;    \`u
small u, acute accent                ?    &#250;    &uacute;    \'u
small u, circumflex accent           ?    &#251;    &ucirc;     \^u
small u, dieresis or umlaut mark     ?    &#252;    &uuml;      \"u
small y, acute accent                ?    &#253;    &yacute;    \'y
small thorn, Icelandic               ?    &#254;    &thorn;     \th
small y, dieresis or umlaut mark     ?    &#255;    &yuml;      \"y

From murdoch.duncan at gmail.com  Sat Jun  8 22:51:33 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 08 Jun 2013 16:51:33 -0400
Subject: [R] reading a character translation table into R
In-Reply-To: <51B394BD.4050301@yorku.ca>
References: <51B394BD.4050301@yorku.ca>
Message-ID: <51B39955.1080902@gmail.com>

On 13-06-08 4:31 PM, Michael Friendly wrote:
> I have a txt file (attached) that defines equivalents among characters
> in latin1 (or iso-8859-1), numeric &#xxx; codes, HTML entities
> and latex equivalents.  A portion of the file is shown inline below, but
> may not be rendered well in this email.
>
> I'd like to read this into R to use as a character translation table,
> but am stuck on two things:
> - The 5 fields in the file are column-aligned and are separated by 2+
> white space characters.
> In perl this is trivial to read and parse via something like
>           @entries = split("\n", $charTable);
>           foreach (@entries) {
>                   ($desc, $char, $code, $html, $tex) = split(/\s\s+/);
>           }
> AFAIK, the only function for reading such data is utils::read.fwf, but I
> have to specify the field widths.
> I don't know of any function that allows even a simple regrex like this
> as a sep= argument.

I see two ways to do this.  Work out the column numbers and use 
read.fwf, or read whole lines, and use sub() to extract columns.  The 
latter is pretty close to the spirit of the Perl method, e.g.

lines <- readLines( filename )
regex <- paste(rep("([^[:space:]]*)[[:space:]]*", 5), collapse="")
desc <- sub(regex, "\\1", lines)
char <- sub(regex, "\\2", lines)
etc.

(Actually, this doesn't work, because the desc field contains embedded 
spaces; I don't think the Perl would work either.  But if you can work 
out the regexp to match the first field, or just extract it using 
substr(), you're good.)

Duncan Murdoch

>
> - The TeX field contains many backslashed codes that need to be escaped
> in R. Is it necessarty
> to manually edit the file to change '\pounds' --> '\\pounds', '\S' -->
> '\\S', etc. or is there something
> like raw mode input that would do this where necessary?
>
> Description                         Char
>    Code      HTML        TeX
> double quote                         "    &#034; &quot;
> ampersand                            &    &#038; &amp        \&
> apostrophe                           '    &#039; &apos;
> less than                            <    &#060; &lt;        $<$
> greater than                         >    &#062; &gt;        $>$
> non-breaking space                   .    &#160; &nbsp;      ~
> inverted exclamation                 ?    &#161; &iexcl;     !'
> cent sign                            ?    &#162; &cent;
> pound sterling                       ?    &#163; &pound;     \pounds
> general currency sign                ?    &#164; &curren;
> yen sign                             ?    &#165; &yen;
> broken vertical bar                  ?    &#166; &brvbar;
> section sign                         ?    &#167; &sect;      \S
> umlaut (dieresis)                    ?    &#168; &uml;       \"{}
> copyright                            ?    &#169; &copy;      \copyright
> feminine ordinal                     ?    &#170; &ordf;      $^a$
> left angle quote, guillemotleft      ?    &#171; &laquo;     \guillemotleft
> not sign                             ?    &#172; &not;
> soft hyphen                          ?    &#173; &shy;
> registered trademark                 ?    &#174; &reg;       \textregistered
> macron accent                        ?    &#175; &macr;
> degree sign                          ?    &#176; &deg;       $^o$
> plus or minus                        ?    &#177; &plusmn;    $\pm$
> superscript two                      ?    &#178; &sup2;      $^2$
> superscript three                    ?    &#179; &sup3;      $^3$
> acute accent                         ?    &#180; &acute;     \'{}
> micro sign                           ?    &#181; &micro;     $\mu$
> paragraph sign                       ?    &#182; &para;      \P
> middle dot                           ?    &#183; &middot;    $\cdot$
> cedilla                              ?    &#184; &cedil;     \c{}
> superscript one                      ?    &#185; &sup1;      $^1$
> masculine ordinal                    ?    &#186; &ordm;      $^o$
> right angle quote, guillemotright    ?    &#187; &raquo;     \guillemotright
> fraction one-fourth                  ?    &#188; &frac14;    $\frac14$
> fraction one-half                    ?    &#189; &frac12;    $\frac12$
> fraction three-fourths               ?    &#190; &frac34;    $\frac34$
> inverted question mark               ?    &#191; &iquest;    ?'
> capital A, grave accent              ?    &#192; &Agrave;    \`A
> capital A, acute accent              ?    &#193; &Aacute;    \'A
> capital A, circumflex accent         ?    &#194; &Acirc;     \^A
> capital A, tilde                     ?    &#195; &Atilde;    \~A
> capital A, dieresis or umlaut mark   ?    &#196; &Auml;      \"A
> capital A, ring                      ?    &#197; &Aring;     \AA
> capital AE diphthong (ligature)      ?    &#198; &AElig;     \AE
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dimitri.liakhovitski at gmail.com  Sat Jun  8 23:59:49 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Sat, 8 Jun 2013 17:59:49 -0400
Subject: [R] splitting a string column into multiple columns faster
In-Reply-To: <CAN2xGJbTSicfCA4LyX2wNcerS=bTvJQ4LGLPrM05zB969f5vTQ@mail.gmail.com>
References: <CAN2xGJa2wfnk3bP0eyR4e1XOHqt8hcPaAgMaP9G+wByHpP511Q@mail.gmail.com>
	<1370660428.56782.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1370662030.9709.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CAN2xGJbTSicfCA4LyX2wNcerS=bTvJQ4LGLPrM05zB969f5vTQ@mail.gmail.com>
Message-ID: <CAN2xGJaSCKP1ai2N8VDGj68vhOTfcHMazZ4HnEeoyn8+-m98mg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130608/e39de080/attachment.pl>

From smartpink111 at yahoo.com  Sun Jun  9 01:08:40 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 8 Jun 2013 16:08:40 -0700 (PDT)
Subject: [R] splitting a string column into multiple columns faster
In-Reply-To: <CAN2xGJaSCKP1ai2N8VDGj68vhOTfcHMazZ4HnEeoyn8+-m98mg@mail.gmail.com>
References: <CAN2xGJa2wfnk3bP0eyR4e1XOHqt8hcPaAgMaP9G+wByHpP511Q@mail.gmail.com>
	<1370660428.56782.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1370662030.9709.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CAN2xGJbTSicfCA4LyX2wNcerS=bTvJQ4LGLPrM05zB969f5vTQ@mail.gmail.com>
	<CAN2xGJaSCKP1ai2N8VDGj68vhOTfcHMazZ4HnEeoyn8+-m98mg@mail.gmail.com>
Message-ID: <1370732920.50674.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi Dimitri,
No problem.
I noticed that it is slower with more number of rows.? You could use data.table().
##1e6 rows
l1<- letters[1:10]
s1<-sapply(seq_along(l1),function(i) paste(rep(l1[i],3),collapse=""))
set.seed(24)
x2<-data.frame(x=paste(paste0(sample(s1,1e6,replace=TRUE),sample(1:15,1e6,replace=TRUE)),paste0(sample(s1,1e6,replace=TRUE),sample(1:15,1e6,replace=TRUE)),paste0(sample(s1,1e6,replace=TRUE),sample(1:15,1e6,replace=TRUE)),sep="_"),stringsAsFactors=FALSE)
system.time(resNew2<-data.frame(x=x2,read.table(text=gsub("[A-Za-z]","",x2[,1]),sep="_",header=FALSE),stringsAsFactors=FALSE))
#
#?? user? system elapsed 
#363.383?? 0.036 364.153 


library(data.table)
dt2<- data.table(x2)
system.time({
?dt2[,xNew:= gsub("[A-Za-z]","",x),]
?dt2[,V1:=unlist(strsplit(xNew,split="_"))[[1]],by=xNew]
?dt2[,V2:=unlist(strsplit(xNew,split="_"))[[2]],by=xNew]
?dt2[,V3:=unlist(strsplit(xNew,split="_"))[[3]],by=xNew]
?dt3<- subset(dt2,select=-2)
})
# user? system elapsed 
#? 3.076?? 0.004?? 3.085?
dim(resNew2)
#[1] 1000000?????? 4
?dim(dt3)
#[1] 1000000?????? 4


?head(resNew2)
#???????????????? x V1 V2 V3
#1? ccc12_ccc3_ggg8 12? 3? 8
#2? ccc8_ccc1_fff11? 8? 1 11
#3 hhh15_ggg2_hhh13 15? 2 13
#4?? fff9_bbb3_ccc9? 9? 3? 9
#5? ggg4_eee2_jjj14? 4? 2 14
#6? jjj7_ddd9_bbb15? 7? 9 15


?head(dt3)
#????????????????? x V1 V2 V3
#1:? ccc12_ccc3_ggg8 12? 3? 8
#2:? ccc8_ccc1_fff11? 8? 1 11
#3: hhh15_ggg2_hhh13 15? 2 13
#4:?? fff9_bbb3_ccc9? 9? 3? 9
#5:? ggg4_eee2_jjj14? 4? 2 14
#6:? jjj7_ddd9_bbb15? 7? 9 15
A.K.


________________________________
From: Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Cc: R help <r-help at r-project.org> 
Sent: Saturday, June 8, 2013 5:59 PM
Subject: Re: [R] splitting a string column into multiple columns faster



Thanks again, guys!
Arun's method worked. I have over 270,000 rows and it took me 1 min.
Dimitri



On Sat, Jun 8, 2013 at 7:47 AM, Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com> wrote:

Thank you so much, Jorge and Arun - I'll give it a try!
>Dimitri
>
>
>
>On Fri, Jun 7, 2013 at 11:27 PM, arun <smartpink111 at yahoo.com> wrote:
>
>HI,
>>Tried it on 1e5 row dataset:
>>
>>l1<- letters[1:10]
>>s1<-sapply(seq_along(l1),function(i) paste(rep(l1[i],3),collapse=""))
>>set.seed(24)
>>x1<-data.frame(x=paste(paste0(sample(s1,1e5,replace=TRUE),sample(1:15,1e5,replace=TRUE)),paste0(sample(s1,1e5,replace=TRUE),sample(1:15,1e5,replace=TRUE)),paste0(sample(s1,1e5,replace=TRUE),sample(1:15,1e5,replace=TRUE)),sep="_"),stringsAsFactors=FALSE)
>>system.time(resNew<-data.frame(x=x1,read.table(text=gsub("[A-Za-z]","",x1[,1]),sep="_",header=FALSE),stringsAsFactors=FALSE))
>>#?? user? system elapsed
>>#? 2.712?? 0.016?? 2.732
>>
>>head(resNew)
>>
>>#????????????????? x V1 V2 V3
>>#1? ccc12_ggg2_jjj14 12? 2 14
>>#2? ccc7_ddd15_aaa11? 7 15 11
>>#3 hhh12_ddd14_fff12 12 14 12
>>#4? fff11_bbb15_aaa6 11 15? 6
>>#5?? ggg12_ccc9_ggg8 12? 9? 8
>>#6?? jjj8_eee12_eee4? 8 12? 4
>>
>>
>>A.K.
>>
>>
>>----- Original Message -----
>>
>>From: arun <smartpink111 at yahoo.com>
>>To: Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com>
>>Cc: R help <r-help at r-project.org>
>>Sent: Friday, June 7, 2013 11:00 PM
>>Subject: Re: [R] splitting a string column into multiple columns faster
>>
>>HI,
>>May be this helps:
>>
>>res<-data.frame(x=x,read.table(text=gsub("[A-Za-z]","",x[,1]),sep="_",header=FALSE),stringsAsFactors=FALSE)
>>res
>>#?????????????? x V1 V2 V3
>>#1 aaa1_bbb1_ccc3? 1? 1? 3
>>#2 aaa2_bbb3_ccc2? 2? 3? 2
>>#3 aaa3_bbb2_ccc1? 3? 2? 1
>>A.K.
>>
>>----- Original Message -----
>>From: Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com>
>>To: r-help <r-help at r-project.org>
>>Cc:
>>Sent: Friday, June 7, 2013 9:24 PM
>>Subject: [R] splitting a string column into multiple columns faster
>>
>>Hello!
>>
>>I have a column in my data frame that I have to split: I have to distill
>>the numbers from the text. Below is my example and my solution.
>>
>>x<-data.frame(x=c("aaa1_bbb1_ccc3","aaa2_bbb3_ccc2","aaa3_bbb2_ccc1"))
>>x
>>library(stringr)
>>out<-as.data.frame(str_split_fixed(x$x,"aaa",2))
>>out2<-as.data.frame(str_split_fixed(out$V2,"_bbb",2))
>>out3<-as.data.frame(str_split_fixed(out2$V2,"_ccc",2))
>>result<-cbind(x,out2[1],out3)
>>result
>>My problem is:
>>str_split.fixed is relatively slow. In my real data frame I have over
>>80,000 rows so that it takes almost 30 seconds to run just one line (like
>>out<-... above)
>>And it's even slower because I have to do it step-by-step many times.
>>
>>Any way to do it by specifying all 3 delimiters at once
>>("aaa","_bbb","_ccc") and then split it in one swoop into a data frame with
>>several columns?
>>
>>Thanks a lot for any pointers!
>>
>>--
>>Dimitri Liakhovitski
>>
>>??? [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>
>-- 
>
>Dimitri Liakhovitski


-- 

Dimitri Liakhovitski


From cmora at dal.ca  Sun Jun  9 02:14:06 2013
From: cmora at dal.ca (Camilo Mora)
Date: Sat, 08 Jun 2013 21:14:06 -0300
Subject: [R] get column index with match using apply
Message-ID: <20130608211406.14743rz3wjisxwu8@wm4.dal.ca>

Hi everyone,
This is probably something very simple but I have just not been able  
to figure it out and wonder if perhaps you may know.

I want to get the column index in which a given value is found. Values  
to match are found in the last column of the dataframe. for instance

dt=
v1   v2   v3   v4    max
0    0    1    2     2
0    1    2    0     2
1    2    3    4     4

expected output:
v1   v2   v3   v4    max colIndex
0    0    1    2     2     4
0    1    2    0     2     3
1    2    3    4     4     4

I am using:

apply(dt, 1, function(x) match(max,x))

but there is an error in setting "max" in match to be dynamic for each  
row. I have play around with different configurations and google it  
with no success.
Any input will be greatly appreciated,

best,

Camilo


Camilo Mora, Ph.D.
Department of Geography, University of Hawaii
Currently available in Colombia
Phone:   Country code: 57
          Provider code: 313
          Phone 776 2282
          From the USA or Canada you have to dial 011 57 313 776 2282
http://www.soc.hawaii.edu/mora/


From matteo.pettinari at gmail.com  Sat Jun  8 13:58:38 2013
From: matteo.pettinari at gmail.com (matteo pettinari)
Date: Sat, 8 Jun 2013 13:58:38 +0200
Subject: [R] plot Predicted survival probabilitie
Message-ID: <CAGCbMdasUw_AX6oW4bz=yLTruqVxOB+xKUzyQgq5wcGxj-fUOQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130608/62e97432/attachment.pl>

From ron_michael70 at yahoo.com  Sat Jun  8 23:02:30 2013
From: ron_michael70 at yahoo.com (Ron Michael)
Date: Sun, 9 Jun 2013 05:02:30 +0800 (SGT)
Subject: [R] Need help on window() function of the 'zoo' package
Message-ID: <1370725350.42095.YahooMailNeo@web190506.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130609/4aac0ab2/attachment.pl>

From smartpink111 at yahoo.com  Sun Jun  9 01:47:45 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 8 Jun 2013 16:47:45 -0700 (PDT)
Subject: [R] Subset dataframe with loop searching for unique values in
	two columns
Message-ID: <1370735265.59507.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
You could try this:

dat2<- read.table(text='
?case pin some_data
?"A"? "1" "data"? 
"A"? "2" "data"? 
"A"? "1" "data"? 
"A"? "2" "data"? 
"B"? "1" "data"? 
"B"? "2" "data"
',sep="",header=TRUE,stringsAsFactors=FALSE)? 
dat2[!duplicated(dat2[,1:2]),]
#? case pin some_data
#1??? A?? 1????? data
#2??? A?? 2????? data
#5??? B?? 1????? data
#6??? B?? 2????? data
#or

?dat2[row.names(unique(dat2[,1:2])),] ##assuming that the third column is different for the duplicated `case` and `pin`
?# case pin some_data
#1 ?? A?? 1????? data
#2??? A?? 2????? data
#5??? B?? 1????? data
#6??? B?? 2????? data


#If `some_data` is same for duplicated rows:
unique(dat2)
#? case pin some_data
#1??? A?? 1????? data
#2??? A?? 2????? data
#5??? B?? 1????? data
#6??? B?? 2????? data


A.K.


Hello, 

First off, I'm sure that this is posted somewhere but I've not 
been able to find what I'm looking for. Please forgive the duplication 
and thank you for your help!!!! 

I have a crime dataset of over 500k observations in one file. To
 simplify my problem, I have a dataframe that has a "case" ID in one 
column, a personal ID number (pin) in another, and associated "data" in 
subsequent columns. 

Example: 
? ? ?case pin some_data 
[1,] "A" ?"1" "data" ? 
[2,] "A" ?"2" "data" ? 
[3,] "A" ?"1" "data" ? 
[4,] "A" ?"2" "data" ? 
[5,] "B" ?"1" "data" ? 
[6,] "B" ?"2" "data" ? 

I would like to subset the data so that only unique PINs and CASES are left with the subsequent data 

? ? ?case pin some_data 
[1,] "A" ?"1" "data" ? 
[2,] "A" ?"2" "data" ? 
? 
[5,] "B" ?"1" "data" ? 
[6,] "B" ?"2" "data" ? 

I'm teaching my self how to program in R and I'm thinking that I want a loop to say something like: 
- find and keep first row of unique PIN & CASE 
- if PIN is duplicate but CASE is different, keep first row of dupe PIN & new CASE 

Longer Explanation: 
The PIN identifies an arrested offender. I want to check and see if 
there was recidivism, repeat offenses and arrests, for each 
offender/PIN. The way I can do that is by checking whether a PIN has 
multiple CASE numbers. I also want to keep the single arrests in the 
dataset too. I have over 6 million cases for several years. 

I hope this makes sense, I've been banging my head for a while on this one and really would appreciate the help!!


From cdwilliamson at cmu.edu  Sat Jun  8 21:35:37 2013
From: cdwilliamson at cmu.edu (Court)
Date: Sat, 8 Jun 2013 12:35:37 -0700 (PDT)
Subject: [R] Error Object Not Found
Message-ID: <1370720137364-4669041.post@n4.nabble.com>

Hello, 

I am having difficulty with a command.  An error message pops up saying:
Error: object 'RWGJ.wload' not found.  I have installed the packages needed
to run the analysis, and have saved them to my working directory.



--
View this message in context: http://r.789695.n4.nabble.com/Error-Object-Not-Found-tp4669041.html
Sent from the R help mailing list archive at Nabble.com.


From luyongfa at msu.edu  Sat Jun  8 22:19:32 2013
From: luyongfa at msu.edu (luyongfa at msu.edu)
Date: Sat, 08 Jun 2013 16:19:32 -0400
Subject: [R] R-help: insufficient space problem occurred during inversion of
 sparse matrix
Message-ID: <20130608161932.1458290hffcad1as@mail.msu.edu>


Hi everyone,

I have one problem with sparse matrix(package "SparseM"). I tried to  
inverse a sparse matrix with solve function in SparseM package. But I  
got warning:Error in .local(x, ...) : insufficient space.

> p=solve(coeff,tmpmax=120*nrow(coeff))
Error in .local(x, ...) : insufficient space

I read the manual and also google a lot and I did not find useful  
information so far. PS: I have increased the limited memory in R  
already.

Anyone can provide suggestion on this problem?

Thanks


From marcolondonuk at gmail.com  Sat Jun  8 15:21:27 2013
From: marcolondonuk at gmail.com (Marco Bianchi)
Date: Sat, 8 Jun 2013 14:21:27 +0100
Subject: [R] colour coded dotchart
Message-ID: <CA+ckjv03wZoP7FT7dtahRnUhFQEHvgqGWHCKYPpWWvPrbXFT_A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130608/177406ed/attachment.pl>

From nadsim88 at hotmail.com  Sat Jun  8 20:53:15 2013
From: nadsim88 at hotmail.com (mansor nad)
Date: Sun, 9 Jun 2013 02:53:15 +0800
Subject: [R] help needed! RMSE
Message-ID: <COL127-W47BAF01B488A83352225B6D39A0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130609/df66a7c2/attachment.pl>

From rex at nosyntax.net  Sun Jun  9 00:27:34 2013
From: rex at nosyntax.net (rex)
Date: Sat, 8 Jun 2013 15:27:34 -0700
Subject: [R] CGIwithR installation failure
Message-ID: <20130608222734.GD31844@ninja.nosyntax.net>

Hello,

CGIwithR apparently is not available on CRAN for R 2.15.x, so I
downloaded the source (0.73) and tried:

~/Downloads$ R CMD INSTALL CGIwithR
* installing to library ?/home/rex/R/x86_64-pc-linux-gnu-library/2.15?
* installing *source* package ?CGIwithR? ...
configure: creating ./config.status
config.status: creating R/CGIwithR.R

       *****************************************

   After the installation of this R package is complete
   copy the files R.cgi and .Rprofile in
       /home/rex/R/x86_64-pc-linux-gnu-library/2.15/CGIwithR/cgi-bin/
   to the cgi-bin area of your Web server. If necessary, 
   modify the settings in the first part of R.cgi to 
   suit your local configuration.

       *****************************************

** R
Error in parse(outFile) : embedded nul in string: '\0'
ERROR: unable to collate and parse R files for package ?CGIwithR?


Any suggestions, including using a different package, appreciated.

Background: I want to solve the classic diet linear programming
problem. The CGI code needs to parse a POST, access a MySQL DB, solve
the problem (probably using the linprog package), and present the
solution to the vistor. I've done CGI programming in Python, but
not in R and don't know if CGIwithR is a good choice. It hasn't
been updated since 2005, so a more current package may be a better
choice. OTOH, my needs are (currently) simple so CGIwithR may
be an OK choice.

I've a Python version that does the above, except for finding the
lowest cost diet that meets constraints. The Python input form will be
used in the R version (no point in reinventing the wheel).

http://www.nosyntax.net/birdnutrit/

Thanks for any help.

-rex
-- 
If at first you do succeed, try not to look astonished.


From thiask at gmx.net  Sat Jun  8 15:38:45 2013
From: thiask at gmx.net (mathias kuhnt)
Date: Sat, 08 Jun 2013 15:38:45 +0200
Subject: [R] segfault -- address 0x29, cause 'memory not mapped'
Message-ID: <51B333E5.9060800@gmx.net>

Dear List,

after a night of calculating, R says goodbye with a segmentation fault.

 *** caught segfault ***
address 0x29, cause 'memory not mapped'

In my functions I subsequently read in network files of about 20KB using
the IGraph package. Admittedly, I read in about 1 million files, in
total 20GB. Still, the function saves the data to the same object and
memory of the prior file should be freed.

The crash occurs after some hours but not at the same time, last time
after having read in 99% of the files. It probably depends on what I did
before I started the function.

Can anybody tell me if these are limitations of the program and I have
to live with it or am I doing something wrong? Is it a general R problem
or rather one of the IGraph package?

Thanks in advance,
Mathias


here the code:
#####################################################
library(igraph)

modnumber<-1200
its<-1000
seriespath<-"/daten/netgen_series/series_m1q2/"
mylim<-200
max<-100
startval<-1


sampledegcorr <- function (model, its, max)
# I suppose it does not matter what I do here but as you see I read in
1000 network files and analyze them
{
    dc<-rep(NA,max)
    for (i in 0:(its-1))
    {
        net<-read.graph(paste(seriespath,model,"/",i,".net", sep =
""),format="pajek")
        net<-simplify(net)
        ndeg <- sapply(V(net),function(x)
mean(degree(net,neighbors(net,x))-1))
        bo<-stats.bin(degree(net),ndeg,breaks=seq(-0.5,max ,1))
        dc<-cbind(dc,bo$stats[2,])
    }
    dck<-as.vector(apply(dc,1,mean, na.rm=T))
    return(cbind(seq(0,max-1,1),dck))
}


dc<-seq(0,max-1,1)
for (i in startval:(modnumber))
# here i start the function above with 1200 different networks
{
    print(paste("calculating model ", i, sep=""))
    dc<-cbind(dc,sampledegcorr(paste("m", i, sep=""),its,mylim)[,2])
    save(dc,file="series_m1q2_dc_results.RData")
}
######################################################

here my specs:

R 3.0.1-3precise
R crashed with SIGSEGV in Rf_StringTrue()
Ubuntu 12.04.1
4 GB RAM


From rolf.turner at xtra.co.nz  Sun Jun  9 03:32:44 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Sun, 09 Jun 2013 13:32:44 +1200
Subject: [R] colour coded dotchart
In-Reply-To: <CA+ckjv03wZoP7FT7dtahRnUhFQEHvgqGWHCKYPpWWvPrbXFT_A@mail.gmail.com>
References: <CA+ckjv03wZoP7FT7dtahRnUhFQEHvgqGWHCKYPpWWvPrbXFT_A@mail.gmail.com>
Message-ID: <51B3DB3C.8000408@xtra.co.nz>

On 09/06/13 01:21, Marco Bianchi wrote:
> Dear R-Users,
>
> I have a vector x <- 1:10 and I would like to produce a dotchart where the
> colour of the dot is black if x <= 5 and red otherwise.
>
> If I use
>
> x <- 1:10
> dotchart(x, col="black")
>
> then all dots are obviously of black colour. Has anybody in the mailing
> list already dealt with a similar task and found a solution?

Easy-peasy:

     ccc <- ifelse(x<=5,"black","red")
     dotchart(x,col=ccc)

You need to get the hang of reading the online help.  The information
required is actually there in ?dotchart --- it's just tersely and obscurely
expressed.  A certain degree of optimism is required.  You need to
***believe*** that the information is there; then ask yourself "What
could they possibly mean by what they have written that would tell
me what I need to know?".

This is how one should interpret the exhortation "RTFM" when it is
inflicted upon one.

After a few millennia it gets easier! :-)

     cheers,

         Rolf Turner


From smartpink111 at yahoo.com  Sun Jun  9 05:48:37 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 8 Jun 2013 20:48:37 -0700 (PDT)
Subject: [R] get column index with match using apply
In-Reply-To: <20130608211406.14743rz3wjisxwu8@wm4.dal.ca>
References: <20130608211406.14743rz3wjisxwu8@wm4.dal.ca>
Message-ID: <1370749717.18598.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,


dat1$colIndex<-apply(dat1,1,function(x) match(max(x),x))
?dat1
#? v1 v2 v3 v4 max colIndex
#1? 0? 0? 1? 2?? 2??????? 4
#2? 0? 1? 2? 0?? 2??????? 3
#3? 1? 2? 3? 4?? 4??????? 4
A.K.



----- Original Message -----
From: Camilo Mora <cmora at dal.ca>
To: r-help at r-project.org
Cc: 
Sent: Saturday, June 8, 2013 8:14 PM
Subject: [R] get column index with match using apply

Hi everyone,
This is probably something very simple but I have just not been able? 
to figure it out and wonder if perhaps you may know.

I want to get the column index in which a given value is found. Values? 
to match are found in the last column of the dataframe. for instance

dt=
v1?  v2?  v3?  v4? ? max
0? ? 0? ? 1? ? 2? ?  2
0? ? 1? ? 2? ? 0? ?  2
1? ? 2? ? 3? ? 4? ?  4

expected output:
v1?  v2?  v3?  v4? ? max colIndex
0? ? 0? ? 1? ? 2? ?  2? ?  4
0? ? 1? ? 2? ? 0? ?  2? ?  3
1? ? 2? ? 3? ? 4? ?  4? ?  4

I am using:

apply(dt, 1, function(x) match(max,x))

but there is an error in setting "max" in match to be dynamic for each? 
row. I have play around with different configurations and google it? 
with no success.
Any input will be greatly appreciated,

best,

Camilo


Camilo Mora, Ph.D.
Department of Geography, University of Hawaii
Currently available in Colombia
Phone:?  Country code: 57
? ? ? ? ? Provider code: 313
? ? ? ? ? Phone 776 2282
? ? ? ? ? From the USA or Canada you have to dial 011 57 313 776 2282
http://www.soc.hawaii.edu/mora/

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From dwinsemius at comcast.net  Sun Jun  9 06:11:29 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 8 Jun 2013 21:11:29 -0700
Subject: [R] plot Predicted survival probabilitie
In-Reply-To: <CAGCbMdasUw_AX6oW4bz=yLTruqVxOB+xKUzyQgq5wcGxj-fUOQ@mail.gmail.com>
References: <CAGCbMdasUw_AX6oW4bz=yLTruqVxOB+xKUzyQgq5wcGxj-fUOQ@mail.gmail.com>
Message-ID: <AF23E726-7529-4D01-8872-8AB7BE9FAF6A@comcast.net>


On Jun 8, 2013, at 4:58 AM, matteo pettinari wrote:

> Dear
> I would like to find a nice way to plot the predicted survival obtained
> from a cph fit and few covariates as Age etc...
> 
> I am working with "predict" from rms package but i found a problem after
> the lines
> 
> predict(cox5, type="lp", se.fit=FALSE, conf.int=TRUE, conf.type=c('mean'))

Many functions in rms woek better with Predict()

> 
> Error in Getlimi(name[i], Limval, need.all = TRUE) :
>  no limits defined by datadist for variable Age

You need to read:

?datadist

And then create a datyadist and don't do what I do all the time and for get to set the options()

The code you offer does not have the cph call which would have been needed to construct a proper datadist argument. Perhaps something like:

ddname <- datadist(yourdataframe)

options(datadist="ddname")

> --
> 
> 
> can someone give me any advice about this problem and to create nice plot
> with x axis a continuous predictor and y axis the predicted survival?
> 
> Thank you
> Dr. Matteo Pettinari
> matteo.pettinari at gmail.com
> matteo.pettinari at uzleuven.be
> 
> Tervuursestraat 43 | 3000 | Leuven | Belgium
> 
> 	[[alternative HTML version deleted]]

Please learn to post in plain text.


David Winsemius
Alameda, CA, USA


From ripley at stats.ox.ac.uk  Sun Jun  9 08:23:32 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 09 Jun 2013 07:23:32 +0100
Subject: [R] CGIwithR installation failure
In-Reply-To: <20130608222734.GD31844@ninja.nosyntax.net>
References: <20130608222734.GD31844@ninja.nosyntax.net>
Message-ID: <51B41F64.3060505@stats.ox.ac.uk>

On 08/06/2013 23:27, rex wrote:
> Hello,
>
> CGIwithR apparently is not available on CRAN for R 2.15.x, so I

It is not hosted on CRAN.  You should ask its maintainer (and package 
installation problems most often belong on the R-devel list).

See what the posting guide says about that and about upgrading your R 
before posting.

> downloaded the source (0.73) and tried:
>
> ~/Downloads$ R CMD INSTALL CGIwithR
> * installing to library ?/home/rex/R/x86_64-pc-linux-gnu-library/2.15?
> * installing *source* package ?CGIwithR? ...
> configure: creating ./config.status
> config.status: creating R/CGIwithR.R
>
>        *****************************************
>
>    After the installation of this R package is complete
>    copy the files R.cgi and .Rprofile in
>        /home/rex/R/x86_64-pc-linux-gnu-library/2.15/CGIwithR/cgi-bin/
>    to the cgi-bin area of your Web server. If necessary,   modify the
> settings in the first part of R.cgi to   suit your local configuration.
>
>        *****************************************
>
> ** R
> Error in parse(outFile) : embedded nul in string: '\0'
> ERROR: unable to collate and parse R files for package ?CGIwithR?
>
>
> Any suggestions, including using a different package, appreciated.
>
> Background: I want to solve the classic diet linear programming
> problem. The CGI code needs to parse a POST, access a MySQL DB, solve
> the problem (probably using the linprog package), and present the
> solution to the vistor. I've done CGI programming in Python, but
> not in R and don't know if CGIwithR is a good choice. It hasn't
> been updated since 2005, so a more current package may be a better
> choice. OTOH, my needs are (currently) simple so CGIwithR may
> be an OK choice.
>
> I've a Python version that does the above, except for finding the
> lowest cost diet that meets constraints. The Python input form will be
> used in the R version (no point in reinventing the wheel).
>
> http://www.nosyntax.net/birdnutrit/
>
> Thanks for any help.
>
> -rex


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rex at nosyntax.net  Sun Jun  9 09:05:14 2013
From: rex at nosyntax.net (rex)
Date: Sun, 9 Jun 2013 00:05:14 -0700
Subject: [R] CGIwithR installation failure [SOLVED]
In-Reply-To: <20130608222734.GD31844@ninja.nosyntax.net>
References: <20130608222734.GD31844@ninja.nosyntax.net>
Message-ID: <20130609070514.GA3333@ninja.nosyntax.net>

rex <rex at nosyntax.net> [2013-06-08 18:05]:
>
>CGIwithR apparently is not available on CRAN for R 2.15.x, so I
>downloaded the source (0.73) and tried:
>
>~/Downloads$ R CMD INSTALL CGIwithR

Typo. Actually, I downloaded 0.72. Later, I found 0.73 here:

http://cran.r-project.org/src/contrib/Archive/CGIwithR/

D/L 0.73
tar -xzvf CGIwithR_0.73-0.tar.gz	
R CMD INSTALL CGIwithR
* installing to library ?/home/rex/R/x86_64-pc-linux-gnu-library/2.15?
* installing *source* package ?CGIwithR? ...
** package ?CGIwithR? successfully unpacked and MD5 sums checked
configure: creating ./config.status
config.status: creating R/CGIwithR.R

        *****************************************

    After the installation of this R package is complete
    copy the files R.cgi and .Rprofile in
        /home/rex/R/x86_64-pc-linux-gnu-library/2.15/CGIwithR/cgi-bin/
    to the cgi-bin area of your Web server. If necessary, 
    modify the settings in the first part of R.cgi to 
    suit your local configuration.

        *****************************************

** R
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** installing vignettes
** testing if installed package can be loaded

* DONE (CGIwithR)


My slightly modified R.cgi, trivial.html & trivial.R are
below for reference (I'm running Debian Testing & R 2.15.3).

R.cgi

#! /bin/sh

###  A shell script to make CGI scripting possible in R.  Part of the
###  "CGIwithR" package for R.
###
###  Author: David Firth, University of Warwick 
###  (d.firth at warwick.ac.uk)
###
###  Terms of use: GPL version 2 or later.  See "COPYING" in the
###  R distribution.
###
###  NO WARRANTY GIVEN, AND NO LIABILITY ACCEPTED FOR LOSS CAUSED BY
###  USE OF THIS PROGRAM
###
###
###  INSTALLING IT:
###
###  This file, and the one-line ".Rprofile" file included with the
###  package, must be placed together in a "cgi-bin" directory.  Both 
###  files should be readable (and this file executable) by the web 
###  server.
###
###
###  CONFIGURING IT:
###    
###  First locate R on the local system (typically the answer 
###  to "which R"). This is the command to run R.
###  Individual R CGI scripts may request execution by a  
###  different, elsewhere-installed version of R; the R specified 
###  here is the default.

R_DEFAULT=/usr/bin/R
#R_DEFAULT=/usr/local/bin/R

###  Graphs can be included in the output using either the 
###  GDD package (available from cran.r-project.org) 
###  or via ghostscript.
###  GDD is the default.  If it is not installed, the webPNG()
###  function will attempt to use ghostscript.  You can specify
###  where the executable is located on your system via the R_GSCMD
###  environment variable.  If using GDD, you can ignore this.

R_GSCMD=/usr/bin/gs
#R_GSCMD=/usr/local/bin/gs
export R_GSCMD

###  The next two lines may optionally be edited to limit access
###  to local resources.
###
###  This line allows specification of the priority
###  given to the R process.  A nice of "0" is the normal  
###  priority, while e.g. "+10" causes R to be run as a 
###  low-priority process.  The value "NONE" should be given if  
###  nice is not implemented locally.

R_NICE=NONE

###  This line allows the imposition of a length limit on the data
###  entered on an HTML form for processing by an R script.  
###  Setting MAX_DATA_LENGTH=1000, for example, aborts  
###  execution if the data length exceeds 1000 characters.  Or
###  use MAX_DATA_LENGTH=NONE to impose no limit here.

MAX_DATA_LENGTH=1000


###
### To make use of packages not installed in the default library for R
### i.e. `R RHOME`/library/, set the environment R_LIBS to identify
### one or more library directories containing the packages (separated by :).
### This is only necessary if the CGIwithR package itself is not located
### in the default library, e.g. if one is using a different version.

R_LIBS=/home/rex/R/x86_64-pc-linux-gnu-library/2.15/
export R_LIBS


###  No further configuration is needed.

No changes made in R.cgi below here.

trivial.html

<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
         "http://www.w3.org/TR/1999/REC-html401-19991224/loose.dtd">
<html>
<head>
         <title>An example form for CGIwithR</title>
         <meta name="generator" content="BBEdit 6.1.2">
</head>
<FORM action="http://www.nosyntax.net/cgi-bin/R.cgi/trivial.R" method="POST">
<body>
Enter some words: <INPUT type="text" name="words" value="" size=20>
<BR><BR>
Now some numbers (separated by any kind of white space):<BR>
<textarea name="numbers" rows=6 cols=20></textarea>

<P><INPUT type="submit" size=3>

</body>
</html>

trivial.R

#! /usr/bin/R

tag(HTML)
     tag(HEAD)
         tag(TITLE)
             cat("An example R.cgi output page")
         untag(TITLE)
     untag(HEAD)
     comments("Some comments to be ignored by the web browser")

     lf(2)

     tag(BODY, bgcolor = "lightyellow")
         lf(2)
         tag(h3)
             cat("A large heading")
         untag(h3)

         lf(2)

         tag(p)
             cat("Your words in italics:")
             tag(i)
                 cat(formData$words)
             untag(i)
         untag(p)

         lf(2)

         tag(p)
             cat("Your numbers:")
             tag(pre)
                 numbers <- as.numeric(scanText(formData$numbers))
                 print(numbers)
             untag(pre)
         untag(p)

         lf(2)

#        cat("Here is a graph:") ; br()
#        graphDir <- "/Users/david/Sites/graphs/"
#        graphURLroot <- "/~david/graphs/"
#        webPNG("temp.png")
#        plot(numbers)
#        img(src = "temp.png") ; br(2)
#
#        lf(2)

         cat("The author is ")
         mailto("David Firth", "d.firth at warwick.ac.uk")
#        mailto("David Firth", "david.firth at nuffield.ox.ac.uk")
         cat(" and here is his ")
         linkto("website.", "http://www2.warwick.ac.uk/fac/sci/statistics/staff/academic-research/firth/") ; br()
         #linkto("website.", "http://www.stats.ox.ac.uk/~firth/") 

         lf()

         tag(p)
             cat("Output produced at ", date())
         untag(p)

-rex
-- 
If at first you do succeed, try not to look astonished.


From ripley at stats.ox.ac.uk  Sun Jun  9 09:21:12 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 09 Jun 2013 08:21:12 +0100
Subject: [R] CGIwithR installation failure [SOLVED]
In-Reply-To: <20130609070514.GA3333@ninja.nosyntax.net>
References: <20130608222734.GD31844@ninja.nosyntax.net>
	<20130609070514.GA3333@ninja.nosyntax.net>
Message-ID: <51B42CE8.1000805@stats.ox.ac.uk>

On 09/06/2013 08:05, rex wrote:
> rex <rex at nosyntax.net> [2013-06-08 18:05]:
>>
>> CGIwithR apparently is not available on CRAN for R 2.15.x, so I
>> downloaded the source (0.73) and tried:
>>
>> ~/Downloads$ R CMD INSTALL CGIwithR
>
> Typo. Actually, I downloaded 0.72. Later, I found 0.73 here:
>
> http://cran.r-project.org/src/contrib/Archive/CGIwithR/

But see http://cran.r-project.org/package=CGIwithR for the current host.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rex at nosyntax.net  Sun Jun  9 09:26:18 2013
From: rex at nosyntax.net (rex)
Date: Sun, 9 Jun 2013 00:26:18 -0700
Subject: [R] CGIwithR installation failure
In-Reply-To: <51B41F64.3060505@stats.ox.ac.uk>
References: <20130608222734.GD31844@ninja.nosyntax.net>
	<51B41F64.3060505@stats.ox.ac.uk>
Message-ID: <20130609072618.GB3333@ninja.nosyntax.net>

Prof Brian Ripley <ripley at stats.ox.ac.uk> [2013-06-08 23:23]:
>On 08/06/2013 23:27, rex wrote:
>>CGIwithR apparently is not available on CRAN for R 2.15.x, so I
>
>It is not hosted on CRAN.  You should ask its maintainer (and package 
>installation problems most often belong on the R-devel list).

Actually it is, but not in the usual place.

>See what the posting guide says about that and about upgrading your R 
>before posting. 

I did read the posting guide before posting, and I'm in no hurry to
upgrade R, thank you. As you can see from my [Solved] post, the problem
was with 0.72, and 0.73 works with R 2.15.3.

>>Background: I want to solve the classic diet linear programming
>>problem. The CGI code needs to parse a POST, access a MySQL DB,
>>solve the problem (probably using the linprog package), and present
>>the solution to the vistor. I've done CGI programming in Python, but
>>not in R and don't know if CGIwithR is a good choice. It hasn't been
>>updated since 2005 [0.73 was updated in 2010], so a more current
>>package may be a better choice. OTOH, my needs are (currently)
>>simple so CGIwithR may be an OK choice.

It would have been nice to get some feedback on the suitability of 
CGIwithR compared to other CGI alternatives.

-rex
-- 
Life would be easier if I had the source code.


From rex at nosyntax.net  Sun Jun  9 09:37:13 2013
From: rex at nosyntax.net (rex)
Date: Sun, 9 Jun 2013 00:37:13 -0700
Subject: [R] CGIwithR installation failure [SOLVED]
In-Reply-To: <51B42CE8.1000805@stats.ox.ac.uk>
References: <20130608222734.GD31844@ninja.nosyntax.net>
	<20130609070514.GA3333@ninja.nosyntax.net>
	<51B42CE8.1000805@stats.ox.ac.uk>
Message-ID: <20130609073713.GC3333@ninja.nosyntax.net>

Prof Brian Ripley <ripley at stats.ox.ac.uk> [2013-06-09 00:22]:
>On 09/06/2013 08:05, rex wrote:
>>Typo. Actually, I downloaded 0.72. Later, I found 0.73 here:
>>
>>http://cran.r-project.org/src/contrib/Archive/CGIwithR/
>
>But see http://cran.r-project.org/package=CGIwithR for the current host.

I did; that's where I found the link to the CRAN archive that has 0.73.
The http://www.omegahat.org/CGIwithR/ link is to 0.72. IOW, the CRAN
archive is more up-to-date than the "current" host.

-rex
-- 
Nostalgia ain't what it used to be.


From ruipbarradas at sapo.pt  Sun Jun  9 10:59:36 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 09 Jun 2013 09:59:36 +0100
Subject: [R] Need help on window() function of the 'zoo' package
In-Reply-To: <1370725350.42095.YahooMailNeo@web190506.mail.sg3.yahoo.com>
References: <1370725350.42095.YahooMailNeo@web190506.mail.sg3.yahoo.com>
Message-ID: <51B443F8.8090001@sapo.pt>

Hello,

Actually, Dat_zoo is not a matrix, it is an object of classes "zooreg" 
and "zoo", with a dim attribute:

class(Dat_zoo)
dim(Dat_zoo)

And the output of window() is of the same classes but without a dim 
attribute:

wnd <- window(Dat_zoo, start = as.Date("2001-01-02"))
class(wnd)
dim(wnd)  # NULL


You can set the dim attribute manually like this:

dim(wnd) <- c(length(wnd), 1)


Hope this helps,

Rui Barradas

Em 08-06-2013 22:02, Ron Michael escreveu:
> Hi,
>
> I observed that if I use window() function available with the 'zoo' package to extract a portion of my times series and if that time series data is stored in some 'zoo' object with only 1 column, then the resulting zoo object is becoming vector.
>
> Here is my observation:
>
>> library(zoo)
>> Dat <- matrix(1:3, nc = 1)
>> Dat
>       [,1]
> [1,]    1
> [2,]    2
> [3,]    3
>> Dat_zoo <- zooreg(Dat, start = as.Date("2001-01-01"), frequency = 1)
>> Dat_zoo
>
> 2001-01-01 1
> 2001-01-02 2
> 2001-01-03 3
>> window(Dat_zoo, start = as.Date("2001-01-02"))   ### why it is becoming vector? I want to retain it as matrix only
> 2001-01-02 2001-01-03
>           2          3
>
> Here you can see that, originally my 'Dat_zoo ' object was basically a matrix. However once I use window() function, it became vector.
>
> Is there any possibility to retain the shape of the original object, particularly if that object is matrix with 1 column?
>
> Thank you very much for your help.
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From moghadameh_mirzai at yahoo.com  Sun Jun  9 09:27:10 2013
From: moghadameh_mirzai at yahoo.com (moghadameh mirzai)
Date: Sun, 9 Jun 2013 00:27:10 -0700 (PDT)
Subject: [R] Dyn.load of sharing object with GSL library
Message-ID: <1370762830.99139.YahooMailClassic@web160801.mail.bf1.yahoo.com>

Dear R-list,
I want to use shared library of gsl in R(2.15.1) on unix .I have a makefile such as 
CC = gcc
CFLAGS = -fPIC -O2
PKG_LIBS -lgsl -lgslcblas -lm -lpthread
?
OBJS_SPB = calc_spb.o k.o dk.o ddk.o
?
?
calc_spb.so : $(OBJS_SPB)
?
????? $(CC) -shared -o calc_spb.so $(LIBS) $(OBJS_SPB)
?
clean :
????? rm -f ../*.o *.o
?
clean.so:
????? rm -f *.so
?
I use R CMD SHLIB calc_spb.c in terminal window of unix and in my directory was built? calc_spb.o and calc_spb.so.
And? I use dyn.load in R the error is
Dyn.load(?calc_spb.so?)
Error in dyn.load(?calc_spb.so?):
Unable to load shared object ?/home/mir/cal/calc_spb.so?:
/home/mir/cal/calc_spb.so: undefined symbol :gsl_finite
Thanks to all who tried to help me in solving my problem.
?
-------------- next part --------------
A non-text attachment was scrubbed...
Name: A problem.pdf
Type: application/pdf
Size: 4392 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130609/cae127dd/attachment.pdf>

From varethugo at gmail.com  Sun Jun  9 11:43:32 2013
From: varethugo at gmail.com (Hugo Varet)
Date: Sun, 9 Jun 2013 11:43:32 +0200
Subject: [R] agnes() in package cluster on R 2.14.1 and R 3.0.1
Message-ID: <CABpMX0t+MJsb4mxj67iE3Q7QnNF_XuuKaPOR24AgN=r=iWnPpw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130609/9b6008f7/attachment.pl>

From ripley at stats.ox.ac.uk  Sun Jun  9 12:32:46 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 09 Jun 2013 11:32:46 +0100
Subject: [R] Dyn.load of sharing object with GSL library
In-Reply-To: <1370762830.99139.YahooMailClassic@web160801.mail.bf1.yahoo.com>
References: <1370762830.99139.YahooMailClassic@web160801.mail.bf1.yahoo.com>
Message-ID: <51B459CE.5060009@stats.ox.ac.uk>

On 09/06/2013 08:27, moghadameh mirzai wrote:
> Dear R-list,
> I want to use shared library of gsl in R(2.15.1) on unix .I have a makefile such as

Well, don't try to use a Makefile as you do not know what you are doing. 
  Use Makevars instead.

> CC = gcc
> CFLAGS = -fPIC -O2
> PKG_LIBS -lgsl -lgslcblas -lm -lpthread

That is missing a =

>
> OBJS_SPB = calc_spb.o k.o dk.o ddk.o
>
>
> calc_spb.so : $(OBJS_SPB)
>
>        $(CC) -shared -o calc_spb.so $(LIBS) $(OBJS_SPB)

You 'defined' PKG_LIBS not LIBS and your terms are in the wrong order.
Whether the latter matters depends on which 'unix' this is.

On most 'unix' systems a Makevars with

PKG_LIBS = -lgsl -lgslcblas -lm

would suffice.  Or even

PKG_LIBS = `gsl-config --libs`

>
> clean :
>        rm -f ../*.o *.o
>
> clean.so:
>        rm -f *.so
>
> I use R CMD SHLIB calc_spb.c in terminal window of unix and in my directory was built  calc_spb.o and calc_spb.so.
> And  I use dyn.load in R the error is
> Dyn.load(?calc_spb.so?)
> Error in dyn.load(?calc_spb.so?):
> Unable to load shared object ?/home/mir/cal/calc_spb.so?:
> /home/mir/cal/calc_spb.so: undefined symbol :gsl_finite
> Thanks to all who tried to help me in solving my problem.
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch.duncan at gmail.com  Sun Jun  9 13:21:53 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 09 Jun 2013 07:21:53 -0400
Subject: [R] Fortunes nomination (was:  colour coded dotchart)
In-Reply-To: <51B3DB3C.8000408@xtra.co.nz>
References: <CA+ckjv03wZoP7FT7dtahRnUhFQEHvgqGWHCKYPpWWvPrbXFT_A@mail.gmail.com>
	<51B3DB3C.8000408@xtra.co.nz>
Message-ID: <51B46551.8020104@gmail.com>

On reading the help pages,

On 13-06-08 9:32 PM, Rolf Turner wrote:
  ...

> You need to get the hang of reading the online help.  The information
> required is actually there in ?dotchart --- it's just tersely and obscurely
> expressed.  A certain degree of optimism is required.  You need to
> ***believe*** that the information is there; then ask yourself "What
> could they possibly mean by what they have written that would tell
> me what I need to know?".

Duncan Murdoch


From Achim.Zeileis at uibk.ac.at  Sun Jun  9 13:37:38 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Sun, 9 Jun 2013 13:37:38 +0200 (CEST)
Subject: [R] Fortunes nomination (was:  colour coded dotchart)
In-Reply-To: <51B46551.8020104@gmail.com>
References: <CA+ckjv03wZoP7FT7dtahRnUhFQEHvgqGWHCKYPpWWvPrbXFT_A@mail.gmail.com>
	<51B3DB3C.8000408@xtra.co.nz> <51B46551.8020104@gmail.com>
Message-ID: <alpine.DEB.2.02.1306091337230.15409@paninaro.uibk.ac.at>

On Sun, 9 Jun 2013, Duncan Murdoch wrote:

> On reading the help pages,

Thanks, online on R-Forge now :-)

Best,
Z

> On 13-06-08 9:32 PM, Rolf Turner wrote:
> ...
>
>> You need to get the hang of reading the online help.  The information
>> required is actually there in ?dotchart --- it's just tersely and obscurely
>> expressed.  A certain degree of optimism is required.  You need to
>> ***believe*** that the information is there; then ask yourself "What
>> could they possibly mean by what they have written that would tell
>> me what I need to know?".
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From landronimirc at gmail.com  Sun Jun  9 14:49:46 2013
From: landronimirc at gmail.com (Liviu Andronic)
Date: Sun, 9 Jun 2013 14:49:46 +0200
Subject: [R] generate simple function with pre-defined constants
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C2FF771@PA-MBX01.na.tibco.com>
References: <CABxs9V=DcRW_CbwMy6DBt41wgqVo=E36Ep2EsCpSFFtkN=XgLg@mail.gmail.com>
	<CABxs9VnCDNt4pcty-1BQnr3UbEDx+WdKPO-08NTj4ud6U_CzTQ@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C2FF771@PA-MBX01.na.tibco.com>
Message-ID: <CABxs9V=JSUBgs4LTQdFYAOd0ZVKXu_oBwOcaJEV08eWoxQt3QQ@mail.gmail.com>

Dear Bill,


On Thu, Jun 6, 2013 at 5:36 PM, William Dunlap <wdunlap at tibco.com> wrote:
> Try the following:
>    generateABFunction <- function(a, b) {
>       force(a)
>       force(b)
>       function(x) a*x + b
>    }
>    f12 <- generateABFunction(1, 2)
>    f53 <- generateABFunction(5,6)
>    f12(10:12) # get 12, 13, 14
>    f53(10:12) # get 56, 61, 66
>
> See, e.g., yesterday's discussion under the subject
> "Trying to build up functions with its names by means of lapply"
> on why the force() calls are required.  Read up on R's environments
> to see why f12 and f53 look the same but act differently (hint:
> look at ls.str(environment(f12))).
>
This is exactly what I was trying to do. Thank you for the explanations,
Liviu


> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
>> Of Liviu Andronic
>> Sent: Thursday, June 06, 2013 8:00 AM
>> To: r-help at r-project.org Help
>> Subject: Re: [R] generate simple function with pre-defined constants
>>
>> On Thu, Jun 6, 2013 at 4:48 PM, Liviu Andronic <landronimirc at gmail.com> wrote:
>> > Dear all,
>> > Given:
>> > a <- 2
>> > b <- 3
>> >
>> > I'd like to obtain the following function:
>> > f <- function(x) 2 + 3*x
>> >
>> > but when I do this:
>> > f <- function(x) a + b*x
>> > ##f
>> > ##function(x) a + b*x
>> >
>> > the 'a' and 'b' objects do not get evaluated to their constants. How
>> > could I do that?
>> >
>> I found one solution:
>> a <- 2
>> b <- 3
>> f <- eval(parse(text=paste("function(z)", a, "+ z * ", b)))
>> f
>> ##function(z) 2 + z *  3
>>
>> but I still have nightmares from:
>> > fortune("parse")
>>
>> If the answer is parse() you should usually rethink the question.
>>    -- Thomas Lumley
>>       R-help (February 2005)
>>
>> Is there a nicer way to approach this? Thanks,
>> Liviu
>>
>>
>> > Thanks,
>> > Liviu
>> >
>> >
>> > --
>> > Do you know how to read?
>> > http://www.alienetworks.com/srtest.cfm
>> > http://goodies.xfce.org/projects/applications/xfce4-dict#speed-reader
>> > Do you know how to write?
>> > http://garbl.home.comcast.net/~garbl/stylemanual/e.htm#e-mail
>>
>>
>>
>> --
>> Do you know how to read?
>> http://www.alienetworks.com/srtest.cfm
>> http://goodies.xfce.org/projects/applications/xfce4-dict#speed-reader
>> Do you know how to write?
>> http://garbl.home.comcast.net/~garbl/stylemanual/e.htm#e-mail
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
Do you know how to read?
http://www.alienetworks.com/srtest.cfm
http://goodies.xfce.org/projects/applications/xfce4-dict#speed-reader
Do you know how to write?
http://garbl.home.comcast.net/~garbl/stylemanual/e.htm#e-mail


From cpolwart at chemo.org.uk  Sun Jun  9 15:14:33 2013
From: cpolwart at chemo.org.uk (Calum Polwart)
Date: Sun, 09 Jun 2013 14:14:33 +0100
Subject: [R] Not sure this is something R could do but it feels like it
 should be.
In-Reply-To: <51B12257.1010602@bitwrit.com.au>
References: <20130606150318.57E504483A7@nhs-pd1e-esg101.ad1.nhs.net>
	<51B12257.1010602@bitwrit.com.au>
Message-ID: <59c4f02b9171b484ec8545ea2b3cc32b@localhost>

>> Calum
>>
> Hi Calum,
> I can only answer from the perspective of someone who calculated
> doses of alcohol for experimental subjects many years ago. It was not
> possible to apply a linear function across the range due to a number
> of factors. One is that BAC, which was the target value, is dependent
> upon the proportion of the weight that represents the water
> compartment of the body. This varies with both weight (heavier people
> typically have a higher proportion of fat) and sex (women also tend 
> to
> have slightly more fat). The real monkey wrench in the works was
> absorption rate, which often made nonsense of my calculations. This
> may not be as important in therapeutic drugs, for we were aiming at a
> specified BAC at a certain time after dosing rather than an average
> level.

All those things affect therapeutic dosing.

I may have oversimplified what we are trying to achieve to avoid 
getting bogged down in the detail of what we are trying to achieve and 
provide something people might be able to relate to.

However, we can assume that they are already sorted out, so we know the 
theoretically know what the 'correct' dose is for a patient.  The hard 
bit is unless you want to give everyone liquid so you can measure any 
dose possible you have to have a dose that is a multiple of something 
(Amoxicillin doses in adults are multiples of 250 because thats the size 
of the capsule).

What we are trying to do is determine the most appropriate number to 
make the capsules.  (Our dosing is more complex but lets stick to 
something simple.  I can safely assure you that vritually no-one 
actually needs 250 or 500mg as a dose of amoxicillin... ...thats just a 
dose to get them into a therapeutic window, and I'm 99% certain 250 and 
500 are used coz they are round numbers.  if 337.5 more reliably got 
everyone in the window without kicking anyone out the window that'd be a 
better dose to use!  So... what I'm looking to do is model the 
'theoretical dose required' (which we know) and the dose delivered using 
several starting points to get the 'best fit'.  We know they need to be 
within 7% of each other, but if one starting point can get 85% of doses 
within 5% we think that might be better than one that only gets 50% 
within 5%.

> However, I suspect that many therapeutic drugs have a different
> dose by weight for children (we weren't dosing children) and choosing
> a starting point at the bottom of the range would almost certainly
> introduce a systematic error. My intuition would be to anchor the
> dosage rate in the middle of the scale and then extrapolate in both
> directions (adults only, of course).
>

We are actually using a starting point that may be middle and going up 
and down if need be.

I think what we may want to do is run a loop through each weight (in 
1kg increments) and calculate their theoretical dose, and the dose for 
each possible starting point (there are certain contraints on that 
already so there may only be 20 possible start points), then we 
calculate the % variance for each dose to theoretical dose and calculate 
the Area Under & Above (some will be negative) the curve and the one 
that has the lowest AUC is then the one that most "precisely" will dose 
the patient...?


From debmidya at yahoo.com  Sun Jun  9 12:58:00 2013
From: debmidya at yahoo.com (Deb Midya)
Date: Sun, 9 Jun 2013 03:58:00 -0700 (PDT)
Subject: [R] How to read a .rar file in R
Message-ID: <1370775480.88771.YahooMailNeo@web141405.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130609/7d936439/attachment.pl>

From ripley at stats.ox.ac.uk  Sun Jun  9 16:01:28 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 09 Jun 2013 15:01:28 +0100
Subject: [R] How to read a .rar file in R
In-Reply-To: <1370775480.88771.YahooMailNeo@web141405.mail.bf1.yahoo.com>
References: <1370775480.88771.YahooMailNeo@web141405.mail.bf1.yahoo.com>
Message-ID: <51B48AB8.9090407@stats.ox.ac.uk>

On 09/06/2013 11:58, Deb Midya wrote:
> Hi,
>
> Thanks in advance.
>
> May I request you to assist me for the following please.
>
> I am using R-3.0.1 on Windows.
>
> Is there any R package or R function to read a .rar file (file with an extension rar)?

Use system() with however you unpack rar files on your OS.  .rar files 
are archives, not files you could usefully read into R (just like tar 
and zip archives).   At least, the commonest such files are, and those 
are already pretty uncommon.

There are several ways to unpack on Windows, at least 7-zip, WinZip, 
UnRAR (2x), WinRAR.


>
> Once again, thank you very much for the time you have given.
>
> Regards,
>
> Deb
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From junxu.r at gmail.com  Sun Jun  9 16:44:19 2013
From: junxu.r at gmail.com (Xu Jun)
Date: Sun, 9 Jun 2013 10:44:19 -0400
Subject: [R] multilevel binary and ordered regression models
In-Reply-To: <CAG_uk918pXxQcj4H1bsLz56BXJU7APaKm45MKVMRrXVUMKBC+w@mail.gmail.com>
References: <CADe_g+W+1cZOoGFquWxc7xt9qUoBLKQU43ApGVrRbrkEk3PdTg@mail.gmail.com>
	<CAG_uk918pXxQcj4H1bsLz56BXJU7APaKm45MKVMRrXVUMKBC+w@mail.gmail.com>
Message-ID: <CADe_g+XkeEKZoSWU7kbPESFxjK9ah40LETXMTQxEJH8v8-=B9g@mail.gmail.com>

Rune,

Thanks a lot for pointing me to your ordinal package. It is wonderful,
and I tried a random intercept model and it worked well except that
probably there is something wrong with my data (size is big), I got
some warning messages indicating that "In sqrt(diag(vc)[1:npar]) :
NaNs produced." Therefore, some of the coefficients do not have
standard errors. I also have a follow-up question: if I want to
estimate a slope as outcome model, how am I supposed to specify the
model. I tried following the few tutorials you posted on CRAN, but was
not able to figure it out:


Here is my model:

level 1: y*_ij = beta_0j + beta_1j*x1_ij + beta_2j*x2_ij +
beta_3j*x3_ij + epsilon_ij

where y* is a latent continuous variable and y is an observed binary
dependent variable.
y  is an observed ordinal variable, say ranging from 1-4, and has been
coded as a factor variable.

x's are predictors at level 1
beta's are regression coefficients at level 1
epsilon's are error terms in level 1 equations

level 2 Eq1: beta_0j  = gamma_00 + gamma_01*w1_j + gamma_02*w2_j + mu_0j
Level 2 Eq2: beta_1j  = gamma_10 + gamma_11*w1_j + gamma_02*w2_j + mu_1j

My guess would be:
# try 1
clmm(y~ x1 + x2 + x3 + w1 + w2 + w1:x1 + w2:x2 + (1 + x1 | group), #
like the syntax in lmer or glmer
                     data=alllev, link="logit",
                     na.action=na.omit,
                     Hess=T)

# or try 2

clmm(y~ x1 + x2 + x3 + w1 + w2 + w1:x1 + w2:x2 + (1  | group) + (1 | group:x1),
                     data=alllev, link="logit",
                     na.action=na.omit,
                     Hess=T)

but none worked. After I issued the first try, I got the following message:

Error: Matrices must have same number of columns in rbind2(..1, r)
In addition: Warning messages:
1: In cntnew:male :
  numerical expression has 177770 elements: only the first used

and after the second try, simply it says that I got to following the
(1|factor) format. I would appreciate that if you could point me to
the right direction. Also, I know I am dealing with a relatively large
data set, but is there any way to speed up the estimation a bit.
Thanks a lot!

Jun

On Fri, Jun 7, 2013 at 1:04 AM, Rune Haubo <rune.haubo at gmail.com> wrote:
> On 6 June 2013 00:13, Xu Jun <junxu.r at gmail.com> wrote:
>> Dear r-helpers,
>>
>> I have two questions on multilevel binary and ordered regression models,
>> respectively:
>>
>> 1. Is there any r function (like lmer or glmer) to run multilevel ordered
>> regression models?
>
> Yes, package ordinal will fit such models.
>
> Cheers,
> Rune


From ligges at statistik.tu-dortmund.de  Sun Jun  9 17:38:06 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 09 Jun 2013 17:38:06 +0200
Subject: [R] Error Object Not Found
In-Reply-To: <1370720137364-4669041.post@n4.nabble.com>
References: <1370720137364-4669041.post@n4.nabble.com>
Message-ID: <51B4A15E.9090707@statistik.tu-dortmund.de>



On 08.06.2013 21:35, Court wrote:
> Hello,
>
> I am having difficulty with a command.  An error message pops up saying:
> Error: object 'RWGJ.wload' not found.  I have installed the packages needed
> to run the analysis, and have saved them to my working directory.

And have you actually loaded them?

Uwe Ligges


>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Error-Object-Not-Found-tp4669041.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Sun Jun  9 17:44:01 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 09 Jun 2013 17:44:01 +0200
Subject: [R] Package 'ChoiceModelR' - Xbetas.csv? Rbetas.csv? betadraws?
In-Reply-To: <CAN2xGJa5PdhfggvX5sW3Xb8indvqucBoB2aM-Gy2mcgp0Kq=AA@mail.gmail.com>
References: <CAN2xGJa5PdhfggvX5sW3Xb8indvqucBoB2aM-Gy2mcgp0Kq=AA@mail.gmail.com>
Message-ID: <51B4A2C1.3060803@statistik.tu-dortmund.de>



On 07.06.2013 21:25, Dimitri Liakhovitski wrote:
> Hope to get some clarity from the creators of a (wonderful) package
> ChoiceModelR. I am using the main function 'choicemodelr'.

Since we do not know if these "creators" are reading the list, why not 
ask them directly?

Best,
Uwe Ligges


>
> Everything works.
>
> ?choicemodelr says "average of MCMC draws of unit-level model coefficients
> are written to Xbetas.csv"
> Question 1: Is this a typo? The real file created in the working directory
> seems to be "Rbetas.csv"
> Questions 2: Are these the averages of the 'use' draws (specified in my
> choicemodelr statement)?
> Question 3: If I had constraints, I assume these averages will be "taking
> into account constraints", right?
>
> ?choicemodelr also says that choicemodelr produces an object that contains,
> among other things, two elemens:
>
>
>
> betadraw
>
> An ni by natt by floor(use/keep) array of MCMC random draws of unit-level
> multinomial logit model parameter estimates.
>
> betadraw.c
>
> An ni by natt by floor(use/keep) array of constrained MCMC random draws of
> unit-level multinomial logit model parameter estimates.
>
>
>
> If I do:
>
> apply(out$betadraw.c,c(1,2),mean)
>
> then what is the difference between the result and the file written to Disk?
>
> One difference I noticed:
>
> apply(out$betadraw.c, c(1,2),mean) contains as many columns as parameters,
> not as many columns as the number of levels.
>
> What else?
>
>
>
> Thank you very much!
>
>


From ligges at statistik.tu-dortmund.de  Sun Jun  9 17:45:21 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 09 Jun 2013 17:45:21 +0200
Subject: [R] Identifying breakpoints/inflection points?
In-Reply-To: <1370588887318-4668889.post@n4.nabble.com>
References: <q2i35fefd7e1004261506g8df50co8302f04380ed57be@mail.gmail.com>
	<1370588887318-4668889.post@n4.nabble.com>
Message-ID: <51B4A311.2090903@statistik.tu-dortmund.de>

Please quote the question you are answering and also send the answer to 
the original poster, not only to this *mailing list* the original poster 
may not be reading himself.

Best,
Uwe Ligges



On 07.06.2013 09:08, dchristop wrote:
> You can try this:
>
> library(inflection)
> #you have to instsall package inflection first
> a<-findiplist(cbind(year),cbind(piproute),1)
> a
>
> The answer:
>       [,1] [,2]   [,3]
> [1,]    5   35 1986.0
> [2,]    5   30 1983.5
>
> shows that the total inflection point is between 1983 and 1986, if we treat
> data as first concave and then convex, as it can be found from a simple
> graph.
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Identifying-breakpoints-inflection-points-tp2065886p4668889.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Sun Jun  9 17:49:02 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 09 Jun 2013 17:49:02 +0200
Subject: [R] It seams that fast99 function (sensitivity package) does
 not work out for norm distribution.
In-Reply-To: <CABmD0bFA0Q_HNQ-4+Z2rKftO=MYtEAjAz7qajKszJ2hK-TQBVA@mail.gmail.com>
References: <CABmD0bFA0Q_HNQ-4+Z2rKftO=MYtEAjAz7qajKszJ2hK-TQBVA@mail.gmail.com>
Message-ID: <51B4A3EE.4040901@statistik.tu-dortmund.de>



On 08.06.2013 00:54, Marino David wrote:
> Dear all mailing listers,
>
> Does Anyone have the same problem as mine when using the fast99
> (extended-FAST method) to perform SA of model with norm distribution inputs?

Why not ask the authors of the function?

Best,
Uwe Ligges

>
> See the simple example given following.
>
> Any suggestion will be greatly appreciated.
>
> Thank you!
>
> Marino
>
>
> # Simple example
>
> # 1. uniform version (It works well)
> library(sensitivity)
> Myfun<-function(x){return(rowSums(x))}
> SA1 <- fast99(model = Myfun, factors = 3, n = 1000, q = "qunif", q.arg =
> list(min = 0, max = 1))
>
>
>> SA1
> Call:
> fast99(model = Myfun, factors = 3, n = 1000, q = "qunif", q.arg =
> list(min = 0,     max = 1))
>
> Model runs: 3000
>
> Estimations of the indices:
>     first order total order
> X1   0.3335243   0.3350584
> X2   0.3335243   0.3350584
> X3   0.3335243   0.3350584
>
>
>
>
>
>
> # 2. norm version (it does not work)
> SA2 <- fast99(model = Myfun, factors = 3, n = 1000, q = "qnorm", q.arg =
> list(mean = 0, sd = 1))
>
>
>> SA2
> Call:
> fast99(model = Myfun, factors = 3, n = 1000, q = "qnorm", q.arg =
> list(mean = 0,     sd = 1))
>
> Model runs: 3000
>
> Estimations of the indices:
>     first order total order
> X1          NA          NA
> X2          NA          NA
> X3          NA          NA
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Sun Jun  9 17:51:10 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 09 Jun 2013 17:51:10 +0200
Subject: [R] segfault -- address 0x29, cause 'memory not mapped'
In-Reply-To: <51B333E5.9060800@gmx.net>
References: <51B333E5.9060800@gmx.net>
Message-ID: <51B4A46E.2030706@statistik.tu-dortmund.de>



On 08.06.2013 15:38, mathias kuhnt wrote:
> Dear List,
>
> after a night of calculating, R says goodbye with a segmentation fault.
>
>   *** caught segfault ***
> address 0x29, cause 'memory not mapped'
>
> In my functions I subsequently read in network files of about 20KB using
> the IGraph package. Admittedly, I read in about 1 million files, in
> total 20GB. Still, the function saves the data to the same object and
> memory of the prior file should be freed.
>
> The crash occurs after some hours but not at the same time, last time
> after having read in 99% of the files. It probably depends on what I did
> before I started the function.
>
> Can anybody tell me if these are limitations of the program and I have
> to live with it or am I doing something wrong? Is it a general R problem
> or rather one of the IGraph package?

I guess igraph, butz cannot be sure without a reproducible example.
Perhaps the best idea is to find an example that generates the problem 
rather quickly and send it to the igraph maintainer.

Best,
Uwe Ligges



>
> Thanks in advance,
> Mathias
>
>
> here the code:
> #####################################################
> library(igraph)
>
> modnumber<-1200
> its<-1000
> seriespath<-"/daten/netgen_series/series_m1q2/"
> mylim<-200
> max<-100
> startval<-1
>
>
> sampledegcorr <- function (model, its, max)
> # I suppose it does not matter what I do here but as you see I read in
> 1000 network files and analyze them
> {
>      dc<-rep(NA,max)
>      for (i in 0:(its-1))
>      {
>          net<-read.graph(paste(seriespath,model,"/",i,".net", sep =
> ""),format="pajek")
>          net<-simplify(net)
>          ndeg <- sapply(V(net),function(x)
> mean(degree(net,neighbors(net,x))-1))
>          bo<-stats.bin(degree(net),ndeg,breaks=seq(-0.5,max ,1))
>          dc<-cbind(dc,bo$stats[2,])
>      }
>      dck<-as.vector(apply(dc,1,mean, na.rm=T))
>      return(cbind(seq(0,max-1,1),dck))
> }
>
>
> dc<-seq(0,max-1,1)
> for (i in startval:(modnumber))
> # here i start the function above with 1200 different networks
> {
>      print(paste("calculating model ", i, sep=""))
>      dc<-cbind(dc,sampledegcorr(paste("m", i, sep=""),its,mylim)[,2])
>      save(dc,file="series_m1q2_dc_results.RData")
> }
> ######################################################
>
> here my specs:
>
> R 3.0.1-3precise
> R crashed with SIGSEGV in Rf_StringTrue()
> Ubuntu 12.04.1
> 4 GB RAM
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Sun Jun  9 17:54:27 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 09 Jun 2013 17:54:27 +0200
Subject: [R] Regression Tolerance Intervals - Dr. Young's Code
In-Reply-To: <E18C153EBB81024CB60FCE9B4C34D57C23331688@pl-emsmb11>
References: <E18C153EBB81024CB60FCE9B4C34D57C23331688@pl-emsmb11>
Message-ID: <51B4A533.8090501@statistik.tu-dortmund.de>



On 08.06.2013 05:17, Muhuri, Pradip (SAMHSA/CBHSQ) wrote:
> Hello,
>
> Below is a reproducible example to generate the output by using Dr. Young's R code on the above subject .   As commented below, the issue is that  part of the code (regtol.int and plottol) does not seem to work.
>
> I would appreciate receiving your advice toward resolving the issue.
>
> Thanks and regards,
>
> Pradip Muhuri
>
>
> setwd ("E:/")
> require ("tolerance")
>
> d1<- "xlndur      ylnant
> 8.910797  0.33901690
> 9.001415  0.36464311
> 8.983936  0.53976194
> 8.948035  0.33901690
> 9.056784  0.39266961
> 9.018593  0.18617770
> 9.001415  0.53976194
> 8.983936 -0.11005034
> 8.966147  0.53102826
> 8.948035  0.59885086
> 6.900000  NA"
>
> xd1 <- read.table(textConnection(d1), header=TRUE, as.is=TRUE)
> print (xd1); str (xd1)
>
> #This code works
> xout1 <- regtol.int (reg=lm (formula=ylnant ~ xlndur, data=xd1),  alpha=.05, P=0.99, side=2)
> print (xout1)
>
>
> #This code does not work
> xout2 <- regtol.int (reg=lm (formula=ylnant ~ xlndur, data=xd1), new.xlndur = NULL,  alpha=.05, P=0.99, side=2)

Come on, start using your brain and replace new.xlndur by new.x?

> print (xout2)
> #This code does not work
> plottol(xout1, x=cbind(1,x), y=y, side="two", x.lab="X", y.lab="Y" )

So replace x and y appropriately?

Best,
Uwe Ligges



> #This code does not work
> plottol(xout2, x=cbind(1,x), y=y, side="two", x.lab="X", y.lab="Y" )
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ulrike.pasda at gmail.com  Sun Jun  9 16:41:06 2013
From: ulrike.pasda at gmail.com (Ulrike Pasda)
Date: Sun, 9 Jun 2013 16:41:06 +0200
Subject: [R] import from Stata, get NA
Message-ID: <CAJ3cU5Sy9+91XnDidKu-93Th1xnjWPEKWEbveyTOLpQb8ps33g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130609/a8bb6fcc/attachment.pl>

From dwinsemius at comcast.net  Sun Jun  9 18:57:55 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 9 Jun 2013 09:57:55 -0700
Subject: [R] import from Stata, get NA
In-Reply-To: <CAJ3cU5Sy9+91XnDidKu-93Th1xnjWPEKWEbveyTOLpQb8ps33g@mail.gmail.com>
References: <CAJ3cU5Sy9+91XnDidKu-93Th1xnjWPEKWEbveyTOLpQb8ps33g@mail.gmail.com>
Message-ID: <2EA14D6C-5984-4652-902A-2BEA7D6C6572@comcast.net>


On Jun 9, 2013, at 7:41 AM, Ulrike Pasda wrote:

> Dear all,
> I have troubles figuring out how to convert missing values from Stata
> (treated as -1 and -2) into NAs in R.
> To read in the dta file I use: data <- read.dta("data.dta")
> 
> Is there an option to tell R to convert the -1 and -2 into NAs ?
> 

The documentation for read.dta in the foreign package suggests that "true" Stata missingness is handled. (I also did not see an 'na.strings=' argument as exists in read.table.) So perhaps you are not using Stata missing indicators and have a private convention for missing. If that is the case then:

   is.na(data$colA) <- data$colA %in% c(-1, -2)

All this assumes many things which I cannot verify (whether that column is numeric class for one). You should in  further questions to Rhelp offer dput(head(dorm)) where the `data` is is the name of the dataframe. Since `data` is an R function (as is "df") I would suggest that you use 'dfr'm for data.frames. (That is not the cause of any problems but will be confusing to readers of your code.)

-- 

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.CA.us  Sun Jun  9 19:06:31 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 09 Jun 2013 10:06:31 -0700
Subject: [R] Fortunes nomination (was:  colour coded dotchart)
In-Reply-To: <alpine.DEB.2.02.1306091337230.15409@paninaro.uibk.ac.at>
References: <CA+ckjv03wZoP7FT7dtahRnUhFQEHvgqGWHCKYPpWWvPrbXFT_A@mail.gmail.com>
	<51B3DB3C.8000408@xtra.co.nz> <51B46551.8020104@gmail.com>
	<alpine.DEB.2.02.1306091337230.15409@paninaro.uibk.ac.at>
Message-ID: <1ee4eb02-1b5e-4a8a-8e2a-8c810d6ec177@email.android.com>

Oh, Lord, give me strength, for I am about to read an R Help file! Give me insight, for I must parse the words of statisticians forced by "R CMD check" to follow the way of the Literate Programmer! And please, Oh Lord, give me the wisdom to recall these tribulations when I set foot upon that road, that I may mark the path I blaze clearly for the novitiate to follow yet my words not become as obscure as those I read!

Commentary:
There is both truth and fiction in Rolf's advice, and for the truth I applaud the nomination, but for the fiction I fear the picture it paints in the unsuspecting mind.

On the one hand, it seems odd to ask that the R user "believe" that meaning is there because this is software, not the Bible. On the other hand, some people seem to think they should not have to study to use this tool properly, so perhaps some faith will help them dig a little harder.

Writing documentation is hard, and R CMD check at least makes package developers write SOMETHING down. That doesn't mean that it verifies that it is complete or clearly written. You can drag the horse to water but you cannot make them drink. Fortunately, the author of the code often does write just what you need to use it... even if it is a bit terse.

There is also a bit of transformation that happens as one learns how R code works, that makes the "obscure" documentation more intuitive. What the beginner does not seem to realize is that documentation that they would think is perfect would likely have to be customized to fit their specific set of educational holes, but would bore others who knew all that stuff. The solution is for certain conventions and shorthand to be used, and to let the user search as deep as they need to get their answer. Also, it is common for teenagers to say they will never be like their parents, yet later find themselves doing just that.

It is worth reminding new users that the maintainer() function is the key to helping improve R documentation, since what beginners think of as "R" is not a monolithic product but rather is the product of many individuals. Having the package maintainer be the gateway for such changes is a bit random, since different maintainers have different time and skills for the job, but communicating with the right person (rather than expecting them to read every message on R- help) is in general the best practice for fixing problems in packages. (Faulty documentation is indeed a problem, but a constructive suggestion for fixing it is far more likely to bring about change than either throwing of stones or abasing oneself before the guru.)
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Achim Zeileis <Achim.Zeileis at uibk.ac.at> wrote:

>On Sun, 9 Jun 2013, Duncan Murdoch wrote:
>
>> On reading the help pages,
>
>Thanks, online on R-Forge now :-)
>
>Best,
>Z
>
>> On 13-06-08 9:32 PM, Rolf Turner wrote:
>> ...
>>
>>> You need to get the hang of reading the online help.  The
>information
>>> required is actually there in ?dotchart --- it's just tersely and
>obscurely
>>> expressed.  A certain degree of optimism is required.  You need to
>>> ***believe*** that the information is there; then ask yourself "What
>>> could they possibly mean by what they have written that would tell
>>> me what I need to know?".
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Jun  9 19:09:06 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 9 Jun 2013 10:09:06 -0700
Subject: [R] Not sure this is something R could do but it feels like it
	should be.
In-Reply-To: <59c4f02b9171b484ec8545ea2b3cc32b@localhost>
References: <20130606150318.57E504483A7@nhs-pd1e-esg101.ad1.nhs.net>
	<51B12257.1010602@bitwrit.com.au>
	<59c4f02b9171b484ec8545ea2b3cc32b@localhost>
Message-ID: <1DFC92EB-B97F-4CC1-AA94-4F1D1571E328@comcast.net>


On Jun 9, 2013, at 6:14 AM, Calum Polwart wrote:

>>> Calum
>>> 
>> Hi Calum,
>> I can only answer from the perspective of someone who calculated
>> doses of alcohol for experimental subjects many years ago. It was not
>> possible to apply a linear function across the range due to a number
>> of factors. One is that BAC, which was the target value, is dependent
>> upon the proportion of the weight that represents the water
>> compartment of the body. This varies with both weight (heavier people
>> typically have a higher proportion of fat) and sex (women also tend to
>> have slightly more fat). The real monkey wrench in the works was
>> absorption rate, which often made nonsense of my calculations. This
>> may not be as important in therapeutic drugs, for we were aiming at a
>> specified BAC at a certain time after dosing rather than an average
>> level.
> 
> All those things affect therapeutic dosing.
> 
> I may have oversimplified what we are trying to achieve to avoid getting bogged down in the detail of what we are trying to achieve and provide something people might be able to relate to.
> 
> However, we can assume that they are already sorted out, so we know the theoretically know what the 'correct' dose is for a patient.  The hard bit is unless you want to give everyone liquid so you can measure any dose possible you have to have a dose that is a multiple of something (Amoxicillin doses in adults are multiples of 250 because thats the size of the capsule).
> 

I think you may have under-simplified rather than over-simplified. There is no such thing as getting "bogged down in detail". We need all the relevant details. I suspect that you have in mind a situation where you have multiple drugs and multiple forms in which they can be administered and are hoping for a processing method that "rounds" to the nearest tespoonful or tablet size given some set of patient specific factors such as age sex height or weight. If my guess is correct then you need to offer a sample set of data of at least theree types for A) drugs and phamacokinetic parameters, B) dosage forms, C) patient features. You also need to supply rules for "rounding" to he nearest "nice" unit of administration.


> What we are trying to do is determine the most appropriate number to make the capsules.  (Our dosing is more complex but lets stick to something simple.  I can safely assure you that vritually no-one actually needs 250 or 500mg as a dose of amoxicillin... ...thats just a dose to get them into a therapeutic window, and I'm 99% certain 250 and 500 are used coz they are round numbers.  if 337.5 more reliably got everyone in the window without kicking anyone out the window that'd be a better dose to use!  So... what I'm looking to do is model the 'theoretical dose required' (which we know) and the dose delivered using several starting points to get the 'best fit'.  We know they need to be within 7% of each other, but if one starting point can get 85% of doses within 5% we think that might be better than one that only gets 50% within 5%.
> 
>> However, I suspect that many therapeutic drugs have a different
>> dose by weight for children (we weren't dosing children) and choosing
>> a starting point at the bottom of the range would almost certainly
>> introduce a systematic error. My intuition would be to anchor the
>> dosage rate in the middle of the scale and then extrapolate in both
>> directions (adults only, of course).
>> 
> 
> We are actually using a starting point that may be middle and going up and down if need be.

You need to describe explicitly how that determination is made.
> 
> I think what we may want to do is run a loop through each weight (in 1kg increments) and calculate their theoretical dose, and the dose for each possible starting point (there are certain contraints on that already so there may only be 20 possible start points), then we calculate the % variance for each dose to theoretical dose and calculate the Area Under & Above (some will be negative) the curve and the one that has the lowest AUC is then the one that most "precisely" will dose the patient??


I think you need to classify what pharmacokinetics apply to a particular drug (zeroth,  or first order kinetics, volume of distribution affected by <whatever>) and choose from a limited number of heuristics for drugs rahter than solving each case from first principles.

-- 
David Winsemius
Alameda, CA, USA


From Pradip.Muhuri at samhsa.hhs.gov  Sun Jun  9 19:16:50 2013
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Sun, 9 Jun 2013 17:16:50 +0000
Subject: [R] Regression Tolerance Intervals - Dr. Young's Code
In-Reply-To: <51B4A533.8090501@statistik.tu-dortmund.de>
References: <E18C153EBB81024CB60FCE9B4C34D57C23331688@pl-emsmb11>,
	<51B4A533.8090501@statistik.tu-dortmund.de>
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C23331E92@pl-emsmb11>

Uwe and Dennis - Thank you so much for your comments, tips and advice. The following reproducible code has worked and given me the desired results. 

Pradip


####################### Revised Code #################


setwd ("C:/RAPP")
require ("tolerance")
set.seed (100);x <- runif (200,0,10); y <- 20+5*x + rnorm (100,0,20); data.frame (cbind (x,y))
out <- regtol.int (reg=lm(y~x), new.x=cbind (c(3,6,12)), side=2, alpha=.05, P=.90);
plottol(out, x=cbind(1,x), y=y, side="two", x.lab="X", y.lab="Y" )



________________________________________
From: Uwe Ligges [ligges at statistik.tu-dortmund.de]
Sent: Sunday, June 09, 2013 11:54 AM
To: Muhuri, Pradip (SAMHSA/CBHSQ)
Cc: "R help ?[r-help at r-project.org]?"; mridulbiva at aol.com
Subject: Re: [R] Regression Tolerance Intervals - Dr. Young's Code

On 08.06.2013 05:17, Muhuri, Pradip (SAMHSA/CBHSQ) wrote:
> Hello,
>
> Below is a reproducible example to generate the output by using Dr. Young's R code on the above subject .   As commented below, the issue is that  part of the code (regtol.int and plottol) does not seem to work.
>
> I would appreciate receiving your advice toward resolving the issue.
>
> Thanks and regards,
>
> Pradip Muhuri
>
>
> setwd ("E:/")
> require ("tolerance")
>
> d1<- "xlndur      ylnant
> 8.910797  0.33901690
> 9.001415  0.36464311
> 8.983936  0.53976194
> 8.948035  0.33901690
> 9.056784  0.39266961
> 9.018593  0.18617770
> 9.001415  0.53976194
> 8.983936 -0.11005034
> 8.966147  0.53102826
> 8.948035  0.59885086
> 6.900000  NA"
>
> xd1 <- read.table(textConnection(d1), header=TRUE, as.is=TRUE)
> print (xd1); str (xd1)
>
> #This code works
> xout1 <- regtol.int (reg=lm (formula=ylnant ~ xlndur, data=xd1),  alpha=.05, P=0.99, side=2)
> print (xout1)
>
>
> #This code does not work
> xout2 <- regtol.int (reg=lm (formula=ylnant ~ xlndur, data=xd1), new.xlndur = NULL,  alpha=.05, P=0.99, side=2)

Come on, start using your brain and replace new.xlndur by new.x?

> print (xout2)
> #This code does not work
> plottol(xout1, x=cbind(1,x), y=y, side="two", x.lab="X", y.lab="Y" )

So replace x and y appropriately?

Best,
Uwe Ligges



> #This code does not work
> plottol(xout2, x=cbind(1,x), y=y, side="two", x.lab="X", y.lab="Y" )
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From colstat at gmail.com  Mon Jun 10 00:13:50 2013
From: colstat at gmail.com (Colstat)
Date: Sun, 9 Jun 2013 18:13:50 -0400
Subject: [R] Coefficients paths - comparison of ridge,
 lasso and elastic net regression
In-Reply-To: <1370442170146-4668722.post@n4.nabble.com>
References: <1370442170146-4668722.post@n4.nabble.com>
Message-ID: <CABc7NqECAKiK4zqvQqu8ky=VysWaxzjBHc2EvFTHMJ_oCQPmzw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130609/6580e6e8/attachment.pl>

From davidmarino838 at gmail.com  Mon Jun 10 01:08:24 2013
From: davidmarino838 at gmail.com (Marino David)
Date: Mon, 10 Jun 2013 07:08:24 +0800
Subject: [R] It seams that fast99 function (sensitivity package) does
 not work out for norm distribution.
In-Reply-To: <51B4A3EE.4040901@statistik.tu-dortmund.de>
References: <CABmD0bFA0Q_HNQ-4+Z2rKftO=MYtEAjAz7qajKszJ2hK-TQBVA@mail.gmail.com>
	<51B4A3EE.4040901@statistik.tu-dortmund.de>
Message-ID: <CABmD0bEFKiW6tpZLc0g8der2PJkGaNg1T=+D1oot_haQmKe6HA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130610/87b41e14/attachment.pl>

From dwinsemius at comcast.net  Mon Jun 10 02:21:24 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 9 Jun 2013 17:21:24 -0700
Subject: [R] It seams that fast99 function (sensitivity package) does
	not work out for norm distribution.
In-Reply-To: <CABmD0bEFKiW6tpZLc0g8der2PJkGaNg1T=+D1oot_haQmKe6HA@mail.gmail.com>
References: <CABmD0bFA0Q_HNQ-4+Z2rKftO=MYtEAjAz7qajKszJ2hK-TQBVA@mail.gmail.com>
	<51B4A3EE.4040901@statistik.tu-dortmund.de>
	<CABmD0bEFKiW6tpZLc0g8der2PJkGaNg1T=+D1oot_haQmKe6HA@mail.gmail.com>
Message-ID: <738553DB-6F11-4557-AA05-28325EDCBB76@comcast.net>


On Jun 9, 2013, at 4:08 PM, Marino David wrote:

> The author has already gave the illustration and solution as well.
> 

Is that supposed to mean that you emailed the author and got a private response?

> Thanks.
> 
> 
> 
> 2013/6/9 Uwe Ligges <ligges at statistik.tu-dortmund.de>
> 
>> 
>> 
>> On 08.06.2013 00:54, Marino David wrote:
>> 
>>> Dear all mailing listers,
>>> 
>>> Does Anyone have the same problem as mine when using the fast99
>>> (extended-FAST method) to perform SA of model with norm distribution
>>> inputs?
>>> 
>> 
>> Why not ask the authors of the function?
>> 
>> Best,
>> Uwe Ligges
>> 
>> 
>>> See the simple example given following.
>>> 
>>> Any suggestion will be greatly appreciated.
>>> 
>>> Thank you!
>>> 
>>> Marino
>>> 
>>> 
>>> # Simple example
>>> 
>>> # 1. uniform version (It works well)
>>> library(sensitivity)
>>> Myfun<-function(x){return(**rowSums(x))}
>>> SA1 <- fast99(model = Myfun, factors = 3, n = 1000, q = "qunif", q.arg =
>>> list(min = 0, max = 1))
>>> 
>>> 
>>> SA1
>>>> 
>>> Call:
>>> fast99(model = Myfun, factors = 3, n = 1000, q = "qunif", q.arg =
>>> list(min = 0,     max = 1))
>>> 
>>> Model runs: 3000
>>> 
>>> Estimations of the indices:
>>>    first order total order
>>> X1   0.3335243   0.3350584
>>> X2   0.3335243   0.3350584
>>> X3   0.3335243   0.3350584
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> # 2. norm version (it does not work)
>>> SA2 <- fast99(model = Myfun, factors = 3, n = 1000, q = "qnorm", q.arg =
>>> list(mean = 0, sd = 1))
>>> 
>>> 
>>> SA2
>>>> 
>>> Call:
>>> fast99(model = Myfun, factors = 3, n = 1000, q = "qnorm", q.arg =
>>> list(mean = 0,     sd = 1))
>>> 
>>> Model runs: 3000
>>> 
>>> Estimations of the indices:
>>>    first order total order
>>> X1          NA          NA
>>> X2          NA          NA
>>> X3          NA          NA
>>> 
>>>        [[alternative HTML version deleted]]

--

David Winsemius
Alameda, CA, USA


From santosh2005 at gmail.com  Mon Jun 10 02:52:16 2013
From: santosh2005 at gmail.com (Santosh)
Date: Sun, 9 Jun 2013 17:52:16 -0700
Subject: [R] Using Lattice,
	LatticeExtra - Hide right and top axes in multipanel plots
Message-ID: <CAN_e6XtOvChJrh5V5kOpUuBqt3rWdG=er3gAz4wrxjO_i2=scQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130609/16e4912b/attachment.pl>

From santosh2005 at gmail.com  Mon Jun 10 03:04:30 2013
From: santosh2005 at gmail.com (Santosh)
Date: Sun, 9 Jun 2013 18:04:30 -0700
Subject: [R] Using Lattice,
 LatticeExtra - Hide right and top axes in multipanel plots
In-Reply-To: <CAN_e6XtOvChJrh5V5kOpUuBqt3rWdG=er3gAz4wrxjO_i2=scQ@mail.gmail.com>
References: <CAN_e6XtOvChJrh5V5kOpUuBqt3rWdG=er3gAz4wrxjO_i2=scQ@mail.gmail.com>
Message-ID: <CAN_e6XtsHkXLVVep_EgrEYF6829a5pz=mt-X7SFuVVs=HMOZUg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130609/d3b122e1/attachment.pl>

From mackay at northnet.com.au  Mon Jun 10 04:09:06 2013
From: mackay at northnet.com.au (Duncan Mackay)
Date: Mon, 10 Jun 2013 12:09:06 +1000
Subject: [R] Using Lattice,
 LatticeExtra - Hide right and top axes  in multipanel plots
In-Reply-To: <CAN_e6XtsHkXLVVep_EgrEYF6829a5pz=mt-X7SFuVVs=HMOZUg@mail.g
	mail.com>
References: <CAN_e6XtOvChJrh5V5kOpUuBqt3rWdG=er3gAz4wrxjO_i2=scQ@mail.gmail.com>
	<CAN_e6XtsHkXLVVep_EgrEYF6829a5pz=mt-X7SFuVVs=HMOZUg@mail.gmail.com>
Message-ID: <201306100209.r5A296qL002878@mail14.tpg.com.au>

Hi

You had to references to strip
The axis.line in the par settings removes the axis line
Have made some slight changes to your code which may be of interest

I keep the panel arguments last and so avoid duplication


         require(grid)
xyplot(b~t|G,data=q2,groups=grp,
        type="l",
        aspect = 1,
        as.table=T,
        layout=c(3,1),
         xlab="t",
         ylab="b",
         main="Overlay of Profiles by Schools and Classes",
         par.settings=list(layout.heights = list(strip =2),
                           axis.line=list(col=0)),
        strip=strip.custom(strip.names=T,strip.levels=T,par.strip.text=list(cex=1.7,font=2),bg=0,var.name="School"),
        scales=list(x=list(rela='free',alternating=0),
                    y=list(rela='free',alternating=0),
                           col=1,
                           tck=c(1,0)),
        panel=panel.superpose,
        panel.groups=function(x=x,y=y,subscripts=subscripts,groups=groups,...,group.number){

          panel.axis(side="top",labels = F,draw.labels = F,ticks = F, 
line.lwd=0, line.alpha=0)
          panel.xyplot(x=x,y=y,subscripts=subscripts,
                       lwd=1,type="l",
                       col=q2$dcol[subscripts],
                       lty=1,
                       cex=0.7)
         }
)

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au



At 11:04 10/06/2013, you wrote:
>I updated the code for the second example.. This time.. all the axes
>disappeared!!
>
>xyplot(b~t|G,data=q2,groups=grp,type="l",as.table=T,
>     layout=c(3,1), par.settings=list(axis.line=list(col=0)),
>scales=list(x=list(rela='free',alternating=0),y=list(rela='free',alternating=0),col=1,tck=c(1,0)),
>     panel=panel.superpose,
>panel.groups=function(x=x,y=y,subscripts=subscripts,groups=groups,...,group.number)
>{
>         require(grid)
>panel.axis(side="top",labels = F,draw.labels = F,ticks = F,line.col=NA,
>line.lty=NA, line.lwd=0, line.alpha=0)
>         panel.xyplot(x=x,y=y,subscripts=subscripts,pch=NA,lwd=1,type="l",
>                         col=q2$dcol[subscripts],lty=1,cex=0.7)
>         },
>strip=F,
>     #
>strip=strip.custom(strip.names=T,strip.levels=T,par.strip.text=list(cex=1.7,font=2),bg=0,
>var.name="School"),
>         xlab="t",
>         ylab="b",
>         main="Overlay of Profiles by Schools and Classes",
>)
>
>
>
>On Sun, Jun 9, 2013 at 5:52 PM, Santosh <santosh2005 at gmail.com> wrote:
>
> > Dear Rxperts,
> > How do I hide the top and right axes in multiple panel plots? A couple of
> > examples are provided below.. Would highly appreciate appreciate your
> > assistance..
> >
> > #Example 1
> > library(latticeExtra)
> > xyplot((1:200)/20 ~ (1:200)/20, type = c("p", "g"),
> > scales = list(x = list(log = 2,alternating=0), y = list(log =
> > 10,alternating=0)),
> > xscale.components = xscale.components.log10ticks,
> > yscale.components = yscale.components.log10ticks,top=F,right=F)
> >
> > #Example 2
> > q <-
> > 
> data.frame(G=rep(paste("G",1:3,sep=""),each=50),D=rep(paste("D",1:5,sep=""),each=30),a=rep(1:15,each=10),t=rep(seq(10),15),b=round(runif(150,10,20)))
> > q$grp <- paste(q$D,q$a,sep=":")
> > q$grp <-  ordered(q$grp, levels=unique(q$grp))
> > q$dcol  <- unlist(sapply(q$D,function(x)
> >         switch(x,"D1"="orange","D2"="blue","D3"="red", "D4"="seagreen",
> > "D5"="black")))
> > q2 <- q[order(q$G,q$D,q$a,q$t),]
> > xyplot(b~t|G,data=q2,groups=grp,type="l",as.table=T,
> >     layout=c(3,1), par.strip.text = list(lines = 2),
> >
> > 
> scales=list(x=list(rela='free',alternating=0),y=list(rela='free',alternating=0),col=1,tck=c(1,0)),
> >     panel=panel.superpose,
> > 
> panel.groups=function(x=x,y=y,subscripts=subscripts,groups=groups,...,group.number)
> > {
> >         require(grid)
> >  panel.axis(side="top",labels = F,draw.labels = F,ticks = F,line.col=NA,
> > line.lty=NA,   line.lwd=0, line.alpha=0)
> >         panel.xyplot(x=x,y=y,subscripts=subscripts,pch=NA,lwd=1,type="l",
> >                         col=q2$dcol[subscripts],lty=1,cex=0.7)
> >         },
> > strip=F,
> >     #
> > 
> strip=strip.custom(strip.names=T,strip.levels=T,par.strip.text=list(cex=1.7,font=2),bg=0,
> > var.name="School"),
> >         xlab="t",
> >         ylab="b",
> >         main="Overlay of Profiles by Schools and Classes",
> > )
> >
> >
> > Thanks so much,
> > Santosh
> >
>
>         [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From kridox at ymail.com  Mon Jun 10 04:17:22 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Mon, 10 Jun 2013 11:17:22 +0900
Subject: [R] cannot load pbdMPI package after compilation
In-Reply-To: <51B1D53C.1090305@u-bourgogne.fr>
References: <51B1D53C.1090305@u-bourgogne.fr>
Message-ID: <51B53732.6050607@ymail.com>

Hello,

I am not sure whether it helps you, but I was able to install it.

OpenSUSE 12.3
R version 3.0.1 Patched (2013-06-09 r62918)
pbdMPI version 0.1-6
gcc version 4.7.2
OpenMPI version 1.6.3

I didn't try with the most recent version of ompi (1.6.4).

Regards,
Pascal


On 07/06/13 21:42, Antoine Migeon wrote:
> Hello,
>
> I try to install pbdMPI.
> Compilation successful, but load fails with segfault.
>
> Is anyone can help me?
>
> R version 3.0.0
> pbdMPI version 0.1-6
> Intel compiler version 13.1.1
> OpenMPI version 1.6.4-1
> CPU Intel x86_64
>
> # R CMD INSTALL pbdMPI_0.1-6.tar.gz
> ..
> ....
> checking for gcc... icc -std=gnu99
> checking whether the C compiler works... yes
> checking for C compiler default output file name... a.out
> checking for suffix of executables...
> checking whether we are cross compiling... no
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether icc -std=gnu99 accepts -g... yes
> checking for icc -std=gnu99 option to accept ISO C89... none needed
> checking for mpirun... mpirun
> checking for mpiexec... mpiexec
> checking for orterun... orterun
> checking for sed... /bin/sed
> checking for mpicc... mpicc
> checking for ompi_info... ompi_info
> checking for mpich2version... F
> found sed, mpicc, and ompi_info ...
>>> TMP_INC_DIRS = /opt/openmpi/1.6.4-1/intel-13.1.1/include
> checking /opt/openmpi/1.6.4-1/intel-13.1.1/include ...
> found /opt/openmpi/1.6.4-1/intel-13.1.1/include/mpi.h ...
>>> TMP_LIB_DIRS = /opt/openmpi/1.6.4-1/intel-13.1.1/lib64
> checking /opt/openmpi/1.6.4-1/intel-13.1.1/lib64 ...
> found /opt/openmpi/1.6.4-1/intel-13.1.1/lib64/libmpi.so ...
> found mpi.h and libmpi.so ...
>>> TMP_INC = /opt/openmpi/1.6.4-1/intel-13.1.1/include
>>> TMP_LIB = /opt/openmpi/1.6.4-1/intel-13.1.1/lib64
> checking for openpty in -lutil... yes
> checking for main in -lpthread... yes
>
> ******************* Results of pbdMPI package configure *****************
>
>>> TMP_INC = /opt/openmpi/1.6.4-1/intel-13.1.1/include
>>> TMP_LIB = /opt/openmpi/1.6.4-1/intel-13.1.1/lib64
>>> MPI_ROOT =
>>> MPITYPE = OPENMPI
>>> MPI_INCLUDE_PATH = /opt/openmpi/1.6.4-1/intel-13.1.1/include
>>> MPI_LIBPATH = /opt/openmpi/1.6.4-1/intel-13.1.1/lib64
>>> MPI_LIBS =  -lutil -lpthread
>>> MPI_DEFS = -DMPI2
>>> MPI_INCL2 =
>>> PKG_CPPFLAGS = -I/opt/openmpi/1.6.4-1/intel-13.1.1/include  -DMPI2
> -DOPENMPI
>>> PKG_LIBS = -L/opt/openmpi/1.6.4-1/intel-13.1.1/lib64 -lmpi  -lutil
> -lpthread
> *************************************************************************
> ..
> icc -std=gnu99 -I/usr/local/R/3.0.0/intel13/lib64/R/include -DNDEBUG
> -I/opt/openmpi/1.6.4-1/intel-13.1.1/include  -DMPI2 -DOPENMPI -O3
> -fp-model precise -pc 64 -axAVX    -fpic  -O3 -fp-model precise  -pc 64
> -axAVX  -c comm_errors.c -o comm_errors.o
> icc -std=gnu99 -I/usr/local/R/3.0.0/intel13/lib64/R/include -DNDEBUG
> -I/opt/openmpi/1.6.4-1/intel-13.1.1/include  -DMPI2 -DOPENMPI -O3
> -fp-model precise -pc 64 -axAVX    -fpic  -O3 -fp-model precise  -pc 64
> -axAVX  -c comm_sort_double.c -o comm_sort_double.o
> .
> ..
> ....
> ** testing if installed package can be loaded
> sh: line 1:  2905 Segmentation fault
> '/usr/local/R/3.0.0/intel13/lib64/R/bin/R' --no-save --slave 2>&1 <
> /tmp/RtmpGkncGK/file1e541c57190
> ERROR: loading failed
>
>   *** caught segfault ***
> address (nil), cause 'unknown'
>
> Traceback:
>   1: .Call("spmd_initialize", PACKAGE = "pbdMPI")
>   2: fun(libname, pkgname)
>   3: doTryCatch(return(expr), name, parentenv, handler)
>   4: tryCatchOne(expr, names, parentenv, handlers[[1L]])
>   5: tryCatchList(expr, classes, parentenv, handlers)
>   6: tryCatch(fun(libname, pkgname), error = identity)
>   7: runHook(".onLoad", env, package.lib, package)
>   8: loadNamespace(package, c(which.lib.loc, lib.loc))
>   9: doTryCatch(return(expr), name, parentenv, handler)
> 10: tryCatchOne(expr, names, parentenv, handlers[[1L]])
> 11: tryCatchList(expr, classes, parentenv, handlers)
> 12: tryCatch(expr, error = function(e) {    call <- conditionCall(e)
> if (!is.null(call)) {        if (identical(call[[1L]],
> quote(doTryCatch)))             call <- sys.call(-4L)        dcall <-
> deparse(call)[1L]        prefix <- paste("Error in", dcall, ": ")
> LONG <- 75L        msg <- conditionMessage(e)        sm <- strsplit(msg,
> "\n")[[1L]]        w <- 14L + nchar(dcall, type = "w") + nchar(sm[1L],
> type = "w")        if (is.na(w))             w <- 14L + nchar(dcall,
> type = "b") + nchar(sm[1L],                 type = "b")        if (w >
> LONG)             prefix <- paste0(prefix, "\n  ")    }    else prefix
> <- "Error : "    msg <- paste0(prefix, conditionMessage(e), "\n")
> .Internal(seterrmessage(msg[1L]))    if (!silent &&
> identical(getOption("show.error.messages"),         TRUE)) {
> cat(msg, file = stderr())        .Internal(printDeferredWarnings())
> }    invisible(structure(msg, class = "try-error", condition = e))})
> 13: try({    ns <- loadNamespace(package, c(which.lib.loc, lib.loc))
> env <- attachNamespace(ns, pos = pos, deps)})
> 14: library(pkg_name, lib.loc = lib, character.only = TRUE,
> logical.return = TRUE)
> 15: withCallingHandlers(expr, packageStartupMessage = function(c)
> invokeRestart("muffleMessage"))
> 16: suppressPackageStartupMessages(library(pkg_name, lib.loc = lib,
> character.only = TRUE, logical.return = TRUE))
> 17: doTryCatch(return(expr), name, parentenv, handler)
> 18: tryCatchOne(expr, names, parentenv, handlers[[1L]])
> 19: tryCatchList(expr, classes, parentenv, handlers)
> 20: tryCatch(expr, error = function(e) {    call <- conditionCall(e)
> if (!is.null(call)) {        if (identical(call[[1L]],
> quote(doTryCatch)))             call <- sys.call(-4L)        dcall <-
> deparse(call)[1L]        prefix <- paste("Error in", dcall, ": ")
> LONG <- 75L        msg <- conditionMessage(e)        sm <- strsplit(msg,
> "\n")[[1L]]        w <- 14L + nchar(dcall, type = "w") + nchar(sm[1L],
> type = "w")        if (is.na(w))             w <- 14L + nchar(dcall,
> type = "b") + nchar(sm[1L],                 type = "b")        if (w >
> LONG)             prefix <- paste0(prefix, "\n  ")    }    else prefix
> <- "Error : "    msg <- paste0(prefix, conditionMessage(e), "\n")
> .Internal(seterrmessage(msg[1L]))    if (!silent &&
> identical(getOption("show.error.messages"),         TRUE)) {
> cat(msg, file = stderr())        .Internal(printDeferredWarnings())
> }    invisible(structure(msg, class = "try-error", condition = e))})
> 21: try(suppressPackageStartupMessages(library(pkg_name, lib.loc =
> lib,     character.only = TRUE, logical.return = TRUE)))
> 22: tools:::.test_load_package("pbdMPI",
> "/usr/local/R/3.0.0/intel13/lib64/R/library")
> aborting ...
>
>


From vickythakre at gmail.com  Mon Jun 10 05:02:29 2013
From: vickythakre at gmail.com (Bhupendrasinh Thakre)
Date: Sun, 9 Jun 2013 22:02:29 -0500
Subject: [R] Sending Email with Attachment
Message-ID: <04e301ce6586$f23e1120$d6ba3360$@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130609/77ddb44c/attachment.pl>

From rex at nosyntax.net  Mon Jun 10 05:27:17 2013
From: rex at nosyntax.net (rex)
Date: Sun, 9 Jun 2013 20:27:17 -0700
Subject: [R] Sending Email with Attachment
In-Reply-To: <04e301ce6586$f23e1120$d6ba3360$@gmail.com>
References: <04e301ce6586$f23e1120$d6ba3360$@gmail.com>
Message-ID: <20130610032717.GA20127@ninja.nosyntax.net>

Bhupendrasinh Thakre <vickythakre at gmail.com> [2013-06-09 20:03]:
>
>library("sendmailR")
>
>from <- "abcd at outlook.com"
>to <-  <mailto:efgh at gmail.com> efgh at gmail.com
>subject <- "Run at"
>mailControl = list(smtpServer="blu-m.hotmail.com")
>attachment <- "type_1.pdf"
>attachmentName <- "target_score.pdf"
>attachmentObject <- mime_part(x= attachment,name= attachmentName)
>body <- "Email Body"
>bodywithAttachement <- list(body, attachmentObject)
>sendmail(from=from,to=to,subject=subject,msg=
>bodywithAttachement,control=mailControl)
>
>However it gives me following Error:
>
>Error:
>
>Error in socketConnection(host = server, port = port, blocking = TRUE) :
>  cannot open the connection
>In addition: Warning message:
>In socketConnection(host = server, port = port, blocking = TRUE) :
>  blu-m.hotmail.com:25 cannot be opened

It's an unsurprising result since telnet doesn't connect either:
  
telnet blu-m.hotmail.com 25
Trying 65.55.121.94...
telnet: Unable to connect to remote host: Connection timed out

Try port 443:

telnet blu-m.hotmail.com 443
Trying 65.55.121.94...
Connected to eas-blu.hot.glbdns.microsoft.com.
Escape character is '^]'.

But it's probably expecting TLS, and sendmailR doesn't support it.

>Please let me know if we have some solution for this.

If you want to use sendmailR, you need to find a mail server that
does not require TLS. This may mean running your own mail server. 

Or, you can call an external program that handles a TLS connection.

-rex
-- 
Proofread carefully to see if you any words out.


From vickythakre at gmail.com  Mon Jun 10 06:06:55 2013
From: vickythakre at gmail.com (Bhupendrasinh Thakre)
Date: Sun, 9 Jun 2013 23:06:55 -0500
Subject: [R] Sending Email with Attachment
In-Reply-To: <20130610032717.GA20127@ninja.nosyntax.net>
References: <04e301ce6586$f23e1120$d6ba3360$@gmail.com>
	<20130610032717.GA20127@ninja.nosyntax.net>
Message-ID: <04f101ce658f$f2be4e90$d83aebb0$@gmail.com>

Thanks Rex for the help. So it seems that I might have to use Python or Perl
to perform the action.



-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of rex
Sent: Sunday, June 09, 2013 10:27 PM
To: r-help at r-project.org
Subject: Re: [R] Sending Email with Attachment

Bhupendrasinh Thakre <vickythakre at gmail.com> [2013-06-09 20:03]:
>
>library("sendmailR")
>
>from <- "abcd at outlook.com"
>to <-  <mailto:efgh at gmail.com> efgh at gmail.com subject <- "Run at"
>mailControl = list(smtpServer="blu-m.hotmail.com")
>attachment <- "type_1.pdf"
>attachmentName <- "target_score.pdf"
>attachmentObject <- mime_part(x= attachment,name= attachmentName) body 
><- "Email Body"
>bodywithAttachement <- list(body, attachmentObject) 
>sendmail(from=from,to=to,subject=subject,msg=
>bodywithAttachement,control=mailControl)
>
>However it gives me following Error:
>
>Error:
>
>Error in socketConnection(host = server, port = port, blocking = TRUE) :
>  cannot open the connection
>In addition: Warning message:
>In socketConnection(host = server, port = port, blocking = TRUE) :
>  blu-m.hotmail.com:25 cannot be opened

It's an unsurprising result since telnet doesn't connect either:
  
telnet blu-m.hotmail.com 25
Trying 65.55.121.94...
telnet: Unable to connect to remote host: Connection timed out

Try port 443:

telnet blu-m.hotmail.com 443
Trying 65.55.121.94...
Connected to eas-blu.hot.glbdns.microsoft.com.
Escape character is '^]'.

But it's probably expecting TLS, and sendmailR doesn't support it.

>Please let me know if we have some solution for this.

If you want to use sendmailR, you need to find a mail server that does not
require TLS. This may mean running your own mail server. 

Or, you can call an external program that handles a TLS connection.

-rex
--
Proofread carefully to see if you any words out.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Aakanksha_Dahiya01 at infosys.com  Mon Jun 10 06:24:25 2013
From: Aakanksha_Dahiya01 at infosys.com (Aakanksha Dahiya01)
Date: Mon, 10 Jun 2013 04:24:25 +0000
Subject: [R] arima time series in R
In-Reply-To: <51B1CB05.1020908@stats.ox.ac.uk>
References: <A70E6C8815CB614D92A3AAD769261E8101E54CFB@BLRKECMBX12.ad.infosys.com>
	<51B1CB05.1020908@stats.ox.ac.uk>
Message-ID: <A70E6C8815CB614D92A3AAD769261E8101E5621E@BLRKECMBX12.ad.infosys.com>

I am just performing arima time series analysis here.. and package used is "forecast".  I am just not  able what is ar1,ma1 and ma2.

-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Sent: Friday, June 07, 2013 5:29 PM
To: Aakanksha Dahiya01
Cc: r-help at r-project.org
Subject: Re: [R] arima time series in R

On 07/06/2013 12:21, Aakanksha Dahiya01 wrote:
>
> Hi
>
> Could just anyone explain me the coefficients in the output of arima 
> model

The person who wrote the help page already did, but that is hardly 'just anyone'.

> timeseriesarima <- arima(series, order=c(1,1,2))
>> timeseriesarima
> Series: series
> ARIMA(1,1,2)
>
> Coefficients:
>           ar1      ma1     ma2
>        0.9744  -1.7695  0.7873
> s.e.  0.0310   0.0481  0.0426
>
> sigma^2 estimated as 337.4:  log likelihood=-1096.03
> AIC=2200.07   AICc=2200.23   BIC=2214.2

That is not from arima in package stats, so you need to follow the posting guide to tell us whose wrapper it is and hence which help page to read.  (Possibly package TSA.)

>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

That does mean you.



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

**************** CAUTION - Disclaimer *****************
This e-mail contains PRIVILEGED AND CONFIDENTIAL INFORMATION intended solely 
for the use of the addressee(s). If you are not the intended recipient, please 
notify the sender by e-mail and delete the original message. Further, you are not 
to copy, disclose, or distribute this e-mail or its contents to any other person and 
any such actions are unlawful. This e-mail may contain viruses. Infosys has taken 
every reasonable precaution to minimize this risk, but is not liable for any damage 
you may sustain as a result of any virus in this e-mail. You should carry out your 
own virus checks before opening the e-mail or attachment. Infosys reserves the 
right to monitor and review the content of all messages sent to or from this e-mail 
address. Messages sent to or from this e-mail address may be stored on the 
Infosys e-mail system.
***INFOSYS******** End of Disclaimer ********INFOSYS***


From cdwilliamson at cmu.edu  Mon Jun 10 00:07:48 2013
From: cdwilliamson at cmu.edu (Court)
Date: Sun, 9 Jun 2013 15:07:48 -0700 (PDT)
Subject: [R] Error Object Not Found
In-Reply-To: <51B4A15E.9090707@statistik.tu-dortmund.de>
References: <1370720137364-4669041.post@n4.nabble.com>
	<51B4A15E.9090707@statistik.tu-dortmund.de>
Message-ID: <1370815668505-4669100.post@n4.nabble.com>

Hi, 

I think that they are loaded.  Here is the response that I get:

 package ?foreign? successfully unpacked and MD5 sums checked




--
View this message in context: http://r.789695.n4.nabble.com/Error-Object-Not-Found-tp4669041p4669100.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Mon Jun 10 03:34:34 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 9 Jun 2013 18:34:34 -0700 (PDT)
Subject: [R] Loop through variables and estimate effects on several
	outcomes
In-Reply-To: <CAFqDh9JBrqw0Jpe3Am3+tX-58hTYSh7VAamRP2+rhAMkyjXRAQ@mail.gmail.com>
References: <4746346.37094.1370556057173.JavaMail.nabble@joe.nabble.com>
	<CAFqDh9JBrqw0Jpe3Am3+tX-58hTYSh7VAamRP2+rhAMkyjXRAQ@mail.gmail.com>
Message-ID: <1370828074.70681.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
I assume this is what you wanted:
#########Your code
library(gamair)
data(chicago)
?library(mgcv)
library(splines)
chicago1<- chicago
chicago1$date<- seq(from=as.Date("1987-01-01"),to=as.Date("2000-12-31"),length=5114)
chicago1$trend<-seq(dim(chicago1)[1])? 
names(chicago1) [2] <-"pm10" 
names(chicago1) [3] <-"pm25" 
names(chicago1) [4] <-"ozone" 
names(chicago1) [5] <-"so2" 
names(chicago1) [7]?? <-"temp" 
chicago1$cv<-rpois(5114, lambda = 35) 
chicago1$resp<-rpois(5114, lambda = 13) 
chicago1$trend<-seq(dim(chicago1)[1]) 
chicago1$year<-as.numeric(format(chicago1$date,"%Y")) 
m1<-glm(death ~ pm10 + pm25+ ns(trend,35) + ns(temp, 6), poisson , na.action = na.omit , data =chicago1) 
m4<-gam(death ~ pm10 + pm25+ s(trend,k=35)? + s(temp, k=6), quasipoisson , na.action = na.omit , data =chicago1)

####Extracting estimates

?coef(summary(m1))[-1,1][!grepl("ns",names(coef(summary(m1))[-1,1]))]
#??????? pm10???????? pm25 
# 0.001772681 -0.001481798 

summary(m4)$p.coeff[-1]
?#?????? pm10???????? pm25 
?#0.001346275 -0.001182925 

varlist<-names(chicago1)[c(1,10:11)]
?varlist
#[1] "death" "cv"??? "resp" 

####glm
fun2glm<- function(varName){
res<- sapply(varName,function(x){
model1<- glm(get(x)~ pm10 + pm25+ ns(trend,35)? + ns(temp, 6) , poisson , na.action = na.omit , data =chicago1)
sM<- coef(summary(model1))[-1,1]
indx<- grepl("ns",names(sM))
sM1<- sM[!indx]
})
res
}

fun2glm(varlist)
#??????????? death??????????? cv????????? resp
#pm10? 0.001772681? 0.0003505286 -0.0006736290
#pm25 -0.001481798 -0.0004193602? 0.0005567137



####gam
fun2gam<- function(varName){
?res<- sapply(varName,function(x){
?model1<- gam(get(x)~pm10+pm25+s(trend,k=35)+s(temp,k=6),quasipoisson,na.action=na.omit,data=chicago1)
?sM<- summary(model1)$p.coeff[-1]
? })
?res
?}
fun2gam(varlist)
#??????????? death??????????? cv????????? resp
#pm10? 0.001346275? 0.0003902584 -0.0008447569
#pm25 -0.001182925 -0.0007072599? 0.0002807046


A.K.









________________________________
From: Gustav Sigtuna <gsigtuna at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Friday, June 7, 2013 5:56 PM
Subject: Re: Loop through variables and estimate effects on several outcomes



Hi Arun,?

Thanks for your response. I use GLM and GAM for Poisson distributed data. I have attached a sample code and data. In the summary I am interested to extract the linear estimates and not the spline terms.

Thanks for your help
G



On Fri, Jun 7, 2013 at 12:01 AM, <smartpink111 at yahoo.com> wrote:

<quote author='decoder'>
>HI,
>No problem.
>Are you using the same dataset or different? ?If you are using poisson or other distribution, the summary output table may be a bit different. ?If you can show the codes and an example dataset (if different), I can take a look.
>
>
>Thanks A.K.
>
>The code works for lm and thanks for that. I have some outcomes which are
>counts and wanted to run GLM with the same code and got the error message
>below.
>
>> fun2(varlist)
>Error in glm.fit(x = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ?:
>? (subscript) logical subscript too long
>
>Can you explain what went wrong with the GLM code and how to rectify it?
>
>Thanks
></quote>
>Quoted from:
>http://r.789695.n4.nabble.com/Loop-through-variables-and-estimate-effects-on-several-outcomes-tp4668814p4668875.html
>
>
>_____________________________________
>Sent from http://r.789695.n4.nabble.com
>
>


From gundalav at gmail.com  Mon Jun 10 05:26:44 2013
From: gundalav at gmail.com (Gundala Viswanath)
Date: Mon, 10 Jun 2013 12:26:44 +0900
Subject: [R] All against all correlation matrix with GGPLOT Facet
Message-ID: <CADVKSzxVUdxSvmhmLcePbdsH2gin2ATzOVDOfMxFzkj8B6eMVg@mail.gmail.com>

I have the following data:

v <- rnorm(13)
w <- rnorm(13)
x <- rnorm(13)
y <- rnorm(13)
z <- rnorm(13)


Using GGPLOT facet, what I want to do is to create a 5*5 matrix,
where each cells plot the correlation between
each pair of the above data. E.g. v-v,v-w; v-x,...,z-z


What's the way to do it?
Attached is the image.

GV.

From Aakanksha_Dahiya01 at infosys.com  Mon Jun 10 07:03:01 2013
From: Aakanksha_Dahiya01 at infosys.com (Aakanksha Dahiya01)
Date: Mon, 10 Jun 2013 05:03:01 +0000
Subject: [R] arima time series in R
References: <A70E6C8815CB614D92A3AAD769261E8101E54CFB@BLRKECMBX12.ad.infosys.com>
	<51B1CB05.1020908@stats.ox.ac.uk> 
Message-ID: <A70E6C8815CB614D92A3AAD769261E8101E5626B@BLRKECMBX12.ad.infosys.com>

It would be great help if someone just tell me what does ar1,ma1 and ma2 signify here.. how do I further predict from these coefficients..

-----Original Message-----
From: Aakanksha Dahiya01 
Sent: Monday, June 10, 2013 9:54 AM
To: 'Prof Brian Ripley'
Cc: r-help at r-project.org
Subject: RE: [R] arima time series in R

I am just performing arima time series analysis here.. and package used is "forecast".  I am just not  able what is ar1,ma1 and ma2.

-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
Sent: Friday, June 07, 2013 5:29 PM
To: Aakanksha Dahiya01
Cc: r-help at r-project.org
Subject: Re: [R] arima time series in R

On 07/06/2013 12:21, Aakanksha Dahiya01 wrote:
>
> Hi
>
> Could just anyone explain me the coefficients in the output of arima 
> model

The person who wrote the help page already did, but that is hardly 'just anyone'.

> timeseriesarima <- arima(series, order=c(1,1,2))
>> timeseriesarima
> Series: series
> ARIMA(1,1,2)
>
> Coefficients:
>           ar1      ma1     ma2
>        0.9744  -1.7695  0.7873
> s.e.  0.0310   0.0481  0.0426
>
> sigma^2 estimated as 337.4:  log likelihood=-1096.03
> AIC=2200.07   AICc=2200.23   BIC=2214.2

That is not from arima in package stats, so you need to follow the posting guide to tell us whose wrapper it is and hence which help page to read.  (Possibly package TSA.)

>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

That does mean you.



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

**************** CAUTION - Disclaimer *****************
This e-mail contains PRIVILEGED AND CONFIDENTIAL INFORMATION intended solely 
for the use of the addressee(s). If you are not the intended recipient, please 
notify the sender by e-mail and delete the original message. Further, you are not 
to copy, disclose, or distribute this e-mail or its contents to any other person and 
any such actions are unlawful. This e-mail may contain viruses. Infosys has taken 
every reasonable precaution to minimize this risk, but is not liable for any damage 
you may sustain as a result of any virus in this e-mail. You should carry out your 
own virus checks before opening the e-mail or attachment. Infosys reserves the 
right to monitor and review the content of all messages sent to or from this e-mail 
address. Messages sent to or from this e-mail address may be stored on the 
Infosys e-mail system.
***INFOSYS******** End of Disclaimer ********INFOSYS***


From gundalav at gmail.com  Mon Jun 10 07:25:51 2013
From: gundalav at gmail.com (Gundala Viswanath)
Date: Mon, 10 Jun 2013 14:25:51 +0900
Subject: [R] How to expand.grid with string elements (the half!)
Message-ID: <CADVKSzww6anEaNpfaJSJcjhj6bgqDf-FhXgzMsVqmjTZ4FESaQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130610/f5bb37d4/attachment.pl>

From kridox at ymail.com  Mon Jun 10 16:48:24 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Mon, 10 Jun 2013 23:48:24 +0900
Subject: [R] arima time series in R
In-Reply-To: <A70E6C8815CB614D92A3AAD769261E8101E5626B@BLRKECMBX12.ad.infosys.com>
References: <A70E6C8815CB614D92A3AAD769261E8101E54CFB@BLRKECMBX12.ad.infosys.com>
	<51B1CB05.1020908@stats.ox.ac.uk>
	<A70E6C8815CB614D92A3AAD769261E8101E5626B@BLRKECMBX12.ad.infosys.com>
Message-ID: <51B5E738.4020304@ymail.com>

Hi,

library(forecast)
?Arima

And if you don't know what "ar" and "ma" are, you probably should read 
some book before to go further.

Regards,
Pascal


On 10/06/13 14:03, Aakanksha Dahiya01 wrote:
> It would be great help if someone just tell me what does ar1,ma1 and ma2 signify here.. how do I further predict from these coefficients..
>
> -----Original Message-----
> From: Aakanksha Dahiya01
> Sent: Monday, June 10, 2013 9:54 AM
> To: 'Prof Brian Ripley'
> Cc: r-help at r-project.org
> Subject: RE: [R] arima time series in R
>
> I am just performing arima time series analysis here.. and package used is "forecast".  I am just not  able what is ar1,ma1 and ma2.
>
> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: Friday, June 07, 2013 5:29 PM
> To: Aakanksha Dahiya01
> Cc: r-help at r-project.org
> Subject: Re: [R] arima time series in R
>
> On 07/06/2013 12:21, Aakanksha Dahiya01 wrote:
>>
>> Hi
>>
>> Could just anyone explain me the coefficients in the output of arima
>> model
>
> The person who wrote the help page already did, but that is hardly 'just anyone'.
>
>> timeseriesarima <- arima(series, order=c(1,1,2))
>>> timeseriesarima
>> Series: series
>> ARIMA(1,1,2)
>>
>> Coefficients:
>>            ar1      ma1     ma2
>>         0.9744  -1.7695  0.7873
>> s.e.  0.0310   0.0481  0.0426
>>
>> sigma^2 estimated as 337.4:  log likelihood=-1096.03
>> AIC=2200.07   AICc=2200.23   BIC=2214.2
>
> That is not from arima in package stats, so you need to follow the posting guide to tell us whose wrapper it is and hence which help page to read.  (Possibly package TSA.)
>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> That does mean you.
>
>
>


From es at enricoschumann.net  Mon Jun 10 08:06:51 2013
From: es at enricoschumann.net (Enrico Schumann)
Date: Mon, 10 Jun 2013 08:06:51 +0200
Subject: [R] Sending Email with Attachment
In-Reply-To: <04f101ce658f$f2be4e90$d83aebb0$@gmail.com> (Bhupendrasinh
	Thakre's message of "Sun, 9 Jun 2013 23:06:55 -0500")
References: <04e301ce6586$f23e1120$d6ba3360$@gmail.com>
	<20130610032717.GA20127@ninja.nosyntax.net>
	<04f101ce658f$f2be4e90$d83aebb0$@gmail.com>
Message-ID: <87wqq2h538.fsf@enricoschumann.net>

On Mon, 10 Jun 2013, "Bhupendrasinh Thakre" <vickythakre at gmail.com> writes:

> Thanks Rex for the help. So it seems that I might have to use Python or Perl
> to perform the action.
>
 
On Windows, you may want to look at Blat ( http://www.blat.net/ ).  You
can easily use it from R scripts via 'system'.


>
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
> Behalf Of rex
> Sent: Sunday, June 09, 2013 10:27 PM
> To: r-help at r-project.org
> Subject: Re: [R] Sending Email with Attachment
>
> Bhupendrasinh Thakre <vickythakre at gmail.com> [2013-06-09 20:03]:
>>
>>library("sendmailR")
>>
>>from <- "abcd at outlook.com"
>>to <-  <mailto:efgh at gmail.com> efgh at gmail.com subject <- "Run at"
>>mailControl = list(smtpServer="blu-m.hotmail.com")
>>attachment <- "type_1.pdf"
>>attachmentName <- "target_score.pdf"
>>attachmentObject <- mime_part(x= attachment,name= attachmentName) body 
>><- "Email Body"
>>bodywithAttachement <- list(body, attachmentObject) 
>>sendmail(from=from,to=to,subject=subject,msg=
>>bodywithAttachement,control=mailControl)
>>
>>However it gives me following Error:
>>
>>Error:
>>
>>Error in socketConnection(host = server, port = port, blocking = TRUE) :
>>  cannot open the connection
>>In addition: Warning message:
>>In socketConnection(host = server, port = port, blocking = TRUE) :
>>  blu-m.hotmail.com:25 cannot be opened
>
> It's an unsurprising result since telnet doesn't connect either:
>   
> telnet blu-m.hotmail.com 25
> Trying 65.55.121.94...

[...]

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From abhishek.vit at gmail.com  Mon Jun 10 08:15:48 2013
From: abhishek.vit at gmail.com (Abhishek Pratap)
Date: Sun, 9 Jun 2013 23:15:48 -0700
Subject: [R] reshaping a data frame
Message-ID: <CAJbA1KCmxcGktKQ8Pm6ssChTwA2Gq873k1pb_=TEFhQOtXtT7g@mail.gmail.com>

Hi Guys

I am trying to cast a data frame but not aggregate the rows for the
same variable.

here is a contrived example.

**input**
temp_df  <- data.frame(names=c('foo','foo','foo'),variable=c('w','w','w'),value=c(34,65,12))
> temp_df
  names variable value
1   foo        w    34
2   foo        w    65
3   foo        w    12


###########
**Want this**
############
names  w
foo         34
foo         65
foo         12


##
**getting this***
##
> cast(temp_df)
Aggregation requires fun.aggregate: length used as default
  names w
1   foo 3


In real dataset  the categorical column 'variable' will have many more
categorical variable.

Thanks!
-Abhi


From ripley at stats.ox.ac.uk  Mon Jun 10 08:19:20 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 10 Jun 2013 07:19:20 +0100
Subject: [R] cannot load pbdMPI package after compilation
In-Reply-To: <51B53732.6050607@ymail.com>
References: <51B1D53C.1090305@u-bourgogne.fr> <51B53732.6050607@ymail.com>
Message-ID: <51B56FE8.50803@stats.ox.ac.uk>

On 10/06/2013 03:17, Pascal Oettli wrote:
> Hello,
>
> I am not sure whether it helps you, but I was able to install it.
>
> OpenSUSE 12.3
> R version 3.0.1 Patched (2013-06-09 r62918)
> pbdMPI version 0.1-6
> gcc version 4.7.2
> OpenMPI version 1.6.3
>
> I didn't try with the most recent version of ompi (1.6.4).

But the system used to accept that version of pdbMPI for CRAN used it, 
with gcc.

The issue here is likely to be using the Intel compiler with OpenMPI. 
This is a programming matter really off-topic for R-help (see the 
posting guide).  The first port of call for help is the package 
maintainer, then if that does not help, the R-devel list.  But very few 
R users have access to an Intel compiler, let alone one as recent as 
that, and you will be expected to use a debugger for yourself (see 
'Writing R Extensions').

>
> Regards,
> Pascal
>
>
> On 07/06/13 21:42, Antoine Migeon wrote:
>> Hello,
>>
>> I try to install pbdMPI.
>> Compilation successful, but load fails with segfault.
>>
>> Is anyone can help me?
>>
>> R version 3.0.0
>> pbdMPI version 0.1-6
>> Intel compiler version 13.1.1
>> OpenMPI version 1.6.4-1
>> CPU Intel x86_64
>>
>> # R CMD INSTALL pbdMPI_0.1-6.tar.gz
>> ..
>> ....
>> checking for gcc... icc -std=gnu99
>> checking whether the C compiler works... yes
>> checking for C compiler default output file name... a.out
>> checking for suffix of executables...
>> checking whether we are cross compiling... no
>> checking for suffix of object files... o
>> checking whether we are using the GNU C compiler... yes
>> checking whether icc -std=gnu99 accepts -g... yes
>> checking for icc -std=gnu99 option to accept ISO C89... none needed
>> checking for mpirun... mpirun
>> checking for mpiexec... mpiexec
>> checking for orterun... orterun
>> checking for sed... /bin/sed
>> checking for mpicc... mpicc
>> checking for ompi_info... ompi_info
>> checking for mpich2version... F
>> found sed, mpicc, and ompi_info ...
>>>> TMP_INC_DIRS = /opt/openmpi/1.6.4-1/intel-13.1.1/include
>> checking /opt/openmpi/1.6.4-1/intel-13.1.1/include ...
>> found /opt/openmpi/1.6.4-1/intel-13.1.1/include/mpi.h ...
>>>> TMP_LIB_DIRS = /opt/openmpi/1.6.4-1/intel-13.1.1/lib64
>> checking /opt/openmpi/1.6.4-1/intel-13.1.1/lib64 ...
>> found /opt/openmpi/1.6.4-1/intel-13.1.1/lib64/libmpi.so ...
>> found mpi.h and libmpi.so ...
>>>> TMP_INC = /opt/openmpi/1.6.4-1/intel-13.1.1/include
>>>> TMP_LIB = /opt/openmpi/1.6.4-1/intel-13.1.1/lib64
>> checking for openpty in -lutil... yes
>> checking for main in -lpthread... yes
>>
>> ******************* Results of pbdMPI package configure *****************
>>
>>>> TMP_INC = /opt/openmpi/1.6.4-1/intel-13.1.1/include
>>>> TMP_LIB = /opt/openmpi/1.6.4-1/intel-13.1.1/lib64
>>>> MPI_ROOT =
>>>> MPITYPE = OPENMPI
>>>> MPI_INCLUDE_PATH = /opt/openmpi/1.6.4-1/intel-13.1.1/include
>>>> MPI_LIBPATH = /opt/openmpi/1.6.4-1/intel-13.1.1/lib64
>>>> MPI_LIBS =  -lutil -lpthread
>>>> MPI_DEFS = -DMPI2
>>>> MPI_INCL2 =
>>>> PKG_CPPFLAGS = -I/opt/openmpi/1.6.4-1/intel-13.1.1/include  -DMPI2
>> -DOPENMPI
>>>> PKG_LIBS = -L/opt/openmpi/1.6.4-1/intel-13.1.1/lib64 -lmpi  -lutil
>> -lpthread
>> *************************************************************************
>> ..
>> icc -std=gnu99 -I/usr/local/R/3.0.0/intel13/lib64/R/include -DNDEBUG
>> -I/opt/openmpi/1.6.4-1/intel-13.1.1/include  -DMPI2 -DOPENMPI -O3
>> -fp-model precise -pc 64 -axAVX    -fpic  -O3 -fp-model precise  -pc 64
>> -axAVX  -c comm_errors.c -o comm_errors.o
>> icc -std=gnu99 -I/usr/local/R/3.0.0/intel13/lib64/R/include -DNDEBUG
>> -I/opt/openmpi/1.6.4-1/intel-13.1.1/include  -DMPI2 -DOPENMPI -O3
>> -fp-model precise -pc 64 -axAVX    -fpic  -O3 -fp-model precise  -pc 64
>> -axAVX  -c comm_sort_double.c -o comm_sort_double.o
>> .
>> ..
>> ....
>> ** testing if installed package can be loaded
>> sh: line 1:  2905 Segmentation fault
>> '/usr/local/R/3.0.0/intel13/lib64/R/bin/R' --no-save --slave 2>&1 <
>> /tmp/RtmpGkncGK/file1e541c57190
>> ERROR: loading failed
>>
>>   *** caught segfault ***
>> address (nil), cause 'unknown'
>>
>> Traceback:
>>   1: .Call("spmd_initialize", PACKAGE = "pbdMPI")
>>   2: fun(libname, pkgname)
>>   3: doTryCatch(return(expr), name, parentenv, handler)
>>   4: tryCatchOne(expr, names, parentenv, handlers[[1L]])
>>   5: tryCatchList(expr, classes, parentenv, handlers)
>>   6: tryCatch(fun(libname, pkgname), error = identity)
>>   7: runHook(".onLoad", env, package.lib, package)
>>   8: loadNamespace(package, c(which.lib.loc, lib.loc))
>>   9: doTryCatch(return(expr), name, parentenv, handler)
>> 10: tryCatchOne(expr, names, parentenv, handlers[[1L]])
>> 11: tryCatchList(expr, classes, parentenv, handlers)
>> 12: tryCatch(expr, error = function(e) {    call <- conditionCall(e)
>> if (!is.null(call)) {        if (identical(call[[1L]],
>> quote(doTryCatch)))             call <- sys.call(-4L)        dcall <-
>> deparse(call)[1L]        prefix <- paste("Error in", dcall, ": ")
>> LONG <- 75L        msg <- conditionMessage(e)        sm <- strsplit(msg,
>> "\n")[[1L]]        w <- 14L + nchar(dcall, type = "w") + nchar(sm[1L],
>> type = "w")        if (is.na(w))             w <- 14L + nchar(dcall,
>> type = "b") + nchar(sm[1L],                 type = "b")        if (w >
>> LONG)             prefix <- paste0(prefix, "\n  ")    }    else prefix
>> <- "Error : "    msg <- paste0(prefix, conditionMessage(e), "\n")
>> .Internal(seterrmessage(msg[1L]))    if (!silent &&
>> identical(getOption("show.error.messages"),         TRUE)) {
>> cat(msg, file = stderr())        .Internal(printDeferredWarnings())
>> }    invisible(structure(msg, class = "try-error", condition = e))})
>> 13: try({    ns <- loadNamespace(package, c(which.lib.loc, lib.loc))
>> env <- attachNamespace(ns, pos = pos, deps)})
>> 14: library(pkg_name, lib.loc = lib, character.only = TRUE,
>> logical.return = TRUE)
>> 15: withCallingHandlers(expr, packageStartupMessage = function(c)
>> invokeRestart("muffleMessage"))
>> 16: suppressPackageStartupMessages(library(pkg_name, lib.loc = lib,
>> character.only = TRUE, logical.return = TRUE))
>> 17: doTryCatch(return(expr), name, parentenv, handler)
>> 18: tryCatchOne(expr, names, parentenv, handlers[[1L]])
>> 19: tryCatchList(expr, classes, parentenv, handlers)
>> 20: tryCatch(expr, error = function(e) {    call <- conditionCall(e)
>> if (!is.null(call)) {        if (identical(call[[1L]],
>> quote(doTryCatch)))             call <- sys.call(-4L)        dcall <-
>> deparse(call)[1L]        prefix <- paste("Error in", dcall, ": ")
>> LONG <- 75L        msg <- conditionMessage(e)        sm <- strsplit(msg,
>> "\n")[[1L]]        w <- 14L + nchar(dcall, type = "w") + nchar(sm[1L],
>> type = "w")        if (is.na(w))             w <- 14L + nchar(dcall,
>> type = "b") + nchar(sm[1L],                 type = "b")        if (w >
>> LONG)             prefix <- paste0(prefix, "\n  ")    }    else prefix
>> <- "Error : "    msg <- paste0(prefix, conditionMessage(e), "\n")
>> .Internal(seterrmessage(msg[1L]))    if (!silent &&
>> identical(getOption("show.error.messages"),         TRUE)) {
>> cat(msg, file = stderr())        .Internal(printDeferredWarnings())
>> }    invisible(structure(msg, class = "try-error", condition = e))})
>> 21: try(suppressPackageStartupMessages(library(pkg_name, lib.loc =
>> lib,     character.only = TRUE, logical.return = TRUE)))
>> 22: tools:::.test_load_package("pbdMPI",
>> "/usr/local/R/3.0.0/intel13/lib64/R/library")
>> aborting ...
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From dchristop at econ.uoa.gr  Mon Jun 10 07:14:53 2013
From: dchristop at econ.uoa.gr (dchristop)
Date: Sun, 9 Jun 2013 22:14:53 -0700 (PDT)
Subject: [R] Identifying breakpoints/inflection points?
In-Reply-To: <q2i35fefd7e1004261506g8df50co8302f04380ed57be@mail.gmail.com>
References: <q2i35fefd7e1004261506g8df50co8302f04380ed57be@mail.gmail.com>
Message-ID: <1370841293504-4669117.post@n4.nabble.com>

You can try this: 

library(inflection) 
#you have to instsall package inflection first 
a<-findiplist(cbind(year),cbind(piproute),1) 
a 

The answer: 
     [,1] [,2]   [,3] 
[1,]    5   35 1986.0 
[2,]    5   30 1983.5 

shows that the total inflection point is between 1983 and 1986, if we treat
data as first concave and then convex, as it can be found from a simple
graph.



--
View this message in context: http://r.789695.n4.nabble.com/Identifying-breakpoints-inflection-points-tp2065886p4669117.html
Sent from the R help mailing list archive at Nabble.com.


From abetz58 at gmail.com  Mon Jun 10 08:37:41 2013
From: abetz58 at gmail.com (andreas betz)
Date: Sun, 9 Jun 2013 23:37:41 -0700
Subject: [R] problems with setClass or/and setMethod
Message-ID: <CAMBc2W4ZTOyJxvwkKHREHa4bUjtF=5jMHWskQrAkokyT8eL-5Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130609/0a0c1958/attachment.pl>

From miaojpm at gmail.com  Mon Jun 10 09:02:41 2013
From: miaojpm at gmail.com (jpm miao)
Date: Mon, 10 Jun 2013 15:02:41 +0800
Subject: [R] Create a package with "package.skeleton"
Message-ID: <CABcx46AwMuPeFMjqrS9ngx1F+5ZSBmEc7dTWCp6XxM4ypOF6ww@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130610/deb8fb06/attachment.pl>

From dwinsemius at comcast.net  Mon Jun 10 09:56:30 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 10 Jun 2013 00:56:30 -0700
Subject: [R] problems with setClass or/and setMethod
In-Reply-To: <CAMBc2W4ZTOyJxvwkKHREHa4bUjtF=5jMHWskQrAkokyT8eL-5Q@mail.gmail.com>
References: <CAMBc2W4ZTOyJxvwkKHREHa4bUjtF=5jMHWskQrAkokyT8eL-5Q@mail.gmail.com>
Message-ID: <C2EB9045-9DED-4580-B629-C744DF530B75@comcast.net>


On Jun 9, 2013, at 11:37 PM, andreas betz wrote:

> Hello,
> 
> I am working my way through "A (not so) Short introduction to S4"
> 
> I created a class
> 
> setClass(Class = "Trajectories",
>         representation = representation(times = "numeric",traj = "matrix"))
> 
> and tried to build a method using
> 
> setMethod(
>          f = "plot",
>          signature = "Trajectories",
>          definition = function(X, y, ...){
>            matplot(x at times, t(x at traj), xaxt = "n", type = "l", ylab = "",
> xlab = "", pch = 1)
>            axis(1, at = x at times)
>          }
>        )
> 
> R responds with an error message:
> 
> Creating a generic function for ?plot? from package ?graphics? in the
> global environment
> Error in conformMethod(signature, mnames, fnames, f, fdef, definition) :
>  in method for ?plot? with signature ?x="Trajectories"?: formal arguments
> (x = "Trajectories", y = "Trajectories", ... = "Trajectories") omitted in
> the method definition cannot be in the signature
> 
> Did anything change in the transition to R-3.0?

I doubt it worked in earlier versions. There is a misprint of "X" where there should be an "x". I'm unable to explain why the "y" is along side the "x" in the argument list since the 'definition' function does nothing with it.

> 
> is there any other, more recent introduction to S4 classes recommended?
> 
> Thank you
> 
> for your help.
> 
> Andreas
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ruipbarradas at sapo.pt  Mon Jun 10 10:47:36 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 10 Jun 2013 09:47:36 +0100
Subject: [R] Error Object Not Found
In-Reply-To: <1370815668505-4669100.post@n4.nabble.com>
References: <1370720137364-4669041.post@n4.nabble.com>
	<51B4A15E.9090707@statistik.tu-dortmund.de>
	<1370815668505-4669100.post@n4.nabble.com>
Message-ID: <51B592A8.4060103@sapo.pt>

Hello,

Please quote context.
The message you get means that package foreign is installed on your 
computer, you need to load it in the R session:

library(foreign)

Hope this helps,

Rui Barradas

Em 09-06-2013 23:07, Court escreveu:
> Hi,
>
> I think that they are loaded.  Here is the response that I get:
>
>   package ?foreign? successfully unpacked and MD5 sums checked
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Error-Object-Not-Found-tp4669041p4669100.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rolf.turner at xtra.co.nz  Mon Jun 10 11:20:14 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Mon, 10 Jun 2013 21:20:14 +1200
Subject: [R] How to expand.grid with string elements (the half!)
In-Reply-To: <CADVKSzww6anEaNpfaJSJcjhj6bgqDf-FhXgzMsVqmjTZ4FESaQ@mail.gmail.com>
References: <CADVKSzww6anEaNpfaJSJcjhj6bgqDf-FhXgzMsVqmjTZ4FESaQ@mail.gmail.com>
Message-ID: <51B59A4E.5040609@xtra.co.nz>


Your question makes no sense at all.  The grid expansion
has 9 rows.  In case you hadn't noticed, 9 is an odd number
(i.e. not divisible by 2).  There are no "halves".

Do not expect the list to read your mind.  Instead, ask a
meaningful question.

     cheers,

         Rolf Turner

On 10/06/13 17:25, Gundala Viswanath wrote:
> I have the following result of expand grid:
>
>> d <- expand.grid(c("x","y","z"),c("x","y","z"))
> What I want is to create a combination of strings
> but only the half of the all combinations:
>
>    Var1 Var2
> 1    x    x
> 2    y    x
> 3   y    y
> 4   z    y
> 5   x    z
> 6    z    z
>
>
> What's the way to do it?


From jim at bitwrit.com.au  Mon Jun 10 11:44:39 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 10 Jun 2013 19:44:39 +1000
Subject: [R] Not sure this is something R could do but it feels like it
 should be.
In-Reply-To: <59c4f02b9171b484ec8545ea2b3cc32b@localhost>
References: <20130606150318.57E504483A7@nhs-pd1e-esg101.ad1.nhs.net>	<51B12257.1010602@bitwrit.com.au>
	<59c4f02b9171b484ec8545ea2b3cc32b@localhost>
Message-ID: <51B5A007.4050700@bitwrit.com.au>

On 06/09/2013 11:14 PM, Calum Polwart wrote:
> ...
> What we are trying to do is determine the most appropriate number to
> make the capsules. (Our dosing is more complex but lets stick to
> something simple. I can safely assure you that vritually no-one actually
> needs 250 or 500mg as a dose of amoxicillin... ...thats just a dose to
> get them into a therapeutic window, and I'm 99% certain 250 and 500 are
> used coz they are round numbers. if 337.5 more reliably got everyone in
> the window without kicking anyone out the window that'd be a better dose
> to use! So... what I'm looking to do is model the 'theoretical dose
> required' (which we know) and the dose delivered using several starting
> points to get the 'best fit'. We know they need to be within 7% of each
> other, but if one starting point can get 85% of doses within 5% we think
> that might be better than one that only gets 50% within 5%.
>

Okay, I think I see what you are attempting now. You are stuck with 
fairly large dosage increments (say powers of two) and you want to have 
a "base" value that will be appropriate for the greatest number of 
patients. So, your range of doses can be generated with:

d * 2 ^ (0:m)

where d is some constant and m+1 is the number of doses you want to 
generate. For your amoxcillin, d=250 and m=1, so you get 250 and 500mg. 
Given this relationship (or any other one you can define), you want to 
set your base dose so that it is close to the mode of the patient 
distribution. This means that the greatest number of patients will be 
suitably dosed with your base dose. I would probably try to solve this 
by brute force, setting the base dose at the mode and then moving it up 
and down until the dose was appropriate for the largest number of patients.

However, there are a lot of people on this list who would be more 
familiar with this sort of problem, and there may be a more elegant 
solution.

Jim


From sguallar at yahoo.com  Mon Jun 10 11:49:18 2013
From: sguallar at yahoo.com (Santiago Guallar)
Date: Mon, 10 Jun 2013 02:49:18 -0700 (PDT)
Subject: [R] modify and append new rows to a data.frame using ddply
Message-ID: <1370857758.48902.YahooMailNeo@web160801.mail.bf1.yahoo.com>

Hi,

I have a data.frame that contains a variable act which records the duration (in seconds) of two states (wet-dry) for several individuals (identified by Ring) over a period of time. Since I want to work with daytime (i.e. from sunrise till sunset) and night time (i.e. from sunset till next sunrise), I have to split act from time[i] till sunset and from sunset until time[i+1], and from time[k] till sunrise and from sunrise until time[k+1].

Here is an example with time and act separated by a comma:

[i] 01-01-2000 20:55:00 , 360?
[i+1] 01-01-2000 21:01:00 , 30 # let's say that sunset is at 01-01-2000 21:00:00

[i+2]?01-01-2000 21:01:30 , 30

.
.
.
My goal is to get:
[i]?01-01-2000 20:55:00 , 300 # act is modified

[i+1]?01-01-2000 21:00:00 , 60 # new row with time=sunset

[i+2]?01-01-2000 21:01:00 , 30 # previously row i+1th

[i+3]?01-01-2000 21:01:30 , 30 # previously row i+2th

.
.
.
I attach a dput with a selection of my data.frame. Here is a piece of existing code that I am trying to adapt just for the daytime/night time change:

? require(plyr)

? xandaynight <- ddply( xan, .(Ring), function(df1){
? # index of day/night changes
? ind <- c( FALSE, diff(df$dif) == 1 )
? add <- df1[ind,]
? add$timepos <- add$dusk
? # rearrangement
? df1 <- rbind( df1, add )
? df1 <- df1[order(df1$timepos),]
? # recalculation of act
? df1$act2 <- c( diff( as.numeric(df1$timepos) ), NA )
? df1} )

This code produces an error message:
"Error en diff(df$dif): error in evaluating the argument 'x' in selecting a method for function 'diff': Error en df$dif: object of type 'closure' is not a subset"

Thank you for your help,

Santi

From hertzogg at student.ethz.ch  Mon Jun 10 12:00:28 2013
From: hertzogg at student.ethz.ch (hertzogg)
Date: Mon, 10 Jun 2013 03:00:28 -0700 (PDT)
Subject: [R] Estimation of covariance matrices and mixing parameter by a
 bivariate normal-lognormal model
Message-ID: <1370858428499-4669143.post@n4.nabble.com>

Dear all,
I have to create a model which is a mixture of a normal and log-normal
distribution. To create it, I need to estimate the 2 covariance matrixes and
the mixing parameter (total =7 parameters) by maximizing the log-likelihood
function. This maximization has to be performed by the nlm routine.
As I use relative data, the means are known and equal to 1.
I?ve already tried to do it in 1 dimension (with 1 set of relative data) and
it works well. However, when I introduce the 2nd set of relative data I get
illogical results for the correlation and a lot of warnings messages.
To estimates the parameters I defined first the log-likelihood function with
the 2 commands dmvnorm and dlnorm.plus. Then I assign starting values of the
parameters and finally I use the nlm routine to estimate the parameters (see
script below).
# Importing and reading the grid files. Output are 2048x2048 matrixes

P <- read.ascii.grid("d:/Documents/JOINT_FREQUENCY/grid_E727_P-3000.asc",
return.header= FALSE ); 
V <- read.ascii.grid("d:/Documents/JOINT_FREQUENCY/grid_E727_V-3000.asc",
return.header= FALSE ); 

p <- c(P); # tranform matrix into a vector
v <- c(V);

p<- p[!is.na(p)] # removing NA values
v<- v[!is.na(v)]

p_rel <- p/mean(p) #Transforming the data to relative values
v_rel <- v/mean(v) 
PV <- cbind(p_rel, v_rel) # create a matrix of vectors

L <- function(par,p_rel,v_rel) {

return (-sum(log( (1- par[7])*dmvnorm(PV, mean=c(1,1), sigma=
matrix(c(par[1], par[1]*par[2]*par[3],par[1]*par[2]*par[3], par[2] ),nrow=2,
ncol=2))+
par[7]*dlnorm.rplus(PV, meanlog=c(1,1), varlog=
matrix(c(par[4],par[4]*par[5]*par[6],par[4]*par[5]*par[6],par[5]),
nrow=2,ncol=2))            )))

}
par.start<- c(0.74, 0.66 ,0.40, 1.4, 1.2, 0.4, 0.5) # log-likelihood
estimators
result<-nlm(L,par.start,v_rel=v_rel,p_rel=p_rel, hessian=TRUE, iterlim=200,
check.analyticals= TRUE)
Il y a eu 50 avis ou plus (utilisez warnings() pour voir les 50 premiers)
1: In log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values) :
production de NaN
2: In sqrt(2 * pi * det(varlog)) : production de NaN
3: In nlm(L, par.start, v_rel = v_rel, p_rel = p_rel, hessian = TRUE,  ... : 
NA/Inf replaced by maximum positive value
4: In log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values) :
production de NaN
5: In sqrt(2 * pi * det(varlog)) : production de NaN
6: In nlm(L, par.start, v_rel = v_rel, p_rel = p_rel, hessian = TRUE,  ... : 
NA/Inf replaced by maximum positive value
par.hat <- result$estimate
cat("sigN_p =", par[1],"\n","sigN_v =", par[2],"\n","rhoN =",
par[3],"\n","sigLN_p =", par[4],"\n","sigLN_v =", par[5],"\n","rhoLN =",
par[6],"\n","mixing parameter =", par[7],"\n")
?sigN_p = 0.2919377 
 sigN_v = 0.4445056 
 rhoN = 1.737904 
 sigLN_p = 2.911735 
 sigLN_v = 2.539405 
 rhoLN = 0.3580525 
 mixing parameter = 0.8112917

Does someone know what is wrong in my model or how should I do to find these
parameters in 2 dimensions?
Thank you very much for taking time to look at my questions.
Regards,
Gladys Hertzog




--
View this message in context: http://r.789695.n4.nabble.com/Estimation-of-covariance-matrices-and-mixing-parameter-by-a-bivariate-normal-lognormal-model-tp4669143.html
Sent from the R help mailing list archive at Nabble.com.


From bhh at xs4all.nl  Mon Jun 10 12:07:16 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 10 Jun 2013 12:07:16 +0200
Subject: [R] modify and append new rows to a data.frame using ddply
In-Reply-To: <1370857758.48902.YahooMailNeo@web160801.mail.bf1.yahoo.com>
References: <1370857758.48902.YahooMailNeo@web160801.mail.bf1.yahoo.com>
Message-ID: <229145EB-0205-4888-B33F-231BE3289B0A@xs4all.nl>


On 10-06-2013, at 11:49, Santiago Guallar <sguallar at yahoo.com> wrote:

> Hi,
> 
> I have a data.frame that contains a variable act which records the duration (in seconds) of two states (wet-dry) for several individuals (identified by Ring) over a period of time. Since I want to work with daytime (i.e. from sunrise till sunset) and night time (i.e. from sunset till next sunrise), I have to split act from time[i] till sunset and from sunset until time[i+1], and from time[k] till sunrise and from sunrise until time[k+1].
> 
> Here is an example with time and act separated by a comma:
> 
> [i] 01-01-2000 20:55:00 , 360 
> [i+1] 01-01-2000 21:01:00 , 30 # let's say that sunset is at 01-01-2000 21:00:00
> 
> [i+2] 01-01-2000 21:01:30 , 30
> 
> .
> .
> .
> My goal is to get:
> [i] 01-01-2000 20:55:00 , 300 # act is modified
> 
> [i+1] 01-01-2000 21:00:00 , 60 # new row with time=sunset
> 
> [i+2] 01-01-2000 21:01:00 , 30 # previously row i+1th
> 
> [i+3] 01-01-2000 21:01:30 , 30 # previously row i+2th
> 
> .
> .
> .
> I attach a dput with a selection of my data.frame. Here is a piece of existing code that I am trying to adapt just for the daytime/night time change:
> 
>   require(plyr)
> 
>   xandaynight <- ddply( xan, .(Ring), function(df1){
>   # index of day/night changes
>   ind <- c( FALSE, diff(df$dif) == 1 )
>   add <- df1[ind,]
>   add$timepos <- add$dusk
>   # rearrangement
>   df1 <- rbind( df1, add )
>   df1 <- df1[order(df1$timepos),]
>   # recalculation of act
>   df1$act2 <- c( diff( as.numeric(df1$timepos) ), NA )
>   df1} )
> 
> This code produces an error message:
> "Error en diff(df$dif): error in evaluating the argument 'x' in selecting a method for function 'diff': Error en df$dif: object of type 'closure' is not a subset"
> 

Shouldn't the line

  ind <- c( FALSE, diff(df$dif) == 1 )

read

  ind <- c( FALSE, diff(df1$dif) == 1 )

Berend


From antoine.migeon at u-bourgogne.fr  Mon Jun 10 14:15:37 2013
From: antoine.migeon at u-bourgogne.fr (Antoine Migeon)
Date: Mon, 10 Jun 2013 14:15:37 +0200
Subject: [R] cannot load pbdMPI package after compilation
In-Reply-To: <51B56FE8.50803@stats.ox.ac.uk>
References: <51B1D53C.1090305@u-bourgogne.fr> <51B53732.6050607@ymail.com>
	<51B56FE8.50803@stats.ox.ac.uk>
Message-ID: <51B5C369.90106@u-bourgogne.fr>

Thank you, I will try contact the developper.

Antoine Migeon
Universit? de Bourgogne
Centre de Calcul et Messagerie
Direction des Syst?mes d'Information

tel : 03 80 39 52 70
Site du CCUB : http://www.u-bourgogne.fr/dsi-ccub

Le 10/06/2013 08:19, Prof Brian Ripley a ?crit :
> On 10/06/2013 03:17, Pascal Oettli wrote:
>> Hello,
>>
>> I am not sure whether it helps you, but I was able to install it.
>>
>> OpenSUSE 12.3
>> R version 3.0.1 Patched (2013-06-09 r62918)
>> pbdMPI version 0.1-6
>> gcc version 4.7.2
>> OpenMPI version 1.6.3
>>
>> I didn't try with the most recent version of ompi (1.6.4).
>
> But the system used to accept that version of pdbMPI for CRAN used it,
> with gcc.
>
> The issue here is likely to be using the Intel compiler with OpenMPI.
> This is a programming matter really off-topic for R-help (see the
> posting guide).  The first port of call for help is the package
> maintainer, then if that does not help, the R-devel list.  But very
> few R users have access to an Intel compiler, let alone one as recent
> as that, and you will be expected to use a debugger for yourself (see
> 'Writing R Extensions').
>
>>
>> Regards,
>> Pascal
>>
>>
>> On 07/06/13 21:42, Antoine Migeon wrote:
>>> Hello,
>>>
>>> I try to install pbdMPI.
>>> Compilation successful, but load fails with segfault.
>>>
>>> Is anyone can help me?
>>>
>>> R version 3.0.0
>>> pbdMPI version 0.1-6
>>> Intel compiler version 13.1.1
>>> OpenMPI version 1.6.4-1
>>> CPU Intel x86_64
>>>
>>> # R CMD INSTALL pbdMPI_0.1-6.tar.gz
>>> ..
>>> ....
>>> checking for gcc... icc -std=gnu99
>>> checking whether the C compiler works... yes
>>> checking for C compiler default output file name... a.out
>>> checking for suffix of executables...
>>> checking whether we are cross compiling... no
>>> checking for suffix of object files... o
>>> checking whether we are using the GNU C compiler... yes
>>> checking whether icc -std=gnu99 accepts -g... yes
>>> checking for icc -std=gnu99 option to accept ISO C89... none needed
>>> checking for mpirun... mpirun
>>> checking for mpiexec... mpiexec
>>> checking for orterun... orterun
>>> checking for sed... /bin/sed
>>> checking for mpicc... mpicc
>>> checking for ompi_info... ompi_info
>>> checking for mpich2version... F
>>> found sed, mpicc, and ompi_info ...
>>>>> TMP_INC_DIRS = /opt/openmpi/1.6.4-1/intel-13.1.1/include
>>> checking /opt/openmpi/1.6.4-1/intel-13.1.1/include ...
>>> found /opt/openmpi/1.6.4-1/intel-13.1.1/include/mpi.h ...
>>>>> TMP_LIB_DIRS = /opt/openmpi/1.6.4-1/intel-13.1.1/lib64
>>> checking /opt/openmpi/1.6.4-1/intel-13.1.1/lib64 ...
>>> found /opt/openmpi/1.6.4-1/intel-13.1.1/lib64/libmpi.so ...
>>> found mpi.h and libmpi.so ...
>>>>> TMP_INC = /opt/openmpi/1.6.4-1/intel-13.1.1/include
>>>>> TMP_LIB = /opt/openmpi/1.6.4-1/intel-13.1.1/lib64
>>> checking for openpty in -lutil... yes
>>> checking for main in -lpthread... yes
>>>
>>> ******************* Results of pbdMPI package configure
>>> *****************
>>>
>>>>> TMP_INC = /opt/openmpi/1.6.4-1/intel-13.1.1/include
>>>>> TMP_LIB = /opt/openmpi/1.6.4-1/intel-13.1.1/lib64
>>>>> MPI_ROOT =
>>>>> MPITYPE = OPENMPI
>>>>> MPI_INCLUDE_PATH = /opt/openmpi/1.6.4-1/intel-13.1.1/include
>>>>> MPI_LIBPATH = /opt/openmpi/1.6.4-1/intel-13.1.1/lib64
>>>>> MPI_LIBS =  -lutil -lpthread
>>>>> MPI_DEFS = -DMPI2
>>>>> MPI_INCL2 =
>>>>> PKG_CPPFLAGS = -I/opt/openmpi/1.6.4-1/intel-13.1.1/include  -DMPI2
>>> -DOPENMPI
>>>>> PKG_LIBS = -L/opt/openmpi/1.6.4-1/intel-13.1.1/lib64 -lmpi  -lutil
>>> -lpthread
>>> *************************************************************************
>>>
>>> ..
>>> icc -std=gnu99 -I/usr/local/R/3.0.0/intel13/lib64/R/include -DNDEBUG
>>> -I/opt/openmpi/1.6.4-1/intel-13.1.1/include  -DMPI2 -DOPENMPI -O3
>>> -fp-model precise -pc 64 -axAVX    -fpic  -O3 -fp-model precise  -pc 64
>>> -axAVX  -c comm_errors.c -o comm_errors.o
>>> icc -std=gnu99 -I/usr/local/R/3.0.0/intel13/lib64/R/include -DNDEBUG
>>> -I/opt/openmpi/1.6.4-1/intel-13.1.1/include  -DMPI2 -DOPENMPI -O3
>>> -fp-model precise -pc 64 -axAVX    -fpic  -O3 -fp-model precise  -pc 64
>>> -axAVX  -c comm_sort_double.c -o comm_sort_double.o
>>> .
>>> ..
>>> ....
>>> ** testing if installed package can be loaded
>>> sh: line 1:  2905 Segmentation fault
>>> '/usr/local/R/3.0.0/intel13/lib64/R/bin/R' --no-save --slave 2>&1 <
>>> /tmp/RtmpGkncGK/file1e541c57190
>>> ERROR: loading failed
>>>
>>>   *** caught segfault ***
>>> address (nil), cause 'unknown'
>>>
>>> Traceback:
>>>   1: .Call("spmd_initialize", PACKAGE = "pbdMPI")
>>>   2: fun(libname, pkgname)
>>>   3: doTryCatch(return(expr), name, parentenv, handler)
>>>   4: tryCatchOne(expr, names, parentenv, handlers[[1L]])
>>>   5: tryCatchList(expr, classes, parentenv, handlers)
>>>   6: tryCatch(fun(libname, pkgname), error = identity)
>>>   7: runHook(".onLoad", env, package.lib, package)
>>>   8: loadNamespace(package, c(which.lib.loc, lib.loc))
>>>   9: doTryCatch(return(expr), name, parentenv, handler)
>>> 10: tryCatchOne(expr, names, parentenv, handlers[[1L]])
>>> 11: tryCatchList(expr, classes, parentenv, handlers)
>>> 12: tryCatch(expr, error = function(e) {    call <- conditionCall(e)
>>> if (!is.null(call)) {        if (identical(call[[1L]],
>>> quote(doTryCatch)))             call <- sys.call(-4L)        dcall <-
>>> deparse(call)[1L]        prefix <- paste("Error in", dcall, ": ")
>>> LONG <- 75L        msg <- conditionMessage(e)        sm <-
>>> strsplit(msg,
>>> "\n")[[1L]]        w <- 14L + nchar(dcall, type = "w") + nchar(sm[1L],
>>> type = "w")        if (is.na(w))             w <- 14L + nchar(dcall,
>>> type = "b") + nchar(sm[1L],                 type = "b")        if (w >
>>> LONG)             prefix <- paste0(prefix, "\n  ")    }    else prefix
>>> <- "Error : "    msg <- paste0(prefix, conditionMessage(e), "\n")
>>> .Internal(seterrmessage(msg[1L]))    if (!silent &&
>>> identical(getOption("show.error.messages"),         TRUE)) {
>>> cat(msg, file = stderr())        .Internal(printDeferredWarnings())
>>> }    invisible(structure(msg, class = "try-error", condition = e))})
>>> 13: try({    ns <- loadNamespace(package, c(which.lib.loc, lib.loc))
>>> env <- attachNamespace(ns, pos = pos, deps)})
>>> 14: library(pkg_name, lib.loc = lib, character.only = TRUE,
>>> logical.return = TRUE)
>>> 15: withCallingHandlers(expr, packageStartupMessage = function(c)
>>> invokeRestart("muffleMessage"))
>>> 16: suppressPackageStartupMessages(library(pkg_name, lib.loc = lib,
>>> character.only = TRUE, logical.return = TRUE))
>>> 17: doTryCatch(return(expr), name, parentenv, handler)
>>> 18: tryCatchOne(expr, names, parentenv, handlers[[1L]])
>>> 19: tryCatchList(expr, classes, parentenv, handlers)
>>> 20: tryCatch(expr, error = function(e) {    call <- conditionCall(e)
>>> if (!is.null(call)) {        if (identical(call[[1L]],
>>> quote(doTryCatch)))             call <- sys.call(-4L)        dcall <-
>>> deparse(call)[1L]        prefix <- paste("Error in", dcall, ": ")
>>> LONG <- 75L        msg <- conditionMessage(e)        sm <-
>>> strsplit(msg,
>>> "\n")[[1L]]        w <- 14L + nchar(dcall, type = "w") + nchar(sm[1L],
>>> type = "w")        if (is.na(w))             w <- 14L + nchar(dcall,
>>> type = "b") + nchar(sm[1L],                 type = "b")        if (w >
>>> LONG)             prefix <- paste0(prefix, "\n  ")    }    else prefix
>>> <- "Error : "    msg <- paste0(prefix, conditionMessage(e), "\n")
>>> .Internal(seterrmessage(msg[1L]))    if (!silent &&
>>> identical(getOption("show.error.messages"),         TRUE)) {
>>> cat(msg, file = stderr())        .Internal(printDeferredWarnings())
>>> }    invisible(structure(msg, class = "try-error", condition = e))})
>>> 21: try(suppressPackageStartupMessages(library(pkg_name, lib.loc =
>>> lib,     character.only = TRUE, logical.return = TRUE)))
>>> 22: tools:::.test_load_package("pbdMPI",
>>> "/usr/local/R/3.0.0/intel13/lib64/R/library")
>>> aborting ...
>>>
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From maechler at stat.math.ethz.ch  Mon Jun 10 15:12:39 2013
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 10 Jun 2013 15:12:39 +0200
Subject: [R] agnes() in package cluster on R 2.14.1 and R 3.0.1
In-Reply-To: <CABpMX0t+MJsb4mxj67iE3Q7QnNF_XuuKaPOR24AgN=r=iWnPpw@mail.gmail.com>
References: <CABpMX0t+MJsb4mxj67iE3Q7QnNF_XuuKaPOR24AgN=r=iWnPpw@mail.gmail.com>
Message-ID: <20917.53447.986054.159726@stat.math.ethz.ch>

>>>>> Hugo Varet <varethugo at gmail.com>
>>>>>     on Sun, 9 Jun 2013 11:43:32 +0200 writes:

    > Dear R users,
    > I discovered something strange using the function agnes() of the cluster
    > package on R 3.0.1 and on R 2.14.1. Indeed, the clusterings obtained are
    > different whereas I ran exactly the same code.

hard to believe... but ..

    > I quickly looked at the source code of the function and I discovered that
    > there was an important change: agnes() in R 2.14.1 used a FORTRAN code
    > whereas agnes() in R 3.0.1 uses a C code.

well, it does so quite a bit longer, e.g., also in R 2.15.0

    > Here is one of the contingency table between R 2.14.1 and R 3.0.1:
    > classe.agnTani.2.14.1
    > classe.agnTani.3.0.1      1        2       3
    > 1    74       0    229
    > 2     0    235        0
    > 3  120       0      15

    > So, I was wondering if it was normal that the C and FORTRAN codes give
    > different results?

It's not normal, and I'm pretty sure I have had many many
examples which gave identical results.

Can you provide a reproducible example, please?
If the example is too large [for dput() ], please send me the *.rda
file produced from 
     save(<your data>, file=<the file I neeed>)
*and* a the exact call to agnes() for your data.

Thank you in advance!

Martin Maechler,
the one you could have e-mailed directly 
to using   maintainer("cluster") ...


    > Best regards,
    > Hugo Varet

    > [[alternative HTML version deleted]]
 ^^^^^^^^^^^^^ try to avoid, please ^^^^^^^^^^^^^^^^^

    > ______________________________________________
    > R-help at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
yes indeed, please.


From jvadams at usgs.gov  Mon Jun 10 15:23:47 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 10 Jun 2013 08:23:47 -0500
Subject: [R] reshaping a data frame
In-Reply-To: <CAJbA1KCmxcGktKQ8Pm6ssChTwA2Gq873k1pb_=TEFhQOtXtT7g@mail.gmail.com>
References: <CAJbA1KCmxcGktKQ8Pm6ssChTwA2Gq873k1pb_=TEFhQOtXtT7g@mail.gmail.com>
Message-ID: <CAN5YmCEVJvCeHd5+Qg7ZqzrkaYAC-7FT-GOZ2JprrJiR5KrsNQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130610/705ddc9f/attachment.pl>

From jrkrideau at inbox.com  Mon Jun 10 15:47:50 2013
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 10 Jun 2013 05:47:50 -0800
Subject: [R] reshaping a data frame
In-Reply-To: <CAJbA1KCmxcGktKQ8Pm6ssChTwA2Gq873k1pb_=TEFhQOtXtT7g@mail.gmail.com>
Message-ID: <3B52DCB6FAB.00000395jrkrideau@inbox.com>

Unless I completely misunderstand what you are doing you don't need to aggregate, just drop the one column and rename things

newtemp  <-  temp_df[, c(1,3)]
names(newtemp) <-  c("names", "w")
newtemp


John Kane
Kingston ON Canada


> -----Original Message-----
> From: abhishek.vit at gmail.com
> Sent: Sun, 9 Jun 2013 23:15:48 -0700
> To: r-help at r-project.org
> Subject: [R] reshaping a data frame
> 
> Hi Guys
> 
> I am trying to cast a data frame but not aggregate the rows for the
> same variable.
> 
> here is a contrived example.
> 
> **input**
> temp_df  <-
> data.frame(names=c('foo','foo','foo'),variable=c('w','w','w'),value=c(34,65,12))
>> temp_df
>   names variable value
> 1   foo        w    34
> 2   foo        w    65
> 3   foo        w    12
> 
> 
> ###########
> **Want this**
> ############
> names  w
> foo         34
> foo         65
> foo         12
> 
> 
> ##
> **getting this***
> ##
>> cast(temp_df)
> Aggregation requires fun.aggregate: length used as default
>   names w
> 1   foo 3
> 
> 
> In real dataset  the categorical column 'variable' will have many more
> categorical variable.
> 
> Thanks!
> -Abhi
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From jrkrideau at inbox.com  Mon Jun 10 16:05:48 2013
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 10 Jun 2013 06:05:48 -0800
Subject: [R] All against all correlation matrix with GGPLOT Facet
In-Reply-To: <CADVKSzxVUdxSvmhmLcePbdsH2gin2ATzOVDOfMxFzkj8B6eMVg@mail.gmail.com>
Message-ID: <3B7B03D1854.000003F5jrkrideau@inbox.com>

No image.  The R-help list tends to strip out a lot of files. A pdf or txt usually gets through.  In any case I understand what you want this may do it.

library(ggplot2)
dat1  <-  data.frame( v = rnorm(13),
w = rnorm(13),
x = rnorm(13),
y = rnorm(13),
z = rnorm(13))
plotmatrix(dat1)

John Kane
Kingston ON Canada


> -----Original Message-----
> From: gundalav at gmail.com
> Sent: Mon, 10 Jun 2013 12:26:44 +0900
> To: r-help at stat.math.ethz.ch
> Subject: [R] All against all correlation matrix with GGPLOT Facet
> 
> I have the following data:
> 
> v <- rnorm(13)
> w <- rnorm(13)
> x <- rnorm(13)
> y <- rnorm(13)
> z <- rnorm(13)
> 
> 
> Using GGPLOT facet, what I want to do is to create a 5*5 matrix,
> where each cells plot the correlation between
> each pair of the above data. E.g. v-v,v-w; v-x,...,z-z
> 
> 
> What's the way to do it?
> Attached is the image.
> 
> GV.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From smartpink111 at yahoo.com  Mon Jun 10 16:13:04 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 10 Jun 2013 07:13:04 -0700 (PDT)
Subject: [R] reshaping a data frame
In-Reply-To: <CAJbA1KCmxcGktKQ8Pm6ssChTwA2Gq873k1pb_=TEFhQOtXtT7g@mail.gmail.com>
References: <CAJbA1KCmxcGktKQ8Pm6ssChTwA2Gq873k1pb_=TEFhQOtXtT7g@mail.gmail.com>
Message-ID: <1370873584.94980.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,If your dataset is similar to the one below:
set.seed(24)
temp1_df<- data.frame(names=rep(c('foo','foo1'),each=6),variable=rep(c('w','x'),times=6),value=sample(25:40,12,replace=TRUE),stringsAsFactors=FALSE)

library(reshape2)
?res<-dcast(within(temp1_df,{Seq1<-ave(value,names,variable,FUN=seq_along)}),names+Seq1~variable,value.var="value")[,-2]
res
#? names? w? x
#1?? foo 29 28
#2?? foo 36 33
#3?? foo 35 39
#4? foo1 29 37
#5? foo1 37 29
#6? foo1 34 30
A.K.


----- Original Message -----
From: Abhishek Pratap <abhishek.vit at gmail.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Monday, June 10, 2013 2:15 AM
Subject: [R] reshaping a data frame

Hi Guys

I am trying to cast a data frame but not aggregate the rows for the
same variable.

here is a contrived example.

**input**
temp_df? <- data.frame(names=c('foo','foo','foo'),variable=c('w','w','w'),value=c(34,65,12))
> temp_df
? names variable value
1?  foo? ? ? ? w? ? 34
2?  foo? ? ? ? w? ? 65
3?  foo? ? ? ? w? ? 12


###########
**Want this**
############
names? w
foo? ? ? ?  34
foo? ? ? ?  65
foo? ? ? ?  12


##
**getting this***
##
> cast(temp_df)
Aggregation requires fun.aggregate: length used as default
? names w
1?  foo 3


In real dataset? the categorical column 'variable' will have many more
categorical variable.

Thanks!
-Abhi

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Mon Jun 10 16:39:26 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 10 Jun 2013 07:39:26 -0700 (PDT)
Subject: [R] please check this
In-Reply-To: <104083AE5AAA634C993249DFCCE4C2030643B8D9@CIPRESTE.ua.pt>
References: <104083AE5AAA634C993249DFCCE4C2030643B8C5@CIPRESTE.ua.pt>,
	<1370873546.26699.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<104083AE5AAA634C993249DFCCE4C2030643B8D9@CIPRESTE.ua.pt>
Message-ID: <1370875166.90268.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Try this:
which(duplicated(res10Percent))
# [1] 117 125 157 189 213 235 267 275 278 293 301 327 331 335 339 367 369 371 379
#[20] 413 415 417 441 459 461 477 479 505
res10PercentSub1<-subset(res10Percent[which(duplicated(res10Percent)),],dummy==1)? #most of the duplicated are dummy==1
res10PercentSub0<-subset(res10Percent[which(duplicated(res10Percent)),],dummy==0)
?indx1<-as.numeric(row.names(res10PercentSub1))
indx11<-sort(c(indx1,indx1+1))
indx0<- as.numeric(row.names(res10PercentSub0))
?indx00<- sort(c(indx0,indx0-1))
indx10<- sort(c(indx11,indx00))

?nrow(res10Percent[-indx10,])
#[1] 452
?res10PercentNew<-res10Percent[-indx10,]
?nrow(subset(res10PercentNew,dummy==1))
#[1] 226
?nrow(subset(res10PercentNew,dummy==0))
#[1] 226
?nrow(unique(res10PercentNew))
#[1] 452
A.K.



----- Original Message -----
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Cc: 
Sent: Monday, June 10, 2013 10:19 AM
Subject: RE: please check this

But I don't want it like this. 
Once a firm is paired with another, these two firms should not be paired again.
Could you solve this?
Thanks,
Cec?lia


________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: segunda-feira, 10 de Junho de 2013 15:12
Para: Cecilia Carmo
Assunto: Re: please check this

I did look into that.
If you look for the nrow() in each category, then it will be different.? It means that the duplicates are not pairwise, but in the whole `result`.? The explanation is again with the multiple matches.? So, here we selected the one with dummy==0 that closely matches the dimension of one dummy==1.? Suppose, the value of dimension with dummy==1` is `2554` and it got a match with dummy==0 with `2580`.? Now, consider another case with dimension as `2570` with dummy==1 (which also comes within the same split group).? Then it got a match with `2580' with dummy==0.? I guess it was based on the way in which it was tested.






________________________________
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Sent: Monday, June 10, 2013 10:02 AM
Subject: please check this




When I do

res10Percent<- fun1(final3New,0.1,200)
dim(res10Percent)
[1] 508?  5
#[1] 508?  5
nrow(subset(res10Percent,dummy==0))
#[1] 254
nrow(subset(res10Percent,dummy==1))
#[1] 254


testingDuplicates<-unique(res10Percent)
nrow(testingDuplicates)
[1] 480 #this should be 508, if not there are duplicated rows, or not?


Thanks
Cecilia


From pauljohn32 at gmail.com  Mon Jun 10 17:09:48 2013
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Mon, 10 Jun 2013 10:09:48 -0500
Subject: [R] recode: how to avoid nested ifelse
In-Reply-To: <20130608191755.GZ1685@neal-SP35>
References: <CAErODj8Tr6KBNweyFy2kXYmqn-CEs=cDJJT0bwoaRc0Jxd-CMw@mail.gmail.com>
	<CANz9Z_LuJjikRcwyi2JF5byL9fbRPZ=kxD7Rq4q2GwX=ZCwMNQ@mail.gmail.com>
	<20130608022553.GY1685@neal-SP35>
	<CANz9Z_J=x6NQHuhmkDxj=jV+K6u_8ZcwfZuBvEw5TfXV3NoUmQ@mail.gmail.com>
	<20130608191755.GZ1685@neal-SP35>
Message-ID: <CAErODj84ASAkq64=eB-T3rWw2XL3QKD35+Cn4F09nUfuXZSrmA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130610/58f4e091/attachment.pl>

From macqueen1 at llnl.gov  Mon Jun 10 17:16:44 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 10 Jun 2013 15:16:44 +0000
Subject: [R] How to expand.grid with string elements (the half!)
In-Reply-To: <CADVKSzww6anEaNpfaJSJcjhj6bgqDf-FhXgzMsVqmjTZ4FESaQ@mail.gmail.com>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A52191447617@PRDEXMBX-08.the-lab.llnl.gov>

If you can explain why those particular six combinations out of the
complete set of nine, then perhaps someone can tell you how.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/9/13 10:25 PM, "Gundala Viswanath" <gundalav at gmail.com> wrote:

>I have the following result of expand grid:
>
>> d <- expand.grid(c("x","y","z"),c("x","y","z"))
>
>What I want is to create a combination of strings
>but only the half of the all combinations:
>
>  Var1 Var2
>1    x    x
>2    y    x
>3   y    y
>4   z    y
>5   x    z
>6    z    z
>
>
>What's the way to do it?
>
>G.V.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From diddle1990 at fastwebnet.it  Mon Jun 10 16:26:54 2013
From: diddle1990 at fastwebnet.it (diddle1990 at fastwebnet.it)
Date: Mon, 10 Jun 2013 16:26:54 +0200 (CEST)
Subject: [R] Substituting the values on the y-axis
Message-ID: <13995809.12181370874414136.JavaMail.defaultUser@defaultHost>

Hello, 

I plotted a graph on R showing how salinity (in ?, y-axis) changes with time(in 
years, x-axis). However, right from the beginning on the Excel spreadsheet the v
alues for salinity appeared as, for example, 35000? instead of 35?, which I gues
sed must have been a typing error for the website from which I extracted the dat
a (NOAA).Thus, I now would like to substitute these values with the correspondin
g smaller value, as it follows: 

25000 35000-> 25, 35   and so on.

Is there any way I can change this on R or do I have to modify these numbers bef
ore inputting the data on R (for example on Excel)? If so, can anybody tell me h
ow to do either of these? 

Many thanks! 

Emanuela 


From bastian.wimmer at fau.de  Mon Jun 10 11:26:53 2013
From: bastian.wimmer at fau.de (Bastian Wimmer)
Date: Mon, 10 Jun 2013 11:26:53 +0200
Subject: [R] Rcmdr seit heute nicht mehr ladbar
Message-ID: <etPan.51b59bdd.74b0dc51.1083@MacBook-Pro.local>

Wenn man ihn mal braucht ist er tot. folgende Fehlermeldung ereilt mich seit heute beim starten des R Commander auf dem Mac:

> library(Rcmdr)
Lade n?tiges Paket: car
Lade n?tiges Paket: MASS
Lade n?tiges Paket: nnet
Error : .onAttach in attachNamespace() f?r 'Rcmdr' fehlgeschlagen, Details:
? Aufruf: structure(.External(.C_dotTclObjv, objv), class = "tclObj")
? Fehler: [tcl] invalid command name "image".

Zus?tzlich: Warnmeldung:
In fun(libname, pkgname) :
? couldn't connect to display "/tmp/launch-K8nELf/org.macosforge.xquartz:0"
Fehler: Laden von Paket oder Namensraum f?r 'Rcmdr' fehlgeschlagen

Ich bin ziemlich angefressen. Folgende erfolglose Versuche:
- R neu installiert
- x11 neu installiert
- alle Ordner dabei gel?scht
- Pakete neu installiert
Nichts. Rcmdr will nicht mehr.?


--  
Beste Gr??e,
Yours,
Bastian Wimmer M.A.

Research Associate at the Chair of Educational?Psychology
University of Erlangen-Nuremberg
Dutzendteichstra?e 24
90478 Nuremberg
Germany

Phone: +49 (0) 9171 83924 84
Fax: +49 (0) 3222 64968 14
Email: bastian.wimmer at fau.de
Web: http://j.mp/Umkf4U (Chair of?educational Psychology)


From vlatka.m at gmail.com  Mon Jun 10 17:10:50 2013
From: vlatka.m at gmail.com (Vlatka Matkovic Puljic)
Date: Mon, 10 Jun 2013 17:10:50 +0200
Subject: [R] twoby2 (Odds Ratio) for variables with 3 or more levels
Message-ID: <CANeAhkbmMp32rCeJjRtgo2e-Kqcq=7fZRSA3-d04MTHCRCmReA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130610/573206a9/attachment.pl>

From gunter.berton at gene.com  Mon Jun 10 17:48:41 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 10 Jun 2013 08:48:41 -0700
Subject: [R] Substituting the values on the y-axis
In-Reply-To: <13995809.12181370874414136.JavaMail.defaultUser@defaultHost>
References: <13995809.12181370874414136.JavaMail.defaultUser@defaultHost>
Message-ID: <CACk-te01GjMUtN+1DEZq3hEDQnG1mjHK9Cba+JE2Eb_nTyiNPw@mail.gmail.com>

Sounds like you have made no effort to learn R, e.g. by reading the
Intro to R tutorial packaged with R or other online tutorial (there
are many).

Don't you think you need to do some homework first?

-- Bert

On Mon, Jun 10, 2013 at 7:26 AM,  <diddle1990 at fastwebnet.it> wrote:
> Hello,
>
> I plotted a graph on R showing how salinity (in ?, y-axis) changes with time(in
> years, x-axis). However, right from the beginning on the Excel spreadsheet the v
> alues for salinity appeared as, for example, 35000? instead of 35?, which I gues
> sed must have been a typing error for the website from which I extracted the dat
> a (NOAA).Thus, I now would like to substitute these values with the correspondin
> g smaller value, as it follows:
>
> 25000 35000-> 25, 35   and so on.
>
> Is there any way I can change this on R or do I have to modify these numbers bef
> ore inputting the data on R (for example on Excel)? If so, can anybody tell me h
> ow to do either of these?
>
> Many thanks!
>
> Emanuela
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From jrkrideau at inbox.com  Mon Jun 10 17:52:53 2013
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 10 Jun 2013 07:52:53 -0800
Subject: [R] Substituting the values on the y-axis
In-Reply-To: <13995809.12181370874414136.JavaMail.defaultUser@defaultHost>
Message-ID: <3C6A5F1FA32.0000058Ajrkrideau@inbox.com>


Just calculate a new sequence if those percentages are in an orderly sequence. See ?seq
 v  <-  seq(25, 200, by = 10)
or perhaps the values are actually  text
?substr
x  <-  substr(v, 1,2)

John Kane
Kingston ON Canada


> -----Original Message-----
> From: diddle1990 at fastwebnet.it
> Sent: Mon, 10 Jun 2013 16:26:54 +0200 (CEST)
> To: r-help at r-project.org
> Subject: [R] Substituting the values on the y-axis
> 
> Hello,
> 
> I plotted a graph on R showing how salinity (in ?, y-axis) changes with
> time(in
> years, x-axis). However, right from the beginning on the Excel
> spreadsheet the v
> alues for salinity appeared as, for example, 35000? instead of 35?, which
> I gues
> sed must have been a typing error for the website from which I extracted
> the dat
> a (NOAA).Thus, I now would like to substitute these values with the
> correspondin
> g smaller value, as it follows:
> 
> 25000 35000-> 25, 35   and so on.
> 
> Is there any way I can change this on R or do I have to modify these
> numbers bef
> ore inputting the data on R (for example on Excel)? If so, can anybody
> tell me h
> ow to do either of these?
> 
> Many thanks!
> 
> Emanuela
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From diddle1990 at fastwebnet.it  Mon Jun 10 18:08:59 2013
From: diddle1990 at fastwebnet.it (Emanuela)
Date: Mon, 10 Jun 2013 09:08:59 -0700 (PDT)
Subject: [R] Substituting the values on the y-axis
In-Reply-To: <13995809.12181370874414136.JavaMail.defaultUser@defaultHost>
References: <13995809.12181370874414136.JavaMail.defaultUser@defaultHost>
Message-ID: <1370880539508-4669171.post@n4.nabble.com>

I did look into tutorials but I could not find the exact request I am looking
for. I just started using R so I am still a beginner.  If you then know
where I can find it, can you please redirect me to it 




--
View this message in context: http://r.789695.n4.nabble.com/Substituting-the-values-on-the-y-axis-tp4669165p4669171.html
Sent from the R help mailing list archive at Nabble.com.


From jfox at mcmaster.ca  Mon Jun 10 18:15:47 2013
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 10 Jun 2013 12:15:47 -0400
Subject: [R] Rcmdr seit heute nicht mehr ladbar
In-Reply-To: <etPan.51b59bdd.74b0dc51.1083@MacBook-Pro.local>
References: <etPan.51b59bdd.74b0dc51.1083@MacBook-Pro.local>
Message-ID: <001301ce65f5$c4f50d30$4edf2790$@mcmaster.ca>

Dear Bastian,

I'm afraid that I don't read German, but (as near as I can tell) since you say that you're using the most recent version of R and have X11 installed, you should have the software you need. Just in case, you might check the Rcmdr installation notes for Mac users at <http://socserv.socsci.mcmaster.ca/jfox/Misc/Rcmdr/installation-notes.html>. Apparently, R is having difficulty connecting to X11. I'm copying this response to Rob Goedman, who has often been able to help with Rcmdr issues under Mac OS X.

Best,
 John

-----------------------------------------------
John Fox
Senator McMaster Professor of Social Statistics
Department of Sociology
McMaster University
Hamilton, Ontario, Canada




> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Bastian Wimmer
> Sent: Monday, June 10, 2013 5:27 AM
> To: r-help at r-project.org
> Subject: [R] Rcmdr seit heute nicht mehr ladbar
> 
> Wenn man ihn mal braucht ist er tot. folgende Fehlermeldung ereilt mich
> seit heute beim starten des R Commander auf dem Mac:
> 
> > library(Rcmdr)
> Lade n?tiges Paket: car
> Lade n?tiges Paket: MASS
> Lade n?tiges Paket: nnet
> Error : .onAttach in attachNamespace() f?r 'Rcmdr' fehlgeschlagen,
> Details:
>   Aufruf: structure(.External(.C_dotTclObjv, objv), class = "tclObj")
>   Fehler: [tcl] invalid command name "image".
> 
> Zus?tzlich: Warnmeldung:
> In fun(libname, pkgname) :
>   couldn't connect to display "/tmp/launch-
> K8nELf/org.macosforge.xquartz:0"
> Fehler: Laden von Paket oder Namensraum f?r 'Rcmdr' fehlgeschlagen
> 
> Ich bin ziemlich angefressen. Folgende erfolglose Versuche:
> - R neu installiert
> - x11 neu installiert
> - alle Ordner dabei gel?scht
> - Pakete neu installiert
> Nichts. Rcmdr will nicht mehr.
> 
> 
> --
> Beste Gr??e,
> Yours,
> Bastian Wimmer M.A.
> 
> Research Associate at the Chair of Educational Psychology
> University of Erlangen-Nuremberg
> Dutzendteichstra?e 24
> 90478 Nuremberg
> Germany
> 
> Phone: +49 (0) 9171 83924 84
> Fax: +49 (0) 3222 64968 14
> Email: bastian.wimmer at fau.de
> Web: http://j.mp/Umkf4U (Chair of educational Psychology)
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From vlatka.m at gmail.com  Mon Jun 10 18:27:41 2013
From: vlatka.m at gmail.com (Vlatka Matkovic Puljic)
Date: Mon, 10 Jun 2013 18:27:41 +0200
Subject: [R] woby2 (Odds Ratio) for variables with 3 or more levels
Message-ID: <CANeAhkYvNju_1eCBmWg5Ss89p4BgiPvX6-Yd4C1vktKFa8Vqyg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130610/4d12a7bf/attachment.pl>

From jrkrideau at inbox.com  Mon Jun 10 18:51:40 2013
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 10 Jun 2013 08:51:40 -0800
Subject: [R] Substituting the values on the y-axis
In-Reply-To: <1370880539508-4669171.post@n4.nabble.com>
References: <13995809.12181370874414136.javamail.defaultuser@defaulthost>
Message-ID: <3CEDBED34DF.0000065Ajrkrideau@inbox.com>

Hi Emanuela,

Welcome to R

It can be hard finding even relatively simple things when you are just starting.  You might want to have a look at 
http://www.unt.edu/rss/class/Jon/R_SC/ or http://www.burns-stat.com/documents/tutorials/impatient-r/ if ou have not already seen them.  Patrick Burn's site http://www.introductoryr.co.uk/R_Resources_for_Beginners.html has some useful links 

If you are a refugee from SAS or SPSS, this paper by Bob Muenchen is very useful www.et.bs.ehu.es/~etptupaf/pub/R/RforSAS&SPSSusers.pdf

Some tricks for asking a good question in the R help list is here:
https://github.com/hadley/devtools/wiki/Reproducibility or  http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

In most cases it is very useful to provide some data. See ?dput in the last two links. A small bit of sample data in your original post would definately have helped.

Many or most R-help readers do not use nabble and really hate to have to go there to see the context of a message.  You should always leave the important parts of earlier messages to let the R-help reader see what the problems and other suggested solutions may be.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: diddle1990 at fastwebnet.it
> Sent: Mon, 10 Jun 2013 09:08:59 -0700 (PDT)
> To: r-help at r-project.org
> Subject: Re: [R] Substituting the values on the y-axis
> 
> I did look into tutorials but I could not find the exact request I am
> looking
> for. I just started using R so I am still a beginner.  If you then know
> where I can find it, can you please redirect me to it
> 
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Substituting-the-values-on-the-y-axis-tp4669165p4669171.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From wdunlap at tibco.com  Mon Jun 10 18:55:55 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 10 Jun 2013 16:55:55 +0000
Subject: [R] How to expand.grid with string elements (the half!)
In-Reply-To: <51B59A4E.5040609@xtra.co.nz>
References: <CADVKSzww6anEaNpfaJSJcjhj6bgqDf-FhXgzMsVqmjTZ4FESaQ@mail.gmail.com>
	<51B59A4E.5040609@xtra.co.nz>
Message-ID: <E66794E69CFDE04D9A70842786030B931C301024@PA-MBX01.na.tibco.com>

Perhaps the OP wants the unique combinations of V1 and V2, as in
  R> d <- expand.grid(V1=c("x","y","z"),V2=c("x","y","z"))
  R> d[ as.numeric(d$V1) <= as.numeric(d$V2), ]
    V1 V2
  1  x  x
  4  x  y
  5  y  y
  7  x  z
  8  y  z
  9  z  z
or
  R> V <- letters[24:26]
  R> rbind(t(combn(V,m=2)), cbind(V,V))
       V   V  
  [1,] "x" "y"
  [2,] "x" "z"
  [3,] "y" "z"
  [4,] "x" "x"
  [5,] "y" "y"
  [6,] "z" "z"

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Rolf Turner
> Sent: Monday, June 10, 2013 2:20 AM
> To: Gundala Viswanath
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] How to expand.grid with string elements (the half!)
> 
> 
> Your question makes no sense at all.  The grid expansion
> has 9 rows.  In case you hadn't noticed, 9 is an odd number
> (i.e. not divisible by 2).  There are no "halves".
> 
> Do not expect the list to read your mind.  Instead, ask a
> meaningful question.
> 
>      cheers,
> 
>          Rolf Turner
> 
> On 10/06/13 17:25, Gundala Viswanath wrote:
> > I have the following result of expand grid:
> >
> >> d <- expand.grid(c("x","y","z"),c("x","y","z"))
> > What I want is to create a combination of strings
> > but only the half of the all combinations:
> >
> >    Var1 Var2
> > 1    x    x
> > 2    y    x
> > 3   y    y
> > 4   z    y
> > 5   x    z
> > 6    z    z
> >
> >
> > What's the way to do it?
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bsmith030465 at gmail.com  Mon Jun 10 19:33:46 2013
From: bsmith030465 at gmail.com (Brian Smith)
Date: Mon, 10 Jun 2013 13:33:46 -0400
Subject: [R] Selecting divergent colors
Message-ID: <CAEQKoCGvRL+CBC3uMmCeMosTHDZkriuNt6Jsw4Wu8F4PSk0gyg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130610/383c2cd4/attachment.pl>

From ivo.welch at gmail.com  Mon Jun 10 19:53:59 2013
From: ivo.welch at gmail.com (ivo welch)
Date: Mon, 10 Jun 2013 10:53:59 -0700
Subject: [R] read.csv timing
Message-ID: <CAPr7RtX14_kQvyLcOU4+N1wb6TEzyeF_ROXjwGpP8gTJWzarPg@mail.gmail.com>

here are some small benchmarks on an i7-2600k with an SSD:

input file: 104,126 rows with 76 columns.  all numeric.

linux> time bzcat bzfile.csv.bz2 > /dev/null  --> 1.8 seconds

R> d <- read.csv( pipe( bzfile ) )   --> 6.3 seconds
R> d <- read.csv( pipe( bzfile ), colClasses="numeric")  --> 4.2 seconds

R more than doubles the time it takes to load the file to convert it
into an R data structure.  if the colClasses are not specified, then
it takes another 50% longer.


some more experiments: save in R format (gzip format) --- this
increases file size from 15MB to 20MB.  how fast is the filesystem?

linux> time gzcat file.Rdata > /dev/null  --> 0.4 seconds


the linux file system and CPU can decompress the 15MB .bz2 file in 1.8
seconds and decompress the 20MB .gz file in 0.4 seconds.  this is
surprising.  let's make sure that this is due to the .gz format.
indeed:

linux> bunzip bzfile.csv.bz2 ; gzip bzfile.csv
linux> time gzcat bzfile.csv.gz > /dev/null  --> 0.4 seconds


reading .gz files is much faster on my linux system than reading bz
files.  this surprises me.  I would have thought my CPU is so fast at
decompressing even bzip2 that it is almost zero, so I thought the disk
space was the primary determinant of speed, and bzip2 should have been
faster.  well, ok, maybe slower, but not by a factor of 4.


now I am thinking that maybe I should use .gz files to store my data.
but the advantages are surprisingly not as great:

R> d <- read.csv( pipe( gzfile ) )   --> 5.7 seconds
R> d <- read.csv( pipe( gzfile ), colClasses="numeric")  --> 2.6 seconds
R> d <- read.csv( gzfile( gzfile ), colClasses="numeric") --> 4.5
seconds   (surprisingly slower)

(the first and second versions are using R's gzfile, but literally
"gzcat .. |" in a pipe here.)


conclusion: a .gz file can be read from file to memory about four
times faster than a .bz file by the linux file system (outside R).
the conversion from strings in memory nto R doubles takes about as
much time as the .bz file system decompression read.  bzip2 is a more
efficient storage method than .gz, but its decompression is
considerably slower (the fact that there is less to read from disk
does not make up for the CPU decompression overhead).

saving the data in native R format essentially has no decompression
penalty and becomes close to native fast reading of .gz data.  chances
are this is because it has .gz support baked in.  gzfile does not help
with read.csv, however.

/iaw
----
Ivo Welch (ivo.welch at gmail.com)


On Mon, Jun 10, 2013 at 10:09 AM, ivo welch <ivo.welch at gmail.com> wrote:
>> Surely you know the types of the columns?  If you specify it in advance,
>> read.table and relatives will be much faster.
>>
>> Duncan Murdoch
>
> thx, duncan.  yes, I do know the types of columns, but I did not
> realize how much faster these functions become.  on my SSD-based
> system, the speedup is about a factor of 2.  that is, read.csv on a
> bzip2 file that takes 10 seconds without colClasses takes 5 seconds
> with colClasses.  I don't know how to benchmark intermittent memory
> usage, but my guess is that with colClasses, it requires less memory,
> too.  in fact, my naive and incorrect assumption had been that
> read.csv would just read ithe file nto a dynamic string array and then
> convert each string, and this would not take much longer than if it
> converted as it went along.  so, I had thought "more memory use but
> not more time."  wrong.
>
> I would add to the man (.Rd) page the sentence "Specifying colClasses
> can speed up read.csv" where it describes the option.)
>
>
> once I will figure out how to bake C into R, I may try to write a fast
> filter function for myself, but share it for others wanting to use it.
>
> regards,
>
> /iaw


From dwinsemius at comcast.net  Mon Jun 10 19:58:26 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 10 Jun 2013 10:58:26 -0700
Subject: [R] woby2 (Odds Ratio) for variables with 3 or more levels
In-Reply-To: <CANeAhkYvNju_1eCBmWg5Ss89p4BgiPvX6-Yd4C1vktKFa8Vqyg@mail.gmail.com>
References: <CANeAhkYvNju_1eCBmWg5Ss89p4BgiPvX6-Yd4C1vktKFa8Vqyg@mail.gmail.com>
Message-ID: <D9B0B394-3D3E-4958-9330-09EA35C81D0F@comcast.net>


On Jun 10, 2013, at 9:27 AM, Vlatka Matkovic Puljic wrote:

> Dear all,
> 
> I am using Epi package to calculate Odds ratio in my bivariate analysis.
> How can I make *twoby2 *in variables that have 3 or more levels.

I hope looking at that again you will see how odd it sounds to be requesting advice about how to use a program for 2 x 2 tables on data that doesn't meet those requirements. If you want to stay within the Epi package world, you can probably use the 'mh' function since it says it can handle multi-way tables (or you can learn to use 'glm' in the regular stats package to do either logistic regression or Poisson regression.)
> 
> For example:
> I have 4 level var (Age)
> m=matrix(c(290, 100,232, 201, 136, 99, 182, 240), nrow=4, ncol=2)
> library (Epi)
> twoby2(m)
> 
> R gives me only
> Comparing : Row 1 vs. Row 2
> 
> While I would like to have reference value in Row 1, and compare Row 2, Row
> 3 and Row 4 with it.

That is the default set of contrasts for 'glm' (and probably for 'mh' although it's not clear from the help page.)

(Epi does have its own mailing list.)

-- 
David Winsemius
Alameda, CA, USA


From sneha.bishnoi at gmail.com  Mon Jun 10 20:47:12 2013
From: sneha.bishnoi at gmail.com (Sneha Bishnoi)
Date: Mon, 10 Jun 2013 14:47:12 -0400
Subject: [R] Where Query in SQL
Message-ID: <CAOsJHwC4=aCD1Co8csmO30e12=p3OLC67qcbmHUnoNd4p8hu2w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130610/dcf53198/attachment.pl>

From james.whanger at gmail.com  Mon Jun 10 21:30:58 2013
From: james.whanger at gmail.com (James C. Whanger)
Date: Mon, 10 Jun 2013 15:30:58 -0400
Subject: [R] woby2 (Odds Ratio) for variables with 3 or more levels
In-Reply-To: <CANeAhkYvNju_1eCBmWg5Ss89p4BgiPvX6-Yd4C1vktKFa8Vqyg@mail.gmail.com>
References: <CANeAhkYvNju_1eCBmWg5Ss89p4BgiPvX6-Yd4C1vktKFa8Vqyg@mail.gmail.com>
Message-ID: <CAGG=QuGvHJyCdWE3=prfyV2DiTTF1Lkp=h3EY008hL3T5rW2iw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130610/57bf4ae3/attachment.pl>

From macqueen1 at llnl.gov  Mon Jun 10 21:35:04 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 10 Jun 2013 19:35:04 +0000
Subject: [R] Where Query in SQL
In-Reply-To: <CAOsJHwC4=aCD1Co8csmO30e12=p3OLC67qcbmHUnoNd4p8hu2w@mail.gmail.com>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A5219144836E@PRDEXMBX-08.the-lab.llnl.gov>

Do this

cat(sql.select,'\n')

and then decide whether the query is what it should be according to
standard SQL syntax.
(If it is not, then fix it.)

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/10/13 11:47 AM, "Sneha Bishnoi" <sneha.bishnoi at gmail.com> wrote:

>Hey all
>
>I am trying to use where in clause in sql query in R
>here is my code:
>
>sql.select<-paste("select PERSON_NAME from UNITS where UNIT_ID in
>('",cathree,"')",sep="")
>
>where cathree is 1 variable with 16 observations as follows
>
>UNIT_ID
>1 205
>2 209
>3 213
>4 217
>5 228
>6 232
>7 236
>8 240
>9 245
>10 249
>11 253
>12 257
>13 268
>14 272
>15 276
>16 280
>
>but when i run this code, 0 rows are selected eventhough there exist 3
>rows
>which satisfy the above query
>
>
>Thanks
>Sneha
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jvadams at usgs.gov  Mon Jun 10 21:46:55 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 10 Jun 2013 14:46:55 -0500
Subject: [R] Selecting divergent colors
In-Reply-To: <CAEQKoCGvRL+CBC3uMmCeMosTHDZkriuNt6Jsw4Wu8F4PSk0gyg@mail.gmail.com>
References: <CAEQKoCGvRL+CBC3uMmCeMosTHDZkriuNt6Jsw4Wu8F4PSk0gyg@mail.gmail.com>
Message-ID: <CAN5YmCE_TaxFUy4uQr9pZqBmUg=dcnmBRzpx=e+HBF_e9C1yrQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130610/6bbeceed/attachment.pl>

From abhishek.vit at gmail.com  Mon Jun 10 21:54:07 2013
From: abhishek.vit at gmail.com (Abhishek Pratap)
Date: Mon, 10 Jun 2013 12:54:07 -0700
Subject: [R] reshaping a data frame
In-Reply-To: <CAJbA1KBjbA73PTzEO=exeDpDde1OJoyn+3DUdR0Wkf5F0LYLJQ@mail.gmail.com>
References: <CAJbA1KCmxcGktKQ8Pm6ssChTwA2Gq873k1pb_=TEFhQOtXtT7g@mail.gmail.com>
	<1370873584.94980.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CAJbA1KBjbA73PTzEO=exeDpDde1OJoyn+3DUdR0Wkf5F0LYLJQ@mail.gmail.com>
Message-ID: <CAJbA1KBiT7NhJByE7G5PzzOu_3N_GREgLR=-nq96bf8Qd__N-A@mail.gmail.com>

Thanks everyone for your quick reply. I think my contrived example hid
the complexity I wanted to show by using only one variable.

@Arun: I think your example is exactly what I was looking for. Very
cool trick with 'ave' and 'seq_along'...just dint occur to me.

Best,
-Abh

>
> On Mon, Jun 10, 2013 at 7:13 AM, arun <smartpink111 at yahoo.com> wrote:
>> Hi,If your dataset is similar to the one below:
>> set.seed(24)
>> temp1_df<- data.frame(names=rep(c('foo','foo1'),each=6),variable=rep(c('w','x'),times=6),value=sample(25:40,12,replace=TRUE),stringsAsFactors=FALSE)
>>
>> library(reshape2)
>>  res<-dcast(within(temp1_df,{Seq1<-ave(value,names,variable,FUN=seq_along)}),names+Seq1~variable,value.var="value")[,-2]
>> res
>> #  names  w  x
>> #1   foo 29 28
>> #2   foo 36 33
>> #3   foo 35 39
>> #4  foo1 29 37
>> #5  foo1 37 29
>> #6  foo1 34 30
>> A.K.
>>
>>
>> ----- Original Message -----
>> From: Abhishek Pratap <abhishek.vit at gmail.com>
>> To: "r-help at r-project.org" <r-help at r-project.org>
>> Cc:
>> Sent: Monday, June 10, 2013 2:15 AM
>> Subject: [R] reshaping a data frame
>>
>> Hi Guys
>>
>> I am trying to cast a data frame but not aggregate the rows for the
>> same variable.
>>
>> here is a contrived example.
>>
>> **input**
>> temp_df  <- data.frame(names=c('foo','foo','foo'),variable=c('w','w','w'),value=c(34,65,12))
>>> temp_df
>>   names variable value
>> 1   foo        w    34
>> 2   foo        w    65
>> 3   foo        w    12
>>
>>
>> ###########
>> **Want this**
>> ############
>> names  w
>> foo         34
>> foo         65
>> foo         12
>>
>>
>> ##
>> **getting this***
>> ##
>>> cast(temp_df)
>> Aggregation requires fun.aggregate: length used as default
>>   names w
>> 1   foo 3
>>
>>
>> In real dataset  the categorical column 'variable' will have many more
>> categorical variable.
>>
>> Thanks!
>> -Abhi
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From hertzogg at student.ethz.ch  Mon Jun 10 22:01:03 2013
From: hertzogg at student.ethz.ch (Hertzog  Gladys)
Date: Mon, 10 Jun 2013 20:01:03 +0000
Subject: [R] parameters estimation of a normal-lognormal multivariate model
Message-ID: <E71E7032F00FCA4AA40DC7943D3DB10E24D1038F@MBX22.d.ethz.ch>

Dear all,

I have to create a model which is a mixture of a normal and log-normal distribution. To create it, I need to estimate the 2 covariance matrixes and the mixing parameter (total =7 parameters) by maximizing the log-likelihood function. This maximization has to be performed by the nlm routine.
As I use relative data, the means are known and equal to 1.

I?ve already tried to do it in 1 dimension (with 1 set of relative data) and it works well. However, when I introduce the 2nd set of relative data I get illogical results for the correlation and a lot of warnings messages (at all 25).

To estimates the parameters I defined first the log-likelihood function with the 2 commands dmvnorm and dlnorm.plus. Then I assign starting values of the parameters and finally I use the nlm routine to estimate the parameters (see script below).

# Importing and reading the grid files. Output are 2048x2048 matrixes
 
P <- read.ascii.grid("d:/Documents/JOINT_FREQUENCY/grid_E727_P-3000.asc", return.header= FALSE ); 
V <- read.ascii.grid("d:/Documents/JOINT_FREQUENCY/grid_E727_V-3000.asc", return.header= FALSE ); 
 
p <- c(P); # tranform matrix into a vector
v <- c(V);
 
p<- p[!is.na(p)] # removing NA values
v<- v[!is.na(v)]
 
p_rel <- p/mean(p) #Transforming the data to relative values
v_rel <- v/mean(v) 
PV <- cbind(p_rel, v_rel) # create a matrix of vectors
 
L <- function(par,p_rel,v_rel) {
 
return (-sum(log( (1- par[7])*dmvnorm(PV, mean=c(1,1), sigma= matrix(c(par[1]^2, par[1]*par[2]*par[3],par[1]*par[2]*par[3], par[2]^2 ),nrow=2, ncol=2))+
par[7]*dlnorm.rplus(PV, meanlog=c(1,1), varlog= matrix(c(par[4]^2,par[4]*par[5]*par[6],par[4]*par[5]*par[6],par[5]^2), nrow=2,ncol=2))            )))
 
}
par.start<- c(0.74, 0.66 ,0.40, 1.4, 1.2, 0.4, 0.5) # log-likelihood estimators
 
result<-nlm(L,par.start,v_rel=v_rel,p_rel=p_rel, hessian=TRUE, iterlim=200, check.analyticals= TRUE)
Messages d'avis :
1: In log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values) :
  production de NaN
2: In sqrt(2 * pi * det(varlog)) : production de NaN
3: In nlm(L, par.start, p_rel = p_rel, v_rel = v_rel, hessian = TRUE) :
  NA/Inf replaced by maximum positive value
4: In log(eigen(sigma, symmetric = TRUE, only.values = TRUE)$values) :
  production de NaN
?. Until 25.

par.hat <- result$estimate
 
cat("sigN_p =", par[1],"\n","sigN_v =", par[2],"\n","rhoN =", par[3],"\n","sigLN_p =", par[4],"\n","sigLN_v =", par[5],"\n","rhoLN =", par[6],"\n","mixing parameter =", par[7],"\n")
 
sigN_p = 0.5403361 
 sigN_v = 0.6667375 
 rhoN = 0.6260181 
 sigLN_p = 1.705626 
 sigLN_v = 1.592832 
 rhoLN = 0.9735974 
 mixing parameter = 0.8113369
 
Does someone know what is wrong in my model or how should I do to find these parameters in 2 dimensions?

Thank you very much for taking time to look at my questions.

Regards,

Gladys Hertzog
Master student in environmental engineering, ETH Zurich

From btupper at bigelow.org  Mon Jun 10 22:07:40 2013
From: btupper at bigelow.org (Ben Tupper)
Date: Mon, 10 Jun 2013 16:07:40 -0400
Subject: [R] Selecting divergent colors
In-Reply-To: <CAN5YmCE_TaxFUy4uQr9pZqBmUg=dcnmBRzpx=e+HBF_e9C1yrQ@mail.gmail.com>
References: <CAEQKoCGvRL+CBC3uMmCeMosTHDZkriuNt6Jsw4Wu8F4PSk0gyg@mail.gmail.com>
	<CAN5YmCE_TaxFUy4uQr9pZqBmUg=dcnmBRzpx=e+HBF_e9C1yrQ@mail.gmail.com>
Message-ID: <5A1C1EF7-733D-4346-9761-401BE00ECC01@bigelow.org>

Hi,

On Jun 10, 2013, at 3:46 PM, Adams, Jean wrote:

> It will be hard to come up with 20 clearly distinguishable colors.  Check
> out the website http://colorbrewer2.org/ and the R package RColorBrewer.
> It does not have a 20-color palette, but it does have some 8- to 12-color
> palettes that are very nice.
> 
> library(RColorBrewer)
> display.brewer.all(n=NULL, type="all", select=NULL, exact.n=TRUE)
> 

It sounds like Brian is looking for categorical coloring rather than divergent coloring.  The Glasbey LUT works really well in image processing for just such purposes.  It would be easy to use that within R for your lines.

http://www.bioss.ac.uk/people/chris/colorpaper.pdf

You might be able to snag the color table out of this collection of Java plugins for ImageJ software. 

http://www.dentistry.bham.ac.uk/landinig/software/morphology.zip

Within that archive is a text file called glasbey.lut which is a simple text file of RGB color values.

Cheers,
Ben




> You could use these colors in combination with line type to build up to 72
> unique combinations.  For example ...
> 
> nuniq <- ncol(mat)
> mycols <- rep(brewer.pal(12, "Set3"), length=nuniq)
> myltys <- rep(1:6, rep(12, 6))[1:nuniq]
> 
> for(k in 1:nuniq){
> plot(density(mat[,k]), col=mycols[k], xlab='', ylab='', axes=F, main=F,
> lwd=3, lty=myltys[k])
> par(new=TRUE)
> }
> legend('topright', legend=snames, col=mycols, lty=myltys, lwd=3)
> 
> Jean
> 
> 
> 
> On Mon, Jun 10, 2013 at 12:33 PM, Brian Smith <bsmith030465 at gmail.com>wrote:
> 
>> Hi,
>> 
>> I was trying to make a density plot with 13 samples. To distinguish each
>> sample, it would be good if each color is as different as possible from the
>> other colors. I could use the built in function, but that does not do more
>> than 8 colors and then goes back to recycling the cols. If I use a palette,
>> then it is really difficult to distinguish between the colors.
>> 
>> So, is there a way that I can select a large number of colors (i.e. perhaps
>> 20) that are as different from each other as possible?
>> 
>> Here is my example code using the palette:
>> 
>> **********************
>> mat <- matrix(sample(1:1000,1000,replace=T),nrow=20,ncol=20)
>> snames <- paste('Sample_',1:ncol(mat),sep='')
>> colnames(mat) <- snames
>> 
>> mycols <- palette(rainbow(ncol(mat)))
>> 
>> for(k in 1:ncol(mat)){
>>  plot(density(mat[,k]),col=mycols[k],xlab='',ylab='',axes=F,main=F)
>>  par(new=T)
>> }
>> 
>> legend(x='topright',legend=snames,fill=mycols)
>> 
>> ****************************
>> 
>> thanks!
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From bogaso.christofer at gmail.com  Mon Jun 10 22:34:14 2013
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Tue, 11 Jun 2013 02:19:14 +0545
Subject: [R] Fwd: Problem with ODBC connection
In-Reply-To: <CA+dpOJnm7HXJPg-ReXb9SDKc3q7MeUqLtg+N0znbAhn0PhO9gw@mail.gmail.com>
References: <CA+dpOJ=gLQyZmniVkrd+gKzjThe_y+dJ5fGBeGw1q6fm_rXCyQ@mail.gmail.com>
	<CA+dpOJnm7HXJPg-ReXb9SDKc3q7MeUqLtg+N0znbAhn0PhO9gw@mail.gmail.com>
Message-ID: <CA+dpOJ=5LGqPiKU1gisL7DDxmNhS_1fmH-7A5x5_6ZPx8M-4nA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130611/5960f498/attachment.pl>

From delanceyevan at gmail.com  Mon Jun 10 19:23:41 2013
From: delanceyevan at gmail.com (edelance)
Date: Mon, 10 Jun 2013 10:23:41 -0700 (PDT)
Subject: [R] Apply a PCA to other datasets
Message-ID: <1370885021395-4669182.post@n4.nabble.com>

I have run a PCA on one data set.  I need the standard deviation of the first
two bands for my analysis.  I now want to apply the same PCA rotation I used
in the first one to all my other data sets.  Is there any way to do this in
r?  Thanks.




--
View this message in context: http://r.789695.n4.nabble.com/Apply-a-PCA-to-other-datasets-tp4669182.html
Sent from the R help mailing list archive at Nabble.com.


From trevordaviswalker at gmail.com  Mon Jun 10 19:28:24 2013
From: trevordaviswalker at gmail.com (Trevor Walker)
Date: Mon, 10 Jun 2013 13:28:24 -0400
Subject: [R] Speed up or alternative to 'For' loop
Message-ID: <CAMDVrE3jbQochoPGOoc8zcDTPRO5AEhY1nZpHVBzz6JWNMPanA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130610/a1c40578/attachment.pl>

From estigarr at email.unc.edu  Mon Jun 10 21:37:09 2013
From: estigarr at email.unc.edu (Estigarribia, Bruno)
Date: Mon, 10 Jun 2013 19:37:09 +0000
Subject: [R] How sum all possible combinations of rows, given 4 matrices
In-Reply-To: <1369677240.28598.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <CDDBA265.74B2%estigarr@email.unc.edu>

It works, Arun. Thanks!
(FYI, a couple a the matrices I am dealing with have 1000+ rows, so I had
to do in on a supercomputer at work. For the curious, I am trying to find
all possible scores in a model f language mixing described in:
Title: Structured Variation in Codeswitching: Towards an Empirically Based
Typology of Bilingual Speech Patterns
Authors: Deuchar, Margaret; Muysken, Pieter; Wang, Sung-Lan
Publication Date: 2007
Journal Name: International Journal of Bilingual Education and
Bilingualism)


Bruno Estigarribia
Assistant Professor of Spanish, Department of Romance Languages and
Literatures
Research Assistant Professor of Psychology, Cognitive Science Program
Affiliate Faculty, Global Studies
Dey Hall, Room 332, CB# 3170
University of North Carolina at Chapel Hill
estigarr at email.unc.edu
917-348-8162





On 5/27/13 1:54 PM, "arun" <smartpink111 at yahoo.com> wrote:

>Hi,
>Not sure if this is what you expected:
>
>set.seed(24)
>mat1<- matrix(sample(1:20,3*4,replace=TRUE),ncol=3)
>set.seed(28)
>mat2<- matrix(sample(1:25,3*6,replace=TRUE),ncol=3)
>set.seed(30)
>mat3<- matrix(sample(1:35,3*8,replace=TRUE),ncol=3)
>set.seed(35)
>mat4<- matrix(sample(1:40,3*10,replace=TRUE),ncol=3)
> 
>dat1<-expand.grid(seq(dim(mat1)[1]),seq(dim(mat2)[1]),seq(dim(mat3)[1]),se
>q(dim(mat4)[1]))
>vec1<-paste0("mat",1:4)
>matNew<-do.call(cbind,lapply(seq_len(ncol(dat1)),function(i)
>get(vec1[i])[dat1[,i],]))
>colnames(matNew)<- (seq(12)-1)%%3+1
>datNew<-data.frame(matNew)
>res<-sapply(split(colnames(datNew),gsub("\\..*","",colnames(datNew))),func
>tion(x) rowSums(datNew[,x]))
>
>dim(res)
>#[1] 1920    3
> head(res)
>#     X1 X2 X3
>#[1,] 46 63 70
>#[2,] 45 68 59
>#[3,] 55 55 66
>#[4,] 51 65 61
>#[5,] 48 84 75
>#[6,] 47 89 64
>
>A.K.
>
>----- Original Message -----
>From: "Estigarribia, Bruno" <estigarr at email.unc.edu>
>To: "r-help at R-project.org" <r-help at r-project.org>
>Cc: 
>Sent: Monday, May 27, 2013 11:24 AM
>Subject: [R] How sum all possible combinations of rows, given 4 matrices
>
>Hello all,
>
>I have 4 matrices with 3 columns each (different number of rows though). I
>want to find a function that returns all possible 3-place vectors
>corresponding to the sum by columns of picking one row from matrix 1, one
>from matrix 2, one from matrix 3, and one from matrix 4. So basically, all
>possible ways of picking one row from each matrix and then sum their
>columns to obtain a 3-place vector.
>Is there a way to use expand.grid and reduce to obtain this result? Or am
>I on the wrong track?
>Thank you,
>Bruno
>PS:I believe I have given all relevant info. I apologize in advance if my
>question is ill-posed or ambiguous.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


From rawal.shreya at gmail.com  Mon Jun 10 22:38:13 2013
From: rawal.shreya at gmail.com (Shreya Rawal)
Date: Mon, 10 Jun 2013 16:38:13 -0400
Subject: [R] Combining CSV data
Message-ID: <CALFKK3xTtutDvi12LpSp4M6hyn0bFR1-Z+7aWMTA6AT8xWG5mA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130610/996bfce2/attachment.pl>

From smartpink111 at yahoo.com  Mon Jun 10 23:05:38 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 10 Jun 2013 14:05:38 -0700 (PDT)
Subject: [R] please check this
In-Reply-To: <104083AE5AAA634C993249DFCCE4C2030643B92F@CIPRESTE.ua.pt>
References: <104083AE5AAA634C993249DFCCE4C2030643B8C5@CIPRESTE.ua.pt>,
	<1370873546.26699.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<104083AE5AAA634C993249DFCCE4C2030643B8D9@CIPRESTE.ua.pt>,
	<1370875166.90268.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<104083AE5AAA634C993249DFCCE4C2030643B8F6@CIPRESTE.ua.pt>,
	<1370884459.21972.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<104083AE5AAA634C993249DFCCE4C2030643B92F@CIPRESTE.ua.pt>
Message-ID: <1370898338.4657.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Try this:
res10Percent<- fun1(final3New,0.1,200)

res10PercentSub1<-subset(res10Percent[duplicated(res10Percent)|duplicated(res10Percent,fromLast=TRUE),],dummy==1)
indx1<-as.numeric(row.names(res10PercentSub1))

res10PercentSub2<-res10PercentSub1[order(res10PercentSub1$dimension),]
indx11<-as.numeric(row.names(res10PercentSub2))
names(indx11)<-(seq_along(indx11)-1)%/%2+1
res10PercentSub3<-res10Percent[c(indx11,indx11+1),]
res10PercentSub3$id<- names(c(indx11,indx11+1))
?res10PercentSub4<-do.call(rbind,lapply(split(res10PercentSub3,res10PercentSub3$id),function(x) {x1<-x[-1,];x2<-x1[which.max(abs(x1$dimension[1]-x1$dimension[-1]))+1,];x3<-x[x$dummy==1,][which.min(abs(as.numeric(row.names(x[x$dummy==1,]))-as.numeric(row.names(x2)))),];rbind(x3,x2)}))
################################################
res10PercentSub0<-subset(res10Percent[duplicated(res10Percent)|duplicated(res10Percent,fromLast=TRUE),],dummy==0)
indx0<-as.numeric(row.names(res10PercentSub0))

res10PercentSub20<-res10PercentSub0[order(res10PercentSub0$dimension),]
indx00<-as.numeric(row.names(res10PercentSub20))
names(indx00)<-(seq_along(indx00)-1)%/%2+1
res10PercentSub30<- res10Percent[c(indx00-1,indx00),]
res10PercentSub30$id<- names(c(indx00-1,indx00))
res10PercentSub40<- do.call(rbind,lapply(split(res10PercentSub30,res10PercentSub30$id),function(x){x1<-subset(x,dummy==1); x2<-subset(x,dummy==0);x3<-x1[which.max(abs(x1$dimension-unique(x2$dimension))),];x4<-x2[which.min(abs(as.numeric(row.names(x3))-as.numeric(row.names(x2)))),];rbind(x3,x4)}))

row.names(res10PercentSub40)<-gsub(".*\\.","",row.names(res10PercentSub40))
indxNew<- sort(as.numeric(c(row.names(res10PercentSub5),row.names(res10PercentSub40))))
res10PercentFinal<-res10Percent[-indxNew,]
?dim(res10PercentFinal)
#[1] 454?? 5
?nrow(subset(res10PercentFinal,dummy==0))
#[1] 227
?nrow(subset(res10PercentFinal,dummy==1))
#[1] 227

nrow(unique(res10PercentFinal))
#[1] 454
which(duplicated(res10Percent)|duplicated(res10Percent,fromLast=TRUE))
# [1] 113 117 123 125 153 157 187 189 207 213 223 235 265 267 269 275 276 278 279
#[20] 283 293 301 303 305 309 317 327 331 335 339 341 343 347 351 367 369 371 379
#[39] 385 399 407 413 415 417 429 437 441 453 459 461 471 473 477 479 501 505
?res10Percent[c(113:114,117:118),]
#???????? firm year industry dummy dimension
#113 500221723 2005?????? 26???? 1????? 3147
#114 500601429 2005?????? 26???? 0????? 3076
#117 500221723 2005?????? 26???? 1????? 3147
#118 502668920 2005?????? 26???? 0????? 3249
?
res10PercentFinal[c(113:114,117:118),]? #deleted the duplicated row and the accompanying pair with the maximum difference
#???????? firm year industry dummy dimension
#113 500221723 2005?????? 26???? 1????? 3147
#114 500601429 2005?????? 26???? 0????? 3076
#119 500115362 2006?????? 26???? 1????? 6239
#120 500060223 2006?????? 26???? 0????? 6208

A.K.

row.names(res10PercentSub4)<-gsub(".*\\.","",row.names(res10PercentSub4))
res10PercentSub5<-res10PercentSub4[order(as.numeric(res10PercentSub4$id)),]

----- Original Message -----
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Cc: 
Sent: Monday, June 10, 2013 1:41 PM
Subject: RE: please check this

I think it could be better to eliminate that one.
If you could do it I appreciate.

Cec?lia

________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: segunda-feira, 10 de Junho de 2013 18:14
Para: Cecilia Carmo
Assunto: Re: please check this

If you wanted to eliminate the duplicate rows that have the pair with the maximum difference, it is possible.
Just informing you.




----- Original Message -----
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Cc:
Sent: Monday, June 10, 2013 10:51 AM
Subject: RE: please check this

I think it is ok now.

Thanks
Cec?lia

________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: segunda-feira, 10 de Junho de 2013 15:39
Para: Cecilia Carmo
Cc: R help
Assunto: Re: please check this

Hi,
Try this:
which(duplicated(res10Percent))
# [1] 117 125 157 189 213 235 267 275 278 293 301 327 331 335 339 367 369 371 379
#[20] 413 415 417 441 459 461 477 479 505
res10PercentSub1<-subset(res10Percent[which(duplicated(res10Percent)),],dummy==1)? #most of the duplicated are dummy==1
res10PercentSub0<-subset(res10Percent[which(duplicated(res10Percent)),],dummy==0)
indx1<-as.numeric(row.names(res10PercentSub1))
indx11<-sort(c(indx1,indx1+1))
indx0<- as.numeric(row.names(res10PercentSub0))
indx00<- sort(c(indx0,indx0-1))
indx10<- sort(c(indx11,indx00))

nrow(res10Percent[-indx10,])
#[1] 452
res10PercentNew<-res10Percent[-indx10,]
nrow(subset(res10PercentNew,dummy==1))
#[1] 226
nrow(subset(res10PercentNew,dummy==0))
#[1] 226
nrow(unique(res10PercentNew))
#[1] 452
A.K.



----- Original Message -----
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Cc:
Sent: Monday, June 10, 2013 10:19 AM
Subject: RE: please check this

But I don't want it like this.
Once a firm is paired with another, these two firms should not be paired again.
Could you solve this?
Thanks,
Cec?lia


________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: segunda-feira, 10 de Junho de 2013 15:12
Para: Cecilia Carmo
Assunto: Re: please check this

I did look into that.
If you look for the nrow() in each category, then it will be different.? It means that the duplicates are not pairwise, but in the whole `result`.? The explanation is again with the multiple matches.? So, here we selected the one with dummy==0 that closely matches the dimension of one dummy==1.? Suppose, the value of dimension with dummy==1` is `2554` and it got a match with dummy==0 with `2580`.? Now, consider another case with dimension as `2570` with dummy==1 (which also comes within the same split group).? Then it got a match with `2580' with dummy==0.? I guess it was based on the way in which it was tested.






________________________________
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Sent: Monday, June 10, 2013 10:02 AM
Subject: please check this




When I do

res10Percent<- fun1(final3New,0.1,200)
dim(res10Percent)
[1] 508?  5
#[1] 508?  5
nrow(subset(res10Percent,dummy==0))
#[1] 254
nrow(subset(res10Percent,dummy==1))
#[1] 254


testingDuplicates<-unique(res10Percent)
nrow(testingDuplicates)
[1] 480 #this should be 508, if not there are duplicated rows, or not?


Thanks
Cecilia


From ruipbarradas at sapo.pt  Mon Jun 10 23:24:17 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 10 Jun 2013 22:24:17 +0100
Subject: [R] Speed up or alternative to 'For' loop
In-Reply-To: <CAMDVrE3jbQochoPGOoc8zcDTPRO5AEhY1nZpHVBzz6JWNMPanA@mail.gmail.com>
References: <CAMDVrE3jbQochoPGOoc8zcDTPRO5AEhY1nZpHVBzz6JWNMPanA@mail.gmail.com>
Message-ID: <51B64401.30804@sapo.pt>

Hello,

One way to speed it up is to use a matrix instead of a data.frame. Since 
data.frames can hold data of all classes, the access to their elements 
is slow. And your data is all numeric so it can be hold in a matrix. The 
second way below gave me a speed up by a factor of 50.


system.time({
for (i in 2:nrow(df))
  {if(df$TreeID[i]==df$TreeID[i-1])
   {df$HeightGrowth[i] <- df$Height[i]-df$Height[i-1]
   }
  }
})

system.time({
df2 <- data.matrix(df)
for(i in seq_len(nrow(df2))[-1]){
	if(df2[i, "TreeID"] == df2[i - 1, "TreeID"])
		df2[i, "HeightGrowth"] <- df2[i, "Height"] - df2[i - 1, "Height"]
}
})

all.equal(df, as.data.frame(df2))  # TRUE


Hope this helps,

Rui Barradas

Em 10-06-2013 18:28, Trevor Walker escreveu:
> I have a For loop that is quite slow and am wondering if there is a faster
> option:
>
> df <- data.frame(TreeID=rep(1:500,each=20), Age=rep(seq(1,20,1),500))
> df$Height <- exp(-0.1 + 0.2*df$Age)
> df$HeightGrowth <- NA   #intialize with NA
> for (i in 2:nrow(df))
>   {if(df$TreeID[i]==df$TreeID[i-1])
>    {df$HeightGrowth[i] <- df$Height[i]-df$Height[i-1]
>    }
>   }
>
> Trevor Walker
> Email: trevordaviswalker at gmail.com
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jholtman at gmail.com  Mon Jun 10 23:46:28 2013
From: jholtman at gmail.com (jim holtman)
Date: Mon, 10 Jun 2013 17:46:28 -0400
Subject: [R] Combining CSV data
In-Reply-To: <CALFKK3xTtutDvi12LpSp4M6hyn0bFR1-Z+7aWMTA6AT8xWG5mA@mail.gmail.com>
References: <CALFKK3xTtutDvi12LpSp4M6hyn0bFR1-Z+7aWMTA6AT8xWG5mA@mail.gmail.com>
Message-ID: <CAAxdm-5nYsPrF67VLDRnHDLc7zfDV4h=ozsWO3tP_WKVQ-SxOA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130610/fadcd92b/attachment.pl>

From macqueen1 at llnl.gov  Mon Jun 10 23:51:04 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 10 Jun 2013 21:51:04 +0000
Subject: [R] Speed up or alternative to 'For' loop
In-Reply-To: <CAMDVrE3jbQochoPGOoc8zcDTPRO5AEhY1nZpHVBzz6JWNMPanA@mail.gmail.com>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A52191448A36@PRDEXMBX-08.the-lab.llnl.gov>

How about

for (ir in unique(df$TreeID)) {
  in.ir <- df$TreeID == ir
  df$HeightGrowth[in.ir] <- cumsum(df$Height[in.ir])
}

Seemed fast enough to me.

In R, it is generally good to look for ways to operate on entire vectors
or arrays, rather than element by element within them. The cumsum()
function does that in this example.

-Don


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/10/13 10:28 AM, "Trevor Walker" <trevordaviswalker at gmail.com> wrote:

>I have a For loop that is quite slow and am wondering if there is a faster
>option:
>
>df <- data.frame(TreeID=rep(1:500,each=20), Age=rep(seq(1,20,1),500))
>df$Height <- exp(-0.1 + 0.2*df$Age)
>df$HeightGrowth <- NA   #intialize with NA
>for (i in 2:nrow(df))
> {if(df$TreeID[i]==df$TreeID[i-1])
>  {df$HeightGrowth[i] <- df$Height[i]-df$Height[i-1]
>  }
> }
>
>Trevor Walker
>Email: trevordaviswalker at gmail.com
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Tue Jun 11 00:08:09 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 10 Jun 2013 15:08:09 -0700 (PDT)
Subject: [R] please check this
In-Reply-To: <104083AE5AAA634C993249DFCCE4C2030643B953@CIPRESTE.ua.pt>
References: <104083AE5AAA634C993249DFCCE4C2030643B8C5@CIPRESTE.ua.pt>,
	<1370873546.26699.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<104083AE5AAA634C993249DFCCE4C2030643B8D9@CIPRESTE.ua.pt>,
	<1370875166.90268.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<104083AE5AAA634C993249DFCCE4C2030643B8F6@CIPRESTE.ua.pt>,
	<1370884459.21972.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<104083AE5AAA634C993249DFCCE4C2030643B92F@CIPRESTE.ua.pt>,
	<1370898338.4657.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<104083AE5AAA634C993249DFCCE4C2030643B953@CIPRESTE.ua.pt>
Message-ID: <1370902089.11914.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Sorry, I forgot to paste some lines and change the names:


res10Percent<- fun1(final3New,0.1,200)

res10PercentSub1<-subset(res10Percent[duplicated(res10Percent)|duplicated(res10Percent,fromLast=TRUE),],dummy==1)
indx1<-as.numeric(row.names(res10PercentSub1))

res10PercentSub2<-res10PercentSub1[order(res10PercentSub1$dimension),]
indx11<-as.numeric(row.names(res10PercentSub2))
names(indx11)<-(seq_along(indx11)-1)%/%2+1
res10PercentSub3<-res10Percent[c(indx11,indx11+1),]
res10PercentSub3$id<- names(c(indx11,indx11+1))
res10PercentSub4<-do.call(rbind,lapply(split(res10PercentSub3,res10PercentSub3$id),function(x) {x1<-x[-1,];x2<-x1[which.max(abs(x1$dimension[1]-x1$dimension[-1]))+1,];x3<-x[x$dummy==1,][which.min(abs(as.numeric(row.names(x[x$dummy==1,]))-as.numeric(row.names(x2)))),];rbind(x3,x2)}))
row.names(res10PercentSub4)<-gsub(".*\\.","",row.names(res10PercentSub4)) #####forgot
################################################
res10PercentSub0<-subset(res10Percent[duplicated(res10Percent)|duplicated(res10Percent,fromLast=TRUE),],dummy==0)
indx0<-as.numeric(row.names(res10PercentSub0))

res10PercentSub20<-res10PercentSub0[order(res10PercentSub0$dimension),]
indx00<-as.numeric(row.names(res10PercentSub20))
names(indx00)<-(seq_along(indx00)-1)%/%2+1
res10PercentSub30<- res10Percent[c(indx00-1,indx00),]
res10PercentSub30$id<- names(c(indx00-1,indx00))
res10PercentSub40<- do.call(rbind,lapply(split(res10PercentSub30,res10PercentSub30$id),function(x){x1<-subset(x,dummy==1); x2<-subset(x,dummy==0);x3<-x1[which.max(abs(x1$dimension-unique(x2$dimension))),];x4<-x2[which.min(abs(as.numeric(row.names(x3))-as.numeric(row.names(x2)))),];rbind(x3,x4)}))

row.names(res10PercentSub40)<-gsub(".*\\.","",row.names(res10PercentSub40))
indxNew<- sort(as.numeric(c(row.names(res10PercentSub4),row.names(res10PercentSub40)))) #####res10PercentSub4
res10PercentFinal<-res10Percent[-indxNew,]
dim(res10PercentFinal)
#[1] 454? 5
nrow(subset(res10PercentFinal,dummy==0))
#[1] 227
nrow(subset(res10PercentFinal,dummy==1))
#[1] 227

nrow(unique(res10PercentFinal))

A.K.

----- Original Message -----
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Cc: 
Sent: Monday, June 10, 2013 5:48 PM
Subject: RE: please check this

Error message:

Error in row.names(res10PercentSub5) : 
? object 'res10PercentSub5' not found


________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: segunda-feira, 10 de Junho de 2013 22:05
Para: Cecilia Carmo
Cc: R help
Assunto: Re: please check this

Hi,
Try this:
res10Percent<- fun1(final3New,0.1,200)

res10PercentSub1<-subset(res10Percent[duplicated(res10Percent)|duplicated(res10Percent,fromLast=TRUE),],dummy==1)
indx1<-as.numeric(row.names(res10PercentSub1))

res10PercentSub2<-res10PercentSub1[order(res10PercentSub1$dimension),]
indx11<-as.numeric(row.names(res10PercentSub2))
names(indx11)<-(seq_along(indx11)-1)%/%2+1
res10PercentSub3<-res10Percent[c(indx11,indx11+1),]
res10PercentSub3$id<- names(c(indx11,indx11+1))
res10PercentSub4<-do.call(rbind,lapply(split(res10PercentSub3,res10PercentSub3$id),function(x) {x1<-x[-1,];x2<-x1[which.max(abs(x1$dimension[1]-x1$dimension[-1]))+1,];x3<-x[x$dummy==1,][which.min(abs(as.numeric(row.names(x[x$dummy==1,]))-as.numeric(row.names(x2)))),];rbind(x3,x2)}))
################################################
res10PercentSub0<-subset(res10Percent[duplicated(res10Percent)|duplicated(res10Percent,fromLast=TRUE),],dummy==0)
indx0<-as.numeric(row.names(res10PercentSub0))

res10PercentSub20<-res10PercentSub0[order(res10PercentSub0$dimension),]
indx00<-as.numeric(row.names(res10PercentSub20))
names(indx00)<-(seq_along(indx00)-1)%/%2+1
res10PercentSub30<- res10Percent[c(indx00-1,indx00),]
res10PercentSub30$id<- names(c(indx00-1,indx00))
res10PercentSub40<- do.call(rbind,lapply(split(res10PercentSub30,res10PercentSub30$id),function(x){x1<-subset(x,dummy==1); x2<-subset(x,dummy==0);x3<-x1[which.max(abs(x1$dimension-unique(x2$dimension))),];x4<-x2[which.min(abs(as.numeric(row.names(x3))-as.numeric(row.names(x2)))),];rbind(x3,x4)}))

row.names(res10PercentSub40)<-gsub(".*\\.","",row.names(res10PercentSub40))
indxNew<- sort(as.numeric(c(row.names(res10PercentSub5),row.names(res10PercentSub40))))
res10PercentFinal<-res10Percent[-indxNew,]
dim(res10PercentFinal)
#[1] 454?  5
nrow(subset(res10PercentFinal,dummy==0))
#[1] 227
nrow(subset(res10PercentFinal,dummy==1))
#[1] 227

nrow(unique(res10PercentFinal))
#[1] 454
which(duplicated(res10Percent)|duplicated(res10Percent,fromLast=TRUE))
# [1] 113 117 123 125 153 157 187 189 207 213 223 235 265 267 269 275 276 278 279
#[20] 283 293 301 303 305 309 317 327 331 335 339 341 343 347 351 367 369 371 379
#[39] 385 399 407 413 415 417 429 437 441 453 459 461 471 473 477 479 501 505
res10Percent[c(113:114,117:118),]
#? ? ? ?  firm year industry dummy dimension
#113 500221723 2005? ? ?  26? ?  1? ? ? 3147
#114 500601429 2005? ? ?  26? ?  0? ? ? 3076
#117 500221723 2005? ? ?  26? ?  1? ? ? 3147
#118 502668920 2005? ? ?  26? ?  0? ? ? 3249

res10PercentFinal[c(113:114,117:118),]? #deleted the duplicated row and the accompanying pair with the maximum difference
#? ? ? ?  firm year industry dummy dimension
#113 500221723 2005? ? ?  26? ?  1? ? ? 3147
#114 500601429 2005? ? ?  26? ?  0? ? ? 3076
#119 500115362 2006? ? ?  26? ?  1? ? ? 6239
#120 500060223 2006? ? ?  26? ?  0? ? ? 6208

A.K.

row.names(res10PercentSub4)<-gsub(".*\\.","",row.names(res10PercentSub4))
res10PercentSub5<-res10PercentSub4[order(as.numeric(res10PercentSub4$id)),]

----- Original Message -----
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Cc:
Sent: Monday, June 10, 2013 1:41 PM
Subject: RE: please check this

I think it could be better to eliminate that one.
If you could do it I appreciate.

Cec?lia

________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: segunda-feira, 10 de Junho de 2013 18:14
Para: Cecilia Carmo
Assunto: Re: please check this

If you wanted to eliminate the duplicate rows that have the pair with the maximum difference, it is possible.
Just informing you.




----- Original Message -----
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Cc:
Sent: Monday, June 10, 2013 10:51 AM
Subject: RE: please check this

I think it is ok now.

Thanks
Cec?lia

________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: segunda-feira, 10 de Junho de 2013 15:39
Para: Cecilia Carmo
Cc: R help
Assunto: Re: please check this

Hi,
Try this:
which(duplicated(res10Percent))
# [1] 117 125 157 189 213 235 267 275 278 293 301 327 331 335 339 367 369 371 379
#[20] 413 415 417 441 459 461 477 479 505
res10PercentSub1<-subset(res10Percent[which(duplicated(res10Percent)),],dummy==1)? #most of the duplicated are dummy==1
res10PercentSub0<-subset(res10Percent[which(duplicated(res10Percent)),],dummy==0)
indx1<-as.numeric(row.names(res10PercentSub1))
indx11<-sort(c(indx1,indx1+1))
indx0<- as.numeric(row.names(res10PercentSub0))
indx00<- sort(c(indx0,indx0-1))
indx10<- sort(c(indx11,indx00))

nrow(res10Percent[-indx10,])
#[1] 452
res10PercentNew<-res10Percent[-indx10,]
nrow(subset(res10PercentNew,dummy==1))
#[1] 226
nrow(subset(res10PercentNew,dummy==0))
#[1] 226
nrow(unique(res10PercentNew))
#[1] 452
A.K.



----- Original Message -----
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Cc:
Sent: Monday, June 10, 2013 10:19 AM
Subject: RE: please check this

But I don't want it like this.
Once a firm is paired with another, these two firms should not be paired again.
Could you solve this?
Thanks,
Cec?lia


________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: segunda-feira, 10 de Junho de 2013 15:12
Para: Cecilia Carmo
Assunto: Re: please check this

I did look into that.
If you look for the nrow() in each category, then it will be different.? It means that the duplicates are not pairwise, but in the whole `result`.? The explanation is again with the multiple matches.? So, here we selected the one with dummy==0 that closely matches the dimension of one dummy==1.? Suppose, the value of dimension with dummy==1` is `2554` and it got a match with dummy==0 with `2580`.? Now, consider another case with dimension as `2570` with dummy==1 (which also comes within the same split group).? Then it got a match with `2580' with dummy==0.? I guess it was based on the way in which it was tested.






________________________________
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Sent: Monday, June 10, 2013 10:02 AM
Subject: please check this




When I do

res10Percent<- fun1(final3New,0.1,200)
dim(res10Percent)
[1] 508?  5
#[1] 508?  5
nrow(subset(res10Percent,dummy==0))
#[1] 254
nrow(subset(res10Percent,dummy==1))
#[1] 254


testingDuplicates<-unique(res10Percent)
nrow(testingDuplicates)
[1] 480 #this should be 508, if not there are duplicated rows, or not?


Thanks
Cecilia


From bbolker at gmail.com  Tue Jun 11 00:15:56 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 10 Jun 2013 22:15:56 +0000
Subject: [R] help needed! RMSE
References: <COL127-W47BAF01B488A83352225B6D39A0@phx.gbl>
Message-ID: <loom.20130611T000710-677@post.gmane.org>

mansor nad <nadsim88 <at> hotmail.com> writes:

 
> i need HELPPP!! how do i calculate the RMSE value for two GEV
> models?first GEV is where the three parameters are constant.2nd GEV
> model a 4 parameter model with the location parameter is allowed to
> vary linearly with respect to time while holding the other
> parameters at constant.  is there any programming code for this?  i
> really really need help. please reply to me as soon as
> possible. thanks in advance.

  Have you read the posting guide (URL/link at the bottom of
every posting at this list)?  Can you provide a reproducible example?
It may seem perverse, but urgency ("I need HELP! ... I really really
need help ... please reply to me as soon as possible ...") doesn't
actually generally improve your chances of getting help here -- it
comes across as shouting.  Providing reproducible examples not only
makes it easier for people to answer, and improving the chances
that the answers you get will be ones you really need, it also 
demonstrates evidence that you have invested some effort.

  You might want to start with this example:

  library("fExtremes")
  g1 <- gevFit(gevSim())
  sqrt(sum(g1 at residuals^2))
  ?gevFit


From dwinsemius at comcast.net  Tue Jun 11 00:26:51 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 10 Jun 2013 15:26:51 -0700
Subject: [R] Speed up or alternative to 'For' loop
In-Reply-To: <CAMDVrE3jbQochoPGOoc8zcDTPRO5AEhY1nZpHVBzz6JWNMPanA@mail.gmail.com>
References: <CAMDVrE3jbQochoPGOoc8zcDTPRO5AEhY1nZpHVBzz6JWNMPanA@mail.gmail.com>
Message-ID: <E920DE69-8987-424D-85B7-C7738679F667@comcast.net>


On Jun 10, 2013, at 10:28 AM, Trevor Walker wrote:

> I have a For loop that is quite slow and am wondering if there is a faster
> option:
> 
> df <- data.frame(TreeID=rep(1:500,each=20), Age=rep(seq(1,20,1),500))
> df$Height <- exp(-0.1 + 0.2*df$Age)
> df$HeightGrowth <- NA   #intialize with NA
> for (i in 2:nrow(df))
> {if(df$TreeID[i]==df$TreeID[i-1])
>  {df$HeightGrowth[i] <- df$Height[i]-df$Height[i-1]
>  }
> }
> 
Ivoid tests with if(){}e;se(). Use vectorized code, possibly with 'ifelse' but in this case you need a function that does calcualtions within groups.

The ave() function with diff() will do it compactly and efficiently:

> df <- data.frame(TreeID=rep(1:5,each=4), Age=rep(seq(1,4,1),5))
> df$Height <- exp(-0.1 + 0.2*df$Age)
> df$HeightGrowth <- NA   #intialize with NA

> df$HeightGrowth <- ave(df$Height, df$TreeID, FUN= function(vec) c(NA, diff(vec)))
> df
   TreeID Age   Height HeightGrowth
1       1   1 1.105171           NA
2       1   2 1.349859    0.2446879
3       1   3 1.648721    0.2988625
4       1   4 2.013753    0.3650314
5       2   1 1.105171           NA
6       2   2 1.349859    0.2446879
7       2   3 1.648721    0.2988625
8       2   4 2.013753    0.3650314
9       3   1 1.105171           NA
10      3   2 1.349859    0.2446879
11      3   3 1.648721    0.2988625
12      3   4 2.013753    0.3650314
13      4   1 1.105171           NA
14      4   2 1.349859    0.2446879
15      4   3 1.648721    0.2988625
16      4   4 2.013753    0.3650314
17      5   1 1.105171           NA
18      5   2 1.349859    0.2446879
19      5   3 1.648721    0.2988625
20      5   4 2.013753    0.3650314

(On my machine it was over six times as fast as the if-based code from Arun. )

-- 

David Winsemius
Alameda, CA, USA


From macqueen1 at llnl.gov  Tue Jun 11 00:29:59 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 10 Jun 2013 22:29:59 +0000
Subject: [R] Speed up or alternative to 'For' loop
In-Reply-To: <5E1B812FAC2C4A49B3D99593B5A52191448A36@PRDEXMBX-08.the-lab.llnl.gov>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A52191448C22@PRDEXMBX-08.the-lab.llnl.gov>

Sorry, it looks like I was hasty.
Absent another dumb mistake, the following should do it.

The request was for differences, i.e., the amount of growth from one
period to the next, separately for each tree.

for (ir in unique(df$TreeID)) {
  in.ir <- df$TreeID == ir
  df$HeightGrowth[in.ir] <- c(NA, diff(df$Height[in.ir]))
}



And this gives the same result as Rui Barradas' previous response.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/10/13 2:51 PM, "MacQueen, Don" <macqueen1 at llnl.gov> wrote:

>How about
>
>for (ir in unique(df$TreeID)) {
>  in.ir <- df$TreeID == ir
>  df$HeightGrowth[in.ir] <- cumsum(df$Height[in.ir])
>}
>
>Seemed fast enough to me.
>
>In R, it is generally good to look for ways to operate on entire vectors
>or arrays, rather than element by element within them. The cumsum()
>function does that in this example.
>
>-Don
>
>
>-- 
>Don MacQueen
>
>Lawrence Livermore National Laboratory
>7000 East Ave., L-627
>Livermore, CA 94550
>925-423-1062
>
>
>
>
>
>On 6/10/13 10:28 AM, "Trevor Walker" <trevordaviswalker at gmail.com> wrote:
>
>>I have a For loop that is quite slow and am wondering if there is a
>>faster
>>option:
>>
>>df <- data.frame(TreeID=rep(1:500,each=20), Age=rep(seq(1,20,1),500))
>>df$Height <- exp(-0.1 + 0.2*df$Age)
>>df$HeightGrowth <- NA   #intialize with NA
>>for (i in 2:nrow(df))
>> {if(df$TreeID[i]==df$TreeID[i-1])
>>  {df$HeightGrowth[i] <- df$Height[i]-df$Height[i-1]
>>  }
>> }
>>
>>Trevor Walker
>>Email: trevordaviswalker at gmail.com
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Tue Jun 11 00:41:58 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 10 Jun 2013 15:41:58 -0700 (PDT)
Subject: [R] Combining CSV data
In-Reply-To: <CALFKK3xTtutDvi12LpSp4M6hyn0bFR1-Z+7aWMTA6AT8xWG5mA@mail.gmail.com>
References: <CALFKK3xTtutDvi12LpSp4M6hyn0bFR1-Z+7aWMTA6AT8xWG5mA@mail.gmail.com>
Message-ID: <1370904118.98031.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Try this:

dat1<-read.table(text="
Row_ID_CR,? Data1,??? Data2,??? Data3
1,????????????????? aa,????????? bb,????????? cc
2,????????????????? dd,????????? ee,????????? ff
",sep=",",header=TRUE,stringsAsFactors=FALSE)

dat2<-read.table(text="
Row_ID_N,? Src_Row_ID,? DataN1
1a,????????????? 1,????????????????? This is comment 1
2a,????????????? 1,????????????????? This is comment 2
3a,????????????? 2,????????????????? This is comment 1
4a,????????????? 1,????????????????? This is comment 3
",sep=",",header=TRUE,stringsAsFactors=FALSE)
library(stringr)
dat2$DataN1<-str_trim(dat2$DataN1)
res<- merge(dat1,dat2,by.x=1,by.y=2)
?res1<-res[,-5]
library(plyr)
?res2<-ddply(res1,.(Row_ID_CR,Data1,Data2,Data3),summarize, DataN1=list(DataN1))
?res2
?# Row_ID_CR??????????????? Data1??????? Data2??????? Data3
#1???????? 1?????????????????? aa?????????? bb?????????? cc
#2???????? 2?????????????????? dd?????????? ee?????????? ff
#?????????????????????????????????????????????????? DataN1
#1 This is comment 1, This is comment 2, This is comment 3
#2?????????????????????????????????????? This is comment 1



res3<-data.frame(res2[,-5],t(apply(do.call(rbind,res2[,5]),1,function(x) {x[duplicated(x)]<-NA;x})))
?colnames(res3)[grep("X",colnames(res3))]<- paste0("DataComment",gsub("[[:alpha:]]","",colnames(res3)[grep("X",colnames(res3))]))
res3
#? Row_ID_CR??????????????? Data1??????? Data2??????? Data3????? DataComment1
#1???????? 1?????????????????? aa?????????? bb?????????? cc This is comment 1
#2???????? 2?????????????????? dd?????????? ee?????????? ff This is comment 1
#?????? DataComment2????? DataComment3
#1 This is comment 2 This is comment 3
#2????????????? <NA>????????????? <NA>

A.K.


----- Original Message -----
From: Shreya Rawal <rawal.shreya at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Monday, June 10, 2013 4:38 PM
Subject: [R] Combining CSV data

Hello R community,

I am trying to combine two CSV files that look like this:

File A

Row_ID_CR,?  Data1,? ? Data2,? ? Data3
1,? ? ? ? ? ? ? ? ?  aa,? ? ? ? ? bb,? ? ? ? ? cc
2,? ? ? ? ? ? ? ? ?  dd,? ? ? ? ? ee,? ? ? ? ? ff


File B

Row_ID_N,?  Src_Row_ID,?  DataN1
1a,? ? ? ? ? ? ?  1,? ? ? ? ? ? ? ? ?  This is comment 1
2a,? ? ? ? ? ? ?  1,? ? ? ? ? ? ? ? ?  This is comment 2
3a,? ? ? ? ? ? ?  2,? ? ? ? ? ? ? ? ?  This is comment 1
4a,? ? ? ? ? ? ?  1,? ? ? ? ? ? ? ? ?  This is comment 3

And the output I am looking for is, comparing the values of Row_ID_CR and
Src_Row_ID

Output

ROW_ID_CR,? ? Data1,? ? Data2,? ? Data3,? ? DataComment1,
DataComment2,? ? ? ? ? DataComment3
1,? ? ? ? ? ? ? ? ? ? ? aa,? ? ? ?  bb,? ? ? ?  cc,? ? ? ? This is
comment1,? ? This is comment2,? ?  This is comment 3
2,? ? ? ? ? ? ? ? ? ? ? dd,? ? ? ? ? ee,? ? ? ?  ff,? ? ? ? ? This is
comment1


I am a novice R user, I am able to replicate a left join but I need a bit
more in the final result.


Thanks!!

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From macqueen1 at llnl.gov  Tue Jun 11 00:51:24 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 10 Jun 2013 22:51:24 +0000
Subject: [R] Speed up or alternative to 'For' loop
In-Reply-To: <5E1B812FAC2C4A49B3D99593B5A52191448A36@PRDEXMBX-08.the-lab.llnl.gov>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A52191448D42@PRDEXMBX-08.the-lab.llnl.gov>

Well, speaking of hasty...

This will also do it, provided that each tree's initial height is less
than the previous tree's final height. In principle, not a safe
assumption, but might be ok depending on where the data came from.

df$delta <- c(NA,diff(df$Height))
df$delta[df$delta < 0] <- NA

-Don



-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/10/13 2:51 PM, "MacQueen, Don" <macqueen1 at llnl.gov> wrote:

>How about
>
>for (ir in unique(df$TreeID)) {
>  in.ir <- df$TreeID == ir
>  df$HeightGrowth[in.ir] <- cumsum(df$Height[in.ir])
>}
>
>Seemed fast enough to me.
>
>In R, it is generally good to look for ways to operate on entire vectors
>or arrays, rather than element by element within them. The cumsum()
>function does that in this example.
>
>-Don
>
>
>-- 
>Don MacQueen
>
>Lawrence Livermore National Laboratory
>7000 East Ave., L-627
>Livermore, CA 94550
>925-423-1062
>
>
>
>
>
>On 6/10/13 10:28 AM, "Trevor Walker" <trevordaviswalker at gmail.com> wrote:
>
>>I have a For loop that is quite slow and am wondering if there is a
>>faster
>>option:
>>
>>df <- data.frame(TreeID=rep(1:500,each=20), Age=rep(seq(1,20,1),500))
>>df$Height <- exp(-0.1 + 0.2*df$Age)
>>df$HeightGrowth <- NA   #intialize with NA
>>for (i in 2:nrow(df))
>> {if(df$TreeID[i]==df$TreeID[i-1])
>>  {df$HeightGrowth[i] <- df$Height[i]-df$Height[i-1]
>>  }
>> }
>>
>>Trevor Walker
>>Email: trevordaviswalker at gmail.com
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Tue Jun 11 01:27:04 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 10 Jun 2013 16:27:04 -0700 (PDT)
Subject: [R] Speed up or alternative to 'For' loop
In-Reply-To: <CAMDVrE3jbQochoPGOoc8zcDTPRO5AEhY1nZpHVBzz6JWNMPanA@mail.gmail.com>
References: <CAMDVrE3jbQochoPGOoc8zcDTPRO5AEhY1nZpHVBzz6JWNMPanA@mail.gmail.com>
Message-ID: <1370906824.35934.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Some speed comparisons:


df <- data.frame(TreeID=rep(1:6000,each=20), Age=rep(seq(1,20,1),6000))
df$Height <- exp(-0.1 + 0.2*df$Age)
df1<- df
df3<-df
library(data.table)
dt1<- data.table(df)
df$HeightGrowth <- NA 


system.time({? #Rui's 2nd function
df2 <- data.matrix(df)
for(i in seq_len(nrow(df2))[-1]){
??? if(df2[i, "TreeID"] == df2[i - 1, "TreeID"])
??? ??? df2[i, "HeightGrowth"] <- df2[i, "Height"] - df2[i - 1, "Height"]
}
})
# user? system elapsed 
?# 1.108?? 0.000?? 1.109 


system.time({for (ir in unique(df$TreeID)) {?? #Don's first function
? in.ir <- df$TreeID == ir
? df$HeightGrowth[in.ir] <- c(NA, diff(df$Height[in.ir]))
}})
#? user? system elapsed 
#100.004?? 0.704 100.903 

system.time({df3$delta <- c(NA,diff(df3$Height)) ##Don's 2nd function
df3$delta[df3$delta < 0] <- NA}) #####winner 
#?? user? system elapsed 
?# 0.016?? 0.000?? 0.014 

system.time(df1$HeightGrowth <- ave(df1$Height, df1$TreeID, FUN= function(vec) c(NA, diff(vec)))) #David's
?#user? system elapsed 
?# 0.136?? 0.000?? 0.137 
?system.time(dt1[,HeightGrowth:=c(NA,diff(Height)),by=TreeID])
#? user? system elapsed 
?# 0.076?? 0.000?? 0.079 


?identical(df1,as.data.frame(dt1))
#[1] TRUE
?identical(df1,df)
#[1] TRUE


head(df1,2)
#? TreeID Age?? Height HeightGrowth
#1????? 1?? 1 1.105171?????????? NA
#2????? 1?? 2 1.349859??? 0.2446879
head(df2,2)
#???? TreeID Age?? Height HeightGrowth
#[1,]????? 1?? 1 1.105171?????????? NA
#[2,]????? 1?? 2 1.349859??? 0.2446879

A.K.



----- Original Message -----
From: Trevor Walker <trevordaviswalker at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Monday, June 10, 2013 1:28 PM
Subject: [R] Speed up or alternative to 'For' loop

I have a For loop that is quite slow and am wondering if there is a faster
option:

df <- data.frame(TreeID=rep(1:500,each=20), Age=rep(seq(1,20,1),500))
df$Height <- exp(-0.1 + 0.2*df$Age)
df$HeightGrowth <- NA?  #intialize with NA
for (i in 2:nrow(df))
{if(df$TreeID[i]==df$TreeID[i-1])
? {df$HeightGrowth[i] <- df$Height[i]-df$Height[i-1]
? }
}

Trevor Walker
Email: trevordaviswalker at gmail.com

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From tgs.public.mail at gmail.com  Tue Jun 11 03:49:21 2013
From: tgs.public.mail at gmail.com (Thomas Stewart)
Date: Mon, 10 Jun 2013 21:49:21 -0400
Subject: [R] Apply a PCA to other datasets
In-Reply-To: <1370885021395-4669182.post@n4.nabble.com>
References: <1370885021395-4669182.post@n4.nabble.com>
Message-ID: <CAHJ=y95hzCeP5djo6xRdjcvjH8hOoRv=P1CMywWR+ExOVA9OUg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130610/19a43f6c/attachment.pl>

From smartpink111 at yahoo.com  Tue Jun 11 04:14:41 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 10 Jun 2013 19:14:41 -0700 (PDT)
Subject: [R] Combining CSV data
In-Reply-To: <1370904118.98031.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <CALFKK3xTtutDvi12LpSp4M6hyn0bFR1-Z+7aWMTA6AT8xWG5mA@mail.gmail.com>
	<1370904118.98031.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1370916881.76218.YahooMailNeo@web142602.mail.bf1.yahoo.com>

HI,
I am not sure about your DataN1 column.? If there is any identifier to differentiate the comments (in this case 1,2,3), then it will easier to place that in the correct column.
? My previous solution is not helpful in situations like these:
dat2<-read.table(text="
Row_ID_N,? Src_Row_ID,? DataN1
1a,????????????? 1,????????????????? This is comment 1
2a,????????????? 1,????????????????? This is comment 2
3a,????????????? 2,????????????????? This is comment 2
4a,????????????? 1,????????????????? This is comment 3
",sep=",",header=TRUE,stringsAsFactors=FALSE)
dat3<-read.table(text="
Row_ID_N,? Src_Row_ID,? DataN1
1a,????????????? 1,????????????????? This is comment 1
2a,????????????? 1,????????????????? This is comment 2
3a,????????????? 2,????????????????? This is comment 3
4a,????????????? 1,????????????????? This is comment 3
5a,??? ??? ?2,????????????????? This is comment 2 
",sep=",",header=TRUE,stringsAsFactors=FALSE)


library(stringr)
library(plyr)
fun1<- function(data1,data2){
??? data2$DataN1<- str_trim(data2$DataN1)??? 
??????? res<- merge(data1,data2,by.x=1,by.y=2)
??? res1<- res[,-5]
??? res2<- ddply(res1,.(Row_ID_CR,Data1,Data2,Data3),summarize,DataN1=list(DataN1))
??? Mx1<- max(sapply(res2[,5],length))
??? res3<- data.frame(res2[,-5],do.call(rbind,lapply(res2[,5],function(x){
??? ??? ??? ??? ??? ??? ??? ??? ? indx<- as.numeric(gsub("[[:alpha:]]","",x))
??? ??? ??? ??? ??? ??? ??? ??? ? x[match(seq(Mx1),indx)]
??? ??? ??? ??? ??? ??? ??? ??? ? })),stringsAsFactors=FALSE)
??? colnames(res3)[grep("X",colnames(res3))]<- paste0("DataComment",gsub("[[:alpha:]]","",colnames(res3)[grep("X",colnames(res3))]))
??? res3
??? }??? ??? ?? 
fun1(dat1,dat2)
#? Row_ID_CR??????????????? Data1??????? Data2??????? Data3????? DataComment1
#1???????? 1?????????????????? aa?????????? bb?????????? cc This is comment 1
#2???????? 2?????????????????? dd?????????? ee?????????? ff????????????? <NA>
#?????? DataComment2????? DataComment3
#1 This is comment 2 This is comment 3
#2 This is comment 2????????????? <NA>
?fun1(dat1,dat3)
#? Row_ID_CR??????????????? Data1??????? Data2??????? Data3????? DataComment1
#1???????? 1?????????????????? aa?????????? bb?????????? cc This is comment 1
#2???????? 2?????????????????? dd?????????? ee?????????? ff????????????? <NA>
#?????? DataComment2????? DataComment3
#1 This is comment 2 This is comment 3
#2 This is comment 2 This is comment 3


A.K.


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Shreya Rawal <rawal.shreya at gmail.com>
Cc: R help <r-help at r-project.org>
Sent: Monday, June 10, 2013 6:41 PM
Subject: Re: [R] Combining CSV data

Hi,
Try this:

dat1<-read.table(text="
Row_ID_CR,? Data1,??? Data2,??? Data3
1,????????????????? aa,????????? bb,????????? cc
2,????????????????? dd,????????? ee,????????? ff
",sep=",",header=TRUE,stringsAsFactors=FALSE)

dat2<-read.table(text="
Row_ID_N,? Src_Row_ID,? DataN1
1a,????????????? 1,????????????????? This is comment 1
2a,????????????? 1,????????????????? This is comment 2
3a,????????????? 2,????????????????? This is comment 1
4a,????????????? 1,????????????????? This is comment 3
",sep=",",header=TRUE,stringsAsFactors=FALSE)
library(stringr)
dat2$DataN1<-str_trim(dat2$DataN1)
res<- merge(dat1,dat2,by.x=1,by.y=2)
?res1<-res[,-5]
library(plyr)
?res2<-ddply(res1,.(Row_ID_CR,Data1,Data2,Data3),summarize, DataN1=list(DataN1))
?res2
?# Row_ID_CR??????????????? Data1??????? Data2??????? Data3
#1???????? 1?????????????????? aa?????????? bb?????????? cc
#2???????? 2?????????????????? dd?????????? ee?????????? ff
#?????????????????????????????????????????????????? DataN1
#1 This is comment 1, This is comment 2, This is comment 3
#2?????????????????????????????????????? This is comment 1



res3<-data.frame(res2[,-5],t(apply(do.call(rbind,res2[,5]),1,function(x) {x[duplicated(x)]<-NA;x})))
?colnames(res3)[grep("X",colnames(res3))]<- paste0("DataComment",gsub("[[:alpha:]]","",colnames(res3)[grep("X",colnames(res3))]))
res3
#? Row_ID_CR??????????????? Data1??????? Data2??????? Data3????? DataComment1
#1???????? 1?????????????????? aa?????????? bb?????????? cc This is comment 1
#2???????? 2?????????????????? dd?????????? ee?????????? ff This is comment 1
#?????? DataComment2????? DataComment3
#1 This is comment 2 This is comment 3
#2????????????? <NA>????????????? <NA>

A.K.


----- Original Message -----
From: Shreya Rawal <rawal.shreya at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Monday, June 10, 2013 4:38 PM
Subject: [R] Combining CSV data

Hello R community,

I am trying to combine two CSV files that look like this:

File A

Row_ID_CR,?? Data1,? ? Data2,? ? Data3
1,? ? ? ? ? ? ? ? ?? aa,? ? ? ? ? bb,? ? ? ? ? cc
2,? ? ? ? ? ? ? ? ?? dd,? ? ? ? ? ee,? ? ? ? ? ff


File B

Row_ID_N,?? Src_Row_ID,?? DataN1
1a,? ? ? ? ? ? ?? 1,? ? ? ? ? ? ? ? ?? This is comment 1
2a,? ? ? ? ? ? ?? 1,? ? ? ? ? ? ? ? ?? This is comment 2
3a,? ? ? ? ? ? ?? 2,? ? ? ? ? ? ? ? ?? This is comment 1
4a,? ? ? ? ? ? ?? 1,? ? ? ? ? ? ? ? ?? This is comment 3

And the output I am looking for is, comparing the values of Row_ID_CR and
Src_Row_ID

Output

ROW_ID_CR,? ? Data1,? ? Data2,? ? Data3,? ? DataComment1,
DataComment2,? ? ? ? ? DataComment3
1,? ? ? ? ? ? ? ? ? ? ? aa,? ? ? ?? bb,? ? ? ?? cc,? ? ? ? This is
comment1,? ? This is comment2,? ?? This is comment 3
2,? ? ? ? ? ? ? ? ? ? ? dd,? ? ? ? ? ee,? ? ? ?? ff,? ? ? ? ? This is
comment1


I am a novice R user, I am able to replicate a left join but I need a bit
more in the final result.


Thanks!!

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From rob.forsyth at newcastle.ac.uk  Mon Jun 10 23:41:42 2013
From: rob.forsyth at newcastle.ac.uk (Rob Forsyth)
Date: Mon, 10 Jun 2013 21:41:42 +0000
Subject: [R] padding specific missing values with NA to allow cbind
Message-ID: <463EEFF4-FBB1-4F44-8D03-918A416E79AE@newcastle.ac.uk>

Dear list

Getting very frustrated with this simple-looking problem

> m1 <- lm(x~y, data=mydata)
> outliers <- abs(stdres(m1))>2
> plot(x~y, data=mydata)

I would like to plot a simple x,y scatter plot with labels giving custom information displayed for the outliers only, i.e. I would like to define a column mydata$labels for the mydata dataframe so that the command

> text(mydata$y, mydata$x, labels=mydata$labels)

will label those rows where outliers[i] = TRUE with text but is otherwise blank

The first problem I have is that due to some NAs in mydata, nrows(outliers) < nrows(mydata) and I'm getting in a tangle trying to pad the appropriate rows of outliers

Thanks

Rob


From arumkone at wrdf.org  Tue Jun 11 01:42:29 2013
From: arumkone at wrdf.org (arum)
Date: Mon, 10 Jun 2013 16:42:29 -0700 (PDT)
Subject: [R] Help with R loop for URL download from FRED to create US time
 series
Message-ID: <1370907749147-4669209.post@n4.nabble.com>

I am downloading time series data from FRED. I have a working download, but I
do not want to write out the download for all 50 states likes this:
 IDRGSP <-
read.table('http://research.stlouisfed.org/fred2/data/IDRGSP.txt', skip=11,
header=TRUE)
IDRGSP$DATE <- as.Date(IDRGSP$DATE, '%Y-%m-%d')
IDRGSP$SERIES <- 'IDRGSP'
IDRGSP$DESC <-  "Real Total Gross Domestic Product by State for Idaho, Mil.
of, A, NSA, 2012-06-05"

WYRGSP <- read.table('http://research.stlouisfed.org/fred2/data/WYRGSP.txt',
skip=11, header=TRUE)
WYRGSP$DATE <- as.Date(WYRGSP$DATE, '%Y-%m-%d')
WYRGSP$SERIES <- 'WYRGSP'
WYRGSP$DESC <-  "Real Total Gross Domestic Product by State for Wyoming,
Mil. of, A, NSA, 2012-06-05"
RGSP <- rbind(IDRGSP, WYRGSP)

I want to loop but I can not get the paste to work correctly. I am trying
this:  Can someone help me figure out the loop so I can build a table for
all 50 states.
ab <- c(state.abb)
base <- "'http://research.stlouisfed.org/fred2/data/"
type <- "RGSP.txt', skip=11, header=TRUE";

tmp <- NULL;
for (a in ab) {
  url <- paste(base, a, type, sep="");

if (is.null(tmp))
    tmp <- read.table(url)
  else tmp <- rbind(tmp, read.table(url))
}
tmp

thanks for your help




--
View this message in context: http://r.789695.n4.nabble.com/Help-with-R-loop-for-URL-download-from-FRED-to-create-US-time-series-tp4669209.html
Sent from the R help mailing list archive at Nabble.com.


From wdunlap at tibco.com  Tue Jun 11 05:59:57 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 11 Jun 2013 03:59:57 +0000
Subject: [R] padding specific missing values with NA to allow cbind
In-Reply-To: <463EEFF4-FBB1-4F44-8D03-918A416E79AE@newcastle.ac.uk>
References: <463EEFF4-FBB1-4F44-8D03-918A416E79AE@newcastle.ac.uk>
Message-ID: <E66794E69CFDE04D9A70842786030B931C3012E3@PA-MBX01.na.tibco.com>

Try adding the argument
   na.action = na.exclude
to your call to lm().  See help("na.exclude") for details.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Rob Forsyth
> Sent: Monday, June 10, 2013 2:42 PM
> To: r-help at r-project.org
> Subject: [R] padding specific missing values with NA to allow cbind
> 
> Dear list
> 
> Getting very frustrated with this simple-looking problem
> 
> > m1 <- lm(x~y, data=mydata)
> > outliers <- abs(stdres(m1))>2
> > plot(x~y, data=mydata)
> 
> I would like to plot a simple x,y scatter plot with labels giving custom information
> displayed for the outliers only, i.e. I would like to define a column mydata$labels for the
> mydata dataframe so that the command
> 
> > text(mydata$y, mydata$x, labels=mydata$labels)
> 
> will label those rows where outliers[i] = TRUE with text but is otherwise blank
> 
> The first problem I have is that due to some NAs in mydata, nrows(outliers) <
> nrows(mydata) and I'm getting in a tangle trying to pad the appropriate rows of outliers
> 
> Thanks
> 
> Rob
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Tue Jun 11 06:15:57 2013
From: jholtman at gmail.com (jim holtman)
Date: Tue, 11 Jun 2013 00:15:57 -0400
Subject: [R] Help with R loop for URL download from FRED to create US
	time series
In-Reply-To: <1370907749147-4669209.post@n4.nabble.com>
References: <1370907749147-4669209.post@n4.nabble.com>
Message-ID: <CAAxdm-4uhC7LM=08B7xuspE6u1Rx8gotLAVsKYjA2pCqwENsug@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130611/66c748f2/attachment.pl>

From jim at bitwrit.com.au  Tue Jun 11 06:21:22 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 11 Jun 2013 14:21:22 +1000
Subject: [R] Substituting the values on the y-axis
In-Reply-To: <13995809.12181370874414136.JavaMail.defaultUser@defaultHost>
References: <13995809.12181370874414136.JavaMail.defaultUser@defaultHost>
Message-ID: <51B6A5C2.2030509@bitwrit.com.au>

On 06/11/2013 12:26 AM, diddle1990 at fastwebnet.it wrote:
> Hello,
>
> I plotted a graph on R showing how salinity (in ?, y-axis) changes with time(in
> years, x-axis). However, right from the beginning on the Excel spreadsheet the v
> alues for salinity appeared as, for example, 35000? instead of 35?, which I gues
> sed must have been a typing error for the website from which I extracted the dat
> a (NOAA).Thus, I now would like to substitute these values with the correspondin
> g smaller value, as it follows:
>
> 25000 35000->  25, 35   and so on.
>
> Is there any way I can change this on R or do I have to modify these numbers bef
> ore inputting the data on R (for example on Excel)? If so, can anybody tell me h
> ow to do either of these?
>
Hi Emanuela,
I think that the axis.mult function in the plotrix package will do what 
you want with mult=0.001. Obviously you won't want to display the 
transformation, so set mult.label="".

Jim


From jdnewmil at dcn.davis.CA.us  Tue Jun 11 06:45:15 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 10 Jun 2013 21:45:15 -0700
Subject: [R] Fwd: Problem with ODBC connection
In-Reply-To: <CA+dpOJ=5LGqPiKU1gisL7DDxmNhS_1fmH-7A5x5_6ZPx8M-4nA@mail.gmail.com>
References: <CA+dpOJ=gLQyZmniVkrd+gKzjThe_y+dJ5fGBeGw1q6fm_rXCyQ@mail.gmail.com>
	<CA+dpOJnm7HXJPg-ReXb9SDKc3q7MeUqLtg+N0znbAhn0PhO9gw@mail.gmail.com>
	<CA+dpOJ=5LGqPiKU1gisL7DDxmNhS_1fmH-7A5x5_6ZPx8M-4nA@mail.gmail.com>
Message-ID: <b1e68d9b-5a06-45ea-bb79-7656f12cb801@email.android.com>

Given the resounding silence, I would venture to guess that no-one here is interested in troubleshooting ODBC connections to Excel. The problem is most likely in the ODBC driver for Excel (not in R or RODBC), and Excel is NOT a database (so any data format problem is unlikely to be detected).
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Christofer Bogaso <bogaso.christofer at gmail.com> wrote:

>Any response please? Was my question not clear to the list? Please let
>me
>know.
>
>Thanks and regards,
>
>---------- Forwarded message ----------
>From: Christofer Bogaso <bogaso.christofer at gmail.com>
>Date: Sat, Jun 8, 2013 at 9:39 PM
>Subject: Re: Problem with ODBC connection
>To: r-help <r-help at r-project.org>
>
>
>Hello All,
>
>My previous post remains unanswered probably because the attachment was
>not
>working properly.
>
>So I am re-posting it again.
>
>My problem is in reading an Excel-2003 file through ODBC connection
>using
>RODBC package. Let say I have this Excel file:
>
>http://www.2shared.com/document/HS3JeFyW/MyFile.html
>
>
>I saved it in my "F:" drive and tried reading the contents using RODBC
>connection:
>
>> library(RODBC)
>> MyData <- sqlFetch(odbcConnectExcel("f:/MyFile.xls"), "aaaa")
>> head(MyData, 30)
>
>
>However it looks that the second column (with header 's') is not read
>properly.
>
>Can somebody here explain this bizarre thing? Did I do something wrong
>in
>reading that?
>
>Really appreciate if someone could point out anything what might go
>wrong.
>
>Thanks and regards,
>
>
>On Fri, Jun 7, 2013 at 4:46 PM, Christofer Bogaso <
>bogaso.christofer at gmail.com> wrote:
>
>> Hello again,
>>
>> I am having problem with ODBC connection using the RODBC package.
>>
>> I am basically trying to read the attached Excel-2003 file using
>RODBC
>> package. Here is my code:
>>
>> > head(sqlFetch(odbcConnectExcel("d:/ssss1.xls"), "aaaa"), 30);
>> odbcCloseAll()
>>    Criteria  s  d fd  f                        fd1
>>     f1                        fd2    f2 fd3 f3 F12 F13 F14 F15 F16
>F17
>> F18 F19 F20
>> 1         a NA NA NA NA 0.000000000000000000000000
>> 0.000000000000000027755576 -0.00000000000000040332321    NA  NA NA 
>NA
>>  NA  NA  NA  NA  NA  NA  NA  NA
>> 2         s NA  0 NA NA 0.000000000000000000000000
>> 0.000000000000000000000000  0.00000000000000000000000    NA  NA NA 
>NA
>>  NA  NA  NA  NA  NA  NA  NA  NA
>> 3         d NA  0 NA NA 0.000000000000000001734723
>> 0.000000000000000006938894  0.00000000000000002775558  5.00  NA NA 
>NA
>>  NA  NA  NA  NA  NA  NA  NA  NA
>> 4         f NA NA NA NA                         NA
>>     NA                         NA -4.25  NA NA  NA  NA  NA  NA  NA 
>NA
>>  NA  NA  NA
>> 5         f NA  0 NA NA 0.000000000000000000000000
>> 0.000000000000000000000000  0.00000000000000000000000 -1.53  NA NA 
>NA
>>  NA  NA  NA  NA  NA  NA  NA  NA
>> 6         f NA NA NA NA                         NA
>>     NA  0.00000000000000000000000  0.00  NA NA  NA  NA  NA  NA  NA 
>NA
>>  NA  NA  NA
>> 7         f NA NA NA NA                         NA
>>     NA  0.00000000000000000000000    NA  NA NA  NA  NA  NA  NA  NA 
>NA
>>  NA  NA  NA
>> 8         f NA  0 NA NA                         NA
>>     NA                         NA    NA  NA NA  NA  NA  NA  NA  NA 
>NA
>>  NA  NA  NA
>> 9         f NA  0 NA NA                         NA
>>     NA                         NA    NA  NA NA  NA  NA  NA  NA  NA 
>NA
>>  NA  NA  NA
>> 10        f NA NA NA NA                         NA
>>     NA                         NA    NA  NA NA  NA  NA  NA  NA  NA 
>NA
>>  NA  NA  NA
>> 11        f NA NA NA NA                         NA
>>     NA                         NA    NA  NA NA  NA  NA  NA  NA  NA 
>NA
>>  NA  NA  NA
>> 12        f NA NA NA NA                         NA
>>     NA                         NA    NA  NA NA  NA  NA  NA  NA  NA 
>NA
>>  NA  NA  NA
>> 13        f NA NA NA NA                         NA
>>     NA                         NA    NA  NA NA  NA  NA  NA  NA  NA 
>NA
>>  NA  NA  NA
>>
>> Here you see the data in second column could not read at all.
>>
>> Can somebody point me if I did something wrong?
>>
>> Thanks and regards,
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From djnordlund at frontier.com  Tue Jun 11 07:32:59 2013
From: djnordlund at frontier.com (Daniel Nordlund)
Date: Mon, 10 Jun 2013 22:32:59 -0700
Subject: [R] Fwd: Problem with ODBC connection
In-Reply-To: <b1e68d9b-5a06-45ea-bb79-7656f12cb801@email.android.com>
References: <CA+dpOJ=gLQyZmniVkrd+gKzjThe_y+dJ5fGBeGw1q6fm_rXCyQ@mail.gmail.com><CA+dpOJnm7HXJPg-ReXb9SDKc3q7MeUqLtg+N0znbAhn0PhO9gw@mail.gmail.com><CA+dpOJ=5LGqPiKU1gisL7DDxmNhS_1fmH-7A5x5_6ZPx8M-4nA@mail.gmail.com>
	<b1e68d9b-5a06-45ea-bb79-7656f12cb801@email.android.com>
Message-ID: <613D46CC723441498177E1198E341B3F@Aragorn>

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Jeff Newmiller
> Sent: Monday, June 10, 2013 9:45 PM
> To: Christofer Bogaso; r-help
> Subject: Re: [R] Fwd: Problem with ODBC connection
> 
> Given the resounding silence, I would venture to guess that no-one here is
> interested in troubleshooting ODBC connections to Excel. The problem is
> most likely in the ODBC driver for Excel (not in R or RODBC), and Excel is
> NOT a database (so any data format problem is unlikely to be detected).
> --------------------------------------------------------------------------
> -
> Jeff Newmiller                        The     .....       .....  Go
> Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> --------------------------------------------------------------------------
> -
> Sent from my phone. Please excuse my brevity.
> 
> Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
> 

I tried reading your workbook using your code, i.e.

library(RODBC)
MyData <- sqlFetch(odbcConnectExcel('mypath/Myfile.xls'), "aaaa")
head(MyData, 30)

and got an error message saying that odbcConnectExcel is only usable with 32-bit Windows and I have a 64-bit system, so I can't help you there.  But there are many other options in R for reading Excel workbooks.  I was able to read your data using the read.xls function from the gdata package.  I am not endorsing that package, it just happened to be the first package on my system that I tried.  

So if you can't read the data one way, try another.  You could install and load the sos package and runthe following function

findFn('xls')

and you will get all sorts of suggestions.


Hope this is helpful,

Dan

Daniel Nordlund
Bothell, WA USA


From jwd at surewest.net  Tue Jun 11 07:34:23 2013
From: jwd at surewest.net (jwd)
Date: Mon, 10 Jun 2013 22:34:23 -0700
Subject: [R] Fwd: Problem with ODBC connection
In-Reply-To: <CA+dpOJ=5LGqPiKU1gisL7DDxmNhS_1fmH-7A5x5_6ZPx8M-4nA@mail.gmail.com>
References: <CA+dpOJ=gLQyZmniVkrd+gKzjThe_y+dJ5fGBeGw1q6fm_rXCyQ@mail.gmail.com>
	<CA+dpOJnm7HXJPg-ReXb9SDKc3q7MeUqLtg+N0znbAhn0PhO9gw@mail.gmail.com>
	<CA+dpOJ=5LGqPiKU1gisL7DDxmNhS_1fmH-7A5x5_6ZPx8M-4nA@mail.gmail.com>
Message-ID: <20130610223423.29ef7e32@draco.site>

On Tue, 11 Jun 2013 02:19:14 +0545
Christofer Bogaso <bogaso.christofer at gmail.com> wrote:

Any real answer would be contingent on a reader being provided a
reproducible example. Since you don't provide that, there's not a lot
of point to an answer. However, to tilt at a windmill, depending on the
size and complexity of your data file, it might be easier to simply
export the data from Excel as a csv file and use read.table to bring it
in to R.

JWDougherty


From miaojpm at gmail.com  Tue Jun 11 07:49:27 2013
From: miaojpm at gmail.com (jpm miao)
Date: Tue, 11 Jun 2013 13:49:27 +0800
Subject: [R] How can we access an element in a structure
Message-ID: <CABcx46Axq_=xo+PCFSn__JQW6Cv4FQ2sgdeoboZVF00Nc6OpLw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130611/e1045d43/attachment.pl>

From jorgeivanvelez at gmail.com  Tue Jun 11 07:55:30 2013
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Tue, 11 Jun 2013 15:55:30 +1000
Subject: [R] How can we access an element in a structure
In-Reply-To: <CABcx46Axq_=xo+PCFSn__JQW6Cv4FQ2sgdeoboZVF00Nc6OpLw@mail.gmail.com>
References: <CABcx46Axq_=xo+PCFSn__JQW6Cv4FQ2sgdeoboZVF00Nc6OpLw@mail.gmail.com>
Message-ID: <CAKL8G3GDUHjCrs=AuJKAYD1cKR8VDWz2P_n3ffixVW+zSqLm=g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130611/87a64608/attachment.pl>

From mackay at northnet.com.au  Tue Jun 11 08:03:21 2013
From: mackay at northnet.com.au (Duncan Mackay)
Date: Tue, 11 Jun 2013 16:03:21 +1000
Subject: [R] Fwd: Problem with ODBC connection
In-Reply-To: <CA+dpOJ=5LGqPiKU1gisL7DDxmNhS_1fmH-7A5x5_6ZPx8M-4nA@mail.g
	mail.com>
References: <CA+dpOJ=gLQyZmniVkrd+gKzjThe_y+dJ5fGBeGw1q6fm_rXCyQ@mail.gmail.com>
	<CA+dpOJnm7HXJPg-ReXb9SDKc3q7MeUqLtg+N0znbAhn0PhO9gw@mail.gmail.com>
	<CA+dpOJ=5LGqPiKU1gisL7DDxmNhS_1fmH-7A5x5_6ZPx8M-4nA@mail.gmail.com>
Message-ID: <201306110603.r5B63MMG025735@mail14.tpg.com.au>

Try

library(RODBC)
Channel1 <- odbcConnectExcel2007("MyFile.xls", readOnly = TRUE)
  Channel1
RODBC Connection 1
Details:
   case=nochange
   DBQ=g:\1\MyFile.xls
   DefaultDir=g:\1
   Driver={Microsoft Excel Driver (*.xls, *.xlsx, *.xlsm, *.xlsb)}
   DriverId=1046
   MaxBufferSize=2048
   PageTimeout=5

aaaa = sqlFetch(Channel1, "aaaa",
            colnames = F,
            rownames = F)
str(aaaa)
'data.frame':   7100 obs. of  21 variables:
  $ Criteria: chr  "a" "s" "d" "f" ...
  $ s       : num  NA NA NA NA NA NA NA NA NA 0 ...
  $ d       : num  NA 0 0 NA 0 NA NA 0 0 NA ...
  $ fd      : logi  NA NA NA NA NA NA ...
  $ f       : logi  NA NA NA NA NA NA ...
  $ fd1     : num  0.00 0.00 1.73e-18 NA 0.00 ...
  $ f1      : num  2.78e-17 0.00 6.94e-18 NA 0.00 ...
  $ fd2     : num  -4.03e-16 0.00 2.78e-17 NA 0.00 ...
  $ f2      : num  NA NA 5 -4.25 -1.53 0 NA NA NA NA ...
  $ fd3     : logi  NA NA NA NA NA NA ...
  $ f3      : logi  NA NA NA NA NA NA ...
  $ F12     : logi  NA NA NA NA NA NA ...
  $ F13     : logi  NA NA NA NA NA NA ...
  $ F14     : logi  NA NA NA NA NA NA ...
  $ F15     : logi  NA NA NA NA NA NA ...
  $ F16     : logi  NA NA NA NA NA NA ...
  $ F17     : logi  NA NA NA NA NA NA ...
  $ F18     : logi  NA NA NA NA NA NA ...
  $ F19     : logi  NA NA NA NA NA NA ...
  $ F20     : logi  NA NA NA NA NA NA ...
  $ F21     : logi  NA NA NA NA NA NA ...

Duncan


Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


At 06:34 11/06/2013, you wrote:
>Any response please? Was my question not clear to the list? Please let me
>know.
>
>Thanks and regards,
>
>---------- Forwarded message ----------
>From: Christofer Bogaso <bogaso.christofer at gmail.com>
>Date: Sat, Jun 8, 2013 at 9:39 PM
>Subject: Re: Problem with ODBC connection
>To: r-help <r-help at r-project.org>
>
>
>Hello All,
>
>My previous post remains unanswered probably because the attachment was not
>working properly.
>
>So I am re-posting it again.
>
>My problem is in reading an Excel-2003 file through ODBC connection using
>RODBC package. Let say I have this Excel file:
>
>http://www.2shared.com/document/HS3JeFyW/MyFile.html
>
>
>I saved it in my "F:" drive and tried reading the contents using RODBC
>connection:
>
> > library(RODBC)
> > MyData <- sqlFetch(odbcConnectExcel("f:/MyFile.xls"), "aaaa")
> > head(MyData, 30)
>
>
>However it looks that the second column (with header 's') is not read
>properly.
>
>Can somebody here explain this bizarre thing? Did I do something wrong in
>reading that?
>
>Really appreciate if someone could point out anything what might go wrong.
>
>Thanks and regards,
>
>
>On Fri, Jun 7, 2013 at 4:46 PM, Christofer Bogaso <
>bogaso.christofer at gmail.com> wrote:
>
> > Hello again,
> >
> > I am having problem with ODBC connection using the RODBC package.
> >
> > I am basically trying to read the attached Excel-2003 file using RODBC
> > package. Here is my code:
> >
> > > head(sqlFetch(odbcConnectExcel("d:/ssss1.xls"), "aaaa"), 30);
> > odbcCloseAll()
> >    Criteria  s  d fd  f                        fd1
> >     f1                        fd2    f2 fd3 f3 F12 F13 F14 F15 F16 F17
> > F18 F19 F20
> > 1         a NA NA NA NA 0.000000000000000000000000
> > 0.000000000000000027755576 -0.00000000000000040332321    NA  NA NA  NA
> >  NA  NA  NA  NA  NA  NA  NA  NA
> > 2         s NA  0 NA NA 0.000000000000000000000000
> > 0.000000000000000000000000  0.00000000000000000000000    NA  NA NA  NA
> >  NA  NA  NA  NA  NA  NA  NA  NA
> > 3         d NA  0 NA NA 0.000000000000000001734723
> > 0.000000000000000006938894  0.00000000000000002775558  5.00  NA NA  NA
> >  NA  NA  NA  NA  NA  NA  NA  NA
> > 4         f NA NA NA NA                         NA
> >     NA                         NA -4.25  NA NA  NA  NA  NA  NA  NA  NA
> >  NA  NA  NA
> > 5         f NA  0 NA NA 0.000000000000000000000000
> > 0.000000000000000000000000  0.00000000000000000000000 -1.53  NA NA  NA
> >  NA  NA  NA  NA  NA  NA  NA  NA
> > 6         f NA NA NA NA                         NA
> >     NA  0.00000000000000000000000  0.00  NA NA  NA  NA  NA  NA  NA  NA
> >  NA  NA  NA
> > 7         f NA NA NA NA                         NA
> >     NA  0.00000000000000000000000    NA  NA NA  NA  NA  NA  NA  NA  NA
> >  NA  NA  NA
> > 8         f NA  0 NA NA                         NA
> >     NA                         NA    NA  NA NA  NA  NA  NA  NA  NA  NA
> >  NA  NA  NA
> > 9         f NA  0 NA NA                         NA
> >     NA                         NA    NA  NA NA  NA  NA  NA  NA  NA  NA
> >  NA  NA  NA
> > 10        f NA NA NA NA                         NA
> >     NA                         NA    NA  NA NA  NA  NA  NA  NA  NA  NA
> >  NA  NA  NA
> > 11        f NA NA NA NA                         NA
> >     NA                         NA    NA  NA NA  NA  NA  NA  NA  NA  NA
> >  NA  NA  NA
> > 12        f NA NA NA NA                         NA
> >     NA                         NA    NA  NA NA  NA  NA  NA  NA  NA  NA
> >  NA  NA  NA
> > 13        f NA NA NA NA                         NA
> >     NA                         NA    NA  NA NA  NA  NA  NA  NA  NA  NA
> >  NA  NA  NA
> >
> > Here you see the data in second column could not read at all.
> >
> > Can somebody point me if I did something wrong?
> >
> > Thanks and regards,
> >
>
>         [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From kridox at ymail.com  Tue Jun 11 08:06:22 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Tue, 11 Jun 2013 15:06:22 +0900
Subject: [R] How can we access an element in a structure
In-Reply-To: <CABcx46Axq_=xo+PCFSn__JQW6Cv4FQ2sgdeoboZVF00Nc6OpLw@mail.gmail.com>
References: <CABcx46Axq_=xo+PCFSn__JQW6Cv4FQ2sgdeoboZVF00Nc6OpLw@mail.gmail.com>
Message-ID: <CAAcyNCyAT9P-sLn9=e9KTzroQpjccnGukRjb6+fR2FvN0fFc3w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130611/c9c177b3/attachment.pl>

From webbe at ufl.edu  Tue Jun 11 08:07:10 2013
From: webbe at ufl.edu (Webb,Elizabeth E)
Date: Tue, 11 Jun 2013 06:07:10 +0000
Subject: [R] mapply on multiple data frames
Message-ID: <BCCC8BAC-5825-4994-B02D-AF918C47383C@ufl.edu>

Hi all-

I am wondering about using the mapply function to multiple data frames.  Specifically, I would like to do a t-test on a subset of multiple data frames.  All data frames have the same structure.
Here is my code so far:

f<-function(x,y) {
test<-t.test(x$col1[x$col3=="num",],v$col2[x$col3=="num",],paired=T,alternative="greater")
out<-test$p.value
return(out) 
}

all_nums<-list(num1,num2,num3,num4)
all_dfs<-list(df1,df2,df3,df4)

mapply(f,all_dfs,all_nums)


This tells me that $ operator is invalid for atomic vectors.  I have tried shifting to notation using [  ,] to denote columns, but that gives me this error: incorrect number of dimensions.  

Thank you in advance,
Elizabeth

From nevil.amos at gmail.com  Tue Jun 11 09:21:48 2013
From: nevil.amos at gmail.com (nevil amos)
Date: Tue, 11 Jun 2013 17:21:48 +1000
Subject: [R] Problem i9ncreasing memory to jvm for XLConnect
Message-ID: <CAN9eD7=L-7M663M+juLmv-nFAH2c3QYW0H35Kmd+NtTzXL72Mw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130611/118d91a8/attachment.pl>

From smartpink111 at yahoo.com  Tue Jun 11 09:29:16 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 11 Jun 2013 00:29:16 -0700 (PDT)
Subject: [R] mapply on multiple data frames
In-Reply-To: <BCCC8BAC-5825-4994-B02D-AF918C47383C@ufl.edu>
References: <BCCC8BAC-5825-4994-B02D-AF918C47383C@ufl.edu>
Message-ID: <1370935756.76838.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
It would be better to provide a reproducible example.
set.seed(25)
all_dfs<- list(df1=data.frame(col1=sample(1:40,20,replace=TRUE),col2=sample(20:40,20,replace=TRUE),col3= sample(1:3,20,replace=TRUE)),df2=data.frame(col1=sample(30:60,20,replace=TRUE),col2=sample(35:65,20,replace=TRUE),col3=sample(1:3,20,replace=TRUE)),df3=data.frame(col1=sample(40:80,20,replace=TRUE),col2=sample(25:45,20,replace=TRUE),col3=sample(1:3,20,replace=TRUE)))

all_nums<-as.list(1:3)

f<- function(x,y){
out<-t.test(x$col1[x$col3==y],x$col2[x$col3==y],paired=T,alternative="greater")$p.value
out
}
mapply(f,all_dfs,all_nums)
#??????? df1???????? df2???????? df3 
#0.926400219 0.713943295 0.004510331 


##Just for validation:
df1New<-all_dfs[[1]]
df2New<-all_dfs[[2]]
df3New<- all_dfs[[3]]
t.test(df1New$col1[df1New$col3==1],df1New$col2[df1New$col3==1],paired=T,alternative="greater")$p.value
#[1] 0.9264002
t.test(df2New$col1[df2New$col3==2],df2New$col2[df2New$col3==2],paired=T,alternative="greater")$p.value
#[1] 0.7139433
?t.test(df3New$col1[df3New$col3==3],df3New$col2[df3New$col3==3],paired=T,alternative="greater")$p.value
#[1] 0.004510331
A.K.



----- Original Message -----
From: "Webb,Elizabeth E" <webbe at ufl.edu>
To: "r-help at R-project.org" <r-help at r-project.org>
Cc: 
Sent: Tuesday, June 11, 2013 2:07 AM
Subject: [R] mapply on multiple data frames

Hi all-

I am wondering about using the mapply function to multiple data frames.? Specifically, I would like to do a t-test on a subset of multiple data frames.? All data frames have the same structure.
Here is my code so far:

f<-function(x,y) {
test<-t.test(x$col1[x$col3=="num",],v$col2[x$col3=="num",],paired=T,alternative="greater")
out<-test$p.value
return(out) 
}

all_nums<-list(num1,num2,num3,num4)
all_dfs<-list(df1,df2,df3,df4)

mapply(f,all_dfs,all_nums)


This tells me that $ operator is invalid for atomic vectors.? I have tried shifting to notation using [? ,] to denote columns, but that gives me this error: incorrect number of dimensions.? 

Thank you in advance,
Elizabeth
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ottorino-luca.pantani at unifi.it  Tue Jun 11 10:09:21 2013
From: ottorino-luca.pantani at unifi.it (ottorino)
Date: Tue, 11 Jun 2013 10:09:21 +0200
Subject: [R] How to "source" a R script in a parent/parallel directory
 (win/linux)
Message-ID: <1370938161.4107.13.camel@lucaottorino4.agr.unifi.it>

Dear R users,
I would like to source a file independently from the operating system,
but I cannot figure out how.
I apologize for the verbosity of this mail, 
but English is not my mother tongue, so I cannot be concise and precise
as I can be in my own language.


I'm writing a script which will be run by some people who are not
familiar with R.
I already tried to teach them some rudiments, but unsuccessfully.
They are only willing to double click an icon, and do not want to bother
with many details.

Consider the following situation, in where I have to run the very same
script under Linux (for debugging) and under windows (for the users)

On Win
C:\\mypath\\user1

On my Linux box the same path is a samba share mounted on
/mnt/mymountpt/user1/mywd

The file I would like to run (say, RunThis.R) with a "source" command
will be located at

C:\\mypath\\PROGRAM
/mnt/mymountpt/mypath/PROGRAM

This location will never change, while "user1" will change each time,
depending on the user or on the data to be processed. In other words
each user will have his/her workspace under different and parallel
directories.

RunThis.R needs also some files and script which will be located under 
C:\\mypath\\PROGRAM\\Constants_and_Functions
/mnt/mymountpt/mypath/PROGRAM/Constants_and_Functions

My intent here is not to allow the users to modify RunThis.R and the
file under Constants_and_Functions.
I already tried this but you probably alredy imagine which were the
problems.

Under each "user?" there will be two dir, one with the raw data to be
processed and another with the outcome of the analysis and the processed
data.

The unfamiliar "user?" will have to modify ONLY a small script (say, C:\
\mypath\\user1\\options.R, C:\\mypath\\user2\\options.R )in which he/she
can modify some options (jpeg or pdf, in English or in Italian, csv or
xls and so on.)

I've found this solution to the problem, but I wonder if there are some
more elegant alternatives.
Each options.R file would finish with lines like the following

if(Sys.info()[1] == "Linux"){
library(gdata)
Fun.Const.Dir <-
    file.path("/mnt/mymountpt/mypath/PROGRAM/",
"Constants_and_Functions")
source(file.path("/mnt/mymountpt/mypath/PROGRAM", "RunThis.R"))
} else {
library(xlsReadWrite)
Fun.Const.Dir <-
    file.path("C:\\mypath\\PROGRAM", "Constants_and_Functions")
source(file.path("C:\\mypath\\PROGRAM", ""RunThis.R"))
}


My idea was that in R would have been possible to write something
similar to what I write in latex with figures, i.e.
\includegraphics{../PROGRAM/InsertThisFigure.pdf}

so something like 
source("../PROGRAM/RunThis.R") would have been worked. but it didn't

I tried a brute attempt like the following: 
step.back <- setwd("..")
source(file.path(step.back, ""RunThis.R"))

but without success.

Any suggestion ?


-- 
Ottorino-Luca Pantani, Universit? di Firenze
Dip.to di Scienze delle Produzioni Agroalimentari e  
dell'Ambiente (DISPAA)
P.zle Cascine 28 50144 Firenze Italia
Debian 7.0 wheezy -- GNOME 3.4.2
GNU Emacs 24.3.50.1 (i486-pc-linux-gnu, GTK+ Version 3.4.2)
ESS version 12.04-4 -- R 2.15.1


From feanor0 at hotmail.com  Tue Jun 11 13:23:54 2013
From: feanor0 at hotmail.com (M M)
Date: Tue, 11 Jun 2013 11:23:54 +0000
Subject: [R] weighted(?) regression
Message-ID: <BAY175-W42A72969C33CE78CFECEB2EE850@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130611/ce120619/attachment.pl>

From friendly at yorku.ca  Tue Jun 11 14:16:21 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Tue, 11 Jun 2013 08:16:21 -0400
Subject: [R] woby2 (Odds Ratio) for variables with 3 or more levels
In-Reply-To: <CANeAhkYvNju_1eCBmWg5Ss89p4BgiPvX6-Yd4C1vktKFa8Vqyg@mail.gmail.com>
References: <CANeAhkYvNju_1eCBmWg5Ss89p4BgiPvX6-Yd4C1vktKFa8Vqyg@mail.gmail.com>
Message-ID: <51B71515.1060604@yorku.ca>

You may want loddsratio in the vcdExtra package

On 6/10/2013 12:27 PM, Vlatka Matkovic Puljic wrote:
> Dear all,
>
> I am using Epi package to calculate Odds ratio in my bivariate analysis.
> How can I make *twoby2 *in variables that have 3 or more levels.
>
> For example:
> I have 4 level var (Age)
> m=matrix(c(290, 100,232, 201, 136, 99, 182, 240), nrow=4, ncol=2)
> library (Epi)
> twoby2(m)
>
> R gives me only
> Comparing : Row 1 vs. Row 2
>
> While I would like to have reference value in Row 1, and compare Row 2, Row
> 3 and Row 4 with it.
>
>
> Thanks for your help!
>
> 	[[alternative HTML version deleted]]
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From f.harrell at vanderbilt.edu  Tue Jun 11 14:52:54 2013
From: f.harrell at vanderbilt.edu (Frank Harrell)
Date: Tue, 11 Jun 2013 05:52:54 -0700 (PDT)
Subject: [R] stepwise discriminant analysis using wilks lambda
In-Reply-To: <1370951791701-4669232.post@n4.nabble.com>
References: <1370521869345-4668817.post@n4.nabble.com>
	<1370951791701-4669232.post@n4.nabble.com>
Message-ID: <1370955174035-4669235.post@n4.nabble.com>

Unless you have detailed simulations to back up the performance of this
method I would avoid it.  It violates several statistical principles.
Frank

Hari wrote
> Hello R geeks, 
> 
> Waiting for an reply.
> 
> Thanks,
> Hari





-----
Frank Harrell
Department of Biostatistics, Vanderbilt University
--
View this message in context: http://r.789695.n4.nabble.com/stepwise-discriminant-analysis-using-wilks-lambda-tp4668817p4669235.html
Sent from the R help mailing list archive at Nabble.com.


From ajdamico at gmail.com  Tue Jun 11 15:02:17 2013
From: ajdamico at gmail.com (Anthony Damico)
Date: Tue, 11 Jun 2013 09:02:17 -0400
Subject: [R] Problem i9ncreasing memory to jvm for XLConnect
In-Reply-To: <CAN9eD7=L-7M663M+juLmv-nFAH2c3QYW0H35Kmd+NtTzXL72Mw@mail.gmail.com>
References: <CAN9eD7=L-7M663M+juLmv-nFAH2c3QYW0H35Kmd+NtTzXL72Mw@mail.gmail.com>
Message-ID: <CAOwvMDwQ1Ge-2Udc28qzLiB8XnLydKpem4ePAmw7Ezs63WAGoA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130611/9386269b/attachment.pl>

From varethugo at gmail.com  Tue Jun 11 15:15:36 2013
From: varethugo at gmail.com (Hugo Varet)
Date: Tue, 11 Jun 2013 15:15:36 +0200
Subject: [R] agnes() in package cluster on R 2.14.1 and R 3.0.1
In-Reply-To: <20917.53447.986054.159726@stat.math.ethz.ch>
References: <CABpMX0t+MJsb4mxj67iE3Q7QnNF_XuuKaPOR24AgN=r=iWnPpw@mail.gmail.com>
	<20917.53447.986054.159726@stat.math.ethz.ch>
Message-ID: <CABpMX0skZ0YpPvPh2Ve_5v27JYTg=qqZKF0kgRxxYNV=Sg1e0A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130611/0f54dc00/attachment.pl>

From kw1958 at gmail.com  Tue Jun 11 15:25:48 2013
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Tue, 11 Jun 2013 09:25:48 -0400
Subject: [R] R-help Digest, Vol 124, Issue 12
In-Reply-To: <mailman.27.1370944809.23972.r-help@r-project.org>
References: <mailman.27.1370944809.23972.r-help@r-project.org>
Message-ID: <C34D38DC-2CC9-4B9A-A840-965CFB958963@gmail.com>

Folks,

Sorry for butting in here. I ran the code from John Kane below and it worked fine. 

I did however get a deprecation message  suggesting the use of ggpairs from the GGally package to make this chart.

Unfortunately I haven't found the correct incantation to get the diagonal to display the density plots using the "diag" parameter.

Any suggestions?

Just trying to learn,
Thanks,
KW

--

On Jun 11, 2013, at 6:00 AM, r-help-request at r-project.org wrote:

> Message: 7
> Date: Mon, 10 Jun 2013 06:05:48 -0800
> From: John Kane <jrkrideau at inbox.com>
> To: Gundala Viswanath <gundalav at gmail.com>, "r-help at stat.math.ethz.ch"
> 	<r-help at stat.math.ethz.ch>
> Subject: Re: [R] All against all correlation matrix with GGPLOT Facet
> Message-ID: <3B7B03D1854.000003F5jrkrideau at inbox.com>
> Content-Type: text/plain; charset="US-ASCII"
> 
> No image.  The R-help list tends to strip out a lot of files. A pdf or txt usually gets through.  In any case I understand what you want this may do it.
> 
> library(ggplot2)
> dat1  <-  data.frame( v = rnorm(13),
> w = rnorm(13),
> x = rnorm(13),
> y = rnorm(13),
> z = rnorm(13))
> plotmatrix(dat1)
> 
> John Kane
> Kingston ON Canada
> 
> 
>> -----Original Message-----
>> From: gundalav at gmail.com
>> Sent: Mon, 10 Jun 2013 12:26:44 +0900
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] All against all correlation matrix with GGPLOT Facet
>> 
>> I have the following data:
>> 
>> v <- rnorm(13)
>> w <- rnorm(13)
>> x <- rnorm(13)
>> y <- rnorm(13)
>> z <- rnorm(13)
>> 
>> 
>> Using GGPLOT facet, what I want to do is to create a 5*5 matrix,
>> where each cells plot the correlation between
>> each pair of the above data. E.g. v-v,v-w; v-x,...,z-z
>> 
>> 
>> What's the way to do it?
>> Attached is the image.
>> 
>> GV.
>> ______________


From rob.forsyth at newcastle.ac.uk  Tue Jun 11 09:29:07 2013
From: rob.forsyth at newcastle.ac.uk (Rob Forsyth)
Date: Tue, 11 Jun 2013 07:29:07 +0000
Subject: [R] padding specific missing values with NA to allow cbind
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C3012E3@PA-MBX01.na.tibco.com>
References: <463EEFF4-FBB1-4F44-8D03-918A416E79AE@newcastle.ac.uk>
	<E66794E69CFDE04D9A70842786030B931C3012E3@PA-MBX01.na.tibco.com>
Message-ID: <930602CC-8E19-4364-9F10-BA650D566FCB@newcastle.ac.uk>

Thanks very much

On 11 Jun 2013, at 4:59 am, William Dunlap wrote:

> Try adding the argument
>   na.action = na.exclude
> to your call to lm().  See help("na.exclude") for details.
> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
> 
> 
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
>> Of Rob Forsyth
>> Sent: Monday, June 10, 2013 2:42 PM
>> To: r-help at r-project.org
>> Subject: [R] padding specific missing values with NA to allow cbind
>> 
>> Dear list
>> 
>> Getting very frustrated with this simple-looking problem
>> 
>>> m1 <- lm(x~y, data=mydata)
>>> outliers <- abs(stdres(m1))>2
>>> plot(x~y, data=mydata)
>> 
>> I would like to plot a simple x,y scatter plot with labels giving custom information
>> displayed for the outliers only, i.e. I would like to define a column mydata$labels for the
>> mydata dataframe so that the command
>> 
>>> text(mydata$y, mydata$x, labels=mydata$labels)
>> 
>> will label those rows where outliers[i] = TRUE with text but is otherwise blank
>> 
>> The first problem I have is that due to some NAs in mydata, nrows(outliers) <
>> nrows(mydata) and I'm getting in a tangle trying to pad the appropriate rows of outliers
>> 
>> Thanks
>> 
>> Rob
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From kulupp at online.de  Tue Jun 11 11:20:46 2013
From: kulupp at online.de (Kulupp)
Date: Tue, 11 Jun 2013 11:20:46 +0200
Subject: [R] Rao's quadratic entropy with fuzzy coded trait data
Message-ID: <51B6EBEE.7040100@online.de>

Ein eingebundener Text mit undefiniertem Zeichensatz wurde abgetrennt.
Name: nicht verf?gbar
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130611/09dcb017/attachment.pl>

From michel.arnaud at cirad.fr  Tue Jun 11 13:49:05 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Tue, 11 Jun 2013 13:49:05 +0200
Subject: [R] a title on the map (function gvisGeoChart package googleVis )
Message-ID: <51B70EB1.1090105@cirad.fr>

Hi
I am using the package googleVis and the function gvisGeoChart
Is it possible to put a title on the map ?

Here is the call of the function :

library(googleVis)
G1 <- gvisGeoChart(PaysProjets, locationvar='Pays', colorvar='NbProj',
options=list(
region= "world",
displayMode="regions",
height=347*1.5, width= 556*1.5
))
plot(G1)
Thank you



-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From felix11_6 at gmx.de  Tue Jun 11 14:18:13 2013
From: felix11_6 at gmx.de (felice)
Date: Tue, 11 Jun 2013 05:18:13 -0700 (PDT)
Subject: [R] R vector
Message-ID: <1370953092997-4669233.post@n4.nabble.com>

hello,

when i use the function rowMeans, which is sum/n, can i divide it in 2
parts, -> Sum(just positive values)/n and Sum(just negative values)/n. i
need both for my regression but dont know how to do it.

for example we have the matrix

1  1  -1  -1   -> rowMeans([1:3 , 2])  just positive -> 1
1 -1 -1  -2                                                                             
1/2  here not 0 because we dont use the -1
1 1   1   1                                                                               
1


thanks for helping



--
View this message in context: http://r.789695.n4.nabble.com/R-vector-tp4669233.html
Sent from the R help mailing list archive at Nabble.com.


From jrkrideau at inbox.com  Tue Jun 11 16:48:31 2013
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 11 Jun 2013 06:48:31 -0800
Subject: [R] ggpairs in GGally replaces plotmatrix in ggplot2
In-Reply-To: <C34D38DC-2CC9-4B9A-A840-965CFB958963@gmail.com>
References: <mailman.27.1370944809.23972.r-help@r-project.org>
Message-ID: <486D23F6BB4.00000161jrkrideau@inbox.com>

Hi  Keith,,
ggpairs(dat1, upper = list(continuous = "density", combo = "box"))
appears to be what you want.



John Kane
Kingston ON Canada


> -----Original Message-----
> From: kw1958 at gmail.com
> Sent: Tue, 11 Jun 2013 09:25:48 -0400
> To: r-help at r-project.org
> Subject: Re: [R] R-help Digest, Vol 124, Issue 12
> 
> Folks,
> 
> Sorry for butting in here. I ran the code from John Kane below and it
> worked fine.
> 
> I did however get a deprecation message  suggesting the use of ggpairs
> from the GGally package to make this chart.
> 
> Unfortunately I haven't found the correct incantation to get the diagonal
> to display the density plots using the "diag" parameter.
> 
> Any suggestions?
> 
> Just trying to learn,
> Thanks,
> KW
> 
> --
> 
> On Jun 11, 2013, at 6:00 AM, r-help-request at r-project.org wrote:
> 
>> Message: 7
>> Date: Mon, 10 Jun 2013 06:05:48 -0800
>> From: John Kane <jrkrideau at inbox.com>
>> To: Gundala Viswanath <gundalav at gmail.com>, "r-help at stat.math.ethz.ch"
>> 	<r-help at stat.math.ethz.ch>
>> Subject: Re: [R] All against all correlation matrix with GGPLOT Facet
>> Message-ID: <3B7B03D1854.000003F5jrkrideau at inbox.com>
>> Content-Type: text/plain; charset="US-ASCII"
>> 
>> No image.  The R-help list tends to strip out a lot of files. A pdf or
>> txt usually gets through.  In any case I understand what you want this
>> may do it.
>> 
>> library(ggplot2)
>> dat1  <-  data.frame( v = rnorm(13),
>> w = rnorm(13),
>> x = rnorm(13),
>> y = rnorm(13),
>> z = rnorm(13))
>> plotmatrix(dat1)
>> 
>> John Kane
>> Kingston ON Canada
>> 
>> 
>>> -----Original Message-----
>>> From: gundalav at gmail.com
>>> Sent: Mon, 10 Jun 2013 12:26:44 +0900
>>> To: r-help at stat.math.ethz.ch
>>> Subject: [R] All against all correlation matrix with GGPLOT Facet
>>> 
>>> I have the following data:
>>> 
>>> v <- rnorm(13)
>>> w <- rnorm(13)
>>> x <- rnorm(13)
>>> y <- rnorm(13)
>>> z <- rnorm(13)
>>> 
>>> 
>>> Using GGPLOT facet, what I want to do is to create a 5*5 matrix,
>>> where each cells plot the correlation between
>>> each pair of the above data. E.g. v-v,v-w; v-x,...,z-z
>>> 
>>> 
>>> What's the way to do it?
>>> Attached is the image.
>>> 
>>> GV.
>>> ______________
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From ruipbarradas at sapo.pt  Tue Jun 11 17:05:41 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 11 Jun 2013 16:05:41 +0100
Subject: [R] R vector
In-Reply-To: <1370953092997-4669233.post@n4.nabble.com>
References: <1370953092997-4669233.post@n4.nabble.com>
Message-ID: <51B73CC5.2010102@sapo.pt>

Hello,

You can write your own function, allowing for a condition argument.


rowMeansCond <- function(x, cond = ">", na.rm= FALSE){
	rowm <- function(x, cond = ">", na.rm = FALSE){
		f <- function(x){
			eval(parse(text = paste("x", cond, "0")))
		}
		if(na.rm) x <- x[!is.na(x)]
		i <- f(x)
		if(any(i)) mean(x[i]) else NA
	}
	apply(x, 1, rowm, cond, na.rm)
}

x1 <- c(1, 1, -1, -1)
x2 <- -2:1
rowMeansCond(cbind(x1, x2))  # note the NA, no values are positive
rowMeansCond(cbind(x1, x2), cond = "<")


Hope this helps,

Rui Barradas

Em 11-06-2013 13:18, felice escreveu:
> hello,
>
> when i use the function rowMeans, which is sum/n, can i divide it in 2
> parts, -> Sum(just positive values)/n and Sum(just negative values)/n. i
> need both for my regression but dont know how to do it.
>
> for example we have the matrix
>
> 1  1  -1  -1   -> rowMeans([1:3 , 2])  just positive -> 1
> 1 -1 -1  -2
> 1/2  here not 0 because we dont use the -1
> 1 1   1   1
> 1
>
>
> thanks for helping
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/R-vector-tp4669233.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ingfimo at gmail.com  Tue Jun 11 17:12:48 2013
From: ingfimo at gmail.com (Filippo Monari)
Date: Tue, 11 Jun 2013 16:12:48 +0100
Subject: [R] Fortran modules
Message-ID: <51B73E70.4020304@gmail.com>

Hi,
I have some subroutines using function and subroutine as well from 
Fortran modules.
In the f90 source code I used the statement:

use mymodule

and it compile well through the R CMD SHL command.

Anyway when I call dyn.load('myF90.so') form R I get the following error:

unable to load shared object '.../myF90.so':
   .../myF90.so: undefined symbol: __mymodue_MOD_myfunction

Am I doing something wrong or R cannot support subroutine using modules?

Thank you in advance,
Filippo


From jvadams at usgs.gov  Tue Jun 11 17:13:37 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 11 Jun 2013 10:13:37 -0500
Subject: [R] R vector
In-Reply-To: <1370953092997-4669233.post@n4.nabble.com>
References: <1370953092997-4669233.post@n4.nabble.com>
Message-ID: <CAN5YmCGu0w3n81kgPRse7b9zeDBdv1N4_-wYGiY4nUVmv9QQbg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130611/4febf406/attachment.pl>

From jrkrideau at inbox.com  Tue Jun 11 17:16:34 2013
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 11 Jun 2013 07:16:34 -0800
Subject: [R] ggpairs in GGally replaces plotmatrix in ggplot2
In-Reply-To: <486D23F6BB4.00000161jrkrideau@inbox.com>
References: <mailman.27.1370944809.23972.r-help@r-project.org>
	<c34d38dc-2cc9-4b9a-a840-965cfb958963@gmail.com>
Message-ID: <48ABD695FDD.000001A7jrkrideau@inbox.com>

Note that the code below might not work in RStudio.  I am gettting an intermittant crash when I use the ggpairs() command in RStudio and sometimes I get a density plot and sometimes not.  Also the command is taking 3-5 minutes to execute.  

This may just be a peculiarity of my machine but the code works fine and fairly fast in a terminal.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: jrkrideau at inbox.com
> Sent: Tue, 11 Jun 2013 06:48:31 -0800
> To: kw1958 at gmail.com, r-help at r-project.org
> Subject: [R] ggpairs in GGally replaces plotmatrix in ggplot2
> 
> Hi  Keith,,
> ggpairs(dat1, upper = list(continuous = "density", combo = "box"))
> appears to be what you want.
> 
> 
> 
> John Kane
> Kingston ON Canada
> 
> 
>> -----Original Message-----
>> From: kw1958 at gmail.com
>> Sent: Tue, 11 Jun 2013 09:25:48 -0400
>> To: r-help at r-project.org
>> Subject: Re: [R] R-help Digest, Vol 124, Issue 12
>> 
>> Folks,
>> 
>> Sorry for butting in here. I ran the code from John Kane below and it
>> worked fine.
>> 
>> I did however get a deprecation message  suggesting the use of ggpairs
>> from the GGally package to make this chart.
>> 
>> Unfortunately I haven't found the correct incantation to get the
>> diagonal
>> to display the density plots using the "diag" parameter.
>> 
>> Any suggestions?
>> 
>> Just trying to learn,
>> Thanks,
>> KW
>> 
>> --
>> 
>> On Jun 11, 2013, at 6:00 AM, r-help-request at r-project.org wrote:
>> 
>>> Message: 7
>>> Date: Mon, 10 Jun 2013 06:05:48 -0800
>>> From: John Kane <jrkrideau at inbox.com>
>>> To: Gundala Viswanath <gundalav at gmail.com>, "r-help at stat.math.ethz.ch"
>>> 	<r-help at stat.math.ethz.ch>
>>> Subject: Re: [R] All against all correlation matrix with GGPLOT Facet
>>> Message-ID: <3B7B03D1854.000003F5jrkrideau at inbox.com>
>>> Content-Type: text/plain; charset="US-ASCII"
>>> 
>>> No image.  The R-help list tends to strip out a lot of files. A pdf or
>>> txt usually gets through.  In any case I understand what you want this
>>> may do it.
>>> 
>>> library(ggplot2)
>>> dat1  <-  data.frame( v = rnorm(13),
>>> w = rnorm(13),
>>> x = rnorm(13),
>>> y = rnorm(13),
>>> z = rnorm(13))
>>> plotmatrix(dat1)
>>> 
>>> John Kane
>>> Kingston ON Canada
>>> 
>>> 
>>>> -----Original Message-----
>>>> From: gundalav at gmail.com
>>>> Sent: Mon, 10 Jun 2013 12:26:44 +0900
>>>> To: r-help at stat.math.ethz.ch
>>>> Subject: [R] All against all correlation matrix with GGPLOT Facet
>>>> 
>>>> I have the following data:
>>>> 
>>>> v <- rnorm(13)
>>>> w <- rnorm(13)
>>>> x <- rnorm(13)
>>>> y <- rnorm(13)
>>>> z <- rnorm(13)
>>>> 
>>>> 
>>>> Using GGPLOT facet, what I want to do is to create a 5*5 matrix,
>>>> where each cells plot the correlation between
>>>> each pair of the above data. E.g. v-v,v-w; v-x,...,z-z
>>>> 
>>>> 
>>>> What's the way to do it?
>>>> Attached is the image.
>>>> 
>>>> GV.
>>>> ______________
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ____________________________________________________________
> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and
> family!
> Visit http://www.inbox.com/photosharing to find out more!
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From smartpink111 at yahoo.com  Tue Jun 11 17:39:22 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 11 Jun 2013 08:39:22 -0700 (PDT)
Subject: [R] R vector
Message-ID: <1370965162.66535.YahooMailNeo@web142604.mail.bf1.yahoo.com>

HI,
Not sure if this is what you wanted.
mat1<- matrix(c(1, 1, -1, -1, 1, -1, -1, -2, 1, 1, 1, 1), byrow=TRUE, nc=4)


fun1<- function(mat){
???? ??? matP<- mat
??? matN<- mat
??? matP[matP<0]<- NA
??? matN[matN>0]<- NA
??? resP<-rowSums(matP,na.rm=TRUE)/ncol(matP)
??? resN<- rowSums(matN,na.rm=TRUE)/ncol(matN)
??? res<- rbind(resP,resN)
??? row.names(res)<- c("Mean_Pos","Mean_Neg")
??? res
??? }
fun1(mat1)
#???????? [,1]? [,2] [,3]
#Mean_Pos? 0.5? 0.25??? 1
#Mean_Neg -0.5 -1.00??? 0
A.K.


hello, 

when i use the function rowMeans, which is sum/n, can i divide 
it in 2 parts, -> Sum(just positive values)/n and Sum(just negative 
values)/n. i need both for my regression but dont know how to do it. 

for example we have the matrix 

1 ?1 ?-1 ?-1 ? -> rowMeans([1:3 , 2]) ?just positive -> 1 
1 -1 -1 ?-2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
 ? ? ? ? ? ? ? ? ? ?1/2 ?here not 0 because we dont use the -1 
1 1 ? 1 ? 1 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?1 


thanks for helping   



From rawal.shreya at gmail.com  Tue Jun 11 18:17:43 2013
From: rawal.shreya at gmail.com (Shreya Rawal)
Date: Tue, 11 Jun 2013 12:17:43 -0400
Subject: [R] Combining CSV data
In-Reply-To: <CAAxdm-5nYsPrF67VLDRnHDLc7zfDV4h=ozsWO3tP_WKVQ-SxOA@mail.gmail.com>
References: <CALFKK3xTtutDvi12LpSp4M6hyn0bFR1-Z+7aWMTA6AT8xWG5mA@mail.gmail.com>
	<CAAxdm-5nYsPrF67VLDRnHDLc7zfDV4h=ozsWO3tP_WKVQ-SxOA@mail.gmail.com>
Message-ID: <CALFKK3ytsG8ZQVizpWS0GF+tpuGDSFytLZZYHYQ18n8=7N+fKw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130611/d3263588/attachment.pl>

From rawal.shreya at gmail.com  Tue Jun 11 18:22:24 2013
From: rawal.shreya at gmail.com (Shreya Rawal)
Date: Tue, 11 Jun 2013 12:22:24 -0400
Subject: [R] Combining CSV data
In-Reply-To: <1370916881.76218.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <CALFKK3xTtutDvi12LpSp4M6hyn0bFR1-Z+7aWMTA6AT8xWG5mA@mail.gmail.com>
	<1370904118.98031.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1370916881.76218.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <CALFKK3zsGycu_yzqM6D1J8fD1px35+ypABQo-K9DXkOhQNSCWg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130611/c0737298/attachment.pl>

From smartpink111 at yahoo.com  Tue Jun 11 19:02:12 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 11 Jun 2013 10:02:12 -0700 (PDT)
Subject: [R] Combining CSV data
In-Reply-To: <CALFKK3zsGycu_yzqM6D1J8fD1px35+ypABQo-K9DXkOhQNSCWg@mail.gmail.com>
References: <CALFKK3xTtutDvi12LpSp4M6hyn0bFR1-Z+7aWMTA6AT8xWG5mA@mail.gmail.com>
	<1370904118.98031.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1370916881.76218.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<CALFKK3zsGycu_yzqM6D1J8fD1px35+ypABQo-K9DXkOhQNSCWg@mail.gmail.com>
Message-ID: <1370970132.53955.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
If the dataset is like this with the comments in the order:
dat2<-read.table(text="
Row_ID_N,? Src_Row_ID,? DataN1
1a,????????????? 1,????????????????? This is comment 1
2a,????????????? 1,????????????????? This is comment 2
3a,????????????? 2,????????????????? This is comment 1
4a,????????????? 1,????????????????? This is comment 3
",sep=",",header=TRUE,stringsAsFactors=FALSE)
dat3<-read.table(text="
Row_ID_N,? Src_Row_ID,? DataN1
1a,????????????? 1,????????????????? This is comment 1
2a,????????????? 1,????????????????? This is comment 2
3a,????????????? 2,????????????????? This is comment 1?? #
4a,????????????? 1,????????????????? This is comment 3
5a,???????? 2,????????????????? This is comment 2? #
",sep=",",header=TRUE,stringsAsFactors=FALSE)


library(stringr)
library(plyr)
fun1<- function(data1,data2){
??? data2$DataN1<- str_trim(data2$DataN1)?? 
??????? res<- merge(data1,data2,by.x=1,by.y=2)
??? res1<- res[,-5]
??? res2<- ddply(res1,.(Row_ID_CR,Data1,Data2,Data3),summarize,DataN1=list(DataN1))
??? Mx1<- max(sapply(res2[,5],length))
??? res3<- data.frame(res2[,-5],do.call(rbind,lapply(res2[,5],function(x){
????????????????????????????????? c(x,rep(NA,Mx1-length(x)))
????????????????????????????????? })),stringsAsFactors=FALSE)
??? colnames(res3)[grep("X",colnames(res3))]<- paste0("DataComment",gsub("[[:alpha:]]","",colnames(res3)[grep("X",colnames(res3))]))
??? res3
??? }??? 

????? 
fun1(dat1,dat2)
#? Row_ID_CR??????????????? Data1??????? Data2??????? Data3????? DataComment1
#1???????? 1?????????????????? aa?????????? bb?????????? cc This is comment 1
#2???????? 2?????????????????? dd?????????? ee?????????? ff This is comment 1
#?????? DataComment2????? DataComment3
#1 This is comment 2 This is comment 3
#2????????????? <NA>????????????? <NA>
?fun1(dat1,dat3)
#? Row_ID_CR??????????????? Data1??????? Data2??????? Data3????? DataComment1
#1???????? 1?????????????????? aa?????????? bb?????????? cc This is comment 1
#2???????? 2?????????????????? dd?????????? ee?????????? ff This is comment 1
?# ???? DataComment2????? DataComment3
#1 This is comment 2 This is comment 3
#2 This is comment 2????????????? <NA>


Otherwise, you need to provide an example that matches the real dataset.
A.K.
________________________________
From: Shreya Rawal <rawal.shreya at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Cc: R help <r-help at r-project.org> 
Sent: Tuesday, June 11, 2013 12:22 PM
Subject: Re: [R] Combining CSV data



Hi Arun,

Thanks for your reply. Unfortunately the Comments are just text in the real data. There is no way to differentiate based on the value of the Comments column. I guess because of that reason I couldn't get your solution to work properly. Do you think I can try it for a more general case where we don't merger/split the comments based on the values?

Thanks for your help, I appreciate! ??



On Mon, Jun 10, 2013 at 10:14 PM, arun <smartpink111 at yahoo.com> wrote:

HI,
>I am not sure about your DataN1 column.? If there is any identifier to differentiate the comments (in this case 1,2,3), then it will easier to place that in the correct column.
>? My previous solution is not helpful in situations like these:
>
>dat2<-read.table(text="
>Row_ID_N,? Src_Row_ID,? DataN1
>1a,????????????? 1,????????????????? This is comment 1
>2a,????????????? 1,????????????????? This is comment 2
>3a,????????????? 2,????????????????? This is comment 2
>4a,????????????? 1,????????????????? This is comment 3
>",sep=",",header=TRUE,stringsAsFactors=FALSE)
>dat3<-read.table(text="
>
>Row_ID_N,? Src_Row_ID,? DataN1
>1a,????????????? 1,????????????????? This is comment 1
>2a,????????????? 1,????????????????? This is comment 2
>3a,????????????? 2,????????????????? This is comment 3
>4a,????????????? 1,????????????????? This is comment 3
>5a,??? ??? ?2,????????????????? This is comment 2
>",sep=",",header=TRUE,stringsAsFactors=FALSE)
>
>
>library(stringr)
>library(plyr)
>fun1<- function(data1,data2){
>??? data2$DataN1<- str_trim(data2$DataN1)???
>??????? res<- merge(data1,data2,by.x=1,by.y=2)
>??? res1<- res[,-5]
>??? res2<- ddply(res1,.(Row_ID_CR,Data1,Data2,Data3),summarize,DataN1=list(DataN1))
>??? Mx1<- max(sapply(res2[,5],length))
>??? res3<- data.frame(res2[,-5],do.call(rbind,lapply(res2[,5],function(x){
>??? ??? ??? ??? ??? ??? ??? ??? ? indx<- as.numeric(gsub("[[:alpha:]]","",x))
>??? ??? ??? ??? ??? ??? ??? ??? ? x[match(seq(Mx1),indx)]
>??? ??? ??? ??? ??? ??? ??? ??? ? })),stringsAsFactors=FALSE)
>
>??? colnames(res3)[grep("X",colnames(res3))]<- paste0("DataComment",gsub("[[:alpha:]]","",colnames(res3)[grep("X",colnames(res3))]))
>??? res3
>??? }??? ??? ??
>fun1(dat1,dat2)
>
>#? Row_ID_CR??????????????? Data1??????? Data2??????? Data3????? DataComment1
>#1???????? 1?????????????????? aa?????????? bb?????????? cc This is comment 1
>#2???????? 2?????????????????? dd?????????? ee?????????? ff????????????? <NA>
>
>#?????? DataComment2????? DataComment3
>#1 This is comment 2 This is comment 3
>#2 This is comment 2????????????? <NA>
>?fun1(dat1,dat3)
>
>#? Row_ID_CR??????????????? Data1??????? Data2??????? Data3????? DataComment1
>#1???????? 1?????????????????? aa?????????? bb?????????? cc This is comment 1
>#2???????? 2?????????????????? dd?????????? ee?????????? ff????????????? <NA>
>
>#?????? DataComment2????? DataComment3
>#1 This is comment 2 This is comment 3
>#2 This is comment 2 This is comment 3
>
>
>
>A.K.
>
>
>----- Original Message -----
>
>From: arun <smartpink111 at yahoo.com>
>To: Shreya Rawal <rawal.shreya at gmail.com>
>Cc: R help <r-help at r-project.org>
>Sent: Monday, June 10, 2013 6:41 PM
>Subject: Re: [R] Combining CSV data
>
>Hi,
>Try this:
>
>dat1<-read.table(text="
>Row_ID_CR,? Data1,??? Data2,??? Data3
>1,????????????????? aa,????????? bb,????????? cc
>2,????????????????? dd,????????? ee,????????? ff
>",sep=",",header=TRUE,stringsAsFactors=FALSE)
>
>dat2<-read.table(text="
>Row_ID_N,? Src_Row_ID,? DataN1
>1a,????????????? 1,????????????????? This is comment 1
>2a,????????????? 1,????????????????? This is comment 2
>3a,????????????? 2,????????????????? This is comment 1
>4a,????????????? 1,????????????????? This is comment 3
>",sep=",",header=TRUE,stringsAsFactors=FALSE)
>library(stringr)
>dat2$DataN1<-str_trim(dat2$DataN1)
>res<- merge(dat1,dat2,by.x=1,by.y=2)
>?res1<-res[,-5]
>library(plyr)
>?res2<-ddply(res1,.(Row_ID_CR,Data1,Data2,Data3),summarize, DataN1=list(DataN1))
>?res2
>?# Row_ID_CR??????????????? Data1??????? Data2??????? Data3
>#1???????? 1?????????????????? aa?????????? bb?????????? cc
>#2???????? 2?????????????????? dd?????????? ee?????????? ff
>#?????????????????????????????????????????????????? DataN1
>#1 This is comment 1, This is comment 2, This is comment 3
>#2?????????????????????????????????????? This is comment 1
>
>
>
>res3<-data.frame(res2[,-5],t(apply(do.call(rbind,res2[,5]),1,function(x) {x[duplicated(x)]<-NA;x})))
>?colnames(res3)[grep("X",colnames(res3))]<- paste0("DataComment",gsub("[[:alpha:]]","",colnames(res3)[grep("X",colnames(res3))]))
>res3
>#? Row_ID_CR??????????????? Data1??????? Data2??????? Data3????? DataComment1
>#1???????? 1?????????????????? aa?????????? bb?????????? cc This is comment 1
>#2???????? 2?????????????????? dd?????????? ee?????????? ff This is comment 1
>#?????? DataComment2????? DataComment3
>#1 This is comment 2 This is comment 3
>#2????????????? <NA>????????????? <NA>
>
>A.K.
>
>
>----- Original Message -----
>From: Shreya Rawal <rawal.shreya at gmail.com>
>To: r-help at r-project.org
>Cc:
>Sent: Monday, June 10, 2013 4:38 PM
>Subject: [R] Combining CSV data
>
>Hello R community,
>
>I am trying to combine two CSV files that look like this:
>
>File A
>
>Row_ID_CR,?? Data1,? ? Data2,? ? Data3
>1,? ? ? ? ? ? ? ? ?? aa,? ? ? ? ? bb,? ? ? ? ? cc
>2,? ? ? ? ? ? ? ? ?? dd,? ? ? ? ? ee,? ? ? ? ? ff
>
>
>File B
>
>Row_ID_N,?? Src_Row_ID,?? DataN1
>1a,? ? ? ? ? ? ?? 1,? ? ? ? ? ? ? ? ?? This is comment 1
>2a,? ? ? ? ? ? ?? 1,? ? ? ? ? ? ? ? ?? This is comment 2
>3a,? ? ? ? ? ? ?? 2,? ? ? ? ? ? ? ? ?? This is comment 1
>4a,? ? ? ? ? ? ?? 1,? ? ? ? ? ? ? ? ?? This is comment 3
>
>And the output I am looking for is, comparing the values of Row_ID_CR and
>Src_Row_ID
>
>Output
>
>ROW_ID_CR,? ? Data1,? ? Data2,? ? Data3,? ? DataComment1,
>DataComment2,? ? ? ? ? DataComment3
>1,? ? ? ? ? ? ? ? ? ? ? aa,? ? ? ?? bb,? ? ? ?? cc,? ? ? ? This is
>comment1,? ? This is comment2,? ?? This is comment 3
>2,? ? ? ? ? ? ? ? ? ? ? dd,? ? ? ? ? ee,? ? ? ?? ff,? ? ? ? ? This is
>comment1
>
>
>I am a novice R user, I am able to replicate a left join but I need a bit
>more in the final result.
>
>
>Thanks!!
>
>??? [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>


From gavin.simpson at ucl.ac.uk  Tue Jun 11 19:12:38 2013
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 11 Jun 2013 11:12:38 -0600
Subject: [R] gamm in mgcv random effect significance
In-Reply-To: <51B7597A.9070506@ucmerced.edu>
References: <51B23EC9.4090109@ucmerced.edu>
	<1370642549.23179.17.camel@haul.biol.uregina.ca>
	<51B7597A.9070506@ucmerced.edu>
Message-ID: <1370970758.18170.15.camel@haul.biol.uregina.ca>

On Tue, 2013-06-11 at 10:08 -0700, William Shadish wrote:
> Gavin et al.,
> 
> Thanks so much for the help. Unfortunately, the command
> 
>  > anova(g1$lme, g2$lme)
> 
> gives "Error in eval(expr, envir, enclos) : object 'fixed' not found

This is with mgcv:::gamm yes? Strange - did you load nlme first? I think
mgcv now imports from the nlme package so to use its functions/methods
explicitly you need to load nlme - before loading mgcv also loaded nlme,
but it no longer does so.

That *should* work.

HTH

G

> and for bam (which is the one that can use a known ar1 term), the error is
> 
>  > AR1 parameter rho unused with generalized model
> 
> Apparently it cannot run for binomial distributions, and presumably also 
> Poisson.
> 
> I did find a Frequently Asked Questions for package mgcv page that said
> 
> "How can I compare gamm models? In the identity link normal errors case, 
> then AIC and hypotheis testing based methods are fine. Otherwise it is 
> best to work out a strategy based on the summary.gam"
> 
> So putting all this together, I take it that my binomial example will 
> not support a direct model comparison to test the significance of the 
> random effects. I'm guessing the best strategy based on the summary.gam 
> is probably just to compare fit indices like Log Likelihoods.
> 
> If anyone has any other suggestions, though, please do let me know.
> 
> Thanks so much.
> 
> Will Shadish
> 
> On 6/7/2013 3:02 PM, Gavin Simpson wrote:
> > On Fri, 2013-06-07 at 13:12 -0700, William Shadish wrote:
> >> Dear R-helpers,
> >>
> >> I'd like to understand how to test the statistical significance of a
> >> random effect in gamm. I am using gamm because I want to test a model
> >> with an AR(1) error structure, and it is my understanding neither gam
> >> nor gamm4 will do the latter.
> >
> > gamm4() can't yes and out of the box mgcv::gam can't either but
> > see ?magic for an example of correlated errors and how the fits can be
> > manipulated to take the AR(1) (or any structure really as far as I can
> > tell) into account.
> >
> > You might like to look at mgcv::bam() which allows an known AR(1) term
> > but do check that it does what you think; with a random effect spline
> > I'm not at all certain that it will nest the AR(1) in the random effect
> > level.
> >
> > <snip />
> >> Consider, for example, two models, both with AR(1) but one allowing a
> >> random effect on xc:
> >>
> >> g1 <- gamm(y ~ s(xc) +z+ int,family=binomial, weights=trial,
> >> correlation=corAR1())
> >> g2 <- gamm(y ~ s(xc) +z+ int,family=binomial, weights=trial, random =
> >> list(xc=~1),correlation=corAR1())
> >
> > Shouldn't you specify how the AR(1) is nested in the hierarchy here,
> > i.e. AR(1) within xc? maybe I'm not following your data structure
> > correctly.
> >
> >> I include the output for g1 and g2 below, but the question is how to
> >> test the significance of the random effect on xc. I considered a test
> >> comparing the Log-Likelihoods, but have no idea what the degrees of
> >> freedom would be given that s(xc) is smoothed. I also tried:
> >>
> >> anova(g1$gam, g2$gam)
> >
> > gamm() fits via the lme() function of package nlme. To do what you want,
> > you need the anova() method for objects of class "lme", e.g.
> >
> > anova(g1$lme, g2$lme)
> >
> > Then I think you should check if the fits were done via REML and also be
> > aware of the issue of testing wether a variance term is 0.
> >
> >> that did not seem to return anything useful for this question.
> >>
> >> A related question is how to test the significance of adding a second
> >> random effect to a model that already has a random effect, such as:
> >>
> >> g3 <- gamm(y ~ xc +z+ s(int),family=binomial, weights=trial, random =
> >> list(Case=~1, z=~1),correlation=corAR1())
> >> g4 <- gamm(y ~ xc +z+ s(int),family=binomial, weights=trial, random =
> >> list(Case=~1, z=~1, int=~1),correlation=corAR1())
> >
> > Again, I think you need anova() on the $lme components.
> >
> > HTH
> >
> > G
> >
> >> Any help would be appreciated.
> >>
> >> Thanks.
> >>
> >> Will Shadish
> >> ********************************************
> >> g1
> >> $lme
> >> Linear mixed-effects model fit by maximum likelihood
> >>     Data: data
> >>     Log-likelihood: -437.696
> >>     Fixed: fixed
> >> X(Intercept)           Xz         Xint    Xs(xc)Fx1
> >>      0.6738466   -2.5688317    0.0137415   -0.1801294
> >>
> >> Random effects:
> >>    Formula: ~Xr - 1 | g
> >>    Structure: pdIdnot
> >>                    Xr1          Xr2          Xr3 Xr4
> >> Xr5          Xr6          Xr7          Xr8 Residual
> >> StdDev: 0.0004377781 0.0004377781 0.0004377781 0.0004377781 0.0004377781
> >> 0.0004377781 0.0004377781 0.0004377781 1.693177
> >>
> >> Correlation Structure: AR(1)
> >>    Formula: ~1 | g
> >>    Parameter estimate(s):
> >>         Phi
> >> 0.3110725
> >> Variance function:
> >>    Structure: fixed weights
> >>    Formula: ~invwt
> >> Number of Observations: 264
> >> Number of Groups: 1
> >>
> >> $gam
> >>
> >> Family: binomial
> >> Link function: logit
> >>
> >> Formula:
> >> y ~ s(xc) + z + int
> >>
> >> Estimated degrees of freedom:
> >> 1  total = 4
> >>
> >> attr(,"class")
> >> [1] "gamm" "list"
> >> ****************************
> >>   > g2
> >> $lme
> >> Linear mixed-effects model fit by maximum likelihood
> >>     Data: data
> >>     Log-likelihood: -443.9495
> >>     Fixed: fixed
> >> X(Intercept)           Xz         Xint    Xs(xc)Fx1
> >>    0.720018143 -2.562155820  0.003457463 -0.045821030
> >>
> >> Random effects:
> >>    Formula: ~Xr - 1 | g
> >>    Structure: pdIdnot
> >>                    Xr1          Xr2          Xr3 Xr4
> >> Xr5          Xr6          Xr7          Xr8
> >> StdDev: 7.056078e-06 7.056078e-06 7.056078e-06 7.056078e-06 7.056078e-06
> >> 7.056078e-06 7.056078e-06 7.056078e-06
> >>
> >>    Formula: ~1 | xc %in% g
> >>            (Intercept) Residual
> >> StdDev: 6.277279e-05 1.683007
> >>
> >> Correlation Structure: AR(1)
> >>    Formula: ~1 | g/xc
> >>    Parameter estimate(s):
> >>         Phi
> >> 0.1809409
> >> Variance function:
> >>    Structure: fixed weights
> >>    Formula: ~invwt
> >> Number of Observations: 264
> >> Number of Groups:
> >>           g xc %in% g
> >>           1        34
> >>
> >> $gam
> >>
> >> Family: binomial
> >> Link function: logit
> >>
> >> Formula:
> >> y ~ s(xc) + z + int
> >>
> >> Estimated degrees of freedom:
> >> 1  total = 4
> >>
> >> attr(,"class")
> >> [1] "gamm" "list"
> >>
> >>
> >
> 

-- 
Gavin Simpson, PhD                          [t] +1 306 337 8863
Adjunct Professor, Department of Biology    [f] +1 306 337 2410
Institute of Environmental Change & Society [e] gavin.simpson at uregina.ca
523 Research and Innovation Centre          [tw] @ucfagls
University of Regina
Regina, SK S4S 0A2, Canada


From bsmith030465 at gmail.com  Tue Jun 11 19:44:18 2013
From: bsmith030465 at gmail.com (Brian Smith)
Date: Tue, 11 Jun 2013 13:44:18 -0400
Subject: [R] ggplot2 error: "Error in as.environment(where) : 'where' is
	missing"
Message-ID: <CAEQKoCFprV1UUV37t+uAAX0Q5_HPk0aocq53JNFiHBm9C3vd6Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130611/57de4d3d/attachment.pl>

From gunter.berton at gene.com  Tue Jun 11 20:06:59 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 11 Jun 2013 11:06:59 -0700
Subject: [R] ggplot2 error: "Error in as.environment(where) : 'where' is
	missing"
In-Reply-To: <CAEQKoCFprV1UUV37t+uAAX0Q5_HPk0aocq53JNFiHBm9C3vd6Q@mail.gmail.com>
References: <CAEQKoCFprV1UUV37t+uAAX0Q5_HPk0aocq53JNFiHBm9C3vd6Q@mail.gmail.com>
Message-ID: <CACk-te2zbczRkeVReFfnrdsrRHx6i7xA+OzQ7XV9PkB29a1t_A@mail.gmail.com>

I just wanted to point out that the construction:

dataf <- as.data.frame(cbind(Sample,Vals))

is **EVIL** .

Why?
cbind() constructs a matrix out of the separate vectors, and must
coerce columns of different types, as is the case here, to do so (a
matrix must be of one data type). Consequently

> sapply(dataf,class)
  Sample     Vals
"factor" "factor"

## is almost certainly not what is wanted.

The correct way to create the data frame is simply:

> df <- data.frame(Sample, Vals)
> sapply(df, class)
   Sample      Vals
 "factor" "integer"

I have no idea whether the evil construction this is related to your
difficulties, but it couldn't help.

Cheers,
Bert

On Tue, Jun 11, 2013 at 10:44 AM, Brian Smith <bsmith030465 at gmail.com> wrote:
> Hmm...I think it used to work before, but it gives an error now. Here is
> some sample code:
>
> =============
> library(ggplot2)
> Sample <- rep(c('A','B'),rep(10,2))
> Vals <- sample(1:1000,20)
> dataf <- as.data.frame(cbind(Sample,Vals))
> myplot <- ggplot(dataf,aes(x=Vals,colour=Sample)) + geom_density()
> myplot
> =============
>
> I get the following error:
>
> "Error in as.environment(where) : 'where' is missing"
>
> Am I doing something wrong?
>
> thanks!
>
>
>
> **************** sessionInfo() ***************
>
> R version 2.15.2 (2012-10-26)
> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] splines   grid      stats     graphics  grDevices utils     datasets
> methods   base
>
> other attached packages:
>  [1] gridExtra_0.9.1       sm_2.2-4.1            imputation_2.0.1
> locfit_1.5-9          TimeProjection_0.2.0  Matrix_1.0-12
> timeDate_2160.97
>  [8] lubridate_1.2.0       gbm_2.0-8             survival_2.37-4
> gplots_2.11.0         MASS_7.3-23           KernSmooth_2.23-10
> caTools_1.14
> [15] gdata_2.12.0          heatmap.plus_1.3      ggdendro_0.1-12
> ggplot2_0.9.3.1       hgu133a.db_2.7.1      affy_1.34.0
> genefilter_1.38.0
> [22] biomaRt_2.12.0        org.Hs.eg.db_2.7.1    GOstats_2.22.0
> graph_1.34.0          Category_2.22.0       GO.db_2.7.1
> RSQLite_0.11.2
> [29] DBI_0.2-5             geneplotter_1.34.0    lattice_0.20-15
> annotate_1.34.1       AnnotationDbi_1.18.4  Biobase_2.16.0
> BiocGenerics_0.2.0
> [36] colorRamps_2.3        RColorBrewer_1.0-5    sparcl_1.0.3
> gap_1.1-9             plotrix_3.4-6         som_0.3-5
> pvclust_1.2-2
> [43] RobustRankAggreg_1.0  impute_1.30.0         reshape_0.8.4
> plyr_1.8              zoo_1.7-9             data.table_1.8.8
> foreach_1.4.0
> [50] foreign_0.8-53        languageR_1.4         preprocessCore_1.18.0
> gtools_2.7.1          BiocInstaller_1.4.9   hash_2.2.6
>
> loaded via a namespace (and not attached):
>  [1] affyio_1.24.0    bitops_1.0-4.2   codetools_0.2-8  colorspace_1.2-1
> dichromat_2.0-0  digest_0.6.3     GSEABase_1.18.0  gtable_0.1.2
> IRanges_1.14.4
> [10] iterators_1.0.6  labeling_0.1     munsell_0.4      proto_0.3-10
> RBGL_1.32.1      RCurl_1.95-4.1   reshape2_1.2.2   scales_0.2.3
> stats4_2.15.2
> [19] stringr_0.6.2    tools_2.15.2     tree_1.0-33      XML_3.96-1.1
> xtable_1.7-1     zlibbioc_1.2.0
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From davidmarino838 at gmail.com  Tue Jun 11 20:10:04 2013
From: davidmarino838 at gmail.com (Marino David)
Date: Wed, 12 Jun 2013 02:10:04 +0800
Subject: [R] It seams that fast99 function (sensitivity package) does
 not work out for norm distribution.
In-Reply-To: <738553DB-6F11-4557-AA05-28325EDCBB76@comcast.net>
References: <CABmD0bFA0Q_HNQ-4+Z2rKftO=MYtEAjAz7qajKszJ2hK-TQBVA@mail.gmail.com>
	<51B4A3EE.4040901@statistik.tu-dortmund.de>
	<CABmD0bEFKiW6tpZLc0g8der2PJkGaNg1T=+D1oot_haQmKe6HA@mail.gmail.com>
	<738553DB-6F11-4557-AA05-28325EDCBB76@comcast.net>
Message-ID: <CABmD0bF0VUBNYo+iP_cDGrTDckBZH951kzp0omX3PJfyz5J0Ww@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/97a7ed39/attachment.pl>

From mcelis at lightminersystems.com  Tue Jun 11 20:26:23 2013
From: mcelis at lightminersystems.com (Mimi Celis)
Date: Tue, 11 Jun 2013 18:26:23 +0000
Subject: [R] QR factorization for aov
Message-ID: <CDDCB9DE.180D%mcelis@lightminersystems.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130611/d9fab658/attachment.pl>

From smartpink111 at yahoo.com  Tue Jun 11 20:26:03 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 11 Jun 2013 11:26:03 -0700 (PDT)
Subject: [R] ggplot2 error: "Error in as.environment(where) : 'where'
	is	missing"
In-Reply-To: <CAEQKoCFprV1UUV37t+uAAX0Q5_HPk0aocq53JNFiHBm9C3vd6Q@mail.gmail.com>
References: <CAEQKoCFprV1UUV37t+uAAX0Q5_HPk0aocq53JNFiHBm9C3vd6Q@mail.gmail.com>
Message-ID: <1370975163.94463.YahooMailNeo@web142603.mail.bf1.yahoo.com>



Hi,
dataf <- as.data.frame(cbind(Sample,Vals))
?str(dataf)
#'data.frame':??? 20 obs. of? 2 variables:
# $ Sample: Factor w/ 2 levels "A","B": 1 1 1 1 1 1 1 1 1 1 ...
# $ Vals? : Factor w/ 20 levels "121","154","159",..: 20 12 13 1 2 14 18 5 17 10 ...
ggplot(dataf,aes(x=Vals,colour=Sample))+geom_density()
#Error in as.environment(where) : 'where' is missing


dataf<- data.frame(Sample,Vals)
?str(dataf)
#'data.frame':??? 20 obs. of? 2 variables:
# $ Sample: Factor w/ 2 levels "A","B": 1 1 1 1 1 1 1 1 1 1 ...
# $ Vals? : int? 96 712 765 121 154 78 821 258 812 51 ...

ggplot(dataf,aes(x=Vals,colour=Sample))+geom_density() #no error
A.K.




----- Original Message -----
From: Brian Smith <bsmith030465 at gmail.com>
To: r-help Help <r-help at r-project.org>
Cc: 
Sent: Tuesday, June 11, 2013 1:44 PM
Subject: [R] ggplot2 error: "Error in as.environment(where) : 'where' is
	missing"

Hmm...I think it used to work before, but it gives an error now. Here is
some sample code:

=============
library(ggplot2)
Sample <- rep(c('A','B'),rep(10,2))
Vals <- sample(1:1000,20)
dataf <- as.data.frame(cbind(Sample,Vals))
myplot <- ggplot(dataf,aes(x=Vals,colour=Sample)) + geom_density()
myplot
=============

I get the following error:

"Error in as.environment(where) : 'where' is missing"

Am I doing something wrong?

thanks!



**************** sessionInfo() ***************

R version 2.15.2 (2012-10-26)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] splines?  grid? ? ? stats? ?  graphics? grDevices utils? ?  datasets
methods?  base

other attached packages:
[1] gridExtra_0.9.1? ? ?  sm_2.2-4.1? ? ? ? ? ? imputation_2.0.1
locfit_1.5-9? ? ? ? ? TimeProjection_0.2.0? Matrix_1.0-12
timeDate_2160.97
[8] lubridate_1.2.0? ? ?  gbm_2.0-8? ? ? ? ? ?  survival_2.37-4
gplots_2.11.0? ? ? ?  MASS_7.3-23? ? ? ? ?  KernSmooth_2.23-10
caTools_1.14
[15] gdata_2.12.0? ? ? ? ? heatmap.plus_1.3? ? ? ggdendro_0.1-12
ggplot2_0.9.3.1? ? ?  hgu133a.db_2.7.1? ? ? affy_1.34.0
genefilter_1.38.0
[22] biomaRt_2.12.0? ? ? ? org.Hs.eg.db_2.7.1? ? GOstats_2.22.0
graph_1.34.0? ? ? ? ? Category_2.22.0? ? ?  GO.db_2.7.1
RSQLite_0.11.2
[29] DBI_0.2-5? ? ? ? ? ?  geneplotter_1.34.0? ? lattice_0.20-15
annotate_1.34.1? ? ?  AnnotationDbi_1.18.4? Biobase_2.16.0
BiocGenerics_0.2.0
[36] colorRamps_2.3? ? ? ? RColorBrewer_1.0-5? ? sparcl_1.0.3
gap_1.1-9? ? ? ? ? ?  plotrix_3.4-6? ? ? ?  som_0.3-5
pvclust_1.2-2
[43] RobustRankAggreg_1.0? impute_1.30.0? ? ? ?  reshape_0.8.4
plyr_1.8? ? ? ? ? ? ? zoo_1.7-9? ? ? ? ? ?  data.table_1.8.8
foreach_1.4.0
[50] foreign_0.8-53? ? ? ? languageR_1.4? ? ? ?  preprocessCore_1.18.0
gtools_2.7.1? ? ? ? ? BiocInstaller_1.4.9?  hash_2.2.6

loaded via a namespace (and not attached):
[1] affyio_1.24.0? ? bitops_1.0-4.2?  codetools_0.2-8? colorspace_1.2-1
dichromat_2.0-0? digest_0.6.3? ?  GSEABase_1.18.0? gtable_0.1.2
IRanges_1.14.4
[10] iterators_1.0.6? labeling_0.1? ?  munsell_0.4? ? ? proto_0.3-10
RBGL_1.32.1? ? ? RCurl_1.95-4.1?  reshape2_1.2.2?  scales_0.2.3
stats4_2.15.2
[19] stringr_0.6.2? ? tools_2.15.2? ?  tree_1.0-33? ? ? XML_3.96-1.1
xtable_1.7-1? ?  zlibbioc_1.2.0

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From bsmith030465 at gmail.com  Tue Jun 11 20:34:35 2013
From: bsmith030465 at gmail.com (Brian Smith)
Date: Tue, 11 Jun 2013 14:34:35 -0400
Subject: [R] ggplot2 error: "Error in as.environment(where) : 'where' is
	missing"
In-Reply-To: <1370975163.94463.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <CAEQKoCFprV1UUV37t+uAAX0Q5_HPk0aocq53JNFiHBm9C3vd6Q@mail.gmail.com>
	<1370975163.94463.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <CAEQKoCEEq09sbMHESiwO3kFY1sW-ZBsKYzSL19eTpnbPuskU_Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130611/1651b001/attachment.pl>

From smartpink111 at yahoo.com  Tue Jun 11 20:52:11 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 11 Jun 2013 11:52:11 -0700 (PDT)
Subject: [R] Help needed in feature extraction from two input files
Message-ID: <1370976731.67112.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
Try this:
lines1<- readLines(textConnection("gene1 or1|1234 or3|56 or4|793
gene4 or2|347
gene5 or3|23 or7|123456789")) 


lines2<-readLines(textConnection(">or1|1234
ATCGGATTCAGG
>or2|347
GAACCTATCGGGGGGGGAATTTATATATTTTA
>or3|56
ATCGGAGATATAACCAATC
>or3|23
AAAATTAACAAGAGAATAGACAAAAAAA
>or4|793
ATCTCTCTCCTCTCTCTCTAAAAA
>or7|123456789
ACGTGTGTACCCCC"))?

lines2New<-unlist(lapply(split(lines2,(seq_along(lines2)-1)%/%2+1),function(x) paste(x,collapse="\n")),use.names=FALSE)


res<-lapply(lines1,function(x) {x1<- strsplit(x," ")[[1]]; x1New<-x1[-1];x2<-? gsub(">(.*)\\n.*","\\1",lines2New);lines3<-lines2New[match(x1New,x2)];write.table(lines3,paste0(x1[1],".txt"),row.names=FALSE,quote=FALSE)})


Attached is one of the files generated by the code.
A.K.


Hi all, 

I have two input files. First file (file1.txt) contains entries in the following tab delimited format: 

gene1	or1|1234	or3|56	or4|793 
gene4	or2|347 
gene5	or3|23	or7|123456789 

....... 
.. 


The second file (file2.txt) contains some additional features along with the header line of the first file, such as: 

>or1|1234 
ATCGGATTCAGG 
>or2|347 
GAACCTATCGGGGGGGGAATTTA 
TATATTTTA 
>or3|56 
ATCGGAGATATAACCAATC 
>or3|23 
AAAATTAACAAGAGAATAGACAAAAAAA 
>or4|793 
ATCTCTCTCCTCTCTCTCTAAAAA 
>or7|123456789 
ACGTGTGTACCCCC 

.... 
.. 

From these two files, I want to extract entries by row wise 
header matching and rename the output file as the first column in file1.
 For example, in the above case, 3 output files will generate. 

the first output file would named as "gene1.txt" and it contains: 

>or1|1234 
ATCGGATTCAGG 
>or3|56 
ATCGGAGATATAACCAATC 
>or4|793 
ATCTCTCTCCTCTCTCTCTAAAAA 

the second output file would named as "gene4.txt" and it contains: 

>or2|347 
GAACCTATCGGGGGGGGAATTTATATATTTTA 

the third output file would named as "gene5.txt" and it contains: 

>or3|23 
AAAATTAACAAGAGAATAGACAAAAAAA 
>or7|123456789 
ACGTGTGTACCCCC 

Any help in solving the problem is highly appreciated. Thanks in advance. 
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: gene1.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130611/5e8cabf1/attachment.txt>

From tjolitz at gmail.com  Tue Jun 11 17:06:54 2013
From: tjolitz at gmail.com (Thorsten Jolitz)
Date: Tue, 11 Jun 2013 17:06:54 +0200
Subject: [R] Big, complex, well-structured .R file for demonstration?
Message-ID: <87vc5khek1.fsf@gmail.com>


Hi List, 

I'm looking for a rather big, but well structured R file that contains
as much of R language features as possible (i.e. that uses a lot of the
functionality described in the 'R Reference Card' and, if possible, S4
classes too).

I want to check some code I wrote against such a file and use it for
demonstration purposes. However, most .R files I find out there are
rather short without much structure.

Any links to candidate (open source) files would be appreciated. 

-- 
cheers,
Thorsten


From bcrombie at utk.edu  Tue Jun 11 18:18:25 2013
From: bcrombie at utk.edu (bcrombie)
Date: Tue, 11 Jun 2013 09:18:25 -0700 (PDT)
Subject: [R] assigning global columns selection for all subset functions in
 script
Message-ID: <1370967505746-4669252.post@n4.nabble.com>

How do I let R know that I always want to select the same columns in my
subset functions (below), so that I don't have to keep copy/pasting the same
selection? (thanks)
	devUni2 <- subset(devUni1, dind02 != 52,
select=c(paidhre,earnhre,earnwke,uhourse,hourslw,otc,ind02,dind02,occ00,docc00,lfsr94,class94,relref95,smsastat,state,weight,year))
	devUni3 <- subset(devUni2, lfsr94 == 1 | lfsr94 == 2 ,
select=c(paidhre,earnhre,earnwke,uhourse,hourslw,otc,ind02,dind02,occ00,docc00,lfsr94,class94,relref95,smsastat,state,weight,year))
	devUni4 <- subset(devUni3, class94 < 6 ,
select=c(paidhre,earnhre,earnwke,uhourse,hourslw,otc,ind02,dind02,occ00,docc00,lfsr94,class94,relref95,smsastat,state,weight,year))
	devUni5 <- subset(devUni4, relref95 < 10 | relref95 ==13 | relref95 >=14,
select=c(paidhre,earnhre,earnwke,uhourse,hourslw,otc,ind02,dind02,occ00,docc00,lfsr94,class94,relref95,smsastat,state,weight,year))



--
View this message in context: http://r.789695.n4.nabble.com/assigning-global-columns-selection-for-all-subset-functions-in-script-tp4669252.html
Sent from the R help mailing list archive at Nabble.com.


From ajin at iknowtion.com  Tue Jun 11 21:14:45 2013
From: ajin at iknowtion.com (Anhai Jin)
Date: Tue, 11 Jun 2013 15:14:45 -0400
Subject: [R] Package for maximizing likelihood function with EM algorithm
Message-ID: <9E7BC5801884234C82DC9BE021596FE973A6248718@SERVER2008.iknowtion2.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130611/7c7c5fbe/attachment.pl>

From elliepapazisi at gmail.com  Tue Jun 11 17:45:39 2013
From: elliepapazisi at gmail.com (Ellie Papazisi)
Date: Tue, 11 Jun 2013 18:45:39 +0300
Subject: [R] extract common rows from a dataframe
Message-ID: <CA+TrG26Gr_-WyfKyx3+yaaV7Ahz1=SjtgNNP5bpr_+aDa6szcw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130611/1d42259d/attachment.pl>

From er.bikash21 at gmail.com  Tue Jun 11 18:01:26 2013
From: er.bikash21 at gmail.com (Bikash Agrawal)
Date: Tue, 11 Jun 2013 18:01:26 +0200
Subject: [R] Bytes to Numeric/Float conversion
Message-ID: <CAPcYNaR+rw5T0uV7iSYca2QNExMzey9YgJvHE2L7_c_kKFfZsA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130611/4ce44875/attachment.pl>

From ferran.casarramona at gmail.com  Tue Jun 11 16:31:34 2013
From: ferran.casarramona at gmail.com (Ferran Casarramona)
Date: Tue, 11 Jun 2013 16:31:34 +0200
Subject: [R] Caret train with glmnet give me Error "arguments imply
 differing number of rows"
Message-ID: <CACrcp22qc90CJZGV+y2vSYe8g50sGBkyO-hMD0wsPLieZAoa6A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130611/7f006ebf/attachment.pl>

From montana3946 at gmail.com  Tue Jun 11 20:52:49 2013
From: montana3946 at gmail.com (John McDermott)
Date: Tue, 11 Jun 2013 11:52:49 -0700
Subject: [R] help using code
Message-ID: <CDDCC011.270E%montana3946@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130611/347b9d6a/attachment.pl>

From toates19 at gmail.com  Tue Jun 11 18:07:12 2013
From: toates19 at gmail.com (Tom Oates)
Date: Tue, 11 Jun 2013 17:07:12 +0100
Subject: [R] Add a column to a dataframe based on multiple other column
	values
Message-ID: <CAGUdn1CxLfxXNzDWQUo515h_h5qeKFMUyG5MsDb1qn6gBQ7cVg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130611/601fc8a5/attachment.pl>

From kw1958 at gmail.com  Tue Jun 11 22:06:08 2013
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Tue, 11 Jun 2013 16:06:08 -0400
Subject: [R] ggpairs in GGally replaces plotmatrix in ggplot2
In-Reply-To: <486D23F6BB4.00000161jrkrideau@inbox.com>
References: <mailman.27.1370944809.23972.r-help@r-project.org>
	<486D23F6BB4.00000161jrkrideau@inbox.com>
Message-ID: <F851A722-A32F-47CE-978A-A0F73AFE8F32@gmail.com>

John,
Thanks for that. Unfortunately it doesn't reproduce the chart in the plotmatrix call from the original question.

That chart had what looked like densities (I think that is correct as I looked at the plotmatrix code) down the diagonal.

I am not sure which options would give that result in ggpairs.

Thanks again,
KW


--

On Jun 11, 2013, at 10:48 AM, John Kane <jrkrideau at inbox.com> wrote:

> Hi  Keith,,
> ggpairs(dat1, upper = list(continuous = "density", combo = "box"))
> appears to be what you want.
> 
> 
> 
> John Kane
> Kingston ON Canada
> 
> 
>> -----Original Message-----
>> From: kw1958 at gmail.com
>> Sent: Tue, 11 Jun 2013 09:25:48 -0400
>> To: r-help at r-project.org
>> Subject: Re: [R] R-help Digest, Vol 124, Issue 12
>> 
>> Folks,
>> 
>> Sorry for butting in here. I ran the code from John Kane below and it
>> worked fine.
>> 
>> I did however get a deprecation message  suggesting the use of ggpairs
>> from the GGally package to make this chart.
>> 
>> Unfortunately I haven't found the correct incantation to get the diagonal
>> to display the density plots using the "diag" parameter.
>> 
>> Any suggestions?
>> 
>> Just trying to learn,
>> Thanks,
>> KW
>> 
>> --
>> 
>> On Jun 11, 2013, at 6:00 AM, r-help-request at r-project.org wrote:
>> 
>>> Message: 7
>>> Date: Mon, 10 Jun 2013 06:05:48 -0800
>>> From: John Kane <jrkrideau at inbox.com>
>>> To: Gundala Viswanath <gundalav at gmail.com>, "r-help at stat.math.ethz.ch"
>>> 	<r-help at stat.math.ethz.ch>
>>> Subject: Re: [R] All against all correlation matrix with GGPLOT Facet
>>> Message-ID: <3B7B03D1854.000003F5jrkrideau at inbox.com>
>>> Content-Type: text/plain; charset="US-ASCII"
>>> 
>>> No image.  The R-help list tends to strip out a lot of files. A pdf or
>>> txt usually gets through.  In any case I understand what you want this
>>> may do it.
>>> 
>>> library(ggplot2)
>>> dat1  <-  data.frame( v = rnorm(13),
>>> w = rnorm(13),
>>> x = rnorm(13),
>>> y = rnorm(13),
>>> z = rnorm(13))
>>> plotmatrix(dat1)
>>> 
>>> John Kane
>>> Kingston ON Canada
>>> 
>>> 
>>>> -----Original Message-----
>>>> From: gundalav at gmail.com
>>>> Sent: Mon, 10 Jun 2013 12:26:44 +0900
>>>> To: r-help at stat.math.ethz.ch
>>>> Subject: [R] All against all correlation matrix with GGPLOT Facet
>>>> 
>>>> I have the following data:
>>>> 
>>>> v <- rnorm(13)
>>>> w <- rnorm(13)
>>>> x <- rnorm(13)
>>>> y <- rnorm(13)
>>>> z <- rnorm(13)
>>>> 
>>>> 
>>>> Using GGPLOT facet, what I want to do is to create a 5*5 matrix,
>>>> where each cells plot the correlation between
>>>> each pair of the above data. E.g. v-v,v-w; v-x,...,z-z
>>>> 
>>>> 
>>>> What's the way to do it?
>>>> Attached is the image.
>>>> 
>>>> GV.
>>>> ______________
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ____________________________________________________________
> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
> Visit http://www.inbox.com/photosharing to find out more!
> 
> 


From wobbegong85 at gmail.com  Tue Jun 11 17:41:15 2013
From: wobbegong85 at gmail.com (Wobbe Gong)
Date: Tue, 11 Jun 2013 17:41:15 +0200
Subject: [R] 'Boolean Index too long'
Message-ID: <CAAnm=StLu1YNPjzHyCM7ywNaWri2NVXrN0B_MBTEa+3yLvgpSA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130611/bdd93d3f/attachment.pl>

From wshadish at ucmerced.edu  Tue Jun 11 19:08:10 2013
From: wshadish at ucmerced.edu (William Shadish)
Date: Tue, 11 Jun 2013 10:08:10 -0700
Subject: [R] gamm in mgcv random effect significance
In-Reply-To: <1370642549.23179.17.camel@haul.biol.uregina.ca>
References: <51B23EC9.4090109@ucmerced.edu>
	<1370642549.23179.17.camel@haul.biol.uregina.ca>
Message-ID: <51B7597A.9070506@ucmerced.edu>

Gavin et al.,

Thanks so much for the help. Unfortunately, the command

 > anova(g1$lme, g2$lme)

gives "Error in eval(expr, envir, enclos) : object 'fixed' not found

and for bam (which is the one that can use a known ar1 term), the error is

 > AR1 parameter rho unused with generalized model

Apparently it cannot run for binomial distributions, and presumably also 
Poisson.

I did find a Frequently Asked Questions for package mgcv page that said

"How can I compare gamm models? In the identity link normal errors case, 
then AIC and hypotheis testing based methods are fine. Otherwise it is 
best to work out a strategy based on the summary.gam"

So putting all this together, I take it that my binomial example will 
not support a direct model comparison to test the significance of the 
random effects. I'm guessing the best strategy based on the summary.gam 
is probably just to compare fit indices like Log Likelihoods.

If anyone has any other suggestions, though, please do let me know.

Thanks so much.

Will Shadish

On 6/7/2013 3:02 PM, Gavin Simpson wrote:
> On Fri, 2013-06-07 at 13:12 -0700, William Shadish wrote:
>> Dear R-helpers,
>>
>> I'd like to understand how to test the statistical significance of a
>> random effect in gamm. I am using gamm because I want to test a model
>> with an AR(1) error structure, and it is my understanding neither gam
>> nor gamm4 will do the latter.
>
> gamm4() can't yes and out of the box mgcv::gam can't either but
> see ?magic for an example of correlated errors and how the fits can be
> manipulated to take the AR(1) (or any structure really as far as I can
> tell) into account.
>
> You might like to look at mgcv::bam() which allows an known AR(1) term
> but do check that it does what you think; with a random effect spline
> I'm not at all certain that it will nest the AR(1) in the random effect
> level.
>
> <snip />
>> Consider, for example, two models, both with AR(1) but one allowing a
>> random effect on xc:
>>
>> g1 <- gamm(y ~ s(xc) +z+ int,family=binomial, weights=trial,
>> correlation=corAR1())
>> g2 <- gamm(y ~ s(xc) +z+ int,family=binomial, weights=trial, random =
>> list(xc=~1),correlation=corAR1())
>
> Shouldn't you specify how the AR(1) is nested in the hierarchy here,
> i.e. AR(1) within xc? maybe I'm not following your data structure
> correctly.
>
>> I include the output for g1 and g2 below, but the question is how to
>> test the significance of the random effect on xc. I considered a test
>> comparing the Log-Likelihoods, but have no idea what the degrees of
>> freedom would be given that s(xc) is smoothed. I also tried:
>>
>> anova(g1$gam, g2$gam)
>
> gamm() fits via the lme() function of package nlme. To do what you want,
> you need the anova() method for objects of class "lme", e.g.
>
> anova(g1$lme, g2$lme)
>
> Then I think you should check if the fits were done via REML and also be
> aware of the issue of testing wether a variance term is 0.
>
>> that did not seem to return anything useful for this question.
>>
>> A related question is how to test the significance of adding a second
>> random effect to a model that already has a random effect, such as:
>>
>> g3 <- gamm(y ~ xc +z+ s(int),family=binomial, weights=trial, random =
>> list(Case=~1, z=~1),correlation=corAR1())
>> g4 <- gamm(y ~ xc +z+ s(int),family=binomial, weights=trial, random =
>> list(Case=~1, z=~1, int=~1),correlation=corAR1())
>
> Again, I think you need anova() on the $lme components.
>
> HTH
>
> G
>
>> Any help would be appreciated.
>>
>> Thanks.
>>
>> Will Shadish
>> ********************************************
>> g1
>> $lme
>> Linear mixed-effects model fit by maximum likelihood
>>     Data: data
>>     Log-likelihood: -437.696
>>     Fixed: fixed
>> X(Intercept)           Xz         Xint    Xs(xc)Fx1
>>      0.6738466   -2.5688317    0.0137415   -0.1801294
>>
>> Random effects:
>>    Formula: ~Xr - 1 | g
>>    Structure: pdIdnot
>>                    Xr1          Xr2          Xr3 Xr4
>> Xr5          Xr6          Xr7          Xr8 Residual
>> StdDev: 0.0004377781 0.0004377781 0.0004377781 0.0004377781 0.0004377781
>> 0.0004377781 0.0004377781 0.0004377781 1.693177
>>
>> Correlation Structure: AR(1)
>>    Formula: ~1 | g
>>    Parameter estimate(s):
>>         Phi
>> 0.3110725
>> Variance function:
>>    Structure: fixed weights
>>    Formula: ~invwt
>> Number of Observations: 264
>> Number of Groups: 1
>>
>> $gam
>>
>> Family: binomial
>> Link function: logit
>>
>> Formula:
>> y ~ s(xc) + z + int
>>
>> Estimated degrees of freedom:
>> 1  total = 4
>>
>> attr(,"class")
>> [1] "gamm" "list"
>> ****************************
>>   > g2
>> $lme
>> Linear mixed-effects model fit by maximum likelihood
>>     Data: data
>>     Log-likelihood: -443.9495
>>     Fixed: fixed
>> X(Intercept)           Xz         Xint    Xs(xc)Fx1
>>    0.720018143 -2.562155820  0.003457463 -0.045821030
>>
>> Random effects:
>>    Formula: ~Xr - 1 | g
>>    Structure: pdIdnot
>>                    Xr1          Xr2          Xr3 Xr4
>> Xr5          Xr6          Xr7          Xr8
>> StdDev: 7.056078e-06 7.056078e-06 7.056078e-06 7.056078e-06 7.056078e-06
>> 7.056078e-06 7.056078e-06 7.056078e-06
>>
>>    Formula: ~1 | xc %in% g
>>            (Intercept) Residual
>> StdDev: 6.277279e-05 1.683007
>>
>> Correlation Structure: AR(1)
>>    Formula: ~1 | g/xc
>>    Parameter estimate(s):
>>         Phi
>> 0.1809409
>> Variance function:
>>    Structure: fixed weights
>>    Formula: ~invwt
>> Number of Observations: 264
>> Number of Groups:
>>           g xc %in% g
>>           1        34
>>
>> $gam
>>
>> Family: binomial
>> Link function: logit
>>
>> Formula:
>> y ~ s(xc) + z + int
>>
>> Estimated degrees of freedom:
>> 1  total = 4
>>
>> attr(,"class")
>> [1] "gamm" "list"
>>
>>
>

-- 
William R. Shadish
Distinguished Professor
Founding Faculty

Mailing Address:
William R. Shadish
University of California
School of Social Sciences, Humanities and Arts
5200 North Lake Rd
Merced CA  95343

Physical/Delivery Address:
University of California Merced
ATTN: William Shadish
School of Social Sciences, Humanities and Arts
Facilities Services Building A
5200 North Lake Rd.
Merced, CA 95343

209-228-4372 voice
209-228-4007 fax (communal fax: be sure to include cover sheet)
wshadish at ucmerced.edu
http://faculty.ucmerced.edu/wshadish/index.htm
http://psychology.ucmerced.edu


From kw1958 at gmail.com  Tue Jun 11 22:07:29 2013
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Tue, 11 Jun 2013 16:07:29 -0400
Subject: [R] ggpairs in GGally replaces plotmatrix in ggplot2
In-Reply-To: <48ABD695FDD.000001A7jrkrideau@inbox.com>
References: <mailman.27.1370944809.23972.r-help@r-project.org>
	<c34d38dc-2cc9-4b9a-a840-965cfb958963@gmail.com>
	<48ABD695FDD.000001A7jrkrideau@inbox.com>
Message-ID: <B3731B5F-EB81-4901-95C6-2C7634BCE9AC@gmail.com>

Yes. I was able to run it in RStudio but it did seem much slower than in R.app (on the Mac).

Note that the "it" that I ran still didn't give the same results as plotmatrix.

Thanks,
KW

--

On Jun 11, 2013, at 11:16 AM, John Kane <jrkrideau at inbox.com> wrote:

> Note that the code below might not work in RStudio.  I am gettting an intermittant crash when I use the ggpairs() command in RStudio and sometimes I get a density plot and sometimes not.  Also the command is taking 3-5 minutes to execute.  
> 
> This may just be a peculiarity of my machine but the code works fine and fairly fast in a terminal.
> 
> John Kane
> Kingston ON Canada


From sarah.goslee at gmail.com  Tue Jun 11 22:11:19 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 11 Jun 2013 16:11:19 -0400
Subject: [R] Big, complex, well-structured .R file for demonstration?
In-Reply-To: <87vc5khek1.fsf@gmail.com>
References: <87vc5khek1.fsf@gmail.com>
Message-ID: <CAM_vjuk4xmn3T=r-n0wpNA3i8tN31KGW8YDHbDrEq0ZA-OCd8Q@mail.gmail.com>

On Tue, Jun 11, 2013 at 11:06 AM, Thorsten Jolitz <tjolitz at gmail.com> wrote:
>
> Hi List,
>
> I'm looking for a rather big, but well structured R file that contains
> as much of R language features as possible (i.e. that uses a lot of the
> functionality described in the 'R Reference Card' and, if possible, S4
> classes too).

http://cran.r-project.org/web/packages/

I might start with MASS, though I have no idea what "well structured"
means to you.

> I want to check some code I wrote against such a file and use it for
> demonstration purposes. However, most .R files I find out there are
> rather short without much structure.

Your request doesn't make a whole lot of sense to me, but there are so
many thousands of R files on CRAN that there's bound to be something
that makes you happy.

Sarah
-- 
Sarah Goslee
http://www.functionaldiversity.org


From bhh at xs4all.nl  Tue Jun 11 22:14:56 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 11 Jun 2013 22:14:56 +0200
Subject: [R] Package for maximizing likelihood function with EM algorithm
In-Reply-To: <9E7BC5801884234C82DC9BE021596FE973A6248718@SERVER2008.iknowtion2.local>
References: <9E7BC5801884234C82DC9BE021596FE973A6248718@SERVER2008.iknowtion2.local>
Message-ID: <DA92611A-AD37-41B9-8716-42BB4CB58907@xs4all.nl>


On 11-06-2013, at 21:14, Anhai Jin <ajin at iknowtion.com> wrote:

> Hi R users,
> 
> I am trying to figure out if there is a package in R that can maximize likelihood function with EM algorithm. Right now, I have derived the log-likelihood function, which is a function of 9 indicator variables with 14 parameters. Is there a package that I can specify the log-likelihood function, along with all variables and parameters, and will generate estimates?
> 

Have a look at package  SQUAREM


Berend


From sarah.goslee at gmail.com  Tue Jun 11 22:17:33 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 11 Jun 2013 16:17:33 -0400
Subject: [R] 'Boolean Index too long'
In-Reply-To: <CAAnm=StLu1YNPjzHyCM7ywNaWri2NVXrN0B_MBTEa+3yLvgpSA@mail.gmail.com>
References: <CAAnm=StLu1YNPjzHyCM7ywNaWri2NVXrN0B_MBTEa+3yLvgpSA@mail.gmail.com>
Message-ID: <CAM_vju=wBNZx3E1RbRs5FXJFO0W3f0QJC7BmMP=Dbk+nosbemA@mail.gmail.com>

Hi,


On Tue, Jun 11, 2013 at 11:41 AM, Wobbe Gong <wobbegong85 at gmail.com> wrote:
> #Hi, I am trying to run an MRPP with community data (spp-site-matrix). I
> use the following code:
>
> mzbtaxa_mrpp <- mrpp(mzbdist,mzbsites$Site)

Are you using mrpp() from the vegan package? It's good practice to say.

> #mzbdist being a distance object (Bray-Curtis similarity matrix) derived
> from my sqrt transformed community data set, created with function
> 'vegdist', mzbsites$Site refers to factors structuring my community.
>
> #when I run this code, I get the following error message:
>
> error in dmat[ind == x, ind == x] : (subscript) boolean index too long
>
> #What does that mean? How can I solve this problem?

You don't provide a reproducible example, but my first guess is that
your grouping variable is not the same size as your dataset.

You don't tell us how you calculated mzbdist but assuming it's an
object of class dist, is

attributes(mzbdist)$Size

the same as

length(mzbsites$Site)

If not, you have a problem with your data preparation.

Sarah

-- 
Sarah Goslee
http://www.functionaldiversity.org


From gunter.berton at gene.com  Tue Jun 11 22:44:13 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 11 Jun 2013 13:44:13 -0700
Subject: [R] extract common rows from a dataframe
In-Reply-To: <CA+TrG26Gr_-WyfKyx3+yaaV7Ahz1=SjtgNNP5bpr_+aDa6szcw@mail.gmail.com>
References: <CA+TrG26Gr_-WyfKyx3+yaaV7Ahz1=SjtgNNP5bpr_+aDa6szcw@mail.gmail.com>
Message-ID: <CACk-te2dyXWbU6PrCH4LtPJovarg0sBxi9h-DPzUCvmxxA3aKA@mail.gmail.com>

1. What does "common" mean?
(noting that 39.35 != 39.33 )

2. But:
?"["
## or easier, but less flexible
?subset


Also, spend some time with "An Introduction to R."

Unless I misunderstand, this is very basic, and you need to first put
in some time to learn R's basic procedures instead of posting here.

Hint:

> x <- data.frame(a = sample(1:3,10,rep=TRUE), b = sample(letters[1:10],10))
> x[x$a == 3,]

Cheers,
Bert

On Tue, Jun 11, 2013 at 8:45 AM, Ellie Papazisi <elliepapazisi at gmail.com> wrote:
> Hello, I'm trying to extract the common rows from a data frame, which is
> something like this :
>
>
> *   DEPTH SALINITY DEPTH SALINITY*
> *18    87    39.06    94    39.06*
> *19   173    39.05   141       NA*
> *20   260    39.00   188    39.07*
> *21   312    38.97   207    39.03*
> *22     1    39.36     1    39.35*
> *23    10    39.36    10    39.33*
> *24    20    39.36    20    39.33*
> *25    30    39.35    30    39.33*
> *
> *
> i want to extract the rows with the same depth.
> i cannot do something like *data.frame[22:25,]* because i have lots of rows
>
> any help?
> thank you
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From dwinsemius at comcast.net  Tue Jun 11 22:45:29 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 11 Jun 2013 13:45:29 -0700
Subject: [R] ggplot2 error: "Error in as.environment(where) : 'where' is
	missing"
In-Reply-To: <CAEQKoCFprV1UUV37t+uAAX0Q5_HPk0aocq53JNFiHBm9C3vd6Q@mail.gmail.com>
References: <CAEQKoCFprV1UUV37t+uAAX0Q5_HPk0aocq53JNFiHBm9C3vd6Q@mail.gmail.com>
Message-ID: <508DC783-FF8B-4287-94FF-A4E5DD7D6DBA@comcast.net>


On Jun 11, 2013, at 10:44 AM, Brian Smith wrote:

> Hmm...I think it used to work before, but it gives an error now. Here is
> some sample code:
> 
> =============
> library(ggplot2)
> Sample <- rep(c('A','B'),rep(10,2))
> Vals <- sample(1:1000,20)
> dataf <- as.data.frame(cbind(Sample,Vals))

It's _almost_always_ incorrect to do:  as.data.frame(cbind(anything))

No error with:

dataf <- data.frame(Sample,Vals)

> myplot <- ggplot(dataf,aes(x=Vals,colour=Sample)) + geom_density()
> myplot
> =============
> 
> I get the following error:
> 
> "Error in as.environment(where) : 'where' is missing"
> 
> Am I doing something wrong?
> 
> thanks!
> 
> 
> 
> **************** sessionInfo() ***************
> 
> R version 2.15.2 (2012-10-26)
> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] splines   grid      stats     graphics  grDevices utils     datasets
> methods   base
> 
> other attached packages:
> [1] gridExtra_0.9.1       sm_2.2-4.1            imputation_2.0.1
> locfit_1.5-9          TimeProjection_0.2.0  Matrix_1.0-12
> timeDate_2160.97
> [8] lubridate_1.2.0       gbm_2.0-8             survival_2.37-4
> gplots_2.11.0         MASS_7.3-23           KernSmooth_2.23-10
> caTools_1.14
> [15] gdata_2.12.0          heatmap.plus_1.3      ggdendro_0.1-12
> ggplot2_0.9.3.1       hgu133a.db_2.7.1      affy_1.34.0
> genefilter_1.38.0
> [22] biomaRt_2.12.0        org.Hs.eg.db_2.7.1    GOstats_2.22.0
> graph_1.34.0          Category_2.22.0       GO.db_2.7.1
> RSQLite_0.11.2
> [29] DBI_0.2-5             geneplotter_1.34.0    lattice_0.20-15
> annotate_1.34.1       AnnotationDbi_1.18.4  Biobase_2.16.0
> BiocGenerics_0.2.0
> [36] colorRamps_2.3        RColorBrewer_1.0-5    sparcl_1.0.3
> gap_1.1-9             plotrix_3.4-6         som_0.3-5
> pvclust_1.2-2
> [43] RobustRankAggreg_1.0  impute_1.30.0         reshape_0.8.4
> plyr_1.8              zoo_1.7-9             data.table_1.8.8
> foreach_1.4.0
> [50] foreign_0.8-53        languageR_1.4         preprocessCore_1.18.0
> gtools_2.7.1          BiocInstaller_1.4.9   hash_2.2.6
> 
> loaded via a namespace (and not attached):
> [1] affyio_1.24.0    bitops_1.0-4.2   codetools_0.2-8  colorspace_1.2-1
> dichromat_2.0-0  digest_0.6.3     GSEABase_1.18.0  gtable_0.1.2
> IRanges_1.14.4
> [10] iterators_1.0.6  labeling_0.1     munsell_0.4      proto_0.3-10
> RBGL_1.32.1      RCurl_1.95-4.1   reshape2_1.2.2   scales_0.2.3
> stats4_2.15.2
> [19] stringr_0.6.2    tools_2.15.2     tree_1.0-33      XML_3.96-1.1
> xtable_1.7-1     zlibbioc_1.2.0
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jrkrideau at inbox.com  Tue Jun 11 22:46:35 2013
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 11 Jun 2013 12:46:35 -0800
Subject: [R] ggpairs in GGally replaces plotmatrix in ggplot2
In-Reply-To: <F851A722-A32F-47CE-978A-A0F73AFE8F32@gmail.com>
References: <mailman.27.1370944809.23972.r-help@r-project.org>
	<486d23f6bb4.00000161jrkrideau@inbox.com>
Message-ID: <4B8D7B42116.00000654jrkrideau@inbox.com>

I don't think I understand exactly what you want. Can you resent the attachment perhaps as a png or pdf file?

And you're right it does not recreate the plotmatrix plot.  I find the ggpairs output less than completely intuitive but I may be okay with it in a while.  

OTOH I may have to ask RStudio about the speed and crashes.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: kw1958 at gmail.com
> Sent: Tue, 11 Jun 2013 16:06:08 -0400
> To: jrkrideau at inbox.com
> Subject: Re: ggpairs in GGally replaces plotmatrix in ggplot2
> 
> John,
> Thanks for that. Unfortunately it doesn't reproduce the chart in the
> plotmatrix call from the original question.
> 
> That chart had what looked like densities (I think that is correct as I
> looked at the plotmatrix code) down the diagonal.
> 
> I am not sure which options would give that result in ggpairs.
> 
> Thanks again,
> KW
> 
> 
> --
> 
> On Jun 11, 2013, at 10:48 AM, John Kane <jrkrideau at inbox.com> wrote:
> 
>> Hi  Keith,,
>> ggpairs(dat1, upper = list(continuous = "density", combo = "box"))
>> appears to be what you want.
>> 
>> 
>> 
>> John Kane
>> Kingston ON Canada
>> 
>> 
>>> -----Original Message-----
>>> From: kw1958 at gmail.com
>>> Sent: Tue, 11 Jun 2013 09:25:48 -0400
>>> To: r-help at r-project.org
>>> Subject: Re: [R] R-help Digest, Vol 124, Issue 12
>>> 
>>> Folks,
>>> 
>>> Sorry for butting in here. I ran the code from John Kane below and it
>>> worked fine.
>>> 
>>> I did however get a deprecation message  suggesting the use of ggpairs
>>> from the GGally package to make this chart.
>>> 
>>> Unfortunately I haven't found the correct incantation to get the
>>> diagonal
>>> to display the density plots using the "diag" parameter.
>>> 
>>> Any suggestions?
>>> 
>>> Just trying to learn,
>>> Thanks,
>>> KW
>>> 
>>> --
>>> 
>>> On Jun 11, 2013, at 6:00 AM, r-help-request at r-project.org wrote:
>>> 
>>>> Message: 7
>>>> Date: Mon, 10 Jun 2013 06:05:48 -0800
>>>> From: John Kane <jrkrideau at inbox.com>
>>>> To: Gundala Viswanath <gundalav at gmail.com>, "r-help at stat.math.ethz.ch"
>>>> 	<r-help at stat.math.ethz.ch>
>>>> Subject: Re: [R] All against all correlation matrix with GGPLOT Facet
>>>> Message-ID: <3B7B03D1854.000003F5jrkrideau at inbox.com>
>>>> Content-Type: text/plain; charset="US-ASCII"
>>>> 
>>>> No image.  The R-help list tends to strip out a lot of files. A pdf or
>>>> txt usually gets through.  In any case I understand what you want this
>>>> may do it.
>>>> 
>>>> library(ggplot2)
>>>> dat1  <-  data.frame( v = rnorm(13),
>>>> w = rnorm(13),
>>>> x = rnorm(13),
>>>> y = rnorm(13),
>>>> z = rnorm(13))
>>>> plotmatrix(dat1)
>>>> 
>>>> John Kane
>>>> Kingston ON Canada
>>>> 
>>>> 
>>>>> -----Original Message-----
>>>>> From: gundalav at gmail.com
>>>>> Sent: Mon, 10 Jun 2013 12:26:44 +0900
>>>>> To: r-help at stat.math.ethz.ch
>>>>> Subject: [R] All against all correlation matrix with GGPLOT Facet
>>>>> 
>>>>> I have the following data:
>>>>> 
>>>>> v <- rnorm(13)
>>>>> w <- rnorm(13)
>>>>> x <- rnorm(13)
>>>>> y <- rnorm(13)
>>>>> z <- rnorm(13)
>>>>> 
>>>>> 
>>>>> Using GGPLOT facet, what I want to do is to create a 5*5 matrix,
>>>>> where each cells plot the correlation between
>>>>> each pair of the above data. E.g. v-v,v-w; v-x,...,z-z
>>>>> 
>>>>> 
>>>>> What's the way to do it?
>>>>> Attached is the image.
>>>>> 
>>>>> GV.
>>>>> ______________
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ____________________________________________________________
>> FREE ONLINE PHOTOSHARING - Share your photos online with your friends
>> and family!
>> Visit http://www.inbox.com/photosharing to find out more!
>> 
>>

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From smartpink111 at yahoo.com  Tue Jun 11 22:54:58 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 11 Jun 2013 13:54:58 -0700 (PDT)
Subject: [R] extract common rows from a dataframe
In-Reply-To: <CA+TrG26Gr_-WyfKyx3+yaaV7Ahz1=SjtgNNP5bpr_+aDa6szcw@mail.gmail.com>
References: <CA+TrG26Gr_-WyfKyx3+yaaV7Ahz1=SjtgNNP5bpr_+aDa6szcw@mail.gmail.com>
Message-ID: <1370984098.37452.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Try this:
dat1<- read.table(text="
DEPTH SALINITY DEPTH SALINITY
18??? 87??? 39.06??? 94??? 39.06
19? 173??? 39.05? 141????? NA
20? 260??? 39.00? 188??? 39.07
21? 312??? 38.97? 207??? 39.03
22??? 1??? 39.36??? 1??? 39.35
23??? 10??? 39.36??? 10??? 39.33
24??? 20??? 39.36??? 20??? 39.33
25??? 30??? 39.35??? 30??? 39.33
",sep="",header=TRUE)

library(matrixStats)
res<-dat1[rowDiffs(as.matrix(dat1[,c(1,3)]))==0,]
res
#?? DEPTH SALINITY DEPTH.1 SALINITY.1
#22???? 1??? 39.36?????? 1????? 39.35
#23??? 10??? 39.36????? 10????? 39.33
#24??? 20??? 39.36????? 20????? 39.33
#25??? 30??? 39.35????? 30????? 39.33


#or
dat1[apply(dat1,1,function(x) x[1]-x[3]==0),]
#?? DEPTH SALINITY DEPTH.1 SALINITY.1
#22???? 1??? 39.36?????? 1????? 39.35
#23??? 10??? 39.36????? 10????? 39.33
#24??? 20??? 39.36????? 20????? 39.33
#25??? 30??? 39.35????? 30????? 39.33
A.K.



----- Original Message -----
From: Ellie Papazisi <elliepapazisi at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Tuesday, June 11, 2013 11:45 AM
Subject: [R] extract common rows from a dataframe

Hello, I'm trying to extract the common rows from a data frame, which is
something like this :


*?  DEPTH SALINITY DEPTH SALINITY*
*18? ? 87? ? 39.06? ? 94? ? 39.06*
*19?  173? ? 39.05?  141? ? ?  NA*
*20?  260? ? 39.00?  188? ? 39.07*
*21?  312? ? 38.97?  207? ? 39.03*
*22? ?  1? ? 39.36? ?  1? ? 39.35*
*23? ? 10? ? 39.36? ? 10? ? 39.33*
*24? ? 20? ? 39.36? ? 20? ? 39.33*
*25? ? 30? ? 39.35? ? 30? ? 39.33*
*
*
i want to extract the rows with the same depth.
i cannot do something like *data.frame[22:25,]* because i have lots of rows

any help?
thank you

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Tue Jun 11 23:09:45 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 11 Jun 2013 14:09:45 -0700 (PDT)
Subject: [R] Combining CSV data
In-Reply-To: <CALFKK3yYMZYMA_pjPTme2U_F9VZq-mc85CMUqBjXNU26sTQr6w@mail.gmail.com>
References: <CALFKK3xTtutDvi12LpSp4M6hyn0bFR1-Z+7aWMTA6AT8xWG5mA@mail.gmail.com>
	<1370904118.98031.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1370916881.76218.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<CALFKK3zsGycu_yzqM6D1J8fD1px35+ypABQo-K9DXkOhQNSCWg@mail.gmail.com>
	<1370970132.53955.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CALFKK3yYMZYMA_pjPTme2U_F9VZq-mc85CMUqBjXNU26sTQr6w@mail.gmail.com>
Message-ID: <1370984985.52466.YahooMailNeo@web142602.mail.bf1.yahoo.com>




HI,
You could use:
result3<- data.frame(result2[,-5],read.table(text=as.character(result2$comment),sep="|",fill=TRUE,na.strings=""),stringsAsFactors=FALSE)
colnames(result3)[5:7]<- paste0("DataComment",1:3)
A.K.
________________________________
From: Shreya Rawal <rawal.shreya at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Tuesday, June 11, 2013 4:22 PM
Subject: Re: [R] Combining CSV data



Hey Arun,

I guess you could guide me with this a little bit. I have been working on the solution Jim suggested (and also because that I could understand it with my little knowledge of R :))

So with these commands I am able to get the data in this format:

> fileA <- read.csv(text = "Row_ID_CR, ? Data1, ? ?Data2, ? ?Data3
+ 1, ? ? ? ? ? ? ? ? ? aa, ? ? ? ? ?bb, ? ? ? ? ?cc
+ 2, ? ? ? ? ? ? ? ? ? dd, ? ? ? ? ?ee, ? ? ? ? ?ff",?as.is?= TRUE)
>?
> fileB <- read.csv(text = "Row_ID_N, ? Src_Row_ID, ? DataN1
+ 1a, ? ? ? ? ? ? ? 1, ? ? ? ? ? ? ? ? ? This is comment 1
+ 2a, ? ? ? ? ? ? ? 1, ? ? ? ? ? ? ? ? ? This is comment 2
+ 3a, ? ? ? ? ? ? ? 2, ? ? ? ? ? ? ? ? ? This is comment 1
+ 4a, ? ? ? ? ? ? ? 1, ? ? ? ? ? ? ? ? ? This is comment 3",?as.is?= TRUE)
>?
> # get rid of leading/trailing blanks on comments
> fileB$DataN1 <- gsub("^ *| *$", "", fileB$DataN1)
>?
> # merge together
> result <- merge(fileA, fileB, by.x = 'Row_ID_CR', by.y = "Src_Row_ID")
>?
> # now partition by Row_ID_CR and aggregate the comments
> result2 <- do.call(rbind,?
+ ? ? lapply(split(result, result$Row_ID_CR), function(.grp){
+ ? ? ? ? cbind(.grp[1L, -c(5,6)], comment = paste(.grp$DataN1, collapse = '|'))
+ ? ? })
+ )

Row_ID_CR ? ? ? ? ? ? ? ? Data1 ? ? ? ?Data2 ? ? ? ?Data3 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? comment
1 ? ? ? ? 1 ? ? ? ? ? ? ? ? ? ?aa ? ? ? ? ? bb ? ? ? ? ? cc ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?This is comment 1| This is comment 2| This is comment 3
2 ? ? ? ? 2 ? ? ? ? ? ? ? ? ? ?dd ? ? ? ? ? ee ? ? ? ? ? ff ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?This is comment 1| This is Comment 2

I can even split the last column by this:?strsplit(as.character(result2$comment), split='\\|')

[[1]]
[1] "This is comment 1" "This is comment 2" " This is comment 3"

[[2]]
[1] "This is comment 1" "This is comment 2"


but now I am not sure how to combine everything together. I guess by now you must have realized how new I am to R :)

Thanks!!
Shreya






On Tue, Jun 11, 2013 at 1:02 PM, arun <smartpink111 at yahoo.com> wrote:

Hi,
>If the dataset is like this with the comments in the order:
>
>dat2<-read.table(text="
>Row_ID_N,? Src_Row_ID,? DataN1
>1a,????????????? 1,????????????????? This is comment 1
>2a,????????????? 1,????????????????? This is comment 2
>3a,????????????? 2,????????????????? This is comment 1
>4a,????????????? 1,????????????????? This is comment 3
>",sep=",",header=TRUE,stringsAsFactors=FALSE)
>
>dat3<-read.table(text="
>Row_ID_N,? Src_Row_ID,? DataN1
>1a,????????????? 1,????????????????? This is comment 1
>2a,????????????? 1,????????????????? This is comment 2
>3a,????????????? 2,????????????????? This is comment 1?? #
>
>4a,????????????? 1,????????????????? This is comment 3
>5a,???????? 2,????????????????? This is comment 2? #
>
>",sep=",",header=TRUE,stringsAsFactors=FALSE)
>
>
>library(stringr)
>library(plyr)
>fun1<- function(data1,data2){
>??? data2$DataN1<- str_trim(data2$DataN1)??
>??????? res<- merge(data1,data2,by.x=1,by.y=2)
>??? res1<- res[,-5]
>??? res2<- ddply(res1,.(Row_ID_CR,Data1,Data2,Data3),summarize,DataN1=list(DataN1))
>??? Mx1<- max(sapply(res2[,5],length))
>??? res3<- data.frame(res2[,-5],do.call(rbind,lapply(res2[,5],function(x){
>????????????????????????????????? c(x,rep(NA,Mx1-length(x)))
>
>????????????????????????????????? })),stringsAsFactors=FALSE)
>??? colnames(res3)[grep("X",colnames(res3))]<- paste0("DataComment",gsub("[[:alpha:]]","",colnames(res3)[grep("X",colnames(res3))]))
>??? res3
>??? }???
>
>?????
>fun1(dat1,dat2)
>#? Row_ID_CR??????????????? Data1??????? Data2??????? Data3????? DataComment1
>#1???????? 1?????????????????? aa?????????? bb?????????? cc This is comment 1
>
>#2???????? 2?????????????????? dd?????????? ee?????????? ff This is comment 1
>#?????? DataComment2????? DataComment3
>#1 This is comment 2 This is comment 3
>#2????????????? <NA>????????????? <NA>
>
>?fun1(dat1,dat3)
>#? Row_ID_CR??????????????? Data1??????? Data2??????? Data3????? DataComment1
>#1???????? 1?????????????????? aa?????????? bb?????????? cc This is comment 1
>
>#2???????? 2?????????????????? dd?????????? ee?????????? ff This is comment 1
>?# ???? DataComment2????? DataComment3
>#1 This is comment 2 This is comment 3
>
>#2 This is comment 2????????????? <NA>
>
>
>Otherwise, you need to provide an example that matches the real dataset.
>A.K.
>
>________________________________
>From: Shreya Rawal <rawal.shreya at gmail.com>
>To: arun <smartpink111 at yahoo.com>
>Cc: R help <r-help at r-project.org>
>Sent: Tuesday, June 11, 2013 12:22 PM
>
>Subject: Re: [R] Combining CSV data
>
>
>
>Hi Arun,
>
>Thanks for your reply. Unfortunately the Comments are just text in the real data. There is no way to differentiate based on the value of the Comments column. I guess because of that reason I couldn't get your solution to work properly. Do you think I can try it for a more general case where we don't merger/split the comments based on the values?
>
>Thanks for your help, I appreciate! ??
>
>
>
>On Mon, Jun 10, 2013 at 10:14 PM, arun <smartpink111 at yahoo.com> wrote:
>
>HI,
>>I am not sure about your DataN1 column.? If there is any identifier to differentiate the comments (in this case 1,2,3), then it will easier to place that in the correct column.
>>? My previous solution is not helpful in situations like these:
>>
>>dat2<-read.table(text="
>>Row_ID_N,? Src_Row_ID,? DataN1
>>1a,????????????? 1,????????????????? This is comment 1
>>2a,????????????? 1,????????????????? This is comment 2
>>3a,????????????? 2,????????????????? This is comment 2
>>4a,????????????? 1,????????????????? This is comment 3
>>",sep=",",header=TRUE,stringsAsFactors=FALSE)
>>dat3<-read.table(text="
>>
>>Row_ID_N,? Src_Row_ID,? DataN1
>>1a,????????????? 1,????????????????? This is comment 1
>>2a,????????????? 1,????????????????? This is comment 2
>>3a,????????????? 2,????????????????? This is comment 3
>>4a,????????????? 1,????????????????? This is comment 3
>>5a,??? ??? ?2,????????????????? This is comment 2
>>",sep=",",header=TRUE,stringsAsFactors=FALSE)
>>
>>
>>library(stringr)
>>library(plyr)
>>fun1<- function(data1,data2){
>>??? data2$DataN1<- str_trim(data2$DataN1)???
>>??????? res<- merge(data1,data2,by.x=1,by.y=2)
>>??? res1<- res[,-5]
>>??? res2<- ddply(res1,.(Row_ID_CR,Data1,Data2,Data3),summarize,DataN1=list(DataN1))
>>??? Mx1<- max(sapply(res2[,5],length))
>>??? res3<- data.frame(res2[,-5],do.call(rbind,lapply(res2[,5],function(x){
>>??? ??? ??? ??? ??? ??? ??? ??? ? indx<- as.numeric(gsub("[[:alpha:]]","",x))
>>??? ??? ??? ??? ??? ??? ??? ??? ? x[match(seq(Mx1),indx)]
>>??? ??? ??? ??? ??? ??? ??? ??? ? })),stringsAsFactors=FALSE)
>>
>>??? colnames(res3)[grep("X",colnames(res3))]<- paste0("DataComment",gsub("[[:alpha:]]","",colnames(res3)[grep("X",colnames(res3))]))
>>??? res3
>>??? }??? ??? ??
>>fun1(dat1,dat2)
>>
>>#? Row_ID_CR??????????????? Data1??????? Data2??????? Data3????? DataComment1
>>#1???????? 1?????????????????? aa?????????? bb?????????? cc This is comment 1
>>#2???????? 2?????????????????? dd?????????? ee?????????? ff????????????? <NA>
>>
>>#?????? DataComment2????? DataComment3
>>#1 This is comment 2 This is comment 3
>>#2 This is comment 2????????????? <NA>
>>?fun1(dat1,dat3)
>>
>>#? Row_ID_CR??????????????? Data1??????? Data2??????? Data3????? DataComment1
>>#1???????? 1?????????????????? aa?????????? bb?????????? cc This is comment 1
>>#2???????? 2?????????????????? dd?????????? ee?????????? ff????????????? <NA>
>>
>>#?????? DataComment2????? DataComment3
>>#1 This is comment 2 This is comment 3
>>#2 This is comment 2 This is comment 3
>>
>>
>>
>>A.K.
>>
>>
>>----- Original Message -----
>>
>>From: arun <smartpink111 at yahoo.com>
>>To: Shreya Rawal <rawal.shreya at gmail.com>
>>Cc: R help <r-help at r-project.org>
>>Sent: Monday, June 10, 2013 6:41 PM
>>Subject: Re: [R] Combining CSV data
>>
>>Hi,
>>Try this:
>>
>>dat1<-read.table(text="
>>Row_ID_CR,? Data1,??? Data2,??? Data3
>>1,????????????????? aa,????????? bb,????????? cc
>>2,????????????????? dd,????????? ee,????????? ff
>>",sep=",",header=TRUE,stringsAsFactors=FALSE)
>>
>>dat2<-read.table(text="
>>Row_ID_N,? Src_Row_ID,? DataN1
>>1a,????????????? 1,????????????????? This is comment 1
>>2a,????????????? 1,????????????????? This is comment 2
>>3a,????????????? 2,????????????????? This is comment 1
>>4a,????????????? 1,????????????????? This is comment 3
>>",sep=",",header=TRUE,stringsAsFactors=FALSE)
>>library(stringr)
>>dat2$DataN1<-str_trim(dat2$DataN1)
>>res<- merge(dat1,dat2,by.x=1,by.y=2)
>>?res1<-res[,-5]
>>library(plyr)
>>?res2<-ddply(res1,.(Row_ID_CR,Data1,Data2,Data3),summarize, DataN1=list(DataN1))
>>?res2
>>?# Row_ID_CR??????????????? Data1??????? Data2??????? Data3
>>#1???????? 1?????????????????? aa?????????? bb?????????? cc
>>#2???????? 2?????????????????? dd?????????? ee?????????? ff
>>#?????????????????????????????????????????????????? DataN1
>>#1 This is comment 1, This is comment 2, This is comment 3
>>#2?????????????????????????????????????? This is comment 1
>>
>>
>>
>>res3<-data.frame(res2[,-5],t(apply(do.call(rbind,res2[,5]),1,function(x) {x[duplicated(x)]<-NA;x})))
>>?colnames(res3)[grep("X",colnames(res3))]<- paste0("DataComment",gsub("[[:alpha:]]","",colnames(res3)[grep("X",colnames(res3))]))
>>res3
>>#? Row_ID_CR??????????????? Data1??????? Data2??????? Data3????? DataComment1
>>#1???????? 1?????????????????? aa?????????? bb?????????? cc This is comment 1
>>#2???????? 2?????????????????? dd?????????? ee?????????? ff This is comment 1
>>#?????? DataComment2????? DataComment3
>>#1 This is comment 2 This is comment 3
>>#2????????????? <NA>????????????? <NA>
>>
>>A.K.
>>
>>
>>----- Original Message -----
>>From: Shreya Rawal <rawal.shreya at gmail.com>
>>To: r-help at r-project.org
>>Cc:
>>Sent: Monday, June 10, 2013 4:38 PM
>>Subject: [R] Combining CSV data
>>
>>Hello R community,
>>
>>I am trying to combine two CSV files that look like this:
>>
>>File A
>>
>>Row_ID_CR,?? Data1,? ? Data2,? ? Data3
>>1,? ? ? ? ? ? ? ? ?? aa,? ? ? ? ? bb,? ? ? ? ? cc
>>2,? ? ? ? ? ? ? ? ?? dd,? ? ? ? ? ee,? ? ? ? ? ff
>>
>>
>>File B
>>
>>Row_ID_N,?? Src_Row_ID,?? DataN1
>>1a,? ? ? ? ? ? ?? 1,? ? ? ? ? ? ? ? ?? This is comment 1
>>2a,? ? ? ? ? ? ?? 1,? ? ? ? ? ? ? ? ?? This is comment 2
>>3a,? ? ? ? ? ? ?? 2,? ? ? ? ? ? ? ? ?? This is comment 1
>>4a,? ? ? ? ? ? ?? 1,? ? ? ? ? ? ? ? ?? This is comment 3
>>
>>And the output I am looking for is, comparing the values of Row_ID_CR and
>>Src_Row_ID
>>
>>Output
>>
>>ROW_ID_CR,? ? Data1,? ? Data2,? ? Data3,? ? DataComment1,
>>DataComment2,? ? ? ? ? DataComment3
>>1,? ? ? ? ? ? ? ? ? ? ? aa,? ? ? ?? bb,? ? ? ?? cc,? ? ? ? This is
>>comment1,? ? This is comment2,? ?? This is comment 3
>>2,? ? ? ? ? ? ? ? ? ? ? dd,? ? ? ? ? ee,? ? ? ?? ff,? ? ? ? ? This is
>>comment1
>>
>>
>>I am a novice R user, I am able to replicate a left join but I need a bit
>>more in the final result.
>>
>>
>>Thanks!!
>>
>>??? [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>>
>>
>


From dwinsemius at comcast.net  Tue Jun 11 23:14:53 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 11 Jun 2013 14:14:53 -0700
Subject: [R] Bytes to Numeric/Float conversion
In-Reply-To: <CAPcYNaR+rw5T0uV7iSYca2QNExMzey9YgJvHE2L7_c_kKFfZsA@mail.gmail.com>
References: <CAPcYNaR+rw5T0uV7iSYca2QNExMzey9YgJvHE2L7_c_kKFfZsA@mail.gmail.com>
Message-ID: <EF554462-F61C-4DBE-BDF4-8D21F34C9386@comcast.net>


On Jun 11, 2013, at 9:01 AM, Bikash Agrawal wrote:

> Is there any packages available in R, that can convert Bytes array to Float.
> Using rJava we can do it. But it is kind of slow. Is there any R
> specific packages.
> I am having problem converting my bytes array to floating point.
> Could any one help me with this problem.

There is a raw data type that is designed to hold bytes than can be indexed.

?raw

`scan` can read files of type raw

?scan

-- 

David Winsemius
Alameda, CA, USA


From cassiejones26 at gmail.com  Tue Jun 11 23:18:59 2013
From: cassiejones26 at gmail.com (cassie jones)
Date: Tue, 11 Jun 2013 16:18:59 -0500
Subject: [R] simulation from truncated skew normal
Message-ID: <CAFkmApPJ7M-JuUfAVntvxof6tSQk8c=RdJ==nGNpshLdeN7TGQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130611/8ae48fb6/attachment.pl>

From hb at biostat.ucsf.edu  Tue Jun 11 23:21:19 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 11 Jun 2013 14:21:19 -0700
Subject: [R] Bytes to Numeric/Float conversion
In-Reply-To: <EF554462-F61C-4DBE-BDF4-8D21F34C9386@comcast.net>
References: <CAPcYNaR+rw5T0uV7iSYca2QNExMzey9YgJvHE2L7_c_kKFfZsA@mail.gmail.com>
	<EF554462-F61C-4DBE-BDF4-8D21F34C9386@comcast.net>
Message-ID: <CAFDcVCSTvCxyY05eeybwBh3ULcTRHv7NxXSbVtuAZTbNrkUSYQ@mail.gmail.com>

On Tue, Jun 11, 2013 at 2:14 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Jun 11, 2013, at 9:01 AM, Bikash Agrawal wrote:
>
>> Is there any packages available in R, that can convert Bytes array to Float.
>> Using rJava we can do it. But it is kind of slow. Is there any R
>> specific packages.
>> I am having problem converting my bytes array to floating point.
>> Could any one help me with this problem.
>
> There is a raw data type that is designed to hold bytes than can be indexed.
>
> ?raw

...and then ?readBin

/Henrik
>
> `scan` can read files of type raw
>
> ?scan
>
> --
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue Jun 11 23:21:55 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 11 Jun 2013 14:21:55 -0700
Subject: [R] assigning global columns selection for all subset functions
	in script
In-Reply-To: <1370967505746-4669252.post@n4.nabble.com>
References: <1370967505746-4669252.post@n4.nabble.com>
Message-ID: <A87EA6DC-7C50-42A2-A38D-23E137290FC2@comcast.net>


On Jun 11, 2013, at 9:18 AM, bcrombie wrote:

> How do I let R know that I always want to select the same columns in my
> subset functions (below), so that I don't have to keep copy/pasting the same
> selection? (thanks)
> 	devUni2 <- subset(devUni1, dind02 != 52,
> select=c(paidhre,earnhre,earnwke,uhourse,hourslw,otc,ind02,dind02,occ00,docc00,lfsr94,class94,relref95,smsastat,state,weight,year))

Perhaps: 

	devUni3 <- subset(devUni2, lfsr94 == 1 | lfsr94 == 2 ,
select=names(devUni2) )

Or just create a character vector:

desired <- names(devUni2)
devUni3 <- subset(devUni2, lfsr94 == 1 | lfsr94 == 2 , select=desired )

Because I am lazy I exprimented a bit to avoid adding all those quote marks:

desired <- expression(paidhre, earnhre,earnwke,uhourse,hourslw,otc,ind02, dind02,occ00,docc00,lfsr94,class94,relref95,smsastat,state,weight,year)

as.character(as.list(desired))
 [1] "paidhre"  "earnhre"  "earnwke"  "uhourse"  "hourslw"  "otc"      "ind02"   
 [8] "dind02"   "occ00"    "docc00"   "lfsr94"   "class94"  "relref95" "smsastat"
[15] "state"    "weight"   "year"    

> 	devUni4 <- subset(devUni3, class94 < 6 ,
> select=c(paidhre,earnhre,earnwke,uhourse,hourslw,otc,ind02,dind02,occ00,docc00,lfsr94,class94,relref95,smsastat,state,weight,year))
> 	devUni5 <- subset(devUni4, relref95 < 10 | relref95 ==13 | relref95 >=14,
> select=c(paidhre,earnhre,earnwke,uhourse,hourslw,otc,ind02,dind02,occ00,docc00,lfsr94,class94,relref95,smsastat,state,weight,year))
> 

-- 

David Winsemius
Alameda, CA, USA


From smartpink111 at yahoo.com  Tue Jun 11 23:23:17 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 11 Jun 2013 14:23:17 -0700 (PDT)
Subject: [R] Add a column to a dataframe based on multiple other
	column	values
In-Reply-To: <CAGUdn1CxLfxXNzDWQUo515h_h5qeKFMUyG5MsDb1qn6gBQ7cVg@mail.gmail.com>
References: <CAGUdn1CxLfxXNzDWQUo515h_h5qeKFMUyG5MsDb1qn6gBQ7cVg@mail.gmail.com>
Message-ID: <1370985797.19936.YahooMailNeo@web142601.mail.bf1.yahoo.com>

HI,
May be this helps:
dat1<- read.table(text="
x1??? y1??? x2??? y2??? x3??? y3??? output
2??? 100??? 190??? 99??? 1430??? 79??? 89
2??? 100??? 192??? 63??? 1431??? 75??? 69
2??? 100??? 192??? 63??? 1444??? 51??? 57
3??? 0??? 195??? 99??? 1499??? 50??? 74.5
3??? 0??? 198??? 98??? 1500??? 80??? 89
30??? 0??? 198??? 100??? 1451??? 97??? 65.66666667
32??? 100??? 868??? 100??? 1451??? 97??? 99
33??? 82??? 870??? 100??? 1490??? 97??? 93
33??? 0??? 871??? 82??? 1494??? 85??? 55.66666667
",sep="",header=TRUE)

dat1$output2<-apply(dat1[,-7],1,function(x) {indx<-((seq(x)-1)%%2+1);indx1<-indx==1; indx2<-indx==2;mean(x[indx2][x[indx1]>10])})
?dat1
#? x1? y1? x2? y2?? x3 y3?? output? output2
#1? 2 100 190? 99 1430 79 89.00000 89.00000
#2? 2 100 192? 63 1431 75 69.00000 69.00000
#3? 2 100 192? 63 1444 51 57.00000 57.00000
#4? 3?? 0 195? 99 1499 50 74.50000 74.50000
#5? 3?? 0 198? 98 1500 80 89.00000 89.00000
#6 30?? 0 198 100 1451 97 65.66667 65.66667
#7 32 100 868 100 1451 97 99.00000 99.00000
#8 33? 82 870 100 1490 97 93.00000 93.00000
#9 33?? 0 871? 82 1494 85 55.66667 55.66667
A.K.



----- Original Message -----
From: Tom Oates <toates19 at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Tuesday, June 11, 2013 12:07 PM
Subject: [R] Add a column to a dataframe based on multiple other column
	values

Hi
I have a dataframe as below:

x1? ? y1? ? x2? ? y2? ? x3? ? y3? ? output
2? ? 100? ? 190? ? 99? ? 1430? ? 79? ? 89
2? ? 100? ? 192? ? 63? ? 1431? ? 75? ? 69
2? ? 100? ? 192? ? 63? ? 1444? ? 51? ? 57
3? ? 0? ? 195? ? 99? ? 1499? ? 50? ? 74.5
3? ? 0? ? 198? ? 98? ? 1500? ? 80? ? 89
30? ? 0? ? 198? ? 100? ? 1451? ? 97? ? 65.66666667
32? ? 100? ? 868? ? 100? ? 1451? ? 97? ? 99
33? ? 82? ? 870? ? 100? ? 1490? ? 97? ? 93
33? ? 0? ? 871? ? 82? ? 1494? ? 85? ? 55.66666667


In reality the dataframe has pairs of columns x & y up to a large number.
As you can see from the column labelled output in the dataframe; I want to
calculate the mean of each row of the yn columns, but only to include each
yn value in the calculation of the mean if the corresponding xn column
value is greater than 10.
So for row 1; you will see that only y2 & y3 are included in calculating
the output column, but for row 6 y1-y3 are all included.
Because the number of paired x & y columns is large I am not sure the best
way to achieve this.
Thanks in advance
Tom

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jrkrideau at inbox.com  Tue Jun 11 23:26:57 2013
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 11 Jun 2013 13:26:57 -0800
Subject: [R] assigning global columns selection for all subset functions
 in script
In-Reply-To: <1370967505746-4669252.post@n4.nabble.com>
Message-ID: <4BE7B57ED74.000006CBjrkrideau@inbox.com>

index the columns to select 
lets say you want to select a set of colmns 2,4,6,8
Try something like this. (not run)
mycols  <-  c(2,4,6,8)
select(mydata[ , mycols] , mdata$x == 3)
John Kane
Kingston ON Canada


> -----Original Message-----
> From: bcrombie at utk.edu
> Sent: Tue, 11 Jun 2013 09:18:25 -0700 (PDT)
> To: r-help at r-project.org
> Subject: [R] assigning global columns selection for all subset functions
> in script
> 
> How do I let R know that I always want to select the same columns in my
> subset functions (below), so that I don't have to keep copy/pasting the
> same
> selection? (thanks)
> 	devUni2 <- subset(devUni1, dind02 != 52,
> select=c(paidhre,earnhre,earnwke,uhourse,hourslw,otc,ind02,dind02,occ00,docc00,lfsr94,class94,relref95,smsastat,state,weight,year))
> 	devUni3 <- subset(devUni2, lfsr94 == 1 | lfsr94 == 2 ,
> select=c(paidhre,earnhre,earnwke,uhourse,hourslw,otc,ind02,dind02,occ00,docc00,lfsr94,class94,relref95,smsastat,state,weight,year))
> 	devUni4 <- subset(devUni3, class94 < 6 ,
> select=c(paidhre,earnhre,earnwke,uhourse,hourslw,otc,ind02,dind02,occ00,docc00,lfsr94,class94,relref95,smsastat,state,weight,year))
> 	devUni5 <- subset(devUni4, relref95 < 10 | relref95 ==13 | relref95
> >=14,
> select=c(paidhre,earnhre,earnwke,uhourse,hourslw,otc,ind02,dind02,occ00,docc00,lfsr94,class94,relref95,smsastat,state,weight,year))
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/assigning-global-columns-selection-for-all-subset-functions-in-script-tp4669252.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From s.wood at bath.ac.uk  Tue Jun 11 23:35:41 2013
From: s.wood at bath.ac.uk (Simon Wood)
Date: Tue, 11 Jun 2013 22:35:41 +0100
Subject: [R] gamm in mgcv random effect significance
In-Reply-To: <51B7597A.9070506@ucmerced.edu>
References: <51B23EC9.4090109@ucmerced.edu>
	<1370642549.23179.17.camel@haul.biol.uregina.ca>
	<51B7597A.9070506@ucmerced.edu>
Message-ID: <51B7982D.20108@bath.ac.uk>

I would be very nervous about relying on an anova call here. It will 
attempt a generalized likelihood ratio test, but gamm is using penalized 
quasi likelihood and there is really no likelihood here (even without 
the problem that if there was a likelihood the null hypothesis would 
still be on the edge of the feasible parameter space making the GLRT 
problematic). The best hope might be to model the random effect of xc 
using a term s(xc,bs="re") in the model formula (xc will need to be a 
factor for this), and then use summary on the gam part of the fitted 
model object to assess significance. If you do this you'll need to 
include the grouping factor explicitly in corAR1 (at present it's picked 
up from the random effect, so is nested in xc).
i.e
   g2 <- gamm(y ~ s(xc) +z+ int,family=binomial, weights=trial, random =
list(xc=~1),correlation=corAR1())
becomes something like...
   xf <- factor(xc)
   g2 <- gamm(y ~ s(xc) +z+ int + s(xf,bs="re"),family=binomial, 
weights=trial,
             correlation=corAR1(form=~1|xf))
   summary(g2$gam)

... I'm also a bit nervous about xc entering as an iid random effect and 
the argument of a smooth, however - does that model structure really 
make sense?

best,
Simon

On 11/06/13 18:08, William Shadish wrote:
> Gavin et al.,
>
> Thanks so much for the help. Unfortunately, the command
>
> > anova(g1$lme, g2$lme)
>
> gives "Error in eval(expr, envir, enclos) : object 'fixed' not found
>
> and for bam (which is the one that can use a known ar1 term), the 
> error is
>
> > AR1 parameter rho unused with generalized model
>
> Apparently it cannot run for binomial distributions, and presumably 
> also Poisson.
>
> I did find a Frequently Asked Questions for package mgcv page that said
>
> "How can I compare gamm models? In the identity link normal errors 
> case, then AIC and hypotheis testing based methods are fine. Otherwise 
> it is best to work out a strategy based on the summary.gam"
>
> So putting all this together, I take it that my binomial example will 
> not support a direct model comparison to test the significance of the 
> random effects. I'm guessing the best strategy based on the 
> summary.gam is probably just to compare fit indices like Log Likelihoods.
>
> If anyone has any other suggestions, though, please do let me know.
>
> Thanks so much.
>
> Will Shadish
>
> On 6/7/2013 3:02 PM, Gavin Simpson wrote:
>> On Fri, 2013-06-07 at 13:12 -0700, William Shadish wrote:
>>> Dear R-helpers,
>>>
>>> I'd like to understand how to test the statistical significance of a
>>> random effect in gamm. I am using gamm because I want to test a model
>>> with an AR(1) error structure, and it is my understanding neither gam
>>> nor gamm4 will do the latter.
>>
>> gamm4() can't yes and out of the box mgcv::gam can't either but
>> see ?magic for an example of correlated errors and how the fits can be
>> manipulated to take the AR(1) (or any structure really as far as I can
>> tell) into account.
>>
>> You might like to look at mgcv::bam() which allows an known AR(1) term
>> but do check that it does what you think; with a random effect spline
>> I'm not at all certain that it will nest the AR(1) in the random effect
>> level.
>>
>> <snip />
>>> Consider, for example, two models, both with AR(1) but one allowing a
>>> random effect on xc:
>>>
>>> g1 <- gamm(y ~ s(xc) +z+ int,family=binomial, weights=trial,
>>> correlation=corAR1())
>>> g2 <- gamm(y ~ s(xc) +z+ int,family=binomial, weights=trial, random =
>>> list(xc=~1),correlation=corAR1())
>>
>> Shouldn't you specify how the AR(1) is nested in the hierarchy here,
>> i.e. AR(1) within xc? maybe I'm not following your data structure
>> correctly.
>>
>>> I include the output for g1 and g2 below, but the question is how to
>>> test the significance of the random effect on xc. I considered a test
>>> comparing the Log-Likelihoods, but have no idea what the degrees of
>>> freedom would be given that s(xc) is smoothed. I also tried:
>>>
>>> anova(g1$gam, g2$gam)
>>
>> gamm() fits via the lme() function of package nlme. To do what you want,
>> you need the anova() method for objects of class "lme", e.g.
>>
>> anova(g1$lme, g2$lme)
>>
>> Then I think you should check if the fits were done via REML and also be
>> aware of the issue of testing wether a variance term is 0.
>>
>>> that did not seem to return anything useful for this question.
>>>
>>> A related question is how to test the significance of adding a second
>>> random effect to a model that already has a random effect, such as:
>>>
>>> g3 <- gamm(y ~ xc +z+ s(int),family=binomial, weights=trial, random =
>>> list(Case=~1, z=~1),correlation=corAR1())
>>> g4 <- gamm(y ~ xc +z+ s(int),family=binomial, weights=trial, random =
>>> list(Case=~1, z=~1, int=~1),correlation=corAR1())
>>
>> Again, I think you need anova() on the $lme components.
>>
>> HTH
>>
>> G
>>
>>> Any help would be appreciated.
>>>
>>> Thanks.
>>>
>>> Will Shadish
>>> ********************************************
>>> g1
>>> $lme
>>> Linear mixed-effects model fit by maximum likelihood
>>>     Data: data
>>>     Log-likelihood: -437.696
>>>     Fixed: fixed
>>> X(Intercept)           Xz         Xint    Xs(xc)Fx1
>>>      0.6738466   -2.5688317    0.0137415   -0.1801294
>>>
>>> Random effects:
>>>    Formula: ~Xr - 1 | g
>>>    Structure: pdIdnot
>>>                    Xr1          Xr2          Xr3 Xr4
>>> Xr5          Xr6          Xr7          Xr8 Residual
>>> StdDev: 0.0004377781 0.0004377781 0.0004377781 0.0004377781 
>>> 0.0004377781
>>> 0.0004377781 0.0004377781 0.0004377781 1.693177
>>>
>>> Correlation Structure: AR(1)
>>>    Formula: ~1 | g
>>>    Parameter estimate(s):
>>>         Phi
>>> 0.3110725
>>> Variance function:
>>>    Structure: fixed weights
>>>    Formula: ~invwt
>>> Number of Observations: 264
>>> Number of Groups: 1
>>>
>>> $gam
>>>
>>> Family: binomial
>>> Link function: logit
>>>
>>> Formula:
>>> y ~ s(xc) + z + int
>>>
>>> Estimated degrees of freedom:
>>> 1  total = 4
>>>
>>> attr(,"class")
>>> [1] "gamm" "list"
>>> ****************************
>>>   > g2
>>> $lme
>>> Linear mixed-effects model fit by maximum likelihood
>>>     Data: data
>>>     Log-likelihood: -443.9495
>>>     Fixed: fixed
>>> X(Intercept)           Xz         Xint    Xs(xc)Fx1
>>>    0.720018143 -2.562155820  0.003457463 -0.045821030
>>>
>>> Random effects:
>>>    Formula: ~Xr - 1 | g
>>>    Structure: pdIdnot
>>>                    Xr1          Xr2          Xr3 Xr4
>>> Xr5          Xr6          Xr7          Xr8
>>> StdDev: 7.056078e-06 7.056078e-06 7.056078e-06 7.056078e-06 
>>> 7.056078e-06
>>> 7.056078e-06 7.056078e-06 7.056078e-06
>>>
>>>    Formula: ~1 | xc %in% g
>>>            (Intercept) Residual
>>> StdDev: 6.277279e-05 1.683007
>>>
>>> Correlation Structure: AR(1)
>>>    Formula: ~1 | g/xc
>>>    Parameter estimate(s):
>>>         Phi
>>> 0.1809409
>>> Variance function:
>>>    Structure: fixed weights
>>>    Formula: ~invwt
>>> Number of Observations: 264
>>> Number of Groups:
>>>           g xc %in% g
>>>           1        34
>>>
>>> $gam
>>>
>>> Family: binomial
>>> Link function: logit
>>>
>>> Formula:
>>> y ~ s(xc) + z + int
>>>
>>> Estimated degrees of freedom:
>>> 1  total = 4
>>>
>>> attr(,"class")
>>> [1] "gamm" "list"
>>>
>>>
>>
>


From jdnewmil at dcn.davis.CA.us  Tue Jun 11 23:38:06 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 11 Jun 2013 14:38:06 -0700
Subject: [R] Bytes to Numeric/Float conversion
In-Reply-To: <EF554462-F61C-4DBE-BDF4-8D21F34C9386@comcast.net>
References: <CAPcYNaR+rw5T0uV7iSYca2QNExMzey9YgJvHE2L7_c_kKFfZsA@mail.gmail.com>
	<EF554462-F61C-4DBE-BDF4-8D21F34C9386@comcast.net>
Message-ID: <3c9c8f83-3b9d-4696-8251-dc992ae0bb0f@email.android.com>

I recommend the hexView package for setting up such conversions.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

David Winsemius <dwinsemius at comcast.net> wrote:

>
>On Jun 11, 2013, at 9:01 AM, Bikash Agrawal wrote:
>
>> Is there any packages available in R, that can convert Bytes array to
>Float.
>> Using rJava we can do it. But it is kind of slow. Is there any R
>> specific packages.
>> I am having problem converting my bytes array to floating point.
>> Could any one help me with this problem.
>
>There is a raw data type that is designed to hold bytes than can be
>indexed.
>
>?raw
>
>`scan` can read files of type raw
>
>?scan


From mxkuhn at gmail.com  Tue Jun 11 23:43:19 2013
From: mxkuhn at gmail.com (Mxkuhn)
Date: Tue, 11 Jun 2013 17:43:19 -0400
Subject: [R] Caret train with glmnet give me Error "arguments imply
	differing number of rows"
In-Reply-To: <CACrcp22qc90CJZGV+y2vSYe8g50sGBkyO-hMD0wsPLieZAoa6A@mail.gmail.com>
References: <CACrcp22qc90CJZGV+y2vSYe8g50sGBkyO-hMD0wsPLieZAoa6A@mail.gmail.com>
Message-ID: <121A87FC-B254-4A4D-B904-F9BCB68B7164@gmail.com>

The data size isn't an issue. Can you send a reproducible example?

Max


On Jun 11, 2013, at 10:31 AM, Ferran Casarramona <ferran.casarramona at gmail.com> wrote:

> Hello,
> 
> I'm training a set of data with Caret package using an elastic net (glmnet).
> Most of the time train works ok, but when the data set grows in size I get
> the following error:
> Error en { :
>  task 1 failed - "arguments imply differing number of rows: 9, 10"
> 
> and several warnings like this one:
> 1: In eval(expr, envir, enclos) :
>  model fit failed for Resample01
> 
> My call to train function is like this:
> fit <- train(TrainingPreCols, TrainingFrame[,PCol], method="glmnet",
> preProcess = c("center","scale"))
> 
> When TrainingPreCols is 17420 obs. of 27 variables, the function works ok.
> But with a size of 47000 obs of 27 variables I get the former error.
> 
> ?Could be the amount of data the cause of this error?
> 
> Any help is appreciated,
>  Ferran
> 
> P.D.:
> This is my sessionInfo()
> R version 2.15.0 (2012-03-30)
> Platform: x86_64-pc-mingw32/x64 (64-bit)
> 
> locale:
> [1] LC_COLLATE=Spanish_Spain.1252  LC_CTYPE=Spanish_Spain.1252
> LC_MONETARY=Spanish_Spain.1252
> [4] LC_NUMERIC=C                   LC_TIME=Spanish_Spain.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] glmnet_1.9-3    Matrix_1.0-12   doSNOW_1.0.7    iterators_1.0.6
> snowfall_1.84-4
> [6] snow_0.3-12     caret_5.16-04   reshape2_1.2.2  plyr_1.8
> lattice_0.20-6
> [11] cluster_1.14.4  foreach_1.4.1
> 
> loaded via a namespace (and not attached):
> [1] codetools_0.2-8 grid_2.15.0     stringr_0.6.2   tools_2.15.0
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sjdavid at alumni.uci.edu  Tue Jun 11 22:30:45 2013
From: sjdavid at alumni.uci.edu (KRAmazon)
Date: Tue, 11 Jun 2013 13:30:45 -0700 (PDT)
Subject: [R] Ancestral state reconstruction under a split-tree for BiSSE
Message-ID: <1370982645505-4669286.post@n4.nabble.com>

Hello!

I am trying to do ancestral reconstruction under a split BiSSE model. 

#phy is my tree
nodes<-c(755,620,602,448,6,340) #vector of nodes at which to split the
phylogeny
nodes.i<-match(nodes,phy$node.label)+length(phy$tip.label)
pars.b<-c(428.597,  90.777, 421.878,  81.815, 0.201, 2.900)  #pars were
taken from the non-split model
pars.b.7<-rep(pars.b,7)
sampling.f<-c(533/23077,705/9547)
lik.split<-make.bisse.split(phy,states,nodes.i,sampling.f=sampling.f)
fit.split<-find.mle(lik.split,pars.b.7,method="optim")

All of that performs as expected, but when I try to perform ancestral
reconstruction on my split model, I get this error:

> asr.split<-asr.marginal(lik.split,coef(fit.split))
Error in check.pars.nonnegative(pars, 6) : 
  Incorrect parameter length: expected 6, got 42

Why does it expect 6 parameters for my split model instead of the 42? Am I
using the wrong
function for the ancestral reconstruction, or is the code incorrect? The
updates for version 0.9-1 
of diversitree state that reconstruction under split models is availabe. 

It was also suggested to me that I could average the parameters from
fit.split and do asr with an unsplit tree. 
Is this viable?


Thank you for your time!



--
View this message in context: http://r.789695.n4.nabble.com/Ancestral-state-reconstruction-under-a-split-tree-for-BiSSE-tp4669286.html
Sent from the R help mailing list archive at Nabble.com.


From tjolitz at gmail.com  Tue Jun 11 22:47:03 2013
From: tjolitz at gmail.com (Thorsten Jolitz)
Date: Tue, 11 Jun 2013 22:47:03 +0200
Subject: [R] Big, complex, well-structured .R file for demonstration?
References: <87vc5khek1.fsf@gmail.com>
	<CAM_vjuk4xmn3T=r-n0wpNA3i8tN31KGW8YDHbDrEq0ZA-OCd8Q@mail.gmail.com>
Message-ID: <877gi0pe7s.fsf@gmail.com>

Sarah Goslee <sarah.goslee at gmail.com> writes:

> On Tue, Jun 11, 2013 at 11:06 AM, Thorsten Jolitz <tjolitz at gmail.com> wrote:
>>
>> Hi List,
>>
>> I'm looking for a rather big, but well structured R file that contains
>> as much of R language features as possible (i.e. that uses a lot of the
>> functionality described in the 'R Reference Card' and, if possible, S4
>> classes too).
>
> http://cran.r-project.org/web/packages/
>
> I might start with MASS, though I have no idea what "well structured"
> means to you.
>
>> I want to check some code I wrote against such a file and use it for
>> demonstration purposes. However, most .R files I find out there are
>> rather short without much structure.
>
> Your request doesn't make a whole lot of sense to me, but there are so
> many thousands of R files on CRAN that there's bound to be something
> that makes you happy.

you are probably right, it might not make any sense, I guess I was
looking for something like a "full application" written in R, not just a
specialized library, but thank you for the link anyway, I decided to
clone the github repo of R, and the sources together with the CRAN
packages should give me what I want. 

-- 
cheers,
Thorsten


From 538280 at gmail.com  Tue Jun 11 23:52:40 2013
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 11 Jun 2013 15:52:40 -0600
Subject: [R] Big, complex, well-structured .R file for demonstration?
In-Reply-To: <87vc5khek1.fsf@gmail.com>
References: <87vc5khek1.fsf@gmail.com>
Message-ID: <CAFEqCdwmwTRQ_Q-nj10im-wDMaunQZT0Fhkho7LXi4UCA8Z+vQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130611/006544b9/attachment.pl>

From smartpink111 at yahoo.com  Tue Jun 11 23:54:00 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 11 Jun 2013 14:54:00 -0700 (PDT)
Subject: [R] Help needed in feature extraction from two input files
In-Reply-To: <1370976731.67112.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1370976731.67112.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1370987640.44957.YahooMailNeo@web142606.mail.bf1.yahoo.com>



Hi,
Try this:
lines1<- readLines("file1.txt")
lines1<- lines1[lines1!=""]
#In "file2.txt", 

>or1|1234
ATCGGATTCAGG
>or2|347
GAACCTATCGGGGGGGGAATTTA  
TATATTTTA###this should be a single line
>or3|56
ATCGGAGATATAACCAATC
>or3|23
AAAATTAACAAGAGAATAGACAAAAAAA
>or4|793
ATCTCTCTCCTCTCTCTCTAAAAA
>or7|123456789
ACGTGTGTACCCCC
#So, I modified the file manually so that it looks like:
>or1|1234 
ATCGGATTCAGG 
>or2|347 
GAACCTATCGGGGGGGGAATTTATATATTTTA 
>or3|56 
ATCGGAGATATAACCAATC 
>or3|23 
AAAATTAACAAGAGAATAGACAAAAAAA 
>or4|793 
ATCTCTCTCCTCTCTCTCTAAAAA 
>or7|123456789 
ACGTGTGTACCCCC

?#and saved.? If you have many lines showing the above mentioned anomaly, then let me know.

#I created a? new line after the last line (by using the `Enter` key) in the file to suppress the warnings() which I removed below.
lines2<- readLines("file2.txt")
lines2<- lines2[lines2!=""]


lines2New<-unlist(lapply(split(lines2,(seq_along(lines2)-1)%/%2+1),function(x) paste(x,collapse="\n")),use.names=FALSE)

##here changed because it was tab limited.
res<-lapply(lines1,function(x) {x1<- strsplit(x,"\t")[[1]]; x1New<-x1[-1];x2<-? gsub(">(.*)\\n.*","\\1",lines2New);lines3<-lines2New[match(x1New,x2)];write.table(lines3,paste0(x1[1],".txt"),row.names=FALSE,quote=FALSE)})


I didn't had any problems in the output.
It looks like below:
gene1.txt

x
>or1|1234
ATCGGATTCAGG
>or3|56
ATCGGAGATATAACCAATC
>or4|793
ATCTCTCTCCTCTCTCTCTAAAAA

A.K.


Hi.. 

Thanks Arun, 

three output files are generated, but they show x and NA,, may be I have to check the input... 

and could u plz modify the script so that it will take ?direct input from files? I have attached the two input files.. 



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Utpal Bakshi <utpalmtbi at gmail.com>
Cc: R help <r-help at r-project.org>
Sent: Tuesday, June 11, 2013 2:52 PM
Subject: Re: Help needed in feature extraction from two input files

Hi,
Try this:
lines1<- readLines(textConnection("gene1 or1|1234 or3|56 or4|793
gene4 or2|347
gene5 or3|23 or7|123456789")) 


lines2<-readLines(textConnection(">or1|1234
ATCGGATTCAGG
>or2|347
GAACCTATCGGGGGGGGAATTTATATATTTTA
>or3|56
ATCGGAGATATAACCAATC
>or3|23
AAAATTAACAAGAGAATAGACAAAAAAA
>or4|793
ATCTCTCTCCTCTCTCTCTAAAAA
>or7|123456789
ACGTGTGTACCCCC"))?

lines2New<-unlist(lapply(split(lines2,(seq_along(lines2)-1)%/%2+1),function(x) paste(x,collapse="\n")),use.names=FALSE)


res<-lapply(lines1,function(x) {x1<- strsplit(x," ")[[1]]; x1New<-x1[-1];x2<-? gsub(">(.*)\\n.*","\\1",lines2New);lines3<-lines2New[match(x1New,x2)];write.table(lines3,paste0(x1[1],".txt"),row.names=FALSE,quote=FALSE)})


Attached is one of the files generated by the code.
A.K.


Hi all, 

I have two input files. First file (file1.txt) contains entries in the following tab delimited format: 

gene1??? or1|1234??? or3|56??? or4|793 
gene4??? or2|347 
gene5??? or3|23??? or7|123456789 

....... 
.. 


The second file (file2.txt) contains some additional features along with the header line of the first file, such as: 

>or1|1234 
ATCGGATTCAGG 
>or2|347 
GAACCTATCGGGGGGGGAATTTA 
TATATTTTA 
>or3|56 
ATCGGAGATATAACCAATC 
>or3|23 
AAAATTAACAAGAGAATAGACAAAAAAA 
>or4|793 
ATCTCTCTCCTCTCTCTCTAAAAA 
>or7|123456789 
ACGTGTGTACCCCC 

.... 
.. 

From these two files, I want to extract entries by row wise 
header matching and rename the output file as the first column in file1.
For example, in the above case, 3 output files will generate. 

the first output file would named as "gene1.txt" and it contains: 

>or1|1234 
ATCGGATTCAGG 
>or3|56 
ATCGGAGATATAACCAATC 
>or4|793 
ATCTCTCTCCTCTCTCTCTAAAAA 

the second output file would named as "gene4.txt" and it contains: 

>or2|347 
GAACCTATCGGGGGGGGAATTTATATATTTTA 

the third output file would named as "gene5.txt" and it contains: 

>or3|23 
AAAATTAACAAGAGAATAGACAAAAAAA 
>or7|123456789 
ACGTGTGTACCCCC 

Any help in solving the problem is highly appreciated. Thanks in advance.


From istazahn at gmail.com  Tue Jun 11 23:54:55 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 11 Jun 2013 17:54:55 -0400
Subject: [R] ggpairs in GGally replaces plotmatrix in ggplot2
In-Reply-To: <B3731B5F-EB81-4901-95C6-2C7634BCE9AC@gmail.com>
References: <mailman.27.1370944809.23972.r-help@r-project.org>
	<c34d38dc-2cc9-4b9a-a840-965cfb958963@gmail.com>
	<48ABD695FDD.000001A7jrkrideau@inbox.com>
	<B3731B5F-EB81-4901-95C6-2C7634BCE9AC@gmail.com>
Message-ID: <CA+vqiLEWQvWuv-w65T8kM5n7xjVx0dTh1P6ij_ZMt+kOFf43Uw@mail.gmail.com>

I think the ggpairs equivalent is

ggpairs(dat1, upper=list(continuous="points"), axisLabels="show")

oddly enough.

ggpairs(dat1)

should default to the same graph as

plotmatrix(dat1)

but there seems to be a conflict between the default
axisLabels="internal" and density plots. Or something. There is a bug
report at https://github.com/ggobi/ggally/issues/18 that may be
related.

Best,
Ista

On Tue, Jun 11, 2013 at 4:07 PM, Keith S Weintraub <kw1958 at gmail.com> wrote:
> Yes. I was able to run it in RStudio but it did seem much slower than in R.app (on the Mac).
>
> Note that the "it" that I ran still didn't give the same results as plotmatrix.
>
> Thanks,
> KW
>
> --
>
> On Jun 11, 2013, at 11:16 AM, John Kane <jrkrideau at inbox.com> wrote:
>
>> Note that the code below might not work in RStudio.  I am gettting an intermittant crash when I use the ggpairs() command in RStudio and sometimes I get a density plot and sometimes not.  Also the command is taking 3-5 minutes to execute.
>>
>> This may just be a peculiarity of my machine but the code works fine and fairly fast in a terminal.
>>
>> John Kane
>> Kingston ON Canada
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Wed Jun 12 00:05:26 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 11 Jun 2013 23:05:26 +0100
Subject: [R] help using code
In-Reply-To: <CDDCC011.270E%montana3946@gmail.com>
References: <CDDCC011.270E%montana3946@gmail.com>
Message-ID: <51B79F26.7090204@sapo.pt>

Hello,

I believe you are making a confusion on how to call a function in R. You 
don't replace the argument in the function declaration. what you do is 
to call the function like this:

importdata("~/path to/filename.xyzuvwrgb")

leaving the function definition alone.

Hope this helps,

Rui Barradas

Em 11-06-2013 19:52, John McDermott escreveu:
> Hi R-helpers,
>
> I inherited some code that I'm trying to use. As a very new R user I'm
> having some confusion.
>
> I have some input files in the form: filename.xyzuvwrgb which I'm trying to
> import using:
>
> importdata = function(filename) {
>
>      p = scan(filename,what=list(x = double(), y = double(), z = double(), u
> = double(),v=double(),w=double()),skip=1,flush=TRUE,sep=" ")
>
>      return(data.frame(x=p$x, y=p$y, z=p$z, u=p$u, v=p$v, w=p$w))
>
> }
>
>
>
> For the filename I replaced both with "~/path to/filename.xyzuvwrgb" and I
> get the following errors:
>
>
>
> Error: unexpected string constant in "importdata =
> function("~/Desktop/thrustScarp1.xyzuvw""
>
>
>
> Error: no function to return from, jumping to top level
>
>
>
> Error: unexpected '}' in "}"
>
>
>
> I'm assuming it has to do with how I am using/formatted the
> function(filename) portion. How can I get this to work?
>
>
>
> Thanks for the help!
>
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From nevil.amos at gmail.com  Wed Jun 12 01:47:57 2013
From: nevil.amos at gmail.com (nevil amos)
Date: Wed, 12 Jun 2013 09:47:57 +1000
Subject: [R] Problem i9ncreasing memory to jvm for XLConnect
In-Reply-To: <CAOwvMDwQ1Ge-2Udc28qzLiB8XnLydKpem4ePAmw7Ezs63WAGoA@mail.gmail.com>
References: <CAN9eD7=L-7M663M+juLmv-nFAH2c3QYW0H35Kmd+NtTzXL72Mw@mail.gmail.com>
	<CAOwvMDwQ1Ge-2Udc28qzLiB8XnLydKpem4ePAmw7Ezs63WAGoA@mail.gmail.com>
Message-ID: <CAN9eD7ko7Gg6cqWbOmNw11ZTJ60Qdz4yPW2oP1+2HbTNOi6Mzg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/a64393b0/attachment.pl>

From montana3946 at gmail.com  Wed Jun 12 01:59:34 2013
From: montana3946 at gmail.com (John McDermott)
Date: Tue, 11 Jun 2013 16:59:34 -0700
Subject: [R] help using code
In-Reply-To: <51B79F26.7090204@sapo.pt>
Message-ID: <CDDD0674.2742%montana3946@gmail.com>

Hello,

Thanks for the help!

Your answer resolved my problem with the function I listed, but brought up
a larger question. How is the output of the importdata function stored for
use with other functions (as in, how do I call on that data for use with
other functions)? As a simple example I have another function:

meanXY = function(xyzuvw) {
	xy = c(mean(xyzuvw$x), mean(xyzuvw$y))
	return(xy)
}

I know that the xyzuvw portion is referring to the output of the
importdata function, but I don't know how to call up the necessary data
(hope this makes sense).

Thanks again for the help!

John




On 6/11/13 3:05 PM, "Rui Barradas" <ruipbarradas at sapo.pt> wrote:

>Hello,
>
>I believe you are making a confusion on how to call a function in R. You
>don't replace the argument in the function declaration. what you do is
>to call the function like this:
>
>importdata("~/path to/filename.xyzuvwrgb")
>
>leaving the function definition alone.
>
>Hope this helps,
>
>Rui Barradas
>
>Em 11-06-2013 19:52, John McDermott escreveu:
>> Hi R-helpers,
>>
>> I inherited some code that I'm trying to use. As a very new R user I'm
>> having some confusion.
>>
>> I have some input files in the form: filename.xyzuvwrgb which I'm
>>trying to
>> import using:
>>
>> importdata = function(filename) {
>>
>>      p = scan(filename,what=list(x = double(), y = double(), z =
>>double(), u
>> = double(),v=double(),w=double()),skip=1,flush=TRUE,sep=" ")
>>
>>      return(data.frame(x=p$x, y=p$y, z=p$z, u=p$u, v=p$v, w=p$w))
>>
>> }
>>
>>
>>
>> For the filename I replaced both with "~/path to/filename.xyzuvwrgb"
>>and I
>> get the following errors:
>>
>>
>>
>> Error: unexpected string constant in "importdata =
>> function("~/Desktop/thrustScarp1.xyzuvw""
>>
>>
>>
>> Error: no function to return from, jumping to top level
>>
>>
>>
>> Error: unexpected '}' in "}"
>>
>>
>>
>> I'm assuming it has to do with how I am using/formatted the
>> function(filename) portion. How can I get this to work?
>>
>>
>>
>> Thanks for the help!
>>
>>
>>
>>
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From kpenner at as.arizona.edu  Wed Jun 12 02:01:31 2013
From: kpenner at as.arizona.edu (Kyle Penner)
Date: Tue, 11 Jun 2013 17:01:31 -0700
Subject: [R] survreg with measurement uncertainties
Message-ID: <CAAF=944aDzh27CT1-5rYMX57=jKXRHxGvGCdhwcnqsYSSCyjkQ@mail.gmail.com>

Hello,

I have some measurements that I am trying to fit a model to.  I also
have uncertainties for these measurements.  Some of the measurements
are not well detected, so I'd like to use a limit instead of the
actual measurement.  (I am always dealing with upper limits, i.e. left
censored data.)

I have successfully run survreg using the combination of well detected
measurements and limits, but I would like to include the measurement
uncertainty (for the well detected measurements) in the fitting.  As
far as I can tell, survreg doesn't support this.  Does anyone have a
suggestion for how to accomplish this?

Thanks,

Kyle


From tjolitz at gmail.com  Wed Jun 12 02:01:55 2013
From: tjolitz at gmail.com (Thorsten Jolitz)
Date: Wed, 12 Jun 2013 02:01:55 +0200
Subject: [R] Big, complex, well-structured .R file for demonstration?
References: <87vc5khek1.fsf@gmail.com>
	<CAFEqCdwmwTRQ_Q-nj10im-wDMaunQZT0Fhkho7LXi4UCA8Z+vQ@mail.gmail.com>
Message-ID: <87y5agnqmk.fsf@gmail.com>

Greg Snow <538280 at gmail.com> writes:

> Some would argue that "big" and "well structured" are not compatible.  Part
> of structuring a project well is knowing when and how to break it into
> smaller pieces, so those authors who are best at creating well structured R
> code will often split it between several small files rather than one big
> file.

As Emacs Org-mode has proven for text files, this structuring into
smaller pieces can be done in one single file too (that is structured as
a hierarchical outline tree) an this can be even more convenient than to
deal with many small files. But otherwise I agree with you, its much
better to split a file up before it becomes a growing mess.

> On Tue, Jun 11, 2013 at 9:06 AM, Thorsten Jolitz <tjolitz at gmail.com> wrote:
>
>>
>> Hi List,
>>
>> I'm looking for a rather big, but well structured R file that contains
>> as much of R language features as possible (i.e. that uses a lot of the
>> functionality described in the 'R Reference Card' and, if possible, S4
>> classes too).
>>
>> I want to check some code I wrote against such a file and use it for
>> demonstration purposes. However, most .R files I find out there are
>> rather short without much structure.
>>
>> Any links to candidate (open source) files would be appreciated.
>>
>> --
>> cheers,
>> Thorsten
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>

-- 
cheers,
Thorsten


From ashenkin at ufl.edu  Wed Jun 12 02:19:04 2013
From: ashenkin at ufl.edu (Alexander Shenkin)
Date: Tue, 11 Jun 2013 19:19:04 -0500
Subject: [R] devtools: rtools not compatible with 3.0.1
Message-ID: <51B7BE78.4040407@ufl.edu>

Hi Folks,

I'm trying to load devtools in R 3.0.1 in order to run the dev version
of lme4.  I've updated devtools, and just installed Rtools30.exe. 
However, I get the following warning (in R-Studio, RGui, and R.exe, both
x64 and i386):

-----------------
WARNING: Rtools is required to build R packages, but no version of
Rtools compatible with R 3.0.1 was found. (Only the following
incompatible version(s) of Rtools were found:3.0)

Please download and install the appropriate version of Rtools from
http://cran.r-project.org/bin/windows/Rtools/ and then run find_rtools().
-----------------

Any ideas?  Rtools30.exe is the most recent that I can find.

Thanks,
Allie

R 3.0.1
Win 7 Pro x64 SP1


From armel.kaptue at sdstate.edu  Wed Jun 12 02:25:18 2013
From: armel.kaptue at sdstate.edu (Kaptue Tchuente, Armel)
Date: Wed, 12 Jun 2013 00:25:18 +0000
Subject: [R] how to extract coefficient from a gamma distribution?
Message-ID: <9879AF1F439EF943BDEE22D3AAA5C3F683FBEAA7@sdsu-ex01.jacks.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/10daadc0/attachment.pl>

From dwinsemius at comcast.net  Wed Jun 12 02:42:46 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 11 Jun 2013 17:42:46 -0700
Subject: [R] how to extract coefficient from a gamma distribution?
In-Reply-To: <9879AF1F439EF943BDEE22D3AAA5C3F683FBEAA7@sdsu-ex01.jacks.local>
References: <9879AF1F439EF943BDEE22D3AAA5C3F683FBEAA7@sdsu-ex01.jacks.local>
Message-ID: <FAD300E7-37DE-48E4-9E6A-6BCC0E22AD3B@comcast.net>


On Jun 11, 2013, at 5:25 PM, Kaptue Tchuente, Armel wrote:

> I'm trying to fit the gamma probability distribution to time series datasets suing the following command gam<-fitdistr(x=hist2fit,"gamma") where hist2fit is the bar histogram of a sample distribution.
> 
> The problem is that for some points, it is not possible to fit the gamma distribution for instance with an histogram having identical value.
> 
> I would like to know how to test whether the command gam<-fitdistr(x=hist2fit,"gamma") properly ended such that I can decide to save the gamma-parameters (for instance as NaN  in this case).
> 

?try
?tryCatch

> Without this test, the program stops when I try to store the scale and the shape parameters.
> 
> Any thoughts for a code will be very much appreciated.
> 
> 
> 
-- 

David Winsemius
Alameda, CA, USA


From bbolker at gmail.com  Wed Jun 12 04:27:39 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 12 Jun 2013 02:27:39 +0000
Subject: [R] devtools: rtools not compatible with 3.0.1
References: <51B7BE78.4040407@ufl.edu>
Message-ID: <loom.20130612T042432-930@post.gmane.org>

Alexander Shenkin <ashenkin <at> ufl.edu> writes:

> 
> Hi Folks,
> 
> I'm trying to load devtools in R 3.0.1 in order to run the dev version
> of lme4.  I've updated devtools, and just installed Rtools30.exe. 
> However, I get the following warning (in R-Studio, RGui, and R.exe, both
> x64 and i386):

  There's a bit of chicken-and-egg problem here, but devtools
has recently been updated to deal with this problem.

https://github.com/hadley/devtools/pull/298

  Until a new version makes it onto CRAN, you might have to 
clone/download the repository and install the package from there.
(Let me know off-list if you want me to pack up the package and
send it to you ...)

  Ben Bolker


From rahmank at frim.gov.my  Wed Jun 12 04:53:03 2013
From: rahmank at frim.gov.my (Abdul Rahman bin Kassim (Dr.))
Date: Wed, 12 Jun 2013 02:53:03 +0000
Subject: [R] Question on Simple Repeated Loops
Message-ID: <CD5D90359E14614081A90E850BE76D6722E835E5@FRIM-EXCHANGE.frim.gov.my>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/ff3ef23b/attachment.pl>

From imvinhs at yahoo.com.vn  Wed Jun 12 03:38:40 2013
From: imvinhs at yahoo.com.vn (vinhnguyen04x)
Date: Tue, 11 Jun 2013 18:38:40 -0700 (PDT)
Subject: [R] odds ratio per standard deviation
Message-ID: <1371001120339-4669315.post@n4.nabble.com>

Hi all

i have a question:

why and when do we use odds ratio per standard deviation instead of odds
ratio? 



--
View this message in context: http://r.789695.n4.nabble.com/odds-ratio-per-standard-deviation-tp4669315.html
Sent from the R help mailing list archive at Nabble.com.


From rahmank at frim.gov.my  Wed Jun 12 04:46:48 2013
From: rahmank at frim.gov.my (Abdul Rahman bin Kassim (Dr.))
Date: Wed, 12 Jun 2013 02:46:48 +0000
Subject: [R] R-help Digest, Vol 124, Issue 12
In-Reply-To: <mailman.27.1370944809.23972.r-help@r-project.org>
References: <mailman.27.1370944809.23972.r-help@r-project.org>
Message-ID: <CD5D90359E14614081A90E850BE76D6722E83578@FRIM-EXCHANGE.frim.gov.my>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/19bf14f8/attachment.pl>

From mixersoft at gishpuppy.com  Wed Jun 12 05:05:59 2013
From: mixersoft at gishpuppy.com (mixersoft)
Date: Tue, 11 Jun 2013 20:05:59 -0700 (PDT)
Subject: [R] R + face detection a good mix?
Message-ID: <1371006359332-4669320.post@n4.nabble.com>

Hello, a newbie here just trying to figure out where to start with R.

I want to build an algorithm that can detect 'duplicate' photos from a
series of photos - the common example is when you take multiple photos of a
group of people, hoping that one shot captured everyone smiling. Any batch
of kid photos would be another example because they rarely sit still for the
camera. 

One approach is to use timestamps to find photos taken at about the same
time, and match the position & spatial relationship of identical faces. I
think OpenCV has a face recognition lib that is well-used.

Is R something I could use to build an algorithm matches faces as above with
a specified degree of tolerance? (i.e. one person in the group blinked or
moved)  

There has been a lot of news recently about sophisticated new image
processing algos in Google+ photos, Facebook, etc for finding good photos
and hiding bad ones.  Has something like this already been done?



--
View this message in context: http://r.789695.n4.nabble.com/R-face-detection-a-good-mix-tp4669320.html
Sent from the R help mailing list archive at Nabble.com.


From totangjie at gmail.com  Wed Jun 12 09:21:25 2013
From: totangjie at gmail.com (Jie Tang)
Date: Wed, 12 Jun 2013 15:21:25 +0800
Subject: [R] How to get a running mean result by R?
Message-ID: <CAMUSh4q+tk964zPa60_6uuuGXf7YXY=hoPfCzfjhEC7Lxed7pQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/5cbe7f03/attachment.pl>

From gallon.li at gmail.com  Wed Jun 12 09:47:41 2013
From: gallon.li at gmail.com (Gallon Li)
Date: Wed, 12 Jun 2013 15:47:41 +0800
Subject: [R] change factor to mtrix
Message-ID: <CAKO0Dpjo9GcB3ay78bpnsqpYA1MVvT-DTTU5Sf9enO18zgwasw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/894427ca/attachment.pl>

From jonathancornelissen at hotmail.com  Wed Jun 12 10:03:51 2013
From: jonathancornelissen at hotmail.com (jonathan cornelissen)
Date: Wed, 12 Jun 2013 08:03:51 +0000
Subject: [R] Instant search for R documentation
Message-ID: <BLU175-W42727150ADA97BBD3C3E53AD860@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/208ce33e/attachment.pl>

From bhh at xs4all.nl  Wed Jun 12 10:43:17 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 12 Jun 2013 10:43:17 +0200
Subject: [R] Question on Simple Repeated Loops
In-Reply-To: <CD5D90359E14614081A90E850BE76D6722E835E5@FRIM-EXCHANGE.frim.gov.my>
References: <CD5D90359E14614081A90E850BE76D6722E835E5@FRIM-EXCHANGE.frim.gov.my>
Message-ID: <65EFEC73-BFF7-4D38-9782-86D7D846EEBB@xs4all.nl>


On 12-06-2013, at 04:53, Abdul Rahman bin Kassim (Dr.) <rahmank at frim.gov.my> wrote:

> 
> Dear R-User,
> 
> Appreciate any helps. It looks simple, but I don't have a clue.
> 
> Given that I have a dataframe of tree population with three variables:
> 
> sp=species ,
> d0=initial_size
> grow=growth increment from initial size per year
> 
> How can I calculate the future growth increment of each tree  for the next 3 years.
> 
> The following Rscript was written,
> 
> #----------
> a0 <- data.frame(d0=seq(5,50,5) , sp=gl(2,5,10),
>   grow=rep(0.5,10))
> a2<- list()
> for( i in 1:3){
>  a1 <- a0$d0+a0$grow
>  a2[[i]] <- cbind(sp=a0$sp,d0=a1+i,yr=i)
>   }
> as.data.frame(do.call(cbind,a2))
> 
>> as.data.frame(do.call(cbind,a2))
>   sp   d0 yr sp   d0 yr sp   d0 yr
> 1   1  6.5  1  1  7.5  2  1  8.5  3
> 2   1 11.5  1  1 12.5  2  1 13.5  3
> 3   1 16.5  1  1 17.5  2  1 18.5  3
> 4   1 21.5  1  1 22.5  2  1 23.5  3
> 5   1 26.5  1  1 27.5  2  1 28.5  3
> 6   2 31.5  1  2 32.5  2  2 33.5  3
> 7   2 36.5  1  2 37.5  2  2 38.5  3
> 8   2 41.5  1  2 42.5  2  2 43.5  3
> 9   2 46.5  1  2 47.5  2  2 48.5  3
> 10  2 51.5  1  2 52.5  2  2 53.5  3
> 
> #-----
> 
> but the results did not produce the expected future d0. I think its my R script  "d0=a1+i"  in the  " a2[[i]] <- cbind(sp=a0$sp,d0=a1+i,yr=i)". Interested to know the correct way of writing the repeated loops in R.
> 
> The expected results is:
> 
>   sp   d0 yr sp   d0 yr sp   d0 yr
> 1   1  6.5  1  1  7.0  2  1  7.5  3
> 2   1 11.5  1  1 12.0  2  1 12.5  3
> 3   1 16.5  1  1 17.0  2  1 17.5  3
> 4   1 21.5  1  1 22.0  2  1 22.5  3
> 5   1 26.5  1  1 27.0  2  1 27.5  3
> 6   2 31.5  1  2 32.0  2  2 32.5  3
> 7   2 36.5  1  2 37.0  2  2 37.5  3
> 8   2 41.5  1  2 42.0  2  2 42.5  3
> 9   2 46.5  1  2 47.0  2  2 47.5  3
> 10  2 51.5  1  2 52.0  2  2 52.5  3
> 

Why is the expression  a1 <- a0$d0+a0$grow inside the for loop?
It doesn't depend on i.

I don't understand your expected result.
Fpr species 1 the initial value in column d0 is 5. I assume that this is in year 0.
So with a growth increment of .5 in year 1 I would expect d0 to be 5.5, in year 2it is  6 and in year 3 it would be 6.5.

So see if this does what you seem to want (and remove the redundant expression for a1)

a3<- list()
for( i in 1:3){
 a3[[i]] <- cbind(sp=a0$sp,d0=a0$d0+i*a0$grow,yr=i)
}
as.data.frame(do.call(cbind,a3))
#    sp   d0 yr sp d0 yr sp   d0 yr
# 1   1  5.5  1  1  6  2  1  6.5  3
# 2   1 10.5  1  1 11  2  1 11.5  3
# 3   1 15.5  1  1 16  2  1 16.5  3
# 4   1 20.5  1  1 21  2  1 21.5  3
# 5   1 25.5  1  1 26  2  1 26.5  3
# 6   2 30.5  1  2 31  2  2 31.5  3
# 7   2 35.5  1  2 36  2  2 36.5  3
# 8   2 40.5  1  2 41  2  2 41.5  3
# 9   2 45.5  1  2 46  2  2 46.5  3
# 10  2 50.5  1  2 51  2  2 51.5  3


Berend


From ruipbarradas at sapo.pt  Wed Jun 12 11:05:25 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 12 Jun 2013 10:05:25 +0100
Subject: [R] help using code
In-Reply-To: <CDDD0674.2742%montana3946@gmail.com>
References: <CDDD0674.2742%montana3946@gmail.com>
Message-ID: <51B839D5.600@sapo.pt>

Hello,

Simply assign the output of a function to a variable:

xyzuvw <- importdata(...)

and then use that output. In this case, a data.frame with, among others, 
vectors 'x' and 'y'.
You need to read an R introductory text. I recommend An Introduction to 
R, file R-intro.pdf in your doc directory.

Rui Barradas


Em 12-06-2013 00:59, John McDermott escreveu:
> Hello,
>
> Thanks for the help!
>
> Your answer resolved my problem with the function I listed, but brought up
> a larger question. How is the output of the importdata function stored for
> use with other functions (as in, how do I call on that data for use with
> other functions)? As a simple example I have another function:
>
> meanXY = function(xyzuvw) {
> 	xy = c(mean(xyzuvw$x), mean(xyzuvw$y))
> 	return(xy)
> }
>
> I know that the xyzuvw portion is referring to the output of the
> importdata function, but I don't know how to call up the necessary data
> (hope this makes sense).
>
> Thanks again for the help!
>
> John
>
>
>
>
> On 6/11/13 3:05 PM, "Rui Barradas" <ruipbarradas at sapo.pt> wrote:
>
>> Hello,
>>
>> I believe you are making a confusion on how to call a function in R. You
>> don't replace the argument in the function declaration. what you do is
>> to call the function like this:
>>
>> importdata("~/path to/filename.xyzuvwrgb")
>>
>> leaving the function definition alone.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Em 11-06-2013 19:52, John McDermott escreveu:
>>> Hi R-helpers,
>>>
>>> I inherited some code that I'm trying to use. As a very new R user I'm
>>> having some confusion.
>>>
>>> I have some input files in the form: filename.xyzuvwrgb which I'm
>>> trying to
>>> import using:
>>>
>>> importdata = function(filename) {
>>>
>>>       p = scan(filename,what=list(x = double(), y = double(), z =
>>> double(), u
>>> = double(),v=double(),w=double()),skip=1,flush=TRUE,sep=" ")
>>>
>>>       return(data.frame(x=p$x, y=p$y, z=p$z, u=p$u, v=p$v, w=p$w))
>>>
>>> }
>>>
>>>
>>>
>>> For the filename I replaced both with "~/path to/filename.xyzuvwrgb"
>>> and I
>>> get the following errors:
>>>
>>>
>>>
>>> Error: unexpected string constant in "importdata =
>>> function("~/Desktop/thrustScarp1.xyzuvw""
>>>
>>>
>>>
>>> Error: no function to return from, jumping to top level
>>>
>>>
>>>
>>> Error: unexpected '}' in "}"
>>>
>>>
>>>
>>> I'm assuming it has to do with how I am using/formatted the
>>> function(filename) portion. How can I get this to work?
>>>
>>>
>>>
>>> Thanks for the help!
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>
>


From jim at bitwrit.com.au  Wed Jun 12 11:09:26 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 12 Jun 2013 19:09:26 +1000
Subject: [R] change factor to mtrix
In-Reply-To: <CAKO0Dpjo9GcB3ay78bpnsqpYA1MVvT-DTTU5Sf9enO18zgwasw@mail.gmail.com>
References: <CAKO0Dpjo9GcB3ay78bpnsqpYA1MVvT-DTTU5Sf9enO18zgwasw@mail.gmail.com>
Message-ID: <51B83AC6.2030503@bitwrit.com.au>

On 06/12/2013 05:47 PM, Gallon Li wrote:
> i wish to change a column of factor variable to multiple columns of
> zero-ones
>
> for example, my factor could be
>
> ff=c('a','a','b','b','c','c')
>
> then I want to have two columns (for three levels) that are
>
> 0 0
> 0 0
> 1 0
> 1 0
> 0 1
> 0 1
>
> how can i do this fast?

Hi Gallon,
If you want exactly the output shown above, it is not trivial. You could 
convert ff to a factor, then use as.numeric to get:

a = 1
b = 2
c = 3

If you subtract one and display the numbers in two digits of binary:

a = 00
b = 01
c = 10

Then if you apply as.character and strsplit, you can get:

a = "0" "0"
b = "0" "1"
c = "1" "0"

Finally, as.numeric will give you numbers. This does not produce the 
numbers above, but it might give you an idea of what to do.

Jim


From kiotoqq at gmail.com  Wed Jun 12 11:14:35 2013
From: kiotoqq at gmail.com (maggy yan)
Date: Wed, 12 Jun 2013 11:14:35 +0200
Subject: [R] loops for matrices
Message-ID: <CAK70=f5bXCG9D6Kq56+x32k4YSc1GSqNM60j-Hb0OhzgUPnwFw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/3f272f67/attachment.pl>

From bodenhofer at bioinf.jku.at  Wed Jun 12 11:16:57 2013
From: bodenhofer at bioinf.jku.at (Ulrich Bodenhofer)
Date: Wed, 12 Jun 2013 11:16:57 +0200
Subject: [R] Version 1.3.2 of apcluster package (+ last announcement of
	Webinar)
Message-ID: <51B83C89.7080907@bioinf.jku.at>

Dear colleagues,

This is to inform you that Version 1.3.2 of the R package *apcluster* 
has been released on CRAN yesterday (note that it may still take a few 
more hours until the Windows binary will be available). We added a 
plotting function that also allows for plotting clustering results along 
with multi-dimensional data (by superimposing clusters in a scatterplot 
matrix). Moreover, we improved the handling of missing values. For more 
details, see the following URLs:

http://www.bioinf.jku.at/software/apcluster/
http://cran.r-project.org/web/packages/apcluster/index.html

Furthermore, I want to remind you that I will be giving a webinar on the 
apcluster package on Thursday, June 13, 2013, 7:00pm CEST (10:00am PDT). 
The outline of the one-hour webinar is as follows:

- Introduction to affinity propagation (AP) clustering
- The apcluster package, its algorithms, and visualization tools
- Live apcluster demonstration
- Question and Answer period

To register for the webinar, please visit the following URL:
https://www3.gotomeeting.com/register/503109182

The webinar is kindly brought to you by the Orange County R User Group 
and will be moderated by its president, Ray DiGiacomo, Jr.


Best regards,
Ulrich


------------------------------------------------------------------------
*Dr. Ulrich Bodenhofer*
Associate Professor
Institute of Bioinformatics

*Johannes Kepler University*
Altenberger Str. 69
4040 Linz, Austria

Tel. +43 732 2468 4526
Fax +43 732 2468 4539
bodenhofer at bioinf.jku.at <mailto:bodenhofer at bioinf.jku.at>
http://www.bioinf.jku.at/ <http://www.bioinf.jku.at>


From rainer.schuermann at gmx.net  Wed Jun 12 11:24:52 2013
From: rainer.schuermann at gmx.net (Rainer Schuermann)
Date: Wed, 12 Jun 2013 11:24:52 +0200
Subject: [R] loops for matrices
In-Reply-To: <CAK70=f5bXCG9D6Kq56+x32k4YSc1GSqNM60j-Hb0OhzgUPnwFw@mail.gmail.com>
References: <CAK70=f5bXCG9D6Kq56+x32k4YSc1GSqNM60j-Hb0OhzgUPnwFw@mail.gmail.com>
Message-ID: <1865581.JSYAAiGDEz@rainer>

The comments on StackOverflow are fair, I believe...
Please dput() your matrices, so that your code becomes reproducible!


On Wednesday 12 June 2013 11:14:35 maggy yan wrote:
> I have to use a loop (while or for) to return the result of hadamard
> product. now it returns a matrix, but when I use is.matrix() to check, it
> returns FALSE, whats wrong?
> 
> Matrix.mul <- function(A, B)
> {
>     while(is.matrix(A) == FALSE | is.matrix(B) == FALSE )
>          {print("error")
>           break}
>     while(is.matrix(A) == T & is.matrix(B) == T)
>          {
>           n <- dim(A)[1]; m <- dim(A)[2];
>           p <- dim(B)[1]; q <- dim(B)[2];
>           while(m == p)
>                {
>                 C <- matrix(0, nrow = n , ncol = q)
>                 for(s in 1:n)
>                    {
>                     for(t in 1:q)
>                        {
>                         c <- array(0, dim = m )
>                         for(k in 1:m)
>                            {
>                             c[k] <- A[s,k] * B[k, t]
> 
>                             }
>                         C[s, t] <- sum(c)
>                        }
>                    }
>                 print(C)
>                 break
>                 }
>           while(m != p)
>                {
>                 print("error")
>                 break
>                 }
>           break
>           }
> }
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ferran.casarramona at gmail.com  Wed Jun 12 12:04:10 2013
From: ferran.casarramona at gmail.com (Ferran Casarramona)
Date: Wed, 12 Jun 2013 12:04:10 +0200
Subject: [R] Caret train with glmnet give me Error "arguments imply
 differing number of rows"
In-Reply-To: <121A87FC-B254-4A4D-B904-F9BCB68B7164@gmail.com>
References: <CACrcp22qc90CJZGV+y2vSYe8g50sGBkyO-hMD0wsPLieZAoa6A@mail.gmail.com>
	<121A87FC-B254-4A4D-B904-F9BCB68B7164@gmail.com>
Message-ID: <CACrcp20V-SW+L7+R95dNajGfZ=TY4+oxhz_4mCG61-Zmqr2eZQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/8a2f7573/attachment.pl>

From ruipbarradas at sapo.pt  Wed Jun 12 12:37:39 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 12 Jun 2013 11:37:39 +0100
Subject: [R] How to get a running mean result by R?
In-Reply-To: <CAMUSh4q+tk964zPa60_6uuuGXf7YXY=hoPfCzfjhEC7Lxed7pQ@mail.gmail.com>
References: <CAMUSh4q+tk964zPa60_6uuuGXf7YXY=hoPfCzfjhEC7Lxed7pQ@mail.gmail.com>
Message-ID: <51B84F73.2000802@sapo.pt>

Hello,

You can use, for instance, function ma() in package forecast.

# if not yet installed
#install.packages('forecast', dependencies = TRUE)
library(forecast)

?ma


Hope this helps,

Rui Barradas


Em 12-06-2013 08:21, Jie Tang escreveu:
> Hi R users:
>    I have a big data and want to calculate the running mean of this data .
> How can I get this kind of result ? I have check the command "mean"
> it seems "mean" could not get the running mean?
>


From er.bikash21 at gmail.com  Wed Jun 12 12:54:40 2013
From: er.bikash21 at gmail.com (Bikash Agrawal)
Date: Wed, 12 Jun 2013 12:54:40 +0200
Subject: [R] Bytes to Numeric/Float conversion
In-Reply-To: <CAPcYNaR+rw5T0uV7iSYca2QNExMzey9YgJvHE2L7_c_kKFfZsA@mail.gmail.com>
References: <CAPcYNaR+rw5T0uV7iSYca2QNExMzey9YgJvHE2L7_c_kKFfZsA@mail.gmail.com>
Message-ID: <CAPcYNaRc=uWSkkohJSMCfaD+7bNeDmB5vmnw6DNMRcPEJvr68Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/569b7571/attachment.pl>

From spencer.graves at structuremonitoring.com  Wed Jun 12 12:58:41 2013
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Wed, 12 Jun 2013 03:58:41 -0700
Subject: [R] Instant search for R documentation
In-Reply-To: <BLU175-W42727150ADA97BBD3C3E53AD860@phx.gbl>
References: <BLU175-W42727150ADA97BBD3C3E53AD860@phx.gbl>
Message-ID: <51B85461.1060101@structuremonitoring.com>

On 6/12/2013 1:03 AM, jonathan cornelissen wrote:
> Hi,
>
> I just wanted to share with you that we made a website over the weekend that allows "instant search" of the R documentation on CRAN, see: www.Rdocumentation.org. It's a first version, so any feedback/comments/criticism most welcome.


       Interesting.  Are you aware of the following:


             * help.start()


             * The R Wiki (the fourth item under "Documentation" on the 
left at "r-project.org").  Might you want to consider merging your 
"rdocumentation.org" with this?


                   - NOTE:  The R Wiki unfortunately has not gotten the 
attention and development I believe it deserves.  I'm not sure why this 
is.  The standard Wikipedia gets many contributors.  One difference I 
noticed is that to edit this, one needs to login. That's not true for 
Wikimedia projects.  Beyond that, with stardard Mediawiki markup 
language can intimidate some people.  Fortunately, difficulties in using 
the Mediawiki softaware will soon be reduced. One of the primary 
priorities of the software development team at the Wikimedia Foundation 
is modifying the Mediawiki software to include a beta version of a 
visual (WYSIWYG) editor.  I saw a demo of a beta version of this a month 
ago.  It's already available for limited use, but I don't think it's 
quite ready yet.  I think it might be wise to check for it later this year.


             * The "sos" package with its vignette for searching CRAN 
packages and getting the result sorted to place first the package with 
the most matches.


       Hope this helps.
       Spencer

> Best regards,
>
> Jonathan 		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kw1958 at gmail.com  Wed Jun 12 13:12:18 2013
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Wed, 12 Jun 2013 07:12:18 -0400
Subject: [R] Add a column to a dataframe based on multiple other column	
	values
In-Reply-To: <mailman.25.1371031207.11759.r-help@r-project.org>
References: <mailman.25.1371031207.11759.r-help@r-project.org>
Message-ID: <1E4B3BA6-0A40-4252-9033-5E2B4AF69499@gmail.com>

Tom,

Here is my solution. Note that I assume the columns are interleaved as you describe below. I'm sure others will have better replies.

Note that using dput helps the helpers.

# From dput(mdat)
mdat<-structure(list(x1 = c(2L, 2L, 2L, 3L, 3L, 30L, 32L, 33L, 33L), 
    y1 = c(100L, 100L, 100L, 0L, 0L, 0L, 100L, 82L, 0L), x2 = c(190L, 
    192L, 192L, 195L, 198L, 198L, 868L, 870L, 871L), y2 = c(99L, 
    63L, 63L, 99L, 98L, 100L, 100L, 100L, 82L), x3 = c(1430L, 
    1431L, 1444L, 1499L, 1500L, 1451L, 1451L, 1490L, 1494L), 
    y3 = c(79L, 75L, 51L, 50L, 80L, 97L, 97L, 97L, 85L), output = c(89, 
    69, 57, 74.5, 89, 65.66666667, 99, 93, 55.66666667)), .Names = c("x1", 
"y1", "x2", "y2", "x3", "y3", "output"), class = "data.frame", row.names = c(NA, 
-9L))

mdat.pure<-mdat[,-ncol(mdat)]

# Function to apply to rows
theFunk<-function(x) {
  nxy<-length(x)/2
  idx<-seq_len(nxy)
  xvec<-x[idx*2 - 1]
  yvec<-x[idx*2]
  mean(yvec[xvec>10])
}

# Apply the function to rows
output<-apply(mdat.pure, 1, theFunk)

Or 

mdat.pure$output<-apply(mdat.pure, 1, theFunk)

will put the calculated column at the end of mdat.pure.

Note that I haven't taken account of missing values.

Hope this helps,
KW

--

On Jun 12, 2013, at 6:00 AM, r-help-request at r-project.org wrote:

> Message: 35
> Date: Tue, 11 Jun 2013 17:07:12 +0100
> From: Tom Oates <toates19 at gmail.com>
> To: r-help at r-project.org
> Subject: [R] Add a column to a dataframe based on multiple other
> 	column	values
> Message-ID:
> 	<CAGUdn1CxLfxXNzDWQUo515h_h5qeKFMUyG5MsDb1qn6gBQ7cVg at mail.gmail.com>
> Content-Type: text/plain
> 
> Hi
> I have a dataframe as below:
> 
> x1    y1    x2    y2    x3    y3    output
> 2    100    190    99    1430    79    89
> 2    100    192    63    1431    75    69
> 2    100    192    63    1444    51    57
> 3    0    195    99    1499    50    74.5
> 3    0    198    98    1500    80    89
> 30    0    198    100    1451    97    65.66666667
> 32    100    868    100    1451    97    99
> 33    82    870    100    1490    97    93
> 33    0    871    82    1494    85    55.66666667
> 
> 
> In reality the dataframe has pairs of columns x & y up to a large number.
> As you can see from the column labelled output in the dataframe; I want to
> calculate the mean of each row of the yn columns, but only to include each
> yn value in the calculation of the mean if the corresponding xn column
> value is greater than 10.
> So for row 1; you will see that only y2 & y3 are included in calculating
> the output column, but for row 6 y1-y3 are all included.
> Because the number of paired x & y columns is large I am not sure the best
> way to achieve this.
> Thanks in advance
> Tom


From murdoch.duncan at gmail.com  Wed Jun 12 13:20:28 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 12 Jun 2013 07:20:28 -0400
Subject: [R] Bytes to Numeric/Float conversion
In-Reply-To: <CAPcYNaRc=uWSkkohJSMCfaD+7bNeDmB5vmnw6DNMRcPEJvr68Q@mail.gmail.com>
References: <CAPcYNaR+rw5T0uV7iSYca2QNExMzey9YgJvHE2L7_c_kKFfZsA@mail.gmail.com>
	<CAPcYNaRc=uWSkkohJSMCfaD+7bNeDmB5vmnw6DNMRcPEJvr68Q@mail.gmail.com>
Message-ID: <51B8597C.1030908@gmail.com>

On 13-06-12 6:54 AM, Bikash Agrawal wrote:
> Actually I am using rJava, running some map-reduce using R.
> The data send is in bytes, but actually it is floating-point number.
>
> On R side, I need to convert this byte into Float. But I couldn't find any
> function.
> I am try using rawToChar() which convert into character. And later on
> as.double to convert it.
>
> But it is not giving the exact value.
> Could any one help me out.
>

If you want exact transfer from bytes, use raw connections.  For example:

 > con <- rawConnection(raw(0), "r+")
 > writeBin(pi, con)
 > rawConnectionValue(con)
[1] 18 2d 44 54 fb 21 09 40
 > seek(con,0)
[1] 8
 > readBin(con, "numeric")
[1] 3.141593

Depending on how you created the bytes, you may need to do some fiddling 
with the optional parameters size and endian of readBin to read them 
properly.

Duncan Murdoch


From pdalgd at gmail.com  Wed Jun 12 13:45:24 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 12 Jun 2013 13:45:24 +0200
Subject: [R] QR factorization for aov
In-Reply-To: <CDDCB9DE.180D%mcelis@lightminersystems.com>
References: <CDDCB9DE.180D%mcelis@lightminersystems.com>
Message-ID: <2C698ACA-B732-44EF-B0D8-B3187A8A1390@gmail.com>


On Jun 11, 2013, at 20:26 , Mimi Celis wrote:

> I am looking at the aov function in R. I see that it uses a modified QR factorization routine dqrdc2 based on the Linpack routine dqrdc. Pivoting is done different than the original Linpack function.
> 
> My questions:
> 
>  *   Why is it necessary to modify the pivoting strategy? Something necessary for aov?
>  *   Will the LAPACK function dgeqp3 work well or would the pivoting have o be modified?
> 


As far as I have understood it, the issue is that to generate the sequential ANOVA table based on a single QR factorization, you can't have it swapping terms around, because there are cases where the order of terms matters. 

So LAPACK won't do. Or rather, to use it, you'd need to rethink the algoritm; you may need refactorizing for each line the ANOVA table. It's not necessarily impossible or seriously inefficient, just one of the things that nobody seems to have an aching desire to tackle.

-pd

> Thank you
> MRC
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Wed Jun 12 13:54:19 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 12 Jun 2013 13:54:19 +0200
Subject: [R] change factor to mtrix
In-Reply-To: <CAKO0Dpjo9GcB3ay78bpnsqpYA1MVvT-DTTU5Sf9enO18zgwasw@mail.gmail.com>
References: <CAKO0Dpjo9GcB3ay78bpnsqpYA1MVvT-DTTU5Sf9enO18zgwasw@mail.gmail.com>
Message-ID: <2222330D-1F9A-414F-A237-E2600CEB4093@gmail.com>


On Jun 12, 2013, at 09:47 , Gallon Li wrote:

> i wish to change a column of factor variable to multiple columns of
> zero-ones
> 
> for example, my factor could be
> 
> ff=c('a','a','b','b','c','c')
> 
> then I want to have two columns (for three levels) that are
> 
> 0 0
> 0 0
> 1 0
> 1 0
> 0 1
> 0 1
> 
> how can i do this fast?

Maybe not fast, but quick:

> fff <- factor(ff)
> model.matrix(~fff)[,-1]
  fffb fffc
1    0    0
2    0    0
3    1    0
4    1    0
5    0    1
6    0    1

Possibly faster, skipping some "red tape":

> CC <- contrasts(fff)
> CC
  b c
a 0 0
b 1 0
c 0 1
> CC[fff,]
  b c
a 0 0
a 0 0
b 1 0
b 1 0
c 0 1
c 0 1



> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jdnewmil at dcn.davis.CA.us  Wed Jun 12 14:51:21 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 12 Jun 2013 06:51:21 -0600
Subject: [R] Big, complex, well-structured .R file for demonstration?
In-Reply-To: <87y5agnqmk.fsf@gmail.com>
References: <87vc5khek1.fsf@gmail.com>
	<CAFEqCdwmwTRQ_Q-nj10im-wDMaunQZT0Fhkho7LXi4UCA8Z+vQ@mail.gmail.com>
	<87y5agnqmk.fsf@gmail.com>
Message-ID: <8916da23-c256-4036-a68b-77564b18b162@email.android.com>

Just because you have an editor that can let you see the organization within the file does not mean the code itself is well-structured. If you do put a lot of code in one file, you will be more likely in your next project that builds on this one to load code you do not need (bloat), and that is a very practical defect in the structure of the current project. Regardless of any arguments you can think of to the contrary, that is why single large files with otherwise well-structured code are uncommon.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Thorsten Jolitz <tjolitz at gmail.com> wrote:

>Greg Snow <538280 at gmail.com> writes:
>
>> Some would argue that "big" and "well structured" are not compatible.
> Part
>> of structuring a project well is knowing when and how to break it
>into
>> smaller pieces, so those authors who are best at creating well
>structured R
>> code will often split it between several small files rather than one
>big
>> file.
>
>As Emacs Org-mode has proven for text files, this structuring into
>smaller pieces can be done in one single file too (that is structured
>as
>a hierarchical outline tree) an this can be even more convenient than
>to
>deal with many small files. But otherwise I agree with you, its much
>better to split a file up before it becomes a growing mess.
>
>> On Tue, Jun 11, 2013 at 9:06 AM, Thorsten Jolitz <tjolitz at gmail.com>
>wrote:
>>
>>>
>>> Hi List,
>>>
>>> I'm looking for a rather big, but well structured R file that
>contains
>>> as much of R language features as possible (i.e. that uses a lot of
>the
>>> functionality described in the 'R Reference Card' and, if possible,
>S4
>>> classes too).
>>>
>>> I want to check some code I wrote against such a file and use it for
>>> demonstration purposes. However, most .R files I find out there are
>>> rather short without much structure.
>>>
>>> Any links to candidate (open source) files would be appreciated.
>>>
>>> --
>>> cheers,
>>> Thorsten
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>


From rawal.shreya at gmail.com  Wed Jun 12 14:58:40 2013
From: rawal.shreya at gmail.com (Shreya Rawal)
Date: Wed, 12 Jun 2013 08:58:40 -0400
Subject: [R] Combining CSV data
In-Reply-To: <1370984985.52466.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <CALFKK3xTtutDvi12LpSp4M6hyn0bFR1-Z+7aWMTA6AT8xWG5mA@mail.gmail.com>
	<1370904118.98031.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1370916881.76218.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<CALFKK3zsGycu_yzqM6D1J8fD1px35+ypABQo-K9DXkOhQNSCWg@mail.gmail.com>
	<1370970132.53955.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CALFKK3yYMZYMA_pjPTme2U_F9VZq-mc85CMUqBjXNU26sTQr6w@mail.gmail.com>
	<1370984985.52466.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <CALFKK3zXwO3L6vcTj+=FC+dOJkXLHknXuReCs14phb77fQ3Utg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/49d0eb36/attachment.pl>

From maechler at stat.math.ethz.ch  Wed Jun 12 14:59:48 2013
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 12 Jun 2013 14:59:48 +0200
Subject: [R] agnes() in package cluster on R 2.14.1 and R 3.0.1
In-Reply-To: <CABpMX0skZ0YpPvPh2Ve_5v27JYTg=qqZKF0kgRxxYNV=Sg1e0A@mail.gmail.com>
References: <CABpMX0t+MJsb4mxj67iE3Q7QnNF_XuuKaPOR24AgN=r=iWnPpw@mail.gmail.com>
	<20917.53447.986054.159726@stat.math.ethz.ch>
	<CABpMX0skZ0YpPvPh2Ve_5v27JYTg=qqZKF0kgRxxYNV=Sg1e0A@mail.gmail.com>
Message-ID: <20920.28868.985646.145811@stat.math.ethz.ch>

>>>>> Hugo Varet <varethugo at gmail.com>
>>>>>     on Tue, 11 Jun 2013 15:15:36 +0200 writes:

    > Dear Martin,
    > Thank you for your answer. Here is the exact call to agnes():
    > setwd("E:/Hugo")
    > library(cluster)
    > load("mydata.rda")
    > tableauTani<-dist.binary(mydata, method = 4, diag = FALSE, upper = FALSE)
    > resAgnes.Tani<-agnes(tableauTani, diss = inherits(tableauTani,
    > "dist"),method = "ward")
    > classe.agnTani.3 <- cutree(resAgnes.Tani, 3)

    > I'm going to send you the data in a separated e-mail.

Thank you, Hugo, and I got that alright.

I can see that many of the distances are *identical*, because
your data is completely binary.
>From experience, I know that this can lead (for some algorithms)
to "arbitrary" decisions in clustering, namely when two
*pairs* of observations / clusters have exactly the same
distance, it is somewhat random which of the pair is "merged" /
"fused" first, in a bottom up hierarchical algorithm such as agnes().

To reproduce your example (above) I need however to know 
*where* you got the the  dist.binary()  function from.
It is not part of standard R nor of the cluster package.

Regards,
Martin


    > Regards,

    > Hugo


    > Le lundi 10 juin 2013, Martin Maechler <maechler at stat.math.ethz.ch> a
    > ?crit :
    >>>>>>> Hugo Varet <varethugo at gmail.com>
    >>>>>>> on Sun, 9 Jun 2013 11:43:32 +0200 writes:
    >> 
    >> > Dear R users,
    >> > I discovered something strange using the function agnes() of the
    > cluster
    >> > package on R 3.0.1 and on R 2.14.1. Indeed, the clusterings
    > obtained are
    >> > different whereas I ran exactly the same code.
    >> 
    >> hard to believe... but ..
    >> 
    >> > I quickly looked at the source code of the function and I
    > discovered that
    >> > there was an important change: agnes() in R 2.14.1 used a FORTRAN
    > code
    >> > whereas agnes() in R 3.0.1 uses a C code.
    >> 
    >> well, it does so quite a bit longer, e.g., also in R 2.15.0
    >> 
    >> > Here is one of the contingency table between R 2.14.1 and R 3.0.1:
    >> > classe.agnTani.2.14.1
    >> > classe.agnTani.3.0.1      1        2       3
    >> > 1    74       0    229
    >> > 2     0    235        0
    >> > 3  120       0      15
    >> 
    >> > So, I was wondering if it was normal that the C and FORTRAN codes
    > give
    >> > different results?
    >> 
    >> It's not normal, and I'm pretty sure I have had many many
    >> examples which gave identical results.
    >> 
    >> Can you provide a reproducible example, please?
    >> If the example is too large [for dput() ], please send me the *.rda
    >> file produced from
    >> save(<your data>, file=<the file I neeed>)
    >> *and* a the exact call to agnes() for your data.
    >> 
    >> Thank you in advance!
    >> 
    >> Martin Maechler,
    >> the one you could have e-mailed directly
    >> to using   maintainer("cluster") ...
    >> 
    >> 
    >> > Best regards,
    >> > Hugo Varet
    >> 
    >> > [[alternative HTML version deleted]]
    >> ^^^^^^^^^^^^^ try to avoid, please ^^^^^^^^^^^^^^^^^
    >> 
    >> > ______________________________________________
    >> > R-help at r-project.org mailing list
    >> > https://stat.ethz.ch/mailman/listinfo/r-help
    >> > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html
    >> > and provide commented, minimal, self-contained, reproducible code.
    >> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    >> yes indeed, please.
    >>


From tim_smith_666 at yahoo.com  Wed Jun 12 15:08:27 2013
From: tim_smith_666 at yahoo.com (Tim Smith)
Date: Wed, 12 Jun 2013 06:08:27 -0700
Subject: [R] GGally installation problems
Message-ID: <1371042507.14498.YahooMailNeo@web121203.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/08ae5b99/attachment.pl>

From smartpink111 at yahoo.com  Wed Jun 12 15:10:29 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 12 Jun 2013 06:10:29 -0700 (PDT)
Subject: [R] Combining CSV data
In-Reply-To: <CALFKK3zXwO3L6vcTj+=FC+dOJkXLHknXuReCs14phb77fQ3Utg@mail.gmail.com>
References: <CALFKK3xTtutDvi12LpSp4M6hyn0bFR1-Z+7aWMTA6AT8xWG5mA@mail.gmail.com>
	<1370904118.98031.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1370916881.76218.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<CALFKK3zsGycu_yzqM6D1J8fD1px35+ypABQo-K9DXkOhQNSCWg@mail.gmail.com>
	<1370970132.53955.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CALFKK3yYMZYMA_pjPTme2U_F9VZq-mc85CMUqBjXNU26sTQr6w@mail.gmail.com>
	<1370984985.52466.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<CALFKK3zXwO3L6vcTj+=FC+dOJkXLHknXuReCs14phb77fQ3Utg@mail.gmail.com>
Message-ID: <1371042629.5707.YahooMailNeo@web142603.mail.bf1.yahoo.com>

HI Shreya,
#Looks like you run the two line code as a single line.

result3<- 
data.frame(result2[,-5],read.table(text=as.character(result2$comment),sep="|",fill=TRUE,na.strings=""),stringsAsFactors=FALSE)


colnames(result3)[5:7]<- paste0("DataComment",1:3)

?result3
#? Row_ID_CR???????????????? Data1??????? Data2??????? Data3????? DataComment1
#1???????? 1??????????????????? aa?????????? bb?????????? cc This is comment 1
#2???????? 2??????????????????? dd?????????? ee?????????? ff This is comment 1
#?????? DataComment2????? DataComment3
#1 This is comment 2 This is comment 3
#2????????????? <NA>????????????? <NA>



A.K.


________________________________
From: Shreya Rawal <rawal.shreya at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Cc: R help <r-help at r-project.org>; jim holtman <jholtman at gmail.com> 
Sent: Wednesday, June 12, 2013 8:58 AM
Subject: Re: [R] Combining CSV data



Great, thanks Arun, but I seem to be running into this error. Not sure what did I miss.

> result<-data.frame(final_ouput[,-5],read.table(text=as.character(final_output$comment),sep="|",fill=TRUE,na.strings=""),stringsAsFactors=FALSE)colnames(result)[5:7]<-paste0("DataComment",1:3)
Error: unexpected symbol in "result<-data.frame(final_ouput[,-5],read.table(text=as.character(final_output$comment),sep="|",fill=TRUE,na.strings=""),stringsAsFactors=FALSE)colnames"



On Tue, Jun 11, 2013 at 5:09 PM, arun <smartpink111 at yahoo.com> wrote:


>
>
>HI,
>You could use:
>result3<- data.frame(result2[,-5],read.table(text=as.character(result2$comment),sep="|",fill=TRUE,na.strings=""),stringsAsFactors=FALSE)
>colnames(result3)[5:7]<- paste0("DataComment",1:3)
>
>A.K.
>________________________________
>From: Shreya Rawal <rawal.shreya at gmail.com>
>To: arun <smartpink111 at yahoo.com>
>Sent: Tuesday, June 11, 2013 4:22 PM
>
>Subject: Re: [R] Combining CSV data
>
>
>
>Hey Arun,
>
>I guess you could guide me with this a little bit. I have been working on the solution Jim suggested (and also because that I could understand it with my little knowledge of R :))
>
>So with these commands I am able to get the data in this format:
>
>> fileA <- read.csv(text = "Row_ID_CR, ? Data1, ? ?Data2, ? ?Data3
>+ 1, ? ? ? ? ? ? ? ? ? aa, ? ? ? ? ?bb, ? ? ? ? ?cc
>+ 2, ? ? ? ? ? ? ? ? ? dd, ? ? ? ? ?ee, ? ? ? ? ?ff",?as.is?= TRUE)
>>?
>> fileB <- read.csv(text = "Row_ID_N, ? Src_Row_ID, ? DataN1
>+ 1a, ? ? ? ? ? ? ? 1, ? ? ? ? ? ? ? ? ? This is comment 1
>+ 2a, ? ? ? ? ? ? ? 1, ? ? ? ? ? ? ? ? ? This is comment 2
>+ 3a, ? ? ? ? ? ? ? 2, ? ? ? ? ? ? ? ? ? This is comment 1
>+ 4a, ? ? ? ? ? ? ? 1, ? ? ? ? ? ? ? ? ? This is comment 3",?as.is?= TRUE)
>>?
>> # get rid of leading/trailing blanks on comments
>> fileB$DataN1 <- gsub("^ *| *$", "", fileB$DataN1)
>>?
>> # merge together
>> result <- merge(fileA, fileB, by.x = 'Row_ID_CR', by.y = "Src_Row_ID")
>>?
>> # now partition by Row_ID_CR and aggregate the comments
>> result2 <- do.call(rbind,?
>+ ? ? lapply(split(result, result$Row_ID_CR), function(.grp){
>+ ? ? ? ? cbind(.grp[1L, -c(5,6)], comment = paste(.grp$DataN1, collapse = '|'))
>+ ? ? })
>+ )
>
>Row_ID_CR ? ? ? ? ? ? ? ? Data1 ? ? ? ?Data2 ? ? ? ?Data3 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? comment
>1 ? ? ? ? 1 ? ? ? ? ? ? ? ? ? ?aa ? ? ? ? ? bb ? ? ? ? ? cc ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?This is comment 1| This is comment 2| This is comment 3
>2 ? ? ? ? 2 ? ? ? ? ? ? ? ? ? ?dd ? ? ? ? ? ee ? ? ? ? ? ff ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?This is comment 1| This is Comment 2
>
>I can even split the last column by this:?strsplit(as.character(result2$comment), split='\\|')
>
>[[1]]
>[1] "This is comment 1" "This is comment 2" " This is comment 3"
>
>[[2]]
>[1] "This is comment 1" "This is comment 2"
>
>
>but now I am not sure how to combine everything together. I guess by now you must have realized how new I am to R :)
>
>Thanks!!
>Shreya
>
>
>
>
>
>
>On Tue, Jun 11, 2013 at 1:02 PM, arun <smartpink111 at yahoo.com> wrote:
>
>Hi,
>>If the dataset is like this with the comments in the order:
>>
>>dat2<-read.table(text="
>>Row_ID_N,? Src_Row_ID,? DataN1
>>1a,????????????? 1,????????????????? This is comment 1
>>2a,????????????? 1,????????????????? This is comment 2
>>3a,????????????? 2,????????????????? This is comment 1
>>4a,????????????? 1,????????????????? This is comment 3
>>",sep=",",header=TRUE,stringsAsFactors=FALSE)
>>
>>dat3<-read.table(text="
>>Row_ID_N,? Src_Row_ID,? DataN1
>>1a,????????????? 1,????????????????? This is comment 1
>>2a,????????????? 1,????????????????? This is comment 2
>>3a,????????????? 2,????????????????? This is comment 1?? #
>>
>>4a,????????????? 1,????????????????? This is comment 3
>>5a,???????? 2,????????????????? This is comment 2? #
>>
>>",sep=",",header=TRUE,stringsAsFactors=FALSE)
>>
>>
>>library(stringr)
>>library(plyr)
>>fun1<- function(data1,data2){
>>??? data2$DataN1<- str_trim(data2$DataN1)??
>>??????? res<- merge(data1,data2,by.x=1,by.y=2)
>>??? res1<- res[,-5]
>>??? res2<- ddply(res1,.(Row_ID_CR,Data1,Data2,Data3),summarize,DataN1=list(DataN1))
>>??? Mx1<- max(sapply(res2[,5],length))
>>??? res3<- data.frame(res2[,-5],do.call(rbind,lapply(res2[,5],function(x){
>>????????????????????????????????? c(x,rep(NA,Mx1-length(x)))
>>
>>????????????????????????????????? })),stringsAsFactors=FALSE)
>>??? colnames(res3)[grep("X",colnames(res3))]<- paste0("DataComment",gsub("[[:alpha:]]","",colnames(res3)[grep("X",colnames(res3))]))
>>??? res3
>>??? }???
>>
>>?????
>>fun1(dat1,dat2)
>>#? Row_ID_CR??????????????? Data1??????? Data2??????? Data3????? DataComment1
>>#1???????? 1?????????????????? aa?????????? bb?????????? cc This is comment 1
>>
>>#2???????? 2?????????????????? dd?????????? ee?????????? ff This is comment 1
>>#?????? DataComment2????? DataComment3
>>#1 This is comment 2 This is comment 3
>>#2????????????? <NA>????????????? <NA>
>>
>>?fun1(dat1,dat3)
>>#? Row_ID_CR??????????????? Data1??????? Data2??????? Data3????? DataComment1
>>#1???????? 1?????????????????? aa?????????? bb?????????? cc This is comment 1
>>
>>#2???????? 2?????????????????? dd?????????? ee?????????? ff This is comment 1
>>?# ???? DataComment2????? DataComment3
>>#1 This is comment 2 This is comment 3
>>
>>#2 This is comment 2????????????? <NA>
>>
>>
>>Otherwise, you need to provide an example that matches the real dataset.
>>A.K.
>>
>>________________________________
>>From: Shreya Rawal <rawal.shreya at gmail.com>
>>To: arun <smartpink111 at yahoo.com>
>>Cc: R help <r-help at r-project.org>
>>Sent: Tuesday, June 11, 2013 12:22 PM
>>
>>Subject: Re: [R] Combining CSV data
>>
>>
>>
>>Hi Arun,
>>
>>Thanks for your reply. Unfortunately the Comments are just text in the real data. There is no way to differentiate based on the value of the Comments column. I guess because of that reason I couldn't get your solution to work properly. Do you think I can try it for a more general case where we don't merger/split the comments based on the values?
>>
>>Thanks for your help, I appreciate! ??
>>
>>
>>
>>On Mon, Jun 10, 2013 at 10:14 PM, arun <smartpink111 at yahoo.com> wrote:
>>
>>HI,
>>>I am not sure about your DataN1 column.? If there is any identifier to differentiate the comments (in this case 1,2,3), then it will easier to place that in the correct column.
>>>? My previous solution is not helpful in situations like these:
>>>
>>>dat2<-read.table(text="
>>>Row_ID_N,? Src_Row_ID,? DataN1
>>>1a,????????????? 1,????????????????? This is comment 1
>>>2a,????????????? 1,????????????????? This is comment 2
>>>3a,????????????? 2,????????????????? This is comment 2
>>>4a,????????????? 1,????????????????? This is comment 3
>>>",sep=",",header=TRUE,stringsAsFactors=FALSE)
>>>dat3<-read.table(text="
>>>
>>>Row_ID_N,? Src_Row_ID,? DataN1
>>>1a,????????????? 1,????????????????? This is comment 1
>>>2a,????????????? 1,????????????????? This is comment 2
>>>3a,????????????? 2,????????????????? This is comment 3
>>>4a,????????????? 1,????????????????? This is comment 3
>>>5a,??? ??? ?2,????????????????? This is comment 2
>>>",sep=",",header=TRUE,stringsAsFactors=FALSE)
>>>
>>>
>>>library(stringr)
>>>library(plyr)
>>>fun1<- function(data1,data2){
>>>??? data2$DataN1<- str_trim(data2$DataN1)???
>>>??????? res<- merge(data1,data2,by.x=1,by.y=2)
>>>??? res1<- res[,-5]
>>>??? res2<- ddply(res1,.(Row_ID_CR,Data1,Data2,Data3),summarize,DataN1=list(DataN1))
>>>??? Mx1<- max(sapply(res2[,5],length))
>>>??? res3<- data.frame(res2[,-5],do.call(rbind,lapply(res2[,5],function(x){
>>>??? ??? ??? ??? ??? ??? ??? ??? ? indx<- as.numeric(gsub("[[:alpha:]]","",x))
>>>??? ??? ??? ??? ??? ??? ??? ??? ? x[match(seq(Mx1),indx)]
>>>??? ??? ??? ??? ??? ??? ??? ??? ? })),stringsAsFactors=FALSE)
>>>
>>>??? colnames(res3)[grep("X",colnames(res3))]<- paste0("DataComment",gsub("[[:alpha:]]","",colnames(res3)[grep("X",colnames(res3))]))
>>>??? res3
>>>??? }??? ??? ??
>>>fun1(dat1,dat2)
>>>
>>>#? Row_ID_CR??????????????? Data1??????? Data2??????? Data3????? DataComment1
>>>#1???????? 1?????????????????? aa?????????? bb?????????? cc This is comment 1
>>>#2???????? 2?????????????????? dd?????????? ee?????????? ff????????????? <NA>
>>>
>>>#?????? DataComment2????? DataComment3
>>>#1 This is comment 2 This is comment 3
>>>#2 This is comment 2????????????? <NA>
>>>?fun1(dat1,dat3)
>>>
>>>#? Row_ID_CR??????????????? Data1??????? Data2??????? Data3????? DataComment1
>>>#1???????? 1?????????????????? aa?????????? bb?????????? cc This is comment 1
>>>#2???????? 2?????????????????? dd?????????? ee?????????? ff????????????? <NA>
>>>
>>>#?????? DataComment2????? DataComment3
>>>#1 This is comment 2 This is comment 3
>>>#2 This is comment 2 This is comment 3
>>>
>>>
>>>
>>>A.K.
>>>
>>>
>>>----- Original Message -----
>>>
>>>From: arun <smartpink111 at yahoo.com>
>>>To: Shreya Rawal <rawal.shreya at gmail.com>
>>>Cc: R help <r-help at r-project.org>
>>>Sent: Monday, June 10, 2013 6:41 PM
>>>Subject: Re: [R] Combining CSV data
>>>
>>>Hi,
>>>Try this:
>>>
>>>dat1<-read.table(text="
>>>Row_ID_CR,? Data1,??? Data2,??? Data3
>>>1,????????????????? aa,????????? bb,????????? cc
>>>2,????????????????? dd,????????? ee,????????? ff
>>>",sep=",",header=TRUE,stringsAsFactors=FALSE)
>>>
>>>dat2<-read.table(text="
>>>Row_ID_N,? Src_Row_ID,? DataN1
>>>1a,????????????? 1,????????????????? This is comment 1
>>>2a,????????????? 1,????????????????? This is comment 2
>>>3a,????????????? 2,????????????????? This is comment 1
>>>4a,????????????? 1,????????????????? This is comment 3
>>>",sep=",",header=TRUE,stringsAsFactors=FALSE)
>>>library(stringr)
>>>dat2$DataN1<-str_trim(dat2$DataN1)
>>>res<- merge(dat1,dat2,by.x=1,by.y=2)
>>>?res1<-res[,-5]
>>>library(plyr)
>>>?res2<-ddply(res1,.(Row_ID_CR,Data1,Data2,Data3),summarize, DataN1=list(DataN1))
>>>?res2
>>>?# Row_ID_CR??????????????? Data1??????? Data2??????? Data3
>>>#1???????? 1?????????????????? aa?????????? bb?????????? cc
>>>#2???????? 2?????????????????? dd?????????? ee?????????? ff
>>>#?????????????????????????????????????????????????? DataN1
>>>#1 This is comment 1, This is comment 2, This is comment 3
>>>#2?????????????????????????????????????? This is comment 1
>>>
>>>
>>>
>>>res3<-data.frame(res2[,-5],t(apply(do.call(rbind,res2[,5]),1,function(x) {x[duplicated(x)]<-NA;x})))
>>>?colnames(res3)[grep("X",colnames(res3))]<- paste0("DataComment",gsub("[[:alpha:]]","",colnames(res3)[grep("X",colnames(res3))]))
>>>res3
>>>#? Row_ID_CR??????????????? Data1??????? Data2??????? Data3????? DataComment1
>>>#1???????? 1?????????????????? aa?????????? bb?????????? cc This is comment 1
>>>#2???????? 2?????????????????? dd?????????? ee?????????? ff This is comment 1
>>>#?????? DataComment2????? DataComment3
>>>#1 This is comment 2 This is comment 3
>>>#2????????????? <NA>????????????? <NA>
>>>
>>>A.K.
>>>
>>>
>>>----- Original Message -----
>>>From: Shreya Rawal <rawal.shreya at gmail.com>
>>>To: r-help at r-project.org
>>>Cc:
>>>Sent: Monday, June 10, 2013 4:38 PM
>>>Subject: [R] Combining CSV data
>>>
>>>Hello R community,
>>>
>>>I am trying to combine two CSV files that look like this:
>>>
>>>File A
>>>
>>>Row_ID_CR,?? Data1,? ? Data2,? ? Data3
>>>1,? ? ? ? ? ? ? ? ?? aa,? ? ? ? ? bb,? ? ? ? ? cc
>>>2,? ? ? ? ? ? ? ? ?? dd,? ? ? ? ? ee,? ? ? ? ? ff
>>>
>>>
>>>File B
>>>
>>>Row_ID_N,?? Src_Row_ID,?? DataN1
>>>1a,? ? ? ? ? ? ?? 1,? ? ? ? ? ? ? ? ?? This is comment 1
>>>2a,? ? ? ? ? ? ?? 1,? ? ? ? ? ? ? ? ?? This is comment 2
>>>3a,? ? ? ? ? ? ?? 2,? ? ? ? ? ? ? ? ?? This is comment 1
>>>4a,? ? ? ? ? ? ?? 1,? ? ? ? ? ? ? ? ?? This is comment 3
>>>
>>>And the output I am looking for is, comparing the values of Row_ID_CR and
>>>Src_Row_ID
>>>
>>>Output
>>>
>>>ROW_ID_CR,? ? Data1,? ? Data2,? ? Data3,? ? DataComment1,
>>>DataComment2,? ? ? ? ? DataComment3
>>>1,? ? ? ? ? ? ? ? ? ? ? aa,? ? ? ?? bb,? ? ? ?? cc,? ? ? ? This is
>>>comment1,? ? This is comment2,? ?? This is comment 3
>>>2,? ? ? ? ? ? ? ? ? ? ? dd,? ? ? ? ? ee,? ? ? ?? ff,? ? ? ? ? This is
>>>comment1
>>>
>>>
>>>I am a novice R user, I am able to replicate a left join but I need a bit
>>>more in the final result.
>>>
>>>
>>>Thanks!!
>>>
>>>??? [[alternative HTML version deleted]]
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>


From rawal.shreya at gmail.com  Wed Jun 12 15:15:56 2013
From: rawal.shreya at gmail.com (Shreya Rawal)
Date: Wed, 12 Jun 2013 09:15:56 -0400
Subject: [R] Combining CSV data
In-Reply-To: <1371042629.5707.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <CALFKK3xTtutDvi12LpSp4M6hyn0bFR1-Z+7aWMTA6AT8xWG5mA@mail.gmail.com>
	<1370904118.98031.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1370916881.76218.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<CALFKK3zsGycu_yzqM6D1J8fD1px35+ypABQo-K9DXkOhQNSCWg@mail.gmail.com>
	<1370970132.53955.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CALFKK3yYMZYMA_pjPTme2U_F9VZq-mc85CMUqBjXNU26sTQr6w@mail.gmail.com>
	<1370984985.52466.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<CALFKK3zXwO3L6vcTj+=FC+dOJkXLHknXuReCs14phb77fQ3Utg@mail.gmail.com>
	<1371042629.5707.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <CALFKK3xTk=CMgk+2YGYqffsBMjXhR9Fjf+EhYQ2Nx0VWryYK1A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/a7365155/attachment.pl>

From chrisaa at med.umich.edu  Wed Jun 12 15:34:46 2013
From: chrisaa at med.umich.edu (Andrews, Chris)
Date: Wed, 12 Jun 2013 13:34:46 +0000
Subject: [R] survreg with measurement uncertainties
In-Reply-To: <CAAF=944aDzh27CT1-5rYMX57=jKXRHxGvGCdhwcnqsYSSCyjkQ@mail.gmail.com>
References: <CAAF=944aDzh27CT1-5rYMX57=jKXRHxGvGCdhwcnqsYSSCyjkQ@mail.gmail.com>
Message-ID: <30411786F64EEF46856EFBA2CD917799E052C1@UHEXMBSPR03.umhs.med.umich.edu>

survreg allows interval censored data, if that is how you want to represent measurement uncertainty.  See

?Surv

-----Original Message-----
From: Kyle Penner [mailto:kpenner at as.arizona.edu] 
Sent: Tuesday, June 11, 2013 8:02 PM
To: r-help at r-project.org
Subject: [R] survreg with measurement uncertainties

Hello,

I have some measurements that I am trying to fit a model to.  I also have uncertainties for these measurements.  Some of the measurements are not well detected, so I'd like to use a limit instead of the actual measurement.  (I am always dealing with upper limits, i.e. left censored data.)

I have successfully run survreg using the combination of well detected measurements and limits, but I would like to include the measurement uncertainty (for the well detected measurements) in the fitting.  As far as I can tell, survreg doesn't support this.  Does anyone have a suggestion for how to accomplish this?

Thanks,

Kyle


**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues 

From jrkrideau at inbox.com  Wed Jun 12 15:47:49 2013
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 12 Jun 2013 05:47:49 -0800
Subject: [R] help using code
In-Reply-To: <CDDD0674.2742%montana3946@gmail.com>
References: <51b79f26.7090204@sapo.pt>
Message-ID: <54781D4CEDB.0000033Ajrkrideau@inbox.com>

Have a look at http://www.burns-stat.com/documents/tutorials/impatient-r/ . I think the section on blank screen syndrome may help.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: montana3946 at gmail.com
> Sent: Tue, 11 Jun 2013 16:59:34 -0700
> To: ruipbarradas at sapo.pt
> Subject: Re: [R] help using code
> 
> Hello,
> 
> Thanks for the help!
> 
> Your answer resolved my problem with the function I listed, but brought
> up
> a larger question. How is the output of the importdata function stored
> for
> use with other functions (as in, how do I call on that data for use with
> other functions)? As a simple example I have another function:
> 
> meanXY = function(xyzuvw) {
> 	xy = c(mean(xyzuvw$x), mean(xyzuvw$y))
> 	return(xy)
> }
> 
> I know that the xyzuvw portion is referring to the output of the
> importdata function, but I don't know how to call up the necessary data
> (hope this makes sense).
> 
> Thanks again for the help!
> 
> John
> 
> 
> 
> 
> On 6/11/13 3:05 PM, "Rui Barradas" <ruipbarradas at sapo.pt> wrote:
> 
> >Hello,
>> 
> >I believe you are making a confusion on how to call a function in R. You
> >don't replace the argument in the function declaration. what you do is
> >to call the function like this:
>> 
> >importdata("~/path to/filename.xyzuvwrgb")
>> 
> >leaving the function definition alone.
>> 
> >Hope this helps,
>> 
> >Rui Barradas
>> 
> >Em 11-06-2013 19:52, John McDermott escreveu:
>>> Hi R-helpers,
>>> 
>>> I inherited some code that I'm trying to use. As a very new R user I'm
>>> having some confusion.
>>> 
>>> I have some input files in the form: filename.xyzuvwrgb which I'm
> >>trying to
>>> import using:
>>> 
>>> importdata = function(filename) {
>>> 
>>>      p = scan(filename,what=list(x = double(), y = double(), z =
> >>double(), u
>>> = double(),v=double(),w=double()),skip=1,flush=TRUE,sep=" ")
>>> 
>>>      return(data.frame(x=p$x, y=p$y, z=p$z, u=p$u, v=p$v, w=p$w))
>>> 
>>> }
>>> 
>>> 
>>> 
>>> For the filename I replaced both with "~/path to/filename.xyzuvwrgb"
> >>and I
>>> get the following errors:
>>> 
>>> 
>>> 
>>> Error: unexpected string constant in "importdata =
>>> function("~/Desktop/thrustScarp1.xyzuvw""
>>> 
>>> 
>>> 
>>> Error: no function to return from, jumping to top level
>>> 
>>> 
>>> 
>>> Error: unexpected '}' in "}"
>>> 
>>> 
>>> 
>>> I'm assuming it has to do with how I am using/formatted the
>>> function(filename) portion. How can I get this to work?
>>> 
>>> 
>>> 
>>> Thanks for the help!
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
> >>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From therneau at mayo.edu  Wed Jun 12 15:51:00 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Wed, 12 Jun 2013 08:51:00 -0500
Subject: [R] survreg with measurement uncertainties
In-Reply-To: <mailman.25.1371031207.11759.r-help@r-project.org>
References: <mailman.25.1371031207.11759.r-help@r-project.org>
Message-ID: <51B87CC4.6050800@mayo.edu>

I will assume that you are talking about uncertainty in the response.  Then one simple way 
to fit the model is to use case weights that are proprional to 1/variance, along with 
+cluster(id) in the model statement to get a correct variance for this case.  In linear 
models this would be called the "White" or "Horvitz-Thompsen" or "GEE working 
independence" variance estimate, depending on which literature you happen to be reading 
(economics, survey sampling, or biostat).

Now if you are talking about errors in the predictor variables, that is a much harder problem.

Terry Therneau


On 06/12/2013 05:00 AM, Kyle Penner wrote:
> Hello,
>
> I have some measurements that I am trying to fit a model to.  I also
> have uncertainties for these measurements.  Some of the measurements
> are not well detected, so I'd like to use a limit instead of the
> actual measurement.  (I am always dealing with upper limits, i.e. left
> censored data.)
>
> I have successfully run survreg using the combination of well detected
> measurements and limits, but I would like to include the measurement
> uncertainty (for the well detected measurements) in the fitting.  As
> far as I can tell, survreg doesn't support this.  Does anyone have a
> suggestion for how to accomplish this?
>
> Thanks,
>
> Kyle


From jrkrideau at inbox.com  Wed Jun 12 16:00:14 2013
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 12 Jun 2013 06:00:14 -0800
Subject: [R] ggpairs in GGally replaces plotmatrix in ggplot2
In-Reply-To: <CA+vqiLEWQvWuv-w65T8kM5n7xjVx0dTh1P6ij_ZMt+kOFf43Uw@mail.gmail.com>
References: <b3731b5f-eb81-4901-95c6-2c7634bce9ac@gmail.com>
	<mailman.27.1370944809.23972.r-help@r-project.org>
	<48abd695fdd.000001a7jrkrideau@inbox.com>
	<c34d38dc-2cc9-4b9a-a840-965cfb958963@gmail.com>
Message-ID: <5493DF4679B.0000035Fjrkrideau@inbox.com>

Thanks, I obviously read the help incorrectly. It does give the same results as plotmatrix(dat1)

I take back "some" of the nasty thoughts I was thinking about ggpairs(). 

Any idea of the problem with RSudio? Keith notices the same speed difference (but no crash) on a Mac while I'm runnng Ubuntu 12.10.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: istazahn at gmail.com
> Sent: Tue, 11 Jun 2013 17:54:55 -0400
> To: kw1958 at gmail.com
> Subject: Re: [R] ggpairs in GGally replaces plotmatrix in ggplot2
> 
> I think the ggpairs equivalent is
> 
> ggpairs(dat1, upper=list(continuous="points"), axisLabels="show")
> 
> oddly enough.
> 
> ggpairs(dat1)
> 
> should default to the same graph as
> 
> plotmatrix(dat1)
> 
> but there seems to be a conflict between the default
> axisLabels="internal" and density plots. Or something. There is a bug
> report at https://github.com/ggobi/ggally/issues/18 that may be
> related.
> 
> Best,
> Ista
> 
> On Tue, Jun 11, 2013 at 4:07 PM, Keith S Weintraub <kw1958 at gmail.com>
> wrote:
>> Yes. I was able to run it in RStudio but it did seem much slower than in
>> R.app (on the Mac).
>> 
>> Note that the "it" that I ran still didn't give the same results as
>> plotmatrix.
>> 
>> Thanks,
>> KW
>> 
>> --
>> 
>> On Jun 11, 2013, at 11:16 AM, John Kane <jrkrideau at inbox.com> wrote:
>> 
>>> Note that the code below might not work in RStudio.  I am gettting an
>>> intermittant crash when I use the ggpairs() command in RStudio and
>>> sometimes I get a density plot and sometimes not.  Also the command is
>>> taking 3-5 minutes to execute.
>>> 
>>> This may just be a peculiarity of my machine but the code works fine
>>> and fairly fast in a terminal.
>>> 
>>> John Kane
>>> Kingston ON Canada
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From smartpink111 at yahoo.com  Wed Jun 12 16:09:45 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 12 Jun 2013 07:09:45 -0700 (PDT)
Subject: [R] Add a column to a dataframe based on multiple other
	column	values
In-Reply-To: <1370985797.19936.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <CAGUdn1CxLfxXNzDWQUo515h_h5qeKFMUyG5MsDb1qn6gBQ7cVg@mail.gmail.com>
	<1370985797.19936.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1371046185.32744.YahooMailNeo@web142601.mail.bf1.yahoo.com>

HI,
You could also try:
dat2<- dat1[-ncol(dat1)]
fun1<- function(dat,value){
??? datNew<- dat
??? n1<- ncol(datNew)
??? indx1<- seq(1,n1,by=2)
??? indx2<- indx1+1
??? datNew[indx2][datNew[indx1]< value]<-NA
??? dat$output<-rowMeans(datNew[indx2],na.rm=TRUE)
??? dat 
??? }
??? fun1(dat2,10)
?# x1? y1? x2? y2?? x3 y3?? output
#1? 2 100 190? 99 1430 79 89.00000
#2? 2 100 192? 63 1431 75 69.00000
#3? 2 100 192? 63 1444 51 57.00000
#4? 3?? 0 195? 99 1499 50 74.50000
#5? 3?? 0 198? 98 1500 80 89.00000
#6 30?? 0 198 100 1451 97 65.66667
#7 32 100 868 100 1451 97 99.00000
#8 33? 82 870 100 1490 97 93.00000
#9 33?? 0 871? 82 1494 85 55.66667
A.K.




----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Tom Oates <toates19 at gmail.com>
Cc: R help <r-help at r-project.org>
Sent: Tuesday, June 11, 2013 5:23 PM
Subject: Re: [R] Add a column to a dataframe based on multiple other column	values

HI,
May be this helps:
dat1<- read.table(text="
x1??? y1??? x2??? y2??? x3??? y3??? output
2??? 100??? 190??? 99??? 1430??? 79??? 89
2??? 100??? 192??? 63??? 1431??? 75??? 69
2??? 100??? 192??? 63??? 1444??? 51??? 57
3??? 0??? 195??? 99??? 1499??? 50??? 74.5
3??? 0??? 198??? 98??? 1500??? 80??? 89
30??? 0??? 198??? 100??? 1451??? 97??? 65.66666667
32??? 100??? 868??? 100??? 1451??? 97??? 99
33??? 82??? 870??? 100??? 1490??? 97??? 93
33??? 0??? 871??? 82??? 1494??? 85??? 55.66666667
",sep="",header=TRUE)

dat1$output2<-apply(dat1[,-7],1,function(x) {indx<-((seq(x)-1)%%2+1);indx1<-indx==1; indx2<-indx==2;mean(x[indx2][x[indx1]>10])})
?dat1
#? x1? y1? x2? y2?? x3 y3?? output? output2
#1? 2 100 190? 99 1430 79 89.00000 89.00000
#2? 2 100 192? 63 1431 75 69.00000 69.00000
#3? 2 100 192? 63 1444 51 57.00000 57.00000
#4? 3?? 0 195? 99 1499 50 74.50000 74.50000
#5? 3?? 0 198? 98 1500 80 89.00000 89.00000
#6 30?? 0 198 100 1451 97 65.66667 65.66667
#7 32 100 868 100 1451 97 99.00000 99.00000
#8 33? 82 870 100 1490 97 93.00000 93.00000
#9 33?? 0 871? 82 1494 85 55.66667 55.66667
A.K.



----- Original Message -----
From: Tom Oates <toates19 at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Tuesday, June 11, 2013 12:07 PM
Subject: [R] Add a column to a dataframe based on multiple other column
??? values

Hi
I have a dataframe as below:

x1? ? y1? ? x2? ? y2? ? x3? ? y3? ? output
2? ? 100? ? 190? ? 99? ? 1430? ? 79? ? 89
2? ? 100? ? 192? ? 63? ? 1431? ? 75? ? 69
2? ? 100? ? 192? ? 63? ? 1444? ? 51? ? 57
3? ? 0? ? 195? ? 99? ? 1499? ? 50? ? 74.5
3? ? 0? ? 198? ? 98? ? 1500? ? 80? ? 89
30? ? 0? ? 198? ? 100? ? 1451? ? 97? ? 65.66666667
32? ? 100? ? 868? ? 100? ? 1451? ? 97? ? 99
33? ? 82? ? 870? ? 100? ? 1490? ? 97? ? 93
33? ? 0? ? 871? ? 82? ? 1494? ? 85? ? 55.66666667


In reality the dataframe has pairs of columns x & y up to a large number.
As you can see from the column labelled output in the dataframe; I want to
calculate the mean of each row of the yn columns, but only to include each
yn value in the calculation of the mean if the corresponding xn column
value is greater than 10.
So for row 1; you will see that only y2 & y3 are included in calculating
the output column, but for row 6 y1-y3 are all included.
Because the number of paired x & y columns is large I am not sure the best
way to achieve this.
Thanks in advance
Tom

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From pauljohn32 at gmail.com  Wed Jun 12 16:35:59 2013
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Wed, 12 Jun 2013 09:35:59 -0500
Subject: [R] Windows R_LIBS_USER confusion under R-3.0.1
Message-ID: <CAErODj8RbBB914Ve5y_7BhOWrbPuxEfV9cCD4D5q5z8+5g47hQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/46f3166c/attachment.pl>

From susanne.ettinger at gmail.com  Wed Jun 12 16:05:55 2013
From: susanne.ettinger at gmail.com (Susanne.Ettinger)
Date: Wed, 12 Jun 2013 16:05:55 +0200
Subject: [R] [R-SIG-Mac] problem with the installation of r commander on
	a mac
Message-ID: <E1700130-80B9-4463-A3DD-A65FDD4C2766@gmail.com>

Dear all,

I am trying to install R and the Rcmdr package on a MacOSX 10.8.4.

It appears that I keep getting the error message "Erreur : le chargement du package ou de l'espace de noms a ?chou? pour 'Rcmdr'" no matter what my approach is. Even downloading XQuartz-2.7.4 did not help.

I found the same problem outlined on the following website 

https://stat.ethz.ch/pipermail/r-help/2012-October/325305.html

and was wondering whether a solution to the problem has been stated since then and if you could help me with instructions how to proceed ?

Thank you very much for your help !

Kind regards,
Susanne

__________________________

Susanne ETTINGER
Postdoctoral researcher
-
Laboratoire Magmas et Volcans
UBP - UMR6524 CNRS - M163 IRD
5, rue Kessler
63038 Clermont-Ferrand
-
Tel : ++33 (0)6.18.27.54.93
Fax : ++33 (0)4.73.34.67.44
-
susanne.ettinger at gmail.com
__________________________

"The eye sees only what the mind is prepared to comprehend."
Robertson Davies


From bcrombie at utk.edu  Wed Jun 12 14:48:17 2013
From: bcrombie at utk.edu (bcrombie)
Date: Wed, 12 Jun 2013 05:48:17 -0700 (PDT)
Subject: [R] assigning global columns selection for all subset functions
 in script
In-Reply-To: <4BE7B57ED74.000006CBjrkrideau@inbox.com>
References: <1370967505746-4669252.post@n4.nabble.com>
	<4BE7B57ED74.000006CBjrkrideau@inbox.com>
Message-ID: <559C998F7039D84C9793AE43D9BBE9CE77A0F6EB@kmbx3.utk.tennessee.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/eb2b8752/attachment.pl>

From bcrombie at utk.edu  Wed Jun 12 14:53:53 2013
From: bcrombie at utk.edu (bcrombie)
Date: Wed, 12 Jun 2013 05:53:53 -0700 (PDT)
Subject: [R] assigning global columns selection for all subset functions
 in script
In-Reply-To: <A87EA6DC-7C50-42A2-A38D-23E137290FC2@comcast.net>
References: <1370967505746-4669252.post@n4.nabble.com>
	<A87EA6DC-7C50-42A2-A38D-23E137290FC2@comcast.net>
Message-ID: <559C998F7039D84C9793AE43D9BBE9CE77A0F703@kmbx3.utk.tennessee.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/9b52bfa6/attachment.pl>

From kota.hattori at canterbury.ac.nz  Wed Jun 12 15:34:13 2013
From: kota.hattori at canterbury.ac.nz (Kota Hattori)
Date: Thu, 13 Jun 2013 01:34:13 +1200
Subject: [R] Permutation test for GLM with proportional data
Message-ID: <482B1843EE6C72459D3BD633C43679EA04447F61@ucexchange2.canterbury.ac.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130613/afb9b599/attachment.pl>

From lv at asquote.com  Wed Jun 12 15:44:52 2013
From: lv at asquote.com (lv at asquote.com)
Date: Wed, 12 Jun 2013 21:44:52 +0800
Subject: [R] Fw: Hi, can you supply tablet pc?
Message-ID: <B70BQDL-QB2-1CSU-JA34-F3FZ225ENHPJ@asquote.com>

Hi, Kejora here.

I didn't get your reply.

Tq,
Kejora

-----------------------------------------------

From: lv at asquote.com
To: r-help at stat.math.ethz.ch
Date: 2013-06-07
Subject: Hi, can you supply tablet pc?

Hi. Kejora here.

I find you on google. Aere you doing distributing business?
We have a clients who need tablet pc urgently(first order about 500 pcs).
If you can provide, please send you products with price(!!!) to me.
Quadcore with 3G are prefered.

Tell me your phone or skype if you like to. I'll call you if your price is
good.

Thanks,
Kejora


From hanson at depauw.edu  Wed Jun 12 16:44:56 2013
From: hanson at depauw.edu (Bryan Hanson)
Date: Wed, 12 Jun 2013 10:44:56 -0400
Subject: [R] Proper way to implement package internal functions
Message-ID: <5577D149-534C-41D8-AB66-D0D901124279@depauw.edu>

[previously posted on Stack Overflow: http://stackoverflow.com/questions/17034309/hiding-undocumented-functions-in-a-package-use-of-function-name ]

I've got some functions I need to make available in a package, and I don't want to export them or write much documentation for them. I'd just hide them inside another function but they need to be available to several functions so doing it that way becomes a scoping and maintenance issue. What is the right way to do this?  By that I mean do they need special names, do they go somewhere other than the R subdirectory, can I put them in a single file, etc? I've checked out the manuals (e.g. Writing R Extensions 1.6.1), and what I'm after is like the .internals concept in the core, but I don't see any instructions about how to do this generally.

For example, if I have functions foo1 and foo2 in a file foofunc.R, and these are intended for internal use only, should they be called foo1 or .foo1?  And the file that holds them, should it be .foofunc.R or foofunc-internals?  What should the Rd look like, or do I even need one?

I know people do this in packages all the time and I feel like I've seen this somewhere, but I can't find any resources just now.  Perhaps a suggestion of a package that does things this way which I could study would be sufficient.

Thanks, Bryan

From 538280 at gmail.com  Wed Jun 12 16:53:02 2013
From: 538280 at gmail.com (Greg Snow)
Date: Wed, 12 Jun 2013 08:53:02 -0600
Subject: [R] odds ratio per standard deviation
In-Reply-To: <1371001120339-4669315.post@n4.nabble.com>
References: <1371001120339-4669315.post@n4.nabble.com>
Message-ID: <CAFEqCdysEi4EFqjZ1bNcwVtU_ORVD2FWmW7kNcv=UOputSO9Qw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/20c049ff/attachment.pl>

From murdoch.duncan at gmail.com  Wed Jun 12 16:57:48 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 12 Jun 2013 10:57:48 -0400
Subject: [R] Proper way to implement package internal functions
In-Reply-To: <5577D149-534C-41D8-AB66-D0D901124279@depauw.edu>
References: <5577D149-534C-41D8-AB66-D0D901124279@depauw.edu>
Message-ID: <51B88C6C.4030302@gmail.com>

On 12/06/2013 10:44 AM, Bryan Hanson wrote:
> [previously posted on Stack Overflow: http://stackoverflow.com/questions/17034309/hiding-undocumented-functions-in-a-package-use-of-function-name ]
>
> I've got some functions I need to make available in a package, and I don't want to export them or write much documentation for them. I'd just hide them inside another function but they need to be available to several functions so doing it that way becomes a scoping and maintenance issue. What is the right way to do this?  By that I mean do they need special names, do they go somewhere other than the R subdirectory, can I put them in a single file, etc? I've checked out the manuals (e.g. Writing R Extensions 1.6.1), and what I'm after is like the .internals concept in the core, but I don't see any instructions about how to do this generally.
>
> For example, if I have functions foo1 and foo2 in a file foofunc.R, and these are intended for internal use only, should they be called foo1 or .foo1?  And the file that holds them, should it be .foofunc.R or foofunc-internals?  What should the Rd look like, or do I even need one?
>
> I know people do this in packages all the time and I feel like I've seen this somewhere, but I can't find any resources just now.  Perhaps a suggestion of a package that does things this way which I could study would be sufficient.

The best way to do this is simply not to export those functions in your 
NAMESPACE file.  If you want to use a naming convention
internally to remind yourself that those are private, you can do so, but 
R doesn't force one on you, and there are no really popular conventions 
in use.   R won't complain if you don't document those functions at all.

There may have been other advice in the version 1.6.1 manual, but that 
is seriously out of date, more than 10 years old.  I recommend that you 
update to 3.0.1.

Duncan Murdoch


From jfox at mcmaster.ca  Wed Jun 12 17:03:41 2013
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 12 Jun 2013 11:03:41 -0400
Subject: [R] [R-SIG-Mac] problem with the installation of r commander
	on	a mac
In-Reply-To: <E1700130-80B9-4463-A3DD-A65FDD4C2766@gmail.com>
References: <E1700130-80B9-4463-A3DD-A65FDD4C2766@gmail.com>
Message-ID: <001b01ce677e$076c95a0$1645c0e0$@mcmaster.ca>

Dear Susanne,

Installation instructions for the Rcmdr are at
<http://socserv.socsci.mcmaster.ca/jfox/Misc/Rcmdr/installation-notes.html>,
but you've apparently done what you normally need to do to get it to work.
Though you don't say so, I assume that you have the latest versions of R
(3.0.1) and the Rcmdr (1.9-6), and that you've not only downloaded XQuartz,
but installed it (a necessary step on Mac OS X 10.8).

Beyond that, you haven't provided much detail about the error, but I suspect
that for some reason XQuartz isn't finding your display. One way to check
whether the error is particular to the Rcmdr is to try to load the tcltk
package in R directly via library(tcltk). You might also try starting the
XQuartz app *before* you start R.

It's a bit disconcerting that others have occasionally reported a similar
problem, solved the problem, but, as far as I know, failed to post the
solution to this list, which seems to me a common courtesy. If I knew the
solution, I could add it to the Rcmdr installation notes.

I'm not a frequent user of Mac OS X, and I've never experienced problems
installing the Rcmdr on it. I imagine that other list members will be able
to offer more concrete help.

Best,
 John

-----------------------------------------------
John Fox
Senator McMaster Professor of Social Statistics
Department of Sociology
McMaster University
Hamilton, Ontario, Canada



> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Susanne.Ettinger
> Sent: Wednesday, June 12, 2013 10:06 AM
> To: r-help at r-project.org
> Subject: Re: [R] [R-SIG-Mac] problem with the installation of r
> commander on a mac
> 
> Dear all,
> 
> I am trying to install R and the Rcmdr package on a MacOSX 10.8.4.
> 
> It appears that I keep getting the error message "Erreur : le
> chargement du package ou de l'espace de noms a ?chou? pour 'Rcmdr'" no
> matter what my approach is. Even downloading XQuartz-2.7.4 did not
> help.
> 
> I found the same problem outlined on the following website
> 
> https://stat.ethz.ch/pipermail/r-help/2012-October/325305.html
> 
> and was wondering whether a solution to the problem has been stated
> since then and if you could help me with instructions how to proceed ?
> 
> Thank you very much for your help !
> 
> Kind regards,
> Susanne
> 
> __________________________
> 
> Susanne ETTINGER
> Postdoctoral researcher
> -
> Laboratoire Magmas et Volcans
> UBP - UMR6524 CNRS - M163 IRD
> 5, rue Kessler
> 63038 Clermont-Ferrand
> -
> Tel : ++33 (0)6.18.27.54.93
> Fax : ++33 (0)4.73.34.67.44
> -
> susanne.ettinger at gmail.com
> __________________________
> 
> "The eye sees only what the mind is prepared to comprehend."
> Robertson Davies
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mikeumo at gmail.com  Wed Jun 12 17:15:51 2013
From: mikeumo at gmail.com (Mikhail Umorin)
Date: Wed, 12 Jun 2013 10:15:51 -0500
Subject: [R] simulation from truncated skew normal
In-Reply-To: <CAFkmApPJ7M-JuUfAVntvxof6tSQk8c=RdJ==nGNpshLdeN7TGQ@mail.gmail.com>
References: <CAFkmApPJ7M-JuUfAVntvxof6tSQk8c=RdJ==nGNpshLdeN7TGQ@mail.gmail.com>
Message-ID: <2577607.tnGzRI5KAV@localhost>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/6f9c59f0/attachment.pl>

From hanson at depauw.edu  Wed Jun 12 17:34:03 2013
From: hanson at depauw.edu (Bryan Hanson)
Date: Wed, 12 Jun 2013 11:34:03 -0400
Subject: [R] Proper way to implement package internal functions
In-Reply-To: <51B88C6C.4030302@gmail.com>
References: <5577D149-534C-41D8-AB66-D0D901124279@depauw.edu>
	<51B88C6C.4030302@gmail.com>
Message-ID: <692DDA2E-D9DC-4C12-A984-1C8A0B40AEB2@depauw.edu>

Thanks Duncan...

Silly me, it's section 1.6.1 not version 1.6.1!

So this warning from check is not a problem in the long run:

* checking for missing documentation entries ... WARNING
Undocumented code objects:
  ?ang0to2pi? ?dAB? ?doBoxesIntersect? ...
All user-level objects in a package should have documentation entries.

if I understand correctly.  I guess the reason I didn't find any documentation is the wide lattitude which is possible.

Thank you.  Bryan

On Jun 12, 2013, at 10:57 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 12/06/2013 10:44 AM, Bryan Hanson wrote:
>> [previously posted on Stack Overflow: http://stackoverflow.com/questions/17034309/hiding-undocumented-functions-in-a-package-use-of-function-name ]
>> 
>> I've got some functions I need to make available in a package, and I don't want to export them or write much documentation for them. I'd just hide them inside another function but they need to be available to several functions so doing it that way becomes a scoping and maintenance issue. What is the right way to do this?  By that I mean do they need special names, do they go somewhere other than the R subdirectory, can I put them in a single file, etc? I've checked out the manuals (e.g. Writing R Extensions 1.6.1), and what I'm after is like the .internals concept in the core, but I don't see any instructions about how to do this generally.
>> 
>> For example, if I have functions foo1 and foo2 in a file foofunc.R, and these are intended for internal use only, should they be called foo1 or .foo1?  And the file that holds them, should it be .foofunc.R or foofunc-internals?  What should the Rd look like, or do I even need one?
>> 
>> I know people do this in packages all the time and I feel like I've seen this somewhere, but I can't find any resources just now.  Perhaps a suggestion of a package that does things this way which I could study would be sufficient.
> 
> The best way to do this is simply not to export those functions in your NAMESPACE file.  If you want to use a naming convention
> internally to remind yourself that those are private, you can do so, but R doesn't force one on you, and there are no really popular conventions in use.   R won't complain if you don't document those functions at all.
> 
> There may have been other advice in the version 1.6.1 manual, but that is seriously out of date, more than 10 years old.  I recommend that you update to 3.0.1.
> 
> Duncan Murdoch


From wdunlap at tibco.com  Wed Jun 12 17:43:08 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 12 Jun 2013 15:43:08 +0000
Subject: [R] How to get a running mean result by R?
In-Reply-To: <CAMUSh4q+tk964zPa60_6uuuGXf7YXY=hoPfCzfjhEC7Lxed7pQ@mail.gmail.com>
References: <CAMUSh4q+tk964zPa60_6uuuGXf7YXY=hoPfCzfjhEC7Lxed7pQ@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C3023AA@PA-MBX01.na.tibco.com>

Look at the filter() function.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Jie Tang
> Sent: Wednesday, June 12, 2013 12:21 AM
> To: r-help at r-project.org
> Subject: [R] How to get a running mean result by R?
> 
> Hi R users:
>   I have a big data and want to calculate the running mean of this data .
> How can I get this kind of result ? I have check the command "mean"
> it seems "mean" could not get the running mean?
> 
> --
> TANG Jie
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Ted.Harding at wlandres.net  Wed Jun 12 18:14:03 2013
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Wed, 12 Jun 2013 17:14:03 +0100 (BST)
Subject: [R] odds ratio per standard deviation
In-Reply-To: <CAFEqCdysEi4EFqjZ1bNcwVtU_ORVD2FWmW7kNcv=UOputSO9Qw@mail.gmail.com>
Message-ID: <XFMail.20130612171403.Ted.Harding@wlandres.net>

[Replies transposed so as to achieve bottom-posting ... ]

On 12-Jun-2013 14:53:02 Greg Snow wrote:
> 
> On Tue, Jun 11, 2013 at 7:38 PM, vinhnguyen04x <imvinhs at yahoo.com.vn> wrote:
> 
>> Hi all
>> i have a question:
>>
>> why and when do we use odds ratio per standard deviation instead of odds
>> ratio?
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/odds-ratio-per-standard-deviation-tp4669315.htm
>> l
>> Sent from the R help mailing list archive at Nabble.com.
>> ______________________________________________
> 
> Without context this is a shot in the dark, but my guess is this is
> referring to something like a logistic regression where the odds ratio
> (exponential of the coefficient) refers to the change in odds for the
> outcome for a 1 unit change in x.  Now often a 1 unit change in x is very
> meaningful, but other times it is not that meaningful, e.g. if x is
> measuring the size of diamonds in carats and the data does not span an
> entire carat, or x is measured in days and our x variable spans years.  In
> these cases it can make more sense to talk about the change in the odds
> relative to a different step size than just a 1 unit change in x, a
> reasonable thing to use is the change in odds for a one standard deviation
> change in x (much smaller than 1 for the diamonds, much larger for the
> days), this may be the odds ratio per standard deviation that you mention.
> -- 
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com

I think there is one comment that needs to be made about this!

The odds ratio "per unit change in x" means exactly what it says,
and can be converted into the odds ratio per any other amount of
change in x very easily. With x originally in (say) days, and
with estimated logistic regression logodds = a + b*x, if you
change your unit of x to, say weeks, so that x' = x/7, then this
is equivalent to changing b to b' = 7*b. Now just take your sliderule;
no need for R (oops, now off-topic ... ).

Another comment: I do not favour blindly "standardising" a variable
relative to its standard deviation in the data. The SD may be what
it is for any number of reasons, ranging from x being randomly sampled
fron a population to x being assigned specific values in a designed
experiment.

Since, for exactly the same meanings of the variables in the regression,
the standard deviation may change from one set of data to another of
exactly the same kind, the "odds per standard deviation" could vary
from dataset to dataset of the same investigation, and even vary
dramatically. That looks like a situation to avoid, unless it is very
carefully discussed!

The one argument that might give some sense to "odds ratio per standard
deviation" could apply when x has been sampled from a population in
which the variation of x can be approximately described by a Normal
distribution. Then "odds ratio per standard deviation" refers to
a change from, say, the mean/median of the population to the 84th
percentile, or from the 31st percentile to the 69th percentile,
or from the 69th percentile to the 93rd percentile, etc.
But these steps cover somewhat different proportions of the populatipn:
50th to 85th = 35%; 31st to 69th = 38%; 69th to 93rd = 24%. So you are
still facing issues of what you mean, or what you want to mean.

Simpler to stick to the original "odds per unit of x" and then apply
it to whatever multiple of the unit you happen to be interested in
as a change (along with the reasons for that interest).

Ted.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 12-Jun-2013  Time: 17:14:00
This message was sent by XFMail


From varethugo at gmail.com  Wed Jun 12 19:13:54 2013
From: varethugo at gmail.com (Hugo Varet)
Date: Wed, 12 Jun 2013 19:13:54 +0200
Subject: [R] agnes() in package cluster on R 2.14.1 and R 3.0.1
In-Reply-To: <20920.28868.985646.145811@stat.math.ethz.ch>
References: <CABpMX0t+MJsb4mxj67iE3Q7QnNF_XuuKaPOR24AgN=r=iWnPpw@mail.gmail.com>
	<20917.53447.986054.159726@stat.math.ethz.ch>
	<CABpMX0skZ0YpPvPh2Ve_5v27JYTg=qqZKF0kgRxxYNV=Sg1e0A@mail.gmail.com>
	<20920.28868.985646.145811@stat.math.ethz.ch>
Message-ID: <CABpMX0tzAvZQXxAuNhjqXpTV5EtQgmO+nvT9CtBRExmdoXaDdA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/0eba46e5/attachment.pl>

From dan.abner99 at gmail.com  Wed Jun 12 19:37:27 2013
From: dan.abner99 at gmail.com (Dan Abner)
Date: Wed, 12 Jun 2013 13:37:27 -0400
Subject: [R] Default colors for barplot() XXXX
Message-ID: <CAPRGo-kAaVi+Zv_QZNw1+sXAXP7A=SsD5mmBBZp5Se9m-F6GAw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/de694831/attachment.pl>

From rik.verdonck at bio.kuleuven.be  Wed Jun 12 19:42:28 2013
From: rik.verdonck at bio.kuleuven.be (Rik Verdonck)
Date: Wed, 12 Jun 2013 19:42:28 +0200
Subject: [R] Functions within functions - environments
Message-ID: <1371058948.3479.4.camel@Goat-Anti-Rabbit>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/6dad7dea/attachment.pl>

From mikeumo at gmail.com  Wed Jun 12 19:48:38 2013
From: mikeumo at gmail.com (Mikhail Umorin)
Date: Wed, 12 Jun 2013 12:48:38 -0500
Subject: [R] How to cast a numeric argument to a two-dimensional array in an
	inline C function?
Message-ID: <2885657.EiHfEdZOJN@localhost>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/77e2744c/attachment.pl>

From marc_schwartz at me.com  Wed Jun 12 19:54:19 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 12 Jun 2013 12:54:19 -0500
Subject: [R] Default colors for barplot() XXXX
In-Reply-To: <CAPRGo-kAaVi+Zv_QZNw1+sXAXP7A=SsD5mmBBZp5Se9m-F6GAw@mail.gmail.com>
References: <CAPRGo-kAaVi+Zv_QZNw1+sXAXP7A=SsD5mmBBZp5Se9m-F6GAw@mail.gmail.com>
Message-ID: <D6460DA1-57F6-49ED-95BB-D87955B7986D@me.com>

On Jun 12, 2013, at 12:37 PM, Dan Abner <dan.abner99 at gmail.com> wrote:

> Hi everyone,
> 
> I have the following call to the barplot() function which produces the
> desired stacked bar chart. HOWEVER, barplot() chooses 4 different shades of
> gray for the stacks. If I want to use the legend=NULL argument in
> combination with a separate call to legend() to customize the legend, how
> do I figure out exactly what shades of gray barplot() has choosen? Can
> these color names be extracted from the barplot after saving it as an
> object?
> 
> barplot(table(credit_rating_num,clu_),
> xlab="Cluster Label",
> ylab="Frequency",
> ylim=c(0,7000),
> legend=c("C2","C3","C4","C5"))
> 
> Thank you,
> 
> Dan



The help file defines the 'col' argument as:


col	a vector of colors for the bars or bar components. By default, grey is used if height is a vector, and a gamma-corrected grey palette if height is a matrix.


However, that is lacking a bit of detail in the latter case, albeit one of the examples on the page uses the gray.colors() function. 

The easiest way to get that detail (in this case or for any function more generally) is to look at the source code for the function, within which you would see:

...
    else if (is.matrix(height)) {
        if (is.null(col)) 
            col <- gray.colors(nrow(height))
...


A better approach would be to simply take proactive control of the colors when you call barplot() and define the 'col' argument to colors of your choosing, which you can then use in the call to legend().

Regards,

Marc Schwartz


From ruipbarradas at sapo.pt  Wed Jun 12 19:55:08 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 12 Jun 2013 18:55:08 +0100
Subject: [R] Functions within functions - environments
In-Reply-To: <1371058948.3479.4.camel@Goat-Anti-Rabbit>
References: <1371058948.3479.4.camel@Goat-Anti-Rabbit>
Message-ID: <51B8B5FC.5040205@sapo.pt>

Hello,

See the help page for parent.frame, and use its argument to go back to 
the frames of variables 'a' and 'b':


innerfunction<-function()
{
     env1 <- parent.frame(1)  # for 'b'
     env2 <- parent.frame(2)  # for 'a'
     print(paste(env2$a, " from inner function"))
     print(paste(env1$b, " from inner function"))
     setwd(wd)
}


Now it complains about 'wd'.
(Are you sure you want to hard code the number of frames to go back to? 
It seems better to write "normal" functions, i.e., functions with 
arguments. innerfunction would have 2 args and middlefunction just one, 
'a'.)

Hope this helps,

Rui Barradas

Em 12-06-2013 18:42, Rik Verdonck escreveu:
> Dear list,
>
>
> I have a problem with nested functions and I don't manage to get it
> solved. I know I should be looking in environments, and I have tried a
> lot, but it keeps on erroring.
> An easy version of the problem is as follows:
>
>
>
> innerfunction<-function()
> {
>      print(paste(a, " from inner function"))
>      print(paste(b, " from inner function"))
>      setwd(wd)
> }
>
>
> middlefunction<-function()
> {
>      b="b"
>      print(paste(b, " from middle function"))
>      innerfunction()
> }
>
>
> outerfunction<-function()
> {
>      a="a"
>      print(paste(a," from outer function"))
>      middlefunction()
> }
>
> outerfunction()
>
>
>
> Here, R will tell me that the inner function has no clue what a or b is.
> So what I want, is the inner function to recognize a and b.
> Any suggestions?
>
> Many thanks!
> Rik
>
>
>
>


From wdunlap at tibco.com  Wed Jun 12 20:09:28 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 12 Jun 2013 18:09:28 +0000
Subject: [R] Functions within functions - environments
In-Reply-To: <1371058948.3479.4.camel@Goat-Anti-Rabbit>
References: <1371058948.3479.4.camel@Goat-Anti-Rabbit>
Message-ID: <E66794E69CFDE04D9A70842786030B931C3024DB@PA-MBX01.na.tibco.com>

A function looks up free variables in the environment in which the function
was defined, not in the environment in which the function was called.  The
latter is called something like 'dynamic scoping' and usually leads to trouble,
the former is 'lexical scoping' and leads to predictable results.  You can do
dynamic scoping in R (using get(), assign(), and parent.frame()), but it
leads to code that only works correctly in favorable circumstances.  You should pass
data from the caller to the callee via the argument list, not via free variables.

To use lexical scoping define your functions as:

outerfunction<-function()
{
     middlefunction<-function()
     {
          innerfunction<-function()
          {
              print(paste(a, " from inner function"))
              print(paste(b, " from inner function"))
              # setwd(wd) # wd was not defined in your mail
        }
        b="b"
        print(paste(b, " from middle function"))
        innerfunction()
     }
     a="a"
     print(paste(a," from outer function"))
     middlefunction()
}

> outerfunction()
[1] "a  from outer function"
[1] "b  from middle function"
[1] "a  from inner function"
[1] "b  from inner function"

(One can change the environment of a function after it is defined, but
there is not often a need to do that.)

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Rik Verdonck
> Sent: Wednesday, June 12, 2013 10:42 AM
> To: r-help at r-project.org
> Subject: [R] Functions within functions - environments
> 
> Dear list,
> 
> 
> I have a problem with nested functions and I don't manage to get it
> solved. I know I should be looking in environments, and I have tried a
> lot, but it keeps on erroring.
> An easy version of the problem is as follows:
> 
> 
> 
> innerfunction<-function()
> {
>     print(paste(a, " from inner function"))
>     print(paste(b, " from inner function"))
>     setwd(wd)
> }
> 
> 
> middlefunction<-function()
> {
>     b="b"
>     print(paste(b, " from middle function"))
>     innerfunction()
> }
> 
> 
> outerfunction<-function()
> {
>     a="a"
>     print(paste(a," from outer function"))
>     middlefunction()
> }
> 
> outerfunction()
> 
> 
> 
> Here, R will tell me that the inner function has no clue what a or b is.
> So what I want, is the inner function to recognize a and b.
> Any suggestions?
> 
> Many thanks!
> Rik
> 
> 
> 
> 
> --
> ________________________________________________
> 
> Rik Verdonck
> 
> 
> 
> Research group of Molecular Developmental Physiology and Signal
> Transduction
> KULeuven, Faculty of Science
> Naamsestraat 59,  Bus 02465
> B-3000 Leuven,Belgium
> Tel. +32 16 32 39 65
> Fax +32 16 32 39 02
> 
> http://bio.kuleuven.be/df/JV/index2.htm
> rik.verdonck at bio.kuleuven.be
> 
> 
> 
> 
> 
>       Please consider the environment before printing this e-mail
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hanson at depauw.edu  Wed Jun 12 20:45:41 2013
From: hanson at depauw.edu (Bryan Hanson)
Date: Wed, 12 Jun 2013 14:45:41 -0400
Subject: [R] grDevices::convertColor XYZ space is it really xyY?
Message-ID: <DAC0C5B6-87CA-46D0-9C02-F118524240EB@depauw.edu>

grDevices::convertColor has arguments 'from' and 'to' which can take on value 'XYZ'.  Can someone confirm that 'XYZ' is the same as the CIE chromaticity coordinates that are also sometimes refered to as 'xyY' in the literature?  Or are these the CIE tristimulus values?  It looks to me like the first case is true, but I would appreciate hearing from one of the people in the know.  Thanks, Bryan


From murdoch.duncan at gmail.com  Wed Jun 12 20:53:36 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 12 Jun 2013 14:53:36 -0400
Subject: [R] grDevices::convertColor XYZ space is it really xyY?
In-Reply-To: <DAC0C5B6-87CA-46D0-9C02-F118524240EB@depauw.edu>
References: <DAC0C5B6-87CA-46D0-9C02-F118524240EB@depauw.edu>
Message-ID: <51B8C3B0.9090105@gmail.com>

On 12/06/2013 2:45 PM, Bryan Hanson wrote:
> grDevices::convertColor has arguments 'from' and 'to' which can take on value 'XYZ'.  Can someone confirm that 'XYZ' is the same as the CIE chromaticity coordinates that are also sometimes refered to as 'xyY' in the literature?  Or are these the CIE tristimulus values?  It looks to me like the first case is true, but I would appreciate hearing from one of the people in the know.  Thanks, Bryan

According to the referenced web page from ?convertColor (i.e. 
http://www.brucelindbloom.com/), XYZ is not xyY, though the conversion 
looks pretty simple.

Duncan Murdoch


From ken.knoblauch at inserm.fr  Wed Jun 12 20:57:13 2013
From: ken.knoblauch at inserm.fr (Ken Knonlauch)
Date: Wed, 12 Jun 2013 18:57:13 +0000
Subject: [R] grDevices::convertColor XYZ space is it really xyY?
References: <DAC0C5B6-87CA-46D0-9C02-F118524240EB@depauw.edu>
Message-ID: <loom.20130612T205139-924@post.gmane.org>

Bryan Hanson <hanson <at> depauw.edu> writes:

> 
> grDevices::convertColor has arguments 'from' and 'to' which can 
take on value 'XYZ'.  Can 
someone confirm
> that 'XYZ' is the same as the CIE chromaticity coordinates 
 are also sometimes refered to 
as 'xyY' in
> the literature?  Or are these the CIE tristimulus values?  
It looks to me like the first case is 
true, but I
> would appreciate hearing from one of the people in 
 know.  Thanks, Bryan
> 
> 

I.'d look at the code or put in some known data to test it, 
but XYZ are tristimulus values and xyY are chromaticity
coordinated and the luminance which is the Y tristimulus
value for the CIE 1931 standard observer.

Ken


From bogaso.christofer at gmail.com  Wed Jun 12 21:07:20 2013
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Thu, 13 Jun 2013 00:52:20 +0545
Subject: [R] Fetching and Saving warnings from a function
Message-ID: <CA+dpOJnZpymfsHZyzdxaEkmZYzq_r0FhRRuzT9bu_ZhgemB75Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130613/bf128d0e/attachment.pl>

From armel.kaptue at sdstate.edu  Wed Jun 12 21:22:04 2013
From: armel.kaptue at sdstate.edu (Kaptue Tchuente, Armel)
Date: Wed, 12 Jun 2013 19:22:04 +0000
Subject: [R] How to fit the cumulative probability distributive functiion
 with the gamma distribution?
Message-ID: <9879AF1F439EF943BDEE22D3AAA5C3F683FBED51@sdsu-ex01.jacks.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/1feb8bce/attachment.pl>

From wdunlap at tibco.com  Wed Jun 12 21:25:55 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 12 Jun 2013 19:25:55 +0000
Subject: [R] Fetching and Saving warnings from a function
In-Reply-To: <CA+dpOJnZpymfsHZyzdxaEkmZYzq_r0FhRRuzT9bu_ZhgemB75Q@mail.gmail.com>
References: <CA+dpOJnZpymfsHZyzdxaEkmZYzq_r0FhRRuzT9bu_ZhgemB75Q@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C302561@PA-MBX01.na.tibco.com>

?withCallingHandlers

E.g.,
R> f <- function(expr) {
      warnings <- character()
      withCallingHandlers(expr, warning=function(e){
         warnings <<- c(warnings, conditionMessage(e))
         invokeRestart("muffleWarning")
      })
      warnings
}
R> f(1:10)
character(0)
R> f(warning("Hmm"))
[1] "Hmm"
R> f({warning("Hmm"); x <- 666 ; warning("Possible problem")})
[1] "Hmm"              "Possible problem"
R> x
[1] 666

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Christofer Bogaso
> Sent: Wednesday, June 12, 2013 12:07 PM
> To: r-help
> Subject: [R] Fetching and Saving warnings from a function
> 
> Hello again,
> 
> Let say I have following user defined function:
> 
> Myfn <- function(x) {
> if (x < 0) {
> warning("Negative value")
> }
> return(x)
> }
> 
> Now I want to create some function which will save the Warnings from
> 'Myfn', so that I can use those warnings later for more analysis. Therefore
> I was thinking of following type of function:
> 
> ProposedWarningStoreFunction <- function() {
>                   .........            ............        ...........
> }
> 
> therefore,if I run 'ProposedWarningStoreFunction', I should get following
> kind of results:
> 
> Warnings <- ProposedWarningStoreFunction({Result <- Myfn(-4)})
> 
> > Result
>  -4
> 
> > Warnings
> In Myfn(-3) : Negative value
> 
> Can somebody here point me how to achieve this? Or is it possible to
> achieve at all?
> 
> Thank you for your help.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kpenner at as.arizona.edu  Wed Jun 12 21:48:40 2013
From: kpenner at as.arizona.edu (Kyle Penner)
Date: Wed, 12 Jun 2013 12:48:40 -0700
Subject: [R] survreg with measurement uncertainties
In-Reply-To: <51B87CC4.6050800@mayo.edu>
References: <mailman.25.1371031207.11759.r-help@r-project.org>
	<51B87CC4.6050800@mayo.edu>
Message-ID: <CAAF=944q7jFhBwK1mOwQKUvtwYhn8sqvyKaZrmWU2r5rkW8VoA@mail.gmail.com>

Hi Terry,

Thanks for your quick reply.  I am talking about uncertainty in the
response.  I have 2 follow up questions:

1) my understanding from the documentation is that 'id' in cluster(id)
should be the same when the predictors are not independent.  Is this
correct?  (To be more concrete: my data are brightnesses at different
wavelengths.  Each brightness is an independent measurement, so the
elements of id should all be different?)

2) I tested survreg with uncertainties on an example where I already
know the answer (and where I am not using limits), and it does not
converge.  Below is the code I used, does anything jump out as
incorrect?

data = c(144.53, 1687.68, 5397.91)
err = c(8.32, 471.22, 796.67)
model = c(71.60, 859.23, 1699.19)
id = c(1, 2, 3)

This works (2.9 is the answer from simple chi_sq fitting):

survreg(Surv(time = data, event = c(1,1,1))~model-1, dist='gaussian',
init=c(2.9))

This does not converge (2.1 is the answer from chi_sq fitting):

survreg(Surv(time = data, event = c(1,1,1))~model-1+cluster(id),
weights=1/(err^2), dist='gaussian', init=c(2.1))

And this does, but the answer it returns is wonky:

data[2] = 3*err[2] # data[2] is very close to 3*err[2] already
survreg(Surv(time = data, event = c(1,2,1))~model-1+cluster(id),
weights=1/(err^2), dist='gaussian', init=c(2.1))

Thanks,

Kyle

On Wed, Jun 12, 2013 at 6:51 AM, Terry Therneau <therneau at mayo.edu> wrote:
> I will assume that you are talking about uncertainty in the response.  Then
> one simple way to fit the model is to use case weights that are proprional
> to 1/variance, along with +cluster(id) in the model statement to get a
> correct variance for this case.  In linear models this would be called the
> "White" or "Horvitz-Thompsen" or "GEE working independence" variance
> estimate, depending on which literature you happen to be reading (economics,
> survey sampling, or biostat).
>
> Now if you are talking about errors in the predictor variables, that is a
> much harder problem.
>
> Terry Therneau
>
>
>
> On 06/12/2013 05:00 AM, Kyle Penner wrote:
>>
>> Hello,
>>
>> I have some measurements that I am trying to fit a model to.  I also
>> have uncertainties for these measurements.  Some of the measurements
>> are not well detected, so I'd like to use a limit instead of the
>> actual measurement.  (I am always dealing with upper limits, i.e. left
>> censored data.)
>>
>> I have successfully run survreg using the combination of well detected
>> measurements and limits, but I would like to include the measurement
>> uncertainty (for the well detected measurements) in the fitting.  As
>> far as I can tell, survreg doesn't support this.  Does anyone have a
>> suggestion for how to accomplish this?
>>
>> Thanks,
>>
>> Kyle


From smartpink111 at yahoo.com  Wed Jun 12 22:03:37 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 12 Jun 2013 13:03:37 -0700 (PDT)
Subject: [R] Creating a new var from conditional values in other vars
Message-ID: <1371067417.95095.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
Try this:
set.seed(25)
dat1<- data.frame(A=sample(1:30,100,replace=TRUE),B=sample(1:35,100,replace=TRUE),C=sample(1:25,100,replace=TRUE))


dat1$pattern<-with(dat1,ifelse(A>20 & B<=2.5 & C<=20,"Normal",ifelse(A <20 & B >2.5 & C >20,"Increased",ifelse(A >=20 & B >2.5 & C <=20,"Low","Other"))))
head(dat1)
#?? A? B? C pattern
#1 13 20? 5?? Other
#2 21 15? 4???? Low
#3? 5 24? 1?? Other
#4 27 13? 6???? Low
#5? 4? 4 10?? Other
#6 30 19 22?? Other
A.K.




I am newbie to R coming from SAS (basic user). Quite a difficult move.... 
I have a dataframe named kappa exported from csv file 
kappa<-read.csv("kappacsv", header=TRUE, sep=";", dec=".") 
kappa contains 3 numeric vars (A,B and C) 
I want to create a new var called "pattern" depending on the values of the conditions in A, B and C 
I have tried many ways one has been this: 
kappa$pattern1<-99 # create a new numeric var in kappa dataframe 

if (A>=20 & B<=2.5 & C <=20){kappa$pattern<-"Normal"} 
else if (A <20 & B >2.5 & C >20){kappa$pattern<-"Increased"} 
else if (A >=20 & B >2.5 & C <=20){kappa$pattern<-"Low"} 
else {kappa$pattern<-?Other?} 
? 
The code does not work and I get errors all the time. 
Any help will be greatly appreciated 
Thanks


From hanson at depauw.edu  Wed Jun 12 22:20:56 2013
From: hanson at depauw.edu (Bryan Hanson)
Date: Wed, 12 Jun 2013 16:20:56 -0400
Subject: [R] grDevices::convertColor XYZ space is it really xyY?
In-Reply-To: <loom.20130612T205139-924@post.gmane.org>
References: <DAC0C5B6-87CA-46D0-9C02-F118524240EB@depauw.edu>
	<loom.20130612T205139-924@post.gmane.org>
Message-ID: <D837E96E-C3E4-4B02-BD0B-B61BF36D2CAB@depauw.edu>

Ken, I followed your suggestion and perhaps I don't understand what to expect from convertColor or maybe I'm not using it correctly.  Consider the following tests:

D65 <- c(0.3127, 0.329, 0.3583) # D65 chromaticity coordinates
X <- D65[1]*D65[3]/D65[2] # conversion per brucelindbloom.com
Y <- D65[3]
Z <- D65[3]*D65[3]/D65[2]
XYZ <- data.frame(X = X, Y = Y, Z = Z) # D65 in tristimulus values (?)
colnames(XYZ) <- c("X", "Y", "Z")

tst1 <- convertColor(XYZ, from = "XYZ", to = "sRGB")
tst2 <- convertColor(D65, from = "XYZ", to = "sRGB")
# none of these are 1,1,1, namely white (they are ~ 0.6, 0.6, 0.6)

So it looks like D65, a white standard, does not come back to something near white in the sRGB space.  What am I doing wrong here, or what do I misunderstand?  Please don't say everything!

Thanks, Bryan

On Jun 12, 2013, at 2:57 PM, Ken Knonlauch <ken.knoblauch at inserm.fr> wrote:

> Bryan Hanson <hanson <at> depauw.edu> writes:
> 
>> 
>> grDevices::convertColor has arguments 'from' and 'to' which can 
> take on value 'XYZ'.  Can 
> someone confirm
>> that 'XYZ' is the same as the CIE chromaticity coordinates 
> are also sometimes refered to 
> as 'xyY' in
>> the literature?  Or are these the CIE tristimulus values?  
> It looks to me like the first case is 
> true, but I
>> would appreciate hearing from one of the people in 
> know.  Thanks, Bryan
>> 
>> 
> 
> I.'d look at the code or put in some known data to test it, 
> but XYZ are tristimulus values and xyY are chromaticity
> coordinated and the luminance which is the Y tristimulus
> value for the CIE 1931 standard observer.
> 
> Ken
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ken.knoblauch at inserm.fr  Wed Jun 12 22:36:46 2013
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Wed, 12 Jun 2013 22:36:46 +0200
Subject: [R] grDevices::convertColor XYZ space is it really xyY?
In-Reply-To: <D837E96E-C3E4-4B02-BD0B-B61BF36D2CAB@depauw.edu>
References: <DAC0C5B6-87CA-46D0-9C02-F118524240EB@depauw.edu>
	<loom.20130612T205139-924@post.gmane.org>
	<D837E96E-C3E4-4B02-BD0B-B61BF36D2CAB@depauw.edu>
Message-ID: <20130612223646.ivlucswc0o0gc8kc@imp.inserm.fr>

You seem to treating the input values as xyY when they should be XYZ
(case matters).
So, I would do something like this

D65 <- c(0.3127, 0.329, 0.3583)

X <- 100 * D65[1]
Y <- 100 * D65[2]
Z <- 100 * D65[3]
XYZ <- data.frame(X = X, Y = Y, Z = Z)

convertColor(XYZ, from = "XYZ", to = "sRGB")
      [,1] [,2] [,3]
[1,]    1    1    1


Quoting Bryan Hanson <hanson at depauw.edu>:

> Ken, I followed your suggestion and perhaps I don't understand what   
> to expect from convertColor or maybe I'm not using it correctly.    
> Consider the following tests:
>
> D65 <- c(0.3127, 0.329, 0.3583) # D65 chromaticity coordinates
> X <- D65[1]*D65[3]/D65[2] # conversion per brucelindbloom.com
> Y <- D65[3]
> Z <- D65[3]*D65[3]/D65[2]
> XYZ <- data.frame(X = X, Y = Y, Z = Z) # D65 in tristimulus values (?)
> colnames(XYZ) <- c("X", "Y", "Z")
>
> tst1 <- convertColor(XYZ, from = "XYZ", to = "sRGB")
> tst2 <- convertColor(D65, from = "XYZ", to = "sRGB")
> # none of these are 1,1,1, namely white (they are ~ 0.6, 0.6, 0.6)
>
> So it looks like D65, a white standard, does not come back to   
> something near white in the sRGB space.  What am I doing wrong here,  
>  or what do I misunderstand?  Please don't say everything!
>
> Thanks, Bryan
>
> On Jun 12, 2013, at 2:57 PM, Ken Knonlauch <ken.knoblauch at inserm.fr> wrote:
>
>> Bryan Hanson <hanson <at> depauw.edu> writes:
>>
>>>
>>> grDevices::convertColor has arguments 'from' and 'to' which can
>> take on value 'XYZ'.  Can
>> someone confirm
>>> that 'XYZ' is the same as the CIE chromaticity coordinates
>> are also sometimes refered to
>> as 'xyY' in
>>> the literature?  Or are these the CIE tristimulus values?
>> It looks to me like the first case is
>> true, but I
>>> would appreciate hearing from one of the people in
>> know.  Thanks, Bryan
>>>
>>>
>>
>> I.'d look at the code or put in some known data to test it,
>> but XYZ are tristimulus values and xyY are chromaticity
>> coordinated and the luminance which is the Y tristimulus
>> value for the CIE 1931 standard observer.
>>
>> Ken
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>



-- 
Kenneth Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html


From hanson at depauw.edu  Wed Jun 12 22:50:35 2013
From: hanson at depauw.edu (Bryan Hanson)
Date: Wed, 12 Jun 2013 16:50:35 -0400
Subject: [R] grDevices::convertColor XYZ space is it really xyY?
In-Reply-To: <20130612223646.ivlucswc0o0gc8kc@imp.inserm.fr>
References: <DAC0C5B6-87CA-46D0-9C02-F118524240EB@depauw.edu>
	<loom.20130612T205139-924@post.gmane.org>
	<D837E96E-C3E4-4B02-BD0B-B61BF36D2CAB@depauw.edu>
	<20130612223646.ivlucswc0o0gc8kc@imp.inserm.fr>
Message-ID: <B31DC070-F86D-4C95-B87E-34A9833FF251@depauw.edu>

Thank you Ken.

90% of my problem was missing the factor of 100.  I was just inputing xyY as a test, I wasn't sure whether the docs were being clear about nomenclature.  Speaking thereof, the D65 values used in the example: I thought they were chromaticity coordinates, but apparently they are tristimulus values - is that correct?

Thanks again.  This solves several problems in a package I am developing.  Bryan

On Jun 12, 2013, at 4:36 PM, Ken Knoblauch <ken.knoblauch at inserm.fr> wrote:

> You seem to treating the input values as xyY when they should be XYZ
> (case matters).
> So, I would do something like this
> 
> D65 <- c(0.3127, 0.329, 0.3583)
> 
> X <- 100 * D65[1]
> Y <- 100 * D65[2]
> Z <- 100 * D65[3]
> XYZ <- data.frame(X = X, Y = Y, Z = Z)
> 
> convertColor(XYZ, from = "XYZ", to = "sRGB")
>     [,1] [,2] [,3]
> [1,]    1    1    1
> 
> 
> Quoting Bryan Hanson <hanson at depauw.edu>:
> 
>> Ken, I followed your suggestion and perhaps I don't understand what  to expect from convertColor or maybe I'm not using it correctly.   Consider the following tests:
>> 
>> D65 <- c(0.3127, 0.329, 0.3583) # D65 chromaticity coordinates
>> X <- D65[1]*D65[3]/D65[2] # conversion per brucelindbloom.com
>> Y <- D65[3]
>> Z <- D65[3]*D65[3]/D65[2]
>> XYZ <- data.frame(X = X, Y = Y, Z = Z) # D65 in tristimulus values (?)
>> colnames(XYZ) <- c("X", "Y", "Z")
>> 
>> tst1 <- convertColor(XYZ, from = "XYZ", to = "sRGB")
>> tst2 <- convertColor(D65, from = "XYZ", to = "sRGB")
>> # none of these are 1,1,1, namely white (they are ~ 0.6, 0.6, 0.6)
>> 
>> So it looks like D65, a white standard, does not come back to  something near white in the sRGB space.  What am I doing wrong here,  or what do I misunderstand?  Please don't say everything!
>> 
>> Thanks, Bryan
>> 
>> On Jun 12, 2013, at 2:57 PM, Ken Knonlauch <ken.knoblauch at inserm.fr> wrote:
>> 
>>> Bryan Hanson <hanson <at> depauw.edu> writes:
>>> 
>>>> 
>>>> grDevices::convertColor has arguments 'from' and 'to' which can
>>> take on value 'XYZ'.  Can
>>> someone confirm
>>>> that 'XYZ' is the same as the CIE chromaticity coordinates
>>> are also sometimes refered to
>>> as 'xyY' in
>>>> the literature?  Or are these the CIE tristimulus values?
>>> It looks to me like the first case is
>>> true, but I
>>>> would appreciate hearing from one of the people in
>>> know.  Thanks, Bryan
>>>> 
>>>> 
>>> 
>>> I.'d look at the code or put in some known data to test it,
>>> but XYZ are tristimulus values and xyY are chromaticity
>>> coordinated and the luminance which is the Y tristimulus
>>> value for the CIE 1931 standard observer.
>>> 
>>> Ken
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
> 
> 
> 
> -- 
> Kenneth Knoblauch
> Inserm U846
> Stem-cell and Brain Research Institute
> Department of Integrative Neurosciences
> 18 avenue du Doyen L?pine
> 69500 Bron
> France
> tel: +33 (0)4 72 91 34 77
> fax: +33 (0)4 72 91 34 61
> portable: +33 (0)6 84 10 64 10
> http://www.sbri.fr/members/kenneth-knoblauch.html
> 
> ----------------------------------------------------------------
> This message was sent using IMP, the Internet Messaging Program.
> 
> 


From ken.knoblauch at inserm.fr  Wed Jun 12 22:55:10 2013
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Wed, 12 Jun 2013 22:55:10 +0200
Subject: [R] grDevices::convertColor XYZ space is it really xyY?
In-Reply-To: <B31DC070-F86D-4C95-B87E-34A9833FF251@depauw.edu>
References: <DAC0C5B6-87CA-46D0-9C02-F118524240EB@depauw.edu>
	<loom.20130612T205139-924@post.gmane.org>
	<D837E96E-C3E4-4B02-BD0B-B61BF36D2CAB@depauw.edu>
	<20130612223646.ivlucswc0o0gc8kc@imp.inserm.fr>
	<B31DC070-F86D-4C95-B87E-34A9833FF251@depauw.edu>
Message-ID: <20130612225510.jscpe1qtussc0kco@imp.inserm.fr>

If they sum to 1 then they are one and the same.  Look at how
chromaticity coordinates are defined in terms of the tristimulus
values.

Quoting Bryan Hanson <hanson at depauw.edu>:

> Thank you Ken.
>
> 90% of my problem was missing the factor of 100.  I was just   
> inputing xyY as a test, I wasn't sure whether the docs were being   
> clear about nomenclature.  Speaking thereof, the D65 values used in   
> the example: I thought they were chromaticity coordinates, but   
> apparently they are tristimulus values - is that correct?
>
> Thanks again.  This solves several problems in a package I am   
> developing.  Bryan
>
> On Jun 12, 2013, at 4:36 PM, Ken Knoblauch <ken.knoblauch at inserm.fr> wrote:
>
>> You seem to treating the input values as xyY when they should be XYZ
>> (case matters).
>> So, I would do something like this
>>
>> D65 <- c(0.3127, 0.329, 0.3583)
>>
>> X <- 100 * D65[1]
>> Y <- 100 * D65[2]
>> Z <- 100 * D65[3]
>> XYZ <- data.frame(X = X, Y = Y, Z = Z)
>>
>> convertColor(XYZ, from = "XYZ", to = "sRGB")
>>     [,1] [,2] [,3]
>> [1,]    1    1    1
>>
>>
>> Quoting Bryan Hanson <hanson at depauw.edu>:
>>
>>> Ken, I followed your suggestion and perhaps I don't understand   
>>> what  to expect from convertColor or maybe I'm not using it   
>>> correctly.   Consider the following tests:
>>>
>>> D65 <- c(0.3127, 0.329, 0.3583) # D65 chromaticity coordinates
>>> X <- D65[1]*D65[3]/D65[2] # conversion per brucelindbloom.com
>>> Y <- D65[3]
>>> Z <- D65[3]*D65[3]/D65[2]
>>> XYZ <- data.frame(X = X, Y = Y, Z = Z) # D65 in tristimulus values (?)
>>> colnames(XYZ) <- c("X", "Y", "Z")
>>>
>>> tst1 <- convertColor(XYZ, from = "XYZ", to = "sRGB")
>>> tst2 <- convertColor(D65, from = "XYZ", to = "sRGB")
>>> # none of these are 1,1,1, namely white (they are ~ 0.6, 0.6, 0.6)
>>>
>>> So it looks like D65, a white standard, does not come back to    
>>> something near white in the sRGB space.  What am I doing wrong   
>>> here,  or what do I misunderstand?  Please don't say everything!
>>>
>>> Thanks, Bryan
>>>
>>> On Jun 12, 2013, at 2:57 PM, Ken Knonlauch <ken.knoblauch at inserm.fr> wrote:
>>>
>>>> Bryan Hanson <hanson <at> depauw.edu> writes:
>>>>
>>>>>
>>>>> grDevices::convertColor has arguments 'from' and 'to' which can
>>>> take on value 'XYZ'.  Can
>>>> someone confirm
>>>>> that 'XYZ' is the same as the CIE chromaticity coordinates
>>>> are also sometimes refered to
>>>> as 'xyY' in
>>>>> the literature?  Or are these the CIE tristimulus values?
>>>> It looks to me like the first case is
>>>> true, but I
>>>>> would appreciate hearing from one of the people in
>>>> know.  Thanks, Bryan
>>>>>
>>>>>
>>>>
>>>> I.'d look at the code or put in some known data to test it,
>>>> but XYZ are tristimulus values and xyY are chromaticity
>>>> coordinated and the luminance which is the Y tristimulus
>>>> value for the CIE 1931 standard observer.
>>>>
>>>> Ken
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide   
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>>
>>
>> --
>> Kenneth Knoblauch
>> Inserm U846
>> Stem-cell and Brain Research Institute
>> Department of Integrative Neurosciences
>> 18 avenue du Doyen L?pine
>> 69500 Bron
>> France
>> tel: +33 (0)4 72 91 34 77
>> fax: +33 (0)4 72 91 34 61
>> portable: +33 (0)6 84 10 64 10
>> http://www.sbri.fr/members/kenneth-knoblauch.html
>>
>> ----------------------------------------------------------------
>> This message was sent using IMP, the Internet Messaging Program.
>>
>>
>
>



-- 
Kenneth Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html


From jfox at mcmaster.ca  Wed Jun 12 22:52:01 2013
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 12 Jun 2013 16:52:01 -0400
Subject: [R] [R-SIG-Mac] problem with the installation of r commander
	on	a mac
In-Reply-To: <E6DF22AD-58B5-4583-82E8-A1C30C47CC7C@gmail.com>
References: <E1700130-80B9-4463-A3DD-A65FDD4C2766@gmail.com>
	<001b01ce677e$076c95a0$1645c0e0$@mcmaster.ca>
	<E6DF22AD-58B5-4583-82E8-A1C30C47CC7C@gmail.com>
Message-ID: <005501ce67ae$b0d0afc0$12720f40$@mcmaster.ca>

Dear Susanne,

You started this thread on r-help (though R-SIG-Mac would have been more
appropriate), and so I'm copying my response to the r-help list. People will
find it confusing if the messages are simply kept private.

It's not obvious to me exactly what your problem is now. In particular, is
the Rcmdr package working when you start XQuartz before R? 

I see that you've installed and loaded the FactoMineR package. Presumably
the Rcmdr package was already installed. Then you executed an R script
provided by the authors of the FactoMineR package, which reinstalls and then
modifies the Rcmdr package. I think that this is ill-advised (as opposed to
providing an Rcmdr plug-in package for FactoMineR, as used to be the case),
and if you're having problems with their script, you should really contact
the authors. 

If I read the messages correctly, the script produces warnings, not errors,
oddly relating to the language you're using (odd because the authors of the
FactoMineR package are French) and it's possible that everything will work
correctly despite the warnings.

I hope this helps,
 John

> -----Original Message-----
> From: Susanne.Ettinger [mailto:susanne.ettinger at gmail.com]
> Sent: Wednesday, June 12, 2013 11:44 AM
> To: John Fox
> Subject: Re: [R] [R-SIG-Mac] problem with the installation of r
> commander on a mac
> 
> Dear John,
> 
> thank you very much for your quick reply - I realize I sent this email
> to the list without being a member, but I am a very beginner and
> started this morning the installation process of R.
> 
> I have been printing out any possibly available information on how to
> get started with R and I am following the exercices exposed in the book
> written by Cornillon et al. (2012) to use FactoMineR to do some PCA
> analysis on vulnerability data.
> 
> I downloaded the 3.0.1 version of R and have the 1.9-6 package of
> Rcmdr. I also checked into the library(tcltk) but do not get an error
> message, this seems to work fine.
> 
> Since I open XQuartz before starting the Rcmdr library, I am getting a
> different error message than the ones of this morning. This is what it
> looks like :
> 
> 
> 	> install.packages()
> 	--- SVP s?lectionner un miroir CRAN pour cette session ---
> 	essai de l'URL 'http://cran.univ-
> lyon1.fr/bin/macosx/contrib/3.0/FactoMineR_1.25.tgz'
> 	Content type 'application/x-gzip' length 3397827 bytes (3.2 Mb)
> 	URL ouverte
> 	==================================================
> 	downloaded 3.2 Mb
> 
> 
> 
> 
> 	Les packages binaires t?l?charg?s sont dans
> 	/var/folders/06/z7b6z3y102xgxls2xh251p5w0000gp/T//Rtmp13nIpm/downl
> oaded_packages
> 	> library(FactoMineR)
> 	Le chargement a n?cessit? le package : car
> 	Le chargement a n?cessit? le package : MASS
> 	Le chargement a n?cessit? le package : nnet
> 	Le chargement a n?cessit? le package : ellipse
> 
> 
> 	Attachement du package : ?ellipse?
> 
> 
> 	L'objet suivant est masqu? from ?package:car?:
> 
> 
> 	    ellipse
> 
> 
> 	Le chargement a n?cessit? le package : lattice
> 	Le chargement a n?cessit? le package : cluster
> 	Le chargement a n?cessit? le package : scatterplot3d
> 	Le chargement a n?cessit? le package : leaps
> 	> source("http://factominer.free.fr/install-facto-fr.r")
> 	essai de l'URL 'http://cran.univ-
> lyon1.fr/bin/macosx/contrib/3.0/Rcmdr_1.9-6.tgz'
> 	Content type 'application/x-gzip' length 3759850 bytes (3.6 Mb)
> 	URL ouverte
> 	==================================================
> 	downloaded 3.6 Mb
> 
> 
> 
> 
> 	The downloaded binary packages are in
> 	/var/folders/06/z7b6z3y102xgxls2xh251p5w0000gp/T//Rtmp13nIpm/downl
> oaded_packages
> 	essai de l'URL 'http://cran.univ-
> lyon1.fr/bin/macosx/contrib/3.0/FactoMineR_1.25.tgz'
> 	Content type 'application/x-gzip' length 3397827 bytes (3.2 Mb)
> 	URL ouverte
> 	==================================================
> 	downloaded 3.2 Mb
> 
> 
> 
> 
> 	The downloaded binary packages are in
> 	/var/folders/06/z7b6z3y102xgxls2xh251p5w0000gp/T//Rtmp13nIpm/downl
> oaded_packages
> 	Avis dans grepl("\n", lines, fixed = TRUE) :
> 	  la cha?ne de caract?res entr?e 1 est incorrecte dans cet
> environnement linguistique
> 	Avis dans grepl("\n", lines, fixed = TRUE) :
> 	  la cha?ne de caract?res entr?e 5 est incorrecte dans cet
> environnement linguistique
> 	Avis dans grepl("\n", lines, fixed = TRUE) :
> 	  la cha?ne de caract?res entr?e 31 est incorrecte dans cet
> environnement linguistique
> 	Avis dans grepl("\n", lines, fixed = TRUE) :
> 	  la cha?ne de caract?res entr?e 35 est incorrecte dans cet
> environnement linguistique
> 	Avis dans grepl("\n", lines, fixed = TRUE) :
> 	  la cha?ne de caract?res entr?e 81 est incorrecte dans cet
> environnement linguistique
> 	Avis dans grepl("\n", lines, fixed = TRUE) :
> 	  la cha?ne de caract?res entr?e 84 est incorrecte dans cet
> environnement linguistique
> 	Avis dans grepl("\n", lines, fixed = TRUE) :
> 	  la cha?ne de caract?res entr?e 92 est incorrecte dans cet
> environnement linguistique
> 	Avis dans grepl("\n", lines, fixed = TRUE) :
> 	  la cha?ne de caract?res entr?e 97 est incorrecte dans cet
> environnement linguistique
> 	Avis dans grepl("\n", lines, fixed = TRUE) :
> 	  la cha?ne de caract?res entr?e 105 est incorrecte dans cet
> environnement linguistique
> 	Avis dans grepl("\n", lines, fixed = TRUE) :
> 	  la cha?ne de caract?res entr?e 114 est incorrecte dans cet
> environnement linguistique
> 	Avis dans grepl("\n", lines, fixed = TRUE) :
> 	  la cha?ne de caract?res entr?e 170 est incorrecte dans cet
> environnement linguistique
> 	

> 
> 
> 
> 
> This is where the file continues line by line with the same error
> message.
> So I think if I manage to get this fixed, I should be good to go 

> If you have ever seen such type of an error and could give me a hint of
> how to resolve the problem, this would be more than appreciated.
> 
> I will let you know whether I can get the Rcmd library to run and how 

> if that ever happens ;-)
> 
> Thank you again !
> 
> Kind regards,
> Susanne
> 
> __________________________
> 
> Susanne ETTINGER
> Postdoctoral researcher
> -
> Laboratoire Magmas et Volcans
> UBP - UMR6524 CNRS - M163 IRD
> 5, rue Kessler
> 63038 Clermont-Ferrand
> -
> Tel : ++33 (0)6.18.27.54.93
> Fax : ++33 (0)4.73.34.67.44
> -
> susanne.ettinger at gmail.com
> __________________________
> 
> "Obstacles are those frightful things you see when you take your eyes
> off your goal."
> Henry Ford
> 
> 
> Le 12 juin 2013 ? 17:03, John Fox <jfox at mcmaster.ca> a ?crit :
> 
> 
> 	Dear Susanne,
> 
> 	Installation instructions for the Rcmdr are at
> 	<http://socserv.socsci.mcmaster.ca/jfox/Misc/Rcmdr/installation-
> notes.html>,
> 	but you've apparently done what you normally need to do to get it
> to work.
> 	Though you don't say so, I assume that you have the latest
> versions of R
> 	(3.0.1) and the Rcmdr (1.9-6), and that you've not only downloaded
> XQuartz,
> 	but installed it (a necessary step on Mac OS X 10.8).
> 
> 	Beyond that, you haven't provided much detail about the error, but
> I suspect
> 	that for some reason XQuartz isn't finding your display. One way
> to check
> 	whether the error is particular to the Rcmdr is to try to load the
> tcltk
> 	package in R directly via library(tcltk). You might also try
> starting the
> 	XQuartz app *before* you start R.
> 
> 	It's a bit disconcerting that others have occasionally reported a
> similar
> 	problem, solved the problem, but, as far as I know, failed to post
> the
> 	solution to this list, which seems to me a common courtesy. If I
> knew the
> 	solution, I could add it to the Rcmdr installation notes.
> 
> 	I'm not a frequent user of Mac OS X, and I've never experienced
> problems
> 	installing the Rcmdr on it. I imagine that other list members will
> be able
> 	to offer more concrete help.
> 
> 	Best,
> 	John
> 
> 	-----------------------------------------------
> 	John Fox
> 	Senator McMaster Professor of Social Statistics
> 	Department of Sociology
> 	McMaster University
> 	Hamilton, Ontario, Canada
> 
> 
> 
> 
> 
> 		-----Original Message-----
> 		From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> 		project.org] On Behalf Of Susanne.Ettinger
> 		Sent: Wednesday, June 12, 2013 10:06 AM
> 		To: r-help at r-project.org
> 		Subject: Re: [R] [R-SIG-Mac] problem with the installation
of
> r
> 		commander on a mac
> 
> 		Dear all,
> 
> 		I am trying to install R and the Rcmdr package on a MacOSX
> 10.8.4.
> 
> 		It appears that I keep getting the error message "Erreur :
le
> 		chargement du package ou de l'espace de noms a ?chou? pour
> 'Rcmdr'" no
> 		matter what my approach is. Even downloading XQuartz-2.7.4
> did not
> 		help.
> 
> 		I found the same problem outlined on the following website
> 
> 		https://stat.ethz.ch/pipermail/r-help/2012-
> October/325305.html
> 
> 		and was wondering whether a solution to the problem has been
> stated
> 		since then and if you could help me with instructions how to
> proceed ?
> 
> 		Thank you very much for your help !
> 
> 		Kind regards,
> 		Susanne
> 
> 		__________________________
> 
> 		Susanne ETTINGER
> 		Postdoctoral researcher
> 		-
> 		Laboratoire Magmas et Volcans
> 		UBP - UMR6524 CNRS - M163 IRD
> 		5, rue Kessler
> 		63038 Clermont-Ferrand
> 		-
> 		Tel : ++33 (0)6.18.27.54.93
> 		Fax : ++33 (0)4.73.34.67.44
> 		-
> 		susanne.ettinger at gmail.com
> 		__________________________
> 
> 		"The eye sees only what the mind is prepared to comprehend."
> 		Robertson Davies
> 
> 		______________________________________________
> 		R-help at r-project.org mailing list
> 		https://stat.ethz.ch/mailman/listinfo/r-help
> 		PLEASE do read the posting guide http://www.R-
> project.org/posting-
> 		guide.html
> 		and provide commented, minimal, self-contained, reproducible
> code.
> 
> 
> 


From ajin at iknowtion.com  Wed Jun 12 16:43:14 2013
From: ajin at iknowtion.com (Anhai Jin)
Date: Wed, 12 Jun 2013 10:43:14 -0400
Subject: [R] how to maximize the log-likelihood function with EM algorithm
Message-ID: <9E7BC5801884234C82DC9BE021596FE973A62487DF@SERVER2008.iknowtion2.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/6bd3f5b3/attachment.pl>

From drew.parkway at taac.im  Wed Jun 12 20:13:19 2013
From: drew.parkway at taac.im (Drew)
Date: Wed, 12 Jun 2013 11:13:19 -0700 (PDT)
Subject: [R] Cannot install RPostgreSQL
Message-ID: <1371060799436-4669380.post@n4.nabble.com>

Hello everyone,

I am extremely new to R. I have yet to write any complicated code myself,
however I have been learning largely by reading code that has already been
written. Long story short, I have been running a code that makes use of the
RPostgreSQL package for some time now. For some reason I just recently
started to get an error. Whenever I try to load the RPostgreSQL package I
get:

> library(RPostgreSQL)
Error in library(RPostgreSQL) : there is no package called ?RPostgreSQL?

I also tried install.packages(RPostgreSQL) and
install.packages("RPostgreSQL"). I've attached a text document of the
resulting error here.

Error.txt <http://r.789695.n4.nabble.com/file/n4669380/Error.txt>  

I'm running R version 2.15.1 on Ubuntu. I can't seem to find a solution to
the problem online. And let me be clear, I was able to load this package
without an issue no longer than a week ago. Any help you can offer would be
much appreciated.

Thanks,

Drew



--
View this message in context: http://r.789695.n4.nabble.com/Cannot-install-RPostgreSQL-tp4669380.html
Sent from the R help mailing list archive at Nabble.com.


From bcrombie at utk.edu  Wed Jun 12 22:36:38 2013
From: bcrombie at utk.edu (bcrombie)
Date: Wed, 12 Jun 2013 13:36:38 -0700 (PDT)
Subject: [R] rewrite script to eliminate constant object reference
Message-ID: <1371069398996-4669393.post@n4.nabble.com>

I'm adding a column (region) to a data frame (devUni8), and the (region)
column will be populated by a numeric code that is a function of another
column (state) in that data frame.  See part of the script below. 

How can I rewrite this so that I could apply the conditions to any data
frame without having to keep typing its name (in this case, "devUni8$"). 
I've heard the attach() function is to be avoided, and I'm not good at with,
while, or if statements right now.  I've tried some other things but keep
getting "object not found" errors.  Assistance appreciated. Thanks.

#Create Region Variable
#########
devUni8$region=0

#Assign Northeast States
#########	
devUni8$region[devUni8$state >= 11 & devUni8$state <= 23 | devUni8$state >=
51 & devUni8$state <= 55] = 1	

#Assign Southeast States
#########
devUni8$region[devUni8$state >= 56 & devUni8$state <= 64 ] = 2



--
View this message in context: http://r.789695.n4.nabble.com/rewrite-script-to-eliminate-constant-object-reference-tp4669393.html
Sent from the R help mailing list archive at Nabble.com.


From nalimilan at club.fr  Wed Jun 12 23:27:27 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Wed, 12 Jun 2013 23:27:27 +0200
Subject: [R] [R-SIG-Mac] problem with the installation of r commander on
 a mac
In-Reply-To: <005501ce67ae$b0d0afc0$12720f40$@mcmaster.ca>
References: <E1700130-80B9-4463-A3DD-A65FDD4C2766@gmail.com>
	<001b01ce677e$076c95a0$1645c0e0$@mcmaster.ca>
	<E6DF22AD-58B5-4583-82E8-A1C30C47CC7C@gmail.com>
	<005501ce67ae$b0d0afc0$12720f40$@mcmaster.ca>
Message-ID: <1371072447.12472.18.camel@milan>

Le mercredi 12 juin 2013 ? 16:52 -0400, John Fox a ?crit :
> Dear Susanne,
> 
> You started this thread on r-help (though R-SIG-Mac would have been more
> appropriate), and so I'm copying my response to the r-help list. People will
> find it confusing if the messages are simply kept private.
> 
> It's not obvious to me exactly what your problem is now. In particular, is
> the Rcmdr package working when you start XQuartz before R? 
> 
> I see that you've installed and loaded the FactoMineR package. Presumably
> the Rcmdr package was already installed. Then you executed an R script
> provided by the authors of the FactoMineR package, which reinstalls and then
> modifies the Rcmdr package. I think that this is ill-advised (as opposed to
> providing an Rcmdr plug-in package for FactoMineR, as used to be the case),
> and if you're having problems with their script, you should really contact
> the authors. 
> 
> If I read the messages correctly, the script produces warnings, not errors,
> oddly relating to the language you're using (odd because the authors of the
> FactoMineR package are French) and it's possible that everything will work
> correctly despite the warnings.
It's possible that the file
http://factominer.free.fr/add-menu-facto-fr.txt that the FactoMineR
script downloads is not read using the correct encoding (it is in
CP2152), and thus contains invalid UTF-8 characters.

So indeed I would reinstall Rcmdr using
install.packages("Rcmdr")

and load Rcmdr separately using
library(Rcmdr)

If that works, the bug is in FactoMineR's nonstandard way of installing
a menu. A workaround might be to use their English install script:
source("http://factominer.free.fr/install-facto.r")


Regards

> I hope this helps,
>  John
> 
> > -----Original Message-----
> > From: Susanne.Ettinger [mailto:susanne.ettinger at gmail.com]
> > Sent: Wednesday, June 12, 2013 11:44 AM
> > To: John Fox
> > Subject: Re: [R] [R-SIG-Mac] problem with the installation of r
> > commander on a mac
> > 
> > Dear John,
> > 
> > thank you very much for your quick reply - I realize I sent this email
> > to the list without being a member, but I am a very beginner and
> > started this morning the installation process of R.
> > 
> > I have been printing out any possibly available information on how to
> > get started with R and I am following the exercices exposed in the book
> > written by Cornillon et al. (2012) to use FactoMineR to do some PCA
> > analysis on vulnerability data.
> > 
> > I downloaded the 3.0.1 version of R and have the 1.9-6 package of
> > Rcmdr. I also checked into the library(tcltk) but do not get an error
> > message, this seems to work fine.
> > 
> > Since I open XQuartz before starting the Rcmdr library, I am getting a
> > different error message than the ones of this morning. This is what it
> > looks like :
> > 
> > 
> > 	> install.packages()
> > 	--- SVP s?lectionner un miroir CRAN pour cette session ---
> > 	essai de l'URL 'http://cran.univ-
> > lyon1.fr/bin/macosx/contrib/3.0/FactoMineR_1.25.tgz'
> > 	Content type 'application/x-gzip' length 3397827 bytes (3.2 Mb)
> > 	URL ouverte
> > 	==================================================
> > 	downloaded 3.2 Mb
> > 
> > 
> > 
> > 
> > 	Les packages binaires t?l?charg?s sont dans
> > 	/var/folders/06/z7b6z3y102xgxls2xh251p5w0000gp/T//Rtmp13nIpm/downl
> > oaded_packages
> > 	> library(FactoMineR)
> > 	Le chargement a n?cessit? le package : car
> > 	Le chargement a n?cessit? le package : MASS
> > 	Le chargement a n?cessit? le package : nnet
> > 	Le chargement a n?cessit? le package : ellipse
> > 
> > 
> > 	Attachement du package : ?ellipse?
> > 
> > 
> > 	L'objet suivant est masqu? from ?package:car?:
> > 
> > 
> > 	    ellipse
> > 
> > 
> > 	Le chargement a n?cessit? le package : lattice
> > 	Le chargement a n?cessit? le package : cluster
> > 	Le chargement a n?cessit? le package : scatterplot3d
> > 	Le chargement a n?cessit? le package : leaps
> > 	> source("http://factominer.free.fr/install-facto-fr.r")
> > 	essai de l'URL 'http://cran.univ-
> > lyon1.fr/bin/macosx/contrib/3.0/Rcmdr_1.9-6.tgz'
> > 	Content type 'application/x-gzip' length 3759850 bytes (3.6 Mb)
> > 	URL ouverte
> > 	==================================================
> > 	downloaded 3.6 Mb
> > 
> > 
> > 
> > 
> > 	The downloaded binary packages are in
> > 	/var/folders/06/z7b6z3y102xgxls2xh251p5w0000gp/T//Rtmp13nIpm/downl
> > oaded_packages
> > 	essai de l'URL 'http://cran.univ-
> > lyon1.fr/bin/macosx/contrib/3.0/FactoMineR_1.25.tgz'
> > 	Content type 'application/x-gzip' length 3397827 bytes (3.2 Mb)
> > 	URL ouverte
> > 	==================================================
> > 	downloaded 3.2 Mb
> > 
> > 
> > 
> > 
> > 	The downloaded binary packages are in
> > 	/var/folders/06/z7b6z3y102xgxls2xh251p5w0000gp/T//Rtmp13nIpm/downl
> > oaded_packages
> > 	Avis dans grepl("\n", lines, fixed = TRUE) :
> > 	  la cha?ne de caract?res entr?e 1 est incorrecte dans cet
> > environnement linguistique
> > 	Avis dans grepl("\n", lines, fixed = TRUE) :
> > 	  la cha?ne de caract?res entr?e 5 est incorrecte dans cet
> > environnement linguistique
> > 	Avis dans grepl("\n", lines, fixed = TRUE) :
> > 	  la cha?ne de caract?res entr?e 31 est incorrecte dans cet
> > environnement linguistique
> > 	Avis dans grepl("\n", lines, fixed = TRUE) :
> > 	  la cha?ne de caract?res entr?e 35 est incorrecte dans cet
> > environnement linguistique
> > 	Avis dans grepl("\n", lines, fixed = TRUE) :
> > 	  la cha?ne de caract?res entr?e 81 est incorrecte dans cet
> > environnement linguistique
> > 	Avis dans grepl("\n", lines, fixed = TRUE) :
> > 	  la cha?ne de caract?res entr?e 84 est incorrecte dans cet
> > environnement linguistique
> > 	Avis dans grepl("\n", lines, fixed = TRUE) :
> > 	  la cha?ne de caract?res entr?e 92 est incorrecte dans cet
> > environnement linguistique
> > 	Avis dans grepl("\n", lines, fixed = TRUE) :
> > 	  la cha?ne de caract?res entr?e 97 est incorrecte dans cet
> > environnement linguistique
> > 	Avis dans grepl("\n", lines, fixed = TRUE) :
> > 	  la cha?ne de caract?res entr?e 105 est incorrecte dans cet
> > environnement linguistique
> > 	Avis dans grepl("\n", lines, fixed = TRUE) :
> > 	  la cha?ne de caract?res entr?e 114 est incorrecte dans cet
> > environnement linguistique
> > 	Avis dans grepl("\n", lines, fixed = TRUE) :
> > 	  la cha?ne de caract?res entr?e 170 est incorrecte dans cet
> > environnement linguistique
> > 	

> > 
> > 
> > 
> > 
> > This is where the file continues line by line with the same error
> > message.
> > So I think if I manage to get this fixed, I should be good to go 

> > If you have ever seen such type of an error and could give me a hint of
> > how to resolve the problem, this would be more than appreciated.
> > 
> > I will let you know whether I can get the Rcmd library to run and how 

> > if that ever happens ;-)
> > 
> > Thank you again !
> > 
> > Kind regards,
> > Susanne
> > 
> > __________________________
> > 
> > Susanne ETTINGER
> > Postdoctoral researcher
> > -
> > Laboratoire Magmas et Volcans
> > UBP - UMR6524 CNRS - M163 IRD
> > 5, rue Kessler
> > 63038 Clermont-Ferrand
> > -
> > Tel : ++33 (0)6.18.27.54.93
> > Fax : ++33 (0)4.73.34.67.44
> > -
> > susanne.ettinger at gmail.com
> > __________________________
> > 
> > "Obstacles are those frightful things you see when you take your eyes
> > off your goal."
> > Henry Ford
> > 
> > 
> > Le 12 juin 2013 ? 17:03, John Fox <jfox at mcmaster.ca> a ?crit :
> > 
> > 
> > 	Dear Susanne,
> > 
> > 	Installation instructions for the Rcmdr are at
> > 	<http://socserv.socsci.mcmaster.ca/jfox/Misc/Rcmdr/installation-
> > notes.html>,
> > 	but you've apparently done what you normally need to do to get it
> > to work.
> > 	Though you don't say so, I assume that you have the latest
> > versions of R
> > 	(3.0.1) and the Rcmdr (1.9-6), and that you've not only downloaded
> > XQuartz,
> > 	but installed it (a necessary step on Mac OS X 10.8).
> > 
> > 	Beyond that, you haven't provided much detail about the error, but
> > I suspect
> > 	that for some reason XQuartz isn't finding your display. One way
> > to check
> > 	whether the error is particular to the Rcmdr is to try to load the
> > tcltk
> > 	package in R directly via library(tcltk). You might also try
> > starting the
> > 	XQuartz app *before* you start R.
> > 
> > 	It's a bit disconcerting that others have occasionally reported a
> > similar
> > 	problem, solved the problem, but, as far as I know, failed to post
> > the
> > 	solution to this list, which seems to me a common courtesy. If I
> > knew the
> > 	solution, I could add it to the Rcmdr installation notes.
> > 
> > 	I'm not a frequent user of Mac OS X, and I've never experienced
> > problems
> > 	installing the Rcmdr on it. I imagine that other list members will
> > be able
> > 	to offer more concrete help.
> > 
> > 	Best,
> > 	John
> > 
> > 	-----------------------------------------------
> > 	John Fox
> > 	Senator McMaster Professor of Social Statistics
> > 	Department of Sociology
> > 	McMaster University
> > 	Hamilton, Ontario, Canada
> > 
> > 
> > 
> > 
> > 
> > 		-----Original Message-----
> > 		From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> > 		project.org] On Behalf Of Susanne.Ettinger
> > 		Sent: Wednesday, June 12, 2013 10:06 AM
> > 		To: r-help at r-project.org
> > 		Subject: Re: [R] [R-SIG-Mac] problem with the installation
> of
> > r
> > 		commander on a mac
> > 
> > 		Dear all,
> > 
> > 		I am trying to install R and the Rcmdr package on a MacOSX
> > 10.8.4.
> > 
> > 		It appears that I keep getting the error message "Erreur :
> le
> > 		chargement du package ou de l'espace de noms a ?chou? pour
> > 'Rcmdr'" no
> > 		matter what my approach is. Even downloading XQuartz-2.7.4
> > did not
> > 		help.
> > 
> > 		I found the same problem outlined on the following website
> > 
> > 		https://stat.ethz.ch/pipermail/r-help/2012-
> > October/325305.html
> > 
> > 		and was wondering whether a solution to the problem has been
> > stated
> > 		since then and if you could help me with instructions how to
> > proceed ?
> > 
> > 		Thank you very much for your help !
> > 
> > 		Kind regards,
> > 		Susanne
> > 
> > 		__________________________
> > 
> > 		Susanne ETTINGER
> > 		Postdoctoral researcher
> > 		-
> > 		Laboratoire Magmas et Volcans
> > 		UBP - UMR6524 CNRS - M163 IRD
> > 		5, rue Kessler
> > 		63038 Clermont-Ferrand
> > 		-
> > 		Tel : ++33 (0)6.18.27.54.93
> > 		Fax : ++33 (0)4.73.34.67.44
> > 		-
> > 		susanne.ettinger at gmail.com
> > 		__________________________
> > 
> > 		"The eye sees only what the mind is prepared to comprehend."
> > 		Robertson Davies
> > 
> > 		______________________________________________
> > 		R-help at r-project.org mailing list
> > 		https://stat.ethz.ch/mailman/listinfo/r-help
> > 		PLEASE do read the posting guide http://www.R-
> > project.org/posting-
> > 		guide.html
> > 		and provide commented, minimal, self-contained, reproducible
> > code.
> > 
> > 
> > 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Wed Jun 12 23:31:38 2013
From: 538280 at gmail.com (Greg Snow)
Date: Wed, 12 Jun 2013 15:31:38 -0600
Subject: [R] rewrite script to eliminate constant object reference
In-Reply-To: <1371069398996-4669393.post@n4.nabble.com>
References: <1371069398996-4669393.post@n4.nabble.com>
Message-ID: <CAFEqCdwi5P_LLteMOZyfXMf7q_GYSdYRkGHcAFEPDi7bamF5mw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/344d535b/attachment.pl>

From jholtman at gmail.com  Wed Jun 12 23:32:41 2013
From: jholtman at gmail.com (Jim Holtman)
Date: Wed, 12 Jun 2013 16:32:41 -0500
Subject: [R] rewrite script to eliminate constant object reference
Message-ID: <lplv399uc9befvrf3j54rd97.1371072761075@email.android.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/4fac2b5e/attachment.pl>

From istazahn at gmail.com  Wed Jun 12 23:38:26 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 12 Jun 2013 17:38:26 -0400
Subject: [R] rewrite script to eliminate constant object reference
In-Reply-To: <1371069398996-4669393.post@n4.nabble.com>
References: <1371069398996-4669393.post@n4.nabble.com>
Message-ID: <CA+vqiLGgpknFETo_VSkMnuHJ+KR8-VV8SZxbSPgfeb3wcn1jSQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/0e59c6f6/attachment.pl>

From smartpink111 at yahoo.com  Thu Jun 13 00:37:57 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 12 Jun 2013 15:37:57 -0700 (PDT)
Subject: [R] new data
In-Reply-To: <104083AE5AAA634C993249DFCCE4C2030643BF94@CIPRESTE.ua.pt>
References: <104083AE5AAA634C993249DFCCE4C2030643BF94@CIPRESTE.ua.pt>
Message-ID: <1371076677.86565.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
Try this:


final3New<-read.table(file="real_data_cecilia.txt",sep="\t")
final3New1<-read.csv("real_data_cecilia_new.csv")
fun2<-function(dat){
??? ??? indx<- duplicated(dat)|duplicated(dat,fromLast=TRUE)??? 
??? ??? dat1<- subset(dat[indx,],dummy==1)
??? ??? dat2<- dat1[order(dat1$dimension),]
??? ??? indx1<- as.numeric(row.names(dat2))
??? ??? names(indx1)<- (seq_along(indx1)-1)%/%2+1
??? ??? dat3<- dat[c(indx1,indx1+1),]
??? ??? dat3$id<- names(c(indx1,indx1+1))
??? ??? lst1<- lapply(split(dat3,dat3$id),function(x){
??? ??? ??? ??????? x1<- x[-1,]
??? ??? ??? ??? x2<- x1[which.min(abs(x1$dimension[1]-x1$dimension[-1]))+1,]
??? ??? ??? ??? x3<- subset(x,dummy==1)
??? ??? ??? ??? rowNx2<- as.numeric(row.names(x2))
??? ??? ??? ??? rowNx3<- as.numeric(row.names(x3))
??? ??? ??? ??? x4<- x3[which.min(abs(rowNx2-rowNx3)),]
??? ??? ??? ??? x5<- rbind(x4,x2)
??? ??? ??? ??????? x6<- x[is.na(match(row.names(x),row.names(x5))),]
??? ??? ??? ??? ? })
??? ? dat4<- do.call(rbind,lst1)
??? ? row.names(dat4)<- gsub(".*\\.","",row.names(dat4))
??? ? indxNew1<- sort(as.numeric(unique(row.names(dat4))))
??? ? dat0<- subset(dat[indx,],dummy==0)
??? ?if(nrow(dat0)>0){??? 
??? ? dat20<-dat0[order(dat0$dimension),]
??? ? indx0<- as.numeric(row.names(dat20))
??? ? names(indx0)<- (seq_along(indx0)-1)%/%2+1
??? ? dat30<- dat[c(indx0-1,indx0),]
??? ? dat30$id<- names(c(indx0-1,indx0))
??? ? lst0<- lapply(split(dat30,dat30$id),function(x) {
??? ??? ??? ??? ??? x1<- subset(x,dummy==1)
??? ??? ??? ??? ??? x2<- subset(x,dummy==0)
??? ??? ??? ??? ??? x3<- x1[which.min(abs(x1$dimension- unique(x2$dimension))),]
??? ??? ??? ??? ??? rowNx2<- as.numeric(row.names(x2))
??? ??? ??? ??? ??? rowNx3<- as.numeric(row.names(x3))
??? ??? ??? ??? ??? x4<- x2[which.min(abs(rowNx2-rowNx3)),]
??? ??? ??? ??? ??????? x5<- rbind(x3,x4)
??? ??? ??? ??? ??? x6<- x[is.na(match(row.names(x),row.names(x5))),]
??? ??? ??? ??? ??? })
??? dat40<- do.call(rbind,lst0)
??? row.names(dat40)<- gsub(".*\\.","",row.names(dat40))
??? indxNew0<- sort(as.numeric(unique(row.names(dat40))))
??? res1Del<-dat[indxNew1,]
??? res0Del<-dat[indxNew0,]
??? indx10<-sort(as.numeric(union(row.names(res0Del),row.names(res1Del))))
??? if(length(indx10)%%2==1){
??? res10Del<-unique(rbind(res1Del,res0Del))
???? ?indx10New<- sort(as.numeric(row.names(res10Del)))
??? ?resF<- dat[-indx10New,]
??? resF
??? }
??? else{
??????? resF<- dat[-indx10,]
??????? resF
??? }
??? }
??? else{
??? resF<- dat[-indxNew1,]
??? }
??? }

###Old Function
fun3<- function(dat){
????????? indx<- duplicated(dat)
??? ? dat1<- subset(dat[indx,],dummy==1)
??? ? dat0<- subset(dat[indx,],dummy==0)
??? ? indx1<- as.numeric(row.names(dat1))
??? ?indx11<- sort(c(indx1,indx1+1))
??? ?indx0<- as.numeric(row.names(dat0))
??? ?indx00<- sort(c(indx0,indx0-1))
??? ? indx10<- sort(c(indx11,indx00))
??? ?res <- dat[-indx10,]
??? res
??? }
##Applying fun1() (from previous post) ? ??? 
res5Percent<- fun1(final3New,0.05,50)
res5Percent1<- fun1(final3New1,0.05,50)
res10Percent<- fun1(final3New,0.10,200)
res10Percent1<- fun1(final3New1,0.10,200)
res20Percent<- fun1(final3New,0.20,100)
res20Percent1<- fun1(final3New1,0.20,100)

###Applying fun2()
res5F2<- fun2(res5Percent)
res5F2_1<- fun2(res5Percent1)
res10F2<- fun2(res10Percent)
res10F2_1<- fun2(res10Percent1)
res20F2<- fun2(res20Percent)
res20F2_1<- fun2(res20Percent1)
??? 
#Applying fun3()
res5F3<- fun3(res5Percent)
res5F3_1<- fun3(res5Percent1)
res10F3<- fun3(res10Percent)
res10F3_1<- fun3(res10Percent1)
res20F3<- fun3(res20Percent)
res20F3_1<- fun3(res20Percent1)

vec1<- rep(c("res5F2","res10F2","res20F2"),2)
vec2<- rep(c("res5F3","res10F3","res20F3"),2)
vec1[4:6]<-paste(vec1[4:6],"_1",sep="")
vec2[4:6]<-paste(vec2[4:6],"_1",sep="")
?resTbl<-data.frame( Dataset=rep(rep(c("final3New","final3New1"),each=3),2),Funct=rep(c("fun2","fun3"),each=6),do.call(rbind,lapply(as.list(c(vec1,vec2)),function(x) {x1<-get(x);c(N_row=nrow(x1),Sub0_Nrow=nrow(subset(x1,dummy==0)),Sub1_Nrow=nrow(subset(x1,dummy==1)),Uniq_Nrow=nrow(unique(x1)))})),stringsAsFactors=FALSE)
?row.names(resTbl)<- c(vec1,vec2)
resTbl
#???????????? Dataset Funct N_row Sub0_Nrow Sub1_Nrow Uniq_Nrow
#res5F2???? final3New? fun2?? 276?????? 138?????? 138?????? 276
#res10F2??? final3New? fun2?? 454?????? 227?????? 227?????? 454
#res20F2??? final3New? fun2?? 284?????? 142?????? 142?????? 284
#res5F2_1? final3New1? fun2?? 288?????? 144?????? 144?????? 288
#res10F2_1 final3New1? fun2?? 488?????? 244?????? 244?????? 488
#res20F2_1 final3New1? fun2?? 310?????? 155?????? 155?????? 310
#res5F3???? final3New? fun3?? 276?????? 138?????? 138?????? 276
#res10F3??? final3New? fun3?? 452?????? 226?????? 226?????? 452
#res20F3??? final3New? fun3?? 284?????? 142?????? 142?????? 284
#res5F3_1? final3New1? fun3?? 288?????? 144?????? 144?????? 288
#res10F3_1 final3New1? fun3?? 488?????? 244?????? 244?????? 488
#res20F3_1 final3New1? fun3?? 310?????? 155?????? 155?????? 310
?head(res5F2_1,4)
#????? firm year industry dummy dimension
#1 500622043 2004??????? 1???? 1????? 1172
#2 501611886 2004??????? 1???? 0????? 1183
#3 500778787 2004??????? 1???? 1????? 5680
#4 500047006 2004??????? 1???? 0????? 5692
A.K.





________________________________
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com> 
Sent: Tuesday, June 11, 2013 4:36 PM
Subject: new data




Here it is.

Cec?lia?


From rolf.turner at xtra.co.nz  Thu Jun 13 00:46:01 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Thu, 13 Jun 2013 10:46:01 +1200
Subject: [R] Proper way to implement package internal functions
In-Reply-To: <692DDA2E-D9DC-4C12-A984-1C8A0B40AEB2@depauw.edu>
References: <5577D149-534C-41D8-AB66-D0D901124279@depauw.edu>
	<51B88C6C.4030302@gmail.com>
	<692DDA2E-D9DC-4C12-A984-1C8A0B40AEB2@depauw.edu>
Message-ID: <51B8FA29.8000301@xtra.co.nz>

On 13/06/13 03:34, Bryan Hanson wrote:

     <SNIP>
> So this warning from check is not a problem in the long run:
>
> * checking for missing documentation entries ... WARNING
> Undocumented code objects:
>    ?ang0to2pi? ?dAB? ?doBoxesIntersect? ...
> All user-level objects in a package should have documentation entries.
>
> if I understand correctly.  I guess the reason I didn't find any documentation is the wide lattitude which is possible.
I think you *might* get flak about the warnings if you submit your package
to CRAN.  I find such warnings annoying, anyhow.

To avoid them you can create a *.Rd file listing all the undocumented 
functions
in your package with an alias for the name of each such function and a
"usage" line for each such function.  Only a mild pain in the pohutukawa,
and it only needs to be done once.  (Possibly with some updating if new
undocumented functions are added to the package.)

The *.Rd file can be called anything you like (as long as it ends in 
".Rd" and
doesn't conflict with other *.Rd filled.  However a fairly common convention
is to name the file "melvin-internal.Rd" where "melvin" is the name of your
package.

     cheers,

         Rolf Turner


From michael.weylandt at gmail.com  Thu Jun 13 00:46:23 2013
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Wed, 12 Jun 2013 23:46:23 +0100
Subject: [R] Proper way to implement package internal functions
In-Reply-To: <692DDA2E-D9DC-4C12-A984-1C8A0B40AEB2@depauw.edu>
References: <5577D149-534C-41D8-AB66-D0D901124279@depauw.edu>
	<51B88C6C.4030302@gmail.com>
	<692DDA2E-D9DC-4C12-A984-1C8A0B40AEB2@depauw.edu>
Message-ID: <E4D2BE53-4570-49A5-A133-F30DCF6C1AB0@gmail.com>



On Jun 12, 2013, at 16:34, Bryan Hanson <hanson at depauw.edu> wrote:

> Thanks Duncan...
> 
> Silly me, it's section 1.6.1 not version 1.6.1!
> 
> So this warning from check is not a problem in the long run:
> 
> * checking for missing documentation entries ... WARNING
> Undocumented code objects:
>  ?ang0to2pi? ?dAB? ?doBoxesIntersect? ...
> All user-level objects in a package should have documentation entries.

What does your NAMESPACE file say?

MW
> 
> if I understand correctly.  I guess the reason I didn't find any documentation is the wide lattitude which is possible.
> 
> Thank you.  Bryan
> 
> On Jun 12, 2013, at 10:57 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
>> On 12/06/2013 10:44 AM, Bryan Hanson wrote:
>>> [previously posted on Stack Overflow: http://stackoverflow.com/questions/17034309/hiding-undocumented-functions-in-a-package-use-of-function-name ]
>>> 
>>> I've got some functions I need to make available in a package, and I don't want to export them or write much documentation for them. I'd just hide them inside another function but they need to be available to several functions so doing it that way becomes a scoping and maintenance issue. What is the right way to do this?  By that I mean do they need special names, do they go somewhere other than the R subdirectory, can I put them in a single file, etc? I've checked out the manuals (e.g. Writing R Extensions 1.6.1), and what I'm after is like the .internals concept in the core, but I don't see any instructions about how to do this generally.
>>> 
>>> For example, if I have functions foo1 and foo2 in a file foofunc.R, and these are intended for internal use only, should they be called foo1 or .foo1?  And the file that holds them, should it be .foofunc.R or foofunc-internals?  What should the Rd look like, or do I even need one?
>>> 
>>> I know people do this in packages all the time and I feel like I've seen this somewhere, but I can't find any resources just now.  Perhaps a suggestion of a package that does things this way which I could study would be sufficient.
>> 
>> The best way to do this is simply not to export those functions in your NAMESPACE file.  If you want to use a naming convention
>> internally to remind yourself that those are private, you can do so, but R doesn't force one on you, and there are no really popular conventions in use.   R won't complain if you don't document those functions at all.
>> 
>> There may have been other advice in the version 1.6.1 manual, but that is seriously out of date, more than 10 years old.  I recommend that you update to 3.0.1.
>> 
>> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Thu Jun 13 01:04:30 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 12 Jun 2013 16:04:30 -0700 (PDT)
Subject: [R] Creating a new var from conditional values in other vars
In-Reply-To: <1371067417.95095.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1371067417.95095.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1371078270.68393.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi `Bangali`,
You can type in the R Console ?with()?
?ifelse()
The details and some examples are there.


In addition to ?with(), you can use: ?within

dat1<-within(dat1,pattern<-ifelse(A>20 & B<=2.5 & C<=20,"Normal",ifelse(A <20 & B >2.5 & C >20,"Increased",ifelse(A >=20 & B >2.5 & C <=20,"Low","Other"))))

library(plyr)
?mutate()
dat1New<-mutate(dat1,pattern=ifelse(A>20 & B<=2.5 & C<=20,"Normal",ifelse(A <20 & B >2.5 & C >20,"Increased",ifelse(A >=20 & B >2.5 & C <=20,"Low","Other"))))
identical(dat1,dat1New)
#[1] TRUE
dat2<-transform(dat1,pattern=ifelse(A>20 & B<=2.5 & C<=20,"Normal",ifelse(A <20 & B >2.5 & C >20,"Increased",ifelse(A >=20 & B >2.5 & C <=20,"Low","Other")))) 
?identical(dat1,dat2)
#[1] TRUE
A.K.




Arun, 

Many thanks! The code works perfectly well. It seems that ifelse
 + with do the trick much better than if/else statement. Now ?I need to 
understand the mechanichs of what you did. Can you provide a link on how
 to use with 
----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Wednesday, June 12, 2013 4:03 PM
Subject: Re: Creating a new var from conditional values in other vars

Hi,
Try this:
set.seed(25)
dat1<- data.frame(A=sample(1:30,100,replace=TRUE),B=sample(1:35,100,replace=TRUE),C=sample(1:25,100,replace=TRUE))


dat1$pattern<-with(dat1,ifelse(A>20 & B<=2.5 & C<=20,"Normal",ifelse(A <20 & B >2.5 & C >20,"Increased",ifelse(A >=20 & B >2.5 & C <=20,"Low","Other"))))
head(dat1)
#?? A? B? C pattern
#1 13 20? 5?? Other
#2 21 15? 4???? Low
#3? 5 24? 1?? Other
#4 27 13? 6???? Low
#5? 4? 4 10?? Other
#6 30 19 22?? Other
A.K.




I am newbie to R coming from SAS (basic user). Quite a difficult move.... 
I have a dataframe named kappa exported from csv file 
kappa<-read.csv("kappacsv", header=TRUE, sep=";", dec=".") 
kappa contains 3 numeric vars (A,B and C) 
I want to create a new var called "pattern" depending on the values of the conditions in A, B and C 
I have tried many ways one has been this: 
kappa$pattern1<-99 # create a new numeric var in kappa dataframe 

if (A>=20 & B<=2.5 & C <=20){kappa$pattern<-"Normal"} 
else if (A <20 & B >2.5 & C >20){kappa$pattern<-"Increased"} 
else if (A >=20 & B >2.5 & C <=20){kappa$pattern<-"Low"} 
else {kappa$pattern<-?Other?} 
? 
The code does not work and I get errors all the time. 
Any help will be greatly appreciated 
Thanks


From hanson at depauw.edu  Thu Jun 13 01:13:33 2013
From: hanson at depauw.edu (Bryan Hanson)
Date: Wed, 12 Jun 2013 19:13:33 -0400
Subject: [R] Proper way to implement package internal functions
In-Reply-To: <51B8FA29.8000301@xtra.co.nz>
References: <5577D149-534C-41D8-AB66-D0D901124279@depauw.edu>
	<51B88C6C.4030302@gmail.com>
	<692DDA2E-D9DC-4C12-A984-1C8A0B40AEB2@depauw.edu>
	<51B8FA29.8000301@xtra.co.nz>
Message-ID: <131EDD96-43C2-4523-9553-09185274D67C@depauw.edu>

Hi Rolf...  Thanks.  I discovered the approach you described by looking at the source for spatstat, which as it turns out does exactly that.  I also discovered by testing that if you don't export a pattern, but rather export the specific names, not including the functions one wants to hide, that the warning goes away.  Since it is less work to change the export statement compared to even a minimal Rd, that's the way I went.  It's interesting that there is not more info about these options available.  Thanks, Bryan

On Jun 12, 2013, at 6:46 PM, Rolf Turner <rolf.turner at xtra.co.nz> wrote:

> On 13/06/13 03:34, Bryan Hanson wrote:
> 
>    <SNIP>
>> So this warning from check is not a problem in the long run:
>> 
>> * checking for missing documentation entries ... WARNING
>> Undocumented code objects:
>>   ?ang0to2pi? ?dAB? ?doBoxesIntersect? ...
>> All user-level objects in a package should have documentation entries.
>> 
>> if I understand correctly.  I guess the reason I didn't find any documentation is the wide lattitude which is possible.
> I think you *might* get flak about the warnings if you submit your package
> to CRAN.  I find such warnings annoying, anyhow.
> 
> To avoid them you can create a *.Rd file listing all the undocumented functions
> in your package with an alias for the name of each such function and a
> "usage" line for each such function.  Only a mild pain in the pohutukawa,
> and it only needs to be done once.  (Possibly with some updating if new
> undocumented functions are added to the package.)
> 
> The *.Rd file can be called anything you like (as long as it ends in ".Rd" and
> doesn't conflict with other *.Rd filled.  However a fairly common convention
> is to name the file "melvin-internal.Rd" where "melvin" is the name of your
> package.
> 
>    cheers,
> 
>        Rolf Turner


From yelin at lbl.gov  Thu Jun 13 02:55:57 2013
From: yelin at lbl.gov (Ye Lin)
Date: Wed, 12 Jun 2013 17:55:57 -0700
Subject: [R] identify data points by certain criteria
Message-ID: <CAAvu=b==j0f8rYobAZgYHVfPvQ29w+Cnk-FQA6cCWji-Jy5pZg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130612/68e1f233/attachment.pl>

From dwinsemius at comcast.net  Thu Jun 13 03:20:10 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 12 Jun 2013 18:20:10 -0700
Subject: [R] identify data points by certain criteria
In-Reply-To: <CAAvu=b==j0f8rYobAZgYHVfPvQ29w+Cnk-FQA6cCWji-Jy5pZg@mail.gmail.com>
References: <CAAvu=b==j0f8rYobAZgYHVfPvQ29w+Cnk-FQA6cCWji-Jy5pZg@mail.gmail.com>
Message-ID: <8A063994-2F0B-482F-83AA-FF3755B354C9@comcast.net>


On Jun 12, 2013, at 5:55 PM, Ye Lin wrote:

> Hey I want to identify data points by criteria, here is an example of my
> 1min data
> 
> Time     Var1      Var2
> 00:00    1              0
> 00:01    0              0
> 00:02    1              0
> 00:03    1              0
> 00:04    0              0
> 00:05    1              0
> 00:06    1              0
> 00:07    1              0
> 00:08    1              0
> 00:09    0              0
> 00:10    1              0
> 00:11    1              0
> 00:12    1              0
> 00:13    0              0
> 
> I want to identify the data points where Var1=0 and Var2=0, ( in this
> example shud be the points highlighted above), then calculate the time
> duration between these data points, (in this example, shud be 3min, 5 min
> and 4min), then identify the starting point of the max time duration ( in
> this example shud be the starting point of 5-min-duration, return the data
> points at 00:09), finally return the value in "Time" column ( in this
> example shud be "00:09")
> 

While you are waiting for an answer you might want to read the Posting Guide:

http://www.R-project.org/posting-guide.html

Points to pay special attention to: Plain-text. Posting code. Posting examples in form that can be pasted into console session (dump or dput functions). Providing context for problem (such as describing the conventions for your time-scale)  and your background (since this looks like a homework exercise.)



> Thanks for your help!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________


David Winsemius
Alameda, CA, USA


From kridox at ymail.com  Thu Jun 13 03:22:32 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 13 Jun 2013 10:22:32 +0900
Subject: [R] Cannot install RPostgreSQL
In-Reply-To: <1371060799436-4669380.post@n4.nabble.com>
References: <1371060799436-4669380.post@n4.nabble.com>
Message-ID: <51B91ED8.7000307@ymail.com>

Hello,

If you carefully check the error message, it is clearly written:

RS-PostgreSQL.h:23:26: fatal error: libpq-fe.h: No such file or directory

Some header files are missing.
Here is the result of a quick search on the web: "libpq-dev" for Ubuntu.

If I may suggest, you should upgrade the version of R.

Regards,
Pascal


On 13/06/13 03:13, Drew wrote:
> Hello everyone,
>
> I am extremely new to R. I have yet to write any complicated code myself,
> however I have been learning largely by reading code that has already been
> written. Long story short, I have been running a code that makes use of the
> RPostgreSQL package for some time now. For some reason I just recently
> started to get an error. Whenever I try to load the RPostgreSQL package I
> get:
>
>> library(RPostgreSQL)
> Error in library(RPostgreSQL) : there is no package called ?RPostgreSQL?
>
> I also tried install.packages(RPostgreSQL) and
> install.packages("RPostgreSQL"). I've attached a text document of the
> resulting error here.
>
> Error.txt <http://r.789695.n4.nabble.com/file/n4669380/Error.txt>
>
> I'm running R version 2.15.1 on Ubuntu. I can't seem to find a solution to
> the problem online. And let me be clear, I was able to load this package
> without an issue no longer than a week ago. Any help you can offer would be
> much appreciated.
>
> Thanks,
>
> Drew
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Cannot-install-RPostgreSQL-tp4669380.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From imvinhs at yahoo.com.vn  Thu Jun 13 01:58:24 2013
From: imvinhs at yahoo.com.vn (vinhnguyen04x)
Date: Wed, 12 Jun 2013 16:58:24 -0700 (PDT)
Subject: [R] odds ratio per standard deviation
In-Reply-To: <XFMail.20130612171403.Ted.Harding@wlandres.net>
References: <1371001120339-4669315.post@n4.nabble.com>
	<CAFEqCdysEi4EFqjZ1bNcwVtU_ORVD2FWmW7kNcv=UOputSO9Qw@mail.gmail.com>
	<XFMail.20130612171403.Ted.Harding@wlandres.net>
Message-ID: <1371081504325-4669411.post@n4.nabble.com>

L. Snow,
Ted,

Many thanks, I am sorry to made a question without context. I use three
parameters of facial temperature, heart rate, and respiratory rate to
distinguish infectious patients from healthy subjects. So I use logistic
regression to generate a classification model and calculate the odds ratio
for these three parameters. In my case, I would like to know what kinds of
odds ratio can be used, odds ratio per standard deviation or odds ratio. 

Thanks you in advance for your help




--
View this message in context: http://r.789695.n4.nabble.com/odds-ratio-per-standard-deviation-tp4669315p4669411.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Thu Jun 13 03:29:26 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 12 Jun 2013 18:29:26 -0700 (PDT)
Subject: [R] identify data points by certain criteria
In-Reply-To: <CAAvu=b==j0f8rYobAZgYHVfPvQ29w+Cnk-FQA6cCWji-Jy5pZg@mail.gmail.com>
References: <CAAvu=b==j0f8rYobAZgYHVfPvQ29w+Cnk-FQA6cCWji-Jy5pZg@mail.gmail.com>
Message-ID: <1371086966.86860.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Not clear about the 'Time' column.
dat1<- read.table(text="
Time??? Var1????? Var2
00:00??? 1????????????? 0
00:01??? 0????????????? 0
00:02??? 1????????????? 0
00:03??? 1????????????? 0
00:04??? 0????????????? 0
00:05??? 1????????????? 0
00:06??? 1????????????? 0
00:07??? 1????????????? 0
00:08??? 1????????????? 0
00:09??? 0????????????? 0
00:10??? 1????????????? 0
00:11??? 1????????????? 0
00:12??? 1????????????? 0
00:13??? 0????????????? 0
",sep="",header=TRUE,stringsAsFactors=FALSE)


indx<-which(rowSums(dat1[,-1])==0)
dat1[indx[which.max(c(1,diff(as.numeric(gsub(".*:","",dat1[,1][indx])))))],]
#??? Time Var1 Var2
#10 00:09??? 0??? 0
dat1[indx[which.max(c(1,diff(as.numeric(gsub(".*:","",dat1[,1][indx])))))],"Time"]
#[1] "00:09"


A.K.



----- Original Message -----
From: Ye Lin <yelin at lbl.gov>
To: R help <r-help at r-project.org>
Cc: 
Sent: Wednesday, June 12, 2013 8:55 PM
Subject: [R] identify data points by certain criteria

Hey I want to identify data points by criteria, here is an example of my
1min data

Time? ?  Var1? ? ? Var2
00:00? ? 1? ? ? ? ? ? ? 0
00:01? ? 0? ? ? ? ? ? ? 0
00:02? ? 1? ? ? ? ? ? ? 0
00:03? ? 1? ? ? ? ? ? ? 0
00:04? ? 0? ? ? ? ? ? ? 0
00:05? ? 1? ? ? ? ? ? ? 0
00:06? ? 1? ? ? ? ? ? ? 0
00:07? ? 1? ? ? ? ? ? ? 0
00:08? ? 1? ? ? ? ? ? ? 0
00:09? ? 0? ? ? ? ? ? ? 0
00:10? ? 1? ? ? ? ? ? ? 0
00:11? ? 1? ? ? ? ? ? ? 0
00:12? ? 1? ? ? ? ? ? ? 0
00:13? ? 0? ? ? ? ? ? ? 0

I want to identify the data points where Var1=0 and Var2=0, ( in this
example shud be the points highlighted above), then calculate the time
duration between these data points, (in this example, shud be 3min, 5 min
and 4min), then identify the starting point of the max time duration ( in
this example shud be the starting point of 5-min-duration, return the data
points at 00:09), finally return the value in "Time" column ( in this
example shud be "00:09")

Thanks for your help!

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From derek at soylentgeek.com  Thu Jun 13 06:09:57 2013
From: derek at soylentgeek.com (Derek Serianni)
Date: Thu, 13 Jun 2013 00:09:57 -0400
Subject: [R] Need help with installing gplots
Message-ID: <CAHgGd1VoX0Mb2-0ZCQ-YTaBrQLNpwyVgXBJwAVoQpA5xuMF8hw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130613/8f0532af/attachment.pl>

From losedaghat at gmail.com  Thu Jun 13 07:26:02 2013
From: losedaghat at gmail.com (L S)
Date: Thu, 13 Jun 2013 01:26:02 -0400
Subject: [R] Plotting gps coordinates on Shapefile
Message-ID: <CAMgNocuFWrfgxicO8BvgaO3iHKS=5+LdO1VWn52n9t4AzgFSZQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130613/4e869667/attachment.pl>

From Andrew.McFadden at mpi.govt.nz  Thu Jun 13 03:43:40 2013
From: Andrew.McFadden at mpi.govt.nz (Andrew McFadden (Andy))
Date: Thu, 13 Jun 2013 01:43:40 +0000
Subject: [R] Lattice different colours for bars
Message-ID: <848DE0191A1C1D49BAEF06A404C5609D3CC7E9@wdcwmsp58.network.maf.govt.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130613/3dde420d/attachment.pl>

From dwinsemius at comcast.net  Thu Jun 13 08:40:06 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 12 Jun 2013 23:40:06 -0700
Subject: [R] odds ratio per standard deviation
In-Reply-To: <1371081504325-4669411.post@n4.nabble.com>
References: <1371001120339-4669315.post@n4.nabble.com>
	<CAFEqCdysEi4EFqjZ1bNcwVtU_ORVD2FWmW7kNcv=UOputSO9Qw@mail.gmail.com>
	<XFMail.20130612171403.Ted.Harding@wlandres.net>
	<1371081504325-4669411.post@n4.nabble.com>
Message-ID: <8D1D0E26-9CE8-4EDF-9EFE-520F651712D0@comcast.net>


On Jun 12, 2013, at 4:58 PM, vinhnguyen04x wrote:

> L. Snow,
> Ted,
> 
> Many thanks, I am sorry to made a question without context. I use three
> parameters of facial temperature, heart rate, and respiratory rate to
> distinguish infectious patients from healthy subjects. So I use logistic
> regression to generate a classification model and calculate the odds ratio
> for these three parameters. In my case, I would like to know what kinds of
> odds ratio can be used, odds ratio per standard deviation or odds ratio. 
> 
> Thanks you in advance for your help
> 

The answer will depend on the distribution of the covariates, about which you have offered no information. It may also depend on what would be considered a relevant distance along the covariate "axes" by your audience. Generally odds ratios comparing a single year of increased age are not very interesting, but a difference of a decade will be understood by most audiences. Frank Harrell's rms/Hmisc package displays differences comparing the interquartile range. For heart rate I would think comparing a value of 80 to a value of 81 would nnot be thought of as clinically relevant. Most people are not capable of transforming odds ratios presented for a single unit difference to ones comparing a ten unit contrast. Differences of a degree of facial temperature might be more sensible given the narrow range over which temeperatures are maintained.  It is your responsibility to make these decisions based on domain knowledge. Any knowledgeable practitioner of statistics can make transformation to another contrast if enough digits of accuracy are offered. (It is rather frustrating to see published comparisons for single units of difference presented with minimal accuracy.)

-- 

David Winsemius
Alameda, CA, USA


From virgilio.gomez at uclm.es  Thu Jun 13 08:46:48 2013
From: virgilio.gomez at uclm.es (Virgilio =?ISO-8859-1?Q?G=F3mez-Rubio?=)
Date: Thu, 13 Jun 2013 08:46:48 +0200
Subject: [R] useR! 2013 conference schedule and data analysis contest
Message-ID: <1371106008.2555.5.camel@virgil-HP-Compaq-8000-Elite-USDT-PC>

Dear all,

This is an announcement that the final schedule for the useR! 2013
conference is available at http://www.r-project.org/useR-2013 .

This year we will be having a Data Analysis Contest open to all
participants. You can find more information here:

http://www.edii.uclm.es/~useR-2013/#contest


Hope to see you soon in Albacete.

-- 
Virgilio G?mez Rubio
Departamento de Matem?ticas
Escuela de Ingenieros Industriales - Albacete
Avda. Espa?a s/n - 02071 Albacete - SPAIN
Tlf: (+34) 967 59 92 00 ext. 8291


From dwinsemius at comcast.net  Thu Jun 13 08:47:51 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 12 Jun 2013 23:47:51 -0700
Subject: [R] Lattice different colours for bars
In-Reply-To: <848DE0191A1C1D49BAEF06A404C5609D3CC7E9@wdcwmsp58.network.maf.govt.nz>
References: <848DE0191A1C1D49BAEF06A404C5609D3CC7E9@wdcwmsp58.network.maf.govt.nz>
Message-ID: <D9C742F3-0C0B-4D82-B1FB-C461EED918A1@comcast.net>


On Jun 12, 2013, at 6:43 PM, Andrew McFadden (Andy) wrote:

> Hi all
> 
> Perhaps this is torturous methodology. I was trying to use lattice to produce a barchart showing the number positive and negative over time. I wasn't quite sure how create a different colour for values of arbo$Ikeda in the example below ie red for ikeda and green for neg.
> 
> 
> library(reshape)
> library(lattice)
> 
> Time=c(rep(6,17), rep(5,17), rep(4,17),
>       rep(3,17),rep(2,17), rep(1,17))
> Ikeda=c(rep("Ikeda",6),rep("Neg",11),
>        rep("Ikeda",0),rep("Neg",17),
>        rep("Ikeda",1),rep("Neg",16),
>        rep("Ikeda",0),rep("Neg",17),
>        rep("Ikeda",0),rep("Neg",17),
>        rep("Ikeda",0),rep("Neg",17))
> Theileria=c(rep("Other",6),rep("Neg",11),
>         rep("Other",12),rep("Neg",5),
>         rep("Other",12),rep("Neg",5),
>         rep("Other",14),rep("Neg",3),
>         rep("Other",14),rep("Neg",3),
>         rep("Other",13),rep("Neg",4))
> value=c(rep(1,102))
> arbo=data.frame(Time, Ikeda,Theileria,value)
> 
> arbo$Time=as.factor(arbo$Time)
> levels(arbo$Time)
> 
> arbo$Time=factor(arbo$Time,
>                    levels=c(1,2,3,4,5,6),
>                    labels=c("Dec 2008", "Dec 2009", "Dec 2010",
>                             "Dec 2011", "Jun 2012", "Dec 2012")
> )
> 
> mdat=melt(arbo,measure.var=c(4),id.var=c(1:3),na.rm=FALSE)
> mdat=cast(mdat,Time +Ikeda~variable,fun.aggregate = c(sum))

barchart(value~Ikeda|Time, data = mdat,
       type="count",
             col=c("green","red")[1+(mdat$Ikeda=="Ikeda")],
       cex=1.1,
       xlab="PCR positive over time",
       aspect = c(1.5),layout = c(6, 1),
       stack=FALSE,
       strip=strip.custom(strip.names=FALSE, strip.levels=TRUE, bg="light blue"),
       par.strip.text=list(cex=1.1), scales=list(cex=c(1.1)))
Any suggestions on how to do this would be appreciated.

> 
> Regards
> 
> Andrew
> 
> Investigation and Diagnostic Centre- Upper Hutt
> 
-- 
David Winsemius
Alameda, CA, USA


From ripley at stats.ox.ac.uk  Thu Jun 13 09:19:59 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 13 Jun 2013 08:19:59 +0100
Subject: [R] Need help with installing gplots
In-Reply-To: <CAHgGd1VoX0Mb2-0ZCQ-YTaBrQLNpwyVgXBJwAVoQpA5xuMF8hw@mail.gmail.com>
References: <CAHgGd1VoX0Mb2-0ZCQ-YTaBrQLNpwyVgXBJwAVoQpA5xuMF8hw@mail.gmail.com>
Message-ID: <51B9729F.1020107@stats.ox.ac.uk>

On 13/06/2013 05:09, Derek Serianni wrote:
> Hi,
>
> I am new to linux so please bear with me.
>
> OS is CentOS 5.9  - This cannot be changed
>
> I am following a guide given to me to setup a server.
>
> I am told to do the following:
>
> To Install R:
>
> sudo yum install gcc
> sudo yum install make
> sudo yum install telnet
> sudo rpm -Uvh
> http://download.fedoraproject.org/pub/epel/5/x86_64/epel-release-5-4.noarch.rpm
> sudo yum install  R
>
> sudo R CMD INSTALL ~/APX.X.X/Rserve_0.6-2.tar.gz
> This does not work .... what should I be doing here?

Explaining what 'does not work' means.  Why do you need Rserve: very few 
other packages rely on it?

>
>
> sudo R
>
> install.packages("gplots")
> --- This is where I run into problems.   When I run this, I am presented
> with the message:  gplot is not available for R version 2.15.2
> --- How can I get a version of gplot that will work with R version 2.15.2

 From the archive at 
http://cran.r-project.org/src/contrib/Archive/gplots/ (assuming you mean 
'gplots').

> --- I am okay with going to another version of R if this will help

That is what the posting guide asked you to do.

>
>
>
> install.packages("chron")
>
> install.packages("party")
>
> install.packages("RColorBrewer")
>
> q("default",1,TRUE) to exit
>
>
>
>
> If anyone could help me I would really appreciate it.
>
>
> Thanks,
>
> D.
>
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From antony.akkara at ge.com  Thu Jun 13 09:08:54 2013
From: antony.akkara at ge.com (R_Antony)
Date: Thu, 13 Jun 2013 00:08:54 -0700 (PDT)
Subject: [R] Search for Matching word in a Dataframe
Message-ID: <1371107334367-4669426.post@n4.nabble.com>

Hi

Here i have a dataframe called MyDat.

MyDat<- data.frame(NAME = c("ANTONY001", "ARUN002", "AKBAR003", 
"JONATHAN004", "PETER005", "AVATAR006", "YULIJIE007", "RAM008", 
"DESILVA009"), 
COL_A = c(0, 0, 0, 1, 0, 1, 2, 3, 1), 
COL_B = c(0, 3, 0, 3, 3, 1, 0, 1, 2), 
COL_C = c(1, 2, 3, 1, 2, 3, 1, 2, 3), stringsAsFactors=FALSE) 

and here my requirement what is, i need to get the row number, where the
NAME column matches with selection criteria.

For eg:- If i give NAME = "ARUN", It should select row no: 2 where 
"ARUN002" comes.

i tried with this way 
nRow<-which("ARUN"==MyDat[,1]) - But here, the row number will select only
the NAME column value match exactly, otherwise it wont select.

My requirment is, it should select the row number(s), where the searching
word should match atleast. Exact match is not compulsory.



- Thanks in Advance.
Antony.



--
View this message in context: http://r.789695.n4.nabble.com/Search-for-Matching-word-in-a-Dataframe-tp4669426.html
Sent from the R help mailing list archive at Nabble.com.


From kridox at ymail.com  Thu Jun 13 09:37:45 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 13 Jun 2013 16:37:45 +0900
Subject: [R] Search for Matching word in a Dataframe
In-Reply-To: <1371107334367-4669426.post@n4.nabble.com>
References: <1371107334367-4669426.post@n4.nabble.com>
Message-ID: <51B976C9.2050406@ymail.com>

Hello,

?grep

 > grep('ARUN', MyDat$NAME)
[1] 2

Regards,
Pascal



On 13/06/13 16:08, R_Antony wrote:
> Hi
>
> Here i have a dataframe called MyDat.
>
> MyDat<- data.frame(NAME = c("ANTONY001", "ARUN002", "AKBAR003",
> "JONATHAN004", "PETER005", "AVATAR006", "YULIJIE007", "RAM008",
> "DESILVA009"),
> COL_A = c(0, 0, 0, 1, 0, 1, 2, 3, 1),
> COL_B = c(0, 3, 0, 3, 3, 1, 0, 1, 2),
> COL_C = c(1, 2, 3, 1, 2, 3, 1, 2, 3), stringsAsFactors=FALSE)
>
> and here my requirement what is, i need to get the row number, where the
> NAME column matches with selection criteria.
>
> For eg:- If i give NAME = "ARUN", It should select row no: 2 where
> "ARUN002" comes.
>
> i tried with this way
> nRow<-which("ARUN"==MyDat[,1]) - But here, the row number will select only
> the NAME column value match exactly, otherwise it wont select.
>
> My requirment is, it should select the row number(s), where the searching
> word should match atleast. Exact match is not compulsory.
>
>
>
> - Thanks in Advance.
> Antony.
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Search-for-Matching-word-in-a-Dataframe-tp4669426.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From gallon.li at gmail.com  Thu Jun 13 09:56:19 2013
From: gallon.li at gmail.com (Gallon Li)
Date: Thu, 13 Jun 2013 15:56:19 +0800
Subject: [R] find the position of first observation for each subject
Message-ID: <CAKO0DpgCM=scU+G6sJS+wB0qdmtvwaDz5ngQ_KV__UnMtaR-Bw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130613/44e4f57e/attachment.pl>

From ccampbell at mango-solutions.com  Thu Jun 13 10:00:34 2013
From: ccampbell at mango-solutions.com (Chris Campbell)
Date: Thu, 13 Jun 2013 08:00:34 +0000
Subject: [R] find the position of first observation for each subject
In-Reply-To: <CAKO0DpgCM=scU+G6sJS+wB0qdmtvwaDz5ngQ_KV__UnMtaR-Bw@mail.gmail.com>
References: <CAKO0DpgCM=scU+G6sJS+wB0qdmtvwaDz5ngQ_KV__UnMtaR-Bw@mail.gmail.com>
Message-ID: <2C2DB2ABEE65DB40B7946E54C71A8C0942F40633@mexchange.Mango.local>

which(!duplicated(ds[, "id"]))


Chris Campbell, PhD
Tel. +44 (0) 1249 705 450?| Mobile. +44 (0) 7929 628 349
mailto:ccampbell at mango-solutions.com?| http://www.mango-solutions.com
Mango Solutions, 2 Methuen Park, Chippenham, Wiltshire , SN14 OGB UK

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Gallon Li
Sent: 13 June 2013 08:56
To: R-help at r-project.org
Subject: [R] find the position of first observation for each subject

suppose I have the following data

id=c(rep(1,3),rep(2,5),rep(3,4))
time=c(seq(1,3),seq(2,6),seq(1,4))

ds=cbind(id,time)

> ds
      id time
 [1,]  1    1
 [2,]  1    2
 [3,]  1    3
 [4,]  2    2
 [5,]  2    3
 [6,]  2    4
 [7,]  2    5
 [8,]  2    6
 [9,]  3    1
[10,]  3    2
[11,]  3    3
[12,]  3    4

i want to return a vector that indicates the position of the first observation for each id. for the above data, i wish to get (1,4,9).

is it possible to get this quickly>?

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

--

LEGAL NOTICE\ \ This message is intended for the use of ...{{dropped:18}}


From b.rowlingson at lancaster.ac.uk  Thu Jun 13 10:27:02 2013
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 13 Jun 2013 09:27:02 +0100
Subject: [R] Plotting gps coordinates on Shapefile
In-Reply-To: <f81ca4125fe34d2eb1269f7d1f0e2103@EX-0-HT0.lancs.local>
References: <f81ca4125fe34d2eb1269f7d1f0e2103@EX-0-HT0.lancs.local>
Message-ID: <CANVKczPYbUT9rSW=r=FaRTQmYMaVPgt93LWVnmSeJu5Z7rjH=w@mail.gmail.com>

On Thu, Jun 13, 2013 at 6:26 AM, L S <losedaghat at gmail.com> wrote:

> I realized that the coordinates are completely different.  The coordinates
> in my data file (i.e. my csv file) are traditional GPS coordinates (e.g. 39.17
> or 76.37).  The shapefile however has x,y values such as 1416813.54262877
> or 561125.546602725. I am not familiar with what type of coordinate system
> those values use.
>
> How can I change the coordinates in my csv file to match the same system as
> my shapefile or the other way around--i.e. to get my shapefile to have
> similar coordinates as my csv file?

 You really need to know the coordinate reference system that your
points are in.

 What you call "traditional GPS coordinates" is formally known as
EPSG:4326. I suspect your points are in some small-region plane
coordinate system. In the UK, for example, we have a square metric
grid system that is EPSG:27700. The units of this system are metres
from a point origin off the south-west of the UK, which is great for
small areas in the UK but not applicable to India, because it assumes
a flat earth. If your data is in the USA, then it might be one of the
state plane systems. There and elsewhere, it might be one of the
global UTM zones (but you have to know which one).

There are thousands of possible coordinate systems:
http://www.epsg-registry.org/ or you can make your own using PROJ4
strings...

 To convert from one coordinate system to another, I normally use
spTransform from the rgdal package since I mostly work with sp-class
objects. I think there's a 'project' function that can work with raw
x-y coordinates in vectors or matrices.

 You can also try asking on the R-sig-geo mailing list where the map
people hang out.

Barry


From careyshan at gmail.com  Thu Jun 13 11:02:06 2013
From: careyshan at gmail.com (Shane Carey)
Date: Thu, 13 Jun 2013 10:02:06 +0100
Subject: [R] Force boxplot y-axis to zero
Message-ID: <CA+jRDxAqZBV4s8EthPqmrJnFU_ARZUY1djYoBv_4fDT2QHO-HA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130613/5164e43a/attachment.pl>

From ruipbarradas at sapo.pt  Thu Jun 13 11:59:06 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 13 Jun 2013 10:59:06 +0100
Subject: [R] Force boxplot y-axis to zero
In-Reply-To: <CA+jRDxAqZBV4s8EthPqmrJnFU_ARZUY1djYoBv_4fDT2QHO-HA@mail.gmail.com>
References: <CA+jRDxAqZBV4s8EthPqmrJnFU_ARZUY1djYoBv_4fDT2QHO-HA@mail.gmail.com>
Message-ID: <51B997EA.1070803@sapo.pt>

Hello,

Something like this?


x <- runif(100, min = 2, max = 10)
boxplot(x, ylim = c(0, max(x)))


Hope this helps,

Rui Barradas

Em 13-06-2013 10:02, Shane Carey escreveu:
> Hi,
>
> I have a Tukey boxplot y-axis starting at 2.5, how do I force it's y-axis
> to start a t zero
>
> Thanks
>


From careyshan at gmail.com  Thu Jun 13 12:18:21 2013
From: careyshan at gmail.com (Shane Carey)
Date: Thu, 13 Jun 2013 11:18:21 +0100
Subject: [R] Force boxplot y-axis to zero
In-Reply-To: <51B997EA.1070803@sapo.pt>
References: <CA+jRDxAqZBV4s8EthPqmrJnFU_ARZUY1djYoBv_4fDT2QHO-HA@mail.gmail.com>
	<51B997EA.1070803@sapo.pt>
Message-ID: <CA+jRDxBvzjrAGdFNKuD8jUo9aV6GnCwE2sZk26V1ES7xJjaQ=g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130613/5eda2c77/attachment.pl>

From careyshan at gmail.com  Thu Jun 13 14:02:41 2013
From: careyshan at gmail.com (Shane Carey)
Date: Thu, 13 Jun 2013 13:02:41 +0100
Subject: [R] Remove levels
Message-ID: <CA+jRDxCiKLwp8z4s4cKXHjGz24SPOKVqT1x94OVBk317X5=CjA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130613/03e68302/attachment.pl>

From albin.blaschka at standortsanalyse.net  Thu Jun 13 14:11:42 2013
From: albin.blaschka at standortsanalyse.net (Albin Blaschka)
Date: Thu, 13 Jun 2013 14:11:42 +0200
Subject: [R] Remove levels
In-Reply-To: <CA+jRDxCiKLwp8z4s4cKXHjGz24SPOKVqT1x94OVBk317X5=CjA@mail.gmail.com>
References: <CA+jRDxCiKLwp8z4s4cKXHjGz24SPOKVqT1x94OVBk317X5=CjA@mail.gmail.com>
Message-ID: <51B9B6FE.5090204@standortsanalyse.net>



Am 13.06.2013 14:02, schrieb Shane Carey:
> I have a dataframe consisting of factors in one column. Im trying to remove
> certain levels using the following code:
> toBeRemoved1<-which(DATA$UnitName_1=="lake")
> DATA<-DATA[-toBeRemoved1,]
>
> However it will not remove the level "lake"

Hello!

Is this a part of the R Inferno?
See "The R Inferno" from Patrick Burns, specially Chapter 8.2.4 
"dropping factor levels ", page 83

http://www.burns-stat.com/pages/Tutor/R_inferno.pdf

HTH,
Albin


-- 
| Albin Blaschka, Mag.rer.nat.
| Etrichstrasse 26, A-5020 Salzburg
| * www.albinblaschka.info * www.thinkanimal.info *
| - It's hard to live in the mountains, hard but not hopeless!


From chrisaa at med.umich.edu  Thu Jun 13 14:46:26 2013
From: chrisaa at med.umich.edu (Andrews, Chris)
Date: Thu, 13 Jun 2013 12:46:26 +0000
Subject: [R] survreg with measurement uncertainties
In-Reply-To: <CAAF=944q7jFhBwK1mOwQKUvtwYhn8sqvyKaZrmWU2r5rkW8VoA@mail.gmail.com>
References: <mailman.25.1371031207.11759.r-help@r-project.org>
	<51B87CC4.6050800@mayo.edu>
	<CAAF=944q7jFhBwK1mOwQKUvtwYhn8sqvyKaZrmWU2r5rkW8VoA@mail.gmail.com>
Message-ID: <30411786F64EEF46856EFBA2CD917799E05486@UHEXMBSPR03.umhs.med.umich.edu>

It seems a line through the origin doesn't fit the data very well.  That may be throwing off the fitting routine.

data = c(144.53, 1687.68, 5397.91)
err = c(8.32, 471.22, 796.67)
model = c(71.60, 859.23, 1699.19)
id = c(1, 2, 3)

# display
plot(data ~ model)
library("Hmisc")
errbar(model, add=TRUE, y = data, yplus= data+err, yminus=data-err, errbar.col=2)
abline(lm(data ~ model - 1))
abline(lm(data ~ model - 1, weights = 1/err^2), col=2)

Making err[1] larger, allows convergence:

err[1] <- 80.32

survreg(Surv(time = data)~model-1+cluster(id), weights=1/(err^2), dist='gaussian', init=c(2.1))

Call:
survreg(formula = Surv(time = data) ~ model - 1 + cluster(id), 
    weights = 1/(err^2), dist = "gaussian", init = c(2.1))

Coefficients:
 model 
2.6055 

Scale= 139.299 

Loglik(model)= 0   Loglik(intercept only)= 0
n= 3


And this matches the standard linear model call:

lm(data ~ model - 1, weights = 1/err^2)

Call:
lm(formula = data ~ model - 1, weights = 1/err^2)

Coefficients:
model  
2.606  


-----Original Message-----
From: Kyle Penner [mailto:kpenner at as.arizona.edu] 
Sent: Wednesday, June 12, 2013 3:49 PM
To: Terry Therneau
Cc: r-help at r-project.org
Subject: Re: [R] survreg with measurement uncertainties

Hi Terry,

Thanks for your quick reply.  I am talking about uncertainty in the response.  I have 2 follow up questions:

1) my understanding from the documentation is that 'id' in cluster(id) should be the same when the predictors are not independent.  Is this correct?  (To be more concrete: my data are brightnesses at different wavelengths.  Each brightness is an independent measurement, so the elements of id should all be different?)

2) I tested survreg with uncertainties on an example where I already know the answer (and where I am not using limits), and it does not converge.  Below is the code I used, does anything jump out as incorrect?

data = c(144.53, 1687.68, 5397.91)
err = c(8.32, 471.22, 796.67)
model = c(71.60, 859.23, 1699.19)
id = c(1, 2, 3)

This works (2.9 is the answer from simple chi_sq fitting):

survreg(Surv(time = data, event = c(1,1,1))~model-1, dist='gaussian',
init=c(2.9))

This does not converge (2.1 is the answer from chi_sq fitting):

survreg(Surv(time = data, event = c(1,1,1))~model-1+cluster(id), weights=1/(err^2), dist='gaussian', init=c(2.1))

And this does, but the answer it returns is wonky:

data[2] = 3*err[2] # data[2] is very close to 3*err[2] already survreg(Surv(time = data, event = c(1,2,1))~model-1+cluster(id), weights=1/(err^2), dist='gaussian', init=c(2.1))

Thanks,

Kyle

On Wed, Jun 12, 2013 at 6:51 AM, Terry Therneau <therneau at mayo.edu> wrote:
> I will assume that you are talking about uncertainty in the response.  
> Then one simple way to fit the model is to use case weights that are 
> proprional to 1/variance, along with +cluster(id) in the model 
> statement to get a correct variance for this case.  In linear models 
> this would be called the "White" or "Horvitz-Thompsen" or "GEE working 
> independence" variance estimate, depending on which literature you 
> happen to be reading (economics, survey sampling, or biostat).
>
> Now if you are talking about errors in the predictor variables, that 
> is a much harder problem.
>
> Terry Therneau
>
>
>
> On 06/12/2013 05:00 AM, Kyle Penner wrote:
>>
>> Hello,
>>
>> I have some measurements that I am trying to fit a model to.  I also 
>> have uncertainties for these measurements.  Some of the measurements 
>> are not well detected, so I'd like to use a limit instead of the 
>> actual measurement.  (I am always dealing with upper limits, i.e. 
>> left censored data.)
>>
>> I have successfully run survreg using the combination of well 
>> detected measurements and limits, but I would like to include the 
>> measurement uncertainty (for the well detected measurements) in the 
>> fitting.  As far as I can tell, survreg doesn't support this.  Does 
>> anyone have a suggestion for how to accomplish this?
>>
>> Thanks,
>>
>> Kyle


**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues 

From careyshan at gmail.com  Thu Jun 13 14:54:24 2013
From: careyshan at gmail.com (Shane Carey)
Date: Thu, 13 Jun 2013 13:54:24 +0100
Subject: [R] Remove levels
In-Reply-To: <51B9B6FE.5090204@standortsanalyse.net>
References: <CA+jRDxCiKLwp8z4s4cKXHjGz24SPOKVqT1x94OVBk317X5=CjA@mail.gmail.com>
	<51B9B6FE.5090204@standortsanalyse.net>
Message-ID: <CA+jRDxAzM4+fzvqQzPV142J8Trt4WLFiuGuPMRJr8Ro_kTH1Lw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130613/f6ac2c1c/attachment.pl>

From smartpink111 at yahoo.com  Thu Jun 13 15:40:43 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 13 Jun 2013 06:40:43 -0700 (PDT)
Subject: [R] find the position of first observation for each subject
In-Reply-To: <CAKO0DpgCM=scU+G6sJS+wB0qdmtvwaDz5ngQ_KV__UnMtaR-Bw@mail.gmail.com>
References: <CAKO0DpgCM=scU+G6sJS+wB0qdmtvwaDz5ngQ_KV__UnMtaR-Bw@mail.gmail.com>
Message-ID: <1371130843.93748.YahooMailNeo@web142602.mail.bf1.yahoo.com>

HI,
Try this:
ds1<- data.frame(id,time)
which(with(ds1,ave(time,id,FUN=seq))==1)
#[1] 1 4 9
A.K.



----- Original Message -----
From: Gallon Li <gallon.li at gmail.com>
To: R-help at r-project.org
Cc: 
Sent: Thursday, June 13, 2013 3:56 AM
Subject: [R] find the position of first observation for each subject

suppose I have the following data

id=c(rep(1,3),rep(2,5),rep(3,4))
time=c(seq(1,3),seq(2,6),seq(1,4))

ds=cbind(id,time)

> ds
? ? ? id time
[1,]? 1? ? 1
[2,]? 1? ? 2
[3,]? 1? ? 3
[4,]? 2? ? 2
[5,]? 2? ? 3
[6,]? 2? ? 4
[7,]? 2? ? 5
[8,]? 2? ? 6
[9,]? 3? ? 1
[10,]? 3? ? 2
[11,]? 3? ? 3
[12,]? 3? ? 4

i want to return a vector that indicates the position of the first
observation for each id. for the above data, i wish to get (1,4,9).

is it possible to get this quickly>?

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jdnewmil at dcn.davis.CA.us  Thu Jun 13 15:55:57 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 13 Jun 2013 07:55:57 -0600
Subject: [R] Remove levels
In-Reply-To: <CA+jRDxAzM4+fzvqQzPV142J8Trt4WLFiuGuPMRJr8Ro_kTH1Lw@mail.gmail.com>
References: <CA+jRDxCiKLwp8z4s4cKXHjGz24SPOKVqT1x94OVBk317X5=CjA@mail.gmail.com>
	<51B9B6FE.5090204@standortsanalyse.net>
	<CA+jRDxAzM4+fzvqQzPV142J8Trt4WLFiuGuPMRJr8Ro_kTH1Lw@mail.gmail.com>
Message-ID: <fe732063-b137-4720-921a-1c1e6ea5cce7@email.android.com>

Please read the Posting Guide, which among other things points out that you should be posting in plain text format, not HTML (which tends to corrupt example R code).

Then please explain why your problem is not addressed by the below referenced section of the R Inferno. You may need to read [1] for advice on providing a reproducible example per the Posting Guide so we can follow your argument clearly.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Shane Carey <careyshan at gmail.com> wrote:

>Nope, but thanks
>
>
>On Thu, Jun 13, 2013 at 1:11 PM, Albin Blaschka <
>albin.blaschka at standortsanalyse.net> wrote:
>
>>
>>
>> Am 13.06.2013 14:02, schrieb Shane Carey:
>>
>>  I have a dataframe consisting of factors in one column. Im trying to
>>> remove
>>> certain levels using the following code:
>>> toBeRemoved1<-which(DATA$**UnitName_1=="lake")
>>> DATA<-DATA[-toBeRemoved1,]
>>>
>>> However it will not remove the level "lake"
>>>
>>
>> Hello!
>>
>> Is this a part of the R Inferno?
>> See "The R Inferno" from Patrick Burns, specially Chapter 8.2.4
>"dropping
>> factor levels ", page 83
>>
>>
>http://www.burns-stat.com/**pages/Tutor/R_inferno.pdf<http://www.burns-stat.com/pages/Tutor/R_inferno.pdf>
>>
>> HTH,
>> Albin
>>
>>
>> --
>> | Albin Blaschka, Mag.rer.nat.
>> | Etrichstrasse 26, A-5020 Salzburg
>> | * www.albinblaschka.info * www.thinkanimal.info *
>> | - It's hard to live in the mountains, hard but not hopeless!
>>
>> ______________________________**________________
>> R-help at r-project.org mailing list
>>
>https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/**
>> posting-guide.html <http://www.R-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>>


From dcarlson at tamu.edu  Thu Jun 13 16:00:28 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Thu, 13 Jun 2013 09:00:28 -0500
Subject: [R] Remove levels
In-Reply-To: <CA+jRDxCiKLwp8z4s4cKXHjGz24SPOKVqT1x94OVBk317X5=CjA@mail.gmail.com>
References: <CA+jRDxCiKLwp8z4s4cKXHjGz24SPOKVqT1x94OVBk317X5=CjA@mail.gmail.com>
Message-ID: <033201ce683e$5c5e5470$151afd50$@tamu.edu>

Works fine for me. Too bad you didn't include actual data:

> set.seed(42)
> DATA <- data.frame(UnitName_1=factor(sample(c("lake", "pond",
"river"),
+         15, replace=TRUE)), Var=sample.int(100, 15))
> DATA
   UnitName_1 Var
1       river  95
2       river  97
3        lake  12
4       river  47
5        pond  54
6        pond  86
7       river  14
8        lake  92
9        pond  88
10      river   8
11       pond  99
12      river  35
13      river  80
14       lake  39
15       pond  72
> toBeRemoved1 <- which(DATA$UnitName_1=="lake")
> toBeRemoved1
[1]  3  8 14
> DATA <- DATA[-toBeRemoved1,]
> DATA
   UnitName_1 Var
1       river  95
2       river  97
4       river  47
5        pond  54
6        pond  86
7       river  14
9        pond  88
10      river   8
11       pond  99
12      river  35
13      river  80
15       pond  72

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Shane Carey
Sent: Thursday, June 13, 2013 7:03 AM
To: r-help at r-project.org
Subject: [R] Remove levels

I have a dataframe consisting of factors in one column. Im trying to
remove
certain levels using the following code:
toBeRemoved1<-which(DATA$UnitName_1=="lake")
DATA<-DATA[-toBeRemoved1,]

However it will not remove the level "lake"

In the past this worked for me, but its not working now. Any help
appreciated.

Thanks

-- 
Shane

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From alain.guillet at uclouvain.be  Thu Jun 13 16:02:58 2013
From: alain.guillet at uclouvain.be (Alain Guillet)
Date: Thu, 13 Jun 2013 16:02:58 +0200
Subject: [R] Remove levels
In-Reply-To: <CA+jRDxCiKLwp8z4s4cKXHjGz24SPOKVqT1x94OVBk317X5=CjA@mail.gmail.com>
References: <CA+jRDxCiKLwp8z4s4cKXHjGz24SPOKVqT1x94OVBk317X5=CjA@mail.gmail.com>
Message-ID: <51B9D112.50407@uclouvain.be>

Hi,

Without more information I guess your problem is that the level name
still exists in the factor whereas it doesn't appear anymore in the
factor. If so, try droplevels.
 

Alain Guillet


On 13/06/13 14:02, Shane Carey wrote:
> I have a dataframe consisting of factors in one column. Im trying to remove
> certain levels using the following code:
> toBeRemoved1<-which(DATA$UnitName_1=="lake")
> DATA<-DATA[-toBeRemoved1,]
>
> However it will not remove the level "lake"
>
> In the past this worked for me, but its not working now. Any help
> appreciated.
>
> Thanks
>

-- 
Alain Guillet
Statistician and Computer Scientist

SMCS - IMMAQ - Universit? catholique de Louvain
http://www.uclouvain.be/smcs

Bureau c.316
Voie du Roman Pays, 20 (bte L1.04.01)
B-1348 Louvain-la-Neuve
Belgium

tel: +32 10 47 30 50

Acc?s: http://www.uclouvain.be/323631.html


From mackay at northnet.com.au  Thu Jun 13 16:04:34 2013
From: mackay at northnet.com.au (Duncan Mackay)
Date: Fri, 14 Jun 2013 00:04:34 +1000
Subject: [R] Lattice different colours for bars
In-Reply-To: <D9C742F3-0C0B-4D82-B1FB-C461EED918A1@comcast.net>
References: <848DE0191A1C1D49BAEF06A404C5609D3CC7E9@wdcwmsp58.network.maf.govt.nz>
	<D9C742F3-0C0B-4D82-B1FB-C461EED918A1@comcast.net>
Message-ID: <201306131404.r5DE4adU021953@mail15.tpg.com.au>

Hi

The example contained errors in the line with cast and it is too late to check

without a reproducible example i am only guessing

perhaps add a groups argument and supply a col argument to superpose polygon eg

groups = Ikeda,
par.settings = list(superpose.polygon = list(col = 12 colours to suit)),

colur order to match levels of Ikeda

Regards

Duncan


Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au



At 16:47 13/06/2013, you wrote:

>On Jun 12, 2013, at 6:43 PM, Andrew McFadden (Andy) wrote:
>
> > Hi all
> >
> > Perhaps this is torturous methodology. I was trying to use 
> lattice to produce a barchart showing the number positive and 
> negative over time. I wasn't quite sure how create a different 
> colour for values of arbo$Ikeda in the example below ie red for 
> ikeda and green for neg.
> >
> >
> > library(reshape)
> > library(lattice)
> >
> > Time=c(rep(6,17), rep(5,17), rep(4,17),
> >       rep(3,17),rep(2,17), rep(1,17))
> > Ikeda=c(rep("Ikeda",6),rep("Neg",11),
> >        rep("Ikeda",0),rep("Neg",17),
> >        rep("Ikeda",1),rep("Neg",16),
> >        rep("Ikeda",0),rep("Neg",17),
> >        rep("Ikeda",0),rep("Neg",17),
> >        rep("Ikeda",0),rep("Neg",17))
> > Theileria=c(rep("Other",6),rep("Neg",11),
> >         rep("Other",12),rep("Neg",5),
> >         rep("Other",12),rep("Neg",5),
> >         rep("Other",14),rep("Neg",3),
> >         rep("Other",14),rep("Neg",3),
> >         rep("Other",13),rep("Neg",4))
> > value=c(rep(1,102))
> > arbo=data.frame(Time, Ikeda,Theileria,value)
> >
> > arbo$Time=as.factor(arbo$Time)
> > levels(arbo$Time)
> >
> > arbo$Time=factor(arbo$Time,
> >                    levels=c(1,2,3,4,5,6),
> >                    labels=c("Dec 2008", "Dec 2009", "Dec 2010",
> >                             "Dec 2011", "Jun 2012", "Dec 2012")
> > )
> >
> > mdat=melt(arbo,measure.var=c(4),id.var=c(1:3),na.rm=FALSE)
> > mdat=cast(mdat,Time +Ikeda~variable,fun.aggregate = c(sum))
>
>barchart(value~Ikeda|Time, data = mdat,
>        type="count",
>              col=c("green","red")[1+(mdat$Ikeda=="Ikeda")],
>        cex=1.1,
>        xlab="PCR positive over time",
>        aspect = c(1.5),layout = c(6, 1),
>        stack=FALSE,
>        strip=strip.custom(strip.names=FALSE, strip.levels=TRUE, 
> bg="light blue"),
>        par.strip.text=list(cex=1.1), scales=list(cex=c(1.1)))
>Any suggestions on how to do this would be appreciated.
>
> >
> > Regards
> >
> > Andrew
> >
> > Investigation and Diagnostic Centre- Upper Hutt
> >
>--
>David Winsemius
>Alameda, CA, USA
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Thu Jun 13 16:07:42 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 13 Jun 2013 07:07:42 -0700 (PDT)
Subject: [R] Remove levels
In-Reply-To: <033201ce683e$5c5e5470$151afd50$@tamu.edu>
References: <CA+jRDxCiKLwp8z4s4cKXHjGz24SPOKVqT1x94OVBk317X5=CjA@mail.gmail.com>
	<033201ce683e$5c5e5470$151afd50$@tamu.edu>
Message-ID: <1371132462.16952.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Not sure if the OP is concerned about this:
Using David's data

?str(DATA)
#'data.frame':??? 15 obs. of? 2 variables:
# $ UnitName_1: Factor w/ 3 levels "lake","pond",..: 3 3 1 3 2 2 3 1 2 3 ...
?#$ Var?????? : int? 95 97 12 47 54 86 14 92 88 8 ...
?toBeRemoved1 <- which(DATA$UnitName_1=="lake")
?DATA <- DATA[-toBeRemoved1,]
?str(DATA)
#'data.frame':??? 12 obs. of? 2 variables:
# $ UnitName_1: Factor w/ 3 levels "lake","pond",..: 3 3 3 2 2 3 2 3 2 3 ...
# $ Var?????? : int? 95 97 47 54 86 14 88 8 99 35 ...
?levels(DATA[,1])
#[1] "lake"? "pond"? "river" ############
?DATA[,1]<- factor(DATA[,1])
?str(DATA)
#'data.frame':??? 12 obs. of? 2 variables:
# $ UnitName_1: Factor w/ 2 levels "pond","river": 2 2 2 1 1 2 1 2 1 2 ...
# $ Var?????? : int? 95 97 47 54 86 14 88 8 99 35 ...
?levels(DATA[,1])
#[1] "pond"? "river"


A.K.



----- Original Message -----
From: David Carlson <dcarlson at tamu.edu>
To: 'Shane Carey' <careyshan at gmail.com>; r-help at r-project.org
Cc: 
Sent: Thursday, June 13, 2013 10:00 AM
Subject: Re: [R] Remove levels

Works fine for me. Too bad you didn't include actual data:

> set.seed(42)
> DATA <- data.frame(UnitName_1=factor(sample(c("lake", "pond",
"river"),
+? ? ? ?  15, replace=TRUE)), Var=sample.int(100, 15))
> DATA
?  UnitName_1 Var
1? ? ?  river? 95
2? ? ?  river? 97
3? ? ? ? lake? 12
4? ? ?  river? 47
5? ? ? ? pond? 54
6? ? ? ? pond? 86
7? ? ?  river? 14
8? ? ? ? lake? 92
9? ? ? ? pond? 88
10? ? ? river?  8
11? ? ?  pond? 99
12? ? ? river? 35
13? ? ? river? 80
14? ? ?  lake? 39
15? ? ?  pond? 72
> toBeRemoved1 <- which(DATA$UnitName_1=="lake")
> toBeRemoved1
[1]? 3? 8 14
> DATA <- DATA[-toBeRemoved1,]
> DATA
?  UnitName_1 Var
1? ? ?  river? 95
2? ? ?  river? 97
4? ? ?  river? 47
5? ? ? ? pond? 54
6? ? ? ? pond? 86
7? ? ?  river? 14
9? ? ? ? pond? 88
10? ? ? river?  8
11? ? ?  pond? 99
12? ? ? river? 35
13? ? ? river? 80
15? ? ?  pond? 72

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Shane Carey
Sent: Thursday, June 13, 2013 7:03 AM
To: r-help at r-project.org
Subject: [R] Remove levels

I have a dataframe consisting of factors in one column. Im trying to
remove
certain levels using the following code:
toBeRemoved1<-which(DATA$UnitName_1=="lake")
DATA<-DATA[-toBeRemoved1,]

However it will not remove the level "lake"

In the past this worked for me, but its not working now. Any help
appreciated.

Thanks

-- 
Shane

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From dcarlson at tamu.edu  Thu Jun 13 16:14:38 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Thu, 13 Jun 2013 09:14:38 -0500
Subject: [R] Remove levels
In-Reply-To: <033201ce683e$5c5e5470$151afd50$@tamu.edu>
References: <CA+jRDxCiKLwp8z4s4cKXHjGz24SPOKVqT1x94OVBk317X5=CjA@mail.gmail.com>
	<033201ce683e$5c5e5470$151afd50$@tamu.edu>
Message-ID: <033901ce6840$56bdad70$04390850$@tamu.edu>

If you've read the R Inferno section, you already know that
following my example with

> levels(DATA$UnitName_1)
[1] "lake"  "pond"  "river"
> DATA$UnitName_1 <- factor(DATA$UnitName_1)
> levels(DATA$UnitName_1)
[1] "pond"  "river"

removes the empty factor level.

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of David Carlson
Sent: Thursday, June 13, 2013 9:00 AM
To: 'Shane Carey'; r-help at r-project.org
Subject: Re: [R] Remove levels

Works fine for me. Too bad you didn't include actual data:

> set.seed(42)
> DATA <- data.frame(UnitName_1=factor(sample(c("lake", "pond",
"river"),
+         15, replace=TRUE)), Var=sample.int(100, 15))
> DATA
   UnitName_1 Var
1       river  95
2       river  97
3        lake  12
4       river  47
5        pond  54
6        pond  86
7       river  14
8        lake  92
9        pond  88
10      river   8
11       pond  99
12      river  35
13      river  80
14       lake  39
15       pond  72
> toBeRemoved1 <- which(DATA$UnitName_1=="lake")
> toBeRemoved1
[1]  3  8 14
> DATA <- DATA[-toBeRemoved1,]
> DATA
   UnitName_1 Var
1       river  95
2       river  97
4       river  47
5        pond  54
6        pond  86
7       river  14
9        pond  88
10      river   8
11       pond  99
12      river  35
13      river  80
15       pond  72

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Shane Carey
Sent: Thursday, June 13, 2013 7:03 AM
To: r-help at r-project.org
Subject: [R] Remove levels

I have a dataframe consisting of factors in one column. Im trying to
remove
certain levels using the following code:
toBeRemoved1<-which(DATA$UnitName_1=="lake")
DATA<-DATA[-toBeRemoved1,]

However it will not remove the level "lake"

In the past this worked for me, but its not working now. Any help
appreciated.

Thanks

-- 
Shane

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Thu Jun 13 16:30:35 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 13 Jun 2013 07:30:35 -0700 (PDT)
Subject: [R] find the position of first observation for each subject
In-Reply-To: <1371130843.93748.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <CAKO0DpgCM=scU+G6sJS+wB0qdmtvwaDz5ngQ_KV__UnMtaR-Bw@mail.gmail.com>
	<1371130843.93748.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1371133835.22570.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Also, if the ids are ordered and numeric:

which(c(1,diff(ds[,1]))>0)
#[1] 1 4 9
A.K.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Gallon Li <gallon.li at gmail.com>
Cc: R help <r-help at r-project.org>
Sent: Thursday, June 13, 2013 9:40 AM
Subject: Re: [R] find the position of first observation for each subject

HI,
Try this:
ds1<- data.frame(id,time)
which(with(ds1,ave(time,id,FUN=seq))==1)
#[1] 1 4 9
A.K.



----- Original Message -----
From: Gallon Li <gallon.li at gmail.com>
To: R-help at r-project.org
Cc: 
Sent: Thursday, June 13, 2013 3:56 AM
Subject: [R] find the position of first observation for each subject

suppose I have the following data

id=c(rep(1,3),rep(2,5),rep(3,4))
time=c(seq(1,3),seq(2,6),seq(1,4))

ds=cbind(id,time)

> ds
? ? ? id time
[1,]? 1? ? 1
[2,]? 1? ? 2
[3,]? 1? ? 3
[4,]? 2? ? 2
[5,]? 2? ? 3
[6,]? 2? ? 4
[7,]? 2? ? 5
[8,]? 2? ? 6
[9,]? 3? ? 1
[10,]? 3? ? 2
[11,]? 3? ? 3
[12,]? 3? ? 4

i want to return a vector that indicates the position of the first
observation for each id. for the above data, i wish to get (1,4,9).

is it possible to get this quickly>?

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ccampbell at mango-solutions.com  Thu Jun 13 16:41:05 2013
From: ccampbell at mango-solutions.com (Chris Campbell)
Date: Thu, 13 Jun 2013 14:41:05 +0000
Subject: [R] How to fit the cumulative probability distributive
 functiion with the gamma distribution?
In-Reply-To: <9879AF1F439EF943BDEE22D3AAA5C3F683FBED51@sdsu-ex01.jacks.local>
References: <9879AF1F439EF943BDEE22D3AAA5C3F683FBED51@sdsu-ex01.jacks.local>
Message-ID: <2C2DB2ABEE65DB40B7946E54C71A8C0942F40C65@mexchange.Mango.local>

val_w_time <- data.frame(time = 1:12,    
    val = c(24,7,4,1,2,1,0,0,0,1,0,0))    
    
fitdistr(val_w_time$val,"gamma")     
# Error in optim(x = c(24, 7, 4, 1, 2, 1, 0, 0, 0, 1, 0, 0), par = list( :      
#   initial value in 'vmmin' is not finite    
    
# this error message doesn't necessarily mean that it    
# won't fit the distribution; just that it can't.   
    
# fitdistr is usually used to fit data to a distribution,     
# rather than data representing the shape of a distribution     
# to that distribution.    
    
  
plot(val_w_time)     
    
g1 <- nls(histd ~ dgamma(time/12, shape = gamma, rate = theta), data = val_w_time,     
    start = list(gamma = 0.5, theta = 4),     
    trace = TRUE)    
# 495.188 :  0.5 4.0    
# 250.5561 :   5.943122 54.029829    
# 241.5951 :  11.20099 98.36401    
# Error in numericDeriv(form[[3L]], names(ind), env) :     
#   Missing value or an infinity produced when evaluating the model    
# In addition: Warning message:    
# In dgamma(time/12, shape = gamma, rate = theta) : NaNs produced    
    
# okay, so we don't get convergence with nls    
    
lines(val_w_time$time,     
    dgamma((1:12)/12, shape = 11.20099, rate = 98.36401), col = "grey", lwd = 2)    
    
# but we're basically fitting to 3 data points    
    
# but we can mess around with the x axis    
    
g2 <- nls(histd ~ dgamma((time/12)^2, shape = gamma, rate = theta), data = val_w_time,     
    start = list(gamma = 0.5, theta = 4),     
    trace = TRUE)    
    
with(val_w_time, lines(time,     
    predict(g2), col = "red", lwd = 2))    
    
# so that the distribution looks more like the data    
    
http://i1277.photobucket.com/albums/y496/CSJCampbell/armel_data_gamma_zpsbb0146ee.png
    
# hopefully this gives you some ideas    
     

Chris Campbell, PhD    
Tel. +44 (0) 1249 705 450?| Mobile. +44 (0) 7929 628349    
mailto:ccampbell at mango-solutions.com?| http://www.mango-solutions.com    
Mango Solutions, 2 Methuen Park,  Chippenham, Wiltshire , SN14 OGB UK    

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Kaptue Tchuente, Armel
Sent: 12 June 2013 20:22
To: r-help at r-project.org
Subject: [R] How to fit the cumulative probability distributive functiion with the gamma distribution?

Hello everyone,



I'm trying to fit the PDF of time series datasets with the gamma distribution.

Nonetheless, this isn't possible for several datasets since the gamma distribution can only been used to fit continuous distribution. For instance, gam<-fitdrib(hist<-c(24,7,4,1,2,1,0,0,0,1,0,0),"gamma") will yield an error message.

To solve this issue, I decided to fit the cumulative distributive function i.e. gam<-fitdistr(hist_cum<-c(24,31,35,36,38,39,39,39,40,40,40)).

Now I don't know how to obtain the corresponding CDF of the gamma distribution which will fit the empirical CDF.

I have already tried some instructions like pgamma(seq(4,4*12,4), scale=1/gam$estimate[2],shape=gam$estimate[1]) without success as you can see on this picture https://docs.google.com/file/d/0BwjZP-sfazLMaDM2bHBDYnFOSWs/edit?usp=sharing where the curve in blue was supposed to be the fitted gamma CDF.

I said "was supposed" because I was obliged to use the instruction par(new=T) in order to super-impose the fitted gamma CDF



Cheers



Armel


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

--

LEGAL NOTICE\ \ This message is intended for the use of ...{{dropped:18}}


From derek at soylentgeek.com  Thu Jun 13 16:18:42 2013
From: derek at soylentgeek.com (Derek Serianni)
Date: Thu, 13 Jun 2013 10:18:42 -0400
Subject: [R] Need help with installing gplots
In-Reply-To: <51B9729F.1020107@stats.ox.ac.uk>
References: <CAHgGd1VoX0Mb2-0ZCQ-YTaBrQLNpwyVgXBJwAVoQpA5xuMF8hw@mail.gmail.com>
	<51B9729F.1020107@stats.ox.ac.uk>
Message-ID: <CAHgGd1VqdDPSgc_epf7HPZ_86BwhbqhY_Si8QwqsN4JXXqvZXA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130613/e7c7753c/attachment.pl>

From bcrombie at utk.edu  Thu Jun 13 14:28:39 2013
From: bcrombie at utk.edu (bcrombie)
Date: Thu, 13 Jun 2013 05:28:39 -0700 (PDT)
Subject: [R] rewrite script to eliminate constant object reference
In-Reply-To: <CA+vqiLGgpknFETo_VSkMnuHJ+KR8-VV8SZxbSPgfeb3wcn1jSQ@mail.gmail.com>
References: <1371069398996-4669393.post@n4.nabble.com>
	<CA+vqiLGgpknFETo_VSkMnuHJ+KR8-VV8SZxbSPgfeb3wcn1jSQ@mail.gmail.com>
Message-ID: <559C998F7039D84C9793AE43D9BBE9CE77A0F8D5@kmbx3.utk.tennessee.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130613/372cefa8/attachment.pl>

From smartpink111 at yahoo.com  Thu Jun 13 15:22:31 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 13 Jun 2013 06:22:31 -0700 (PDT)
Subject: [R] Search for Matching word in a Dataframe
In-Reply-To: <1371107334367-4669426.post@n4.nabble.com>
References: <1371107334367-4669426.post@n4.nabble.com>
Message-ID: <1371129751.24010.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
You could use:
?grep
grep("ARUN",MyDat[,1])
#[1] 2
#or
library(stringr)
?which(!is.na(str_match(MyDat[,1],"ARUN")))
#[1] 2
?vec1<-c(MyDat[,1],"ARUN003","Arun")
?which(!is.na(str_match(toupper(vec1),"ARUN")))
#[1]? 2 10 11
A.K.




----- Original Message -----
From: R_Antony <antony.akkara at ge.com>
To: r-help at r-project.org
Cc: 
Sent: Thursday, June 13, 2013 3:08 AM
Subject: [R] Search for Matching word in a Dataframe

Hi

Here i have a dataframe called MyDat.

MyDat<- data.frame(NAME = c("ANTONY001", "ARUN002", "AKBAR003", 
"JONATHAN004", "PETER005", "AVATAR006", "YULIJIE007", "RAM008", 
"DESILVA009"), 
COL_A = c(0, 0, 0, 1, 0, 1, 2, 3, 1), 
COL_B = c(0, 3, 0, 3, 3, 1, 0, 1, 2), 
COL_C = c(1, 2, 3, 1, 2, 3, 1, 2, 3), stringsAsFactors=FALSE) 

and here my requirement what is, i need to get the row number, where the
NAME column matches with selection criteria.

For eg:- If i give NAME = "ARUN", It should select row no: 2 where 
"ARUN002" comes.

i tried with this way 
nRow<-which("ARUN"==MyDat[,1]) - But here, the row number will select only
the NAME column value match exactly, otherwise it wont select.

My requirment is, it should select the row number(s), where the searching
word should match atleast. Exact match is not compulsory.



- Thanks in Advance.
Antony.



--
View this message in context: http://r.789695.n4.nabble.com/Search-for-Matching-word-in-a-Dataframe-tp4669426.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From htl10 at users.sourceforge.net  Thu Jun 13 16:40:13 2013
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Thu, 13 Jun 2013 15:40:13 +0100 (BST)
Subject: [R] new window cairo bundle Re: [Rd] R/Sweave/cairo/freetype
	bug fix.
In-Reply-To: <1364911302.48242.YahooMailClassic@web172304.mail.ir2.yahoo.com>
Message-ID: <1371134413.44971.YahooMailClassic@web172306.mail.ir2.yahoo.com>

Freetype 2.4.12 was released in early May. Just so that we are clear that this is a freetype bug which affects R's use of Cairo (among other things). So there are updated bundles, and also bundles for Mac OS X as well, for both a patched 2.4.11 and 2.4.12 proper. The accompanying *.txt has a listing of versions.

http://sourceforge.net/projects/outmodedbonsai/files/R/

Unix users should just upgrade. I'll get round to build R 2.15.3 (or 2.15.x) for windows and Mac OS X at some stage, but if somebody want to beat me to it, please feel free to do so.

--- On Tue, 2/4/13, Hin-Tak Leung <htl10 at users.sourceforge.net> wrote:

> --- On Mon, 1/4/13, Hin-Tak Leung
> <htl10 at users.sourceforge.net>
> wrote:
> > --- On Sat, 30/3/13, Hin-Tak Leung
> > <htl10 at users.sourceforge.net>
> > wrote:
> > 
> > > "... was committed to freetype in January and will
> form
> > the
> > > next release (2.4.12)". 
> > 
> > It is perhaps worth repeating the quote:? 'The
> official
> > R binaries for windows ... are compiled against static
> > libraries of cairo 1.10.2 ... are firmly in the "do not
> work
> > correctly" category'
> > 
> > The minimum version of cairo to work being 1.11.2. On
> closer
> > examination, the official bundle (http://www.rforge.net/Cairo/files/cairo-current-win.tar.gz)
> > is built with neither fontconfig nor freetype. So even
> if it
> > is bumped to current version (1.12.x), it does not
> work
> > correctly.
> 
> Here is a drop-in replacement for the above:
> http://sourceforge.net/projects/outmodedbonsai/files/R/cairo-1.12.14%2Bft%2Bfc-win.tar.gz
> 
> Besides being over 2 years more up-to-date, cairo (1.12.14)
> is also built with fontconfig and freetype enabled, and
> freetype being 2.4.11 + back-ported patch (https://bugzilla.redhat.com/show_bug.cgi?id=891457#c35)
> so at least there is a a better chance of R working
> correctly.
> 
> The full list of the tar ball is (a superset of the above,
> due to addition of fontconfig and freetype and their
> dependencies):
> -------
> cairo-1.12.14
> pixman-0.26.2
> libpng-1.5.13
> zlib-1.2.7
> fontconfig-2.10.1
> freetype-2.4.11 (patched)
> glib2-2.34.3
> expat-2.1.0
> bzip2-1.0.6
> libffi-3.0.11
> gettext-0.18.2
> ---------
> This allows the C-based cairo bug demo (#c10) to build so I
> am sure it is sufficient for building windows R. At some
> stage I'll rebuild a less-buggy R 2.15.3 for windows, but
> not for a few weeks so if somebody wants to beat me to it,
> please feel free to do so.
> 
> > Perhaps also wasn't clear in the bugzilla thread -
> everybody
> > from fontconfig/cairo/freetype involved knew it being
> the
> > issue so it has never been explicitly spelled out -
> the
> > problem was (is) with cairo's pdf/ps generation, aided
> by
> > freetype.
> > 
> > > ------------------------------
> > > On Sat, Mar 30, 2013 18:54 GMT Simon Urbanek
> wrote:
> > > 
> > > >On Mar 30, 2013, at 9:24 AM, Hin-Tak Leung
> wrote:
> > > >
> > > >> Perhaps that's too much details. There
> is
> > (will be)
> > > a new freetype because of cairo's unanticipated
> usage
> > (which
> > > R uses, among other cairo users). Most people
> should
> > upgrade
> > > or request an upgrade eventually, when they are
> > > comfortable.
> > > >> 
> > > >
> > > >Which versions are affected? R binary for OS
> X
> > uses
> > > freetype 2.4.11 (and cairo 1.12.14) so I just need
> to
> > know
> > > if there is an action item.
> > > >
> > > >Thanks,
> > > >SImon
> > > >
> > > >
> > > >
> > > >> --- On Sat, 30/3/13, peter dalgaard
> <pdalgd at gmail.com>
> > > wrote:
> > > >> 
> > > >> Huh?
> > > >> 
> > > >> This is utterly incomprehensible without
> > reading
> > > the redhat
> > > >> bugzilla, and even after reading, I'm not
> sure
> > what
> > > the
> > > >> issue is. Something with bold Chinese
> fonts in
> > X11,
> > > but
> > > >> maybe also affecting Latin fonts, ....?
> > > >> 
> > > >> Please explain yourself.
> > > >> 
> > > >> -pd
> > > >> 
> > > >> On Mar 30, 2013, at 09:25 , Hin-Tak
> Leung
> > wrote:
> > > >> 
> > > >>> The problem was first seen with
> R/Sweave
> > (#c0)
> > > then
> > > >> reproduced directly with cairo (#c10) and
> was
> > > eventually
> > > >> traced to freetype. The 5-part bug fix:
> > > >>>
> 610ee58e07090ead529849b2a454bb6c503b4995
> > > >>>
> da11e5e7647b668dee46fd0418ea5ecbc33ae3b2
> > > >>>
> e1a2ac1900f2f16ec48fb4840a6b7965a8373c2b
> > > >>>
> 869fb8c49ddf292d6daf4826172a308973d3e11f
> > > >>>
> d56e544d653b09c657911629557ffc5277a503e3
> > > >>> was committed to freetype in January
> and
> > will
> > > form the
> > > >> next release (2.4.12). They were back
> ported
> > to
> > > 2.4.11
> > > >>> https://bugzilla.redhat.com/show_bug.cgi?id=891457#c35
> > > >>> and the redhat people had further
> > back-ported
> > > it to
> > > >> 2.4.10 for fedora 18/19 (#c51).
> > > >>> 
> > > >>> The freetype people had reproduced
> the
> > problem
> > > with a
> > > >> latin font, so this affects most people,
> > unlike
> > > what the
> > > >> initial report (#c0) suggests.
> > > >>> 
> > > >>> Since freetype is part of X11, most
> > unix/linux
> > > users
> > > >> would be understandably nervous about
> breaking
> > X
> > > (see #c45
> > > >> for screenshot of broken gnome terminal!)
> and
> > > should wait up
> > > >> to a year before the new and
> not-yet-released
> > > 2.4.12 becomes
> > > >> an official upgrade; or contact their
> > favourite
> > > unix vendors
> > > >> and/or Apple for upgrades. AFAIK,
> current
> > > up-to-date linux
> > > >> distributions ships the rather older
> 2.4.10,
> > with
> > > the
> > > >> exception of fedora 18/19 (#c51). Mac OS
> X
> > 10.5
> > > ships
> > > >> freetype 2.3.5 as part of X11; I haven't
> > bother
> > > looking up
> > > >> later Mac OS X's.
> > > >>> 
> > > >>> The official R binaries for windows
> and
> > mac OS
> > > X are
> > > >> compiled against static libraries of
> cairo
> > 1.10.2
> > > (over 2
> > > >> years old), and cairo 1.11.2 and
> freetype
> > 2.4.4
> > > >> respectively, and are firmly in the "do
> not
> > work
> > > correctly"
> > > >> category.
> > > >>> 
> > > >>> The long and short of the story is
> that
> > > R/Sweave uses a
> > > >> feature of cairo which wasn't
> implemented
> > before
> > > cairo
> > > >> 1.11.2 (#c13, Jan 2011), which in turn
> depends
> > on a
> > > feature
> > > >> of freetype that has been around since
> 2005
> > but did
> > > not
> > > >> anticipate cairo's usage. It is
> commendable
> > that
> > > the
> > > >> freetype people did not refer to cairo's
> usage
> > as
> > > "misuse"
> > > >> but took the patience to address the
> problem,
> > > unlike some
> > > >> group's style.
> > > >>> 
> > > >>> It has been an interesting few
> months
> > returning
> > > to
> > > >> freetype after about 17 years, I think.
> > > >>> 
> > > >>> Here is how to look up what version
> of
> > freetype
> > > -
> > > >> libfreetype.so.x.y.z for most unix
> platforms,
> > and
> > > >> /usr/X11/lib/libfreetype.x.y.z.dylib on
> Mac OS
> > X:
> > > >>> 
> > > >>> (excerpt from docs/VERSION.DLL)
> > > >>> 
> > > >>>? ? ? version???
> > > >> x.y.z???date of release
> > > >>>? ? ? 2.4.11 
> > > >>? ? 6.10.0? Dec 2012
> > > >>>? ? ? 2.4.10 
> > > >>? ? 6.9.0???June 2012
> > > >>>? ? ? 2.4.9?
> > > ???
> > > >> 6.8.1???March 2012
> > > >>> ...
> > > >>>? ? ? 2.4.4?
> > > ???
> > > >> 6.6.2???Nov 2010? (official R
> > > mac
> > > >> binaries)
> > > >>> ...
> > > >>>? ? ? 2.3.5?
> > > ???
> > > >> 6.3.16? July 2007 (Mac OS X 10.5)
> > > >>> 
> > > >>> 
> > > >>>
> > ______________________________________________
> > > >>> R-devel at r-project.org
> > > >> mailing list
> > > >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> > > >> 
> > > >> -- 
> > > >> Peter Dalgaard, Professor,
> > > >> Center for Statistics, Copenhagen
> Business
> > School
> > > >> Solbjerg Plads 3, 2000 Frederiksberg,
> Denmark
> > > >> Phone: (+45)38153501
> > > >> Email: pd.mes at cbs.dk 
> > > >> Priv: PDalgd at gmail.com
> > > >> 
> > > >> 
> > > >> 
> > > >> 
> > > >> 
> > > >> 
> > > >> 
> > > >> 
> > > >> 
> > > >> 
> > > >>
> > ______________________________________________
> > > >> R-devel at r-project.org
> > > mailing list
> > > >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > > >> 
> > > >> 
> > > >
> > > 
> > >
> >
>


From mbadawy at pm-engr.com  Thu Jun 13 17:13:19 2013
From: mbadawy at pm-engr.com (Mohamed Badawy)
Date: Thu, 13 Jun 2013 15:13:19 +0000
Subject: [R] Unexpected behavior from hist()
Message-ID: <fcb53dfa4a214d698059dcb3d6a8c7db@BY2PR07MB010.namprd07.prod.outlook.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130613/861b1be1/attachment.pl>

From sarah.goslee at gmail.com  Thu Jun 13 17:35:56 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 13 Jun 2013 11:35:56 -0400
Subject: [R] Unexpected behavior from hist()
In-Reply-To: <fcb53dfa4a214d698059dcb3d6a8c7db@BY2PR07MB010.namprd07.prod.outlook.com>
References: <fcb53dfa4a214d698059dcb3d6a8c7db@BY2PR07MB010.namprd07.prod.outlook.com>
Message-ID: <CAM_vjukNz7Nh1wLu0Ke78j+UsqF7Z-j3oT2z6Mv=naoOSt8vww@mail.gmail.com>

Hi,

On Thu, Jun 13, 2013 at 11:13 AM, Mohamed Badawy <mbadawy at pm-engr.com> wrote:
> Hi... I'm still a beginner in R. While doing some curve-fitting with a raw data set of length 22,000, here is what I had:
>
>
>
>> hist(y,col="red")
>
> gives me the frequency histogram, 13 total rectangles, highest is near 5000.
>

You don't provide a reproducible example, so here's some fake data:

somedata <- runif(1000)


> Now
>
>> hist(y,prob=TRUE,col="red",ylim=c(0,1.5))
>
> gives me the density (probability?) histogram, same number f rectangles, but the highest rectangle is obviously higher than 1, how can this be?!!!

Because you misread the help. using freq=FALSE (equivalent to
prob=TRUE, which is a legacy option), you are getting:

freq: logical; if ?TRUE?, the histogram graphic is a representation
          of frequencies, the ?counts? component of the result; if
          ?FALSE?, probability densities, component ?density?, are
          plotted (so that the histogram has a total area of one).
          Defaults to ?TRUE? _if and only if_ ?breaks? are equidistant
          (and ?probability? is not specified).


It sounds like what you actually want is:

somehist <- hist(somedata, plot=FALSE)
somehist$counts <- somehist$counts/sum(somehist$counts)
plot(somehist)

> P.S. I had to post this thread via email as it got rejected as I posted it from Nabble, reason was "Message rejected by filter rule match"

Nabble is not the R-help mailing list. Posting via email is the
correct thing to do.

Sarah

-- 
Sarah Goslee
http://www.functionaldiversity.org


From ingfimo at gmail.com  Thu Jun 13 17:47:49 2013
From: ingfimo at gmail.com (Filippo Monari)
Date: Thu, 13 Jun 2013 16:47:49 +0100
Subject: [R] strange boolean results
Message-ID: <51B9E9A5.6070404@gmail.com>

Hi,
anyone can explain to me the following?

 > rho
  [1] 0.9452398 0.8792735 0.9641829 0.9876954 0.9993560 0.9826084 1.0000000
  [8] 1.0000000 0.7982916 1.0000000 0.3361956

 > any(rho >= 1)
[1] FALSE

thanks, regards
Filippo


From yelin at lbl.gov  Thu Jun 13 17:46:09 2013
From: yelin at lbl.gov (Ye Lin)
Date: Thu, 13 Jun 2013 08:46:09 -0700
Subject: [R] identify data points by certain criteria
In-Reply-To: <8A063994-2F0B-482F-83AA-FF3755B354C9@comcast.net>
References: <CAAvu=b==j0f8rYobAZgYHVfPvQ29w+Cnk-FQA6cCWji-Jy5pZg@mail.gmail.com>
	<8A063994-2F0B-482F-83AA-FF3755B354C9@comcast.net>
Message-ID: <CAAvu=bkP1HYk5=_aSphuApQbVxhduoDto+pCEQOWFvsk7F7cQw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130613/63e0e1ff/attachment.pl>

From dcarlson at tamu.edu  Thu Jun 13 17:56:05 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Thu, 13 Jun 2013 10:56:05 -0500
Subject: [R] Unexpected behavior from hist()
In-Reply-To: <CAM_vjukNz7Nh1wLu0Ke78j+UsqF7Z-j3oT2z6Mv=naoOSt8vww@mail.gmail.com>
References: <fcb53dfa4a214d698059dcb3d6a8c7db@BY2PR07MB010.namprd07.prod.outlook.com>
	<CAM_vjukNz7Nh1wLu0Ke78j+UsqF7Z-j3oT2z6Mv=naoOSt8vww@mail.gmail.com>
Message-ID: <035b01ce684e$82c0bc10$88423430$@tamu.edu>

Density means that the AREAS of the bars add to 1, not the HEIGHTS
of the bars. You probably have intervals that are less than 1. Eg:

> set.seed(42)
> x <- rpois(1000, 5)/100
> info <- hist(x, prob=TRUE)
> info
$breaks
 [1] 0.00 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.10 0.11
0.12 0.13

$counts
 [1]  42  88 151 177 178 131  97  70  43  14   6   2   1

$density
 [1]  4.2  8.8 15.1 17.7 17.8 13.1  9.7  7.0  4.3  1.4  0.6  0.2
0.1

$mids
 [1] 0.005 0.015 0.025 0.035 0.045 0.055 0.065 0.075 0.085 0.095
0.105 0.115
[13] 0.125

$xname
[1] "x"

$equidist
[1] TRUE

attr(,"class")
[1] "histogram"
> diff(info$breaks)*info$density # Areas of each bar
 [1] 0.042 0.088 0.151 0.177 0.178 0.131 0.097 0.070 0.043 0.014
0.006 0.002
[13] 0.001
> sum(diff(info$breaks)*info$density) # Sum of the areas
[1] 1

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Sarah Goslee
Sent: Thursday, June 13, 2013 10:36 AM
To: Mohamed Badawy
Cc: r-help at r-project.org
Subject: Re: [R] Unexpected behavior from hist()

Hi,

On Thu, Jun 13, 2013 at 11:13 AM, Mohamed Badawy
<mbadawy at pm-engr.com> wrote:
> Hi... I'm still a beginner in R. While doing some curve-fitting
with a raw data set of length 22,000, here is what I had:
>
>
>
>> hist(y,col="red")
>
> gives me the frequency histogram, 13 total rectangles, highest is
near 5000.
>

You don't provide a reproducible example, so here's some fake data:

somedata <- runif(1000)


> Now
>
>> hist(y,prob=TRUE,col="red",ylim=c(0,1.5))
>
> gives me the density (probability?) histogram, same number f
rectangles, but the highest rectangle is obviously higher than 1,
how can this be?!!!

Because you misread the help. using freq=FALSE (equivalent to
prob=TRUE, which is a legacy option), you are getting:

freq: logical; if 'TRUE', the histogram graphic is a representation
          of frequencies, the 'counts' component of the result; if
          'FALSE', probability densities, component 'density', are
          plotted (so that the histogram has a total area of one).
          Defaults to 'TRUE' _if and only if_ 'breaks' are
equidistant
          (and 'probability' is not specified).


It sounds like what you actually want is:

somehist <- hist(somedata, plot=FALSE)
somehist$counts <- somehist$counts/sum(somehist$counts)
plot(somehist)

> P.S. I had to post this thread via email as it got rejected as I
posted it from Nabble, reason was "Message rejected by filter rule
match"

Nabble is not the R-help mailing list. Posting via email is the
correct thing to do.

Sarah

-- 
Sarah Goslee
http://www.functionaldiversity.org

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Thu Jun 13 18:00:21 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 13 Jun 2013 12:00:21 -0400
Subject: [R] puzzling behavior of within
Message-ID: <CA+vqiLEuB6iUdEEH-h-8dTz0kNeR80iCkbR48fOy7h0igAQwrA@mail.gmail.com>

Hi all,

In answering a question yesterday about avoiding repeatedly typing the
name of a data.frame when making modifications to it I discovered the
following unexpected behavior of within:

mtcars <- within(mtcars, {
    x <- 0
    x[gear==4] <- 1
})

generates a column named x in mtcars equal to 1 if gear equals 4, and
NA otherwise. What happend to my zeros? I thought maybe you just can't
modify an object more than once, but that is not true:

mtcars <- within(mtcars, {
    x <- 0
    x[gear==4] <- 1
    x[gear==3] <- 2
})

returns a data.frame in with the x column is 1 if gear is 4, 2 if gear
is 3, and NA otherwise. What is going on here?

Surprised by these results I tried a few other things, and found
another surprising behavior:

mtcars <- within(mtcars, {
    x <- 0
    x[1] <- 1
})

generates a column named x in mtcars equal to 1. But I thought I said
only change the first value to one! What happend?

I've been reading and re-reading the documentation, but I can't see
anything that explains these results.

Thanks for any insight,
Ista


From sarah.goslee at gmail.com  Thu Jun 13 18:02:25 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 13 Jun 2013 12:02:25 -0400
Subject: [R] strange boolean results
In-Reply-To: <51B9E9A5.6070404@gmail.com>
References: <51B9E9A5.6070404@gmail.com>
Message-ID: <CAM_vjunZ_a-ujjZTnpYSGiAq13ru=9YwmbM6ygymfvJKqubS0Q@mail.gmail.com>

R FAQ 7.31.

http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f

On Thu, Jun 13, 2013 at 11:47 AM, Filippo Monari <ingfimo at gmail.com> wrote:
> Hi,
> anyone can explain to me the following?
>
>> rho
>  [1] 0.9452398 0.8792735 0.9641829 0.9876954 0.9993560 0.9826084 1.0000000
>  [8] 1.0000000 0.7982916 1.0000000 0.3361956
>
>> any(rho >= 1)
> [1] FALSE
>
> thanks, regards
> Filippo
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From dcarlson at tamu.edu  Thu Jun 13 18:08:34 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Thu, 13 Jun 2013 11:08:34 -0500
Subject: [R] strange boolean results
In-Reply-To: <51B9E9A5.6070404@gmail.com>
References: <51B9E9A5.6070404@gmail.com>
Message-ID: <036f01ce6850$41388aa0$c3a99fe0$@tamu.edu>

Frequently Asked Questions 7.31 Why doesn't R think these numbers
are equal?
http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think
-these-numbers-are-equal_003f

For more details read the First Circle of the R Inferno:
http://www.burns-stat.com/pages/Tutor/R_inferno.pdf

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Filippo Monari
Sent: Thursday, June 13, 2013 10:48 AM
To: r-help at r-project.org
Subject: [R] strange boolean results

Hi,
anyone can explain to me the following?

 > rho
  [1] 0.9452398 0.8792735 0.9641829 0.9876954 0.9993560 0.9826084
1.0000000
  [8] 1.0000000 0.7982916 1.0000000 0.3361956

 > any(rho >= 1)
[1] FALSE

thanks, regards
Filippo

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Thu Jun 13 18:11:40 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 13 Jun 2013 09:11:40 -0700
Subject: [R] puzzling behavior of within
In-Reply-To: <CA+vqiLEuB6iUdEEH-h-8dTz0kNeR80iCkbR48fOy7h0igAQwrA@mail.gmail.com>
References: <CA+vqiLEuB6iUdEEH-h-8dTz0kNeR80iCkbR48fOy7h0igAQwrA@mail.gmail.com>
Message-ID: <CACk-te3aQzEhxtp+_5r6n95mJdOZ4Wim_Ck2_cbdLr0__Zt=uw@mail.gmail.com>

Why are you surprised? It has nothing to do with within() . ?"[<-"

> x <- 0
> g <- 1:2
> x[g==1]<- 5
> x
[1]  5 NA

-- Bert

On Thu, Jun 13, 2013 at 9:00 AM, Ista Zahn <istazahn at gmail.com> wrote:
> Hi all,
>
> In answering a question yesterday about avoiding repeatedly typing the
> name of a data.frame when making modifications to it I discovered the
> following unexpected behavior of within:
>
> mtcars <- within(mtcars, {
>     x <- 0
>     x[gear==4] <- 1
> })
>
> generates a column named x in mtcars equal to 1 if gear equals 4, and
> NA otherwise. What happend to my zeros? I thought maybe you just can't
> modify an object more than once, but that is not true:
>
> mtcars <- within(mtcars, {
>     x <- 0
>     x[gear==4] <- 1
>     x[gear==3] <- 2
> })
>
> returns a data.frame in with the x column is 1 if gear is 4, 2 if gear
> is 3, and NA otherwise. What is going on here?
>
> Surprised by these results I tried a few other things, and found
> another surprising behavior:
>
> mtcars <- within(mtcars, {
>     x <- 0
>     x[1] <- 1
> })
>
> generates a column named x in mtcars equal to 1. But I thought I said
> only change the first value to one! What happend?
>
> I've been reading and re-reading the documentation, but I can't see
> anything that explains these results.
>
> Thanks for any insight,
> Ista
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From istazahn at gmail.com  Thu Jun 13 18:17:55 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 13 Jun 2013 12:17:55 -0400
Subject: [R] puzzling behavior of within
In-Reply-To: <CACk-te3aQzEhxtp+_5r6n95mJdOZ4Wim_Ck2_cbdLr0__Zt=uw@mail.gmail.com>
References: <CA+vqiLEuB6iUdEEH-h-8dTz0kNeR80iCkbR48fOy7h0igAQwrA@mail.gmail.com>
	<CACk-te3aQzEhxtp+_5r6n95mJdOZ4Wim_Ck2_cbdLr0__Zt=uw@mail.gmail.com>
Message-ID: <CA+vqiLEvVwo=A4XLh7gF3ur4xB8pLV9E0VHSXJfuMQZ_CpPZ6A@mail.gmail.com>

On Thu, Jun 13, 2013 at 12:11 PM, Bert Gunter <gunter.berton at gene.com> wrote:
> Why are you surprised?

Because I missed the significance of "examines the environment after
the evaluation of 'expr' and makes the corresponding modifications to
'data'" in ?within, and thought my example should be equivalent to

mtcars <- within(mtcars, {
    x <- 0
    x[gear==4] <- 1
})


It has nothing to do with within() . ?"[<-"
>
>> x <- 0
>> g <- 1:2
>> x[g==1]<- 5
>> x
> [1]  5 NA

Thanks Bert. Makes me feel stupid, but I guess that's the price I pay
for enlightenment.

Best,
Ista

>
> -- Bert
>
> On Thu, Jun 13, 2013 at 9:00 AM, Ista Zahn <istazahn at gmail.com> wrote:
>> Hi all,
>>
>> In answering a question yesterday about avoiding repeatedly typing the
>> name of a data.frame when making modifications to it I discovered the
>> following unexpected behavior of within:
>>
>> mtcars <- within(mtcars, {
>>     x <- 0
>>     x[gear==4] <- 1
>> })
>>
>> generates a column named x in mtcars equal to 1 if gear equals 4, and
>> NA otherwise. What happend to my zeros? I thought maybe you just can't
>> modify an object more than once, but that is not true:
>>
>> mtcars <- within(mtcars, {
>>     x <- 0
>>     x[gear==4] <- 1
>>     x[gear==3] <- 2
>> })
>>
>> returns a data.frame in with the x column is 1 if gear is 4, 2 if gear
>> is 3, and NA otherwise. What is going on here?
>>
>> Surprised by these results I tried a few other things, and found
>> another surprising behavior:
>>
>> mtcars <- within(mtcars, {
>>     x <- 0
>>     x[1] <- 1
>> })
>>
>> generates a column named x in mtcars equal to 1. But I thought I said
>> only change the first value to one! What happend?
>>
>> I've been reading and re-reading the documentation, but I can't see
>> anything that explains these results.
>>
>> Thanks for any insight,
>> Ista
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
>
> Internal Contact Info:
> Phone: 467-7374
> Website:
> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From istazahn at gmail.com  Thu Jun 13 18:19:15 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 13 Jun 2013 12:19:15 -0400
Subject: [R] puzzling behavior of within
In-Reply-To: <CA+vqiLEvVwo=A4XLh7gF3ur4xB8pLV9E0VHSXJfuMQZ_CpPZ6A@mail.gmail.com>
References: <CA+vqiLEuB6iUdEEH-h-8dTz0kNeR80iCkbR48fOy7h0igAQwrA@mail.gmail.com>
	<CACk-te3aQzEhxtp+_5r6n95mJdOZ4Wim_Ck2_cbdLr0__Zt=uw@mail.gmail.com>
	<CA+vqiLEvVwo=A4XLh7gF3ur4xB8pLV9E0VHSXJfuMQZ_CpPZ6A@mail.gmail.com>
Message-ID: <CA+vqiLG8=brmAjwRyJn=D_Ts8bbXDoh=KuhqD0z7XPYbbJCCjQ@mail.gmail.com>

On Thu, Jun 13, 2013 at 12:17 PM, Ista Zahn <istazahn at gmail.com> wrote:
> On Thu, Jun 13, 2013 at 12:11 PM, Bert Gunter <gunter.berton at gene.com> wrote:
>> Why are you surprised?
>
> Because I missed the significance of "examines the environment after
> the evaluation of 'expr' and makes the corresponding modifications to
> 'data'" in ?within, and thought my example should be equivalent to
>
> mtcars <- within(mtcars, {
>     x <- 0
>     x[gear==4] <- 1
> })

I meant, "thought my example should be equivalent to

mtcars$x <- 0
mtcars$x[mtcars$gear==4] <- 1
"

Thanks again,
Ista

>
>
> It has nothing to do with within() . ?"[<-"
>>
>>> x <- 0
>>> g <- 1:2
>>> x[g==1]<- 5
>>> x
>> [1]  5 NA
>
> Thanks Bert. Makes me feel stupid, but I guess that's the price I pay
> for enlightenment.
>
> Best,
> Ista
>
>>
>> -- Bert
>>
>> On Thu, Jun 13, 2013 at 9:00 AM, Ista Zahn <istazahn at gmail.com> wrote:
>>> Hi all,
>>>
>>> In answering a question yesterday about avoiding repeatedly typing the
>>> name of a data.frame when making modifications to it I discovered the
>>> following unexpected behavior of within:
>>>
>>> mtcars <- within(mtcars, {
>>>     x <- 0
>>>     x[gear==4] <- 1
>>> })
>>>
>>> generates a column named x in mtcars equal to 1 if gear equals 4, and
>>> NA otherwise. What happend to my zeros? I thought maybe you just can't
>>> modify an object more than once, but that is not true:
>>>
>>> mtcars <- within(mtcars, {
>>>     x <- 0
>>>     x[gear==4] <- 1
>>>     x[gear==3] <- 2
>>> })
>>>
>>> returns a data.frame in with the x column is 1 if gear is 4, 2 if gear
>>> is 3, and NA otherwise. What is going on here?
>>>
>>> Surprised by these results I tried a few other things, and found
>>> another surprising behavior:
>>>
>>> mtcars <- within(mtcars, {
>>>     x <- 0
>>>     x[1] <- 1
>>> })
>>>
>>> generates a column named x in mtcars equal to 1. But I thought I said
>>> only change the first value to one! What happend?
>>>
>>> I've been reading and re-reading the documentation, but I can't see
>>> anything that explains these results.
>>>
>>> Thanks for any insight,
>>> Ista
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>>
>> Internal Contact Info:
>> Phone: 467-7374
>> Website:
>> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From smartpink111 at yahoo.com  Thu Jun 13 18:51:44 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 13 Jun 2013 09:51:44 -0700 (PDT)
Subject: [R] puzzling behavior of within
In-Reply-To: <CA+vqiLEvVwo=A4XLh7gF3ur4xB8pLV9E0VHSXJfuMQZ_CpPZ6A@mail.gmail.com>
References: <CA+vqiLEuB6iUdEEH-h-8dTz0kNeR80iCkbR48fOy7h0igAQwrA@mail.gmail.com>
	<CACk-te3aQzEhxtp+_5r6n95mJdOZ4Wim_Ck2_cbdLr0__Zt=uw@mail.gmail.com>
	<CA+vqiLEvVwo=A4XLh7gF3ur4xB8pLV9E0VHSXJfuMQZ_CpPZ6A@mail.gmail.com>
Message-ID: <1371142304.10045.YahooMailNeo@web142604.mail.bf1.yahoo.com>

within(mtcars,{ x<-rep(0,nrow(mtcars));x[gear==4]<-1;x[gear==3]<-2}) #should fix this;
A.K.



----- Original Message -----
From: Ista Zahn <istazahn at gmail.com>
To: Bert Gunter <gunter.berton at gene.com>
Cc: r-help at r-project.org
Sent: Thursday, June 13, 2013 12:17 PM
Subject: Re: [R] puzzling behavior of within

On Thu, Jun 13, 2013 at 12:11 PM, Bert Gunter <gunter.berton at gene.com> wrote:
> Why are you surprised?

Because I missed the significance of "examines the environment after
the evaluation of 'expr' and makes the corresponding modifications to
'data'" in ?within, and thought my example should be equivalent to

mtcars <- within(mtcars, {
? ? x <- 0
? ? x[gear==4] <- 1
})


It has nothing to do with within() . ?"[<-"
>
>> x <- 0
>> g <- 1:2
>> x[g==1]<- 5
>> x
> [1]? 5 NA

Thanks Bert. Makes me feel stupid, but I guess that's the price I pay
for enlightenment.

Best,
Ista

>
> -- Bert
>
> On Thu, Jun 13, 2013 at 9:00 AM, Ista Zahn <istazahn at gmail.com> wrote:
>> Hi all,
>>
>> In answering a question yesterday about avoiding repeatedly typing the
>> name of a data.frame when making modifications to it I discovered the
>> following unexpected behavior of within:
>>
>> mtcars <- within(mtcars, {
>>? ?  x <- 0
>>? ?  x[gear==4] <- 1
>> })
>>
>> generates a column named x in mtcars equal to 1 if gear equals 4, and
>> NA otherwise. What happend to my zeros? I thought maybe you just can't
>> modify an object more than once, but that is not true:
>>
>> mtcars <- within(mtcars, {
>>? ?  x <- 0
>>? ?  x[gear==4] <- 1
>>? ?  x[gear==3] <- 2
>> })
>>
>> returns a data.frame in with the x column is 1 if gear is 4, 2 if gear
>> is 3, and NA otherwise. What is going on here?
>>
>> Surprised by these results I tried a few other things, and found
>> another surprising behavior:
>>
>> mtcars <- within(mtcars, {
>>? ?  x <- 0
>>? ?  x[1] <- 1
>> })
>>
>> generates a column named x in mtcars equal to 1. But I thought I said
>> only change the first value to one! What happend?
>>
>> I've been reading and re-reading the documentation, but I can't see
>> anything that explains these results.
>>
>> Thanks for any insight,
>> Ista
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
>
> Internal Contact Info:
> Phone: 467-7374
> Website:
> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From mbadawy at pm-engr.com  Thu Jun 13 18:06:36 2013
From: mbadawy at pm-engr.com (R_noob#314159)
Date: Thu, 13 Jun 2013 09:06:36 -0700 (PDT)
Subject: [R] Unexpected behavior from hist()
In-Reply-To: <035b01ce684e$82c0bc10$88423430$@tamu.edu>
References: <1371136055427-4669457.post@n4.nabble.com>
	<fcb53dfa4a214d698059dcb3d6a8c7db@BY2PR07MB010.namprd07.prod.outlook.com>
	<CAM_vjukNz7Nh1wLu0Ke78j+UsqF7Z-j3oT2z6Mv=naoOSt8vww@mail.gmail.com>
	<035b01ce684e$82c0bc10$88423430$@tamu.edu>
Message-ID: <31d90ff5f07b460aadc5e4c333fcf5d7@BY2PR07MB010.namprd07.prod.outlook.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130613/28817426/attachment.pl>

From plalehzari at platinumlp.com  Thu Jun 13 17:59:27 2013
From: plalehzari at platinumlp.com (Pooya Lalehzari)
Date: Thu, 13 Jun 2013 15:59:27 +0000
Subject: [R] set.seed(x)
Message-ID: <92FD11F467D9CA41A8AEA01FE4D76DEB0AC6CA85@EX02.platinum.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130613/767bd411/attachment.pl>

From smartpink111 at yahoo.com  Thu Jun 13 19:03:40 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 13 Jun 2013 10:03:40 -0700 (PDT)
Subject: [R] Getting rid of rows matching a certain condition
Message-ID: <1371143020.88142.YahooMailNeo@web142602.mail.bf1.yahoo.com>

HI,
Please check this link (http://r.789695.n4.nabble.com/Remove-levels-td4669441.html).? It was posted today.
df1<-subset(df, Trt!="blank") 
df2<- df1
df1$Trt<- factor(df1$Trt)
levels(df1$Trt)
#[1] "Trt1" "Trt2"


#or
?df2$Trt<-droplevels(df2$Trt)
?levels(df2$Trt)
#[1] "Trt1" "Trt2"
A.K.



Hey guys 
I am new and a beginner. So far I searched the forum for an answer. Did not found anything. 
Here is the Problem. 

I have a data.frame 



Time <- c(1,2,1,1,2,2,3,3) ? ? ? ? ? ? ? ? ? ? ? 
Trt <- factor(c("blank", "blank", "Trt1", "Trt1", "Trt1", "Trt2", "Trt2", "Trt2")) 
OD600 <- c(0.1,0.2,0.18,0.3,0.16,0.21,0.25,0.16) 
df <- data.frame(Time,Trt,OD600) 

No I apply: 

df<-subset(df, Trt!="blank") 
? 
So the data.frame has no rows matching Trt=blank" anymore (looking at the data set). So far so good. 

However if I type in: 
levels(df$Trt) 
I get the result: [1] "blank" "Trt1" ?"Trt2" 

Somehow it is still somwhere. How can I remove the blank from the data.frame definitely? 

Thanks for the help. 



From macqueen1 at llnl.gov  Thu Jun 13 19:20:02 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 13 Jun 2013 17:20:02 +0000
Subject: [R] Plotting gps coordinates on Shapefile
In-Reply-To: <CAMgNocuFWrfgxicO8BvgaO3iHKS=5+LdO1VWn52n9t4AzgFSZQ@mail.gmail.com>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A5219144D31A@PRDEXMBX-08.the-lab.llnl.gov>

Your shapefile should include specifications for its coordinate system.
Look for a file names maryland.prj in the same directory as maryland.shp.
And that coordinate system should be included in your 'border' object. You
might need to change to using readOGR() to load the shapefile into R. Use

  str(border)

to find out.

If your border object does in fact include its projection, then you can
use spTransform(), as Barry suggested, to transform it to lat/long. Then
your overlay should succeed.

And I second Barry's recommendation to ask this kind of question on
r-sig-geo.


You will need to learn how to specify coordinate systems; a starting point
is
  ?proj4string
(from the sp package). r-sig-geo is definitely a good place to get help
for that.
I myself have used QGIS (Quantum GIS) to look up projection specs, as it
has a nice listing which you can search by name; in your case I'd search
for 'Maryland'. 

-Don


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/12/13 10:26 PM, "L S" <losedaghat at gmail.com> wrote:

>Hi,
>
>I am new to doing spatial analysis.  I am interested in trying many things
>in R, but one of the first things I would like to do is plot all of my
>lat,
>lon points in a csv file within a window defined by a shapefile.
>
>I have read in the shape file by doing the following:
>border <-readShapePoly("shapefiles/maryland.shp")
>plot(border, border="red", las=1)  # plot confirms correct shape
>border <-as(border, "owin")
>
>However, once I try to do:
>data_ppp <-ppp(data$Latitude, data$Longitude, window=border)
>
>I get the error that:
>In ppp(data$Latitude, data$Longitude, window = border) :
>  523461 points were rejected as lying outside the specified window
>
>I realized that the coordinates are completely different.  The coordinates
>in my data file (i.e. my csv file) are traditional GPS coordinates (e.g.
>39.17
>or 76.37).  The shapefile however has x,y values such as 1416813.54262877
>or 561125.546602725. I am not familiar with what type of coordinate system
>those values use.
>
>How can I change the coordinates in my csv file to match the same system
>as
>my shapefile or the other way around--i.e. to get my shapefile to have
>similar coordinates as my csv file?
>
>Any help would be appreciated.
>
>Thank you.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From r_vardavas at hotmail.com  Thu Jun 13 19:26:00 2013
From: r_vardavas at hotmail.com (Raffaello Vardavas)
Date: Thu, 13 Jun 2013 10:26:00 -0700
Subject: [R] =?windows-1252?q?Installing_package=28s=29_into_=2E=2E=2E_=28?=
 =?windows-1252?q?as_=91lib=92_is_unspecified=29?=
Message-ID: <DUB106-W44E15F82D03F25D068390AE6870@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130613/16c3be6c/attachment.pl>

From halldor.bjornsson at gmail.com  Thu Jun 13 19:29:05 2013
From: halldor.bjornsson at gmail.com (=?ISO-8859-1?Q?Halld=F3r_Bj=F6rnsson?=)
Date: Thu, 13 Jun 2013 13:29:05 -0400
Subject: [R] Memory issues with R on Ubuntu
Message-ID: <CAMenLRCNZ45_D6DgHVBT=CdOuSxGuC0b75JjAcWwU4CYxGuNag@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130613/3f51f5d8/attachment.pl>

From murdoch.duncan at gmail.com  Thu Jun 13 19:32:19 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 13 Jun 2013 13:32:19 -0400
Subject: [R] set.seed(x)
In-Reply-To: <92FD11F467D9CA41A8AEA01FE4D76DEB0AC6CA85@EX02.platinum.com>
References: <92FD11F467D9CA41A8AEA01FE4D76DEB0AC6CA85@EX02.platinum.com>
Message-ID: <51BA0223.5080201@gmail.com>

On 13/06/2013 11:59 AM, Pooya Lalehzari wrote:
> Hello,
> If I use set.seed(x) to set a seed for the random number generator, how can I undo that to revert a random output every time I run my code?

If you remove .Random.seed, then the next time a seed is needed it will 
be generated from the system clock, so it will appear random.

Duncan Murdoch


From 538280 at gmail.com  Thu Jun 13 19:34:48 2013
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 13 Jun 2013 11:34:48 -0600
Subject: [R]
	=?windows-1252?q?Installing_package=28s=29_into_=2E=2E=2E_=28?=
	=?windows-1252?q?as_=91lib=92_is_unspecified=29?=
In-Reply-To: <DUB106-W44E15F82D03F25D068390AE6870@phx.gbl>
References: <DUB106-W44E15F82D03F25D068390AE6870@phx.gbl>
Message-ID: <CAFEqCdx8DnLRsRAjynMCDyVUDEmTwYjC35WLKYS2G1yH1XzmZQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130613/ecd6af77/attachment.pl>

From murdoch.duncan at gmail.com  Thu Jun 13 19:35:50 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 13 Jun 2013 13:35:50 -0400
Subject: [R]
 =?windows-1252?q?Installing_package=28s=29_into_=2E=2E=2E_=28?=
 =?windows-1252?q?as_=91lib=92_is_unspecified=29?=
In-Reply-To: <DUB106-W44E15F82D03F25D068390AE6870@phx.gbl>
References: <DUB106-W44E15F82D03F25D068390AE6870@phx.gbl>
Message-ID: <51BA02F6.10006@gmail.com>

On 13/06/2013 1:26 PM, Raffaello Vardavas wrote:
> Dear All,
>
> this may be a trivial problem. A collaborator has created an R package for internal use (not available on CRAN). This installs and works fine on my Mac but fails to install on windows.
>
>   
>
> When I install the packagein windows by browing and pointing to the .zip file I get the following error:
>
>   
>
> > install.packages("C:/Users/rvardava/RiskPerceptionNetworks/Tools/nirm/nirm.tags/nirm_0.6.5.zip", repos = NULL)
> Installing package(s) into ?C:/Program Files/R/R-2.15.3/library?
> (as ?lib? is unspecified)
> > install.packages("C:/Users/rvardava/RiskPerceptionNetworks/Tools/nirm/nirm.tags/nirm_0.6.4.zip", repos = NULL)
> Installing package(s) into ?C:/Program Files/R/R-2.15.3/library?
> (as ?lib? is unspecified)

Those are not errors, they are just notes to let you know where it was 
installed.
>   
>
> However if I install a package from CRAN (e.g. deSolve) the same warning appears initially - but it continues and installs the package with no problems:
>
>
> > install.packages("deSolve")
> Installing package(s) into ?C:/Program Files/R/R-2.15.3/library?
> (as ?lib? is unspecified)
> trying URL 'http://cran.stat.ucla.edu/bin/windows/contrib/2.15/deSolve_1.10-6.zip'
> Content type 'application/zip' length 2659517 bytes (2.5 Mb)
> opened URL
> downloaded 2.5 Mb
>
> package ?deSolve? successfully unpacked and MD5 sums checked
>
> The downloaded binary packages are in
>   C:\Users\rvardava\AppData\Local\Temp\RtmpO8Ul1g\downloaded_packages


You haven't shown us any error, but if the package doesn't work, it 
might be because it wasn't built properly.  A .zip file that works on a 
Mac is unlikely to also work on Windows:  Windows uses the .zip 
extension for *binary* installs.

Duncan Murdoch


From scott.raynaud at yahoo.com  Thu Jun 13 19:37:27 2013
From: scott.raynaud at yahoo.com (Scott Raynaud)
Date: Thu, 13 Jun 2013 10:37:27 -0700 (PDT)
Subject: [R] Survey imputation
Message-ID: <1371145047.34864.YahooMailNeo@web142704.mail.bf1.yahoo.com>

I'm working with NHIS survye data.? I'd like the to use muliple imputation 
to cover the missing data for the variables in which I'm interested.? My 
question concerns the use of certain variables in the imputation model.? 
For example, race would be an important predictor in the imputation 
model, but it has been imputed (hot deck) as have other variables that 
might be useful in the imputation model.? What is the wisdom of using 
data that have been imputed in subsequent imputations models?


From gunter.berton at gene.com  Thu Jun 13 19:45:37 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 13 Jun 2013 10:45:37 -0700
Subject: [R] Survey imputation
In-Reply-To: <1371145047.34864.YahooMailNeo@web142704.mail.bf1.yahoo.com>
References: <1371145047.34864.YahooMailNeo@web142704.mail.bf1.yahoo.com>
Message-ID: <CACk-te1WMDFrCfLF4ZQ1g4zR51BjTRFj13UF+A_irAPCPLb6zA@mail.gmail.com>

Is this an R question?

Seems like it belongs on a statistical or survey list, not r-help.

Cheers,
Bert

On Thu, Jun 13, 2013 at 10:37 AM, Scott Raynaud <scott.raynaud at yahoo.com> wrote:
> I'm working with NHIS survye data.  I'd like the to use muliple imputation
> to cover the missing data for the variables in which I'm interested.  My
> question concerns the use of certain variables in the imputation model.
> For example, race would be an important predictor in the imputation
> model, but it has been imputed (hot deck) as have other variables that
> might be useful in the imputation model.  What is the wisdom of using
> data that have been imputed in subsequent imputations models?
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From yelin at lbl.gov  Thu Jun 13 19:50:57 2013
From: yelin at lbl.gov (Ye Lin)
Date: Thu, 13 Jun 2013 10:50:57 -0700
Subject: [R] Survey imputation
In-Reply-To: <CACk-te1WMDFrCfLF4ZQ1g4zR51BjTRFj13UF+A_irAPCPLb6zA@mail.gmail.com>
References: <1371145047.34864.YahooMailNeo@web142704.mail.bf1.yahoo.com>
	<CACk-te1WMDFrCfLF4ZQ1g4zR51BjTRFj13UF+A_irAPCPLb6zA@mail.gmail.com>
Message-ID: <CAAvu=b=E3bfwBLXcaUoKEaNUvNvHvzCTHSDbLRe5kPcEpz5GyA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130613/636eb906/attachment.pl>

From scott.raynaud at yahoo.com  Thu Jun 13 19:51:54 2013
From: scott.raynaud at yahoo.com (Scott Raynaud)
Date: Thu, 13 Jun 2013 10:51:54 -0700 (PDT)
Subject: [R] Survey imputation
In-Reply-To: <CACk-te1WMDFrCfLF4ZQ1g4zR51BjTRFj13UF+A_irAPCPLb6zA@mail.gmail.com>
References: <1371145047.34864.YahooMailNeo@web142704.mail.bf1.yahoo.com>
	<CACk-te1WMDFrCfLF4ZQ1g4zR51BjTRFj13UF+A_irAPCPLb6zA@mail.gmail.com>
Message-ID: <1371145914.16205.YahooMailNeo@web142706.mail.bf1.yahoo.com>

I paln on using R to do the imputation once I figure out how to do it.

?
----- Original Message -----
From: Bert Gunter <gunter.berton at gene.com>
To: Scott Raynaud <scott.raynaud at yahoo.com>
Cc: "r-help at r-project.org" <r-help at r-project.org>
Sent: Thursday, June 13, 2013 12:45 PM
Subject: Re: [R] Survey imputation

Is this an R question?

Seems like it belongs on a statistical or survey list, not r-help.

Cheers,
Bert

On Thu, Jun 13, 2013 at 10:37 AM, Scott Raynaud <scott.raynaud at yahoo.com> wrote:
> I'm working with NHIS survye data.? I'd like the to use muliple imputation
> to cover the missing data for the variables in which I'm interested.? My
> question concerns the use of certain variables in the imputation model.
> For example, race would be an important predictor in the imputation
> model, but it has been imputed (hot deck) as have other variables that
> might be useful in the imputation model.? What is the wisdom of using
> data that have been imputed in subsequent imputations models?
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm



From rune.haubo at gmail.com  Thu Jun 13 21:11:07 2013
From: rune.haubo at gmail.com (Rune Haubo)
Date: Thu, 13 Jun 2013 21:11:07 +0200
Subject: [R] multilevel binary and ordered regression models
In-Reply-To: <CADe_g+XkeEKZoSWU7kbPESFxjK9ah40LETXMTQxEJH8v8-=B9g@mail.gmail.com>
References: <CADe_g+W+1cZOoGFquWxc7xt9qUoBLKQU43ApGVrRbrkEk3PdTg@mail.gmail.com>
	<CAG_uk918pXxQcj4H1bsLz56BXJU7APaKm45MKVMRrXVUMKBC+w@mail.gmail.com>
	<CADe_g+XkeEKZoSWU7kbPESFxjK9ah40LETXMTQxEJH8v8-=B9g@mail.gmail.com>
Message-ID: <CAG_uk93PuTwMgq-xn7z2y7PN2Cd503XGjq1atCHJvqsqET2CKA@mail.gmail.com>

Could you share the results of sessionInfo() and str(alllev)?

Also please share the exact in- and output with relevant error
messages; for example 'cntnew:male' does not make much sense without
context.

Unfortunately I don't understand your model specification and is lost
in the interpretation of gammas, w's, x's, mu's beta's and their
indexes, so it is hard for me to say whether you are specifying the
models you seek correctly i clmm. Perhaps the package vignettes can be
an inspiration here? Ahh, I see you have discovered those.

And yes, the current implementation only allows random effects terms
on the form (1| <grouping_factor>), so unless x1 is a factor
(1|group:x1) wont work. I currently have a working implementation that
allows all kinds of random effects terms on the form
(<general_formula> | <grouping_factor>) like glmer allows for, but I
lack the time to wrap it up and test it before I can release it on
CRAN.

Others have successfully fitted models to large data sets (nobs > 1e6)
with several random effects terms, so I don't expect that is a
problem. If you there are a lot of parameters in your models, then,
yes, they can take a while to fit. Equally important is the
identifiability of the estimation problem; the optimum of a ill
defined model can be very hard to locate.

Cheers,
Rune

On 9 June 2013 16:44, Xu Jun <junxu.r at gmail.com> wrote:
> Rune,
>
> Thanks a lot for pointing me to your ordinal package. It is wonderful,
> and I tried a random intercept model and it worked well except that
> probably there is something wrong with my data (size is big), I got
> some warning messages indicating that "In sqrt(diag(vc)[1:npar]) :
> NaNs produced." Therefore, some of the coefficients do not have
> standard errors. I also have a follow-up question: if I want to
> estimate a slope as outcome model, how am I supposed to specify the
> model. I tried following the few tutorials you posted on CRAN, but was
> not able to figure it out:
>
>
> Here is my model:
>
> level 1: y*_ij = beta_0j + beta_1j*x1_ij + beta_2j*x2_ij +
> beta_3j*x3_ij + epsilon_ij
>
> where y* is a latent continuous variable and y is an observed binary
> dependent variable.
> y  is an observed ordinal variable, say ranging from 1-4, and has been
> coded as a factor variable.
>
> x's are predictors at level 1
> beta's are regression coefficients at level 1
> epsilon's are error terms in level 1 equations
>
> level 2 Eq1: beta_0j  = gamma_00 + gamma_01*w1_j + gamma_02*w2_j + mu_0j
> Level 2 Eq2: beta_1j  = gamma_10 + gamma_11*w1_j + gamma_02*w2_j + mu_1j
>
> My guess would be:
> # try 1
> clmm(y~ x1 + x2 + x3 + w1 + w2 + w1:x1 + w2:x2 + (1 + x1 | group), #
> like the syntax in lmer or glmer
>                      data=alllev, link="logit",
>                      na.action=na.omit,
>                      Hess=T)
>
> # or try 2
>
> clmm(y~ x1 + x2 + x3 + w1 + w2 + w1:x1 + w2:x2 + (1  | group) + (1 | group:x1),
>                      data=alllev, link="logit",
>                      na.action=na.omit,
>                      Hess=T)
>
> but none worked. After I issued the first try, I got the following message:
>
> Error: Matrices must have same number of columns in rbind2(..1, r)
> In addition: Warning messages:
> 1: In cntnew:male :
>   numerical expression has 177770 elements: only the first used
>
> and after the second try, simply it says that I got to following the
> (1|factor) format. I would appreciate that if you could point me to
> the right direction. Also, I know I am dealing with a relatively large
> data set, but is there any way to speed up the estimation a bit.
> Thanks a lot!
>
> Jun
>
> On Fri, Jun 7, 2013 at 1:04 AM, Rune Haubo <rune.haubo at gmail.com> wrote:
>> On 6 June 2013 00:13, Xu Jun <junxu.r at gmail.com> wrote:
>>> Dear r-helpers,
>>>
>>> I have two questions on multilevel binary and ordered regression models,
>>> respectively:
>>>
>>> 1. Is there any r function (like lmer or glmer) to run multilevel ordered
>>> regression models?
>>
>> Yes, package ordinal will fit such models.
>>
>> Cheers,
>> Rune


From mark.hornick at oracle.com  Thu Jun 13 19:22:06 2013
From: mark.hornick at oracle.com (Mark Hornick)
Date: Thu, 13 Jun 2013 13:22:06 -0400
Subject: [R] Database Connectivity Performance Comparison with ROracle
Message-ID: <51B9FFBE.7050301@oracle.com>

R users have a few choices of how to connect to their Oracle Database. 
The most commonly seen include: RODBC, RJDBC, and ROracle. However, 
these three packages have significantly different performance and 
scalability characteristics which can greatly impact application 
development. This blog article 
[https://blogs.oracle.com/R/entry/r_to_oracle_database_connectivity] 
provides benchmark results comparing these alternatives and highlights 
performance on a wide range of data sets.

Cheers,
Mark

--
Mark Hornick
Oracle Advanced Analytics


From dwinsemius at comcast.net  Thu Jun 13 21:43:14 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 13 Jun 2013 12:43:14 -0700
Subject: [R] Survey imputation
In-Reply-To: <1371145914.16205.YahooMailNeo@web142706.mail.bf1.yahoo.com>
References: <1371145047.34864.YahooMailNeo@web142704.mail.bf1.yahoo.com>
	<CACk-te1WMDFrCfLF4ZQ1g4zR51BjTRFj13UF+A_irAPCPLb6zA@mail.gmail.com>
	<1371145914.16205.YahooMailNeo@web142706.mail.bf1.yahoo.com>
Message-ID: <3793EC86-61E0-40AA-A4BF-7C64D78133CB@comcast.net>

See Lumley's text "Complex Surveys", chapter 9: "Missing Data". In addition to the survey package he also uses teh RSQLite and mitols packages in his worked examples. He doesn't use the NHIS data for the missing data chapter, but he does provide examples using NHIS for other tasks.

-- 
David.


On Jun 13, 2013, at 10:51 AM, Scott Raynaud wrote:

> I paln on using R to do the imputation once I figure out how to do it.
> 
>  
> ----- Original Message -----
> From: Bert Gunter <gunter.berton at gene.com>
> To: Scott Raynaud <scott.raynaud at yahoo.com>
> Cc: "r-help at r-project.org" <r-help at r-project.org>
> Sent: Thursday, June 13, 2013 12:45 PM
> Subject: Re: [R] Survey imputation
> 
> Is this an R question?
> 
> Seems like it belongs on a statistical or survey list, not r-help.
> 
> Cheers,
> Bert
> 
> On Thu, Jun 13, 2013 at 10:37 AM, Scott Raynaud <scott.raynaud at yahoo.com> wrote:
>> I'm working with NHIS survye data.  I'd like the to use muliple imputation
>> to cover the missing data for the variables in which I'm interested.  My
>> question concerns the use of certain variables in the imputation model.
>> For example, race would be an important predictor in the imputation
>> model, but it has been imputed (hot deck) as have other variables that
>> might be useful in the imputation model.  What is the wisdom of using
>> data that have been imputed in subsequent imputations models?
>> 


David Winsemius
Alameda, CA, USA


From jonathancornelissen at hotmail.com  Thu Jun 13 22:12:08 2013
From: jonathancornelissen at hotmail.com (jonathan cornelissen)
Date: Thu, 13 Jun 2013 20:12:08 +0000
Subject: [R] Instant search for R documentation
In-Reply-To: <51B85461.1060101@structuremonitoring.com>
References: <BLU175-W42727150ADA97BBD3C3E53AD860@phx.gbl>,
	<51B85461.1060101@structuremonitoring.com>
Message-ID: <BLU175-W101F83EBEE4867687534FFAD870@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130613/dec5655d/attachment.pl>

From smartpink111 at yahoo.com  Thu Jun 13 22:15:24 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 13 Jun 2013 13:15:24 -0700 (PDT)
Subject: [R] identify data points by certain criteria
In-Reply-To: <CAAvu=bmUYmWLobPnQR==VQQwwnip_Ct+JVd5kpR7URe+1Oj=gQ@mail.gmail.com>
References: <CAAvu=b==j0f8rYobAZgYHVfPvQ29w+Cnk-FQA6cCWji-Jy5pZg@mail.gmail.com>
	<1371086966.86860.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CAAvu=bnKRbWck2JD1kTgPFsS6XYAsbBH0nobzyuQkLbXgXruqw@mail.gmail.com>
	<1371141769.16551.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CAAvu=bmsJKasZ8nUv7d81p37AK63bVrM3kC=GiJwa=hrndQUSQ@mail.gmail.com>
	<1371142631.42822.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CAAvu=bmUYmWLobPnQR==VQQwwnip_Ct+JVd5kpR7URe+1Oj=gQ@mail.gmail.com>
Message-ID: <1371154524.46060.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
May be this helps:
source("Ye_data.txt")
?dim(dat1)
#[1] 44640???? 3
library(xts)
?xt1<- xts(dat1[,-1],strptime(dat1[,1],"%m/%d/%Y %H:%M"))
xtSub<-xt1["T00:00:00/T08:00:00"]
?dim(xt1)
#[1] 44640???? 2
?dim(xtSub)
#[1] 14911???? 2
lst1<-split(xtSub,as.Date(index(xtSub)))

sapply(lst1,function(x) {indx<- which(rowSums(x)==0);indx1<-which.max(c(1,diff(index(x)[indx]))) })
#2012-12-01 2012-12-02 2012-12-03 2012-12-04 2012-12-05 2012-12-06 2012-12-07 
#?????? 373???????? 41??????? 262??????? 268??????? 266??????? 254??????? 274 
#2012-12-08 2012-12-09 2012-12-10 2012-12-11 2012-12-12 2012-12-13 2012-12-14 
#?????? 109????????? 1??????? 323??????? 264??????? 279??????? 353??????? 265 
#2012-12-15 2012-12-16 2012-12-17 2012-12-18 2012-12-19 2012-12-20 2012-12-21 
#?????? 327??????? 226??????? 264??????? 269??????? 271??????? 267??????? 276 
#2012-12-22 2012-12-23 2012-12-24 2012-12-25 2012-12-26 2012-12-27 2012-12-28 
#?????? 360??????? 162??????? 222???????? 81??????? 231??????? 143??????? 364 
#2012-12-29 2012-12-30 2012-12-31 
?#????? 122??????? 399??????? 418 
?lst2<-lapply(lst1,function(x) {indx<- which(rowSums(x)==0);indx1<-which.max(c(1,diff(index(x)[indx])));index(x)[indx1] })

lst2[1:3]
#$`2012-12-01`
#[1] "2012-12-01 06:12:00 EST"
#
#$`2012-12-02`
#[1] "2012-12-02 00:40:00 EST"
#
#$`2012-12-03`
#[1] "2012-12-03 04:21:00 EST"
A.K.






________________________________
From: Ye Lin <yelin at lbl.gov>
To: arun <smartpink111 at yahoo.com> 
Sent: Thursday, June 13, 2013 1:11 PM
Subject: Re: [R] identify data points by certain criteria



hey Arun,

Sorry about the confusion. My intention to apply a simple sample is to simply the question and I can self-educate/modify on the code you provided and apply to my real data.

Here is how my real data looks like. It is 1 min data for entire month. I will focus on the time period from 0:00-08:00 everyday ( from midnight to 8am) and try to find out the timestamp meets the criteria I mentioned before.?

Thanks for your help!

Ye



On Thu, Jun 13, 2013 at 9:57 AM, arun <smartpink111 at yahoo.com> wrote:


>
>
>HI Ye,
>Could you provide an example that mimic your real dataset?? Because if I spend some time on this and it is not the case, then it is a waste of time.
>
>
>
>
>________________________________
>From: Ye Lin <yelin at lbl.gov>
>To: arun <smartpink111 at yahoo.com>
>Sent: Thursday, June 13, 2013 12:54 PM
>
>Subject: Re: [R] identify data points by certain criteria
>
>
>
>oh~sorry~
>
>its gonna be from 00:00-23:59 ~ 1 day range
>
>
>
>On Thu, Jun 13, 2013 at 9:42 AM, arun <smartpink111 at yahoo.com> wrote:
>
>
>>
>>Hi,
>>
>>I was talking about the timestamp itself.? I don't know the range of your timestamp.
>>
>>
>>indx[which.max(c(1,diff(as.numeric(gsub(".*:","",dat1[,1][indx])))))]
>>#[1] 10
>>
>>?dat1[indx[which.max(c(1,diff(as.numeric(gsub(".*:","",dat1[,1][indx])))))],]
>>#??? Time Var1 Var2
>>#10 00:09??? 0??? 0
>>A.K.
>>
>>________________________________
>>From: Ye Lin <yelin at lbl.gov>
>>To: arun <smartpink111 at yahoo.com>
>>Sent: Thursday, June 13, 2013 12:00 PM
>>Subject: Re: [R] identify data points by certain criteria
>>
>>
>>
>>
>>Basically what I am trying to do is to find out the first timestamp that meets the criteria, in other words "when does it happen"
>>
>>
>>
>>On Wed, Jun 12, 2013 at 6:29 PM, arun <smartpink111 at yahoo.com> wrote:
>>
>>Hi,
>>>Not clear about the 'Time' column.
>>>dat1<- read.table(text="
>>>
>>>Time??? Var1????? Var2
>>>00:00??? 1????????????? 0
>>>00:01??? 0????????????? 0
>>>00:02??? 1????????????? 0
>>>00:03??? 1????????????? 0
>>>00:04??? 0????????????? 0
>>>00:05??? 1????????????? 0
>>>00:06??? 1????????????? 0
>>>00:07??? 1????????????? 0
>>>00:08??? 1????????????? 0
>>>00:09??? 0????????????? 0
>>>00:10??? 1????????????? 0
>>>00:11??? 1????????????? 0
>>>00:12??? 1????????????? 0
>>>00:13??? 0????????????? 0
>>>",sep="",header=TRUE,stringsAsFactors=FALSE)
>>>
>>>
>>>indx<-which(rowSums(dat1[,-1])==0)
>>>dat1[indx[which.max(c(1,diff(as.numeric(gsub(".*:","",dat1[,1][indx])))))],]
>>>#??? Time Var1 Var2
>>>#10 00:09??? 0??? 0
>>>dat1[indx[which.max(c(1,diff(as.numeric(gsub(".*:","",dat1[,1][indx])))))],"Time"]
>>>#[1] "00:09"
>>>
>>>
>>>A.K.
>>>
>>>
>>>
>>>
>>>----- Original Message -----
>>>From: Ye Lin <yelin at lbl.gov>
>>>To: R help <r-help at r-project.org>
>>>Cc:
>>>Sent: Wednesday, June 12, 2013 8:55 PM
>>>Subject: [R] identify data points by certain criteria
>>>
>>>Hey I want to identify data points by criteria, here is an example of my
>>>1min data
>>>
>>>Time? ? ?Var1? ? ? Var2
>>>00:00? ? 1? ? ? ? ? ? ? 0
>>>00:01? ? 0? ? ? ? ? ? ? 0
>>>00:02? ? 1? ? ? ? ? ? ? 0
>>>00:03? ? 1? ? ? ? ? ? ? 0
>>>00:04? ? 0? ? ? ? ? ? ? 0
>>>00:05? ? 1? ? ? ? ? ? ? 0
>>>00:06? ? 1? ? ? ? ? ? ? 0
>>>00:07? ? 1? ? ? ? ? ? ? 0
>>>00:08? ? 1? ? ? ? ? ? ? 0
>>>00:09? ? 0? ? ? ? ? ? ? 0
>>>00:10? ? 1? ? ? ? ? ? ? 0
>>>00:11? ? 1? ? ? ? ? ? ? 0
>>>00:12? ? 1? ? ? ? ? ? ? 0
>>>00:13? ? 0? ? ? ? ? ? ? 0
>>>
>>>I want to identify the data points where Var1=0 and Var2=0, ( in this
>>>example shud be the points highlighted above), then calculate the time
>>>duration between these data points, (in this example, shud be 3min, 5 min
>>>and 4min), then identify the starting point of the max time duration ( in
>>>this example shud be the starting point of 5-min-duration, return the data
>>>points at 00:09), finally return the value in "Time" column ( in this
>>>example shud be "00:09")
>>>
>>>Thanks for your help!
>>>
>>>
>>>??? [[alternative HTML version deleted]]
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>


From lorenzo.isella at gmail.com  Thu Jun 13 22:49:21 2013
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Thu, 13 Jun 2013 22:49:21 +0200
Subject: [R] Linear Model with Discrete Data
Message-ID: <op.wymxgjn9zqkd1e@paperasse>

Dear All,
I am struggling with a linear model and an allegedly trivial data set.
The data set does not consist of categorical variables, but rather of  
numerical discrete variables (essentially, they count the number of times  
that something happened).
Can I still use a standard linear regression, i.e. something like lm(y~x)?
I attach a small snippet that illustrates the difficulties that I am  
experiencing (I do not understand why R complains about a list()).
Any suggestion is appreciated.
The data file can be downloaded from

http://db.tt/hEKv1wH2

Cheers

Lorenzo


#####################################

data <- read.csv("testData.csv", header=TRUE)


data <- subset(data,select= -c (X100, X182))


y <- data$X358

z <- subset(data, select=-c(X358))

myLM <- lm(y~z)


#####################


From gunter.berton at gene.com  Thu Jun 13 23:21:34 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 13 Jun 2013 14:21:34 -0700
Subject: [R] Linear Model with Discrete Data
In-Reply-To: <op.wymxgjn9zqkd1e@paperasse>
References: <op.wymxgjn9zqkd1e@paperasse>
Message-ID: <CACk-te3QgVyu0kGnga-VRnAi6D2uKJ_UDv06XoWBAYanDB0hmA@mail.gmail.com>

Lorenzo:

1. This is a statistics question, not an R question.

2. Your statistical background appears inadequate  -- it looks like
Poisson regression, which would fall under "generalized linear
models". But it depends on how "discrete" discrete is (on some level,
all measurements are discrete, discretized to the resolution of the
measurement process).

3. So I would advise seeking local statistical help. Getting
statistical advice remotely over the internet (even on a proper forum
for statistical advice, which this is not) is fraught with hazard and
the risk of bad science (not due to incompetence or maliciousness;
just due to the possibilities of misunderstanding and confusion) --
imho only, of course.

Of course, feel free to reject this and proceed at your own risk.

Cheers,
Bert



On Thu, Jun 13, 2013 at 1:49 PM, Lorenzo Isella
<lorenzo.isella at gmail.com> wrote:
> Dear All,
> I am struggling with a linear model and an allegedly trivial data set.
> The data set does not consist of categorical variables, but rather of
> numerical discrete variables (essentially, they count the number of times
> that something happened).
> Can I still use a standard linear regression, i.e. something like lm(y~x)?
> I attach a small snippet that illustrates the difficulties that I am
> experiencing (I do not understand why R complains about a list()).
> Any suggestion is appreciated.
> The data file can be downloaded from
>
> http://db.tt/hEKv1wH2
>
> Cheers
>
> Lorenzo
>
>
> #####################################
>
> data <- read.csv("testData.csv", header=TRUE)
>
>
> data <- subset(data,select= -c (X100, X182))
>
>
> y <- data$X358
>
> z <- subset(data, select=-c(X358))
>
> myLM <- lm(y~z)
>
>
> #####################
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From michael.weylandt at gmail.com  Thu Jun 13 23:27:45 2013
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Thu, 13 Jun 2013 22:27:45 +0100
Subject: [R] set.seed(x)
In-Reply-To: <51BA0223.5080201@gmail.com>
References: <92FD11F467D9CA41A8AEA01FE4D76DEB0AC6CA85@EX02.platinum.com>
	<51BA0223.5080201@gmail.com>
Message-ID: <7165C467-37F9-4981-B64E-82DFAB50CA2D@gmail.com>



On Jun 13, 2013, at 18:32, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 13/06/2013 11:59 AM, Pooya Lalehzari wrote:
>> Hello,
>> If I use set.seed(x) to set a seed for the random number generator, how can I undo that to revert a random output every time I run my code?
> 
> If you remove .Random.seed, then the next time a seed is needed it will be generated from the system clock, so it will appear random.

Also, in recent versions of R (>= 3.0.0 I believe) set.seed(NULL) will do the same. 

MW


> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tmrsg11 at gmail.com  Thu Jun 13 23:59:32 2013
From: tmrsg11 at gmail.com (C W)
Date: Thu, 13 Jun 2013 17:59:32 -0400
Subject: [R] set.seed(x)
In-Reply-To: <7165C467-37F9-4981-B64E-82DFAB50CA2D@gmail.com>
References: <92FD11F467D9CA41A8AEA01FE4D76DEB0AC6CA85@EX02.platinum.com>
	<51BA0223.5080201@gmail.com>
	<7165C467-37F9-4981-B64E-82DFAB50CA2D@gmail.com>
Message-ID: <CAE2FW2k0ca45umW+unnDzijWhoc5bfFRxnZHCyMSyy6KVtyfQg@mail.gmail.com>

I asked a similar question earlier in the year,
http://r.789695.n4.nabble.com/How-to-stop-set-seed-besides-exiting-out-of-R-td4661717.html

I liked this solution from William,
> rm(list=".Random.seed", envir=globalenv())

Mike

On Thu, Jun 13, 2013 at 5:27 PM, Michael Weylandt
<michael.weylandt at gmail.com> wrote:
>
>
> On Jun 13, 2013, at 18:32, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
>> On 13/06/2013 11:59 AM, Pooya Lalehzari wrote:
>>> Hello,
>>> If I use set.seed(x) to set a seed for the random number generator, how can I undo that to revert a random output every time I run my code?
>>
>> If you remove .Random.seed, then the next time a seed is needed it will be generated from the system clock, so it will appear random.
>
> Also, in recent versions of R (>= 3.0.0 I believe) set.seed(NULL) will do the same.
>
> MW
>
>
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From santosh2005 at gmail.com  Fri Jun 14 01:16:38 2013
From: santosh2005 at gmail.com (Santosh)
Date: Thu, 13 Jun 2013 16:16:38 -0700
Subject: [R] Using tables package - request for help
Message-ID: <CAN_e6XtECKp_-5a6_WLGuvXT_TK+7qCEjp6QRHXx9Qqw3JP2FA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130613/b89fb9f8/attachment.pl>

From santosh2005 at gmail.com  Fri Jun 14 01:28:51 2013
From: santosh2005 at gmail.com (Santosh)
Date: Thu, 13 Jun 2013 16:28:51 -0700
Subject: [R] Using tables package - request for help
In-Reply-To: <CAN_e6XtECKp_-5a6_WLGuvXT_TK+7qCEjp6QRHXx9Qqw3JP2FA@mail.gmail.com>
References: <CAN_e6XtECKp_-5a6_WLGuvXT_TK+7qCEjp6QRHXx9Qqw3JP2FA@mail.gmail.com>
Message-ID: <CAN_e6XudqCGLpPkx6gOTDSdaa4RK-Kc_6VLYiNAGfLSnV=-kpQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130613/01715c98/attachment.pl>

From dwinsemius at comcast.net  Fri Jun 14 02:00:46 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 13 Jun 2013 17:00:46 -0700
Subject: [R] Linear Model with Discrete Data
In-Reply-To: <CACk-te3QgVyu0kGnga-VRnAi6D2uKJ_UDv06XoWBAYanDB0hmA@mail.gmail.com>
References: <op.wymxgjn9zqkd1e@paperasse>
	<CACk-te3QgVyu0kGnga-VRnAi6D2uKJ_UDv06XoWBAYanDB0hmA@mail.gmail.com>
Message-ID: <39C40E47-AA71-462D-9480-FD3F9619D846@comcast.net>


On Jun 13, 2013, at 2:21 PM, Bert Gunter wrote:

> Lorenzo:
> 
> 1. This is a statistics question, not an R question.
> 
> 2. Your statistical background appears inadequate  -- it looks like
> Poisson regression, which would fall under "generalized linear
> models". But it depends on how "discrete" discrete is (on some level,
> all measurements are discrete, discretized to the resolution of the
> measurement process).

There is an excellent R vignette on handling count data by authors: Achim Zeileis, Christian Kleiber, Simon Jackman. Easy to find with a Google search.

There's also a somewhat older but possibly useful resource a set of worked S/R examples to accompany Agresti's text on categorical data by Laura Thompson. Alsi easy to find on Google.

-- 
David.
> 
> 3. So I would advise seeking local statistical help. Getting
> statistical advice remotely over the internet (even on a proper forum
> for statistical advice, which this is not) is fraught with hazard and
> the risk of bad science (not due to incompetence or maliciousness;
> just due to the possibilities of misunderstanding and confusion) --
> imho only, of course.
> 
> Of course, feel free to reject this and proceed at your own risk.
> 
> Cheers,
> Bert
> 
> 
> 
> On Thu, Jun 13, 2013 at 1:49 PM, Lorenzo Isella
> <lorenzo.isella at gmail.com> wrote:
>> Dear All,
>> I am struggling with a linear model and an allegedly trivial data set.
>> The data set does not consist of categorical variables, but rather of
>> numerical discrete variables (essentially, they count the number of times
>> that something happened).
>> Can I still use a standard linear regression, i.e. something like lm(y~x)?
>> I attach a small snippet that illustrates the difficulties that I am
>> experiencing (I do not understand why R complains about a list()).
>> Any suggestion is appreciated.
>> The data file can be downloaded from
>> 
>> http://db.tt/hEKv1wH2
>> 
>> Cheers
>> 
>> Lorenzo
>> 
>> 
>> #####################################
>> 
>> data <- read.csv("testData.csv", header=TRUE)
>> 
>> 
>> data <- subset(data,select= -c (X100, X182))
>> 
>> 
>> y <- data$X358
>> 
>> z <- subset(data, select=-c(X358))
>> 
>> myLM <- lm(y~z)
>> 
>> 
>> #####################
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> 
> Internal Contact Info:
> Phone: 467-7374
> Website:
> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From imvinhs at yahoo.com.vn  Fri Jun 14 01:36:48 2013
From: imvinhs at yahoo.com.vn (vinhnguyen04x)
Date: Thu, 13 Jun 2013 16:36:48 -0700 (PDT)
Subject: [R] odds ratio per standard deviation
In-Reply-To: <8D1D0E26-9CE8-4EDF-9EFE-520F651712D0@comcast.net>
References: <1371001120339-4669315.post@n4.nabble.com>
	<CAFEqCdysEi4EFqjZ1bNcwVtU_ORVD2FWmW7kNcv=UOputSO9Qw@mail.gmail.com>
	<XFMail.20130612171403.Ted.Harding@wlandres.net>
	<1371081504325-4669411.post@n4.nabble.com>
	<8D1D0E26-9CE8-4EDF-9EFE-520F651712D0@comcast.net>
Message-ID: <1371166608844-4669501.post@n4.nabble.com>

Thanks, David, I appreciate your help.



--
View this message in context: http://r.789695.n4.nabble.com/odds-ratio-per-standard-deviation-tp4669315p4669501.html
Sent from the R help mailing list archive at Nabble.com.


From totangjie at gmail.com  Fri Jun 14 03:50:14 2013
From: totangjie at gmail.com (Jie Tang)
Date: Fri, 14 Jun 2013 09:50:14 +0800
Subject: [R] How to get a running mean result by R?
In-Reply-To: <51B84F73.2000802@sapo.pt>
References: <CAMUSh4q+tk964zPa60_6uuuGXf7YXY=hoPfCzfjhEC7Lxed7pQ@mail.gmail.com>
	<51B84F73.2000802@sapo.pt>
Message-ID: <CAMUSh4odjrHfMDb+0eWZsiUJrV0yt4+zKJUNX8b7xJ4te6Wwnw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130614/afbb4018/attachment.pl>

From smartpink111 at yahoo.com  Fri Jun 14 04:21:52 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 13 Jun 2013 19:21:52 -0700 (PDT)
Subject: [R] identify data points by certain criteria
In-Reply-To: <1371175479.61348.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <CAAvu=b==j0f8rYobAZgYHVfPvQ29w+Cnk-FQA6cCWji-Jy5pZg@mail.gmail.com>
	<1371086966.86860.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CAAvu=bnKRbWck2JD1kTgPFsS6XYAsbBH0nobzyuQkLbXgXruqw@mail.gmail.com>
	<1371141769.16551.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CAAvu=bmsJKasZ8nUv7d81p37AK63bVrM3kC=GiJwa=hrndQUSQ@mail.gmail.com>
	<1371142631.42822.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CAAvu=bmUYmWLobPnQR==VQQwwnip_Ct+JVd5kpR7URe+1Oj=gQ@mail.gmail.com>
	<1371154524.46060.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1371154689.22949.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CAAvu=bn+2Dum=zgUyEP1updh_NFKhkSGXxbOr2gcoPBc0o8KzA@mail.gmail.com>
	<1371167904.91959.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CAAvu=bm5Y28KVFRXjKPEREMFPscjUA6Py5BAGoeQeQcFZ-VZZw@mail.gmail.com>
	<1371175479.61348.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1371176512.21206.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
Check if this works for you:
source("Ye_data.txt")
?dim(dat1)
library(xts)
?xt1<- xts(dat1[,-1],strptime(dat1[,1],"%m/%d/%Y %H:%M"))
xtSub<-xt1["T00:00:00/T08:00:00"]
lst1<-split(xtSub,as.Date(index(xtSub)))
res<- do.call(rbind,lapply(lst1,function(x){indx<- which(rowSums(x)==0);x[indx[which.max(c(diff(indx),0))],]}))
tail(res)

? # ????????????????? Var1 Var2
#2012-12-26 03:49:00??? 0??? 0
#2012-12-27 02:24:00??? 0??? 0
#2012-12-28 06:13:00??? 0??? 0
#2012-12-29 02:02:00??? 0??? 0
#2012-12-30 06:37:00??? 0??? 0
#2012-12-31 07:07:00??? 0??? 0
A.K.


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Ye Lin <yelin at lbl.gov>
Cc: 
Sent: Thursday, June 13, 2013 10:04 PM
Subject: Re: [R] identify data points by certain criteria




"""
e.g. 12/31, the time period where sum(Var1+Var2)=0 are:

?from 00:00:00 to 00:55:00 (55 min)

from 01:07:00 to 07:07:00 ? (6h=360min)
from 07:43:00 to 08:00:00 ? (17min)

then when apply "sapply(lst1,function(x) {indx <- 
which(rowSums(x)==0);indx1 <- 
which.max(c(1,diff(index(x)[indx])))})", for 12/31 it should return 360 
and 01:07:00

"""

I was trying to understand what you meant by 55 min and 360 min in this case: here, the rows from 1:07:00 to 07:07:00 are zero's for Var1 and Var2.? So, the difference should be 1,1,1,........................1 instead of 55, and 360.? If the 01:07:00 row had both the rows==0 and then all the rows until 07:07:00 have either one of the variables>0, then the difference should 360.? Do you think so?

________________________________
From: Ye Lin <yelin at lbl.gov>
To: arun <smartpink111 at yahoo.com> 
Sent: Thursday, June 13, 2013 8:14 PM
Subject: Re: [R] identify data points by certain criteria



Thanks so much Arun! I feel bad that I take up your spare time though.....

Yes you are right, I dont know what happened to my brain when I typed up the question...It shud return the starting point of max duration of (Var1=0 and Var2=0)






On Thu, Jun 13, 2013 at 4:58 PM, arun <smartpink111 at yahoo.com> wrote:

HI Ye,
>
>I will look it later when I get back to home.
>But before, that let me go back to your dummy dataset.
>
>dat2<-read.table(text="
>
>Time??? Var1????? Var2
>00:00??? 1????????????? 0
>00:01??? 0????????????? 0
>00:02??? 1????????????? 0
>00:03??? 1????????????? 0
>00:04??? 0????????????? 0
>00:05??? 1????????????? 0
>00:06??? 1????????????? 0
>00:07??? 1????????????? 0
>00:08??? 1????????????? 0
>00:09??? 0????????????? 0
>00:10??? 1????????????? 0
>00:11??? 1????????????? 0
>00:12??? 1????????????? 0
>00:13??? 0????????????? 0
>",sep="",header=TRUE,stringsAsFactors=FALSE)
>
>
>##Your question:
>
>>>>>I want to identify the data points where Var1=0 and Var2=0, ( in this
>>>>>example shud be the points highlighted above), then calculate the time
>>>>>duration between these data points, (in this example, shud be 3min, 5 min
>>>>>and 4min), then identify the starting point of the max time duration ( in
>>>>>this example shud be the starting point of 5-min-duration, return the data
>>>>>points at 00:09), finally return the value in "Time" column ( in this
>>>>>example shud be "00:09")
>
>
>?indx<- which(rowSums(dat2[,-1])==0)
>?indx
>#[1]? 2? 5 10 14
>###According to this, the starting point of the max time duration is 00:04
>
>
>?dat2[indx[which.max(c(diff(as.numeric(gsub(".*:","",dat2[,1][indx]))),0))],]
>#?? Time Var1 Var2
>#5 00:04??? 0??? 0
>
>
>Let us clear this first before going to the real dataset.
>
>
>
>
>________________________________
>From: Ye Lin <yelin at lbl.gov>
>To: arun <smartpink111 at yahoo.com>
>Sent: Thursday, June 13, 2013 7:21 PM
>
>Subject: Re: [R] identify data points by certain criteria
>
>
>
>Hey Arun,
>
>The code doesnt return the correct timastamp index.?
>
>e.g. 12/31, the time period where sum(Var1+Var2)=0 are:
>
>?from 00:00:00 to 00:55:00 (55 min)
>
>from 01:07:00 to 07:07:00 ? (6h=360min)
>from 07:43:00 to 08:00:00 ? (17min)
>
>then when apply "sapply(lst1,function(x) {indx <- which(rowSums(x)==0);indx1 <- which.max(c(1,diff(index(x)[indx])))})", for 12/31 it should return 360 and 01:07:00
>
>however, it returns:
>
>> sapply(lst1,function(x) {indx <- which(rowSums(x)==0);indx1 <- which.max(c(1,diff(index(x)[indx])))})
>2012-12-01 2012-12-02 2012-12-03 2012-12-04 2012-12-05 2012-12-06 2012-12-07?
>? ? ? ?373 ? ? ? ? 41 ? ? ? ?262 ? ? ? ?268 ? ? ? ?266 ? ? ? ?254 ? ? ? ?274?
>2012-12-08 2012-12-09 2012-12-10 2012-12-11 2012-12-12 2012-12-13 2012-12-14?
>? ? ? ?109 ? ? ? ? ?1 ? ? ? ?323 ? ? ? ?264 ? ? ? ?279 ? ? ? ?353 ? ? ? ?265?
>2012-12-15 2012-12-16 2012-12-17 2012-12-18 2012-12-19 2012-12-20 2012-12-21?
>? ? ? ?327 ? ? ? ?226 ? ? ? ?264 ? ? ? ?269 ? ? ? ?271 ? ? ? ?267 ? ? ? ?276?
>2012-12-22 2012-12-23 2012-12-24 2012-12-25 2012-12-26 2012-12-27 2012-12-28?
>? ? ? ?360 ? ? ? ?162 ? ? ? ?222 ? ? ? ? 81 ? ? ? ?231 ? ? ? ?143 ? ? ? ?364?
>2012-12-29 2012-12-30 2012-12-31?
>? ? ? ?122 ? ? ? ?399 ? ? ? ?418
>
>
>>lst2 <- lapply(lst1,function(x) {indx <- which(rowSums(x)==0);indx1 <- which.max(c(1,diff(index(x)[indx])));index(x)[indx1] })
>
>$`2012-12-31`
>[1] "2012-12-31 06:57:00 PST"
>
>12/31 data:
>2012-12-31 00:00:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:01:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:02:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:03:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:04:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:05:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:06:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:07:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:08:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:09:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:10:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:11:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:12:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:13:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:14:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:15:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:16:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:17:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:18:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:19:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:20:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:21:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:22:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:23:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:24:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:25:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:26:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:27:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:28:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:29:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:30:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:31:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:32:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:33:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:34:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:35:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:36:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:37:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:38:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:39:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:40:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:41:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:42:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:43:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:44:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:45:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:46:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:47:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:48:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:49:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:50:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:51:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:52:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:53:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:54:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:55:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 00:56:00 ? ? ? ? ? ?1.690 ? ? ?0.00
>2012-12-31 00:57:00 ? ? ? ? ? ?2.324 ? ? ?0.00
>2012-12-31 00:58:00 ? ? ? ? ? ?2.318 ? ? ?0.00
>2012-12-31 00:59:00 ? ? ? ? ? ?2.308 ? ? ?0.00
>2012-12-31 01:00:00 ? ? ? ? ? ?2.303 ? ? ?0.00
>2012-12-31 01:01:00 ? ? ? ? ? ?2.300 ? ? ?0.00
>2012-12-31 01:02:00 ? ? ? ? ? ?2.324 ? ? ?0.00
>2012-12-31 01:03:00 ? ? ? ? ? ?2.333 ? ? ?0.00
>2012-12-31 01:04:00 ? ? ? ? ? ?2.335 ? ? ?0.00
>2012-12-31 01:05:00 ? ? ? ? ? ?2.334 ? ? ?0.00
>2012-12-31 01:06:00 ? ? ? ? ? ?2.258 ? ? ?0.00
>2012-12-31 01:07:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:08:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:09:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:10:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:11:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:12:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:13:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:14:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:15:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:16:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:17:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:18:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:19:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:20:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:21:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:22:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:23:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:24:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:25:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:26:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:27:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:28:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:29:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:30:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:31:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:32:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:33:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:34:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:35:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:36:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:37:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:38:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:39:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:40:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:41:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:42:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:43:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:44:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:45:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:46:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:47:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:48:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:49:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:50:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:51:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:52:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:53:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:54:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:55:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:56:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:57:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:58:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 01:59:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:00:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:01:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:02:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:03:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:04:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:05:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:06:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:07:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:08:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:09:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:10:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:11:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:12:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:13:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:14:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:15:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:16:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:17:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:18:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:19:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:20:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:21:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:22:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:23:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:24:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:25:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:26:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:27:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:28:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:29:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:30:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:31:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:32:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:33:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:34:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:35:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:36:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:37:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:38:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:39:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:40:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:41:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:42:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:43:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:44:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:45:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:46:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:47:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:48:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:49:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:50:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:51:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:52:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:53:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:54:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:55:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:56:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:57:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:58:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 02:59:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:00:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:01:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:02:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:03:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:04:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:05:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:06:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:07:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:08:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:09:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:10:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:11:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:12:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:13:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:14:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:15:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:16:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:17:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:18:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:19:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:20:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:21:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:22:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:23:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:24:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:25:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:26:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:27:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:28:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:29:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:30:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:31:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:32:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:33:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:34:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:35:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:36:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:37:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:38:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:39:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:40:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:41:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:42:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:43:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:44:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:45:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:46:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:47:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:48:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:49:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:50:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:51:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:52:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:53:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:54:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:55:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:56:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:57:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:58:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 03:59:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:00:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:01:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:02:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:03:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:04:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:05:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:06:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:07:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:08:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:09:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:10:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:11:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:12:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:13:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:14:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:15:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:16:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:17:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:18:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:19:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:20:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:21:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:22:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:23:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:24:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:25:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:26:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:27:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:28:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:29:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:30:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:31:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:32:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:33:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:34:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:35:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:36:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:37:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:38:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:39:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:40:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:41:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:42:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:43:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:44:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:45:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:46:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:47:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:48:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:49:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:50:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:51:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:52:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:53:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:54:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:55:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:56:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:57:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:58:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 04:59:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:00:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:01:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:02:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:03:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:04:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:05:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:06:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:07:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:08:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:09:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:10:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:11:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:12:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:13:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:14:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:15:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:16:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:17:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:18:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:19:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:20:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:21:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:22:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:23:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:24:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:25:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:26:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:27:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:28:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:29:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:30:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:31:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:32:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:33:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:34:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:35:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:36:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:37:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:38:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:39:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:40:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:41:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:42:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:43:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:44:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:45:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:46:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:47:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:48:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:49:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:50:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:51:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:52:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:53:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:54:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:55:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:56:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:57:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:58:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 05:59:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:00:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:01:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:02:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:03:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:04:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:05:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:06:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:07:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:08:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:09:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:10:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:11:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:12:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:13:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:14:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:15:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:16:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:17:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:18:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:19:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:20:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:21:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:22:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:23:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:24:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:25:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:26:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:27:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:28:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:29:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:30:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:31:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:32:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:33:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:34:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:35:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:36:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:37:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:38:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:39:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:40:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:41:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:42:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:43:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:44:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:45:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:46:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:47:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:48:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:49:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:50:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:51:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:52:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:53:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:54:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:55:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:56:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:57:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:58:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 06:59:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 07:00:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 07:01:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 07:02:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 07:03:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 07:04:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 07:05:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 07:06:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 07:07:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 07:08:00 ? ? ? ? ? ?0.410 ? ? ?0.00
>2012-12-31 07:09:00 ? ? ? ? ? ?2.289 ? ? ?0.00
>2012-12-31 07:10:00 ? ? ? ? ? ?2.305 ? ? ?0.00
>2012-12-31 07:11:00 ? ? ? ? ? ?2.303 ? ? ?0.00
>2012-12-31 07:12:00 ? ? ? ? ? ?2.301 ? ? ?0.00
>2012-12-31 07:13:00 ? ? ? ? ? ?2.296 ? ? ?0.00
>2012-12-31 07:14:00 ? ? ? ? ? ?2.296 ? ? ?0.00
>2012-12-31 07:15:00 ? ? ? ? ? ?2.299 ? ? ?0.00
>2012-12-31 07:16:00 ? ? ? ? ? ?2.296 ? ? ?0.00
>2012-12-31 07:17:00 ? ? ? ? ? ?2.297 ? ? ?0.00
>2012-12-31 07:18:00 ? ? ? ? ? ?2.298 ? ? ?0.00
>2012-12-31 07:19:00 ? ? ? ? ? ?2.301 ? ? ?0.00
>2012-12-31 07:20:00 ? ? ? ? ? ?2.302 ? ? ?0.00
>2012-12-31 07:21:00 ? ? ? ? ? ?2.304 ? ? ?0.00
>2012-12-31 07:22:00 ? ? ? ? ? ?2.296 ? ? ?0.00
>2012-12-31 07:23:00 ? ? ? ? ? ?2.281 ? ? ?0.00
>2012-12-31 07:24:00 ? ? ? ? ? ?2.270 ? ? ?0.00
>2012-12-31 07:25:00 ? ? ? ? ? ?2.267 ? ? ?0.00
>2012-12-31 07:26:00 ? ? ? ? ? ?2.257 ? ? ?0.00
>2012-12-31 07:27:00 ? ? ? ? ? ?2.258 ? ? ?0.00
>2012-12-31 07:28:00 ? ? ? ? ? ?2.261 ? ? ?0.00
>2012-12-31 07:29:00 ? ? ? ? ? ?2.263 ? ? ?0.00
>2012-12-31 07:30:00 ? ? ? ? ? ?2.261 ? ? ?0.00
>2012-12-31 07:31:00 ? ? ? ? ? ?2.259 ? ? ?0.00
>2012-12-31 07:32:00 ? ? ? ? ? ?2.267 ? ? ?0.00
>2012-12-31 07:33:00 ? ? ? ? ? ?2.288 ? ? ?0.00
>2012-12-31 07:34:00 ? ? ? ? ? ?2.284 ? ? ?0.00
>2012-12-31 07:35:00 ? ? ? ? ? ?2.284 ? ? ?0.00
>2012-12-31 07:36:00 ? ? ? ? ? ?2.287 ? ? ?0.00
>2012-12-31 07:37:00 ? ? ? ? ? ?2.285 ? ? ?0.00
>2012-12-31 07:38:00 ? ? ? ? ? ?2.305 ? ? ?0.00
>2012-12-31 07:39:00 ? ? ? ? ? ?2.307 ? ? ?0.00
>2012-12-31 07:40:00 ? ? ? ? ? ?2.308 ? ? ?0.00
>2012-12-31 07:41:00 ? ? ? ? ? ?2.307 ? ? ?0.00
>2012-12-31 07:42:00 ? ? ? ? ? ?1.631 ? ? ?0.00
>2012-12-31 07:43:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 07:44:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 07:45:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 07:46:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 07:47:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 07:48:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 07:49:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 07:50:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 07:51:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 07:52:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 07:53:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 07:54:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 07:55:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 07:56:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 07:57:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 07:58:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 07:59:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>2012-12-31 08:00:00 ? ? ? ? ? ?0.000 ? ? ?0.00
>
>I have no clue why it returns index list like that as the code looks fine with me, could you help me with this?
>


From entropy053 at gmail.com  Fri Jun 14 06:51:57 2013
From: entropy053 at gmail.com (Yasin Gocgun)
Date: Fri, 14 Jun 2013 00:51:57 -0400
Subject: [R] merging data frames
Message-ID: <CAJJuoESfw6QHf=3J3sYOgwfBtjgZi9hP1AsJsmQHu8VdLGHDVg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130614/1aaf12fe/attachment.pl>

From simolas2008 at gmail.com  Fri Jun 14 07:14:27 2013
From: simolas2008 at gmail.com (Simonas Kecorius)
Date: Fri, 14 Jun 2013 07:14:27 +0200
Subject: [R] Problem with Get_map getting maps without country name
Message-ID: <CAHR3agoA476BVSQP4Tes70ej3V7b+VQfMUytTsOaQyg1eyEAww@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130614/88d167a7/attachment.pl>

From miaojpm at gmail.com  Fri Jun 14 08:18:34 2013
From: miaojpm at gmail.com (jpm miao)
Date: Fri, 14 Jun 2013 14:18:34 +0800
Subject: [R] Problems with R package building
Message-ID: <CABcx46Aes7E_FGNrhmXhq+Y2ziO5eT+2xUB7viv7qDQHP=+XjA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130614/77a88196/attachment.pl>

From entropy053 at gmail.com  Fri Jun 14 08:26:35 2013
From: entropy053 at gmail.com (Yasin Gocgun)
Date: Fri, 14 Jun 2013 02:26:35 -0400
Subject: [R] merging data frames
In-Reply-To: <CAJJuoESfw6QHf=3J3sYOgwfBtjgZi9hP1AsJsmQHu8VdLGHDVg@mail.gmail.com>
References: <CAJJuoESfw6QHf=3J3sYOgwfBtjgZi9hP1AsJsmQHu8VdLGHDVg@mail.gmail.com>
Message-ID: <CAJJuoETM46SR94DjXs5Kt0ec1v3N11-K3nrFUczd+wCZGAYCkA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130614/bee978f2/attachment.pl>

From jholtman at gmail.com  Fri Jun 14 08:26:55 2013
From: jholtman at gmail.com (Jim Holtman)
Date: Fri, 14 Jun 2013 02:26:55 -0400
Subject: [R] merging data frames
In-Reply-To: <CAJJuoESfw6QHf=3J3sYOgwfBtjgZi9hP1AsJsmQHu8VdLGHDVg@mail.gmail.com>
References: <CAJJuoESfw6QHf=3J3sYOgwfBtjgZi9hP1AsJsmQHu8VdLGHDVg@mail.gmail.com>
Message-ID: <0B595BCF-296A-4D09-A17D-BF3814DA58EA@gmail.com>

?merge

Sent from my iPad

On Jun 14, 2013, at 0:51, Yasin Gocgun <entropy053 at gmail.com> wrote:

> Hi,
> 
> I have been struggling with the issue of merging data frames that have
> common columns and have different dimensions. Although I made alot of
> search about it on internet, I could not find any function that would
> efficiently perform the required operation. So I would appreciate if anyone
> knowing how to resolve the problem would explain me the solution.
> 
> As you will see, the below data frames have one common column (they would
> have multiple common columns in general), and I simply want to create a
> table that is the union of A and B, say table C. So the first row of C must
> include all the necessary info about the person with the respective COMPID,
> which is provided in A and B.
> 
> A:
> COMPID CLR_DOT CA_TYPE CA_YEAR DT_FNDNG DT_BIOP NORMAL  1030956 XXGRX P 10
> 19890919 19890919 0  2511425 XXXRX T 6 19891005 19891030 0  3205129 XXGRX T
> 8 19900227 19900227 0 ...
> 
> B:
> COMPID CNTR_ALL ALLOC AG_GRCAL ENRL_DT EXP_SCR  1000012 0 NO 1 19800122 5
> 1000021 0 NO 2 19800121 5  1000030 0 NO 3 19800121 5  1000049 0 NO 4
> 19800121 5 ...
> 
> I tried rbind.fill but it did not work. I am aware that such operations can
> be done in SAS in a minute, so I thought R should be as efficient as SAS in
> performing such operations...
> 
> Thank you in advance,
> 
> Yasin
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rn27in at gmail.com  Fri Jun 14 08:43:48 2013
From: rn27in at gmail.com (rn27in .)
Date: Fri, 14 Jun 2013 12:13:48 +0530
Subject: [R] Need help on creating Adjacency matrix in R
Message-ID: <CA+0+WdL1E2xk1KL2GfOEhN7Qz7m4MgbTedW0pFG-XeHru0eHPw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130614/502c7983/attachment.pl>

From michael.weylandt at gmail.com  Fri Jun 14 09:10:13 2013
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Fri, 14 Jun 2013 08:10:13 +0100
Subject: [R] Problems with R package building
In-Reply-To: <CABcx46Aes7E_FGNrhmXhq+Y2ziO5eT+2xUB7viv7qDQHP=+XjA@mail.gmail.com>
References: <CABcx46Aes7E_FGNrhmXhq+Y2ziO5eT+2xUB7viv7qDQHP=+XjA@mail.gmail.com>
Message-ID: <73D195CC-66CB-47D2-9116-A29244061166@gmail.com>



On Jun 14, 2013, at 7:18, jpm miao <miaojpm at gmail.com> wrote:

> Hi,
> 
>  I try to build a toy package by running the following codes in an R
> program
> 
> require(stats)
> f <- function(x,y) x+y
> g <- function(x,y) x-y
> d <- data.frame(a=1, b=2)
> e <- rnorm(1000)
> package.skeleton(list=c("f","g","d","e"), name="test1pkg",
> path="D:/R/pkgtest")
> 
>   Then the program runs smoothly
> 
> Creating directories ...
> Creating DESCRIPTION ...
> Creating NAMESPACE ...
> Creating Read-and-delete-me ...
> Saving functions and data ...
> Making help files ...
> Done.
> Further steps are described in 'D:/R/pkgtest/test1pkg/Read-and-delete-me'.
> 
>    Since it is a test, I skip all the documentation work and then type
> this line:
> 
>> R CMD build test1pkg
> Error: unexpected symbol in "R CMD"
> 
>   I check on the web about the error message. It's said that the command
> should be typed in a DOS window (command prompt window?). However it does
> not work  in my DOS window either. Could someone tell me how to process the
> package building process?
> 

Have you installed the Windows Rtools from CRAN and made sure your PATH is set properly?

MW


>   Thanks,
> 
> Miao
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From totangjie at gmail.com  Fri Jun 14 09:27:17 2013
From: totangjie at gmail.com (Jie Tang)
Date: Fri, 14 Jun 2013 15:27:17 +0800
Subject: [R] how to output the data array without colname and row number
Message-ID: <CAMUSh4oxXY+31b5Fy1MUp21HeL1Umo=hiHjTpZU7hSx7WhGn+g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130614/b863f8b1/attachment.pl>

From jholtman at gmail.com  Fri Jun 14 09:32:33 2013
From: jholtman at gmail.com (Jim Holtman)
Date: Fri, 14 Jun 2013 03:32:33 -0400
Subject: [R] how to output the data array without colname and row number
In-Reply-To: <CAMUSh4oxXY+31b5Fy1MUp21HeL1Umo=hiHjTpZU7hSx7WhGn+g@mail.gmail.com>
References: <CAMUSh4oxXY+31b5Fy1MUp21HeL1Umo=hiHjTpZU7hSx7WhGn+g@mail.gmail.com>
Message-ID: <595DD860-0159-4438-8FF6-39E155E50882@gmail.com>

how about reading the help file on 'write.table' and look at row.names and col.names.

Sent from my iPad

On Jun 14, 2013, at 3:27, Jie Tang <totangjie at gmail.com> wrote:

> hi r users:
>  I have a datadset and want to write into a file .
> 
> when i use :
> write.table(u_bar, file = "u_test.txt")
> 
> the data in the outpuf file is shown as below which included the
> row number from "1" to "14" and colname .e.g."X32N"
> 
> How could I output the numbers and excluded the colname and row number?
> 
> thank you .
> 
> "X32N" "X60N" "X89N" "X139N" "X179N" "X212N" "X263N" "X298N" "X32S" "X60S"
> "X89S" "X139S" "X179S" "X212S" "X263S" "X298S"
> "1" 5 4.3 4.3 5.9 7.8 4.9 6.4 4.4 5.4 5 4.7 5 " NAN" 7.4 2.3 4.4
> "2" 4.7 4.3 4.3 5.9 9.4 4.8 6.4 4.4 7 5 5.5 5 " NAN" 4.6 2.3 5
> "3" 4.7 4.6 5.2 4.9 9.4 4.8 5.2 5 7 5.1 5.5 5.9 " NAN" 4.6 2 5
> "4" 5 4.6 5.2 4.9 9.4 5.4 5.2 5 6.3 5.1 6.7 5.9 " NAN" 5.3 2 6.3
> "5" 5 5 6.2 4.2 9.4 5.4 7 6.3 6.3 2.4 6.7 6.2 " NAN" 5.3 5.2 6.3
> "6" 5.4 5 6.2 4.2 9.8 5.3 7 6.3 5.1 2.4 6.5 6.2 " NAN" 4.8 5.2 5.6
> "7" 5.4 3.9 6.5 5.4 9.8 5.3 7.3 5.6 5.1 1.7 6.5 6.2 " NAN" 4.8 2.3 5.6
> "8" 5.1 3.9 6.5 5.4 9.8 6.2 7.3 5.6 1.9 1.7 5.9 6.2 " NAN" 7.1 2.3 6.5
> "9" 5.1 3.8 7 5.9 9.8 6.2 6.3 6.5 1.9 1.9 5.9 5.8 " NAN" 7.1 -0.4 6.5
> "10" 5.3 3.8 7 5.9 9.4 6.1 6.3 6.5 7 1.9 6.4 5.8 " NAN" 2 -0.4 6.7
> "11" 5.3 5.2 5.6 6.6 9.4 6.1 5.9 6.7 7 7.8 6.4 4.6 " NAN" 2 0.4 6.7
> "12" 5.4 5.2 5.6 6.6 9.4 6.7 5.9 6.7 7.4 7.8 6.4 4.6 " NAN" 5.2 0.4 5.6
> "13" 5.4 5.9 5.3 5.8 9.4 6.7 7.4 5.6 7.4 5.6 6.4 4.4 " NAN" 5.2 0.2 5.6
> "14" 5.6 5.9 5.3 5.8 7.8 7 7.4 5.6 5.9 5.6 7.6 4.4 " NAN" 4.3 0.2 7.6
> 
> -- 
> TANG Jie
> Email: totangjie at gmail.com
> Tel: 0086-2154896104
> Shanghai Typhoon Institute,China
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Fri Jun 14 10:38:38 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 14 Jun 2013 09:38:38 +0100
Subject: [R] How to get a running mean result by R?
In-Reply-To: <CAMUSh4odjrHfMDb+0eWZsiUJrV0yt4+zKJUNX8b7xJ4te6Wwnw@mail.gmail.com>
References: <CAMUSh4q+tk964zPa60_6uuuGXf7YXY=hoPfCzfjhEC7Lxed7pQ@mail.gmail.com>
	<51B84F73.2000802@sapo.pt>
	<CAMUSh4odjrHfMDb+0eWZsiUJrV0yt4+zKJUNX8b7xJ4te6Wwnw@mail.gmail.com>
Message-ID: <51BAD68E.6080203@sapo.pt>

Hello,

As for Inf, the mean value of Inf and anything is Inf, so there's no way 
to solve it. As for NaN, you can set them to NA prior to calling the 
function.
That leaves us with NA handling. forecast::ma handles NAs, it propagates 
them, as it should. An alternative function using filter() like it was 
proposed would do the same:

ma2 <- function(x, order, sides = 2){
	y <- filter(x, rep(1/order, order), method = "convolution", sides = sides)
	as.numeric(y)
}

x <- 1:10
x[3] <- NA

ma2(x, 3)
forecast::ma(x, 3)


But if instead of NA the problem value is NaN, I prefer forecast::ma.


x[3] <- NaN

ma2(x, 3)
forecast::ma(x, 3)


Finally, if the value is Inf, both functions work as expected.



x <- 1:10
x[3] <- Inf

ma2(x, 3)
forecast::ma(x, 3)

So I would say that forecast::ma does handle the three cases.


Hope this helps,

Rui Barradas

Em 14-06-2013 02:50, Jie Tang escreveu:
> yes ,Ma in forecast package does works but when the data included NA,NAN
> or INF ,it could not go on calculating the running
>
>
> 2013/6/12 Rui Barradas <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>>
>
>     Hello,
>
>     You can use, for instance, function ma() in package forecast.
>
>     # if not yet installed
>     #install.packages('forecast', dependencies = TRUE)
>     library(forecast)
>
>     ?ma
>
>
>     Hope this helps,
>
>     Rui Barradas
>
>
>     Em 12-06-2013 08:21, Jie Tang escreveu:
>
>         Hi R users:
>             I have a big data and want to calculate the running mean of
>         this data .
>         How can I get this kind of result ? I have check the command "mean"
>         it seems "mean" could not get the running mean?
>
>
>
>
> --
> TANG Jie
> Email: totangjie at gmail.com <mailto:totangjie at gmail.com>
> Tel: 0086-2154896104
> Shanghai Typhoon Institute,China


From raziq_fazli at yahoo.com  Fri Jun 14 12:24:33 2013
From: raziq_fazli at yahoo.com (Fazli Raziq)
Date: Fri, 14 Jun 2013 03:24:33 -0700 (PDT)
Subject: [R] Problem in Matrix
Message-ID: <1371205473.43069.YahooMailNeo@web162902.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130614/36945f9f/attachment.pl>

From igauravsehrawat at gmail.com  Fri Jun 14 09:47:57 2013
From: igauravsehrawat at gmail.com (Gaurav Sehrawat)
Date: Fri, 14 Jun 2013 13:17:57 +0530
Subject: [R] Problem in linking a library in R package
Message-ID: <CAC2qNN7yPRa2K6K3XeCMkvdYpA9scx_Gi6J3AwXayFS8T59bvQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130614/96da826b/attachment.pl>

From arman.eshaghi at gmail.com  Fri Jun 14 15:34:22 2013
From: arman.eshaghi at gmail.com (Arman Eshaghi)
Date: Fri, 14 Jun 2013 18:04:22 +0430
Subject: [R] rename and concatenate name of columns
Message-ID: <CAKy1A=E7HUHjTiefN=bwP-ncvxgM_iUs=mtLvazWDTj3Ttx0QQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130614/30dff65f/attachment.pl>

From smartpink111 at yahoo.com  Fri Jun 14 15:44:22 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 14 Jun 2013 06:44:22 -0700 (PDT)
Subject: [R] Need help on creating Adjacency matrix in R
In-Reply-To: <CA+0+WdL1E2xk1KL2GfOEhN7Qz7m4MgbTedW0pFG-XeHru0eHPw@mail.gmail.com>
References: <CA+0+WdL1E2xk1KL2GfOEhN7Qz7m4MgbTedW0pFG-XeHru0eHPw@mail.gmail.com>
Message-ID: <1371217462.76906.YahooMailNeo@web142603.mail.bf1.yahoo.com>



HI,

May be this helps:
dat1<- read.table(text="
Col1 Col2 Weight
? A D 0.1
? B C 0.4
? C M 0.6
? D P 0.8
? E W 1
? F D 1.2
? G C 3.1
? H M 4
",sep="",header=TRUE,stringsAsFactors=FALSE)
?vec1<- c(unique(dat1[,1]),unique(dat1[,2]))
datNew<- expand.grid(vec1,vec1)
colnames(datNew)<- colnames(dat1)[-3]
library(plyr)
?dat2<-join(datNew,dat1,type="left")
dat2$Weight[is.na(dat2$Weight)]<-0
m1<-xtabs(Weight~Col1+Col2,data=dat2)
library(igraph)
g <- graph.adjacency(m1, mode="directed", weighted=TRUE, diag=TRUE)
get.adjacency(g)
#11 x 11 sparse Matrix of class "dgCMatrix"
#?? [[ suppressing 11 column names ?A?, ?B?, ?C? ... ]]
#?????????????????????? 
#A . . . 1 . . . . . . .
#B . . 1 . . . . . . . .
#C . . . . . . . . 1 . .
#D . . . . . . . . . 1 .
#E . . . . . . . . . . 1
#F . . . 1 . . . . . . .
#G . . 1 . . . . . . . .
#H . . . . . . . . 1 . .
#M . . . . . . . . . . .
#P . . . . . . . . . . .
#W . . . . . . . . . . .

#or
library(reshape2)
m2<-dcast(dat2,Col1~Col2,value.var="Weight",fill=0)
row.names(m2)<- m2[,1]
m2<- as.matrix(m2[,-1])

g1 <- graph.adjacency(m2, mode="directed", weighted=TRUE, diag=TRUE)
?get.adjacency(g1)
#11 x 11 sparse Matrix of class "dgCMatrix"
#?? [[ suppressing 11 column names ?A?, ?B?, ?C? ... ]]
#?????????????????????? 
#A . . . 1 . . . . . . .
#B . . 1 . . . . . . . .
#C . . . . . . . . 1 . .
#D . . . . . . . . . 1 .
#E . . . . . . . . . . 1
#F . . . 1 . . . . . . .
#G . . 1 . . . . . . . .
#H . . . . . . . . 1 . .
#M . . . . . . . . . . .
#P . . . . . . . . . . .
#W . . . . . . . . . . .

A.K.

----- Original Message -----
From: rn27in . <rn27in at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Friday, June 14, 2013 2:43 AM
Subject: [R] Need help on creating Adjacency matrix in R

Hello everyone

I am relatively new to R and wanted some help on creating adjacency matrix

I have a dataset as given below and wanted to create an adjacency matrix in
R. For creating an adjacency matrix, the matrix should be a square matrix.
I tried creating a matrix directly, but it would not be a square matrix.
Can any one help me out with this problem.

Thanks
Rohit

Col 1 Col 2? ?  Weight? A D 0.1? B C 0.4? C M 0.6? D P 0.8? E W 1? F D 1.2
G C 3.1? H M 4

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From murdoch.duncan at gmail.com  Fri Jun 14 15:45:36 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 14 Jun 2013 09:45:36 -0400
Subject: [R] Problem in linking a library in R package
In-Reply-To: <CAC2qNN7yPRa2K6K3XeCMkvdYpA9scx_Gi6J3AwXayFS8T59bvQ@mail.gmail.com>
References: <CAC2qNN7yPRa2K6K3XeCMkvdYpA9scx_Gi6J3AwXayFS8T59bvQ@mail.gmail.com>
Message-ID: <51BB1E80.1080001@gmail.com>

On 13-06-14 3:47 AM, Gaurav Sehrawat wrote:
> Hello everyone ,
> I am facing a simple problem , I trying to add functionality in one of R
> package .
> I want a profiling library to link to R package so that when R package is
> used the profiling out put comes automatically with that.
>
> Problem is that I am not able to link it with the package , I tried to use
> the makevars.in in src folder to give it path to compile but no luck.
> I have made a shared library of the library i am using so that it compiles
> dynamically.
>
> Any help on this .

You need to show us what you did, and what the results were.

Duncan Murdoch

P.S.  Please don't reply to me personally, reply to the list.


From smartpink111 at yahoo.com  Fri Jun 14 16:01:28 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 14 Jun 2013 07:01:28 -0700 (PDT)
Subject: [R] rename and concatenate name of columns
In-Reply-To: <CAKy1A=E7HUHjTiefN=bwP-ncvxgM_iUs=mtLvazWDTj3Ttx0QQ@mail.gmail.com>
References: <CAKy1A=E7HUHjTiefN=bwP-ncvxgM_iUs=mtLvazWDTj3Ttx0QQ@mail.gmail.com>
Message-ID: <1371218488.63517.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
rename_columns<- function(dat){
??? for(i in 2:(ncol(dat))){
??? names(dat)[i]<- paste(names(dat)[1],names(dat)[i],sep="_")
??? 
??? }
dat
}

dat1<- read.table(text="
chr??? pos??? ref??? alt
chr1??? 5??? A??? G
chr1??? 8??? T??? C
chr2??? 2??? C??? T
",sep="",header=TRUE,stringsAsFactors=FALSE)


?rename_columns(dat1)
#?? chr chr_pos chr_ref chr_alt
#1 chr1?????? 5?????? A?????? G
#2 chr1?????? 8?????? T?????? C
#3 chr2?????? 2?????? C?????? T
A.K.



----- Original Message -----
From: Arman Eshaghi <arman.eshaghi at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Friday, June 14, 2013 9:34 AM
Subject: [R] rename and concatenate name of columns

Dear all,

I have different data frames for which I would like to modify names of each
column such that the new name would include the name of the first column
added to the name of other columns; I came up with the following code.
Nothing changes when I run the following code. I would be grateful if
someone could help me.

All the best,
-Arman

rename_columns <- function(dataset) {
for (i in 2:(ncol(dataset))) {names(dataset)[i] <- paste(names(dataset)[1],
names(dataset)[i], sep="_")
}
}

rename_columns(dataset) %nothing happens!

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From istazahn at gmail.com  Fri Jun 14 16:07:04 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Fri, 14 Jun 2013 10:07:04 -0400
Subject: [R] rename and concatenate name of columns
In-Reply-To: <1371218488.63517.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <CAKy1A=E7HUHjTiefN=bwP-ncvxgM_iUs=mtLvazWDTj3Ttx0QQ@mail.gmail.com>
	<1371218488.63517.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <CA+vqiLF0td3rvEJfvF5spiEaJZpeQ4nL_RThxrbMDgamx0H1=w@mail.gmail.com>

On Fri, Jun 14, 2013 at 10:01 AM, arun <smartpink111 at yahoo.com> wrote:
> Hi,
> rename_columns<- function(dat){
>     for(i in 2:(ncol(dat))){
>     names(dat)[i]<- paste(names(dat)[1],names(dat)[i],sep="_")
>
>     }
> dat
> }

Or even better, get rid of the unnecessary loop:

rename_columns <- function(DF) {
    names(DF) <- c(names(DF)[1], paste(names(DF)[1], names(DF)[-1], sep="_"))
    return(DF)
}



Best,
Ista
>
> dat1<- read.table(text="
> chr    pos    ref    alt
> chr1    5    A    G
> chr1    8    T    C
> chr2    2    C    T
> ",sep="",header=TRUE,stringsAsFactors=FALSE)
>
>
>  rename_columns(dat1)
> #   chr chr_pos chr_ref chr_alt
> #1 chr1       5       A       G
> #2 chr1       8       T       C
> #3 chr2       2       C       T
> A.K.
>
>
>
> ----- Original Message -----
> From: Arman Eshaghi <arman.eshaghi at gmail.com>
> To: r-help at r-project.org
> Cc:
> Sent: Friday, June 14, 2013 9:34 AM
> Subject: [R] rename and concatenate name of columns
>
> Dear all,
>
> I have different data frames for which I would like to modify names of each
> column such that the new name would include the name of the first column
> added to the name of other columns; I came up with the following code.
> Nothing changes when I run the following code. I would be grateful if
> someone could help me.
>
> All the best,
> -Arman
>
> rename_columns <- function(dataset) {
> for (i in 2:(ncol(dataset))) {names(dataset)[i] <- paste(names(dataset)[1],
> names(dataset)[i], sep="_")
> }
> }
>
> rename_columns(dataset) %nothing happens!
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rainer.schuermann at gmx.net  Fri Jun 14 16:10:02 2013
From: rainer.schuermann at gmx.net (Rainer Schuermann)
Date: Fri, 14 Jun 2013 16:10:02 +0200
Subject: [R] rename and concatenate name of columns
In-Reply-To: <CAKy1A=E7HUHjTiefN=bwP-ncvxgM_iUs=mtLvazWDTj3Ttx0QQ@mail.gmail.com>
References: <CAKy1A=E7HUHjTiefN=bwP-ncvxgM_iUs=mtLvazWDTj3Ttx0QQ@mail.gmail.com>
Message-ID: <23648782.VxNWy9YV2N@augeatur>

df1 <- data.frame( A = runif( 10 ), B = runif( 10 ) * 5, C = runif( 10 ) * 10, D = runif( 10 ) * 20 )
df2 <- data.frame( X = runif( 10 ), Y = runif( 10 ) * 5, Z = runif( 10 ) * 10 )
rename_columns <- function( dataset )
{
	for( i in 2:ncol( dataset ) )
		colnames( dataset )[i] <- paste( colnames( dataset )[1], colnames( dataset )[i], sep = "_" )
	return( dataset )
}

df1 <- rename_columns( df1 )  
df1
            A       A_B          A_C       A_D
1  0.79914742 4.4898911 2.8869670979 11.067921
2  0.34552180 3.5456202 7.4774973304  8.610913
3  0.02950957 3.1754457 2.4493258283 17.649965
4  0.41804920 3.6180818 2.4680344155  5.038590
5  0.69496877 1.7169792 0.8790624910  3.476689
6  0.79293910 0.4452258 9.5359219401  3.668066
7  0.06135734 0.9188141 8.4256720915  9.980292
8  0.86066946 1.2674735 4.1982888198 13.561160
9  0.41895427 0.1434889 0.0007853331  3.187101
10 0.09498189 4.5215823 1.0008131783 10.428556





On Friday 14 June 2013 18:04:22 Arman Eshaghi wrote:
> Dear all,
> 
> I have different data frames for which I would like to modify names of each
> column such that the new name would include the name of the first column
> added to the name of other columns; I came up with the following code.
> Nothing changes when I run the following code. I would be grateful if
> someone could help me.
> 
> All the best,
> -Arman
> 
> rename_columns <- function(dataset) {
> for (i in 2:(ncol(dataset))) {names(dataset)[i] <- paste(names(dataset)[1],
> names(dataset)[i], sep="_")
> }
> }
> 
> rename_columns(dataset) %nothing happens!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From katherine_gobin at yahoo.com  Fri Jun 14 16:03:32 2013
From: katherine_gobin at yahoo.com (Katherine Gobin)
Date: Fri, 14 Jun 2013 22:03:32 +0800 (SGT)
Subject: [R] Removing "NA" from matrix
Message-ID: <1371218612.14912.YahooMailNeo@web193206.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130614/348b06ff/attachment.pl>

From arman.eshaghi at gmail.com  Fri Jun 14 16:17:21 2013
From: arman.eshaghi at gmail.com (Arman Eshaghi)
Date: Fri, 14 Jun 2013 18:47:21 +0430
Subject: [R] rename and concatenate name of columns
In-Reply-To: <23648782.VxNWy9YV2N@augeatur>
References: <CAKy1A=E7HUHjTiefN=bwP-ncvxgM_iUs=mtLvazWDTj3Ttx0QQ@mail.gmail.com>
	<23648782.VxNWy9YV2N@augeatur>
Message-ID: <CAKy1A=GbRsn-MQzi9OBwwPgYgMbAoryg_o8ZKMKNTxFaHkcb_A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130614/759ef6a6/attachment.pl>

From smartpink111 at yahoo.com  Fri Jun 14 16:34:04 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 14 Jun 2013 07:34:04 -0700 (PDT)
Subject: [R] Removing "NA" from matrix
In-Reply-To: <1371218612.14912.YahooMailNeo@web193206.mail.sg3.yahoo.com>
References: <1371218612.14912.YahooMailNeo@web193206.mail.sg3.yahoo.com>
Message-ID: <1371220444.93687.YahooMailNeo@web142605.mail.bf1.yahoo.com>

HI,
Try:
dat1<-dat[sapply(dat,function(x) length(unique(x)))>1]

cor(dat1)
#?????????? ABC???????? DEF???????? JKL??????? MNO
#ABC? 1.0000000 -0.75600764? 0.55245223 -0.2735585
#DEF -0.7560076? 1.00000000 -0.06479082? 0.2020781
#JKL? 0.5524522 -0.06479082? 1.00000000? 0.4564568
#MNO -0.2735585? 0.20207810? 0.45645683? 1.0000000


A.K.
From: Katherine Gobin <katherine_gobin at yahoo.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Friday, June 14, 2013 10:03 AM
Subject: [R] Removing "NA" from matrix

Dear R forum,

I have a data frame 


dat = data.frame(
ABC = c(25.28000732,48.33857234,19.8013245,10.68361461),
DEF = c(14.02722251,10.57985168,11.81890316,21.40171514),
GHI = c(1,1,1,1),
JKL = c(45.96423231,44.52986236,16.56514176,32.14545122),
MNO = c(45.38438063,15.54338206,18.78444777,24.29486984))

> dat
?????? ABC????? DEF GHI????? JKL????? MNO
1 25.28001 14.02722?? 1 45.96423 45.38438
2 48.33857 10.57985?? 1 44.52986 15.54338
3 19.80132 11.81890?? 1 16.56514 18.78445
4 10.68361 21.40172?? 1 32.14545 24.29487


When I try to find the correlation I get (which is obvious as my one column shows no variation)

dat_cor = cor(dat)


Warning message:
In cor(dat) : the standard deviation is zero
> dat_cor
?????????? ABC???????? DEF GHI???????? JKL??????? MNO
ABC? 1.0000000 -0.75600764? NA? 0.55245223 -0.2735585
DEF -0.7560076? 1.00000000? NA -0.06479082? 0.2020781
GHI???????? NA????????? NA?? 1????????? NA???????? NA
JKL? 0.5524522 -0.06479082? NA? 1.00000000? 0.4564568
MNO -0.2735585? 0.20207810? NA? 0.45645683? 1.0000000


In reality I am dealing with about 300 variables and don't know which variables don't vary.

My query is how do I remove the columns and rows with NA's.

So for example, I need the correlation matrix for ABC, DEF, JKL and MNO only.

Kindly guide.

Thanking in advance.

Regards

Katherine

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Fri Jun 14 16:40:14 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 14 Jun 2013 07:40:14 -0700 (PDT)
Subject: [R] Removing "NA" from matrix
In-Reply-To: <1371220444.93687.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1371218612.14912.YahooMailNeo@web193206.mail.sg3.yahoo.com>
	<1371220444.93687.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1371220814.31402.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Probably, this also works:
dat2<-dat[,(colSums(dat)/dat[1,])!=nrow(dat)]
cor(dat2)

dat$NewCol<-5
?dat3<-dat[,(colSums(dat)/dat[1,])!=nrow(dat)]
?cor(dat3)
#?????????? ABC???????? DEF???????? JKL??????? MNO
#ABC? 1.0000000 -0.75600764? 0.55245223 -0.2735585
#DEF -0.7560076? 1.00000000 -0.06479082? 0.2020781
#JKL? 0.5524522 -0.06479082? 1.00000000? 0.4564568
#MNO -0.2735585? 0.20207810? 0.45645683? 1.0000000
A.K.




----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Katherine Gobin <katherine_gobin at yahoo.com>
Cc: R help <r-help at r-project.org>
Sent: Friday, June 14, 2013 10:34 AM
Subject: Re: [R] Removing "NA" from matrix

HI,
Try:
dat1<-dat[sapply(dat,function(x) length(unique(x)))>1]

cor(dat1)
#?????????? ABC???????? DEF???????? JKL??????? MNO
#ABC? 1.0000000 -0.75600764? 0.55245223 -0.2735585
#DEF -0.7560076? 1.00000000 -0.06479082? 0.2020781
#JKL? 0.5524522 -0.06479082? 1.00000000? 0.4564568
#MNO -0.2735585? 0.20207810? 0.45645683? 1.0000000


A.K.
From: Katherine Gobin <katherine_gobin at yahoo.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Friday, June 14, 2013 10:03 AM
Subject: [R] Removing "NA" from matrix

Dear R forum,

I have a data frame 


dat = data.frame(
ABC = c(25.28000732,48.33857234,19.8013245,10.68361461),
DEF = c(14.02722251,10.57985168,11.81890316,21.40171514),
GHI = c(1,1,1,1),
JKL = c(45.96423231,44.52986236,16.56514176,32.14545122),
MNO = c(45.38438063,15.54338206,18.78444777,24.29486984))

> dat
?????? ABC????? DEF GHI????? JKL????? MNO
1 25.28001 14.02722?? 1 45.96423 45.38438
2 48.33857 10.57985?? 1 44.52986 15.54338
3 19.80132 11.81890?? 1 16.56514 18.78445
4 10.68361 21.40172?? 1 32.14545 24.29487


When I try to find the correlation I get (which is obvious as my one column shows no variation)

dat_cor = cor(dat)


Warning message:
In cor(dat) : the standard deviation is zero
> dat_cor
?????????? ABC???????? DEF GHI???????? JKL??????? MNO
ABC? 1.0000000 -0.75600764? NA? 0.55245223 -0.2735585
DEF -0.7560076? 1.00000000? NA -0.06479082? 0.2020781
GHI???????? NA????????? NA?? 1????????? NA???????? NA
JKL? 0.5524522 -0.06479082? NA? 1.00000000? 0.4564568
MNO -0.2735585? 0.20207810? NA? 0.45645683? 1.0000000


In reality I am dealing with about 300 variables and don't know which variables don't vary.

My query is how do I remove the columns and rows with NA's.

So for example, I need the correlation matrix for ABC, DEF, JKL and MNO only.

Kindly guide.

Thanking in advance.

Regards

Katherine

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From macqueen1 at llnl.gov  Fri Jun 14 16:44:06 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 14 Jun 2013 14:44:06 +0000
Subject: [R] find the position of first observation for each subject
In-Reply-To: <CAKO0DpgCM=scU+G6sJS+wB0qdmtvwaDz5ngQ_KV__UnMtaR-Bw@mail.gmail.com>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521914533A7@PRDEXMBX-08.the-lab.llnl.gov>

I would typically use rle() for this kind of thing:

> tmp <- cumsum(rle(id)$lengths)
> c(1, tmp[-length(tmp)]+1)
[1] 1 4 9


It does assume that all rows for each unique value of id are grouped
together, but does not require that the rows be sorted by id.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/13/13 12:56 AM, "Gallon Li" <gallon.li at gmail.com> wrote:

>suppose I have the following data
>
>id=c(rep(1,3),rep(2,5),rep(3,4))
>time=c(seq(1,3),seq(2,6),seq(1,4))
>
>ds=cbind(id,time)
>
>> ds
>      id time
> [1,]  1    1
> [2,]  1    2
> [3,]  1    3
> [4,]  2    2
> [5,]  2    3
> [6,]  2    4
> [7,]  2    5
> [8,]  2    6
> [9,]  3    1
>[10,]  3    2
>[11,]  3    3
>[12,]  3    4
>
>i want to return a vector that indicates the position of the first
>observation for each id. for the above data, i wish to get (1,4,9).
>
>is it possible to get this quickly>?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Jun 14 16:44:46 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 14 Jun 2013 07:44:46 -0700
Subject: [R] Removing "NA" from matrix
In-Reply-To: <1371218612.14912.YahooMailNeo@web193206.mail.sg3.yahoo.com>
References: <1371218612.14912.YahooMailNeo@web193206.mail.sg3.yahoo.com>
Message-ID: <FB7CBDB0-339E-4ADB-90A3-EDC77363E476@comcast.net>


On Jun 14, 2013, at 7:03 AM, Katherine Gobin wrote:

> Dear R forum,
> 
> I have a data frame 
> 
> 
> dat = data.frame(
> ABC = c(25.28000732,48.33857234,19.8013245,10.68361461),
> DEF = c(14.02722251,10.57985168,11.81890316,21.40171514),
> GHI = c(1,1,1,1),
> JKL = c(45.96423231,44.52986236,16.56514176,32.14545122),
> MNO = c(45.38438063,15.54338206,18.78444777,24.29486984))
> 
>> dat
>        ABC      DEF GHI      JKL      MNO
> 1 25.28001 14.02722   1 45.96423 45.38438
> 2 48.33857 10.57985   1 44.52986 15.54338
> 3 19.80132 11.81890   1 16.56514 18.78445
> 4 10.68361 21.40172   1 32.14545 24.29487
> 
> 
> When I try to find the correlation I get (which is obvious as my one column shows no variation)

Perhaps:

dat_cor = cor(dat[ , sapply(dat, function(col) sd(col) != 0 ) ] )

> Warning message:
> In cor(dat) : the standard deviation is zero
>> dat_cor
>            ABC         DEF GHI         JKL        MNO
> ABC  1.0000000 -0.75600764  NA  0.55245223 -0.2735585
> DEF -0.7560076  1.00000000  NA -0.06479082  0.2020781
> GHI         NA          NA   1          NA         NA
> JKL  0.5524522 -0.06479082  NA  1.00000000  0.4564568
> MNO -0.2735585  0.20207810  NA  0.45645683  1.0000000
> 
> 
> In reality I am dealing with about 300 variables and don't know which variables don't vary.
> 
> My query is how do I remove the columns and rows with NA's.
> 
> So for example, I need the correlation matrix for ABC, DEF, JKL and MNO only.
> 
> Kindly guide.
> 
> Thanking in advance.
> 
> Regards
> 
> Katherine
> 
> 	[[alternative HTML version deleted]]

Please post in plain text.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Jun 14 17:02:52 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 14 Jun 2013 08:02:52 -0700
Subject: [R] rename and concatenate name of columns
In-Reply-To: <CAKy1A=E7HUHjTiefN=bwP-ncvxgM_iUs=mtLvazWDTj3Ttx0QQ@mail.gmail.com>
References: <CAKy1A=E7HUHjTiefN=bwP-ncvxgM_iUs=mtLvazWDTj3Ttx0QQ@mail.gmail.com>
Message-ID: <BDF430E1-94E1-4D2E-A2EA-3D96AB8C4AF1@comcast.net>


On Jun 14, 2013, at 6:34 AM, Arman Eshaghi wrote:

> Dear all,
> 
> I have different data frames for which I would like to modify names of each
> column such that the new name would include the name of the first column
> added to the name of other columns; I came up with the following code.
> Nothing changes when I run the following code. I would be grateful if
> someone could help me.
> 
> All the best,
> -Arman
> 
> rename_columns <- function(dataset) {
> for (i in 2:(ncol(dataset))) {names(dataset)[i] <- paste(names(dataset)[1],
> names(dataset)[i], sep="_")
> }
> }
> 
> rename_columns(dataset) %nothing happens!

A bit of commentary: Something did happen. It's just that you didn't do anything with _what_ happened. The copy of the 'dataset'-object got modified but you never returned it from the function, and and also didn't reassign it to the original 'dataset'. Functions return their last assignment. In the case of the 'for'-function, it somewhat surprisingly returns a NULL. It is a rather odd function in the functional R world, since its main role in life is doing things by side-effects, and so when used inside functions has seemingly paradoxical behavior. Check your results with:

rename_columns <- function(dataset) {
for (i in 2:(ncol(dataset))) {names(dataset)[i] <- paste(names(dataset)[1],
names(dataset)[i], sep="_")
}
dataset}

dataset <- rename_columns(dataset)

> 	[[alternative HTML version deleted]]

And do learn to post in plain text.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From igauravsehrawat at gmail.com  Fri Jun 14 16:16:41 2013
From: igauravsehrawat at gmail.com (Gaurav Sehrawat)
Date: Fri, 14 Jun 2013 19:46:41 +0530
Subject: [R] Problem in linking a library in R package
In-Reply-To: <51BB1E80.1080001@gmail.com>
References: <CAC2qNN7yPRa2K6K3XeCMkvdYpA9scx_Gi6J3AwXayFS8T59bvQ@mail.gmail.com>
	<51BB1E80.1080001@gmail.com>
Message-ID: <CAC2qNN7NA3wQfowjzrA7HZ7X6YrKgwhbxH+MkTSxvqLCA6VUfw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130614/fdbd025c/attachment.pl>

From neelesh0 at gmail.com  Fri Jun 14 16:24:25 2013
From: neelesh0 at gmail.com (Neelesh Gupta)
Date: Fri, 14 Jun 2013 19:54:25 +0530
Subject: [R] How to interactively create manually guided Decision Tree
Message-ID: <CAOZ5VVLNN5Dahyhj1JBThZPLGOan1zZP4tUBLfbg7hudGjVBkQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130614/e7611e23/attachment.pl>

From anferg806 at aol.com  Fri Jun 14 16:52:03 2013
From: anferg806 at aol.com (anferg806 at aol.com)
Date: Fri, 14 Jun 2013 10:52:03 -0400 (EDT)
Subject: [R] R session freezes when I try to save a new script
Message-ID: <8D03725DDC146D0-142C-77C5@Webmail-d104.sysops.aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130614/3d86e96f/attachment.pl>

From jrkrideau at inbox.com  Fri Jun 14 17:57:14 2013
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 14 Jun 2013 07:57:14 -0800
Subject: [R] R session freezes when I try to save a new script
In-Reply-To: <8D03725DDC146D0-142C-77C5@Webmail-d104.sysops.aol.com>
Message-ID: <6EBEAE6CCC4.0000109Ejrkrideau@inbox.com>

It would probably help if you posted your sessionInfo() 

Just before everything freezes issue the command
sessionInfor()
copy the output and paste it into an email.



John Kane
Kingston ON Canada


> -----Original Message-----
> From: anferg806 at aol.com
> Sent: Fri, 14 Jun 2013 10:52:03 -0400 (EDT)
> To: r-help at r-project.org
> Subject: [R] R session freezes when I try to save a new script
> 
> All:
> 
> 
> Recently my R session freezes when I try to open a file or save a new
> script after I have run existing scripts.  The session freezes so that I
> can no longer click on any windows within the R session -- including
> other scripts that are open or the R console.  (I hear the "ding" sound
> when I try to click on anything.)  I have looked at the Task Manager on
> the computer and R is still running (and is still responsive according to
> the Task Manager), but I cannot do anything within R.  I have tried
> pressing Esc and that does not help.
> 
> 
> Any suggestions would be greatly appreciated!  I am using a 32 bit
> Windows 7 computer with 4gb ram and 250gb hard drive.
> 
> 
> Thanks in advance for any suggestions!
> 
> 
> ~Amanda Ferguson
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From jmichel.fortin at hotmail.fr  Fri Jun 14 18:16:57 2013
From: jmichel.fortin at hotmail.fr (Jean-Michel Fortin)
Date: Fri, 14 Jun 2013 12:16:57 -0400
Subject: [R] Trying to get the 'Digitize' package
Message-ID: <BAY167-W9131F9546B6A25603DF2DEF0800@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130614/52fcc130/attachment.pl>

From gunter.berton at gene.com  Fri Jun 14 18:18:15 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 14 Jun 2013 09:18:15 -0700
Subject: [R] How to interactively create manually guided Decision Tree
In-Reply-To: <CAOZ5VVLNN5Dahyhj1JBThZPLGOan1zZP4tUBLfbg7hudGjVBkQ@mail.gmail.com>
References: <CAOZ5VVLNN5Dahyhj1JBThZPLGOan1zZP4tUBLfbg7hudGjVBkQ@mail.gmail.com>
Message-ID: <CACk-te0D58t0Ax6bKrokBXHNVTUjXCLyj98eLi_qRP3oRjrKpQ@mail.gmail.com>

You need to do some reading, both about decision trees and R!

What you need to do for R is to use cut() on Age (?cut) to create a
new categorical variable, ageCat, say, and then use that in your tree
building instead of Age.

Cheers,
Bert

On Fri, Jun 14, 2013 at 7:24 AM, Neelesh Gupta <neelesh0 at gmail.com> wrote:
> I am new in using R. I want to know all about building decision tree model
> in R.
> Few options which I searched are rpart and rattle to build a decision
> tree.Both the functions are giving me splits which are  statistically
> appropriate.
>
> But I am not able to figure out how to  change those splits as per my
> business requirement.
>
> for example : the automatic split of Age by using rattle is > 30 and <= 30
> but I want a  split of <= 20 , 21-30 , 30-50 and >= 50
>
> I also want to know how to know the predictive strength of each variable
> after each split so that I can choose which variable should come next in my
> list.
>
> I
>
> Thanks in advance
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From optionsraghu at gmail.com  Fri Jun 14 19:04:52 2013
From: optionsraghu at gmail.com (Raghuraman Ramachandran)
Date: Fri, 14 Jun 2013 18:04:52 +0100
Subject: [R] MS Access
Message-ID: <CADgEnD=+z1nTer-Hd40fN1oB0xbm_8+=_OVs6U4ZyHN-GC3ZgQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130614/7fe36d4f/attachment.pl>

From 538280 at gmail.com  Fri Jun 14 19:05:48 2013
From: 538280 at gmail.com (Greg Snow)
Date: Fri, 14 Jun 2013 11:05:48 -0600
Subject: [R] Trying to get the 'Digitize' package
In-Reply-To: <BAY167-W9131F9546B6A25603DF2DEF0800@phx.gbl>
References: <BAY167-W9131F9546B6A25603DF2DEF0800@phx.gbl>
Message-ID: <CAFEqCdxbTNCLdnbvPLg__Uvk7jDPD=H9CbD4UxX1GufZ6wYhGQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130614/e1c7b655/attachment.pl>

From dwinsemius at comcast.net  Fri Jun 14 19:33:26 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 14 Jun 2013 10:33:26 -0700
Subject: [R] MS Access
In-Reply-To: <CADgEnD=+z1nTer-Hd40fN1oB0xbm_8+=_OVs6U4ZyHN-GC3ZgQ@mail.gmail.com>
References: <CADgEnD=+z1nTer-Hd40fN1oB0xbm_8+=_OVs6U4ZyHN-GC3ZgQ@mail.gmail.com>
Message-ID: <46E1BFF4-9C5F-41F1-85C6-30F116AB3AE6@comcast.net>


On Jun 14, 2013, at 10:04 AM, Raghuraman Ramachandran wrote:

> Dear guRus
> 
> Can I use R inside Microsoft access Macros and programmes? I understand
> that R-Excel is compatible but wish to know if I can use R inside Access
> programmes please?
> 

RExcel has a separate mailing list. You should ask there.

> Many thanks
> Raghu
> 
> 	[[alternative HTML version deleted]]
> 


David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.CA.us  Fri Jun 14 20:16:17 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 14 Jun 2013 12:16:17 -0600
Subject: [R] R session freezes when I try to save a new script
In-Reply-To: <8D03725DDC146D0-142C-77C5@Webmail-d104.sysops.aol.com>
References: <8D03725DDC146D0-142C-77C5@Webmail-d104.sysops.aol.com>
Message-ID: <0d3c5d44-0752-4d2e-a259-986244542d2a@email.android.com>

You will probably need to read the Posting Guide and follow its recommendations to get a constructive response. Things like posting in text instead of HTML and providing the output of sessionInfo go a long way toward speeding up the troubleshooting process.

You can also begin the process of identifying what your in-memory objects look like by stopping your script just before you run the function or click on a menu that hangs, and providing to us the output of the ls() function in your next email. You may have redefined an object with an important name. Alternatively, you may have a windows permissions issue (which would be outside the scope of this mailing list.

Ideally you would generate a self- contained reproducible example, but if that is not possible then you will have to live with guesses as responses. (The dump or dput functions may let you share the problematic memory configuration.)
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

anferg806 at aol.com wrote:

>All:
>
>
>Recently my R session freezes when I try to open a file or save a new
>script after I have run existing scripts.  The session freezes so that
>I can no longer click on any windows within the R session -- including
>other scripts that are open or the R console.  (I hear the "ding" sound
>when I try to click on anything.)  I have looked at the Task Manager on
>the computer and R is still running (and is still responsive according
>to the Task Manager), but I cannot do anything within R.  I have tried
>pressing Esc and that does not help.
>
>
>Any suggestions would be greatly appreciated!  I am using a 32 bit
>Windows 7 computer with 4gb ram and 250gb hard drive.
>
>
>Thanks in advance for any suggestions!
>
>
>~Amanda Ferguson
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From kpenner at as.arizona.edu  Fri Jun 14 20:24:14 2013
From: kpenner at as.arizona.edu (Kyle Penner)
Date: Fri, 14 Jun 2013 11:24:14 -0700
Subject: [R] survreg with measurement uncertainties
In-Reply-To: <30411786F64EEF46856EFBA2CD917799E05486@UHEXMBSPR03.umhs.med.umich.edu>
References: <mailman.25.1371031207.11759.r-help@r-project.org>
	<51B87CC4.6050800@mayo.edu>
	<CAAF=944q7jFhBwK1mOwQKUvtwYhn8sqvyKaZrmWU2r5rkW8VoA@mail.gmail.com>
	<30411786F64EEF46856EFBA2CD917799E05486@UHEXMBSPR03.umhs.med.umich.edu>
Message-ID: <CAAF=947uQ-ydSbtjkbr0BOVpoT3fw86GLS9fnpfMgxAVzqxbxw@mail.gmail.com>

Hrm, thanks.  The uncertainties are what they are, though (and the
model is what it is, too) -- is there an alternative to modifying
them?  Maybe another type of analysis that handles upper limits?

Kyle

On Thu, Jun 13, 2013 at 5:46 AM, Andrews, Chris <chrisaa at med.umich.edu> wrote:
> It seems a line through the origin doesn't fit the data very well.  That may be throwing off the fitting routine.
>
> data = c(144.53, 1687.68, 5397.91)
> err = c(8.32, 471.22, 796.67)
> model = c(71.60, 859.23, 1699.19)
> id = c(1, 2, 3)
>
> # display
> plot(data ~ model)
> library("Hmisc")
> errbar(model, add=TRUE, y = data, yplus= data+err, yminus=data-err, errbar.col=2)
> abline(lm(data ~ model - 1))
> abline(lm(data ~ model - 1, weights = 1/err^2), col=2)
>
> Making err[1] larger, allows convergence:
>
> err[1] <- 80.32
>
> survreg(Surv(time = data)~model-1+cluster(id), weights=1/(err^2), dist='gaussian', init=c(2.1))
>
> Call:
> survreg(formula = Surv(time = data) ~ model - 1 + cluster(id),
>     weights = 1/(err^2), dist = "gaussian", init = c(2.1))
>
> Coefficients:
>  model
> 2.6055
>
> Scale= 139.299
>
> Loglik(model)= 0   Loglik(intercept only)= 0
> n= 3
>
>
> And this matches the standard linear model call:
>
> lm(data ~ model - 1, weights = 1/err^2)
>
> Call:
> lm(formula = data ~ model - 1, weights = 1/err^2)
>
> Coefficients:
> model
> 2.606
>
>
> -----Original Message-----
> From: Kyle Penner [mailto:kpenner at as.arizona.edu]
> Sent: Wednesday, June 12, 2013 3:49 PM
> To: Terry Therneau
> Cc: r-help at r-project.org
> Subject: Re: [R] survreg with measurement uncertainties
>
> Hi Terry,
>
> Thanks for your quick reply.  I am talking about uncertainty in the response.  I have 2 follow up questions:
>
> 1) my understanding from the documentation is that 'id' in cluster(id) should be the same when the predictors are not independent.  Is this correct?  (To be more concrete: my data are brightnesses at different wavelengths.  Each brightness is an independent measurement, so the elements of id should all be different?)
>
> 2) I tested survreg with uncertainties on an example where I already know the answer (and where I am not using limits), and it does not converge.  Below is the code I used, does anything jump out as incorrect?
>
> data = c(144.53, 1687.68, 5397.91)
> err = c(8.32, 471.22, 796.67)
> model = c(71.60, 859.23, 1699.19)
> id = c(1, 2, 3)
>
> This works (2.9 is the answer from simple chi_sq fitting):
>
> survreg(Surv(time = data, event = c(1,1,1))~model-1, dist='gaussian',
> init=c(2.9))
>
> This does not converge (2.1 is the answer from chi_sq fitting):
>
> survreg(Surv(time = data, event = c(1,1,1))~model-1+cluster(id), weights=1/(err^2), dist='gaussian', init=c(2.1))
>
> And this does, but the answer it returns is wonky:
>
> data[2] = 3*err[2] # data[2] is very close to 3*err[2] already survreg(Surv(time = data, event = c(1,2,1))~model-1+cluster(id), weights=1/(err^2), dist='gaussian', init=c(2.1))
>
> Thanks,
>
> Kyle
>
> On Wed, Jun 12, 2013 at 6:51 AM, Terry Therneau <therneau at mayo.edu> wrote:
>> I will assume that you are talking about uncertainty in the response.
>> Then one simple way to fit the model is to use case weights that are
>> proprional to 1/variance, along with +cluster(id) in the model
>> statement to get a correct variance for this case.  In linear models
>> this would be called the "White" or "Horvitz-Thompsen" or "GEE working
>> independence" variance estimate, depending on which literature you
>> happen to be reading (economics, survey sampling, or biostat).
>>
>> Now if you are talking about errors in the predictor variables, that
>> is a much harder problem.
>>
>> Terry Therneau
>>
>>
>>
>> On 06/12/2013 05:00 AM, Kyle Penner wrote:
>>>
>>> Hello,
>>>
>>> I have some measurements that I am trying to fit a model to.  I also
>>> have uncertainties for these measurements.  Some of the measurements
>>> are not well detected, so I'd like to use a limit instead of the
>>> actual measurement.  (I am always dealing with upper limits, i.e.
>>> left censored data.)
>>>
>>> I have successfully run survreg using the combination of well
>>> detected measurements and limits, but I would like to include the
>>> measurement uncertainty (for the well detected measurements) in the
>>> fitting.  As far as I can tell, survreg doesn't support this.  Does
>>> anyone have a suggestion for how to accomplish this?
>>>
>>> Thanks,
>>>
>>> Kyle
>
>
> **********************************************************
> Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues


From ejoffe at hotmail.com  Fri Jun 14 20:05:17 2013
From: ejoffe at hotmail.com (Erel JOFFE)
Date: Fri, 14 Jun 2013 18:05:17 +0000
Subject: [R] addtable2plot problem with adding summary object
Message-ID: <DUB114-W28D93B55FA05D7FBF93377CA800@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130614/9c62d271/attachment.pl>

From gunter.berton at gene.com  Fri Jun 14 22:25:26 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 14 Jun 2013 13:25:26 -0700
Subject: [R] rename and concatenate name of columns
In-Reply-To: <BDF430E1-94E1-4D2E-A2EA-3D96AB8C4AF1@comcast.net>
References: <CAKy1A=E7HUHjTiefN=bwP-ncvxgM_iUs=mtLvazWDTj3Ttx0QQ@mail.gmail.com>
	<BDF430E1-94E1-4D2E-A2EA-3D96AB8C4AF1@comcast.net>
Message-ID: <CACk-te3Kv2nH5Y7Kk3hUwy350cHk_L-i8FESN05ipe+QHJt6uQ@mail.gmail.com>

For the record:

...

------------
>
> A bit of commentary: Something did happen. It's just that you didn't do anything with _what_ happened. The copy of the 'dataset'-object got modified but you never returned it from the function, and and also didn't reassign it to the original 'dataset'. Functions return their last assignment. In the case of the 'for'-function, it somewhat surprisingly returns a NULL. It is a rather odd function in the functional R world, since its main role in life is doing things by side-effects,
---------

for() is **not** a function.

?"for" describes it as a "basic control-flow [sic] construct."

Ergo, it's behavior is not odd.


Cheers,
Bert



and so when used inside functions has seemingly paradoxical behavior.
Check your results with:
>
> rename_columns <- function(dataset) {
> for (i in 2:(ncol(dataset))) {names(dataset)[i] <- paste(names(dataset)[1],
> names(dataset)[i], sep="_")
> }
> dataset}
>
> dataset <- rename_columns(dataset)
>
>>       [[alternative HTML version deleted]]
>
> And do learn to post in plain text.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From smartpink111 at yahoo.com  Sat Jun 15 00:05:02 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 14 Jun 2013 15:05:02 -0700 (PDT)
Subject: [R] matched samples, dataframe, panel data
In-Reply-To: <104083AE5AAA634C993249DFCCE4C20306440637@CIPRESTE.ua.pt>
References: <104083AE5AAA634C993249DFCCE4C20306440637@CIPRESTE.ua.pt>
Message-ID: <1371247502.28146.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
I changed the fun1().? Now, it should be possible to get all the possible combinations within each group.


final3New<-read.table(file="real_data_cecilia.txt",sep="\t",header=T)
final3New1<-read.csv("real_data_cecilia_new.csv")
fun1New<- function(dat,percent,number){
??? lst1<- split(dat,list(dat$year,dat$industry))
??? lst2<- lst1[lapply(lst1,nrow)>1]
??? lst3<- lapply(lst2,function(x) {
??? ??? ??? ??? ??? CombN1<-combn(seq_len(nrow(x)),2)
??? ??? ??? ??? ??? lapply(split(CombN1,col(CombN1)),function(y){
??? ??? ??? ??? ??? ??? ??? x1<-x[y,]
??? ??? ??? ??? ??? ??? ??? x1[sum(x1$dummy)==1,]
??? ??? ??? ??? ??? ??? ??? })
??? ??? ??? ??? ??? })

??????? lst4<- lapply(lst3,function(x) x[lapply(x,nrow)>0])
??? lst5<- lst4[lapply(lst4,length)>0]
??? lst6<- lapply(lst5,function(x){
??? ??? ??? ??? ?? lapply(x,function(y){
??? ??? ??? ??? ??? x1<- abs(diff(y$dimension))< number
??? ??? ??? ??? ??? x2<- y$dimension[2]+ (y$dimension[2]*percent)
??? ??? ??? ??? ??? x3<- y$dimension[2]- (y$dimension[2]*percent)
??? ??? ??? ??? ??? x4<- (y$dimension[1] < x2) & (y$dimension[1] > x3)
??? ??? ??? ??? ??? y[x4 & x1,]
??? ??? ??? ??? ??? })
??? ??? ??? ??? ??? }
??? ??? ??? ??? ??? )
??? lst7<- lapply(lst6,function(x) x[lapply(x,nrow)>0])
??? lst8<- lst7[lapply(lst7,length)>0]
??? res<- do.call(rbind,lapply(lst8,function(x){
??? ??? ??? ??? ??? ?????? do.call(rbind,x)
??? ??? ??? ??? ??? ??? }))
??? row.names(res)<- 1:nrow(res)
??? res
??? }??? 
??? ??? ??? ??? ??? 
##Applying fun1New
res5Percent<- fun1New(final3New,0.05,50)
dim(res5Percent)
#[1] 718?? 5
res5PercentHigh<- fun1New(final3New,0.05,500000)
?dim(res5PercentHigh)
#[1] 2788??? 5

res5Percent1<- fun1New(final3New1,0.05,50)
dim(res5Percent1)
#[1] 870?? 5
res5Percent1High<- fun1New(final3New1,0.05,500000)
dim(res5Percent1High)
#[1] 2902??? 5

res10Percent<- fun1New(final3New,0.10,200)
dim(res10Percent)
#[1] 2928??? 5
res10Percent1<- fun1New(final3New1,0.10,200)
dim(res10Percent1)
#[1] 3092??? 5

fun3<- function(dat){
????????? indx<- duplicated(dat)
??? ? dat1<- subset(dat[indx,],dummy==1)
??? ? dat0<- subset(dat[indx,],dummy==0)
??? ? indx1<- as.numeric(row.names(dat1))
??? ?indx11<- sort(c(indx1,indx1+1))
??? ?indx0<- as.numeric(row.names(dat0))
??? ?indx00<- sort(c(indx0,indx0-1))
??? ? indx10<- sort(c(indx11,indx00))
??? ?res <- dat[-indx10,]
??? res
??? }




#Applying fun3()
res5F3<- fun3(res5Percent)
dim(res5F3)
#[1] 278?? 5

res5F3High<- fun3(res5PercentHigh)
dim(res5F3High)
#[1] 546?? 5

res5F3_1<- fun3(res5Percent1)
#[1] 302?? 5
res5F3High_1<- fun3(res5Percent1High)
dim(res5F3High_1)
#[1] 570?? 5

res10F3<- fun3(res10Percent)
dim(res10F3)
#[1] 462?? 5
res10F3_1<- fun3(res10Percent1)
#[1] 474?? 5
nrow(subset(res5F3,dummy==0))
#[1] 139
?nrow(subset(res5F3,dummy==1))
#[1] 139


?nrow(subset(res5F3High,dummy==1))
#[1] 273
?nrow(subset(res5F3High,dummy==0))
#[1] 273


?nrow(subset(res10F3,dummy==0))
#[1] 231
?nrow(subset(res10F3,dummy==1))
#[1] 231
?nrow(subset(res10F3_1,dummy==1))
#[1] 237
?nrow(subset(res10F3_1,dummy==0))
#[1] 237
?dim(unique(res5F3))
#[1] 278?? 5
dim(unique(res5F3High))
#[1] 546?? 5

?dim(unique(res10F3_1))
#[1] 474?? 5
?dim(unique(res10F3))
#[1] 462?? 5
A.K.



________________________________
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com> 
Sent: Friday, June 14, 2013 10:44 AM
Subject: me again




There some matchs that are missing. That is, it is possible to have more matchs.
I'm sending you a sript and the data.

Than you.
Cec?lia?


From hnorpois at gmail.com  Fri Jun 14 21:51:40 2013
From: hnorpois at gmail.com (Hermann Norpois)
Date: Fri, 14 Jun 2013 21:51:40 +0200
Subject: [R] combination of columns in a matrix
Message-ID: <CAKyZeBsJH62pJ9Xu3vzm2XM=u=2kAVYeGGSfgkLVVzZPiERE-g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130614/7f9b45ea/attachment.pl>

From mahajanr at vcu.edu  Fri Jun 14 23:07:21 2013
From: mahajanr at vcu.edu (Rahul Mahajan)
Date: Fri, 14 Jun 2013 17:07:21 -0400
Subject: [R] significance testing for the difference in the ratio of means
Message-ID: <CAB4NwkCbxRYb+BtRKMu--eyR1eNAik813_8fgFiKFAmPx7LZ6A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130614/595cea06/attachment.pl>

From smartpink111 at yahoo.com  Sat Jun 15 00:38:02 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 14 Jun 2013 15:38:02 -0700 (PDT)
Subject: [R] combination of columns in a matrix
In-Reply-To: <CAKyZeBsJH62pJ9Xu3vzm2XM=u=2kAVYeGGSfgkLVVzZPiERE-g@mail.gmail.com>
References: <CAKyZeBsJH62pJ9Xu3vzm2XM=u=2kAVYeGGSfgkLVVzZPiERE-g@mail.gmail.com>
Message-ID: <1371249482.12736.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
sapply(colnames(m)[-ncol(m)],function(i) {x1<-cbind(m[,i],m[,ncol(m)]); length(which(x1[,1]!=0 & x1[,2]!=0))})
#A B C 
#2 1 2 
A.K.



----- Original Message -----
From: Hermann Norpois <hnorpois at gmail.com>
To: r-help <r-help at r-project.org>
Cc: 
Sent: Friday, June 14, 2013 3:51 PM
Subject: [R] combination of columns in a matrix

Hello,

I have a matrix m and I want to know how often does 1 (or !0) simultanously
appear in A and REF, B and REF, C and REF.

So actually I wish to automate following expression:
> length (which (m[,1]!=0&m[,4]!=0))
[1] 2
> length (which (m[,2]!=0&m[,4]!=0))
[1] 1



Thanks
Hermann

> m
?  A B C REF
r1 1 0 0?  1
r2 1 1 0?  0
r3 0 0 1?  1
r4 0 0 1?  1
r5 1 1 0?  1
> dput (m)
structure(c(1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,
1, 1, 1), .Dim = c(5L, 4L), .Dimnames = list(c("r1", "r2", "r3",
"r4", "r5"), c("A", "B", "C", "REF")))

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From gunter.berton at gene.com  Sat Jun 15 01:13:42 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 14 Jun 2013 16:13:42 -0700
Subject: [R] significance testing for the difference in the ratio of
	means
In-Reply-To: <CAB4NwkCbxRYb+BtRKMu--eyR1eNAik813_8fgFiKFAmPx7LZ6A@mail.gmail.com>
References: <CAB4NwkCbxRYb+BtRKMu--eyR1eNAik813_8fgFiKFAmPx7LZ6A@mail.gmail.com>
Message-ID: <CACk-te1j4vG_s+YEM=vtj2AAYJMcs9hS594_afkEe43KOu8nUg@mail.gmail.com>

Sigh...

(Again!) These are primarily statistical, not R, issues.  I would urge
that you seek local statistical help. You appear to be approaching
this with a good deal of semi-informed adhoc-ery. Standard methodology
should be applicable, but it would be presumptuous and ill-advised of
me to offer specifics remotely  without understanding in detail the
goals of your research, the nature of your design (e.g. protocols,
randomization?), and the behavior of your data (what do appropriate
plots tell you??)

Others may be bolder. Proceed at your own risk.

Cheers,
Bert

On Fri, Jun 14, 2013 at 2:07 PM, Rahul Mahajan <mahajanr at vcu.edu> wrote:
> I have a question regarding significance testing for the difference in the
> ratio of means.
> The data consists of a control and a test group, each with and without
> treatment.  I am interested in testing if the treatment has a significantly
> different effect (say, in terms of fold-activation) on the test group
> compared to the control.
>
> The form of the data with arbitrary n and not assuming equal variance:
>
> m1 = mean of (control group) n = 7
> m2 = mean of (control group w/ treatment) n=  10
> m3 = mean of (test group) n = 8
> m4 = mean of (test group w/ treatment) n = 9
>
> H0: m2/m1 = m4/m3
> restated,
> H0: m2/m1 - m4/m3 = 0;
>
> Method 1: Fieller's Intervals
> Use fieller's theorum available in R as part of the mratios package.  This
> is a promising way to compute standard error/confidence intervals for each
> of the two ratios but will not yield p-values for significance testing.
>  Significance by non-overlap of confidence intervals is too stringent a
> test and will lead to frequent type II errors.
>
> Method 2: Bootstrap
> Abandoning an analytical solution, we try a numerical solution.  I can
> repeatedly (1000 or 10,000 times)  draw with replacement samples of size
> 7,10,8,9 from m1,m2,m3,m4 respectively.  Each iteration, I can compute the
> ratio for m2/m1 and m4/m3 as well as the difference.  Standard deviations
> of the m2/m1 and the m4/m3 bootstrap distributions can give me standard
> errors for these two ratios.  Then, I can test to see where "0" falls on
> the third distribution, the distribution of the difference of the ratios.
>  If 0 falls on one of the tails, beyond the 2.5th or 97.5th percentile, I
> can declare a significant difference in the two ratios.  My question here
> is if I can correctly report the percentile location of "0" as the p-value?
>
> Method 3: Permutation test
> I understand the best way to obtain a p-value for the significance test
> would be to resample under the null hypothesis.  However, as I am comparing
> the ratio of means, I do not have individual observations to randomize
> between the groups.  The best I can think to do is create an exhaustive
> list of all (7x10) = 70 possible observations for m2/m1 from the data.
>  Then create a similar list of all (8x9) = 72 possible observations for
> m4/m3. Pool all (70+72) = 142 observations and repeatedly randomly assign
> them to two groups  of size 70 and 72 to represent the two ratios and
> compute the difference in means.  This distribution could represent the
> distribution under the null hypothesis and I could then measure where my
> observed value falls to compute the p-value.  This however, makes me
> uncomfortable as it seems to treat the data as a "mean of ratios" rather
> than a "ratio of means".
>
> Method 4: Combination of bootstrap and permutation test
> Sample with replacement samples of size 7,10,8,9 from m1,m2,m3,m4
> respectively as in method 2 above.  Calculate the two ratios for these 4
> samples (m2/m1 and m4/m3).  Record these two ratios into a list.  Repeat
> this process an arbitrary (B) number of times and record the two ratios
> into your growing list each time.  Hence if B = 10, we will have 20
> observations of the ratios.  Then proceed with permutation testing with
> these 20 ratio observations by repeatedly randomizing them into two equal
> groups of 10 and computing the difference in means of the two groups as we
> did in method 3 above.  This could potentially yeild a distribution under
> the null hypothesis and p-values could be obtained by localizing the
> observed value on this distribution.  I am unsure of appropriate values for
> B or if this method is valid at all.
>
> Another complication would be the concern for multiple comparisons if I
> wished to include additional  test groups (m5 = testgroup2; m6 = testgroup2
> w/ treatment; m7 = testgroup3, m8 = testgoup3 w/ treatment...etc) and how
> that might be appropriately handled.
>
> Method 2 seems the most intuitive to me.  Bootstrapping this way will
> likely yield appropriate Starndard Errors for the two ratios.  However, I
> am very much interested in appropriate p-values for the comparison and I am
> not sure if localizing "0" on the bootstrap distribution of the difference
> of means is appropriate.
>
> Thank you in advance for your suggestions.
>
> -Rahul
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From dwinsemius at comcast.net  Sat Jun 15 02:45:46 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 14 Jun 2013 17:45:46 -0700
Subject: [R] rename and concatenate name of columns
In-Reply-To: <CACk-te3Kv2nH5Y7Kk3hUwy350cHk_L-i8FESN05ipe+QHJt6uQ@mail.gmail.com>
References: <CAKy1A=E7HUHjTiefN=bwP-ncvxgM_iUs=mtLvazWDTj3Ttx0QQ@mail.gmail.com>
	<BDF430E1-94E1-4D2E-A2EA-3D96AB8C4AF1@comcast.net>
	<CACk-te3Kv2nH5Y7Kk3hUwy350cHk_L-i8FESN05ipe+QHJt6uQ@mail.gmail.com>
Message-ID: <029620D3-114F-4A66-9644-BCF62C9F1AD7@comcast.net>


On Jun 14, 2013, at 1:25 PM, Bert Gunter wrote:

> For the record:
> 
> ...
> 
> ------------
>> 
>> A bit of commentary: Something did happen. It's just that you didn't do anything with _what_ happened. The copy of the 'dataset'-object got modified but you never returned it from the function, and and also didn't reassign it to the original 'dataset'. Functions return their last assignment.

This line was probably more worthy of criticism. Functions return the result of last evaluated expression. (Which is often not what the beginning R programmer expected.)

>> In the case of the 'for'-function, it somewhat surprisingly returns a NULL. It is a rather odd function in the functional R world, since its main role in life is doing things by side-effects,
> ---------
> 
> for() is **not** a function.
> 
> ?"for" describes it as a "basic control-flow [sic] construct."

Nonetheless it does return NULL.
> 
> Ergo, it's behavior is not odd.

That remains a matter of opinion.

-- 
David


> 
> 
> Cheers,
> Bert
> 
> 
> 
> and so when used inside functions has seemingly paradoxical behavior.
> Check your results with:
>> 
>> rename_columns <- function(dataset) {
>> for (i in 2:(ncol(dataset))) {names(dataset)[i] <- paste(names(dataset)[1],
>> names(dataset)[i], sep="_")
>> }
>> dataset}
>> 
>> dataset <- rename_columns(dataset)
>> 
>>>      [[alternative HTML version deleted]]
>> 
>> And do learn to post in plain text.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> 
> Internal Contact Info:
> Phone: 467-7374
> Website:
> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm

David Winsemius
Alameda, CA, USA


From dkesh at qcue.com  Sat Jun 15 01:02:33 2013
From: dkesh at qcue.com (Dan Keshet)
Date: Fri, 14 Jun 2013 18:02:33 -0500
Subject: [R] "Error: cannot allocate vector of size 1.9 Gb" when loading
	xtable help
Message-ID: <CANhnsHOocoRGs8-29aO5JYoS4fSRi0J4dZ1Pd5yngNcqjCaraw@mail.gmail.com>

I am using xtable version 1.7-1 built for R 3.0.1 on:

R version 3.0.1 (2013-05-16)
Platform: i686-pc-linux-gnu (32-bit)

Sometimes, not every time, when I load xtable or attempt to load the
help, I get an error such as this "Error: cannot allocate vector of
size 1.9 Gb" (Stacktrace from recover() below).

Other times, when loading packages that depend on xtable, I get an
error such as this:

Loading required namespace: xtable
Error in assign(identifier, list(name, description, identifier, help,  :
  lazy-load database 'P' is corrupt

I have attempted to reinstall the package using
install.packages("xtable", type="source"), but the error persists (and
the xtable.rdb file is identical).

I have also tried this on macs and gotten the same error.

Thank you for any help.

-------------
> ?xtable
Error: cannot allocate vector of size 1.9 Gb

Enter a frame number, or 0 to exit

1: print("/usr/local/analytics/rlibs/xtable/help/xtable")
2: print.help_files_with_topic("/usr/local/analytics/rlibs/xtable/help/xtable"
3: tools::Rd2txt(.getHelpFile(file), out = tempfile("Rtxt"), package = pkgname
4: prepare_Rd(Rd, defines = defines, stages = stages, fragment = fragment, ...
5: .getHelpFile(file)
6: tools:::fetchRdDB(RdDB, basename(file))
7: lazyLoadDBexec(filebase, fun)
8: fun(environment())
9: fetch(key)


From mahajanr at vcu.edu  Sat Jun 15 04:36:25 2013
From: mahajanr at vcu.edu (Rahul Mahajan)
Date: Fri, 14 Jun 2013 22:36:25 -0400
Subject: [R] significance testing for the difference in the ratio of
	means
Message-ID: <CAB4NwkB6WNz-4OT1NxjdN-PCHhXGkA5qJHLRHepUzCUT8sA-hQ@mail.gmail.com>

My apologies if my request is off topic and for my admittedly
half-baked understanding of the topic.  I'm afraid trying to talk with
the "local statistical help", and trying to post on several general
statistical forums to look for proper guidance has not yielded any
response much less any helpful ones.  I turned to this forum in
desperation because 1) I will be using R to implement the chosen
strategy and 2) looking through the archives of this forum seemed
promising especially because of past helpful posts as this:

https://stat.ethz.ch/pipermail/r-help/2009-April/194843.html

Perhaps you can suggest a resource which would cover the applicable
"standard methodology" and perhaps its implementation in R?  I would
truly appreciate any guidance.

My protocols/design = each observation within the 4 groups represents
a recording of a continuous variable (whole-cell current from 1 cell
in electrophysiology measurements).  The data for each group appears
roughly normal (albeit small n values from 7-10 per group).  The
variance is not equal among the groups because it seems to vary with
the mean, ie larger currents = larger absolute variance.  There is no
explicit randomization involved as these observations are merely the
measurements of wholecell currents for cells receiving an identical
experimental treatment.  I am interested comparing the
"fold-activation" effect of the treatment for control cells versus for
testgroup cells which have differing baseline pre-treatment current
values.

Best,
Rahul




On Fri, Jun 14, 2013 at 7:13 PM, Bert Gunter <gunter.berton at gene.com> wrote:
> Sigh...
>
> (Again!) These are primarily statistical, not R, issues.  I would urge
> that you seek local statistical help. You appear to be approaching
> this with a good deal of semi-informed adhoc-ery. Standard methodology
> should be applicable, but it would be presumptuous and ill-advised of
> me to offer specifics remotely  without understanding in detail the
> goals of your research, the nature of your design (e.g. protocols,
> randomization?), and the behavior of your data (what do appropriate
> plots tell you??)
>
> Others may be bolder. Proceed at your own risk.
>
> Cheers,
> Bert
>
> On Fri, Jun 14, 2013 at 2:07 PM, Rahul Mahajan <mahajanr at vcu.edu> wrote:
>> I have a question regarding significance testing for the difference in the
>> ratio of means.
>> The data consists of a control and a test group, each with and without
>> treatment.  I am interested in testing if the treatment has a significantly
>> different effect (say, in terms of fold-activation) on the test group
>> compared to the control.
>>
>> The form of the data with arbitrary n and not assuming equal variance:
>>
>> m1 = mean of (control group) n = 7
>> m2 = mean of (control group w/ treatment) n=  10
>> m3 = mean of (test group) n = 8
>> m4 = mean of (test group w/ treatment) n = 9
>>
>> H0: m2/m1 = m4/m3
>> restated,
>> H0: m2/m1 - m4/m3 = 0;
>>
>> Method 1: Fieller's Intervals
>> Use fieller's theorum available in R as part of the mratios package.  This
>> is a promising way to compute standard error/confidence intervals for each
>> of the two ratios but will not yield p-values for significance testing.
>>  Significance by non-overlap of confidence intervals is too stringent a
>> test and will lead to frequent type II errors.
>>
>> Method 2: Bootstrap
>> Abandoning an analytical solution, we try a numerical solution.  I can
>> repeatedly (1000 or 10,000 times)  draw with replacement samples of size
>> 7,10,8,9 from m1,m2,m3,m4 respectively.  Each iteration, I can compute the
>> ratio for m2/m1 and m4/m3 as well as the difference.  Standard deviations
>> of the m2/m1 and the m4/m3 bootstrap distributions can give me standard
>> errors for these two ratios.  Then, I can test to see where "0" falls on
>> the third distribution, the distribution of the difference of the ratios.
>>  If 0 falls on one of the tails, beyond the 2.5th or 97.5th percentile, I
>> can declare a significant difference in the two ratios.  My question here
>> is if I can correctly report the percentile location of "0" as the p-value?
>>
>> Method 3: Permutation test
>> I understand the best way to obtain a p-value for the significance test
>> would be to resample under the null hypothesis.  However, as I am comparing
>> the ratio of means, I do not have individual observations to randomize
>> between the groups.  The best I can think to do is create an exhaustive
>> list of all (7x10) = 70 possible observations for m2/m1 from the data.
>>  Then create a similar list of all (8x9) = 72 possible observations for
>> m4/m3. Pool all (70+72) = 142 observations and repeatedly randomly assign
>> them to two groups  of size 70 and 72 to represent the two ratios and
>> compute the difference in means.  This distribution could represent the
>> distribution under the null hypothesis and I could then measure where my
>> observed value falls to compute the p-value.  This however, makes me
>> uncomfortable as it seems to treat the data as a "mean of ratios" rather
>> than a "ratio of means".
>>
>> Method 4: Combination of bootstrap and permutation test
>> Sample with replacement samples of size 7,10,8,9 from m1,m2,m3,m4
>> respectively as in method 2 above.  Calculate the two ratios for these 4
>> samples (m2/m1 and m4/m3).  Record these two ratios into a list.  Repeat
>> this process an arbitrary (B) number of times and record the two ratios
>> into your growing list each time.  Hence if B = 10, we will have 20
>> observations of the ratios.  Then proceed with permutation testing with
>> these 20 ratio observations by repeatedly randomizing them into two equal
>> groups of 10 and computing the difference in means of the two groups as we
>> did in method 3 above.  This could potentially yeild a distribution under
>> the null hypothesis and p-values could be obtained by localizing the
>> observed value on this distribution.  I am unsure of appropriate values for
>> B or if this method is valid at all.
>>
>> Another complication would be the concern for multiple comparisons if I
>> wished to include additional  test groups (m5 = testgroup2; m6 = testgroup2
>> w/ treatment; m7 = testgroup3, m8 = testgoup3 w/ treatment...etc) and how
>> that might be appropriately handled.
>>
>> Method 2 seems the most intuitive to me.  Bootstrapping this way will
>> likely yield appropriate Starndard Errors for the two ratios.  However, I
>> am very much interested in appropriate p-values for the comparison and I am
>> not sure if localizing "0" on the bootstrap distribution of the difference
>> of means is appropriate.
>>
>> Thank you in advance for your suggestions.
>>
>> -Rahul
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
>
> Internal Contact Info:
> Phone: 467-7374
> Website:
> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From ral at lcfltd.com  Sat Jun 15 05:59:18 2013
From: ral at lcfltd.com (Robert A LaBudde)
Date: Fri, 14 Jun 2013 23:59:18 -0400
Subject: [R] significance testing for the difference in the ratio
	of	means
In-Reply-To: <CAB4NwkB6WNz-4OT1NxjdN-PCHhXGkA5qJHLRHepUzCUT8sA-hQ@mail.g
	mail.com>
References: <CAB4NwkB6WNz-4OT1NxjdN-PCHhXGkA5qJHLRHepUzCUT8sA-hQ@mail.gmail.com>
Message-ID: <0MOF005QD1R4K840@vms173005.mailsrvcs.net>

The fact that your currents are apparently intrinsically positive and 
the variance increases with current plus the fact that you are 
interested in ratio statistics suggests that your data would benefit 
from an initial log transform of the data. All of your issues would 
then disappear, given that the log-transformed data were roughly 
normally distributed.

At 10:36 PM 6/14/2013, Rahul Mahajan wrote:
>My apologies if my request is off topic and for my admittedly
>half-baked understanding of the topic.  I'm afraid trying to talk with
>the "local statistical help", and trying to post on several general
>statistical forums to look for proper guidance has not yielded any
>response much less any helpful ones.  I turned to this forum in
>desperation because 1) I will be using R to implement the chosen
>strategy and 2) looking through the archives of this forum seemed
>promising especially because of past helpful posts as this:
>
>https://stat.ethz.ch/pipermail/r-help/2009-April/194843.html
>
>Perhaps you can suggest a resource which would cover the applicable
>"standard methodology" and perhaps its implementation in R?  I would
>truly appreciate any guidance.
>
>My protocols/design = each observation within the 4 groups represents
>a recording of a continuous variable (whole-cell current from 1 cell
>in electrophysiology measurements).  The data for each group appears
>roughly normal (albeit small n values from 7-10 per group).  The
>variance is not equal among the groups because it seems to vary with
>the mean, ie larger currents = larger absolute variance.  There is no
>explicit randomization involved as these observations are merely the
>measurements of wholecell currents for cells receiving an identical
>experimental treatment.  I am interested comparing the
>"fold-activation" effect of the treatment for control cells versus for
>testgroup cells which have differing baseline pre-treatment current
>values.
>
>Best,
>Rahul
>
>
>
>
>On Fri, Jun 14, 2013 at 7:13 PM, Bert Gunter <gunter.berton at gene.com> wrote:
> > Sigh...
> >
> > (Again!) These are primarily statistical, not R, issues.  I would urge
> > that you seek local statistical help. You appear to be approaching
> > this with a good deal of semi-informed adhoc-ery. Standard methodology
> > should be applicable, but it would be presumptuous and ill-advised of
> > me to offer specifics remotely  without understanding in detail the
> > goals of your research, the nature of your design (e.g. protocols,
> > randomization?), and the behavior of your data (what do appropriate
> > plots tell you??)
> >
> > Others may be bolder. Proceed at your own risk.
> >
> > Cheers,
> > Bert
> >
> > On Fri, Jun 14, 2013 at 2:07 PM, Rahul Mahajan <mahajanr at vcu.edu> wrote:
> >> I have a question regarding significance testing for the difference in the
> >> ratio of means.
> >> The data consists of a control and a test group, each with and without
> >> treatment.  I am interested in testing if the treatment has a 
> significantly
> >> different effect (say, in terms of fold-activation) on the test group
> >> compared to the control.
> >>
> >> The form of the data with arbitrary n and not assuming equal variance:
> >>
> >> m1 = mean of (control group) n = 7
> >> m2 = mean of (control group w/ treatment) n=  10
> >> m3 = mean of (test group) n = 8
> >> m4 = mean of (test group w/ treatment) n = 9
> >>
> >> H0: m2/m1 = m4/m3
> >> restated,
> >> H0: m2/m1 - m4/m3 = 0;
> >>
> >> Method 1: Fieller's Intervals
> >> Use fieller's theorum available in R as part of the mratios package.  This
> >> is a promising way to compute standard error/confidence intervals for each
> >> of the two ratios but will not yield p-values for significance testing.
> >>  Significance by non-overlap of confidence intervals is too stringent a
> >> test and will lead to frequent type II errors.
> >>
> >> Method 2: Bootstrap
> >> Abandoning an analytical solution, we try a numerical solution.  I can
> >> repeatedly (1000 or 10,000 times)  draw with replacement samples of size
> >> 7,10,8,9 from m1,m2,m3,m4 respectively.  Each iteration, I can compute the
> >> ratio for m2/m1 and m4/m3 as well as the difference.  Standard deviations
> >> of the m2/m1 and the m4/m3 bootstrap distributions can give me standard
> >> errors for these two ratios.  Then, I can test to see where "0" falls on
> >> the third distribution, the distribution of the difference of the ratios.
> >>  If 0 falls on one of the tails, beyond the 2.5th or 97.5th percentile, I
> >> can declare a significant difference in the two ratios.  My question here
> >> is if I can correctly report the percentile location of "0" as 
> the p-value?
> >>
> >> Method 3: Permutation test
> >> I understand the best way to obtain a p-value for the significance test
> >> would be to resample under the null hypothesis.  However, as I 
> am comparing
> >> the ratio of means, I do not have individual observations to randomize
> >> between the groups.  The best I can think to do is create an exhaustive
> >> list of all (7x10) = 70 possible observations for m2/m1 from the data.
> >>  Then create a similar list of all (8x9) = 72 possible observations for
> >> m4/m3. Pool all (70+72) = 142 observations and repeatedly randomly assign
> >> them to two groups  of size 70 and 72 to represent the two ratios and
> >> compute the difference in means.  This distribution could represent the
> >> distribution under the null hypothesis and I could then measure where my
> >> observed value falls to compute the p-value.  This however, makes me
> >> uncomfortable as it seems to treat the data as a "mean of ratios" rather
> >> than a "ratio of means".
> >>
> >> Method 4: Combination of bootstrap and permutation test
> >> Sample with replacement samples of size 7,10,8,9 from m1,m2,m3,m4
> >> respectively as in method 2 above.  Calculate the two ratios for these 4
> >> samples (m2/m1 and m4/m3).  Record these two ratios into a list.  Repeat
> >> this process an arbitrary (B) number of times and record the two ratios
> >> into your growing list each time.  Hence if B = 10, we will have 20
> >> observations of the ratios.  Then proceed with permutation testing with
> >> these 20 ratio observations by repeatedly randomizing them into two equal
> >> groups of 10 and computing the difference in means of the two groups as we
> >> did in method 3 above.  This could potentially yeild a distribution under
> >> the null hypothesis and p-values could be obtained by localizing the
> >> observed value on this distribution.  I am unsure of appropriate 
> values for
> >> B or if this method is valid at all.
> >>
> >> Another complication would be the concern for multiple comparisons if I
> >> wished to include additional  test groups (m5 = testgroup2; m6 = 
> testgroup2
> >> w/ treatment; m7 = testgroup3, m8 = testgoup3 w/ treatment...etc) and how
> >> that might be appropriately handled.
> >>
> >> Method 2 seems the most intuitive to me.  Bootstrapping this way will
> >> likely yield appropriate Starndard Errors for the two ratios.  However, I
> >> am very much interested in appropriate p-values for the 
> comparison and I am
> >> not sure if localizing "0" on the bootstrap distribution of the difference
> >> of means is appropriate.
> >>
> >> Thank you in advance for your suggestions.
> >>
> >> -Rahul
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> >
> > Bert Gunter
> > Genentech Nonclinical Biostatistics
> >
> > Internal Contact Info:
> > Phone: 467-7374
> > Website:
> > 
> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

================================================================
Robert A. LaBudde, PhD, PAS, Dpl. ACAFS  e-mail: ral at lcfltd.com
Least Cost Formulations, Ltd.            URL: http://lcfltd.com/
824 Timberlake Drive                     Tel: 757-467-0954
Virginia Beach, VA 23464-3239            Fax: 757-467-2947

"Vere scire est per causas scire"


From entropy053 at gmail.com  Sat Jun 15 06:33:31 2013
From: entropy053 at gmail.com (Yasin Gocgun)
Date: Sat, 15 Jun 2013 00:33:31 -0400
Subject: [R] checking certain digits of a number in a column
Message-ID: <CAJJuoETJVSDqyHXT-Fz0vQrfkfYU6p995jekSL210AmD9ct7XA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130615/6836c7df/attachment.pl>

From dwinsemius at comcast.net  Sat Jun 15 06:45:48 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 14 Jun 2013 21:45:48 -0700
Subject: [R] checking certain digits of a number in a column
In-Reply-To: <CAJJuoETJVSDqyHXT-Fz0vQrfkfYU6p995jekSL210AmD9ct7XA@mail.gmail.com>
References: <CAJJuoETJVSDqyHXT-Fz0vQrfkfYU6p995jekSL210AmD9ct7XA@mail.gmail.com>
Message-ID: <CAFBF96C-DB17-400F-B9FE-DDB6A5951753@comcast.net>


On Jun 14, 2013, at 9:33 PM, Yasin Gocgun wrote:

> Hi,
> 
> I need to check whether certain digits of a number, say, last five digits,
> appear in a column of a data frame. For instance,
> 
> For example,103 in "000103" (  data [data[,3] == "...103"] instead of
> data [data[,3] == "000103"] ) or 54780 in "12354780". Can someone let me
> know how to do so.
> 

R has a 'substr' function.

--
David Winsemius
Alameda, CA, USA


From rainer.schuermann at gmx.net  Sat Jun 15 06:48:26 2013
From: rainer.schuermann at gmx.net (Rainer Schuermann)
Date: Sat, 15 Jun 2013 06:48:26 +0200
Subject: [R] checking certain digits of a number in a column
In-Reply-To: <CAJJuoETJVSDqyHXT-Fz0vQrfkfYU6p995jekSL210AmD9ct7XA@mail.gmail.com>
References: <CAJJuoETJVSDqyHXT-Fz0vQrfkfYU6p995jekSL210AmD9ct7XA@mail.gmail.com>
Message-ID: <2604181.3BIPRN9hVz@augeatur>

Try
?grep

or
library( stringr )
?str_detect




On Saturday 15 June 2013 00:33:31 Yasin Gocgun wrote:
> Hi,
> 
> I need to check whether certain digits of a number, say, last five digits,
> appear in a column of a data frame. For instance,
> 
> For example,103 in "000103" (  data [data[,3] == "...103"] instead of
> data [data[,3] == "000103"] ) or 54780 in "12354780". Can someone let me
> know how to do so.
> 
> Thanks in advance,
> 
> Yasin
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From debmidya at yahoo.com  Sat Jun 15 09:05:55 2013
From: debmidya at yahoo.com (Deb Midya)
Date: Sat, 15 Jun 2013 00:05:55 -0700 (PDT)
Subject: [R] Multi-Level classification
Message-ID: <1371279955.73724.YahooMailNeo@web141403.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130615/c69cbc14/attachment.pl>

From jickneba at yahoo.ie  Sat Jun 15 09:56:43 2013
From: jickneba at yahoo.ie (jickngea alexand)
Date: Sat, 15 Jun 2013 08:56:43 +0100 (BST)
Subject: [R] Reading shape files in R
Message-ID: <1371283003.98555.YahooMailNeo@web172103.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130615/3844a660/attachment.pl>

From laurent.franckx at vito.be  Sat Jun 15 10:45:55 2013
From: laurent.franckx at vito.be (Franckx Laurent)
Date: Sat, 15 Jun 2013 08:45:55 +0000
Subject: [R] passing of arguments to R CMD BATCH in bash script that is
 submitted to torque (Linux platform)
Message-ID: <3FA7C532AA08284AB2ACA7B0AB56EF870D971A82@vitomail4.vito.local>

Dear all

I want to call R repeatedly in batch mode from a bash script that is then submitted to torque.

My calls to R depend on optional arguments.

When I introduce these arguments as literals, the calls work fine, for instance:

R CMD BATCH  --no-save "--args PERIOD='08' YEAR='2008' SC='BAU' " preparecostvectors.R

However, the arguments PERIOD, YEAR and SC are really variables over which I 'loop'.

When these variables are defined in the same script as the call to R CMD BATCH, this still works, for instance:

year="2008"
sc="BAU"
R CMD BATCH  --no-save "--args PERIOD='08' YEAR=\"$year\" SC=\"$sc\"  " preparecostvectors.R

Things go wrong when the script is called from another script, for instanced with:

qsub -v year="2008",sc="BAU"  ATLAS_assign.sh

"echo $sc" and "echo $year" in ATLAS_assign.sh yield "BAU" and "2008" respectively.

Thus, as far as I can see, nothing goes wrong in the passing of the optional arguments in qsub.

However,

R CMD BATCH  --no-save "--args PERIOD='08' YEAR=\"$year\" SC=\"$sc\"  " preparecostvectors.R

is not executed. I do not get even an Rout file, so I suppose the R script is not even called.

I suppose there is something wrong in the format in which I submit year and sc, but I do not see what.


Laurent Franckx, PhD
VITO NV
Boeretang 200, 2400 MOL, Belgium
Tel. + 32 14 33 58 22
Skype: laurent.franckx
laurent.franckx at vito.be
Visit our website: www.vito.be/english and http://www.vito.be/transport











[http://www.vito.be/e-maildisclaimer/vito.png]


Ontdek hoe VITO de transitie naar een duurzame maatschappij op gang trekt: www.vito.be/duurzaamheidsverslag2012<http://www.vito.be/duurzaamheidsverslag2012>
Discover how VITO initiates the transition towards a sustainable society: www.vito.be/sustainabilityreport2012<http://www.vito.be/sustainabilityreport2012>


VITO Disclaimer: http://www.vito.be/e-maildisclaimer


From olacabaj at gmail.com  Sat Jun 15 12:36:23 2013
From: olacabaj at gmail.com (Ola Cabaj)
Date: Sat, 15 Jun 2013 12:36:23 +0200
Subject: [R] Trouble sorting the matrix
Message-ID: <CABdLAhQG5EVcqYzLjB8kL1UanVY9MMr9sk+ETVi92XJQwQanDA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130615/e87234a3/attachment.pl>

From djandrija at gmail.com  Sat Jun 15 13:15:56 2013
From: djandrija at gmail.com (andrija djurovic)
Date: Sat, 15 Jun 2013 13:15:56 +0200
Subject: [R] Trouble sorting the matrix
In-Reply-To: <CABdLAhQG5EVcqYzLjB8kL1UanVY9MMr9sk+ETVi92XJQwQanDA@mail.gmail.com>
References: <CABdLAhQG5EVcqYzLjB8kL1UanVY9MMr9sk+ETVi92XJQwQanDA@mail.gmail.com>
Message-ID: <CABcwgRRDfz=uLjWtmeM6-HDQWtqBR06n41RbAsCXvXOi7JLHwA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130615/18050b17/attachment.pl>

From murdoch.duncan at gmail.com  Sat Jun 15 13:18:16 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 15 Jun 2013 07:18:16 -0400
Subject: [R] "Error: cannot allocate vector of size 1.9 Gb" when loading
 xtable help
In-Reply-To: <CANhnsHOocoRGs8-29aO5JYoS4fSRi0J4dZ1Pd5yngNcqjCaraw@mail.gmail.com>
References: <CANhnsHOocoRGs8-29aO5JYoS4fSRi0J4dZ1Pd5yngNcqjCaraw@mail.gmail.com>
Message-ID: <51BC4D78.8020200@gmail.com>

On 13-06-14 7:02 PM, Dan Keshet wrote:
> I am using xtable version 1.7-1 built for R 3.0.1 on:
>
> R version 3.0.1 (2013-05-16)
> Platform: i686-pc-linux-gnu (32-bit)
>
> Sometimes, not every time, when I load xtable or attempt to load the
> help, I get an error such as this "Error: cannot allocate vector of
> size 1.9 Gb" (Stacktrace from recover() below).
>
> Other times, when loading packages that depend on xtable, I get an
> error such as this:
>
> Loading required namespace: xtable
> Error in assign(identifier, list(name, description, identifier, help,  :
>    lazy-load database 'P' is corrupt
>
> I have attempted to reinstall the package using
> install.packages("xtable", type="source"), but the error persists (and
> the xtable.rdb file is identical).
>
> I have also tried this on macs and gotten the same error.
>
> Thank you for any help.
>
> -------------
>> ?xtable
> Error: cannot allocate vector of size 1.9 Gb

I would guess this is not related to the xtable help page, but is a sign 
of something being corrupted (e.g. an out of range write in memory), and 
this is just a symptom of the corruption.

If we could make this reliably reproducible, we could track it down, but 
without that, it is nearly impossible.

Could try starting an empty R session (nothing reloaded from .Rdata),
run until you trigger the error, then save the session history?  See if 
replaying that history triggers the error again in the same place.  If 
so, see if you can shrink it to a minimal script that others can try, 
and post that.

Duncan Murdoch

>
> Enter a frame number, or 0 to exit
>
> 1: print("/usr/local/analytics/rlibs/xtable/help/xtable")
> 2: print.help_files_with_topic("/usr/local/analytics/rlibs/xtable/help/xtable"
> 3: tools::Rd2txt(.getHelpFile(file), out = tempfile("Rtxt"), package = pkgname
> 4: prepare_Rd(Rd, defines = defines, stages = stages, fragment = fragment, ...
> 5: .getHelpFile(file)
> 6: tools:::fetchRdDB(RdDB, basename(file))
> 7: lazyLoadDBexec(filebase, fun)
> 8: fun(environment())
> 9: fetch(key)
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch.duncan at gmail.com  Sat Jun 15 13:23:45 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 15 Jun 2013 07:23:45 -0400
Subject: [R] R session freezes when I try to save a new script
In-Reply-To: <8D03725DDC146D0-142C-77C5@Webmail-d104.sysops.aol.com>
References: <8D03725DDC146D0-142C-77C5@Webmail-d104.sysops.aol.com>
Message-ID: <51BC4EC1.3010702@gmail.com>

On 13-06-14 10:52 AM, anferg806 at aol.com wrote:
> All:
>
>
> Recently my R session freezes when I try to open a file or save a new script after I have run existing scripts.  The session freezes so that I can no longer click on any windows within the R session -- including other scripts that are open or the R console.  (I hear the "ding" sound when I try to click on anything.)  I have looked at the Task Manager on the computer and R is still running (and is still responsive according to the Task Manager), but I cannot do anything within R.  I have tried pressing Esc and that does not help.
>
>
> Any suggestions would be greatly appreciated!  I am using a 32 bit Windows 7 computer with 4gb ram and 250gb hard drive.
>
>
> Thanks in advance for any suggestions!

I have sometimes seen symptoms like that when an open file dialog gets 
hidden behind another window.  R is waiting for the dialog to complete, 
but since it is hidden, it never does.  Generally it pops up eventually; 
I'm not sure why it is allowed to be hidden at all.

Duncan Murdoch


From ruipbarradas at sapo.pt  Sat Jun 15 13:32:48 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 15 Jun 2013 12:32:48 +0100
Subject: [R] Trouble sorting the matrix
In-Reply-To: <CABdLAhQG5EVcqYzLjB8kL1UanVY9MMr9sk+ETVi92XJQwQanDA@mail.gmail.com>
References: <CABdLAhQG5EVcqYzLjB8kL1UanVY9MMr9sk+ETVi92XJQwQanDA@mail.gmail.com>
Message-ID: <51BC50E0.8020202@sapo.pt>

Hello,

If I understand it correctly, the following should sort all columns of 
matrix3 and then unsort the sorted matrix.


ord <- apply(matrix3, 2, order)

# sort matrix3
mat4 <- sapply(seq_len(ncol(ord)), function(i) matrix3[ord[,i], i])
mat4

# unsort mat4
mat5 <- sapply(seq_len(ncol(ord)), function(i) mat4[order(ord[,i]), i])

identical(matrix3, mat5)  # TRUE


Hope this helps,

Rui Barradas

Em 15-06-2013 11:36, Ola Cabaj escreveu:
> I would like to sort matrix3, so that every column in output matrix is
> sorted. Also I have to "unsort" it later on.
>
> matrix1<-matrix(rnorm(100,354,78),ncol=10)
> matrix2<-matrix(rnorm(100,225,102),ncol=10)
> matrix3<-cbind(matrix1,matrix2)
> nrCol<-length(matrix3[1,])
> class1<-1:10
>    for(i in 1:nrCol)
>    {
>      sorted.matrix<-matrix3[order(matrix3[class1,i]),]
>    }
>   for(i in 1:liczbaKolumn)
>    {
>     output<-sorted.matrix[order(matrix3[class1,i]),]
>    }
>


From ruipbarradas at sapo.pt  Sat Jun 15 14:19:52 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 15 Jun 2013 13:19:52 +0100
Subject: [R] Trouble sorting the matrix
In-Reply-To: <CABdLAhQKZv-NDnccVbXpKGGcMwFwG3yXxKFjDP-R4gwTN4OQkw@mail.gmail.com>
References: <CABdLAhQG5EVcqYzLjB8kL1UanVY9MMr9sk+ETVi92XJQwQanDA@mail.gmail.com>
	<51BC50E0.8020202@sapo.pt>
	<CABdLAhQKZv-NDnccVbXpKGGcMwFwG3yXxKFjDP-R4gwTN4OQkw@mail.gmail.com>
Message-ID: <51BC5BE8.5050403@sapo.pt>

Hello,

Yes, you can do it like you say. Or you can unsort first and multiply later.

mat5.1 <- sapply(seq_len(ncol(ord)), function(i) mat4[order(ord[,i]), i])

multip<-mat4*2
mat5.2 <- sapply(seq_len(ncol(ord)), function(i) multip[order(ord[,i]), i])

identical(mat5.1*2, mat5.2)  #TRUE


Also, it's better if you Cc the list, for others to read and eventually 
find it of some use.

Rui Barradas

Em 15-06-2013 12:48, Ola Cabaj escreveu:
> Thanks, that helps a lot! I got another question, if you don't mind.
> If I would like to multiply mat4 by a number/vector
> multip<-mat4*2
>
> so to unsort this multiplied matrix I have to change mat4 to multip?
> mat5 <- sapply(seq_len(ncol(ord)), function(i) multip[order(ord[,i]), i])
>
>
> 2013/6/15 Rui Barradas <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>>
>
>     Hello,
>
>     If I understand it correctly, the following should sort all columns
>     of matrix3 and then unsort the sorted matrix.
>
>
>     ord <- apply(matrix3, 2, order)
>
>     # sort matrix3
>     mat4 <- sapply(seq_len(ncol(ord)), function(i) matrix3[ord[,i], i])
>     mat4
>
>     # unsort mat4
>     mat5 <- sapply(seq_len(ncol(ord)), function(i) mat4[order(ord[,i]), i])
>
>     identical(matrix3, mat5)  # TRUE
>
>
>     Hope this helps,
>
>     Rui Barradas
>
>     Em 15-06-2013 11:36, Ola Cabaj escreveu:
>
>         I would like to sort matrix3, so that every column in output
>         matrix is
>         sorted. Also I have to "unsort" it later on.
>
>         matrix1<-matrix(rnorm(100,354,__78),ncol=10)
>         matrix2<-matrix(rnorm(100,225,__102),ncol=10)
>         matrix3<-cbind(matrix1,__matrix2)
>         nrCol<-length(matrix3[1,])
>         class1<-1:10
>             for(i in 1:nrCol)
>             {
>               sorted.matrix<-matrix3[order(__matrix3[class1,i]),]
>             }
>            for(i in 1:liczbaKolumn)
>             {
>              output<-sorted.matrix[order(__matrix3[class1,i]),]
>             }
>
>
>
>
> --
> Aleksandra Cabaj


From birdada85 at gmail.com  Sat Jun 15 14:18:49 2013
From: birdada85 at gmail.com (Birdada Simret)
Date: Sat, 15 Jun 2013 14:18:49 +0200
Subject: [R] Plotting two y-axis vs non-numeric x-axis
Message-ID: <CA+YeWVvoVfEo3iTm-9EvniLX-b_CeuOZgaB+raYetG5Bdr57jg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130615/c476c065/attachment.pl>

From ligges at statistik.tu-dortmund.de  Sat Jun 15 16:48:23 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 15 Jun 2013 16:48:23 +0200
Subject: [R] GGally installation problems
In-Reply-To: <1371042507.14498.YahooMailNeo@web121203.mail.ne1.yahoo.com>
References: <1371042507.14498.YahooMailNeo@web121203.mail.ne1.yahoo.com>
Message-ID: <51BC7EB7.2030205@statistik.tu-dortmund.de>



On 12.06.2013 15:08, Tim Smith wrote:
> Hi,
>
> I was trying to install the GGally package, but was getting errors. Here is what I get:
>
>> install.packages("GGally")
> Installing package(s) into ???/Users/ts2w/Library/R/2.15/library???
> (as ???lib??? is unspecified)
> Warning in install.packages :
> ?  package ???GGally??? is not available (for R version 2.15.2)
>
>> install.packages("GGally",repos="http://cran-r.project.org")


Wrong repository: "http://cran-r.project.org" -> 
http://cran.r-project.org" ?

uwe ligges


> Installing package(s) into ???/Users/ts2w/Library/R/2.15/library???
> (as ???lib??? is unspecified)
> Warning in install.packages :
> ?  cannot open: HTTP status was '404 Not Found'
> Warning in install.packages :
> ?  cannot open: HTTP status was '404 Not Found'
> Warning in install.packages :
> ?  unable to access index for repository http://cran-r.project.org/src/contrib
> Warning in install.packages :
> ?  package ???GGally??? is not available (for R version 2.15.2)
> Warning in install.packages :
> ?  cannot open: HTTP status was '404 Not Found'
> Warning in install.packages :
> ?  cannot open: HTTP status was '404 Not Found'
> Warning in install.packages :
> ?  unable to access index for repository http://cran-r.project.org/bin/macosx/leopard/contrib/2.15
>
> thanks.
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From chet.seligman at gmail.com  Sat Jun 15 16:50:45 2013
From: chet.seligman at gmail.com (Chet Seligman)
Date: Sat, 15 Jun 2013 07:50:45 -0700
Subject: [R] Widows 8
Message-ID: <CALcksu0C_EUR1thYsFq1hbyqWt4Cx0qjkW9_J6wTA1BLAf7-vw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130615/204bc4d6/attachment.pl>

From jrkrideau at inbox.com  Sat Jun 15 16:55:56 2013
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 15 Jun 2013 06:55:56 -0800
Subject: [R] Widows 8
In-Reply-To: <CALcksu0C_EUR1thYsFq1hbyqWt4Cx0qjkW9_J6wTA1BLAf7-vw@mail.gmail.com>
Message-ID: <7AC850639CA.00000170jrkrideau@inbox.com>

Seems unlikely but it runs on Windows 8

John Kane
Kingston ON Canada


> -----Original Message-----
> From: chet.seligman at gmail.com
> Sent: Sat, 15 Jun 2013 07:50:45 -0700
> To: r-help at r-project.org
> Subject: [R] Widows 8
> 
> Can anyone confirm that R runs on Widows 8?
> 
> Thanks,
> Chet Seligman
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From jdnewmil at dcn.davis.ca.us  Sat Jun 15 17:19:11 2013
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 15 Jun 2013 08:19:11 -0700 (PDT)
Subject: [R] Widows 8
In-Reply-To: <CALcksu0C_EUR1thYsFq1hbyqWt4Cx0qjkW9_J6wTA1BLAf7-vw@mail.gmail.com>
References: <CALcksu0C_EUR1thYsFq1hbyqWt4Cx0qjkW9_J6wTA1BLAf7-vw@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1306150817360.73363@pedal.dcn.davis.ca.us>

On Sat, 15 Jun 2013, Chet Seligman wrote:

> Can anyone confirm that R runs on Widows 8?

You can : http://lmgtfy.com/?q=site%3Astat.ethz.ch+%22windows+8%22

> Thanks,
> Chet Seligman

> 	[[alternative HTML version deleted]]

Please read the Posting Guide, and asi it requests post in plain text.

> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From liuwensui at gmail.com  Sat Jun 15 17:56:41 2013
From: liuwensui at gmail.com (Wensui Liu)
Date: Sat, 15 Jun 2013 11:56:41 -0400
Subject: [R] Widows 8
In-Reply-To: <CALcksu0C_EUR1thYsFq1hbyqWt4Cx0qjkW9_J6wTA1BLAf7-vw@mail.gmail.com>
References: <CALcksu0C_EUR1thYsFq1hbyqWt4Cx0qjkW9_J6wTA1BLAf7-vw@mail.gmail.com>
Message-ID: <CAKyN3iAXTm=UT54OT7gpj7AAZC5anHbhc_-6POmFmxa0QgOQEg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130615/8473c11f/attachment.pl>

From scac_1041 at hotmail.com  Sat Jun 15 16:46:54 2013
From: scac_1041 at hotmail.com (Ali Arslan Kazmi)
Date: Sat, 15 Jun 2013 17:46:54 +0300
Subject: [R] A strange issue with GSub
Message-ID: <DUB123-W358BA44FA9BA962B2AB0D486810@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130615/c3c51080/attachment.pl>

From dwinsemius at comcast.net  Sat Jun 15 18:20:34 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 15 Jun 2013 09:20:34 -0700
Subject: [R] Plotting two y-axis vs non-numeric x-axis
In-Reply-To: <CA+YeWVvoVfEo3iTm-9EvniLX-b_CeuOZgaB+raYetG5Bdr57jg@mail.gmail.com>
References: <CA+YeWVvoVfEo3iTm-9EvniLX-b_CeuOZgaB+raYetG5Bdr57jg@mail.gmail.com>
Message-ID: <1AA9F901-3CD2-448B-A2AF-E1897AD6F432@comcast.net>


On Jun 15, 2013, at 5:18 AM, Birdada Simret wrote:

> Hi dear all, the following code is correct. but I want to use non-numeric
> x-axis, for example
> if I replace   time <- seq(0,72,6)  by
> month <-
> c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec","Pag")
> 
> Ofcourse I use factor(month)  instead of time; but I didn't get similar
> plot as the example shown. any help is greatful ;)

We are not seeing any example. Please read the documentation for the Rhelp mailing list more carefully. The information about attachments may not be in the PostingGuide but instead in the listinfo page.  (I for one do not understand what you are requesting.)
> 
> month <-
> c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec","Pag")
> music <- c(0.05,0.18,0.25,0.31,0.32,0.34,0.35,
> 0.36,0.37,0.38,0.39,0.40,0.41)
> actor <- c(0,1000,2000,3000,4000,5000,6000,7000,8000,9000,10000,11000,12000)
> par(mar=c(5, 4, 4, 4) + 0.1)
> plot(factor(month), music, pch=16, axes=F, ylim=c(0,1), xlab="", ylab="",
> type="b",col="black", main="Enjoy")
> axis(2, ylim=c(0,1),col="black")
> mtext("Music",side=2,line=2.5)
> box()
> par(new=T)
> plot(factor(month), actor, pch=15,  xlab="", ylab="", ylim=c(0,13000),
> axes=F,  type="b", col="red")
> mtext("Actor",side=4,col="red",line=2.5)
> axis(4, ylim=c(0,13000), col="red",col.axis="red")
> axis(1,pretty(range(month),10))
> mtext("Month",side=1,col="black",line=2.5)
> legend(5,13000,legend=c("Music","Actor"),text.col=c("black","red"),pch=c(16,15),col=c("black","red"))
> 
> 	[[alternative HTML version deleted]]

-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sat Jun 15 18:31:12 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 15 Jun 2013 09:31:12 -0700
Subject: [R] A strange issue with GSub
In-Reply-To: <DUB123-W358BA44FA9BA962B2AB0D486810@phx.gbl>
References: <DUB123-W358BA44FA9BA962B2AB0D486810@phx.gbl>
Message-ID: <AE02D6FA-593E-43EE-AC3F-0D39AB62702E@comcast.net>


On Jun 15, 2013, at 7:46 AM, Ali Arslan Kazmi wrote:

> Greetings, 
> 
> Apologies if this turns out to be a very silly question, but because I am the only person learning/using R at my workplace, I have no choice but to ask folks here.
> I have been using Gsub to change some expressions in my Corpus object. After applying the gsub function, say
> newCorpus<- gsub("game","war",newCorpus, fixed=TRUE)
> an object of class character is returned by the gsub function, as is understandable, like so:
> [1] this is the text of the 1st document....[1000] this is the text of the 1000th document.
> However, all such text is enclosed as such:
> [1] "c(\"this is the text of the 1st document.\", \"\\a\")" ...[1000] "c(\"this is the text of the 1000th document.\", \"\\a\")" 
> The worst part is that I tried recreating the problem with another example to post here, but I face no such problem with the example. So, after banging my head against the computer for two days now, I still remain clueless as to why this is happening. I was wondering if somebody had an explanation to why this happens? That will be very helpful.
> The only thing I can think of is that I had initially converted MS word documents into txt files, and then imported them using R's plain text reader. Could this be the issue?
> 
> Thanks. 		 	   		  
> 	[[alternative HTML version deleted]]

You are misspelling the gsub function name. You are not describing your process with enough detail to replicate it. You are using packages that you are not naming. I suspect you are using gsub with an item of a class for which it was never intended. Consider this:

> mydf <- data.frame(a=c("this is a test", "another test"), b=c("athird", "a fourth"))
> gsub("test","tester", mydf)
[1] "c(2, 1)" "c(2, 1)"

Please read the Posting Guide. Please make your example reproducible.

-- 

David Winsemius
Alameda, CA, USA


From smartpink111 at yahoo.com  Sat Jun 15 18:20:57 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 15 Jun 2013 09:20:57 -0700 (PDT)
Subject: [R] Plotting two y-axis vs non-numeric x-axis
In-Reply-To: <CA+YeWVvoVfEo3iTm-9EvniLX-b_CeuOZgaB+raYetG5Bdr57jg@mail.gmail.com>
References: <CA+YeWVvoVfEo3iTm-9EvniLX-b_CeuOZgaB+raYetG5Bdr57jg@mail.gmail.com>
Message-ID: <1371313257.51039.YahooMailNeo@web142603.mail.bf1.yahoo.com>



Hi,

You could use ?twoord.plot() from library(plotrix):
library(plotrix)
dat2<- data.frame(month,music,actor)
dat2$month<- factor(month,labels=c(month.abb,"Pag"))
dat2New<-dat2[order(dat2$month),]

?with(dat2New,twoord.plot(month,music,actor,
??????????????????????? lylim=c(0,1),rylim=c(0,13000),
??????????????????????? ylab="Music",
??????????????????????? rylab="Actor",main="Enjoy",
??????????????????????? type=c("p","b"),lcol=1,rcol="red",xtickpos=month,xticklab=month))
???? legend(5,13000,legend=c("Music","Actor"),text.col=c("black","red"),col=c("black","red"))?? 

#I tried to change the plotting symbol using "pch" inside the twoord.plot(), but it seems to be not working. 
?with(dat2New,twoord.plot(month,music,actor,
???????????????????????? lylim=c(0,1),rylim=c(0,13000),
???????????????????????? ylab="Music",
???????????????????????? rylab="Actor",main="Enjoy",
???????????????????????? type=c("p","b"),pch=c(1,4),lcol=1,rcol="red",xtickpos=month,xticklab=month))
#Error in localWindow(xlim, ylim, log, asp, ...) : 
?# formal argument "pch" matched by multiple actual arguments

A.K.
?????????????? 


----- Original Message -----
From: Birdada Simret <birdada85 at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Saturday, June 15, 2013 8:18 AM
Subject: [R] Plotting two y-axis vs non-numeric x-axis

Hi dear all, the following code is correct. but I want to use non-numeric
x-axis, for example
if I replace?  time <- seq(0,72,6)? by
month <-
c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec","Pag")

Ofcourse I use factor(month)? instead of time; but I didn't get similar
plot as the example shown. any help is greatful ;)

month <-
c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec","Pag")
music <- c(0.05,0.18,0.25,0.31,0.32,0.34,0.35,
0.36,0.37,0.38,0.39,0.40,0.41)
actor <- c(0,1000,2000,3000,4000,5000,6000,7000,8000,9000,10000,11000,12000)
par(mar=c(5, 4, 4, 4) + 0.1)
plot(factor(month), music, pch=16, axes=F, ylim=c(0,1), xlab="", ylab="",
type="b",col="black", main="Enjoy")
axis(2, ylim=c(0,1),col="black")
mtext("Music",side=2,line=2.5)
box()
par(new=T)
plot(factor(month), actor, pch=15,? xlab="", ylab="", ylim=c(0,13000),
axes=F,? type="b", col="red")
mtext("Actor",side=4,col="red",line=2.5)
axis(4, ylim=c(0,13000), col="red",col.axis="red")
axis(1,pretty(range(month),10))
mtext("Month",side=1,col="black",line=2.5)
legend(5,13000,legend=c("Music","Actor"),text.col=c("black","red"),pch=c(16,15),col=c("black","red"))

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Sat Jun 15 19:15:22 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 15 Jun 2013 10:15:22 -0700 (PDT)
Subject: [R] transform summary table list to summary table (for .csv
	output)
Message-ID: <1371316522.98698.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
You could try this:
#In one of the list element

SampleSummary$ConcLow
#?? Min. 1st Qu.? Median??? Mean 3rd Qu.??? Max.??? NA's 
# 0.4200? 0.6100? 0.7300? 0.7373? 0.8150? 1.6600?????? 1 

#additional entry for NA.? You may need to check the data and remove the missing value.? Here, I removed that entry.


library(stringr)

res<-data.frame(lapply(SampleSummary,function(x) {x1<-x[names(x)!="NA's"];Nch1<-max(nchar(names(x1)));x2<-str_pad(names(x1),Nch1,side="right",pad=" ");paste(x2,x1,sep=":") }),stringsAsFactors=FALSE)
?res1<-as.table(as.matrix(res))

dimnames(res1)[[1]]<-rep("",nrow(res1))
?str(res1)
# 'table' chr [1:6, 1:17] "Min.?? :1995-10-10" "1st Qu.:1996-06-16" ...
# - attr(*, "dimnames")=List of 2
#? ..$ : chr [1:6] "" "" "" "" ...
#? ..$ : chr [1:17] "Date" "ConcLow" "ConcHigh" "Uncen" ...

?str(summarySample)
# 'table' chr [1:6, 1:17] "Min.?? :2002-05-23? " "1st Qu.:2002-09-02? " ...
# - attr(*, "dimnames")=List of 2
#? ..$ : chr [1:6] "" "" "" "" ...
#? ..$ : chr [1:17] "???? Date" "?? ConcLow" "?? ConcHigh" "??? Uncen" ...
?summarySample[,1:3]
#????? Date???????????????? ConcLow??????????? ConcHigh?????? 
# "Min.?? :2002-05-23? " "Min.?? :0.5800? " "Min.?? :0.5800? "
# "1st Qu.:2002-09-02? " "1st Qu.:0.7525? " "1st Qu.:0.7525? "
# "Median :2003-01-07? " "Median :0.7800? " "Median :0.7800? "
# "Mean?? :2003-01-16? " "Mean?? :0.8100? " "Mean?? :0.8100? "
# "3rd Qu.:2003-05-29? " "3rd Qu.:0.9025? " "3rd Qu.:0.9025? "
# "Max.?? :2003-09-04? " "Max.?? :1.0900? " "Max.?? :1.0900? "
?res1[,1:3]
# Date???????????????? ConcLow????????? ConcHigh??????? 
# "Min.?? :1995-10-10" "Min.?? :0.42"?? "Min.?? :0.27"? 
# "1st Qu.:1996-06-16" "1st Qu.:0.61"?? "1st Qu.:0.605" 
# "Median :1996-12-10" "Median :0.73"?? "Median :0.7275"
# "Mean?? :1998-01-08" "Mean?? :0.7373" "Mean?? :0.7322"
# "3rd Qu.:1998-03-12" "3rd Qu.:0.815"? "3rd Qu.:0.8125"
# "Max.?? :2003-09-04" "Max.?? :1.66"?? "Max.?? :1.66"? 


#There is some space on the right for each column of summarySample.?? Not sure if you wanted that in res1. 

A.K.


Hi, I have a R object called Sample which I am obtaining the summary 
table for through 2 methods: summarySample <- summary(Sample) & 
SampleSummary <- lapply(Sample, summary). I would like to transform 
the results of lapply(Sample, summary) into the same format as 
summary(Sample). I have included dput for both summary results. After I 
obtain the summary results I am exporting the table to a .csv and I 
would like both .csv files to be similarly formatted; however, I am not 
able to do that now. I have searched online for assistance, but I have 
not been successful yet. 

Thank you. 

Irucka Embry 

summarySample 
dput(summarySample) 
structure(c("Min. ? :2002-05-23 ?", "1st Qu.:2002-09-02 ?", "Median :2003-01-07 ?", 
"Mean ? :2003-01-16 ?", "3rd Qu.:2003-05-29 ?", "Max. ? :2003-09-04 ?", 
"Min. ? :0.5800 ?", "1st Qu.:0.7525 ?", "Median :0.7800 ?", "Mean ? :0.8100 ?", 
"3rd Qu.:0.9025 ?", "Max. ? :1.0900 ?", "Min. ? :0.5800 ?", "1st Qu.:0.7525 ?", 
"Median :0.7800 ?", "Mean ? :0.8100 ?", "3rd Qu.:0.9025 ?", "Max. ? :1.0900 ?", 
"Min. ? :1 ?", "1st Qu.:1 ?", "Median :1 ?", "Mean ? :1 ?", "3rd Qu.:1 ?", 
"Max. ? :1 ?", "Min. ? :0.5800 ?", "1st Qu.:0.7525 ?", "Median :0.7800 ?", 
"Mean ? :0.8100 ?", "3rd Qu.:0.9025 ?", "Max. ? :1.0900 ?", "Min. ? :55659 ?", 
"1st Qu.:55762 ?", "Median :55888 ?", "Mean ? :55898 ?", "3rd Qu.:56031 ?", 
"Max. ? :56128 ?", "Min. ? : 2 ?", "1st Qu.: 5 ?", "Median : 7 ?", 
"Mean ? : 7 ?", "3rd Qu.: 9 ?", "Max. ? :12 ?", "Min. ? : 35.0 ?", 
"1st Qu.:142.5 ?", "Median :201.5 ?", "Mean ? :199.3 ?", "3rd Qu.:247.2 ?", 
"Max. ? :345.0 ?", "Min. ? :2002 ?", "1st Qu.:2003 ?", "Median :2003 ?", 
"Mean ? :2003 ?", "3rd Qu.:2003 ?", "Max. ? :2004 ?", "Min. ? :1829 ?", 
"1st Qu.:1833 ?", "Median :1837 ?", "Mean ? :1837 ?", "3rd Qu.:1841 ?", 
"Max. ? :1845 ?", "Min. ? :-0.9670 ?", "1st Qu.:-0.8075 ?", "Median :-0.2531 ?", 
"Mean ? :-0.1224 ?", "3rd Qu.: 0.5788 ?", "Max. ? : 0.9906 ?", 
"Min. ? :-0.9917 ?", "1st Qu.:-0.7986 ?", "Median :-0.5209 ?", 
"Mean ? :-0.3123 ?", "3rd Qu.: 0.1663 ?", "Max. ? : 0.9327 ?", 
"Min. ? :0.1189 ?", "1st Qu.:0.5154 ?", "Median :1.3734 ?", "Mean ? :1.6672 ?", 
"3rd Qu.:2.6618 ?", "Max. ? :5.7483 ?", "Min. ? :-2.12921 ?", 
"1st Qu.:-0.71031 ?", "Median : 0.30516 ?", "Mean ? : 0.02173 ?", 
"3rd Qu.: 0.97834 ?", "Max. ? : 1.74891 ?", "Min. ? :-0.4057 ?", 
"1st Qu.:-0.2986 ?", "Median :-0.2131 ?", "Mean ? :-0.2022 ?", 
"3rd Qu.:-0.1459 ?", "Max. ? : 0.0798 ?", "Min. ? :0.02030 ?", 
"1st Qu.:0.03857 ?", "Median :0.06197 ?", "Mean ? :0.06628 ?", 
"3rd Qu.:0.08225 ?", "Max. ? :0.17336 ?", "Min. ? :0.6766 ?", 
"1st Qu.:0.7432 ?", "Median :0.8117 ?", "Mean ? :0.8259 ?", "3rd Qu.:0.8646 ?", 
"Max. ? :1.0838 ?"), .Dim = c(6L, 17L), .Dimnames = list(c("", 
"", "", "", "", ""), c(" ? ? Date", " ? ConcLow", " ? ConcHigh", 
" ? ?Uncen", " ? ConcAve", " ? ?Julian", " ? ?Month", " ? ? Day", 
" ? DecYear", " ? MonthSeq", " ? ?SinDY", " ? ?CosDY", " ? ? ?Q", 
" ? ? LogQ", " ? ? yHat", " ? ? ?SE", " ? ConcHat")), class = "table") 


SampleSummary 
dput(SampleSummary) 
structure(list(Date = structure(c(9413, 9663, 9840, 10234.0652174, 
10297.75, 12299), .Names = c("Min.", "1st Qu.", "Median", "Mean", 
"3rd Qu.", "Max."), class = c("summaryDefault", "table", "Date" 
)), ConcLow = structure(c(0.42, 0.61, 0.73, 0.7373, 0.815, 1.66, 
1), .Names = c("Min.", "1st Qu.", "Median", "Mean", "3rd Qu.", 
"Max.", "NA's"), class = c("summaryDefault", "table")), ConcHigh = structure(c(0.27, 
0.605, 0.7275, 0.7322, 0.8125, 1.66), .Names = c("Min.", "1st Qu.", 
"Median", "Mean", "3rd Qu.", "Max."), class = c("summaryDefault", 
"table")), Uncen = structure(c(0, 1, 1, 0.9891, 1, 1), .Names = c("Min.", 
"1st Qu.", "Median", "Mean", "3rd Qu.", "Max."), class = c("summaryDefault", 
"table")), ConcAve = structure(c(0.135, 0.605, 0.7275, 0.7307, 
0.8125, 1.66), .Names = c("Min.", "1st Qu.", "Median", "Mean", 
"3rd Qu.", "Max."), class = c("summaryDefault", "table")), Julian = structure(c(53240, 
53490, 53670, 54060, 54130, 56130), .Names = c("Min.", "1st Qu.", 
"Median", "Mean", "3rd Qu.", "Max."), class = c("summaryDefault", 
"table")), Month = structure(c(1, 3.75, 6, 6.315, 9, 12), .Names = c("Min.", 
"1st Qu.", "Median", "Mean", "3rd Qu.", "Max."), class = c("summaryDefault", 
"table")), Day = structure(c(6, 89.5, 173.5, 175, 249.5, 356), .Names = c("Min.", 
"1st Qu.", "Median", "Mean", "3rd Qu.", "Max."), class = c("summaryDefault", 
"table")), DecYear = structure(c(1996, 1996, 1997, 1998, 1998, 
2004), .Names = c("Min.", "1st Qu.", "Median", "Mean", "3rd Qu.", 
"Max."), class = c("summaryDefault", "table")), MonthSeq = structure(c(1750, 
1758, 1764, 1777, 1779, 1845), .Names = c("Min.", "1st Qu.", 
"Median", "Mean", "3rd Qu.", "Max."), class = c("summaryDefault", 
"table")), SinDY = structure(c(-0.9999, -0.7539, 0.1113, 0.02759, 
0.6849, 1), .Names = c("Min.", "1st Qu.", "Median", "Mean", "3rd Qu.", 
"Max."), class = c("summaryDefault", "table")), CosDY = structure(c(-1, 
-0.7595, -0.1707, -0.08807, 0.5758, 0.9955), .Names = c("Min.", 
"1st Qu.", "Median", "Mean", "3rd Qu.", "Max."), class = c("summaryDefault", 
"table")), Q = structure(c(0.1189, 0.7646, 1.529, 2.951, 2.895, 
24.41), .Names = c("Min.", "1st Qu.", "Median", "Mean", "3rd Qu.", 
"Max."), class = c("summaryDefault", "table")), LogQ = structure(c(-2.129, 
-0.2685, 0.4245, 0.492, 1.063, 3.195), .Names = c("Min.", "1st Qu.", 
"Median", "Mean", "3rd Qu.", "Max."), class = c("summaryDefault", 
"table")), yHat = structure(c(-0.5147, -0.4256, -0.3506, -0.3377, 
-0.2826, 0.1143), .Names = c("Min.", "1st Qu.", "Median", "Mean", 
"3rd Qu.", "Max."), class = c("summaryDefault", "table")), SE = structure(c(0.1045, 
0.1934, 0.2169, 0.2214, 0.2622, 0.3152), .Names = c("Min.", "1st Qu.", 
"Median", "Mean", "3rd Qu.", "Max."), class = c("summaryDefault", 
"table")), ConcHat = structure(c(0.601, 0.6781, 0.7206, 0.736, 
0.7777, 1.127), .Names = c("Min.", "1st Qu.", "Median", "Mean", 
"3rd Qu.", "Max."), class = c("summaryDefault", "table"))), .Names = c("Date", 
"ConcLow", "ConcHigh", "Uncen", "ConcAve", "Julian", "Month", 
"Day", "DecYear", "MonthSeq", "SinDY", "CosDY", "Q", "LogQ", 
"yHat", "SE", "ConcHat"))


From ligges at statistik.tu-dortmund.de  Sat Jun 15 19:17:20 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 15 Jun 2013 19:17:20 +0200
Subject: [R] Windows R_LIBS_USER confusion under R-3.0.1
In-Reply-To: <CAErODj8RbBB914Ve5y_7BhOWrbPuxEfV9cCD4D5q5z8+5g47hQ@mail.gmail.com>
References: <CAErODj8RbBB914Ve5y_7BhOWrbPuxEfV9cCD4D5q5z8+5g47hQ@mail.gmail.com>
Message-ID: <51BCA1A0.608@statistik.tu-dortmund.de>



On 12.06.2013 16:35, Paul Johnson wrote:
> I would appreciate ideas about MS Windows install issues. I'm at our stats
> summer camp and have been looking at a lot of Windows R installs and there
> are some wrinkles about R_LIBS_USER.
>
> On a clean Win7 or Win8 system, with R-3.0.1, we see the user library for
> packages defaulting to  $HOME/R/win-library.
>
> I think that's awesome, the way it should be. Yea! But it does not appear
> that way on all systems, and I think it is because of lingering
> after-effects of previous R installs.
>
> In previous versions of R, R_LIBS_USER defaulted to
> $HOME/AppData/Roaming/... That was not so great because it was (default)
> hidden to the students and they were disoriented about how something that
> does not exist (or show) could hold packages. Aside from teaching them how
> to configure the file manager, we could navigate that.
>
> The problem is that with R-3.0.1, sometimes we are seeing the user package
> installs going into $HOME/AppData/Roaming/....
>
> In the user account, there is no $HOME/.Rprofile or $HOME/.Renviron.
>
> I hate to tell non-expert users that they ought to go fishing in the
> Windows registry, but I'm starting to suspect that is what they ought to
> do.  What do you think?


There is nothing in the registry, but maybe some startup file in the 
current working directory? Some declaration of environment variables 
somewhere else?

Best,
Uwe Ligges


>
> PJ
>


From smartpink111 at yahoo.com  Sat Jun 15 20:03:16 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 15 Jun 2013 11:03:16 -0700 (PDT)
Subject: [R] Calculate days with R
Message-ID: <1371319396.17583.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
May be this helps:
dat1<- read.table(text="
pbnr??????? dat? dep? dys? sop? ago? mis age female
1 10023 1994-02-21 0.75 1.00 0.50 0.50 0.75? 35????? 1
2 10023 1994-05-25 0.75 1.00 0.50 0.50 0.75? 35????? 1
3 10028 1994-02-01 2.00 1.75 3.00 0.50 1.50? 42????? 1
4 10028 1999-01-15 1.25 0.75 2.25 0.50 0.25? 42????? 1
5 10053 1994-03-16 2.50 0.75 1.25 0.50 1.25? 22????? 1
6 10053 1994-09-23 3.25 1.25 1.25 0.75 2.25? 22????? 1
",sep="",header=TRUE,stringsAsFactors=FALSE)
dat1$dat<- as.Date(dat1$dat)
?with(dat1,tapply(dat,list(pbnr),FUN=diff))
#10023 10028 10053 
#?? 93? 1809?? 191 
library(plyr)
?ddply(dat1,.(pbnr),mutate,Datediff=diff(dat))
?#? pbnr??????? dat? dep? dys? sop? ago? mis age female Datediff
#1 10023 1994-02-21 0.75 1.00 0.50 0.50 0.75? 35????? 1?????? 93
#2 10023 1994-05-25 0.75 1.00 0.50 0.50 0.75? 35????? 1?????? 93
#3 10028 1994-02-01 2.00 1.75 3.00 0.50 1.50? 42????? 1???? 1809
#4 10028 1999-01-15 1.25 0.75 2.25 0.50 0.25? 42????? 1???? 1809
#5 10053 1994-03-16 2.50 0.75 1.25 0.50 1.25? 22????? 1????? 191
#6 10053 1994-09-23 3.25 1.25 1.25 0.75 2.25? 22????? 1????? 191

#or
?dat2<-aggregate(dat~pbnr,data=dat1,diff)
?colnames(dat2)[2]<- "Datediff"
?join(dat1,dat2,by="pbnr")
#?? pbnr??????? dat? dep? dys? sop? ago? mis age female Datediff
#1 10023 1994-02-21 0.75 1.00 0.50 0.50 0.75? 35????? 1????? 93 
#2 10023 1994-05-25 0.75 1.00 0.50 0.50 0.75? 35????? 1????? 93 
#3 10028 1994-02-01 2.00 1.75 3.00 0.50 1.50? 42????? 1??? 1809 
#4 10028 1999-01-15 1.25 0.75 2.25 0.50 0.25? 42????? 1??? 1809 
#5 10053 1994-03-16 2.50 0.75 1.25 0.50 1.25? 22????? 1???? 191 
#6 10053 1994-09-23 3.25 1.25 1.25 0.75 2.25? 22????? 1???? 191 


A.K.



Hi, I am new to this forum, and have a problem. I have data that looks like this: 

pbnr ? ? ? ?dat ?dep ?dys ?sop ?ago ?mis age female 
1 10023 1994-02-21 0.75 1.00 0.50 0.50 0.75 ?35 ? ? ?1 
2 10023 1994-05-25 0.75 1.00 0.50 0.50 0.75 ?35 ? ? ?1 
3 10028 1994-02-01 2.00 1.75 3.00 0.50 1.50 ?42 ? ? ?1 
4 10028 1999-01-15 1.25 0.75 2.25 0.50 0.25 ?42 ? ? ?1 
5 10053 1994-03-16 2.50 0.75 1.25 0.50 1.25 ?22 ? ? ?1 
6 10053 1994-09-23 3.25 1.25 1.25 0.75 2.25 ?22 ? ? ?1 
..... 
And I want to know how many days each person (pbnr) has been in 
therapy. row 1 is first a date for person 10023 and row 2 the second but
 what do I do now???? 
Thanks for you help!! 
Sophie


From mulone at rome.com  Sat Jun 15 20:00:49 2013
From: mulone at rome.com (Mulone)
Date: Sat, 15 Jun 2013 11:00:49 -0700 (PDT)
Subject: [R] [igraph] Counting edges for each vertex
Message-ID: <1371319249132-4669613.post@n4.nabble.com>

Hi all,

I'm analysing an e-mail network. I loaded the following information in a
directed igraph:

*Vertex* types: person, e-mail
V(g)[ type == "person" ]
V(g)[ type == "email" ]

*Edge* types: sends, receives
E(g)[ type == "send" ]
E(g)[ type == "receive" ]

So for example:

John --send--> email1 --receive--> Mary
John --send--> email2 --receive--> Mary
Mary --send--> email3 --receive--> John

I would like to generate a summary of the e-mail activity, with edges with
an attribute representing the number of emails:

John --2--> Mary
Mary --1--> John

I tried to do this, but I haven't figured it out yet.
I managed to get in/out edges for each letter, but then I don't know what to
do to hold a count.

  lapply(V(g)[type=="email"],
    function(e){
      outedges = V(g) [ from(e) ]
      print(outedges)
      inedges = V(g) [ to(e) ]
      print(inedges)
    })

I just started using igraph, and I find even basic operations quite
difficult to carry out. :-/
How would I go about to do that?

Thanks,
Mulone



--
View this message in context: http://r.789695.n4.nabble.com/igraph-Counting-edges-for-each-vertex-tp4669613.html
Sent from the R help mailing list archive at Nabble.com.


From birdada85 at gmail.com  Sat Jun 15 20:14:16 2013
From: birdada85 at gmail.com (Birdada Simret)
Date: Sat, 15 Jun 2013 20:14:16 +0200
Subject: [R] Plotting two y-axis vs non-numeric x-axis
In-Reply-To: <1371313257.51039.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <CA+YeWVvoVfEo3iTm-9EvniLX-b_CeuOZgaB+raYetG5Bdr57jg@mail.gmail.com>
	<1371313257.51039.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <CA+YeWVufww+q=fryaT+3KYQ2CkWQ1yia=vNuzNx8LHD8b+CsHQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130615/899d3a8e/attachment.pl>

From dwinsemius at comcast.net  Sat Jun 15 20:45:53 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 15 Jun 2013 11:45:53 -0700
Subject: [R] Plotting two y-axis vs non-numeric x-axis
In-Reply-To: <CA+YeWVufww+q=fryaT+3KYQ2CkWQ1yia=vNuzNx8LHD8b+CsHQ@mail.gmail.com>
References: <CA+YeWVvoVfEo3iTm-9EvniLX-b_CeuOZgaB+raYetG5Bdr57jg@mail.gmail.com>
	<1371313257.51039.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CA+YeWVufww+q=fryaT+3KYQ2CkWQ1yia=vNuzNx8LHD8b+CsHQ@mail.gmail.com>
Message-ID: <C4CBB7AF-459D-41FC-9A02-01A7D3C73602@comcast.net>


On Jun 15, 2013, at 11:14 AM, Birdada Simret wrote:

> Thank you.
> @David: The example is exactly this:
> time <- seq(0,72,6)
> music <- c(0.05,0.18,0.25,0.31,0.32,0.34,0.35,
> 0.36,0.37,0.38,0.39,0.40,0.41)
> actor <- c(0,1000,2000,3000,4000,5000,6000,7000,8000,9000,10000,11000,12000)
> par(mar=c(5, 4, 4, 4) + 0.1)
> plot(time, music, pch=16, axes=F, ylim=c(0,1), xlab="", ylab="",
> type="b",col="black", main="Enjoy")
> axis(2, ylim=c(0,1),col="black")
> mtext("Music",side=2,line=2.5)
> box()
> par(new=T)
> plot(time, actor, pch=15,  xlab="", ylab="", ylim=c(0,13000), axes=F,
> type="b", col="red")
> mtext("Actor",side=4,col="red",line=2.5)
> axis(4, ylim=c(0,13000), col="red",col.axis="red")
> axis(1,pretty(range(time),10))
> mtext("Time (Hours)",side=1,col="black",line=2.5)
> legend(5,13000,legend=c("Music","Actor"),text.col=c("black","red"),pch=c(16,15),col=c("black","red"))
> 
> Now, what if time is replaced by month <-
> c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec","Pag")
> 
> when I tried"
> I got error like
> "In pretty.default(range(month), 10) : NAs introduced by coercion"   I am
> newbie to R ;) many thanks

Er, Not really. The error was the line above that warning:

"Error in plot.window(...) : need finite 'xlim' values
In addition: Warning messages:
1: In xy.coords(x, y, xlabel, ylabel, log) : NAs introduced by coercion
2: In min(x) : no non-missing arguments to min; returning Inf
3: In max(x) : no non-missing arguments to max; returning -Inf"

You are sending a character vector to plot() as the first argument, and plotting dispatch system cannot find a 'plot.character' method so it sends it to 'plot.default' which is expecting a numeric vector for x and things all fall apart from there.

You could use: seq_along(month)  # instead of month

(And obviously the xlab would need to be changed, since you are no longer working with "Hours".)

And. Please learn to post in plain text.

-- David


> @Arun, It is really helpful, thank you. though only the red marked plot is
> perfectly shown.
> 
> 
> On Sat, Jun 15, 2013 at 6:20 PM, arun <smartpink111 at yahoo.com> wrote:
> 
>> 
>> 
>> Hi,
>> 
>> You could use ?twoord.plot() from library(plotrix):
>> library(plotrix)
>> dat2<- data.frame(month,music,actor)
>> dat2$month<- factor(month,labels=c(month.abb,"Pag"))
>> dat2New<-dat2[order(dat2$month),]
>> 
>> with(dat2New,twoord.plot(month,music,actor,
>>                        lylim=c(0,1),rylim=c(0,13000),
>>                        ylab="Music",
>>                        rylab="Actor",main="Enjoy",
>> 
>> type=c("p","b"),lcol=1,rcol="red",xtickpos=month,xticklab=month))
>> 
>> legend(5,13000,legend=c("Music","Actor"),text.col=c("black","red"),col=c("black","red"))
>> 
>> #I tried to change the plotting symbol using "pch" inside the
>> twoord.plot(), but it seems to be not working.
>> with(dat2New,twoord.plot(month,music,actor,
>>                         lylim=c(0,1),rylim=c(0,13000),
>>                         ylab="Music",
>>                         rylab="Actor",main="Enjoy",
>> 
>> type=c("p","b"),pch=c(1,4),lcol=1,rcol="red",xtickpos=month,xticklab=month))
>> #Error in localWindow(xlim, ylim, log, asp, ...) :
>> # formal argument "pch" matched by multiple actual arguments
>> 
>> A.K.
>> 
>> 
>> 
>> ----- Original Message -----
>> From: Birdada Simret <birdada85 at gmail.com>
>> To: r-help at r-project.org
>> Cc:
>> Sent: Saturday, June 15, 2013 8:18 AM
>> Subject: [R] Plotting two y-axis vs non-numeric x-axis
>> 
>> Hi dear all, the following code is correct. but I want to use non-numeric
>> x-axis, for example
>> if I replace   time <- seq(0,72,6)  by
>> month <-
>> 
>> c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec","Pag")
>> 
>> Ofcourse I use factor(month)  instead of time; but I didn't get similar
>> plot as the example shown. any help is greatful ;)
>> 
>> month <-
>> 
>> c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec","Pag")
>> music <- c(0.05,0.18,0.25,0.31,0.32,0.34,0.35,
>> 0.36,0.37,0.38,0.39,0.40,0.41)
>> actor <-
>> c(0,1000,2000,3000,4000,5000,6000,7000,8000,9000,10000,11000,12000)
>> par(mar=c(5, 4, 4, 4) + 0.1)
>> plot(factor(month), music, pch=16, axes=F, ylim=c(0,1), xlab="", ylab="",
>> type="b",col="black", main="Enjoy")
>> axis(2, ylim=c(0,1),col="black")
>> mtext("Music",side=2,line=2.5)
>> box()
>> par(new=T)
>> plot(factor(month), actor, pch=15,  xlab="", ylab="", ylim=c(0,13000),
>> axes=F,  type="b", col="red")
>> mtext("Actor",side=4,col="red",line=2.5)
>> axis(4, ylim=c(0,13000), col="red",col.axis="red")
>> axis(1,pretty(range(month),10))
>> mtext("Month",side=1,col="black",line=2.5)
>> 
>> legend(5,13000,legend=c("Music","Actor"),text.col=c("black","red"),pch=c(16,15),col=c("black","red"))
>> 
>>    [[alternative HTML version deleted]]
>> 
>> 

David Winsemius
Alameda, CA, USA


From james at crosb.ie  Sat Jun 15 20:41:51 2013
From: james at crosb.ie (jcrosbie)
Date: Sat, 15 Jun 2013 11:41:51 -0700 (PDT)
Subject: [R] Downloading CSV file - RCurl help
Message-ID: <1371321711500-4669616.post@n4.nabble.com>

There are some CSV file from the link below. 

I'm having trouble installing the package. Is this the package I have to use
or is there another one I need to use? If so how do I get this one loaded. 



https://www.enmax.com/Power/Energy+Retailers/Settlement+Reports/Profile+settlement+report.htm

 install.packages("RCurl", repos =
"http://cran.r-project.org/bin/windows/contrib/r-release/RCurl_1.95-4.1.zip",
type="source")
Installing package into ?C:/Users/James/Documents/R/win-library/3.0?
(as ?lib? is unspecified)
Warning: unable to access index for repository
http://cran.r-project.org/bin/windows/contrib/r-release/RCurl_1.95-4.1.zip/src/contrib
Warning message:
package ?RCurl? is not available (for R version 3.0.1) 



--
View this message in context: http://r.789695.n4.nabble.com/Downloading-CSV-file-RCurl-help-tp4669616.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Sat Jun 15 21:03:43 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 15 Jun 2013 12:03:43 -0700
Subject: [R] Downloading CSV file - RCurl help
In-Reply-To: <1371321711500-4669616.post@n4.nabble.com>
References: <1371321711500-4669616.post@n4.nabble.com>
Message-ID: <AFA101E3-16E6-424D-8967-A582D0092369@comcast.net>


On Jun 15, 2013, at 11:41 AM, jcrosbie wrote:

> There are some CSV file from the link below. 
> 
> I'm having trouble installing the package. Is this the package I have to use
> or is there another one I need to use? If so how do I get this one loaded. 
> 
> 
> 
> https://www.enmax.com/Power/Energy+Retailers/Settlement+Reports/Profile+settlement+report.htm
> 
> install.packages("RCurl", repos =
> "http://cran.r-project.org/bin/windows/contrib/r-release/RCurl_1.95-4.1.zip",
> type="source")

Packages of type="source" are not generally distributed as zip files. So R is unable to find it in the CRAN source directory. If you do want source you will also need RTools. But why not install as a binary file?

> Installing package into ?C:/Users/James/Documents/R/win-library/3.0?
> (as ?lib? is unspecified)
> Warning: unable to access index for repository
> http://cran.r-project.org/bin/windows/contrib/r-release/RCurl_1.95-4.1.zip/src/contrib
> Warning message:
> package ?RCurl? is not available (for R version 3.0.1) 
> 
-- 

David Winsemius
Alameda, CA, USA


From sophie.homeyer at googlemail.com  Sat Jun 15 22:58:23 2013
From: sophie.homeyer at googlemail.com (Sophie Homeyer)
Date: Sat, 15 Jun 2013 22:58:23 +0200
Subject: [R] quick Help needed
Message-ID: <CACi=cgbfYqmjS18eC25d+O3hKCucXEsf_R_k6Lq0_HHhmtBqfQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130615/e822ab23/attachment.pl>

From fabrice.ciup at gmail.com  Sat Jun 15 23:38:02 2013
From: fabrice.ciup at gmail.com (Fabrice Tourre)
Date: Sat, 15 Jun 2013 17:38:02 -0400
Subject: [R] How can make loop more faster?
Message-ID: <CAN31xkfBH_n47m+hdVKZLKQ68CzyucM-TEM09_aPYWXKpwHcUQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130615/4b3d791d/attachment.pl>

From vickythakre at gmail.com  Sat Jun 15 23:42:13 2013
From: vickythakre at gmail.com (Bhupendrasinh Thakre)
Date: Sat, 15 Jun 2013 16:42:13 -0500
Subject: [R] quick Help needed
In-Reply-To: <CACi=cgbfYqmjS18eC25d+O3hKCucXEsf_R_k6Lq0_HHhmtBqfQ@mail.gmail.com>
References: <CACi=cgbfYqmjS18eC25d+O3hKCucXEsf_R_k6Lq0_HHhmtBqfQ@mail.gmail.com>
Message-ID: <12AA7E1F-9280-460F-804E-97D8F363A492@gmail.com>

table(scltotal$female,scltotal$dys)


Best Regards,

Bhupendrasinh Thakre

Sent from my iPad

On Jun 15, 2013, at 3:58 PM, Sophie Homeyer <sophie.homeyer at googlemail.com> wrote:

> Hi,
> i am new to this forum and not sure how it works,
> I am trying to do deskriptive descripe my data in terms of gender:
> 
> head(scltotal)
> 
>   pbnr        dat  dep  dys  sop  ago  mis age female messpunkt2
> messpunkt1 tage eintrittsjahr
> 
> 1 10023 1994-02-21 0.75 1.00 0.50 0.50 0.75  35      1       8817
> 8817    0          1994
> 
> 2 10023 1994-05-25 0.75 1.00 0.50 0.50 0.75  35      1       8910
> 8817   93          1994
> 
> 3 10028 1994-02-01 2.00 1.75 3.00 0.50 1.50  42      1       8797
> 8797    0          1994
> 
> 4 10028 1999-01-15 1.25 0.75 2.25 0.50 0.25  42      1      10606
> 8797 1809          1999
> 
> 5 10053 1994-03-16 2.50 0.75 1.25 0.50 1.25  22      1       8840
> 8840    0          1994
> 
> 6 10053 1994-09-23 3.25 1.25 1.25 0.75 2.25  22      1       9031
> 8840  191          1994
> so female is either 0 or 1 I assume 0 is male and 1 is female. And I want
> to look at dep, dys, sop, ago and mis how they are in terms of gender
> (female or male) I have no clue what to do :-(
> thanks for your help
> sophie
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Jun 16 00:54:05 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 15 Jun 2013 15:54:05 -0700
Subject: [R] How can make loop more faster?
In-Reply-To: <CAN31xkfBH_n47m+hdVKZLKQ68CzyucM-TEM09_aPYWXKpwHcUQ@mail.gmail.com>
References: <CAN31xkfBH_n47m+hdVKZLKQ68CzyucM-TEM09_aPYWXKpwHcUQ@mail.gmail.com>
Message-ID: <DBE3D720-CBE4-4EDC-B0D5-43C5BC83ACF6@comcast.net>


On Jun 15, 2013, at 2:38 PM, Fabrice Tourre wrote:

> Dear expert,
> 
> How can I make follow codematrix function more faster?
> 
> top20.dat <- top20.dat[,7:length(top20.dat[1,])]
> top40.dat <-
> read.table("top40snps.ped",header=F,sep="\t",stringsAsFactors=F)

Did you attach a file with a non-'.txt' extension?

> row.names(top40.dat) <- top40.dat[,1]
> top40.dat <- top40.dat[,7:length(top40.dat[1,])]
> codematrix <- function(dat)
> {
>    new.dat <- dat
>    for(col in 1:length(dat[1,]))
>    {

I'm guessing that using `ifelse` would be much faster than going column by column and and then row by painful row through this testing with nested `if(cond){conseq}else{alter}` . You should gain efficiency by setting up the results of the `strsplit` operation on a full column at a time. Build a function that would work one column at a time and then lapply it to the dataframe.

>        tbl <- table(dat[,col])
>        max.allel <- names(which(tbl==max(table(dat[,col]))))
>        for(row in 1:length(dat[,1]))
>            {
>                if(dat[row,col]=="0 0")
>                {
>                    new.dat[row,col]=NA
>                }else{
>                    if(dat[row,col]==max.allel) {
>                        new.dat[row,col]=0
>                    }else{
>                        allele <- unlist(strsplit(
> as.character(dat[row,col])," "))
>                        if(allele[1]==allele[2]){
>                            new.dat[row,col]=2
>                        }else{
>                            new.dat[row,col]=1

You could leave the "==max.allelle" test on the outer of nested ifelse operations to "overwrite" the resutls of the testing of the two split-bits. But I would make it a %in%-test so that it won't fail when mor than one maximum occur.

Perhaps (untested and a lot of guesswork):

testsplitfunc <- function(col){
         temptbl <- table(col)
         tempspl <-  strsplit(as.character(col) , split=" ")
         allele <-cbind( sapply(temp, "[", 1),
                         sapply(temp, "[", 2) )
         res <- ifelse ( col %in% names(temptbl)[ which(tbl==max(temptbl))] , 
                     0,
                     ifelse( allele[,1]==allele[,2], 2, 1) )
         is.na(res) <- col=="0 0"
         }

code.top20 <- do.call(cbind, lapply(top20.dat, testsplitfunc) )
                     




>                        }
>                    }
>                }
>            }
>        #})
>        cat(paste(col," ",sep=""))
>    }
>    return(new.dat)
> }
> code.top20 <- codematrix(top20.dat)

In the absence of a problem description I will leave the details unaddressed.
> 
> 	[[alternative HTML version deleted]]


David Winsemius
Alameda, CA, USA


From graham.mcdannel at gmail.com  Sun Jun 16 02:08:35 2013
From: graham.mcdannel at gmail.com (Graham McDannel)
Date: Sat, 15 Jun 2013 19:08:35 -0500
Subject: [R] Optimization of a function using optim
Message-ID: <CAJhGg+0U98D9VhZ+gghvJ8y-AXSqQ=F5uSsi3XeXivC4u1c9Yg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130615/28b6e753/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Sun Jun 16 02:46:54 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 15 Jun 2013 17:46:54 -0700
Subject: [R] Optimization of a function using optim
In-Reply-To: <CAJhGg+0U98D9VhZ+gghvJ8y-AXSqQ=F5uSsi3XeXivC4u1c9Yg@mail.gmail.com>
References: <CAJhGg+0U98D9VhZ+gghvJ8y-AXSqQ=F5uSsi3XeXivC4u1c9Yg@mail.gmail.com>
Message-ID: <dee03088-8dbc-45dc-999f-83a1d619f9cd@email.android.com>

Not unless you read the Posting Guide, stop posting in HTML mail format, and provide a reproducible example.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Graham McDannel <graham.mcdannel at gmail.com> wrote:

>I am attempting to optimize a function I have developed using optim.
>
>I am getting the below error message:
>
>Error in n < 1: 'n' is missing
>
>Could some one provide some additional clarity regarding this message
>and
>what it entails, as well as, how to rectify this issue.
>
>Thanks
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jim at bitwrit.com.au  Sun Jun 16 02:48:03 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sun, 16 Jun 2013 10:48:03 +1000
Subject: [R] Plotting two y-axis vs non-numeric x-axis
In-Reply-To: <CA+YeWVufww+q=fryaT+3KYQ2CkWQ1yia=vNuzNx8LHD8b+CsHQ@mail.gmail.com>
References: <CA+YeWVvoVfEo3iTm-9EvniLX-b_CeuOZgaB+raYetG5Bdr57jg@mail.gmail.com>	<1371313257.51039.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CA+YeWVufww+q=fryaT+3KYQ2CkWQ1yia=vNuzNx8LHD8b+CsHQ@mail.gmail.com>
Message-ID: <51BD0B43.2070206@bitwrit.com.au>

On 06/16/2013 04:14 AM, Birdada Simret wrote:
> Thank you.
> @David: The example is exactly this:
> time <- seq(0,72,6)
> music <- c(0.05,0.18,0.25,0.31,0.32,0.34,0.35,
> 0.36,0.37,0.38,0.39,0.40,0.41)
> actor <- c(0,1000,2000,3000,4000,5000,6000,7000,8000,9000,10000,11000,12000)
> par(mar=c(5, 4, 4, 4) + 0.1)
> plot(time, music, pch=16, axes=F, ylim=c(0,1), xlab="", ylab="",
>   type="b",col="black", main="Enjoy")
>   axis(2, ylim=c(0,1),col="black")
> mtext("Music",side=2,line=2.5)
>   box()
> par(new=T)
>   plot(time, actor, pch=15,  xlab="", ylab="", ylim=c(0,13000), axes=F,
>   type="b", col="red")
>   mtext("Actor",side=4,col="red",line=2.5)
> axis(4, ylim=c(0,13000), col="red",col.axis="red")
>   axis(1,pretty(range(time),10))
> mtext("Time (Hours)",side=1,col="black",line=2.5)
> legend(5,13000,legend=c("Music","Actor"),text.col=c("black","red"),pch=c(16,15),col=c("black","red"))
>
> Now, what if time is replaced by month <-
> c("Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec","Pag")
>
Hi Birdada,
You can get the month labels using something like this:

twoord.plot(time,music,time,actor,lylim=c(0,1),type=c("l","b"),
  xtickpos=seq(0,70,by=10),xticklab=month.abb[1:8])

Hi arun,
This question may already have been answered, but to change the symbols, 
you have to use "lpch=" and "rpch=". I get the appropriate types of plot 
when using the above, and I tried several combinations of point, line, 
both that all worked okay. If I figure out what happened in your example 
I'll email the answer.

Jim


From rolf.turner at xtra.co.nz  Sun Jun 16 02:51:58 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Sun, 16 Jun 2013 12:51:58 +1200
Subject: [R] Optimization of a function using optim
In-Reply-To: <CAJhGg+0U98D9VhZ+gghvJ8y-AXSqQ=F5uSsi3XeXivC4u1c9Yg@mail.gmail.com>
References: <CAJhGg+0U98D9VhZ+gghvJ8y-AXSqQ=F5uSsi3XeXivC4u1c9Yg@mail.gmail.com>
Message-ID: <51BD0C2E.8080202@xtra.co.nz>



The r-help list should institute a prize for "Most Obtuse Question
of the Month".  This one should be a shoe-in for the June 2013 prize.

     cheers,

         Rolf Turner

On 16/06/13 12:08, Graham McDannel wrote:
> I am attempting to optimize a function I have developed using optim.
>
> I am getting the below error message:
>
> Error in n < 1: 'n' is missing
>
> Could some one provide some additional clarity regarding this message and
> what it entails, as well as, how to rectify this issue.
>
> Thanks


From smartpink111 at yahoo.com  Sun Jun 16 05:28:50 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 15 Jun 2013 20:28:50 -0700 (PDT)
Subject: [R] quick Help needed
In-Reply-To: <CACi=cgbfYqmjS18eC25d+O3hKCucXEsf_R_k6Lq0_HHhmtBqfQ@mail.gmail.com>
References: <CACi=cgbfYqmjS18eC25d+O3hKCucXEsf_R_k6Lq0_HHhmtBqfQ@mail.gmail.com>
Message-ID: <1371353330.52483.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
It is better to ?dput() the dummy dataset.
I made up some data for female==0
dat1<- read.table(text="
?pbnr??????? dat? dep? dys? sop? ago? mis age female messpunkt2 messpunkt1 tage eintrittsjahr
1 10023 1994-02-21 0.75 1.00 0.50 0.50 0.75? 35????? 1?????? 8817 8817??? 0????????? 1994
2 10023 1994-05-25 0.75 1.00 0.50 0.50 0.75? 35????? 1?????? 8910 8817?? 93????????? 1994
3 10028 1994-02-01 2.00 1.75 3.00 0.50 1.50? 42????? 1?????? 8797 8797??? 0????????? 1994
4 10028 1999-01-15 1.25 0.75 2.25 0.50 0.25? 42????? 1????? 10606 8797 1809????????? 1999
5 10053 1994-03-16 2.50 0.75 1.25 0.50 1.25? 22????? 1?????? 8840 8840??? 0????????? 1994
6 10053 1994-09-23 3.25 1.25 1.25 0.75 2.25? 22????? 1?????? 9031 8840? 191????????? 1994
7 10043 1994-02-21 0.85 1.20 0.51 0.55 0.95? 45????? 0?????? 8917 8817??? 0????????? 1994
8 10043 1994-05-25 0.95 1.10 0.55 0.55 0.85? 35????? 0?????? 8950 8717?? 93????????? 1994
9 10038 1994-02-01 2.50 1.85 3.20 0.70 1.70? 45????? 0?????? 9797 8897??? 0????????? 1994
10 10038 1999-01-15 1.55 0.85 2.35 0.70 0.55? 47????? 0????? 11606 9797 1809????????? 1999
11 10063 1994-03-16 2.20 0.65 1.55 0.85 1.25? 28????? 0?????? 8940 8850??? 0????????? 1994
12 10063 1994-09-23 3.55 1.35 1.55 0.95 2.35? 32????? 0?????? 9531 8340? 191????????? 1994
",sep="",header=TRUE,stringsAsFactors=FALSE)

?by(dat1[, c(3:8)], dat1[,"female"], summary)
#or
library(psych)
describeBy(dat1[,3:8],dat1$female)
#or
?describeBy(dat1[,3:8],dat1$female,mat=TRUE)


A.K.



----- Original Message -----
From: Sophie Homeyer <sophie.homeyer at googlemail.com>
To: r-help at r-project.org
Cc: 
Sent: Saturday, June 15, 2013 4:58 PM
Subject: [R] quick Help needed

Hi,
i am new to this forum and not sure how it works,
I am trying to do deskriptive descripe my data in terms of gender:

head(scltotal)

?  pbnr? ? ? ? dat? dep? dys? sop? ago? mis age female messpunkt2
messpunkt1 tage eintrittsjahr

1 10023 1994-02-21 0.75 1.00 0.50 0.50 0.75? 35? ? ? 1? ? ?  8817
8817? ? 0? ? ? ? ? 1994

2 10023 1994-05-25 0.75 1.00 0.50 0.50 0.75? 35? ? ? 1? ? ?  8910
8817?  93? ? ? ? ? 1994

3 10028 1994-02-01 2.00 1.75 3.00 0.50 1.50? 42? ? ? 1? ? ?  8797
8797? ? 0? ? ? ? ? 1994

4 10028 1999-01-15 1.25 0.75 2.25 0.50 0.25? 42? ? ? 1? ? ? 10606
8797 1809? ? ? ? ? 1999

5 10053 1994-03-16 2.50 0.75 1.25 0.50 1.25? 22? ? ? 1? ? ?  8840
8840? ? 0? ? ? ? ? 1994

6 10053 1994-09-23 3.25 1.25 1.25 0.75 2.25? 22? ? ? 1? ? ?  9031
8840? 191? ? ? ? ? 1994
so female is either 0 or 1 I assume 0 is male and 1 is female. And I want
to look at dep, dys, sop, ago and mis how they are in terms of gender
(female or male) I have no clue what to do :-(
thanks for your help
sophie

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From matzke at berkeley.edu  Sun Jun 16 07:06:43 2013
From: matzke at berkeley.edu (Nick Matzke)
Date: Sat, 15 Jun 2013 22:06:43 -0700
Subject: [R] extract all numbers from a string
Message-ID: <51BD47E3.6090808@berkeley.edu>

Hi all,

I have been beating my head against this problem for a bit, 
but I can't figure it out.

I have a series of strings of variable length, and each will 
have one or more numbers, of varying format.  E.g., I might 
have:


tmpstr = "The first number is: 32.  Another one is: 32.1. 
Here's a number in scientific format, 0.3523e10, and 
another, 0.3523e-10, and a negative, -313.1"

How could I get R to just give me a list of numerics 
containing the numbers therein?

Thanks very much to the regexp wizards!

Cheers,
Nick



-- 
====================================================
Nicholas J. Matzke
Ph.D. Candidate, Graduate Student Researcher

Huelsenbeck Lab
Center for Theoretical Evolutionary Genomics
4151 VLSB (Valley Life Sciences Building)
Department of Integrative Biology
University of California, Berkeley

Graduate Student Instructor, IB200B
Principles of Phylogenetics: Ecology and Evolution
http://ib.berkeley.edu/courses/ib200b/
http://phylo.wikidot.com/


Lab websites:
http://ib.berkeley.edu/people/lab_detail.php?lab=54
http://fisher.berkeley.edu/cteg/hlab.html
Dept. personal page: 
http://ib.berkeley.edu/people/students/person_detail.php?person=370
Lab personal page: 
http://fisher.berkeley.edu/cteg/members/matzke.html
Lab phone: 510-643-6299
Dept. fax: 510-643-6264

Cell phone: 510-301-0179
Email: matzke at berkeley.edu

Mailing address:
Department of Integrative Biology
1005 Valley Life Sciences Building #3140
Berkeley, CA 94720-3140

-----------------------------------------------------
"[W]hen people thought the earth was flat, they were wrong. 
When people thought the earth was spherical, they were 
wrong. But if you think that thinking the earth is spherical 
is just as wrong as thinking the earth is flat, then your 
view is wronger than both of them put together."

Isaac Asimov (1989). "The Relativity of Wrong." The 
Skeptical Inquirer, 14(1), 35-44. Fall 1989.
http://chem.tufts.edu/AnswersInScience/RelativityofWrong.htm


From smartpink111 at yahoo.com  Sun Jun 16 07:46:54 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 15 Jun 2013 22:46:54 -0700 (PDT)
Subject: [R] extract all numbers from a string
In-Reply-To: <51BD47E3.6090808@berkeley.edu>
References: <51BD47E3.6090808@berkeley.edu>
Message-ID: <1371361614.53710.YahooMailNeo@web142606.mail.bf1.yahoo.com>



HI,
One way would be:

library(stringr)
tmpstr = "The first number is: 32.? Another one is: 32.1.
Here's a number in scientific format, 0.3523e10, and
another, 0.3523e-10, and a negative, -313.1"
pattern<- "(\\d)+|(\\d+\\.\\d+)|(-\\d+\\.\\d+)|(\\d+.\\d+e\\d+)|(\\d+\\.\\d+e-\\d+)"
str_extract_all(tmpstr,pattern)[[1]]
#[1] "32"???????? "32.1"?????? "0.3523e10"? "0.3523e-10" "-313.1"??? 
?as.numeric(str_extract_all(tmpstr,pattern)[[1]])
A.K.



----- Original Message -----
From: Nick Matzke <matzke at berkeley.edu>
To: R-help at r-project.org
Cc: 
Sent: Sunday, June 16, 2013 1:06 AM
Subject: [R] extract all numbers from a string

Hi all,

I have been beating my head against this problem for a bit, 
but I can't figure it out.

I have a series of strings of variable length, and each will 
have one or more numbers, of varying format.? E.g., I might 
have:


tmpstr = "The first number is: 32.? Another one is: 32.1. 
Here's a number in scientific format, 0.3523e10, and 
another, 0.3523e-10, and a negative, -313.1"

How could I get R to just give me a list of numerics 
containing the numbers therein?

Thanks very much to the regexp wizards!

Cheers,
Nick



-- 
====================================================
Nicholas J. Matzke
Ph.D. Candidate, Graduate Student Researcher

Huelsenbeck Lab
Center for Theoretical Evolutionary Genomics
4151 VLSB (Valley Life Sciences Building)
Department of Integrative Biology
University of California, Berkeley

Graduate Student Instructor, IB200B
Principles of Phylogenetics: Ecology and Evolution
http://ib.berkeley.edu/courses/ib200b/
http://phylo.wikidot.com/


Lab websites:
http://ib.berkeley.edu/people/lab_detail.php?lab=54
http://fisher.berkeley.edu/cteg/hlab.html
Dept. personal page: 
http://ib.berkeley.edu/people/students/person_detail.php?person=370
Lab personal page: 
http://fisher.berkeley.edu/cteg/members/matzke.html
Lab phone: 510-643-6299
Dept. fax: 510-643-6264

Cell phone: 510-301-0179
Email: matzke at berkeley.edu

Mailing address:
Department of Integrative Biology
1005 Valley Life Sciences Building #3140
Berkeley, CA 94720-3140

-----------------------------------------------------
"[W]hen people thought the earth was flat, they were wrong. 
When people thought the earth was spherical, they were 
wrong. But if you think that thinking the earth is spherical 
is just as wrong as thinking the earth is flat, then your 
view is wronger than both of them put together."

Isaac Asimov (1989). "The Relativity of Wrong." The 
Skeptical Inquirer, 14(1), 35-44. Fall 1989.
http://chem.tufts.edu/AnswersInScience/RelativityofWrong.htm

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From mackay at northnet.com.au  Sun Jun 16 07:49:42 2013
From: mackay at northnet.com.au (Duncan Mackay)
Date: Sun, 16 Jun 2013 15:49:42 +1000
Subject: [R] extract all numbers from a string
In-Reply-To: <51BD47E3.6090808@berkeley.edu>
References: <51BD47E3.6090808@berkeley.edu>
Message-ID: <201306160549.r5G5nlBj025082@mail12.tpg.com.au>

Nick

try

as.numeric(
  strsplit(gsub("[[:alpha:][:punct:][:space:]]{2,}",",",tmpstr),",")[[1]][-1]
)

see ?regexpr for information

HTH

Duncan


Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au



At 15:06 16/06/2013, you wrote:
>Hi all,
>
>I have been beating my head against this problem for a bit, but I 
>can't figure it out.
>
>I have a series of strings of variable length, and each will have 
>one or more numbers, of varying format.  E.g., I might have:
>
>
>tmpstr = "The first number is: 32.  Another one is: 32.1. Here's a 
>number in scientific format, 0.3523e10, and another, 0.3523e-10, and 
>a negative, -313.1"
>
>How could I get R to just give me a list of numerics containing the 
>numbers therein?
>
>Thanks very much to the regexp wizards!
>
>Cheers,
>Nick
>
>
>
>--
>====================================================
>Nicholas J. Matzke
>Ph.D. Candidate, Graduate Student Researcher
>
>Huelsenbeck Lab
>Center for Theoretical Evolutionary Genomics
>4151 VLSB (Valley Life Sciences Building)
>Department of Integrative Biology
>University of California, Berkeley
>
>Graduate Student Instructor, IB200B
>Principles of Phylogenetics: Ecology and Evolution
>http://ib.berkeley.edu/courses/ib200b/
>http://phylo.wikidot.com/
>
>
>Lab websites:
>http://ib.berkeley.edu/people/lab_detail.php?lab=54
>http://fisher.berkeley.edu/cteg/hlab.html
>Dept. personal page: 
>http://ib.berkeley.edu/people/students/person_detail.php?person=370
>Lab personal page: http://fisher.berkeley.edu/cteg/members/matzke.html
>Lab phone: 510-643-6299
>Dept. fax: 510-643-6264
>
>Cell phone: 510-301-0179
>Email: matzke at berkeley.edu
>
>Mailing address:
>Department of Integrative Biology
>1005 Valley Life Sciences Building #3140
>Berkeley, CA 94720-3140
>
>-----------------------------------------------------
>"[W]hen people thought the earth was flat, they were wrong. When 
>people thought the earth was spherical, they were wrong. But if you 
>think that thinking the earth is spherical is just as wrong as 
>thinking the earth is flat, then your view is wronger than both of 
>them put together."
>
>Isaac Asimov (1989). "The Relativity of Wrong." The Skeptical 
>Inquirer, 14(1), 35-44. Fall 1989.
>http://chem.tufts.edu/AnswersInScience/RelativityofWrong.htm
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


From kevinchavers at gmail.com  Sun Jun 16 06:12:46 2013
From: kevinchavers at gmail.com (Kevin Chavers)
Date: Sun, 16 Jun 2013 00:12:46 -0400
Subject: [R] R for Chrome OS
Message-ID: <CAHvNr3rbPtmen_CUXFjaKXJ-mvs02oJyqnH6ACNLaG8njpOQiw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130616/7a5fa40f/attachment.pl>

From grv144 at yahoo.com  Sun Jun 16 04:35:30 2013
From: grv144 at yahoo.com (G Vishwanath)
Date: Sat, 15 Jun 2013 19:35:30 -0700 (PDT)
Subject: [R] Matrix Mulitplication: A*B*C*D...?
Message-ID: <1371350130.67939.YahooMailNeo@web122202.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130615/ce64f9ac/attachment.pl>

From jamesbond.indranil at gmail.com  Sun Jun 16 05:17:35 2013
From: jamesbond.indranil at gmail.com (INDRANIL GHOSH)
Date: Sat, 15 Jun 2013 20:17:35 -0700
Subject: [R] Simulating from a special type of bivariate exponential
	distribution
Message-ID: <CAGMzmw22LeA+OX7i_crvV73Q495n8FcEYP2-6E3AB5VZtXagrQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130615/932963e1/attachment.pl>

From guylaina_nd at yahoo.fr  Sun Jun 16 09:05:30 2013
From: guylaina_nd at yahoo.fr (Guylaine NOUWOUE)
Date: Sun, 16 Jun 2013 09:05:30 +0200
Subject: [R]  Problems using log() in a plm() regression.
Message-ID: <000001ce6a5f$e5b47790$b11d66b0$@fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130616/9779579e/attachment.pl>

From suparna.mitra.sm at gmail.com  Sun Jun 16 09:20:37 2013
From: suparna.mitra.sm at gmail.com (Suparna Mitra)
Date: Sun, 16 Jun 2013 15:20:37 +0800
Subject: [R] Creating subset using selected columns
Message-ID: <CAFdg=fUNCOGAps13k2TTonE5MSuQmFh_qV5LaNkJVC_KoqKjig@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130616/ac613daa/attachment.pl>

From ruipbarradas at sapo.pt  Sun Jun 16 10:40:00 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 16 Jun 2013 09:40:00 +0100
Subject: [R] Creating subset using selected columns
In-Reply-To: <CAFdg=fUNCOGAps13k2TTonE5MSuQmFh_qV5LaNkJVC_KoqKjig@mail.gmail.com>
References: <CAFdg=fUNCOGAps13k2TTonE5MSuQmFh_qV5LaNkJVC_KoqKjig@mail.gmail.com>
Message-ID: <51BD79E0.6010803@sapo.pt>

Hello,

You could try something like the following.
The example below assumes your data.frame is named 'dat'


cnums <- grep("Peak\\.Area", colnames(dat))
subdat <- dat[cnums]

See ?regexp for the regular expressions used by ?grep.

Hope this helps,

Rui Barradas

Em 16-06-2013 08:20, Suparna Mitra escreveu:
> Hello R experts,
>   I need a help to create a subset file. I know with subset comand, its very
> easy to select many different columns, or threshold. But here I have a bit
> problem as in my data file is big. And I don't want to identify the column
> numbers
>
> or names manually. I am trying to find any way to automatise this.
>
> For example I have a file with about 1500 columns from TRFLP intensity
> data.
>
>
> And the column names are like:
>   [1] "Sample.Name"    "Marker"         "RE"             "Dye"
>   "Allele.1"       "Size.1"         "Height.1"       "Peak.Area.1"
>   "Data.Point.1"
>    [10] "Allele.2"       "Size.2"         "Height.2"       "Peak.Area.2"
>   "Data.Point.2"   "Allele.3"       "Size.3"         "Height.3"
> "Peak.Area.3"
>    [19] "Data.Point.3"   "Allele.4"       "Size.4"         "Height.4"
> "Peak.Area.4"    "Data.Point.4"   "Allele.5"       "Size.5"
> "Height.5"
>    [28] "Peak.Area.5"    "Data.Point.5"   "Allele.6"       "Size.6"
> "Height.6"       "Peak.Area.6"    "Data.Point.6"   "Allele.7"
> "Size.7"
>    [37] "Height.7"       "Peak.Area.7"    "Data.Point.7"   "Allele.8"
> "Size.8"         "Height.8"       "Peak.Area.8"    "Data.Point.8"
> "Allele.9"
>    [46] "Size.9"         "Height.9"       "Peak.Area.9"    "Data.Point.9"
> "Allele.10"      "Size.10"        "Height.10"      "Peak.Area.10"
> "Data.Point.10"
> .....
>
> Suppose I want to create a subset selecting all the columns with
> name Peak.Area
> (as in unix Peak.Area.*)
> How can I do that in R?
> Thanks a lot for the help.
> Best wishes,
> Mitra
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rainer.schuermann at gmx.net  Sun Jun 16 10:42:33 2013
From: rainer.schuermann at gmx.net (Rainer Schuermann)
Date: Sun, 16 Jun 2013 10:42:33 +0200
Subject: [R] Creating subset using selected columns
In-Reply-To: <CAFdg=fUNCOGAps13k2TTonE5MSuQmFh_qV5LaNkJVC_KoqKjig@mail.gmail.com>
References: <CAFdg=fUNCOGAps13k2TTonE5MSuQmFh_qV5LaNkJVC_KoqKjig@mail.gmail.com>
Message-ID: <1601191.ozr5mS5u3M@augeatur>

Supposed your data.frame is called x, try
x[ which( substr( colnames( x ), 1, 4 ) == "Peak" ) ]


On Sunday 16 June 2013 15:20:37 Suparna Mitra wrote:
> Hello R experts,
>  I need a help to create a subset file. I know with subset comand, its very
> easy to select many different columns, or threshold. But here I have a bit
> problem as in my data file is big. And I don't want to identify the column
> numbers  
> 
> or names manually. I am trying to find any way to automatise this.
> 
> For example I have a file with about 1500 columns from TRFLP intensity
> data.
> 
> 
> And the column names are like:
>  [1] "Sample.Name"    "Marker"         "RE"             "Dye"
>  "Allele.1"       "Size.1"         "Height.1"       "Peak.Area.1"
>  "Data.Point.1"
>   [10] "Allele.2"       "Size.2"         "Height.2"       "Peak.Area.2"
>  "Data.Point.2"   "Allele.3"       "Size.3"         "Height.3"
> "Peak.Area.3"
>   [19] "Data.Point.3"   "Allele.4"       "Size.4"         "Height.4"
> "Peak.Area.4"    "Data.Point.4"   "Allele.5"       "Size.5"
> "Height.5"
>   [28] "Peak.Area.5"    "Data.Point.5"   "Allele.6"       "Size.6"
> "Height.6"       "Peak.Area.6"    "Data.Point.6"   "Allele.7"
> "Size.7"
>   [37] "Height.7"       "Peak.Area.7"    "Data.Point.7"   "Allele.8"
> "Size.8"         "Height.8"       "Peak.Area.8"    "Data.Point.8"
> "Allele.9"
>   [46] "Size.9"         "Height.9"       "Peak.Area.9"    "Data.Point.9"
> "Allele.10"      "Size.10"        "Height.10"      "Peak.Area.10"
> "Data.Point.10"
> .....
> 
> Suppose I want to create a subset selecting all the columns with
> name Peak.Area
> (as in unix Peak.Area.*)
> How can I do that in R? 
> Thanks a lot for the help.
> Best wishes,
> Mitra
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From zadig_1 at excite.com  Sun Jun 16 12:42:20 2013
From: zadig_1 at excite.com (ce)
Date: Sun, 16 Jun 2013 06:42:20 -0400
Subject: [R] can't install rugarch and nloptr packages in R 3.01 opensuse
	linux
Message-ID: <20130616064220.30872@web007.roc2.bluetie.com>

I can't install rugarch package because installation of nloptr package fails .

I use opensuse 12.3 
# uname -a
Linux candide 3.7.10-1.11-desktop #1 SMP PREEMPT Thu May 16 20:27:27 UTC 2013 (adf31bb) x86_64 x86_64 x86_64 GNU/Linux
my gcc version is 4.8.1

I compiled and installed R 3.01 . then I tried to install rugarch package but it fails because it can't install depended package nloptr.  I try to install nloptr individually with install.packages("nloptr"), i get a lot of deprecated messages and it fails. I attach log file . when I try to compile nlopt software it also gives similar messages. 

Following fails too:

R version 3.0.1 (2013-05-16) -- "Good Sport"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

>  install.packages("nloptr",repos="http://R-Forge.R-project.org")
Warning message:
package ?nloptr? is not available (for R version 3.0.1) 
-------------- next part --------------

R version 3.0.1 (2013-05-16) -- "Good Sport"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> install.packages("nloptr")
trying URL 'http://cran.r-mirror.de/src/contrib/nloptr_0.9.1.tar.gz'
Content type 'application/x-gzip' length 289044 bytes (282 Kb)
opened URL
==================================================
downloaded 282 Kb

* installing *source* package ?nloptr? ...
** package ?nloptr? successfully unpacked and MD5 sums checked
** libs
`"/usr/local/lib64/R/bin/Rscript" -e "download.file(url='http://ab-initio.mit.edu/nlopt/nlopt-2.3.tar.gz', destfile='nlopt-2.3.tar.gz')"`
trying URL 'http://ab-initio.mit.edu/nlopt/nlopt-2.3.tar.gz'
Content type 'application/x-gzip' length 2353879 bytes (2.2 Mb)
opened URL
==================================================
downloaded 2.2 Mb

`"/usr/local/lib64/R/bin/Rscript" -e "untar(tarfile='nlopt-2.3.tar.gz')"`
rm -rf nlopt-2.3.tar.gz
echo "Installing library to: `pwd`/nlopt-2.3"
Installing library to: /tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3
cd nlopt-2.3; \
./configure --prefix="`pwd`" --enable-shared --enable-static --without-octave --without-matlab --without-guile --without-python --with-cxx CC="gcc -std=gnu99" CFLAGS="-g -O2 " CPP="`"/usr/local/lib64/R/bin/R" CMD config CPP`" CPPFLAGS="-I/usr/local/include" CXX="g++" CXXFLAGS="-g -O2 " CXXCPP="g++ -E"; \
make; \
make install; \
ls | grep -v ^include$ | grep -v ^lib$ | xargs rm -rf; \
    rm -rf .libs;
configure: loading site script /usr/share/site/x86_64-unknown-linux-gnu
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... yes
checking for a thread-safe mkdir -p... /usr/bin/mkdir -p
checking for gawk... gawk
checking whether make sets $(MAKE)... yes
checking whether to enable maintainer-specific portions of Makefiles... no
checking for gcc... gcc -std=gnu99
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables... 
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc -std=gnu99 accepts -g... yes
checking for gcc -std=gnu99 option to accept ISO C89... none needed
checking for style of include used by make... GNU
checking dependency style of gcc -std=gnu99... gcc3
checking for gcc -std=gnu99 option to accept ISO C99... none needed
checking for gcc -std=gnu99 option to accept ISO Standard C... (cached) none needed
checking whether ln -s works... yes
checking whether make sets $(MAKE)... (cached) yes
checking build system type... x86_64-unknown-linux-gnu
checking host system type... x86_64-unknown-linux-gnu
checking how to print strings... printf
checking for a sed that does not truncate output... /usr/bin/sed
checking for grep that handles long lines and -e... /usr/bin/grep
checking for egrep... /usr/bin/grep -E
checking for fgrep... /usr/bin/grep -F
checking for ld used by gcc -std=gnu99... /usr/bin/ld
checking if the linker (/usr/bin/ld) is GNU ld... yes
checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B
checking the name lister (/usr/bin/nm -B) interface... BSD nm
checking the maximum length of command line arguments... 1572864
checking whether the shell understands some XSI constructs... yes
checking whether the shell understands "+="... yes
checking how to convert x86_64-unknown-linux-gnu file names to x86_64-unknown-linux-gnu format... func_convert_file_noop
checking how to convert x86_64-unknown-linux-gnu file names to toolchain format... func_convert_file_noop
checking for /usr/bin/ld option to reload object files... -r
checking for objdump... objdump
checking how to recognize dependent libraries... pass_all
checking for dlltool... dlltool
checking how to associate runtime and link libraries... printf %s\n
checking for ar... ar
checking for archiver @FILE support... @
checking for strip... strip
checking for ranlib... ranlib
checking command to parse /usr/bin/nm -B output from gcc -std=gnu99 object... ok
checking for sysroot... no
checking for mt... mt
checking if mt is a manifest tool... no
checking how to run the C preprocessor... gcc -std=gnu99 -E
checking for ANSI C header files... yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking for dlfcn.h... yes
checking for objdir... .libs
checking if gcc -std=gnu99 supports -fno-rtti -fno-exceptions... no
checking for gcc -std=gnu99 option to produce PIC... -fPIC -DPIC
checking if gcc -std=gnu99 PIC flag -fPIC -DPIC works... yes
checking if gcc -std=gnu99 static flag -static works... no
checking if gcc -std=gnu99 supports -c -o file.o... yes
checking if gcc -std=gnu99 supports -c -o file.o... (cached) yes
checking whether the gcc -std=gnu99 linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
checking whether -lc should be explicitly linked in... no
checking dynamic linker characteristics... GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking whether stripping libraries is possible... yes
checking if libtool supports shared libraries... yes
checking whether to build shared libraries... yes
checking whether to build static libraries... yes
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
checking dependency style of g++... gcc3
checking how to run the C++ preprocessor... g++ -E
checking for ld used by g++... /usr/bin/ld -m elf_x86_64
checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yes
checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
checking for g++ option to produce PIC... -fPIC -DPIC
checking if g++ PIC flag -fPIC -DPIC works... yes
checking if g++ static flag -static works... no
checking if g++ supports -c -o file.o... yes
checking if g++ supports -c -o file.o... (cached) yes
checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
checking dynamic linker characteristics... (cached) GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking for ANSI C header files... (cached) yes
checking whether time.h and sys/time.h may both be included... yes
checking for unistd.h... (cached) yes
checking getopt.h usability... yes
checking getopt.h presence... yes
checking for getopt.h... yes
checking for stdint.h... (cached) yes
checking for an ANSI C-conforming const... yes
checking for inline... inline
checking for C thread-local keyword... __thread
checking size of unsigned int... 4
checking size of unsigned long... 8
checking for uint32_t... yes
checking for sin in -lm... yes
checking for BSDgettimeofday... no
checking for gettimeofday... yes
checking for time... yes
checking for qsort_r... yes
checking for getpid... yes
checking for gettid syscall... yes
checking for isnan... yes
checking for isinf... yes
checking for copysign... yes
checking for mkoctfile... mkoctfile
checking for mex... no
checking for working HUGE_VAL... ok
checking that generated files are newer than configure... done
configure: creating ./config.status
config.status: creating Makefile
config.status: creating nlopt.pc
config.status: creating api/Makefile
config.status: creating util/Makefile
config.status: creating octave/Makefile
config.status: creating direct/Makefile
config.status: creating cdirect/Makefile
config.status: creating stogo/Makefile
config.status: creating praxis/Makefile
config.status: creating lbfgs/Makefile
config.status: creating luksan/Makefile
config.status: creating crs/Makefile
config.status: creating mlsl/Makefile
config.status: creating mma/Makefile
config.status: creating cobyla/Makefile
config.status: creating newuoa/Makefile
config.status: creating neldermead/Makefile
config.status: creating auglag/Makefile
config.status: creating bobyqa/Makefile
config.status: creating isres/Makefile
config.status: creating slsqp/Makefile
config.status: creating test/Makefile
config.status: creating swig/Makefile
config.status: creating swig/nlopt.scm
config.status: creating config.h
config.status: executing depfiles commands
config.status: executing libtool commands
make[1]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3'
make  all-recursive
make[2]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3'
Making all in util
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/util'
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../api -I/usr/local/include  -g -O2  -MT mt19937ar.lo -MD -MP -MF .deps/mt19937ar.Tpo -c -o mt19937ar.lo mt19937ar.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../api -I/usr/local/include -g -O2 -MT mt19937ar.lo -MD -MP -MF .deps/mt19937ar.Tpo -c mt19937ar.c  -fPIC -DPIC -o .libs/mt19937ar.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../api -I/usr/local/include -g -O2 -MT mt19937ar.lo -MD -MP -MF .deps/mt19937ar.Tpo -c mt19937ar.c -o mt19937ar.o >/dev/null 2>&1
mv -f .deps/mt19937ar.Tpo .deps/mt19937ar.Plo
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../api -I/usr/local/include  -g -O2  -MT sobolseq.lo -MD -MP -MF .deps/sobolseq.Tpo -c -o sobolseq.lo sobolseq.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../api -I/usr/local/include -g -O2 -MT sobolseq.lo -MD -MP -MF .deps/sobolseq.Tpo -c sobolseq.c  -fPIC -DPIC -o .libs/sobolseq.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../api -I/usr/local/include -g -O2 -MT sobolseq.lo -MD -MP -MF .deps/sobolseq.Tpo -c sobolseq.c -o sobolseq.o >/dev/null 2>&1
mv -f .deps/sobolseq.Tpo .deps/sobolseq.Plo
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../api -I/usr/local/include  -g -O2  -MT timer.lo -MD -MP -MF .deps/timer.Tpo -c -o timer.lo timer.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../api -I/usr/local/include -g -O2 -MT timer.lo -MD -MP -MF .deps/timer.Tpo -c timer.c  -fPIC -DPIC -o .libs/timer.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../api -I/usr/local/include -g -O2 -MT timer.lo -MD -MP -MF .deps/timer.Tpo -c timer.c -o timer.o >/dev/null 2>&1
mv -f .deps/timer.Tpo .deps/timer.Plo
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../api -I/usr/local/include  -g -O2  -MT stop.lo -MD -MP -MF .deps/stop.Tpo -c -o stop.lo stop.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../api -I/usr/local/include -g -O2 -MT stop.lo -MD -MP -MF .deps/stop.Tpo -c stop.c  -fPIC -DPIC -o .libs/stop.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../api -I/usr/local/include -g -O2 -MT stop.lo -MD -MP -MF .deps/stop.Tpo -c stop.c -o stop.o >/dev/null 2>&1
mv -f .deps/stop.Tpo .deps/stop.Plo
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../api -I/usr/local/include  -g -O2  -MT redblack.lo -MD -MP -MF .deps/redblack.Tpo -c -o redblack.lo redblack.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../api -I/usr/local/include -g -O2 -MT redblack.lo -MD -MP -MF .deps/redblack.Tpo -c redblack.c  -fPIC -DPIC -o .libs/redblack.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../api -I/usr/local/include -g -O2 -MT redblack.lo -MD -MP -MF .deps/redblack.Tpo -c redblack.c -o redblack.o >/dev/null 2>&1
mv -f .deps/redblack.Tpo .deps/redblack.Plo
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../api -I/usr/local/include  -g -O2  -MT qsort_r.lo -MD -MP -MF .deps/qsort_r.Tpo -c -o qsort_r.lo qsort_r.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../api -I/usr/local/include -g -O2 -MT qsort_r.lo -MD -MP -MF .deps/qsort_r.Tpo -c qsort_r.c  -fPIC -DPIC -o .libs/qsort_r.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../api -I/usr/local/include -g -O2 -MT qsort_r.lo -MD -MP -MF .deps/qsort_r.Tpo -c qsort_r.c -o qsort_r.o >/dev/null 2>&1
mv -f .deps/qsort_r.Tpo .deps/qsort_r.Plo
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../api -I/usr/local/include  -g -O2  -MT rescale.lo -MD -MP -MF .deps/rescale.Tpo -c -o rescale.lo rescale.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../api -I/usr/local/include -g -O2 -MT rescale.lo -MD -MP -MF .deps/rescale.Tpo -c rescale.c  -fPIC -DPIC -o .libs/rescale.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../api -I/usr/local/include -g -O2 -MT rescale.lo -MD -MP -MF .deps/rescale.Tpo -c rescale.c -o rescale.o >/dev/null 2>&1
mv -f .deps/rescale.Tpo .deps/rescale.Plo
/bin/sh ../libtool --tag=CC   --mode=link g++  -g -O2    -o libutil.la  mt19937ar.lo sobolseq.lo timer.lo stop.lo redblack.lo qsort_r.lo rescale.lo  -lm 
libtool: link: ar cru .libs/libutil.a .libs/mt19937ar.o .libs/sobolseq.o .libs/timer.o .libs/stop.o .libs/redblack.o .libs/qsort_r.o .libs/rescale.o 
libtool: link: ranlib .libs/libutil.a
libtool: link: ( cd ".libs" && rm -f "libutil.la" && ln -s "../libutil.la" "libutil.la" )
g++ -DHAVE_CONFIG_H -I. -I..  -I../api -I/usr/local/include  -g -O2  -MT redblack_test.o -MD -MP -MF .deps/redblack_test.Tpo -c -o redblack_test.o redblack_test.c
mv -f .deps/redblack_test.Tpo .deps/redblack_test.Po
/bin/sh ../libtool --tag=CC   --mode=link g++  -g -O2    -o redblack_test redblack_test.o libutil.la -lm 
libtool: link: g++ -g -O2 -o redblack_test redblack_test.o  ./.libs/libutil.a -lm
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/util'
Making all in direct
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/direct'
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT DIRect.lo -MD -MP -MF .deps/DIRect.Tpo -c -o DIRect.lo DIRect.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT DIRect.lo -MD -MP -MF .deps/DIRect.Tpo -c DIRect.c  -fPIC -DPIC -o .libs/DIRect.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT DIRect.lo -MD -MP -MF .deps/DIRect.Tpo -c DIRect.c -o DIRect.o >/dev/null 2>&1
mv -f .deps/DIRect.Tpo .deps/DIRect.Plo
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT direct_wrap.lo -MD -MP -MF .deps/direct_wrap.Tpo -c -o direct_wrap.lo direct_wrap.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT direct_wrap.lo -MD -MP -MF .deps/direct_wrap.Tpo -c direct_wrap.c  -fPIC -DPIC -o .libs/direct_wrap.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT direct_wrap.lo -MD -MP -MF .deps/direct_wrap.Tpo -c direct_wrap.c -o direct_wrap.o >/dev/null 2>&1
mv -f .deps/direct_wrap.Tpo .deps/direct_wrap.Plo
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT DIRserial.lo -MD -MP -MF .deps/DIRserial.Tpo -c -o DIRserial.lo DIRserial.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT DIRserial.lo -MD -MP -MF .deps/DIRserial.Tpo -c DIRserial.c  -fPIC -DPIC -o .libs/DIRserial.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT DIRserial.lo -MD -MP -MF .deps/DIRserial.Tpo -c DIRserial.c -o DIRserial.o >/dev/null 2>&1
mv -f .deps/DIRserial.Tpo .deps/DIRserial.Plo
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT DIRsubrout.lo -MD -MP -MF .deps/DIRsubrout.Tpo -c -o DIRsubrout.lo DIRsubrout.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT DIRsubrout.lo -MD -MP -MF .deps/DIRsubrout.Tpo -c DIRsubrout.c  -fPIC -DPIC -o .libs/DIRsubrout.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT DIRsubrout.lo -MD -MP -MF .deps/DIRsubrout.Tpo -c DIRsubrout.c -o DIRsubrout.o >/dev/null 2>&1
mv -f .deps/DIRsubrout.Tpo .deps/DIRsubrout.Plo
/bin/sh ../libtool --tag=CC   --mode=link g++  -g -O2    -o libdirect.la  DIRect.lo direct_wrap.lo DIRserial.lo DIRsubrout.lo  -lm 
libtool: link: ar cru .libs/libdirect.a .libs/DIRect.o .libs/direct_wrap.o .libs/DIRserial.o .libs/DIRsubrout.o 
libtool: link: ranlib .libs/libdirect.a
libtool: link: ( cd ".libs" && rm -f "libdirect.la" && ln -s "../libdirect.la" "libdirect.la" )
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/direct'
Making all in cdirect
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/cdirect'
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT cdirect.lo -MD -MP -MF .deps/cdirect.Tpo -c -o cdirect.lo cdirect.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT cdirect.lo -MD -MP -MF .deps/cdirect.Tpo -c cdirect.c  -fPIC -DPIC -o .libs/cdirect.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT cdirect.lo -MD -MP -MF .deps/cdirect.Tpo -c cdirect.c -o cdirect.o >/dev/null 2>&1
mv -f .deps/cdirect.Tpo .deps/cdirect.Plo
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT hybrid.lo -MD -MP -MF .deps/hybrid.Tpo -c -o hybrid.lo hybrid.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT hybrid.lo -MD -MP -MF .deps/hybrid.Tpo -c hybrid.c  -fPIC -DPIC -o .libs/hybrid.o
hybrid.c: In function 'nlopt_result optimize_rect(double*, params*)':
hybrid.c:91:12: warning: 'nlopt_result nlopt_minimize(nlopt_algorithm, int, nlopt_func_old, void*, const double*, const double*, double*, double*, double, double, double, double, const double*, int, double)' is deprecated (declared at ../api/nlopt.h:325) [-Wdeprecated-declarations]
      ret = nlopt_minimize(p->local_alg, n, fcount, p, 
            ^
hybrid.c:99:39: warning: 'nlopt_result nlopt_minimize(nlopt_algorithm, int, nlopt_func_old, void*, const double*, const double*, double*, double*, double, double, double, double, const double*, int, double)' is deprecated (declared at ../api/nlopt.h:325) [-Wdeprecated-declarations]
      stop->maxtime - (t - stop->start));
                                       ^
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT hybrid.lo -MD -MP -MF .deps/hybrid.Tpo -c hybrid.c -o hybrid.o >/dev/null 2>&1
mv -f .deps/hybrid.Tpo .deps/hybrid.Plo
/bin/sh ../libtool --tag=CC   --mode=link g++  -g -O2    -o libcdirect.la  cdirect.lo hybrid.lo  -lm 
libtool: link: ar cru .libs/libcdirect.a .libs/cdirect.o .libs/hybrid.o 
libtool: link: ranlib .libs/libcdirect.a
libtool: link: ( cd ".libs" && rm -f "libcdirect.la" && ln -s "../libcdirect.la" "libcdirect.la" )
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/cdirect'
Making all in stogo
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/stogo'
/bin/sh ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT global.lo -MD -MP -MF .deps/global.Tpo -c -o global.lo global.cc
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT global.lo -MD -MP -MF .deps/global.Tpo -c global.cc  -fPIC -DPIC -o .libs/global.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT global.lo -MD -MP -MF .deps/global.Tpo -c global.cc -o global.o >/dev/null 2>&1
mv -f .deps/global.Tpo .deps/global.Plo
/bin/sh ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT linalg.lo -MD -MP -MF .deps/linalg.Tpo -c -o linalg.lo linalg.cc
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT linalg.lo -MD -MP -MF .deps/linalg.Tpo -c linalg.cc  -fPIC -DPIC -o .libs/linalg.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT linalg.lo -MD -MP -MF .deps/linalg.Tpo -c linalg.cc -o linalg.o >/dev/null 2>&1
mv -f .deps/linalg.Tpo .deps/linalg.Plo
/bin/sh ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT local.lo -MD -MP -MF .deps/local.Tpo -c -o local.lo local.cc
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT local.lo -MD -MP -MF .deps/local.Tpo -c local.cc  -fPIC -DPIC -o .libs/local.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT local.lo -MD -MP -MF .deps/local.Tpo -c local.cc -o local.o >/dev/null 2>&1
mv -f .deps/local.Tpo .deps/local.Plo
/bin/sh ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT stogo.lo -MD -MP -MF .deps/stogo.Tpo -c -o stogo.lo stogo.cc
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT stogo.lo -MD -MP -MF .deps/stogo.Tpo -c stogo.cc  -fPIC -DPIC -o .libs/stogo.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT stogo.lo -MD -MP -MF .deps/stogo.Tpo -c stogo.cc -o stogo.o >/dev/null 2>&1
mv -f .deps/stogo.Tpo .deps/stogo.Plo
/bin/sh ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT tools.lo -MD -MP -MF .deps/tools.Tpo -c -o tools.lo tools.cc
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT tools.lo -MD -MP -MF .deps/tools.Tpo -c tools.cc  -fPIC -DPIC -o .libs/tools.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT tools.lo -MD -MP -MF .deps/tools.Tpo -c tools.cc -o tools.o >/dev/null 2>&1
mv -f .deps/tools.Tpo .deps/tools.Plo
/bin/sh ../libtool --tag=CXX   --mode=link g++  -g -O2    -o libstogo.la  global.lo linalg.lo local.lo stogo.lo tools.lo  -lm 
libtool: link: ar cru .libs/libstogo.a .libs/global.o .libs/linalg.o .libs/local.o .libs/stogo.o .libs/tools.o 
libtool: link: ranlib .libs/libstogo.a
libtool: link: ( cd ".libs" && rm -f "libstogo.la" && ln -s "../libstogo.la" "libstogo.la" )
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/stogo'
Making all in praxis
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/praxis'
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT praxis.lo -MD -MP -MF .deps/praxis.Tpo -c -o praxis.lo praxis.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT praxis.lo -MD -MP -MF .deps/praxis.Tpo -c praxis.c  -fPIC -DPIC -o .libs/praxis.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT praxis.lo -MD -MP -MF .deps/praxis.Tpo -c praxis.c -o praxis.o >/dev/null 2>&1
mv -f .deps/praxis.Tpo .deps/praxis.Plo
/bin/sh ../libtool --tag=CC   --mode=link g++  -g -O2    -o libpraxis.la  praxis.lo  -lm 
libtool: link: ar cru .libs/libpraxis.a .libs/praxis.o 
libtool: link: ranlib .libs/libpraxis.a
libtool: link: ( cd ".libs" && rm -f "libpraxis.la" && ln -s "../libpraxis.la" "libpraxis.la" )
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/praxis'
Making all in luksan
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/luksan'
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT plis.lo -MD -MP -MF .deps/plis.Tpo -c -o plis.lo plis.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT plis.lo -MD -MP -MF .deps/plis.Tpo -c plis.c  -fPIC -DPIC -o .libs/plis.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT plis.lo -MD -MP -MF .deps/plis.Tpo -c plis.c -o plis.o >/dev/null 2>&1
mv -f .deps/plis.Tpo .deps/plis.Plo
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT plip.lo -MD -MP -MF .deps/plip.Tpo -c -o plip.lo plip.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT plip.lo -MD -MP -MF .deps/plip.Tpo -c plip.c  -fPIC -DPIC -o .libs/plip.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT plip.lo -MD -MP -MF .deps/plip.Tpo -c plip.c -o plip.o >/dev/null 2>&1
mv -f .deps/plip.Tpo .deps/plip.Plo
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT pnet.lo -MD -MP -MF .deps/pnet.Tpo -c -o pnet.lo pnet.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT pnet.lo -MD -MP -MF .deps/pnet.Tpo -c pnet.c  -fPIC -DPIC -o .libs/pnet.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT pnet.lo -MD -MP -MF .deps/pnet.Tpo -c pnet.c -o pnet.o >/dev/null 2>&1
mv -f .deps/pnet.Tpo .deps/pnet.Plo
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT mssubs.lo -MD -MP -MF .deps/mssubs.Tpo -c -o mssubs.lo mssubs.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT mssubs.lo -MD -MP -MF .deps/mssubs.Tpo -c mssubs.c  -fPIC -DPIC -o .libs/mssubs.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT mssubs.lo -MD -MP -MF .deps/mssubs.Tpo -c mssubs.c -o mssubs.o >/dev/null 2>&1
mv -f .deps/mssubs.Tpo .deps/mssubs.Plo
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT pssubs.lo -MD -MP -MF .deps/pssubs.Tpo -c -o pssubs.lo pssubs.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT pssubs.lo -MD -MP -MF .deps/pssubs.Tpo -c pssubs.c  -fPIC -DPIC -o .libs/pssubs.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT pssubs.lo -MD -MP -MF .deps/pssubs.Tpo -c pssubs.c -o pssubs.o >/dev/null 2>&1
mv -f .deps/pssubs.Tpo .deps/pssubs.Plo
/bin/sh ../libtool --tag=CC   --mode=link g++  -g -O2    -o libluksan.la  plis.lo plip.lo pnet.lo mssubs.lo pssubs.lo  -lm 
libtool: link: ar cru .libs/libluksan.a .libs/plis.o .libs/plip.o .libs/pnet.o .libs/mssubs.o .libs/pssubs.o 
libtool: link: ranlib .libs/libluksan.a
libtool: link: ( cd ".libs" && rm -f "libluksan.la" && ln -s "../libluksan.la" "libluksan.la" )
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/luksan'
Making all in crs
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/crs'
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT crs.lo -MD -MP -MF .deps/crs.Tpo -c -o crs.lo crs.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT crs.lo -MD -MP -MF .deps/crs.Tpo -c crs.c  -fPIC -DPIC -o .libs/crs.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT crs.lo -MD -MP -MF .deps/crs.Tpo -c crs.c -o crs.o >/dev/null 2>&1
mv -f .deps/crs.Tpo .deps/crs.Plo
/bin/sh ../libtool --tag=CC   --mode=link g++  -g -O2    -o libcrs.la  crs.lo  -lm 
libtool: link: ar cru .libs/libcrs.a .libs/crs.o 
libtool: link: ranlib .libs/libcrs.a
libtool: link: ( cd ".libs" && rm -f "libcrs.la" && ln -s "../libcrs.la" "libcrs.la" )
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/crs'
Making all in mlsl
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/mlsl'
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT mlsl.lo -MD -MP -MF .deps/mlsl.Tpo -c -o mlsl.lo mlsl.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT mlsl.lo -MD -MP -MF .deps/mlsl.Tpo -c mlsl.c  -fPIC -DPIC -o .libs/mlsl.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT mlsl.lo -MD -MP -MF .deps/mlsl.Tpo -c mlsl.c -o mlsl.o >/dev/null 2>&1
mv -f .deps/mlsl.Tpo .deps/mlsl.Plo
/bin/sh ../libtool --tag=CC   --mode=link g++  -g -O2    -o libmlsl.la  mlsl.lo  -lm 
libtool: link: ar cru .libs/libmlsl.a .libs/mlsl.o 
libtool: link: ranlib .libs/libmlsl.a
libtool: link: ( cd ".libs" && rm -f "libmlsl.la" && ln -s "../libmlsl.la" "libmlsl.la" )
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/mlsl'
Making all in mma
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/mma'
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT mma.lo -MD -MP -MF .deps/mma.Tpo -c -o mma.lo mma.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT mma.lo -MD -MP -MF .deps/mma.Tpo -c mma.c  -fPIC -DPIC -o .libs/mma.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT mma.lo -MD -MP -MF .deps/mma.Tpo -c mma.c -o mma.o >/dev/null 2>&1
mv -f .deps/mma.Tpo .deps/mma.Plo
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT ccsa_quadratic.lo -MD -MP -MF .deps/ccsa_quadratic.Tpo -c -o ccsa_quadratic.lo ccsa_quadratic.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT ccsa_quadratic.lo -MD -MP -MF .deps/ccsa_quadratic.Tpo -c ccsa_quadratic.c  -fPIC -DPIC -o .libs/ccsa_quadratic.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT ccsa_quadratic.lo -MD -MP -MF .deps/ccsa_quadratic.Tpo -c ccsa_quadratic.c -o ccsa_quadratic.o >/dev/null 2>&1
mv -f .deps/ccsa_quadratic.Tpo .deps/ccsa_quadratic.Plo
/bin/sh ../libtool --tag=CC   --mode=link g++  -g -O2    -o libmma.la  mma.lo ccsa_quadratic.lo  -lm 
libtool: link: ar cru .libs/libmma.a .libs/mma.o .libs/ccsa_quadratic.o 
libtool: link: ranlib .libs/libmma.a
libtool: link: ( cd ".libs" && rm -f "libmma.la" && ln -s "../libmma.la" "libmma.la" )
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/mma'
Making all in cobyla
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/cobyla'
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT cobyla.lo -MD -MP -MF .deps/cobyla.Tpo -c -o cobyla.lo cobyla.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT cobyla.lo -MD -MP -MF .deps/cobyla.Tpo -c cobyla.c  -fPIC -DPIC -o .libs/cobyla.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT cobyla.lo -MD -MP -MF .deps/cobyla.Tpo -c cobyla.c -o cobyla.o >/dev/null 2>&1
mv -f .deps/cobyla.Tpo .deps/cobyla.Plo
/bin/sh ../libtool --tag=CC   --mode=link g++  -g -O2    -o libcobyla.la  cobyla.lo  -lm 
libtool: link: ar cru .libs/libcobyla.a .libs/cobyla.o 
libtool: link: ranlib .libs/libcobyla.a
libtool: link: ( cd ".libs" && rm -f "libcobyla.la" && ln -s "../libcobyla.la" "libcobyla.la" )
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/cobyla'
Making all in newuoa
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/newuoa'
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT newuoa.lo -MD -MP -MF .deps/newuoa.Tpo -c -o newuoa.lo newuoa.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT newuoa.lo -MD -MP -MF .deps/newuoa.Tpo -c newuoa.c  -fPIC -DPIC -o .libs/newuoa.o
newuoa.c: In function 'nlopt_result trsapp_(int*, int*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, double*, const double*, const double*, const double*)':
newuoa.c:184:9: warning: 'nlopt_result nlopt_minimize_constrained(nlopt_algorithm, int, nlopt_func_old, void*, int, nlopt_func_old, void*, ptrdiff_t, const double*, const double*, double*, double*, double, double, double, double, const double*, int, double)' is deprecated (declared at ../api/nlopt.h:335) [-Wdeprecated-declarations]
   ret = nlopt_minimize_constrained(NLOPT_LD_MMA, *n, quad_model, &qmd,
         ^
newuoa.c:187:35: warning: 'nlopt_result nlopt_minimize_constrained(nlopt_algorithm, int, nlopt_func_old, void*, int, nlopt_func_old, void*, ptrdiff_t, const double*, const double*, double*, double*, double, double, double, double, const double*, int, double)' is deprecated (declared at ../api/nlopt.h:335) [-Wdeprecated-declarations]
         0., 0., 0., xtol, 1000, 0.);
                                   ^
newuoa.c: In function 'nlopt_result biglag_(int*, int*, double*, double*, double*, double*, int*, int*, int*, double*, double*, double*, double*, double*, double*, double*, double*, const double*, const double*, const double*)':
newuoa.c:1241:10: warning: 'nlopt_result nlopt_minimize_constrained(nlopt_algorithm, int, nlopt_func_old, void*, int, nlopt_func_old, void*, ptrdiff_t, const double*, const double*, double*, double*, double, double, double, double, const double*, int, double)' is deprecated (declared at ../api/nlopt.h:335) [-Wdeprecated-declarations]
   return nlopt_minimize_constrained(NLOPT_LD_MMA, *n, lag, &ld,
          ^
newuoa.c:1244:35: warning: 'nlopt_result nlopt_minimize_constrained(nlopt_algorithm, int, nlopt_func_old, void*, int, nlopt_func_old, void*, ptrdiff_t, const double*, const double*, double*, double*, double, double, double, double, const double*, int, double)' is deprecated (declared at ../api/nlopt.h:335) [-Wdeprecated-declarations]
         0., 0., 0., xtol, 1000, 0.);
                                   ^
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT newuoa.lo -MD -MP -MF .deps/newuoa.Tpo -c newuoa.c -o newuoa.o >/dev/null 2>&1
mv -f .deps/newuoa.Tpo .deps/newuoa.Plo
/bin/sh ../libtool --tag=CC   --mode=link g++  -g -O2    -o libnewuoa.la  newuoa.lo  -lm 
libtool: link: ar cru .libs/libnewuoa.a .libs/newuoa.o 
libtool: link: ranlib .libs/libnewuoa.a
libtool: link: ( cd ".libs" && rm -f "libnewuoa.la" && ln -s "../libnewuoa.la" "libnewuoa.la" )
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/newuoa'
Making all in lbfgs
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/lbfgs'
make[3]: Nothing to be done for `all'.
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/lbfgs'
Making all in neldermead
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/neldermead'
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT nldrmd.lo -MD -MP -MF .deps/nldrmd.Tpo -c -o nldrmd.lo nldrmd.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT nldrmd.lo -MD -MP -MF .deps/nldrmd.Tpo -c nldrmd.c  -fPIC -DPIC -o .libs/nldrmd.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT nldrmd.lo -MD -MP -MF .deps/nldrmd.Tpo -c nldrmd.c -o nldrmd.o >/dev/null 2>&1
mv -f .deps/nldrmd.Tpo .deps/nldrmd.Plo
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT sbplx.lo -MD -MP -MF .deps/sbplx.Tpo -c -o sbplx.lo sbplx.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT sbplx.lo -MD -MP -MF .deps/sbplx.Tpo -c sbplx.c  -fPIC -DPIC -o .libs/sbplx.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT sbplx.lo -MD -MP -MF .deps/sbplx.Tpo -c sbplx.c -o sbplx.o >/dev/null 2>&1
mv -f .deps/sbplx.Tpo .deps/sbplx.Plo
/bin/sh ../libtool --tag=CC   --mode=link g++  -g -O2    -o libneldermead.la  nldrmd.lo sbplx.lo  -lm 
libtool: link: ar cru .libs/libneldermead.a .libs/nldrmd.o .libs/sbplx.o 
libtool: link: ranlib .libs/libneldermead.a
libtool: link: ( cd ".libs" && rm -f "libneldermead.la" && ln -s "../libneldermead.la" "libneldermead.la" )
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/neldermead'
Making all in auglag
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/auglag'
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT auglag.lo -MD -MP -MF .deps/auglag.Tpo -c -o auglag.lo auglag.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT auglag.lo -MD -MP -MF .deps/auglag.Tpo -c auglag.c  -fPIC -DPIC -o .libs/auglag.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT auglag.lo -MD -MP -MF .deps/auglag.Tpo -c auglag.c -o auglag.o >/dev/null 2>&1
mv -f .deps/auglag.Tpo .deps/auglag.Plo
/bin/sh ../libtool --tag=CC   --mode=link g++  -g -O2    -o libauglag.la  auglag.lo  -lm 
libtool: link: ar cru .libs/libauglag.a .libs/auglag.o 
libtool: link: ranlib .libs/libauglag.a
libtool: link: ( cd ".libs" && rm -f "libauglag.la" && ln -s "../libauglag.la" "libauglag.la" )
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/auglag'
Making all in bobyqa
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/bobyqa'
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT bobyqa.lo -MD -MP -MF .deps/bobyqa.Tpo -c -o bobyqa.lo bobyqa.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT bobyqa.lo -MD -MP -MF .deps/bobyqa.Tpo -c bobyqa.c  -fPIC -DPIC -o .libs/bobyqa.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT bobyqa.lo -MD -MP -MF .deps/bobyqa.Tpo -c bobyqa.c -o bobyqa.o >/dev/null 2>&1
mv -f .deps/bobyqa.Tpo .deps/bobyqa.Plo
/bin/sh ../libtool --tag=CC   --mode=link g++  -g -O2    -o libbobyqa.la  bobyqa.lo  -lm 
libtool: link: ar cru .libs/libbobyqa.a .libs/bobyqa.o 
libtool: link: ranlib .libs/libbobyqa.a
libtool: link: ( cd ".libs" && rm -f "libbobyqa.la" && ln -s "../libbobyqa.la" "libbobyqa.la" )
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/bobyqa'
Making all in isres
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/isres'
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT isres.lo -MD -MP -MF .deps/isres.Tpo -c -o isres.lo isres.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT isres.lo -MD -MP -MF .deps/isres.Tpo -c isres.c  -fPIC -DPIC -o .libs/isres.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT isres.lo -MD -MP -MF .deps/isres.Tpo -c isres.c -o isres.o >/dev/null 2>&1
mv -f .deps/isres.Tpo .deps/isres.Plo
/bin/sh ../libtool --tag=CC   --mode=link g++  -g -O2    -o libisres.la  isres.lo  -lm 
libtool: link: ar cru .libs/libisres.a .libs/isres.o 
libtool: link: ranlib .libs/libisres.a
libtool: link: ( cd ".libs" && rm -f "libisres.la" && ln -s "../libisres.la" "libisres.la" )
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/isres'
Making all in slsqp
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/slsqp'
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../util -I../api -I/usr/local/include  -g -O2  -MT slsqp.lo -MD -MP -MF .deps/slsqp.Tpo -c -o slsqp.lo slsqp.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT slsqp.lo -MD -MP -MF .deps/slsqp.Tpo -c slsqp.c  -fPIC -DPIC -o .libs/slsqp.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -I/usr/local/include -g -O2 -MT slsqp.lo -MD -MP -MF .deps/slsqp.Tpo -c slsqp.c -o slsqp.o >/dev/null 2>&1
mv -f .deps/slsqp.Tpo .deps/slsqp.Plo
/bin/sh ../libtool --tag=CC   --mode=link g++  -g -O2    -o libslsqp.la  slsqp.lo  -lm 
libtool: link: ar cru .libs/libslsqp.a .libs/slsqp.o 
libtool: link: ranlib .libs/libslsqp.a
libtool: link: ( cd ".libs" && rm -f "libslsqp.la" && ln -s "../libslsqp.la" "libslsqp.la" )
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/slsqp'
Making all in api
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/api'
make  all-am
make[4]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/api'
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../cdirect -I../direct -I../stogo -I../praxis -I../lbfgs -I../luksan -I../crs -I../mlsl -I../mma -I../cobyla -I../newuoa -I../neldermead -I../auglag -I../bobyqa -I../isres -I../slsqp -I../util -I/usr/local/include  -g -O2  -MT general.lo -MD -MP -MF .deps/general.Tpo -c -o general.lo general.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../cdirect -I../direct -I../stogo -I../praxis -I../lbfgs -I../luksan -I../crs -I../mlsl -I../mma -I../cobyla -I../newuoa -I../neldermead -I../auglag -I../bobyqa -I../isres -I../slsqp -I../util -I/usr/local/include -g -O2 -MT general.lo -MD -MP -MF .deps/general.Tpo -c general.c  -fPIC -DPIC -o .libs/general.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../cdirect -I../direct -I../stogo -I../praxis -I../lbfgs -I../luksan -I../crs -I../mlsl -I../mma -I../cobyla -I../newuoa -I../neldermead -I../auglag -I../bobyqa -I../isres -I../slsqp -I../util -I/usr/local/include -g -O2 -MT general.lo -MD -MP -MF .deps/general.Tpo -c general.c -o general.o >/dev/null 2>&1
mv -f .deps/general.Tpo .deps/general.Plo
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../cdirect -I../direct -I../stogo -I../praxis -I../lbfgs -I../luksan -I../crs -I../mlsl -I../mma -I../cobyla -I../newuoa -I../neldermead -I../auglag -I../bobyqa -I../isres -I../slsqp -I../util -I/usr/local/include  -g -O2  -MT options.lo -MD -MP -MF .deps/options.Tpo -c -o options.lo options.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../cdirect -I../direct -I../stogo -I../praxis -I../lbfgs -I../luksan -I../crs -I../mlsl -I../mma -I../cobyla -I../newuoa -I../neldermead -I../auglag -I../bobyqa -I../isres -I../slsqp -I../util -I/usr/local/include -g -O2 -MT options.lo -MD -MP -MF .deps/options.Tpo -c options.c  -fPIC -DPIC -o .libs/options.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../cdirect -I../direct -I../stogo -I../praxis -I../lbfgs -I../luksan -I../crs -I../mlsl -I../mma -I../cobyla -I../newuoa -I../neldermead -I../auglag -I../bobyqa -I../isres -I../slsqp -I../util -I/usr/local/include -g -O2 -MT options.lo -MD -MP -MF .deps/options.Tpo -c options.c -o options.o >/dev/null 2>&1
mv -f .deps/options.Tpo .deps/options.Plo
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../cdirect -I../direct -I../stogo -I../praxis -I../lbfgs -I../luksan -I../crs -I../mlsl -I../mma -I../cobyla -I../newuoa -I../neldermead -I../auglag -I../bobyqa -I../isres -I../slsqp -I../util -I/usr/local/include  -g -O2  -MT optimize.lo -MD -MP -MF .deps/optimize.Tpo -c -o optimize.lo optimize.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../cdirect -I../direct -I../stogo -I../praxis -I../lbfgs -I../luksan -I../crs -I../mlsl -I../mma -I../cobyla -I../newuoa -I../neldermead -I../auglag -I../bobyqa -I../isres -I../slsqp -I../util -I/usr/local/include -g -O2 -MT optimize.lo -MD -MP -MF .deps/optimize.Tpo -c optimize.c  -fPIC -DPIC -o .libs/optimize.o
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../cdirect -I../direct -I../stogo -I../praxis -I../lbfgs -I../luksan -I../crs -I../mlsl -I../mma -I../cobyla -I../newuoa -I../neldermead -I../auglag -I../bobyqa -I../isres -I../slsqp -I../util -I/usr/local/include -g -O2 -MT optimize.lo -MD -MP -MF .deps/optimize.Tpo -c optimize.c -o optimize.o >/dev/null 2>&1
mv -f .deps/optimize.Tpo .deps/optimize.Plo
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../cdirect -I../direct -I../stogo -I../praxis -I../lbfgs -I../luksan -I../crs -I../mlsl -I../mma -I../cobyla -I../newuoa -I../neldermead -I../auglag -I../bobyqa -I../isres -I../slsqp -I../util -I/usr/local/include  -g -O2  -MT deprecated.lo -MD -MP -MF .deps/deprecated.Tpo -c -o deprecated.lo deprecated.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../cdirect -I../direct -I../stogo -I../praxis -I../lbfgs -I../luksan -I../crs -I../mlsl -I../mma -I../cobyla -I../newuoa -I../neldermead -I../auglag -I../bobyqa -I../isres -I../slsqp -I../util -I/usr/local/include -g -O2 -MT deprecated.lo -MD -MP -MF .deps/deprecated.Tpo -c deprecated.c  -fPIC -DPIC -o .libs/deprecated.o
deprecated.c: In function 'nlopt_result nlopt_minimize_constrained(nlopt_algorithm, int, nlopt_func_old, void*, int, nlopt_func_old, void*, ptrdiff_t, const double*, const double*, double*, double*, double, double, double, double, const double*, int, double)':
deprecated.c:149:13: warning: 'nlopt_result nlopt_minimize_econstrained(nlopt_algorithm, int, nlopt_func_old, void*, int, nlopt_func_old, void*, ptrdiff_t, int, nlopt_func_old, void*, ptrdiff_t, const double*, const double*, double*, double*, double, double, double, double, const double*, double, double, int, double)' is deprecated (declared at deprecated.c:65) [-Wdeprecated-declarations]
      return nlopt_minimize_econstrained(
             ^
deprecated.c:153:60: warning: 'nlopt_result nlopt_minimize_econstrained(nlopt_algorithm, int, nlopt_func_old, void*, int, nlopt_func_old, void*, ptrdiff_t, int, nlopt_func_old, void*, ptrdiff_t, const double*, const double*, double*, double*, double, double, double, double, const double*, double, double, int, double)' is deprecated (declared at deprecated.c:65) [-Wdeprecated-declarations]
    xtol_rel, xtol_abs, ftol_rel, ftol_abs, maxeval, maxtime);
                                                            ^
deprecated.c: In function 'nlopt_result nlopt_minimize(nlopt_algorithm, int, nlopt_func_old, void*, const double*, const double*, double*, double*, double, double, double, double, const double*, int, double)':
deprecated.c:167:13: warning: 'nlopt_result nlopt_minimize_constrained(nlopt_algorithm, int, nlopt_func_old, void*, int, nlopt_func_old, void*, ptrdiff_t, const double*, const double*, double*, double*, double, double, double, double, const double*, int, double)' is deprecated (declared at deprecated.c:138) [-Wdeprecated-declarations]
      return nlopt_minimize_constrained(
             ^
deprecated.c:170:40: warning: 'nlopt_result nlopt_minimize_constrained(nlopt_algorithm, int, nlopt_func_old, void*, int, nlopt_func_old, void*, ptrdiff_t, const double*, const double*, double*, double*, double, double, double, double, const double*, int, double)' is deprecated (declared at deprecated.c:138) [-Wdeprecated-declarations]
    xtol_rel, xtol_abs, maxeval, maxtime);
                                        ^
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../cdirect -I../direct -I../stogo -I../praxis -I../lbfgs -I../luksan -I../crs -I../mlsl -I../mma -I../cobyla -I../newuoa -I../neldermead -I../auglag -I../bobyqa -I../isres -I../slsqp -I../util -I/usr/local/include -g -O2 -MT deprecated.lo -MD -MP -MF .deps/deprecated.Tpo -c deprecated.c -o deprecated.o >/dev/null 2>&1
mv -f .deps/deprecated.Tpo .deps/deprecated.Plo
/bin/sh ../libtool --tag=CC   --mode=compile g++ -DHAVE_CONFIG_H -I. -I..  -I../cdirect -I../direct -I../stogo -I../praxis -I../lbfgs -I../luksan -I../crs -I../mlsl -I../mma -I../cobyla -I../newuoa -I../neldermead -I../auglag -I../bobyqa -I../isres -I../slsqp -I../util -I/usr/local/include  -g -O2  -MT f77api.lo -MD -MP -MF .deps/f77api.Tpo -c -o f77api.lo f77api.c
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../cdirect -I../direct -I../stogo -I../praxis -I../lbfgs -I../luksan -I../crs -I../mlsl -I../mma -I../cobyla -I../newuoa -I../neldermead -I../auglag -I../bobyqa -I../isres -I../slsqp -I../util -I/usr/local/include -g -O2 -MT f77api.lo -MD -MP -MF .deps/f77api.Tpo -c f77api.c  -fPIC -DPIC -o .libs/f77api.o
In file included from f77api.c:103:0:
f77funcs.h: In function 'void nloptc_(int*, const int*, const int*, nlopt_f77_func, void*, const int*, nlopt_f77_func, char*, char*, const double*, const double*, double*, double*, const double*, const double*, const double*, const double*, const double*, const int*, const int*, const double*)':
f77funcs.h:57:14: warning: 'nlopt_result nlopt_minimize_constrained(nlopt_algorithm, int, nlopt_func_old, void*, int, nlopt_func_old, void*, ptrdiff_t, const double*, const double*, double*, double*, double, double, double, double, const double*, int, double)' is deprecated (declared at nlopt.h:335) [-Wdeprecated-declarations]
      *info = nlopt_minimize_constrained((nlopt_algorithm) *algorithm, 
              ^
f77funcs.h:65:24: warning: 'nlopt_result nlopt_minimize_constrained(nlopt_algorithm, int, nlopt_func_old, void*, int, nlopt_func_old, void*, ptrdiff_t, const double*, const double*, double*, double*, double, double, double, double, const double*, int, double)' is deprecated (declared at nlopt.h:335) [-Wdeprecated-declarations]
      *maxeval, *maxtime);
                        ^
f77funcs.h: In function 'void nlogls_(int*, int*, int*)':
f77funcs.h:96:6: warning: 'void nlopt_get_local_search_algorithm(nlopt_algorithm*, nlopt_algorithm*, int*)' is deprecated (declared at nlopt.h:359) [-Wdeprecated-declarations]
      nlopt_get_local_search_algorithm(&deriv, &nonderiv, maxeval);
      ^
f77funcs.h:96:65: warning: 'void nlopt_get_local_search_algorithm(nlopt_algorithm*, nlopt_algorithm*, int*)' is deprecated (declared at nlopt.h:359) [-Wdeprecated-declarations]
      nlopt_get_local_search_algorithm(&deriv, &nonderiv, maxeval);
                                                                 ^
f77funcs.h: In function 'void nlosls_(int*, int*, int*)':
f77funcs.h:104:6: warning: 'void nlopt_set_local_search_algorithm(nlopt_algorithm, nlopt_algorithm, int)' is deprecated (declared at nlopt.h:362) [-Wdeprecated-declarations]
      nlopt_set_local_search_algorithm(deriv, nonderiv, *maxeval);
      ^
f77funcs.h:104:64: warning: 'void nlopt_set_local_search_algorithm(nlopt_algorithm, nlopt_algorithm, int)' is deprecated (declared at nlopt.h:362) [-Wdeprecated-declarations]
      nlopt_set_local_search_algorithm(deriv, nonderiv, *maxeval);
                                                                ^
f77funcs.h: In function 'void nlogsp_(int*)':
f77funcs.h:109:13: warning: 'int nlopt_get_stochastic_population()' is deprecated (declared at nlopt.h:366) [-Wdeprecated-declarations]
      *pop = nlopt_get_stochastic_population();
             ^
f77funcs.h:109:45: warning: 'int nlopt_get_stochastic_population()' is deprecated (declared at nlopt.h:366) [-Wdeprecated-declarations]
      *pop = nlopt_get_stochastic_population();
                                             ^
f77funcs.h: In function 'void nlossp_(const int*)':
f77funcs.h:113:6: warning: 'void nlopt_set_stochastic_population(int)' is deprecated (declared at nlopt.h:367) [-Wdeprecated-declarations]
      nlopt_set_stochastic_population(*pop);
      ^
f77funcs.h:113:42: warning: 'void nlopt_set_stochastic_population(int)' is deprecated (declared at nlopt.h:367) [-Wdeprecated-declarations]
      nlopt_set_stochastic_population(*pop);
                                          ^
In file included from f77api.c:114:0:
f77funcs.h: In function 'void nloptc(int*, const int*, const int*, nlopt_f77_func, void*, const int*, nlopt_f77_func, char*, char*, const double*, const double*, double*, double*, const double*, const double*, const double*, const double*, const double*, const int*, const int*, const double*)':
f77funcs.h:57:14: warning: 'nlopt_result nlopt_minimize_constrained(nlopt_algorithm, int, nlopt_func_old, void*, int, nlopt_func_old, void*, ptrdiff_t, const double*, const double*, double*, double*, double, double, double, double, const double*, int, double)' is deprecated (declared at nlopt.h:335) [-Wdeprecated-declarations]
      *info = nlopt_minimize_constrained((nlopt_algorithm) *algorithm, 
              ^
f77funcs.h:65:24: warning: 'nlopt_result nlopt_minimize_constrained(nlopt_algorithm, int, nlopt_func_old, void*, int, nlopt_func_old, void*, ptrdiff_t, const double*, const double*, double*, double*, double, double, double, double, const double*, int, double)' is deprecated (declared at nlopt.h:335) [-Wdeprecated-declarations]
      *maxeval, *maxtime);
                        ^
f77funcs.h: In function 'void nlogls(int*, int*, int*)':
f77funcs.h:96:6: warning: 'void nlopt_get_local_search_algorithm(nlopt_algorithm*, nlopt_algorithm*, int*)' is deprecated (declared at nlopt.h:359) [-Wdeprecated-declarations]
      nlopt_get_local_search_algorithm(&deriv, &nonderiv, maxeval);
      ^
f77funcs.h:96:65: warning: 'void nlopt_get_local_search_algorithm(nlopt_algorithm*, nlopt_algorithm*, int*)' is deprecated (declared at nlopt.h:359) [-Wdeprecated-declarations]
      nlopt_get_local_search_algorithm(&deriv, &nonderiv, maxeval);
                                                                 ^
f77funcs.h: In function 'void nlosls(int*, int*, int*)':
f77funcs.h:104:6: warning: 'void nlopt_set_local_search_algorithm(nlopt_algorithm, nlopt_algorithm, int)' is deprecated (declared at nlopt.h:362) [-Wdeprecated-declarations]
      nlopt_set_local_search_algorithm(deriv, nonderiv, *maxeval);
      ^
f77funcs.h:104:64: warning: 'void nlopt_set_local_search_algorithm(nlopt_algorithm, nlopt_algorithm, int)' is deprecated (declared at nlopt.h:362) [-Wdeprecated-declarations]
      nlopt_set_local_search_algorithm(deriv, nonderiv, *maxeval);
                                                                ^
f77funcs.h: In function 'void nlogsp(int*)':
f77funcs.h:109:13: warning: 'int nlopt_get_stochastic_population()' is deprecated (declared at nlopt.h:366) [-Wdeprecated-declarations]
      *pop = nlopt_get_stochastic_population();
             ^
f77funcs.h:109:45: warning: 'int nlopt_get_stochastic_population()' is deprecated (declared at nlopt.h:366) [-Wdeprecated-declarations]
      *pop = nlopt_get_stochastic_population();
                                             ^
f77funcs.h: In function 'void nlossp(const int*)':
f77funcs.h:113:6: warning: 'void nlopt_set_stochastic_population(int)' is deprecated (declared at nlopt.h:367) [-Wdeprecated-declarations]
      nlopt_set_stochastic_population(*pop);
      ^
f77funcs.h:113:42: warning: 'void nlopt_set_stochastic_population(int)' is deprecated (declared at nlopt.h:367) [-Wdeprecated-declarations]
      nlopt_set_stochastic_population(*pop);
                                          ^
In file included from f77api.c:129:0:
f77funcs.h: In function 'void NLOPTC(int*, const int*, const int*, nlopt_f77_func, void*, const int*, nlopt_f77_func, char*, char*, const double*, const double*, double*, double*, const double*, const double*, const double*, const double*, const double*, const int*, const int*, const double*)':
f77funcs.h:57:14: warning: 'nlopt_result nlopt_minimize_constrained(nlopt_algorithm, int, nlopt_func_old, void*, int, nlopt_func_old, void*, ptrdiff_t, const double*, const double*, double*, double*, double, double, double, double, const double*, int, double)' is deprecated (declared at nlopt.h:335) [-Wdeprecated-declarations]
      *info = nlopt_minimize_constrained((nlopt_algorithm) *algorithm, 
              ^
f77funcs.h:65:24: warning: 'nlopt_result nlopt_minimize_constrained(nlopt_algorithm, int, nlopt_func_old, void*, int, nlopt_func_old, void*, ptrdiff_t, const double*, const double*, double*, double*, double, double, double, double, const double*, int, double)' is deprecated (declared at nlopt.h:335) [-Wdeprecated-declarations]
      *maxeval, *maxtime);
                        ^
f77funcs.h: In function 'void NLOGLS(int*, int*, int*)':
f77funcs.h:96:6: warning: 'void nlopt_get_local_search_algorithm(nlopt_algorithm*, nlopt_algorithm*, int*)' is deprecated (declared at nlopt.h:359) [-Wdeprecated-declarations]
      nlopt_get_local_search_algorithm(&deriv, &nonderiv, maxeval);
      ^
f77funcs.h:96:65: warning: 'void nlopt_get_local_search_algorithm(nlopt_algorithm*, nlopt_algorithm*, int*)' is deprecated (declared at nlopt.h:359) [-Wdeprecated-declarations]
      nlopt_get_local_search_algorithm(&deriv, &nonderiv, maxeval);
                                                                 ^
f77funcs.h: In function 'void NLOSLS(int*, int*, int*)':
f77funcs.h:104:6: warning: 'void nlopt_set_local_search_algorithm(nlopt_algorithm, nlopt_algorithm, int)' is deprecated (declared at nlopt.h:362) [-Wdeprecated-declarations]
      nlopt_set_local_search_algorithm(deriv, nonderiv, *maxeval);
      ^
f77funcs.h:104:64: warning: 'void nlopt_set_local_search_algorithm(nlopt_algorithm, nlopt_algorithm, int)' is deprecated (declared at nlopt.h:362) [-Wdeprecated-declarations]
      nlopt_set_local_search_algorithm(deriv, nonderiv, *maxeval);
                                                                ^
f77funcs.h: In function 'void NLOGSP(int*)':
f77funcs.h:109:13: warning: 'int nlopt_get_stochastic_population()' is deprecated (declared at nlopt.h:366) [-Wdeprecated-declarations]
      *pop = nlopt_get_stochastic_population();
             ^
f77funcs.h:109:45: warning: 'int nlopt_get_stochastic_population()' is deprecated (declared at nlopt.h:366) [-Wdeprecated-declarations]
      *pop = nlopt_get_stochastic_population();
                                             ^
f77funcs.h: In function 'void NLOSSP(const int*)':
f77funcs.h:113:6: warning: 'void nlopt_set_stochastic_population(int)' is deprecated (declared at nlopt.h:367) [-Wdeprecated-declarations]
      nlopt_set_stochastic_population(*pop);
      ^
f77funcs.h:113:42: warning: 'void nlopt_set_stochastic_population(int)' is deprecated (declared at nlopt.h:367) [-Wdeprecated-declarations]
      nlopt_set_stochastic_population(*pop);
                                          ^
libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -I../cdirect -I../direct -I../stogo -I../praxis -I../lbfgs -I../luksan -I../crs -I../mlsl -I../mma -I../cobyla -I../newuoa -I../neldermead -I../auglag -I../bobyqa -I../isres -I../slsqp -I../util -I/usr/local/include -g -O2 -MT f77api.lo -MD -MP -MF .deps/f77api.Tpo -c f77api.c -o f77api.o >/dev/null 2>&1
mv -f .deps/f77api.Tpo .deps/f77api.Plo
/bin/sh ../libtool --tag=CC   --mode=link g++  -g -O2    -o libapi.la  general.lo options.lo optimize.lo deprecated.lo f77api.lo  -lm 
libtool: link: ar cru .libs/libapi.a .libs/general.o .libs/options.o .libs/optimize.o .libs/deprecated.o .libs/f77api.o 
libtool: link: ranlib .libs/libapi.a
libtool: link: ( cd ".libs" && rm -f "libapi.la" && ln -s "../libapi.la" "libapi.la" )
make[4]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/api'
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/api'
Making all in .
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3'
/bin/sh ./libtool --tag=CC   --mode=link g++  -g -O2  -version-info 7:0:7  -o libnlopt_cxx.la -rpath /tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/lib64  direct/libdirect.la cdirect/libcdirect.la stogo/libstogo.la praxis/libpraxis.la  luksan/libluksan.la crs/libcrs.la mlsl/libmlsl.la mma/libmma.la cobyla/libcobyla.la newuoa/libnewuoa.la neldermead/libneldermead.la auglag/libauglag.la bobyqa/libbobyqa.la isres/libisres.la slsqp/libslsqp.la api/libapi.la util/libutil.la -lm 
libtool: link: gcc -std=gnu99 -shared  -fPIC -DPIC  -Wl,--whole-archive direct/.libs/libdirect.a cdirect/.libs/libcdirect.a stogo/.libs/libstogo.a praxis/.libs/libpraxis.a luksan/.libs/libluksan.a crs/.libs/libcrs.a mlsl/.libs/libmlsl.a mma/.libs/libmma.a cobyla/.libs/libcobyla.a newuoa/.libs/libnewuoa.a neldermead/.libs/libneldermead.a auglag/.libs/libauglag.a bobyqa/.libs/libbobyqa.a isres/.libs/libisres.a slsqp/.libs/libslsqp.a api/.libs/libapi.a util/.libs/libutil.a -Wl,--no-whole-archive  -Wl,-rpath -Wl,/usr/local/lib64/../lib64 -Wl,-rpath -Wl,/usr/local/lib64/../lib64 /usr/local/lib64/../lib64/libstdc++.so -lm  -O2   -Wl,-soname -Wl,libnlopt_cxx.so.0 -o .libs/libnlopt_cxx.so.0.7.0
libtool: link: (cd ".libs" && rm -f "libnlopt_cxx.so.0" && ln -s "libnlopt_cxx.so.0.7.0" "libnlopt_cxx.so.0")
libtool: link: (cd ".libs" && rm -f "libnlopt_cxx.so" && ln -s "libnlopt_cxx.so.0.7.0" "libnlopt_cxx.so")
libtool: link: (cd .libs/libnlopt_cxx.lax/libdirect.a && ar x "/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/direct/.libs/libdirect.a")
libtool: link: (cd .libs/libnlopt_cxx.lax/libcdirect.a && ar x "/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/cdirect/.libs/libcdirect.a")
libtool: link: (cd .libs/libnlopt_cxx.lax/libstogo.a && ar x "/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/stogo/.libs/libstogo.a")
libtool: link: (cd .libs/libnlopt_cxx.lax/libpraxis.a && ar x "/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/praxis/.libs/libpraxis.a")
libtool: link: (cd .libs/libnlopt_cxx.lax/libluksan.a && ar x "/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/luksan/.libs/libluksan.a")
libtool: link: (cd .libs/libnlopt_cxx.lax/libcrs.a && ar x "/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/crs/.libs/libcrs.a")
libtool: link: (cd .libs/libnlopt_cxx.lax/libmlsl.a && ar x "/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/mlsl/.libs/libmlsl.a")
libtool: link: (cd .libs/libnlopt_cxx.lax/libmma.a && ar x "/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/mma/.libs/libmma.a")
libtool: link: (cd .libs/libnlopt_cxx.lax/libcobyla.a && ar x "/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/cobyla/.libs/libcobyla.a")
libtool: link: (cd .libs/libnlopt_cxx.lax/libnewuoa.a && ar x "/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/newuoa/.libs/libnewuoa.a")
libtool: link: (cd .libs/libnlopt_cxx.lax/libneldermead.a && ar x "/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/neldermead/.libs/libneldermead.a")
libtool: link: (cd .libs/libnlopt_cxx.lax/libauglag.a && ar x "/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/auglag/.libs/libauglag.a")
libtool: link: (cd .libs/libnlopt_cxx.lax/libbobyqa.a && ar x "/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/bobyqa/.libs/libbobyqa.a")
libtool: link: (cd .libs/libnlopt_cxx.lax/libisres.a && ar x "/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/isres/.libs/libisres.a")
libtool: link: (cd .libs/libnlopt_cxx.lax/libslsqp.a && ar x "/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/slsqp/.libs/libslsqp.a")
libtool: link: (cd .libs/libnlopt_cxx.lax/libapi.a && ar x "/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/api/.libs/libapi.a")
libtool: link: (cd .libs/libnlopt_cxx.lax/libutil.a && ar x "/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/util/.libs/libutil.a")
libtool: link: ar cru .libs/libnlopt_cxx.a   .libs/libnlopt_cxx.lax/libdirect.a/DIRect.o .libs/libnlopt_cxx.lax/libdirect.a/DIRserial.o .libs/libnlopt_cxx.lax/libdirect.a/DIRsubrout.o .libs/libnlopt_cxx.lax/libdirect.a/direct_wrap.o  .libs/libnlopt_cxx.lax/libcdirect.a/cdirect.o .libs/libnlopt_cxx.lax/libcdirect.a/hybrid.o  .libs/libnlopt_cxx.lax/libstogo.a/global.o .libs/libnlopt_cxx.lax/libstogo.a/linalg.o .libs/libnlopt_cxx.lax/libstogo.a/local.o .libs/libnlopt_cxx.lax/libstogo.a/stogo.o .libs/libnlopt_cxx.lax/libstogo.a/tools.o  .libs/libnlopt_cxx.lax/libpraxis.a/praxis.o  .libs/libnlopt_cxx.lax/libluksan.a/mssubs.o .libs/libnlopt_cxx.lax/libluksan.a/plip.o .libs/libnlopt_cxx.lax/libluksan.a/plis.o .libs/libnlopt_cxx.lax/libluksan.a/pnet.o .libs/libnlopt_cxx.lax/libluksan.a/pssubs.o  .libs/libnlopt_cxx.lax/libcrs.a/crs.o  .libs/libnlopt_cxx.lax/libmlsl.a/mlsl.o  .libs/libnlopt_cxx.lax/libmma.a/ccsa_quadratic.o .libs/libnlopt_cxx.lax/libmma.a/mma.o  .libs/libnlopt_cxx.lax/libcobyla.a/cobyla.o  .libs/libnlopt_cxx.lax/libnewuoa.a/newuoa.o  .libs/libnlopt_cxx.lax/libneldermead.a/nldrmd.o .libs/libnlopt_cxx.lax/libneldermead.a/sbplx.o  .libs/libnlopt_cxx.lax/libauglag.a/auglag.o  .libs/libnlopt_cxx.lax/libbobyqa.a/bobyqa.o  .libs/libnlopt_cxx.lax/libisres.a/isres.o  .libs/libnlopt_cxx.lax/libslsqp.a/slsqp.o  .libs/libnlopt_cxx.lax/libapi.a/deprecated.o .libs/libnlopt_cxx.lax/libapi.a/f77api.o .libs/libnlopt_cxx.lax/libapi.a/general.o .libs/libnlopt_cxx.lax/libapi.a/optimize.o .libs/libnlopt_cxx.lax/libapi.a/options.o  .libs/libnlopt_cxx.lax/libutil.a/mt19937ar.o .libs/libnlopt_cxx.lax/libutil.a/qsort_r.o .libs/libnlopt_cxx.lax/libutil.a/redblack.o .libs/libnlopt_cxx.lax/libutil.a/rescale.o .libs/libnlopt_cxx.lax/libutil.a/sobolseq.o .libs/libnlopt_cxx.lax/libutil.a/stop.o .libs/libnlopt_cxx.lax/libutil.a/timer.o 
libtool: link: ranlib .libs/libnlopt_cxx.a
libtool: link: rm -fr .libs/libnlopt_cxx.lax
libtool: link: ( cd ".libs" && rm -f "libnlopt_cxx.la" && ln -s "../libnlopt_cxx.la" "libnlopt_cxx.la" )
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3'
Making all in octave
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/octave'
make  all-am
make[4]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/octave'
g++ -DHAVE_CONFIG_H -I. -I..  -I../api -I../util -I/usr/local/include  -g -O2  -MT dummy.o -MD -MP -MF .deps/dummy.Tpo -c -o dummy.o dummy.c
mv -f .deps/dummy.Tpo .deps/dummy.Po
/bin/sh ../libtool --tag=CC   --mode=link g++  -g -O2    -o dummy dummy.o  -lm 
libtool: link: g++ -g -O2 -o dummy dummy.o  -lm
make[4]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/octave'
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/octave'
Making all in test
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/test'
g++ -DHAVE_CONFIG_H -I. -I..  -I../api -I../util -I/usr/local/include  -g -O2  -MT testfuncs.o -MD -MP -MF .deps/testfuncs.Tpo -c -o testfuncs.o testfuncs.c
mv -f .deps/testfuncs.Tpo .deps/testfuncs.Po
g++ -DHAVE_CONFIG_H -I. -I..  -I../api -I../util -I/usr/local/include  -g -O2  -MT testopt.o -MD -MP -MF .deps/testopt.Tpo -c -o testopt.o testopt.cpp
testopt.cpp: In function ?int test_function(int)?:
testopt.cpp:218:11: warning: ?nlopt_result nlopt_minimize(nlopt_algorithm, int, nlopt_func_old, void*, const double*, const double*, double*, double*, double, double, double, double, const double*, int, double)? is deprecated (declared at ../api/nlopt.h:325) [-Wdeprecated-declarations]
     ret = nlopt_minimize(algorithm,
           ^
testopt.cpp:223:21: warning: ?nlopt_result nlopt_minimize(nlopt_algorithm, int, nlopt_func_old, void*, const double*, const double*, double*, double*, double, double, double, double, const double*, int, double)? is deprecated (declared at ../api/nlopt.h:325) [-Wdeprecated-declarations]
     maxeval, maxtime);
                     ^
mv -f .deps/testopt.Tpo .deps/testopt.Po
/bin/sh ../libtool --tag=CXX   --mode=link g++  -g -O2    -o testopt testfuncs.o testopt.o ../libnlopt_cxx.la -lm 
libtool: link: g++ -g -O2 -o .libs/testopt testfuncs.o testopt.o  ../.libs/libnlopt_cxx.so /usr/local/lib64/../lib64/libstdc++.so -lm -Wl,-rpath -Wl,/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/lib64 -Wl,-rpath -Wl,/usr/local/lib64/../lib64
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/test'
Making all in swig
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/swig'
make  all-am
make[4]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/swig'
make[4]: Nothing to be done for `all-am'.
make[4]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/swig'
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/swig'
make[2]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3'
make[1]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3'
make[1]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3'
Making install in util
make[2]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/util'
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/util'
make[3]: Nothing to be done for `install-exec-am'.
make[3]: Nothing to be done for `install-data-am'.
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/util'
make[2]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/util'
Making install in direct
make[2]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/direct'
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/direct'
make[3]: Nothing to be done for `install-exec-am'.
make[3]: Nothing to be done for `install-data-am'.
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/direct'
make[2]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/direct'
Making install in cdirect
make[2]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/cdirect'
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/cdirect'
make[3]: Nothing to be done for `install-exec-am'.
make[3]: Nothing to be done for `install-data-am'.
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/cdirect'
make[2]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/cdirect'
Making install in stogo
make[2]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/stogo'
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/stogo'
make[3]: Nothing to be done for `install-exec-am'.
make[3]: Nothing to be done for `install-data-am'.
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/stogo'
make[2]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/stogo'
Making install in praxis
make[2]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/praxis'
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/praxis'
make[3]: Nothing to be done for `install-exec-am'.
make[3]: Nothing to be done for `install-data-am'.
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/praxis'
make[2]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/praxis'
Making install in luksan
make[2]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/luksan'
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/luksan'
make[3]: Nothing to be done for `install-exec-am'.
make[3]: Nothing to be done for `install-data-am'.
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/luksan'
make[2]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/luksan'
Making install in crs
make[2]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/crs'
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/crs'
make[3]: Nothing to be done for `install-exec-am'.
make[3]: Nothing to be done for `install-data-am'.
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/crs'
make[2]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/crs'
Making install in mlsl
make[2]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/mlsl'
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/mlsl'
make[3]: Nothing to be done for `install-exec-am'.
make[3]: Nothing to be done for `install-data-am'.
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/mlsl'
make[2]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/mlsl'
Making install in mma
make[2]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/mma'
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/mma'
make[3]: Nothing to be done for `install-exec-am'.
make[3]: Nothing to be done for `install-data-am'.
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/mma'
make[2]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/mma'
Making install in cobyla
make[2]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/cobyla'
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/cobyla'
make[3]: Nothing to be done for `install-exec-am'.
make[3]: Nothing to be done for `install-data-am'.
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/cobyla'
make[2]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/cobyla'
Making install in newuoa
make[2]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/newuoa'
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/newuoa'
make[3]: Nothing to be done for `install-exec-am'.
make[3]: Nothing to be done for `install-data-am'.
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/newuoa'
make[2]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/newuoa'
Making install in lbfgs
make[2]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/lbfgs'
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/lbfgs'
make[3]: Nothing to be done for `install-exec-am'.
make[3]: Nothing to be done for `install-data-am'.
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/lbfgs'
make[2]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/lbfgs'
Making install in neldermead
make[2]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/neldermead'
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/neldermead'
make[3]: Nothing to be done for `install-exec-am'.
make[3]: Nothing to be done for `install-data-am'.
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/neldermead'
make[2]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/neldermead'
Making install in auglag
make[2]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/auglag'
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/auglag'
make[3]: Nothing to be done for `install-exec-am'.
make[3]: Nothing to be done for `install-data-am'.
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/auglag'
make[2]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/auglag'
Making install in bobyqa
make[2]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/bobyqa'
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/bobyqa'
make[3]: Nothing to be done for `install-exec-am'.
make[3]: Nothing to be done for `install-data-am'.
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/bobyqa'
make[2]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/bobyqa'
Making install in isres
make[2]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/isres'
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/isres'
make[3]: Nothing to be done for `install-exec-am'.
make[3]: Nothing to be done for `install-data-am'.
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/isres'
make[2]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/isres'
Making install in slsqp
make[2]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/slsqp'
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/slsqp'
make[3]: Nothing to be done for `install-exec-am'.
make[3]: Nothing to be done for `install-data-am'.
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/slsqp'
make[2]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/slsqp'
Making install in api
make[2]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/api'
make  install-am
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/api'
make[4]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/api'
make[4]: Nothing to be done for `install-exec-am'.
 /usr/bin/mkdir -p '/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/include'
 /usr/bin/install -c -m 644 nlopt.h nlopt.f nlopt.hpp '/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/include'
 /usr/bin/mkdir -p '/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/share/man/man3'
 /usr/bin/install -c -m 644 nlopt.3 '/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/share/man/man3'
make[4]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/api'
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/api'
make[2]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/api'
Making install in .
make[2]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3'
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3'
 /usr/bin/mkdir -p '/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/lib64'
 /bin/sh ./libtool   --mode=install /usr/bin/install -c   libnlopt_cxx.la '/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/lib64'
libtool: install: /usr/bin/install -c .libs/libnlopt_cxx.so.0.7.0 /tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/lib64/libnlopt_cxx.so.0.7.0
libtool: install: (cd /tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/lib64 && { ln -s -f libnlopt_cxx.so.0.7.0 libnlopt_cxx.so.0 || { rm -f libnlopt_cxx.so.0 && ln -s libnlopt_cxx.so.0.7.0 libnlopt_cxx.so.0; }; })
libtool: install: (cd /tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/lib64 && { ln -s -f libnlopt_cxx.so.0.7.0 libnlopt_cxx.so || { rm -f libnlopt_cxx.so && ln -s libnlopt_cxx.so.0.7.0 libnlopt_cxx.so; }; })
libtool: install: /usr/bin/install -c .libs/libnlopt_cxx.lai /tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/lib64/libnlopt_cxx.la
libtool: install: /usr/bin/install -c .libs/libnlopt_cxx.a /tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/lib64/libnlopt_cxx.a
libtool: install: chmod 644 /tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/lib64/libnlopt_cxx.a
libtool: install: ranlib /tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/lib64/libnlopt_cxx.a
libtool: finish: PATH="/sbin:/usr/sbin:/usr/local/sbin:/root/bin:/usr/local/bin:/usr/bin:/bin:/usr/bin/X11:/usr/X11R6/bin:/usr/games:/sbin" ldconfig -n /tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/lib64
----------------------------------------------------------------------
Libraries have been installed in:
   /tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/lib64

If you ever happen to want to link against installed libraries
in a given directory, LIBDIR, you must either use libtool, and
specify the full pathname of the library, or use the `-LLIBDIR'
flag during linking and do at least one of the following:
   - add LIBDIR to the `LD_LIBRARY_PATH' environment variable
     during execution
   - add LIBDIR to the `LD_RUN_PATH' environment variable
     during linking
   - use the `-Wl,-rpath -Wl,LIBDIR' linker flag
   - have your system administrator add LIBDIR to `/etc/ld.so.conf'

See any operating system documentation about shared libraries for
more information, such as the ld(1) and ld.so(8) manual pages.
----------------------------------------------------------------------
 /usr/bin/mkdir -p '/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/lib64/pkgconfig'
 /usr/bin/install -c -m 644 nlopt.pc '/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/lib64/pkgconfig'
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3'
make[2]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3'
Making install in octave
make[2]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/octave'
make  install-am
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/octave'
make[4]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/octave'
make[4]: Nothing to be done for `install-exec-am'.
make[4]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/octave'
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/octave'
make[2]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/octave'
Making install in test
make[2]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/test'
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/test'
make[3]: Nothing to be done for `install-exec-am'.
make[3]: Nothing to be done for `install-data-am'.
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/test'
make[2]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/test'
Making install in swig
make[2]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/swig'
make  install-am
make[3]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/swig'
make[4]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/swig'
make[4]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/swig'
make[3]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/swig'
make[2]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3/swig'
make[1]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3'
gcc -std=gnu99 -I/usr/local/lib64/R/include -DNDEBUG  -I/usr/local/include    -I./nlopt-2.3/include -fpic  -g -O2  -c nloptr.c -o nloptr.o
echo "Installing library to: `pwd`/nlopt-2.3"
Installing library to: /tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3
cd nlopt-2.3; \
./configure --prefix="`pwd`" --enable-shared --enable-static --without-octave --without-matlab --without-guile --without-python --with-cxx CC="gcc -std=gnu99" CFLAGS="-g -O2 " CPP="`"/usr/local/lib64/R/bin/R" CMD config CPP`" CPPFLAGS="-I/usr/local/include" CXX="g++" CXXFLAGS="-g -O2 " CXXCPP="g++ -E"; \
make; \
make install; \
ls | grep -v ^include$ | grep -v ^lib$ | xargs rm -rf; \
    rm -rf .libs;
/bin/sh: line 1: ./configure: No such file or directory
make[1]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3'
make[1]: *** No targets specified and no makefile found.  Stop.
make[1]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3'
make[1]: Entering directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3'
make[1]: *** No rule to make target `install'.  Stop.
make[1]: Leaving directory `/tmp/RtmpP3IzvG/R.INSTALL47bf4b181dcf/nloptr/src/nlopt-2.3'
gcc -std=gnu99 -shared -L/usr/local/lib64 -o nloptr.so nloptr.o -lm nlopt-2.3/lib/libnlopt_cxx.a -lstdc++ -L/usr/local/lib64/R/lib -lR
gcc: error: nlopt-2.3/lib/libnlopt_cxx.a: No such file or directory
make: *** [nloptr.so] Error 1
ERROR: compilation failed for package ?nloptr?
* removing ?/usr/local/lib64/R/library/nloptr?

The downloaded source packages are in
	?/tmp/RtmpHQHp8I/downloaded_packages?
Updating HTML index of packages in '.Library'
Making 'packages.html' ... done
Warning message:
In install.packages("nloptr") :
  installation of package ?nloptr? had non-zero exit status

From jdnewmil at dcn.davis.CA.us  Sun Jun 16 13:51:24 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 16 Jun 2013 04:51:24 -0700
Subject: [R] R for Chrome OS
In-Reply-To: <CAHvNr3rbPtmen_CUXFjaKXJ-mvs02oJyqnH6ACNLaG8njpOQiw@mail.gmail.com>
References: <CAHvNr3rbPtmen_CUXFjaKXJ-mvs02oJyqnH6ACNLaG8njpOQiw@mail.gmail.com>
Message-ID: <59e76765-43f4-48aa-8c33-45681850809a@email.android.com>

You should probably try to study a bit more about what ChromeOS is about before asking questions like that. The real question you should have asked is whether R is offered as SAAS in the cloud. (I don't think so.) You can setup an instance of Linux in the cloud and run R there. RStudio Server may also be helpful. If you don't like paying for your use of R by the minute, then you may want to purchase your own server or reconsider using ChromeOS at all.

Also, please post here in plain text rather than using HTML email as the Posting Guide requests.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Kevin Chavers <kevinchavers at gmail.com> wrote:

>Hello,
>
>I have heard that Chrome OS is Linux based, so I am wondering if there
>is
>anyway to use R on a Google Chromebook using one of your Linux
>packages. If
>not, do you plan on making a version of R that is compatible with
>chromebooks or cloud based?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From nalimilan at club.fr  Sun Jun 16 13:59:13 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Sun, 16 Jun 2013 13:59:13 +0200
Subject: [R] Problems using log() in a plm() regression.
In-Reply-To: <000001ce6a5f$e5b47790$b11d66b0$@fr>
References: <000001ce6a5f$e5b47790$b11d66b0$@fr>
Message-ID: <1371383953.12472.126.camel@milan>

Le dimanche 16 juin 2013 ? 09:05 +0200, Guylaine NOUWOUE a ?crit :
> Hello,
> 
> I am performing a panel model and I have an error. In fact, I would like to
> set up the pooling model and I have an error message. Any help
> 
> >pool<plm(panel$lexportijt~ldistit+lpopit+lpopjt+lpibit+lpibjt+lpibcit+lpibc
> jt+langueij+histoireij+infrasij+frontiereij+simijt+enclaviit,data=panel,inde
> x=c("origine","annee"))
> 
> Erreur dans parse(text = x) : 
> 
>   fin d'entre inattendu(e) dans "panel$lexportijt ~ ldistit + lpopit +
> lpopjt + lpibit + lpibjt +     lpibcit + lpibcjt + langueij + histoireij +
> infrasij + frontiereij +     simijt + enclaviit +  + "
This is not a problem with log() at all... this is a mere syntax error.

First, there is no need to repeat "panel$" since you specify a data
argument. Second, I think you should add more spacing and line breaks to
your code to make it readable.

Finally, the real bug is that you typed "<" instead of "<-". I think you
should read an introduction to the R language.

This should do what you want :

pool <- plm(lexportijt ~ ldistit + lpopit + lpopjt + lpibit + lpibjt + lpibcit
                       + lpibcjt + langueij + histoireij + infrasij + frontiereij
                       + simijt + enclaviit,
            data=panel, index=c("origine", "annee"))


Regards


From michael.weylandt at gmail.com  Sun Jun 16 14:17:36 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Sun, 16 Jun 2013 13:17:36 +0100
Subject: [R] rename and concatenate name of columns
In-Reply-To: <029620D3-114F-4A66-9644-BCF62C9F1AD7@comcast.net>
References: <CAKy1A=E7HUHjTiefN=bwP-ncvxgM_iUs=mtLvazWDTj3Ttx0QQ@mail.gmail.com>
	<BDF430E1-94E1-4D2E-A2EA-3D96AB8C4AF1@comcast.net>
	<CACk-te3Kv2nH5Y7Kk3hUwy350cHk_L-i8FESN05ipe+QHJt6uQ@mail.gmail.com>
	<029620D3-114F-4A66-9644-BCF62C9F1AD7@comcast.net>
Message-ID: <CAAmySGPJRWRgjGsO-Qf__L5fHoBXtuuZCBOMoMHM+GLjwLS8eA@mail.gmail.com>

On Sat, Jun 15, 2013 at 1:45 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Jun 14, 2013, at 1:25 PM, Bert Gunter wrote:
>
>> For the record:
>>
>> ...
>>
>> ------------
>>>
>>> A bit of commentary: Something did happen. It's just that you didn't do anything with _what_ happened. The copy of the 'dataset'-object got modified but you never returned it from the function, and and also didn't reassign it to the original 'dataset'. Functions return their last assignment.
>
> This line was probably more worthy of criticism. Functions return the result of last evaluated expression. (Which is often not what the beginning R programmer expected.)
>
>>> In the case of the 'for'-function, it somewhat surprisingly returns a NULL. It is a rather odd function in the functional R world, since its main role in life is doing things by side-effects,
>> ---------
>>
>> for() is **not** a function.
>>
>> ?"for" describes it as a "basic control-flow [sic] construct."

Which is implemented as a function in C, as can be seen by examining
the table in names.c. It fails, however, to be a closure as are most
things which are defined with the "function" keyword in R.

That is, admittedly, only an implementation detail and cannot be found
(on brief examination) in the language definition.

>
> Nonetheless it does return NULL.
>>
>> Ergo, it's behavior is not odd.
>
> That remains a matter of opinion.

Note that the "foreach" developers do take advantage of foreach()
returning a value, so there's at least some reason to expect "for"
could return a value. I could also see a case being made for
consistency with if/else.

MW


From ligges at statistik.tu-dortmund.de  Sun Jun 16 15:14:49 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 16 Jun 2013 15:14:49 +0200
Subject: [R] Matrix Mulitplication: A*B*C*D...?
In-Reply-To: <1371350130.67939.YahooMailNeo@web122202.mail.ne1.yahoo.com>
References: <1371350130.67939.YahooMailNeo@web122202.mail.ne1.yahoo.com>
Message-ID: <51BDBA49.2000701@statistik.tu-dortmund.de>



On 16.06.2013 04:35, G Vishwanath wrote:
> Is there a R package or function that will multiple an arbitrary number of matrices supplied to it, preferably optimizing the sequence
>
> R_function(matA, matB, matC,  matD,....)
>     return matA %*%  matB %*%  matC %matD %....
>
> and optimizing wether it is better to do A(BC) or (AB)C ?


For part 1) or your question:

Reduce("%*%", list(matA, matB, matC, matD, ...)

for part 2): No idea.

Best,
Uwe Ligges



>
> Thanks,
> Shiv
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dmck at u.washington.edu  Sun Jun 16 16:05:47 2013
From: dmck at u.washington.edu (Don McKenzie)
Date: Sun, 16 Jun 2013 07:05:47 -0700
Subject: [R] Simulating from a special type of bivariate exponential
	distribution
In-Reply-To: <CAGMzmw22LeA+OX7i_crvV73Q495n8FcEYP2-6E3AB5VZtXagrQ@mail.gmail.com>
References: <CAGMzmw22LeA+OX7i_crvV73Q495n8FcEYP2-6E3AB5VZtXagrQ@mail.gmail.com>
Message-ID: <365D1682-F0B9-41A9-B085-CAC86EE9DA01@u.washington.edu>

This looks like a homework problem, and has no R question in it.

If it is homework, ask your professor or fellow students for help.  

If not, and you have a question about R, please post that.

On Jun 15, 2013, at 8:17 PM, INDRANIL GHOSH <jamesbond.indranil at gmail.com> wrote:

> Hi,
> I have the following problem in simulating samples from a bivariate
> exponential distribution with the following construction:
> 
> Start with three independent exponential random variables say W1,W2 and W3
> with intensity parameters lambda 1, lambda 2 and lambda 3 respectively.
> 
> Now I construct a bivariate distribution (X,Y) such that
> 
> (X,Y) is distributed as (W1,W2  given that W0<min(W1,W2)).
> 
> The resulting distribution has the form
> 
> f(x,y)=((lambda 1+lambda 2+lambda 3)/lambda 3)*exp(-lambda 1*x-lambda 2*y)
> *(1-exp(lambda 3*min(x,y)), with the joint support x>0, y>0.
> 
> Any suggestion is appreciated.
> 
> Thanks,
> 
> 
> -- 
> Indranil
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Don McKenzie, Research Ecologist
Pacific WIldland Fire Sciences Lab
US Forest Service

Affiliate Professor
School of Forest Resources, College of the Environment
CSES Climate Impacts Group
University of Washington

phone: 206-732-7824
dmck at uw.edu


From Roger.bivand at nhh.no  Sun Jun 16 14:24:44 2013
From: Roger.bivand at nhh.no (Roger Bivand)
Date: Sun, 16 Jun 2013 12:24:44 +0000
Subject: [R] Reading shape files in R
References: <1371283003.98555.YahooMailNeo@web172103.mail.ir2.yahoo.com>
Message-ID: <loom.20130616T141637-321@post.gmane.org>

jickngea alexand <jickneba <at> yahoo.ie> writes:

> 
> Hi everyone,
> ?????????????????????? I am new with spatial data analysis in R and I'm
not able
> to read a shape because of this error message but the shapefile is in my
work directory.? Here are my
> commands; ogrLireadstLayers("border.shp"),
border=OGR("border.shp","border"). What does it
> mean?. Any help?

Yes, read the help files for the function you are using, and try out the
examples using shapefiles provided with the package. If still in doubt, look
at the OGR formats page to see how OGR reads shapefiles:

http://www.gdal.org/ogr/drv_shapefile.html

where you also need dsn and layer arguments. Almost certainly:

ogrListLayers(".")

will list the shapefile layers in your working directory, and 

border=OGR(".", "border")

will read the file if it is complete. Always also include the output of
sessionInfo() in questions, as the answer may depend on the version(s) of
package(s) - here rgdal, but not mentioned by you. Even better, give a
worked example of your problem - in constructing the question, you would
certainly have answered it yourself.

Other questions on spatial and spatio-temporal matters may be answered
faster on R-sig-geo.

> Error in file(paste(dsn, .Platform$file.sep, layer, ".dbf", sep = ""),  :
 cannot open the connection In
> addition: Warning message: In file(paste(dsn, .Platform$file.sep, layer,
".dbf", sep = ""),  : cannot
> open file 'border.shp/border.dbf': No such file or directory
> 
> Alexand
> Msc.agriScs
> 
> 	[[alternative HTML version deleted]]
> 

Only post plain text!

Roger

> 
>


From dwinsemius at comcast.net  Sun Jun 16 16:59:59 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 16 Jun 2013 07:59:59 -0700
Subject: [R] can't install rugarch and nloptr packages in R 3.01
	opensuse linux
In-Reply-To: <20130616064220.30872@web007.roc2.bluetie.com>
References: <20130616064220.30872@web007.roc2.bluetie.com>
Message-ID: <66466FBB-99BB-4256-9A69-D770A66B6D06@comcast.net>


On Jun 16, 2013, at 3:42 AM, ce wrote:

> I can't install rugarch package because installation of nloptr package fails .
> 
> I use opensuse 12.3 
> # uname -a
> Linux candide 3.7.10-1.11-desktop #1 SMP PREEMPT Thu May 16 20:27:27 UTC 2013 (adf31bb) x86_64 x86_64 x86_64 GNU/Linux
> my gcc version is 4.8.1
> 
> I compiled and installed R 3.01 . then I tried to install rugarch package but it fails because it can't install depended package nloptr.  I try to install nloptr individually with install.packages("nloptr"), i get a lot of deprecated messages and it fails. I attach log file . when I try to compile nlopt software it also gives similar messages. 

The first (and only) error says:

gcc -std=gnu99 -shared -L/usr/local/lib64 -o nloptr.so nloptr.o -lm nlopt-2.3/lib/libnlopt_cxx.a -lstdc++ -L/usr/local/lib64/R/lib -lR
gcc: error: nlopt-2.3/lib/libnlopt_cxx.a: No such file or directory
make: *** [nloptr.so] Error 1
ERROR: compilation failed for package ?nloptr?
* removing ?/usr/local/lib64/R/library/nloptr?

It's unclear how that could be "similar" to messages when attempting to install NLopt.

There are a variety of build requirements for NLopt listed at the opens use repository:

https://build.opensuse.org/package/view_file?file=nlopt.spec&package=nlopt&project=science&rev=284a615adbf4dd3fd550237da1a4e89b

BuildRequires:  gcc-c++
BuildRequires:  hdf5-devel
BuildRequires:  octave-devel
BuildRequires:  pkgconfig
BuildRequires:  python-numpy-devel

You nave not mentioned any of those (non-R)  packages. It would seem that you should be seeking assistance in installing NLopt and that your provided material is not particularly on point of that issue. I suspect there is a mailing list for opensuse.


-- 
David.

> Following fails too:
> 
> R version 3.0.1 (2013-05-16) -- "Good Sport"
> Copyright (C) 2013 The R Foundation for Statistical Computing
> Platform: x86_64-unknown-linux-gnu (64-bit)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
> 
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
> 
>> install.packages("nloptr",repos="http://R-Forge.R-project.org")
> Warning message:
> package ?nloptr? is not available (for R version 3.0.1) 
> <nloptr.txt>______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jr297 at exeter.ac.uk  Sun Jun 16 16:39:40 2013
From: jr297 at exeter.ac.uk (Rapkin, James)
Date: Sun, 16 Jun 2013 14:39:40 +0000
Subject: [R] trying to fit a thin plate spline to a triangular plot
Message-ID: <2F26AF2C2FA31A43AEEDD56E1492C19D19240920@VMEXCHANGEMBS3A.isad.isadroot.ex.ac.uk>

Hi

Has anyone tried to fit a thin plate spine to a triangular plot before? I'm having trouble working out a piece of code to make it possible with three axes. I have done it before with two axes. 

I've found a package I prefer that makes triangular plots (plotrix) using the triax.plot() function. An example of some data and the plot follows:

graph.data<-data.frame(a=c(9,6.2, 5.9,8.1,8.9,56.9,50,39.5,62.1,49.9,4.2,3,6,4.1),
                       b=c(1.8,1.2,1.2,1.6,1.8,11.4,10,7.9,12.4,10,4.2,3,6,4.1),
                       c=c(1.8,1.2,1.2,1.6,1.8,11.4,10,7.9,12.4,10,4.2,3,6,4.1),
                       d=c(10,15,16,14,13,18,19,17,20,19,21,22,22,23))

triax.plot(graph.data, main="Title", no.add=F, show.grid=T,tick.labels=list(l=seq(10,90,by=10),r=seq(10,90,by=10),b=seq(10,90,by=10)),
           pch=1,cc.axes=TRUE)
                     
I want to fit the 'd' data as a spline to the plot. 

Any help is greatly appreciated. 

Thank you
James


PhD Researcher
University of Exeter - Cornwall Campus
College of Life and Enivironmental Science
Centre for Ecology and Conservation


From dwinsemius at comcast.net  Sun Jun 16 18:53:41 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 16 Jun 2013 09:53:41 -0700
Subject: [R] trying to fit a thin plate spline to a triangular plot
In-Reply-To: <2F26AF2C2FA31A43AEEDD56E1492C19D19240920@VMEXCHANGEMBS3A.isad.isadroot.ex.ac.uk>
References: <2F26AF2C2FA31A43AEEDD56E1492C19D19240920@VMEXCHANGEMBS3A.isad.isadroot.ex.ac.uk>
Message-ID: <C9D4CB93-8403-4A81-AC88-C3EEF8D0946C@comcast.net>


On Jun 16, 2013, at 7:39 AM, Rapkin, James wrote:

> Hi
> 
> Has anyone tried to fit a thin plate spine to a triangular plot before? I'm having trouble working out a piece of code to make it possible with three axes.

Only two axes in a triangular plot are independent.

> I have done it before with two axes. 
> 
> I've found a package I prefer that makes triangular plots (plotrix) using the triax.plot() function. An example of some data and the plot follows:
> 
> graph.data<-data.frame(a=c(9,6.2, 5.9,8.1,8.9,56.9,50,39.5,62.1,49.9,4.2,3,6,4.1),
>                       b=c(1.8,1.2,1.2,1.6,1.8,11.4,10,7.9,12.4,10,4.2,3,6,4.1),
>                       c=c(1.8,1.2,1.2,1.6,1.8,11.4,10,7.9,12.4,10,4.2,3,6,4.1),
>                       d=c(10,15,16,14,13,18,19,17,20,19,21,22,22,23))
> 
> triax.plot(graph.data, main="Title", no.add=F, show.grid=T,tick.labels=list(l=seq(10,90,by=10),r=seq(10,90,by=10),b=seq(10,90,by=10)),
>           pch=1,cc.axes=TRUE)
> 
> I want to fit the 'd' data as a spline to the plot. 

Looking at the data I am unable to imagine how that could meaningfully support a 2d spline fit.

> 
> Any help is greatly appreciated. 

This was cross-posted to StackOverflow and R-help. SO does not have a policy against cross-posting, but Rhelp does.

-- 
David Winsemius
Alameda, CA, USA


From zadig_1 at excite.com  Sun Jun 16 20:46:06 2013
From: zadig_1 at excite.com (ce)
Date: Sun, 16 Jun 2013 14:46:06 -0400
Subject: [R] can't install rugarch and nloptr packages in R 3.01
	opensuse linux
Message-ID: <20130616144606.1492@web002.roc2.bluetie.com>

Thanks for the answer.
All packages in build-requires are installed. Anyway neither configure nor make complains . After make install I get :

# find /usr -name "*nlopt*"
/usr/local/share/man/man3/nlopt.3
/usr/local/include/nlopt.f
/usr/local/include/nlopt.hpp
/usr/local/include/nlopt.h
/usr/local/lib64/libnlopt.la
/usr/local/lib64/libnlopt.a
/usr/local/lib64/pkgconfig/nlopt.pc

I attach log file of nlopt installation too.  (nlopt_opensuse.txt) 


-----Original Message-----
From: "David Winsemius" [dwinsemius at comcast.net]
Date: 06/16/2013 11:00 AM
To: "ce" <zadig_1 at excite.com>
CC: "" <r-help at r-project.org>
Subject: Re: [R] can't install rugarch and nloptr packages in R 3.01 opensuse linux


On Jun 16, 2013, at 3:42 AM, ce wrote:

> I can't install rugarch package because installation of nloptr package fails .
> 
> I use opensuse 12.3 
> # uname -a
> Linux candide 3.7.10-1.11-desktop #1 SMP PREEMPT Thu May 16 20:27:27 UTC 2013 (adf31bb) x86_64 x86_64 x86_64 GNU/Linux
> my gcc version is 4.8.1
> 
> I compiled and installed R 3.01 . then I tried to install rugarch package but it fails because it can't install depended package nloptr.  I try to install nloptr individually with install.packages("nloptr"), i get a lot of deprecated messages and it fails. I attach log file . when I try to compile nlopt software it also gives similar messages. 

The first (and only) error says:

gcc -std=gnu99 -shared -L/usr/local/lib64 -o nloptr.so nloptr.o -lm nlopt-2.3/lib/libnlopt_cxx.a -lstdc++ -L/usr/local/lib64/R/lib -lR
gcc: error: nlopt-2.3/lib/libnlopt_cxx.a: No such file or directory
make: *** [nloptr.so] Error 1
ERROR: compilation failed for package ?nloptr?
* removing ?/usr/local/lib64/R/library/nloptr?

It's unclear how that could be "similar" to messages when attempting to install NLopt.

There are a variety of build requirements for NLopt listed at the opens use repository:

https://build.opensuse.org/package/view_file?file=nlopt.spec&package=nlopt&project=science&rev=284a615adbf4dd3fd550237da1a4e89b

BuildRequires:  gcc-c++
BuildRequires:  hdf5-devel
BuildRequires:  octave-devel
BuildRequires:  pkgconfig
BuildRequires:  python-numpy-devel

You nave not mentioned any of those (non-R)  packages. It would seem that you should be seeking assistance in installing NLopt and that your provided material is not particularly on point of that issue. I suspect there is a mailing list for opensuse.


-- 
David.

> Following fails too:
> 
> R version 3.0.1 (2013-05-16) -- "Good Sport"
> Copyright (C) 2013 The R Foundation for Statistical Computing
> Platform: x86_64-unknown-linux-gnu (64-bit)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
> 
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
> 
>> install.packages("nloptr",repos="http://R-Forge.R-project.org")
> Warning message:
> package ?nloptr? is not available (for R version 3.0.1) 
> <nloptr.txt>______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


-------------- next part --------------
configure: loading site script /usr/share/site/x86_64-unknown-linux-gnu
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... yes
checking for a thread-safe mkdir -p... /usr/bin/mkdir -p
checking for gawk... gawk
checking whether make sets $(MAKE)... yes
checking whether to enable maintainer-specific portions of Makefiles... no
checking for gcc... gcc
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables... 
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ISO C89... none needed
checking for style of include used by make... GNU
checking dependency style of gcc... gcc3
checking for gcc option to accept ISO C99... -std=gnu99
checking for gcc -std=gnu99 option to accept ISO Standard C... (cached) -std=gnu99
checking whether ln -s works... yes
checking whether make sets $(MAKE)... (cached) yes
checking build system type... x86_64-unknown-linux-gnu
checking host system type... x86_64-unknown-linux-gnu
checking how to print strings... printf
checking for a sed that does not truncate output... /usr/bin/sed
checking for grep that handles long lines and -e... /usr/bin/grep
checking for egrep... /usr/bin/grep -E
checking for fgrep... /usr/bin/grep -F
checking for ld used by gcc -std=gnu99... /usr/bin/ld
checking if the linker (/usr/bin/ld) is GNU ld... yes
checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B
checking the name lister (/usr/bin/nm -B) interface... BSD nm
checking the maximum length of command line arguments... 1572864
checking whether the shell understands some XSI constructs... yes
checking whether the shell understands "+="... yes
checking how to convert x86_64-unknown-linux-gnu file names to x86_64-unknown-linux-gnu format... func_convert_file_noop
checking how to convert x86_64-unknown-linux-gnu file names to toolchain format... func_convert_file_noop
checking for /usr/bin/ld option to reload object files... -r
checking for objdump... objdump
checking how to recognize dependent libraries... pass_all
checking for dlltool... dlltool
checking how to associate runtime and link libraries... printf %s\n
checking for ar... ar
checking for archiver @FILE support... @
checking for strip... strip
checking for ranlib... ranlib
checking command to parse /usr/bin/nm -B output from gcc -std=gnu99 object... ok
checking for sysroot... no
checking for mt... mt
checking if mt is a manifest tool... no
checking how to run the C preprocessor... gcc -std=gnu99 -E
checking for ANSI C header files... yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking for dlfcn.h... yes
checking for objdir... .libs
checking if gcc -std=gnu99 supports -fno-rtti -fno-exceptions... no
checking for gcc -std=gnu99 option to produce PIC... -fPIC -DPIC
checking if gcc -std=gnu99 PIC flag -fPIC -DPIC works... yes
checking if gcc -std=gnu99 static flag -static works... no
checking if gcc -std=gnu99 supports -c -o file.o... yes
checking if gcc -std=gnu99 supports -c -o file.o... (cached) yes
checking whether the gcc -std=gnu99 linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
checking dynamic linker characteristics... GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking whether stripping libraries is possible... yes
checking if libtool supports shared libraries... yes
checking whether to build shared libraries... no
checking whether to build static libraries... yes
checking for g++... g++
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
checking dependency style of g++... gcc3
checking how to run the C++ preprocessor... g++ -E
checking for ld used by g++... /usr/bin/ld -m elf_x86_64
checking if the linker (/usr/bin/ld -m elf_x86_64) is GNU ld... yes
checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
checking for g++ option to produce PIC... -fPIC -DPIC
checking if g++ PIC flag -fPIC -DPIC works... yes
checking if g++ static flag -static works... no
checking if g++ supports -c -o file.o... yes
checking if g++ supports -c -o file.o... (cached) yes
checking whether the g++ linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
checking dynamic linker characteristics... (cached) GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking for ANSI C header files... (cached) yes
checking whether time.h and sys/time.h may both be included... yes
checking for unistd.h... (cached) yes
checking getopt.h usability... yes
checking getopt.h presence... yes
checking for getopt.h... yes
checking for stdint.h... (cached) yes
checking for an ANSI C-conforming const... yes
checking for inline... inline
checking for C thread-local keyword... __thread
checking size of unsigned int... 4
checking size of unsigned long... 8
checking for uint32_t... yes
checking for sin in -lm... yes
checking for BSDgettimeofday... no
checking for gettimeofday... yes
checking for time... yes
checking for qsort_r... yes
checking for getpid... yes
checking for gettid syscall... yes
checking for isnan... yes
checking for isinf... yes
checking for copysign... yes
configure: WARNING: Python and Guile wrappers require --enable-shared; disabling
checking for mkoctfile... mkoctfile
checking for octave... octave
checking for octave-config... octave-config
checking where octave plugins go... /usr/lib64/octave/3.6.2/site/oct/x86_64-suse-linux-gnu
checking where octave scripts go... /usr/share/octave/3.6.2/site/m
configure: WARNING: mkoctfile requires --enable-shared; won't compile Octave plugin
checking for mex... no
configure: WARNING: can't find mex: won't be able to compile Matlab plugin
checking for working HUGE_VAL... ok
checking that generated files are newer than configure... done
configure: creating ./config.status
config.status: creating Makefile
config.status: creating nlopt.pc
config.status: creating api/Makefile
config.status: creating util/Makefile
config.status: creating octave/Makefile
config.status: creating direct/Makefile
config.status: creating cdirect/Makefile
config.status: creating stogo/Makefile
config.status: creating praxis/Makefile
config.status: creating lbfgs/Makefile
config.status: creating luksan/Makefile
config.status: creating crs/Makefile
config.status: creating mlsl/Makefile
config.status: creating mma/Makefile
config.status: creating cobyla/Makefile
config.status: creating newuoa/Makefile
config.status: creating neldermead/Makefile
config.status: creating auglag/Makefile
config.status: creating bobyqa/Makefile
config.status: creating isres/Makefile
config.status: creating slsqp/Makefile
config.status: creating test/Makefile
config.status: creating swig/Makefile
config.status: creating swig/nlopt.scm
config.status: creating config.h
config.status: config.h is unchanged
config.status: executing depfiles commands
config.status: executing libtool commands
[1m[31mcandide:/home/root/nlopt-2.3 # (B[mmake
make  all-recursive
make[1]: Entering directory `/home/root/nlopt-2.3'
Making all in util
make[2]: Entering directory `/home/root/nlopt-2.3/util'
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../api   -g -O2 -MT mt19937ar.lo -MD -MP -MF .deps/mt19937ar.Tpo -c -o mt19937ar.lo mt19937ar.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../api -g -O2 -MT mt19937ar.lo -MD -MP -MF .deps/mt19937ar.Tpo -c mt19937ar.c -o mt19937ar.o
mv -f .deps/mt19937ar.Tpo .deps/mt19937ar.Plo
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../api   -g -O2 -MT sobolseq.lo -MD -MP -MF .deps/sobolseq.Tpo -c -o sobolseq.lo sobolseq.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../api -g -O2 -MT sobolseq.lo -MD -MP -MF .deps/sobolseq.Tpo -c sobolseq.c -o sobolseq.o
mv -f .deps/sobolseq.Tpo .deps/sobolseq.Plo
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../api   -g -O2 -MT timer.lo -MD -MP -MF .deps/timer.Tpo -c -o timer.lo timer.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../api -g -O2 -MT timer.lo -MD -MP -MF .deps/timer.Tpo -c timer.c -o timer.o
mv -f .deps/timer.Tpo .deps/timer.Plo
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../api   -g -O2 -MT stop.lo -MD -MP -MF .deps/stop.Tpo -c -o stop.lo stop.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../api -g -O2 -MT stop.lo -MD -MP -MF .deps/stop.Tpo -c stop.c -o stop.o
mv -f .deps/stop.Tpo .deps/stop.Plo
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../api   -g -O2 -MT redblack.lo -MD -MP -MF .deps/redblack.Tpo -c -o redblack.lo redblack.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../api -g -O2 -MT redblack.lo -MD -MP -MF .deps/redblack.Tpo -c redblack.c -o redblack.o
mv -f .deps/redblack.Tpo .deps/redblack.Plo
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../api   -g -O2 -MT qsort_r.lo -MD -MP -MF .deps/qsort_r.Tpo -c -o qsort_r.lo qsort_r.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../api -g -O2 -MT qsort_r.lo -MD -MP -MF .deps/qsort_r.Tpo -c qsort_r.c -o qsort_r.o
mv -f .deps/qsort_r.Tpo .deps/qsort_r.Plo
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../api   -g -O2 -MT rescale.lo -MD -MP -MF .deps/rescale.Tpo -c -o rescale.lo rescale.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../api -g -O2 -MT rescale.lo -MD -MP -MF .deps/rescale.Tpo -c rescale.c -o rescale.o
mv -f .deps/rescale.Tpo .deps/rescale.Plo
/bin/sh ../libtool --tag=CC   --mode=link gcc -std=gnu99  -g -O2   -o libutil.la  mt19937ar.lo sobolseq.lo timer.lo stop.lo redblack.lo qsort_r.lo rescale.lo  -lm 
libtool: link: ar cru .libs/libutil.a  mt19937ar.o sobolseq.o timer.o stop.o redblack.o qsort_r.o rescale.o
libtool: link: ranlib .libs/libutil.a
libtool: link: ( cd ".libs" && rm -f "libutil.la" && ln -s "../libutil.la" "libutil.la" )
gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../api   -g -O2 -MT redblack_test.o -MD -MP -MF .deps/redblack_test.Tpo -c -o redblack_test.o redblack_test.c
mv -f .deps/redblack_test.Tpo .deps/redblack_test.Po
/bin/sh ../libtool --tag=CC   --mode=link gcc -std=gnu99  -g -O2   -o redblack_test redblack_test.o libutil.la -lm 
libtool: link: gcc -std=gnu99 -g -O2 -o redblack_test redblack_test.o  ./.libs/libutil.a -lm
make[2]: Leaving directory `/home/root/nlopt-2.3/util'
Making all in direct
make[2]: Entering directory `/home/root/nlopt-2.3/direct'
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../util -I../api   -g -O2 -MT DIRect.lo -MD -MP -MF .deps/DIRect.Tpo -c -o DIRect.lo DIRect.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -g -O2 -MT DIRect.lo -MD -MP -MF .deps/DIRect.Tpo -c DIRect.c -o DIRect.o
mv -f .deps/DIRect.Tpo .deps/DIRect.Plo
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../util -I../api   -g -O2 -MT direct_wrap.lo -MD -MP -MF .deps/direct_wrap.Tpo -c -o direct_wrap.lo direct_wrap.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -g -O2 -MT direct_wrap.lo -MD -MP -MF .deps/direct_wrap.Tpo -c direct_wrap.c -o direct_wrap.o
mv -f .deps/direct_wrap.Tpo .deps/direct_wrap.Plo
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../util -I../api   -g -O2 -MT DIRserial.lo -MD -MP -MF .deps/DIRserial.Tpo -c -o DIRserial.lo DIRserial.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -g -O2 -MT DIRserial.lo -MD -MP -MF .deps/DIRserial.Tpo -c DIRserial.c -o DIRserial.o
mv -f .deps/DIRserial.Tpo .deps/DIRserial.Plo
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../util -I../api   -g -O2 -MT DIRsubrout.lo -MD -MP -MF .deps/DIRsubrout.Tpo -c -o DIRsubrout.lo DIRsubrout.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -g -O2 -MT DIRsubrout.lo -MD -MP -MF .deps/DIRsubrout.Tpo -c DIRsubrout.c -o DIRsubrout.o
mv -f .deps/DIRsubrout.Tpo .deps/DIRsubrout.Plo
/bin/sh ../libtool --tag=CC   --mode=link gcc -std=gnu99  -g -O2   -o libdirect.la  DIRect.lo direct_wrap.lo DIRserial.lo DIRsubrout.lo  -lm 
libtool: link: ar cru .libs/libdirect.a  DIRect.o direct_wrap.o DIRserial.o DIRsubrout.o
libtool: link: ranlib .libs/libdirect.a
libtool: link: ( cd ".libs" && rm -f "libdirect.la" && ln -s "../libdirect.la" "libdirect.la" )
make[2]: Leaving directory `/home/root/nlopt-2.3/direct'
Making all in cdirect
make[2]: Entering directory `/home/root/nlopt-2.3/cdirect'
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../util -I../api   -g -O2 -MT cdirect.lo -MD -MP -MF .deps/cdirect.Tpo -c -o cdirect.lo cdirect.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -g -O2 -MT cdirect.lo -MD -MP -MF .deps/cdirect.Tpo -c cdirect.c -o cdirect.o
mv -f .deps/cdirect.Tpo .deps/cdirect.Plo
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../util -I../api   -g -O2 -MT hybrid.lo -MD -MP -MF .deps/hybrid.Tpo -c -o hybrid.lo hybrid.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -g -O2 -MT hybrid.lo -MD -MP -MF .deps/hybrid.Tpo -c hybrid.c -o hybrid.o
hybrid.c: In function 'optimize_rect':
hybrid.c:91:6: warning: 'nlopt_minimize' is deprecated (declared at ../api/nlopt.h:325) [-Wdeprecated-declarations]
      ret = nlopt_minimize(p->local_alg, n, fcount, p, 
      ^
mv -f .deps/hybrid.Tpo .deps/hybrid.Plo
/bin/sh ../libtool --tag=CC   --mode=link gcc -std=gnu99  -g -O2   -o libcdirect.la  cdirect.lo hybrid.lo  -lm 
libtool: link: ar cru .libs/libcdirect.a  cdirect.o hybrid.o
libtool: link: ranlib .libs/libcdirect.a
libtool: link: ( cd ".libs" && rm -f "libcdirect.la" && ln -s "../libcdirect.la" "libcdirect.la" )
make[2]: Leaving directory `/home/root/nlopt-2.3/cdirect'
Making all in praxis
make[2]: Entering directory `/home/root/nlopt-2.3/praxis'
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../util -I../api   -g -O2 -MT praxis.lo -MD -MP -MF .deps/praxis.Tpo -c -o praxis.lo praxis.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -g -O2 -MT praxis.lo -MD -MP -MF .deps/praxis.Tpo -c praxis.c -o praxis.o
mv -f .deps/praxis.Tpo .deps/praxis.Plo
/bin/sh ../libtool --tag=CC   --mode=link gcc -std=gnu99  -g -O2   -o libpraxis.la  praxis.lo  -lm 
libtool: link: ar cru .libs/libpraxis.a  praxis.o
libtool: link: ranlib .libs/libpraxis.a
libtool: link: ( cd ".libs" && rm -f "libpraxis.la" && ln -s "../libpraxis.la" "libpraxis.la" )
make[2]: Leaving directory `/home/root/nlopt-2.3/praxis'
Making all in luksan
make[2]: Entering directory `/home/root/nlopt-2.3/luksan'
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../util -I../api   -g -O2 -MT plis.lo -MD -MP -MF .deps/plis.Tpo -c -o plis.lo plis.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -g -O2 -MT plis.lo -MD -MP -MF .deps/plis.Tpo -c plis.c -o plis.o
mv -f .deps/plis.Tpo .deps/plis.Plo
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../util -I../api   -g -O2 -MT plip.lo -MD -MP -MF .deps/plip.Tpo -c -o plip.lo plip.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -g -O2 -MT plip.lo -MD -MP -MF .deps/plip.Tpo -c plip.c -o plip.o
mv -f .deps/plip.Tpo .deps/plip.Plo
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../util -I../api   -g -O2 -MT pnet.lo -MD -MP -MF .deps/pnet.Tpo -c -o pnet.lo pnet.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -g -O2 -MT pnet.lo -MD -MP -MF .deps/pnet.Tpo -c pnet.c -o pnet.o
mv -f .deps/pnet.Tpo .deps/pnet.Plo
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../util -I../api   -g -O2 -MT mssubs.lo -MD -MP -MF .deps/mssubs.Tpo -c -o mssubs.lo mssubs.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -g -O2 -MT mssubs.lo -MD -MP -MF .deps/mssubs.Tpo -c mssubs.c -o mssubs.o
mv -f .deps/mssubs.Tpo .deps/mssubs.Plo
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../util -I../api   -g -O2 -MT pssubs.lo -MD -MP -MF .deps/pssubs.Tpo -c -o pssubs.lo pssubs.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -g -O2 -MT pssubs.lo -MD -MP -MF .deps/pssubs.Tpo -c pssubs.c -o pssubs.o
mv -f .deps/pssubs.Tpo .deps/pssubs.Plo
/bin/sh ../libtool --tag=CC   --mode=link gcc -std=gnu99  -g -O2   -o libluksan.la  plis.lo plip.lo pnet.lo mssubs.lo pssubs.lo  -lm 
libtool: link: ar cru .libs/libluksan.a  plis.o plip.o pnet.o mssubs.o pssubs.o
libtool: link: ranlib .libs/libluksan.a
libtool: link: ( cd ".libs" && rm -f "libluksan.la" && ln -s "../libluksan.la" "libluksan.la" )
make[2]: Leaving directory `/home/root/nlopt-2.3/luksan'
Making all in crs
make[2]: Entering directory `/home/root/nlopt-2.3/crs'
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../util -I../api   -g -O2 -MT crs.lo -MD -MP -MF .deps/crs.Tpo -c -o crs.lo crs.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -g -O2 -MT crs.lo -MD -MP -MF .deps/crs.Tpo -c crs.c -o crs.o
mv -f .deps/crs.Tpo .deps/crs.Plo
/bin/sh ../libtool --tag=CC   --mode=link gcc -std=gnu99  -g -O2   -o libcrs.la  crs.lo  -lm 
libtool: link: ar cru .libs/libcrs.a  crs.o
libtool: link: ranlib .libs/libcrs.a
libtool: link: ( cd ".libs" && rm -f "libcrs.la" && ln -s "../libcrs.la" "libcrs.la" )
make[2]: Leaving directory `/home/root/nlopt-2.3/crs'
Making all in mlsl
make[2]: Entering directory `/home/root/nlopt-2.3/mlsl'
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../util -I../api   -g -O2 -MT mlsl.lo -MD -MP -MF .deps/mlsl.Tpo -c -o mlsl.lo mlsl.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -g -O2 -MT mlsl.lo -MD -MP -MF .deps/mlsl.Tpo -c mlsl.c -o mlsl.o
mv -f .deps/mlsl.Tpo .deps/mlsl.Plo
/bin/sh ../libtool --tag=CC   --mode=link gcc -std=gnu99  -g -O2   -o libmlsl.la  mlsl.lo  -lm 
libtool: link: ar cru .libs/libmlsl.a  mlsl.o
libtool: link: ranlib .libs/libmlsl.a
libtool: link: ( cd ".libs" && rm -f "libmlsl.la" && ln -s "../libmlsl.la" "libmlsl.la" )
make[2]: Leaving directory `/home/root/nlopt-2.3/mlsl'
Making all in mma
make[2]: Entering directory `/home/root/nlopt-2.3/mma'
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../util -I../api   -g -O2 -MT mma.lo -MD -MP -MF .deps/mma.Tpo -c -o mma.lo mma.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -g -O2 -MT mma.lo -MD -MP -MF .deps/mma.Tpo -c mma.c -o mma.o
mv -f .deps/mma.Tpo .deps/mma.Plo
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../util -I../api   -g -O2 -MT ccsa_quadratic.lo -MD -MP -MF .deps/ccsa_quadratic.Tpo -c -o ccsa_quadratic.lo ccsa_quadratic.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -g -O2 -MT ccsa_quadratic.lo -MD -MP -MF .deps/ccsa_quadratic.Tpo -c ccsa_quadratic.c -o ccsa_quadratic.o
mv -f .deps/ccsa_quadratic.Tpo .deps/ccsa_quadratic.Plo
/bin/sh ../libtool --tag=CC   --mode=link gcc -std=gnu99  -g -O2   -o libmma.la  mma.lo ccsa_quadratic.lo  -lm 
libtool: link: ar cru .libs/libmma.a  mma.o ccsa_quadratic.o
libtool: link: ranlib .libs/libmma.a
libtool: link: ( cd ".libs" && rm -f "libmma.la" && ln -s "../libmma.la" "libmma.la" )
make[2]: Leaving directory `/home/root/nlopt-2.3/mma'
Making all in cobyla
make[2]: Entering directory `/home/root/nlopt-2.3/cobyla'
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../util -I../api   -g -O2 -MT cobyla.lo -MD -MP -MF .deps/cobyla.Tpo -c -o cobyla.lo cobyla.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -g -O2 -MT cobyla.lo -MD -MP -MF .deps/cobyla.Tpo -c cobyla.c -o cobyla.o
mv -f .deps/cobyla.Tpo .deps/cobyla.Plo
/bin/sh ../libtool --tag=CC   --mode=link gcc -std=gnu99  -g -O2   -o libcobyla.la  cobyla.lo  -lm 
libtool: link: ar cru .libs/libcobyla.a  cobyla.o
libtool: link: ranlib .libs/libcobyla.a
libtool: link: ( cd ".libs" && rm -f "libcobyla.la" && ln -s "../libcobyla.la" "libcobyla.la" )
make[2]: Leaving directory `/home/root/nlopt-2.3/cobyla'
Making all in newuoa
make[2]: Entering directory `/home/root/nlopt-2.3/newuoa'
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../util -I../api   -g -O2 -MT newuoa.lo -MD -MP -MF .deps/newuoa.Tpo -c -o newuoa.lo newuoa.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -g -O2 -MT newuoa.lo -MD -MP -MF .deps/newuoa.Tpo -c newuoa.c -o newuoa.o
newuoa.c: In function 'trsapp_':
newuoa.c:184:3: warning: 'nlopt_minimize_constrained' is deprecated (declared at ../api/nlopt.h:335) [-Wdeprecated-declarations]
   ret = nlopt_minimize_constrained(NLOPT_LD_MMA, *n, quad_model, &qmd,
   ^
newuoa.c: In function 'biglag_':
newuoa.c:1241:3: warning: 'nlopt_minimize_constrained' is deprecated (declared at ../api/nlopt.h:335) [-Wdeprecated-declarations]
   return nlopt_minimize_constrained(NLOPT_LD_MMA, *n, lag, &ld,
   ^
mv -f .deps/newuoa.Tpo .deps/newuoa.Plo
/bin/sh ../libtool --tag=CC   --mode=link gcc -std=gnu99  -g -O2   -o libnewuoa.la  newuoa.lo  -lm 
libtool: link: ar cru .libs/libnewuoa.a  newuoa.o
libtool: link: ranlib .libs/libnewuoa.a
libtool: link: ( cd ".libs" && rm -f "libnewuoa.la" && ln -s "../libnewuoa.la" "libnewuoa.la" )
make[2]: Leaving directory `/home/root/nlopt-2.3/newuoa'
Making all in lbfgs
make[2]: Entering directory `/home/root/nlopt-2.3/lbfgs'
make[2]: Nothing to be done for `all'.
make[2]: Leaving directory `/home/root/nlopt-2.3/lbfgs'
Making all in neldermead
make[2]: Entering directory `/home/root/nlopt-2.3/neldermead'
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../util -I../api   -g -O2 -MT nldrmd.lo -MD -MP -MF .deps/nldrmd.Tpo -c -o nldrmd.lo nldrmd.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -g -O2 -MT nldrmd.lo -MD -MP -MF .deps/nldrmd.Tpo -c nldrmd.c -o nldrmd.o
mv -f .deps/nldrmd.Tpo .deps/nldrmd.Plo
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../util -I../api   -g -O2 -MT sbplx.lo -MD -MP -MF .deps/sbplx.Tpo -c -o sbplx.lo sbplx.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -g -O2 -MT sbplx.lo -MD -MP -MF .deps/sbplx.Tpo -c sbplx.c -o sbplx.o
mv -f .deps/sbplx.Tpo .deps/sbplx.Plo
/bin/sh ../libtool --tag=CC   --mode=link gcc -std=gnu99  -g -O2   -o libneldermead.la  nldrmd.lo sbplx.lo  -lm 
libtool: link: ar cru .libs/libneldermead.a  nldrmd.o sbplx.o
libtool: link: ranlib .libs/libneldermead.a
libtool: link: ( cd ".libs" && rm -f "libneldermead.la" && ln -s "../libneldermead.la" "libneldermead.la" )
make[2]: Leaving directory `/home/root/nlopt-2.3/neldermead'
Making all in auglag
make[2]: Entering directory `/home/root/nlopt-2.3/auglag'
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../util -I../api   -g -O2 -MT auglag.lo -MD -MP -MF .deps/auglag.Tpo -c -o auglag.lo auglag.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -g -O2 -MT auglag.lo -MD -MP -MF .deps/auglag.Tpo -c auglag.c -o auglag.o
mv -f .deps/auglag.Tpo .deps/auglag.Plo
/bin/sh ../libtool --tag=CC   --mode=link gcc -std=gnu99  -g -O2   -o libauglag.la  auglag.lo  -lm 
libtool: link: ar cru .libs/libauglag.a  auglag.o
libtool: link: ranlib .libs/libauglag.a
libtool: link: ( cd ".libs" && rm -f "libauglag.la" && ln -s "../libauglag.la" "libauglag.la" )
make[2]: Leaving directory `/home/root/nlopt-2.3/auglag'
Making all in bobyqa
make[2]: Entering directory `/home/root/nlopt-2.3/bobyqa'
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../util -I../api   -g -O2 -MT bobyqa.lo -MD -MP -MF .deps/bobyqa.Tpo -c -o bobyqa.lo bobyqa.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -g -O2 -MT bobyqa.lo -MD -MP -MF .deps/bobyqa.Tpo -c bobyqa.c -o bobyqa.o
mv -f .deps/bobyqa.Tpo .deps/bobyqa.Plo
/bin/sh ../libtool --tag=CC   --mode=link gcc -std=gnu99  -g -O2   -o libbobyqa.la  bobyqa.lo  -lm 
libtool: link: ar cru .libs/libbobyqa.a  bobyqa.o
libtool: link: ranlib .libs/libbobyqa.a
libtool: link: ( cd ".libs" && rm -f "libbobyqa.la" && ln -s "../libbobyqa.la" "libbobyqa.la" )
make[2]: Leaving directory `/home/root/nlopt-2.3/bobyqa'
Making all in isres
make[2]: Entering directory `/home/root/nlopt-2.3/isres'
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../util -I../api   -g -O2 -MT isres.lo -MD -MP -MF .deps/isres.Tpo -c -o isres.lo isres.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -g -O2 -MT isres.lo -MD -MP -MF .deps/isres.Tpo -c isres.c -o isres.o
mv -f .deps/isres.Tpo .deps/isres.Plo
/bin/sh ../libtool --tag=CC   --mode=link gcc -std=gnu99  -g -O2   -o libisres.la  isres.lo  -lm 
libtool: link: ar cru .libs/libisres.a  isres.o
libtool: link: ranlib .libs/libisres.a
libtool: link: ( cd ".libs" && rm -f "libisres.la" && ln -s "../libisres.la" "libisres.la" )
make[2]: Leaving directory `/home/root/nlopt-2.3/isres'
Making all in slsqp
make[2]: Entering directory `/home/root/nlopt-2.3/slsqp'
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../util -I../api   -g -O2 -MT slsqp.lo -MD -MP -MF .deps/slsqp.Tpo -c -o slsqp.lo slsqp.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../util -I../api -g -O2 -MT slsqp.lo -MD -MP -MF .deps/slsqp.Tpo -c slsqp.c -o slsqp.o
mv -f .deps/slsqp.Tpo .deps/slsqp.Plo
/bin/sh ../libtool --tag=CC   --mode=link gcc -std=gnu99  -g -O2   -o libslsqp.la  slsqp.lo  -lm 
libtool: link: ar cru .libs/libslsqp.a  slsqp.o
libtool: link: ranlib .libs/libslsqp.a
libtool: link: ( cd ".libs" && rm -f "libslsqp.la" && ln -s "../libslsqp.la" "libslsqp.la" )
make[2]: Leaving directory `/home/root/nlopt-2.3/slsqp'
Making all in api
make[2]: Entering directory `/home/root/nlopt-2.3/api'
make  all-am
make[3]: Entering directory `/home/root/nlopt-2.3/api'
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../cdirect -I../direct -I../stogo -I../praxis -I../lbfgs -I../luksan -I../crs -I../mlsl -I../mma -I../cobyla -I../newuoa -I../neldermead -I../auglag -I../bobyqa -I../isres -I../slsqp -I../util   -g -O2 -MT general.lo -MD -MP -MF .deps/general.Tpo -c -o general.lo general.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../cdirect -I../direct -I../stogo -I../praxis -I../lbfgs -I../luksan -I../crs -I../mlsl -I../mma -I../cobyla -I../newuoa -I../neldermead -I../auglag -I../bobyqa -I../isres -I../slsqp -I../util -g -O2 -MT general.lo -MD -MP -MF .deps/general.Tpo -c general.c -o general.o
mv -f .deps/general.Tpo .deps/general.Plo
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../cdirect -I../direct -I../stogo -I../praxis -I../lbfgs -I../luksan -I../crs -I../mlsl -I../mma -I../cobyla -I../newuoa -I../neldermead -I../auglag -I../bobyqa -I../isres -I../slsqp -I../util   -g -O2 -MT options.lo -MD -MP -MF .deps/options.Tpo -c -o options.lo options.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../cdirect -I../direct -I../stogo -I../praxis -I../lbfgs -I../luksan -I../crs -I../mlsl -I../mma -I../cobyla -I../newuoa -I../neldermead -I../auglag -I../bobyqa -I../isres -I../slsqp -I../util -g -O2 -MT options.lo -MD -MP -MF .deps/options.Tpo -c options.c -o options.o
mv -f .deps/options.Tpo .deps/options.Plo
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../cdirect -I../direct -I../stogo -I../praxis -I../lbfgs -I../luksan -I../crs -I../mlsl -I../mma -I../cobyla -I../newuoa -I../neldermead -I../auglag -I../bobyqa -I../isres -I../slsqp -I../util   -g -O2 -MT optimize.lo -MD -MP -MF .deps/optimize.Tpo -c -o optimize.lo optimize.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../cdirect -I../direct -I../stogo -I../praxis -I../lbfgs -I../luksan -I../crs -I../mlsl -I../mma -I../cobyla -I../newuoa -I../neldermead -I../auglag -I../bobyqa -I../isres -I../slsqp -I../util -g -O2 -MT optimize.lo -MD -MP -MF .deps/optimize.Tpo -c optimize.c -o optimize.o
mv -f .deps/optimize.Tpo .deps/optimize.Plo
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../cdirect -I../direct -I../stogo -I../praxis -I../lbfgs -I../luksan -I../crs -I../mlsl -I../mma -I../cobyla -I../newuoa -I../neldermead -I../auglag -I../bobyqa -I../isres -I../slsqp -I../util   -g -O2 -MT deprecated.lo -MD -MP -MF .deps/deprecated.Tpo -c -o deprecated.lo deprecated.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../cdirect -I../direct -I../stogo -I../praxis -I../lbfgs -I../luksan -I../crs -I../mlsl -I../mma -I../cobyla -I../newuoa -I../neldermead -I../auglag -I../bobyqa -I../isres -I../slsqp -I../util -g -O2 -MT deprecated.lo -MD -MP -MF .deps/deprecated.Tpo -c deprecated.c -o deprecated.o
deprecated.c: In function 'nlopt_minimize_constrained':
deprecated.c:149:6: warning: 'nlopt_minimize_econstrained' is deprecated (declared at deprecated.c:65) [-Wdeprecated-declarations]
      return nlopt_minimize_econstrained(
      ^
deprecated.c: In function 'nlopt_minimize':
deprecated.c:167:6: warning: 'nlopt_minimize_constrained' is deprecated (declared at deprecated.c:138) [-Wdeprecated-declarations]
      return nlopt_minimize_constrained(
      ^
mv -f .deps/deprecated.Tpo .deps/deprecated.Plo
/bin/sh ../libtool --tag=CC   --mode=compile gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../cdirect -I../direct -I../stogo -I../praxis -I../lbfgs -I../luksan -I../crs -I../mlsl -I../mma -I../cobyla -I../newuoa -I../neldermead -I../auglag -I../bobyqa -I../isres -I../slsqp -I../util   -g -O2 -MT f77api.lo -MD -MP -MF .deps/f77api.Tpo -c -o f77api.lo f77api.c
libtool: compile:  gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I.. -I../cdirect -I../direct -I../stogo -I../praxis -I../lbfgs -I../luksan -I../crs -I../mlsl -I../mma -I../cobyla -I../newuoa -I../neldermead -I../auglag -I../bobyqa -I../isres -I../slsqp -I../util -g -O2 -MT f77api.lo -MD -MP -MF .deps/f77api.Tpo -c f77api.c -o f77api.o
In file included from f77api.c:103:0:
f77funcs.h: In function 'nloptc_':
f77funcs.h:57:6: warning: 'nlopt_minimize_constrained' is deprecated (declared at nlopt.h:335) [-Wdeprecated-declarations]
      *info = nlopt_minimize_constrained((nlopt_algorithm) *algorithm, 
      ^
f77funcs.h: In function 'nlogls_':
f77funcs.h:96:6: warning: 'nlopt_get_local_search_algorithm' is deprecated (declared at nlopt.h:359) [-Wdeprecated-declarations]
      nlopt_get_local_search_algorithm(&deriv, &nonderiv, maxeval);
      ^
f77funcs.h: In function 'nlosls_':
f77funcs.h:104:6: warning: 'nlopt_set_local_search_algorithm' is deprecated (declared at nlopt.h:362) [-Wdeprecated-declarations]
      nlopt_set_local_search_algorithm(deriv, nonderiv, *maxeval);
      ^
f77funcs.h: In function 'nlogsp_':
f77funcs.h:109:6: warning: 'nlopt_get_stochastic_population' is deprecated (declared at nlopt.h:366) [-Wdeprecated-declarations]
      *pop = nlopt_get_stochastic_population();
      ^
f77funcs.h: In function 'nlossp_':
f77funcs.h:113:6: warning: 'nlopt_set_stochastic_population' is deprecated (declared at nlopt.h:367) [-Wdeprecated-declarations]
      nlopt_set_stochastic_population(*pop);
      ^
In file included from f77api.c:114:0:
f77funcs.h: In function 'nloptc':
f77funcs.h:57:6: warning: 'nlopt_minimize_constrained' is deprecated (declared at nlopt.h:335) [-Wdeprecated-declarations]
      *info = nlopt_minimize_constrained((nlopt_algorithm) *algorithm, 
      ^
f77funcs.h: In function 'nlogls':
f77funcs.h:96:6: warning: 'nlopt_get_local_search_algorithm' is deprecated (declared at nlopt.h:359) [-Wdeprecated-declarations]
      nlopt_get_local_search_algorithm(&deriv, &nonderiv, maxeval);
      ^
f77funcs.h: In function 'nlosls':
f77funcs.h:104:6: warning: 'nlopt_set_local_search_algorithm' is deprecated (declared at nlopt.h:362) [-Wdeprecated-declarations]
      nlopt_set_local_search_algorithm(deriv, nonderiv, *maxeval);
      ^
f77funcs.h: In function 'nlogsp':
f77funcs.h:109:6: warning: 'nlopt_get_stochastic_population' is deprecated (declared at nlopt.h:366) [-Wdeprecated-declarations]
      *pop = nlopt_get_stochastic_population();
      ^
f77funcs.h: In function 'nlossp':
f77funcs.h:113:6: warning: 'nlopt_set_stochastic_population' is deprecated (declared at nlopt.h:367) [-Wdeprecated-declarations]
      nlopt_set_stochastic_population(*pop);
      ^
In file included from f77api.c:129:0:
f77funcs.h: In function 'NLOPTC':
f77funcs.h:57:6: warning: 'nlopt_minimize_constrained' is deprecated (declared at nlopt.h:335) [-Wdeprecated-declarations]
      *info = nlopt_minimize_constrained((nlopt_algorithm) *algorithm, 
      ^
f77funcs.h: In function 'NLOGLS':
f77funcs.h:96:6: warning: 'nlopt_get_local_search_algorithm' is deprecated (declared at nlopt.h:359) [-Wdeprecated-declarations]
      nlopt_get_local_search_algorithm(&deriv, &nonderiv, maxeval);
      ^
f77funcs.h: In function 'NLOSLS':
f77funcs.h:104:6: warning: 'nlopt_set_local_search_algorithm' is deprecated (declared at nlopt.h:362) [-Wdeprecated-declarations]
      nlopt_set_local_search_algorithm(deriv, nonderiv, *maxeval);
      ^
f77funcs.h: In function 'NLOGSP':
f77funcs.h:109:6: warning: 'nlopt_get_stochastic_population' is deprecated (declared at nlopt.h:366) [-Wdeprecated-declarations]
      *pop = nlopt_get_stochastic_population();
      ^
f77funcs.h: In function 'NLOSSP':
f77funcs.h:113:6: warning: 'nlopt_set_stochastic_population' is deprecated (declared at nlopt.h:367) [-Wdeprecated-declarations]
      nlopt_set_stochastic_population(*pop);
      ^
mv -f .deps/f77api.Tpo .deps/f77api.Plo
/bin/sh ../libtool --tag=CC   --mode=link gcc -std=gnu99  -g -O2   -o libapi.la  general.lo options.lo optimize.lo deprecated.lo f77api.lo  -lm 
libtool: link: ar cru .libs/libapi.a  general.o options.o optimize.o deprecated.o f77api.o
libtool: link: ranlib .libs/libapi.a
libtool: link: ( cd ".libs" && rm -f "libapi.la" && ln -s "../libapi.la" "libapi.la" )
make[3]: Leaving directory `/home/root/nlopt-2.3/api'
make[2]: Leaving directory `/home/root/nlopt-2.3/api'
Making all in .
make[2]: Entering directory `/home/root/nlopt-2.3'
/bin/sh ./libtool --tag=CC   --mode=link gcc -std=gnu99  -g -O2 -no-undefined -version-info 7:0:7  -o libnlopt.la -rpath /usr/local/lib64  direct/libdirect.la cdirect/libcdirect.la  praxis/libpraxis.la  luksan/libluksan.la crs/libcrs.la mlsl/libmlsl.la mma/libmma.la cobyla/libcobyla.la newuoa/libnewuoa.la neldermead/libneldermead.la auglag/libauglag.la bobyqa/libbobyqa.la isres/libisres.la slsqp/libslsqp.la api/libapi.la util/libutil.la -lm 
libtool: link: (cd .libs/libnlopt.lax/libdirect.a && ar x "/home/root/nlopt-2.3/direct/.libs/libdirect.a")
libtool: link: (cd .libs/libnlopt.lax/libcdirect.a && ar x "/home/root/nlopt-2.3/cdirect/.libs/libcdirect.a")
libtool: link: (cd .libs/libnlopt.lax/libpraxis.a && ar x "/home/root/nlopt-2.3/praxis/.libs/libpraxis.a")
libtool: link: (cd .libs/libnlopt.lax/libluksan.a && ar x "/home/root/nlopt-2.3/luksan/.libs/libluksan.a")
libtool: link: (cd .libs/libnlopt.lax/libcrs.a && ar x "/home/root/nlopt-2.3/crs/.libs/libcrs.a")
libtool: link: (cd .libs/libnlopt.lax/libmlsl.a && ar x "/home/root/nlopt-2.3/mlsl/.libs/libmlsl.a")
libtool: link: (cd .libs/libnlopt.lax/libmma.a && ar x "/home/root/nlopt-2.3/mma/.libs/libmma.a")
libtool: link: (cd .libs/libnlopt.lax/libcobyla.a && ar x "/home/root/nlopt-2.3/cobyla/.libs/libcobyla.a")
libtool: link: (cd .libs/libnlopt.lax/libnewuoa.a && ar x "/home/root/nlopt-2.3/newuoa/.libs/libnewuoa.a")
libtool: link: (cd .libs/libnlopt.lax/libneldermead.a && ar x "/home/root/nlopt-2.3/neldermead/.libs/libneldermead.a")
libtool: link: (cd .libs/libnlopt.lax/libauglag.a && ar x "/home/root/nlopt-2.3/auglag/.libs/libauglag.a")
libtool: link: (cd .libs/libnlopt.lax/libbobyqa.a && ar x "/home/root/nlopt-2.3/bobyqa/.libs/libbobyqa.a")
libtool: link: (cd .libs/libnlopt.lax/libisres.a && ar x "/home/root/nlopt-2.3/isres/.libs/libisres.a")
libtool: link: (cd .libs/libnlopt.lax/libslsqp.a && ar x "/home/root/nlopt-2.3/slsqp/.libs/libslsqp.a")
libtool: link: (cd .libs/libnlopt.lax/libapi.a && ar x "/home/root/nlopt-2.3/api/.libs/libapi.a")
libtool: link: (cd .libs/libnlopt.lax/libutil.a && ar x "/home/root/nlopt-2.3/util/.libs/libutil.a")
libtool: link: ar cru .libs/libnlopt.a   .libs/libnlopt.lax/libdirect.a/DIRect.o .libs/libnlopt.lax/libdirect.a/DIRserial.o .libs/libnlopt.lax/libdirect.a/DIRsubrout.o .libs/libnlopt.lax/libdirect.a/direct_wrap.o  .libs/libnlopt.lax/libcdirect.a/cdirect.o .libs/libnlopt.lax/libcdirect.a/hybrid.o  .libs/libnlopt.lax/libpraxis.a/praxis.o  .libs/libnlopt.lax/libluksan.a/mssubs.o .libs/libnlopt.lax/libluksan.a/plip.o .libs/libnlopt.lax/libluksan.a/plis.o .libs/libnlopt.lax/libluksan.a/pnet.o .libs/libnlopt.lax/libluksan.a/pssubs.o  .libs/libnlopt.lax/libcrs.a/crs.o  .libs/libnlopt.lax/libmlsl.a/mlsl.o  .libs/libnlopt.lax/libmma.a/ccsa_quadratic.o .libs/libnlopt.lax/libmma.a/mma.o  .libs/libnlopt.lax/libcobyla.a/cobyla.o  .libs/libnlopt.lax/libnewuoa.a/newuoa.o  .libs/libnlopt.lax/libneldermead.a/nldrmd.o .libs/libnlopt.lax/libneldermead.a/sbplx.o  .libs/libnlopt.lax/libauglag.a/auglag.o  .libs/libnlopt.lax/libbobyqa.a/bobyqa.o  .libs/libnlopt.lax/libisres.a/isres.o  .libs/libnlopt.lax/libslsqp.a/slsqp.o  .libs/libnlopt.lax/libapi.a/deprecated.o .libs/libnlopt.lax/libapi.a/f77api.o .libs/libnlopt.lax/libapi.a/general.o .libs/libnlopt.lax/libapi.a/optimize.o .libs/libnlopt.lax/libapi.a/options.o  .libs/libnlopt.lax/libutil.a/mt19937ar.o .libs/libnlopt.lax/libutil.a/qsort_r.o .libs/libnlopt.lax/libutil.a/redblack.o .libs/libnlopt.lax/libutil.a/rescale.o .libs/libnlopt.lax/libutil.a/sobolseq.o .libs/libnlopt.lax/libutil.a/stop.o .libs/libnlopt.lax/libutil.a/timer.o 
libtool: link: ranlib .libs/libnlopt.a
libtool: link: rm -fr .libs/libnlopt.lax
libtool: link: ( cd ".libs" && rm -f "libnlopt.la" && ln -s "../libnlopt.la" "libnlopt.la" )
make[2]: Leaving directory `/home/root/nlopt-2.3'
Making all in octave
make[2]: Entering directory `/home/root/nlopt-2.3/octave'
make  all-am
make[3]: Entering directory `/home/root/nlopt-2.3/octave'
gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../api -I../util   -g -O2 -MT dummy.o -MD -MP -MF .deps/dummy.Tpo -c -o dummy.o dummy.c
mv -f .deps/dummy.Tpo .deps/dummy.Po
/bin/sh ../libtool --tag=CC   --mode=link gcc -std=gnu99  -g -O2   -o dummy dummy.o  -lm 
libtool: link: gcc -std=gnu99 -g -O2 -o dummy dummy.o  -lm
make[3]: Leaving directory `/home/root/nlopt-2.3/octave'
make[2]: Leaving directory `/home/root/nlopt-2.3/octave'
Making all in test
make[2]: Entering directory `/home/root/nlopt-2.3/test'
gcc -std=gnu99 -DHAVE_CONFIG_H -I. -I..  -I../api -I../util   -g -O2 -MT testfuncs.o -MD -MP -MF .deps/testfuncs.Tpo -c -o testfuncs.o testfuncs.c
mv -f .deps/testfuncs.Tpo .deps/testfuncs.Po
g++ -DHAVE_CONFIG_H -I. -I..  -I../api -I../util   -g -O2 -MT testopt.o -MD -MP -MF .deps/testopt.Tpo -c -o testopt.o testopt.cpp
testopt.cpp: In function ?int test_function(int)?:
testopt.cpp:218:11: warning: ?nlopt_result nlopt_minimize(nlopt_algorithm, int, nlopt_func_old, void*, const double*, const double*, double*, double*, double, double, double, double, const double*, int, double)? is deprecated (declared at ../api/nlopt.h:325) [-Wdeprecated-declarations]
     ret = nlopt_minimize(algorithm,
           ^
testopt.cpp:223:21: warning: ?nlopt_result nlopt_minimize(nlopt_algorithm, int, nlopt_func_old, void*, const double*, const double*, double*, double*, double, double, double, double, const double*, int, double)? is deprecated (declared at ../api/nlopt.h:325) [-Wdeprecated-declarations]
     maxeval, maxtime);
                     ^
mv -f .deps/testopt.Tpo .deps/testopt.Po
/bin/sh ../libtool --tag=CXX   --mode=link g++  -g -O2   -o testopt testfuncs.o testopt.o ../libnlopt.la -lm 
libtool: link: g++ -g -O2 -o testopt testfuncs.o testopt.o  ../.libs/libnlopt.a -lm
make[2]: Leaving directory `/home/root/nlopt-2.3/test'
Making all in swig
make[2]: Entering directory `/home/root/nlopt-2.3/swig'
make  all-am
make[3]: Entering directory `/home/root/nlopt-2.3/swig'
make[3]: Nothing to be done for `all-am'.
make[3]: Leaving directory `/home/root/nlopt-2.3/swig'
make[2]: Leaving directory `/home/root/nlopt-2.3/swig'
make[1]: Leaving directory `/home/root/nlopt-2.3'
[1m[31mcandide:/home/root/nlopt-2.3 # (B[mmake install
Making install in util
make[1]: Entering directory `/home/root/nlopt-2.3/util'
make[2]: Entering directory `/home/root/nlopt-2.3/util'
make[2]: Nothing to be done for `install-exec-am'.
make[2]: Nothing to be done for `install-data-am'.
make[2]: Leaving directory `/home/root/nlopt-2.3/util'
make[1]: Leaving directory `/home/root/nlopt-2.3/util'
Making install in direct
make[1]: Entering directory `/home/root/nlopt-2.3/direct'
make[2]: Entering directory `/home/root/nlopt-2.3/direct'
make[2]: Nothing to be done for `install-exec-am'.
make[2]: Nothing to be done for `install-data-am'.
make[2]: Leaving directory `/home/root/nlopt-2.3/direct'
make[1]: Leaving directory `/home/root/nlopt-2.3/direct'
Making install in cdirect
make[1]: Entering directory `/home/root/nlopt-2.3/cdirect'
make[2]: Entering directory `/home/root/nlopt-2.3/cdirect'
make[2]: Nothing to be done for `install-exec-am'.
make[2]: Nothing to be done for `install-data-am'.
make[2]: Leaving directory `/home/root/nlopt-2.3/cdirect'
make[1]: Leaving directory `/home/root/nlopt-2.3/cdirect'
Making install in praxis
make[1]: Entering directory `/home/root/nlopt-2.3/praxis'
make[2]: Entering directory `/home/root/nlopt-2.3/praxis'
make[2]: Nothing to be done for `install-exec-am'.
make[2]: Nothing to be done for `install-data-am'.
make[2]: Leaving directory `/home/root/nlopt-2.3/praxis'
make[1]: Leaving directory `/home/root/nlopt-2.3/praxis'
Making install in luksan
make[1]: Entering directory `/home/root/nlopt-2.3/luksan'
make[2]: Entering directory `/home/root/nlopt-2.3/luksan'
make[2]: Nothing to be done for `install-exec-am'.
make[2]: Nothing to be done for `install-data-am'.
make[2]: Leaving directory `/home/root/nlopt-2.3/luksan'
make[1]: Leaving directory `/home/root/nlopt-2.3/luksan'
Making install in crs
make[1]: Entering directory `/home/root/nlopt-2.3/crs'
make[2]: Entering directory `/home/root/nlopt-2.3/crs'
make[2]: Nothing to be done for `install-exec-am'.
make[2]: Nothing to be done for `install-data-am'.
make[2]: Leaving directory `/home/root/nlopt-2.3/crs'
make[1]: Leaving directory `/home/root/nlopt-2.3/crs'
Making install in mlsl
make[1]: Entering directory `/home/root/nlopt-2.3/mlsl'
make[2]: Entering directory `/home/root/nlopt-2.3/mlsl'
make[2]: Nothing to be done for `install-exec-am'.
make[2]: Nothing to be done for `install-data-am'.
make[2]: Leaving directory `/home/root/nlopt-2.3/mlsl'
make[1]: Leaving directory `/home/root/nlopt-2.3/mlsl'
Making install in mma
make[1]: Entering directory `/home/root/nlopt-2.3/mma'
make[2]: Entering directory `/home/root/nlopt-2.3/mma'
make[2]: Nothing to be done for `install-exec-am'.
make[2]: Nothing to be done for `install-data-am'.
make[2]: Leaving directory `/home/root/nlopt-2.3/mma'
make[1]: Leaving directory `/home/root/nlopt-2.3/mma'
Making install in cobyla
make[1]: Entering directory `/home/root/nlopt-2.3/cobyla'
make[2]: Entering directory `/home/root/nlopt-2.3/cobyla'
make[2]: Nothing to be done for `install-exec-am'.
make[2]: Nothing to be done for `install-data-am'.
make[2]: Leaving directory `/home/root/nlopt-2.3/cobyla'
make[1]: Leaving directory `/home/root/nlopt-2.3/cobyla'
Making install in newuoa
make[1]: Entering directory `/home/root/nlopt-2.3/newuoa'
make[2]: Entering directory `/home/root/nlopt-2.3/newuoa'
make[2]: Nothing to be done for `install-exec-am'.
make[2]: Nothing to be done for `install-data-am'.
make[2]: Leaving directory `/home/root/nlopt-2.3/newuoa'
make[1]: Leaving directory `/home/root/nlopt-2.3/newuoa'
Making install in lbfgs
make[1]: Entering directory `/home/root/nlopt-2.3/lbfgs'
make[2]: Entering directory `/home/root/nlopt-2.3/lbfgs'
make[2]: Nothing to be done for `install-exec-am'.
make[2]: Nothing to be done for `install-data-am'.
make[2]: Leaving directory `/home/root/nlopt-2.3/lbfgs'
make[1]: Leaving directory `/home/root/nlopt-2.3/lbfgs'
Making install in neldermead
make[1]: Entering directory `/home/root/nlopt-2.3/neldermead'
make[2]: Entering directory `/home/root/nlopt-2.3/neldermead'
make[2]: Nothing to be done for `install-exec-am'.
make[2]: Nothing to be done for `install-data-am'.
make[2]: Leaving directory `/home/root/nlopt-2.3/neldermead'
make[1]: Leaving directory `/home/root/nlopt-2.3/neldermead'
Making install in auglag
make[1]: Entering directory `/home/root/nlopt-2.3/auglag'
make[2]: Entering directory `/home/root/nlopt-2.3/auglag'
make[2]: Nothing to be done for `install-exec-am'.
make[2]: Nothing to be done for `install-data-am'.
make[2]: Leaving directory `/home/root/nlopt-2.3/auglag'
make[1]: Leaving directory `/home/root/nlopt-2.3/auglag'
Making install in bobyqa
make[1]: Entering directory `/home/root/nlopt-2.3/bobyqa'
make[2]: Entering directory `/home/root/nlopt-2.3/bobyqa'
make[2]: Nothing to be done for `install-exec-am'.
make[2]: Nothing to be done for `install-data-am'.
make[2]: Leaving directory `/home/root/nlopt-2.3/bobyqa'
make[1]: Leaving directory `/home/root/nlopt-2.3/bobyqa'
Making install in isres
make[1]: Entering directory `/home/root/nlopt-2.3/isres'
make[2]: Entering directory `/home/root/nlopt-2.3/isres'
make[2]: Nothing to be done for `install-exec-am'.
make[2]: Nothing to be done for `install-data-am'.
make[2]: Leaving directory `/home/root/nlopt-2.3/isres'
make[1]: Leaving directory `/home/root/nlopt-2.3/isres'
Making install in slsqp
make[1]: Entering directory `/home/root/nlopt-2.3/slsqp'
make[2]: Entering directory `/home/root/nlopt-2.3/slsqp'
make[2]: Nothing to be done for `install-exec-am'.
make[2]: Nothing to be done for `install-data-am'.
make[2]: Leaving directory `/home/root/nlopt-2.3/slsqp'
make[1]: Leaving directory `/home/root/nlopt-2.3/slsqp'
Making install in api
make[1]: Entering directory `/home/root/nlopt-2.3/api'
make  install-am
make[2]: Entering directory `/home/root/nlopt-2.3/api'
make[3]: Entering directory `/home/root/nlopt-2.3/api'
make[3]: Nothing to be done for `install-exec-am'.
 /usr/bin/mkdir -p '/usr/local/include'
 /usr/bin/install -c -m 644 nlopt.h nlopt.f nlopt.hpp '/usr/local/include'
 /usr/bin/mkdir -p '/usr/local/share/man/man3'
 /usr/bin/install -c -m 644 nlopt.3 '/usr/local/share/man/man3'
make[3]: Leaving directory `/home/root/nlopt-2.3/api'
make[2]: Leaving directory `/home/root/nlopt-2.3/api'
make[1]: Leaving directory `/home/root/nlopt-2.3/api'
Making install in .
make[1]: Entering directory `/home/root/nlopt-2.3'
make[2]: Entering directory `/home/root/nlopt-2.3'
 /usr/bin/mkdir -p '/usr/local/lib64'
 /bin/sh ./libtool   --mode=install /usr/bin/install -c   libnlopt.la '/usr/local/lib64'
libtool: install: /usr/bin/install -c .libs/libnlopt.lai /usr/local/lib64/libnlopt.la
libtool: install: /usr/bin/install -c .libs/libnlopt.a /usr/local/lib64/libnlopt.a
libtool: install: chmod 644 /usr/local/lib64/libnlopt.a
libtool: install: ranlib /usr/local/lib64/libnlopt.a
libtool: finish: PATH="/sbin:/usr/sbin:/usr/local/sbin:/root/bin:/usr/local/bin:/usr/bin:/bin:/usr/bin/X11:/usr/X11R6/bin:/usr/games:/sbin" ldconfig -n /usr/local/lib64
ldconfig: /usr/local/lib64/libstdc++.so.6.0.18-gdb.py is not an ELF file - it has the wrong magic bytes at the start.

----------------------------------------------------------------------
Libraries have been installed in:
   /usr/local/lib64

If you ever happen to want to link against installed libraries
in a given directory, LIBDIR, you must either use libtool, and
specify the full pathname of the library, or use the `-LLIBDIR'
flag during linking and do at least one of the following:
   - add LIBDIR to the `LD_LIBRARY_PATH' environment variable
     during execution
   - add LIBDIR to the `LD_RUN_PATH' environment variable
     during linking
   - use the `-Wl,-rpath -Wl,LIBDIR' linker flag
   - have your system administrator add LIBDIR to `/etc/ld.so.conf'

See any operating system documentation about shared libraries for
more information, such as the ld(1) and ld.so(8) manual pages.
----------------------------------------------------------------------
 /usr/bin/mkdir -p '/usr/local/lib64/pkgconfig'
 /usr/bin/install -c -m 644 nlopt.pc '/usr/local/lib64/pkgconfig'
make[2]: Leaving directory `/home/root/nlopt-2.3'
make[1]: Leaving directory `/home/root/nlopt-2.3'
Making install in octave
make[1]: Entering directory `/home/root/nlopt-2.3/octave'
make  install-am
make[2]: Entering directory `/home/root/nlopt-2.3/octave'
make[3]: Entering directory `/home/root/nlopt-2.3/octave'
make[3]: Nothing to be done for `install-exec-am'.
make[3]: Leaving directory `/home/root/nlopt-2.3/octave'
make[2]: Leaving directory `/home/root/nlopt-2.3/octave'
make[1]: Leaving directory `/home/root/nlopt-2.3/octave'
Making install in test
make[1]: Entering directory `/home/root/nlopt-2.3/test'
make[2]: Entering directory `/home/root/nlopt-2.3/test'
make[2]: Nothing to be done for `install-exec-am'.
make[2]: Nothing to be done for `install-data-am'.
make[2]: Leaving directory `/home/root/nlopt-2.3/test'
make[1]: Leaving directory `/home/root/nlopt-2.3/test'
Making install in swig
make[1]: Entering directory `/home/root/nlopt-2.3/swig'
make  install-am
make[2]: Entering directory `/home/root/nlopt-2.3/swig'
make[3]: Entering directory `/home/root/nlopt-2.3/swig'
make[3]: Leaving directory `/home/root/nlopt-2.3/swig'
make[2]: Leaving directory `/home/root/nlopt-2.3/swig'
make[1]: Leaving directory `/home/root/nlopt-2.3/swig'

From matzke at berkeley.edu  Mon Jun 17 03:00:49 2013
From: matzke at berkeley.edu (Nick Matzke)
Date: Sun, 16 Jun 2013 18:00:49 -0700
Subject: [R] extract all numbers from a string
In-Reply-To: <1371361614.53710.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <51BD47E3.6090808@berkeley.edu>
	<1371361614.53710.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <51BE5FC1.9020209@berkeley.edu>

Thanks *VERY* much, this is great!

I realized a few more cases, I think I've got something that 
covers all the possibilities now:


library(stringr)
tmpstr = "The first number is: 32.  Another one is: 32.1. 
Here's a number in scientific format, 0.3523e10, and 
another, 0.3523e-10, and a negative, -313.1"

patternslist = NULL
p=0
patternslist[[(p=p+1)]] = "(\\d+)"				# positive integer
patternslist[[(p=p+1)]] = "(-\\d+)"				# negative integer
patternslist[[(p=p+1)]] = "(\\d+\\.\\d+)"		# positive float
patternslist[[(p=p+1)]] = "(\\d+\\.\\d+e\\d+)"	# positive 
float, scientific w. positive power
patternslist[[(p=p+1)]] = "(\\d+\\.\\d+e-\\d+)" # positive 
float, scientific w. negative power
patternslist[[(p=p+1)]] = "(-\\d+\\.\\d+)"		# negative float
patternslist[[(p=p+1)]] = "(-\\d+\\.\\d+e\\d+)"	# negative 
float, scientific w. positive power
patternslist[[(p=p+1)]] = "(-\\d+\\.\\d+e-\\d+)"# negative 
float, scientific w. negative power

patternslist[[(p=p+1)]] = "(\\d+e\\d+)"			# positive int, 
scientific w. positive power
patternslist[[(p=p+1)]] = "(\\d+e-\\d+)" 		# positive int, 
scientific w. negative power
patternslist[[(p=p+1)]] = "(-\\d+e\\d+)"		# negative int, 
scientific w. positive power
patternslist[[(p=p+1)]] = "(-\\d+e-\\d+)"		# negative int, 
scientific w. negative power

pattern = paste(patternslist, collapse="|", sep="")
pattern
as.numeric(str_extract_all(tmpstr,pattern)[[1]])

# A more complex string
tmpstr = "The first number is: 32.  342 342.1   -3234e-10 
3234e-1 Another one is: 32.1. Here's a number in scientific 
format, 0.3523e10, and another, 0.3523e-10, and a negative, 
-313.1"
#pattern = 
"(\\d)+|(-\\d)+|(\\d+\\.\\d+)|(-\\d+\\.\\d+)|(\\d+.\\d+e\\d+)|(\\d+\\.\\d+e-\\d+)|(-\\d+.\\d+e\\d+)|(-\\d+\\.\\d+e-\\d+)"
as.numeric(str_extract_all(tmpstr,pattern)[[1]])



Cheers!
Nick


PS: A function version:


# Extract numbers / get numbers / get all numbers from a 
text string
getnums <- function(tmpstr)
	{
	# Example string
	# tmpstr = "The first number is: 32.  342 342.1   -3234e-10 
  3234e-1 Another one is: 32.1. Here's a number in 
scientific format, 0.3523e10, and another, 0.3523e-10, and a 
negative, -313.1"
	
	library(stringr)
	
# 	patternslist = NULL
# 	p=0
# 	patternslist[[(p=p+1)]] = "(\\d+)"				# positive integer
# 	patternslist[[(p=p+1)]] = "(-\\d+)"				# negative integer
# 	patternslist[[(p=p+1)]] = "(\\d+\\.\\d+)"		# positive float
# 	patternslist[[(p=p+1)]] = "(\\d+\\.\\d+e\\d+)"	# positive 
float, scientific w. positive power
# 	patternslist[[(p=p+1)]] = "(\\d+\\.\\d+e-\\d+)" # 
positive float, scientific w. negative power
# 	patternslist[[(p=p+1)]] = "(-\\d+\\.\\d+)"		# negative float
# 	patternslist[[(p=p+1)]] = "(-\\d+\\.\\d+e\\d+)"	# 
negative float, scientific w. positive power
# 	patternslist[[(p=p+1)]] = "(-\\d+\\.\\d+e-\\d+)"# 
negative float, scientific w. negative power
# 	
# 	patternslist[[(p=p+1)]] = "(\\d+e\\d+)"			# positive int, 
scientific w. positive power
# 	patternslist[[(p=p+1)]] = "(\\d+e-\\d+)" 		# positive 
int, scientific w. negative power
# 	patternslist[[(p=p+1)]] = "(-\\d+e\\d+)"		# negative int, 
scientific w. positive power
# 	patternslist[[(p=p+1)]] = "(-\\d+e-\\d+)"		# negative 
int, scientific w. negative power
# 	
# 	pattern = paste(patternslist, collapse="|", sep="")

	# set up the pattern
	pattern = 
"(\\d+)|(-\\d+)|(\\d+\\.\\d+)|(\\d+\\.\\d+e\\d+)|(\\d+\\.\\d+e-\\d+)|(-\\d+\\.\\d+)|(-\\d+\\.\\d+e\\d+)|(-\\d+\\.\\d+e-\\d+)|(\\d+e\\d+)|(\\d+e-\\d+)|(-\\d+e\\d+)|(-\\d+e-\\d+)"
	
	# Get the numbers
	nums_from_tmpstr = 
as.numeric(str_extract_all(tmpstr,pattern)[[1]])

	# Return them
	return(nums_from_tmpstr)
	}












On 6/15/13 10:46 PM, arun wrote:
>
>
> HI,
> One way would be:
>
> library(stringr)
> tmpstr = "The first number is: 32.  Another one is: 32.1.
> Here's a number in scientific format, 0.3523e10, and
> another, 0.3523e-10, and a negative, -313.1"
> pattern<- "(\\d)+|(\\d+\\.\\d+)|(-\\d+\\.\\d+)|(\\d+.\\d+e\\d+)|(\\d+\\.\\d+e-\\d+)"
> str_extract_all(tmpstr,pattern)[[1]]
> #[1] "32"         "32.1"       "0.3523e10"  "0.3523e-10" "-313.1"
>   as.numeric(str_extract_all(tmpstr,pattern)[[1]])
> A.K.
>
>
>
> ----- Original Message -----
> From: Nick Matzke <matzke at berkeley.edu>
> To: R-help at r-project.org
> Cc:
> Sent: Sunday, June 16, 2013 1:06 AM
> Subject: [R] extract all numbers from a string
>
> Hi all,
>
> I have been beating my head against this problem for a bit,
> but I can't figure it out.
>
> I have a series of strings of variable length, and each will
> have one or more numbers, of varying format.  E.g., I might
> have:
>
>
> tmpstr = "The first number is: 32.  Another one is: 32.1.
> Here's a number in scientific format, 0.3523e10, and
> another, 0.3523e-10, and a negative, -313.1"
>
> How could I get R to just give me a list of numerics
> containing the numbers therein?
>
> Thanks very much to the regexp wizards!
>
> Cheers,
> Nick
>
>
>

-- 
====================================================
Nicholas J. Matzke
Ph.D. Candidate, Graduate Student Researcher

Huelsenbeck Lab
Center for Theoretical Evolutionary Genomics
4151 VLSB (Valley Life Sciences Building)
Department of Integrative Biology
University of California, Berkeley

Graduate Student Instructor, IB200B
Principles of Phylogenetics: Ecology and Evolution
http://ib.berkeley.edu/courses/ib200b/
http://phylo.wikidot.com/


Lab websites:
http://ib.berkeley.edu/people/lab_detail.php?lab=54
http://fisher.berkeley.edu/cteg/hlab.html
Dept. personal page: 
http://ib.berkeley.edu/people/students/person_detail.php?person=370
Lab personal page: 
http://fisher.berkeley.edu/cteg/members/matzke.html
Lab phone: 510-643-6299
Dept. fax: 510-643-6264

Cell phone: 510-301-0179
Email: matzke at berkeley.edu

Mailing address:
Department of Integrative Biology
1005 Valley Life Sciences Building #3140
Berkeley, CA 94720-3140

-----------------------------------------------------
"[W]hen people thought the earth was flat, they were wrong. 
When people thought the earth was spherical, they were 
wrong. But if you think that thinking the earth is spherical 
is just as wrong as thinking the earth is flat, then your 
view is wronger than both of them put together."

Isaac Asimov (1989). "The Relativity of Wrong." The 
Skeptical Inquirer, 14(1), 35-44. Fall 1989.
http://chem.tufts.edu/AnswersInScience/RelativityofWrong.htm


From smartpink111 at yahoo.com  Mon Jun 17 03:33:28 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 16 Jun 2013 18:33:28 -0700 (PDT)
Subject: [R] matched samples, dataframe, panel data
In-Reply-To: <104083AE5AAA634C993249DFCCE4C20306446735@CIPRESTE.ua.pt>
References: <104083AE5AAA634C993249DFCCE4C20306440637@CIPRESTE.ua.pt>
	<1371247502.28146.YahooMailNeo@web142603.mail.bf1.yahoo.com>,
	<1371247789.33449.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<104083AE5AAA634C993249DFCCE4C20306446735@CIPRESTE.ua.pt>
Message-ID: <1371432808.43522.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
This gives me more combinations than you got with SAS.? Also, this selects the one with minimum dimension between duplicates.


final3New<-read.table(file="real_data_cecilia.txt",sep="\t",header=T)
final3New1<-read.csv("real_data_cecilia_new.csv")

fun3<- function(dat){
??? ??? if(any(duplicated(dat))){
??? ?????? ??? indx<- which(duplicated(dat))
??? ??? row.names(dat)<-1:nrow(dat)
??? ? ??? dat1<- subset(dat[indx,],dummy==1)
??? ? ??? dat0<- subset(dat[indx,],dummy==0)
??? ? ??? indx1<- as.numeric(row.names(dat1))
??? ???? indx11<- sort(c(indx1,indx1+1))
??? ???? indx0<- as.numeric(row.names(dat0))
??? ???? indx00<- sort(c(indx0,indx0-1))
??? ? ??? indx10<- sort(c(indx11,indx00))
??? ???? res <- dat[-indx10,]
??? ??? res
??? ??? }
??? ??? else {
??? ??? ??? dat
??? ??? }
??? ??? }

fun1New<-function(dat,percent,number){
??? lst1<- split(dat,list(dat$year,dat$industry))
??? lst2<- lst1[lapply(lst1,nrow)>1]
??? lst3<- lapply(lst2,function(x) {
??? ??? ??? ??? ??? CombN1<-combn(seq_len(nrow(x)),2)
??? ??? ??? ??? ??? lapply(split(CombN1,col(CombN1)),function(y){
??? ??? ??? ??? ??? ??? ??? x1<-x[y,]
??? ??? ??? ??? ??? ??? ??? x1[sum(x1$dummy)==1,]
??? ??? ??? ??? ??? ??? ??? })
??? ??? ??? ??? ??? })

??????? lst4<- lapply(lst3,function(x) x[lapply(x,nrow)>0])
??? lst5<- lst4[lapply(lst4,length)>0]
??? lst6<- lapply(lst5,function(x){
??? ??? ??? ??? ?? lapply(x,function(y){
??? ??? ??? ??? ??? x1<- abs(diff(y$dimension))< number
??? ??? ??? ??? ??? x2<- y$dimension[2]+ (y$dimension[2]*percent)
??? ??? ??? ??? ??? x3<- y$dimension[2]- (y$dimension[2]*percent)
??? ??? ??? ??? ??? x4<- y$dimension[1]+ (y$dimension[1]*percent)
??? ??? ??? ??? ??? x5<- y$dimension[1]- (y$dimension[1]*percent)
??? ??? ??? ??? ??? x6<- (y$dimension[1] < x2) & (y$dimension[1] > x3)
??? ??? ??? ??? ??? x7<- (y$dimension[2]< x4) & (y$dimension[2]> x5)
??? ??? ??? ??? ??? ??? y[((x6 & x1)| (x7 & x1)),]
??? ??? ??? ??? ??? })
??? ??? ??? ??? ??? }
??? ??? ??? ??? ??? )
??? lst7<- lapply(lst6,function(x) x[lapply(x,nrow)>0])
??? lst8<- lst7[lapply(lst7,length)>0]
??? lst9<- lapply(lst8,function(x) do.call(rbind,x))
??? lst10<-lapply(lst9,function(x) {
??? ??? ??? ??? row.names(x)<- 1:nrow(x)
??? ??? ??? ??? x1<-x[x$dummy==1,]
??? ??? ??? ??? do.call(rbind,lapply(split(x1,x1$dimension),function(y){
??? ??? ??? ??? ????? indx1<-sort(c(as.numeric(row.names(y)),as.numeric(row.names(y))+1))
??? ??? ??? ??? ????? x2<-x[indx1,]
??? ??? ??? ??? ????? x3<- subset(x2,dummy==0)
??? ??? ??? ??? ????? x4<-x3[which.min(abs(x2$dimension[1]-x3$dimension)),]
??? ??? ??? ??? ????? rbind(x2[1,],x4)
??? ??? ??? ??? ??? }))
??? ??? ??? ??? ??? })
?????? res<- do.call(rbind,lapply(lst10,fun3))
?????? row.names(res)<- 1:nrow(res)
??? res
??? }


??? ??? 
???? 

####1st dataset

res10PercentHigh<- fun1New(final3New,0.10,500000000)
?dim(res10PercentHigh)
#[1] 764?? 5
?dim(unique(res10PercentHigh))
#[1] 764?? 5
?nrow(subset(res10PercentHigh,dummy==0))
#[1] 382
?nrow(subset(res10PercentHigh,dummy==1))
#[1] 382
res10PercentLow<- fun1New(final3New,0.10,50)
?dim(res10PercentLow)
#[1] 294?? 5
?dim(unique(res10PercentLow))
#[1] 294?? 5
?nrow(subset(res10PercentLow,dummy==0))
#[1] 147
?nrow(subset(res10PercentLow,dummy==1))
#[1] 147

res5PercentHigh<- fun1New(final3New,0.05,500000000)
?dim(res5PercentHigh)
#[1] 630?? 5
?dim(unique(res5PercentHigh))
#[1] 630?? 5
?nrow(subset(res5PercentHigh,dummy==0))
#[1] 315
?nrow(subset(res5PercentHigh,dummy==1))
#[1] 315

res5PercentLow<- fun1New(final3New,0.05,50)
?dim(res5PercentLow)
#[1] 294?? 5

?dim(unique(res5PercentLow))
#[1] 294?? 5
?nrow(subset(res5PercentLow,dummy==0))
#[1] 147
?nrow(subset(res5PercentLow,dummy==1))
#[1] 147

#######2nd dataset
res10PercentHigh<- fun1New(final3New1,0.10,500000000)
?dim(res10PercentHigh)
#[1] 760?? 5
?dim(unique(res10PercentHigh))
#[1] 760?? 5

?nrow(subset(res10PercentHigh,dummy==0))
#[1] 380
?nrow(subset(res10PercentHigh,dummy==1))
#[1] 380
res10PercentLow<- fun1New(final3New1,0.10,100)
?dim(res10PercentLow)
#[1] 418?? 5

?dim(unique(res10PercentLow))
#[1] 418?? 5
?nrow(subset(res10PercentLow,dummy==0))
#[1] 209
?nrow(subset(res10PercentLow,dummy==1))
#[1] 209


res5PercentHigh<- fun1New(final3New1,0.05,500000000)
?dim(res5PercentHigh)
#[1] 640?? 5
?dim(unique(res5PercentHigh))
#[1] 640?? 5

?nrow(subset(res5PercentHigh,dummy==0))
#[1] 320
?nrow(subset(res5PercentHigh,dummy==1))
#[1] 320
res5PercentLow<- fun1New(final3New1,0.05,50)
?dim(res5PercentLow)
#[1] 310?? 5

?dim(unique(res5PercentLow))
#[1] 310?? 5
?nrow(subset(res5PercentLow,dummy==0))
#[1] 155
?nrow(subset(res5PercentLow,dummy==1))
#[1] 155

res20PercentHigh<- fun1New(final3New1,0.20,500000000)
dim(res20PercentHigh)
#[1] 846?? 5

?dim(unique(res20PercentHigh))
#[1] 846?? 5

?nrow(subset(res20PercentHigh,dummy==0))
#[1] 423
?nrow(subset(res20PercentHigh,dummy==1))
#[1] 423


A.K.

----- Original Message -----
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Cc: 
Sent: Sunday, June 16, 2013 5:57 AM
Subject: RE: matched samples, dataframe, panel data

In the script I send you and with the file that? I sent with it and with the old function 1 and 2 
it got 350 combinations and it was possible to have more

Now with new fun 1 and 3 I have less, so it is not ok, does it?

> res10Percent<- fun1New(final3New2,0.10,500000000)
> res10F3<- fun3(res10Percent)
> dim(res10F3)
[1] 600?  5
> nrow(subset(res10F3,dummy==0))
[1] 300
> nrow(subset(res10F3,dummy==1))
[1] 300

Sorry for making you spending so much time. I thought it could be easier.

Cec?lia

________________________________________
De: arun [smartpink111 at yahoo.com]
Enviado: sexta-feira, 14 de Junho de 2013 23:09
Para: Cecilia Carmo
Assunto: Re: matched samples, dataframe, panel data

One thing I forgot to mention.? I used fun3() because i found fun2() still have some problems with getting the correct dimensions.? You can check the results of fun1() and fun3() and see if all the combinations are got.? Then, if I get chance, I will correct fun2().
"""""
And you conclude that they are the same!
"""""""
Here, also I am not concluding anything.
A.K.


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Cecilia Carmo <cecilia.carmo at ua.pt>
Cc: R help <r-help at r-project.org>
Sent: Friday, June 14, 2013 6:05 PM
Subject: Re: matched samples, dataframe, panel data

Hi,
I changed the fun1().? Now, it should be possible to get all the possible combinations within each group.


final3New<-read.table(file="real_data_cecilia.txt",sep="\t",header=T)
final3New1<-read.csv("real_data_cecilia_new.csv")
fun1New<- function(dat,percent,number){
? ? lst1<- split(dat,list(dat$year,dat$industry))
? ? lst2<- lst1[lapply(lst1,nrow)>1]
? ? lst3<- lapply(lst2,function(x) {
? ? ? ? ? ? ? ? ? ? CombN1<-combn(seq_len(nrow(x)),2)
? ? ? ? ? ? ? ? ? ? lapply(split(CombN1,col(CombN1)),function(y){
? ? ? ? ? ? ? ? ? ? ? ? ? ? x1<-x[y,]
? ? ? ? ? ? ? ? ? ? ? ? ? ? x1[sum(x1$dummy)==1,]
? ? ? ? ? ? ? ? ? ? ? ? ? ? })
? ? ? ? ? ? ? ? ? ? })

? ? ? ? lst4<- lapply(lst3,function(x) x[lapply(x,nrow)>0])
? ? lst5<- lst4[lapply(lst4,length)>0]
? ? lst6<- lapply(lst5,function(x){
? ? ? ? ? ? ? ? ?  lapply(x,function(y){
? ? ? ? ? ? ? ? ? ? x1<- abs(diff(y$dimension))< number
? ? ? ? ? ? ? ? ? ? x2<- y$dimension[2]+ (y$dimension[2]*percent)
? ? ? ? ? ? ? ? ? ? x3<- y$dimension[2]- (y$dimension[2]*percent)
? ? ? ? ? ? ? ? ? ? x4<- (y$dimension[1] < x2) & (y$dimension[1] > x3)
? ? ? ? ? ? ? ? ? ? y[x4 & x1,]
? ? ? ? ? ? ? ? ? ? })
? ? ? ? ? ? ? ? ? ? }
? ? ? ? ? ? ? ? ? ? )
? ? lst7<- lapply(lst6,function(x) x[lapply(x,nrow)>0])
? ? lst8<- lst7[lapply(lst7,length)>0]
? ? res<- do.call(rbind,lapply(lst8,function(x){
? ? ? ? ? ? ? ? ? ? ? ? ?  do.call(rbind,x)
? ? ? ? ? ? ? ? ? ? ? ? }))
? ? row.names(res)<- 1:nrow(res)
? ? res
? ? }? 

##Applying fun1New
res5Percent<- fun1New(final3New,0.05,50)
dim(res5Percent)
#[1] 718?  5
res5PercentHigh<- fun1New(final3New,0.05,500000)
dim(res5PercentHigh)
#[1] 2788? ? 5

res5Percent1<- fun1New(final3New1,0.05,50)
dim(res5Percent1)
#[1] 870?  5
res5Percent1High<- fun1New(final3New1,0.05,500000)
dim(res5Percent1High)
#[1] 2902? ? 5

res10Percent<- fun1New(final3New,0.10,200)
dim(res10Percent)
#[1] 2928? ? 5
res10Percent1<- fun1New(final3New1,0.10,200)
dim(res10Percent1)
#[1] 3092? ? 5

fun3<- function(dat){
? ? ? ? ? indx<- duplicated(dat)
? ? ? dat1<- subset(dat[indx,],dummy==1)
? ? ? dat0<- subset(dat[indx,],dummy==0)
? ? ? indx1<- as.numeric(row.names(dat1))
? ?  indx11<- sort(c(indx1,indx1+1))
? ?  indx0<- as.numeric(row.names(dat0))
? ?  indx00<- sort(c(indx0,indx0-1))
? ? ? indx10<- sort(c(indx11,indx00))
? ?  res <- dat[-indx10,]
? ? res
? ? }




#Applying fun3()
res5F3<- fun3(res5Percent)
dim(res5F3)
#[1] 278?  5

res5F3High<- fun3(res5PercentHigh)
dim(res5F3High)
#[1] 546?  5

res5F3_1<- fun3(res5Percent1)
#[1] 302?  5
res5F3High_1<- fun3(res5Percent1High)
dim(res5F3High_1)
#[1] 570?  5

res10F3<- fun3(res10Percent)
dim(res10F3)
#[1] 462?  5
res10F3_1<- fun3(res10Percent1)
#[1] 474?  5
nrow(subset(res5F3,dummy==0))
#[1] 139
nrow(subset(res5F3,dummy==1))
#[1] 139


nrow(subset(res5F3High,dummy==1))
#[1] 273
nrow(subset(res5F3High,dummy==0))
#[1] 273


nrow(subset(res10F3,dummy==0))
#[1] 231
nrow(subset(res10F3,dummy==1))
#[1] 231
nrow(subset(res10F3_1,dummy==1))
#[1] 237
nrow(subset(res10F3_1,dummy==0))
#[1] 237
dim(unique(res5F3))
#[1] 278?  5
dim(unique(res5F3High))
#[1] 546?  5

dim(unique(res10F3_1))
#[1] 474?  5
dim(unique(res10F3))
#[1] 462?  5
A.K.



________________________________
From: Cecilia Carmo <cecilia.carmo at ua.pt>
To: arun <smartpink111 at yahoo.com>
Sent: Friday, June 14, 2013 10:44 AM
Subject: me again




There some matchs that are missing. That is, it is possible to have more matchs.
I'm sending you a sript and the data.

Than you.
Cec?lia

From cassiejones26 at gmail.com  Mon Jun 17 03:46:56 2013
From: cassiejones26 at gmail.com (cassie jones)
Date: Sun, 16 Jun 2013 20:46:56 -0500
Subject: [R] problem with input of integrate function
Message-ID: <CAFkmApMEz3TyunkPshzVdGXowu=2bsKXvvTOsFW11YKagAV2yQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130616/edd58ee0/attachment.pl>

From dwinsemius at comcast.net  Mon Jun 17 04:15:39 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 16 Jun 2013 19:15:39 -0700
Subject: [R] problem with input of integrate function
In-Reply-To: <CAFkmApMEz3TyunkPshzVdGXowu=2bsKXvvTOsFW11YKagAV2yQ@mail.gmail.com>
References: <CAFkmApMEz3TyunkPshzVdGXowu=2bsKXvvTOsFW11YKagAV2yQ@mail.gmail.com>
Message-ID: <E7C22FFB-06A5-4A57-AFCE-036A9F74CEA6@comcast.net>


On Jun 16, 2013, at 6:46 PM, cassie jones wrote:

> Dear R-users,
> 
> I am trying to integrate a function using integrate command in R.
> The function is as follows,
> 
> integrand
> function(x,a)
> {
> exp(-0.5*a*(1+x^2))/(1+x^2)
> }
> 
> Now while I want to integrate it using the command integrate, I get the
> following error,
> 
> integrate(integrand(x,2),0,inf)
> 
> Error in match.fun(f) :
>  'integrand(x, 2)' is not a function, character or symbol
> 
> I understand that the argument of integrate needs to be solely dependent on
> x, that is why it is not able to recognize the input as there are both x
> and a. But I need to have the integrand dependent on the variable a. Does
> anyone know how can I handle the problem? Any help is appreciated.

You also misspelled `Inf`

> integrand <- function(x,a=2)
+ {
+ exp(-0.5*a*(1+x^2))/(1+x^2)
+ }
> 
> integrate(integrand,0,Inf)
0.247085 with absolute error < 3e-05


> 
> Thanks in advance.
> 
> -Cassie
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Mon Jun 17 04:19:01 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 16 Jun 2013 19:19:01 -0700
Subject: [R] problem with input of integrate function
In-Reply-To: <E7C22FFB-06A5-4A57-AFCE-036A9F74CEA6@comcast.net>
References: <CAFkmApMEz3TyunkPshzVdGXowu=2bsKXvvTOsFW11YKagAV2yQ@mail.gmail.com>
	<E7C22FFB-06A5-4A57-AFCE-036A9F74CEA6@comcast.net>
Message-ID: <B7371851-0B29-4A84-A15F-69C27AA7B408@comcast.net>


On Jun 16, 2013, at 7:15 PM, David Winsemius wrote:

> 
> On Jun 16, 2013, at 6:46 PM, cassie jones wrote:
> 
>> Dear R-users,
>> 
>> I am trying to integrate a function using integrate command in R.
>> The function is as follows,
>> 
>> integrand
>> function(x,a)
>> {
>> exp(-0.5*a*(1+x^2))/(1+x^2)
>> }
>> 
>> Now while I want to integrate it using the command integrate, I get the
>> following error,
>> 
>> integrate(integrand(x,2),0,inf)
>> 
>> Error in match.fun(f) :
>> 'integrand(x, 2)' is not a function, character or symbol
>> 
>> I understand that the argument of integrate needs to be solely dependent on
>> x, that is why it is not able to recognize the input as there are both x
>> and a. But I need to have the integrand dependent on the variable a. Does
>> anyone know how can I handle the problem? Any help is appreciated.
> 
> You also misspelled `Inf`
> 
>> integrand <- function(x,a=2)
> + {
> + exp(-0.5*a*(1+x^2))/(1+x^2)
> + }
>> 
>> integrate(integrand,0,Inf)
> 0.247085 with absolute error < 3e-05

Can also use '..." argument:

?integrate

 integrand <- function(x,a)
 {
 exp(-0.5*a*(1+x^2))/(1+x^2)
 }
 
 integrate(integrand,0,Inf, a=2)
# 0.247085 with absolute error < 3e-05
> 
> 
>> 
>> Thanks in advance.
>> 
>> -Cassie
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From cassiejones26 at gmail.com  Mon Jun 17 05:12:27 2013
From: cassiejones26 at gmail.com (cassie jones)
Date: Sun, 16 Jun 2013 22:12:27 -0500
Subject: [R] problem with input of integrate function
In-Reply-To: <B7371851-0B29-4A84-A15F-69C27AA7B408@comcast.net>
References: <CAFkmApMEz3TyunkPshzVdGXowu=2bsKXvvTOsFW11YKagAV2yQ@mail.gmail.com>
	<E7C22FFB-06A5-4A57-AFCE-036A9F74CEA6@comcast.net>
	<B7371851-0B29-4A84-A15F-69C27AA7B408@comcast.net>
Message-ID: <CAFkmApPWLGBVC9vPG1Jo3uDt1g7X-yk7+arJ-xYUYi-YKxcvmQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130616/c622a88f/attachment.pl>

From ggrothendieck at gmail.com  Mon Jun 17 05:42:44 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 16 Jun 2013 23:42:44 -0400
Subject: [R] extract all numbers from a string
In-Reply-To: <51BE5FC1.9020209@berkeley.edu>
References: <51BD47E3.6090808@berkeley.edu>
	<1371361614.53710.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<51BE5FC1.9020209@berkeley.edu>
Message-ID: <CAP01uRn01UgFUj7AHV6308_nTa1GrbNuO7dYzL8ngipjAus1jg@mail.gmail.com>

On Sun, Jun 16, 2013 at 9:00 PM, Nick Matzke <matzke at berkeley.edu> wrote:
> Thanks *VERY* much, this is great!
>
> I realized a few more cases, I think I've got something that covers all the
> possibilities now:
>
>
>
> library(stringr)
> tmpstr = "The first number is: 32.  Another one is: 32.1. Here's a number in
> scientific format, 0.3523e10, and another, 0.3523e-10, and a negative,
> -313.1"
>
> patternslist = NULL
> p=0
> patternslist[[(p=p+1)]] = "(\\d+)"                              # positive
> integer
> patternslist[[(p=p+1)]] = "(-\\d+)"                             # negative
> integer
> patternslist[[(p=p+1)]] = "(\\d+\\.\\d+)"               # positive float
> patternslist[[(p=p+1)]] = "(\\d+\\.\\d+e\\d+)"  # positive float, scientific
> w. positive power
> patternslist[[(p=p+1)]] = "(\\d+\\.\\d+e-\\d+)" # positive float, scientific
> w. negative power
> patternslist[[(p=p+1)]] = "(-\\d+\\.\\d+)"              # negative float
> patternslist[[(p=p+1)]] = "(-\\d+\\.\\d+e\\d+)" # negative float, scientific
> w. positive power
> patternslist[[(p=p+1)]] = "(-\\d+\\.\\d+e-\\d+)"# negative float, scientific
> w. negative power
>
> patternslist[[(p=p+1)]] = "(\\d+e\\d+)"                 # positive int,
> scientific w. positive power
> patternslist[[(p=p+1)]] = "(\\d+e-\\d+)"                # positive int,
> scientific w. negative power
> patternslist[[(p=p+1)]] = "(-\\d+e\\d+)"                # negative int,
> scientific w. positive power
> patternslist[[(p=p+1)]] = "(-\\d+e-\\d+)"               # negative int,
> scientific w. negative power
>
> pattern = paste(patternslist, collapse="|", sep="")
> pattern
> as.numeric(str_extract_all(tmpstr,pattern)[[1]])
>
> # A more complex string
> tmpstr = "The first number is: 32.  342 342.1   -3234e-10 3234e-1 Another
> one is: 32.1. Here's a number in scientific format, 0.3523e10, and another,
> 0.3523e-10, and a negative, -313.1"
> #pattern =
> "(\\d)+|(-\\d)+|(\\d+\\.\\d+)|(-\\d+\\.\\d+)|(\\d+.\\d+e\\d+)|(\\d+\\.\\d+e-\\d+)|(-\\d+.\\d+e\\d+)|(-\\d+\\.\\d+e-\\d+)"
> as.numeric(str_extract_all(tmpstr,pattern)[[1]])

This much simpler single pattern may be good enough:

> library(gsubfn)
> pat <- "[-+.e0-9]*\\d"
> strapplyc(tmpstr, pat)[[1]]
[1] "32"         "342"        "342.1"      "-3234e-10"  "3234e-1"
[6] "32.1"       "0.3523e10"  "0.3523e-10" "-313.1"
> strapply(tmpstr, pat, as.numeric)[[1]]
[1]  3.200e+01  3.420e+02  3.421e+02 -3.234e-07  3.234e+02  3.210e+01  3.523e+09
[8]  3.523e-11 -3.131e+02

--
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From matzke at berkeley.edu  Mon Jun 17 08:31:20 2013
From: matzke at berkeley.edu (Nick Matzke)
Date: Sun, 16 Jun 2013 23:31:20 -0700
Subject: [R] extract all numbers from a string
In-Reply-To: <CAP01uRn01UgFUj7AHV6308_nTa1GrbNuO7dYzL8ngipjAus1jg@mail.gmail.com>
References: <51BD47E3.6090808@berkeley.edu>
	<1371361614.53710.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<51BE5FC1.9020209@berkeley.edu>
	<CAP01uRn01UgFUj7AHV6308_nTa1GrbNuO7dYzL8ngipjAus1jg@mail.gmail.com>
Message-ID: <51BEAD38.1070508@berkeley.edu>

Ooh, nice! Thanks!
Nick


On 6/16/13 8:42 PM, Gabor Grothendieck wrote:
> On Sun, Jun 16, 2013 at 9:00 PM, Nick Matzke <matzke at berkeley.edu> wrote:
>> Thanks *VERY* much, this is great!
>>
>> I realized a few more cases, I think I've got something that covers all the
>> possibilities now:
>>
>>
>>
>> library(stringr)
>> tmpstr = "The first number is: 32.  Another one is: 32.1. Here's a number in
>> scientific format, 0.3523e10, and another, 0.3523e-10, and a negative,
>> -313.1"
>>
>> patternslist = NULL
>> p=0
>> patternslist[[(p=p+1)]] = "(\\d+)"                              # positive
>> integer
>> patternslist[[(p=p+1)]] = "(-\\d+)"                             # negative
>> integer
>> patternslist[[(p=p+1)]] = "(\\d+\\.\\d+)"               # positive float
>> patternslist[[(p=p+1)]] = "(\\d+\\.\\d+e\\d+)"  # positive float, scientific
>> w. positive power
>> patternslist[[(p=p+1)]] = "(\\d+\\.\\d+e-\\d+)" # positive float, scientific
>> w. negative power
>> patternslist[[(p=p+1)]] = "(-\\d+\\.\\d+)"              # negative float
>> patternslist[[(p=p+1)]] = "(-\\d+\\.\\d+e\\d+)" # negative float, scientific
>> w. positive power
>> patternslist[[(p=p+1)]] = "(-\\d+\\.\\d+e-\\d+)"# negative float, scientific
>> w. negative power
>>
>> patternslist[[(p=p+1)]] = "(\\d+e\\d+)"                 # positive int,
>> scientific w. positive power
>> patternslist[[(p=p+1)]] = "(\\d+e-\\d+)"                # positive int,
>> scientific w. negative power
>> patternslist[[(p=p+1)]] = "(-\\d+e\\d+)"                # negative int,
>> scientific w. positive power
>> patternslist[[(p=p+1)]] = "(-\\d+e-\\d+)"               # negative int,
>> scientific w. negative power
>>
>> pattern = paste(patternslist, collapse="|", sep="")
>> pattern
>> as.numeric(str_extract_all(tmpstr,pattern)[[1]])
>>
>> # A more complex string
>> tmpstr = "The first number is: 32.  342 342.1   -3234e-10 3234e-1 Another
>> one is: 32.1. Here's a number in scientific format, 0.3523e10, and another,
>> 0.3523e-10, and a negative, -313.1"
>> #pattern =
>> "(\\d)+|(-\\d)+|(\\d+\\.\\d+)|(-\\d+\\.\\d+)|(\\d+.\\d+e\\d+)|(\\d+\\.\\d+e-\\d+)|(-\\d+.\\d+e\\d+)|(-\\d+\\.\\d+e-\\d+)"
>> as.numeric(str_extract_all(tmpstr,pattern)[[1]])
>
> This much simpler single pattern may be good enough:
>
>> library(gsubfn)
>> pat <- "[-+.e0-9]*\\d"
>> strapplyc(tmpstr, pat)[[1]]
> [1] "32"         "342"        "342.1"      "-3234e-10"  "3234e-1"
> [6] "32.1"       "0.3523e10"  "0.3523e-10" "-313.1"
>> strapply(tmpstr, pat, as.numeric)[[1]]
> [1]  3.200e+01  3.420e+02  3.421e+02 -3.234e-07  3.234e+02  3.210e+01  3.523e+09
> [8]  3.523e-11 -3.131e+02
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
>

-- 
====================================================
Nicholas J. Matzke
Ph.D. Candidate, Graduate Student Researcher

Huelsenbeck Lab
Center for Theoretical Evolutionary Genomics
4151 VLSB (Valley Life Sciences Building)
Department of Integrative Biology
University of California, Berkeley

Graduate Student Instructor, IB200B
Principles of Phylogenetics: Ecology and Evolution
http://ib.berkeley.edu/courses/ib200b/
http://phylo.wikidot.com/


Lab websites:
http://ib.berkeley.edu/people/lab_detail.php?lab=54
http://fisher.berkeley.edu/cteg/hlab.html
Dept. personal page: 
http://ib.berkeley.edu/people/students/person_detail.php?person=370
Lab personal page: 
http://fisher.berkeley.edu/cteg/members/matzke.html
Lab phone: 510-643-6299
Dept. fax: 510-643-6264

Cell phone: 510-301-0179
Email: matzke at berkeley.edu

Mailing address:
Department of Integrative Biology
1005 Valley Life Sciences Building #3140
Berkeley, CA 94720-3140

-----------------------------------------------------
"[W]hen people thought the earth was flat, they were wrong. 
When people thought the earth was spherical, they were 
wrong. But if you think that thinking the earth is spherical 
is just as wrong as thinking the earth is flat, then your 
view is wronger than both of them put together."

Isaac Asimov (1989). "The Relativity of Wrong." The 
Skeptical Inquirer, 14(1), 35-44. Fall 1989.
http://chem.tufts.edu/AnswersInScience/RelativityofWrong.htm


From erinm.hodgess at gmail.com  Mon Jun 17 08:32:16 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Mon, 17 Jun 2013 01:32:16 -0500
Subject: [R]  R-3.0.1 for Centos 5?
Message-ID: <CACxE24kP_ZU_mWBYh2_rBbXHB7bsfwe5AdWgM4C8xCjiYGpZxw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130617/4baea8df/attachment.pl>

From alexandre.piche at mail.mcgill.ca  Mon Jun 17 08:22:44 2013
From: alexandre.piche at mail.mcgill.ca (AlexPiche)
Date: Sun, 16 Jun 2013 23:22:44 -0700 (PDT)
Subject: [R] Data frame to Matrix by category
Message-ID: <1371450164950-4669669.post@n4.nabble.com>

Hello Folks,

I try to use plyr and reshape 2 to take a data frame of the form:

> head(cf_dt)
          isin         dt
1 FR0109970386 2010-01-12
2 FR0109970386 2011-01-12
3 FR0109970386 2012-01-12
4 FR0116114978 2010-01-12
5 FR0116114978 2011-01-12
6 FR0116114978 2012-01-12

 to create a matrix of the form 

FR0109970386     FR0116114978       ...
2010-01-12                2010-01-12          ...
2011-01-12                2011-01-12          ...
2012-01-12                2012-01-12          ...
NA                                      ....                    ...
...                                         NA                   ...
NA                                      NA                   ....

I would like to have 22 columns and 33 rows, since I have 22 bonds name and
my longest cash flow is 33 dates long.

Regards,

Alex





--
View this message in context: http://r.789695.n4.nabble.com/Data-frame-to-Matrix-by-category-tp4669669.html
Sent from the R help mailing list archive at Nabble.com.


From michael.weylandt at gmail.com  Mon Jun 17 08:44:00 2013
From: michael.weylandt at gmail.com (Michael Weylandt)
Date: Mon, 17 Jun 2013 07:44:00 +0100
Subject: [R] R-3.0.1 for Centos 5?
In-Reply-To: <CACxE24kP_ZU_mWBYh2_rBbXHB7bsfwe5AdWgM4C8xCjiYGpZxw@mail.gmail.com>
References: <CACxE24kP_ZU_mWBYh2_rBbXHB7bsfwe5AdWgM4C8xCjiYGpZxw@mail.gmail.com>
Message-ID: <4189CCAC-BD05-48F9-92A1-D984A2E996E5@gmail.com>



On Jun 17, 2013, at 7:32, Erin Hodgess <erinm.hodgess at gmail.com> wrote:

> Dear R People:
> 
> I am working with a Centos 5 machine and would like to install R-3.0.1.
> 
> However, the only version that shows up "automatically" is R-2.15.2.
> 
> I have tried the following:
> 
> root at erinminfo [~]# wget
> http://dl.fedoraproject.org/pub/epel/5/x86_64/epel-release-5-4.noarch.rpm
> --2013-06-17 06:20:30--
> http://dl.fedoraproject.org/pub/epel/5/x86_64/epel-release-5-4.noarch.rpm
> Resolving dl.fedoraproject.org... 209.132.181.26, 209.132.181.27,
> 209.132.181.23, ...
> Connecting to dl.fedoraproject.org|209.132.181.26|:80... connected.
> HTTP request sent, awaiting response... 200 OK
> Length: 12232 (12K) [application/x-rpm]
> Saving to: `epel-release-5-4.noarch.rpm'
> 
> 100%[======================================>] 12,232      --.-K/s   in
> 0.06s
> 
> 2013-06-17 06:20:30 (196 KB/s) - `epel-release-5-4.noarch.rpm' saved
> [12232/12232]
> 
> root at erinminfo [~]# wget
> http://rpms.famillecollet.com/enterprise/remi-release-5.rpm
> --2013-06-17 06:20:30--
> http://rpms.famillecollet.com/enterprise/remi-release-5.rpm
> Resolving rpms.famillecollet.com... 88.191.74.232,
> 2a01:e0b:1:74:2e0:f4ff:fe1b:b827
> Connecting to rpms.famillecollet.com|88.191.74.232|:80... connected.
> HTTP request sent, awaiting response... 200 OK
> Length: 5180 (5.1K) [application/x-rpm]
> Saving to: `remi-release-5.rpm'
> 
> 100%[======================================>] 5,180       --.-K/s   in
> 0.1s
> 
> 2013-06-17 06:20:31 (50.9 KB/s) - `remi-release-5.rpm' saved [5180/5180]
> 
> root at erinminfo [~]# sudo rpm -Uvh remi-release-5*.rpm epel-release-5*.rpm
> warning: remi-release-5.rpm: Header V3 DSA signature: NOKEY, key ID 00f97f56
> Preparing...                ###########################################
> [100%]
>    package epel-release-5-4.noarch is already installed
> root at erinminfo [~]# cd /etc/yum.repos.d
> root at erinminfo [/etc/yum.repos.d]# ls
> ./   CentOS-Base.repo       CentOS-Media.repo  dag.repo   epel-testing.repo
> ../  CentOS-Debuginfo.repo  CentOS-Vault.repo  epel.repo  r1soft.repo
> root at erinminfo [/etc/yum.repos.d]# cd
> root at erinminfo [~]# find / -name remi-release-5.rpm
> /root/remi-release-5.rpm
> 
> root at erinminfo [~]# sudo nano remi-release-5.rpm
> root at erinminfo [~]# ls remi*
> remi-release-5.rpm  remi-release-6.rpm.1
> remi-release-6.rpm  remi-release-6.rpm.2
> root at erinminfo [~]# wget http://rpms.famillecollet.com/enterprise/remi.repo
> --2013-06-17 06:24:05--  http://rpms.famillecollet.com/enterprise/remi.repo
> Resolving rpms.famillecollet.com... 88.191.74.232,
> 2a01:e0b:1:74:2e0:f4ff:fe1b:b827
> Connecting to rpms.famillecollet.com|88.191.74.232|:80... connected.
> HTTP request sent, awaiting response... 200 OK
> Length: 645 [text/plain]
> Saving to: `remi.repo'
> 
> 100%[======================================>] 645         --.-K/s   in
> 0s
> 
> 2013-06-17 06:24:06 (38.4 MB/s) - `remi.repo' saved [645/645]
> 
> root at erinminfo [~]# ls remi*
> remi-release-5.rpm  remi-release-6.rpm.1  remi.repo
> remi-release-6.rpm  remi-release-6.rpm.2
> root at erinminfo [~]# sudo nano remi-repo
> root at erinminfo [~]# sudo nano remi.repo
> root at erinminfo [~]# sudo yum clean all
> Loaded plugins: fastestmirror, security
> Cleaning up Everything
> root at erinminfo [~]# sudo yum install R
> Loaded plugins: fastestmirror, security
> Determining fastest mirrors
> * base: mirror.thelinuxfix.com
> * epel: mirrors.servercentral.net
> * extras: yum.singlehop.com
> * updates: yum.singlehop.com
> base                                                     | 1.1 kB
> 00:00
> base/primary                                             | 1.2 MB
> 00:00
> base
> 3641/3641
> dag                                                      | 1.9 kB
> 00:00
> dag/primary_db                                           | 7.0 MB
> 01:16
> epel                                                     | 3.6 kB
> 00:00
> epel/primary_db                                          | 3.8 MB
> 00:02
> extras                                                   | 2.1 kB
> 00:00
> extras/primary_db                                        | 188 kB
> 00:00
> updates                                                  | 1.9 kB
> 00:00
> updates/primary_db                                       | 473 kB
> 00:00
> Excluding Packages in global exclude list
> Finished
> Setting up Install Process
> Package R-2.15.2-1.el5.x86_64 already installed and latest version
> Nothing to do
> root at erinminfo [~]# sudo yum upgrade R
> Loaded plugins: fastestmirror, security
> Loading mirror speeds from cached hostfile
> * base: mirror.thelinuxfix.com
> * epel: mirrors.servercentral.net
> * extras: yum.singlehop.com
> * updates: yum.singlehop.com
> Excluding Packages in global exclude list
> Finished
> Skipping security plugin, no data
> Setting up Upgrade Process
> No Packages marked for Update
> root at erinminfo [~]#
> 
> 
> but to no avail.
> 
> Would I be better off compiling from source, please?

Yes; also check out the R-SIG-Fedora list. 

MW

> 
> I have looked and I don't see much about R version 3 on Centos 5.
> 
> Thanks,
> Sincerely,
> Erin
> 
> 
> 
> -- 
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From msuzen at gmail.com  Mon Jun 17 09:11:31 2013
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Mon, 17 Jun 2013 09:11:31 +0200
Subject: [R] Optimization of a function using optim
In-Reply-To: <CAJhGg+0U98D9VhZ+gghvJ8y-AXSqQ=F5uSsi3XeXivC4u1c9Yg@mail.gmail.com>
References: <CAJhGg+0U98D9VhZ+gghvJ8y-AXSqQ=F5uSsi3XeXivC4u1c9Yg@mail.gmail.com>
Message-ID: <CAPtbhHw_6fs5MUkeLnVc1Nx+yGLcW47yj8sP4X8E-TRgv+kDXg@mail.gmail.com>

Dear Graham,

On 16 June 2013 02:08, Graham McDannel <graham.mcdannel at gmail.com> wrote:
> I am attempting to optimize a function I have developed using optim.
>
> I am getting the below error message:
>
> Error in n < 1: 'n' is missing
>

I suspect a function requires an argument named n, and you
didn't pass one.  Either in your objective function or in optim.
See blow example that produce a similar error:
> f <- function(n) {
+    if(n <1) {
+     print("one")
+    }
+ }
> f()
Error in n < 1 : 'n' is missing


Best Wishes,
-m


From dave at mailbox.co.uk  Mon Jun 17 10:14:41 2013
From: dave at mailbox.co.uk (Dave Clark)
Date: Mon, 17 Jun 2013 09:14:41 +0100
Subject: [R] chi square test
Message-ID: <F332F190B39E463F94F2FFE3C2219E8A@DavePC>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130617/2d59134b/attachment.pl>

From michael.weylandt at gmail.com  Mon Jun 17 10:36:35 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Mon, 17 Jun 2013 09:36:35 +0100
Subject: [R] chi square test
In-Reply-To: <F332F190B39E463F94F2FFE3C2219E8A@DavePC>
References: <F332F190B39E463F94F2FFE3C2219E8A@DavePC>
Message-ID: <CAAmySGMuqG9Vn5yYiSepYA-EbqZm22n58k=E3W0KetpSm0MafA@mail.gmail.com>

On Mon, Jun 17, 2013 at 9:14 AM, Dave Clark <dave at mailbox.co.uk> wrote:
> I`m doing the chi square test in R, see below code:
>
>> row1 <- c(27,17,13,21,80,24,35,41,18,51) #Category A (1-10) counts
>> row2 <- c(27,11,26,13,30,28,17,30,10,21) #Category B (1-10) counts
>> data.table <- rbind(row1,row2)
>> data.table
>
> then:
>> chisq.test(data.table)
>
> This gives me the chi figure, degrees of freedom and p value.
>
> But how do I get the results of individual cells?

What do you mean 'results of individual cells'? As documented in
?chisq.test, you might be looking for one or more of

data.table$observed
data.table$expected
data.table$residuals
data.table$stdres

Pick your poison. ;-)

MW

>
> And has anyone got any good ideas on a decent post hoc test to the chi
> square test.
>
> Thanks all in advance,
>
>
>
> Dave Clark
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Mon Jun 17 10:48:42 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 17 Jun 2013 09:48:42 +0100
Subject: [R] Data frame to Matrix by category
In-Reply-To: <1371450164950-4669669.post@n4.nabble.com>
References: <1371450164950-4669669.post@n4.nabble.com>
Message-ID: <51BECD6A.1010401@sapo.pt>

Hello,

Maybe something like the following.



dat <- read.table(text = "
          isin         dt
1 FR0109970386 2010-01-12
2 FR0109970386 2011-01-12
3 FR0109970386 2012-01-12
4 FR0116114978 2010-01-12
5 FR0116114978 2011-01-12
6 FR0116114978 2012-01-12
", header = TRUE, stringsAsFactors = FALSE)

library(reshape2)
dcast(dat, dt ~ isin)[-1]


Hope this helps,

Rui Barradas

Em 17-06-2013 07:22, AlexPiche escreveu:
> Hello Folks,
>
> I try to use plyr and reshape 2 to take a data frame of the form:
>
>> head(cf_dt)
>            isin         dt
> 1 FR0109970386 2010-01-12
> 2 FR0109970386 2011-01-12
> 3 FR0109970386 2012-01-12
> 4 FR0116114978 2010-01-12
> 5 FR0116114978 2011-01-12
> 6 FR0116114978 2012-01-12
>
>   to create a matrix of the form
>
> FR0109970386     FR0116114978       ...
> 2010-01-12                2010-01-12          ...
> 2011-01-12                2011-01-12          ...
> 2012-01-12                2012-01-12          ...
> NA                                      ....                    ...
> ...                                         NA                   ...
> NA                                      NA                   ....
>
> I would like to have 22 columns and 33 rows, since I have 22 bonds name and
> my longest cash flow is 33 dates long.
>
> Regards,
>
> Alex
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Data-frame-to-Matrix-by-category-tp4669669.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pdalgd at gmail.com  Mon Jun 17 11:07:45 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 17 Jun 2013 11:07:45 +0200
Subject: [R] chi square test
In-Reply-To: <CAAmySGMuqG9Vn5yYiSepYA-EbqZm22n58k=E3W0KetpSm0MafA@mail.gmail.com>
References: <F332F190B39E463F94F2FFE3C2219E8A@DavePC>
	<CAAmySGMuqG9Vn5yYiSepYA-EbqZm22n58k=E3W0KetpSm0MafA@mail.gmail.com>
Message-ID: <1E16809E-7E70-48CC-9DDA-4E80662E5757@gmail.com>


On Jun 17, 2013, at 10:36 , R. Michael Weylandt wrote:

> On Mon, Jun 17, 2013 at 9:14 AM, Dave Clark <dave at mailbox.co.uk> wrote:
>> I`m doing the chi square test in R, see below code:
>> 
>>> row1 <- c(27,17,13,21,80,24,35,41,18,51) #Category A (1-10) counts
>>> row2 <- c(27,11,26,13,30,28,17,30,10,21) #Category B (1-10) counts
>>> data.table <- rbind(row1,row2)
>>> data.table
>> 
>> then:
>>> chisq.test(data.table)
>> 
>> This gives me the chi figure, degrees of freedom and p value.
>> 
>> But how do I get the results of individual cells?
> 
> What do you mean 'results of individual cells'? As documented in
> ?chisq.test, you might be looking for one or more of
> 
> data.table$observed
> data.table$expected
> data.table$residuals
> data.table$stdres
> 
> Pick your poison. ;-)
> 
> MW

Replace with chisq.test(data.table)$observed, etc.


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From michael.weylandt at gmail.com  Mon Jun 17 11:11:45 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Mon, 17 Jun 2013 10:11:45 +0100
Subject: [R] chi square test
In-Reply-To: <1E16809E-7E70-48CC-9DDA-4E80662E5757@gmail.com>
References: <F332F190B39E463F94F2FFE3C2219E8A@DavePC>
	<CAAmySGMuqG9Vn5yYiSepYA-EbqZm22n58k=E3W0KetpSm0MafA@mail.gmail.com>
	<1E16809E-7E70-48CC-9DDA-4E80662E5757@gmail.com>
Message-ID: <CAAmySGOe_fDMGtnnFJsPNWoM9Y60VTuuwODvY7bSU8gRSx8ynQ@mail.gmail.com>

On Mon, Jun 17, 2013 at 10:07 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>
> On Jun 17, 2013, at 10:36 , R. Michael Weylandt wrote:
>>
>> What do you mean 'results of individual cells'? As documented in
>> ?chisq.test, you might be looking for one or more of
>>
>> data.table$observed
>> data.table$expected
>> data.table$residuals
>> data.table$stdres
>>
>> Pick your poison. ;-)
>>
>> MW
>
> Replace with chisq.test(data.table)$observed, etc.
>

D'Oh! Thanks for that, Peter.

MW


From kridox at ymail.com  Mon Jun 17 11:30:21 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Mon, 17 Jun 2013 18:30:21 +0900
Subject: [R] can't install rugarch and nloptr packages in R 3.01
 opensuse linux
In-Reply-To: <20130616064220.30872@web007.roc2.bluetie.com>
References: <20130616064220.30872@web007.roc2.bluetie.com>
Message-ID: <51BED72D.1030905@ymail.com>

Hello,

I was able to install the "nloptr" package by editing the src/Makevars file.

I added the line
         mv .libs lib; \
between
         make install; \
         ls | grep -v ^include$$ | grep -v ^lib$$ | xargs rm -rf; \
for NLopt compilation.

You probably should contact the package maintainer for more details.

Hope this helps,
Pascal


On 16/06/13 19:42, ce wrote:
> I can't install rugarch package because installation of nloptr package fails .
>
> I use opensuse 12.3
> # uname -a
> Linux candide 3.7.10-1.11-desktop #1 SMP PREEMPT Thu May 16 20:27:27 UTC 2013 (adf31bb) x86_64 x86_64 x86_64 GNU/Linux
> my gcc version is 4.8.1
>
> I compiled and installed R 3.01 . then I tried to install rugarch package but it fails because it can't install depended package nloptr.  I try to install nloptr individually with install.packages("nloptr"), i get a lot of deprecated messages and it fails. I attach log file . when I try to compile nlopt software it also gives similar messages.
>
> Following fails too:
>
> R version 3.0.1 (2013-05-16) -- "Good Sport"
> Copyright (C) 2013 The R Foundation for Statistical Computing
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>
>>   install.packages("nloptr",repos="http://R-Forge.R-project.org")
> Warning message:
> package ?nloptr? is not available (for R version 3.0.1)
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From alice.jones at noc.soton.ac.uk  Mon Jun 17 11:17:46 2013
From: alice.jones at noc.soton.ac.uk (alice.jones)
Date: Mon, 17 Jun 2013 02:17:46 -0700 (PDT)
Subject: [R] Can you use two offsets in gam (mgcv)?
Message-ID: <1371460666584-4669684.post@n4.nabble.com>

Hello, 
I have been trying to find out whether it is possible to use more than one
offset in a gam (in mgcv).  
The reason I would like to do this is to 1) account for area surveyed in a
Poisson model of sightings of porpoises within defined grid cells (each cell
has a slightly different area) and 2) account for detection probability
within each grid cell (some grid cells are further away from the observer
than others, and this affects the likelihood of seeing the porpoises). 
I would like to specify the model as something like:
gam(porpoises ~ s(covariates) + log(offset(grid cell area) +
log(offset(detection), family = "poisson").  Does this seems sensible?  I am
unsure of the way the two offsets will work together........ are they going
to be additive? I have had a search online and looked in the Wood 2006 book,
mgcv manual etc, but haven't managed to find anything that mentions using
multiple offsets.
Any advice would be very welcome.
Cheers, 
Alice 



--
View this message in context: http://r.789695.n4.nabble.com/Can-you-use-two-offsets-in-gam-mgcv-tp4669684.html
Sent from the R help mailing list archive at Nabble.com.


From dizem.uerek at alumni.fh-aachen.de  Mon Jun 17 11:01:31 2013
From: dizem.uerek at alumni.fh-aachen.de (Dzu)
Date: Mon, 17 Jun 2013 02:01:31 -0700 (PDT)
Subject: [R] Reading multiple csv files with a for loop
Message-ID: <1371459691888-4669681.post@n4.nabble.com>

Dear R-help users,

I am quite new in R. I have multiple csv.files with different size. I would
like to read them by using a for- loop and parallel by reading I need to add
a new column which can be specified by myself.

But my for-loop does not work !
Could somebody give me any idea ?
Many thanks!

myfiles <-list()
for ( i in 1:11) myfiles[i] <- read.csv(toread,header = TRUE, sep=")
names(myfiles) <- paste(myfiles)
mytotalfiles <- myfiles

#sample the data by the number of the columns by adding a new column 
sample(i1, 1000, replace = FALSE, prob = NULL)
for n <- 1000
sample <- myfiles[sample(nrow (df), 1000),]







--
View this message in context: http://r.789695.n4.nabble.com/Reading-multiple-csv-files-with-a-for-loop-tp4669681.html
Sent from the R help mailing list archive at Nabble.com.


From Giovanni_Millo at Generali.com  Mon Jun 17 13:35:48 2013
From: Giovanni_Millo at Generali.com (Millo Giovanni)
Date: Mon, 17 Jun 2013 13:35:48 +0200
Subject: [R]   Problems using log() in a plm() regression.
Message-ID: <D41D66AB93B9E04BBA5378B621FFDACB0249A03D@BEMAILEXPD01.corp.generali.net>


Dear Guylaine,

this has nothing to do with either 'plm' or logs. The error message says it all: "fin d'entr?e inattendu(e)". Somehow, you're inputting '+' twice in the R console, so the formula is syntactically invalid. Moreover, you assign the forula through '<' instead of '<-' so that this becomes a logical operation instead of an assignment.

May I suggest you break up the task to avoid confusion: first make a formula, like 'fm <- y ~ x1 + x2', check that it be a valid 'formula' object, then use it in 'plm(fm, data=mydata)' etc..

It is also best to use spacings, indentation, etc. to avoid messing things up.

Best Wishes,
Giovanni

######### original message ##########

------------------------------

Message: 42
Date: Sun, 16 Jun 2013 09:05:30 +0200
From: "Guylaine NOUWOUE" <guylaina_nd at yahoo.fr>
To: <r-help at r-project.org>
Subject: [R]  Problems using log() in a plm() regression.
Message-ID: <000001ce6a5f$e5b47790$b11d66b0$@fr>
Content-Type: text/plain

Hello,

I am performing a panel model and I have an error. In fact, I would like to
set up the pooling model and I have an error message. Any help

 

 

>pool<plm(panel$lexportijt~ldistit+lpopit+lpopjt+lpibit+lpibjt+lpibcit+lpibc
jt+langueij+histoireij+infrasij+frontiereij+simijt+enclaviit,data=panel,inde
x=c("origine","annee"))

Erreur dans parse(text = x) : 

  fin d'entr?e inattendu(e) dans "panel$lexportijt ~ ldistit + lpopit +
lpopjt + lpibit + lpibjt +     lpibcit + lpibcjt + langueij + histoireij +
infrasij + frontiereij +     simijt + enclaviit +  + "

 

Thanks in advance

Guylaina



########### end original message ########

?
Ai sensi del D.Lgs. 196/2003 si precisa che le informazi...{{dropped:12}}


From s.wood at bath.ac.uk  Mon Jun 17 14:01:20 2013
From: s.wood at bath.ac.uk (Simon Wood)
Date: Mon, 17 Jun 2013 13:01:20 +0100
Subject: [R] Can you use two offsets in gam (mgcv)?
In-Reply-To: <1371460666584-4669684.post@n4.nabble.com>
References: <1371460666584-4669684.post@n4.nabble.com>
Message-ID: <51BEFA90.8000005@bath.ac.uk>

Hi Alice

An offset is just a fixed vector added to the linear predictor of a 
model, so if you want to add two fixed vectors, you might as well add 
them together first. i.e. I think you want something like

off <- log(grid.cell.area) + log(detection)
gam(porpoises ~ s(covariates) + offset(off), family = "poisson")

Simon


On 17/06/13 10:17, alice.jones wrote:
> Hello,
> I have been trying to find out whether it is possible to use more than one
> offset in a gam (in mgcv).
> The reason I would like to do this is to 1) account for area surveyed in a
> Poisson model of sightings of porpoises within defined grid cells (each cell
> has a slightly different area) and 2) account for detection probability
> within each grid cell (some grid cells are further away from the observer
> than others, and this affects the likelihood of seeing the porpoises).
> I would like to specify the model as something like:
> gam(porpoises ~ s(covariates) + log(offset(grid cell area) +
> log(offset(detection), family = "poisson").  Does this seems sensible?  I am
> unsure of the way the two offsets will work together........ are they going
> to be additive? I have had a search online and looked in the Wood 2006 book,
> mgcv manual etc, but haven't managed to find anything that mentions using
> multiple offsets.
> Any advice would be very welcome.
> Cheers,
> Alice
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Can-you-use-two-offsets-in-gam-mgcv-tp4669684.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
+44 (0)1225 386603               http://people.bath.ac.uk/sw283


From ruipbarradas at sapo.pt  Mon Jun 17 14:04:20 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 17 Jun 2013 13:04:20 +0100
Subject: [R] Reading multiple csv files with a for loop
In-Reply-To: <1371459691888-4669681.post@n4.nabble.com>
References: <1371459691888-4669681.post@n4.nabble.com>
Message-ID: <51BEFB44.3010401@sapo.pt>

Hello,

You are reading 11 times the same file, 'toread'.
Assuming that 'toread' is a vector with 11 different filenames in it, 
something like the following might do what you want.

for ( i in 1:11) myfiles[i] <- read.csv(toread[i], header = TRUE, sep=")

AS for the final "for loop", it does nothing. Why have you posted that 
ugly thing?

Hope this helps,

Rui Barradas

Em 17-06-2013 10:01, Dzu escreveu:
> Dear R-help users,
>
> I am quite new in R. I have multiple csv.files with different size. I would
> like to read them by using a for- loop and parallel by reading I need to add
> a new column which can be specified by myself.
>
> But my for-loop does not work !
> Could somebody give me any idea ?
> Many thanks!
>
> myfiles <-list()
> for ( i in 1:11) myfiles[i] <- read.csv(toread,header = TRUE, sep=")
> names(myfiles) <- paste(myfiles)
> mytotalfiles <- myfiles
>
> #sample the data by the number of the columns by adding a new column
> sample(i1, 1000, replace = FALSE, prob = NULL)
> for n <- 1000
> sample <- myfiles[sample(nrow (df), 1000),]
>
>
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Reading-multiple-csv-files-with-a-for-loop-tp4669681.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From fgnu32 at yahoo.com  Mon Jun 17 15:20:47 2013
From: fgnu32 at yahoo.com (Fg Nu)
Date: Mon, 17 Jun 2013 06:20:47 -0700 (PDT)
Subject: [R] Building shared libraries in subdirectories
Message-ID: <1371475247.9657.YahooMailNeo@web160105.mail.bf1.yahoo.com>




Hi all,

I tried SO for this, but got no response. Trying here in hope of better luck.

----------------------------------------------------------------------------------------------------------

I am trying to build an R package that uses some C code. I have a C library that is compiled into an executable, that can be called from the command line. There is a Makefile associated with it.?

I am trying to grok the information [here][1], where it says

> If you want to create and then link to a library, say using code in a
> subdirectory, use something like

? ? ?.PHONY: all mylibs
? ? ?
? ? ?all: $(SHLIB)
? ? ?$(SHLIB): mylibs
? ? ?
? ? ?mylibs:
? ? ? ? ? ? ?(cd subdir; make)?

> Be careful to create all the necessary dependencies, as there is a no
> guarantee that the dependencies of all
> will be run in a particular order (and some of the CRAN build machines
> use multiple CPUs and parallel makes).



If I create a new subdirectory of the `src` folder in my package, called `someLibrary`, with the code and Makefile unchanged, and in turn, in the original `Makevars` file for my package I add the above code unchanged, then I will be able to build that shared library to be exported using `useDynLib`?

----
Edit 1:
----
Following information [here][2], I changed the `Makefile` to create a shared library by adding?

? ? CFLAG = -fPIC -g -O3?
? ? LDFLAGS= -shared

However, this leads to the problem that the `.so` file is not exported directly to the `libs` directory of the package. If I hard code the path into the target, then the file is sent to the `libs` directory of the package (this is all by the way of calls to `R CMD INSTALL myPackage`).?

----
Edit 2:
----
Lastly, I would like to know how to make calls to the shared library, given that it has a `main()` method that I could call from the command line executable.

What is the procedure to expose this to the R `NAMESPACE`, so that it can be called via `.Call`?

PS. ?Please let me know if I should make the last bit a separate question.

? [1]: http://cran.r-project.org/doc/manuals/R-exts.html#Using-Makevars
? [2]: http://stackoverflow.com/questions/8096015/creating-a-simple-make-file-to-create-a-shared-library-whats-wrong-with-this-m


From smartpink111 at yahoo.com  Mon Jun 17 15:39:15 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 17 Jun 2013 06:39:15 -0700 (PDT)
Subject: [R] selecting observations
Message-ID: <1371476355.13157.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,

May be this helps.
set.seed(29)
GLSS<- data.frame(hhid=sample(1:10,30,replace=TRUE),value=rnorm(30))
IDstoSelect<- c(1,5,7)
?GLSS[!is.na(match(GLSS[,1],IDstoSelect)),]
#?? hhid?????? value
#1???? 1 -0.34216061
#6???? 1? 0.28240263
#14??? 7? 0.04197496
#17??? 7? 0.15005878
#21??? 7 -1.18640939
#22??? 7 -0.68378601
#25??? 7 -2.43423380
#27??? 5? 0.95672044
#29??? 7? 1.76127732
#or

?GLSS[GLSS[,1]%in% IDstoSelect,]
#?? hhid?????? value
#1???? 1 -0.34216061
#6???? 1? 0.28240263
#14??? 7? 0.04197496
#17??? 7? 0.15005878
#21??? 7 -1.18640939
#22??? 7 -0.68378601
#25??? 7 -2.43423380
#27??? 5? 0.95672044
#29??? 7? 1.76127732
A.K.




Hello, 

i have a dataset GLSS in which one of the variables is household
 id (GLSS$hhid). Now i have a variable selecting which households i want
 to use in a subset (glss1H1). How do I select in an easy way the 
household id's that need to go to my subset? 

Would be great if someone can give me a help. Thanks!


From smartpink111 at yahoo.com  Mon Jun 17 15:49:30 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 17 Jun 2013 06:49:30 -0700 (PDT)
Subject: [R] Inputs for plots
In-Reply-To: <EB2D2D799706D645AA4808B7CB24D41A315BC6BF@MLBMBX4.marlabs.com>
References: <EB2D2D799706D645AA4808B7CB24D41A315BC6BF@MLBMBX4.marlabs.com>
Message-ID: <1371476970.95626.YahooMailNeo@web142605.mail.bf1.yahoo.com>



HI,
Try this:

X<- c("0","659-1000","641-659","634-641","630-634","630-630","626-628","618-626","604-618","574-604","0-574")
?Y<- c(0,2.166477,6.347396,12.23869,20.18244,26.07374,36.64006,48.15659,61.61155,77.95515,100.152)
?dat1<- data.frame(X,Y)
dat2<-dat1[order(dat1$Y,dat1$X),]
dat2$X<-factor(dat2$X,levels=dat2$X)
plot(as.numeric(dat2$X),dat2$Y,xaxt="n",xlab="X",ylab="Y",type="b")
?axis(1,at=as.numeric(dat2$X),labels=levels(dat2$X))
A.K.



________________________________
From: Sudha Krishnan <Sudha.Krishnan at marlabs.com>
To: "arun (smartpink111 at yahoo.com)" <smartpink111 at yahoo.com> 
Sent: Monday, June 17, 2013 9:09 AM
Subject: Inputs for plots




Arun, 

I am somehow getting struck while I try to Input values to a plot. I am really not sure how to go about better understanding how to input data for an column category names in X axis. Is there a way where I can get some understanding of this rather than trial and error? 


In this case, I have two columns X and Y (which I read from a csv). Column X has values like 659-1000,641-659,634-641,630-634,630-630,626-628,618-626,604-618,574-604,0-574( I have arrived at these values by calculating min and max values for a set of standard scores) 

Column Y has cumulative values (0,2.166477,6.347396,12.23869,20.18244,26.07374,36.64006,48.15659,61.61155,77.95515,100.152) 


I want to plot these in X and Y axis respectively, with those list of column ?X that must appear as column category names. 

plot(mydata$X,mydata$Y,type="l",col="red",xlim=c(0,10),ylim=c(0,100),xaxp=c(0,10,10),xaxs="i",yaxs="i")
abline(0,10)


But I don?t see a proper curve when I do this. 

Is there anything that you can suggest for me to go about this? I technically want 659-1000,641-659,634-641,630-634,630-630,626-628,618-626,604-618,574-604,0-574 range listed in my column category instead of 0,1,2?..

Thanks
Sudha Krishnan???????????


From grv144 at yahoo.com  Mon Jun 17 17:48:10 2013
From: grv144 at yahoo.com (G Vishwanath)
Date: Mon, 17 Jun 2013 08:48:10 -0700 (PDT)
Subject: [R] Vectorize a series of  Matrix Multiplications
In-Reply-To: <1371350130.67939.YahooMailNeo@web122202.mail.ne1.yahoo.com>
References: <1371350130.67939.YahooMailNeo@web122202.mail.ne1.yahoo.com>
Message-ID: <1371484090.69759.YahooMailNeo@web122201.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130617/568946c9/attachment.pl>

From 538280 at gmail.com  Mon Jun 17 18:35:54 2013
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 17 Jun 2013 10:35:54 -0600
Subject: [R] Simulating from a special type of bivariate exponential
	distribution
In-Reply-To: <CAGMzmw22LeA+OX7i_crvV73Q495n8FcEYP2-6E3AB5VZtXagrQ@mail.gmail.com>
References: <CAGMzmw22LeA+OX7i_crvV73Q495n8FcEYP2-6E3AB5VZtXagrQ@mail.gmail.com>
Message-ID: <CAFEqCdyq7=k6CNMzJRH9qqWJPsbNpXgMTzSTJrJFmYHrwBS8_g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130617/1c44c86a/attachment.pl>

From alexander.braumann at tuwien.ac.at  Mon Jun 17 17:28:17 2013
From: alexander.braumann at tuwien.ac.at (Alexander Braumann)
Date: Mon, 17 Jun 2013 17:28:17 +0200
Subject: [R] Invert a positive definite symmetric Block Toeplitz Matrix
Message-ID: <51BF2B11.5090203@tuwien.ac.at>

Is there a function in r that let's you efficiently invert a positive 
definite symmetric Block Toeplitz matrix? My matrices are the covariance 
matrices of observations of a multivariate time series and can be 
1000*1000 or larger.

I know the package 'ltsa' which seems to use the Trench algorithm to 
compute the inverse of a Toeplitz matrix. I am looking for a so to say 
"multivariate" version of that. I found the Block Levinson algorithm in 
Matlab, but didn't find any version of it in R.

My problem is part of a bigger problem, which is first computing the 
log-likelihood of the observations Y_T=(Y_1, ..., Y_T) of an 
n-dimensional time-series (Y_t) and second, finding an approximation of 
the MLE by using e.g. the BFGS algorithm.

As this algorithm does not function properly (no convergence), I thought 
that maybe the inversion of the big covariance matrix EY_T Y_T' may be a 
source a trouble.


Thanks for inputs in advance!


From cyri at live.it  Mon Jun 17 09:22:00 2013
From: cyri at live.it (laura bettella)
Date: Mon, 17 Jun 2013 09:22:00 +0200
Subject: [R] problemi di allocazione di memoria
Message-ID: <DUB116-W13443CFF44107128E0EC492DE830@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130617/d988d883/attachment.pl>

From rawal.shreya at gmail.com  Mon Jun 17 15:55:50 2013
From: rawal.shreya at gmail.com (Shreya Rawal)
Date: Mon, 17 Jun 2013 09:55:50 -0400
Subject: [R] Combining CSV data
In-Reply-To: <1371043513.43455.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <CALFKK3xTtutDvi12LpSp4M6hyn0bFR1-Z+7aWMTA6AT8xWG5mA@mail.gmail.com>
	<1370904118.98031.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1370916881.76218.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<CALFKK3zsGycu_yzqM6D1J8fD1px35+ypABQo-K9DXkOhQNSCWg@mail.gmail.com>
	<1370970132.53955.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CALFKK3yYMZYMA_pjPTme2U_F9VZq-mc85CMUqBjXNU26sTQr6w@mail.gmail.com>
	<1370984985.52466.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<CALFKK3zXwO3L6vcTj+=FC+dOJkXLHknXuReCs14phb77fQ3Utg@mail.gmail.com>
	<1371042629.5707.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CALFKK3xTk=CMgk+2YGYqffsBMjXhR9Fjf+EhYQ2Nx0VWryYK1A@mail.gmail.com>
	<1371043513.43455.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <CALFKK3w6XXypggPaR5ds7yEMWehQLVE6heekNXW5jJjznTpWbw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130617/2de6afb8/attachment.pl>

From leblkarin at hotmail.com  Mon Jun 17 16:38:49 2013
From: leblkarin at hotmail.com (Karin Lebl)
Date: Mon, 17 Jun 2013 14:38:49 +0000
Subject: [R] Rcpp/RcppArmadillo - matrix manipulation
Message-ID: <DUB112-W3518A60E026C76682A4931B7830@phx.gbl>

Hello all,
 
I?ve been working with R for some years, but I am beginner to Rcpp (and have no experience with C++).
 
I am trying to set zeros in a matrix to Inf. In R I would do this:

x=matrix(8:0,3) 
x[which(x==0)]=Inf
 

My try with Rcpp and RcppArmadillo looked like this (as I do not know how it works with inf I just set it to 100 in a first step):
 
library(Rcpp)
library(inline)
library(RcppArmadillo)
 
code <- '
 arma::mat M0 = Rcpp::as<arma::mat>(a);
 arma::mat M1 = Rcpp::as<arma::mat>(a);
 arma::uvec xx = find (M1==0); 
M1(xx)=100;
 M1=M0+M1;
 return Rcpp::wrap(M1);
 '
tf <- cxxfunction(signature(a="numeric"), code,plugin="RcppArmadillo")
tf(x) 

But this just produces errors *? However, setting the index ?manually? would work (changing M1(xx)=100 to M1(8)=100).
 
What do I have to change to make it work?
 
If I understood it correctly, it should be possible to use inf (http://arma.sourceforge.net/docs.html&constants). Can I do this simply by setting 
M1(xx)=inf; ?
 
Thanks to anyone who takes the time to answer my questions.
 
Best wishes,
Karin
 

* They are long and (I think) not very informative. But I can provide them if requested. 		 	   		  

From elizabethbeck0 at gmail.com  Mon Jun 17 19:02:54 2013
From: elizabethbeck0 at gmail.com (Elizabeth Beck)
Date: Mon, 17 Jun 2013 11:02:54 -0600
Subject: [R] NMDS with missing data?
In-Reply-To: <026501ce4ff0$c39350c0$4ab9f240$@tamu.edu>
References: <CAEWzS+FE0Rnj2PBD1GOxNwaNmQDuzKKxYHL1kDdXKcLd9Xamxw@mail.gmail.com>
	<01f501ce4cbc$39b8d460$ad2a7d20$@tamu.edu>
	<CAEWzS+Fp_hZ6ZMNPQAV-cSY+Ths8n-L8vcZhm-5EPA98bcU3Mw@mail.gmail.com>
	<026501ce4ff0$c39350c0$4ab9f240$@tamu.edu>
Message-ID: <CAEWzS+HyFwGK2X6HiDkF+K47eSaqEiQWKHmH4yWkuVvfpm95WQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130617/34b5edd8/attachment.pl>

From bhh at xs4all.nl  Mon Jun 17 19:06:12 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 17 Jun 2013 19:06:12 +0200
Subject: [R] problemi di allocazione di memoria
In-Reply-To: <DUB116-W13443CFF44107128E0EC492DE830@phx.gbl>
References: <DUB116-W13443CFF44107128E0EC492DE830@phx.gbl>
Message-ID: <F6A8DC44-3717-48CC-BFDC-5160E313E67C@xs4all.nl>



Italian is not spoken on this list.
And you were asked not to post in html.
You did and your code is totally messed up and thus completely unreadable.
In addition it is too much.

Berend

On 17-06-2013, at 09:22, laura bettella <cyri at live.it> wrote:

> Buongiorno,
> io sto usando R per fare un lavoro di simulazione per la mia tesi. Il lavoro consiste nel simulare 100 modelli da replicare 300 volte, fare le previsione, e combinarle usando determinati pesi.Il problema purtroppo ? che il programma di ferma a 30 modelli perch? dice non non avere abbastanza spazio nella memoria. Pensavo di aver ovviato a questo problema andando in: risorse del computer -> C -> propriet? -> gestione quote e mettendo che non ci sia un limite alle quote. Lo spazio disponibile in C ? di 417 GB.
> Di seguito vi metto il mio codice (so che pu? sembrare lungo):
> # liberiamo l'ambiente di lavoro e carichiamo i pacchetti utilirm(list=objects())library(VGAM) # serve per generare dati dall'esponenziale doppia (Laplace)
> # percorsi e parametri del codicebasepath = "C:/Documents and Settings/Laura/Desktop/top secret -)/lavoroLaura/lavoroLaura/"outputpath = paste0(basepath, "outputbreak/")nrep = 100 # numero replicazioni (numero modelli AR2 da cui simuleremo)#nrep = 1 # per provansim = 300 # numero simulazioni per ogni modello#nsim = 3 # per provaseme = 123 # seme simulazione dati (per replicare i risultati ottenuti)set.seed(seme)
> # varianza sigma2 = 3
> # funzione phi_s(.) di H-AFTERphis = function(x,s) {  if (x>=-1 & x<=s) {    x^2  } else {    if (x>s) {      2*s*x-s^2    } else {      -2*x-1    }  }}
> # s e lambda: parametri (fissi) di H-AFTER e L1-AFTERs = 1lambda = 1
> # dataframe che conterr?  gli nrep vettori di parametri degli AR3 da cui simuleremods_coeff_ar25 = data.frame(theta1=double(nrep*50),                           theta2=double(nrep*50),                           theta3=double(nrep*50),                           theta4=double(nrep*50),                           theta5=double(nrep*50))
> # codice per tenere solo le combinazioni di parametri che danno luogo a modelli stazionari# (devono essere stazionari sia i modelli ar2, che gli ar5)for (i in 1:(nrep*50)) {  coeff_ar12 = runif(2,-1,1)  coeff_ar345 = runif(3,-1,1)  stazRoot12 = abs(polyroot(c(1,-coeff_ar12)))  stazRoot12345 = abs(polyroot(c(1,-coeff_ar12,-coeff_ar345)))  if (sum(stazRoot12>1)==2 & sum(stazRoot12345>1)==5) {     ds_coeff_ar25[i,] = c(coeff_ar12,coeff_ar345)  }}
> # teniamo solo i modelli stazionari (in entrambi i casi)ds_coeff_ar25 = ds_coeff_ar25[which(ds_coeff_ar25$theta1!=0 & ds_coeff_ar25$theta2!=0 & ds_coeff_ar25$theta3!=0 &                                    ds_coeff_ar25$theta4!=0 & ds_coeff_ar25$theta5!=0),]ds_coeff_ar25 = ds_coeff_ar25[1:nrep,]
> # lista che conterr?  tutti i risultati (sar?  lunga nrep)allResultsList = list()
> # liste che conterranno, per ognuna delle 4 distribuzioni di errore,# i dati generati dagli AR3 per ogni replicazione (saranno lunghe nsim)yAr25Norm = list()yAr25ShGamma = list()yAr25DoubExp = list()yAr25T = list()
> # liste che conterranno, per ognuna delle 4 distribuzioni di errore,# i 5 modelli AR stimati sui dati generati precedentemente (saranno lunghe 5)fitArNorm = list()fitArShGamma = list()fitArDoubExp = list()fitArT = list()
> # liste che conterranno, per ognuna delle 4 distribuzioni di errore,# le previsioni fatte sulle ultime 25 osservazioniprevArNorm = list()prevArShGamma = list()prevArDoubExp = list()prevArT = list()
> 
> cat("\n")beginTime0 = format(Sys.time(), "%Y-%m-%d %H:%M:%S")beginTime0Math = Sys.time()cat("La procedura inizia in data e ora", beginTime0, "\n")cat("\n")
> # ciclo che fa tutto per ognuno degli nrep modelli AR3for (r in 1:nrep) {    cat("\n")  beginTime = format(Sys.time(), "%Y-%m-%d %H:%M:%S")  beginTimeMath = Sys.time()  cat("Inizia la replicazione", r, "in data e ora", beginTime, "\n")  cat("\n")    # ciclo che per ogni simulazione simula i dati, stima i modelli e fa le previsioni (nsim volte)  cat("Inizio generazione dei dati, stima dei modelli e calcolo delle previsioni\n")  for (k in 1:nsim) {        # per ognuna delle 4 distribuzioni generiamo 125 dati dall'AR2/5 con coefficienti ds_coeff_ar25[r,]    yAr25Norm[[k]] = ts(c(arima.sim(model=list(order=c(2,0,0), ar=as.vector(t(ds_coeff_ar25[r,1:2]))), n=115, sd=sqrt(sigma2)),                         arima.sim(model=list(order=c(5,0,0), ar=as.vector(t(ds_coeff_ar25[r,]))), n=10, sd=sqrt(sigma2))))    yAr25ShGamma[[k]] = ts(c(arima.sim(model=list(order=c(2,0,0), ar=as.vector(t(ds_coeff_ar25[r,1:2]))), n=115, rand.gen=function(n,...) sqrt(sigma2/3)*(rgamma(n, shape=3, scale=1) - 3)),                            arima.sim(model=list(order=c(5,0,0), ar=as.vector(t(ds_coeff_ar25[r,]))), n=10, rand.gen=function(n,...) sqrt(sigma2/3)*(rgamma(n, shape=3, scale=1) - 3))))    yAr25DoubExp[[k]] = ts(c(arima.sim(model=list(order=c(2,0,0), ar=as.vector(t(ds_coeff_ar25[r,1:2]))), n=115, rand.gen=function(n,...)  sqrt(sigma2/2)*rlaplace(n, location=0, scale=1)),                            arima.sim(model=list(order=c(5,0,0), ar=as.vector(t(ds_coeff_ar25[r,]))), n=10, rand.gen=function(n,...)  sqrt(sigma2/2)*rlaplace(n, location=0, scale=1))))    yAr25T[[k]] = ts(c(arima.sim(model=list(order=c(2,0,0), ar=as.vector(t(ds_coeff_ar25[r,1:2]))), n=115, rand.gen=function(n,...) sqrt(sigma2/2)*rt(n, df=4)),                      arima.sim(model=list(order=c(5,0,0), ar=as.vector(t(ds_coeff_ar25[r,]))), n=10, rand.gen=function(n,...) sqrt(sigma2/2)*rt(n, df=4))))        # stimiamo i 5 modelli AR sui primi 100 dati e con questi facciamo le previsioni sugli ultimi 25 dati    # generati dall'AR2/5 con errori normali    # AR1Norm    # proviamo il metodo CSS-ML    AR1Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(1,0,0), method="CSS-ML"), silent=FALSE)    # se CSS-ML d?  errore, proviamo il metodo ML    if (class(AR1Norm)=="try-error") {      AR1Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(1,0,0), method="ML"), silent=FALSE)      # se anche ML d?  errore, proviamo il metodo CSS      if (class(AR1Norm)=="try-error") {            AR1Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(1,0,0), method="CSS"), silent=FALSE)      }      # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS      else {        if (sum(diag(AR1Norm$var.coef)>0)<2) {               AR1Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(1,0,0), method="CSS"), silent=FALSE)        }      }    }    # se CSS-ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo ML    else {      if (sum(diag(AR1Norm$var.coef)>0)<2) {             AR1Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(1,0,0), method="ML"), silent=FALSE)         # se anche ML d?  errore, proviamo il metodo CSS        if (class(AR1Norm)=="try-error") {              AR1Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(1,0,0), method="CSS"), silent=FALSE)        }        # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS        else {          if (sum(diag(AR1Norm$var.coef)>0)<2) {                 AR1Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(1,0,0), method="CSS"), silent=FALSE)          }        }      }    }    # AR2Norm    # proviamo il metodo CSS-ML    AR2Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(2,0,0), method="CSS-ML"), silent=FALSE)    # se CSS-ML d?  errore, proviamo il metodo ML    if (class(AR2Norm)=="try-error") {      AR2Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(2,0,0), method="ML"), silent=FALSE)      # se anche ML d?  errore, proviamo il metodo CSS      if (class(AR2Norm)=="try-error") {            AR2Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(2,0,0), method="CSS"), silent=FALSE)      }      # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS      else {        if (sum(diag(AR2Norm$var.coef)>0)<2) {               AR2Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(2,0,0), method="CSS"), silent=FALSE)        }      }    }    # se CSS-ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo ML    else {      if (sum(diag(AR2Norm$var.coef)>0)<2) {             AR2Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(2,0,0), method="ML"), silent=FALSE)         # se anche ML d?  errore, proviamo il metodo CSS        if (class(AR2Norm)=="try-error") {              AR2Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(2,0,0), method="CSS"), silent=FALSE)        }        # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS        else {          if (sum(diag(AR2Norm$var.coef)>0)<2) {                 AR2Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(2,0,0), method="CSS"), silent=FALSE)          }        }      }    }    # AR3Norm    # proviamo il metodo CSS-ML    AR3Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(3,0,0), method="CSS-ML"), silent=FALSE)    # se CSS-ML d?  errore, proviamo il metodo ML    if (class(AR3Norm)=="try-error") {      AR3Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(3,0,0), method="ML"), silent=FALSE)      # se anche ML d?  errore, proviamo il metodo CSS      if (class(AR3Norm)=="try-error") {            AR3Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(3,0,0), method="CSS"), silent=FALSE)      }      # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS      else {        if (sum(diag(AR3Norm$var.coef)>0)<2) {               AR3Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(3,0,0), method="CSS"), silent=FALSE)        }      }    }    # se CSS-ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo ML    else {      if (sum(diag(AR3Norm$var.coef)>0)<2) {             AR3Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(3,0,0), method="ML"), silent=FALSE)         # se anche ML d?  errore, proviamo il metodo CSS        if (class(AR3Norm)=="try-error") {              AR3Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(3,0,0), method="CSS"), silent=FALSE)        }        # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS        else {          if (sum(diag(AR3Norm$var.coef)>0)<2) {                 AR3Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(3,0,0), method="CSS"), silent=FALSE)          }        }      }    }    # AR4Norm    # proviamo il metodo CSS-ML    AR4Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(4,0,0), method="CSS-ML"), silent=FALSE)    # se CSS-ML d?  errore, proviamo il metodo ML    if (class(AR4Norm)=="try-error") {      AR4Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(4,0,0), method="ML"), silent=FALSE)      # se anche ML d?  errore, proviamo il metodo CSS      if (class(AR4Norm)=="try-error") {            AR4Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(4,0,0), method="CSS"), silent=FALSE)      }      # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS      else {        if (sum(diag(AR4Norm$var.coef)>0)<2) {               AR4Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(4,0,0), method="CSS"), silent=FALSE)        }      }    }    # se CSS-ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo ML    else {      if (sum(diag(AR4Norm$var.coef)>0)<2) {             AR4Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(4,0,0), method="ML"), silent=FALSE)         # se anche ML d?  errore, proviamo il metodo CSS        if (class(AR4Norm)=="try-error") {              AR4Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(4,0,0), method="CSS"), silent=FALSE)        }        # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS        else {          if (sum(diag(AR4Norm$var.coef)>0)<2) {                 AR4Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(4,0,0), method="CSS"), silent=FALSE)          }        }      }    }    # AR5Norm    # proviamo il metodo CSS-ML    AR5Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(5,0,0), method="CSS-ML"), silent=FALSE)    # se CSS-ML d?  errore, proviamo il metodo ML    if (class(AR5Norm)=="try-error") {      AR5Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(5,0,0), method="ML"), silent=FALSE)      # se anche ML d?  errore, proviamo il metodo CSS      if (class(AR5Norm)=="try-error") {            AR5Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(5,0,0), method="CSS"), silent=FALSE)      }      # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS      else {        if (sum(diag(AR5Norm$var.coef)>0)<2) {               AR5Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(5,0,0), method="CSS"), silent=FALSE)        }      }    }    # se CSS-ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo ML    else {      if (sum(diag(AR5Norm$var.coef)>0)<2) {             AR5Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(5,0,0), method="ML"), silent=FALSE)         # se anche ML d?  errore, proviamo il metodo CSS        if (class(AR5Norm)=="try-error") {              AR5Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(5,0,0), method="CSS"), silent=FALSE)        }        # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS        else {          if (sum(diag(AR5Norm$var.coef)>0)<2) {                 AR5Norm = try(arima(x=yAr25Norm[[k]][1:100],order=c(5,0,0), method="CSS"), silent=FALSE)          }        }      }    }    fitArNorm[[k]] = list(AR1 = AR1Norm,                          AR2 = AR2Norm,                          AR3 = AR3Norm,                          AR4 = AR4Norm,                          AR5 = AR5Norm)    prevArNorm[[k]] = list(AR1 = predict(object=fitArNorm[[k]]$AR1, n.ahead=25),                           AR2 = predict(object=fitArNorm[[k]]$AR2, n.ahead=25),                           AR3 = predict(object=fitArNorm[[k]]$AR3, n.ahead=25),                           AR4 = predict(object=fitArNorm[[k]]$AR4, n.ahead=25),                           AR5 = predict(object=fitArNorm[[k]]$AR5, n.ahead=25) )        # stimiamo i 5 modelli AR sui primi 100 dati e con questi facciamo le previsioni sugli ultimi 25 dati    # generati dall'AR3 con errori gamma traslata    # AR1ShGamma    # proviamo il metodo CSS-ML    AR1ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(1,0,0), method="CSS-ML"), silent=FALSE)    # se CSS-ML d?  errore, proviamo il metodo ML    if (class(AR1ShGamma)=="try-error") {      AR1ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(1,0,0), method="ML"), silent=FALSE)      # se anche ML d?  errore, proviamo il metodo CSS      if (class(AR1ShGamma)=="try-error") {            AR1ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(1,0,0), method="CSS"), silent=FALSE)      }      # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS      else {        if (sum(diag(AR1ShGamma$var.coef)>0)<2) {               AR1ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(1,0,0), method="CSS"), silent=FALSE)        }      }    }    # se CSS-ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo ML    else {      if (sum(diag(AR1ShGamma$var.coef)>0)<2) {             AR1ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(1,0,0), method="ML"), silent=FALSE)         # se anche ML d?  errore, proviamo il metodo CSS        if (class(AR1ShGamma)=="try-error") {              AR1ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(1,0,0), method="CSS"), silent=FALSE)        }        # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS        else {          if (sum(diag(AR1ShGamma$var.coef)>0)<2) {                 AR1ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(1,0,0), method="CSS"), silent=FALSE)          }        }      }    }    # AR2ShGamma    # proviamo il metodo CSS-ML    AR2ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(2,0,0), method="CSS-ML"), silent=FALSE)    # se CSS-ML d?  errore, proviamo il metodo ML    if (class(AR2ShGamma)=="try-error") {      AR2ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(2,0,0), method="ML"), silent=FALSE)      # se anche ML d?  errore, proviamo il metodo CSS      if (class(AR2ShGamma)=="try-error") {            AR2ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(2,0,0), method="CSS"), silent=FALSE)      }      # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS      else {        if (sum(diag(AR2ShGamma$var.coef)>0)<2) {               AR2ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(2,0,0), method="CSS"), silent=FALSE)        }      }    }    # se CSS-ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo ML    else {      if (sum(diag(AR2ShGamma$var.coef)>0)<2) {             AR2ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(2,0,0), method="ML"), silent=FALSE)         # se anche ML d?  errore, proviamo il metodo CSS        if (class(AR2ShGamma)=="try-error") {              AR2ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(2,0,0), method="CSS"), silent=FALSE)        }        # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS        else {          if (sum(diag(AR2ShGamma$var.coef)>0)<2) {                 AR2ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(2,0,0), method="CSS"), silent=FALSE)          }        }      }    }    # AR3ShGamma    # proviamo il metodo CSS-ML    AR3ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(3,0,0), method="CSS-ML"), silent=FALSE)    # se CSS-ML d?  errore, proviamo il metodo ML    if (class(AR3ShGamma)=="try-error") {      AR3ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(3,0,0), method="ML"), silent=FALSE)      # se anche ML d?  errore, proviamo il metodo CSS      if (class(AR3ShGamma)=="try-error") {            AR3ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(3,0,0), method="CSS"), silent=FALSE)      }      # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS      else {        if (sum(diag(AR3ShGamma$var.coef)>0)<2) {               AR3ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(3,0,0), method="CSS"), silent=FALSE)        }      }    }    # se CSS-ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo ML    else {      if (sum(diag(AR3ShGamma$var.coef)>0)<2) {             AR3ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(3,0,0), method="ML"), silent=FALSE)         # se anche ML d?  errore, proviamo il metodo CSS        if (class(AR3ShGamma)=="try-error") {              AR3ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(3,0,0), method="CSS"), silent=FALSE)        }        # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS        else {          if (sum(diag(AR3ShGamma$var.coef)>0)<2) {                 AR3ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(3,0,0), method="CSS"), silent=FALSE)          }        }      }    }    # AR4ShGamma    # proviamo il metodo CSS-ML    AR4ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(4,0,0), method="CSS-ML"), silent=FALSE)    # se CSS-ML d?  errore, proviamo il metodo ML    if (class(AR4ShGamma)=="try-error") {      AR4ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(4,0,0), method="ML"), silent=FALSE)      # se anche ML d?  errore, proviamo il metodo CSS      if (class(AR4ShGamma)=="try-error") {            AR4ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(4,0,0), method="CSS"), silent=FALSE)      }      # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS      else {        if (sum(diag(AR4ShGamma$var.coef)>0)<2) {               AR4ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(4,0,0), method="CSS"), silent=FALSE)        }      }    }    # se CSS-ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo ML    else {      if (sum(diag(AR4ShGamma$var.coef)>0)<2) {             AR4ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(4,0,0), method="ML"), silent=FALSE)         # se anche ML d?  errore, proviamo il metodo CSS        if (class(AR4ShGamma)=="try-error") {              AR4ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(4,0,0), method="CSS"), silent=FALSE)        }        # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS        else {          if (sum(diag(AR4ShGamma$var.coef)>0)<2) {                 AR4ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(4,0,0), method="CSS"), silent=FALSE)          }        }      }    }    # AR5ShGamma    # proviamo il metodo CSS-ML    AR5ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(5,0,0), method="CSS-ML"), silent=FALSE)    # se CSS-ML d?  errore, proviamo il metodo ML    if (class(AR5ShGamma)=="try-error") {      AR5ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(5,0,0), method="ML"), silent=FALSE)      # se anche ML d?  errore, proviamo il metodo CSS      if (class(AR5ShGamma)=="try-error") {            AR5ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(5,0,0), method="CSS"), silent=FALSE)      }      # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS      else {        if (sum(diag(AR5ShGamma$var.coef)>0)<2) {               AR5ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(5,0,0), method="CSS"), silent=FALSE)        }      }    }    # se CSS-ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo ML    else {      if (sum(diag(AR5ShGamma$var.coef)>0)<2) {             AR5ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(5,0,0), method="ML"), silent=FALSE)         # se anche ML d?  errore, proviamo il metodo CSS        if (class(AR5ShGamma)=="try-error") {              AR5ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(5,0,0), method="CSS"), silent=FALSE)        }        # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS        else {          if (sum(diag(AR5ShGamma$var.coef)>0)<2) {                 AR5ShGamma = try(arima(x=yAr25ShGamma[[k]][1:100],order=c(5,0,0), method="CSS"), silent=FALSE)          }        }      }    }    fitArShGamma[[k]] = list(AR1 = AR1ShGamma,                             AR2 = AR2ShGamma,                             AR3 = AR3ShGamma,                             AR4 = AR4ShGamma,                             AR5 = AR5ShGamma)    prevArShGamma[[k]] = list(AR1 = predict(object=fitArShGamma[[k]]$AR1, n.ahead=25),                              AR2 = predict(object=fitArShGamma[[k]]$AR2, n.ahead=25),                              AR3 = predict(object=fitArShGamma[[k]]$AR3, n.ahead=25),                              AR4 = predict(object=fitArShGamma[[k]]$AR4, n.ahead=25),                              AR5 = predict(object=fitArShGamma[[k]]$AR5, n.ahead=25) )        # stimiamo i 5 modelli AR sui primi 100 dati e con questi facciamo le previsioni sugli ultimi 25 dati    # generati dall'AR3 con errori Laplace    # AR1DoubExp    # proviamo il metodo CSS-ML    AR1DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(1,0,0), method="CSS-ML"), silent=FALSE)    # se CSS-ML d?  errore, proviamo il metodo ML    if (class(AR1DoubExp)=="try-error") {      AR1DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(1,0,0), method="ML"), silent=FALSE)      # se anche ML d?  errore, proviamo il metodo CSS      if (class(AR1DoubExp)=="try-error") {            AR1DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(1,0,0), method="CSS"), silent=FALSE)      }      # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS      else {        if (sum(diag(AR1DoubExp$var.coef)>0)<2) {               AR1DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(1,0,0), method="CSS"), silent=FALSE)        }      }    }    # se CSS-ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo ML    else {      if (sum(diag(AR1DoubExp$var.coef)>0)<2) {             AR1DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(1,0,0), method="ML"), silent=FALSE)         # se anche ML d?  errore, proviamo il metodo CSS        if (class(AR1DoubExp)=="try-error") {              AR1DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(1,0,0), method="CSS"), silent=FALSE)        }        # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS        else {          if (sum(diag(AR1DoubExp$var.coef)>0)<2) {                 AR1DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(1,0,0), method="CSS"), silent=FALSE)          }        }      }    }    # AR2DoubExp    # proviamo il metodo CSS-ML    AR2DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(2,0,0), method="CSS-ML"), silent=FALSE)    # se CSS-ML d?  errore, proviamo il metodo ML    if (class(AR2DoubExp)=="try-error") {      AR2DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(2,0,0), method="ML"), silent=FALSE)      # se anche ML d?  errore, proviamo il metodo CSS      if (class(AR2DoubExp)=="try-error") {            AR2DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(2,0,0), method="CSS"), silent=FALSE)      }      # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS      else {        if (sum(diag(AR2DoubExp$var.coef)>0)<2) {               AR2DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(2,0,0), method="CSS"), silent=FALSE)        }      }    }    # se CSS-ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo ML    else {      if (sum(diag(AR2DoubExp$var.coef)>0)<2) {             AR2DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(2,0,0), method="ML"), silent=FALSE)         # se anche ML d?  errore, proviamo il metodo CSS        if (class(AR2DoubExp)=="try-error") {              AR2DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(2,0,0), method="CSS"), silent=FALSE)        }        # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS        else {          if (sum(diag(AR2DoubExp$var.coef)>0)<2) {                 AR2DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(2,0,0), method="CSS"), silent=FALSE)          }        }      }    }    # AR3DoubExp    # proviamo il metodo CSS-ML    AR3DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(3,0,0), method="CSS-ML"), silent=FALSE)    # se CSS-ML d?  errore, proviamo il metodo ML    if (class(AR3DoubExp)=="try-error") {      AR3DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(3,0,0), method="ML"), silent=FALSE)      # se anche ML d?  errore, proviamo il metodo CSS      if (class(AR3DoubExp)=="try-error") {            AR3DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(3,0,0), method="CSS"), silent=FALSE)      }      # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS      else {        if (sum(diag(AR3DoubExp$var.coef)>0)<2) {               AR3DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(3,0,0), method="CSS"), silent=FALSE)        }      }    }    # se CSS-ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo ML    else {      if (sum(diag(AR3DoubExp$var.coef)>0)<2) {             AR3DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(3,0,0), method="ML"), silent=FALSE)         # se anche ML d?  errore, proviamo il metodo CSS        if (class(AR3DoubExp)=="try-error") {              AR3DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(3,0,0), method="CSS"), silent=FALSE)        }        # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS        else {          if (sum(diag(AR3DoubExp$var.coef)>0)<2) {                 AR3DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(3,0,0), method="CSS"), silent=FALSE)          }        }      }    }    # AR4DoubExp    # proviamo il metodo CSS-ML    AR4DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(4,0,0), method="CSS-ML"), silent=FALSE)    # se CSS-ML d?  errore, proviamo il metodo ML    if (class(AR4DoubExp)=="try-error") {      AR4DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(4,0,0), method="ML"), silent=FALSE)      # se anche ML d?  errore, proviamo il metodo CSS      if (class(AR4DoubExp)=="try-error") {            AR4DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(4,0,0), method="CSS"), silent=FALSE)      }      # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS      else {        if (sum(diag(AR4DoubExp$var.coef)>0)<2) {               AR4DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(4,0,0), method="CSS"), silent=FALSE)        }      }    }    # se CSS-ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo ML    else {      if (sum(diag(AR4DoubExp$var.coef)>0)<2) {             AR4DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(4,0,0), method="ML"), silent=FALSE)         # se anche ML d?  errore, proviamo il metodo CSS        if (class(AR4DoubExp)=="try-error") {              AR4DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(4,0,0), method="CSS"), silent=FALSE)        }        # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS        else {          if (sum(diag(AR4DoubExp$var.coef)>0)<2) {                 AR4DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(4,0,0), method="CSS"), silent=FALSE)          }        }      }    }    # AR5DoubExp    # proviamo il metodo CSS-ML    AR5DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(5,0,0), method="CSS-ML"), silent=FALSE)    # se CSS-ML d?  errore, proviamo il metodo ML    if (class(AR5DoubExp)=="try-error") {      AR5DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(5,0,0), method="ML"), silent=FALSE)      # se anche ML d?  errore, proviamo il metodo CSS      if (class(AR5DoubExp)=="try-error") {            AR5DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(5,0,0), method="CSS"), silent=FALSE)      }      # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS      else {        if (sum(diag(AR5DoubExp$var.coef)>0)<2) {               AR5DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(5,0,0), method="CSS"), silent=FALSE)        }      }    }    # se CSS-ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo ML    else {      if (sum(diag(AR5DoubExp$var.coef)>0)<2) {             AR5DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(5,0,0), method="ML"), silent=FALSE)         # se anche ML d?  errore, proviamo il metodo CSS        if (class(AR5DoubExp)=="try-error") {              AR5DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(5,0,0), method="CSS"), silent=FALSE)        }        # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS        else {          if (sum(diag(AR5DoubExp$var.coef)>0)<2) {                 AR5DoubExp = try(arima(x=yAr25DoubExp[[k]][1:100],order=c(5,0,0), method="CSS"), silent=FALSE)          }        }      }    }    fitArDoubExp[[k]] = list(AR1 = AR1DoubExp,                             AR2 = AR2DoubExp,                             AR3 = AR3DoubExp,                             AR4 = AR4DoubExp,                             AR5 = AR5DoubExp)    prevArDoubExp[[k]] = list(AR1 = predict(object=fitArDoubExp[[k]]$AR1, n.ahead=25),                              AR2 = predict(object=fitArDoubExp[[k]]$AR2, n.ahead=25),                              AR3 = predict(object=fitArDoubExp[[k]]$AR3, n.ahead=25),                              AR4 = predict(object=fitArDoubExp[[k]]$AR4, n.ahead=25),                              AR5 = predict(object=fitArDoubExp[[k]]$AR5, n.ahead=25) )        # stimiamo i 5 modelli AR sui primi 100 dati e con questi facciamo le previsioni sugli ultimi 25 dati    # generati dall'AR3 con errori t di Student    # AR1T    # proviamo il metodo CSS-ML    AR1T = try(arima(x=yAr25T[[k]][1:100],order=c(1,0,0), method="CSS-ML"), silent=FALSE)    # se CSS-ML d?  errore, proviamo il metodo ML    if (class(AR1T)=="try-error") {      AR1T = try(arima(x=yAr25T[[k]][1:100],order=c(1,0,0), method="ML"), silent=FALSE)      # se anche ML d?  errore, proviamo il metodo CSS      if (class(AR1T)=="try-error") {            AR1T = try(arima(x=yAr25T[[k]][1:100],order=c(1,0,0), method="CSS"), silent=FALSE)      }      # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS      else {        if (sum(diag(AR1T$var.coef)>0)<2) {               AR1T = try(arima(x=yAr25T[[k]][1:100],order=c(1,0,0), method="CSS"), silent=FALSE)        }      }    }    # se CSS-ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo ML    else {      if (sum(diag(AR1T$var.coef)>0)<2) {             AR1T = try(arima(x=yAr25T[[k]][1:100],order=c(1,0,0), method="ML"), silent=FALSE)         # se anche ML d?  errore, proviamo il metodo CSS        if (class(AR1T)=="try-error") {              AR1T = try(arima(x=yAr25T[[k]][1:100],order=c(1,0,0), method="CSS"), silent=FALSE)        }        # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS        else {          if (sum(diag(AR1T$var.coef)>0)<2) {                 AR1T = try(arima(x=yAr25T[[k]][1:100],order=c(1,0,0), method="CSS"), silent=FALSE)          }        }      }    }    # AR2T    # proviamo il metodo CSS-ML    AR2T = try(arima(x=yAr25T[[k]][1:100],order=c(2,0,0), method="CSS-ML"), silent=FALSE)    # se CSS-ML d?  errore, proviamo il metodo ML    if (class(AR2T)=="try-error") {      AR2T = try(arima(x=yAr25T[[k]][1:100],order=c(2,0,0), method="ML"), silent=FALSE)      # se anche ML d?  errore, proviamo il metodo CSS      if (class(AR2T)=="try-error") {            AR2T = try(arima(x=yAr25T[[k]][1:100],order=c(2,0,0), method="CSS"), silent=FALSE)      }      # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS      else {        if (sum(diag(AR2T$var.coef)>0)<2) {               AR2T = try(arima(x=yAr25T[[k]][1:100],order=c(2,0,0), method="CSS"), silent=FALSE)        }      }    }    # se CSS-ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo ML    else {      if (sum(diag(AR2T$var.coef)>0)<2) {             AR2T = try(arima(x=yAr25T[[k]][1:100],order=c(2,0,0), method="ML"), silent=FALSE)         # se anche ML d?  errore, proviamo il metodo CSS        if (class(AR2T)=="try-error") {              AR2T = try(arima(x=yAr25T[[k]][1:100],order=c(2,0,0), method="CSS"), silent=FALSE)        }        # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS        else {          if (sum(diag(AR2T$var.coef)>0)<2) {                 AR2T = try(arima(x=yAr25T[[k]][1:100],order=c(2,0,0), method="CSS"), silent=FALSE)          }        }      }    }    # AR3T    # proviamo il metodo CSS-ML    AR3T = try(arima(x=yAr25T[[k]][1:100],order=c(3,0,0), method="CSS-ML"), silent=FALSE)    # se CSS-ML d?  errore, proviamo il metodo ML    if (class(AR3T)=="try-error") {      AR3T = try(arima(x=yAr25T[[k]][1:100],order=c(3,0,0), method="ML"), silent=FALSE)      # se anche ML d?  errore, proviamo il metodo CSS      if (class(AR3T)=="try-error") {            AR3T = try(arima(x=yAr25T[[k]][1:100],order=c(3,0,0), method="CSS"), silent=FALSE)      }      # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS      else {        if (sum(diag(AR3T$var.coef)>0)<2) {               AR3T = try(arima(x=yAr25T[[k]][1:100],order=c(3,0,0), method="CSS"), silent=FALSE)        }      }    }    # se CSS-ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo ML    else {      if (sum(diag(AR3T$var.coef)>0)<2) {             AR3T = try(arima(x=yAr25T[[k]][1:100],order=c(3,0,0), method="ML"), silent=FALSE)         # se anche ML d?  errore, proviamo il metodo CSS        if (class(AR3T)=="try-error") {              AR3T = try(arima(x=yAr25T[[k]][1:100],order=c(3,0,0), method="CSS"), silent=FALSE)        }        # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS        else {          if (sum(diag(AR3T$var.coef)>0)<2) {                 AR3T = try(arima(x=yAr25T[[k]][1:100],order=c(3,0,0), method="CSS"), silent=FALSE)          }        }      }    }    # AR4T    # proviamo il metodo CSS-ML    AR4T = try(arima(x=yAr25T[[k]][1:100],order=c(4,0,0), method="CSS-ML"), silent=FALSE)    # se CSS-ML d?  errore, proviamo il metodo ML    if (class(AR4T)=="try-error") {      AR4T = try(arima(x=yAr25T[[k]][1:100],order=c(4,0,0), method="ML"), silent=FALSE)      # se anche ML d?  errore, proviamo il metodo CSS      if (class(AR4T)=="try-error") {            AR4T = try(arima(x=yAr25T[[k]][1:100],order=c(4,0,0), method="CSS"), silent=FALSE)      }      # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS      else {        if (sum(diag(AR4T$var.coef)>0)<2) {               AR4T = try(arima(x=yAr25T[[k]][1:100],order=c(4,0,0), method="CSS"), silent=FALSE)        }      }    }    # se CSS-ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo ML    else {      if (sum(diag(AR4T$var.coef)>0)<2) {             AR4T = try(arima(x=yAr25T[[k]][1:100],order=c(4,0,0), method="ML"), silent=FALSE)         # se anche ML d?  errore, proviamo il metodo CSS        if (class(AR4T)=="try-error") {              AR4T = try(arima(x=yAr25T[[k]][1:100],order=c(4,0,0), method="CSS"), silent=FALSE)        }        # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS        else {          if (sum(diag(AR4T$var.coef)>0)<2) {                 AR4T = try(arima(x=yAr25T[[k]][1:100],order=c(4,0,0), method="CSS"), silent=FALSE)          }        }      }    }    # AR5T    # proviamo il metodo CSS-ML    AR5T = try(arima(x=yAr25T[[k]][1:100],order=c(5,0,0), method="CSS-ML"), silent=FALSE)    # se CSS-ML d?  errore, proviamo il metodo ML    if (class(AR5T)=="try-error") {      AR5T = try(arima(x=yAr25T[[k]][1:100],order=c(5,0,0), method="ML"), silent=FALSE)      # se anche ML d?  errore, proviamo il metodo CSS      if (class(AR5T)=="try-error") {            AR5T = try(arima(x=yAr25T[[k]][1:100],order=c(5,0,0), method="CSS"), silent=FALSE)      }      # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS      else {        if (sum(diag(AR5T$var.coef)>0)<2) {               AR5T = try(arima(x=yAr25T[[k]][1:100],order=c(5,0,0), method="CSS"), silent=FALSE)        }      }    }    # se CSS-ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo ML    else {      if (sum(diag(AR5T$var.coef)>0)<2) {             AR5T = try(arima(x=yAr25T[[k]][1:100],order=c(5,0,0), method="ML"), silent=FALSE)         # se anche ML d?  errore, proviamo il metodo CSS        if (class(AR5T)=="try-error") {              AR5T = try(arima(x=yAr25T[[k]][1:100],order=c(5,0,0), method="CSS"), silent=FALSE)        }        # se ML non d?  errore, controlliamo le varianze: se ce n'?? almeno una negativa, proviamo il metodo CSS        else {          if (sum(diag(AR5T$var.coef)>0)<2) {                 AR5T = try(arima(x=yAr25T[[k]][1:100],order=c(5,0,0), method="CSS"), silent=FALSE)          }        }      }    }    fitArT[[k]] = list(AR1 = AR1T,                       AR2 = AR2T,                       AR3 = AR3T,                       AR4 = AR4T,                       AR5 = AR5T)    prevArT[[k]] = list(AR1 = predict(object=fitArT[[k]]$AR1, n.ahead=25),                        AR2 = predict(object=fitArT[[k]]$AR2, n.ahead=25),                        AR3 = predict(object=fitArT[[k]]$AR3, n.ahead=25),                        AR4 = predict(object=fitArT[[k]]$AR4, n.ahead=25),                        AR5 = predict(object=fitArT[[k]]$AR5, n.ahead=25) )        if (k %% 10 == 0) print(k)  }  cat("Fine generazione dei dati, stima dei modelli e calcolo delle previsioni\n")    # liste che, per ognuna delle 4 distribuzioni, conterranno i pesi delle previsioni combinate  weightListNorm = list()  weightListShGamma = list()  weightListDoubExp = list()  weightListT = list()    # numero di previsioni e numero di modelli AR usati per la previsione combinata  weightT = 25  M = 5    # ciclo che per ogni simulazione calcoler?  i pesi delle previsioni combinate con i 3 metodi  cat("Inizio calcolo dei pesi delle previsioni combinate con i 3 metodi\n")  for (k in 1:nsim) {        # lista che conterr?  i pesi nel caso normale    weightListNorm[[k]] = list(   AFTER = data.frame(AR1=double(weightT),                                                     AR2=double(weightT),                                                     AR3=double(weightT),                                                     AR4=double(weightT),                                                     AR5=double(weightT)),                                  L1.AFTER = data.frame(AR1=double(weightT),                                                        AR2=double(weightT),                                                        AR3=double(weightT),                                                        AR4=double(weightT),                                                        AR5=double(weightT)),                                  H.AFTER = data.frame(AR1=double(weightT),                                                       AR2=double(weightT),                                                       AR3=double(weightT),                                                       AR4=double(weightT),                                                       AR5=double(weightT)) )    weightListNorm[[k]]$AFTER[1,] = rep(1/M,M)    weightListNorm[[k]]$L1.AFTER[1,] = rep(1/M,M)    weightListNorm[[k]]$H.AFTER[1,] = rep(1/M,M)        for (i in 2:weightT) {      for (j in 1:M) {        weightListNorm[[k]]$L1.AFTER[i,j] = weightListNorm[[k]]$L1.AFTER[i-1,1]/sd(yAr25Norm[[k]][1:(100+i-1)])*exp(-lambda*    abs(yAr25Norm[[k]][100+i-1]-prevArNorm[[k]][[j]]$pred[i-1])  /(         sd(yAr25Norm[[k]][1:(100+i-1)])))        weightListNorm[[k]]$   AFTER[i,j] = weightListNorm[[k]]$AFTER[i-1,1]   /sd(yAr25Norm[[k]][1:(100+i-1)])*exp(-              (yAr25Norm[[k]][100+i-1]-prevArNorm[[k]][[j]]$pred[i-1])^2/(      2*var(yAr25Norm[[k]][1:(100+i-1)])))        weightListNorm[[k]]$H.AFTER[i,j]  = weightListNorm[[k]]$H.AFTER[i-1,1] /sd(yAr25Norm[[k]][1:(100+i-1)])*exp(-lambda*phis(x=(yAr25Norm[[k]][100+i-1]-prevArNorm[[k]][[j]]$pred[i-1])  /(sqrt( 2)*sd(yAr25Norm[[k]][1:(100+i-1)])), s=s))      }      }          sumWeightsNorm = list(AFTER    = apply(weightListNorm[[k]]$AFTER, 1, sum),                          L1.AFTER = apply(weightListNorm[[k]]$L1.AFTER, 1, sum),                          H.AFTER  = apply(weightListNorm[[k]]$H.AFTER, 1, sum) )        for (i in 1:weightT) {      for (j in 1:M) {        weightListNorm[[k]]$AFTER[i,j]    = weightListNorm[[k]]$AFTER[i,j]   /sumWeightsNorm$AFTER[i]        weightListNorm[[k]]$L1.AFTER[i,j] = weightListNorm[[k]]$L1.AFTER[i,j]/sumWeightsNorm$L1.AFTER[i]        weightListNorm[[k]]$H.AFTER[i,j]  = weightListNorm[[k]]$H.AFTER[i,j] /sumWeightsNorm$H.AFTER[i]      }      }        # lista che conterr?  i pesi nel caso gamma traslata    weightListShGamma[[k]] = list(   AFTER = data.frame(AR1=double(weightT),                                                        AR2=double(weightT),                                                        AR3=double(weightT),                                                        AR4=double(weightT),                                                        AR5=double(weightT)),                                     L1.AFTER = data.frame(AR1=double(weightT),                                                           AR2=double(weightT),                                                           AR3=double(weightT),                                                           AR4=double(weightT),                                                           AR5=double(weightT)),                                     H.AFTER = data.frame(AR1=double(weightT),                                                          AR2=double(weightT),                                                          AR3=double(weightT),                                                          AR4=double(weightT),                                                          AR5=double(weightT)) )    weightListShGamma[[k]]$AFTER[1,] = rep(1/M,M)    weightListShGamma[[k]]$L1.AFTER[1,] = rep(1/M,M)    weightListShGamma[[k]]$H.AFTER[1,] = rep(1/M,M)        for (i in 2:weightT) {      for (j in 1:M) {        weightListShGamma[[k]]$L1.AFTER[i,j] = weightListShGamma[[k]]$L1.AFTER[i-1,1]/sd(yAr25ShGamma[[k]][1:(100+i-1)])*exp(-lambda*    abs(yAr25ShGamma[[k]][100+i-1]-prevArShGamma[[k]][[j]]$pred[i-1])  /(         sd(yAr25ShGamma[[k]][1:(100+i-1)])))        weightListShGamma[[k]]$   AFTER[i,j] = weightListShGamma[[k]]$AFTER[i-1,1]   /sd(yAr25ShGamma[[k]][1:(100+i-1)])*exp(-              (yAr25ShGamma[[k]][100+i-1]-prevArShGamma[[k]][[j]]$pred[i-1])^2/(      2*var(yAr25ShGamma[[k]][1:(100+i-1)])))        weightListShGamma[[k]]$H.AFTER[i,j]  = weightListShGamma[[k]]$H.AFTER[i-1,1] /sd(yAr25ShGamma[[k]][1:(100+i-1)])*exp(-lambda*phis(x=(yAr25ShGamma[[k]][100+i-1]-prevArShGamma[[k]][[j]]$pred[i-1])  /(sqrt( 2)*sd(yAr25ShGamma[[k]][1:(100+i-1)])), s=s))      }      }          sumWeightsShGamma = list(AFTER    = apply(weightListShGamma[[k]]$AFTER, 1, sum),                             L1.AFTER = apply(weightListShGamma[[k]]$L1.AFTER, 1, sum),                             H.AFTER  = apply(weightListShGamma[[k]]$H.AFTER, 1, sum) )        for (i in 1:weightT) {      for (j in 1:M) {        weightListShGamma[[k]]$AFTER[i,j]    = weightListShGamma[[k]]$AFTER[i,j]   /sumWeightsShGamma$AFTER[i]        weightListShGamma[[k]]$L1.AFTER[i,j] = weightListShGamma[[k]]$L1.AFTER[i,j]/sumWeightsShGamma$L1.AFTER[i]        weightListShGamma[[k]]$H.AFTER[i,j]  = weightListShGamma[[k]]$H.AFTER[i,j] /sumWeightsShGamma$H.AFTER[i]      }      }        # lista che conterr?  i pesi nel caso Laplace    weightListDoubExp[[k]] = list(   AFTER = data.frame(AR1=double(weightT),                                                        AR2=double(weightT),                                                        AR3=double(weightT),                                                        AR4=double(weightT),                                                        AR5=double(weightT)),                                     L1.AFTER = data.frame(AR1=double(weightT),                                                           AR2=double(weightT),                                                           AR3=double(weightT),                                                           AR4=double(weightT),                                                           AR5=double(weightT)),                                     H.AFTER = data.frame(AR1=double(weightT),                                                          AR2=double(weightT),                                                          AR3=double(weightT),                                                          AR4=double(weightT),                                                          AR5=double(weightT)) )    weightListDoubExp[[k]]$AFTER[1,] = rep(1/M,M)    weightListDoubExp[[k]]$L1.AFTER[1,] = rep(1/M,M)    weightListDoubExp[[k]]$H.AFTER[1,] = rep(1/M,M)        for (i in 2:weightT) {      for (j in 1:M) {        weightListDoubExp[[k]]$L1.AFTER[i,j] = weightListDoubExp[[k]]$L1.AFTER[i-1,1]/sd(yAr25DoubExp[[k]][1:(100+i-1)])*exp(-lambda*    abs(yAr25DoubExp[[k]][100+i-1]-prevArDoubExp[[k]][[j]]$pred[i-1])  /(         sd(yAr25DoubExp[[k]][1:(100+i-1)])))        weightListDoubExp[[k]]$   AFTER[i,j] = weightListDoubExp[[k]]$AFTER[i-1,1]   /sd(yAr25DoubExp[[k]][1:(100+i-1)])*exp(-              (yAr25DoubExp[[k]][100+i-1]-prevArDoubExp[[k]][[j]]$pred[i-1])^2/(      2*var(yAr25DoubExp[[k]][1:(100+i-1)])))        weightListDoubExp[[k]]$H.AFTER[i,j]  = weightListDoubExp[[k]]$H.AFTER[i-1,1] /sd(yAr25DoubExp[[k]][1:(100+i-1)])*exp(-lambda*phis(x=(yAr25DoubExp[[k]][100+i-1]-prevArDoubExp[[k]][[j]]$pred[i-1])  /(sqrt( 2)*sd(yAr25DoubExp[[k]][1:(100+i-1)])), s=s))      }      }          sumWeightsDoubExp = list(AFTER    = apply(weightListDoubExp[[k]]$AFTER, 1, sum),                             L1.AFTER = apply(weightListDoubExp[[k]]$L1.AFTER, 1, sum),                             H.AFTER  = apply(weightListDoubExp[[k]]$H.AFTER, 1, sum) )        for (i in 1:weightT) {      for (j in 1:M) {        weightListDoubExp[[k]]$AFTER[i,j]    = weightListDoubExp[[k]]$AFTER[i,j]   /sumWeightsDoubExp$AFTER[i]        weightListDoubExp[[k]]$L1.AFTER[i,j] = weightListDoubExp[[k]]$L1.AFTER[i,j]/sumWeightsDoubExp$L1.AFTER[i]        weightListDoubExp[[k]]$H.AFTER[i,j]  = weightListDoubExp[[k]]$H.AFTER[i,j] /sumWeightsDoubExp$H.AFTER[i]      }      }        # lista che conterr?  i pesi nel caso t di Student    weightListT[[k]] = list(   AFTER = data.frame(AR1=double(weightT),                                                  AR2=double(weightT),                                                  AR3=double(weightT),                                                  AR4=double(weightT),                                                  AR5=double(weightT)),                               L1.AFTER = data.frame(AR1=double(weightT),                                                     AR2=double(weightT),                                                     AR3=double(weightT),                                                     AR4=double(weightT),                                                     AR5=double(weightT)),                               H.AFTER = data.frame(AR1=double(weightT),                                                    AR2=double(weightT),                                                    AR3=double(weightT),                                                    AR4=double(weightT),                                                    AR5=double(weightT)) )    weightListT[[k]]$AFTER[1,] = rep(1/M,M)    weightListT[[k]]$L1.AFTER[1,] = rep(1/M,M)    weightListT[[k]]$H.AFTER[1,] = rep(1/M,M)        for (i in 2:weightT) {      for (j in 1:M) {        weightListT[[k]]$L1.AFTER[i,j] = weightListT[[k]]$L1.AFTER[i-1,1]/sd(yAr25T[[k]][1:(100+i-1)])*exp(-lambda*    abs(yAr25T[[k]][100+i-1]-prevArT[[k]][[j]]$pred[i-1])  /(         sd(yAr25T[[k]][1:(100+i-1)])))        weightListT[[k]]$   AFTER[i,j] = weightListT[[k]]$AFTER[i-1,1]   /sd(yAr25T[[k]][1:(100+i-1)])*exp(-              (yAr25T[[k]][100+i-1]-prevArT[[k]][[j]]$pred[i-1])^2/(      2*var(yAr25T[[k]][1:(100+i-1)])))        weightListT[[k]]$H.AFTER[i,j]  = weightListT[[k]]$H.AFTER[i-1,1] /sd(yAr25T[[k]][1:(100+i-1)])*exp(-lambda*phis(x=(yAr25T[[k]][100+i-1]-prevArT[[k]][[j]]$pred[i-1])  /(sqrt( 2)*sd(yAr25T[[k]][1:(100+i-1)])), s=s))      }      }          sumWeightsT = list(AFTER    = apply(weightListT[[k]]$AFTER, 1, sum),                       L1.AFTER = apply(weightListT[[k]]$L1.AFTER, 1, sum),                       H.AFTER  = apply(weightListT[[k]]$H.AFTER, 1, sum) )        for (i in 1:weightT) {      for (j in 1:M) {        weightListT[[k]]$AFTER[i,j]    = weightListT[[k]]$AFTER[i,j]   /sumWeightsT$AFTER[i]        weightListT[[k]]$L1.AFTER[i,j] = weightListT[[k]]$L1.AFTER[i,j]/sumWeightsT$L1.AFTER[i]        weightListT[[k]]$H.AFTER[i,j]  = weightListT[[k]]$H.AFTER[i,j] /sumWeightsT$H.AFTER[i]      }      }        if (k %% 10 == 0) print(k)      }  cat("Fine calcolo dei pesi delle previsioni combinate con i 3 metodi\n")    # liste che, per ognuna delle 4 distribuzioni, conterranno le previsioni combinate  combinedPredictNorm = list()  combinedPredictShGamma = list()  combinedPredictDoubExp = list()  combinedPredictT = list()    cat("Inizio calcolo delle previsioni combinate con i 3 metodi\n")  for (k in 1:nsim) {    # previsioni combinate per il caso normale    combinedPredictNorm[[k]] = list(AFTER    = double(weightT),                                    L1.AFTER = double(weightT),                                    H.AFTER  = double(weightT))        for (i in 1:weightT) {      prevArNormki = c(prevArNorm[[k]]$AR1$pred[i],                       prevArNorm[[k]]$AR2$pred[i],                       prevArNorm[[k]]$AR3$pred[i],                       prevArNorm[[k]]$AR4$pred[i],                       prevArNorm[[k]]$AR5$pred[i])                   combinedPredictNorm[[k]]$AFTER[i]    = sum(weightListNorm[[k]]$AFTER[i,]   *prevArNormki)      combinedPredictNorm[[k]]$L1.AFTER[i] = sum(weightListNorm[[k]]$L1.AFTER[i,]*prevArNormki)      combinedPredictNorm[[k]]$H.AFTER[i]  = sum(weightListNorm[[k]]$H.AFTER[i,] *prevArNormki)    }        # previsioni combinate per il caso gamma traslata    combinedPredictShGamma[[k]] = list(AFTER    = double(weightT),                                       L1.AFTER = double(weightT),                                       H.AFTER  = double(weightT))        for (i in 1:weightT) {      prevArShGammaki = c(prevArShGamma[[k]]$AR1$pred[i],                          prevArShGamma[[k]]$AR2$pred[i],                          prevArShGamma[[k]]$AR3$pred[i],                          prevArShGamma[[k]]$AR4$pred[i],                          prevArShGamma[[k]]$AR5$pred[i])                   combinedPredictShGamma[[k]]$AFTER[i]    = sum(weightListShGamma[[k]]$AFTER[i,]   *prevArShGammaki)      combinedPredictShGamma[[k]]$L1.AFTER[i] = sum(weightListShGamma[[k]]$L1.AFTER[i,]*prevArShGammaki)      combinedPredictShGamma[[k]]$H.AFTER[i]  = sum(weightListShGamma[[k]]$H.AFTER[i,] *prevArShGammaki)    }        # previsioni combinate per il caso Laplace    combinedPredictDoubExp[[k]] = list(AFTER    = double(weightT),                                       L1.AFTER = double(weightT),                                       H.AFTER  = double(weightT))        for (i in 1:weightT) {      prevArDoubExpki = c(prevArDoubExp[[k]]$AR1$pred[i],                          prevArDoubExp[[k]]$AR2$pred[i],                          prevArDoubExp[[k]]$AR3$pred[i],                          prevArDoubExp[[k]]$AR4$pred[i],                          prevArDoubExp[[k]]$AR5$pred[i])                   combinedPredictDoubExp[[k]]$AFTER[i]    = sum(weightListDoubExp[[k]]$AFTER[i,]   *prevArDoubExpki)      combinedPredictDoubExp[[k]]$L1.AFTER[i] = sum(weightListDoubExp[[k]]$L1.AFTER[i,]*prevArDoubExpki)      combinedPredictDoubExp[[k]]$H.AFTER[i]  = sum(weightListDoubExp[[k]]$H.AFTER[i,] *prevArDoubExpki)    }        # previsioni combinate per il caso t di Student    combinedPredictT[[k]] = list(AFTER    = double(weightT),                                 L1.AFTER = double(weightT),                                 H.AFTER  = double(weightT))        for (i in 1:weightT) {      prevArTki = c(prevArT[[k]]$AR1$pred[i],                    prevArT[[k]]$AR2$pred[i],                    prevArT[[k]]$AR3$pred[i],                    prevArT[[k]]$AR4$pred[i],                    prevArT[[k]]$AR5$pred[i])                   combinedPredictT[[k]]$AFTER[i]    = sum(weightListT[[k]]$AFTER[i,]   *prevArTki)      combinedPredictT[[k]]$L1.AFTER[i] = sum(weightListT[[k]]$L1.AFTER[i,]*prevArTki)      combinedPredictT[[k]]$H.AFTER[i]  = sum(weightListT[[k]]$H.AFTER[i,] *prevArTki)    }        if (k %% 10 == 0) print(k)  }  cat("Fine calcolo delle previsioni combinate con i 3 metodi\n")    # MSE nel caso normale (delle 25 osservazioni previste si usano le ultime 20)  cat("Inizio calcolo degli MSE con i 3 metodi\n")  MSENorm = data.frame(AFTER = double(nsim),                       L1.AFTER = double(nsim),                       H.AFTER = double(nsim))    for (k in 1:nsim) {    MSENorm[k,"AFTER"]    = mean((yAr25Norm[[k]][106:125]-combinedPredictNorm[[k]]$AFTER[6:25])^2)    MSENorm[k,"L1.AFTER"] = mean((yAr25Norm[[k]][106:125]-combinedPredictNorm[[k]]$L1.AFTER[6:25])^2)    MSENorm[k,"H.AFTER"]  = mean((yAr25Norm[[k]][106:125]-combinedPredictNorm[[k]]$H.AFTER[6:25])^2)#     print(k)  }    # MSE nel caso gamma traslata (delle 25 osservazioni previste si usano le ultime 20)  MSEShGamma = data.frame(AFTER = double(nsim),                          L1.AFTER = double(nsim),                          H.AFTER = double(nsim))    for (k in 1:nsim) {    MSEShGamma[k,"AFTER"]    = mean((yAr25ShGamma[[k]][106:125]-combinedPredictShGamma[[k]]$AFTER[6:25])^2)    MSEShGamma[k,"L1.AFTER"] = mean((yAr25ShGamma[[k]][106:125]-combinedPredictShGamma[[k]]$L1.AFTER[6:25])^2)    MSEShGamma[k,"H.AFTER"]  = mean((yAr25ShGamma[[k]][106:125]-combinedPredictShGamma[[k]]$H.AFTER[6:25])^2)#     print(k)  }    # MSE nel caso Laplace (delle 25 osservazioni previste si usano le ultime 20)  MSEDoubExp = data.frame(AFTER = double(nsim),                          L1.AFTER = double(nsim),                          H.AFTER = double(nsim))    for (k in 1:nsim) {    MSEDoubExp[k,"AFTER"]    = mean((yAr25DoubExp[[k]][106:125]-combinedPredictDoubExp[[k]]$AFTER[6:25])^2)    MSEDoubExp[k,"L1.AFTER"] = mean((yAr25DoubExp[[k]][106:125]-combinedPredictDoubExp[[k]]$L1.AFTER[6:25])^2)    MSEDoubExp[k,"H.AFTER"]  = mean((yAr25DoubExp[[k]][106:125]-combinedPredictDoubExp[[k]]$H.AFTER[6:25])^2)#     print(k)  }    # MSE nel caso t di Student (delle 25 osservazioni previste si usano le ultime 20)  MSET = data.frame(AFTER = double(nsim),                    L1.AFTER = double(nsim),                    H.AFTER = double(nsim))    for (k in 1:nsim) {    MSET[k,"AFTER"]    = mean((yAr25T[[k]][106:125]-combinedPredictT[[k]]$AFTER[6:25])^2)    MSET[k,"L1.AFTER"] = mean((yAr25T[[k]][106:125]-combinedPredictT[[k]]$L1.AFTER[6:25])^2)    MSET[k,"H.AFTER"]  = mean((yAr25T[[k]][106:125]-combinedPredictT[[k]]$H.AFTER[6:25])^2)    if (k %% 10 == 0) print(k)  }  cat("Fine calcolo degli MSE con i 3 metodi\n")    # LISTA FINALE, LUNGA nrep, CHE CONTIENE TUTTI I RISULTATI PER OGNI REPLICAZIONE!!!  allResultsList[[r]] = list(coeff_ar3 = ds_coeff_ar25[r,],                             sigma2 = sigma2,                             lambda = lambda,                             s = s,                             yAr25Norm = yAr25Norm,                             yAr25ShGamma = yAr25ShGamma,                             yAr25DoubExp = yAr25DoubExp,                             yAr25T = yAr25T,                             fitArNorm = fitArNorm,                             fitArShGamma = fitArShGamma,                             fitArDoubExp = fitArDoubExp,                             fitArT = fitArT,                             prevArNorm = prevArNorm,                             prevArShGamma = prevArShGamma,                             prevArDoubExp = prevArDoubExp,                             prevArT = prevArT,                             weightListNorm = weightListNorm,                             weightListShGamma = weightListShGamma,                             weightListDoubExp = weightListDoubExp,                             weightListT = weightListT,                             combinedPredictNorm = combinedPredictNorm,                             combinedPredictShGamma = combinedPredictShGamma,                             combinedPredictDoubExp = combinedPredictDoubExp,                             combinedPredictT = combinedPredictT,                             MSENorm = MSENorm,                             MSEShGamma = MSEShGamma,                             MSEDoubExp = MSEDoubExp,                             MSET = MSET)    # salvataggio dei dataframe con gli MSE, identificati per varianza e replicazione (da 1 a nrep)  write.table(allResultsList[[r]]$MSENorm, file=paste0(outputpath, "MSENorm-varianza", sigma2, "-modello", r, ".csv"), sep="|", quote=FALSE, row.names=FALSE)  write.table(allResultsList[[r]]$MSEShGamma, file=paste0(outputpath, "MSEShGamma-varianza", sigma2, "-modello", r, ".csv"), sep="|", quote=FALSE, row.names=FALSE)  write.table(allResultsList[[r]]$MSEDoubExp, file=paste0(outputpath, "MSEDoubExp-varianza", sigma2, "-modello", r, ".csv"), sep="|", quote=FALSE, row.names=FALSE)  write.table(allResultsList[[r]]$MSET, file=paste0(outputpath, "MSET-varianza", sigma2, "-modello", r, ".csv"), sep="|", quote=FALSE, row.names=FALSE)    cat("Finisce la replicazione", r, "\n")    cat("\n")    endTime = format(Sys.time(), "%Y-%m-%d %H:%M:%S")  endTimeMath = Sys.time()  cat("Finisce la replicazione", r, "in data e ora", endTime, "\n")  print(endTimeMath-beginTimeMath)  cat("\n")
> }
> endTime0 = format(Sys.time(), "%Y-%m-%d %H:%M:%S")endTime0Math = Sys.time()cat("La procedura ?? iniziata in data e ora", beginTime0, "\n")cat("La procedura ?? finita in data e ora", endTime0, "\n")print(endTime0Math-beginTime0Math)cat("\n")
> 
> # salvataggio del dataset con i coefficienti degli AR3 da cui abbiamo simulatowrite.table(ds_coeff_ar25, file=paste0(outputpath, "coefficientiAR25veriBreak-varianza", sigma2, ".csv"), sep="|", quote=FALSE, row.names=FALSE)
> # salvataggio della LISTA FINALE CON TUTTI I RISULTATI per ogni varianza utilizzatasave(allResultsList, file=paste0(outputpath, "risultatiBreak-varianza", sigma2, ".Rdata"))
> 
> # # summary di tutto insiemesummary(MSENorm[,"L1.AFTER"]/MSENorm[,"AFTER"])summary(MSENorm[,"H.AFTER"]/MSENorm[,"AFTER"])summary(MSEShGamma[,"L1.AFTER"]/MSEShGamma[,"AFTER"])summary(MSEShGamma[,"H.AFTER"]/MSEShGamma[,"AFTER"])summary(MSEDoubExp[,"L1.AFTER"]/MSEDoubExp[,"AFTER"])summary(MSEDoubExp[,"H.AFTER"]/MSEDoubExp[,"AFTER"])summary(MSET[,"L1.AFTER"]/MSET[,"AFTER"])summary(MSET[,"H.AFTER"]/MSET[,"AFTER"])
> Spero davvero che mi possiate aiutare!! 
> Grazie 
> Laura Bettella
> 
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Mon Jun 17 19:11:10 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 17 Jun 2013 10:11:10 -0700 (PDT)
Subject: [R] Combining CSV data
In-Reply-To: <CALFKK3w6XXypggPaR5ds7yEMWehQLVE6heekNXW5jJjznTpWbw@mail.gmail.com>
References: <CALFKK3xTtutDvi12LpSp4M6hyn0bFR1-Z+7aWMTA6AT8xWG5mA@mail.gmail.com>
	<1370904118.98031.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1370916881.76218.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<CALFKK3zsGycu_yzqM6D1J8fD1px35+ypABQo-K9DXkOhQNSCWg@mail.gmail.com>
	<1370970132.53955.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CALFKK3yYMZYMA_pjPTme2U_F9VZq-mc85CMUqBjXNU26sTQr6w@mail.gmail.com>
	<1370984985.52466.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<CALFKK3zXwO3L6vcTj+=FC+dOJkXLHknXuReCs14phb77fQ3Utg@mail.gmail.com>
	<1371042629.5707.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CALFKK3xTk=CMgk+2YGYqffsBMjXhR9Fjf+EhYQ2Nx0VWryYK1A@mail.gmail.com>
	<1371043513.43455.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<CALFKK3w6XXypggPaR5ds7yEMWehQLVE6heekNXW5jJjznTpWbw@mail.gmail.com>
Message-ID: <1371489070.49725.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Modification of my previous function seems to work for the given example:
dat1<-read.table(text="
Row_ID_CR,? Data1,??? Data2,??? Data3
1,????????????????? aa,????????? bb,????????? cc
2,????????????????? dd,????????? ee,????????? ff
",sep=",",header=TRUE,stringsAsFactors=FALSE)

dat2<- read.table(text="
ROW_ID,SRC_ROW_ID,NOTE
1a,1,Comment 1
2a,2,Comment 1a
3a,2,Comment 2a
4a,1,Comment 2
5a,1,Comment 3
",sep=",",header=TRUE,stringsAsFactors=FALSE)


library(plyr)

fun1<- function(data1,data2){
??? data2$NOTE<- str_trim(data2$NOTE)? 
??????? res<- merge(data1,data2,by.x=1,by.y=2)
??? res1<- res[,-5]
??? res2<- ddply(res1,.(Row_ID_CR,Data1,Data2,Data3),summarize,NOTE=list(NOTE))
??? Mx1<- max(sapply(res2[,5],length))
??? res3<- data.frame(res2,do.call(rbind,lapply(res2[,5],function(x){
????????????????????????????????? c(x,rep(NA,Mx1-length(x)))
????????????????????????????????? })),stringsAsFactors=FALSE)
??? colnames(res3)[grep("X",colnames(res3))]<- paste0("Comment",gsub("[[:alpha:]]","",colnames(res3)[grep("X",colnames(res3))]))
??? res3
??? }??? 

?fun1(dat1,dat2)
#? Row_ID_CR??????????????? Data1??????? Data2??????? Data3
#1???????? 1?????????????????? aa?????????? bb?????????? cc
#2???????? 2?????????????????? dd?????????? ee?????????? ff
? # ????????????????????????? NOTE?? Comment1?? Comment2? Comment3
#1 Comment 1, Comment 2, Comment 3? Comment 1? Comment 2 Comment 3
#2????????? Comment 1a, Comment 2a Comment 1a Comment 2a????? <NA>
A.K.






________________________________
From: Shreya Rawal <rawal.shreya at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Cc: R mailing list <r-help at r-project.org>; jim holtman <jholtman at gmail.com> 
Sent: Monday, June 17, 2013 9:55 AM
Subject: Re: [R] Combining CSV data



Hi Arun,

Sorry to bother you again with this. When I was trying it out over the weekend with different data files I realized that its not exactly working the way it should.

For this file B:

ROW_ID ? ? ? ? |SRC_ROW_ID ? ? |NOTE
1a ? ? ? ? ? ? ? ? ?|1 ? ? ? ? ? ? ? ? ? ? ? ? |Comment 1
2a ? ? ? ? ? ? ? ? ?|2 ? ? ? ? ? ? ? ? ? ? ? ? |Comment 1a
3a ? ? ? ? ? ? ? ? ?|2 ? ? ? ? ? ? ? ? ? ? ? ? |Comment 2a
4a ? ? ? ? ? ? ? ? ?|1 ? ? ? ? ? ? ? ? ? ? ? ? |Comment 2
5a ? ? ? ? ? ? ? ? ?|1 ? ? ? ? ? ? ? ? ? ? ? ? |Comment 3


I am getting the following output for the comment columns:

NOTEcommentComment.1aComment.2a
Comment 1aComment 1a|Comment 2aComment 2Comment 3
Comment 1Comment 1|Comment 2| Comment 3Comment 2Comment 3


Where as the expected result should be:
NOTEcommentCommentxCommentx ? ? ? Commentx
Comment 1aComment 1a|Comment 2aComment 1aComment 2a
Comment 1Comment 1|Comment 2| Comment 3Comment 1Comment 2 ? ? ? ? Comment 3


I am not really concerned about the column heading, they can all be same or even blank. Just the values needs to be under different columns.

Thanks again!!



On Wed, Jun 12, 2013 at 9:25 AM, arun <smartpink111 at yahoo.com> wrote:

Hi,
>No problem.
>Arun
>
>
>
>
>
>
>
>________________________________
>From: Shreya Rawal <rawal.shreya at gmail.com>
>To: arun <smartpink111 at yahoo.com>
>Cc: R help <r-help at r-project.org>
>Sent: Wednesday, June 12, 2013 9:15 AM
>
>Subject: Re: [R] Combining CSV data
>
>
>
>Ah that makes sense. This looks perfect now. Thanks for your help on this!
>
>
>
>
>On Wed, Jun 12, 2013 at 9:10 AM, arun <smartpink111 at yahoo.com> wrote:
>
>HI Shreya,
>>#Looks like you run the two line code as a single line.
>>
>>
>>result3<-
>>data.frame(result2[,-5],read.table(text=as.character(result2$comment),sep="|",fill=TRUE,na.strings=""),stringsAsFactors=FALSE)
>>
>>
>>colnames(result3)[5:7]<- paste0("DataComment",1:3)
>>
>>?result3
>>
>>#? Row_ID_CR???????????????? Data1??????? Data2??????? Data3????? DataComment1
>>#1???????? 1??????????????????? aa?????????? bb?????????? cc This is comment 1
>>#2???????? 2??????????????????? dd?????????? ee?????????? ff This is comment 1
>>#?????? DataComment2????? DataComment3
>>#1 This is comment 2 This is comment 3
>>#2????????????? <NA>????????????? <NA>
>>
>>
>>
>>A.K.
>>
>>
>>
>>________________________________
>>From: Shreya Rawal <rawal.shreya at gmail.com>
>>To: arun <smartpink111 at yahoo.com>
>>Cc: R help <r-help at r-project.org>; jim holtman <jholtman at gmail.com>
>>Sent: Wednesday, June 12, 2013 8:58 AM
>>
>>Subject: Re: [R] Combining CSV data
>>
>>
>>
>>Great, thanks Arun, but I seem to be running into this error. Not sure what did I miss.
>>
>>> result<-data.frame(final_ouput[,-5],read.table(text=as.character(final_output$comment),sep="|",fill=TRUE,na.strings=""),stringsAsFactors=FALSE)colnames(result)[5:7]<-paste0("DataComment",1:3)
>>Error: unexpected symbol in "result<-data.frame(final_ouput[,-5],read.table(text=as.character(final_output$comment),sep="|",fill=TRUE,na.strings=""),stringsAsFactors=FALSE)colnames"
>>
>>
>>
>>On Tue, Jun 11, 2013 at 5:09 PM, arun <smartpink111 at yahoo.com> wrote:
>>
>>
>>>
>>>
>>>HI,
>>>You could use:
>>>result3<- data.frame(result2[,-5],read.table(text=as.character(result2$comment),sep="|",fill=TRUE,na.strings=""),stringsAsFactors=FALSE)
>>>colnames(result3)[5:7]<- paste0("DataComment",1:3)
>>>
>>>A.K.
>>>________________________________
>>>From: Shreya Rawal <rawal.shreya at gmail.com>
>>>To: arun <smartpink111 at yahoo.com>
>>>Sent: Tuesday, June 11, 2013 4:22 PM
>>>
>>>Subject: Re: [R] Combining CSV data
>>>
>>>
>>>
>>>Hey Arun,
>>>
>>>I guess you could guide me with this a little bit. I have been working on the solution Jim suggested (and also because that I could understand it with my little knowledge of R :))
>>>
>>>So with these commands I am able to get the data in this format:
>>>
>>>> fileA <- read.csv(text = "Row_ID_CR, ? Data1, ? ?Data2, ? ?Data3
>>>+ 1, ? ? ? ? ? ? ? ? ? aa, ? ? ? ? ?bb, ? ? ? ? ?cc
>>>+ 2, ? ? ? ? ? ? ? ? ? dd, ? ? ? ? ?ee, ? ? ? ? ?ff",?as.is?= TRUE)
>>>>?
>>>> fileB <- read.csv(text = "Row_ID_N, ? Src_Row_ID, ? DataN1
>>>+ 1a, ? ? ? ? ? ? ? 1, ? ? ? ? ? ? ? ? ? This is comment 1
>>>+ 2a, ? ? ? ? ? ? ? 1, ? ? ? ? ? ? ? ? ? This is comment 2
>>>+ 3a, ? ? ? ? ? ? ? 2, ? ? ? ? ? ? ? ? ? This is comment 1
>>>+ 4a, ? ? ? ? ? ? ? 1, ? ? ? ? ? ? ? ? ? This is comment 3",?as.is?= TRUE)
>>>>?
>>>> # get rid of leading/trailing blanks on comments
>>>> fileB$DataN1 <- gsub("^ *| *$", "", fileB$DataN1)
>>>>?
>>>> # merge together
>>>> result <- merge(fileA, fileB, by.x = 'Row_ID_CR', by.y = "Src_Row_ID")
>>>>?
>>>> # now partition by Row_ID_CR and aggregate the comments
>>>> result2 <- do.call(rbind,?
>>>+ ? ? lapply(split(result, result$Row_ID_CR), function(.grp){
>>>+ ? ? ? ? cbind(.grp[1L, -c(5,6)], comment = paste(.grp$DataN1, collapse = '|'))
>>>+ ? ? })
>>>+ )
>>>
>>>Row_ID_CR ? ? ? ? ? ? ? ? Data1 ? ? ? ?Data2 ? ? ? ?Data3 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? comment
>>>1 ? ? ? ? 1 ? ? ? ? ? ? ? ? ? ?aa ? ? ? ? ? bb ? ? ? ? ? cc ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?This is comment 1| This is comment 2| This is comment 3
>>>2 ? ? ? ? 2 ? ? ? ? ? ? ? ? ? ?dd ? ? ? ? ? ee ? ? ? ? ? ff ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?This is comment 1| This is Comment 2
>>>
>>>I can even split the last column by this:?strsplit(as.character(result2$comment), split='\\|')
>>>
>>>[[1]]
>>>[1] "This is comment 1" "This is comment 2" " This is comment 3"
>>>
>>>[[2]]
>>>[1] "This is comment 1" "This is comment 2"
>>>
>>>
>>>but now I am not sure how to combine everything together. I guess by now you must have realized how new I am to R :)
>>>
>>>Thanks!!
>>>Shreya
>>>
>>>
>>>
>>>
>>>
>>>
>>>On Tue, Jun 11, 2013 at 1:02 PM, arun <smartpink111 at yahoo.com> wrote:
>>>
>>>Hi,
>>>>If the dataset is like this with the comments in the order:
>>>>
>>>>dat2<-read.table(text="
>>>>Row_ID_N,? Src_Row_ID,? DataN1
>>>>1a,????????????? 1,????????????????? This is comment 1
>>>>2a,????????????? 1,????????????????? This is comment 2
>>>>3a,????????????? 2,????????????????? This is comment 1
>>>>4a,????????????? 1,????????????????? This is comment 3
>>>>",sep=",",header=TRUE,stringsAsFactors=FALSE)
>>>>
>>>>dat3<-read.table(text="
>>>>Row_ID_N,? Src_Row_ID,? DataN1
>>>>1a,????????????? 1,????????????????? This is comment 1
>>>>2a,????????????? 1,????????????????? This is comment 2
>>>>3a,????????????? 2,????????????????? This is comment 1?? #
>>>>
>>>>4a,????????????? 1,????????????????? This is comment 3
>>>>5a,???????? 2,????????????????? This is comment 2? #
>>>>
>>>>",sep=",",header=TRUE,stringsAsFactors=FALSE)
>>>>
>>>>
>>>>library(stringr)
>>>>library(plyr)
>>>>fun1<- function(data1,data2){
>>>>??? data2$DataN1<- str_trim(data2$DataN1)??
>>>>??????? res<- merge(data1,data2,by.x=1,by.y=2)
>>>>??? res1<- res[,-5]
>>>>??? res2<- ddply(res1,.(Row_ID_CR,Data1,Data2,Data3),summarize,DataN1=list(DataN1))
>>>>??? Mx1<- max(sapply(res2[,5],length))
>>>>??? res3<- data.frame(res2[,-5],do.call(rbind,lapply(res2[,5],function(x){
>>>>????????????????????????????????? c(x,rep(NA,Mx1-length(x)))
>>>>
>>>>????????????????????????????????? })),stringsAsFactors=FALSE)
>>>>??? colnames(res3)[grep("X",colnames(res3))]<- paste0("DataComment",gsub("[[:alpha:]]","",colnames(res3)[grep("X",colnames(res3))]))
>>>>??? res3
>>>>??? }???
>>>>
>>>>?????
>>>>fun1(dat1,dat2)
>>>>#? Row_ID_CR??????????????? Data1??????? Data2??????? Data3????? DataComment1
>>>>#1???????? 1?????????????????? aa?????????? bb?????????? cc This is comment 1
>>>>
>>>>#2???????? 2?????????????????? dd?????????? ee?????????? ff This is comment 1
>>>>#?????? DataComment2????? DataComment3
>>>>#1 This is comment 2 This is comment 3
>>>>#2????????????? <NA>????????????? <NA>
>>>>
>>>>?fun1(dat1,dat3)
>>>>#? Row_ID_CR??????????????? Data1??????? Data2??????? Data3????? DataComment1
>>>>#1???????? 1?????????????????? aa?????????? bb?????????? cc This is comment 1
>>>>
>>>>#2???????? 2?????????????????? dd?????????? ee?????????? ff This is comment 1
>>>>?# ???? DataComment2????? DataComment3
>>>>#1 This is comment 2 This is comment 3
>>>>
>>>>#2 This is comment 2????????????? <NA>
>>>>
>>>>
>>>>Otherwise, you need to provide an example that matches the real dataset.
>>>>A.K.
>>>>
>>>>________________________________
>>>>From: Shreya Rawal <rawal.shreya at gmail.com>
>>>>To: arun <smartpink111 at yahoo.com>
>>>>Cc: R help <r-help at r-project.org>
>>>>Sent: Tuesday, June 11, 2013 12:22 PM
>>>>
>>>>Subject: Re: [R] Combining CSV data
>>>>
>>>>
>>>>
>>>>Hi Arun,
>>>>
>>>>Thanks for your reply. Unfortunately the Comments are just text in the real data. There is no way to differentiate based on the value of the Comments column. I guess because of that reason I couldn't get your solution to work properly. Do you think I can try it for a more general case where we don't merger/split the comments based on the values?
>>>>
>>>>Thanks for your help, I appreciate! ??
>>>>
>>>>
>>>>
>>>>On Mon, Jun 10, 2013 at 10:14 PM, arun <smartpink111 at yahoo.com> wrote:
>>>>
>>>>HI,
>>>>>I am not sure about your DataN1 column.? If there is any identifier to differentiate the comments (in this case 1,2,3), then it will easier to place that in the correct column.
>>>>>? My previous solution is not helpful in situations like these:
>>>>>
>>>>>dat2<-read.table(text="
>>>>>Row_ID_N,? Src_Row_ID,? DataN1
>>>>>1a,????????????? 1,????????????????? This is comment 1
>>>>>2a,????????????? 1,????????????????? This is comment 2
>>>>>3a,????????????? 2,????????????????? This is comment 2
>>>>>4a,????????????? 1,????????????????? This is comment 3
>>>>>",sep=",",header=TRUE,stringsAsFactors=FALSE)
>>>>>dat3<-read.table(text="
>>>>>
>>>>>Row_ID_N,? Src_Row_ID,? DataN1
>>>>>1a,????????????? 1,????????????????? This is comment 1
>>>>>2a,????????????? 1,????????????????? This is comment 2
>>>>>3a,????????????? 2,????????????????? This is comment 3
>>>>>4a,????????????? 1,????????????????? This is comment 3
>>>>>5a,??? ??? ?2,????????????????? This is comment 2
>>>>>",sep=",",header=TRUE,stringsAsFactors=FALSE)
>>>>>
>>>>>
>>>>>library(stringr)
>>>>>library(plyr)
>>>>>fun1<- function(data1,data2){
>>>>>??? data2$DataN1<- str_trim(data2$DataN1)???
>>>>>??????? res<- merge(data1,data2,by.x=1,by.y=2)
>>>>>??? res1<- res[,-5]
>>>>>??? res2<- ddply(res1,.(Row_ID_CR,Data1,Data2,Data3),summarize,DataN1=list(DataN1))
>>>>>??? Mx1<- max(sapply(res2[,5],length))
>>>>>??? res3<- data.frame(res2[,-5],do.call(rbind,lapply(res2[,5],function(x){
>>>>>??? ??? ??? ??? ??? ??? ??? ??? ? indx<- as.numeric(gsub("[[:alpha:]]","",x))
>>>>>??? ??? ??? ??? ??? ??? ??? ??? ? x[match(seq(Mx1),indx)]
>>>>>??? ??? ??? ??? ??? ??? ??? ??? ? })),stringsAsFactors=FALSE)
>>>>>
>>>>>??? colnames(res3)[grep("X",colnames(res3))]<- paste0("DataComment",gsub("[[:alpha:]]","",colnames(res3)[grep("X",colnames(res3))]))
>>>>>??? res3
>>>>>??? }??? ??? ??
>>>>>fun1(dat1,dat2)
>>>>>
>>>>>#? Row_ID_CR??????????????? Data1??????? Data2??????? Data3????? DataComment1
>>>>>#1???????? 1?????????????????? aa?????????? bb?????????? cc This is comment 1
>>>>>#2???????? 2?????????????????? dd?????????? ee?????????? ff????????????? <NA>
>>>>>
>>>>>#?????? DataComment2????? DataComment3
>>>>>#1 This is comment 2 This is comment 3
>>>>>#2 This is comment 2????????????? <NA>
>>>>>?fun1(dat1,dat3)
>>>>>
>>>>>#? Row_ID_CR??????????????? Data1??????? Data2??????? Data3????? DataComment1
>>>>>#1???????? 1?????????????????? aa?????????? bb?????????? cc This is comment 1
>>>>>#2???????? 2?????????????????? dd?????????? ee?????????? ff????????????? <NA>
>>>>>
>>>>>#?????? DataComment2????? DataComment3
>>>>>#1 This is comment 2 This is comment 3
>>>>>#2 This is comment 2 This is comment 3
>>>>>
>>>>>
>>>>>
>>>>>A.K.
>>>>>
>>>>>
>>>>>----- Original Message -----
>>>>>
>>>>>From: arun <smartpink111 at yahoo.com>
>>>>>To: Shreya Rawal <rawal.shreya at gmail.com>
>>>>>Cc: R help <r-help at r-project.org>
>>>>>Sent: Monday, June 10, 2013 6:41 PM
>>>>>Subject: Re: [R] Combining CSV data
>>>>>
>>>>>Hi,
>>>>>Try this:
>>>>>
>>>>>dat1<-read.table(text="
>>>>>Row_ID_CR,? Data1,??? Data2,??? Data3
>>>>>1,????????????????? aa,????????? bb,????????? cc
>>>>>2,????????????????? dd,????????? ee,????????? ff
>>>>>",sep=",",header=TRUE,stringsAsFactors=FALSE)
>>>>>
>>>>>dat2<-read.table(text="
>>>>>Row_ID_N,? Src_Row_ID,? DataN1
>>>>>1a,????????????? 1,????????????????? This is comment 1
>>>>>2a,????????????? 1,????????????????? This is comment 2
>>>>>3a,????????????? 2,????????????????? This is comment 1
>>>>>4a,????????????? 1,????????????????? This is comment 3
>>>>>",sep=",",header=TRUE,stringsAsFactors=FALSE)
>>>>>library(stringr)
>>>>>dat2$DataN1<-str_trim(dat2$DataN1)
>>>>>res<- merge(dat1,dat2,by.x=1,by.y=2)
>>>>>?res1<-res[,-5]
>>>>>library(plyr)
>>>>>?res2<-ddply(res1,.(Row_ID_CR,Data1,Data2,Data3),summarize, DataN1=list(DataN1))
>>>>>?res2
>>>>>?# Row_ID_CR??????????????? Data1??????? Data2??????? Data3
>>>>>#1???????? 1?????????????????? aa?????????? bb?????????? cc
>>>>>#2???????? 2?????????????????? dd?????????? ee?????????? ff
>>>>>#?????????????????????????????????????????????????? DataN1
>>>>>#1 This is comment 1, This is comment 2, This is comment 3
>>>>>#2?????????????????????????????????????? This is comment 1
>>>>>
>>>>>
>>>>>
>>>>>res3<-data.frame(res2[,-5],t(apply(do.call(rbind,res2[,5]),1,function(x) {x[duplicated(x)]<-NA;x})))
>>>>>?colnames(res3)[grep("X",colnames(res3))]<- paste0("DataComment",gsub("[[:alpha:]]","",colnames(res3)[grep("X",colnames(res3))]))
>>>>>res3
>>>>>#? Row_ID_CR??????????????? Data1??????? Data2??????? Data3????? DataComment1
>>>>>#1???????? 1?????????????????? aa?????????? bb?????????? cc This is comment 1
>>>>>#2???????? 2?????????????????? dd?????????? ee?????????? ff This is comment 1
>>>>>#?????? DataComment2????? DataComment3
>>>>>#1 This is comment 2 This is comment 3
>>>>>#2????????????? <NA>????????????? <NA>
>>>>>
>>>>>A.K.
>>>>>
>>>>>
>>>>>----- Original Message -----
>>>>>From: Shreya Rawal <rawal.shreya at gmail.com>
>>>>>To: r-help at r-project.org
>>>>>Cc:
>>>>>Sent: Monday, June 10, 2013 4:38 PM
>>>>>Subject: [R] Combining CSV data
>>>>>
>>>>>Hello R community,
>>>>>
>>>>>I am trying to combine two CSV files that look like this:
>>>>>
>>>>>File A
>>>>>
>>>>>Row_ID_CR,?? Data1,? ? Data2,? ? Data3
>>>>>1,? ? ? ? ? ? ? ? ?? aa,? ? ? ? ? bb,? ? ? ? ? cc
>>>>>2,? ? ? ? ? ? ? ? ?? dd,? ? ? ? ? ee,? ? ? ? ? ff
>>>>>
>>>>>
>>>>>File B
>>>>>
>>>>>Row_ID_N,?? Src_Row_ID,?? DataN1
>>>>>1a,? ? ? ? ? ? ?? 1,? ? ? ? ? ? ? ? ?? This is comment 1
>>>>>2a,? ? ? ? ? ? ?? 1,? ? ? ? ? ? ? ? ?? This is comment 2
>>>>>3a,? ? ? ? ? ? ?? 2,? ? ? ? ? ? ? ? ?? This is comment 1
>>>>>4a,? ? ? ? ? ? ?? 1,? ? ? ? ? ? ? ? ?? This is comment 3
>>>>>
>>>>>And the output I am looking for is, comparing the values of Row_ID_CR and
>>>>>Src_Row_ID
>>>>>
>>>>>Output
>>>>>
>>>>>ROW_ID_CR,? ? Data1,? ? Data2,? ? Data3,? ? DataComment1,
>>>>>DataComment2,? ? ? ? ? DataComment3
>>>>>1,? ? ? ? ? ? ? ? ? ? ? aa,? ? ? ?? bb,? ? ? ?? cc,? ? ? ? This is
>>>>>comment1,? ? This is comment2,? ?? This is comment 3
>>>>>2,? ? ? ? ? ? ? ? ? ? ? dd,? ? ? ? ? ee,? ? ? ?? ff,? ? ? ? ? This is
>>>>>comment1
>>>>>
>>>>>
>>>>>I am a novice R user, I am able to replicate a left join but I need a bit
>>>>>more in the final result.
>>>>>
>>>>>
>>>>>Thanks!!
>>>>>
>>>>>??? [[alternative HTML version deleted]]
>>>>>
>>>>>______________________________________________
>>>>>R-help at r-project.org mailing list
>>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>
>>>>
>>>
>>
>?


From gunter.berton at gene.com  Mon Jun 17 19:34:30 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 17 Jun 2013 10:34:30 -0700
Subject: [R] NMDS with missing data?
In-Reply-To: <CAEWzS+HyFwGK2X6HiDkF+K47eSaqEiQWKHmH4yWkuVvfpm95WQ@mail.gmail.com>
References: <CAEWzS+FE0Rnj2PBD1GOxNwaNmQDuzKKxYHL1kDdXKcLd9Xamxw@mail.gmail.com>
	<01f501ce4cbc$39b8d460$ad2a7d20$@tamu.edu>
	<CAEWzS+Fp_hZ6ZMNPQAV-cSY+Ths8n-L8vcZhm-5EPA98bcU3Mw@mail.gmail.com>
	<026501ce4ff0$c39350c0$4ab9f240$@tamu.edu>
	<CAEWzS+HyFwGK2X6HiDkF+K47eSaqEiQWKHmH4yWkuVvfpm95WQ@mail.gmail.com>
Message-ID: <CACk-te0sK-uiZfZUT7DyP==3v3s_KrefQWabiokrHjOKCUp8ng@mail.gmail.com>

Just wanted to note that one does **not** use
"prcomp() on the correlation matrix of the variables."

As ?prcomp says, it uses the svd of the data matrix, which is
generally preferable.

Cheers,
Bert

On Mon, Jun 17, 2013 at 10:02 AM, Elizabeth Beck
<elizabethbeck0 at gmail.com> wrote:
> Hello David,
>
> Yes my variables are all numeric....I have a few questions regarding your 2
> options.
>
> Would these still be the best options if missing data was not an issue? I
> was told that I should be performing NMDS as it has few assumptions on the
> data distribution but neither of your options use this.
>
> If NMDS is not preferred and I were to perform a PCA, can you tell me why
> you chose prcomp()? My statistical text (Discovering Statistics Using R)
> explains PCA quite well using principal() in the psych package so I am just
> wondering the advantages of one over the other... I am overwhelmed by the
> number of ordination methods!
>
> Thank you,
> Elizabeth
>
> On Mon, May 13, 2013 at 9:44 AM, David Carlson <dcarlson at tamu.edu> wrote:
>
>> First. Do not use html messages. They are converted to plain text and your
>> table ends up a mess. See below. It appears the variables are all numeric?
>> If so, there are two standard approaches to handling multiple scales and
>> magnitudes with cluster analysis:
>>
>> 1. Use z-scores. The scale() function will convert each variable into a
>> standard score with a mean of 0 and a standard deviation of 1. Then use
>> Euclidean distance in the dist() function which will adjust for your
>> missing
>> values.
>>
>> 2. Use prcomp() on the correlation matrix of the variables to extract a set
>> of principal components and use the principal component scores in the
>> cluster analysis. This may allow you to reduce the number of variables in
>> the data set if the 29 variables are correlated with one another.
>>
>> -------------------------------------
>> David L Carlson
>> Associate Professor of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>>
>> From: Elizabeth Beck [mailto:elizabethbeck0 at gmail.com]
>> Sent: Friday, May 10, 2013 1:20 PM
>> To: dcarlson at tamu.edu
>> Cc: r-help at r-project.org
>> Subject: Re: [R] NMDS with missing data?
>>
>> Hi David,
>>
>> You are right in that Bray-Curtis is not suitable for my dataset, and that
>> my variables are very different. Given your suggestions, I am struggling
>> with how to transform or standardize my data given that they vary so much.
>> Additionally, looking at the dist() package I am not sure which distance
>> measure would be most appropriate. Euclidean seems to most widely used but
>> I'm not sure if it is appropriate for myself (there much more help for
>> ecology data than toxicology). Given a sample of my data below ( total of
>> 287 obs. of  29 variables) can you suggest a starting point?
>>
>> SODIUM
>> K
>> CL
>> HCO3
>> ANION
>> CA
>> P
>> GLUCOSE
>>  CHOLEST
>>        GGT
>>    GLDH
>> CK
>> AST
>> PROTEIN
>> ALBUMIN
>> GLOBULIN
>> A_G
>> UA
>> BA
>> CORTICO
>> T3
>> T4
>> THYROID
>> 145
>> 3.3
>> 102
>> 24
>> 22
>> 2.9
>> 2.45
>> 9.8
>> 5.7
>> 3
>> 3
>> 678
>> 5
>> 34
>> 15
>> 19
>> 0.79
>> 180
>> 6
>> 70.97
>> 1.31
>> 12.77
>> 0.102376
>> 146
>> 3.2
>> 102
>> 21
>> 26
>> 2.89
>> 2.68
>> 11.1
>> 6.78
>> 3
>> 4
>> 1290
>> 9
>> 36
>> 18
>> 18
>> 1
>> 170
>> 13
>> 79.1
>> 3.51
>> 18.78
>> 0.186751
>> 147
>> 2.5
>> 103
>> 22
>> 25
>> 2.96
>> 2.59
>> 10
>> 5.78
>> 3
>> 6
>> 1582
>> 11
>> 35
>> 17
>> 18
>> 0.94
>> 272
>> 10
>> 65.84
>> 1.84
>> 15.5
>> 0.118602
>> 148
>> 2.5
>> 101
>> 21
>> 29
>> 2.91
>> 2.91
>> 10.6
>> 5.83
>> 3
>> 3
>> 1479
>> 8
>> 35
>> 17
>> 18
>> 0.94
>> 317
>> 8
>> 74.9
>> 2.59
>> 20.68
>> 0.125389
>>
>> Thank you!
>> Elizabeth
>>
>> On Thu, May 9, 2013 at 7:50 AM, David Carlson <dcarlson at tamu.edu> wrote:
>> Since you pass your entire data.frame to metaMDS(), your first error
>> probably comes from the fact that you have included ID as one of the
>> variables. You should look at the results of
>>
>> str(dat)
>>
>> You can drop cases with missing values using
>>
>> > dat2 <- na.omit(dat)
>> > metaMDS(dat2[,-1])
>>
>> would run the analysis on all but the first column (ID) with all the cases
>> containing complete data. But that assumes that sex and exposure are not
>> factors.
>>
>> Or you could use one of the distance functions in dist() which adjust for
>> missing values. However dist() does not have an option to use Bray-Curtis
>> (the default in metaMDS()). Bray-Curtis is designed for comparing species
>> counts or proportions so it is not clear that it is an appropriate
>> dissimilarity measure for your data. Further, your data seem contain a
>> mixture of measurement scales and/or magnitudes so some variable
>> standardization or transformations are probably necessary before you can
>> get
>> any useful results from MDS.
>>
>> -------------------------------------
>> David L Carlson
>> Associate Professor of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On
>> Behalf Of Elizabeth Beck
>> Sent: Wednesday, May 8, 2013 3:39 PM
>> To: r-help at r-project.org
>> Subject: [R] NMDS with missing data?
>>
>> Hi,
>> I'm trying to run NMDS (non-metric multidimensional scaling) with R vegan
>> (metaMDS) but I have a few NAs in my data set. I've tried to run it 2 ways.
>>
>> The first way with my entire data set which includes variables such as ID,
>> sex, exposure, treatment, sodium, potassium, chloride....
>>
>> mydata.mds<-metaMDS(dat)
>>
>> I get the following error:
>>
>>  in if (any(autotransform, noshare > 0, wascores) && any(comm < 0)) { :
>>   missing value where TRUE/FALSE needed
>> In addition: Warning messages:
>> 1: In Ops.factor(left, right) : < not meaningful for factors
>> 2: In Ops.factor(left, right) : < not meaningful for factors
>> 3: In Ops.factor(left, right) : < not meaningful for factors
>> 4: In Ops.factor(left, right) : < not meaningful for factors
>> 5: In Ops.factor(left, right) : < not meaningful for factors
>>
>> The second way with only those last biochemical variables (29 in total).
>>
>> mydata.mds<-metaMDS(measurements)
>>
>> I get this error:
>>
>> Error in if (any(autotransform, noshare > 0, wascores) && any(comm < 0)) {
>> :
>>   missing value where TRUE/FALSE needed
>>
>> My go to "na.rm=TRUE" does nothing. Any ideas on how to account for NAs and
>> if so which of the above options I should be using?
>> Thanks!
>> Elizabeth
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From bhh at xs4all.nl  Mon Jun 17 19:48:30 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 17 Jun 2013 19:48:30 +0200
Subject: [R] problemi di allocazione di memoria
In-Reply-To: <BLU0-SMTP169AEE76DCCA9CE045EEC22DE830@phx.gbl>
References: <BLU0-SMTP169AEE76DCCA9CE045EEC22DE830@phx.gbl>
Message-ID: <4A9BDABB-1BE3-41AE-A505-727464FBD86B@xs4all.nl>



Please do not reply privately.
Reply to the list.

If you have 417GB and that is not enough there must be something wrong with your approach.
As I said your code is too long. You should try to make a small, short example illustrating what you are attempting to do.

Berend

On 17-06-2013, at 19:24, Laura Bettella <cyri at live.it> wrote:

> I'm sorry!
> I thinh my problem is about the memory allocation, because after a number of simulation, there is a warning message that says that i haven't enough memory, but I have 417 GB! How can I resolve it? May I could expand the memory? How?
> 
> Thanks
> 
> 
> Inviato da Samsung Mobile


From dcarlson at tamu.edu  Mon Jun 17 20:02:03 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 17 Jun 2013 13:02:03 -0500
Subject: [R] NMDS with missing data?
In-Reply-To: <CACk-te0sK-uiZfZUT7DyP==3v3s_KrefQWabiokrHjOKCUp8ng@mail.gmail.com>
References: <CAEWzS+FE0Rnj2PBD1GOxNwaNmQDuzKKxYHL1kDdXKcLd9Xamxw@mail.gmail.com>	<01f501ce4cbc$39b8d460$ad2a7d20$@tamu.edu>	<CAEWzS+Fp_hZ6ZMNPQAV-cSY+Ths8n-L8vcZhm-5EPA98bcU3Mw@mail.gmail.com>	<026501ce4ff0$c39350c0$4ab9f240$@tamu.edu>	<CAEWzS+HyFwGK2X6HiDkF+K47eSaqEiQWKHmH4yWkuVvfpm95WQ@mail.gmail.com>
	<CACk-te0sK-uiZfZUT7DyP==3v3s_KrefQWabiokrHjOKCUp8ng@mail.gmail.com>
Message-ID: <027101ce6b84$c572e720$5058b560$@tamu.edu>

First, Bert is correct. I should have said to use prcomp(dat, center=TRUE, scale=TRUE). That will run the svd on the standardized variables which is equivalent to using princomp(dat, cor=TRUE). You will have to remove the cases with missing variables or impute the missing variables using one of many options in R.

The principal() function in package psych should be fine and will probably give nearly identical results. It does have the ability to generate a pairwise-deletion correlation matrix so you could include your cases with missing values. I would set rotate="none" least initially. Hopefully your text will explain why this is a good idea.

I assume you are looking for interesting patterns in the data rather than trying to test a specific hypothesis. Given that, you should try both (or all three with principal()) and see if there are any interesting differences between them.

Earlier I asked if all your variables are numeric (or dichotomies). If any are categorical (factors), these suggestions may have to be revised.

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: Bert Gunter [mailto:gunter.berton at gene.com] 
Sent: Monday, June 17, 2013 12:35 PM
To: Elizabeth Beck
Cc: David Carlson; r-help at r-project.org
Subject: Re: [R] NMDS with missing data?

Just wanted to note that one does **not** use
"prcomp() on the correlation matrix of the variables."

As ?prcomp says, it uses the svd of the data matrix, which is
generally preferable.

Cheers,
Bert

On Mon, Jun 17, 2013 at 10:02 AM, Elizabeth Beck
<elizabethbeck0 at gmail.com> wrote:
> Hello David,
>
> Yes my variables are all numeric....I have a few questions regarding your 2
> options.
>
> Would these still be the best options if missing data was not an issue? I
> was told that I should be performing NMDS as it has few assumptions on the
> data distribution but neither of your options use this.
>
> If NMDS is not preferred and I were to perform a PCA, can you tell me why
> you chose prcomp()? My statistical text (Discovering Statistics Using R)
> explains PCA quite well using principal() in the psych package so I am just
> wondering the advantages of one over the other... I am overwhelmed by the
> number of ordination methods!
>
> Thank you,
> Elizabeth
>
> On Mon, May 13, 2013 at 9:44 AM, David Carlson <dcarlson at tamu.edu> wrote:
>
>> First. Do not use html messages. They are converted to plain text and your
>> table ends up a mess. See below. It appears the variables are all numeric?
>> If so, there are two standard approaches to handling multiple scales and
>> magnitudes with cluster analysis:
>>
>> 1. Use z-scores. The scale() function will convert each variable into a
>> standard score with a mean of 0 and a standard deviation of 1. Then use
>> Euclidean distance in the dist() function which will adjust for your
>> missing
>> values.
>>
>> 2. Use prcomp() on the correlation matrix of the variables to extract a set
>> of principal components and use the principal component scores in the
>> cluster analysis. This may allow you to reduce the number of variables in
>> the data set if the 29 variables are correlated with one another.
>>
>> -------------------------------------
>> David L Carlson
>> Associate Professor of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>>
>> From: Elizabeth Beck [mailto:elizabethbeck0 at gmail.com]
>> Sent: Friday, May 10, 2013 1:20 PM
>> To: dcarlson at tamu.edu
>> Cc: r-help at r-project.org
>> Subject: Re: [R] NMDS with missing data?
>>
>> Hi David,
>>
>> You are right in that Bray-Curtis is not suitable for my dataset, and that
>> my variables are very different. Given your suggestions, I am struggling
>> with how to transform or standardize my data given that they vary so much.
>> Additionally, looking at the dist() package I am not sure which distance
>> measure would be most appropriate. Euclidean seems to most widely used but
>> I'm not sure if it is appropriate for myself (there much more help for
>> ecology data than toxicology). Given a sample of my data below ( total of
>> 287 obs. of  29 variables) can you suggest a starting point?
>>
>> SODIUM
>> K
>> CL
>> HCO3
>> ANION
>> CA
>> P
>> GLUCOSE
>>  CHOLEST
>>        GGT
>>    GLDH
>> CK
>> AST
>> PROTEIN
>> ALBUMIN
>> GLOBULIN
>> A_G
>> UA
>> BA
>> CORTICO
>> T3
>> T4
>> THYROID
>> 145
>> 3.3
>> 102
>> 24
>> 22
>> 2.9
>> 2.45
>> 9.8
>> 5.7
>> 3
>> 3
>> 678
>> 5
>> 34
>> 15
>> 19
>> 0.79
>> 180
>> 6
>> 70.97
>> 1.31
>> 12.77
>> 0.102376
>> 146
>> 3.2
>> 102
>> 21
>> 26
>> 2.89
>> 2.68
>> 11.1
>> 6.78
>> 3
>> 4
>> 1290
>> 9
>> 36
>> 18
>> 18
>> 1
>> 170
>> 13
>> 79.1
>> 3.51
>> 18.78
>> 0.186751
>> 147
>> 2.5
>> 103
>> 22
>> 25
>> 2.96
>> 2.59
>> 10
>> 5.78
>> 3
>> 6
>> 1582
>> 11
>> 35
>> 17
>> 18
>> 0.94
>> 272
>> 10
>> 65.84
>> 1.84
>> 15.5
>> 0.118602
>> 148
>> 2.5
>> 101
>> 21
>> 29
>> 2.91
>> 2.91
>> 10.6
>> 5.83
>> 3
>> 3
>> 1479
>> 8
>> 35
>> 17
>> 18
>> 0.94
>> 317
>> 8
>> 74.9
>> 2.59
>> 20.68
>> 0.125389
>>
>> Thank you!
>> Elizabeth
>>
>> On Thu, May 9, 2013 at 7:50 AM, David Carlson <dcarlson at tamu.edu> wrote:
>> Since you pass your entire data.frame to metaMDS(), your first error
>> probably comes from the fact that you have included ID as one of the
>> variables. You should look at the results of
>>
>> str(dat)
>>
>> You can drop cases with missing values using
>>
>> > dat2 <- na.omit(dat)
>> > metaMDS(dat2[,-1])
>>
>> would run the analysis on all but the first column (ID) with all the cases
>> containing complete data. But that assumes that sex and exposure are not
>> factors.
>>
>> Or you could use one of the distance functions in dist() which adjust for
>> missing values. However dist() does not have an option to use Bray-Curtis
>> (the default in metaMDS()). Bray-Curtis is designed for comparing species
>> counts or proportions so it is not clear that it is an appropriate
>> dissimilarity measure for your data. Further, your data seem contain a
>> mixture of measurement scales and/or magnitudes so some variable
>> standardization or transformations are probably necessary before you can
>> get
>> any useful results from MDS.
>>
>> -------------------------------------
>> David L Carlson
>> Associate Professor of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On
>> Behalf Of Elizabeth Beck
>> Sent: Wednesday, May 8, 2013 3:39 PM
>> To: r-help at r-project.org
>> Subject: [R] NMDS with missing data?
>>
>> Hi,
>> I'm trying to run NMDS (non-metric multidimensional scaling) with R vegan
>> (metaMDS) but I have a few NAs in my data set. I've tried to run it 2 ways.
>>
>> The first way with my entire data set which includes variables such as ID,
>> sex, exposure, treatment, sodium, potassium, chloride....
>>
>> mydata.mds<-metaMDS(dat)
>>
>> I get the following error:
>>
>>  in if (any(autotransform, noshare > 0, wascores) && any(comm < 0)) { :
>>   missing value where TRUE/FALSE needed
>> In addition: Warning messages:
>> 1: In Ops.factor(left, right) : < not meaningful for factors
>> 2: In Ops.factor(left, right) : < not meaningful for factors
>> 3: In Ops.factor(left, right) : < not meaningful for factors
>> 4: In Ops.factor(left, right) : < not meaningful for factors
>> 5: In Ops.factor(left, right) : < not meaningful for factors
>>
>> The second way with only those last biochemical variables (29 in total).
>>
>> mydata.mds<-metaMDS(measurements)
>>
>> I get this error:
>>
>> Error in if (any(autotransform, noshare > 0, wascores) && any(comm < 0)) {
>> :
>>   missing value where TRUE/FALSE needed
>>
>> My go to "na.rm=TRUE" does nothing. Any ideas on how to account for NAs and
>> if so which of the above options I should be using?
>> Thanks!
>> Elizabeth
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From gunter.berton at gene.com  Mon Jun 17 20:28:43 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 17 Jun 2013 11:28:43 -0700
Subject: [R] NMDS with missing data?
In-Reply-To: <027101ce6b84$c572e720$5058b560$@tamu.edu>
References: <CAEWzS+FE0Rnj2PBD1GOxNwaNmQDuzKKxYHL1kDdXKcLd9Xamxw@mail.gmail.com>
	<01f501ce4cbc$39b8d460$ad2a7d20$@tamu.edu>
	<CAEWzS+Fp_hZ6ZMNPQAV-cSY+Ths8n-L8vcZhm-5EPA98bcU3Mw@mail.gmail.com>
	<026501ce4ff0$c39350c0$4ab9f240$@tamu.edu>
	<CAEWzS+HyFwGK2X6HiDkF+K47eSaqEiQWKHmH4yWkuVvfpm95WQ@mail.gmail.com>
	<CACk-te0sK-uiZfZUT7DyP==3v3s_KrefQWabiokrHjOKCUp8ng@mail.gmail.com>
	<027101ce6b84$c572e720$5058b560$@tamu.edu>
Message-ID: <CACk-te16H06QYQPUKvQWE1QEJNX-CuBpo6HQX7oL3zY9Gy-gOg@mail.gmail.com>

David et. al.:

I hate to be a pest but ...

On Mon, Jun 17, 2013 at 11:02 AM, David Carlson <dcarlson at tamu.edu> wrote:
> First, Bert is correct. I should have said to use prcomp(dat, center=TRUE, scale=TRUE). That will run the svd on the standardized variables which is equivalent to using princomp(dat, cor=TRUE).


***You will have to remove the cases with missing variables or impute
the missing variables using one of many options in R. ***

Depending on the number of missings and nature of the missingness,
this can be a crucial issue. Omitting all data with missing entries
makes very strong assumptions about the nature of the missingness and
can lead to highly biased results. Which is problematic for
exploration, even. The same is true with imputation -- you need to do
it properly. Again, depending on the number of cases at issue.

So it may be wise for Elizabeth to consult a local statistical expert
and not rely on superficial background from a text and remote advice.
There may be dragons ...

Cheers,
Bert


>
> The principal() function in package psych should be fine and will probably give nearly identical results. It does have the ability to generate a pairwise-deletion correlation matrix so you could include your cases with missing values. I would set rotate="none" least initially. Hopefully your text will explain why this is a good idea.
>
> I assume you are looking for interesting patterns in the data rather than trying to test a specific hypothesis. Given that, you should try both (or all three with principal()) and see if there are any interesting differences between them.
>
> Earlier I asked if all your variables are numeric (or dichotomies). If any are categorical (factors), these suggestions may have to be revised.
>
> -------------------------------------
> David L Carlson
> Associate Professor of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
> -----Original Message-----
> From: Bert Gunter [mailto:gunter.berton at gene.com]
> Sent: Monday, June 17, 2013 12:35 PM
> To: Elizabeth Beck
> Cc: David Carlson; r-help at r-project.org
> Subject: Re: [R] NMDS with missing data?
>
> Just wanted to note that one does **not** use
> "prcomp() on the correlation matrix of the variables."
>
> As ?prcomp says, it uses the svd of the data matrix, which is
> generally preferable.
>
> Cheers,
> Bert
>
> On Mon, Jun 17, 2013 at 10:02 AM, Elizabeth Beck
> <elizabethbeck0 at gmail.com> wrote:
>> Hello David,
>>
>> Yes my variables are all numeric....I have a few questions regarding your 2
>> options.
>>
>> Would these still be the best options if missing data was not an issue? I
>> was told that I should be performing NMDS as it has few assumptions on the
>> data distribution but neither of your options use this.
>>
>> If NMDS is not preferred and I were to perform a PCA, can you tell me why
>> you chose prcomp()? My statistical text (Discovering Statistics Using R)
>> explains PCA quite well using principal() in the psych package so I am just
>> wondering the advantages of one over the other... I am overwhelmed by the
>> number of ordination methods!
>>
>> Thank you,
>> Elizabeth
>>
>> On Mon, May 13, 2013 at 9:44 AM, David Carlson <dcarlson at tamu.edu> wrote:
>>
>>> First. Do not use html messages. They are converted to plain text and your
>>> table ends up a mess. See below. It appears the variables are all numeric?
>>> If so, there are two standard approaches to handling multiple scales and
>>> magnitudes with cluster analysis:
>>>
>>> 1. Use z-scores. The scale() function will convert each variable into a
>>> standard score with a mean of 0 and a standard deviation of 1. Then use
>>> Euclidean distance in the dist() function which will adjust for your
>>> missing
>>> values.
>>>
>>> 2. Use prcomp() on the correlation matrix of the variables to extract a set
>>> of principal components and use the principal component scores in the
>>> cluster analysis. This may allow you to reduce the number of variables in
>>> the data set if the 29 variables are correlated with one another.
>>>
>>> -------------------------------------
>>> David L Carlson
>>> Associate Professor of Anthropology
>>> Texas A&M University
>>> College Station, TX 77840-4352
>>>
>>> From: Elizabeth Beck [mailto:elizabethbeck0 at gmail.com]
>>> Sent: Friday, May 10, 2013 1:20 PM
>>> To: dcarlson at tamu.edu
>>> Cc: r-help at r-project.org
>>> Subject: Re: [R] NMDS with missing data?
>>>
>>> Hi David,
>>>
>>> You are right in that Bray-Curtis is not suitable for my dataset, and that
>>> my variables are very different. Given your suggestions, I am struggling
>>> with how to transform or standardize my data given that they vary so much.
>>> Additionally, looking at the dist() package I am not sure which distance
>>> measure would be most appropriate. Euclidean seems to most widely used but
>>> I'm not sure if it is appropriate for myself (there much more help for
>>> ecology data than toxicology). Given a sample of my data below ( total of
>>> 287 obs. of  29 variables) can you suggest a starting point?
>>>
>>> SODIUM
>>> K
>>> CL
>>> HCO3
>>> ANION
>>> CA
>>> P
>>> GLUCOSE
>>>  CHOLEST
>>>        GGT
>>>    GLDH
>>> CK
>>> AST
>>> PROTEIN
>>> ALBUMIN
>>> GLOBULIN
>>> A_G
>>> UA
>>> BA
>>> CORTICO
>>> T3
>>> T4
>>> THYROID
>>> 145
>>> 3.3
>>> 102
>>> 24
>>> 22
>>> 2.9
>>> 2.45
>>> 9.8
>>> 5.7
>>> 3
>>> 3
>>> 678
>>> 5
>>> 34
>>> 15
>>> 19
>>> 0.79
>>> 180
>>> 6
>>> 70.97
>>> 1.31
>>> 12.77
>>> 0.102376
>>> 146
>>> 3.2
>>> 102
>>> 21
>>> 26
>>> 2.89
>>> 2.68
>>> 11.1
>>> 6.78
>>> 3
>>> 4
>>> 1290
>>> 9
>>> 36
>>> 18
>>> 18
>>> 1
>>> 170
>>> 13
>>> 79.1
>>> 3.51
>>> 18.78
>>> 0.186751
>>> 147
>>> 2.5
>>> 103
>>> 22
>>> 25
>>> 2.96
>>> 2.59
>>> 10
>>> 5.78
>>> 3
>>> 6
>>> 1582
>>> 11
>>> 35
>>> 17
>>> 18
>>> 0.94
>>> 272
>>> 10
>>> 65.84
>>> 1.84
>>> 15.5
>>> 0.118602
>>> 148
>>> 2.5
>>> 101
>>> 21
>>> 29
>>> 2.91
>>> 2.91
>>> 10.6
>>> 5.83
>>> 3
>>> 3
>>> 1479
>>> 8
>>> 35
>>> 17
>>> 18
>>> 0.94
>>> 317
>>> 8
>>> 74.9
>>> 2.59
>>> 20.68
>>> 0.125389
>>>
>>> Thank you!
>>> Elizabeth
>>>
>>> On Thu, May 9, 2013 at 7:50 AM, David Carlson <dcarlson at tamu.edu> wrote:
>>> Since you pass your entire data.frame to metaMDS(), your first error
>>> probably comes from the fact that you have included ID as one of the
>>> variables. You should look at the results of
>>>
>>> str(dat)
>>>
>>> You can drop cases with missing values using
>>>
>>> > dat2 <- na.omit(dat)
>>> > metaMDS(dat2[,-1])
>>>
>>> would run the analysis on all but the first column (ID) with all the cases
>>> containing complete data. But that assumes that sex and exposure are not
>>> factors.
>>>
>>> Or you could use one of the distance functions in dist() which adjust for
>>> missing values. However dist() does not have an option to use Bray-Curtis
>>> (the default in metaMDS()). Bray-Curtis is designed for comparing species
>>> counts or proportions so it is not clear that it is an appropriate
>>> dissimilarity measure for your data. Further, your data seem contain a
>>> mixture of measurement scales and/or magnitudes so some variable
>>> standardization or transformations are probably necessary before you can
>>> get
>>> any useful results from MDS.
>>>
>>> -------------------------------------
>>> David L Carlson
>>> Associate Professor of Anthropology
>>> Texas A&M University
>>> College Station, TX 77840-4352
>>>
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>>> On
>>> Behalf Of Elizabeth Beck
>>> Sent: Wednesday, May 8, 2013 3:39 PM
>>> To: r-help at r-project.org
>>> Subject: [R] NMDS with missing data?
>>>
>>> Hi,
>>> I'm trying to run NMDS (non-metric multidimensional scaling) with R vegan
>>> (metaMDS) but I have a few NAs in my data set. I've tried to run it 2 ways.
>>>
>>> The first way with my entire data set which includes variables such as ID,
>>> sex, exposure, treatment, sodium, potassium, chloride....
>>>
>>> mydata.mds<-metaMDS(dat)
>>>
>>> I get the following error:
>>>
>>>  in if (any(autotransform, noshare > 0, wascores) && any(comm < 0)) { :
>>>   missing value where TRUE/FALSE needed
>>> In addition: Warning messages:
>>> 1: In Ops.factor(left, right) : < not meaningful for factors
>>> 2: In Ops.factor(left, right) : < not meaningful for factors
>>> 3: In Ops.factor(left, right) : < not meaningful for factors
>>> 4: In Ops.factor(left, right) : < not meaningful for factors
>>> 5: In Ops.factor(left, right) : < not meaningful for factors
>>>
>>> The second way with only those last biochemical variables (29 in total).
>>>
>>> mydata.mds<-metaMDS(measurements)
>>>
>>> I get this error:
>>>
>>> Error in if (any(autotransform, noshare > 0, wascores) && any(comm < 0)) {
>>> :
>>>   missing value where TRUE/FALSE needed
>>>
>>> My go to "na.rm=TRUE" does nothing. Any ideas on how to account for NAs and
>>> if so which of the above options I should be using?
>>> Thanks!
>>> Elizabeth
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
>
> Internal Contact Info:
> Phone: 467-7374
> Website:
> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From motyocska at yahoo.com  Mon Jun 17 20:29:34 2013
From: motyocska at yahoo.com (Andras Farkas)
Date: Mon, 17 Jun 2013 11:29:34 -0700 (PDT)
Subject: [R] vector question
Message-ID: <1371493774.85936.YahooMailClassic@web140405.mail.bf1.yahoo.com>

Dear All,

would you please help with the following:
let us say I have: 

a <-c(0,1,12,13,24,25,36,37)
b <-c(6,24.6,27)
#then I extract every 2nd element from "a"
d <-a[seq(1, length(a), 2)]

and what I need help with is to extract the 1st value from d that is greater than the values in b, so as a result I should have "f" as:

f <-c(12,36,36)

appreciate the insights,

thank you,

Andras


From jvadams at usgs.gov  Mon Jun 17 20:42:37 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 17 Jun 2013 13:42:37 -0500
Subject: [R] Conference on Statistical Practice
Message-ID: <CAN5YmCH03NP9tOwy6-y=W0oj+wEJR76_OOb28+QnZt1-5Tai=Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130617/63505ba2/attachment.pl>

From elizabethbeck0 at gmail.com  Mon Jun 17 20:43:03 2013
From: elizabethbeck0 at gmail.com (Elizabeth Beck)
Date: Mon, 17 Jun 2013 12:43:03 -0600
Subject: [R] NMDS with missing data?
In-Reply-To: <CACk-te16H06QYQPUKvQWE1QEJNX-CuBpo6HQX7oL3zY9Gy-gOg@mail.gmail.com>
References: <CAEWzS+FE0Rnj2PBD1GOxNwaNmQDuzKKxYHL1kDdXKcLd9Xamxw@mail.gmail.com>
	<01f501ce4cbc$39b8d460$ad2a7d20$@tamu.edu>
	<CAEWzS+Fp_hZ6ZMNPQAV-cSY+Ths8n-L8vcZhm-5EPA98bcU3Mw@mail.gmail.com>
	<026501ce4ff0$c39350c0$4ab9f240$@tamu.edu>
	<CAEWzS+HyFwGK2X6HiDkF+K47eSaqEiQWKHmH4yWkuVvfpm95WQ@mail.gmail.com>
	<CACk-te0sK-uiZfZUT7DyP==3v3s_KrefQWabiokrHjOKCUp8ng@mail.gmail.com>
	<027101ce6b84$c572e720$5058b560$@tamu.edu>
	<CACk-te16H06QYQPUKvQWE1QEJNX-CuBpo6HQX7oL3zY9Gy-gOg@mail.gmail.com>
Message-ID: <CAEWzS+EzhXJx3sZp7FWpjHxC+up75s33mccXPtuY+m5=gy4AbA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130617/9a2a19d7/attachment.pl>

From smartpink111 at yahoo.com  Mon Jun 17 20:45:10 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 17 Jun 2013 11:45:10 -0700 (PDT)
Subject: [R] vector question
In-Reply-To: <1371493774.85936.YahooMailClassic@web140405.mail.bf1.yahoo.com>
References: <1371493774.85936.YahooMailClassic@web140405.mail.bf1.yahoo.com>
Message-ID: <1371494710.76207.YahooMailNeo@web142602.mail.bf1.yahoo.com>

May be this helps:

d[cumsum(sapply(d,function(x) any(x>b)))>=1]
#[1] 12 24 36
A.K.


----- Original Message -----
From: Andras Farkas <motyocska at yahoo.com>
To: r-help at r-project.org
Cc: 
Sent: Monday, June 17, 2013 2:29 PM
Subject: [R] vector question

Dear All,

would you please help with the following:
let us say I have: 

a <-c(0,1,12,13,24,25,36,37)
b <-c(6,24.6,27)
#then I extract every 2nd element from "a"
d <-a[seq(1, length(a), 2)]

and what I need help with is to extract the 1st value from d that is greater than the values in b, so as a result I should have "f" as:

f <-c(12,36,36)

appreciate the insights,

thank you,

Andras

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From amandali at uchicago.edu  Mon Jun 17 19:14:33 2013
From: amandali at uchicago.edu (Amanda Li)
Date: Tue, 18 Jun 2013 01:14:33 +0800
Subject: [R] write a function to do pairwise calculation
Message-ID: <CALwvZ4WepoyBN3SdwAqwqZOhxHO9SN6q5-XCwS939kmuwN3vJg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130618/7a9e256d/attachment.pl>

From bcrombie at utk.edu  Mon Jun 17 19:59:53 2013
From: bcrombie at utk.edu (bcrombie)
Date: Mon, 17 Jun 2013 10:59:53 -0700 (PDT)
Subject: [R] help with text patterns in strings
Message-ID: <1371491993351-4669714.post@n4.nabble.com>

Let?s say I have a data set that includes a column of answers to a question
?What days of the week are you most likely to eat steak??.
The answers provided are [1] ?Friday?, [2] ?Wednesday?, [3] ?Friday,
Saturday, Sunday", [4] "Saturday?, [5] ?Sat, Sun?, [6] ?Th, F, Sa? 
How can I tell R to count ?Friday, Saturday, Sunday?, ?Sat, Sun?, and ?Th,
F, Sa? as three separate entries for each unique observation?
And is there a way to simultaneously tell R that, for example, ?Friday? is
the same as ?Fri? or ?F?; ?Saturday? is the same as ?Sat? or ?Sa?; etc.?
Thanks for your assistance.




--
View this message in context: http://r.789695.n4.nabble.com/help-with-text-patterns-in-strings-tp4669714.html
Sent from the R help mailing list archive at Nabble.com.


From nghanimi at gmail.com  Mon Jun 17 20:49:30 2013
From: nghanimi at gmail.com (nofe ganmi)
Date: Mon, 17 Jun 2013 21:49:30 +0300
Subject: [R] SVMREF infinte number of genes
Message-ID: <CAHa6OEjN8vhNHPCgcYEE=mVM+MweU4GAUk=JSTMTBts_4FnkxQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130617/aaa6e9c8/attachment.pl>

From smartpink111 at yahoo.com  Mon Jun 17 20:58:03 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 17 Jun 2013 11:58:03 -0700 (PDT)
Subject: [R] vector question
In-Reply-To: <1371494933.44938.YahooMailClassic@web140404.mail.bf1.yahoo.com>
References: <1371494710.76207.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1371494933.44938.YahooMailClassic@web140404.mail.bf1.yahoo.com>
Message-ID: <1371495483.38987.YahooMailNeo@web142604.mail.bf1.yahoo.com>

HI Andras,
Sorry, I misunderstood your question:

Try this:
?sapply(sapply(b,function(x) d[x<d]),`[`,1)
#[1] 12 36 36




----- Original Message -----
From: Andras Farkas <motyocska at yahoo.com>
To: arun <smartpink111 at yahoo.com>
Cc: 
Sent: Monday, June 17, 2013 2:48 PM
Subject: Re: [R] vector question

Arun,

thank you. Looking at it I am wondering if there is a way to get 36 in the result instead of the 24. The 2nd value in b is 24.6, therefore the 1st value greater then that in d is 36.

appreciate the help,

Andras

--- On Mon, 6/17/13, arun <smartpink111 at yahoo.com> wrote:

> From: arun <smartpink111 at yahoo.com>
> Subject: Re: [R] vector question
> To: "Andras Farkas" <motyocska at yahoo.com>
> Cc: "R help" <r-help at r-project.org>
> Date: Monday, June 17, 2013, 2:45 PM
> May be this helps:
> 
> d[cumsum(sapply(d,function(x) any(x>b)))>=1]
> #[1] 12 24 36
> A.K.
> 
> 
> ----- Original Message -----
> From: Andras Farkas <motyocska at yahoo.com>
> To: r-help at r-project.org
> Cc: 
> Sent: Monday, June 17, 2013 2:29 PM
> Subject: [R] vector question
> 
> Dear All,
> 
> would you please help with the following:
> let us say I have: 
> 
> a <-c(0,1,12,13,24,25,36,37)
> b <-c(6,24.6,27)
> #then I extract every 2nd element from "a"
> d <-a[seq(1, length(a), 2)]
> 
> and what I need help with is to extract the 1st value from d
> that is greater than the values in b, so as a result I
> should have "f" as:
> 
> f <-c(12,36,36)
> 
> appreciate the insights,
> 
> thank you,
> 
> Andras
> 
> ______________________________________________
> R-help at r-project.org
> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible
> code.
> 
> 



From wdunlap at tibco.com  Mon Jun 17 21:02:08 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 17 Jun 2013 19:02:08 +0000
Subject: [R] vector question
In-Reply-To: <1371495483.38987.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1371494710.76207.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1371494933.44938.YahooMailClassic@web140404.mail.bf1.yahoo.com>
	<1371495483.38987.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C3038F9@PA-MBX01.na.tibco.com>

Or perhaps something based on findInterval, like
  > d[findInterval(b, c(d,Inf))+1]
  [1] 12 36 36
The details depend on if your inequality is strict or not.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of arun
> Sent: Monday, June 17, 2013 11:58 AM
> To: Andras Farkas
> Cc: R help
> Subject: Re: [R] vector question
> 
> HI Andras,
> Sorry, I misunderstood your question:
> 
> Try this:
> ?sapply(sapply(b,function(x) d[x<d]),`[`,1)
> #[1] 12 36 36
> 
> 
> 
> 
> ----- Original Message -----
> From: Andras Farkas <motyocska at yahoo.com>
> To: arun <smartpink111 at yahoo.com>
> Cc:
> Sent: Monday, June 17, 2013 2:48 PM
> Subject: Re: [R] vector question
> 
> Arun,
> 
> thank you. Looking at it I am wondering if there is a way to get 36 in the result instead of
> the 24. The 2nd value in b is 24.6, therefore the 1st value greater then that in d is 36.
> 
> appreciate the help,
> 
> Andras
> 
> --- On Mon, 6/17/13, arun <smartpink111 at yahoo.com> wrote:
> 
> > From: arun <smartpink111 at yahoo.com>
> > Subject: Re: [R] vector question
> > To: "Andras Farkas" <motyocska at yahoo.com>
> > Cc: "R help" <r-help at r-project.org>
> > Date: Monday, June 17, 2013, 2:45 PM
> > May be this helps:
> >
> > d[cumsum(sapply(d,function(x) any(x>b)))>=1]
> > #[1] 12 24 36
> > A.K.
> >
> >
> > ----- Original Message -----
> > From: Andras Farkas <motyocska at yahoo.com>
> > To: r-help at r-project.org
> > Cc:
> > Sent: Monday, June 17, 2013 2:29 PM
> > Subject: [R] vector question
> >
> > Dear All,
> >
> > would you please help with the following:
> > let us say I have:
> >
> > a <-c(0,1,12,13,24,25,36,37)
> > b <-c(6,24.6,27)
> > #then I extract every 2nd element from "a"
> > d <-a[seq(1, length(a), 2)]
> >
> > and what I need help with is to extract the 1st value from d
> > that is greater than the values in b, so as a result I
> > should have "f" as:
> >
> > f <-c(12,36,36)
> >
> > appreciate the insights,
> >
> > thank you,
> >
> > Andras
> >
> > ______________________________________________
> > R-help at r-project.org
> > mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible
> > code.
> >
> >
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cjpauw at gmail.com  Mon Jun 17 21:08:25 2013
From: cjpauw at gmail.com (Christiaan Pauw)
Date: Mon, 17 Jun 2013 21:08:25 +0200
Subject: [R] SVMREF infinte number of genes
In-Reply-To: <CAHa6OEjN8vhNHPCgcYEE=mVM+MweU4GAUk=JSTMTBts_4FnkxQ@mail.gmail.com>
References: <CAHa6OEjN8vhNHPCgcYEE=mVM+MweU4GAUk=JSTMTBts_4FnkxQ@mail.gmail.com>
Message-ID: <CAJESSmZDKS+Bzg27jznoJN6TrA-feu8QpL00NpB7x4L2=FbR6w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130617/d95dcb3f/attachment.pl>

From gunter.berton at gene.com  Mon Jun 17 21:11:10 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 17 Jun 2013 12:11:10 -0700
Subject: [R] SVMREF infinte number of genes
In-Reply-To: <CAHa6OEjN8vhNHPCgcYEE=mVM+MweU4GAUk=JSTMTBts_4FnkxQ@mail.gmail.com>
References: <CAHa6OEjN8vhNHPCgcYEE=mVM+MweU4GAUk=JSTMTBts_4FnkxQ@mail.gmail.com>
Message-ID: <CACk-te0f4TNNJCUbcVhSUEjE9CFiyMEBVBtyw+sH0+q49-wedw@mail.gmail.com>

I think proving  whether P = NP would be easier than plotting an
infinite number of genes..

;-)

-- Bert

On Mon, Jun 17, 2013 at 11:49 AM, nofe ganmi <nghanimi at gmail.com> wrote:
> dear all,
>
> I am a student in cs college. I would like to know how to plot infinte
> number of genes after using the svm.
>
> the data set i have consists of
>
> x which is a matrix of 39 cancer patients [rows] and 2000 gene names
> [colmns]. each cell is the value of the gene for a particular patient.
> there are two types of cancer people  representedas factor y.
>
> here is the code:
> library(e1071)
> #load database
>
> db <-
> read.csv(file="databases\\colon-cancer\\colon-cancer.csv",head=FALSE,sep=",")
>
> x = as.matrix(db[,1:(ncol(db)-1)])
>  y = as.factor(db[,ncol(db)])
>
>
>   svmModel = svm(x, y, cost = 10, cachesize=500,  scale=F,
>  type="C-classification", kernel="linear" )
>
> Now how to plot this infinte number of genes after classification using
> SVM???
>
> thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From zadig_1 at excite.com  Mon Jun 17 21:11:34 2013
From: zadig_1 at excite.com (ce)
Date: Mon, 17 Jun 2013 15:11:34 -0400
Subject: [R] can't install rugarch and nloptr packages in R 3.01
	opensuse linux
Message-ID: <20130617151134.27376@web003.roc2.bluetie.com>

Hi Pascal,

Indeed by following your advice I succeeded to install nloptr. 
Thank you very much,


-----Original Message-----
From: "Pascal Oettli" [kridox at ymail.com]
Date: 06/17/2013 05:30 AM
To: "ce" <zadig_1 at excite.com>
CC: "" <r-help at r-project.org>
Subject: Re: [R] can't install rugarch and nloptr packages in R 3.01 opensuse
 linux

Hello,

I was able to install the "nloptr" package by editing the src/Makevars file.

I added the line
         mv .libs lib; \
between
         make install; \
         ls | grep -v ^include$$ | grep -v ^lib$$ | xargs rm -rf; \
for NLopt compilation.

You probably should contact the package maintainer for more details.

Hope this helps,
Pascal


On 16/06/13 19:42, ce wrote:
> I can't install rugarch package because installation of nloptr package fails .
>
> I use opensuse 12.3
> # uname -a
> Linux candide 3.7.10-1.11-desktop #1 SMP PREEMPT Thu May 16 20:27:27 UTC 2013 (adf31bb) x86_64 x86_64 x86_64 GNU/Linux
> my gcc version is 4.8.1
>
> I compiled and installed R 3.01 . then I tried to install rugarch package but it fails because it can't install depended package nloptr.  I try to install nloptr individually with install.packages("nloptr"), i get a lot of deprecated messages and it fails. I attach log file . when I try to compile nlopt software it also gives similar messages.
>
> Following fails too:
>
> R version 3.0.1 (2013-05-16) -- "Good Sport"
> Copyright (C) 2013 The R Foundation for Statistical Computing
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>
>>   install.packages("nloptr",repos="http://R-Forge.R-project.org")
> Warning message:
> package ?nloptr? is not available (for R version 3.0.1)
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Mon Jun 17 21:15:20 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 17 Jun 2013 12:15:20 -0700 (PDT)
Subject: [R] help with text patterns in strings
In-Reply-To: <1371491993351-4669714.post@n4.nabble.com>
References: <1371491993351-4669714.post@n4.nabble.com>
Message-ID: <1371496520.95656.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
May be this helps:

dat1<- data.frame(Ans=c("Friday","Wednesday","Friday,Saturday,Sunday","Saturday","Sat,Sun","Th,F,Sa"),stringsAsFactors=FALSE)
?dat1
???????????????????? Ans
1???????????????? Friday
2????????????? Wednesday
3 Friday,Saturday,Sunday
4?????????????? Saturday
5??????????????? Sat,Sun
6??????????????? Th,F,Sa


?vec1<- c("Su","M","Tu","W","Th","F","Sa")
?vec2<-unlist(strsplit(dat1$Ans,","))

vec2

?#[1] "Friday"??? "Wednesday" "Friday"??? "Saturday"? "Sunday"??? "Saturday" 
?#[7] "Sat"?????? "Sun"?????? "Th"??????? "F"???????? "Sa"????? 
sapply(vec1,function(x) length(vec2[grep(x,vec2)]) )
#Su? M Tu? W Th? F Sa 
# 2? 0? 0? 1? 1? 3? 4 

A.K.


----- Original Message -----
From: bcrombie <bcrombie at utk.edu>
To: r-help at r-project.org
Cc: 
Sent: Monday, June 17, 2013 1:59 PM
Subject: [R] help with text patterns in strings

Let?s say I have a data set that includes a column of answers to a question
?What days of the week are you most likely to eat steak??.
The answers provided are [1] ?Friday?, [2] ?Wednesday?, [3] ?Friday,
Saturday, Sunday", [4] "Saturday?, [5] ?Sat, Sun?, [6] ?Th, F, Sa? 
How can I tell R to count ?Friday, Saturday, Sunday?, ?Sat, Sun?, and ?Th,
F, Sa? as three separate entries for each unique observation?
And is there a way to simultaneously tell R that, for example, ?Friday? is
the same as ?Fri? or ?F?; ?Saturday? is the same as ?Sat? or ?Sa?; etc.?
Thanks for your assistance.




--
View this message in context: http://r.789695.n4.nabble.com/help-with-text-patterns-in-strings-tp4669714.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From wdunlap at tibco.com  Mon Jun 17 21:51:24 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 17 Jun 2013 19:51:24 +0000
Subject: [R] help with text patterns in strings
In-Reply-To: <1371496520.95656.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1371491993351-4669714.post@n4.nabble.com>
	<1371496520.95656.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C303946@PA-MBX01.na.tibco.com>

> And is there a way to simultaneously tell R that, for example, ?Friday? is
> the same as ?Fri? or ?F?; ?Saturday? is the same as ?Sat? or ?Sa?; etc.?

Look at pmatch (partial match):
  > dayNames <- c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")
  > dayNames[pmatch(c("F", "Fr", "Friday", "Tu", "Th", "T", "Lunes"), dayNames, duplicates.ok=TRUE)]
  [1] "Friday"   "Friday"   "Friday"   "Tuesday"  "Thursday" NA         NA
"T" could be either "Tuesday" or "Thursday" so it is mapped to NA, as are entries like "Lunes" that do not match at all.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of arun
> Sent: Monday, June 17, 2013 12:15 PM
> To: bcrombie
> Cc: R help 
> Subject: Re: [R] help with text patterns in strings
> 
> Hi,
> May be this helps:
> 
> dat1<-
> data.frame(Ans=c("Friday","Wednesday","Friday,Saturday,Sunday","Saturday","Sat,Sun",
> "Th,F,Sa"),stringsAsFactors=FALSE)
> ?dat1
> ???????????????????? Ans
> 1???????????????? Friday
> 2????????????? Wednesday
> 3 Friday,Saturday,Sunday
> 4?????????????? Saturday
> 5??????????????? Sat,Sun
> 6??????????????? Th,F,Sa
> 
> 
> ?vec1<- c("Su","M","Tu","W","Th","F","Sa")
> ?vec2<-unlist(strsplit(dat1$Ans,","))
> 
> vec2
> 
> ?#[1] "Friday"??? "Wednesday" "Friday"??? "Saturday"? "Sunday"??? "Saturday"
> ?#[7] "Sat"?????? "Sun"?????? "Th"??????? "F"???????? "Sa"
> sapply(vec1,function(x) length(vec2[grep(x,vec2)]) )
> #Su? M Tu? W Th? F Sa
> # 2? 0? 0? 1? 1? 3? 4
> 
> A.K.
> 
> 
> ----- Original Message -----
> From: bcrombie <bcrombie at utk.edu>
> To: r-help at r-project.org
> Cc:
> Sent: Monday, June 17, 2013 1:59 PM
> Subject: [R] help with text patterns in strings
> 
> Let?s say I have a data set that includes a column of answers to a question
> ?What days of the week are you most likely to eat steak??.
> The answers provided are [1] ?Friday?, [2] ?Wednesday?, [3] ?Friday,
> Saturday, Sunday", [4] "Saturday?, [5] ?Sat, Sun?, [6] ?Th, F, Sa?
> How can I tell R to count ?Friday, Saturday, Sunday?, ?Sat, Sun?, and ?Th,
> F, Sa? as three separate entries for each unique observation?
> And is there a way to simultaneously tell R that, for example, ?Friday? is
> the same as ?Fri? or ?F?; ?Saturday? is the same as ?Sat? or ?Sa?; etc.?
> Thanks for your assistance.
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/help-with-text-patterns-in-
> strings-tp4669714.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From jvadams at usgs.gov  Mon Jun 17 22:03:40 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 17 Jun 2013 15:03:40 -0500
Subject: [R] Problem in Matrix
In-Reply-To: <1371205473.43069.YahooMailNeo@web162902.mail.bf1.yahoo.com>
References: <1371205473.43069.YahooMailNeo@web162902.mail.bf1.yahoo.com>
Message-ID: <CAN5YmCHvbFkoiQJuWc-bp1VHBULzL7j_U5BMe2c2dkAaCBGTnA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130617/f4e538de/attachment.pl>

From dcarlson at tamu.edu  Mon Jun 17 22:17:58 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 17 Jun 2013 15:17:58 -0500
Subject: [R] NMDS with missing data?
In-Reply-To: <CAEWzS+EzhXJx3sZp7FWpjHxC+up75s33mccXPtuY+m5=gy4AbA@mail.gmail.com>
References: <CAEWzS+FE0Rnj2PBD1GOxNwaNmQDuzKKxYHL1kDdXKcLd9Xamxw@mail.gmail.com>	<01f501ce4cbc$39b8d460$ad2a7d20$@tamu.edu>	<CAEWzS+Fp_hZ6ZMNPQAV-cSY+Ths8n-L8vcZhm-5EPA98bcU3Mw@mail.gmail.com>	<026501ce4ff0$c39350c0$4ab9f240$@tamu.edu>	<CAEWzS+HyFwGK2X6HiDkF+K47eSaqEiQWKHmH4yWkuVvfpm95WQ@mail.gmail.com>	<CACk-te0sK-uiZfZUT7DyP==3v3s_KrefQWabiokrHjOKCUp8ng@mail.gmail.com>	<027101ce6b84$c572e720$5058b560$@tamu.edu>	<CACk-te16H06QYQPUKvQWE1QEJNX-CuBpo6HQX7oL3zY9Gy-gOg@mail.gmail.com>
	<CAEWzS+EzhXJx3sZp7FWpjHxC+up75s33mccXPtuY+m5=gy4AbA@mail.gmail.com>
Message-ID: <029d01ce6b97$c21569a0$46403ce0$@tamu.edu>

Principal components analysis and factor analysis are two techniques
that have different histories, but overlap in the computational
procedures used. Strictly speaking, principal components is a
descriptive procedure used to project a multivariate data set into a
space with fewer dimensions. The first principal component is the
direction of maximum covariance (or correlation) through the data
cloud. The second is the direction of the next highest covariance
(correlation) that is also uncorrelated with the previous component,
etc. The principal component loadings indicate generally which
variables are important in defining each component. 

Factor analysis attempts to discover latent variables under the
assumption that the measured variables are "caused" by unobservable
factors and the correlations between the observed variables provide
evidence of these latent variables. Factors are often initially
extracted using principal components analysis and then rotated so
that they are more interpretable. The rotation tries to create
factors with either very low or very high loadings for each
variable. Psychologists generally come from a factor analysis
background and tend to prefer rotated factors. Researchers using
principal components to simplify their data to look for clusters or
other patterns prefer to keep the original components since they
reflect the covariance structure of the data in a way that is lost
by rotation.

Your latest post suggests that you are planning to use the
components in a regression analysis - hence as latent variables.
Rotation may make it easier to interpret those components.
Multidimensional scaling will give you something analogous to
unrotated principal components but you do not get loadings so you
have no easy way to relate the MDS dimensions back to the original
variables (although you could run correlations between the original
variables and the mds dimensions to get similar information). 

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

From: Elizabeth Beck [mailto:elizabethbeck0 at gmail.com] 
Sent: Monday, June 17, 2013 1:43 PM
To: Bert Gunter
Cc: David Carlson; r-help at r-project.org
Subject: Re: [R] NMDS with missing data?

Hi Bert & David -?

I'm putting aside the issues with the missing data for the moment -
the NAs are due to not enough sample volume for testing and there
are only about 6 of them for 1 variable. I have multiple data sets
to look and not all with missing values. I do intend to find some
local consulting options once I have a bit more of a grasp on my
options.?

If I were to stick with the principal() function using my
standardized variables...rotate=none would make sense initially,
although several papers I have read with very similar data sets have
used a Varimax factor rotation (orthogonal transformation).?

My reasoning behind the PCA is to reduce the number of variables (as
many are likely correlated) and then use those new factors to run a
perMANOVA. All of my categorical factors are explanatory variables
(sex, exposure, treatment) so will be used in the final model.?

Is PCA still the preferred ordination method for this type of data?
Are there advantages to NMDS instead??

I appreciate the input...
Elizabeth


On Mon, Jun 17, 2013 at 12:28 PM, Bert Gunter
<gunter.berton at gene.com> wrote:
David et. al.:

I hate to be a pest but ...

On Mon, Jun 17, 2013 at 11:02 AM, David Carlson <dcarlson at tamu.edu>
wrote:
> First, Bert is correct. I should have said to use prcomp(dat,
center=TRUE, scale=TRUE). That will run the svd on the standardized
variables which is equivalent to using princomp(dat, cor=TRUE).

***You will have to remove the cases with missing variables or
impute
the missing variables using one of many options in R. ***

Depending on the number of missings and nature of the missingness,
this can be a crucial issue. Omitting all data with missing entries
makes very strong assumptions about the nature of the missingness
and
can lead to highly biased results. Which is problematic for
exploration, even. The same is true with imputation -- you need to
do
it properly. Again, depending on the number of cases at issue.

So it may be wise for Elizabeth to consult a local statistical
expert
and not rely on superficial background from a text and remote
advice.
There may be dragons ...

Cheers,
Bert


>
> The principal() function in package psych should be fine and will
probably give nearly identical results. It does have the ability to
generate a pairwise-deletion correlation matrix so you could include
your cases with missing values. I would set rotate="none" least
initially. Hopefully your text will explain why this is a good idea.
>
> I assume you are looking for interesting patterns in the data
rather than trying to test a specific hypothesis. Given that, you
should try both (or all three with principal()) and see if there are
any interesting differences between them.
>
> Earlier I asked if all your variables are numeric (or
dichotomies). If any are categorical (factors), these suggestions
may have to be revised.
>
> -------------------------------------
> David L Carlson
> Associate Professor of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
> -----Original Message-----
> From: Bert Gunter [mailto:gunter.berton at gene.com]
> Sent: Monday, June 17, 2013 12:35 PM
> To: Elizabeth Beck
> Cc: David Carlson; r-help at r-project.org
> Subject: Re: [R] NMDS with missing data?
>
> Just wanted to note that one does **not** use
> "prcomp() on the correlation matrix of the variables."
>
> As ?prcomp says, it uses the svd of the data matrix, which is
> generally preferable.
>
> Cheers,
> Bert
>
> On Mon, Jun 17, 2013 at 10:02 AM, Elizabeth Beck
> <elizabethbeck0 at gmail.com> wrote:
>> Hello David,
>>
>> Yes my variables are all numeric....I have a few questions
regarding your 2
>> options.
>>
>> Would these still be the best options if missing data was not an
issue? I
>> was told that I should be performing NMDS as it has few
assumptions on the
>> data distribution but neither of your options use this.
>>
>> If NMDS is not preferred and I were to perform a PCA, can you
tell me why
>> you chose prcomp()? My statistical text (Discovering Statistics
Using R)
>> explains PCA quite well using principal() in the psych package so
I am just
>> wondering the advantages of one over the other... I am
overwhelmed by the
>> number of ordination methods!
>>
>> Thank you,
>> Elizabeth
>>
>> On Mon, May 13, 2013 at 9:44 AM, David Carlson
<dcarlson at tamu.edu> wrote:
>>
>>> First. Do not use html messages. They are converted to plain
text and your
>>> table ends up a mess. See below. It appears the variables are
all numeric?
>>> If so, there are two standard approaches to handling multiple
scales and
>>> magnitudes with cluster analysis:
>>>
>>> 1. Use z-scores. The scale() function will convert each variable
into a
>>> standard score with a mean of 0 and a standard deviation of 1.
Then use
>>> Euclidean distance in the dist() function which will adjust for
your
>>> missing
>>> values.
>>>
>>> 2. Use prcomp() on the correlation matrix of the variables to
extract a set
>>> of principal components and use the principal component scores
in the
>>> cluster analysis. This may allow you to reduce the number of
variables in
>>> the data set if the 29 variables are correlated with one
another.
>>>
>>> -------------------------------------
>>> David L Carlson
>>> Associate Professor of Anthropology
>>> Texas A&M University
>>> College Station, TX 77840-4352
>>>
>>> From: Elizabeth Beck [mailto:elizabethbeck0 at gmail.com]
>>> Sent: Friday, May 10, 2013 1:20 PM
>>> To: dcarlson at tamu.edu
>>> Cc: r-help at r-project.org
>>> Subject: Re: [R] NMDS with missing data?
>>>
>>> Hi David,
>>>
>>> You are right in that Bray-Curtis is not suitable for my
dataset, and that
>>> my variables are very different. Given your suggestions, I am
struggling
>>> with how to transform or standardize my data given that they
vary so much.
>>> Additionally, looking at the dist() package I am not sure which
distance
>>> measure would be most appropriate. Euclidean seems to most
widely used but
>>> I'm not sure if it is appropriate for myself (there much more
help for
>>> ecology data than toxicology). Given a sample of my data below (
total of
>>> 287 obs. of ?29 variables) can you suggest a starting point?
>>>
>>> SODIUM
>>> K
>>> CL
>>> HCO3
>>> ANION
>>> CA
>>> P
>>> GLUCOSE
>>> ?CHOLEST
>>> ? ? ? ?GGT
>>> ? ?GLDH
>>> CK
>>> AST
>>> PROTEIN
>>> ALBUMIN
>>> GLOBULIN
>>> A_G
>>> UA
>>> BA
>>> CORTICO
>>> T3
>>> T4
>>> THYROID
>>> 145
>>> 3.3
>>> 102
>>> 24
>>> 22
>>> 2.9
>>> 2.45
>>> 9.8
>>> 5.7
>>> 3
>>> 3
>>> 678
>>> 5
>>> 34
>>> 15
>>> 19
>>> 0.79
>>> 180
>>> 6
>>> 70.97
>>> 1.31
>>> 12.77
>>> 0.102376
>>> 146
>>> 3.2
>>> 102
>>> 21
>>> 26
>>> 2.89
>>> 2.68
>>> 11.1
>>> 6.78
>>> 3
>>> 4
>>> 1290
>>> 9
>>> 36
>>> 18
>>> 18
>>> 1
>>> 170
>>> 13
>>> 79.1
>>> 3.51
>>> 18.78
>>> 0.186751
>>> 147
>>> 2.5
>>> 103
>>> 22
>>> 25
>>> 2.96
>>> 2.59
>>> 10
>>> 5.78
>>> 3
>>> 6
>>> 1582
>>> 11
>>> 35
>>> 17
>>> 18
>>> 0.94
>>> 272
>>> 10
>>> 65.84
>>> 1.84
>>> 15.5
>>> 0.118602
>>> 148
>>> 2.5
>>> 101
>>> 21
>>> 29
>>> 2.91
>>> 2.91
>>> 10.6
>>> 5.83
>>> 3
>>> 3
>>> 1479
>>> 8
>>> 35
>>> 17
>>> 18
>>> 0.94
>>> 317
>>> 8
>>> 74.9
>>> 2.59
>>> 20.68
>>> 0.125389
>>>
>>> Thank you!
>>> Elizabeth
>>>
>>> On Thu, May 9, 2013 at 7:50 AM, David Carlson
<dcarlson at tamu.edu> wrote:
>>> Since you pass your entire data.frame to metaMDS(), your first
error
>>> probably comes from the fact that you have included ID as one of
the
>>> variables. You should look at the results of
>>>
>>> str(dat)
>>>
>>> You can drop cases with missing values using
>>>
>>> > dat2 <- na.omit(dat)
>>> > metaMDS(dat2[,-1])
>>>
>>> would run the analysis on all but the first column (ID) with all
the cases
>>> containing complete data. But that assumes that sex and exposure
are not
>>> factors.
>>>
>>> Or you could use one of the distance functions in dist() which
adjust for
>>> missing values. However dist() does not have an option to use
Bray-Curtis
>>> (the default in metaMDS()). Bray-Curtis is designed for
comparing species
>>> counts or proportions so it is not clear that it is an
appropriate
>>> dissimilarity measure for your data. Further, your data seem
contain a
>>> mixture of measurement scales and/or magnitudes so some variable
>>> standardization or transformations are probably necessary before
you can
>>> get
>>> any useful results from MDS.
>>>
>>> -------------------------------------
>>> David L Carlson
>>> Associate Professor of Anthropology
>>> Texas A&M University
>>> College Station, TX 77840-4352
>>>
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org]
>>> On
>>> Behalf Of Elizabeth Beck
>>> Sent: Wednesday, May 8, 2013 3:39 PM
>>> To: r-help at r-project.org
>>> Subject: [R] NMDS with missing data?
>>>
>>> Hi,
>>> I'm trying to run NMDS (non-metric multidimensional scaling)
with R vegan
>>> (metaMDS) but I have a few NAs in my data set. I've tried to run
it 2 ways.
>>>
>>> The first way with my entire data set which includes variables
such as ID,
>>> sex, exposure, treatment, sodium, potassium, chloride....
>>>
>>> mydata.mds<-metaMDS(dat)
>>>
>>> I get the following error:
>>>
>>> ?in if (any(autotransform, noshare > 0, wascores) && any(comm <
0)) { :
>>> ? missing value where TRUE/FALSE needed
>>> In addition: Warning messages:
>>> 1: In Ops.factor(left, right) : < not meaningful for factors
>>> 2: In Ops.factor(left, right) : < not meaningful for factors
>>> 3: In Ops.factor(left, right) : < not meaningful for factors
>>> 4: In Ops.factor(left, right) : < not meaningful for factors
>>> 5: In Ops.factor(left, right) : < not meaningful for factors
>>>
>>> The second way with only those last biochemical variables (29 in
total).
>>>
>>> mydata.mds<-metaMDS(measurements)
>>>
>>> I get this error:
>>>
>>> Error in if (any(autotransform, noshare > 0, wascores) &&
any(comm < 0)) {
>>> :
>>> ? missing value where TRUE/FALSE needed
>>>
>>> My go to "na.rm=TRUE" does nothing. Any ideas on how to account
for NAs and
>>> if so which of the above options I should be using?
>>> Thanks!
>>> Elizabeth
>>> ? ? ? ? [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible
code.
>>>
>>>
>>>
>>
>> ? ? ? ? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible
code.
>
>
>
> --
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
>
> Internal Contact Info:
> Phone: 467-7374
> Website:
>
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/p
db-biostatistics/pdb-ncb-home.htm
>



--

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/p
db-biostatistics/pdb-ncb-home.htm


From dcarlson at tamu.edu  Mon Jun 17 22:43:46 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 17 Jun 2013 15:43:46 -0500
Subject: [R] SVMREF infinte number of genes
In-Reply-To: <CACk-te0f4TNNJCUbcVhSUEjE9CFiyMEBVBtyw+sH0+q49-wedw@mail.gmail.com>
References: <CAHa6OEjN8vhNHPCgcYEE=mVM+MweU4GAUk=JSTMTBts_4FnkxQ@mail.gmail.com>
	<CACk-te0f4TNNJCUbcVhSUEjE9CFiyMEBVBtyw+sH0+q49-wedw@mail.gmail.com>
Message-ID: <02ab01ce6b9b$5cde79b0$169b6d10$@tamu.edu>

It cannot be done because there is not enough time to create the
plot. In about a billion years the sun will be 10% brighter than
today and the oceans will start to boil away. You will still be
plotting genes when that happens.

:-(

-------------------------------------
David

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
Sent: Monday, June 17, 2013 2:11 PM
To: nofe ganmi
Cc: r-help at r-project.org
Subject: Re: [R] SVMREF infinte number of genes

I think proving  whether P = NP would be easier than plotting an
infinite number of genes..

;-)

-- Bert

On Mon, Jun 17, 2013 at 11:49 AM, nofe ganmi <nghanimi at gmail.com>
wrote:
> dear all,
>
> I am a student in cs college. I would like to know how to plot
infinte
> number of genes after using the svm.
>
> the data set i have consists of
>
> x which is a matrix of 39 cancer patients [rows] and 2000 gene
names
> [colmns]. each cell is the value of the gene for a particular
patient.
> there are two types of cancer people  representedas factor y.
>
> here is the code:
> library(e1071)
> #load database
>
> db <-
>
read.csv(file="databases\\colon-cancer\\colon-cancer.csv",head=FALSE
,sep=",")
>
> x = as.matrix(db[,1:(ncol(db)-1)])
>  y = as.factor(db[,ncol(db)])
>
>
>   svmModel = svm(x, y, cost = 10, cachesize=500,  scale=F,
>  type="C-classification", kernel="linear" )
>
> Now how to plot this infinte number of genes after classification
using
> SVM???
>
> thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/p
db-biostatistics/pdb-ncb-home.htm

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Brian.Davis at uth.tmc.edu  Mon Jun 17 23:02:46 2013
From: Brian.Davis at uth.tmc.edu (Davis, Brian)
Date: Mon, 17 Jun 2013 16:02:46 -0500
Subject: [R] Help understanding environments
Message-ID: <8AB18F255888194F82934830982C82C13DA7376FD1@UTHCMS1.uthouston.edu>

I have a collection of .RData files that have result objects that I would like to combine.  Specifically, skatCohort objects from the skatMeta package, but I've run into a similar issue with simple data.frames also.

If I run something like

FILES <- list.files(path="/path/to/my/results", pattern=".RData$", full.names=TRUE)
combined <- NULL
  for (FILE in FILES) {
    load(FILE)
    if (!is.null(combined)) {
      combined <- c(combined, res)
    } else {
      combined <- res
    }
  }

I get all my objects combined.  However, if I wrap this into a function I get the following error

c_objects <- function(FILES) {
  combined <- NULL
  for (FILE in FILES) {
    load(FILE)
    if (!is.null(combined)) {
      combined <- c(combined, res)
    } else {
      combined <- res
    }
  }
  return(combined)
}

combined_results <- c_objects(FILES)
Error in eval(expr, envir, enclos) : object 'combined' not found

How should I write this function such that it can find "combined".   I've tried reading the help on envirnaments, and the exisits function but I haven't been able to figure this out.  Are there any other resources to read up on this?

Thanks in advance,

-Brian 


From nghanimi at gmail.com  Mon Jun 17 23:19:57 2013
From: nghanimi at gmail.com (nofe ganmi)
Date: Tue, 18 Jun 2013 00:19:57 +0300
Subject: [R] SVMREF infinte number of genes
In-Reply-To: <02ab01ce6b9b$5cde79b0$169b6d10$@tamu.edu>
References: <CAHa6OEjN8vhNHPCgcYEE=mVM+MweU4GAUk=JSTMTBts_4FnkxQ@mail.gmail.com>
	<CACk-te0f4TNNJCUbcVhSUEjE9CFiyMEBVBtyw+sH0+q49-wedw@mail.gmail.com>
	<02ab01ce6b9b$5cde79b0$169b6d10$@tamu.edu>
Message-ID: <CAHa6OEheVZSGSD_gXmGWCbZdwTbDR83cP_FOHBj7MLH_V+YrwQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130618/697b0855/attachment.pl>

From Brian.Davis at uth.tmc.edu  Mon Jun 17 23:27:23 2013
From: Brian.Davis at uth.tmc.edu (Davis, Brian)
Date: Mon, 17 Jun 2013 16:27:23 -0500
Subject: [R] Help understanding environments
In-Reply-To: <51BF7E8E.9050205@sapo.pt>
References: <8AB18F255888194F82934830982C82C13DA7376FD1@UTHCMS1.uthouston.edu>
	<51BF7E8E.9050205@sapo.pt>
Message-ID: <8AB18F255888194F82934830982C82C13DA7376FD5@UTHCMS1.uthouston.edu>

I probably should have been more specific.  The .RData objects which get loaded have a list called 'res'.  This isn't a reproducible example, as I haven't included any of the RData files.

-----Original Message-----
From: Rui Barradas [mailto:ruipbarradas at sapo.pt] 
Sent: Monday, June 17, 2013 4:25 PM
To: Davis, Brian
Subject: Re: [R] Help understanding environments

Hello,

The error I get is: Error: object 'res' not found You are using an undefined variable, 'res'. I don't believe this has something to do with environments.

Rui Barradas


Em 17-06-2013 22:02, Davis, Brian escreveu:
> I have a collection of .RData files that have result objects that I would like to combine.  Specifically, skatCohort objects from the skatMeta package, but I've run into a similar issue with simple data.frames also.
>
> If I run something like
>
> FILES <- list.files(path="/path/to/my/results", pattern=".RData$", 
> full.names=TRUE) combined <- NULL
>    for (FILE in FILES) {
>      load(FILE)
>      if (!is.null(combined)) {
>        combined <- c(combined, res)
>      } else {
>        combined <- res
>      }
>    }
>
> I get all my objects combined.  However, if I wrap this into a 
> function I get the following error
>
> c_objects <- function(FILES) {
>    combined <- NULL
>    for (FILE in FILES) {
>      load(FILE)
>      if (!is.null(combined)) {
>        combined <- c(combined, res)
>      } else {
>        combined <- res
>      }
>    }
>    return(combined)
> }
>
> combined_results <- c_objects(FILES)
> Error in eval(expr, envir, enclos) : object 'combined' not found
>
> How should I write this function such that it can find "combined".   I've tried reading the help on envirnaments, and the exisits function but I haven't been able to figure this out.  Are there any other resources to read up on this?
>
> Thanks in advance,
>
> -Brian
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sachs at math.berkeley.edu  Mon Jun 17 22:20:23 2013
From: sachs at math.berkeley.edu (Rainer Sachs)
Date: Mon, 17 Jun 2013 13:20:23 -0700 (PDT)
Subject: [R] package expm: matrix powers within a product of matrices:
 operation precedence
Message-ID: <1371500423650-4669733.post@n4.nabble.com>


package expm: matrix powers within a product of matrices: operation
precedence

    I want to double check that for M and N kxk mtrices and v a k-vector
    M%^%2%*%N%*%v is not automatically read as (M%^%2)%*%N%*%v or
    M%*%N%^%2%*%v is not automatically read as M%*%(N%^%2)%*%v or
    both

    I had been assuming the usual precedence (powers first, then
multiplication) applies for matrix powers and multiplication in expm. I was
getting unexpected results. In desperation I tried putting in the
parentheses and seem to be getting much more reasonable answers. But I am so
surprised that the matrix power operation is, apparently, not automatically
given precedence over the matrix multiplication operation that I do not
trust that adding parentheses has cured my bug. Maybe I am still making some
other mistake instead. Can anyone confirm that in fact the parentheses are
(sometimes?) essential? I could not find any documentation, one way or the
other, just definitions of the power operator and of matrix exponentials.

    TIA Rainer K. Sachs, Prof emertitus of math 





--
View this message in context: http://r.789695.n4.nabble.com/package-expm-matrix-powers-within-a-product-of-matrices-operation-precedence-tp4669733.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Mon Jun 17 22:37:49 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 17 Jun 2013 13:37:49 -0700 (PDT)
Subject: [R] help with text patterns in strings
In-Reply-To: <559C998F7039D84C9793AE43D9BBE9CE77A0FC69@kmbx3.utk.tennessee.edu>
References: <1371491993351-4669714.post@n4.nabble.com>
	<1371496520.95656.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<559C998F7039D84C9793AE43D9BBE9CE77A0FC69@kmbx3.utk.tennessee.edu>
Message-ID: <1371501469.76400.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
dat1$Ans<-tolower(dat1$Ans)
#But, if you do this:

?vec1<- c("su","m","tu","w","th","f","sa")
?vec2<-unlist(strsplit(dat1$Ans,","))
?sapply(vec1,function(x) length(vec2[grep(x,vec2)]) )
#su? m tu? w th? f sa? # which is incorrect here "tu" got two matches in sa"tu"rday
# 2? 0? 2? 1? 1? 3? 4 



Instead:
#Suppose your data looks like this: 

dat2<- data.frame(Ans=c("friday","wednesday","Friday,Saturday,sunday","saturday","sat,Sun","th,F,Sa"),stringsAsFactors=FALSE)
vec2<- unlist(strsplit(dat2$Ans,","))
library(Hmisc)
vec2New<-capitalize(vec2)
vec2New
#[1] "Friday"??? "Wednesday" "Friday"??? "Saturday"? "Sunday"??? "Saturday" 
?#[7] "Sat"?????? "Sun"?????? "Th"??????? "F"???????? "Sa"?????? 
vec1<- c("Su","M","Tu","W","Th","F","Sa")

sapply(vec1,function(x) length(vec2New[grep(x,vec2New)]) )

#Su? M Tu? W Th? F Sa 
# 2? 0? 0? 1? 1? 3? 4 


#Or Using Bills' solution:
dayNames[pmatch(vec2New,dayNames,duplicates.ok=TRUE)]
# [1] "Friday"??? "Wednesday" "Friday"??? "Saturday"? "Sunday"??? "Saturday" 
?#[7] "Saturday"? "Sunday"??? "Thursday"? "Friday"??? "Saturday" 


table(dayNames[pmatch(vec2New,dayNames,duplicates.ok=TRUE)])
#?? Friday? Saturday??? Sunday? Thursday Wednesday 
?# ????? 3???????? 4???????? 2???????? 1???????? 1 



A.K.


----- Original Message -----
From: "Crombie, Burnette N" <bcrombie at utk.edu>
To: arun <smartpink111 at yahoo.com>
Cc: 
Sent: Monday, June 17, 2013 4:12 PM
Subject: RE: [R] help with text patterns in strings

Arun, thanks.? Your script achieves the goal I stated, but now I'm tweaking it as I see possible obstacles with my real data.
I anticipate the responses, since they are handwritten, with be a mixture of upper- & lowercase text, so I decided to prevent issues by using the "tolower()" function.
It did not work as I intended when editing your script (see below).
How do I use "tolower()" so that it will save the modification of my variable in the data frame.
Do I have to rename the original data frame in order to save my changes (create new object)?

dat1<- data.frame(Ans=c("Friday","Wednesday","Friday,Saturday,Sunday","Saturday","Sat,Sun","Th,F,Sa"),stringsAsFactors=FALSE)
dat1
#? ? ? ? ? ? ? ?  Ans
# 1? ? ? ? ? ? ? ?  Friday
# 2? ? ? ? ? ? ? Wednesday
# 3 Friday,Saturday,Sunday
# 4? ? ? ? ? ? ?  Saturday
# 5? ? ? ? ? ? ? ? Sat,Sun
# 6? ? ? ? ? ? ? ? Th,F,Sa

tolower(dat1$Ans)
dat1
#the output I want:
#? ? ? ? ? ? ? ?  Ans
# 1? ? ? ? ? ? ? ?  friday
# 2? ? ? ? ? ? ? wednesday
# 3 friday,saturday,sunday
# 4? ? ? ? ? ? ?  saturday
# 5? ? ? ? ? ? ? ? sat,sun
# 6? ? ? ? ? ? ? ? th,f,sa
#but the real R output is not all lowercase

vec1<- c("su","m","tu","w","th","f","sa")
vec2<-unlist(strsplit(dat1$Ans,","))

vec2
#the output I want
#[1] "friday"? ? "wednesday" "friday"? ? "saturday"? "sunday"? ? "saturday" 
#[7] "sat"? ? ?  "sun"? ? ?  "th"? ? ? ? "f"? ? ? ?  "sa"
#but the real R output is not all lowercase

sapply(vec1,function(x) length(vec2[grep(x,vec2)]) )
#su? m tu? w th? f sa
# 2? 0? 0? 1? 1? 3? 4

-----Original Message-----
From: arun [mailto:smartpink111 at yahoo.com] 
Sent: Monday, June 17, 2013 3:15 PM
To: Crombie, Burnette N
Cc: R help
Subject: Re: [R] help with text patterns in strings

Hi,
May be this helps:

dat1<- data.frame(Ans=c("Friday","Wednesday","Friday,Saturday,Sunday","Saturday","Sat,Sun","Th,F,Sa"),stringsAsFactors=FALSE)
?dat1
???????????????????? Ans
1???????????????? Friday
2????????????? Wednesday
3 Friday,Saturday,Sunday
4?????????????? Saturday
5??????????????? Sat,Sun
6??????????????? Th,F,Sa


?vec1<- c("Su","M","Tu","W","Th","F","Sa")
?vec2<-unlist(strsplit(dat1$Ans,","))

vec2

?#[1] "Friday"??? "Wednesday" "Friday"??? "Saturday"? "Sunday"??? "Saturday" 
?#[7] "Sat"?????? "Sun"?????? "Th"??????? "F"???????? "Sa"
sapply(vec1,function(x) length(vec2[grep(x,vec2)]) ) #Su? M Tu? W Th? F Sa # 2? 0? 0? 1? 1? 3? 4 

A.K.


----- Original Message -----
From: bcrombie <bcrombie at utk.edu>
To: r-help at r-project.org
Cc: 
Sent: Monday, June 17, 2013 1:59 PM
Subject: [R] help with text patterns in strings

Let?s say I have a data set that includes a column of answers to a question ?What days of the week are you most likely to eat steak??.
The answers provided are [1] ?Friday?, [2] ?Wednesday?, [3] ?Friday, Saturday, Sunday", [4] "Saturday?, [5] ?Sat, Sun?, [6] ?Th, F, Sa? 
How can I tell R to count ?Friday, Saturday, Sunday?, ?Sat, Sun?, and ?Th, F, Sa? as three separate entries for each unique observation?
And is there a way to simultaneously tell R that, for example, ?Friday? is the same as ?Fri? or ?F?; ?Saturday? is the same as ?Sat? or ?Sa?; etc.?
Thanks for your assistance.




--
View this message in context: http://r.789695.n4.nabble.com/help-with-text-patterns-in-strings-tp4669714.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Mon Jun 17 23:58:44 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 17 Jun 2013 21:58:44 +0000
Subject: [R] package expm: matrix powers within a product of matrices:
 operation precedence
In-Reply-To: <1371500423650-4669733.post@n4.nabble.com>
References: <1371500423650-4669733.post@n4.nabble.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C3039C0@PA-MBX01.na.tibco.com>

All operators of the form %<something>% have the same precedence,
that of %*%.    R does not look at the <something> between the percent
signs to determine the precedence.  Hence you must use parentheses
to get the order of operations that you want.

(I think that %<something>% operators are overused - providing the same
functionality in a standard functional form is often more convenient.  It
certainly would eliminate your problem.)

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Rainer Sachs
> Sent: Monday, June 17, 2013 1:20 PM
> To: r-help at r-project.org
> Subject: [R] package expm: matrix powers within a product of matrices: operation
> precedence
> 
> 
> package expm: matrix powers within a product of matrices: operation
> precedence
> 
>     I want to double check that for M and N kxk mtrices and v a k-vector
>     M%^%2%*%N%*%v is not automatically read as (M%^%2)%*%N%*%v or
>     M%*%N%^%2%*%v is not automatically read as M%*%(N%^%2)%*%v or
>     both
> 
>     I had been assuming the usual precedence (powers first, then
> multiplication) applies for matrix powers and multiplication in expm. I was
> getting unexpected results. In desperation I tried putting in the
> parentheses and seem to be getting much more reasonable answers. But I am so
> surprised that the matrix power operation is, apparently, not automatically
> given precedence over the matrix multiplication operation that I do not
> trust that adding parentheses has cured my bug. Maybe I am still making some
> other mistake instead. Can anyone confirm that in fact the parentheses are
> (sometimes?) essential? I could not find any documentation, one way or the
> other, just definitions of the power operator and of matrix exponentials.
> 
>     TIA Rainer K. Sachs, Prof emertitus of math
> 
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/package-expm-matrix-
> powers-within-a-product-of-matrices-operation-precedence-tp4669733.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gleynes+r at gmail.com  Tue Jun 18 00:02:30 2013
From: gleynes+r at gmail.com (Gene Leynes)
Date: Mon, 17 Jun 2013 17:02:30 -0500
Subject: [R] Failure to install RSer
Message-ID: <CAOBARVi6mxSw8T=HHsioUVsJFq05t3p4xukQaw-nLVR2k-Sd8A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130617/8c15bd6b/attachment.pl>

From smartpink111 at yahoo.com  Tue Jun 18 00:09:15 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 17 Jun 2013 15:09:15 -0700 (PDT)
Subject: [R] write a function to do pairwise calculation
In-Reply-To: <CALwvZ4WepoyBN3SdwAqwqZOhxHO9SN6q5-XCwS939kmuwN3vJg@mail.gmail.com>
References: <CALwvZ4WepoyBN3SdwAqwqZOhxHO9SN6q5-XCwS939kmuwN3vJg@mail.gmail.com>
Message-ID: <1371506955.87513.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi, 

You didn't provide any information about the package.? I guess it is from "energy".? 


library(energy)
x <- iris[1:50, 1:4]?? #examples given in the package
y <- iris[51:100, 1:4]
z<- iris[101:150,1:4]
vec1<-c("x","y","z")
mat1<- combn(vec1,2)

sapply(split(mat1,col(mat1)),function(.dat) dcor(get(.dat[1]),get(.dat[2]),1.5))
#??????? 1???????? 2???????? 3 
#0.1862890 0.2331567 0.2303689 


A.K.





----- Original Message -----
From: Amanda Li <amandali at uchicago.edu>
To: r-help at r-project.org
Cc: 
Sent: Monday, June 17, 2013 1:14 PM
Subject: [R] write a function to do pairwise calculation

Hello,

I want to write a function to do pairwise calculation, but I don' know how
to write it. Could anyone help?

i.e. I have A (2*3), B(3*3), C(4*3) three matrices. I want to calculate
distance correlation between each pair of matrices using code "dcor". How
do I write a function so that I can get the result as a matrix integrating
all the? pairwise results?

Thanks in advance for your help!

Best,
Amanda

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From gleynes+r at gmail.com  Tue Jun 18 00:11:31 2013
From: gleynes+r at gmail.com (Gene Leynes)
Date: Mon, 17 Jun 2013 17:11:31 -0500
Subject: [R] Failure to install RSer
In-Reply-To: <CAOBARVi6mxSw8T=HHsioUVsJFq05t3p4xukQaw-nLVR2k-Sd8A@mail.gmail.com>
References: <CAOBARVi6mxSw8T=HHsioUVsJFq05t3p4xukQaw-nLVR2k-Sd8A@mail.gmail.com>
Message-ID: <CAOBARVjZUgpxMcQN+=6U1uJjHdo5kc5st382eSA=YeHjE5DmAA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130617/1d9572c0/attachment.pl>

From may.katharina at googlemail.com  Tue Jun 18 00:23:16 2013
From: may.katharina at googlemail.com (Katharina May)
Date: Tue, 18 Jun 2013 00:23:16 +0200
Subject: [R] Package zoo - na.rm ignored?
Message-ID: <CALRJQiMhEwLNZe_B0-+6bwW1bngNpruhDdOF4Eh3v--yCcgazw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130618/d96f8ef4/attachment.pl>

From istazahn at gmail.com  Tue Jun 18 00:27:44 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 17 Jun 2013 18:27:44 -0400
Subject: [R] Failure to install RSer
In-Reply-To: <CAOBARVjZUgpxMcQN+=6U1uJjHdo5kc5st382eSA=YeHjE5DmAA@mail.gmail.com>
References: <CAOBARVi6mxSw8T=HHsioUVsJFq05t3p4xukQaw-nLVR2k-Sd8A@mail.gmail.com>
	<CAOBARVjZUgpxMcQN+=6U1uJjHdo5kc5st382eSA=YeHjE5DmAA@mail.gmail.com>
Message-ID: <CA+vqiLFRXhOw6cPtNwwJzVmpozfryHwsAqkAm=T0ymvKFBmhUw@mail.gmail.com>

On Mon, Jun 17, 2013 at 6:11 PM, Gene Leynes <gleynes+r at gmail.com> wrote:
>
> I should have called this "failure to install several packages"
>
> Here is the list of libraries that I can't install in 3.0.1 that I could
> install to 3.0.0
>
> Have others had the same problem?
>
> [1] "BiocGenerics"  "BiocInstaller" "gdata"         "graph"
> [5] "rCharts"       "RCurl"         "Rgraphviz"     "Rserve"
>

Some of these are bioconductor packages--you won't be able to install
them using install.packages(). See
http://www.bioconductor.org/install/. Some (or at least one) has been
removed from CRAN (see
http://cran.r-project.org/web/packages/graph/index.html). As for the
rest, you should post the error messages so we can see what the
problem is.

Best,
Ista
>
>
>
> On Mon, Jun 17, 2013 at 5:02 PM, Gene Leynes <gleynes+r at gmail.com> wrote:
>
> > Hello,
> >
> > I just upgraded to 3.0.1 and a bunch of packages won't install, including
> > Rserve and RCurl
> >
> > Any hints on why?
> >
> > Thanks
> >
> > > install.packages('Rserve')
> > --- Please select a CRAN mirror for use in this session ---
> > trying URL '
> > http://cran.case.edu/bin/windows/contrib/3.0/Rserve_0.6-8.1.zip'
> > Content type 'application/zip' length 600457 bytes (586 Kb)
> > opened URL
> > downloaded 586 Kb
> >
> > package ?Rserve? successfully unpacked and MD5 sums checked
> > Warning: unable to move temporary installation ?C:\Program
> > Files\R\R-3.0.1\library\fileb6c18782cd4\Rserve? to ?C:\Program
> > Files\R\R-3.0.1\library\Rserve?
> >
> > The downloaded binary packages are in
> >         C:\Users\gene\AppData\Local\Temp\RtmpMZlycb\downloaded_packages
> >
> > > sessionInfo()
> > R version 3.0.1 (2013-05-16)
> > Platform: x86_64-w64-mingw32/x64 (64-bit)
> >
> > locale:
> > [1] LC_COLLATE=English_United States.1252
> > [2] LC_CTYPE=English_United States.1252
> > [3] LC_MONETARY=English_United States.1252
> > [4] LC_NUMERIC=C
> > [5] LC_TIME=English_United States.1252
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > loaded via a namespace (and not attached):
> > [1] tools_3.0.1
> > >
> >
> >
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch.duncan at gmail.com  Tue Jun 18 00:39:36 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 17 Jun 2013 18:39:36 -0400
Subject: [R] Help understanding environments
In-Reply-To: <8AB18F255888194F82934830982C82C13DA7376FD1@UTHCMS1.uthouston.edu>
References: <8AB18F255888194F82934830982C82C13DA7376FD1@UTHCMS1.uthouston.edu>
Message-ID: <51BF9028.20900@gmail.com>

On 13-06-17 5:02 PM, Davis, Brian wrote:
> I have a collection of .RData files that have result objects that I would like to combine.  Specifically, skatCohort objects from the skatMeta package, but I've run into a similar issue with simple data.frames also.
>
> If I run something like
>
> FILES <- list.files(path="/path/to/my/results", pattern=".RData$", full.names=TRUE)
> combined <- NULL
>    for (FILE in FILES) {
>      load(FILE)
>      if (!is.null(combined)) {
>        combined <- c(combined, res)
>      } else {
>        combined <- res
>      }
>    }
>
> I get all my objects combined.  However, if I wrap this into a function I get the following error
>
> c_objects <- function(FILES) {
>    combined <- NULL
>    for (FILE in FILES) {
>      load(FILE)
>      if (!is.null(combined)) {
>        combined <- c(combined, res)
>      } else {
>        combined <- res
>      }
>    }
>    return(combined)
> }
>
> combined_results <- c_objects(FILES)
> Error in eval(expr, envir, enclos) : object 'combined' not found
>
> How should I write this function such that it can find "combined".   I've tried reading the help on envirnaments, and the exisits function but I haven't been able to figure this out.  Are there any other resources to read up on this?

You are doing something that you aren't showing us:  I don't see any 
calls to eval(), but it's eval() that generated the error.

Calling traceback() after the error might be informative.

Duncan Murdoch


From ggrothendieck at gmail.com  Tue Jun 18 00:50:45 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 17 Jun 2013 18:50:45 -0400
Subject: [R] Package zoo - na.rm ignored?
In-Reply-To: <CALRJQiMhEwLNZe_B0-+6bwW1bngNpruhDdOF4Eh3v--yCcgazw@mail.gmail.com>
References: <CALRJQiMhEwLNZe_B0-+6bwW1bngNpruhDdOF4Eh3v--yCcgazw@mail.gmail.com>
Message-ID: <CAP01uR==ibtDiGXgEy6_y6Y65vNVbmPOmCp3DEoPH-LvQB=m5w@mail.gmail.com>

On Mon, Jun 17, 2013 at 6:23 PM, Katharina May
<may.katharina at googlemail.com> wrote:
> Dear R Users,
>
> I've got a strange problem, which I do not really understand:
>
> when I use na.spline from the zoo package, the option na.rm is just being
> ignored, see this adjusted example from the na.spline help page:
> ########################
> d0 <- as.Date("2000-01-01")
> z <- zoo(c(NA, 11, 13, NA, 15, NA), d0 + 1:6)
> na.spline(z)
> na.spline(z, na.rm = FALSE)
> na.spline(z, na.rm = T)
> #######################
>
> In all 3 cases, the output looks like this with the trailing NA being
> replaced:
> 2000-01-02 2000-01-03 2000-01-04 2000-01-05 2000-01-06 2000-01-07
>   8.333333  11.000000  13.000000  14.333333  15.000000  15.000000
>
> Am I missing something here?
> Any help is very much appreciated...
>

If the result of the spline interpolation still results in NAs then
na.rm=TRUE will remove any leading NAs.  It may be that all currently
supported methods produce no NAs in which case this argument would
only be there for compatability with na.approx and in case future
additional spline methods do produce NAs.


From may.katharina at googlemail.com  Tue Jun 18 01:03:18 2013
From: may.katharina at googlemail.com (Katharina May)
Date: Tue, 18 Jun 2013 01:03:18 +0200
Subject: [R] Package zoo - na.rm ignored?
Message-ID: <CALRJQiNBUnZnannj8PJUcRrAPJVMBOSqE2n6W7f=1otRXWLp2g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130618/6371aaae/attachment.pl>

From ivo.welch at anderson.ucla.edu  Tue Jun 18 01:07:50 2013
From: ivo.welch at anderson.ucla.edu (ivo welch)
Date: Mon, 17 Jun 2013 16:07:50 -0700
Subject: [R] load() into a data frame with my chosen name => .ThisEnv ?
Message-ID: <CAPr7RtV26umGKfJzvm+d-C80nnidRsz3jhOOwkm_E-jN8sizbg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130617/48e090e6/attachment.pl>

From wdunlap at tibco.com  Tue Jun 18 01:23:22 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 17 Jun 2013 23:23:22 +0000
Subject: [R] load() into a data frame with my chosen name => .ThisEnv ?
In-Reply-To: <CAPr7RtV26umGKfJzvm+d-C80nnidRsz3jhOOwkm_E-jN8sizbg@mail.gmail.com>
References: <CAPr7RtV26umGKfJzvm+d-C80nnidRsz3jhOOwkm_E-jN8sizbg@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C303A36@PA-MBX01.na.tibco.com>

> very simple question.  I probably forgot the answer (early stage onset),
> and I could not find it via google and r-help.
> 
> I have a number of files, each containing one saved data frame.  I want to
> do the equivalent of
> 
>    d <- .GlobalEnv[[ load(file="dxxxx.Rdata") ]

Did you try using load's 'envir' argument, which should be mentioned in its help file?
E.g., define the function
   getMyData <- function(RDataFile) {
       # RDataFile should be *.RData file containing exactly one object
       .ThisEnv <- new.env(parent = emptyenv())
       loadedNames <- load(file=RDataFile, envir=.ThisEnv)
       stopifnot(length(loadedNames)==1)
       .ThisEnv[[ loadedNames ]]
   }
and use it in the loop as
  d <- getMyData(RDataFile = fname)
   

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of ivo welch
> Sent: Monday, June 17, 2013 4:08 PM
> To: r-help
> Subject: [R] load() into a data frame with my chosen name => .ThisEnv ?
> 
> very simple question.  I probably forgot the answer (early stage onset),
> and I could not find it via google and r-help.
> 
> I have a number of files, each containing one saved data frame.  I want to
> do the equivalent of
> 
>    d <- .GlobalEnv[[ load(file="dxxxx.Rdata") ]
> 
> but inside a function, and I don't need the original name (dxxxx).  in the
> end, I want to do something like
> 
>    run <- function( i ) {
>         fname <- paste0( "d", i, ".Rdata")
>         stopifnot( length(fname)==1 )
>         d <- .ThisEnv[[ load(file=fname) ]]
>         coef( lm(d[,1] ~ d[,2]) )  ## calculate two coefficients and return
> them
>    }
> 
>    results <- mclapply( 1:10000, run )
> 
> stumped over something that should be easy...pointer appreciated.
> 
> /iaw
> ----
> Ivo Welch (ivo.welch at gmail.com)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From miaojpm at gmail.com  Tue Jun 18 04:02:49 2013
From: miaojpm at gmail.com (jpm miao)
Date: Tue, 18 Jun 2013 10:02:49 +0800
Subject: [R] =?windows-1252?q?=93arch=2Etest=94_in_=93vars=94_package_with?=
	=?windows-1252?q?_multivariate=2Eonly_=3D_FALSE?=
Message-ID: <CABcx46BuwgArnkfDLdPqRG3z7-1h6_Us6aoQqYk20wYpDfyXUw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130618/08c945a7/attachment.pl>

From alongway at gmail.com  Tue Jun 18 00:52:52 2013
From: alongway at gmail.com (CompBiol ATL)
Date: Mon, 17 Jun 2013 18:52:52 -0400
Subject: [R] help with string split in R
Message-ID: <CALimP=iOOZwO0hVwZ8i+nAU1nTO=QiU9NES5=r9EcWaf2wphSg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130617/419951b0/attachment.pl>

From rainersachs at berkeley.edu  Tue Jun 18 00:08:38 2013
From: rainersachs at berkeley.edu (Rainer K. SACHS)
Date: Mon, 17 Jun 2013 15:08:38 -0700
Subject: [R] package expm: matrix powers within a product of matrices:
 operation precedence
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C3039C0@PA-MBX01.na.tibco.com>
References: <1371500423650-4669733.post@n4.nabble.com>
	<E66794E69CFDE04D9A70842786030B931C3039C0@PA-MBX01.na.tibco.com>
Message-ID: <CA+G8hjyjX75sG53wD2Gv9sLrK3MJQ=nYyNE=_djA9hVAU8DizQ@mail.gmail.com>

Thanks, that clears everything up completely. It might be worth adding
your comment to the available documentation.

On 6/17/13, William Dunlap <wdunlap at tibco.com> wrote:
> All operators of the form %<something>% have the same precedence,
> that of %*%.    R does not look at the <something> between the percent
> signs to determine the precedence.  Hence you must use parentheses
> to get the order of operations that you want.
>
> (I think that %<something>% operators are overused - providing the same
> functionality in a standard functional form is often more convenient.  It
> certainly would eliminate your problem.)
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On Behalf
>> Of Rainer Sachs
>> Sent: Monday, June 17, 2013 1:20 PM
>> To: r-help at r-project.org
>> Subject: [R] package expm: matrix powers within a product of matrices:
>> operation
>> precedence
>>
>>
>> package expm: matrix powers within a product of matrices: operation
>> precedence
>>
>>     I want to double check that for M and N kxk mtrices and v a k-vector
>>     M%^%2%*%N%*%v is not automatically read as (M%^%2)%*%N%*%v or
>>     M%*%N%^%2%*%v is not automatically read as M%*%(N%^%2)%*%v or
>>     both
>>
>>     I had been assuming the usual precedence (powers first, then
>> multiplication) applies for matrix powers and multiplication in expm. I
>> was
>> getting unexpected results. In desperation I tried putting in the
>> parentheses and seem to be getting much more reasonable answers. But I am
>> so
>> surprised that the matrix power operation is, apparently, not
>> automatically
>> given precedence over the matrix multiplication operation that I do not
>> trust that adding parentheses has cured my bug. Maybe I am still making
>> some
>> other mistake instead. Can anyone confirm that in fact the parentheses
>> are
>> (sometimes?) essential? I could not find any documentation, one way or
>> the
>> other, just definitions of the power operator and of matrix exponentials.
>>
>>     TIA Rainer K. Sachs, Prof emertitus of math
>>
>>
>>
>>
>>
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/package-expm-matrix-
>> powers-within-a-product-of-matrices-operation-precedence-tp4669733.html
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From nfultz at ucla.edu  Tue Jun 18 03:49:02 2013
From: nfultz at ucla.edu (Neal Fultz)
Date: Mon, 17 Jun 2013 18:49:02 -0700
Subject: [R] load() into a data frame with my chosen name => .ThisEnv ?
In-Reply-To: <CAPr7RtV26umGKfJzvm+d-C80nnidRsz3jhOOwkm_E-jN8sizbg@mail.gmail.com>
References: <CAPr7RtV26umGKfJzvm+d-C80nnidRsz3jhOOwkm_E-jN8sizbg@mail.gmail.com>
Message-ID: <20130618014902.GA10022@neal-SP35>

For your problem, you might want to use saveRDS and readRDS instead of
save and load. I would also use dir to get a list of files rather
than paste. 

Then your solution might look like:


run <- function(filename) {
    df <- readRDS(filename);
    coef( lm(df[,1] ~ df[,2]) ) 
}

results <- lapply( dir(pattern=glob2rx('d*.rds')), run)

If this is disk-bound, using multiple threads probably won't help much.
You'll have to try it out for yourself.

-nfultz

On Mon, Jun 17, 2013 at 04:07:50PM -0700, ivo welch wrote:
> very simple question.  I probably forgot the answer (early stage onset),
> and I could not find it via google and r-help.
> 
> I have a number of files, each containing one saved data frame.  I want to
> do the equivalent of
> 
>    d <- .GlobalEnv[[ load(file="dxxxx.Rdata") ]
> 
> but inside a function, and I don't need the original name (dxxxx).  in the
> end, I want to do something like
> 
>    run <- function( i ) {
>         fname <- paste0( "d", i, ".Rdata")
>         stopifnot( length(fname)==1 )
>         d <- .ThisEnv[[ load(file=fname) ]]
>         coef( lm(d[,1] ~ d[,2]) )  ## calculate two coefficients and return
> them
>    }
> 
>    results <- mclapply( 1:10000, run )
> 
> stumped over something that should be easy...pointer appreciated.
> 
> /iaw
> ----
> Ivo Welch (ivo.welch at gmail.com)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Tue Jun 18 06:23:34 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 18 Jun 2013 00:23:34 -0400
Subject: [R] help with string split in R
In-Reply-To: <CALimP=iOOZwO0hVwZ8i+nAU1nTO=QiU9NES5=r9EcWaf2wphSg@mail.gmail.com>
References: <CALimP=iOOZwO0hVwZ8i+nAU1nTO=QiU9NES5=r9EcWaf2wphSg@mail.gmail.com>
Message-ID: <b60c46ca-0f61-4188-a648-c6fed4dfb300@email.android.com>

?sub
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

CompBiol ATL <alongway at gmail.com> wrote:

>#I want to remove '_alpha' in a vector of strings
>myInput = c( "afg3_alpha", "alg12_alpha", "dbp3_alpha",  "elp4_alpha",
> "fob1_alpha",  "gpr1_alpha")
>
>#my current solution
>tmpsplit = strsplit(myInput, '_')
>tmp = NA
>for (item in tmpsplit){
>  tmp = c(tmp, item[1])
>}
>results1  = tmp[-1];
>#this is what I need, but I want a better solution.
>
>#Here is what I come up with, but it is pretty awkward
>tmp3 = lapply(myInput, FUN=function(x){strsplit(x, '_')[[1]][1]})
>results2 = unlist(tmp3)
>
>#Please help me revise the above loop. Thanks, -- Hong
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Tue Jun 18 06:25:13 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 17 Jun 2013 21:25:13 -0700 (PDT)
Subject: [R] help with string split in R
In-Reply-To: <CALimP=iOOZwO0hVwZ8i+nAU1nTO=QiU9NES5=r9EcWaf2wphSg@mail.gmail.com>
References: <CALimP=iOOZwO0hVwZ8i+nAU1nTO=QiU9NES5=r9EcWaf2wphSg@mail.gmail.com>
Message-ID: <1371529513.63074.YahooMailNeo@web142602.mail.bf1.yahoo.com>

gsub("_.*","",myInput)
#[1] "afg3"? "alg12" "dbp3"? "elp4"? "fob1"? "gpr1" 
A.K.



----- Original Message -----
From: CompBiol ATL <alongway at gmail.com>
To: r-help at r-project.org
Cc: Hong Qin <qinstat at gmail.com>
Sent: Monday, June 17, 2013 6:52 PM
Subject: [R] help with string split in R

#I want to remove '_alpha' in a vector of strings
myInput = c( "afg3_alpha", "alg12_alpha", "dbp3_alpha",? "elp4_alpha",
"fob1_alpha",? "gpr1_alpha")

#my current solution
tmpsplit = strsplit(myInput, '_')
tmp = NA
for (item in tmpsplit){
? tmp = c(tmp, item[1])
}
results1? = tmp[-1];
#this is what I need, but I want a better solution.

#Here is what I come up with, but it is pretty awkward
tmp3 = lapply(myInput, FUN=function(x){strsplit(x, '_')[[1]][1]})
results2 = unlist(tmp3)

#Please help me revise the above loop. Thanks, -- Hong

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From alexandre.piche at mail.mcgill.ca  Tue Jun 18 07:00:38 2013
From: alexandre.piche at mail.mcgill.ca (AlexPiche)
Date: Mon, 17 Jun 2013 22:00:38 -0700 (PDT)
Subject: [R] Data frame to Matrix by category
In-Reply-To: <51BECD6A.1010401@sapo.pt>
References: <1371450164950-4669669.post@n4.nabble.com>
	<51BECD6A.1010401@sapo.pt>
Message-ID: <1371531638554-4669768.post@n4.nabble.com>

Thank you mate!



--
View this message in context: http://r.789695.n4.nabble.com/Data-frame-to-Matrix-by-category-tp4669669p4669768.html
Sent from the R help mailing list archive at Nabble.com.


From eliza_botto at hotmail.com  Tue Jun 18 11:50:01 2013
From: eliza_botto at hotmail.com (eliza botto)
Date: Tue, 18 Jun 2013 09:50:01 +0000
Subject: [R] regression in 3D space
Message-ID: <BLU170-W370DB7579ACBD8A3E69447898C0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130618/96653408/attachment.pl>

From raziq_fazli at yahoo.com  Tue Jun 18 14:10:56 2013
From: raziq_fazli at yahoo.com (Fazli Raziq)
Date: Tue, 18 Jun 2013 05:10:56 -0700 (PDT)
Subject: [R] Problem in Two way Matrix
Message-ID: <1371557456.29269.YahooMailNeo@web162902.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130618/f661a834/attachment.pl>

From motyocska at yahoo.com  Tue Jun 18 14:34:47 2013
From: motyocska at yahoo.com (Andras Farkas)
Date: Tue, 18 Jun 2013 05:34:47 -0700 (PDT)
Subject: [R] find closest value in a vector based on another vector values
Message-ID: <1371558887.88366.YahooMailClassic@web140401.mail.bf1.yahoo.com>

Dear All,

would you please provide your thoughts on the following:
let us say I have:

a <-c(1,5,8,15,32,69)
b <-c(8.5,33)

and I would like to extract from "a" the two values that are closest to the values in "b", where the length of this vectors may change but b will allways be shorter than "a". So at the end based on this example I should have the result "f" as

f <-c(8,32)

appreciate the help,

Andras


From ggrothendieck at gmail.com  Tue Jun 18 14:39:11 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 18 Jun 2013 08:39:11 -0400
Subject: [R] Package zoo - na.rm ignored?
In-Reply-To: <CALRJQiNBUnZnannj8PJUcRrAPJVMBOSqE2n6W7f=1otRXWLp2g@mail.gmail.com>
References: <CALRJQiNBUnZnannj8PJUcRrAPJVMBOSqE2n6W7f=1otRXWLp2g@mail.gmail.com>
Message-ID: <CAP01uRk=_k5u=ChvD7++fi5v8hhdFuDBh0Z9AS+y94cAT+V0oA@mail.gmail.com>

On Mon, Jun 17, 2013 at 7:03 PM, Katharina May
<may.katharina at googlemail.com> wrote:
> many thanks for the enlightenment - I guess I completely misunderstood the
> na.rm option here...
>

Looking at the help file the na argument seems not suffiiciently well
explained. Will improve.

--
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From jorgeivanvelez at gmail.com  Tue Jun 18 14:43:39 2013
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Tue, 18 Jun 2013 22:43:39 +1000
Subject: [R] find closest value in a vector based on another vector
	values
In-Reply-To: <1371558887.88366.YahooMailClassic@web140401.mail.bf1.yahoo.com>
References: <1371558887.88366.YahooMailClassic@web140401.mail.bf1.yahoo.com>
Message-ID: <CAKL8G3G852LAPTgEJ8Uo9RBr_YB3Z5qLUT=dWe1vXZGohJQd7w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130618/850c38e8/attachment.pl>

From fjsanala at gmail.com  Tue Jun 18 12:41:53 2013
From: fjsanala at gmail.com (Francisco Javier Santos Alamillos)
Date: Tue, 18 Jun 2013 12:41:53 +0200
Subject: [R] Linear combination of time series for approximating another one.
Message-ID: <CAJZkWGtm+DUsGYKJ_80bWx5h7RC4qG9fP3dGQjO8L-LjiHq4+Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130618/a596d234/attachment.pl>

From smartpink111 at yahoo.com  Tue Jun 18 15:12:12 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 18 Jun 2013 06:12:12 -0700 (PDT)
Subject: [R] find closest value in a vector based on another vector
	values
In-Reply-To: <1371558887.88366.YahooMailClassic@web140401.mail.bf1.yahoo.com>
References: <1371558887.88366.YahooMailClassic@web140401.mail.bf1.yahoo.com>
Message-ID: <1371561132.14748.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Perhaps this works:

a[sapply(b,function(x) which.min(abs(x-a)))]
#[1]? 8 32

A.K.

----- Original Message -----
From: Andras Farkas <motyocska at yahoo.com>
To: r-help at r-project.org
Cc: 
Sent: Tuesday, June 18, 2013 8:34 AM
Subject: [R] find closest value in a vector based on another vector values

Dear All,

would you please provide your thoughts on the following:
let us say I have:

a <-c(1,5,8,15,32,69)
b <-c(8.5,33)

and I would like to extract from "a" the two values that are closest to the values in "b", where the length of this vectors may change but b will allways be shorter than "a". So at the end based on this example I should have the result "f" as

f <-c(8,32)

appreciate the help,

Andras

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From Gerrit.Eichner at math.uni-giessen.de  Tue Jun 18 15:25:40 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Tue, 18 Jun 2013 15:25:40 +0200 (MEST)
Subject: [R] regression in 3D space
In-Reply-To: <BLU170-W370DB7579ACBD8A3E69447898C0@phx.gbl>
References: <BLU170-W370DB7579ACBD8A3E69447898C0@phx.gbl>
Message-ID: <Pine.SOC.4.64.1306181513340.9335@solcom.hrz.uni-giessen.de>

Dear Eliza,

the more unspecific a question is formulated, the more is the poster in an 
urgent need for a statistical consultant nearby and -- at the same time -- 
the less likely is is to get a useful answer on this list ...

I suggest you to read the posting guide, look at CRAN's Task Views and/or 
to find a (patient) stats consultant near you, and then to come back to 
this list.

  No harm meant  --  Gerrit


On Tue, 18 Jun 2013, eliza botto wrote:

> Dear UseRs,I need to know that is there a way in R for a 3D regression 
> analysis?i actually have a data in 3 dimensional space showing 
> differences between regimes in 3D space and i want to do its regression 
> analysis with another data which is also in 3D space.
> thanks in advance for your help,
> Eliza
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Brian.Davis at uth.tmc.edu  Tue Jun 18 15:57:12 2013
From: Brian.Davis at uth.tmc.edu (Davis, Brian)
Date: Tue, 18 Jun 2013 08:57:12 -0500
Subject: [R] Help understanding environments
In-Reply-To: <51BF9028.20900@gmail.com>
References: <8AB18F255888194F82934830982C82C13DA7376FD1@UTHCMS1.uthouston.edu>
	<51BF9028.20900@gmail.com>
Message-ID: <8AB18F255888194F82934830982C82C13DA7376FD8@UTHCMS1.uthouston.edu>

In my haste to make a smaller example than my actual code I used 'is.null' instead of 'exists' as is in my code.  Here's a small reproducible example


res <- list(abc=letters, ABC=LETTERS)
save(res, file="results.RData")
res <- list(zyx=rev(letters), ZYX=rev(LETTERS))
save(res, file="results2.RData")

rm(res)
FILES <- c("results.RData", "results2.RData")


c_objects <- function(FILES) {
  for (FILE in FILES) {
    load(FILE)
    if (exists(combined)) {
      combined <- c(combined, res)
    } else {
      combined <- res
    }
  }
  return(combined)
}

combined_results <- c_objects(FILES)


-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Monday, June 17, 2013 5:40 PM
To: Davis, Brian
Cc: r-help at r-project.org
Subject: Re: [R] Help understanding environments

On 13-06-17 5:02 PM, Davis, Brian wrote:
> I have a collection of .RData files that have result objects that I would like to combine.  Specifically, skatCohort objects from the skatMeta package, but I've run into a similar issue with simple data.frames also.
>
> If I run something like
>
> FILES <- list.files(path="/path/to/my/results", pattern=".RData$", 
> full.names=TRUE) combined <- NULL
>    for (FILE in FILES) {
>      load(FILE)
>      if (!is.null(combined)) {
>        combined <- c(combined, res)
>      } else {
>        combined <- res
>      }
>    }
>
> I get all my objects combined.  However, if I wrap this into a 
> function I get the following error
>
> c_objects <- function(FILES) {
>    combined <- NULL
>    for (FILE in FILES) {
>      load(FILE)
>      if (!is.null(combined)) {
>        combined <- c(combined, res)
>      } else {
>        combined <- res
>      }
>    }
>    return(combined)
> }
>
> combined_results <- c_objects(FILES)
> Error in eval(expr, envir, enclos) : object 'combined' not found
>
> How should I write this function such that it can find "combined".   I've tried reading the help on envirnaments, and the exisits function but I haven't been able to figure this out.  Are there any other resources to read up on this?

You are doing something that you aren't showing us:  I don't see any calls to eval(), but it's eval() that generated the error.

Calling traceback() after the error might be informative.

Duncan Murdoch


From gunter.berton at gene.com  Tue Jun 18 16:07:04 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 18 Jun 2013 07:07:04 -0700
Subject: [R] find closest value in a vector based on another vector
	values
In-Reply-To: <CAKL8G3G852LAPTgEJ8Uo9RBr_YB3Z5qLUT=dWe1vXZGohJQd7w@mail.gmail.com>
References: <1371558887.88366.YahooMailClassic@web140401.mail.bf1.yahoo.com>
	<CAKL8G3G852LAPTgEJ8Uo9RBr_YB3Z5qLUT=dWe1vXZGohJQd7w@mail.gmail.com>
Message-ID: <CACk-te1tfcMGLG_aMjnYP0Ve-1UUVkKZN1YhqC--5PaDRb0rFQ@mail.gmail.com>

Jorge: No.

> a <-c(1,5,8,15,32,33.5,69)
> b <-c(8.5,33)
> a[findInterval(b, a)]
[1]  8 32  ##should be  8   33.5

I believe it has to be done explicitly by finding all the differences
and choosing those n with minimum values, depending on what n you
want.

Note that the problem is incompletely specified. What if the same
value of a is closest to several values of b? -- do you want all the
values you choose to be different or not, in which case they may not
be minimum?

a <- c(1, 8, 9)
b <- c(2,3)

Then what are the 2 closest values of a to b?

-- Bert

On Tue, Jun 18, 2013 at 5:43 AM, Jorge I Velez <jorgeivanvelez at gmail.com> wrote:
> Dear Andras,
>
> Try
>
>> a[findInterval(b, a)]
> [1]  8 32
>
> HTH,
> Jorge.-
>
>
> On Tue, Jun 18, 2013 at 10:34 PM, Andras Farkas <motyocska at yahoo.com> wrote:
>
>> Dear All,
>>
>> would you please provide your thoughts on the following:
>> let us say I have:
>>
>> a <-c(1,5,8,15,32,69)
>> b <-c(8.5,33)
>>
>> and I would like to extract from "a" the two values that are closest to
>> the values in "b", where the length of this vectors may change but b will
>> allways be shorter than "a". So at the end based on this example I should
>> have the result "f" as
>>
>> f <-c(8,32)
>>
>> appreciate the help,
>>
>> Andras
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From smartpink111 at yahoo.com  Tue Jun 18 16:23:48 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 18 Jun 2013 07:23:48 -0700 (PDT)
Subject: [R] Problem with the mod function %%
Message-ID: <1371565428.84215.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Possibly, R FAQ: 7.31
http://www.hep.by/gnu/r-patched/r-faq/R-FAQ_82.html

(1.1%%1)-0.1
#[1] 8.326673e-17

fun1 <- function(x, y, eps = .Machine$double.eps^0.5) abs(x - y) < eps
?fun1(1.1%%1,0.1)
#[1] TRUE
A.K.



0.1%%1==0.1 
returns TRUE, which is right 

But 
1.1%%1==0.1 
returns FALSE !! 

Note that 1.1%%1>0.1 returns TRUE 

Can someone explain what is wrong? 
I'm using R version 2.15.3 on a mac. 

Thank you in advance


From jorgeivanvelez at gmail.com  Tue Jun 18 16:29:18 2013
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Wed, 19 Jun 2013 00:29:18 +1000
Subject: [R] find closest value in a vector based on another vector
	values
In-Reply-To: <CACk-te1tfcMGLG_aMjnYP0Ve-1UUVkKZN1YhqC--5PaDRb0rFQ@mail.gmail.com>
References: <1371558887.88366.YahooMailClassic@web140401.mail.bf1.yahoo.com>
	<CAKL8G3G852LAPTgEJ8Uo9RBr_YB3Z5qLUT=dWe1vXZGohJQd7w@mail.gmail.com>
	<CACk-te1tfcMGLG_aMjnYP0Ve-1UUVkKZN1YhqC--5PaDRb0rFQ@mail.gmail.com>
Message-ID: <CAKL8G3H30+OsvOGUu3CcRYWs4AcEk+3A1=_8XLStK1_aFwM4Fg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130619/ad6f0a02/attachment.pl>

From smartpink111 at yahoo.com  Tue Jun 18 16:32:56 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 18 Jun 2013 07:32:56 -0700 (PDT)
Subject: [R] Elementary Help
Message-ID: <1371565976.18433.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
May be this helps:
set.seed(24)
dat1<- data.frame(ID=1:200,value=sample(c(5:200,NA),200,replace=TRUE))
?which(is.na(dat1$value))
#[1]? 56 146 184
sum(which(is.na(dat1$value)))? #Not clear about the 2nd part of the question
#[1] 386

?sum(is.na(dat1$value))
#[1] 3
table(is.na(dat1$value))
#FALSE? TRUE 
#? 197???? 3 
A.K.


>I am totally new to R, therefore probably this question will be very 
easy for most of you. I have a range of values in a column ranging from 5 to 200. >Some of the values are missing, that is, not all student 
numbers are there. How do I find which are these missing numbers and 
obtain the sum of >these integers?


From motyocska at yahoo.com  Tue Jun 18 16:41:48 2013
From: motyocska at yahoo.com (Andras Farkas)
Date: Tue, 18 Jun 2013 07:41:48 -0700 (PDT)
Subject: [R] find closest value in a vector based on another vector
	values
In-Reply-To: <CACk-te1tfcMGLG_aMjnYP0Ve-1UUVkKZN1YhqC--5PaDRb0rFQ@mail.gmail.com>
Message-ID: <1371566508.53406.YahooMailClassic@web140403.mail.bf1.yahoo.com>

Bert,

thanks... The values should not repeat themselves if the same a is closest to all b, so probably aruns example extended with a unique command works best?

unique(a[sapply(b,function(x) which.min(abs(x-a)))])

thanks,

Andras

--- On Tue, 6/18/13, Bert Gunter <gunter.berton at gene.com> wrote:

> From: Bert Gunter <gunter.berton at gene.com>
> Subject: Re: [R] find closest value in a vector based on another vector values
> To: "Jorge I Velez" <jorgeivanvelez at gmail.com>
> Cc: "Andras Farkas" <motyocska at yahoo.com>, "R mailing list" <r-help at r-project.org>
> Date: Tuesday, June 18, 2013, 10:07 AM
> Jorge: No.
> 
> > a <-c(1,5,8,15,32,33.5,69)
> > b <-c(8.5,33)
> > a[findInterval(b, a)]
> [1]? 8 32? ##should be?
> 8???33.5
> 
> I believe it has to be done explicitly by finding all the
> differences
> and choosing those n with minimum values, depending on what
> n you
> want.
> 
> Note that the problem is incompletely specified. What if the
> same
> value of a is closest to several values of b? -- do you want
> all the
> values you choose to be different or not, in which case they
> may not
> be minimum?
> 
> a <- c(1, 8, 9)
> b <- c(2,3)
> 
> Then what are the 2 closest values of a to b?
> 
> -- Bert
> 
> On Tue, Jun 18, 2013 at 5:43 AM, Jorge I Velez <jorgeivanvelez at gmail.com>
> wrote:
> > Dear Andras,
> >
> > Try
> >
> >> a[findInterval(b, a)]
> > [1]? 8 32
> >
> > HTH,
> > Jorge.-
> >
> >
> > On Tue, Jun 18, 2013 at 10:34 PM, Andras Farkas <motyocska at yahoo.com>
> wrote:
> >
> >> Dear All,
> >>
> >> would you please provide your thoughts on the
> following:
> >> let us say I have:
> >>
> >> a <-c(1,5,8,15,32,69)
> >> b <-c(8.5,33)
> >>
> >> and I would like to extract from "a" the two values
> that are closest to
> >> the values in "b", where the length of this vectors
> may change but b will
> >> allways be shorter than "a". So at the end based on
> this example I should
> >> have the result "f" as
> >>
> >> f <-c(8,32)
> >>
> >> appreciate the help,
> >>
> >> Andras
> >>
> >> ______________________________________________
> >> R-help at r-project.org
> mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained,
> reproducible code.
> >>
> >
> >? ? ? ???[[alternative
> HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org
> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained,
> reproducible code.
> 
> 
> 
> -- 
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> 
> Internal Contact Info:
> Phone: 467-7374
> Website:
> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm
>


From gunter.berton at gene.com  Tue Jun 18 16:55:18 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 18 Jun 2013 07:55:18 -0700
Subject: [R] find closest value in a vector based on another vector
	values
In-Reply-To: <1371566508.53406.YahooMailClassic@web140403.mail.bf1.yahoo.com>
References: <CACk-te1tfcMGLG_aMjnYP0Ve-1UUVkKZN1YhqC--5PaDRb0rFQ@mail.gmail.com>
	<1371566508.53406.YahooMailClassic@web140403.mail.bf1.yahoo.com>
Message-ID: <CACk-te0_R+3DZEW37ZL7fAnvWkzQtL-q3c6VSOaYLPvmKOJ_rA@mail.gmail.com>

Andras:

No.
Using the a = c(1,8,9) and b = 2:3 that ** I posted before**,  you get
the single unique value of 1.

Please stop guessing, think carefully about what you want to do, and
**test** your code.

-- Bert

On Tue, Jun 18, 2013 at 7:41 AM, Andras Farkas <motyocska at yahoo.com> wrote:
> Bert,
>
> thanks... The values should not repeat themselves if the same a is closest to all b, so probably aruns example extended with a unique command works best?
>
> unique(a[sapply(b,function(x) which.min(abs(x-a)))])
>
> thanks,
>
> Andras
>
> --- On Tue, 6/18/13, Bert Gunter <gunter.berton at gene.com> wrote:
>
>> From: Bert Gunter <gunter.berton at gene.com>
>> Subject: Re: [R] find closest value in a vector based on another vector values
>> To: "Jorge I Velez" <jorgeivanvelez at gmail.com>
>> Cc: "Andras Farkas" <motyocska at yahoo.com>, "R mailing list" <r-help at r-project.org>
>> Date: Tuesday, June 18, 2013, 10:07 AM
>> Jorge: No.
>>
>> > a <-c(1,5,8,15,32,33.5,69)
>> > b <-c(8.5,33)
>> > a[findInterval(b, a)]
>> [1]  8 32  ##should be
>> 8   33.5
>>
>> I believe it has to be done explicitly by finding all the
>> differences
>> and choosing those n with minimum values, depending on what
>> n you
>> want.
>>
>> Note that the problem is incompletely specified. What if the
>> same
>> value of a is closest to several values of b? -- do you want
>> all the
>> values you choose to be different or not, in which case they
>> may not
>> be minimum?
>>
>> a <- c(1, 8, 9)
>> b <- c(2,3)
>>
>> Then what are the 2 closest values of a to b?
>>
>> -- Bert
>>
>> On Tue, Jun 18, 2013 at 5:43 AM, Jorge I Velez <jorgeivanvelez at gmail.com>
>> wrote:
>> > Dear Andras,
>> >
>> > Try
>> >
>> >> a[findInterval(b, a)]
>> > [1]  8 32
>> >
>> > HTH,
>> > Jorge.-
>> >
>> >
>> > On Tue, Jun 18, 2013 at 10:34 PM, Andras Farkas <motyocska at yahoo.com>
>> wrote:
>> >
>> >> Dear All,
>> >>
>> >> would you please provide your thoughts on the
>> following:
>> >> let us say I have:
>> >>
>> >> a <-c(1,5,8,15,32,69)
>> >> b <-c(8.5,33)
>> >>
>> >> and I would like to extract from "a" the two values
>> that are closest to
>> >> the values in "b", where the length of this vectors
>> may change but b will
>> >> allways be shorter than "a". So at the end based on
>> this example I should
>> >> have the result "f" as
>> >>
>> >> f <-c(8,32)
>> >>
>> >> appreciate the help,
>> >>
>> >> Andras
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org
>> mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained,
>> reproducible code.
>> >>
>> >
>> >         [[alternative
>> HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org
>> mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained,
>> reproducible code.
>>
>>
>>
>> --
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>>
>> Internal Contact Info:
>> Phone: 467-7374
>> Website:
>> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm
>>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From ruipbarradas at sapo.pt  Tue Jun 18 16:56:45 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 18 Jun 2013 15:56:45 +0100
Subject: [R] Help understanding environments
In-Reply-To: <8AB18F255888194F82934830982C82C13DA7376FD8@UTHCMS1.uthouston.edu>
References: <8AB18F255888194F82934830982C82C13DA7376FD1@UTHCMS1.uthouston.edu>
	<51BF9028.20900@gmail.com>
	<8AB18F255888194F82934830982C82C13DA7376FD8@UTHCMS1.uthouston.edu>
Message-ID: <51C0752D.5020304@sapo.pt>

Hello,

The first argument to exists() must be the name of an object given as a 
character string, as stated in the help page. See ?exists. You have also 
forgot to initialize combined to NULL, this time.
Your function revised would then become


c_objects <- function(FILES) {
   combined <- NULL
   for (FILE in FILES) {
     load(FILE)
     if (exists("combined")) {
       combined <- c(combined, res)
     } else {
       combined <- res
     }
   }
   return(combined)
}


And all works as expected.

Hope this helps,

Rui Barradas


Em 18-06-2013 14:57, Davis, Brian escreveu:
> In my haste to make a smaller example than my actual code I used 'is.null' instead of 'exists' as is in my code.  Here's a small reproducible example
>
>
> res <- list(abc=letters, ABC=LETTERS)
> save(res, file="results.RData")
> res <- list(zyx=rev(letters), ZYX=rev(LETTERS))
> save(res, file="results2.RData")
>
> rm(res)
> FILES <- c("results.RData", "results2.RData")
>
>
> c_objects <- function(FILES) {
>    for (FILE in FILES) {
>      load(FILE)
>      if (exists(combined)) {
>        combined <- c(combined, res)
>      } else {
>        combined <- res
>      }
>    }
>    return(combined)
> }
>
> combined_results <- c_objects(FILES)
>
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Monday, June 17, 2013 5:40 PM
> To: Davis, Brian
> Cc: r-help at r-project.org
> Subject: Re: [R] Help understanding environments
>
> On 13-06-17 5:02 PM, Davis, Brian wrote:
>> I have a collection of .RData files that have result objects that I would like to combine.  Specifically, skatCohort objects from the skatMeta package, but I've run into a similar issue with simple data.frames also.
>>
>> If I run something like
>>
>> FILES <- list.files(path="/path/to/my/results", pattern=".RData$",
>> full.names=TRUE) combined <- NULL
>>     for (FILE in FILES) {
>>       load(FILE)
>>       if (!is.null(combined)) {
>>         combined <- c(combined, res)
>>       } else {
>>         combined <- res
>>       }
>>     }
>>
>> I get all my objects combined.  However, if I wrap this into a
>> function I get the following error
>>
>> c_objects <- function(FILES) {
>>     combined <- NULL
>>     for (FILE in FILES) {
>>       load(FILE)
>>       if (!is.null(combined)) {
>>         combined <- c(combined, res)
>>       } else {
>>         combined <- res
>>       }
>>     }
>>     return(combined)
>> }
>>
>> combined_results <- c_objects(FILES)
>> Error in eval(expr, envir, enclos) : object 'combined' not found
>>
>> How should I write this function such that it can find "combined".   I've tried reading the help on envirnaments, and the exisits function but I haven't been able to figure this out.  Are there any other resources to read up on this?
>
> You are doing something that you aren't showing us:  I don't see any calls to eval(), but it's eval() that generated the error.
>
> Calling traceback() after the error might be informative.
>
> Duncan Murdoch
>


From Brian.Davis at uth.tmc.edu  Tue Jun 18 16:57:57 2013
From: Brian.Davis at uth.tmc.edu (Davis, Brian)
Date: Tue, 18 Jun 2013 09:57:57 -0500
Subject: [R] Help understanding environments
In-Reply-To: <51C0752D.5020304@sapo.pt>
References: <8AB18F255888194F82934830982C82C13DA7376FD1@UTHCMS1.uthouston.edu>
	<51BF9028.20900@gmail.com>
	<8AB18F255888194F82934830982C82C13DA7376FD8@UTHCMS1.uthouston.edu>
	<51C0752D.5020304@sapo.pt>
Message-ID: <8AB18F255888194F82934830982C82C13DA7376FDD@UTHCMS1.uthouston.edu>

Thanks a bunch.  Can't believe I missed that.

-----Original Message-----
From: Rui Barradas [mailto:ruipbarradas at sapo.pt] 
Sent: Tuesday, June 18, 2013 9:57 AM
To: Davis, Brian
Cc: r-help at r-project.org
Subject: Re: [R] Help understanding environments

Hello,

The first argument to exists() must be the name of an object given as a character string, as stated in the help page. See ?exists. You have also forgot to initialize combined to NULL, this time.
Your function revised would then become


c_objects <- function(FILES) {
   combined <- NULL
   for (FILE in FILES) {
     load(FILE)
     if (exists("combined")) {
       combined <- c(combined, res)
     } else {
       combined <- res
     }
   }
   return(combined)
}


And all works as expected.

Hope this helps,

Rui Barradas


Em 18-06-2013 14:57, Davis, Brian escreveu:
> In my haste to make a smaller example than my actual code I used 
> 'is.null' instead of 'exists' as is in my code.  Here's a small 
> reproducible example
>
>
> res <- list(abc=letters, ABC=LETTERS)
> save(res, file="results.RData")
> res <- list(zyx=rev(letters), ZYX=rev(LETTERS)) save(res, 
> file="results2.RData")
>
> rm(res)
> FILES <- c("results.RData", "results2.RData")
>
>
> c_objects <- function(FILES) {
>    for (FILE in FILES) {
>      load(FILE)
>      if (exists(combined)) {
>        combined <- c(combined, res)
>      } else {
>        combined <- res
>      }
>    }
>    return(combined)
> }
>
> combined_results <- c_objects(FILES)
>
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Monday, June 17, 2013 5:40 PM
> To: Davis, Brian
> Cc: r-help at r-project.org
> Subject: Re: [R] Help understanding environments
>
> On 13-06-17 5:02 PM, Davis, Brian wrote:
>> I have a collection of .RData files that have result objects that I would like to combine.  Specifically, skatCohort objects from the skatMeta package, but I've run into a similar issue with simple data.frames also.
>>
>> If I run something like
>>
>> FILES <- list.files(path="/path/to/my/results", pattern=".RData$",
>> full.names=TRUE) combined <- NULL
>>     for (FILE in FILES) {
>>       load(FILE)
>>       if (!is.null(combined)) {
>>         combined <- c(combined, res)
>>       } else {
>>         combined <- res
>>       }
>>     }
>>
>> I get all my objects combined.  However, if I wrap this into a 
>> function I get the following error
>>
>> c_objects <- function(FILES) {
>>     combined <- NULL
>>     for (FILE in FILES) {
>>       load(FILE)
>>       if (!is.null(combined)) {
>>         combined <- c(combined, res)
>>       } else {
>>         combined <- res
>>       }
>>     }
>>     return(combined)
>> }
>>
>> combined_results <- c_objects(FILES)
>> Error in eval(expr, envir, enclos) : object 'combined' not found
>>
>> How should I write this function such that it can find "combined".   I've tried reading the help on envirnaments, and the exisits function but I haven't been able to figure this out.  Are there any other resources to read up on this?
>
> You are doing something that you aren't showing us:  I don't see any calls to eval(), but it's eval() that generated the error.
>
> Calling traceback() after the error might be informative.
>
> Duncan Murdoch
>


From dizem.uerek at alumni.fh-aachen.de  Tue Jun 18 16:54:26 2013
From: dizem.uerek at alumni.fh-aachen.de (Dzu)
Date: Tue, 18 Jun 2013 07:54:26 -0700 (PDT)
Subject: [R] hist function in a for loop
Message-ID: <1371567266710-4669797.post@n4.nabble.com>

Dear all,

I need to create a for-loop in which I can compute multiple histograms
My code is the following :
#singlefile includes huge csv file
#I want to specify the binsize
#I would like to compute in the for -loop the histograms


    numfiles <- length(singlefile)
    for (i in 1 :51)
    { 
    binsize <- -20 :20/2
    hist(singlefile(singlefile$GVC[singlefile$new_id==i]], break=seq(), by =
binsize)))

What do I have to do ?
How can I specify the range for i  ?

I am totally lost
Thanks for support
D.U



--
View this message in context: http://r.789695.n4.nabble.com/hist-function-in-a-for-loop-tp4669797.html
Sent from the R help mailing list archive at Nabble.com.


From bbolker at gmail.com  Tue Jun 18 17:28:33 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 18 Jun 2013 15:28:33 +0000
Subject: [R] package expm: matrix powers within a product of matrices:
	operation precedence
References: <1371500423650-4669733.post@n4.nabble.com>
	<E66794E69CFDE04D9A70842786030B931C3039C0@PA-MBX01.na.tibco.com>
	<CA+G8hjyjX75sG53wD2Gv9sLrK3MJQ=nYyNE=_djA9hVAU8DizQ@mail.gmail.com>
Message-ID: <loom.20130618T165840-505@post.gmane.org>

Rainer K. SACHS <rainersachs <at> berkeley.edu> writes:

> 
> Thanks, that clears everything up completely. It might be worth adding
> your comment to the available documentation.

  This request should probably go the maintainer of the expm
package (library("expm"); maintainer("expm")), who may or may
not be reading this list at present ...

  Ben Bolker


From wdunlap at tibco.com  Tue Jun 18 17:41:19 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 18 Jun 2013 15:41:19 +0000
Subject: [R] Help understanding environments
In-Reply-To: <51C0752D.5020304@sapo.pt>
References: <8AB18F255888194F82934830982C82C13DA7376FD1@UTHCMS1.uthouston.edu>
	<51BF9028.20900@gmail.com>
	<8AB18F255888194F82934830982C82C13DA7376FD8@UTHCMS1.uthouston.edu>
	<51C0752D.5020304@sapo.pt>
Message-ID: <E66794E69CFDE04D9A70842786030B931C303D4B@PA-MBX01.na.tibco.com>

Since you set
   combined <- NULL
at the top of the function
   exists("combined")
will always return TRUE.  If you initialize 'combined' to NULL,
use is.null(combined) to see if it is still in its virgin state.  If you
don't initialize it to anything then use exists("combined").
In this example you are combining the results with c(), which
essentially ignores NULL arguments so you don't need the
if-else at all if you initialize 'combined' to NULL. 

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Rui Barradas
> Sent: Tuesday, June 18, 2013 7:57 AM
> To: Davis, Brian
> Cc: r-help at r-project.org
> Subject: Re: [R] Help understanding environments
> 
> Hello,
> 
> The first argument to exists() must be the name of an object given as a
> character string, as stated in the help page. See ?exists. You have also
> forgot to initialize combined to NULL, this time.
> Your function revised would then become
> 
> 
> c_objects <- function(FILES) {
>    combined <- NULL
>    for (FILE in FILES) {
>      load(FILE)
>      if (exists("combined")) {
>        combined <- c(combined, res)
>      } else {
>        combined <- res
>      }
>    }
>    return(combined)
> }
> 
> 
> And all works as expected.
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> Em 18-06-2013 14:57, Davis, Brian escreveu:
> > In my haste to make a smaller example than my actual code I used 'is.null' instead of
> 'exists' as is in my code.  Here's a small reproducible example
> >
> >
> > res <- list(abc=letters, ABC=LETTERS)
> > save(res, file="results.RData")
> > res <- list(zyx=rev(letters), ZYX=rev(LETTERS))
> > save(res, file="results2.RData")
> >
> > rm(res)
> > FILES <- c("results.RData", "results2.RData")
> >
> >
> > c_objects <- function(FILES) {
> >    for (FILE in FILES) {
> >      load(FILE)
> >      if (exists(combined)) {
> >        combined <- c(combined, res)
> >      } else {
> >        combined <- res
> >      }
> >    }
> >    return(combined)
> > }
> >
> > combined_results <- c_objects(FILES)
> >
> >
> > -----Original Message-----
> > From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> > Sent: Monday, June 17, 2013 5:40 PM
> > To: Davis, Brian
> > Cc: r-help at r-project.org
> > Subject: Re: [R] Help understanding environments
> >
> > On 13-06-17 5:02 PM, Davis, Brian wrote:
> >> I have a collection of .RData files that have result objects that I would like to combine.
> Specifically, skatCohort objects from the skatMeta package, but I've run into a similar
> issue with simple data.frames also.
> >>
> >> If I run something like
> >>
> >> FILES <- list.files(path="/path/to/my/results", pattern=".RData$",
> >> full.names=TRUE) combined <- NULL
> >>     for (FILE in FILES) {
> >>       load(FILE)
> >>       if (!is.null(combined)) {
> >>         combined <- c(combined, res)
> >>       } else {
> >>         combined <- res
> >>       }
> >>     }
> >>
> >> I get all my objects combined.  However, if I wrap this into a
> >> function I get the following error
> >>
> >> c_objects <- function(FILES) {
> >>     combined <- NULL
> >>     for (FILE in FILES) {
> >>       load(FILE)
> >>       if (!is.null(combined)) {
> >>         combined <- c(combined, res)
> >>       } else {
> >>         combined <- res
> >>       }
> >>     }
> >>     return(combined)
> >> }
> >>
> >> combined_results <- c_objects(FILES)
> >> Error in eval(expr, envir, enclos) : object 'combined' not found
> >>
> >> How should I write this function such that it can find "combined".   I've tried reading
> the help on envirnaments, and the exisits function but I haven't been able to figure this
> out.  Are there any other resources to read up on this?
> >
> > You are doing something that you aren't showing us:  I don't see any calls to eval(), but
> it's eval() that generated the error.
> >
> > Calling traceback() after the error might be informative.
> >
> > Duncan Murdoch
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Tue Jun 18 18:08:09 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 18 Jun 2013 09:08:09 -0700 (PDT)
Subject: [R] Problem with the mod function %%
In-Reply-To: <CAKdEGU8+_G8TjKFDgXQZtvTw03PYpZV_PFH1ceOd+i8Ugy50NQ@mail.gmail.com>
References: <1371565428.84215.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CAKdEGU8+_G8TjKFDgXQZtvTw03PYpZV_PFH1ceOd+i8Ugy50NQ@mail.gmail.com>
Message-ID: <1371571689.12016.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi Benjamin,
Thanks for pointing that out.
Sorry, didn't read the question carefully.
(0.1%%1)-0.1
#[1] 0
?(1.1%%1)-0.1
#[1] 8.326673e-17

(1%%1.1)
#[1] 1


A.K.






________________________________
From: Benjamin <hess.bn at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Tuesday, June 18, 2013 11:33 AM
Subject: Re: [R] Problem with the mod function %%



Hi, Arun.

I think you have an order of operations problem. ?Try parentheses around 1.1%%1.

Best,
Benjamin



On Tue, Jun 18, 2013 at 10:23 AM, arun <smartpink111 at yahoo.com> wrote:

Hi,
>Possibly, R FAQ: 7.31
>http://www.hep.by/gnu/r-patched/r-faq/R-FAQ_82.html
>
>(1.1%%1)-0.1
>#[1] 8.326673e-17
>
>fun1 <- function(x, y, eps = .Machine$double.eps^0.5) abs(x - y) < eps
>?fun1(1.1%%1,0.1)
>#[1] TRUE
>A.K.
>
>
>
>0.1%%1==0.1
>returns TRUE, which is right
>
>But
>1.1%%1==0.1
>returns FALSE !!
>
>Note that 1.1%%1>0.1 returns TRUE
>
>Can someone explain what is wrong?
>I'm using R version 2.15.3 on a mac.
>
>Thank you in advance
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


From d_bacha at yahoo.com  Tue Jun 18 18:25:04 2013
From: d_bacha at yahoo.com (Dereje Bacha)
Date: Tue, 18 Jun 2013 09:25:04 -0700 (PDT)
Subject: [R] FW: Dereje Bacha
Message-ID: <1371572704.45865.YahooMailNeo@web124704.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130618/c986b729/attachment.pl>

From ruipbarradas at sapo.pt  Tue Jun 18 18:57:32 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 18 Jun 2013 17:57:32 +0100
Subject: [R] hist function in a for loop
In-Reply-To: <51C07CEC.6090702@sapo.pt>
References: <1371567266710-4669797.post@n4.nabble.com>
	<51C07CEC.6090702@sapo.pt>
Message-ID: <51C0917C.70507@sapo.pt>

Hello,

Sorry, I forgot to Cc the list.

Rui Barradas
Em 18-06-2013 16:29, Rui Barradas escreveu:
> Hello,
>
> Inline.
>
> Em 18-06-2013 15:54, Dzu escreveu:
>> Dear all,
>>
>> I need to create a for-loop in which I can compute multiple histograms
>> My code is the following :
>> #singlefile includes huge csv file
>> #I want to specify the binsize
>> #I would like to compute in the for -loop the histograms
>>
>>
>>      numfiles <- length(singlefile)
>>      for (i in 1 :51)
>>      {
>>      binsize <- -20 :20/2
>>      hist(singlefile(singlefile$GVC[singlefile$new_id==i]],
>> break=seq(), by =
>> binsize)))
>
> hist() does not have a 'by' argument.
> Maybe what you want is something like the following.
>
> binsize <- -20:20/2
> h <- vector("list", 51)
> for (i in 1:51)
>      h[[i]] <- hist(singlefile$GVC[singlefile$new_id==i, ],
> break=binsize, plot = FALSE)
>
>
> This computes the histograms. Now to plot the histograms you use the
> plot() function:
>
> plot(h[[1]])  # plots the first
>
>
>>
>> What do I have to do ?
>> How can I specify the range for i  ?
>
> I don't understand. You want to match several values for i at once?
>
> singlefile$GVC[singlefile$new_id %in% irange, ]
>
>
> Hope this helps,
>
> Rui Barradas
>>
>> I am totally lost
>> Thanks for support
>> D.U
>>
>>
>>
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/hist-function-in-a-for-loop-tp4669797.html
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From michel.arnaud at cirad.fr  Tue Jun 18 18:57:56 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Tue, 18 Jun 2013 18:57:56 +0200
Subject: [R] transform 3 numeric vectors empty of 0/1
Message-ID: <51C09194.2080505@cirad.fr>

Dear all,
Without a loop, I would like transform 3 numeric vectors empty of 0/1 of 
same length
Vec1 : transform 1 to A and 0 to ""
Vec2 : transform 1 to B and 0 to ""
Vec3 : transform 1 to C and 0 to ""
to obtain only 1 vector Vec who is the paste of the 3 vectors (Ex : ABC, 
BC, AC, AB,...)
Any idea ?
Thank you for your help

-- 
Michel ARNAUD


From dcarlson at tamu.edu  Tue Jun 18 19:08:16 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Tue, 18 Jun 2013 12:08:16 -0500
Subject: [R] transform 3 numeric vectors empty of 0/1
In-Reply-To: <51C09194.2080505@cirad.fr>
References: <51C09194.2080505@cirad.fr>
Message-ID: <03b501ce6c46$6c7bb440$45731cc0$@tamu.edu>

Try this

> set.seed(42)
> Vec1 <- sample(0:1, 15, replace=TRUE)
> Vec2 <- sample(0:1, 15, replace=TRUE)
> Vec3 <- sample(0:1, 15, replace=TRUE)
> paste0(ifelse(Vec1,"A",""), ifelse(Vec2,"B",""),
ifelse(Vec3,"C",""))
 [1] "ABC" "ABC" ""    "AC"  "AB"  "ABC" "A"   "B"   "ABC" "AC"  "B"
"A"  
[13] "AB"  "C"   "B"  

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Arnaud Michel
Sent: Tuesday, June 18, 2013 11:58 AM
To: r-help at r-project.org
Subject: [R] transform 3 numeric vectors empty of 0/1

Dear all,
Without a loop, I would like transform 3 numeric vectors empty of
0/1 of 
same length
Vec1 : transform 1 to A and 0 to ""
Vec2 : transform 1 to B and 0 to ""
Vec3 : transform 1 to C and 0 to ""
to obtain only 1 vector Vec who is the paste of the 3 vectors (Ex :
ABC, 
BC, AC, AB,...)
Any idea ?
Thank you for your help

-- 
Michel ARNAUD

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From motyocska at yahoo.com  Tue Jun 18 19:23:32 2013
From: motyocska at yahoo.com (Andras Farkas)
Date: Tue, 18 Jun 2013 10:23:32 -0700 (PDT)
Subject: [R] find closest value in a vector based on another vector
	values
In-Reply-To: <CACk-te0_R+3DZEW37ZL7fAnvWkzQtL-q3c6VSOaYLPvmKOJ_rA@mail.gmail.com>
Message-ID: <1371576212.83423.YahooMailClassic@web140404.mail.bf1.yahoo.com>

Bert,

I guess I could have been a little more authoritative: the code 
unique(a[sapply(b,function(x) which.min(abs(x-a)))]) is exactly what I need. Thanks for the input, your comments helped us make the code better,

Andras


--- On Tue, 6/18/13, Bert Gunter <gunter.berton at gene.com> wrote:

> From: Bert Gunter <gunter.berton at gene.com>
> Subject: Re: [R] find closest value in a vector based on another vector values
> To: "Andras Farkas" <motyocska at yahoo.com>
> Cc: "Jorge I Velez" <jorgeivanvelez at gmail.com>, "R mailing list" <r-help at r-project.org>
> Date: Tuesday, June 18, 2013, 10:55 AM
> Andras:
> 
> No.
> Using the a = c(1,8,9) and b = 2:3 that ** I posted
> before**,? you get
> the single unique value of 1.
> 
> Please stop guessing, think carefully about what you want to
> do, and
> **test** your code.
> 
> -- Bert
> 
> On Tue, Jun 18, 2013 at 7:41 AM, Andras Farkas <motyocska at yahoo.com>
> wrote:
> > Bert,
> >
> > thanks... The values should not repeat themselves if
> the same a is closest to all b, so probably aruns example
> extended with a unique command works best?
> >
> > unique(a[sapply(b,function(x) which.min(abs(x-a)))])
> >
> > thanks,
> >
> > Andras
> >
> > --- On Tue, 6/18/13, Bert Gunter <gunter.berton at gene.com>
> wrote:
> >
> >> From: Bert Gunter <gunter.berton at gene.com>
> >> Subject: Re: [R] find closest value in a vector
> based on another vector values
> >> To: "Jorge I Velez" <jorgeivanvelez at gmail.com>
> >> Cc: "Andras Farkas" <motyocska at yahoo.com>,
> "R mailing list" <r-help at r-project.org>
> >> Date: Tuesday, June 18, 2013, 10:07 AM
> >> Jorge: No.
> >>
> >> > a <-c(1,5,8,15,32,33.5,69)
> >> > b <-c(8.5,33)
> >> > a[findInterval(b, a)]
> >> [1]? 8 32? ##should be
> >> 8???33.5
> >>
> >> I believe it has to be done explicitly by finding
> all the
> >> differences
> >> and choosing those n with minimum values, depending
> on what
> >> n you
> >> want.
> >>
> >> Note that the problem is incompletely specified.
> What if the
> >> same
> >> value of a is closest to several values of b? -- do
> you want
> >> all the
> >> values you choose to be different or not, in which
> case they
> >> may not
> >> be minimum?
> >>
> >> a <- c(1, 8, 9)
> >> b <- c(2,3)
> >>
> >> Then what are the 2 closest values of a to b?
> >>
> >> -- Bert
> >>
> >> On Tue, Jun 18, 2013 at 5:43 AM, Jorge I Velez
> <jorgeivanvelez at gmail.com>
> >> wrote:
> >> > Dear Andras,
> >> >
> >> > Try
> >> >
> >> >> a[findInterval(b, a)]
> >> > [1]? 8 32
> >> >
> >> > HTH,
> >> > Jorge.-
> >> >
> >> >
> >> > On Tue, Jun 18, 2013 at 10:34 PM, Andras
> Farkas <motyocska at yahoo.com>
> >> wrote:
> >> >
> >> >> Dear All,
> >> >>
> >> >> would you please provide your thoughts on
> the
> >> following:
> >> >> let us say I have:
> >> >>
> >> >> a <-c(1,5,8,15,32,69)
> >> >> b <-c(8.5,33)
> >> >>
> >> >> and I would like to extract from "a" the
> two values
> >> that are closest to
> >> >> the values in "b", where the length of
> this vectors
> >> may change but b will
> >> >> allways be shorter than "a". So at the end
> based on
> >> this example I should
> >> >> have the result "f" as
> >> >>
> >> >> f <-c(8,32)
> >> >>
> >> >> appreciate the help,
> >> >>
> >> >> Andras
> >> >>
> >> >>
> ______________________________________________
> >> >> R-help at r-project.org
> >> mailing list
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> >> >> http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal,
> self-contained,
> >> reproducible code.
> >> >>
> >> >
> >> >? ? ?
> ???[[alternative
> >> HTML version deleted]]
> >> >
> >> >
> ______________________________________________
> >> > R-help at r-project.org
> >> mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal,
> self-contained,
> >> reproducible code.
> >>
> >>
> >>
> >> --
> >>
> >> Bert Gunter
> >> Genentech Nonclinical Biostatistics
> >>
> >> Internal Contact Info:
> >> Phone: 467-7374
> >> Website:
> >> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm
> >>
> 
> 
> 
> -- 
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> 
> Internal Contact Info:
> Phone: 467-7374
> Website:
> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm
>


From smartpink111 at yahoo.com  Tue Jun 18 20:19:43 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 18 Jun 2013 11:19:43 -0700 (PDT)
Subject: [R] transform 3 numeric vectors empty of 0/1
In-Reply-To: <03b501ce6c46$6c7bb440$45731cc0$@tamu.edu>
References: <51C09194.2080505@cirad.fr>
	<03b501ce6c46$6c7bb440$45731cc0$@tamu.edu>
Message-ID: <1371579583.10450.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
You could also use:
dat1<- data.frame(Vec1,Vec2,Vec3)
Reduce(paste0,lapply(seq_len(ncol(dat1)),function(i) {x1<- as.character(factor(dat1[,i],labels=c("",LETTERS[i])))}))
# [1] "ABC" "ABC" ""??? "AC"? "AB"? "ABC" "A"?? "B"?? "ABC" "AC"? "B"?? "A"? 
#[13] "AB"? "C"?? "B"? 
#or
library(plyr)
library(car)
dat2<-colwise(recode)(dat1,recodes="1='ABC';0=''")
?Reduce(paste0,lapply(seq_len(ncol(dat2)),function(i) substr(dat2[,i],i,i)))
# [1] "ABC" "ABC" ""??? "AC"? "AB"? "ABC" "A"?? "B"?? "ABC" "AC"? "B"?? "A"? 
#[13] "AB"? "C"?? "B"? 

#or
?paste0(recode(Vec1,'1="A";0=""'),recode(Vec2,'1="B";0=""'),recode(Vec3,'1="C";0=""'))
# [1] "ABC" "ABC" ""??? "AC"? "AB"? "ABC" "A"?? "B"?? "ABC" "AC"? "B"?? "A"? 
#[13] "AB"? "C"?? "B"? 



#Speed comparisons:
set.seed(42)
?Vec1 <- sample(0:1, 1e6, replace=TRUE)
?Vec2 <- sample(0:1, 1e6, replace=TRUE)
?Vec3 <- sample(0:1, 1e6, replace=TRUE)
system.time(res<- paste0(ifelse(Vec1,"A",""), ifelse(Vec2,"B",""),ifelse(Vec3,"C","")))
# user? system elapsed 
#? 2.028?? 0.020?? 2.051 

set.seed(42)
system.time(res1<-Reduce(paste0,lapply(1:3,function(i) {x1<- as.character(factor(sample(0:1,1e6,replace=TRUE),labels=c("",LETTERS[i])))})))
?#user? system elapsed 
?# 1.216?? 0.000?? 1.219 


dat1<- data.frame(Vec1,Vec2,Vec3)
system.time(res2<-Reduce(paste0,lapply(seq_len(ncol(dat1)),function(i) {x1<- as.character(factor(dat1[,i],labels=c("",LETTERS[i])))})))
?#? user? system elapsed 
?# 1.256?? 0.000?? 1.257 

system.time({
dat2<-colwise(recode)(dat1,recodes="1='ABC';0=''")
?res3<-Reduce(paste0,lapply(seq_len(ncol(dat2)),function(i) substr(dat2[,i],i,i)))
})
# user? system elapsed 
#? 2.232?? 0.008?? 2.249 
?system.time(res4<-paste0(recode(Vec1,'1="A";0=""'),recode(Vec2,'1="B";0=""'),recode(Vec3,'1="C";0=""')))
?#? user? system elapsed 
?# 1.716?? 0.012?? 1.728 


identical(res1,res)
#[1] TRUE
identical(res,res2)
#[1] TRUE
?identical(res,res3)
#[1] TRUE
identical(res,res4)
#[1] TRUE

A.K.


----- Original Message -----
From: David Carlson <dcarlson at tamu.edu>
To: 'Arnaud Michel' <michel.arnaud at cirad.fr>; r-help at r-project.org
Cc: 
Sent: Tuesday, June 18, 2013 1:08 PM
Subject: Re: [R] transform 3 numeric vectors empty of 0/1

Try this

> set.seed(42)
> Vec1 <- sample(0:1, 15, replace=TRUE)
> Vec2 <- sample(0:1, 15, replace=TRUE)
> Vec3 <- sample(0:1, 15, replace=TRUE)
> paste0(ifelse(Vec1,"A",""), ifelse(Vec2,"B",""),
ifelse(Vec3,"C",""))
[1] "ABC" "ABC" ""? ? "AC"? "AB"? "ABC" "A"?  "B"?  "ABC" "AC"? "B"
"A"? 
[13] "AB"? "C"?  "B"? 

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Arnaud Michel
Sent: Tuesday, June 18, 2013 11:58 AM
To: r-help at r-project.org
Subject: [R] transform 3 numeric vectors empty of 0/1

Dear all,
Without a loop, I would like transform 3 numeric vectors empty of
0/1 of 
same length
Vec1 : transform 1 to A and 0 to ""
Vec2 : transform 1 to B and 0 to ""
Vec3 : transform 1 to C and 0 to ""
to obtain only 1 vector Vec who is the paste of the 3 vectors (Ex :
ABC, 
BC, AC, AB,...)
Any idea ?
Thank you for your help

-- 
Michel ARNAUD

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ruipbarradas at sapo.pt  Tue Jun 18 22:47:41 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 18 Jun 2013 21:47:41 +0100
Subject: [R] hist in a for loop
In-Reply-To: <fb9bc05a195b3e.51c0d977@alumni.fh-aachen.de>
References: <fb9bc05a195b3e.51c0d977@alumni.fh-aachen.de>
Message-ID: <51C0C76D.2010106@sapo.pt>

Hello,

Please post to the list, like this the odds for more and better answers 
are greater.

I don't understand what you want with

singlefile$GVC(singlefile$new_id[,i]

singlefile$GVC is a function?

How do you plot one single histogram? Post the code and maybe it will 
become more clear.

Rui Barradas

Em 18-06-2013 21:04, Dizem Uerek escreveu:
> Hello
> Thanks for reply
>
> I want to compute several histograms in a for loop.I am trying to set the binsize constant in the beginning.
>
> #compute the histograms
>   for (i in 1:12)
>      {
>      binsize <- -20 :20/2
>
>      hist(singlefile$GVC(singlefile$new_id[,i], freq = FALSE,xlab ="Graph i", col = "pink",main ="Example Histogram", ylim = c(-3.0,3.0)))
>      singlefile$GVCmin <- min(singlefile$GVC[1])
>      singlefile$GVCmin <- min(singlefile$GVC[1])
>      x1 <- seq(-3.0,3.0,by=.01)
>      lines(x1,dnorm(x1),col ="black")
>      }
>
> I tried also this but it does not do anything. I also tried your proposal , but it says that : breaks = binsize  is not allowed.
>
> I think I am totaly far away from that what I want to do with my code .
>
> One single histogram plotting and computing is easy , but if it is in the loop , by the syntax to feed the function with counter i is not working
>
> Thanks
> Dizem
> Mit freundlichen Gruessen
> Best Regards
> Dizem Uerek
>


From wdunlap at tibco.com  Tue Jun 18 23:33:39 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 18 Jun 2013 21:33:39 +0000
Subject: [R] find closest value in a vector based on another
	vector	values
In-Reply-To: <1371576212.83423.YahooMailClassic@web140404.mail.bf1.yahoo.com>
References: <CACk-te0_R+3DZEW37ZL7fAnvWkzQtL-q3c6VSOaYLPvmKOJ_rA@mail.gmail.com>
	<1371576212.83423.YahooMailClassic@web140404.mail.bf1.yahoo.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C303F08@PA-MBX01.na.tibco.com>

> I guess I could have been a little more authoritative: the code
> unique(a[sapply(b,function(x) which.min(abs(x-a)))]) is exactly what I need. 

That method could be written as the following function
f0 <- function (a, b, unique = TRUE) 
{
    ret <- a[sapply(b, function(x) which.min(abs(x - a)))]
    if (unique) { 
        ret <- unique(ret)
    }
    ret
}

If 'a' is in sorted order then I think the following, based on findInterval,
does the same thing in less time, especially when 'b' is longish.
If 'a' may not be sorted then add

f1 <- function (a, b, unique = TRUE) 
{
    leftI <- findInterval(b, a)
    rightI <- leftI + 1
    leftI[leftI == 0] <- 1
    rightI[rightI > length(a)] <- length(a)
    ret <- ifelse(abs(b - a[leftI]) < abs(b - a[rightI]), a[leftI],  a[rightI])
    if (unique) { 
        ret <- unique(ret)
    }
    ret
}

E.g.,

R> a <- sort(rnorm(1e6))
R> b <- sort(rnorm(1000))
R> system.time(r0 <- f0(a, b))
   user  system elapsed 
   4.88    3.48    8.36 
R> system.time(r1 <- f1(a, b))
   user  system elapsed 
      0       0       0 
R> identical(r0, r1)
[1] TRUE

If 'a' might be unsorted then add
    if (is.unsorted(a))  a <- sort(a)
at the beginning.  If the output must be in the same order as the original
'a' then use order(a) and subscript 'a' and 'ret' with its output.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Andras Farkas
> Sent: Tuesday, June 18, 2013 10:24 AM
> To: Bert Gunter
> Cc: R mailing list
> Subject: Re: [R] find closest value in a vector based on another vector values
> 
> Bert,
> 
> I guess I could have been a little more authoritative: the code
> unique(a[sapply(b,function(x) which.min(abs(x-a)))]) is exactly what I need. Thanks for the
> input, your comments helped us make the code better,
> 
> Andras
> 
> 
> --- On Tue, 6/18/13, Bert Gunter <gunter.berton at gene.com> wrote:
> 
> > From: Bert Gunter <gunter.berton at gene.com>
> > Subject: Re: [R] find closest value in a vector based on another vector values
> > To: "Andras Farkas" <motyocska at yahoo.com>
> > Cc: "Jorge I Velez" <jorgeivanvelez at gmail.com>, "R mailing list" <r-help at r-
> project.org>
> > Date: Tuesday, June 18, 2013, 10:55 AM
> > Andras:
> >
> > No.
> > Using the a = c(1,8,9) and b = 2:3 that ** I posted
> > before**,? you get
> > the single unique value of 1.
> >
> > Please stop guessing, think carefully about what you want to
> > do, and
> > **test** your code.
> >
> > -- Bert
> >
> > On Tue, Jun 18, 2013 at 7:41 AM, Andras Farkas <motyocska at yahoo.com>
> > wrote:
> > > Bert,
> > >
> > > thanks... The values should not repeat themselves if
> > the same a is closest to all b, so probably aruns example
> > extended with a unique command works best?
> > >
> > > unique(a[sapply(b,function(x) which.min(abs(x-a)))])
> > >
> > > thanks,
> > >
> > > Andras
> > >
> > > --- On Tue, 6/18/13, Bert Gunter <gunter.berton at gene.com>
> > wrote:
> > >
> > >> From: Bert Gunter <gunter.berton at gene.com>
> > >> Subject: Re: [R] find closest value in a vector
> > based on another vector values
> > >> To: "Jorge I Velez" <jorgeivanvelez at gmail.com>
> > >> Cc: "Andras Farkas" <motyocska at yahoo.com>,
> > "R mailing list" <r-help at r-project.org>
> > >> Date: Tuesday, June 18, 2013, 10:07 AM
> > >> Jorge: No.
> > >>
> > >> > a <-c(1,5,8,15,32,33.5,69)
> > >> > b <-c(8.5,33)
> > >> > a[findInterval(b, a)]
> > >> [1]? 8 32? ##should be
> > >> 8???33.5
> > >>
> > >> I believe it has to be done explicitly by finding
> > all the
> > >> differences
> > >> and choosing those n with minimum values, depending
> > on what
> > >> n you
> > >> want.
> > >>
> > >> Note that the problem is incompletely specified.
> > What if the
> > >> same
> > >> value of a is closest to several values of b? -- do
> > you want
> > >> all the
> > >> values you choose to be different or not, in which
> > case they
> > >> may not
> > >> be minimum?
> > >>
> > >> a <- c(1, 8, 9)
> > >> b <- c(2,3)
> > >>
> > >> Then what are the 2 closest values of a to b?
> > >>
> > >> -- Bert
> > >>
> > >> On Tue, Jun 18, 2013 at 5:43 AM, Jorge I Velez
> > <jorgeivanvelez at gmail.com>
> > >> wrote:
> > >> > Dear Andras,
> > >> >
> > >> > Try
> > >> >
> > >> >> a[findInterval(b, a)]
> > >> > [1]? 8 32
> > >> >
> > >> > HTH,
> > >> > Jorge.-
> > >> >
> > >> >
> > >> > On Tue, Jun 18, 2013 at 10:34 PM, Andras
> > Farkas <motyocska at yahoo.com>
> > >> wrote:
> > >> >
> > >> >> Dear All,
> > >> >>
> > >> >> would you please provide your thoughts on
> > the
> > >> following:
> > >> >> let us say I have:
> > >> >>
> > >> >> a <-c(1,5,8,15,32,69)
> > >> >> b <-c(8.5,33)
> > >> >>
> > >> >> and I would like to extract from "a" the
> > two values
> > >> that are closest to
> > >> >> the values in "b", where the length of
> > this vectors
> > >> may change but b will
> > >> >> allways be shorter than "a". So at the end
> > based on
> > >> this example I should
> > >> >> have the result "f" as
> > >> >>
> > >> >> f <-c(8,32)
> > >> >>
> > >> >> appreciate the help,
> > >> >>
> > >> >> Andras
> > >> >>
> > >> >>
> > ______________________________________________
> > >> >> R-help at r-project.org
> > >> mailing list
> > >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> >> PLEASE do read the posting guide
> > >> >> http://www.R-project.org/posting-guide.html
> > >> >> and provide commented, minimal,
> > self-contained,
> > >> reproducible code.
> > >> >>
> > >> >
> > >> >
> > ???[[alternative
> > >> HTML version deleted]]
> > >> >
> > >> >
> > ______________________________________________
> > >> > R-help at r-project.org
> > >> mailing list
> > >> > https://stat.ethz.ch/mailman/listinfo/r-help
> > >> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > >> > and provide commented, minimal,
> > self-contained,
> > >> reproducible code.
> > >>
> > >>
> > >>
> > >> --
> > >>
> > >> Bert Gunter
> > >> Genentech Nonclinical Biostatistics
> > >>
> > >> Internal Contact Info:
> > >> Phone: 467-7374
> > >> Website:
> > >> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-
> biostatistics/pdb-ncb-home.htm
> > >>
> >
> >
> >
> > --
> >
> > Bert Gunter
> > Genentech Nonclinical Biostatistics
> >
> > Internal Contact Info:
> > Phone: 467-7374
> > Website:
> > http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-
> biostatistics/pdb-ncb-home.htm
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gleynes+r at gmail.com  Wed Jun 19 00:06:39 2013
From: gleynes+r at gmail.com (Gene Leynes)
Date: Tue, 18 Jun 2013 17:06:39 -0500
Subject: [R] Failure to install RSer
In-Reply-To: <CA+vqiLFRXhOw6cPtNwwJzVmpozfryHwsAqkAm=T0ymvKFBmhUw@mail.gmail.com>
References: <CAOBARVi6mxSw8T=HHsioUVsJFq05t3p4xukQaw-nLVR2k-Sd8A@mail.gmail.com>
	<CAOBARVjZUgpxMcQN+=6U1uJjHdo5kc5st382eSA=YeHjE5DmAA@mail.gmail.com>
	<CA+vqiLFRXhOw6cPtNwwJzVmpozfryHwsAqkAm=T0ymvKFBmhUw@mail.gmail.com>
Message-ID: <CAOBARVjN8aNV2J-yDUp_MA8kkNA5WLFSEdUfhwOy18YeJbb71Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130618/56494c64/attachment.pl>

From lcmail4lists at gmail.com  Tue Jun 18 21:16:51 2013
From: lcmail4lists at gmail.com (=?ISO-8859-1?Q?L=EDvio?= Cipriano)
Date: Tue, 18 Jun 2013 20:16:51 +0100
Subject: [R] Retrieving Labels from vars/cols
Message-ID: <9160533.jDkeJi3ZQS@venus.lcipriano.pt>

Hi,

How can I read/retrieve the Labels strings of the $variables.label proprety of 
a data Frame?

Regards

L?vio Cipriano


From dizem.uerek at alumni.fh-aachen.de  Tue Jun 18 20:53:53 2013
From: dizem.uerek at alumni.fh-aachen.de (Dzu)
Date: Tue, 18 Jun 2013 11:53:53 -0700 (PDT)
Subject: [R] hist function in a for loop
In-Reply-To: <51C0917C.70507@sapo.pt>
References: <1371567266710-4669797.post@n4.nabble.com> <51C0917C.70507@sapo.pt>
Message-ID: <1371581633265-4669816.post@n4.nabble.com>

Hello 
Thanks for reply

I want to compute several histograms in a for loop.I am trying to set the
binsize constant in the beginning.

#compute the histograms
 for (i in 1:12)
    { 
    binsize <- -20 :20/2

    hist(singlefile$GVC(singlefile$new_id[,i], freq = FALSE,xlab ="Graph i",
col = "pink",main ="Example Histogram", ylim = c(-3.0,3.0)))
    singlefile$GVCmin <- min(singlefile$GVC[1])
    singlefile$GVCmin <- min(singlefile$GVC[1])
    x1 <- seq(-3.0,3.0,by=.01)
    lines(x1,dnorm(x1),col ="black")
    }

I tried also this but it does not do anything. I also tried your proposal ,
but it says that : breaks = binsize  is not allowed.

I think I am totaly far away from that what I want to do with my code .

One single histogram plotting and computing is easy , but if it is in the
loop , by the syntax to feed the function with counter i is not working

Thanks
Dizem




--
View this message in context: http://r.789695.n4.nabble.com/hist-function-in-a-for-loop-tp4669797p4669816.html
Sent from the R help mailing list archive at Nabble.com.


From lcipriano at iol.pt  Tue Jun 18 22:09:45 2013
From: lcipriano at iol.pt (=?ISO-8859-1?Q?L=EDvio?= Cipriano)
Date: Tue, 18 Jun 2013 21:09:45 +0100
Subject: [R] Retrieving Labels from vars/cols
Message-ID: <274334492.JYGpA32tsu@venus.lcipriano.pt>

Hi,

How can I read/retrieve the Labels strings of the $variables.label proprety of 
a data Frame?

Regards

L?vio Cipriano


From dizem.uerek at alumni.fh-aachen.de  Wed Jun 19 00:00:26 2013
From: dizem.uerek at alumni.fh-aachen.de (Dzu)
Date: Tue, 18 Jun 2013 15:00:26 -0700 (PDT)
Subject: [R] hist function in a for loop
In-Reply-To: <1371581633265-4669816.post@n4.nabble.com>
References: <1371567266710-4669797.post@n4.nabble.com> <51C0917C.70507@sapo.pt>
	<1371581633265-4669816.post@n4.nabble.com>
Message-ID: <1371592826743-4669823.post@n4.nabble.com>

Dear,

I want to do the following :

#I have created a huge csv.files with 44 colums
#I want to select the specific colums from these files
#CL1 consist data from which I want to compute the histogramms, CL2 is the
cloumn which has numbers that identifies  know from which line my second
histogram data should start.
THE CSV FILE  loos like this:

CL1   CL2  CL3   CL4     ..........    CLn
0.3    1        6.7      4.3          ...        ....
...       ..       ...           ....          ....        ....  
0.8    2      ..         .....

My target is to select only CL1 and CL2 compute histogram using CL1 data for
each CL2-block as an example [1:2] until CL2 [1:60]

I could print the histogramms but I can do only one by one. I want to
compute all of them with the same binsize!!

Therefore I wrote this code:

#combine diffrent csv files into one

files <- list.files (path = "./Inputfiles",".csv")
numfiles <- length(files)
print(files)
singlefile <- list()

#for loop
        offset <- 1
        mytotaldata <- list()   #mytotaldata includes merged csv.file
        for (i in 1:numfiles)
{
	mytotaldata[[files[i]]] <- read.csv(files[i], header = TRUE, sep = ","
,quote = "\"")

#CL5 adding and giving an identification
        mytotaldata[[files[i]]]["CL5"] <-  i

#CL2 adding and create identification for the number of lines 

	mytotaldata[[files[i]]]["CL2"] <-
as.character(floor(as.numeric(rownames(mytotaldata[[files[i]]]))/1000)+offset)
	offset <- as.numeric(tail(mytotaldata[[files[i]]],1)["CL2"]) + 1

#Create a singlefile for the whole data
      	singlefile <- rbind(singlefile,mytotaldata[[files[i]]])
}

#Now I have combined csv file added 2 columns CL2, CL5
# Compute the histograms
    #library (lattice)
    numfiles <- length(singlefile)  ###Is this necessary???????
    for (i in 1:i)
    { 
    #all the histograms with the same csv file
    binsize <- -20 :20/2
    hist(singlefile$CL1(singlefile$CL2[,1], freq = FALSE,xlab ="Graph i",
col = "pink",main ="Example Histogram", ylim = c(-3.0,3.0)))
    singlefile$GVCmin <- min(singlefile$CL1[1])
    singlefile$GVCmin <- min(singlefile$CL1[1])
    x1 <- seq(-3.0,3.0,by=.01)
    lines(x1,dnorm(x1),col ="black")
    }

My struggle point is the for-loop with the histograms computation in the
loop and using the binsize I have specified.

Maybe now the question is clear!
In case somebody has faced a similar problem ,please let me know about
tircks, ideas !!
I am trying many diffrent thing to let this for loop work but I did not find
a solution, therefore I decided to ask in the forum

Thanks in advance
DZU















--
View this message in context: http://r.789695.n4.nabble.com/hist-function-in-a-for-loop-tp4669797p4669823.html
Sent from the R help mailing list archive at Nabble.com.


From canamika at gmail.com  Wed Jun 19 00:08:27 2013
From: canamika at gmail.com (Anamika Chaudhuri)
Date: Tue, 18 Jun 2013 18:08:27 -0400
Subject: [R] Automation using R2WinBUGS
Message-ID: <CALv--daP-yEhp31qfKfrahdefoBTPHS3NNbU9D4rs65H0b1p7Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130618/16a7f8a6/attachment.pl>

From motyocska at yahoo.com  Wed Jun 19 01:46:25 2013
From: motyocska at yahoo.com (Andras Farkas)
Date: Tue, 18 Jun 2013 16:46:25 -0700 (PDT)
Subject: [R] deSolve question
Message-ID: <1371599185.84369.YahooMailClassic@web140401.mail.bf1.yahoo.com>



Dear All

wonder if you could provide some insights on the following: currently I have this code which produces the expected results:

require(deSolve)
pars <- list(k = 0.08,v=15)
intimes <- c(0,0.5,12)
input   <- c(800,0,0)
forc <- approxfun(intimes, input, method="constant", rule=2)

derivs <- function(t, state, pars) {
  inp <- forc(t)
  dy1 <- - pars$k * state[1] + inp/pars$v
  return(list(c(dy1)))
}

model <- function(pars, times=seq(0, 13, by = 0.01)) {
  state <- c(y = 0)
  return(ode(y = state, times = times, func = derivs, parms = pars,
             method="lsoda"))
}

plot(model(pars))

intuitively it would make sense to me that if I change the derivs as:

derivs <- function(t, state, pars) {
  inp <- forc(t)
  #note the added ()
  dy1 <- (- pars$k * state[1] + inp)/pars$v
  return(list(c(dy1)))
}

than I would get the same results, but that is not the case. I need to "relocate" pars$v to another position within derivs so that I could implement it in a forcing function to be able to change its value during derivation. Appreciate your help,

Andras


From robert.b.lynch at gmail.com  Wed Jun 19 02:16:00 2013
From: robert.b.lynch at gmail.com (Robert Lynch)
Date: Tue, 18 Jun 2013 17:16:00 -0700
Subject: [R] data selection
Message-ID: <CACYeG1gCfyTNEmuO7TYDT-ppRgJg7UYWhcm-=NNSqDbJiwdv7g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130618/7b4132f1/attachment.pl>

From franklin.johnson at email.wsu.edu  Wed Jun 19 01:06:43 2013
From: franklin.johnson at email.wsu.edu (Johnson, Franklin Theodore)
Date: Tue, 18 Jun 2013 23:06:43 +0000
Subject: [R] install a package made using bioconductor package pdInfoBuilder
Message-ID: <FC1FDE065EE18243A56F1F09940B37671BAC31D1@CH1PRD0102MB136.prod.exchangelabs.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130618/f3cd9acf/attachment.pl>

From jinskip at sfu.ca  Wed Jun 19 01:08:01 2013
From: jinskip at sfu.ca (Jessica Inskip)
Date: Tue, 18 Jun 2013 16:08:01 -0700
Subject: [R] Spectrum decomposition
Message-ID: <CDE63661.3D3F9%jinskip@sfu.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130618/1ca17815/attachment.pl>

From smartpink111 at yahoo.com  Wed Jun 19 04:24:36 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 18 Jun 2013 19:24:36 -0700 (PDT)
Subject: [R] data selection
In-Reply-To: <CACYeG1gCfyTNEmuO7TYDT-ppRgJg7UYWhcm-=NNSqDbJiwdv7g@mail.gmail.com>
References: <CACYeG1gCfyTNEmuO7TYDT-ppRgJg7UYWhcm-=NNSqDbJiwdv7g@mail.gmail.com>
Message-ID: <1371608676.13577.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
May be this helps:
set.seed(24)
B101<- data.frame(SID=sample(400:450,20,replace=FALSE),zGRADE=sample(0:10,20,replace=TRUE),col3=rnorm(20))
set.seed(28)
B2A<- data.frame(SID=sample(400:600,50,replace=FALSE),zGRADE=sample(0:10,50,replace=TRUE),col3=rnorm(50))
set.seed(35)
B2B<- data.frame(SID=sample(400:600,50,replace=FALSE),zGRADE=sample(0:10,50,replace=TRUE),col3=rnorm(50))
set.seed(45)
B2C<- data.frame(SID=sample(400:600,120,replace=FALSE),zGRADE=sample(0:10,120,replace=TRUE),col3=rnorm(120))
Master<- data.frame(SID=400:600)
library(plyr)
Master1<-join_all(list(Master,B101[,1:2],B2A[,1:2],B2B[,1:2],B2C[,1:2]),by="SID")
colnames(Master1)[-1]<- c("B101","B2A","B2B","B2C")

? head(Master1,3)
#? SID B101 B2A B2B B2C
#1 400?? NA?? 8? NA?? 3
#2 401??? 6? NA? NA?? 9
#3 402?? NA? NA?? 5? NA
?tail(Master1,3)
#??? SID B101 B2A B2B B2C
#199 598?? NA? NA? NA? NA
#200 599?? NA? NA? NA?? 8
#201 600?? NA?? 2? NA?? 4

A.K.




----- Original Message -----
From: Robert Lynch <robert.b.lynch at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Tuesday, June 18, 2013 8:16 PM
Subject: [R] data selection

I have two different data frames ( actually a set of data frames for each
class and one master one into which i want pull some data from each of the
frame in the set)
one? is all students that have taken a course

so the set of data frames is
B101
B2A
B2B
B2C
etc. . .


and each one has lots of data e.g.
B101
SID? ?  zGRADE
444? ?  -.2
458? ? ? 0
587? ? ? .2
etc

and
Master
SID
587
etc

and I would like? to make a field in master for each data frame
e.g. Master$B101, Master$B2A
and populate it with the zGrades from each of the data frames

the SID in Master are a? wholely containted sub set of the ones in each of
the other data frames

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From mtmorgan at fhcrc.org  Wed Jun 19 04:27:12 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 18 Jun 2013 19:27:12 -0700
Subject: [R] install a package made using bioconductor package
	pdInfoBuilder
In-Reply-To: <FC1FDE065EE18243A56F1F09940B37671BAC31D1@CH1PRD0102MB136.prod.exchangelabs.com>
References: <FC1FDE065EE18243A56F1F09940B37671BAC31D1@CH1PRD0102MB136.prod.exchangelabs.com>
Message-ID: <51C11700.9060906@fhcrc.org>

On 06/18/2013 04:06 PM, Johnson, Franklin Theodore wrote:
> Dear maintainer,
>
>
>
> I used bioconductor package, pdInfoBuilder, to make a microarray platform
> annotation package.
>
> I named this package, pd.pdinfo.gpl11164.ndf.txt. This "self-made package" is
> to be used with oligo package.
>

Please ask questions about Bioconductor packages on the Bioconductor mailing list.

   http://bioconductor.org/help/mailing-list/mailform/

Please indicate how you built your pdInfo package, e.g., following the 
instructions on the vignettes at

   http://bioconductor.org/packages/release/bioc/html/pdInfoBuilder.html


Martin

>
>
> Prior to using oligo package, I need to install the annotation package,
> pd.pdinfo.gpl11164.ndf.txt, and cannot just copy it to the library tree.
>
> I tried using the install.packages with various arguments, only to fail the
> installation.
>
>
>
> For example:
>
> install.packages("pd.pdinfo.gpl11164.ndf.txt", lib="C:/Program
> Files/R/R-3.0.1/library", destdir="C:/Users/ZHUGRP/Desktop/Yanmin's
> Microarray Paper/Yanmin Microarray RAW/pdInfoBuilder").
>
>
>
> I also tried to change the enviroment to .tar.gz, which also failed.
>
> install.packages("pd.pdinfo.gpl11164.ndf.txt.tar.gz", lib="C:/Program
> Files/R/R-3.0.1/library", destdir="C:/Users/ZHUGRP/Desktop/Yanmin's
> Microarray Paper/Yanmin Microarray RAW/pdInfoBuilder", repos=NULL)
>
>
>
> The pd.pdinfo.gpl11164.ndf.txt.tar.gz is located on my OS Windows 7 machine.
> I am trying to install it from my machine, using R "Good Sport."
>
>
>
> I've looked in manuals and FAQs with no success.
>
> If possible, I know this is very straight forward, however, am I missing a
> critical argument?
>
> Hope to hear from you soon.
>
>
>
> Regards,
>
> Franklin
>
>
>
>> sessionInfo()
> R version 3.0.1 (2013-05-16) Platform: i386-w64-mingw32/i386 (32-bit)
>
>
>
> locale: [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252    LC_MONETARY=English_United States.1252 [4] LC_NUMERIC=C
> LC_TIME=English_United States.1252
>
> attached base packages: [1] parallel  stats     graphics  grDevices utils
> datasets  methods   base
>
> loaded via a namespace (and not attached): [1] tools_3.0.1
>
>
>
>
>
>
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________ R-help at r-project.org mailing
> list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the posting
> guide http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From gunter.berton at gene.com  Wed Jun 19 06:06:29 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 18 Jun 2013 21:06:29 -0700
Subject: [R] Spectrum decomposition
In-Reply-To: <CDE63661.3D3F9%jinskip@sfu.ca>
References: <CDE63661.3D3F9%jinskip@sfu.ca>
Message-ID: <CACk-te3PO4-rXzggs3gCopftNnZO++TVHG5vFHtNDwxamRA0Fg@mail.gmail.com>

1. Have you googled or binged?

2. Have you tried R Task Views: http://cran.r-project.org/web/views/
(esp. the TimeSeries one) ?

No guarantees, of course.

-- Bert

On Tue, Jun 18, 2013 at 4:08 PM, Jessica Inskip <jinskip at sfu.ca> wrote:
> Hi,
>
> I am currently performing heart rate variability analyses on beat-to-beat
> heart rate data using a non-parametric approach (AR power spectral density).
> I am interested in decomposing a AR-spectrum into its components (main
> outcomes of interest are the centre frequency and the power of the
> bell-shaped spectral components) similar to this function in octave
> http://www-2.nersc.no/~even/matlab/toolbox/biosig4octmat-2/tsa/ar_spa.m
>
> I have searched R packages and forums for leads on how I might be able to do
> this in R without success.
> Any help pointing me in the right direction would be greatly appreciated.
>
> Thank you very much,
> Jessica
>
> _________________________________
> Jessica Inskip, PhD Candidate
> Cardiovascular Physiology Laboratory, K8512 | Department of Biomedical
> Physiology and Kinesiology
> Simon Fraser University, 8888 University Drive, Burnaby BC, V5A 1S6
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From erinm.hodgess at gmail.com  Wed Jun 19 06:33:45 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Tue, 18 Jun 2013 23:33:45 -0500
Subject: [R]  solving equations symbolically
Message-ID: <CACxE24=7vP3dj+Oum26C_apJoVjOFW0qCtJhL7ZZa2iDA-C74A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130618/84d5ad25/attachment.pl>

From erinm.hodgess at gmail.com  Wed Jun 19 06:39:02 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Tue, 18 Jun 2013 23:39:02 -0500
Subject: [R] solving equations symbolically
In-Reply-To: <CACxE24=7vP3dj+Oum26C_apJoVjOFW0qCtJhL7ZZa2iDA-C74A@mail.gmail.com>
References: <CACxE24=7vP3dj+Oum26C_apJoVjOFW0qCtJhL7ZZa2iDA-C74A@mail.gmail.com>
Message-ID: <CACxE24mKfqxH-rkQ2mLmMS_S-VzVM-ER4+qAa6Y4kwek+ZwtnA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130618/13a53c71/attachment.pl>

From erinm.hodgess at gmail.com  Wed Jun 19 07:03:04 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Wed, 19 Jun 2013 00:03:04 -0500
Subject: [R]  evaluation of equations from Ryacas
Message-ID: <CACxE24krkNxdRRTkakyJSr8OLK7cReQ0FLcOWx86Aprsgi5rkQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130619/d64ffb0d/attachment.pl>

From sorenh at math.aau.dk  Wed Jun 19 09:06:06 2013
From: sorenh at math.aau.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Wed, 19 Jun 2013 07:06:06 +0000
Subject: [R] evaluation of equations from Ryacas
In-Reply-To: <CACxE24krkNxdRRTkakyJSr8OLK7cReQ0FLcOWx86Aprsgi5rkQ@mail.gmail.com>
References: <CACxE24krkNxdRRTkakyJSr8OLK7cReQ0FLcOWx86Aprsgi5rkQ@mail.gmail.com>
Message-ID: <7E8037094A0C2146AA3E6F94DAE621C34454BA96@AD-EXCHMBX2-1.aau.dk>

Dear Erin,

Not exactly elegant, but

> e<-expression(list(R == 100 * (1 - 2 * y/10000)))
> ee <- e[[1]][2]
> ee
(R == 100 * (1 - 2 * y/10000))()
> eval(parse(text=(substring(paste(ee), 5))), list(y=5))
[1] 99.9

Regards
S?ren


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Erin Hodgess
Sent: 19. juni 2013 07:03
To: R help
Subject: [R] evaluation of equations from Ryacas

Hello again.

Now I have the following:
> xx
[1] "Solve(1 - R/100==(2*y)/10000,R)"
> yacas(xx)
expression(list(R == 100 * (1 - 2 * y/10000)))
>

I would like to put in a value for y and obtain R.
I've tried more stuff with eval and Eval, but no luck yet.

Any suggestions would be much appreciated.

Thanks,
Erin


--
Erin Hodgess
Associate Professor
Department of Computer and Mathematical Sciences University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From raziq_fazli at yahoo.com  Wed Jun 19 09:30:03 2013
From: raziq_fazli at yahoo.com (Fazli Raziq)
Date: Wed, 19 Jun 2013 00:30:03 -0700 (PDT)
Subject: [R] Problems in Constructing Two way Matrix
Message-ID: <1371627003.41266.YahooMailNeo@web162903.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130619/bb6b5fa5/attachment.pl>

From bhh at xs4all.nl  Wed Jun 19 09:43:06 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 19 Jun 2013 09:43:06 +0200
Subject: [R] Problems in Constructing Two way Matrix
In-Reply-To: <1371627003.41266.YahooMailNeo@web162903.mail.bf1.yahoo.com>
References: <1371627003.41266.YahooMailNeo@web162903.mail.bf1.yahoo.com>
Message-ID: <12DD713B-4808-4442-A768-B851F90AD398@xs4all.nl>


On 19-06-2013, at 09:30, Fazli Raziq <raziq_fazli at yahoo.com> wrote:

> Hello,
> 
> Where is the problem in this programming. I want two way matrix, but it gives problem.

What is the problem?
What are you expecting and what are you getting?

> The program is given below:
> 
> Thanks in advance.
> 
> Regards
> Fazli Raziq
> 
> 
> rep = 2
> genes = 5
> pred = c()
> iter   = array (dim = c(rep, pred))
> pred = array(dim = c(1, genes))
> m = c()
> l = 1
> w = 1
> for(m in 1:rep) {
> t = time
> c = cens
> tab = cbind(t, c)
> 
> # Resampling Time and Censoring
> cc = sample(c, replace = TRUE)
> tt = sample(t, replace = TRUE)
> xx = Surv(tt, cc)
> 
> P = predic[,1:5]
> n = 310
> ma = matrix(P, n)
> boot <- sample(seq(n), replace=TRUE)
> genes5 = ma[boot, ]
> 
> 
> for(p in 1: genes){
> i = c()
> 
> for(i in w:l) {
> z = genes5[,w: l]
> y = coxph(xx ~ z)
> 
> }
> Pval = summary(y) $ coeff[, 5]
> 
> if( any(Pval <= 0.01) ) sign <- 1 else sign <- 0
> pred[1, p] = sign[1]
> }
> 
> iter [m, 1:5] = pred[1: 5]
> 
> }

Running this code gives an error message:

Error: object 'cens' not found


And what is the purpose of t = time? time is a stats function.
> 	[[alternative HTML version deleted]]
> 

You are asked to NOT post in html.

Berend

> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From alexandre.piche at mail.mcgill.ca  Wed Jun 19 09:53:49 2013
From: alexandre.piche at mail.mcgill.ca (AlexPiche)
Date: Wed, 19 Jun 2013 00:53:49 -0700 (PDT)
Subject: [R] knitr without R studio
Message-ID: <1371628429300-4669841.post@n4.nabble.com>

Hello folks,

I`m using knitr on R studio, which make it easy to use, but a coworker of
mine would like to run it on "simple" R. So I was wondering if you know what
is the equivalent of  the button "knit HTML" in RStudio in R. I tried 


knit2HTML( 

<html>
<head>
  <title></title>   
</head>
<body style="background-color:white">




  <p style="font-size:16px; text-align:center">
Graph 1 <#location1>      Graph 2 <#location2>  
  </p>

```{r table1, comment=NA, results='asis'}
library(xtable)
data(iris)
print(xtable(head(iris, 10)), type = "html", include.rownames = T)
```



```{r, include=FALSE}


opts_knit$set(progress = TRUE, verbose = TRUE)
opts_chunk$set(fig.width=20, fig.height=12)
knit_hooks$set(fig.bg = function(before, options, envir) {
  if (before) par(bg = options$fig.bg)
})

```






```{r graphs,fig.keep=?last?} 
for (x in 1:10) plot(rnorm(100), col = x)
```



  
```{r graph1} 

plot(rnorm(500), type="lines", main="Graph1")
```
  Top of the Page <#top>  


 


```{r graph2} 


plot(rpois(500,3), type="lines", main="Graph2") 

```

Top of the Page <#top>  





</body>
</html>
)


But R keep sending me error message, any clue?

Regards,

Alex



--
View this message in context: http://r.789695.n4.nabble.com/knitr-without-R-studio-tp4669841.html
Sent from the R help mailing list archive at Nabble.com.


From bhh at xs4all.nl  Wed Jun 19 10:32:14 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 19 Jun 2013 10:32:14 +0200
Subject: [R] Problems in Constructing Two way Matrix
In-Reply-To: <1371630562.82406.YahooMailNeo@web162904.mail.bf1.yahoo.com>
References: <1371627003.41266.YahooMailNeo@web162903.mail.bf1.yahoo.com>
	<12DD713B-4808-4442-A768-B851F90AD398@xs4all.nl>
	<1371630562.82406.YahooMailNeo@web162904.mail.bf1.yahoo.com>
Message-ID: <F7868E2B-8B17-4BBD-9FAA-1BBF55B31B94@xs4all.nl>


I'm cc'ing this to the R-help list.

Please reply to the list and privately.
You will get more response that way.

Your reply does not address the issue I mentioned.

Berend

On 19-06-2013, at 10:29, Fazli Raziq <raziq_fazli at yahoo.com> wrote:

> Dear Mr. Berend,
> 
> I want to construct "Two way Matrix". The Algorithm is like:
> 
> 1)  Data of time with censoring or events
> 2)  Predictor variables (genes)
> 3)  Resample data in step 1 and 2 by WR
> 4)  Apply Coxph Model to resample data. Apply Surv function to each Predictor variable, individually.
> 5)  Give value 1 if it's P-value is less than 0.05, otherwise 0. Save it in the first Column (Column of 0's and 1's) of the Matrix.
> 6)  Iterate the process 1 to 5, 10 times. And make 10 Columns of 0's and 1's.
> 
> I have done the programming for it, but gives problem in Matrix.
> Thanks for replying to my mail. Hope for the best.
> 
> Best Regards
> Fazli Raziq
> 
> From: Berend Hasselman <bhh at xs4all.nl>
> To: Fazli Raziq <raziq_fazli at yahoo.com> 
> Cc: "r-help at r-project.org" <r-help at r-project.org> 
> Sent: Wednesday, 19 June 2013, 9:43
> Subject: Re: [R] Problems in Constructing Two way Matrix
> 
> 
> On 19-06-2013, at 09:30, Fazli Raziq <raziq_fazli at yahoo.com> wrote:
> 
> > Hello,
> > 
> > Where is the problem in this programming. I want two way matrix, but it gives problem.
> 
> What is the problem?
> What are you expecting and what are you getting?
> 
> > The program is given below:
> > 
> > Thanks in advance.
> > 
> > Regards
> > Fazli Raziq
> > 
> > 
> > rep = 2
> > genes = 5
> > pred = c()
> > iter  = array (dim = c(rep, pred))
> > pred = array(dim = c(1, genes))
> > m = c()
> > l = 1
> > w = 1
> > for(m in 1:rep) {
> > t = time
> > c = cens
> > tab = cbind(t, c)
> > 
> > # Resampling Time and Censoring
> > cc = sample(c, replace = TRUE)
> > tt = sample(t, replace = TRUE)
> > xx = Surv(tt, cc)
> > 
> > P = predic[,1:5]
> > n = 310
> > ma = matrix(P, n)
> > boot <- sample(seq(n), replace=TRUE)
> > genes5 = ma[boot, ]
> > 
> > 
> > for(p in 1: genes){
> > i = c()
> > 
> > for(i in w:l) {
> > z = genes5[,w: l]
> > y = coxph(xx ~ z)
> > 
> > }
> > Pval = summary(y) $ coeff[, 5]
> > 
> > if( any(Pval <= 0.01) ) sign <- 1 else sign <- 0
> > pred[1, p] = sign[1]
> > }
> > 
> > iter [m, 1:5] = pred[1: 5]
> > 
> > }
> 
> Running this code gives an error message:
> 
> Error: object 'cens' not found
> 
> 
> And what is the purpose of t = time? time is a stats function.
> >     [[alternative HTML version deleted]]
> > 
> 
> You are asked to NOT post in html.
> 
> Berend
> 
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 


From bhh at xs4all.nl  Wed Jun 19 10:44:03 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 19 Jun 2013 10:44:03 +0200
Subject: [R] Problems in Constructing Two way Matrix
In-Reply-To: <F7868E2B-8B17-4BBD-9FAA-1BBF55B31B94@xs4all.nl>
References: <1371627003.41266.YahooMailNeo@web162903.mail.bf1.yahoo.com>
	<12DD713B-4808-4442-A768-B851F90AD398@xs4all.nl>
	<1371630562.82406.YahooMailNeo@web162904.mail.bf1.yahoo.com>
	<F7868E2B-8B17-4BBD-9FAA-1BBF55B31B94@xs4all.nl>
Message-ID: <07C5C36F-80CA-49F2-8B00-D98356014675@xs4all.nl>


On 19-06-2013, at 10:32, Berend Hasselman <bhh at xs4all.nl> wrote:

> 
> I'm cc'ing this to the R-help list.
> 
> Please reply to the list and privately.

Sorry. I meant NOT privately.

Berend


From raziq_fazli at yahoo.com  Wed Jun 19 10:52:27 2013
From: raziq_fazli at yahoo.com (Fazli Raziq)
Date: Wed, 19 Jun 2013 01:52:27 -0700 (PDT)
Subject: [R] I am facing problems in Two way Matrix
Message-ID: <1371631947.36792.YahooMailNeo@web162902.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130619/ac704f46/attachment.pl>

From ludovicofrate at hotmail.it  Wed Jun 19 12:11:04 2013
From: ludovicofrate at hotmail.it (Ludovico Frate)
Date: Wed, 19 Jun 2013 10:11:04 +0000
Subject: [R] (senza oggetto)
Message-ID: <DUB404-EAS4223A3DC7E259923C658A9ED68D0@phx.gbl>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130619/5bfe158c/attachment.pl>

From ruipbarradas at sapo.pt  Wed Jun 19 13:02:54 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 19 Jun 2013 12:02:54 +0100
Subject: [R] hist function in a for loop
In-Reply-To: <1371592826743-4669823.post@n4.nabble.com>
References: <1371567266710-4669797.post@n4.nabble.com> <51C0917C.70507@sapo.pt>
	<1371581633265-4669816.post@n4.nabble.com>
	<1371592826743-4669823.post@n4.nabble.com>
Message-ID: <51C18FDE.70609@sapo.pt>

Hello,

Your code doesn't work because you are calling a non-function:

hist(singlefile$CL1( ... )) # here

singlefile$CL1 is not a function.

For us to be able to help you please do the following.

1. paste the output of the command below in a post

dput(head(singlefile, 50))

2. Post a call to hist() that does work, without a for loop.

Rui Barradas


> I want to do the following :
>
> #I have created a huge csv.files with 44 colums
> #I want to select the specific colums from these files
> #CL1 consist data from which I want to compute the histogramms, CL2 is the
> cloumn which has numbers that identifies  know from which line my second
> histogram data should start.
> THE CSV FILE  loos like this:
>
> CL1   CL2  CL3   CL4     ..........    CLn
> 0.3    1        6.7      4.3          ...        ....
> ...       ..       ...           ....          ....        ....
> 0.8    2      ..         .....
>
> My target is to select only CL1 and CL2 compute histogram using CL1 data for
> each CL2-block as an example [1:2] until CL2 [1:60]
>
> I could print the histogramms but I can do only one by one. I want to
> compute all of them with the same binsize!!
>
> Therefore I wrote this code:
>
> #combine diffrent csv files into one
>
> files <- list.files (path = "./Inputfiles",".csv")
> numfiles <- length(files)
> print(files)
> singlefile <- list()
>
> #for loop
>          offset <- 1
>          mytotaldata <- list()   #mytotaldata includes merged csv.file
>          for (i in 1:numfiles)
> {
> 	mytotaldata[[files[i]]] <- read.csv(files[i], header = TRUE, sep = ","
> ,quote = "\"")
>
> #CL5 adding and giving an identification
>          mytotaldata[[files[i]]]["CL5"] <-  i
>
> #CL2 adding and create identification for the number of lines
>
> 	mytotaldata[[files[i]]]["CL2"] <-
> as.character(floor(as.numeric(rownames(mytotaldata[[files[i]]]))/1000)+offset)
> 	offset <- as.numeric(tail(mytotaldata[[files[i]]],1)["CL2"]) + 1
>
> #Create a singlefile for the whole data
>        	singlefile <- rbind(singlefile,mytotaldata[[files[i]]])
> }
>
> #Now I have combined csv file added 2 columns CL2, CL5
> # Compute the histograms
>      #library (lattice)
>      numfiles <- length(singlefile)  ###Is this necessary???????
>      for (i in 1:i)
>      {
>      #all the histograms with the same csv file
>      binsize <- -20 :20/2
>      hist(singlefile$CL1(singlefile$CL2[,1], freq = FALSE,xlab ="Graph i",
> col = "pink",main ="Example Histogram", ylim = c(-3.0,3.0)))
>      singlefile$GVCmin <- min(singlefile$CL1[1])
>      singlefile$GVCmin <- min(singlefile$CL1[1])
>      x1 <- seq(-3.0,3.0,by=.01)
>      lines(x1,dnorm(x1),col ="black")
>      }
>
> My struggle point is the for-loop with the histograms computation in the
> loop and using the binsize I have specified.
>
> Maybe now the question is clear!
> In case somebody has faced a similar problem ,please let me know about
> tircks, ideas !!
> I am trying many diffrent thing to let this for loop work but I did not find
> a solution, therefore I decided to ask in the forum
>
> Thanks in advance
> DZU
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/hist-function-in-a-for-loop-tp4669797p4669823.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From yyz at tongji.edu.cn  Wed Jun 19 13:04:28 2013
From: yyz at tongji.edu.cn (Yanyuan Zhu)
Date: Wed, 19 Jun 2013 19:04:28 +0800
Subject: [R] how to get growth rate of a (time series) data?
Message-ID: <CAHf4n+TMEj30C9qXgYSeJePMEmJaMDmhM__PDDx9tp5NytHqzA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130619/6c635325/attachment.pl>

From michael.weylandt at gmail.com  Wed Jun 19 13:24:01 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Wed, 19 Jun 2013 12:24:01 +0100
Subject: [R] how to get growth rate of a (time series) data?
In-Reply-To: <CAHf4n+TMEj30C9qXgYSeJePMEmJaMDmhM__PDDx9tp5NytHqzA@mail.gmail.com>
References: <CAHf4n+TMEj30C9qXgYSeJePMEmJaMDmhM__PDDx9tp5NytHqzA@mail.gmail.com>
Message-ID: <CAAmySGMbo3Hp2CA6UAXFko58UKdG_2s08fgOvORGosFgiKAf5Q@mail.gmail.com>

On Wed, Jun 19, 2013 at 12:04 PM, Yanyuan Zhu <yyz at tongji.edu.cn> wrote:
> Hello all, now I'm trying to switch from Excel to R to deal with the data,
> and as a newbie i got the problem as follows.
>
> suppose I have a data named "test"
> test<- data.frame(year=c(1996:2011),
> Y=c(74163.6,81658.5,86531.6,91125.0,98749.0,109028.0,120475.6,136613.4,160956.6,187423.5,222712.5,266599.2,315974.6,348775.1,402816.5,465731.3))
> in which Y means the GDP of a country
>
> If i want to get Delta Y = Y(t)-Y(t-1) , i could use diff() in R
> diff(test$Y)
>
> but what if i want to get gY=(Y(t)-Y(t-1))/Y(t-1)?
> seems diff(test$Y)/(test$Y)[-1] doesnt work ...

Odd, I would have thought it did.

No matter anyways: if you are using time series data, I'd strongly
recommend that you place your data in an object of the "xts" class and
use all of the time series functionality available for those objects.

Notably, you'll also want to load the "TTR" package (all of these are
available through the install.packages() function off the CRAN mirror
system) and to use its ROC function.

Cheers,
MW

>
> thanks in advance
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From josh.m.ulrich at gmail.com  Wed Jun 19 13:42:37 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Wed, 19 Jun 2013 06:42:37 -0500
Subject: [R] how to get growth rate of a (time series) data?
In-Reply-To: <CAAmySGMbo3Hp2CA6UAXFko58UKdG_2s08fgOvORGosFgiKAf5Q@mail.gmail.com>
References: <CAHf4n+TMEj30C9qXgYSeJePMEmJaMDmhM__PDDx9tp5NytHqzA@mail.gmail.com>
	<CAAmySGMbo3Hp2CA6UAXFko58UKdG_2s08fgOvORGosFgiKAf5Q@mail.gmail.com>
Message-ID: <CAPPM_gQyH2+iqxFYBKdUmvi1fRFS=3EthNj8qCJB8kfwwVa8tg@mail.gmail.com>

On Wed, Jun 19, 2013 at 6:24 AM, R. Michael Weylandt
<michael.weylandt at gmail.com> wrote:
> On Wed, Jun 19, 2013 at 12:04 PM, Yanyuan Zhu <yyz at tongji.edu.cn> wrote:
>> Hello all, now I'm trying to switch from Excel to R to deal with the data,
>> and as a newbie i got the problem as follows.
>>
>> suppose I have a data named "test"
>> test<- data.frame(year=c(1996:2011),
>> Y=c(74163.6,81658.5,86531.6,91125.0,98749.0,109028.0,120475.6,136613.4,160956.6,187423.5,222712.5,266599.2,315974.6,348775.1,402816.5,465731.3))
>> in which Y means the GDP of a country
>>
>> If i want to get Delta Y = Y(t)-Y(t-1) , i could use diff() in R
>> diff(test$Y)
>>
>> but what if i want to get gY=(Y(t)-Y(t-1))/Y(t-1)?
>> seems diff(test$Y)/(test$Y)[-1] doesnt work ...
>
> Odd, I would have thought it did.
>
> No matter anyways: if you are using time series data, I'd strongly
> recommend that you place your data in an object of the "xts" class and
> use all of the time series functionality available for those objects.
>
> Notably, you'll also want to load the "TTR" package (all of these are
> available through the install.packages() function off the CRAN mirror
> system) and to use its ROC function.
>
But note that TTR::ROC uses continuous, not discrete, compounding by default.

So you need:
ROC(test$Y, n=1, type="discrete")

Best,
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From istazahn at gmail.com  Wed Jun 19 13:42:37 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 19 Jun 2013 07:42:37 -0400
Subject: [R] knitr without R studio
In-Reply-To: <1371628429300-4669841.post@n4.nabble.com>
References: <1371628429300-4669841.post@n4.nabble.com>
Message-ID: <CA+vqiLF2Wp1MSSSXKhe2aRLdoZ37UaECgNknWw7c=u84F2MQcQ@mail.gmail.com>

Hi Alex,

Have you read the ?knit or ?knit2html documentation? I don't believe
there is a kit2HTML function (notice the uppercase), and the input
should be the path to a file. Please do read the documentation.

Best,
Ista

On Wed, Jun 19, 2013 at 3:53 AM, AlexPiche
<alexandre.piche at mail.mcgill.ca> wrote:
> Hello folks,
>
> I`m using knitr on R studio, which make it easy to use, but a coworker of
> mine would like to run it on "simple" R. So I was wondering if you know what
> is the equivalent of  the button "knit HTML" in RStudio in R. I tried
>
>
> knit2HTML(
>
> <html>
> <head>
>   <title></title>
> </head>
> <body style="background-color:white">
>
>
>
>
>   <p style="font-size:16px; text-align:center">
> Graph 1 <#location1>      Graph 2 <#location2>
>   </p>
>
> ```{r table1, comment=NA, results='asis'}
> library(xtable)
> data(iris)
> print(xtable(head(iris, 10)), type = "html", include.rownames = T)
> ```
>
>
>
> ```{r, include=FALSE}
>
>
> opts_knit$set(progress = TRUE, verbose = TRUE)
> opts_chunk$set(fig.width=20, fig.height=12)
> knit_hooks$set(fig.bg = function(before, options, envir) {
>   if (before) par(bg = options$fig.bg)
> })
>
> ```
>
>
>
>
>
>
> ```{r graphs,fig.keep=?last?}
> for (x in 1:10) plot(rnorm(100), col = x)
> ```
>
>
>
>
> ```{r graph1}
>
> plot(rnorm(500), type="lines", main="Graph1")
> ```
>   Top of the Page <#top>
>
>
>
>
>
> ```{r graph2}
>
>
> plot(rpois(500,3), type="lines", main="Graph2")
>
> ```
>
> Top of the Page <#top>
>
>
>
>
>
> </body>
> </html>
> )
>
>
> But R keep sending me error message, any clue?
>
> Regards,
>
> Alex
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/knitr-without-R-studio-tp4669841.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nblaser at ispm.unibe.ch  Wed Jun 19 13:50:34 2013
From: nblaser at ispm.unibe.ch (Blaser Nello)
Date: Wed, 19 Jun 2013 13:50:34 +0200
Subject: [R] how to get growth rate of a (time series) data?
In-Reply-To: <CAHf4n+TMEj30C9qXgYSeJePMEmJaMDmhM__PDDx9tp5NytHqzA@mail.gmail.com>
References: <CAHf4n+TMEj30C9qXgYSeJePMEmJaMDmhM__PDDx9tp5NytHqzA@mail.gmail.com>
Message-ID: <17EE8C62EA18B84B94C2BA96A143064C01721A7B@mx01.ispm.unibe.ch>

diff(test$Y)/(test$Y)[-1] calculates (Y(t)-Y(t-1))/Y(t). 

To get (Y(t)-Y(t-1))/Y(t-1) instead, use 
diff(test$Y)/(test$Y)[-length(test$Y)]
or better
diff(test[,"Y"])/test[-nrow(test), "Y"]

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
On Behalf Of Yanyuan Zhu
Sent: Mittwoch, 19. Juni 2013 13:04
To: r-help at r-project.org
Subject: [R] how to get growth rate of a (time series) data?

Hello all, now I'm trying to switch from Excel to R to deal with the
data, and as a newbie i got the problem as follows.

suppose I have a data named "test"
test<- data.frame(year=c(1996:2011),
Y=c(74163.6,81658.5,86531.6,91125.0,98749.0,109028.0,120475.6,136613.4,1
60956.6,187423.5,222712.5,266599.2,315974.6,348775.1,402816.5,465731.3))
in which Y means the GDP of a country

If i want to get Delta Y = Y(t)-Y(t-1) , i could use diff() in R
diff(test$Y)

but what if i want to get gY=(Y(t)-Y(t-1))/Y(t-1)?
seems diff(test$Y)/(test$Y)[-1] doesnt work ...

thanks in advance

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From prudentxavier at gmail.com  Wed Jun 19 14:08:33 2013
From: prudentxavier at gmail.com (Xavier Prudent)
Date: Wed, 19 Jun 2013 14:08:33 +0200
Subject: [R] Simple example of variables decorrelation using the Cholesky
	decomposition
Message-ID: <CAF7OBP-oY09em-JBPQ+aWOdfGCUZo9NjyUwh6fac4XokPyT++w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130619/cbb2fad7/attachment.pl>

From ggrothendieck at gmail.com  Wed Jun 19 14:11:47 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 19 Jun 2013 08:11:47 -0400
Subject: [R] how to get growth rate of a (time series) data?
In-Reply-To: <CAHf4n+TMEj30C9qXgYSeJePMEmJaMDmhM__PDDx9tp5NytHqzA@mail.gmail.com>
References: <CAHf4n+TMEj30C9qXgYSeJePMEmJaMDmhM__PDDx9tp5NytHqzA@mail.gmail.com>
Message-ID: <CAP01uR==hvpzXOH-K414pu=nYXbptNTFqMNMbdauWUQT5SX4MQ@mail.gmail.com>

On Wed, Jun 19, 2013 at 7:04 AM, Yanyuan Zhu <yyz at tongji.edu.cn> wrote:
> Hello all, now I'm trying to switch from Excel to R to deal with the data,
> and as a newbie i got the problem as follows.
>
> suppose I have a data named "test"
> test<- data.frame(year=c(1996:2011),
> Y=c(74163.6,81658.5,86531.6,91125.0,98749.0,109028.0,120475.6,136613.4,160956.6,187423.5,222712.5,266599.2,315974.6,348775.1,402816.5,465731.3))
> in which Y means the GDP of a country
>
> If i want to get Delta Y = Y(t)-Y(t-1) , i could use diff() in R
> diff(test$Y)
>
> but what if i want to get gY=(Y(t)-Y(t-1))/Y(t-1)?
> seems diff(test$Y)/(test$Y)[-1] doesnt work ...

As already mentioned, that R expression gives (Y[t] - Y[t-1]) / Yt[t]
whereas you want

Y <- test$Y
n <- length(Y)
diff(Y) / Y[-n]

or you might want to use a time series class for simpler
manipluations:  Using ts class:

Y.ts <- ts(test[, 2], start = test[1,1])
Ydiff.ts <- diff(Y.ts) / lag(Y.ts, - 1)

or, using tis class which is frequently used for equally spaced
eoconomic series:

Y.tis <- tis(test[, 2], start = test[1,1], freq = 1)
Ydiff.tis <- diff(Y.tis) / lag(Y.tis, - 1)

or using zoo class which, in addition, supports non-equally spaced
series and also allows for two different approaches here:

library(zoo)
Y.z <- read.zoo(test, FUN = identity)
Ydiff.z <- diff(Y.z) / lag(Y.z, - 1)

This also works with zoo:

Ydiff.z <- diff(Y.z, arith = FALSE) - 1

--
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From laomeng_3 at 163.com  Wed Jun 19 11:27:35 2013
From: laomeng_3 at 163.com (meng)
Date: Wed, 19 Jun 2013 17:27:35 +0800 (CST)
Subject: [R] p values of lmer
Message-ID: <5e360438.fe90.13f5bc2ba32.Coremail.laomeng_3@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130619/96f441ba/attachment.pl>

From kicco1991 at hotmail.it  Wed Jun 19 09:44:10 2013
From: kicco1991 at hotmail.it (Francesco Miranda)
Date: Wed, 19 Jun 2013 09:44:10 +0200
Subject: [R] quantile
Message-ID: <DUB107-W32EA6614649CAB95ADB82FDE8D0@phx.gbl>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130619/e3d3d918/attachment.pl>

From fjsanala at gmail.com  Wed Jun 19 11:20:12 2013
From: fjsanala at gmail.com (Francisco Javier Santos Alamillos)
Date: Wed, 19 Jun 2013 11:20:12 +0200
Subject: [R] Linear combination of time series for approximating another one
Message-ID: <CAJZkWGt_kbeSXEAMoCh=s_kLUPu1bGGedkq891ZjeGtGUrX4Cg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130619/df6b0cfd/attachment.pl>

From pkount at bgc-jena.mpg.de  Wed Jun 19 13:28:29 2013
From: pkount at bgc-jena.mpg.de (pakoun)
Date: Wed, 19 Jun 2013 04:28:29 -0700 (PDT)
Subject: [R] nls singular gradient ..as always..
Message-ID: <1371641309773-4669859.post@n4.nabble.com>

Hi all. Sorry for posting again such a topic but I went through previous 
posts but couldn't find a solution.

I use the following code to fit an exponential model to my data. I have 4
different datasets. For 3 datasets nls seems to work fine and I have no
error messages. But for 1 dataset I am getting the "world known" singular
gradient error.
 
   xfit.dNEE <-
nls(vario.dNEE~V*(1-exp(-1*dist/L)),data=ndat,start=list(V=vstart,L=lstart),trace=T)
     
I tried also with different starting values but still the same error...
Any help would be highly welcome.

Thank you in advance.



--
View this message in context: http://r.789695.n4.nabble.com/nls-singular-gradient-as-always-tp4669859.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Wed Jun 19 14:50:21 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 19 Jun 2013 05:50:21 -0700 (PDT)
Subject: [R] write a function to do pairwise calculation
In-Reply-To: <CALwvZ4VHVx1eDsNsjAYSOppkeMmbKP5CrgAE9t3tY-EiZj0zhA@mail.gmail.com>
References: <CALwvZ4WepoyBN3SdwAqwqZOhxHO9SN6q5-XCwS939kmuwN3vJg@mail.gmail.com>
	<1371506955.87513.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CALwvZ4VHVx1eDsNsjAYSOppkeMmbKP5CrgAE9t3tY-EiZj0zhA@mail.gmail.com>
Message-ID: <1371646221.35580.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Even if you have 15 matrices, you should be able to do it in the same way.

For example in the case of 5 matrices:
set.seed(24)
A<- matrix(sample(1:50,20,replace=TRUE),ncol=4)
B<- matrix(sample(40:60,20,replace=TRUE),ncol=4)
C<- matrix(sample(1:60,20,replace=TRUE),ncol=4)
D<- matrix(sample(1:30,20,replace=TRUE),ncol=4)
E<- matrix(sample(30:50,20,replace=TRUE),ncol=4)

mat1<- combn(LETTERS[1:5],2) 

#combn(1:15,2) ###For 15 matrices.? Change `1:15` by the names of the matrices


library(energy)
?res<-sapply(split(mat1,col(mat1)),function(.dat) dcor(get(.dat[1]),get(.dat[2]),1.5))
names(res)<-apply(mat1,2,paste,collapse="")


res
#?????? AB??????? AC??????? AD??????? AE??????? BC??????? BD??????? BE??????? CD 
#0.9435313 0.8097978 0.6819835 0.8065327 0.7639587 0.8123220 0.7919720 0.6971948 
?# ???? CE??????? DE 
#0.7002440 0.8506617 


Also, I dcor() needs matrices that are compatible.


Make sure that the dimensions are compatible:
There was a typo in my previous reply. It should be

cor(A,B)

set.seed(24)
?A<- matrix(sample(1:50,20,replace=TRUE),ncol=4)
?B<- matrix(sample(40:60,30,replace=TRUE),ncol=6)
C<- matrix(sample(1:60,20,replace=TRUE),ncol=5)
D<- matrix(sample(1:30,20,replace=TRUE),ncol=2)
E<- matrix(sample(30:50,20,replace=TRUE),ncol=5)

cor(A,B) #works
?dcor(A,B)
#[1] 0.9651803


cor(A,C)
#Error in cor(A, C) : incompatible dimensions
dcor(A,C)
#Error in .dcov(x, y, index) : Sample sizes must agree
?cor(A,D)
#Error in cor(A, D) : incompatible dimensions


A.K.



________________________________
From: Amanda Li <amandali at uchicago.edu>
To: arun <smartpink111 at yahoo.com> 
Sent: Wednesday, June 19, 2013 1:11 AM
Subject: Re: [R] write a function to do pairwise calculation



Hello,

Thanks for your help! I am a novice in R, and may I ask how I am supposed to do it if it is actually 15 matrices instead of 3?

I gave up dcor because the matrices are too large. I was thinking of cor(A,B)*cor(A,B)/length(cor(A,B)) (the length varies because the matrices are of different dimensions). May I ask how am I supposed to write the function to make it work?

And also could you recommend a book that is suitable for R novice? Thank you so much for your help! I really appreciate it!

Best,
Amanda


2013/6/18 arun <smartpink111 at yahoo.com>

Hi,
>
>You didn't provide any information about the package.? I guess it is from "energy".?
>
>
>library(energy)
>x <- iris[1:50, 1:4]?? #examples given in the package
>y <- iris[51:100, 1:4]
>z<- iris[101:150,1:4]
>vec1<-c("x","y","z")
>mat1<- combn(vec1,2)
>
>sapply(split(mat1,col(mat1)),function(.dat) dcor(get(.dat[1]),get(.dat[2]),1.5))
>#??????? 1???????? 2???????? 3
>#0.1862890 0.2331567 0.2303689
>
>
>A.K.
>
>
>
>
>
>
>----- Original Message -----
>From: Amanda Li <amandali at uchicago.edu>
>To: r-help at r-project.org
>Cc:
>Sent: Monday, June 17, 2013 1:14 PM
>Subject: [R] write a function to do pairwise calculation
>
>Hello,
>
>I want to write a function to do pairwise calculation, but I don' know how
>to write it. Could anyone help?
>
>i.e. I have A (2*3), B(3*3), C(4*3) three matrices. I want to calculate
>distance correlation between each pair of matrices using code "dcor". How
>do I write a function so that I can get the result as a matrix integrating
>all the? pairwise results?
>
>Thanks in advance for your help!
>
>Best,
>Amanda
>
>??? [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>


From smartpink111 at yahoo.com  Wed Jun 19 14:57:19 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 19 Jun 2013 05:57:19 -0700 (PDT)
Subject: [R] quantile
In-Reply-To: <DUB107-W32EA6614649CAB95ADB82FDE8D0@phx.gbl>
References: <DUB107-W32EA6614649CAB95ADB82FDE8D0@phx.gbl>
Message-ID: <1371646639.67642.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
May be this helps:

set.seed(28)
?x<- sample(1:40,20,replace=TRUE)
?qx<-quantile(x,probs=0.10)
?qx
#10% 
#3.8 
?qx+1
#10% 
#4.8 
attr(qx,"names")<-NULL
qx
#[1] 3.8
?qx+1
#[1] 4.8
A.K.

?



----- Original Message -----
From: Francesco Miranda <kicco1991 at hotmail.it>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Wednesday, June 19, 2013 3:44 AM
Subject: [R] quantile

Hello,How do I extract only the value from the quantile function?example:quantile (x, probs = 0.10)? ? ? 10%-1.83442I want to add salt only the number -1.83442
SincerelyFrancesco Miranda ??? ???  ??? ?  ??? ??? ? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From rune.haubo at gmail.com  Wed Jun 19 15:00:17 2013
From: rune.haubo at gmail.com (Rune Haubo)
Date: Wed, 19 Jun 2013 15:00:17 +0200
Subject: [R] p values of lmer
In-Reply-To: <5e360438.fe90.13f5bc2ba32.Coremail.laomeng_3@163.com>
References: <5e360438.fe90.13f5bc2ba32.Coremail.laomeng_3@163.com>
Message-ID: <CAG_uk92oENKSwXYuT0HxmdeCBWJHZk3-6jnw3SXabn8mcOjJqQ@mail.gmail.com>

Try

library(lmerTest)
fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
summary(fm1)

Linear mixed model fit by REML
Formula: Reaction ~ Days + (Days | Subject)
   Data: sleepstudy
  AIC  BIC logLik deviance REMLdev
 1756 1775 -871.8     1752    1744
Random effects:
 Groups   Name        Variance Std.Dev. Corr
 Subject  (Intercept) 612.092  24.7405
          Days         35.072   5.9221  0.066
 Residual             654.941  25.5918
Number of obs: 180, groups: Subject, 18

Fixed effects:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  251.405      6.825   36.84  < 2e-16 ***
Days          10.467      1.546    6.77 3.27e-06 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Correlation of Fixed Effects:
     (Intr)
Days -0.138

Cheers,
Rune

On 19 June 2013 11:27, meng <laomeng_3 at 163.com> wrote:
> Hi all:
> I met a question about lmer.
>
> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
> summary(fm1)
>
> ...
>
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)  251.405      6.825   36.84
> Days          10.467      1.546    6.77
>
> ...
>
> My question:
> Why p values of (Intercept) and Days are not given?
>
>
> Many thanks!
>
> Best.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From michael.weylandt at gmail.com  Wed Jun 19 15:02:15 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Wed, 19 Jun 2013 14:02:15 +0100
Subject: [R] p values of lmer
In-Reply-To: <5e360438.fe90.13f5bc2ba32.Coremail.laomeng_3@163.com>
References: <5e360438.fe90.13f5bc2ba32.Coremail.laomeng_3@163.com>
Message-ID: <CAAmySGM3Pw1TAnYiQTdhPhcWcaeJd2U=NZCKpEbMFeqjF3ud6Q@mail.gmail.com>

On Wed, Jun 19, 2013 at 10:27 AM, meng <laomeng_3 at 163.com> wrote:
> Hi all:
> I met a question about lmer.
>
> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
> summary(fm1)
>
> ...
>
> Fixed effects:
>             Estimate Std. Error t value
> (Intercept)  251.405      6.825   36.84
> Days          10.467      1.546    6.77
>
> ...
>
> My question:
> Why p values of (Intercept) and Days are not given?

Take a look at R FAQ 7.35.

http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-are-p_002dvalues-not-displayed-when-using-lmer_0028_0029_003f


>
>
> Many thanks!
>
> Best.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From friendly at yorku.ca  Wed Jun 19 15:23:27 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 19 Jun 2013 09:23:27 -0400
Subject: [R] knitr: side-by-side figures in R markdown
Message-ID: <51C1B0CF.3080702@yorku.ca>

I've read all the docs on knitr and some blogs on this topic, but can't 
figure out how
to produce side-by-side figures in R markdown, except by composing a 
single figure
in R with par(mfrow=c(1,2)).
I know this can be done easily with the LaTeX engine, but why not with 
HTML output?

A small test file is below.  If I were composing HTML directly, I would 
just wrap the images
in a table, e.g.,

<table>
<tr><td><img src="fig1.png"></td>
     <td><img src="fig2.png"></td>
</tr>
</table>

Is there someway to achieve this with knitr, perhaps a chunk hook?

--- test-figs.Rmd -----
Testing side-by-side figs
==========================

```{r knitr-setup, include=FALSE}
library(knitr)
library(vcd)
opts_chunk$set(out.extra='style="display:block; margin: auto"', 
fig.align="center", fig.width=4, fig.height=4)
opts_knit$set(progress = FALSE, verbose = TRUE)
```

This doesn't do what I want:
```{r chunck1, fig.show='hold'}
plot(1:10)
plot(10:1)
```

This does:
```{r chunck2, fig.show='hold', fig.width=8}
op <- par(mfrow=c(1,2))
plot(1:10)
plot(10:1)
par(op)
```

What to do with grid-based graphics (requires messing with viewports):

```{r chunck3, fig.width=6}
data(Titanic, package="datasets")
mosaic(Titanic)
mosaic(Titanic, shade=TRUE)
```

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From smartpink111 at yahoo.com  Wed Jun 19 15:26:14 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 19 Jun 2013 06:26:14 -0700 (PDT)
Subject: [R] Elementary Help
In-Reply-To: <1371565976.18433.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1371565976.18433.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1371648374.25764.YahooMailNeo@web142605.mail.bf1.yahoo.com>

HI,
Probably, this is the case.? It is better to provide a reproducible example data as mentioned in the posting guide.
set.seed(24)
dat1<- data.frame(ID=c(1:3,5:8,10:14),value=sample(1:40,12,replace=TRUE))
?IDs<- 1:14? #the possible ID list
setdiff(IDs,dat1$ID)
#[1] 4 9
length(setdiff(IDs,dat1$ID))
#[1] 2
A.K.

Hi, Unfortunately somehow it won't help. The unused values are not NA, 
the unused values are simply not there. Since these are student Ids, for
 instance there is no 4,8,9 etc... I need to find out which of these are
 not there. 



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Tuesday, June 18, 2013 10:32 AM
Subject: Re: Elementary Help

Hi,
May be this helps:
set.seed(24)
dat1<- data.frame(ID=1:200,value=sample(c(5:200,NA),200,replace=TRUE))
?which(is.na(dat1$value))
#[1]? 56 146 184
sum(which(is.na(dat1$value)))? #Not clear about the 2nd part of the question
#[1] 386

?sum(is.na(dat1$value))
#[1] 3
table(is.na(dat1$value))
#FALSE? TRUE 
#? 197???? 3 
A.K.


>I am totally new to R, therefore probably this question will be very 
easy for most of you. I have a range of values in a column ranging from 5 to 200. >Some of the values are missing, that is, not all student 
numbers are there. How do I find which are these missing numbers and 
obtain the sum of >these integers?


From smartpink111 at yahoo.com  Wed Jun 19 15:40:33 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 19 Jun 2013 06:40:33 -0700 (PDT)
Subject: [R] How to combine and transpose lists
Message-ID: <1371649233.12427.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
Please use ?dput(). 

?If `lst1` is the list.


do.call(rbind,lapply(lst1,t))
#????????? Estimate? Std. Error?? t value?? Pr(>|t|)
#card1? 0.000577912 0.003956905 0.1460515 0.88388493
#card2? 0.005164347 0.003311546 1.5594972 0.11892405
#card3? 0.002682773 0.003683422 0.7283372 0.46643165
#cardva 0.003123452 0.002727940 1.1449856 0.25225436
#resp1? 0.005552192 0.007135446 0.7781142 0.43652806
#resp2? 0.010337814 0.004848899 2.1319923 0.03304227
#resp3? 0.002850401 0.006422570 0.4438100 0.65719368
#respir 0.006212050 0.004121313 1.5072989 0.13177931


A.K.


I have lists that look like the following: 

[[1]] 

? ? ? ? ? ? ? ? ? ? ? card1 ? ? card2 ? ? card3 ? ? ?cardva 
Estimate ? 0.000577912 0.005164347 0.002682773 0.003123452 
Std. Error 0.003956905 0.003311546 0.003683422 0.002727940 
t value ? ?0.146051523 1.559497247 0.728337154 1.144985607 
Pr(>|t|) ? 0.883884930 0.118924052 0.466431647 0.252254365 

[[2]] 
? ? ? ? ? ? ? ? ? ? ? resp1 ? ? resp2 ? ? resp3 ? ? ?respir 
Estimate ? 0.005552192 0.010337814 0.002850401 0.006212050 
Std. Error 0.007135446 0.004848899 0.006422570 0.004121313 
t value ? ?0.778114195 2.131992269 0.443810047 1.507298878 
Pr(>|t|) ? 0.436528058 0.033042268 0.657193676 0.131779306 


My aim is to combine the lists and transpose them. ?The 
final output is to have effect estimates with corresponding std error 
and p values as column headers and card1, ?card2 , etc... as rows. How 
can I do that? 

Thanks in advance


From smartpink111 at yahoo.com  Wed Jun 19 15:43:53 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 19 Jun 2013 06:43:53 -0700 (PDT)
Subject: [R] How to combine and transpose lists
In-Reply-To: <1371649233.12427.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1371649233.12427.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1371649433.31419.YahooMailNeo@web142601.mail.bf1.yahoo.com>

You could also use:

t(data.frame(lst1))
#????????? Estimate? Std. Error?? t value?? Pr(>|t|)
#card1? 0.000577912 0.003956905 0.1460515 0.88388493
#card2? 0.005164347 0.003311546 1.5594972 0.11892405
#card3? 0.002682773 0.003683422 0.7283372 0.46643165
#cardva 0.003123452 0.002727940 1.1449856 0.25225436
#resp1? 0.005552192 0.007135446 0.7781142 0.43652806
#resp2? 0.010337814 0.004848899 2.1319923 0.03304227
#resp3? 0.002850401 0.006422570 0.4438100 0.65719368
#respir 0.006212050 0.004121313 1.5072989 0.13177931

A.K.

----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Wednesday, June 19, 2013 9:40 AM
Subject: Re: How to combine and transpose lists

Hi,
Please use ?dput(). 

?If `lst1` is the list.


do.call(rbind,lapply(lst1,t))
#????????? Estimate? Std. Error?? t value?? Pr(>|t|)
#card1? 0.000577912 0.003956905 0.1460515 0.88388493
#card2? 0.005164347 0.003311546 1.5594972 0.11892405
#card3? 0.002682773 0.003683422 0.7283372 0.46643165
#cardva 0.003123452 0.002727940 1.1449856 0.25225436
#resp1? 0.005552192 0.007135446 0.7781142 0.43652806
#resp2? 0.010337814 0.004848899 2.1319923 0.03304227
#resp3? 0.002850401 0.006422570 0.4438100 0.65719368
#respir 0.006212050 0.004121313 1.5072989 0.13177931


A.K.


I have lists that look like the following: 

[[1]] 

? ? ? ? ? ? ? ? ? ? ? card1 ? ? card2 ? ? card3 ? ? ?cardva 
Estimate ? 0.000577912 0.005164347 0.002682773 0.003123452 
Std. Error 0.003956905 0.003311546 0.003683422 0.002727940 
t value ? ?0.146051523 1.559497247 0.728337154 1.144985607 
Pr(>|t|) ? 0.883884930 0.118924052 0.466431647 0.252254365 

[[2]] 
? ? ? ? ? ? ? ? ? ? ? resp1 ? ? resp2 ? ? resp3 ? ? ?respir 
Estimate ? 0.005552192 0.010337814 0.002850401 0.006212050 
Std. Error 0.007135446 0.004848899 0.006422570 0.004121313 
t value ? ?0.778114195 2.131992269 0.443810047 1.507298878 
Pr(>|t|) ? 0.436528058 0.033042268 0.657193676 0.131779306 


My aim is to combine the lists and transpose them. ?The 
final output is to have effect estimates with corresponding std error 
and p values as column headers and card1, ?card2 , etc... as rows. How 
can I do that? 

Thanks in advance


From jspark4 at uic.edu  Wed Jun 19 15:50:28 2013
From: jspark4 at uic.edu (Sparks, John James)
Date: Wed, 19 Jun 2013 08:50:28 -0500
Subject: [R] T test for Single Mean
Message-ID: <d6f7a2a4a1d8c2c86d05a7e06b968989.squirrel@webmail.uic.edu>

Dear R Helpers,

I am stuck on some syntax and I thought that I was following one of the
examples that I found out there quite faithfully.

I just want to know how to do a t test on a single mean for whether or not
it is greater than a specific value.  So I am using the data set sleep and
I want to know if the mean of extra is greater then zero.  I was under the
impression that the syntax is

t.test(sleep$extra,mu=0,"greater")

but I get the error message

Error in t.test.default(sleep$extra, mu = 0, "greater") :
  not enough 'y' observations

I have tried this on a few other data sets that have more then 20
observations and I get the same error.  I looked in the documentation but
the examples are for the comparison of two groups, not a single group
mean.

Any help would be most appreciated.

--John J. Sparks, Ph.D.


From jvadams at usgs.gov  Wed Jun 19 15:57:25 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 19 Jun 2013 08:57:25 -0500
Subject: [R] Retrieving Labels from vars/cols
In-Reply-To: <9160533.jDkeJi3ZQS@venus.lcipriano.pt>
References: <9160533.jDkeJi3ZQS@venus.lcipriano.pt>
Message-ID: <CAN5YmCHMM-2PTo_j3TBHzJ0FjVf6AfqkekdtFxfJ0YF-_ja1Ng@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130619/efca26b4/attachment.pl>

From gunter.berton at gene.com  Wed Jun 19 16:04:07 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 19 Jun 2013 07:04:07 -0700
Subject: [R] T test for Single Mean
In-Reply-To: <d6f7a2a4a1d8c2c86d05a7e06b968989.squirrel@webmail.uic.edu>
References: <d6f7a2a4a1d8c2c86d05a7e06b968989.squirrel@webmail.uic.edu>
Message-ID: <CACk-te2_j+hO0eOKyfj3cGEh1zkR_kdOByxS8ubYpUpBkz7A3Q@mail.gmail.com>

(Re-) Read the docs (e.g. Intro to R, R Language Definition) . ...
arguments have to be named!

t.test(sleep$extra,mu=0, alt = "greater")  ## works

-- Bert

On Wed, Jun 19, 2013 at 6:50 AM, Sparks, John James <jspark4 at uic.edu> wrote:
> Dear R Helpers,
>
> I am stuck on some syntax and I thought that I was following one of the
> examples that I found out there quite faithfully.
>
> I just want to know how to do a t test on a single mean for whether or not
> it is greater than a specific value.  So I am using the data set sleep and
> I want to know if the mean of extra is greater then zero.  I was under the
> impression that the syntax is
>
> t.test(sleep$extra,mu=0,"greater")
>
> but I get the error message
>
> Error in t.test.default(sleep$extra, mu = 0, "greater") :
>   not enough 'y' observations
>
> I have tried this on a few other data sets that have more then 20
> observations and I get the same error.  I looked in the documentation but
> the examples are for the comparison of two groups, not a single group
> mean.
>
> Any help would be most appreciated.
>
> --John J. Sparks, Ph.D.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From jvadams at usgs.gov  Wed Jun 19 16:12:27 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 19 Jun 2013 09:12:27 -0500
Subject: [R] (senza oggetto)
In-Reply-To: <DUB404-EAS4223A3DC7E259923C658A9ED68D0@phx.gbl>
References: <DUB404-EAS4223A3DC7E259923C658A9ED68D0@phx.gbl>
Message-ID: <CAN5YmCGHwSb6_UOR_JynUt=AmrvwWwFN4X5B_eaH=SON2NnSwg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130619/2b1345cd/attachment.pl>

From michel.arnaud at cirad.fr  Wed Jun 19 16:23:25 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Wed, 19 Jun 2013 16:23:25 +0200
Subject: [R] to build a data.frame
Message-ID: <51C1BEDD.4090707@cirad.fr>

Hello

I have the following dataframe

df <- data.frame(
Project=c("Abaco","Abaco","Abac","Abaco","Abaco","Abaco",
"Abaco","Adaptclone","Adaptclone","Adaptclone","Adaptclone","Adaptclone",
"Adaptclone","Adopt","Adopt","Adopt"),

Country=c("Zimbabwe","Burkina Faso","South Africa","Madagascar","Tanzania",
"Mali","Mozambique","Madagascar","Ghana","Nigeria","Kenya","Burkina Faso",
  "South Africa","Tanzania","Kenya","Ethiopia" ),

Iso=c("ZW","BF","ZA","MG","TZ","ML","MZ","MG","GH","NG","KE","BF",
  "ZA","TZ","KE","ET"))

I would like to build a other dataframe with name Country
where column 1 is country,
the column 2 is number of project (in the country)
the column 3 is the code Iso (wich correspond with the country : Ex ZW 
is ISO of Zimbabwe)
       Pays        PaysIso  NbrProj
    Zimbabwe      ZW       1
  Burkina Faso    BF        2


I know associate Country and Number of projets but how associate Iso

Any idea ?
Thank you for your help

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From dcarlson at tamu.edu  Wed Jun 19 16:26:30 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Wed, 19 Jun 2013 09:26:30 -0500
Subject: [R] Retrieving Labels from vars/cols
In-Reply-To: <CAN5YmCHMM-2PTo_j3TBHzJ0FjVf6AfqkekdtFxfJ0YF-_ja1Ng@mail.gmail.com>
References: <9160533.jDkeJi3ZQS@venus.lcipriano.pt>
	<CAN5YmCHMM-2PTo_j3TBHzJ0FjVf6AfqkekdtFxfJ0YF-_ja1Ng@mail.gmail.com>
Message-ID: <04d901ce6cf8$fdfd05b0$f9f71110$@tamu.edu>

Perhaps you are talking about the variable.labels attribute returned
by read.spss in package foreign? If so, you should try the
attributes() or the attr() function:

?attributes
?attr

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Adams, Jean
Sent: Wednesday, June 19, 2013 8:57 AM
To: L?vio Cipriano
Cc: R help
Subject: Re: [R] Retrieving Labels from vars/cols

I'm not sure what you mean by the $variables.label property.
Are you just looking for the column names?
If your data frame is called "df", try
     names(df)

Jean


On Tue, Jun 18, 2013 at 2:16 PM, Lmvio Cipriano
<lcmail4lists at gmail.com>wrote:

> Hi,
>
> How can I read/retrieve the Labels strings of the $variables.label
> proprety of
> a data Frame?
>
> Regards
>
> Lmvio Cipriano
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Wed Jun 19 16:30:39 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 19 Jun 2013 09:30:39 -0500
Subject: [R] nls singular gradient ..as always..
In-Reply-To: <1371641309773-4669859.post@n4.nabble.com>
References: <1371641309773-4669859.post@n4.nabble.com>
Message-ID: <CAN5YmCFqNezNAj1YqeD7+pOJ9kthzPMbLuugNJUGAfi1Jdd=4Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130619/ef13572d/attachment.pl>

From ruipbarradas at sapo.pt  Wed Jun 19 16:31:36 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 19 Jun 2013 15:31:36 +0100
Subject: [R] to build a data.frame
In-Reply-To: <51C1BEDD.4090707@cirad.fr>
References: <51C1BEDD.4090707@cirad.fr>
Message-ID: <51C1C0C8.8090803@sapo.pt>

Hello,

Try the following.

aggregate(Project ~ Country + Iso, data = df, FUN = length)


Hope this helps,

Rui Barradas

Em 19-06-2013 15:23, Arnaud Michel escreveu:
> Hello
>
> I have the following dataframe
>
> df <- data.frame(
> Project=c("Abaco","Abaco","Abac","Abaco","Abaco","Abaco",
> "Abaco","Adaptclone","Adaptclone","Adaptclone","Adaptclone","Adaptclone",
> "Adaptclone","Adopt","Adopt","Adopt"),
>
> Country=c("Zimbabwe","Burkina Faso","South Africa","Madagascar","Tanzania",
> "Mali","Mozambique","Madagascar","Ghana","Nigeria","Kenya","Burkina Faso",
>   "South Africa","Tanzania","Kenya","Ethiopia" ),
>
> Iso=c("ZW","BF","ZA","MG","TZ","ML","MZ","MG","GH","NG","KE","BF",
>   "ZA","TZ","KE","ET"))
>
> I would like to build a other dataframe with name Country
> where column 1 is country,
> the column 2 is number of project (in the country)
> the column 3 is the code Iso (wich correspond with the country : Ex ZW
> is ISO of Zimbabwe)
>        Pays        PaysIso  NbrProj
>     Zimbabwe      ZW       1
>   Burkina Faso    BF        2
>
>
> I know associate Country and Number of projets but how associate Iso
>
> Any idea ?
> Thank you for your help
>


From smartpink111 at yahoo.com  Wed Jun 19 16:47:26 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 19 Jun 2013 07:47:26 -0700 (PDT)
Subject: [R] to build a data.frame
In-Reply-To: <51C1BEDD.4090707@cirad.fr>
References: <51C1BEDD.4090707@cirad.fr>
Message-ID: <1371653246.60784.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
May be this helps:
library(plyr)
?ddply(df,.(Country,Iso),summarize,NbrProj=length(Project))
#??????? Country Iso NbrProj
#1? Burkina Faso? BF?????? 2
#2????? Ethiopia? ET?????? 1
#3???????? Ghana? GH?????? 1
#4???????? Kenya? KE?????? 2
#5??? Madagascar? MG?????? 2
#6????????? Mali? ML?????? 1
#7??? Mozambique? MZ?????? 1
#8?????? Nigeria? NG?????? 1
#9? South Africa? ZA?????? 2
#10???? Tanzania? TZ?????? 2
#11???? Zimbabwe? ZW?????? 1
A.K.


A.K.




----- Original Message -----
From: Arnaud Michel <michel.arnaud at cirad.fr>
To: r-help at r-project.org
Cc: 
Sent: Wednesday, June 19, 2013 10:23 AM
Subject: [R] to build a data.frame

Hello

I have the following dataframe

df <- data.frame(
Project=c("Abaco","Abaco","Abac","Abaco","Abaco","Abaco",
"Abaco","Adaptclone","Adaptclone","Adaptclone","Adaptclone","Adaptclone",
"Adaptclone","Adopt","Adopt","Adopt"),

Country=c("Zimbabwe","Burkina Faso","South Africa","Madagascar","Tanzania",
"Mali","Mozambique","Madagascar","Ghana","Nigeria","Kenya","Burkina Faso",
? "South Africa","Tanzania","Kenya","Ethiopia" ),

Iso=c("ZW","BF","ZA","MG","TZ","ML","MZ","MG","GH","NG","KE","BF",
? "ZA","TZ","KE","ET"))

I would like to build a other dataframe with name Country
where column 1 is country,
the column 2 is number of project (in the country)
the column 3 is the code Iso (wich correspond with the country : Ex ZW 
is ISO of Zimbabwe)
? ? ?  Pays? ? ? ? PaysIso? NbrProj
? ? Zimbabwe? ? ? ZW? ? ?  1
? Burkina Faso? ? BF? ? ? ? 2


I know associate Country and Number of projets but how associate Iso

Any idea ?
Thank you for your help

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Wed Jun 19 16:48:32 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Wed, 19 Jun 2013 09:48:32 -0500
Subject: [R] to build a data.frame
In-Reply-To: <51C1BEDD.4090707@cirad.fr>
References: <51C1BEDD.4090707@cirad.fr>
Message-ID: <04ea01ce6cfc$11c27c80$35477580$@tamu.edu>

Try this:

> aggregate(Project~Country+Iso, df, length)
        Country Iso Project
1  Burkina Faso  BF       2
2      Ethiopia  ET       1
3         Ghana  GH       1
4         Kenya  KE       2
5    Madagascar  MG       2
6          Mali  ML       1
7    Mozambique  MZ       1
8       Nigeria  NG       1
9      Tanzania  TZ       2
10 South Africa  ZA       2
11     Zimbabwe  ZW       1

Or if you prefer left-aligned:

> print(aggregate(Project~Country+Iso, df, length), right=FALSE)
   Country      Iso Project
1  Burkina Faso BF  2      
2  Ethiopia     ET  1      
3  Ghana        GH  1      
4  Kenya        KE  2      
5  Madagascar   MG  2      
6  Mali         ML  1      
7  Mozambique   MZ  1      
8  Nigeria      NG  1      
9  Tanzania     TZ  2      
10 South Africa ZA  2      
11 Zimbabwe     ZW  1      

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Arnaud Michel
Sent: Wednesday, June 19, 2013 9:23 AM
To: r-help at r-project.org
Subject: [R] to build a data.frame

Hello

I have the following dataframe

df <- data.frame(
Project=c("Abaco","Abaco","Abac","Abaco","Abaco","Abaco",
"Abaco","Adaptclone","Adaptclone","Adaptclone","Adaptclone","Adaptcl
one",
"Adaptclone","Adopt","Adopt","Adopt"),

Country=c("Zimbabwe","Burkina Faso","South
Africa","Madagascar","Tanzania",
"Mali","Mozambique","Madagascar","Ghana","Nigeria","Kenya","Burkina
Faso",
  "South Africa","Tanzania","Kenya","Ethiopia" ),

Iso=c("ZW","BF","ZA","MG","TZ","ML","MZ","MG","GH","NG","KE","BF",
  "ZA","TZ","KE","ET"))

I would like to build a other dataframe with name Country
where column 1 is country,
the column 2 is number of project (in the country)
the column 3 is the code Iso (wich correspond with the country : Ex
ZW 
is ISO of Zimbabwe)
       Pays        PaysIso  NbrProj
    Zimbabwe      ZW       1
  Burkina Faso    BF        2


I know associate Country and Number of projets but how associate Iso

Any idea ?
Thank you for your help

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From S.Ellison at lgcgroup.com  Wed Jun 19 17:00:05 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Wed, 19 Jun 2013 16:00:05 +0100
Subject: [R] quantile
In-Reply-To: <1371646639.67642.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <DUB107-W32EA6614649CAB95ADB82FDE8D0@phx.gbl>
	<1371646639.67642.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED4AC9E0CC0E@GOLD.corp.lgc-group.com>

Or cast to vector: 

> set.seed(28)
> ?x<- sample(1:40,20,replace=TRUE)
> ?qx<-quantile(x,probs=0.10)
> ?qx
> #10%
> #3.8

> as.vector(qx)
> #3.8



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From ejoffe at hotmail.com  Wed Jun 19 17:36:37 2013
From: ejoffe at hotmail.com (Erel JOFFE)
Date: Wed, 19 Jun 2013 15:36:37 +0000
Subject: [R] Outputting a random survival forest to rf2rfz in windows
Message-ID: <DUB114-W111318AFD80489B5996A73ECA8D0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130619/f2c89515/attachment.pl>

From erinm.hodgess at gmail.com  Wed Jun 19 17:50:15 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Wed, 19 Jun 2013 10:50:15 -0500
Subject: [R]  Ryacas loads but yacas has an error
Message-ID: <CACxE24kQARvDz1BKP89R50b-8BCw6gXeMhT=i74CvHPCbhQ6nw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130619/a1595361/attachment.pl>

From wdunlap at tibco.com  Wed Jun 19 17:52:03 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 19 Jun 2013 15:52:03 +0000
Subject: [R] evaluation of equations from Ryacas
In-Reply-To: <7E8037094A0C2146AA3E6F94DAE621C34454BA96@AD-EXCHMBX2-1.aau.dk>
References: <CACxE24krkNxdRRTkakyJSr8OLK7cReQ0FLcOWx86Aprsgi5rkQ@mail.gmail.com>
	<7E8037094A0C2146AA3E6F94DAE621C34454BA96@AD-EXCHMBX2-1.aau.dk>
Message-ID: <E66794E69CFDE04D9A70842786030B931C3043D8@PA-MBX01.na.tibco.com>

> > e<-expression(list(R == 100 * (1 - 2 * y/10000)))
> > ee <- e[[1]][2]
> > ee
> (R == 100 * (1 - 2 * y/10000))()
> > eval(parse(text=(substring(paste(ee), 5))), list(y=5))
> [1] 99.9

The following avoids the fragile substring(paste(expression)) business:
  > eval(e[[1]][[2]][[3]], list(y=5))
  [1] 99.9
The [[1]] pulls the call to list out of the expression object.
The [[2]] pulls the first (and only) argument out of the call to list.
I assume that argument is a call to '==' with 2 arguments ('R' and
'100 * (1 -2 * y/10000)') so the [[3]] pulls out the second argument.
This solution may be fragile as well, but it doesn't depend on you
knowing the number of characters in the variable names.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of S?ren H?jsgaard
> Sent: Wednesday, June 19, 2013 12:06 AM
> To: Erin Hodgess; R help
> Subject: Re: [R] evaluation of equations from Ryacas
> 
> Dear Erin,
> 
> Not exactly elegant, but
> 
> > e<-expression(list(R == 100 * (1 - 2 * y/10000)))
> > ee <- e[[1]][2]
> > ee
> (R == 100 * (1 - 2 * y/10000))()
> > eval(parse(text=(substring(paste(ee), 5))), list(y=5))
> [1] 99.9
> 
> Regards
> S?ren
> 
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Erin Hodgess
> Sent: 19. juni 2013 07:03
> To: R help
> Subject: [R] evaluation of equations from Ryacas
> 
> Hello again.
> 
> Now I have the following:
> > xx
> [1] "Solve(1 - R/100==(2*y)/10000,R)"
> > yacas(xx)
> expression(list(R == 100 * (1 - 2 * y/10000)))
> >
> 
> I would like to put in a value for y and obtain R.
> I've tried more stuff with eval and Eval, but no luck yet.
> 
> Any suggestions would be much appreciated.
> 
> Thanks,
> Erin
> 
> 
> --
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sorenh at math.aau.dk  Wed Jun 19 18:24:47 2013
From: sorenh at math.aau.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Wed, 19 Jun 2013 16:24:47 +0000
Subject: [R] Ryacas loads but yacas has an error
In-Reply-To: <CACxE24kQARvDz1BKP89R50b-8BCw6gXeMhT=i74CvHPCbhQ6nw@mail.gmail.com>
References: <CACxE24kQARvDz1BKP89R50b-8BCw6gXeMhT=i74CvHPCbhQ6nw@mail.gmail.com>
Message-ID: <7E8037094A0C2146AA3E6F94DAE621C34454C2A0@AD-EXCHMBX2-1.aau.dk>

Dear Erin,

I don't have solution, but there is a remark on connection issues at http://code.google.com/p/ryacas/ 

An alternative could be to look at the rSymPy or rmathpiper packages which may do what you want.

Regards
S?ren

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Erin Hodgess
Sent: 19. juni 2013 17:50
To: R help
Subject: [R] Ryacas loads but yacas has an error

Hello yet again, R People:

I was working with Ryacas and yacas last night and all was well.

Now this morning, I keep getting the following:

> a <- Sym("a")
> a
Error in summary.connection(x) : invalid connection
>

When I go to yacas from the command line, it works fine.

Any suggestions, please?

I'm thinking that a port might be open, but here I have:
> showConnections()
     description class mode text isopen can read can write
>

I'm working with R-3.0.1 on Windows 7.

Thanks,
Erin

--
Erin Hodgess
Associate Professor
Department of Computer and Mathematical Sciences University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ggrothendieck at gmail.com  Wed Jun 19 18:29:31 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 19 Jun 2013 12:29:31 -0400
Subject: [R] evaluation of equations from Ryacas
In-Reply-To: <CACxE24krkNxdRRTkakyJSr8OLK7cReQ0FLcOWx86Aprsgi5rkQ@mail.gmail.com>
References: <CACxE24krkNxdRRTkakyJSr8OLK7cReQ0FLcOWx86Aprsgi5rkQ@mail.gmail.com>
Message-ID: <CAP01uRkmCVQobyBdRRHPWTC6fWV5zqyATX4oTt6Ay4-EOCd6yA@mail.gmail.com>

On Wed, Jun 19, 2013 at 1:03 AM, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> Hello again.
>
> Now I have the following:
>> xx
> [1] "Solve(1 - R/100==(2*y)/10000,R)"
>> yacas(xx)
> expression(list(R == 100 * (1 - 2 * y/10000)))
>>

Try the Ryacas Sym interface:

> library(Ryacas)
>
> R <- Sym("R")
> y <- Sym("y")
> ans <- Solve(R == 100 * (1 - 2 * y / 10000), R)
> ans
expression(list(R == 100 * (1 - 2 * y/10000)))
> Set(y, 3)
expression(3)
> ans
expression(list(R == 4997/50))
> Set(y, 4)
expression(4)
> ans
expression(list(R == 2498/25))


--
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From smartpink111 at yahoo.com  Wed Jun 19 18:42:08 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 19 Jun 2013 09:42:08 -0700 (PDT)
Subject: [R] Elementary Help
In-Reply-To: <1371648374.25764.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1371565976.18433.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1371648374.25764.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1371660128.55480.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Based on the information you provided, the solution should be the one I provided earlier.? Otherwise, I must have misunderstood your question.? In your first post, you mentioned the IDs range from 5:200.?? So, the question is not clear.


dat1<- read.table(text="
timeSec pupilId pupilName
137237 57 LaurenColes
137250 57 LaurenColes
137254 59 JackGough
137262 57 LaurenColes
137275 92 GraceChapman
137281 59 JackGough
137285 111 DavidHenderson
137291 57 LaurenColes
137297 92 GraceChapman
137305 68 AmeliaNorth
137306 82 AlexBruce
137309 92 GraceChapman
137311 111 DavidHenderson
137325 57 LaurenColes
137328 82 AlexBruce
137329 68 AmeliaNorth
137330 111 DavidHenderson
137330 104 SofiaMorrison
137335 15 KieraNoble
137340 34 LouisTalbot
137342 20 EllaOConnor
137345 68 AmeliaNorth
137346 57 LaurenColes
137349 65 AmeliaMiller
137351 40 KatieWinter
137353 34 LouisTalbot
137357 115 NoahStorey
137357 92 GraceChapman
",sep="",header=TRUE,stringsAsFactors=FALSE) 

?IDs<-1:161
?setdiff(IDs,dat1$pupilId)
#? [1]?? 1?? 2?? 3?? 4?? 5?? 6?? 7?? 8?? 9? 10? 11? 12? 13? 14? 16? 17? 18? 19
# [19]? 21? 22? 23? 24? 25? 26? 27? 28? 29? 30? 31? 32? 33? 35? 36? 37? 38? 39
# [37]? 41? 42? 43? 44? 45? 46? 47? 48? 49? 50? 51? 52? 53? 54? 55? 56? 58? 60
# [55]? 61? 62? 63? 64? 66? 67? 69? 70? 71? 72? 73? 74? 75? 76? 77? 78? 79? 80
# [73]? 81? 83? 84? 85? 86? 87? 88? 89? 90? 91? 93? 94? 95? 96? 97? 98? 99 100
# [91] 101 102 103 105 106 107 108 109 110 112 113 114 116 117 118 119 120 121
#[109] 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139
#[127] 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157
#[145] 158 159 160 161
?sum(setdiff(IDs,dat1$pupilId))
#[1] 12179
?length(setdiff(IDs,dat1$pupilId))? #changes when you use the actual dataset
#[1] 148


A.K.


Sorry, this is my first time I am using the forum. The data I have is the following: 

timeSec	pupilId	pupilName 
137237	57	LaurenColes 
137250	57	LaurenColes 
137254	59	JackGough 
137262	57	LaurenColes 
137275	92	GraceChapman 
137281	59	JackGough 
137285	111	DavidHenderson 
137291	57	LaurenColes 
137297	92	GraceChapman 
137305	68	AmeliaNorth 
137306	82	AlexBruce 
137309	92	GraceChapman 
137311	111	DavidHenderson 
137325	57	LaurenColes 
137328	82	AlexBruce 
137329	68	AmeliaNorth 
137330	111	DavidHenderson 
137330	104	SofiaMorrison 
137335	15	KieraNoble 
137340	34	LouisTalbot 
137342	20	EllaOConnor 
137345	68	AmeliaNorth 
137346	57	LaurenColes 
137349	65	AmeliaMiller 
137351	40	KatieWinter 
137353	34	LouisTalbot 
137357	115	NoahStorey 
137357	92	GraceChapman 
etc... 

The exact quesiton is the following: 

Some ids in the range 1 to 161 are unused (e.g. 4,7,9). In fact,
 there are 30 unused pupil Ids ?between 1 and 161. What is the sum of 
these 30 integers? 
----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Wednesday, June 19, 2013 9:26 AM
Subject: Re: Elementary Help

HI,
Probably, this is the case.? It is better to provide a reproducible example data as mentioned in the posting guide.
set.seed(24)
dat1<- data.frame(ID=c(1:3,5:8,10:14),value=sample(1:40,12,replace=TRUE))
?IDs<- 1:14? #the possible ID list
setdiff(IDs,dat1$ID)
#[1] 4 9
length(setdiff(IDs,dat1$ID))
#[1] 2
A.K.

Hi, Unfortunately somehow it won't help. The unused values are not NA, 
the unused values are simply not there. Since these are student Ids, for
instance there is no 4,8,9 etc... I need to find out which of these are
not there. 



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Tuesday, June 18, 2013 10:32 AM
Subject: Re: Elementary Help

Hi,
May be this helps:
set.seed(24)
dat1<- data.frame(ID=1:200,value=sample(c(5:200,NA),200,replace=TRUE))
?which(is.na(dat1$value))
#[1]? 56 146 184
sum(which(is.na(dat1$value)))? #Not clear about the 2nd part of the question
#[1] 386

?sum(is.na(dat1$value))
#[1] 3
table(is.na(dat1$value))
#FALSE? TRUE 
#? 197???? 3 
A.K.


>I am totally new to R, therefore probably this question will be very 
easy for most of you. I have a range of values in a column ranging from 5 to 200. >Some of the values are missing, that is, not all student 
numbers are there. How do I find which are these missing numbers and 
obtain the sum of >these integers?


From ggrothendieck at gmail.com  Wed Jun 19 18:57:26 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 19 Jun 2013 12:57:26 -0400
Subject: [R] Ryacas loads but yacas has an error
In-Reply-To: <CACxE24kQARvDz1BKP89R50b-8BCw6gXeMhT=i74CvHPCbhQ6nw@mail.gmail.com>
References: <CACxE24kQARvDz1BKP89R50b-8BCw6gXeMhT=i74CvHPCbhQ6nw@mail.gmail.com>
Message-ID: <CAP01uRkiHuamgUQnnyXD7xTFaAnqrdcY0+4Adw18UWQaubXeSA@mail.gmail.com>

On Wed, Jun 19, 2013 at 11:50 AM, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> Hello yet again, R People:
>
> I was working with Ryacas and yacas last night and all was well.
>
> Now this morning, I keep getting the following:
>
>> a <- Sym("a")
>> a
> Error in summary.connection(x) : invalid connection
>>
>
> When I go to yacas from the command line, it works fine.
>
> Any suggestions, please?
>
> I'm thinking that a port might be open, but here I have:
>> showConnections()
>      description class mode text isopen can read can write
>>
>
> I'm working with R-3.0.1 on Windows 7.
>

I am running Ryacas using R 3.0.1 on Windows 8 so its unlikely it does
not run on Windows 7.  Read the troubleshooting section on the home
page.  http://ryacas.googlecode.com


--
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From dwinsemius at comcast.net  Wed Jun 19 19:57:49 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 19 Jun 2013 10:57:49 -0700
Subject: [R] Vectorize a series of  Matrix Multiplications
In-Reply-To: <1371484090.69759.YahooMailNeo@web122201.mail.ne1.yahoo.com>
References: <1371350130.67939.YahooMailNeo@web122202.mail.ne1.yahoo.com>
	<1371484090.69759.YahooMailNeo@web122201.mail.ne1.yahoo.com>
Message-ID: <A80ECDDA-1E09-450C-8285-EF4FA6148034@comcast.net>


On Jun 17, 2013, at 8:48 AM, G Vishwanath wrote:

> Can I have some help in vectorizing a series of matrix multiplications?
> Toy Example
> 
> mat_size=2; num_matrices=3; num_users=2
> 
> ToyArray=array(1,dim=c(mat_size,   mat_size, num_matrices, num_users))
> /* So I open an 4-dim array to store 3  2 X 2 matrrices  for 2 users.  For each user I want to multiple the 3, 2 X 2 matrices so that  at the end I have 1 matrix for each of the 2 users */
> 
> This works:
>  output=array(NA,dim=c(mat_size, mat_size, num_users));
> 
>  for ( i in 1:num_users) {
>   output[,,i]= as.matrix(ToyArray[,,1,i]) %*% as.matrix(ba[,,2,i]) %*% as.matrix(ba[,,3,i])
>  };

I'm pretty sure you can drop the as.matrix() calls since ToyArray[,,1,i] and ba[,,2,i] will be matrices. Look at the documentation for  ?"[" and pay attention to the "drop" argument (or look at ?drop since it is an R function). That should provide some increase in speed.

> ToyArray[,,1,2]
     [,1] [,2]
[1,]    1    1
[2,]    1    1


> 
> Can I do better? Can I vectorize this over the user dimension?

I don't know. I would guess "not" since none of the help pages for array or ?matmult or the ones linking from it suggested that "%*%" should operate on arrays. (I would have tested my half-baked ideas if you had provided a reproducible example of 'ba'.)

> 
> 
> And even better (and a different question): what strategy can I use if the matrices are not all of the same  size?


This question is unclear to me. Sorry. It's lacking in details and example. (And I apologize if there is a duplicate of this that explains why smarter people than I have not already addressed it.)

-- 
David Winsemius
Alameda, CA, USA


From joao_quariguasi at hotmail.com  Wed Jun 19 15:17:32 2013
From: joao_quariguasi at hotmail.com (Joao Quariguasi)
Date: Wed, 19 Jun 2013 14:17:32 +0100
Subject: [R] sum epsilon-regression only works with certain epsilon values
Message-ID: <BLU0-SMTP2928D8BF30DD89EE07C545C8C8D0@phx.gbl>

Hello,

I am trying to run the following piece of command:

svm.linear<-svm(price~., subset = generation >0, data = trainset, cost = C, epsilon = 1, type = 'eps-regression')

If epsilon = 1, the program runs fine. For larger values, e.g. 10, I get the following error:

Error in predict.svm(ret, xhold, decision.values = TRUE) : 
  Model is empty!
Calls: RegressionAnalyses ... svm.formula -> svm.default -> na.action -> predict -> predict.svm
Execution halted

My impression is that sum.linear is returning empty. I initially believed that it could be coursed by an infeasible solution, but I think now that this may not be the case as we allow 
for slacks in both constraints, i.e. xi. Can someone help me here? 

I am a little stuck. 

(btw, C=300)


From beperron at umich.edu  Wed Jun 19 15:24:50 2013
From: beperron at umich.edu (Brian Perron)
Date: Wed, 19 Jun 2013 09:24:50 -0400
Subject: [R] alternative to ifelse
Message-ID: <CADB2ZiTDKkAHjawnZi4pdfFZ1JYwWfQYUvUVs-nE2KZaBTUxDA@mail.gmail.com>

Greetings:

I am looking for a way to avoid using the ifelse function for
constructing a new variable.  More specifically, assume I have a set
of variables with scores ranging from 1 to 30.

set.seed(12345)
x <- c(1:30)
x1 <- sample(x, 15, replace = TRUE)
x2 <- sample(x, 15, replace = TRUE)
x3 <- sample(x, 15, replace = TRUE)
x4 <- sample(x, 15, replace = TRUE)

I want to construct a dichotomous variable that tests whether any of
the variables contains the value 1.

newVar <-ifelse(x1 == 1 | x2 == 1 | x3 == 1 | x4 == 1, 1, 0)

I want to avoid the ifelse function because I have a number of large
variable lists that will require new variables to be created.  I'm
sure there is a simple way to do this, but I haven't had any luck with
my search!

Thanks in advance.

Brian


From bsr505 at gmail.com  Wed Jun 19 17:44:32 2013
From: bsr505 at gmail.com (Bruce Rawlings)
Date: Wed, 19 Jun 2013 16:44:32 +0100
Subject: [R] GLMM predictor variables
Message-ID: <CAGY2N4swj1GuTMtHYRKHjc4Fc+x7nyDuzeaxoj4L=B2iEgXZMw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130619/e074e3ee/attachment.pl>

From pkount at bgc-jena.mpg.de  Wed Jun 19 17:45:29 2013
From: pkount at bgc-jena.mpg.de (pakoun)
Date: Wed, 19 Jun 2013 08:45:29 -0700 (PDT)
Subject: [R] nls singular gradient ..as always..
In-Reply-To: <CAN5YmCFqNezNAj1YqeD7+pOJ9kthzPMbLuugNJUGAfi1Jdd=4Q@mail.gmail.com>
References: <1371641309773-4669859.post@n4.nabble.com>
	<CAN5YmCFqNezNAj1YqeD7+pOJ9kthzPMbLuugNJUGAfi1Jdd=4Q@mail.gmail.com>
Message-ID: <1371656729569-4669898.post@n4.nabble.com>

Yes it should look like that... what i am doing is a variogram fit . But the
data of course are spread almost all over.. I would guess might be problem
with the data only? 



--
View this message in context: http://r.789695.n4.nabble.com/nls-singular-gradient-as-always-tp4669859p4669898.html
Sent from the R help mailing list archive at Nabble.com.


From xie at yihui.name  Wed Jun 19 20:07:52 2013
From: xie at yihui.name (Yihui Xie)
Date: Wed, 19 Jun 2013 11:07:52 -0700
Subject: [R] knitr without R studio
In-Reply-To: <CA+vqiLF2Wp1MSSSXKhe2aRLdoZ37UaECgNknWw7c=u84F2MQcQ@mail.gmail.com>
References: <1371628429300-4669841.post@n4.nabble.com>
	<CA+vqiLF2Wp1MSSSXKhe2aRLdoZ37UaECgNknWw7c=u84F2MQcQ@mail.gmail.com>
Message-ID: <CANROs4feHEqRmh6bd29a_vuPNK=f6+cWLVB9Gb9WsaLFzTw4RQ@mail.gmail.com>

knitr is not tied to RStudio, and I believe this StackOverflow post
can answer your question: http://stackoverflow.com/q/10646665/559676

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 206-667-4385 Web: http://yihui.name
Fred Hutchinson Cancer Research Center, Seattle


On Wed, Jun 19, 2013 at 4:42 AM, Ista Zahn <istazahn at gmail.com> wrote:
> Hi Alex,
>
> Have you read the ?knit or ?knit2html documentation? I don't believe
> there is a kit2HTML function (notice the uppercase), and the input
> should be the path to a file. Please do read the documentation.
>
> Best,
> Ista
>
> On Wed, Jun 19, 2013 at 3:53 AM, AlexPiche
> <alexandre.piche at mail.mcgill.ca> wrote:
>> Hello folks,
>>
>> I`m using knitr on R studio, which make it easy to use, but a coworker of
>> mine would like to run it on "simple" R. So I was wondering if you know what
>> is the equivalent of  the button "knit HTML" in RStudio in R. I tried
>>
>>
>> knit2HTML(
>>
>> <html>
>> <head>
>>   <title></title>
>> </head>
>> <body style="background-color:white">
>>
>>
>>
>>
>>   <p style="font-size:16px; text-align:center">
>> Graph 1 <#location1>      Graph 2 <#location2>
>>   </p>
>>
>> ```{r table1, comment=NA, results='asis'}
>> library(xtable)
>> data(iris)
>> print(xtable(head(iris, 10)), type = "html", include.rownames = T)
>> ```
>>
>>
>>
>> ```{r, include=FALSE}
>>
>>
>> opts_knit$set(progress = TRUE, verbose = TRUE)
>> opts_chunk$set(fig.width=20, fig.height=12)
>> knit_hooks$set(fig.bg = function(before, options, envir) {
>>   if (before) par(bg = options$fig.bg)
>> })
>>
>> ```
>>
>>
>>
>>
>>
>>
>> ```{r graphs,fig.keep=?last?}
>> for (x in 1:10) plot(rnorm(100), col = x)
>> ```
>>
>>
>>
>>
>> ```{r graph1}
>>
>> plot(rnorm(500), type="lines", main="Graph1")
>> ```
>>   Top of the Page <#top>
>>
>>
>>
>>
>>
>> ```{r graph2}
>>
>>
>> plot(rpois(500,3), type="lines", main="Graph2")
>>
>> ```
>>
>> Top of the Page <#top>
>>
>>
>>
>>
>>
>> </body>
>> </html>
>> )
>>
>>
>> But R keep sending me error message, any clue?
>>
>> Regards,
>>
>> Alex


From rmh at temple.edu  Wed Jun 19 20:12:51 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 19 Jun 2013 14:12:51 -0400
Subject: [R] alternative to ifelse
In-Reply-To: <CADB2ZiTDKkAHjawnZi4pdfFZ1JYwWfQYUvUVs-nE2KZaBTUxDA@mail.gmail.com>
References: <CADB2ZiTDKkAHjawnZi4pdfFZ1JYwWfQYUvUVs-nE2KZaBTUxDA@mail.gmail.com>
Message-ID: <CAGx1TMDzV6k0fmur=wAUtUpvGst+nCHdZOYqZX4T-r7D63+G0A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130619/622f2472/attachment.pl>

From jvadams at usgs.gov  Wed Jun 19 20:17:29 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 19 Jun 2013 13:17:29 -0500
Subject: [R] nls singular gradient ..as always..
In-Reply-To: <1371656729569-4669898.post@n4.nabble.com>
References: <1371641309773-4669859.post@n4.nabble.com>
	<CAN5YmCFqNezNAj1YqeD7+pOJ9kthzPMbLuugNJUGAfi1Jdd=4Q@mail.gmail.com>
	<1371656729569-4669898.post@n4.nabble.com>
Message-ID: <CAN5YmCEF9Ut5J-Zqh6URYOn0bfH=M=cUGMgDmtzy9OwWkrw24A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130619/1ed374fc/attachment.pl>

From es at enricoschumann.net  Wed Jun 19 20:20:40 2013
From: es at enricoschumann.net (Enrico Schumann)
Date: Wed, 19 Jun 2013 20:20:40 +0200
Subject: [R] alternative to ifelse
In-Reply-To: <CADB2ZiTDKkAHjawnZi4pdfFZ1JYwWfQYUvUVs-nE2KZaBTUxDA@mail.gmail.com>
	(Brian Perron's message of "Wed, 19 Jun 2013 09:24:50 -0400")
References: <CADB2ZiTDKkAHjawnZi4pdfFZ1JYwWfQYUvUVs-nE2KZaBTUxDA@mail.gmail.com>
Message-ID: <8761xa9d3b.fsf@enricoschumann.net>

On Wed, 19 Jun 2013, Brian Perron <beperron at umich.edu> writes:

> Greetings:
>
> I am looking for a way to avoid using the ifelse function for
> constructing a new variable.  More specifically, assume I have a set
> of variables with scores ranging from 1 to 30.
>
> set.seed(12345)
> x <- c(1:30)
> x1 <- sample(x, 15, replace = TRUE)
> x2 <- sample(x, 15, replace = TRUE)
> x3 <- sample(x, 15, replace = TRUE)
> x4 <- sample(x, 15, replace = TRUE)
>
> I want to construct a dichotomous variable that tests whether any of
> the variables contains the value 1.
>
> newVar <-ifelse(x1 == 1 | x2 == 1 | x3 == 1 | x4 == 1, 1, 0)
>
> I want to avoid the ifelse function because I have a number of large
> variable lists that will require new variables to be created.  I'm
> sure there is a simple way to do this, but I haven't had any luck with
> my search!
>
> Thanks in advance.
>
> Brian
>

Hi Brian,

put all your x into a matrix and use apply:

  X <- cbind(x1, x2, x3, x4)
  apply(X, 1, function(x) if (any(x == 1L)) 1 else 0)

  ## [1] 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0

or, since TRUE and FALSE evaluate to 1 and 0 when coerced to numeric:

  as.integer(apply(X, 1, function(x) any(x == 1L)))

  ## [1] 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0



Regards,
        Enrico       

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From marc_schwartz at me.com  Wed Jun 19 20:21:53 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 19 Jun 2013 13:21:53 -0500
Subject: [R] alternative to ifelse
In-Reply-To: <CADB2ZiTDKkAHjawnZi4pdfFZ1JYwWfQYUvUVs-nE2KZaBTUxDA@mail.gmail.com>
References: <CADB2ZiTDKkAHjawnZi4pdfFZ1JYwWfQYUvUVs-nE2KZaBTUxDA@mail.gmail.com>
Message-ID: <0F818937-F09E-4236-AAFE-0AFB7E9B3F4F@me.com>


On Jun 19, 2013, at 8:24 AM, Brian Perron <beperron at umich.edu> wrote:

> Greetings:
> 
> I am looking for a way to avoid using the ifelse function for
> constructing a new variable.  More specifically, assume I have a set
> of variables with scores ranging from 1 to 30.
> 
> set.seed(12345)
> x <- c(1:30)
> x1 <- sample(x, 15, replace = TRUE)
> x2 <- sample(x, 15, replace = TRUE)
> x3 <- sample(x, 15, replace = TRUE)
> x4 <- sample(x, 15, replace = TRUE)
> 
> I want to construct a dichotomous variable that tests whether any of
> the variables contains the value 1.
> 
> newVar <-ifelse(x1 == 1 | x2 == 1 | x3 == 1 | x4 == 1, 1, 0)
> 
> I want to avoid the ifelse function because I have a number of large
> variable lists that will require new variables to be created.  I'm
> sure there is a simple way to do this, but I haven't had any luck with
> my search!
> 
> Thanks in advance.
> 
> Brian



If each of the vectors will be of the same length, create a matrix that contains each one as a column:

set.seed(12345)
x <- c(1:30)
x1 <- sample(x, 15, replace = TRUE)
x2 <- sample(x, 15, replace = TRUE)
x3 <- sample(x, 15, replace = TRUE)
x4 <- sample(x, 15, replace = TRUE)

> cbind(x1, x2, x3, x4)
      x1 x2 x3 x4
 [1,] 22 14 24 10
 [2,] 27 12  1  2
 [3,] 23 13  6  2
 [4,] 27  6 21  2
 [5,] 14 29 12 19
 [6,]  5 14 11 29
 [7,] 10 10 27 25
 [8,] 16 29 28 10
 [9,] 22 22 19  7
[10,] 30 20  5 22
[11,]  2 12 24 15
[12,]  5 21 13 22
[13,] 23 17 28  3
[14,]  1  7 24 14
[15,] 12 15  8  8


Then you can use:

> rowSums(cbind(x1, x2, x3, x4) == 1)
 [1] 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0


which gets you the same result as:

> ifelse(x1 == 1 | x2 == 1 | x3 == 1 | x4 == 1, 1, 0)
 [1] 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0


Regards,

Marc Schwartz


From marc_schwartz at me.com  Wed Jun 19 20:23:30 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 19 Jun 2013 13:23:30 -0500
Subject: [R] alternative to ifelse
In-Reply-To: <CADB2ZiTDKkAHjawnZi4pdfFZ1JYwWfQYUvUVs-nE2KZaBTUxDA@mail.gmail.com>
References: <CADB2ZiTDKkAHjawnZi4pdfFZ1JYwWfQYUvUVs-nE2KZaBTUxDA@mail.gmail.com>
Message-ID: <14218DBF-7852-4FC9-86DD-ECA89EBAF7B7@me.com>


On Jun 19, 2013, at 8:24 AM, Brian Perron <beperron at umich.edu> wrote:

> Greetings:
> 
> I am looking for a way to avoid using the ifelse function for
> constructing a new variable.  More specifically, assume I have a set
> of variables with scores ranging from 1 to 30.
> 
> set.seed(12345)
> x <- c(1:30)
> x1 <- sample(x, 15, replace = TRUE)
> x2 <- sample(x, 15, replace = TRUE)
> x3 <- sample(x, 15, replace = TRUE)
> x4 <- sample(x, 15, replace = TRUE)
> 
> I want to construct a dichotomous variable that tests whether any of
> the variables contains the value 1.
> 
> newVar <-ifelse(x1 == 1 | x2 == 1 | x3 == 1 | x4 == 1, 1, 0)
> 
> I want to avoid the ifelse function because I have a number of large
> variable lists that will require new variables to be created.  I'm
> sure there is a simple way to do this, but I haven't had any luck with
> my search!
> 
> Thanks in advance.
> 
> Brian



If each of the vectors will be of the same length, create a matrix that contains each one as a column:

set.seed(12345)
x <- c(1:30)
x1 <- sample(x, 15, replace = TRUE)
x2 <- sample(x, 15, replace = TRUE)
x3 <- sample(x, 15, replace = TRUE)
x4 <- sample(x, 15, replace = TRUE)

> cbind(x1, x2, x3, x4)
     x1 x2 x3 x4
[1,] 22 14 24 10
[2,] 27 12  1  2
[3,] 23 13  6  2
[4,] 27  6 21  2
[5,] 14 29 12 19
[6,]  5 14 11 29
[7,] 10 10 27 25
[8,] 16 29 28 10
[9,] 22 22 19  7
[10,] 30 20  5 22
[11,]  2 12 24 15
[12,]  5 21 13 22
[13,] 23 17 28  3
[14,]  1  7 24 14
[15,] 12 15  8  8


Then you can use:

> rowSums(cbind(x1, x2, x3, x4) == 1)
[1] 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0


which gets you the same result as:

> ifelse(x1 == 1 | x2 == 1 | x3 == 1 | x4 == 1, 1, 0)
[1] 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0


Regards,

Marc Schwartz


From marc_schwartz at me.com  Wed Jun 19 20:47:07 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 19 Jun 2013 13:47:07 -0500
Subject: [R] alternative to ifelse
In-Reply-To: <14218DBF-7852-4FC9-86DD-ECA89EBAF7B7@me.com>
References: <CADB2ZiTDKkAHjawnZi4pdfFZ1JYwWfQYUvUVs-nE2KZaBTUxDA@mail.gmail.com>
	<14218DBF-7852-4FC9-86DD-ECA89EBAF7B7@me.com>
Message-ID: <A4D4ADD8-353D-4E64-8E5F-3BDA68B7E88D@me.com>


On Jun 19, 2013, at 1:23 PM, Marc Schwartz <marc_schwartz at me.com> wrote:

> 
> On Jun 19, 2013, at 8:24 AM, Brian Perron <beperron at umich.edu> wrote:
> 
>> Greetings:
>> 
>> I am looking for a way to avoid using the ifelse function for
>> constructing a new variable.  More specifically, assume I have a set
>> of variables with scores ranging from 1 to 30.
>> 
>> set.seed(12345)
>> x <- c(1:30)
>> x1 <- sample(x, 15, replace = TRUE)
>> x2 <- sample(x, 15, replace = TRUE)
>> x3 <- sample(x, 15, replace = TRUE)
>> x4 <- sample(x, 15, replace = TRUE)
>> 
>> I want to construct a dichotomous variable that tests whether any of
>> the variables contains the value 1.
>> 
>> newVar <-ifelse(x1 == 1 | x2 == 1 | x3 == 1 | x4 == 1, 1, 0)
>> 
>> I want to avoid the ifelse function because I have a number of large
>> variable lists that will require new variables to be created.  I'm
>> sure there is a simple way to do this, but I haven't had any luck with
>> my search!
>> 
>> Thanks in advance.
>> 
>> Brian
> 
> 
> 
> If each of the vectors will be of the same length, create a matrix that contains each one as a column:
> 
> set.seed(12345)
> x <- c(1:30)
> x1 <- sample(x, 15, replace = TRUE)
> x2 <- sample(x, 15, replace = TRUE)
> x3 <- sample(x, 15, replace = TRUE)
> x4 <- sample(x, 15, replace = TRUE)
> 
>> cbind(x1, x2, x3, x4)
>    x1 x2 x3 x4
> [1,] 22 14 24 10
> [2,] 27 12  1  2
> [3,] 23 13  6  2
> [4,] 27  6 21  2
> [5,] 14 29 12 19
> [6,]  5 14 11 29
> [7,] 10 10 27 25
> [8,] 16 29 28 10
> [9,] 22 22 19  7
> [10,] 30 20  5 22
> [11,]  2 12 24 15
> [12,]  5 21 13 22
> [13,] 23 17 28  3
> [14,]  1  7 24 14
> [15,] 12 15  8  8
> 
> 
> Then you can use:
> 
>> rowSums(cbind(x1, x2, x3, x4) == 1)
> [1] 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0
> 
> 
> which gets you the same result as:
> 
>> ifelse(x1 == 1 | x2 == 1 | x3 == 1 | x4 == 1, 1, 0)
> [1] 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0


Actually, correction. That works in the case where only one of the values in the row is a 1, which happened to fit the example data. If there is a chance that more than one value in a row may be a 1, it returns a value equal to the number of 1's found.

Thus, a more generic approach, I believe, would be:

> sign(rowSums(cbind(x1, x2, x3, x4) == 1))
[1] 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0


Regards,

Marc


From marc_schwartz at me.com  Wed Jun 19 20:47:38 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 19 Jun 2013 13:47:38 -0500
Subject: [R] alternative to ifelse
In-Reply-To: <14218DBF-7852-4FC9-86DD-ECA89EBAF7B7@me.com>
References: <CADB2ZiTDKkAHjawnZi4pdfFZ1JYwWfQYUvUVs-nE2KZaBTUxDA@mail.gmail.com>
	<14218DBF-7852-4FC9-86DD-ECA89EBAF7B7@me.com>
Message-ID: <4453C662-35C1-4549-AECF-3757B41E63C6@me.com>


On Jun 19, 2013, at 1:23 PM, Marc Schwartz <marc_schwartz at me.com> wrote:

> 
> On Jun 19, 2013, at 8:24 AM, Brian Perron <beperron at umich.edu> wrote:
> 
>> Greetings:
>> 
>> I am looking for a way to avoid using the ifelse function for
>> constructing a new variable.  More specifically, assume I have a set
>> of variables with scores ranging from 1 to 30.
>> 
>> set.seed(12345)
>> x <- c(1:30)
>> x1 <- sample(x, 15, replace = TRUE)
>> x2 <- sample(x, 15, replace = TRUE)
>> x3 <- sample(x, 15, replace = TRUE)
>> x4 <- sample(x, 15, replace = TRUE)
>> 
>> I want to construct a dichotomous variable that tests whether any of
>> the variables contains the value 1.
>> 
>> newVar <-ifelse(x1 == 1 | x2 == 1 | x3 == 1 | x4 == 1, 1, 0)
>> 
>> I want to avoid the ifelse function because I have a number of large
>> variable lists that will require new variables to be created.  I'm
>> sure there is a simple way to do this, but I haven't had any luck with
>> my search!
>> 
>> Thanks in advance.
>> 
>> Brian
> 
> 
> 
> If each of the vectors will be of the same length, create a matrix that contains each one as a column:
> 
> set.seed(12345)
> x <- c(1:30)
> x1 <- sample(x, 15, replace = TRUE)
> x2 <- sample(x, 15, replace = TRUE)
> x3 <- sample(x, 15, replace = TRUE)
> x4 <- sample(x, 15, replace = TRUE)
> 
>> cbind(x1, x2, x3, x4)
>   x1 x2 x3 x4
> [1,] 22 14 24 10
> [2,] 27 12  1  2
> [3,] 23 13  6  2
> [4,] 27  6 21  2
> [5,] 14 29 12 19
> [6,]  5 14 11 29
> [7,] 10 10 27 25
> [8,] 16 29 28 10
> [9,] 22 22 19  7
> [10,] 30 20  5 22
> [11,]  2 12 24 15
> [12,]  5 21 13 22
> [13,] 23 17 28  3
> [14,]  1  7 24 14
> [15,] 12 15  8  8
> 
> 
> Then you can use:
> 
>> rowSums(cbind(x1, x2, x3, x4) == 1)
> [1] 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0
> 
> 
> which gets you the same result as:
> 
>> ifelse(x1 == 1 | x2 == 1 | x3 == 1 | x4 == 1, 1, 0)
> [1] 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0


Actually, correction. That works in the case where only one of the values in the row is a 1, which happened to fit the example data. If there is a chance that more than one value in a row may be a 1, it returns a value equal to the number of 1's found.

Thus, a more generic approach, I believe, would be:

> sign(rowSums(cbind(x1, x2, x3, x4) == 1))
[1] 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0


Regards,

Marc


From smartpink111 at yahoo.com  Wed Jun 19 21:14:57 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 19 Jun 2013 12:14:57 -0700 (PDT)
Subject: [R] alternative to ifelse
In-Reply-To: <CADB2ZiTDKkAHjawnZi4pdfFZ1JYwWfQYUvUVs-nE2KZaBTUxDA@mail.gmail.com>
References: <CADB2ZiTDKkAHjawnZi4pdfFZ1JYwWfQYUvUVs-nE2KZaBTUxDA@mail.gmail.com>
Message-ID: <1371669297.97825.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
May bet this also helps:
set.seed(12345)
x <- c(1:30)
x1 <- sample(x, 15, replace = TRUE)
x2 <- sample(x, 15, replace = TRUE)
x3 <- sample(x, 15, replace = TRUE)
x4 <- sample(x, 15, replace = TRUE)

indx<-1+2*(x1==1)+4*(x2==1)+8*(x3==1)+16*(x4==1)
?as.numeric(indx!=1)
#[1] 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0


#Speed comparisons 
set.seed(1235)
x <- c(1:1e7)
x1 <- sample(x, 1e7, replace = TRUE)
x2 <- sample(x, 1e7, replace = TRUE)
x3 <- sample(x, 1e7, replace = TRUE)
x4 <- sample(x, 1e7, replace = TRUE)

system.time(res1 <-ifelse(x1 == 1 | x2 == 1 | x3 == 1 | x4 == 1, 1, 0))
?# user? system elapsed 
?# 3.740?? 0.256?? 4.003 

system.time(res2<-as.numeric(x1 == 1 | x2 == 1 | x3 == 1 | x4 == 1))
# user? system elapsed 
#? 0.996?? 0.076?? 1.077 

system.time({indx<-1+2*(x1==1)+4*(x2==1)+8*(x3==1)+16*(x4==1)
?res3<-as.numeric(indx!=1)})
# user? system elapsed 
#? 0.596?? 0.240?? 0.840 

system.time(res4<-rowSums(cbind(x1, x2, x3, x4) == 1))
# user? system elapsed 
#? 0.732?? 0.192?? 0.926 
?
system.time(res4New<-sign(rowSums(cbind(x1, x2, x3, x4) == 1)))
?# user? system elapsed 
?# 0.824?? 0.232?? 1.062 

X <- cbind(x1, x2, x3, x4)
system.time({ 
res5<-as.integer(apply(X, 1, function(x) any(x == 1L)))})
?# user? system elapsed 
#113.308?? 0.208 113.729 

system.time(res6<-apply(X, 1, function(x) if (any(x == 1L)) 1 else 0))
?#user? system elapsed 
# 61.660?? 0.216? 61.989 

identical(res1,res6)
#[1] TRUE

identical(res1,res2)
#[1] TRUE
?identical(res1,res3)
#[1] TRUE

identical(res1,res4)
#[1] TRUE
?identical(res1,res4New)
#[1] TRUE
A.K.



----- Original Message -----
From: Brian Perron <beperron at umich.edu>
To: r-help at r-project.org
Cc: 
Sent: Wednesday, June 19, 2013 9:24 AM
Subject: [R] alternative to ifelse

Greetings:

I am looking for a way to avoid using the ifelse function for
constructing a new variable.? More specifically, assume I have a set
of variables with scores ranging from 1 to 30.

set.seed(12345)
x <- c(1:30)
x1 <- sample(x, 15, replace = TRUE)
x2 <- sample(x, 15, replace = TRUE)
x3 <- sample(x, 15, replace = TRUE)
x4 <- sample(x, 15, replace = TRUE)

I want to construct a dichotomous variable that tests whether any of
the variables contains the value 1.

newVar <-ifelse(x1 == 1 | x2 == 1 | x3 == 1 | x4 == 1, 1, 0)

I want to avoid the ifelse function because I have a number of large
variable lists that will require new variables to be created.? I'm
sure there is a simple way to do this, but I haven't had any luck with
my search!

Thanks in advance.

Brian

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Wed Jun 19 22:46:27 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 19 Jun 2013 13:46:27 -0700 (PDT)
Subject: [R] help with text patterns in strings
In-Reply-To: <559C998F7039D84C9793AE43D9BBE9CE77A0FF5C@kmbx3.utk.tennessee.edu>
References: <1371491993351-4669714.post@n4.nabble.com>
	<1371496520.95656.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<559C998F7039D84C9793AE43D9BBE9CE77A0FC69@kmbx3.utk.tennessee.edu>
	<1371501469.76400.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<559C998F7039D84C9793AE43D9BBE9CE77A0FCA0@kmbx3.utk.tennessee.edu>
	<1371502465.96019.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<559C998F7039D84C9793AE43D9BBE9CE77A0FF5C@kmbx3.utk.tennessee.edu>
Message-ID: <1371674787.56731.YahooMailNeo@web142601.mail.bf1.yahoo.com>

HI Burnette,
As this is continuation of the earlier thread, you could post it on the same thread by cc: to rhelp.


Try this:
res1<-sapply(vec3,function(x) length(vec2New[grep(x,vec2New)]) )
dat1<-data.frame(res1,Name=names(vec3))

?dat1$Name<-factor(dat1$Name,levels=c("early","mid","late","wknd"))
?with(dat1,tapply(res1,list(Name),FUN=sum))
#early?? mid? late? wknd 
?# ? 0???? 1???? 4???? 6 

#or
?sapply(split(res1,names(vec3)),sum)
#early? late?? mid? wknd 
?# ? 0???? 4???? 1???? 6 
A.K.

----- Original Message -----
From: "Crombie, Burnette N" <bcrombie at utk.edu>
To: arun <smartpink111 at yahoo.com>
Cc: 
Sent: Wednesday, June 19, 2013 3:55 PM
Subject: RE: [R] help with text patterns in strings

Arun, let me know if I should post this email separately, but it involves the script from our previous conversation.? I've been messing around as I think of potential scenarios with my data and am unclear how I can recount vec3 after assigning range names to the different days of the week.? For this example, I want my output to go from:
#Su? M Tu? W Th? F Sa
# 2? ? 0?  0? ?  1?  1? ? 3? 4
to:
# early?  mid?  late?  wknd
#?  0? ? ? ? ? 1? ? ? ? ? 4? ? ? ? ? 6

Thanks for your help throughout, but, again, let me know if I should start a new thread.

Burnette

##########################################
Begin script
##########################################
dat3<- read.csv("~/Rburnette/TextStringMatch.csv", stringsAsFactors=FALSE)
dat3
#respondent.ID? ? ? ? ? ? response
# 1? ? ? ? ? ? ? ? ? ? ?  Friday
# 2? ? ? ? ? ? ? ? ? ? ?  Wednesday
# 3? ? ? ? ? ? ? ? ? ? ?  Friday, saturday,Sunday
# 4? ? ? ? ? ? ? ? ? ? ?  Saturday
# 5? ? ? ? ? ? ? ? ? ? ?  Sat, sun
# 6? ? ? ? ? ? ? ? ? ? ?  Th,F, Sa

# Rename the variable ?response? to ?Ans? to fit the script that?s already been written
# fix(dat3) can be used to do this manually, but then you need to keep "dat3" as the data frame, not "dat3edit"
# if not familiar, fix() generates a popup window like a spreadsheet that can be edited, and character vs numeric property can be changed
# the data set being ?fixed? is saved automatically upon closing, but I think only within the current R session
# I think you need to redefine the fix() as a new object to keep the changes outside the R session? (need to test this)
##########################################
library(gdata)
dat3edit <- rename.vars(dat3,from="response", to="Ans")
dat3edit
#respondent.ID? ? ? ? ? ? Ans
# 1? ? ? ? ? ? ? ? ? ? ?  Friday
# 2? ? ? ? ? ? ? ? ? ? ?  Wednesday
# 3? ? ? ? ? ? ? ? ? ? ?  Friday, saturday,Sunday
# 4? ? ? ? ? ? ? ? ? ? ?  Saturday
# 5? ? ? ? ? ? ? ? ? ? ?  Sat, sun
# 6? ? ? ? ? ? ? ? ? ? ?  Th,F, Sa

# get rid of the spaces embedded in text strings
##########################################
dat3edit$Ans2 <- gsub(" ","",dat3edit$Ans)
dat3edit$Ans2
# [1] "Friday"? ? ? ? ? ? ? ?  "Wednesday"? ? ? ? ? ? ? "Friday,saturday,Sunday" "Saturday"? ? ? ? ? ? ? 
# [5] "Sat,sun"? ? ? ? ? ? ? ? "Th,F,Sa" 

# split up multiple responses within an observation so they can be counted separately
##########################################
vec2<-unlist(strsplit(dat3edit$Ans2,","))
vec2
# [1] "Friday"? ? "Wednesday" "Friday"? ? "saturday"? "Sunday"? ? "Saturday"? "Sat"? ? ?  "sun"? ? ? 
# [9] "Th"? ? ? ? "F"? ? ? ?  "Sa" 

#consistently format all (split up) responses to start with a capital letter for more accurate matching to a ?universal? response code created in the next step
##########################################
library(Hmisc)
vec2New<-capitalize(vec2)
vec2New
# [1] "Friday"? ? "Wednesday" "Friday"? ? "Saturday"? "Sunday"? ? "Saturday"? "Sat"? ? ?  "Sun"? ? ? 
# [9] "Th"? ? ? ? "F"? ? ? ?  "Sa"

#match capitalized data to a ?universal? response code of choice
##########################################
vec3<- c("Su","M","Tu","W","Th","F","Sa")
sapply(vec3,function(x) length(vec2New[grep(x,vec2New)]) )
#Su? M Tu? W Th? F Sa
# 2? 0? 0? 1? 1? 3? 4

#assign range names to vec3
##########################################
names(vec3) <- c("wknd","early","early","mid","late","late","wknd")
vec3
# wknd early early?  mid? late? late? wknd 
# "Su"?  "M"? "Tu"?  "W"? "Th"?  "F"? "Sa"


From xie at yihui.name  Wed Jun 19 23:31:41 2013
From: xie at yihui.name (Yihui Xie)
Date: Wed, 19 Jun 2013 14:31:41 -0700
Subject: [R] knitr: side-by-side figures in R markdown
In-Reply-To: <51C1B0CF.3080702@yorku.ca>
References: <51C1B0CF.3080702@yorku.ca>
Message-ID: <CANROs4fTuK=up_w0vohsXxQ6+WKtqMD=kpnvMiL38qQ64zF6uA@mail.gmail.com>

You need to remove out.extra='style="display:block; margin: auto"'. In
CSS, display:block; means this element stands in its own line, and no
other elements can sit by its side. This is applied to individual
images, so the two images will not be arranged side by side.

But you will lose the center alignment without display:block. The
difficulty comes from the fact that Markdown images are not put into
div containers as in HTML.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 206-667-4385 Web: http://yihui.name
Fred Hutchinson Cancer Research Center, Seattle


On Wed, Jun 19, 2013 at 6:23 AM, Michael Friendly <friendly at yorku.ca> wrote:
> I've read all the docs on knitr and some blogs on this topic, but can't
> figure out how
> to produce side-by-side figures in R markdown, except by composing a single
> figure
> in R with par(mfrow=c(1,2)).
> I know this can be done easily with the LaTeX engine, but why not with HTML
> output?
>
> A small test file is below.  If I were composing HTML directly, I would just
> wrap the images
> in a table, e.g.,
>
> <table>
> <tr><td><img src="fig1.png"></td>
>     <td><img src="fig2.png"></td>
> </tr>
> </table>
>
> Is there someway to achieve this with knitr, perhaps a chunk hook?
>
> --- test-figs.Rmd -----
> Testing side-by-side figs
> ==========================
>
> ```{r knitr-setup, include=FALSE}
> library(knitr)
> library(vcd)
> opts_chunk$set(out.extra='style="display:block; margin: auto"',
> fig.align="center", fig.width=4, fig.height=4)
> opts_knit$set(progress = FALSE, verbose = TRUE)
> ```
>
> This doesn't do what I want:
> ```{r chunck1, fig.show='hold'}
> plot(1:10)
> plot(10:1)
> ```
>
> This does:
> ```{r chunck2, fig.show='hold', fig.width=8}
> op <- par(mfrow=c(1,2))
> plot(1:10)
> plot(10:1)
> par(op)
> ```
>
> What to do with grid-based graphics (requires messing with viewports):
>
> ```{r chunck3, fig.width=6}
> data(Titanic, package="datasets")
> mosaic(Titanic)
> mosaic(Titanic, shade=TRUE)
> ```
>
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Wed Jun 19 23:49:10 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 19 Jun 2013 14:49:10 -0700
Subject: [R] GLMM predictor variables
In-Reply-To: <CAGY2N4swj1GuTMtHYRKHjc4Fc+x7nyDuzeaxoj4L=B2iEgXZMw@mail.gmail.com>
References: <CAGY2N4swj1GuTMtHYRKHjc4Fc+x7nyDuzeaxoj4L=B2iEgXZMw@mail.gmail.com>
Message-ID: <CACk-te15JQ8PPNszeR=Pgg7BjqUKrR61WLpYzAY-ngbDO0NSWw@mail.gmail.com>

Wrong list -- Your question is not about R.

Post on a statistics list like stats.stackexchange.com
-- or better yet, consult a local statistician for guidance.

Cheers,
Bert

On Wed, Jun 19, 2013 at 8:44 AM, Bruce Rawlings <bsr505 at gmail.com> wrote:
> Hi all,
>
> I have a quick question regarding predictor variables in a GLMM analysis, a
> subject I am new to.
>
> I am running a study investigating multi-modal communication in primates.
> specifically, primate gestures that accompany vocalizations.
>
> I have measured the call rate, call duration and peak frequency (response
> variables)  for 200 calls (100 accompanied by gestures, 100 without
> gestures).
>
> I would like to use the following predictor variables: 1) Call type, 2)
> Presence of gesture, 3) Gesture type
>
> Is it possible to use  GESTURE TYPE here as a predictor variable? I am not
> sure if it's appropriate since this will only be for 50% of the overall
>  the data (where calls are accompanied by gestures).
>
> Any advice would be greatly appreciated.
>
> Bruce Rawlings
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From rolf.turner at xtra.co.nz  Thu Jun 20 00:16:24 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Thu, 20 Jun 2013 10:16:24 +1200
Subject: [R] how to get growth rate of a (time series) data?
In-Reply-To: <CAAmySGMbo3Hp2CA6UAXFko58UKdG_2s08fgOvORGosFgiKAf5Q@mail.gmail.com>
References: <CAHf4n+TMEj30C9qXgYSeJePMEmJaMDmhM__PDDx9tp5NytHqzA@mail.gmail.com>
	<CAAmySGMbo3Hp2CA6UAXFko58UKdG_2s08fgOvORGosFgiKAf5Q@mail.gmail.com>
Message-ID: <51C22DB8.3080208@xtra.co.nz>

On 19/06/13 23:24, R. Michael Weylandt wrote:
> On Wed, Jun 19, 2013 at 12:04 PM, Yanyuan Zhu <yyz at tongji.edu.cn> wrote:
>> Hello all, now I'm trying to switch from Excel to R to deal with the data,
>> and as a newbie i got the problem as follows.
>>
>> suppose I have a data named "test"
>> test<- data.frame(year=c(1996:2011),
>> Y=c(74163.6,81658.5,86531.6,91125.0,98749.0,109028.0,120475.6,136613.4,160956.6,187423.5,222712.5,266599.2,315974.6,348775.1,402816.5,465731.3))
>> in which Y means the GDP of a country
>>
>> If i want to get Delta Y = Y(t)-Y(t-1) , i could use diff() in R
>> diff(test$Y)
>>
>> but what if i want to get gY=(Y(t)-Y(t-1))/Y(t-1)?
>> seems diff(test$Y)/(test$Y)[-1] doesnt work ...
> Odd, I would have thought it did.
     <SNIP>

No, "clearly" ( :-) ) it doesn't.  It gives

(Y[2] - Y[1])/Y[2], (Y[3]-Y[2])/Y[3], .... when what is wanted is

(Y[2] - Y[1])/Y[1], (Y[3]-Y[2])/Y[2], ....

The OP needs to do:

     with(test,diff(Y)/Y[-length(Y)])

This is yet another illustration of the rule that if there is a 50-50 
chance of
getting things the wrong way around, then there is actually a probability
of one of getting things the wrong way around.

     cheers,

         Rolf


From thomas.parr at maine.edu  Thu Jun 20 02:16:02 2013
From: thomas.parr at maine.edu (Thomas Parr)
Date: Wed, 19 Jun 2013 20:16:02 -0400
Subject: [R] Returning name of dataframe?
Message-ID: <000f01ce6d4b$59f18ba0$0dd4a2e0$@maine.edu>

I am writing a function and I would like to return the name of a data frame
in a paste call, but I can't figure out how to just get the name. The names
of the data frames used, won't be the same each time.  I have to be
overlooking the obvious.

#For example:

a<-replicate(5, rnorm(20))
b<-replicate(5, rnorm(20))

xyz<-function(x,y){
  z<-x+y
  print(paste("the sum of", x, "and", y,"is", sep=" "))
  z 
}

xyz(a,b)

#That function should return:

>"the sum of a and b is:"
>.and some data.

Not surprisingly, it returns all the data in the data frame.

Thanks,
Thomas


From santosh2005 at gmail.com  Thu Jun 20 02:16:27 2013
From: santosh2005 at gmail.com (Santosh)
Date: Wed, 19 Jun 2013 17:16:27 -0700
Subject: [R] Trouble with SASxport in R.3.0. under 32-bit and 64-bit Windows
 (both 7 and Vista)
Message-ID: <CAN_e6XtytPg=A9YxA6v+8rdeCdBBE-QO+HcUyK+C3iWUcA11qw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130619/bc7e8bb0/attachment.pl>

From jholtman at gmail.com  Thu Jun 20 03:27:38 2013
From: jholtman at gmail.com (jim holtman)
Date: Wed, 19 Jun 2013 21:27:38 -0400
Subject: [R] Returning name of dataframe?
In-Reply-To: <000f01ce6d4b$59f18ba0$0dd4a2e0$@maine.edu>
References: <000f01ce6d4b$59f18ba0$0dd4a2e0$@maine.edu>
Message-ID: <CAAxdm-6OJJNZH67GhWwLM-xjUUqeXwpK9jEwz6Q=oW85ELBMEg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130619/ca9684e7/attachment.pl>

From smartpink111 at yahoo.com  Thu Jun 20 03:39:26 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 19 Jun 2013 18:39:26 -0700 (PDT)
Subject: [R] Returning name of dataframe?
In-Reply-To: <000f01ce6d4b$59f18ba0$0dd4a2e0$@maine.edu>
References: <000f01ce6d4b$59f18ba0$0dd4a2e0$@maine.edu>
Message-ID: <1371692366.18948.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
May be this helps:

xyz<-function(x,y){
? z<-x+y
? print(paste("the sum of", deparse(substitute(x)), "and", deparse(substitute(y)),"is", sep=" "))
? z
}

xyz(a,b)
[1] "the sum of a and b is"
???????????? [,1]??????? [,2]??????? [,3]??????? [,4]??????? [,5]
?[1,] -1.38805146 -1.15706888 -1.09420046? 1.64717323? 0.27514289
?[2,]? 0.22261237 -0.73175081? 1.68966845? 0.22596732 -1.17044669
?[3,]? 0.22500501 -0.75974026? 0.90409054 -1.45650109? 1.67901527
?[4,] -1.48843138 -1.94294190 -2.16271187? 0.63399385 -1.57638747
?[5,] -1.82516894 -3.99381921? 0.60723679? 1.29199176? 2.48361508
?[6,]? 1.17253015? 1.06681277 -0.92285478? 0.17471185 -2.15750294
?[7,] -0.07154138 -0.66920922? 1.05733601 -0.66156409 -1.40881929
?[8,]? 0.10070360 -0.92133842 -1.13318982 -0.55892454? 1.03856347
?[9,] -0.28225914 -1.24651183? 2.64215721 -2.95011897 -0.88959061
[10,] -0.71393462 -1.80015777 -0.07966670? 0.86487927 -0.02940905
[11,] -0.22453213 -0.78472943 -0.41515830? 0.09789192 -0.47531826
[12,] -1.30255845 -0.40284910 -1.60752283? 1.47922017? 1.93232550
[13,]? 1.18939368 -1.15079413? 0.93800266? 1.98916709 -0.10855782
[14,] -2.94616816 -1.95470339? 0.51466407 -1.54365972? 0.21532896
[15,] -1.18251544? 0.60247030 -0.27653274 -1.29190483? 2.16970664
[16,] -0.25704995? 0.03947102 -0.07675004 -0.19652487 -0.61109230
[17,] -1.67056007 -0.43978334? 0.46164805 -0.97022452 -0.92957787
[18,]? 0.34908174? 1.29140274 -0.69428669 -0.94739520? 0.67424984
[19,] -0.07291139? 0.14937308? 0.25048958 -0.21737017? 0.33106716
[20,]? 0.45590314? 1.78337639 -1.17198752 -0.59142492? 0.70282106
A.K.


----- Original Message -----
From: Thomas Parr <thomas.parr at maine.edu>
To: r-help at r-project.org
Cc: 
Sent: Wednesday, June 19, 2013 8:16 PM
Subject: [R] Returning name of dataframe?

I am writing a function and I would like to return the name of a data frame
in a paste call, but I can't figure out how to just get the name. The names
of the data frames used, won't be the same each time.? I have to be
overlooking the obvious.

#For example:

a<-replicate(5, rnorm(20))
b<-replicate(5, rnorm(20))

xyz<-function(x,y){
? z<-x+y
? print(paste("the sum of", x, "and", y,"is", sep=" "))
? z 
}

xyz(a,b)

#That function should return:

>"the sum of a and b is:"
>.and some data.

Not surprisingly, it returns all the data in the data frame.

Thanks,
Thomas

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From dwinsemius at comcast.net  Thu Jun 20 03:40:28 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 19 Jun 2013 18:40:28 -0700
Subject: [R] Returning name of dataframe?
In-Reply-To: <CAAxdm-6OJJNZH67GhWwLM-xjUUqeXwpK9jEwz6Q=oW85ELBMEg@mail.gmail.com>
References: <000f01ce6d4b$59f18ba0$0dd4a2e0$@maine.edu>
	<CAAxdm-6OJJNZH67GhWwLM-xjUUqeXwpK9jEwz6Q=oW85ELBMEg@mail.gmail.com>
Message-ID: <FB9846B6-5592-4B99-8EDE-CBD934EE02A9@comcast.net>


On Jun 19, 2013, at 6:27 PM, jim holtman wrote:

> 'a' and 'b' are vectors of length 100, so the sum of them would also
> produce a vector of 100.  

Just to (hopefully) clarify,  R code `sum(z)` would be a vector of length:1 but `z` which is _not_ `sum(z)` but rather `x+y` would be length:100.

-- 
David.


> So in one case, your code should look like this:
> 
>> a<-replicate(5, rnorm(20))
>> b<-replicate(5, rnorm(20))
>> 
>> xyz<-function(x,y){
> +   z<-x+y
> +   print(paste("the sum of", x, "and", y,"is", z, sep=" "))
> + }
>> 
>> xyz(a,b)
>  [1] "the sum of 0.078437532748926 and 1.42398359867007 is 1.502421131419"
> 
>  [2] "the sum of -0.779261070429696 and 0.484730511200338 is
> -0.294530559229357"
>  [3] "the sum of 0.16655966873187 and 0.349236445934426 is
> 0.515796114666296"
>  [4] "the sum of 0.265324569774749 and 0.860124249616191 is
> 1.12544881939094"
>  [5] "the sum of 0.890780709620268 and 0.404611144608053 is
> 1.29539185422832"
>  [6] "the sum of -0.467888369466512 and 0.367044921399527 is
> -0.100843448066985"
>  [7] "the sum of 0.758374556806851 and -1.51919904950798 is
> -0.760824492701126"
> .........
> 
> Is this your expected output?  If not, give a clear example of what you are
> expecting.  Could it be:
> 
>> sum(a + b)
> [1] 16.90667
> 
> 
> 
> On Wed, Jun 19, 2013 at 8:16 PM, Thomas Parr <thomas.parr at maine.edu> wrote:
> 
>> I am writing a function and I would like to return the name of a data frame
>> in a paste call, but I can't figure out how to just get the name. The names
>> of the data frames used, won't be the same each time.  I have to be
>> overlooking the obvious.
>> 
>> #For example:
>> 
>> a<-replicate(5, rnorm(20))
>> b<-replicate(5, rnorm(20))
>> 
>> xyz<-function(x,y){
>>  z<-x+y
>>  print(paste("the sum of", x, "and", y,"is", sep=" "))
>>  z
>> }
>> 
>> xyz(a,b)
>> 
>> #That function should return:
>> 
>>> "the sum of a and b is:"
>>> .and some data.
>> 
>> Not surprisingly, it returns all the data in the data frame.
>> 
>> Thanks,
>> Thomas
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> 
> -- 
> Jim Holtman
> Data Munger Guru
> 
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From thomas.parr at maine.edu  Thu Jun 20 04:04:44 2013
From: thomas.parr at maine.edu (Thomas Parr)
Date: Wed, 19 Jun 2013 22:04:44 -0400
Subject: [R] Returning name of dataframe?
In-Reply-To: <1371692366.18948.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <000f01ce6d4b$59f18ba0$0dd4a2e0$@maine.edu>
	<1371692366.18948.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <CADUm0t5mrncnNGunoMAF4pjuYmcb8D7DVv31dCGTwaoey+AUUg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130619/18b3141c/attachment.pl>

From lcmail4lists at gmail.com  Wed Jun 19 21:36:46 2013
From: lcmail4lists at gmail.com (=?ISO-8859-1?Q?L=EDvio?= Cipriano)
Date: Wed, 19 Jun 2013 20:36:46 +0100
Subject: [R] Retrieving Labels from vars/cols
In-Reply-To: <04d901ce6cf8$fdfd05b0$f9f71110$@tamu.edu>
References: <9160533.jDkeJi3ZQS@venus.lcipriano.pt>
	<CAN5YmCHMM-2PTo_j3TBHzJ0FjVf6AfqkekdtFxfJ0YF-_ja1Ng@mail.gmail.com>
	<04d901ce6cf8$fdfd05b0$f9f71110$@tamu.edu>
Message-ID: <2073734.e3Fq9OZrgb@venus.lcipriano.pt>

On 19 June 2013 09:26:30 David Carlson wrote:
> Perhaps you are talking about the variable.labels attribute returned
> by read.spss in package foreign?

That is it. I'll try it 

Thanks

L?vio Cipriano


From lcmail4lists at gmail.com  Wed Jun 19 22:41:53 2013
From: lcmail4lists at gmail.com (=?ISO-8859-1?Q?L=EDvio?= Cipriano)
Date: Wed, 19 Jun 2013 21:41:53 +0100
Subject: [R] Retrieving Labels from vars/cols
In-Reply-To: <04d901ce6cf8$fdfd05b0$f9f71110$@tamu.edu>
References: <9160533.jDkeJi3ZQS@venus.lcipriano.pt>
	<CAN5YmCHMM-2PTo_j3TBHzJ0FjVf6AfqkekdtFxfJ0YF-_ja1Ng@mail.gmail.com>
	<04d901ce6cf8$fdfd05b0$f9f71110$@tamu.edu>
Message-ID: <13190903.nxHAYCNPme@venus.lcipriano.pt>

On 19 June 2013 09:26:30 David Carlson wrote:
> variable.labels attribute returned
> by read.spss in package foreign? If so, you should try the
> attributes() or the attr() function:

Hi,


I used

attr(test,"variable.labels")[i][1]) and it worked.

Thanks

L?vio Cipriano


From suparna.mitra.sm at gmail.com  Thu Jun 20 06:56:24 2013
From: suparna.mitra.sm at gmail.com (Suparna Mitra)
Date: Thu, 20 Jun 2013 12:56:24 +0800
Subject: [R] how to add any extra word to existing column heading in R
Message-ID: <CAFdg=fWAqD5qz=dsLAcqs4kBXm1vcAR8F914-HFNVBHL8DPd4A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130620/241ec99e/attachment.pl>

From kridox at ymail.com  Thu Jun 20 07:04:50 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 20 Jun 2013 14:04:50 +0900
Subject: [R] how to add any extra word to existing column heading in R
In-Reply-To: <CAFdg=fWAqD5qz=dsLAcqs4kBXm1vcAR8F914-HFNVBHL8DPd4A@mail.gmail.com>
References: <CAFdg=fWAqD5qz=dsLAcqs4kBXm1vcAR8F914-HFNVBHL8DPd4A@mail.gmail.com>
Message-ID: <51C28D72.8050706@ymail.com>

Hello,

What did you try to do by yourself before to ask?

Regards,
Pascal


On 20/06/13 13:56, Suparna Mitra wrote:
> Hello R experts,
>    I want to add some extra words to number to existing column header. Can
> anybody tell me how to do that.
>
> e.g. if I have a data.frame
>        Height.1 Height.2 Height.6 Height.8 Height.10 Height.11 Height.17
> Height.20 Height.22 Height.31
> MBR1        74       72        0      104         0       250       144
>      0         0         0
> MBR2         0       94        0      150         0       250       158
>      0         0         0
> MBR3        93      167        0      199         0       250       208
>      0         0         0
> MBR4       146      106        0      165         0       250       135
>      0         0         0
> MBR5       149      106        0        0         0       250       141
>      0         0         0
> MBR6       120        0        0       97         0       250       175
>      0         0         0
> MBR7       120        0        0       76       145       250       130
>      0         0        79
> MBR8        89       70        0      114         0       250       211
>      0         0         0
>
> I want to rename the heading as
>
>        Height.1.D1 Height.2.D1 Height.6.D1 Height.8.D1 Height.10.D1
> Height.11.D1 Height.17.D1 Height.20.D1 Height.22.D1 Height.31.D1
> MBR1        74       72        0      104         0       250       144
>      0         0         0
> MBR2         0       94        0      150         0       250       158
>      0         0         0
> MBR3        93      167        0      199         0       250       208
>      0         0         0
> MBR4       146      106        0      165         0       250       135
>      0         0         0
> MBR5       149      106        0        0         0       250       141
>      0         0         0
> MBR6       120        0        0       97         0       250       175
>      0         0         0
> MBR7       120        0        0       76       145       250       130
>      0         0        79
> MBR8        89       70        0      114         0       250       211
>      0         0         0
> MBR9       168        0        0        0         0       250       137
>      0         0         0
> MBR11       78       68        0      117         0       250       161
>      0        49         0
>
> Any help will be really great.
> Thanks,
> Mitra
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From suparna.mitra.sm at gmail.com  Thu Jun 20 07:09:54 2013
From: suparna.mitra.sm at gmail.com (Suparna Mitra)
Date: Thu, 20 Jun 2013 13:09:54 +0800
Subject: [R] how to add any extra word to existing column heading in R
In-Reply-To: <51C28D72.8050706@ymail.com>
References: <CAFdg=fWAqD5qz=dsLAcqs4kBXm1vcAR8F914-HFNVBHL8DPd4A@mail.gmail.com>
	<51C28D72.8050706@ymail.com>
Message-ID: <CAFdg=fUH-eCaAnFtv-x7LOJRm791owWOJhU3=6ieV7EquypXTQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130620/bf8bcc9c/attachment.pl>

From kridox at ymail.com  Thu Jun 20 07:19:42 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 20 Jun 2013 14:19:42 +0900
Subject: [R] how to add any extra word to existing column heading in R
In-Reply-To: <CAFdg=fUH-eCaAnFtv-x7LOJRm791owWOJhU3=6ieV7EquypXTQ@mail.gmail.com>
References: <CAFdg=fWAqD5qz=dsLAcqs4kBXm1vcAR8F914-HFNVBHL8DPd4A@mail.gmail.com>
	<51C28D72.8050706@ymail.com>
	<CAFdg=fUH-eCaAnFtv-x7LOJRm791owWOJhU3=6ieV7EquypXTQ@mail.gmail.com>
Message-ID: <51C290EE.1010700@ymail.com>

Hello,

Two keywords: "colnames" and "paste".

Regards,
Pascal


On 20/06/13 14:09, Suparna Mitra wrote:
> Hello,
> I
> was trying ways to define new column names. Or very traditional way to
> export the data and add names in excel.
>   But thought there must a way, but searched with several key words in
> forum, but couldn't find the exact what I mean.
> May be my search terms are not perfect.
> Thanks,
> Mitra
>
>
>
> On 20 June 2013 13:04, Pascal Oettli <kridox at ymail.com
> <mailto:kridox at ymail.com>> wrote:
>
>     Hello,
>
>     What did you try to do by yourself before to ask?
>
>     Regards,
>     Pascal
>
>
>
>     On 20/06/13 13:56, Suparna Mitra wrote:
>
>         Hello R experts,
>             I want to add some extra words to number to existing column
>         header. Can
>         anybody tell me how to do that.
>
>         e.g. if I have a data.frame
>                 Height.1 Height.2 Height.6 Height.8 Height.10 Height.11
>         Height.17
>         Height.20 Height.22 Height.31
>         MBR1        74       72        0      104         0       250
>              144
>               0         0         0
>         MBR2         0       94        0      150         0       250
>              158
>               0         0         0
>         MBR3        93      167        0      199         0       250
>              208
>               0         0         0
>         MBR4       146      106        0      165         0       250
>              135
>               0         0         0
>         MBR5       149      106        0        0         0       250
>              141
>               0         0         0
>         MBR6       120        0        0       97         0       250
>              175
>               0         0         0
>         MBR7       120        0        0       76       145       250
>              130
>               0         0        79
>         MBR8        89       70        0      114         0       250
>              211
>               0         0         0
>
>         I want to rename the heading as
>
>                 Height.1.D1 Height.2.D1 Height.6.D1 Height.8.D1 Height.10.D1
>         Height.11.D1 Height.17.D1 Height.20.D1 Height.22.D1 Height.31.D1
>         MBR1        74       72        0      104         0       250
>              144
>               0         0         0
>         MBR2         0       94        0      150         0       250
>              158
>               0         0         0
>         MBR3        93      167        0      199         0       250
>              208
>               0         0         0
>         MBR4       146      106        0      165         0       250
>              135
>               0         0         0
>         MBR5       149      106        0        0         0       250
>              141
>               0         0         0
>         MBR6       120        0        0       97         0       250
>              175
>               0         0         0
>         MBR7       120        0        0       76       145       250
>              130
>               0         0        79
>         MBR8        89       70        0      114         0       250
>              211
>               0         0         0
>         MBR9       168        0        0        0         0       250
>              137
>               0         0         0
>         MBR11       78       68        0      117         0       250
>              161
>               0        49         0
>
>         Any help will be really great.
>         Thanks,
>         Mitra
>
>                  [[alternative HTML version deleted]]
>
>         ________________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         https://stat.ethz.ch/mailman/__listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/__posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>


From safisce at gmail.com  Thu Jun 20 08:57:55 2013
From: safisce at gmail.com (Safiye Celik)
Date: Wed, 19 Jun 2013 23:57:55 -0700
Subject: [R] Difference between Lloyd and Forgy algorithms used in R
 built-in kmeans clustering function
Message-ID: <CAJRSaT-ieEDKuC-e+F7JFLHScBmn+BZQ0=EWwh=BuLmtOLV2Ug@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130619/07e33256/attachment.pl>

From kridox at ymail.com  Thu Jun 20 09:18:46 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 20 Jun 2013 16:18:46 +0900
Subject: [R] Difference between Lloyd and Forgy algorithms used in R
 built-in kmeans clustering function
In-Reply-To: <CAJRSaT-ieEDKuC-e+F7JFLHScBmn+BZQ0=EWwh=BuLmtOLV2Ug@mail.gmail.com>
References: <CAJRSaT-ieEDKuC-e+F7JFLHScBmn+BZQ0=EWwh=BuLmtOLV2Ug@mail.gmail.com>
Message-ID: <51C2ACD6.7000300@ymail.com>

Hi,

A 5-second search on Internet brought me here:

http://en.wikibooks.org/wiki/Data_Mining_Algorithms_In_R/Clustering/K-Means

Regards,
Pascal


On 20/06/13 15:57, Safiye Celik wrote:
> Hi,
>
> Does anybody know the difference between the Lloyd and Forgy algorithms
> specified for R's kmeans clustering options? I know how Lloyd works, but I
> cannot access Forgy's paper and could not find any specific information on
> the web about how it really differs from Lloyd's method.
>
> I appreciate your help. Thanks!
>


From teotjunk at gmail.com  Thu Jun 20 09:26:25 2013
From: teotjunk at gmail.com (Tjun Kiat Teo)
Date: Thu, 20 Jun 2013 15:26:25 +0800
Subject: [R] Installing Jags on 64 Bit Fedora
Message-ID: <CAH=5_TXeYPWpuu3uideUzZQEzsrEKqkD4ceyuikY2NwJa3sEpw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130620/6620845b/attachment.pl>

From alexandre.piche at mail.mcgill.ca  Thu Jun 20 09:26:36 2013
From: alexandre.piche at mail.mcgill.ca (AlexPiche)
Date: Thu, 20 Jun 2013 00:26:36 -0700 (PDT)
Subject: [R] knitr without R studio
In-Reply-To: <1371628429300-4669841.post@n4.nabble.com>
References: <1371628429300-4669841.post@n4.nabble.com>
Message-ID: <1371713196256-4669951.post@n4.nabble.com>

Thank you for your time guys, I solve my issue.
Regards,

Alex



--
View this message in context: http://r.789695.n4.nabble.com/knitr-without-R-studio-tp4669841p4669951.html
Sent from the R help mailing list archive at Nabble.com.


From miaojpm at gmail.com  Thu Jun 20 10:01:12 2013
From: miaojpm at gmail.com (jpm miao)
Date: Thu, 20 Jun 2013 16:01:12 +0800
Subject: [R] Problems with R package building
In-Reply-To: <73D195CC-66CB-47D2-9116-A29244061166@gmail.com>
References: <CABcx46Aes7E_FGNrhmXhq+Y2ziO5eT+2xUB7viv7qDQHP=+XjA@mail.gmail.com>
	<73D195CC-66CB-47D2-9116-A29244061166@gmail.com>
Message-ID: <CABcx46DChL+uNgp6Uri_27JvD=bfb7_-2PzL5L1s1td03aOPrA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130620/d56de046/attachment.pl>

From alexandre.piche at mail.mcgill.ca  Thu Jun 20 10:04:35 2013
From: alexandre.piche at mail.mcgill.ca (AlexPiche)
Date: Thu, 20 Jun 2013 01:04:35 -0700 (PDT)
Subject: [R] Produce HTML reference in knitr using rmd
Message-ID: <1371715475701-4669954.post@n4.nabble.com>

Hello guys,

I'm new to knitr and to R in general. I'm using RStudio and knitr, both the
latest version.

I am trying to produce an html page with multiple graph, which has a url
reference to each of them that bring us lower on the page. For those produce
separately it is pretty easy, since I just include the html location like I
did for graph 1.

But in a loop, I am struggling to reference them. I'm not sure where to
start, I took a look to option like fig.path and check a lot of post in the
forum, but I haven't been able to figure it out.


  <p style="font-size:16px; text-align:center">
Lightpt <#location1>     Lightb <#location2>    LightbT <#location3>   
Graph 4 <#location4>  
  </p>

  
graph 1



```{r, include=FALSE}
plot <- function(cCode, model = "y", years = 3) {
 
    CairoPNG(paste(cCode, ".png", sep = ""), width=600, wheigth=675)
    lapply(1:ncol(pcmat), function(x) {
        
       ...
                 })
    
dev.off()}
```

Thank you for your time,

Alex



--
View this message in context: http://r.789695.n4.nabble.com/Produce-HTML-reference-in-knitr-using-rmd-tp4669954.html
Sent from the R help mailing list archive at Nabble.com.


From kridox at ymail.com  Thu Jun 20 10:09:24 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 20 Jun 2013 17:09:24 +0900
Subject: [R] Problems with R package building
In-Reply-To: <CABcx46DChL+uNgp6Uri_27JvD=bfb7_-2PzL5L1s1td03aOPrA@mail.gmail.com>
References: <CABcx46Aes7E_FGNrhmXhq+Y2ziO5eT+2xUB7viv7qDQHP=+XjA@mail.gmail.com>
	<73D195CC-66CB-47D2-9116-A29244061166@gmail.com>
	<CABcx46DChL+uNgp6Uri_27JvD=bfb7_-2PzL5L1s1td03aOPrA@mail.gmail.com>
Message-ID: <51C2B8B4.1020906@ymail.com>

Hi,

Did you run "R CMD build test1pkg" in a command prompt window?

Regards,
Pascal


On 20/06/13 17:01, jpm miao wrote:
> Hi,
>
>     Following your advice, I install R tools from
> http://cran.r-project.org/bin/windows/Rtools/
> Rtools215.exe <http://cran.r-project.org/bin/windows/Rtools/Rtools215.exe>
>
>     Files are automatically installed here:
> C:\Rtools
>
> I run the code again and get the message
>
> Creating directories ...
> Error in package.skeleton(list = c("f", "g", "d", "e"), name = "test1pkg",
>   :
>    directory 'D:/R/pkgtest/test1pkg' already exists
>> R CMD build test1pkg
> Error: unexpected symbol in "R CMD"
>
>     Is there anything else I need to do ?
>
> Miao
>
>
>
> 2013/6/14 Michael Weylandt <michael.weylandt at gmail.com>
>
>>
>>
>> On Jun 14, 2013, at 7:18, jpm miao <miaojpm at gmail.com> wrote:
>>
>>> Hi,
>>>
>>>   I try to build a toy package by running the following codes in an R
>>> program
>>>
>>> require(stats)
>>> f <- function(x,y) x+y
>>> g <- function(x,y) x-y
>>> d <- data.frame(a=1, b=2)
>>> e <- rnorm(1000)
>>> package.skeleton(list=c("f","g","d","e"), name="test1pkg",
>>> path="D:/R/pkgtest")
>>>
>>>    Then the program runs smoothly
>>>
>>> Creating directories ...
>>> Creating DESCRIPTION ...
>>> Creating NAMESPACE ...
>>> Creating Read-and-delete-me ...
>>> Saving functions and data ...
>>> Making help files ...
>>> Done.
>>> Further steps are described in
>> 'D:/R/pkgtest/test1pkg/Read-and-delete-me'.
>>>
>>>     Since it is a test, I skip all the documentation work and then type
>>> this line:
>>>
>>>> R CMD build test1pkg
>>> Error: unexpected symbol in "R CMD"
>>>
>>>    I check on the web about the error message. It's said that the command
>>> should be typed in a DOS window (command prompt window?). However it does
>>> not work  in my DOS window either. Could someone tell me how to process
>> the
>>> package building process?
>>>
>>
>> Have you installed the Windows Rtools from CRAN and made sure your PATH is
>> set properly?
>>
>> MW
>>
>>
>>>    Thanks,
>>>
>>> Miao
>>>
>>>     [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From miaojpm at gmail.com  Thu Jun 20 10:13:16 2013
From: miaojpm at gmail.com (jpm miao)
Date: Thu, 20 Jun 2013 16:13:16 +0800
Subject: [R] Problems with R package building
In-Reply-To: <51C2B8B4.1020906@ymail.com>
References: <CABcx46Aes7E_FGNrhmXhq+Y2ziO5eT+2xUB7viv7qDQHP=+XjA@mail.gmail.com>
	<73D195CC-66CB-47D2-9116-A29244061166@gmail.com>
	<CABcx46DChL+uNgp6Uri_27JvD=bfb7_-2PzL5L1s1td03aOPrA@mail.gmail.com>
	<51C2B8B4.1020906@ymail.com>
Message-ID: <CABcx46CgjCsDMMOB=0qW76fXN4cOO-D2=yq+4aJ-du-AbMVk=A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130620/6580b3f7/attachment.pl>

From bhh at xs4all.nl  Thu Jun 20 10:14:10 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 20 Jun 2013 10:14:10 +0200
Subject: [R] Problems with R package building
In-Reply-To: <CABcx46DChL+uNgp6Uri_27JvD=bfb7_-2PzL5L1s1td03aOPrA@mail.gmail.com>
References: <CABcx46Aes7E_FGNrhmXhq+Y2ziO5eT+2xUB7viv7qDQHP=+XjA@mail.gmail.com>
	<73D195CC-66CB-47D2-9116-A29244061166@gmail.com>
	<CABcx46DChL+uNgp6Uri_27JvD=bfb7_-2PzL5L1s1td03aOPrA@mail.gmail.com>
Message-ID: <011ED28D-506E-4A12-906A-25340B824DAD@xs4all.nl>


On 20-06-2013, at 10:01, jpm miao <miaojpm at gmail.com> wrote:

> Hi,
> 
>   Following your advice, I install R tools from
> http://cran.r-project.org/bin/windows/Rtools/
> Rtools215.exe <http://cran.r-project.org/bin/windows/Rtools/Rtools215.exe>
> 
>   Files are automatically installed here:
> C:\Rtools
> 
> I run the code again and get the message
> 
> Creating directories ...
> Error in package.skeleton(list = c("f", "g", "d", "e"), name = "test1pkg",
> :
>  directory 'D:/R/pkgtest/test1pkg' already exists
>> R CMD build test1pkg
> Error: unexpected symbol in "R CMD"
> 

You are supposed to run R CMD build test1pkg from the commandline in the directory directly above test1pkg
On Windows in a Windows console window.

Berend


From miaojpm at gmail.com  Thu Jun 20 10:25:12 2013
From: miaojpm at gmail.com (jpm miao)
Date: Thu, 20 Jun 2013 16:25:12 +0800
Subject: [R] Problems with R package building
In-Reply-To: <011ED28D-506E-4A12-906A-25340B824DAD@xs4all.nl>
References: <CABcx46Aes7E_FGNrhmXhq+Y2ziO5eT+2xUB7viv7qDQHP=+XjA@mail.gmail.com>
	<73D195CC-66CB-47D2-9116-A29244061166@gmail.com>
	<CABcx46DChL+uNgp6Uri_27JvD=bfb7_-2PzL5L1s1td03aOPrA@mail.gmail.com>
	<011ED28D-506E-4A12-906A-25340B824DAD@xs4all.nl>
Message-ID: <CABcx46BNNvC3wH6v1DFFfX2q9jTgB6MzsVM+-i6G4AGtfQQuEA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130620/ff96bd7c/attachment.pl>

From erinm.hodgess at gmail.com  Thu Jun 20 10:53:46 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Thu, 20 Jun 2013 03:53:46 -0500
Subject: [R]  installation problems from an Rstudio server
Message-ID: <CACxE24=8GwfKz4OiFqW5NCtNkxmboiz+MB2vS3G=uzri0iG2_A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130620/0deb4834/attachment.pl>

From pdalgd at gmail.com  Thu Jun 20 11:18:32 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 20 Jun 2013 11:18:32 +0200
Subject: [R] how to get growth rate of a (time series) data?
In-Reply-To: <51C22DB8.3080208@xtra.co.nz>
References: <CAHf4n+TMEj30C9qXgYSeJePMEmJaMDmhM__PDDx9tp5NytHqzA@mail.gmail.com>
	<CAAmySGMbo3Hp2CA6UAXFko58UKdG_2s08fgOvORGosFgiKAf5Q@mail.gmail.com>
	<51C22DB8.3080208@xtra.co.nz>
Message-ID: <EF43E562-4E98-4C00-9878-089C1A6A7386@gmail.com>


On Jun 20, 2013, at 00:16 , Rolf Turner wrote:

> This is yet another illustration of the rule that if there is a 50-50 chance of
> getting things the wrong way around, then there is actually a probability
> of one of getting things the wrong way around.

Isn't that suppposed to be ... Oh, wait.... .-)

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ripley at stats.ox.ac.uk  Thu Jun 20 11:28:39 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Jun 2013 10:28:39 +0100
Subject: [R] installation problems from an Rstudio server
In-Reply-To: <CACxE24=8GwfKz4OiFqW5NCtNkxmboiz+MB2vS3G=uzri0iG2_A@mail.gmail.com>
References: <CACxE24=8GwfKz4OiFqW5NCtNkxmboiz+MB2vS3G=uzri0iG2_A@mail.gmail.com>
Message-ID: <51C2CB47.8090306@stats.ox.ac.uk>

On 20/06/2013 09:53, Erin Hodgess wrote:
> Dear R People:
>
> I'm not sure if this is an R problem or a Centos 5 problem, but here it
> goes:


It is not an R problem.  Your message is garbled (don't send HTML?), but 
the essence is

gcc: error trying to exec 'as': execvp: Permission denied

That is a problem with your compiler installation: it cannot execute its 
assembler pass.

>
> I'm running Rstudio from a Centos 5 server.  When I try to install packages
> from a non-root account, I get the following:
>
>> Sys.umask()[1] "22"> install.packages("maps")Installing package into ?/home/erin1/R/x86_64-unknown-linux-gnu-library/3.0?
> (as ?lib? is unspecified)trying URL
> 'http://cran.rstudio.com/src/contrib/maps_2.3-2.tar.gz'Content type
> 'application/x-gzip' length 1426362 bytes (1.4 Mb)opened
> URL==================================================downloaded 1.4 Mb
> * installing *source* package ?maps? ...** package ?maps? successfully
> unpacked and MD5 sums checked** libs** arch - gcc -std=gnu99 -g -O2
> -I/usr/local/include -L/usr/local/lib64  Gmake.c   -o GmakeGmake.c: In
> function ?get_lh?:
> Gmake.c:111: warning: cast from pointer to integer of different
> sizeGmake.c:113: warning: cast from pointer to integer of different
> sizeGmake.c: In function ?main?:Gmake.c:211: warning: cast from
> pointer to integer of different sizeGmake.c:214: warning: cast from
> pointer to integer of different sizeGmake.c:217: warning: cast from
> pointer to integer of different sizeGmake.c:219: warning: cast from
> pointer to integer of different sizeGmake.c:221: warning: cast from
> pointer to integer of different sizeGmake.c:224: warning: cast from
> pointer to integer of different sizeGmake.c:227: warning: cast from
> pointer to integer of different sizegcc: error trying to exec 'as':
> execvp: Permission deniedmake: *** [Gmake] Error 1ERROR: compilation
> failed for package ?maps?* removing
> ?/home/erin1/R/x86_64-unknown-linux-gnu-library/3.0/maps?Warning in
> install.packages :
>    installation of package ?maps? had non-zero exit status
>
> The downloaded source packages are in
> 	?/tmp/RtmpIF6S0R/downloaded_packages?> sessionInfo()R version 3.0.1
> (2013-05-16)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> LC_TIME=en_US.UTF-8
>   [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8
> LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=C                 LC_NAME=C
> LC_ADDRESS=C
> [10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8
> LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.0.1
>
>
>>
>
>
> I've changed the permissions, and updated the umask to 022.
>
> Any help would be much appreciated.
>
> Sincerely,
> Erin
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ccampbell at mango-solutions.com  Thu Jun 20 11:47:38 2013
From: ccampbell at mango-solutions.com (Chris Campbell)
Date: Thu, 20 Jun 2013 09:47:38 +0000
Subject: [R] deSolve question
In-Reply-To: <1371599185.84369.YahooMailClassic@web140401.mail.bf1.yahoo.com>
References: <1371599185.84369.YahooMailClassic@web140401.mail.bf1.yahoo.com>
Message-ID: <2C2DB2ABEE65DB40B7946E54C71A8C0942F46CF5@mexchange.Mango.local>

Dear Andras

In algebra (and computing) terms are operated upon in order of priority. Terms in brackets are evaluated first. In your original code, - pars$k * state[1] is not divided by pars$v since division happens before addition. When you use the brackets that expression becomes part of the term that is divided.

Therefore the outputs of these functions should not be the same.

Best wishes

Chris

Chris Campbell, PhD    
Tel. +44 (0) 1249 705 450?| Mobile. +44 (0) 7929 628 349    
mailto:ccampbell at mango-solutions.com?| http://www.mango-solutions.com    
Mango Solutions, 2 Methuen Park, Chippenham, Wiltshire , SN14 OGB UK    

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Andras Farkas
Sent: 19 June 2013 00:46
To: r-help at r-project.org; r-sig-dynamic-models at r-project.org
Subject: [R] deSolve question



Dear All

wonder if you could provide some insights on the following: currently I have this code which produces the expected results:

require(deSolve)
pars <- list(k = 0.08,v=15)
intimes <- c(0,0.5,12)
input   <- c(800,0,0)
forc <- approxfun(intimes, input, method="constant", rule=2)

derivs <- function(t, state, pars) {
  inp <- forc(t)
  dy1 <- - pars$k * state[1] + inp/pars$v
  return(list(c(dy1)))
}

model <- function(pars, times=seq(0, 13, by = 0.01)) {
  state <- c(y = 0)
  return(ode(y = state, times = times, func = derivs, parms = pars,
             method="lsoda"))
}

plot(model(pars))

intuitively it would make sense to me that if I change the derivs as:

derivs <- function(t, state, pars) {
  inp <- forc(t)
  #note the added ()
  dy1 <- (- pars$k * state[1] + inp)/pars$v
  return(list(c(dy1)))
}

than I would get the same results, but that is not the case. I need to "relocate" pars$v to another position within derivs so that I could implement it in a forcing function to be able to change its value during derivation. Appreciate your help,

Andras

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

--

LEGAL NOTICE\ \ This message is intended for the use of ...{{dropped:18}}


From bt_jannis at yahoo.de  Thu Jun 20 13:42:52 2013
From: bt_jannis at yahoo.de (Jannis)
Date: Thu, 20 Jun 2013 13:42:52 +0200
Subject: [R] showing error line
Message-ID: <51C2EABC.7070605@yahoo.de>

Dear R users,


i am trying to get the line number of the code where an error is 
produced. With the options:

options(keep.source = TRUE, show.error.locations = TRUE, 
keep.source.pkgs = TRUE)

I have managed to get the error locations to show up when i source the 
respective files. They do not, however, show up for the same errors when 
I use installed packages. Do I have to build these packages in a 
specific way?


Cheers
Jannis


From kridox at ymail.com  Thu Jun 20 13:55:23 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 20 Jun 2013 20:55:23 +0900
Subject: [R] showing error line
In-Reply-To: <51C2EABC.7070605@yahoo.de>
References: <51C2EABC.7070605@yahoo.de>
Message-ID: <CAAcyNCyRK3ZtMRfrGTRha8oaaZpYtTp8cAPCiLruabCA+0YtGA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130620/7f03961f/attachment.pl>

From murdoch.duncan at gmail.com  Thu Jun 20 14:00:20 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 20 Jun 2013 08:00:20 -0400
Subject: [R] showing error line
In-Reply-To: <51C2EABC.7070605@yahoo.de>
References: <51C2EABC.7070605@yahoo.de>
Message-ID: <51C2EED4.30508@gmail.com>

On 13-06-20 7:42 AM, Jannis wrote:
> Dear R users,
>
>
> i am trying to get the line number of the code where an error is
> produced. With the options:
>
> options(keep.source = TRUE, show.error.locations = TRUE,
> keep.source.pkgs = TRUE)
>
> I have managed to get the error locations to show up when i source the
> respective files. They do not, however, show up for the same errors when
> I use installed packages. Do I have to build these packages in a
> specific way?

You need to install them from source with those options in place.  A 
binary install won't include the line number information.

If you do your installs from the command line, you can set environment 
variable

R_KEEP_PKG_SOURCE=yes

but you can also do it from within R with the options above, using

install.packages("foo.tar.gz", type="source", repos=NULL)

Duncan Murdoch


From highstat at highstat.com  Thu Jun 20 14:29:37 2013
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 20 Jun 2013 13:29:37 +0100
Subject: [R] New book: Beginner's Guide to GLM and GLMM with R
Message-ID: <51C2F5B1.7030105@highstat.com>

Members of this mailing list may be interested in the following new book:


Beginner's Guide to GLM and GLMM with R.
- A frequentist and Bayesian perspective for ecologists -

Zuur AF, Hilbe JM and Ieno EN


This book is only available from:
http://www.highstat.com/BGGLM.htm



This book presents Generalized Linear Models (GLM) and Generalized 
Linear Mixed Models (GLMM) based on both frequency-based and Bayesian 
concepts. Using ecological data from real-world studies, the text 
introduces the reader to the basics of GLM and mixed effects models, 
with demonstrations of binomial, gamma, Poisson, negative binomial 
regression, and beta and beta-binomial GLMs and GLMMs. The book uses the 
functions glm, lmer, glmer, glmmADMB, and also JAGS from within R. JAGS 
results are compared with frequentist results.

R code to construct, fit, interpret, and comparatively evaluate models 
is provided at every stage. Otherwise challenging procedures are 
presented in a clear and comprehensible manner with each step of the 
modelling process explained in detail, and all code is provided so that 
it can be reproduced by the reader.

Readers of this book have free access to:

Chapter 1 of Zero Inflated Models and Generalized Linear Mixed Models 
with R. (2012a) Zuur, Saveliev, Ieno.
Chapter 1 of Beginner's Guide to Generalized Additive Models with R. 
(2012b) Zuur, AF.


Keywords
Introduction to GLM
Poisson GLM and Negative binomial GLM for count data
Binomial GLM for binary data
Binomial GLM for proportional data
Other distributions
GLM applied to red squirrel data
Bayesian approach ? running the Poisson GLM
Running JAGS via R
Applying a negative binomial GLM in JAGS
GLM applied to presence-absence Polychaeta data
Model selection using AIC, DIC and BIC in jags
Introduction to mixed effects models
GLMM applied on honeybee pollination data
Poisson GLMM using glmer and JAGS
Negative binomial GLMM using glmmADMD and JAGS
GLMM with auto-regressive correlation
GLMM for strictly positive data: biomass of rainforest trees
gamma GLM using a frequentist approach
Fitting a gamma GLM using JAGS
Truncated Gaussian linear regression
Tobit model in JAGS
Tobit model with random effects in JAGS
Binomial, beta-binomial, and beta GLMM applied to cheetah data

Kind regards,

Alain Zuur




-- 

Dr. Alain F. Zuur
First author of:

1. Analysing Ecological Data (2007).
Zuur, AF, Ieno, EN and Smith, GM. Springer. 680 p.
URL: www.springer.com/0-387-45967-7


2. Mixed effects models and extensions in ecology with R. (2009).
Zuur, AF, Ieno, EN, Walker, N, Saveliev, AA, and Smith, GM. Springer.
http://www.springer.com/life+sci/ecology/book/978-0-387-87457-9


3. A Beginner's Guide to R (2009).
Zuur, AF, Ieno, EN, Meesters, EHWG. Springer
http://www.springer.com/statistics/computational/book/978-0-387-93836-3


4. Zero Inflated Models and Generalized Linear Mixed Models with R. (2012) Zuur, Saveliev, Ieno.
http://www.highstat.com/book4.htm

Other books: http://www.highstat.com/books.htm


Statistical consultancy, courses, data analysis and software
Highland Statistics Ltd.
6 Laverock road
UK - AB41 6FN Newburgh
Tel: 0044 1358 788177
Email: highstat at highstat.com
URL: www.highstat.com
URL: www.brodgar.com


From friendly at yorku.ca  Thu Jun 20 14:32:18 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 20 Jun 2013 08:32:18 -0400
Subject: [R] knitr: side-by-side figures in R markdown
In-Reply-To: <CANROs4fTuK=up_w0vohsXxQ6+WKtqMD=kpnvMiL38qQ64zF6uA@mail.gmail.com>
References: <51C1B0CF.3080702@yorku.ca>
	<CANROs4fTuK=up_w0vohsXxQ6+WKtqMD=kpnvMiL38qQ64zF6uA@mail.gmail.com>
Message-ID: <51C2F652.5000602@yorku.ca>

On 6/19/2013 5:31 PM, Yihui Xie wrote:
> You need to remove out.extra='style="display:block; margin: auto"'. In
> CSS, display:block; means this element stands in its own line, and no
> other elements can sit by its side. This is applied to individual
> images, so the two images will not be arranged side by side.
>
Thanks, Yihui.  I had simply copied that option from the 
corrplot-intro.Rmd example,
without fully understanding the implication.  Might be good to document 
this somewhere.

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From Roger.Vallejo at ARS.USDA.GOV  Thu Jun 20 14:53:43 2013
From: Roger.Vallejo at ARS.USDA.GOV (Vallejo, Roger)
Date: Thu, 20 Jun 2013 12:53:43 +0000
Subject: [R] BINARY traits GENETIC CORRELATION
Message-ID: <3DCD67B8B481FA47AF340FE7868200EE0B7B7931@001FSN2MPN1-062.001f.mgd2.msft.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130620/86a9ec05/attachment.pl>

From pdalgd at gmail.com  Thu Jun 20 15:17:43 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 20 Jun 2013 15:17:43 +0200
Subject: [R] p values of lmer
In-Reply-To: <CAAmySGM3Pw1TAnYiQTdhPhcWcaeJd2U=NZCKpEbMFeqjF3ud6Q@mail.gmail.com>
References: <5e360438.fe90.13f5bc2ba32.Coremail.laomeng_3@163.com>
	<CAAmySGM3Pw1TAnYiQTdhPhcWcaeJd2U=NZCKpEbMFeqjF3ud6Q@mail.gmail.com>
Message-ID: <044FE56C-AAAA-4BE1-8E27-C0539BAB1B6B@gmail.com>


On Jun 19, 2013, at 15:02 , R. Michael Weylandt wrote:

> On Wed, Jun 19, 2013 at 10:27 AM, meng <laomeng_3 at 163.com> wrote:
>> Hi all:
>> I met a question about lmer.
>> 
>> fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
>> summary(fm1)
>> 
>> ...
>> 
>> Fixed effects:
>>            Estimate Std. Error t value
>> (Intercept)  251.405      6.825   36.84
>> Days          10.467      1.546    6.77
>> 
>> ...
>> 
>> My question:
>> Why p values of (Intercept) and Days are not given?
> 
> Take a look at R FAQ 7.35.
> 
> http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-are-p_002dvalues-not-displayed-when-using-lmer_0028_0029_003f
> 
> 

That's getting a bit old. It has a reference to Doug Bates posting from 2006, which basically says "because degree of freedom issues are unresolved". 

Important developments have happened since, and Rune's reference to package lmerTest (and, implicitly, pbkrtest) is more precise these days. 

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jgrn at illinois.edu  Thu Jun 20 16:45:39 2013
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Thu, 20 Jun 2013 09:45:39 -0500
Subject: [R] Determining the maximum memory usage of a function
Message-ID: <CABG0rftAwo_CGr+hMrw6K3cZ7=TgeeFPrQv=DBaCte34kaWgcg@mail.gmail.com>

Folks:

I apologize for the cross-posting between r-help and r-sig-hpc, but I
figured this question was relevant to both lists.  I'm writing a
function to be applied to an input dataset that will be broken up into
chunks for memory management reasons and for parallel execution.  I am
trying to determine, for a given function, what the *maximum* memory
usage during its execution is (which may not be the beginning or the
end of the function, but somewhere in the middle), so I can "plan" for
the chunk size (e.g. have a table of chunk size vs. max memory usage).

Is there a trick for determining this?

--j

--
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
607 South Mathews Avenue, MC 150
Urbana, IL 61801
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From vilanew at gmail.com  Thu Jun 20 16:46:23 2013
From: vilanew at gmail.com (David martin)
Date: Thu, 20 Jun 2013 16:46:23 +0200
Subject: [R] errorest slow
Message-ID: <kpv4lo$22n$1@ger.gmane.org>

Hi ,
When using errorest on a large dataset (12000 variables) it performs 
very slow. By looking at the randomforest package it says that for 
largedatasets the use of the formula is discouraged.

So it's better to use the x and y terms as the example below:
rf<-randomForest(x=df[trainindices,-1],y=df[trainindices,1],xtest=df[testindices,-1],ytest=df[testindices,1], 
do.trace=5, ntree=500)

Would it be possible to modify errorest so that it uses x and y rather 
than formula. I think that would increase speed on large datasets.

errorest(type~.,data=mydate, model=randomForest,mtry=2)#will perform slow
errorest(x=type,y=variables,data=mydate, 
model=randomForest,mtry=2)#would perform faster if implemented

thanks,
david


From jholtman at gmail.com  Thu Jun 20 17:07:03 2013
From: jholtman at gmail.com (jim holtman)
Date: Thu, 20 Jun 2013 11:07:03 -0400
Subject: [R] Determining the maximum memory usage of a function
In-Reply-To: <CABG0rftAwo_CGr+hMrw6K3cZ7=TgeeFPrQv=DBaCte34kaWgcg@mail.gmail.com>
References: <CABG0rftAwo_CGr+hMrw6K3cZ7=TgeeFPrQv=DBaCte34kaWgcg@mail.gmail.com>
Message-ID: <CAAxdm-5zcz32GSLKbGXZ4VKL+PbqTMo-NTBtFmgP4ofGjdTv4g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130620/5bcc3388/attachment.pl>

From ripley at stats.ox.ac.uk  Thu Jun 20 17:34:58 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 20 Jun 2013 16:34:58 +0100
Subject: [R] Determining the maximum memory usage of a function
In-Reply-To: <CABG0rftAwo_CGr+hMrw6K3cZ7=TgeeFPrQv=DBaCte34kaWgcg@mail.gmail.com>
References: <CABG0rftAwo_CGr+hMrw6K3cZ7=TgeeFPrQv=DBaCte34kaWgcg@mail.gmail.com>
Message-ID: <51C32122.8020905@stats.ox.ac.uk>

On 20/06/2013 15:45, Jonathan Greenberg wrote:
> Folks:
>
> I apologize for the cross-posting between r-help and r-sig-hpc, but I
> figured this question was relevant to both lists.  I'm writing a
> function to be applied to an input dataset that will be broken up into
> chunks for memory management reasons and for parallel execution.  I am
> trying to determine, for a given function, what the *maximum* memory
> usage during its execution is (which may not be the beginning or the
> end of the function, but somewhere in the middle), so I can "plan" for
> the chunk size (e.g. have a table of chunk size vs. max memory usage).
>
> Is there a trick for determining this?

Note that your subject line and the body of your message are different 
questions.

You cannot determine the memory usage of any part of R, in particular 
not of a function's execution.  Objects are shared, garbage collection 
happens asynchronously ....

However, gc() is a good start.  Call gc(reset = TRUE) before and gc() 
after your task, and you will see the maximum extra memory used by R in 
the interim. (This does not include memory malloced by compiled code, 
which is much harder to measure as it gets re-used.)

Note that calls to gc() do affect the usage, and the usage also depends 
on what had already been done in the session (as the trigger values 
adapt to usage).

>
> --j
>
> --
> Jonathan A. Greenberg, PhD
> Assistant Professor
> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> Department of Geography and Geographic Information Science
> University of Illinois at Urbana-Champaign
> 607 South Mathews Avenue, MC 150
> Urbana, IL 61801
> Phone: 217-300-1924
> http://www.geog.illinois.edu/~jgrn/
> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jgrn at illinois.edu  Thu Jun 20 17:36:21 2013
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Thu, 20 Jun 2013 10:36:21 -0500
Subject: [R] Determining the maximum memory usage of a function
In-Reply-To: <53cf559ebff640a7a1e9f80751e26a2f@CHIHT4.ad.uillinois.edu>
References: <CABG0rftAwo_CGr+hMrw6K3cZ7=TgeeFPrQv=DBaCte34kaWgcg@mail.gmail.com>
	<53cf559ebff640a7a1e9f80751e26a2f@CHIHT4.ad.uillinois.edu>
Message-ID: <CABG0rfue9j5pqA+BPaE3tbOtQOmPD7fC70eRXLC1YjPDmhUJxw@mail.gmail.com>

Jim:

Thanks, but I'm looking for something that can be used somewhat
automatically -- the function in question would be user-provided and
passed to my "chunking" algorithm, so in this case it would be the
end-user (not me) who would have to embed these -- would
Rprof(memory.profiling=TRUE)
# my function
Rprof(NULL)
... and then taking the max of the tseries output be a reasonable
approach?  If so, which of the three outputs (vsize.small vsize.large
  nodes) would be best compared against the available memory?

Cheers!

--j

On Thu, Jun 20, 2013 at 10:07 AM, jim holtman <jholtman at gmail.com> wrote:
> What I would do is to use "memory.size()" to get the amount of memory being
> used.  Do a call at the beginning of the function to determine the base, and
> then at other points in the code to see what the difference from the base is
> and keep track of the maximum difference.  I am not sure if just getting the
> memory usage at the end would be sufficient since there may be some garbage
> collection in between, or you might be creating some large objects and then
> deleting/reusing them.  So keep track after large chunks of code to see what
> is happening.
>
>
> On Thu, Jun 20, 2013 at 10:45 AM, Jonathan Greenberg <jgrn at illinois.edu>
> wrote:
>>
>> Folks:
>>
>> I apologize for the cross-posting between r-help and r-sig-hpc, but I
>> figured this question was relevant to both lists.  I'm writing a
>> function to be applied to an input dataset that will be broken up into
>> chunks for memory management reasons and for parallel execution.  I am
>> trying to determine, for a given function, what the *maximum* memory
>> usage during its execution is (which may not be the beginning or the
>> end of the function, but somewhere in the middle), so I can "plan" for
>> the chunk size (e.g. have a table of chunk size vs. max memory usage).
>>
>> Is there a trick for determining this?
>>
>> --j
>>
>> --
>> Jonathan A. Greenberg, PhD
>> Assistant Professor
>> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>> Department of Geography and Geographic Information Science
>> University of Illinois at Urbana-Champaign
>> 607 South Mathews Avenue, MC 150
>> Urbana, IL 61801
>> Phone: 217-300-1924
>> http://www.geog.illinois.edu/~jgrn/
>> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.



-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
607 South Mathews Avenue, MC 150
Urbana, IL 61801
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From michel.arnaud at cirad.fr  Thu Jun 20 19:40:38 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Thu, 20 Jun 2013 19:40:38 +0200
Subject: [R] a question to transform a dataframe empty 0/1
Message-ID: <51C33E96.3020707@cirad.fr>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
URL : <https://stat.ethz.ch/pipermail/r-help/attachments/20130620/728372b5/attachment.pl>

From David.Reiner at xrtrading.com  Thu Jun 20 19:41:10 2013
From: David.Reiner at xrtrading.com (David Reiner)
Date: Thu, 20 Jun 2013 12:41:10 -0500
Subject: [R] C symbol name "psmirnov2x" not in load table
Message-ID: <9DE405308A6AA24AA794B76282C6C00F4A55B0F1B3@HQ-POST1>

I'm working with some old code that worked under R 2.15.3 but gives an error under 3.0.0 and 3.0.1 :

> 1.0 - .C("psmirnov2x", p = as.double(10.0), as.integer(1000), as.integer(1000))$p
Error in .C("psmirnov2x", p = as.double(10), as.integer(1000), as.integer(1000)) :
  C symbol name "psmirnov2x" not in load table

I don't understand why that function would not be in the 'load table'.
I've looked at release notes, but apparently missed the change that makes psmirnov2x unable to be called with .C .
I can see the function in ks.c source for 3.0.0, but apparently it can't be called with .C anymore?
Can anyone tell me how I can get the same results please?

Thanks,
-- David



This e-mail and any materials attached hereto, including, without limitation, all content hereof and thereof (collectively, "XR Content") are confidential and proprietary to XR Trading, LLC ("XR") and/or its affiliates, and are protected by intellectual property laws.  Without the prior written consent of XR, the XR Content may not (i) be disclosed to any third party or (ii) be reproduced or otherwise used by anyone other than current employees of XR or its affiliates, on behalf of XR or its affiliates.

THE XR CONTENT IS PROVIDED AS IS, WITHOUT REPRESENTATIONS OR WARRANTIES OF ANY KIND.  TO THE MAXIMUM EXTENT PERMISSIBLE UNDER APPLICABLE LAW, XR HEREBY DISCLAIMS ANY AND ALL WARRANTIES, EXPRESS AND IMPLIED, RELATING TO THE XR CONTENT, AND NEITHER XR NOR ANY OF ITS AFFILIATES SHALL IN ANY EVENT BE LIABLE FOR ANY DAMAGES OF ANY NATURE WHATSOEVER, INCLUDING, BUT NOT LIMITED TO, DIRECT, INDIRECT, CONSEQUENTIAL, SPECIAL AND PUNITIVE DAMAGES, LOSS OF PROFITS AND TRADING LOSSES, RESULTING FROM ANY PERSON'S USE OR RELIANCE UPON, OR INABILITY TO USE, ANY XR CONTENT, EVEN IF XR IS ADVISED OF THE POSSIBILITY OF SUCH DAMAGES OR IF SUCH DAMAGES WERE FORESEEABLE.


From smartpink111 at yahoo.com  Thu Jun 20 19:44:11 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 20 Jun 2013 10:44:11 -0700 (PDT)
Subject: [R] Reading a Vector into R
Message-ID: <1371750251.42036.YahooMailNeo@web142603.mail.bf1.yahoo.com>

HI,
You could save it in a .txt file. (e.g. "vec1.txt")


?source("vec1.txt")
?length(drg_470)
[1] 4495
?head(drg_470)
#[1]? 7558? 9485 10481 10609 10650 10891
str(drg_470)
# num [1:4495] 7558 9485 10481 10609 10650 ...
A.K.


Hi there, 
I am having trouble successfully reading this vector into R: 
drg_470 <- 
c(7558,9485,10481,10609,10650,10891,10909,11226,11265,11284,11342,11588,12044,12283,12355,12406,12465,12480,12553,12558,12574,12592,12606,12649,12660,12666,12667,12724,12730,12744,12748,12818,12851,12851,12856,12866,12872,12885,12895,12901,12921,12931,12932,12933,12939,12948,12979,12999,13007,13016,13065,13070,13091,13095,13115,13117,13119,13127,13135,13153,13154,13167,13172,13180,13220,13221,13226,13258,13259,13275,13320,13331,13338,13340,13343,13344,13369,13383,13390,13401,13420,13422,13424,13427,13438,13444,13445,13451,13464,13469,13473,13478,13490,13500,13506,13513,13514,13515,13520,13521,13522,13524,13524,13534,13535,13536,13540,13542,13554,13559,13561,13567,13580,13593,13594,13610,13613,13626,13629,13632,13642,13651,13660,13664,13665,13671,13672,13672,13673,13676,13681,13692,13697,13718,13720,13724,13730,13733,13754,13757,13763,13774,13779,13783,13784,13788,13798,13803,13809,13811,13814,13816,13820,13824,13836,13841,13850,13852,13857,13860,13862,1
3862,13866,13870,13870,13871,13871,13875,13876,13884,13890,13891,13891,13894,13896,13900,13903,13905,13906,13908,13908,13908,13935,13936,13941,13943,13943,13943,13947,13947,13948,13948,13950,13951,13952,13958,13959,13971,13972,13981,13994,13995,13997,14000,14003,14005,14015,14026,14027,14038,14042,14042,14045,14054,14059,14070,14070,14078,14091,14094,14094,14099,14122,14125,14128,14133,14134,14138,14148,14150,14156,14163,14164,14164,14167,14177,14179,14197,14200,14201,14204,14207,14215,14218,14225,14226,14229,14245,14247,14248,14252,14254,14271,14273,14283,14285,14285,14286,14289,14291,14293,14295,14299,14305,14316,14317,14343,14354,14354,14359,14364,14366,14367,14372,14375,14381,14387,14392,14395,14396,14398,14403,14404,14409,14410,14413,14413,14417,14424,14438,14439,14444,14444,14445,14452,14462,14464,14464,14466,14475,14480,14494,14494,14496,14507,14509,14512,14513,14517,14523,14523,14525,14539,14541,14541,14545,14546,14548,14572,14576,14579,14579,14
579,14583,14584,14595,14599,14600,14602,14603,14608,14612,14627,14628,14629,14641,14646,14654,14660,14661,14664,14664,14667,14672,14675,14676,14682,14682,14684,14690,14693,14705,14711,14713,14717,14723,14733,14734,14740,14743,14746,14747,14748,14752,14752,14754,14756,14756,14760,14760,14761,14761,14763,14769,14775,14778,14779,14780,14782,14787,14788,14788,14790,14792,14795,14795,14803,14813,14817,14818,14827,14831,14834,14834,14835,14836,14839,14840,14845,14849,14849,14855,14859,14862,14866,14868,14868,14869,14879,14882,14884,14884,14889,14904,14907,14909,14919,14921,14925,14928,14928,14931,14936,14941,14947,14949,14950,14959,14962,14962,14968,14975,14977,14981,14989,14995,14996,15001,15004,15020,15022,15026,15035,15037,15044,15048,15049,15049,15051,15069,15076,15078,15080,15087,15087,15091,15092,15094,15099,15111,15115,15119,15122,15128,15132,15132,15132,15135,15144,15145,15145,15150,15154,15156,15163,15165,15166,15170,15175,15176,15179,15182,15184,151
85,15194,15203,15206,15224,15224,15226,15227,15235,15237,15237,15239,15244,15244,15250,15252,15260,15261,15262,15275,15277,15277,15285,15286,15289,15289,15295,15298,15299,15308,15310,15311,15312,15316,15321,15326,15326,15331,15341,15343,15345,15346,15350,15354,15355,15356,15358,15363,15364,15365,15372,15376,15394,15395,15396,15402,15403,15404,15404,15405,15406,15411,15411,15416,15417,15418,15419,15420,15429,15429,15437,15440,15440,15442,15447,15451,15451,15451,15455,15456,15461,15464,15466,15469,15470,15472,15475,15478,15483,15489,15499,15507,15508,15509,15510,15514,15515,15516,15518,15525,15527,15533,15534,15538,15538,15539,15544,15546,15546,15548,15551,15553,15553,15556,15558,15558,15560,15561,15562,15562,15566,15572,15576,15581,15582,15585,15591,15591,15592,15592,15597,15599,15608,15610,15611,15615,15617,15619,15619,15622,15623,15628,15633,15633,15634,15637,15637,15637,15638,15645,15647,15649,15652,15653,15660,15661,15662,15664,15665,15665,15667,1567
4,15674,15675,15676,15677,15680,15689,15690,15691,15693,15696,15697,15699,15705,15707,15707,15707,15708,15713,15715,15717,15718,15723,15727,15728,15728,15728,15731,15731,15732,15733,15735,15738,15738,15738,15738,15740,15744,15745,15748,15749,15752,15753,15759,15759,15761,15775,15777,15779,15783,15785,15791,15794,15794,15796,15799,15802,15803,15805,15806,15806,15808,15809,15810,15812,15812,15813,15820,15821,15832,15832,15832,15833,15834,15835,15837,15838,15842,15843,15847,15847,15848,15849,15851,15851,15853,15855,15858,15859,15860,15863,15864,15865,15869,15869,15871,15874,15875,15877,15879,15881,15883,15888,15890,15891,15892,15894,15897,15897,15901,15906,15907,15909,15909,15912,15912,15912,15914,15917,15920,15921,15922,15925,15929,15933,15934,15934,15935,15936,15939,15939,15940,15940,15942,15945,15947,15947,15948,15950,15952,15956,15961,15963,15964,15965,15965,15971,15972,15977,15977,15978,15979,15984,15985,15985,15988,15990,15993,15994,15996,15996,15996
,15997,15999,16000,16000,16001,16002,16002,16003,16010,16010,16015,16016,16017,16019,16020,16022,16023,16024,16024,16024,16024,16024,16026,16026,16028,16031,16032,16036,16038,16043,16046,16047,16053,16055,16056,16056,16061,16061,16061,16065,16065,16067,16069,16069,16070,16072,16077,16080,16080,16082,16085,16085,16086,16087,16089,16090,16095,16096,16096,16097,16098,16098,16098,16099,16100,16100,16100,16101,16103,16105,16112,16113,16113,16115,16116,16117,16119,16122,16125,16126,16129,16130,16130,16131,16132,16136,16137,16144,16145,16145,16146,16147,16150,16151,16152,16154,16155,16160,16163,16163,16163,16163,16166,16169,16171,16173,16175,16176,16178,16179,16180,16181,16181,16183,16187,16188,16190,16194,16196,16197,16198,16199,16201,16203,16204,16206,16207,16207,16207,16208,16210,16211,16217,16218,16219,16220,16220,16222,16224,16225,16225,16225,16226,16228,16231,16237,16240,16240,16241,16241,16243,16244,16245,16245,16249,16250,16251,16252,16255,16257,16257,
16259,16260,16264,16266,16268,16269,16272,16273,16276,16278,16279,16281,16283,16284,16288,16294,16297,16297,16298,16300,16301,16305,16305,16307,16308,16309,16309,16309,16310,16313,16315,16317,16322,16324,16324,16326,16328,16329,16331,16333,16333,16334,16336,16343,16343,16345,16345,16347,16348,16350,16351,16353,16357,16360,16361,16362,16365,16365,16366,16368,16369,16369,16374,16374,16377,16377,16377,16378,16379,16382,16384,16384,16384,16385,16388,16390,16392,16395,16395,16395,16396,16397,16399,16401,16401,16402,16402,16403,16404,16406,16407,16411,16412,16416,16424,16424,16426,16431,16433,16437,16439,16439,16442,16445,16449,16451,16453,16455,16457,16460,16460,16461,16462,16463,16463,16464,16465,16466,16468,16475,16475,16483,16483,16485,16485,16488,16492,16494,16495,16497,16498,16500,16501,16504,16507,16514,16515,16517,16517,16522,16523,16524,16524,16524,16525,16526,16526,16528,16528,16528,16529,16529,16531,16532,16533,16539,16539,16540,16542,16542,16543,1
6544,16546,16546,16547,16547,16551,16551,16556,16558,16562,16562,16567,16569,16571,16582,16583,16584,16585,16587,16588,16590,16592,16593,16594,16597,16597,16600,16604,16604,16605,16605,16605,16614,16615,16615,16616,16616,16617,16617,16618,16619,16622,16626,16627,16628,16631,16631,16634,16636,16638,16639,16640,16642,16642,16643,16643,16644,16649,16649,16650,16653,16655,16659,16660,16664,16666,16667,16668,16671,16671,16674,16674,16678,16679,16679,16681,16681,16685,16686,16691,16695,16695,16703,16708,16708,16714,16715,16716,16717,16719,16720,16720,16721,16724,16725,16731,16733,16733,16733,16735,16736,16737,16740,16742,16742,16744,16745,16745,16746,16748,16749,16749,16750,16751,16752,16752,16753,16757,16762,16763,16766,16767,16768,16769,16779,16781,16782,16782,16787,16789,16795,16802,16803,16804,16805,16811,16812,16812,16814,16814,16816,16817,16817,16819,16820,16821,16823,16828,16829,16830,16830,16830,16831,16836,16836,16842,16844,16844,16845,16845,16846,16
848,16848,16849,16849,16851,16855,16856,16862,16865,16866,16866,16867,16868,16870,16871,16872,16875,16876,16877,16877,16878,16879,16882,16882,16883,16884,16887,16887,16888,16889,16889,16891,16891,16891,16892,16894,16902,16906,16908,16909,16911,16913,16916,16917,16920,16920,16922,16923,16923,16930,16930,16931,16938,16939,16939,16941,16943,16945,16945,16947,16947,16949,16951,16955,16956,16961,16962,16963,16966,16969,16971,16971,16972,16974,16975,16977,16979,16979,16983,16983,16983,16985,16987,16988,16996,16998,16998,17001,17001,17002,17003,17008,17010,17012,17013,17013,17014,17018,17022,17024,17026,17026,17027,17029,17032,17032,17034,17038,17040,17040,17042,17043,17043,17046,17047,17048,17049,17049,17049,17050,17051,17056,17056,17056,17056,17060,17064,17069,17069,17074,17075,17076,17079,17083,17083,17086,17087,17087,17088,17093,17093,17095,17098,17099,17101,17102,17105,17105,17109,17109,17112,17117,17118,17119,17119,17119,17126,17126,17129,17130,17137,171
37,17137,17138,17139,17140,17140,17141,17144,17144,17144,17147,17149,17150,17152,17155,17156,17157,17158,17160,17161,17161,17161,17165,17165,17165,17168,17172,17172,17173,17175,17179,17180,17181,17183,17185,17185,17186,17186,17187,17188,17189,17190,17191,17196,17197,17199,17199,17202,17202,17202,17206,17210,17212,17215,17217,17220,17221,17227,17227,17230,17231,17232,17234,17235,17235,17238,17239,17240,17241,17243,17245,17246,17246,17247,17249,17252,17254,17254,17258,17259,17260,17262,17264,17272,17273,17280,17282,17283,17283,17283,17285,17287,17287,17288,17289,17289,17290,17296,17298,17299,17299,17301,17302,17303,17303,17309,17309,17312,17313,17318,17327,17330,17334,17334,17338,17341,17342,17342,17342,17343,17347,17347,17349,17350,17350,17352,17355,17357,17357,17358,17359,17360,17362,17362,17365,17365,17368,17370,17371,17372,17374,17375,17377,17377,17379,17381,17381,17382,17382,17386,17391,17394,17395,17396,17397,17397,17399,17403,17404,17408,17408,1741
4,17417,17417,17418,17422,17426,17431,17433,17434,17439,17440,17442,17446,17447,17448,17448,17449,17449,17452,17453,17454,17455,17456,17457,17460,17463,17463,17463,17464,17465,17465,17466,17466,17468,17470,17473,17478,17479,17483,17486,17491,17493,17496,17505,17506,17506,17507,17508,17512,17513,17516,17516,17517,17519,17520,17521,17522,17522,17524,17525,17525,17530,17530,17535,17535,17537,17540,17543,17544,17547,17550,17556,17567,17567,17568,17573,17576,17579,17580,17580,17582,17582,17582,17582,17583,17585,17591,17592,17593,17594,17598,17598,17601,17602,17605,17606,17606,17609,17612,17622,17624,17625,17626,17627,17627,17628,17635,17635,17636,17639,17640,17642,17643,17645,17649,17651,17653,17655,17656,17660,17663,17666,17668,17672,17675,17676,17680,17680,17686,17687,17687,17688,17689,17693,17694,17696,17697,17699,17700,17701,17704,17704,17711,17712,17717,17719,17720,17724,17724,17725,17727,17731,17732,17737,17738,17738,17738,17748,17752,17753,17754,17756
,17757,17759,17759,17761,17761,17762,17766,17766,17767,17771,17771,17772,17773,17773,17775,17781,17784,17785,17788,17789,17792,17793,17794,17799,17800,17800,17801,17801,17801,17804,17805,17806,17806,17812,17812,17812,17813,17815,17818,17819,17822,17822,17825,17832,17833,17834,17836,17837,17838,17838,17840,17841,17854,17855,17856,17860,17861,17866,17868,17869,17873,17880,17884,17888,17889,17889,17892,17895,17898,17898,17902,17906,17908,17909,17910,17912,17913,17915,17916,17917,17918,17920,17923,17925,17928,17936,17936,17937,17946,17946,17946,17952,17952,17958,17958,17962,17963,17963,17964,17966,17969,17970,17972,17974,17975,17975,17977,17983,17985,17987,17988,17988,17988,17990,18003,18005,18007,18009,18011,18013,18014,18016,18019,18021,18022,18024,18026,18026,18028,18029,18029,18031,18035,18035,18036,18037,18041,18041,18042,18045,18052,18053,18053,18055,18059,18061,18062,18063,18066,18066,18070,18070,18075,18076,18081,18083,18084,18084,18086,18093,18093,
18100,18100,18101,18103,18107,18112,18113,18119,18120,18120,18121,18124,18124,18125,18126,18132,18133,18134,18135,18140,18147,18150,18150,18153,18153,18159,18159,18160,18174,18176,18177,18179,18182,18185,18187,18189,18192,18192,18202,18211,18213,18215,18217,18218,18219,18220,18221,18221,18225,18226,18229,18231,18234,18237,18237,18239,18241,18241,18247,18249,18249,18256,18260,18260,18262,18262,18262,18264,18265,18265,18270,18271,18271,18277,18280,18280,18300,18300,18307,18312,18313,18317,18321,18321,18322,18323,18323,18325,18326,18327,18336,18337,18339,18339,18343,18344,18344,18347,18349,18360,18368,18371,18372,18375,18375,18377,18378,18379,18384,18385,18390,18392,18393,18395,18397,18405,18406,18407,18407,18411,18414,18421,18421,18423,18426,18427,18428,18428,18429,18430,18435,18436,18436,18439,18444,18448,18451,18453,18454,18457,18463,18464,18468,18469,18471,18474,18477,18478,18481,18484,18488,18490,18495,18499,18501,18512,18516,18519,18520,18531,18533,1
8534,18534,18542,18544,18545,18546,18547,18548,18555,18556,18557,18559,18561,18563,18564,18565,18565,18570,18572,18573,18575,18577,18585,18591,18593,18594,18594,18599,18599,18600,18602,18604,18606,18606,18607,18607,18612,18614,18615,18616,18617,18618,18619,18624,18626,18628,18629,18629,18632,18633,18634,18641,18641,18643,18645,18647,18648,18650,18651,18655,18659,18660,18661,18661,18677,18677,18682,18684,18687,18699,18703,18713,18716,18717,18721,18721,18723,18725,18727,18743,18745,18745,18746,18749,18749,18751,18756,18760,18763,18766,18770,18770,18770,18777,18779,18791,18796,18805,18805,18814,18816,18822,18829,18831,18834,18838,18840,18841,18841,18842,18843,18853,18862,18866,18868,18872,18873,18881,18884,18890,18891,18891,18897,18900,18901,18904,18908,18913,18917,18918,18919,18923,18924,18925,18928,18930,18938,18940,18944,18947,18948,18954,18969,18973,18973,18974,18977,18978,18978,18982,18985,18986,18988,18990,18992,18994,18995,18998,18999,19000,19002,19
004,19013,19014,19016,19020,19021,19027,19034,19038,19046,19050,19051,19055,19057,19058,19060,19065,19066,19066,19067,19070,19071,19073,19075,19083,19088,19088,19095,19097,19103,19105,19106,19110,19113,19113,19118,19118,19122,19127,19132,19133,19141,19143,19149,19151,19159,19161,19162,19163,19163,19173,19179,19179,19180,19182,19189,19211,19216,19218,19224,19227,19227,19237,19240,19242,19246,19250,19255,19262,19263,19263,19273,19275,19279,19281,19283,19283,19290,19291,19296,19297,19301,19304,19306,19308,19308,19311,19314,19315,19316,19323,19324,19327,19330,19334,19337,19339,19339,19349,19360,19363,19366,19367,19369,19385,19386,19387,19393,19398,19403,19404,19413,19417,19418,19432,19439,19440,19440,19441,19446,19450,19457,19459,19460,19464,19472,19477,19478,19490,19491,19491,19491,19495,19496,19504,19508,19510,19515,19520,19527,19537,19554,19556,19559,19561,19564,19566,19572,19576,19581,19582,19590,19595,19596,19597,19599,19611,19611,19617,19619,19619,196
26,19627,19630,19633,19634,19647,19651,19655,19655,19658,19664,19665,19671,19671,19675,19683,19697,19700,19712,19716,19718,19732,19734,19745,19751,19766,19767,19769,19779,19786,19786,19788,19790,19797,19798,19802,19805,19817,19823,19824,19841,19847,19859,19860,19863,19864,19866,19871,19871,19874,19877,19885,19888,19896,19899,19902,19904,19915,19920,19925,19928,19929,19931,19934,19938,19939,19940,19942,19942,19943,19947,19953,19956,19956,19959,19967,19971,19978,19986,19986,20001,20002,20008,20026,20044,20051,20057,20060,20064,20071,20080,20091,20114,20115,20125,20126,20134,20135,20138,20138,20145,20148,20150,20150,20152,20154,20155,20160,20162,20167,20167,20174,20175,20175,20194,20197,20200,20202,20203,20211,20215,20215,20218,20220,20222,20224,20226,20230,20236,20256,20258,20260,20270,20271,20276,20277,20284,20288,20306,20316,20320,20321,20325,20332,20333,20334,20335,20343,20343,20347,20354,20356,20359,20368,20371,20384,20387,20416,20417,20425,20427,2043
6,20446,20457,20469,20473,20475,20476,20478,20483,20483,20490,20501,20502,20506,20509,20511,20515,20536,20543,20546,20546,20550,20559,20580,20581,20589,20592,20595,20596,20598,20616,20621,20626,20627,20630,20631,20637,20639,20647,20648,20648,20650,20652,20659,20667,20674,20683,20684,20688,20692,20693,20709,20711,20720,20741,20785,20794,20796,20797,20804,20812,20815,20841,20842,20878,20894,20897,20904,20905,20905,20911,20921,20932,20946,20962,20964,20965,20976,20977,20988,20989,20992,20995,20998,21001,21010,21019,21029,21042,21064,21065,21066,21078,21088,21092,21093,21108,21113,21115,21118,21120,21123,21124,21147,21149,21156,21168,21169,21178,21179,21185,21197,21206,21227,21230,21235,21236,21242,21244,21245,21253,21255,21256,21257,21258,21262,21266,21268,21271,21276,21288,21304,21307,21319,21322,21342,21369,21370,21375,21385,21396,21420,21420,21420,21421,21430,21431,21431,21432,21442,21442,21453,21471,21481,21491,21491,21492,21495,21497,21504,21523,21531
,21536,21538,21544,21552,21554,21561,21563,21564,21564,21568,21570,21570,21570,21574,21580,21583,21585,21588,21589,21595,21596,21605,21616,21620,21626,21628,21630,21637,21638,21639,21640,21640,21648,21650,21657,21660,21664,21666,21671,21683,21693,21705,21714,21719,21720,21726,21728,21732,21740,21741,21754,21755,21777,21779,21782,21785,21797,21808,21808,21820,21835,21860,21860,21867,21869,21882,21883,21891,21893,21905,21907,21925,21936,21950,21961,21974,21981,21984,21986,21988,21993,21995,22000,22010,22027,22036,22053,22055,22055,22059,22064,22074,22084,22086,22087,22102,22102,22113,22115,22122,22125,22142,22174,22177,22177,22214,22216,22219,22225,22235,22246,22256,22259,22294,22295,22303,22304,22308,22310,22318,22325,22332,22355,22368,22369,22378,22396,22405,22420,22425,22427,22454,22456,22467,22471,22478,22495,22496,22514,22514,22515,22530,22531,22531,22536,22554,22555,22557,22569,22571,22575,22583,22617,22618,22629,22635,22638,22642,22645,22654,22673,
22679,22686,22687,22687,22693,22696,22706,22711,22723,22751,22769,22783,22785,22786,22792,22794,22800,22807,22817,22827,22836,22861,22866,22868,22876,22896,22902,22920,22929,22938,22952,22962,22975,22976,22989,22992,23000,23012,23016,23021,23041,23047,23049,23061,23062,23065,23084,23086,23099,23101,23108,23114,23119,23126,23132,23163,23181,23189,23194,23210,23213,23213,23226,23240,23245,23259,23275,23288,23288,23294,23295,23297,23304,23315,23316,23335,23342,23347,23350,23361,23362,23367,23371,23381,23385,23398,23409,23415,23418,23425,23429,23430,23438,23439,23465,23472,23481,23484,23485,23488,23497,23512,23522,23530,23544,23558,23570,23570,23581,23583,23604,23614,23616,23618,23621,23623,23636,23650,23659,23661,23689,23690,23695,23698,23721,23722,23725,23740,23744,23746,23748,23759,23761,23762,23762,23774,23779,23790,23791,23797,23804,23806,23822,23824,23826,23826,23834,23836,23844,23849,23860,23880,23881,23881,23886,23899,23910,23911,23917,23931,23955,2
3974,23988,23990,23991,23993,24001,24008,24022,24022,24025,24032,24033,24037,24041,24041,24047,24066,24068,24069,24074,24075,24081,24083,24085,24094,24096,24111,24112,24120,24121,24124,24125,24126,24131,24138,24138,24144,24147,24149,24154,24156,24162,24175,24196,24201,24207,24207,24220,24230,24236,24248,24268,24282,24287,24300,24317,24320,24325,24348,24360,24392,24397,24398,24430,24431,24443,24448,24454,24459,24462,24472,24473,24476,24489,24512,24516,24519,24535,24542,24543,24546,24554,24556,24572,24584,24591,24595,24595,24610,24615,24651,24651,24677,24711,24720,24731,24732,24749,24749,24751,24752,24755,24756,24757,24758,24762,24774,24785,24789,24815,24833,24834,24834,24845,24856,24859,24863,24886,24889,24889,24893,24897,24902,24907,24908,24915,24926,24944,24957,24977,24987,24988,25015,25028,25051,25063,25082,25086,25101,25103,25107,25122,25131,25147,25148,25158,25180,25184,25185,25190,25197,25209,25211,25213,25217,25217,25219,25231,25232,25233,25243,25
244,25244,25248,25264,25272,25281,25305,25317,25330,25336,25362,25367,25371,25391,25394,25404,25405,25406,25417,25428,25452,25456,25460,25467,25467,25467,25490,25496,25532,25536,25539,25542,25542,25554,25577,25578,25580,25581,25594,25596,25607,25614,25619,25632,25634,25635,25635,25647,25652,25654,25666,25671,25723,25725,25726,25741,25749,25749,25767,25783,25803,25812,25817,25826,25829,25839,25870,25877,25885,25917,25921,25926,25940,25946,25948,25950,25963,25964,25977,25982,25987,26006,26014,26017,26049,26056,26064,26065,26088,26094,26117,26132,26145,26170,26191,26205,26236,26239,26240,26257,26269,26269,26273,26274,26281,26281,26288,26295,26299,26311,26312,26329,26358,26375,26381,26384,26393,26397,26423,26427,26429,26435,26443,26447,26458,26473,26479,26480,26482,26486,26538,26557,26575,26576,26589,26595,26596,26606,26615,26637,26638,26643,26648,26663,26691,26694,26694,26695,26699,26712,26722,26732,26733,26743,26763,26765,26776,26804,26822,26831,26835,268
36,26840,26850,26858,26863,26888,26924,26939,26945,26947,26953,26955,26956,26964,26968,26982,27002,27007,27007,27007,27023,27031,27032,27034,27061,27093,27097,27107,27115,27130,27142,27148,27162,27172,27185,27191,27191,27198,27207,27207,27234,27271,27310,27314,27322,27333,27339,27346,27354,27359,27373,27395,27397,27419,27421,27454,27461,27487,27510,27519,27566,27569,27571,27575,27577,27578,27580,27588,27594,27596,27598,27614,27620,27623,27633,27645,27664,27682,27688,27698,27715,27717,27719,27727,27760,27773,27781,27793,27794,27808,27841,27858,27858,27872,27920,27921,27924,27925,27926,27965,27972,27982,27995,27996,28004,28017,28026,28037,28052,28101,28139,28150,28168,28194,28200,28217,28224,28241,28244,28251,28260,28263,28263,28269,28274,28348,28351,28363,28366,28367,28372,28406,28428,28431,28433,28441,28447,28448,28453,28466,28466,28467,28477,28494,28569,28574,28579,28580,28581,28624,28655,28657,28667,28671,28711,28712,28713,28730,28733,28734,28759,2877
5,28805,28811,28818,28858,28868,28881,28899,28915,28915,28932,28940,28943,28949,28967,28984,28997,29001,29001,29009,29014,29044,29045,29050,29065,29073,29075,29082,29084,29104,29116,29120,29128,29133,29133,29137,29142,29145,29152,29153,29158,29168,29185,29185,29191,29196,29200,29204,29209,29210,29213,29214,29217,29219,29256,29267,29271,29279,29289,29289,29299,29304,29311,29318,29322,29328,29328,29346,29350,29360,29374,29376,29383,29396,29409,29415,29420,29440,29441,29446,29459,29496,29502,29524,29579,29598,29600,29608,29623,29638,29644,29665,29673,29676,29677,29686,29716,29776,29783,29792,29800,29811,29812,29837,29844,29859,29863,29865,29874,29900,29902,29915,29933,29935,29949,29957,29959,29961,29984,30002,30028,30030,30033,30042,30043,30065,30078,30081,30091,30096,30142,30161,30171,30195,30197,30197,30201,30204,30216,30261,30262,30274,30305,30317,30317,30341,30345,30381,30390,30409,30413,30414,30418,30420,30449,30449,30500,30511,30517,30532,30539,30544
,30570,30589,30594,30601,30610,30611,30612,30617,30622,30632,30633,30642,30644,30647,30650,30699,30701,30702,30702,30718,30723,30739,30745,30757,30766,30781,30783,30783,30790,30790,30792,30793,30811,30814,30843,30844,30881,30882,30888,30889,30900,30913,30927,30933,30934,30987,31002,31014,31047,31068,31076,31109,31121,31123,31123,31146,31235,31252,31261,31274,31299,31300,31301,31317,31319,31323,31324,31344,31348,31353,31355,31370,31389,31415,31416,31417,31428,31444,31462,31465,31467,31469,31487,31500,31505,31518,31521,31525,31542,31550,31552,31555,31560,31608,31611,31634,31647,31674,31690,31698,31699,31725,31759,31834,31920,31934,31937,31945,31953,31979,31982,31987,31995,32013,32044,32081,32091,32098,32158,32161,32165,32201,32233,32241,32247,32249,32285,32306,32318,32319,32319,32326,32360,32368,32428,32438,32480,32516,32517,32532,32548,32573,32593,32608,32611,32619,32643,32650,32657,32689,32700,32710,32738,32761,32770,32805,32808,32829,32831,32886,32910,
32913,32916,32925,32930,32932,32947,32983,32992,32999,32999,33090,33102,33103,33149,33156,33161,33207,33247,33251,33286,33315,33370,33371,33379,33394,33442,33454,33472,33489,33507,33507,33523,33524,33525,33530,33530,33573,33605,33609,33642,33648,33659,33669,33698,33707,33768,33772,33777,33801,33812,33886,33908,33928,33959,33962,33970,33979,33981,33984,34039,34045,34098,34098,34101,34110,34117,34161,34162,34199,34201,34228,34239,34245,34266,34269,34274,34295,34362,34375,34385,34410,34428,34443,34448,34457,34465,34507,34571,34582,34592,34638,34656,34726,34728,34830,34889,34916,34969,34972,34982,34992,35049,35060,35097,35102,35120,35164,35172,35198,35207,35232,35269,35295,35307,35331,35333,35340,35345,35375,35376,35403,35405,35425,35436,35441,35457,35483,35503,35508,35530,35534,35543,35573,35580,35625,35635,35695,35722,35732,35740,35743,35771,35804,35806,35825,35860,35867,35880,35930,35934,35983,36056,36098,36109,36178,36181,36223,36229,36273,36286,36290,3
6296,36369,36388,36406,36421,36457,36482,36485,36551,36596,36639,36640,36643,36652,36657,36696,36720,36741,36766,36780,36867,36876,36907,36947,36967,37040,37061,37079,37082,37100,37104,37175,37178,37185,37207,37240,37290,37315,37318,37318,37322,37334,37345,37352,37380,37393,37460,37471,37534,37557,37620,37630,37633,37649,37664,37665,37670,37683,37712,37722,37737,37745,37764,37783,37798,37800,37808,37809,37828,37863,37878,37913,37927,37932,37964,37981,38008,38022,38042,38136,38188,38195,38285,38289,38298,38354,38397,38398,38419,38425,38455,38471,38498,38515,38607,38650,38714,38756,38803,38941,39022,39081,39120,39145,39196,39218,39269,39327,39336,39385,39410,39431,39465,39551,39563,39586,39593,39633,39650,39654,39661,39761,39801,39915,39972,39996,40000,40043,40122,40210,40223,40226,40304,40341,40361,40478,40493,40502,40521,40585,40597,40672,40681,40693,40719,40722,40800,40923,40940,41072,41107,41118,41173,41176,41202,41207,41255,41272,41279,41420,41424,41
438,41442,41461,41484,41493,41497,41503,41620,41652,41675,41736,41747,41991,42032,42071,42075,42165,42198,42220,42306,42309,42448,42520,42564,42802,42976,42989,42994,43018,43033,43036,43142,43180,43261,43331,43343,43658,43753,43824,43879,43942,43955,44069,44137,44176,44232,44234,44257,44269,44297,44371,44574,44648,44665,44732,44777,44891,44946,44976,45067,45083,45164,45178,45189,45190,45246,45266,45377,45470,45626,45629,45662,45690,45796,45821,45955,46034,46055,46066,46180,46183,46186,46198,46418,46517,46617,46618,46686,46722,46839,46856,46875,46961,46980,46999,47088,47143,47189,47256,47315,47348,47503,47521,47645,47902,47922,47956,47989,48014,48112,48293,48400,48487,48558,48628,48743,48759,48934,48954,48996,49130,49183,49194,49228,49330,49420,49620,49730,49762,49867,49883,49921,50016,50020,50139,50177,50197,50292,50351,50478,50579,50605,50648,50762,50834,50847,50848,50903,50932,50951,50961,51015,51024,51045,51134,51150,51319,51487,51644,51682,51754,517
81,51860,51862,52187,52236,52539,52670,52802,52962,53041,53071,53359,53626,53673,53684,53711,53774,53815,53945,54132,54207,54230,54353,54404,54553,54655,54661,54787,55076,55123,55216,55317,55424,55435,55777,55864,56073,56110,56526,56645,57050,57073,57396,57439,57536,57737,57772,57781,57931,57969,57994,58025,58028,58205,58214,58221,58412,58969,59100,59373,59710,59781,59836,60313,60318,60368,60375,61038,61077,61185,61724,61937,61953,62055,62411,62994,63076,63184,63345,63359,63415,63593,63679,63802,64092,64275,64620,65093,65108,65298,65363,65477,65550,66040,66071,66130,66316,66363,66980,67100,67467,67795,67999,68178,68366,68381,69157,69288,69551,69969,70069,70094,70101,70350,70632,70887,71011,71188,72564,72972,73325,74545,75132,75787,75808,76434,76834,77738,78411,78993,81683,82245,82465,83761,85753,86194,87245,90203,90249,99215,101584,102654,106640,130054) 
drg_470 

I receive error messages concerning: "unexpected numeric 
constant" & "unexpected ','". ?Effort has been made to ensure that 
the input values are numeric & a check for commas. ?A similar, but 
shorter, vector has been inputted with no problems. ?This vector is 
length 4495. ? 

This is a basic problem, but I am unsure why this is occurring. ? 

Your help is most appreciated.


From ligges at statistik.tu-dortmund.de  Thu Jun 20 19:53:38 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 20 Jun 2013 19:53:38 +0200
Subject: [R] errorest slow
In-Reply-To: <kpv4lo$22n$1@ger.gmane.org>
References: <kpv4lo$22n$1@ger.gmane.org>
Message-ID: <51C341A2.7070003@statistik.tu-dortmund.de>



On 20.06.2013 16:46, David martin wrote:
> Hi ,
> When using errorest on a large dataset (12000 variables) it performs
> very slow. By looking at the randomforest package it says that for
> largedatasets the use of the formula is discouraged.
>
> So it's better to use the x and y terms as the example below:
> rf<-randomForest(x=df[trainindices,-1],y=df[trainindices,1],xtest=df[testindices,-1],ytest=df[testindices,1],
> do.trace=5, ntree=500)
>
> Would it be possible to modify errorest so that it uses x and y rather
> than formula. I think that would increase speed on large datasets.
>
> errorest(type~.,data=mydate, model=randomForest,mtry=2)#will perform slow
> errorest(x=type,y=variables,data=mydate,
> model=randomForest,mtry=2)#would perform faster if implemented

Talk to the maintainer of the package you found errorest() in?

Best,
Uwe Ligges

> thanks,
> david
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Thu Jun 20 19:55:54 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 20 Jun 2013 10:55:54 -0700 (PDT)
Subject: [R] a question to transform a dataframe empty 0/1
Message-ID: <1371750954.69952.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,

Not sure if you wanted the entries with "0".

library(reshape2)
?dfMelt<-melt(df,id.var=c("Country","Iso")) 

#subset those with "1"

dfNew<- subset(dfMelt,value==1,select=-4)?row.names(dfNew)<- 1:nrow(dfNew)
?dfNew
#??????? Country Iso?? variable
#1????? Zimbabwe? ZW????? Abaco
#2? South Africa? ZA????? Abaco
#3??? Madagascar? MG????? Abaco
#4????????? Mali? ML????? Abaco
#5???????? Kenya? KE????? Abaco
#6? Burkina Faso? BF????? Abaco
#7????? Tanzania? TZ Adaptclone
#8????????? Mali? ML Adaptclone
#9??? Mozambique? MZ Adaptclone
#10?? Madagascar? MG Adaptclone
#11??????? Ghana? GH Adaptclone
#12????? Nigeria? NG Adaptclone


A.K.


Hello 

I have the following dataframe : 
df <- data.frame( 
Country=c("Zimbabwe","Burkina Faso","South Africa","Madagascar","Tanzania", 
"Mali","Mozambique","Madagascar","Ghana","Nigeria","Kenya","Burkina Faso", 
? "South Africa","Tanzania","Kenya","Ethiopia" ) , 

Iso=c("ZW","BF","ZA","MG","TZ","ML","MZ","MG","GH","NG","KE","BF", 
? "ZA","TZ","KE","ET") , 

Abaco=c(1,0,1,1,0,1,0,0,0,0,1,1,0,0,0,0) , 
Adaptclone= c(0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,0) 
) 
There is a lot of column like Abaco, Adaptclone,... 
I would like to built a dataframe 
wich transforms the initial dataframe of 4 columns into a dataframe of 3 
columns as the following dataframe 

Country ? ? ? ? ?Iso ? ?Project 
Zimbabwe ? ? ? ? ZW ? ? Abaco 
South Africa ? ? ZA ? ? Abaco 
Madagascar ? ? ? MG ? ? Abaco 
Tanzania ? ? ? ? TZ ? ? Adaptclone 
Mali ? ? ? ? ? ? ML ? ? Abaco 
Mali ? ? ? ? ? ? ML ? ? Adaptclone 
...... 

Any idea ? 
Michel 

-- 
Michel ARNAUD 
Charg? de mission aupr?s du DRH 
DGDRD-Drh - TA 174/04 
Av Agropolis 34398 Montpellier cedex 5 
tel : 04.67.61.75.38 
fax : 04.67.61.57.87 
port: 06.47.43.55.31 



From dkesh at qcue.com  Thu Jun 20 20:46:04 2013
From: dkesh at qcue.com (Dan Keshet)
Date: Thu, 20 Jun 2013 13:46:04 -0500
Subject: [R] [SOLVED] Re: "Error: cannot allocate vector of size 1.9 Gb"
 when loading xtable help
Message-ID: <CANhnsHONXO4x+kAL6F0RkY849rfRtS34dC6Eq4ZyJjS3C6RHOw@mail.gmail.com>

Solved on my end.  Turned out to be caused by cyclic dependencies in
our (internal) packages.  Attempts to install/load them all caused
wonky things to happen later on.

On Sat, Jun 15, 2013 at 6:18 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 13-06-14 7:02 PM, Dan Keshet wrote:
>>
>> I am using xtable version 1.7-1 built for R 3.0.1 on:
>>
>> R version 3.0.1 (2013-05-16)
>> Platform: i686-pc-linux-gnu (32-bit)
>>
>> Sometimes, not every time, when I load xtable or attempt to load the
>> help, I get an error such as this "Error: cannot allocate vector of
>> size 1.9 Gb" (Stacktrace from recover() below).
>>
>> Other times, when loading packages that depend on xtable, I get an
>> error such as this:
>>
>> Loading required namespace: xtable
>> Error in assign(identifier, list(name, description, identifier, help,  :
>>    lazy-load database 'P' is corrupt
>>
>> I have attempted to reinstall the package using
>> install.packages("xtable", type="source"), but the error persists (and
>> the xtable.rdb file is identical).
>>
>> I have also tried this on macs and gotten the same error.
>>
>> Thank you for any help.
>>
>> -------------
>>>
>>> ?xtable
>>
>> Error: cannot allocate vector of size 1.9 Gb
>
>
> I would guess this is not related to the xtable help page, but is a sign of
> something being corrupted (e.g. an out of range write in memory), and this
> is just a symptom of the corruption.
>
> If we could make this reliably reproducible, we could track it down, but
> without that, it is nearly impossible.
>
> Could try starting an empty R session (nothing reloaded from .Rdata),
> run until you trigger the error, then save the session history?  See if
> replaying that history triggers the error again in the same place.  If so,
> see if you can shrink it to a minimal script that others can try, and post
> that.
>
> Duncan Murdoch
>
>>
>> Enter a frame number, or 0 to exit
>>
>> 1: print("/usr/local/analytics/rlibs/xtable/help/xtable")
>> 2:
>> print.help_files_with_topic("/usr/local/analytics/rlibs/xtable/help/xtable"
>> 3: tools::Rd2txt(.getHelpFile(file), out = tempfile("Rtxt"), package =
>> pkgname
>> 4: prepare_Rd(Rd, defines = defines, stages = stages, fragment = fragment,
>> ...
>> 5: .getHelpFile(file)
>> 6: tools:::fetchRdDB(RdDB, basename(file))
>> 7: lazyLoadDBexec(filebase, fun)
>> 8: fun(environment())
>> 9: fetch(key)
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From smartpink111 at yahoo.com  Thu Jun 20 22:49:12 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 20 Jun 2013 13:49:12 -0700 (PDT)
Subject: [R] adding by categories in a data frame???
Message-ID: <1371761352.29720.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
dat1<- read.table(text="
name?? number
a??????????? 2
a??????????? 3
b??????????? 5
b??????????? 7
c???????????? 9
c???????????? 1
",sep="",header=TRUE,stringsAsFactors=FALSE) 


aggregate(number~name,data=dat1,sum)
#? name number
#1??? a????? 5
#2??? b???? 12
#3??? c???? 10

#or
library(plyr)
ddply(dat1,.(name),summarize,Sum_Number=sum(number))
#? name Sum_Number
#1??? a????????? 5
#2??? b???????? 12
#3??? c???????? 10

#or
library(data.table)
dt1<- data.table(dat1)

dt1[,list(Sum_Number=sum(number)),by=name]
#?? name Sum_Number
#1:??? a????????? 5
#2:??? b???????? 12
#3:??? c???????? 10


##Speed comparison:
set.seed(1254)
name<- sample(letters,1e6,replace=TRUE)
number<- sample(1:10,1e6,replace=TRUE)

datTest<- data.frame(name,number,stringsAsFactors=FALSE)

system.time(res1<-aggregate(number~name,data=datTest,sum))
# user? system elapsed 
#? 2.184?? 0.000?? 1.772 


system.time(res2<-ddply(datTest,.(name),summarize,Sum_Number=sum(number)))
# user? system elapsed 
#? 0.256?? 0.000?? 0.227?

dtTest<- data.table(datTest)

system.time(res3<- dtTest[,list(Sum_Number=sum(number)),by=name])
#user? system elapsed 
#? 0.084?? 0.000?? 0.066 
?names(res1)[2]<- names(res2)[2]
?identical(res1,res2)
#[1] TRUE
?res3New<- res3[order(name),]
identical(res1,as.data.frame(res3New))
#[1] TRUE




#to get descriptive statistics
by(dat1[,2],dat1[,1],summary)

#or
library(psych)
?describeBy(dat1[,2],dat1[,1],mat=TRUE)

A.K.


Hello. I have a big table and need to have descriptive statistics by sub-groups of data. 
For example: 
name ? number 
a ? ? ? ? ? ?2 
a ? ? ? ? ? ?3 
b ? ? ? ? ? ?5 
b ? ? ? ? ? ?7 
c ? ? ? ? ? ? 9 
c ? ? ? ? ? ? 1 
How can I get/print a table that show the sum of numbers for each name? 
a = 5 
b = 12 
c = 10 
?Thank you!!!


From Roger.Vallejo at ARS.USDA.GOV  Thu Jun 20 22:57:35 2013
From: Roger.Vallejo at ARS.USDA.GOV (Vallejo, Roger)
Date: Thu, 20 Jun 2013 20:57:35 +0000
Subject: [R] BINARY traits GENETIC CORRELATION
Message-ID: <3DCD67B8B481FA47AF340FE7868200EE0B7B7A84@001FSN2MPN1-062.001f.mgd2.msft.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130620/c3202016/attachment.pl>

From mayer at iiasa.ac.at  Thu Jun 20 11:07:38 2013
From: mayer at iiasa.ac.at (MAYER Hans)
Date: Thu, 20 Jun 2013 11:07:38 +0200
Subject: [R] compiling Rcpp with 3.0.1 on Solaris 10
Message-ID: <AEB6E9807EE5E04BA2F4A6CD4CE9DB198EA0FAD93D@rhine.iiasa.ac.at>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130620/58d00dda/attachment.pl>

From katherine_gobin at yahoo.com  Thu Jun 20 12:45:28 2013
From: katherine_gobin at yahoo.com (Katherine Gobin)
Date: Thu, 20 Jun 2013 18:45:28 +0800 (SGT)
Subject: [R] Choosing subset of data.frame
Message-ID: <1371725128.9803.YahooMailNeo@web193204.mail.sg3.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130620/9f223907/attachment.pl>

From bcrombie at utk.edu  Thu Jun 20 15:38:17 2013
From: bcrombie at utk.edu (Crombie, Burnette N)
Date: Thu, 20 Jun 2013 13:38:17 +0000
Subject: [R] help with text patterns in strings
In-Reply-To: <1371674787.56731.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1371491993351-4669714.post@n4.nabble.com>
	<1371496520.95656.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<559C998F7039D84C9793AE43D9BBE9CE77A0FC69@kmbx3.utk.tennessee.edu>
	<1371501469.76400.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<559C998F7039D84C9793AE43D9BBE9CE77A0FCA0@kmbx3.utk.tennessee.edu>
	<1371502465.96019.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<559C998F7039D84C9793AE43D9BBE9CE77A0FF5C@kmbx3.utk.tennessee.edu>,
	<1371674787.56731.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <559C998F7039D84C9793AE43D9BBE9CE77A0FFAC@kmbx3.utk.tennessee.edu>

Thanks, Arun.  I will study this as soon as possible.  I really appreciate your time and R mentoring.
________________________________________

Try this:
res1<-sapply(vec3,function(x) length(vec2New[grep(x,vec2New)]) )
dat1<-data.frame(res1,Name=names(vec3))

 dat1$Name<-factor(dat1$Name,levels=c("early","mid","late","wknd"))
 with(dat1,tapply(res1,list(Name),FUN=sum))
#early   mid  late  wknd
 #   0     1     4     6

#or
 sapply(split(res1,names(vec3)),sum)
#early  late   mid  wknd
 #   0     4     1     6
A.K.

From budhua at mail.nih.gov  Thu Jun 20 15:54:53 2013
From: budhua at mail.nih.gov (Budhu, Anuradha (NIH/NCI) [E])
Date: Thu, 20 Jun 2013 13:54:53 +0000
Subject: [R] Combining Affy data
Message-ID: <5C68317AC16857498C5C37BF60F639BE0FFBF3@MLBXv05.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130620/a91fb5ae/attachment.pl>

From lillea011084 at hotmail.com  Thu Jun 20 16:21:33 2013
From: lillea011084 at hotmail.com (Annette Timm)
Date: Thu, 20 Jun 2013 16:21:33 +0200
Subject: [R] How to make a test for linearity of a Passing-Bablok Regression
Message-ID: <COL126-W463049867D37B112BDD103C28E0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130620/d9dcfb17/attachment.pl>

From tchen10 at qub.ac.uk  Thu Jun 20 17:41:42 2013
From: tchen10 at qub.ac.uk (tong)
Date: Thu, 20 Jun 2013 08:41:42 -0700 (PDT)
Subject: [R] how to run copula-based quantile regression
Message-ID: <1371742902644-4669984.post@n4.nabble.com>

Hi,

I want to run a quantile regression (Y=a+bX+e) using normal and t copula for
my dissertation.

I 've read the documentation of "copula" and "copBasic". However, I still
have difficulty to deal with my data.

Details are as following:

I've already loaded xls data into r using "XLConnect" package.
 excel.file<-file.path("Q:/dailyvstoxx.xls")
 dailyvstoxx<-readWorksheetFromFile(excel.file, sheet=1)

Then, I've loaded "copBasic"package.

According to the example 'qua.regressCOP'  in the documentation "copBasic":

theta <- 10
R <- qua.regressCOP(cop=PLACKETTcop, para=c(theta))

 I have two questions:

1) how to solve out the 'theta' of my data

2)I want to use normal copula, so I try:

R<- qua.regressCOP(cop=NORMALcop, para=c(theta))

However, I get:

Error in derCOP(cop = cop, u = u, v = x, delu = delu, para = para, ...) : 
  object 'NORMALcop' not found

I wonder what is the code for normal copula and t copula in copBasic.

I am looking forward to your reply.

Yours,

Tong












--
View this message in context: http://r.789695.n4.nabble.com/how-to-run-copula-based-quantile-regression-tp4669984.html
Sent from the R help mailing list archive at Nabble.com.


From safisce at gmail.com  Thu Jun 20 20:20:21 2013
From: safisce at gmail.com (Safiye Celik)
Date: Thu, 20 Jun 2013 11:20:21 -0700
Subject: [R] Difference between Lloyd and Forgy algorithms used in R
 built-in kmeans clustering function
In-Reply-To: <51C2ACD6.7000300@ymail.com>
References: <CAJRSaT-ieEDKuC-e+F7JFLHScBmn+BZQ0=EWwh=BuLmtOLV2Ug@mail.gmail.com>
	<51C2ACD6.7000300@ymail.com>
Message-ID: <CAJRSaT-HqaYiuw9usExQMEKF5SDZCjy-YFRCibMvsGDC3oEnZA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130620/2a1788f5/attachment.pl>

From nashjc at uottawa.ca  Thu Jun 20 22:42:26 2013
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Thu, 20 Jun 2013 16:42:26 -0400
Subject: [R] R-help Digest, Vol 124, Issue 21
In-Reply-To: <mailman.27.1371722409.12621.r-help@r-project.org>
References: <mailman.27.1371722409.12621.r-help@r-project.org>
Message-ID: <51C36932.3000602@uottawa.ca>

And it could be that you should try nlmrt or minpack.lm.

I don't think you were at my talk in Jena May 23 -- might have been very 
helpful to you.

JN


On 13-06-20 06:00 AM, r-help-request at r-project.org wrote:
> Message: 47
> Date: Wed, 19 Jun 2013 13:17:29 -0500
> From: "Adams, Jean"<jvadams at usgs.gov>
> To: pakoun<pkount at bgc-jena.mpg.de>
> Cc: R help<r-help at r-project.org>
> Subject: Re: [R] nls singular gradient ..as always..
> Message-ID:
> 	<CAN5YmCEF9Ut5J-Zqh6URYOn0bfH=M=cUGMgDmtzy9OwWkrw24A at mail.gmail.com>
> Content-Type: text/plain
>
> It's hard to say without seeing the data.  It could be the data, it could
> be the starting values, it could be the model choice.
>
> Jean


From jffv201 at exeter.ac.uk  Thu Jun 20 13:22:32 2013
From: jffv201 at exeter.ac.uk (Viana, Joana)
Date: Thu, 20 Jun 2013 11:22:32 +0000
Subject: [R] help - transforming closure to vector
Message-ID: <6759C8D1991F1A479F396C2A6BD7E833FE1192@VMEXCHANGEMBS1A.isad.isadroot.ex.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130620/b6a22b50/attachment.pl>

From tsonnekus at gmail.com  Thu Jun 20 13:38:28 2013
From: tsonnekus at gmail.com (Tinus Sonnekus)
Date: Thu, 20 Jun 2013 13:38:28 +0200
Subject: [R] Help with line graph
Message-ID: <CAPEc57Ewda5f5hY__-rugGfQ7rGY+3Fb=Mm5L-Hkkc23gPaRsA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130620/c31d8799/attachment.pl>

From vera.hinz at wiso.uni-hamburg.de  Thu Jun 20 13:39:08 2013
From: vera.hinz at wiso.uni-hamburg.de (Vera)
Date: Thu, 20 Jun 2013 04:39:08 -0700 (PDT)
Subject: [R] Problem with "dea.boot" under R 3.0.1
Message-ID: <1371728348586-4669964.post@n4.nabble.com>

Hi all,

we conducted a DEA and wanted to correct our efficiency for bias by
bootstrapping with R version 3.0.1. With this version, the package "FEAR"
does not work anymore. Therefore, we used "dea.boot" for bootstrapping.
This, however, returns us negative bias-corrected efficiencies. 

In the past, we have used "boot.fear" and this never delivered any negative
bias-corrected efficiencies. 
Is this a bug of dea.boot or of R 3.0.1? How can we solve this?

Thanks and best regards,
Vera



--
View this message in context: http://r.789695.n4.nabble.com/Problem-with-dea-boot-under-R-3-0-1-tp4669964.html
Sent from the R help mailing list archive at Nabble.com.


From djandrija at gmail.com  Thu Jun 20 23:48:05 2013
From: djandrija at gmail.com (andrija djurovic)
Date: Thu, 20 Jun 2013 23:48:05 +0200
Subject: [R] Choosing subset of data.frame
In-Reply-To: <1371725128.9803.YahooMailNeo@web193204.mail.sg3.yahoo.com>
References: <1371725128.9803.YahooMailNeo@web193204.mail.sg3.yahoo.com>
Message-ID: <CABcwgRTDu8fYLrBoMhtsBvMtnVxCftwcgoEJT5Yk_RiMOjtBtg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130620/4834cc08/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Thu Jun 20 23:48:56 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 20 Jun 2013 17:48:56 -0400
Subject: [R] BINARY traits GENETIC CORRELATION
In-Reply-To: <3DCD67B8B481FA47AF340FE7868200EE0B7B7A84@001FSN2MPN1-062.001f.mgd2.msft.net>
References: <3DCD67B8B481FA47AF340FE7868200EE0B7B7A84@001FSN2MPN1-062.001f.mgd2.msft.net>
Message-ID: <cd27712f-1d3f-4f1e-8a96-2de56e879ea2@email.android.com>

Re-posting, particularly without referencing your earlier post, is bad mailing-list etiquette. Posting in HTML is particularly frowned upon here also. Nor is this a statistical methods support forum... it is about R. I for one am finding your question very jargonish and obscure. If your question is straightforward in the genetics domain then there might be more responsiveness in the Bioconductor mailing list. Otherwise, you may need to frame your question more directly in terms of the R language, with an example starting data set and expected results [1].

You are also expected to read the Posting Guide mentioned at the end of every R-help email.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

"Vallejo, Roger" <Roger.Vallejo at ARS.USDA.GOV> wrote:

>Dear R Users,
>I have always used ASReml, MTDFREML, SAS, etc. to estimate genetic
>correlation (Rg) between two continuous quantitative traits (also
>continuous and binary trait) but I have never used R package to
>estimate Rg. However, I use R package for many of my other statistical
>analysis needs. The R package is a great tool that has advanced to a
>level that now we can estimate whole genome-enabled breeding values in
>genomic selection research. So, with the aim of moving out of those
>packages (listed above) which are either expensive or have little
>support, I would like to know if we can estimate Rg between two binary
>traits (disease status: alive vs. dead) with the R package.
>
>My data: we have 100 full-sib (FS) families, and two random samples
>(each with n= 200 FS fish) from each FS family were evaluated for
>resistance response to two different bacterial diseases, separately. It
>implies that both traits are not recorded in the same individual; each
>trait is recorded in different groups of full-sibs (random sampled from
>a FS family). So using this family relationship (full-sibs), I would
>like to estimate the Rg between these two disease resistance traits; of
>course I would like to estimate Rg with the R package. I will
>appreciate having directions on which R package to use if any, or
>combination of R functions needed to use to calculate the Rg (between
>two binary traits; disease survival traits).
>Thank you very much in advance for your help.
>Roger
>
>
>Roger L. Vallejo, Ph.D.
>U.S. Department of Agriculture, ARS, NCCCWA
>Voice:  (304) 724-8340 Ext. 2141
>Email:  roger.vallejo at ars.usda.gov<mailto:roger.vallejo at ars.usda.gov>
>http://www.ars.usda.gov/pandp/people/people.htm?personid=37662
>
>
>
>
>
>This electronic message contains information generated by the USDA
>solely for the intended recipients. Any unauthorized interception of
>this message or the use or disclosure of the information it contains
>may violate the law and subject the violator to civil or criminal
>penalties. If you believe you have received this message in error,
>please notify the sender and delete the email immediately.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From teotjunk at gmail.com  Fri Jun 21 00:23:32 2013
From: teotjunk at gmail.com (Tjun Kiat Teo)
Date: Fri, 21 Jun 2013 06:23:32 +0800
Subject: [R] Generalized Cholesky Inverse
Message-ID: <CAH=5_TXdXUY9w66WtKGvo1pNtzdjzoqX09y26ecpNAgfRzb=mg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130621/e0cc2339/attachment.pl>

From smartpink111 at yahoo.com  Fri Jun 21 00:34:26 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 20 Jun 2013 15:34:26 -0700 (PDT)
Subject: [R] Choosing subset of data.frame
In-Reply-To: <1371725128.9803.YahooMailNeo@web193204.mail.sg3.yahoo.com>
References: <1371725128.9803.YahooMailNeo@web193204.mail.sg3.yahoo.com>
Message-ID: <1371767666.75228.YahooMailNeo@web142606.mail.bf1.yahoo.com>

HI,
You could also use:

beta_results[!is.na(match(beta_results[,1],instru)),]
#? instrument beta_values
#3??????? JKL?????? 0.529
#6??????? STU????? -1.080
#8??????? XYZ?????? 0.420


#If there are no duplicates, this could also work

beta_results[match(instru,beta_results[,1]),]
#? instrument beta_values
#3??????? JKL?????? 0.529
#6??????? STU????? -1.080
#8??????? XYZ?????? 0.420

A.K.


----- Original Message -----
From: Katherine Gobin <katherine_gobin at yahoo.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Thursday, June 20, 2013 6:45 AM
Subject: [R] Choosing subset of data.frame

Dear R Forum

I have a data frame as

beta_results = data.frame(instrument = c("ABC", "DEF", "JKL",? "LMN", "PQR", "STU", "UVW", "XYZ"), 

beta_values = c(1.27, -0.22, 0.529, 0.011, 2.31, -1.08, -2.7, 0.42))

> beta_results
? instrument beta_values
1??????? ABC?????? 1.270
2??????? DEF????? -0.220
3??????? JKL?????? 0.529
4??????? LMN?????? 0.011
5??????? PQR?????? 2.310
6??????? STU????? -1.080
7??????? UVW????? -2.700
8??????? XYZ?????? 0.420


Through some other process, I am getting instrument names as say (which may change each time I run this process
and hence I can't hard code it).


instru = c("JKL", "STU", "XYZ")

Now I want the subset of beta_results, (say beta_results_A)? pertaining to only instru i.e

beta_results_A = 


? instrument beta_values
3??????? JKL?????? 0.529
6??????? STU????? -1.080
8??????? XYZ?????? 0.420


I did try

beta_results_A = beta_results[instru]
or
beta_results_A = subset(beta_results, beta_results$instrument = instru]

but I guess it's failing.

Kindly guide

Regards

Katherine
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ivo.welch at anderson.ucla.edu  Fri Jun 21 00:45:29 2013
From: ivo.welch at anderson.ucla.edu (ivo welch)
Date: Thu, 20 Jun 2013 15:45:29 -0700
Subject: [R] canonical AR1 w/ measurement error -> pointers?
Message-ID: <CAPr7RtVFKHTP+4qKfdC6zQ7ST2OzBFHrbxNtDgx06aitvB8PuA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130620/7ca5fa36/attachment.pl>

From markleeds2 at gmail.com  Fri Jun 21 01:07:11 2013
From: markleeds2 at gmail.com (Mark Leeds)
Date: Thu, 20 Jun 2013 19:07:11 -0400
Subject: [R] canonical AR1 w/ measurement error -> pointers?
In-Reply-To: <CAPr7RtVFKHTP+4qKfdC6zQ7ST2OzBFHrbxNtDgx06aitvB8PuA@mail.gmail.com>
References: <CAPr7RtVFKHTP+4qKfdC6zQ7ST2OzBFHrbxNtDgx06aitvB8PuA@mail.gmail.com>
Message-ID: <CAHz+bWb3xVURnRHsRzE3FVOYe0uwq6Bp-YH6mzkvK8p8Edu9+Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130620/a5396288/attachment.pl>

From ivo.welch at gmail.com  Fri Jun 21 02:19:42 2013
From: ivo.welch at gmail.com (ivo welch)
Date: Thu, 20 Jun 2013 17:19:42 -0700
Subject: [R] canonical AR1 w/ measurement error -> pointers?
In-Reply-To: <CAHz+bWb3xVURnRHsRzE3FVOYe0uwq6Bp-YH6mzkvK8p8Edu9+Q@mail.gmail.com>
References: <CAPr7RtVFKHTP+4qKfdC6zQ7ST2OzBFHrbxNtDgx06aitvB8PuA@mail.gmail.com>
	<CAHz+bWb3xVURnRHsRzE3FVOYe0uwq6Bp-YH6mzkvK8p8Edu9+Q@mail.gmail.com>
Message-ID: <CAPr7RtXpGEdTSXCcK+B2wafb70+-A_Bgk7GF+pQCyZrOVCbang@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130620/fd461138/attachment.pl>

From kridox at ymail.com  Fri Jun 21 02:26:38 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Fri, 21 Jun 2013 09:26:38 +0900
Subject: [R] Generalized Cholesky Inverse
In-Reply-To: <CAH=5_TXdXUY9w66WtKGvo1pNtzdjzoqX09y26ecpNAgfRzb=mg@mail.gmail.com>
References: <CAH=5_TXdXUY9w66WtKGvo1pNtzdjzoqX09y26ecpNAgfRzb=mg@mail.gmail.com>
Message-ID: <CAAcyNCz0cYcypT3bgxpOb53KRx4kFQq1a2fWQae6tT5mW7xYrg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130621/02b9ba6d/attachment.pl>

From jim at mail.bitwrit.com.au  Fri Jun 21 03:43:14 2013
From: jim at mail.bitwrit.com.au (Jim Lemon)
Date: Fri, 21 Jun 2013 11:43:14 +1000 (EST)
Subject: [R] Help with line graph
In-Reply-To: <CAPEc57Ewda5f5hY__-rugGfQ7rGY+3Fb=Mm5L-Hkkc23gPaRsA@mail.gmail.com>
References: <CAPEc57Ewda5f5hY__-rugGfQ7rGY+3Fb=Mm5L-Hkkc23gPaRsA@mail.gmail.com>
Message-ID: <53752.64.134.228.190.1371778994.squirrel@www.bitwrit.com.au>

Hi Tinus,
Given your read.csv commands, the names of the seamounts will be read as
factors, so col=as.numeric(All$Seamount) should get you started.

Jim

> Hi
>
> Struggling to get this correct today. There is 6 seamounts and I would
> like
> each seamount to be a different line colour.
>
> The part of data set looks like this
>
>   Seamount Group.1     Depthm        NO3     SiO4       PO4        NO2
> 1 Atlantis   Below 177.257182 4.90729821 4.402966 0.4059566 0.06988687
> 2 Atlantis    Fmax  59.687077 0.91698665 3.275964 0.3092102 0.08840281
> 3 Atlantis    Deep  50.612571 0.07528409 2.941385 0.1900287 0.05543472
> 4 Atlantis Shallow  25.467875 0.54261259 2.604665 0.2801735 0.07639043
> 5 Atlantis Surface   4.429333 0.63933469 3.897832 0.2377492 0.08753721
> 6   Sapmer   Below 176.621000 3.39728310 4.481637 0.2970078 0.14552190
> 7   Sapmer    Fmax  30.986270 0.82713310 3.324292 0.2625740 0.15888890
> 8   Sapmer Shallow  21.623250 0.47957940 2.370052 0.2627357 0.10683190
> 9   Sapmer Surface   4.872000 0.80187680 2.643195 0.2581714 0.16521010
>
> The code that I am using looks like this. It makes to different colour
> points but line is
>
> setwd("C:\\Users\\Tinus\\Documents\\NMMU\\R\\Seamounts")
> All <- read.csv("Book1.csv")
>
> # Column headers
> colnames(All)
>
> # Get the unique seamounts
> as.character(unique(All$Seamount))
> sm <- as.character(unique(All$Seamount))
>
> # Use a loop to loop through each of the seamounts
> for( i in sm[1:2]) {
>  NO3 <- All[i%in%sm,4]
>  Depth <- -All[i%in%sm,3]
> plot(NO3, Depth,pch=1,col = 1:2) #plot
> lines(NO3, Depth,pch=1,col = 1:2) #plot
> }
>
> Thanks for helping me.
>
> Regards,
> Tinus
>
> --
> M.J. Sonnekus
> PhD Candidate (The Phytoplankton of the southern Agulhas Current Large
> Marine Ecosystem (ACLME))
> Department of Botany
> South Campus
> Nelson Mandela Metropolitan University
> PO Box 77000
> Port Elizabeth
> South Africa
> 6031
>
> Cell: 082 080 9638
> E-mail: tsonnekus at gmail.com
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From michel.arnaud at cirad.fr  Fri Jun 21 06:10:20 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Fri, 21 Jun 2013 06:10:20 +0200
Subject: [R] a question to transform a dataframe empty 0/1
In-Reply-To: <1371750954.69952.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1371750954.69952.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <51C3D22C.1060403@cirad.fr>

Thank you arun !
I don't know the library reshape2
Michel

Le 20/06/2013 19:55, arun a ?crit :
> Hi,
>
> Not sure if you wanted the entries with "0".
>
> library(reshape2)
>   dfMelt<-melt(df,id.var=c("Country","Iso"))
>
> #subset those with "1"
>
> dfNew<- subset(dfMelt,value==1,select=-4) row.names(dfNew)<- 1:nrow(dfNew)
>   dfNew
> #        Country Iso   variable
> #1      Zimbabwe  ZW      Abaco
> #2  South Africa  ZA      Abaco
> #3    Madagascar  MG      Abaco
> #4          Mali  ML      Abaco
> #5         Kenya  KE      Abaco
> #6  Burkina Faso  BF      Abaco
> #7      Tanzania  TZ Adaptclone
> #8          Mali  ML Adaptclone
> #9    Mozambique  MZ Adaptclone
> #10   Madagascar  MG Adaptclone
> #11        Ghana  GH Adaptclone
> #12      Nigeria  NG Adaptclone
>
>
> A.K.
>
>
> Hello
>
> I have the following dataframe :
> df <- data.frame(
> Country=c("Zimbabwe","Burkina Faso","South Africa","Madagascar","Tanzania",
> "Mali","Mozambique","Madagascar","Ghana","Nigeria","Kenya","Burkina Faso",
>    "South Africa","Tanzania","Kenya","Ethiopia" ) ,
>
> Iso=c("ZW","BF","ZA","MG","TZ","ML","MZ","MG","GH","NG","KE","BF",
>    "ZA","TZ","KE","ET") ,
>
> Abaco=c(1,0,1,1,0,1,0,0,0,0,1,1,0,0,0,0) ,
> Adaptclone= c(0,0,0,0,1,1,1,1,1,1,0,0,0,0,0,0)
> )
> There is a lot of column like Abaco, Adaptclone,...
> I would like to built a dataframe
> wich transforms the initial dataframe of 4 columns into a dataframe of 3
> columns as the following dataframe
>
> Country          Iso    Project
> Zimbabwe         ZW     Abaco
> South Africa     ZA     Abaco
> Madagascar       MG     Abaco
> Tanzania         TZ     Adaptclone
> Mali             ML     Abaco
> Mali             ML     Adaptclone
> ......
>
> Any idea ?
> Michel
>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From mayer at iiasa.ac.at  Fri Jun 21 09:03:51 2013
From: mayer at iiasa.ac.at (MAYER Hans)
Date: Fri, 21 Jun 2013 09:03:51 +0200
Subject: [R] compiling Rcpp with 3.0.1 on Solaris 10
Message-ID: <AEB6E9807EE5E04BA2F4A6CD4CE9DB198EA0FAD940@rhine.iiasa.ac.at>



Hello 

My colleagues asked me to install "R" with module "shiny". 
R version 3.0.1 compiled fine on Solaris 10 and is running well. 

I tried to install "shiny". With the dependencies "Rcpp" should be installed before. But the compile step did fail. See below. 
The initial error message is "Error in dyn.load(file, DLLpath = DLLpath, ...) :" 
Before there are some warning. The final problem is, that the shared library Rcpp.so was not generated.

I am not familiar with R but I? could manage to compile a lot of source code on Solaris. Very often it's only a small change in Makefile or source code. 
Is there a way to compile "Rcpp" manually ? 
Or how-to fix this problem. I am sure, it's not a major issue. 

Kind regards
Hans




# R

R version 3.0.1 (2013-05-16) -- "Good Sport"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: sparc-sun-solaris2.10 (32-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> install.packages('Rcpp')
--- Please select a CRAN mirror for use in this session ---
trying URL 'http://cran.rstudio.com/src/contrib/Rcpp_0.10.3.tar.gz'
Content type 'application/x-gzip' length 2395986 bytes (2.3 Mb)
opened URL
==================================================
downloaded 2.3 Mb

* installing *source* package 'Rcpp' ...
** package 'Rcpp' successfully unpacked and MD5 sums checked
** libs
g++ -I/usr/local/lib/R/include -DNDEBUG -I../inst/include/ -I/usr/local/include -I/usr/sfw/include -I/opt/sfw/include??? -fPIC? -g -O2? -c Date.cpp -o Date.o
Date.cpp: In member function `void Rcpp::Date::update_tm()':
Date.cpp:108: warning: converting to `time_t' from `double'
Date.cpp: In member function `double Rcpp::Date::mktime00(tm&) const':
Date.cpp:134: warning: converting to `int' from `double'
Date.cpp:137: warning: converting to `int' from `double'
Date.cpp: In function `Rcpp::Date Rcpp::operator+(const Rcpp::Date&, int)':
Date.cpp:164: warning: converting to `time_t' from `double'
Date.cpp: In function `int Rcpp::operator-(const Rcpp::Date&, const Rcpp::Date&)':
Date.cpp:170: warning: converting to `int' from `double'
Date.cpp: In function `tm* Rcpp::timesub(const time_t*, long int, const Rcpp::state*, tm*)':
Date.cpp:1523: warning: converting to `long int' from `double'
g++ -I/usr/local/lib/R/include -DNDEBUG -I../inst/include/ -I/usr/local/include -I/usr/sfw/include -I/opt/sfw/include??? -fPIC? -g -O2? -c Module.cpp -o Module.o
gcc -std=gnu99 -I/usr/local/lib/R/include -DNDEBUG -I../inst/include/ -I/usr/local/include -I/usr/sfw/include -I/opt/sfw/include??? -fPIC? -g -O2? -c Rcpp_init.c -o Rcpp_init.o
g++ -I/usr/local/lib/R/include -DNDEBUG -I../inst/include/ -I/usr/local/include -I/usr/sfw/include -I/opt/sfw/include??? -fPIC? -g -O2? -c Timer.cpp -o Timer.o
g++ -I/usr/local/lib/R/include -DNDEBUG -I../inst/include/ -I/usr/local/include -I/usr/sfw/include -I/opt/sfw/include??? -fPIC? -g -O2? -c api.cpp -o api.o
g++ -I/usr/local/lib/R/include -DNDEBUG -I../inst/include/ -I/usr/local/include -I/usr/sfw/include -I/opt/sfw/include??? -fPIC? -g -O2? -c attributes.cpp -o attributes.o
attributes.cpp: In member function `std::vector<Rcpp::attributes::Param, std::allocator<Rcpp::attributes::Param> > Rcpp::attributes::SourceFileAttributesParser::parseParameters(const std::string&)':
attributes.cpp:986: warning: converting of negative value `-0x00000000000000001' to `size_t'
g++ -I/usr/local/lib/R/include -DNDEBUG -I../inst/include/ -I/usr/local/include -I/usr/sfw/include -I/opt/sfw/include??? -fPIC? -g -O2? -c barrier.cpp -o barrier.o
g++ -I/usr/local/lib/R/include -DNDEBUG -I../inst/include/ -I/usr/local/include -I/usr/sfw/include -I/opt/sfw/include??? -fPIC? -g -O2? -c exceptions.cpp -o exceptions.o
g++ -shared -L/usr/local/lib -L/usr/sfw/lib -L/opt/sfw/lib -L/opt/solarisstudio12.3/lib -L/opt/solarisstudio12.3/prod/lib -o Rcpp.so Date.o Module.o Rcpp_init.o Timer.o api.o attributes.o barrier.o exceptions.o
g++ -o libRcpp.so Date.o Module.o Rcpp_init.o Timer.o api.o attributes.o barrier.o exceptions.o -shared
ar qc libRcpp.a Date.o Module.o Rcpp_init.o Timer.o api.o attributes.o barrier.o exceptions.o
cp libRcpp.so ../inst/lib
cp libRcpp.a ../inst/lib
rm libRcpp.so libRcpp.a
installing to /usr/local/lib/R/library/Rcpp/libs
** R
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** installing vignettes
?? 'Rcpp-FAQ.Rnw'
?? 'Rcpp-attributes.Rnw'
?? 'Rcpp-extending.Rnw'
?? 'Rcpp-introduction.Rnw'
?? 'Rcpp-modules.Rnw'
?? 'Rcpp-package.Rnw'
?? 'Rcpp-quickref.Rnw'
?? 'Rcpp-sugar.Rnw'
?? 'Rcpp-unitTests.Rnw'
** testing if installed package can be loaded
Error in dyn.load(file, DLLpath = DLLpath, ...) :
? unable to load shared object '/usr/local/lib/R/library/Rcpp/libs/Rcpp.so':
? ld.so.1: R: fatal: relocation error: file /usr/local/lib/R/library/Rcpp/libs/Rcpp.so: symbol backtrace: referenced symbol not found
Error: loading failed
Execution halted
ERROR: loading failed
* removing '/usr/local/lib/R/library/Rcpp'

The downloaded source packages are in
??????? '/tmp/RtmpfijlH9/downloaded_packages'
Updating HTML index of packages in '.Library'
Making 'packages.html' ... done
Warning message:
In install.packages("Rcpp") :
? installation of package 'Rcpp' had non-zero exit status
>


From s.wood at bath.ac.uk  Fri Jun 21 10:18:12 2013
From: s.wood at bath.ac.uk (Simon Wood)
Date: Fri, 21 Jun 2013 09:18:12 +0100
Subject: [R] mgcv summary.gam
In-Reply-To: <1177.10.254.253.3.1371798164.squirrel@sqmail.gn.apc.org>
References: <1177.10.254.253.3.1371798164.squirrel@sqmail.gn.apc.org>
Message-ID: <51C40C44.9080704@bath.ac.uk>

Hi Greg

On 21/06/13 08:02, Greg Dropkin wrote:
 > hi
 >
 > I'm trying to understand (a little) the code behind summary.gam, and have
 > the Biometrika article referred to in the Help. But am stuck early on.
 >
 > In the code, starting at line 167:
 >
 > if (est.disp)
 >    rdf <- residual.df
 > else rdf <- -1
 > res <- testStat(p, Xt, V, df[i], type = p.type,
 >    res.df = rdf)
 >
 > 1) shouldn't there be some brackets in the if else statement?
- I don't think so. rdf is either the residual degrees of freedom used 
to compute the scale parameter estimate or a signal of fixed scale 
parameter, to be passed to testStat.

 > 2) what is testStat?
mgcv:::testStat
- probably worth looking at the original source code which includes some 
comments. It does the actual computation.

best,
Simon

 > thanks
 >
 > Greg
 >
 >
 >
 >


-- 
Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
+44 (0)1225 386603               http://people.bath.ac.uk/sw283 On



-- 
Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
+44 (0)1225 386603               http://people.bath.ac.uk/sw283


From pdalgd at gmail.com  Fri Jun 21 11:35:49 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 21 Jun 2013 11:35:49 +0200
Subject: [R] How to make a test for linearity of a Passing-Bablok
	Regression
In-Reply-To: <COL126-W463049867D37B112BDD103C28E0@phx.gbl>
References: <COL126-W463049867D37B112BDD103C28E0@phx.gbl>
Message-ID: <0D77BE13-3814-481C-93E1-DE8CD208E903@gmail.com>


On Jun 20, 2013, at 16:21 , Annette Timm wrote:

> Hi All
> I am having some trouble making a test for linearity of my passing bablok regression.As far as I am concerned i need to make cusum test for linearity to get a p-value. I can make a cusum plot, but I can not figure out how to test for linearity.
> I hope that my question is clear and that someone can help me.Thanks
> -AT 		 	   		  
> 	[[alternative HTML version deleted]]
> 

Is this an R question? Anyways:

According to ideology (the maths of the P-B paper is heuristic at best),
the cusum test is equivalent to a two-sample Kolmogorov-Smirnov test, so you should be able to either use ks.test as is, or, with the appropriate scaling, feed the max(abs(cusum)) to pkstwo (which can be lifted from the sources of ks.test).

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dencoussie at gmail.com  Fri Jun 21 10:12:26 2013
From: dencoussie at gmail.com (pieter)
Date: Fri, 21 Jun 2013 10:12:26 +0200
Subject: [R] Levene's test output
Message-ID: <51C40AEA.2060602@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130621/e4181829/attachment.pl>

From gregd at gn.apc.org  Fri Jun 21 09:02:44 2013
From: gregd at gn.apc.org (Greg Dropkin)
Date: Fri, 21 Jun 2013 08:02:44 +0100 (BST)
Subject: [R] mgcv summary.gam
Message-ID: <1177.10.254.253.3.1371798164.squirrel@sqmail.gn.apc.org>

hi

I'm trying to understand (a little) the code behind summary.gam, and have
the Biometrika article referred to in the Help. But am stuck early on.

In the code, starting at line 167:

if (est.disp)
  rdf <- residual.df
else rdf <- -1
res <- testStat(p, Xt, V, df[i], type = p.type,
  res.df = rdf)

1) shouldn't there be some brackets in the if else statement?
2) what is testStat?

thanks

Greg


From t.kuehne at gmx.ch  Fri Jun 21 10:31:32 2013
From: t.kuehne at gmx.ch (thomas.k)
Date: Fri, 21 Jun 2013 01:31:32 -0700 (PDT)
Subject: [R] R Error, very odd....
In-Reply-To: <1338966776553-4632492.post@n4.nabble.com>
References: <1276876443574-887545.post@n4.nabble.com>
	<1338966776553-4632492.post@n4.nabble.com>
Message-ID: <1371803492232-4670026.post@n4.nabble.com>

I received the same error message. With me, the problem was that I had the
cells in my CSV file in Excel formatted as percentages. R read them as
factors and not as numeric values. After changing the cell format from
percentage to general in Excel, the problem was solved.



--
View this message in context: http://r.789695.n4.nabble.com/R-Error-very-odd-tp887545p4670026.html
Sent from the R help mailing list archive at Nabble.com.


From mario.lavezzi at unipa.it  Fri Jun 21 11:56:27 2013
From: mario.lavezzi at unipa.it (A M Lavezzi)
Date: Fri, 21 Jun 2013 11:56:27 +0200
Subject: [R] matching similar character strings
Message-ID: <CAOZPQW7F3iT4rCP3z2dAJJm32uoBaDmNpPf9tgkruGdBvvNkOw@mail.gmail.com>

Hello everybody

I have this problem: I need to match an addresses database F1 with the
information contained in a toponymic database F2.

The format of F1 is given by three columns and 800 rows, with the
columns being:

A1. Street/Road/Avenue
A2. Name
A3. Number

Consider for instance Avenue J. Kennedy , 3011. In F1 this is:

A1. Avenue
A2. J. Kennedy
A3. 3011

The format of F2 file is instead given by 20000 rows and five columns:

B1. Street/Road/Avenue
B2. Name
B3. Starting Street Number
B4. Ending Street Number
B5. Census section

So my problem is attributing the  B5 Census section to every
observation of F1 if: A1=B1, A2=B2, and A3 is comprised between B3 and
B4.

The problem is that while the information in A2 is irregularly
recorded, B2 has a given format that is Family name (space) Given
name.

So I could have that while in B2 the information is:

Kennedy John

In A2 it could be:

John Kennedy
JF Kennedy
J. Kennedy

and so on.

Thanks,

Mario

-- 
Andrea Mario Lavezzi
Dipartimento di Scienze Giuridiche, della Societ? e dello Sport
Sezione Diritto e Societ?
Universit? di Palermo
Piazza Bologni 8
90134 Palermo, Italy
tel. ++39 091 23892208
fax ++39 091 6111268
skype: lavezzimario
email: mario.lavezzi (at) unipa.it
web: http://www.unipa.it/~mario.lavezzi


From S.Ellison at lgcgroup.com  Fri Jun 21 12:12:14 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Fri, 21 Jun 2013 11:12:14 +0100
Subject: [R] alternative to ifelse
In-Reply-To: <4453C662-35C1-4549-AECF-3757B41E63C6@me.com>
References: <CADB2ZiTDKkAHjawnZi4pdfFZ1JYwWfQYUvUVs-nE2KZaBTUxDA@mail.gmail.com>
	<14218DBF-7852-4FC9-86DD-ECA89EBAF7B7@me.com>
	<4453C662-35C1-4549-AECF-3757B41E63C6@me.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED4AC9E8CA1B@GOLD.corp.lgc-group.com>

 
Once you have this matrix:
mx <- cbind(x1, x2, x3, x4)
> >   x1 x2 x3 x4
> > [1,] 22 14 24 10
> > [2,] 27 12  1  2
> > [3,] 23 13  6  2
> > [4,] 27  6 21  2
> > [5,] 14 29 12 19
> > [6,]  5 14 11 29
> > [7,] 10 10 27 25
> > [8,] 16 29 28 10
> > [9,] 22 22 19  7
> > [10,] 30 20  5 22
> > [11,]  2 12 24 15
> > [12,]  5 21 13 22
> > [13,] 23 17 28  3
> > [14,]  1  7 24 14
> > [15,] 12 15  8  8

ifelse( apply(mx, 1, function(x) any(x==1)), 1, 0 )
#or
as.numeric( apply(mx, 1, function(x) any(x==1)) )

should work.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From S.Ellison at lgcgroup.com  Fri Jun 21 12:22:20 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Fri, 21 Jun 2013 11:22:20 +0100
Subject: [R] Levene's test output
In-Reply-To: <51C40AEA.2060602@gmail.com>
References: <51C40AEA.2060602@gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED4AC9E8CA2C@GOLD.corp.lgc-group.com>

 

> I don't really get the output of the performed Levene's test.

One answer would be to read John Fox's rather good book, for which car is the corresponding R package.

Another is to look up leven'es test; a reasonably authoritative web reference for the calculation is http://www.itl.nist.gov/div898/handbook/eda/section3/eda35a.htm
if you followed that, you would find that 356 turns up somewhere important ...

A clue: It is unlikely to be coincidence that you have 358 data points in 2 groups.... and that the 356 turns up in the column headed "Df" in the leveneTest output.


S Ellison

*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From stefan.sobernig at wu.ac.at  Fri Jun 21 12:39:59 2013
From: stefan.sobernig at wu.ac.at (Stefan Sobernig)
Date: Fri, 21 Jun 2013 12:39:59 +0200
Subject: [R] Gini coefficient sensitive to "skewness" of Lorenz curve?
Message-ID: <51C42D7F.8080801@wu.ac.at>

Dear list,

I have already posted to sci.stat.consult, however, I was hoping that 
there might be some experience in the R community on the following question:

> I am wondering whether anyone has experience with variants of (parametric) Gini coefficients (or alternatives) which allow for reflecting/penalising the skewness of a Lorenz curve?
>
> For my part, I just stumbled across the following:
> http://www.accessecon.com/Pubs/EB/2010/Volume30/EB-10-V30-I2-P146.pdf
>
> While appealing to me, I did not find any alternatives, nor any reported use of this variant; nor is there any account of its liabilities (e.g., strategies to estimate the parameters).
>
 > ...
 >
> P.S.: My background is not in economics/econometrics or the like, rather i am currently evaluating the use of inequality measures for software measurement. See for some background:
> http://dx.doi.org/10.1109/ICSM.2011.6080798

I'd appreciate any hint in this direction!

stefan


From ruipbarradas at sapo.pt  Fri Jun 21 13:11:45 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 21 Jun 2013 12:11:45 +0100
Subject: [R] Levene's test output
In-Reply-To: <51C42554.9030103@gmail.com>
References: <51C40AEA.2060602@gmail.com> <51C42336.7010306@sapo.pt>
	<51C42554.9030103@gmail.com>
Message-ID: <51C434F1.9020103@sapo.pt>

Hello,

The Pr(>F) is a regular p-value, with the usual meaning.

Rui Barradas

Em 21-06-2013 11:05, pieter escreveu:
> k.
> Thanks.
> Sorry i'm not the biggest statician, but I still find the output write
> out not the clearest of all. Anyway, that is probably a personal
> problem. :-)
>
> Just one question. the Pr(>F) is just the regular p value, right? so
> above the treshold means equal variance?
>
> Thanks alot.
>
> Pieter
>
> On vr 21 jun 2013 11:56:06 CEST, Rui Barradas wrote:
>> Hello,
>>
>> You need to know what is the Levene test, that output is as clear as
>> water. 75 + 283 == 358. Minus two groups gives 356.
>> See
>>
>> http://en.wikipedia.org/wiki/Levene%27s_test
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Em 21-06-2013 09:12, pieter escreveu:
>>> Hey,
>>> I don't really get the output of the performed Levene's test.
>>> So in short.
>>> two data sets, one with 75 elements, one with 283.
>>> And I want to check whether they have the same variance.
>>>
>>> I did a LeveneTest
>>> And this is the output:
>>>
>>> Levene's Test for Homogeneity of Variance (center = median)
>>>          Df F value   Pr(>F)
>>> group   1  10.948 0.001033 **
>>>         356
>>> ---
>>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>>
>>> So I would think that H0 is being rejected? for everything except 99.9%?
>>> But what does the 356 mean?
>>> Is this test performed correctly? group is a vector with 1's and 2's
>>> appointing the two datasets...
>>>
>>>
>>>
>>>     [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>


From ruipbarradas at sapo.pt  Fri Jun 21 13:25:34 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 21 Jun 2013 12:25:34 +0100
Subject: [R] Levene's test output
In-Reply-To: <51C434F1.9020103@sapo.pt>
References: <51C40AEA.2060602@gmail.com> <51C42336.7010306@sapo.pt>
	<51C42554.9030103@gmail.com> <51C434F1.9020103@sapo.pt>
Message-ID: <51C4382E.1000702@sapo.pt>

Hello,

Just to add to the last post, you can try to get that p-value using what 
that output gives you:


df1 <- 1
df2 <- 356
F_stat <- 10.948
pf(F_stat, df1, df2, lower.tail = FALSE) # same value


Hope this helps,

Rui Barradas

Em 21-06-2013 12:11, Rui Barradas escreveu:
> Hello,
>
> The Pr(>F) is a regular p-value, with the usual meaning.
>
> Rui Barradas
>
> Em 21-06-2013 11:05, pieter escreveu:
>> k.
>> Thanks.
>> Sorry i'm not the biggest statician, but I still find the output write
>> out not the clearest of all. Anyway, that is probably a personal
>> problem. :-)
>>
>> Just one question. the Pr(>F) is just the regular p value, right? so
>> above the treshold means equal variance?
>>
>> Thanks alot.
>>
>> Pieter
>>
>> On vr 21 jun 2013 11:56:06 CEST, Rui Barradas wrote:
>>> Hello,
>>>
>>> You need to know what is the Levene test, that output is as clear as
>>> water. 75 + 283 == 358. Minus two groups gives 356.
>>> See
>>>
>>> http://en.wikipedia.org/wiki/Levene%27s_test
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>> Em 21-06-2013 09:12, pieter escreveu:
>>>> Hey,
>>>> I don't really get the output of the performed Levene's test.
>>>> So in short.
>>>> two data sets, one with 75 elements, one with 283.
>>>> And I want to check whether they have the same variance.
>>>>
>>>> I did a LeveneTest
>>>> And this is the output:
>>>>
>>>> Levene's Test for Homogeneity of Variance (center = median)
>>>>          Df F value   Pr(>F)
>>>> group   1  10.948 0.001033 **
>>>>         356
>>>> ---
>>>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>>>
>>>> So I would think that H0 is being rejected? for everything except
>>>> 99.9%?
>>>> But what does the 356 mean?
>>>> Is this test performed correctly? group is a vector with 1's and 2's
>>>> appointing the two datasets...
>>>>
>>>>
>>>>
>>>>     [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tsonnekus at gmail.com  Fri Jun 21 14:30:23 2013
From: tsonnekus at gmail.com (Tinus Sonnekus)
Date: Fri, 21 Jun 2013 14:30:23 +0200
Subject: [R] Category error resulting in a ylim error
Message-ID: <CAPEc57HN9UQLiq3uUoEq8204jWRPx6H_KD4cxvK5uSVsgpqosQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130621/9db9db18/attachment.pl>

From stefano.sofia at regione.marche.it  Fri Jun 21 15:48:09 2013
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Fri, 21 Jun 2013 13:48:09 +0000
Subject: [R] Apply a Seasonal ARMA process
Message-ID: <8B435C9568170B469AE31E8891E8CC4FFE9F@ESINO.regionemarche.intra>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130621/73a3e90e/attachment.pl>

From smartpink111 at yahoo.com  Fri Jun 21 16:06:02 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 21 Jun 2013 07:06:02 -0700 (PDT)
Subject: [R] keep row names into data
Message-ID: <1371823562.82243.YahooMailNeo@web142606.mail.bf1.yahoo.com>



Hi,
Try:
dat1<- read.csv("mydata.csv",sep="\t",row.names=1)? #sep could be different in your case.
?dat1
#?????? A B C D E
#Jhon?? 1 3 6 9 8
#Kelly? 2 3 4 6 9
#Audrey 3 5 6 9 7
A.K.



Hi, 

I am calling my csv data with 37 columns and 16 rows into R. However I really need to keep coloumns names as well as row names. 
Columns names is easy to keep using the command below. But how to keep row names? ? 

data<-read.csv("mydata", header=TRUE) 

My spreadsheet is like: 
? ? ? ? ? ? ? ? ? A B C D E ... 
Jhon ? ? ? ? 1 ?3 6 9 8 
Kelly ? ? ? ? 2 ?3 4 6 9 
Audrey ? ?3 ?5 6 9 7 
... 

In this case I need students names. 
Thanks anyone.


From dcarlson at tamu.edu  Fri Jun 21 16:25:32 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Fri, 21 Jun 2013 09:25:32 -0500
Subject: [R] matching similar character strings
In-Reply-To: <CAOZPQW7F3iT4rCP3z2dAJJm32uoBaDmNpPf9tgkruGdBvvNkOw@mail.gmail.com>
References: <CAOZPQW7F3iT4rCP3z2dAJJm32uoBaDmNpPf9tgkruGdBvvNkOw@mail.gmail.com>
Message-ID: <018e01ce6e8b$2ffde140$8ff9a3c0$@tamu.edu>

I think you have to assume there could be other coding errors as
well, such as misspellings or abbreviating Street as St. You
probably will need to use sub() to correct A2 and possibly A1 before
trying to merge. To figure where the problems are, you might try
something like this. The last command lists the paste(A1, A2)
entries that do not match anything in paste(B1, B2).

> set.seed(42)
> a <- paste(sample(c(letters, LETTERS[1:5]), 150, replace=TRUE),
+   sample(c("St", "Rd", "Ave"), 150, replace=TRUE))
> b <- paste(sample(letters, 1000, replace=TRUE), 
+   sample(c("St", "Rd", "Ave"), 1000, replace=TRUE))
> (ua <- sort(unique(a)))
 [1] "a Ave" "a Rd"  "A Rd"  "a St"  "A St"  "b Rd"  "B Rd"  "b St"
"c Ave"
[10] "C Ave" "c Rd"  "C Rd"  "C St"  "D Ave" "D Rd"  "d St"  "D St"
"e Ave"
[19] "E Ave" "e Rd"  "E Rd"  "e St"  "E St"  "f Ave" "f Rd"  "g Ave"
"g Rd" 
[28] "g St"  "h Ave" "h Rd"  "h St"  "i Ave" "i Rd"  "i St"  "j Rd"
"j St" 
[37] "k Ave" "k Rd"  "k St"  "l St"  "m Ave" "m Rd"  "m St"  "n Ave"
"n St" 
[46] "o Ave" "o Rd"  "o St"  "p St"  "q Ave" "q Rd"  "q St"  "r Ave"
"r Rd" 
[55] "r St"  "s Ave" "s Rd"  "s St"  "t Ave" "t Rd"  "t St"  "u Ave"
"u Rd" 
[64] "u St"  "v Ave" "v Rd"  "v St"  "w Ave" "w Rd"  "w St"  "x Rd"
"x St" 
[73] "y Ave" "y Rd"  "z Ave" "z Rd"  "z St" 
> (ub <- sort(unique(b)))
 [1] "a Ave" "a Rd"  "a St"  "b Ave" "b Rd"  "b St"  "c Ave" "c Rd"
"c St" 
[10] "d Ave" "d Rd"  "d St"  "e Ave" "e Rd"  "e St"  "f Ave" "f Rd"
"f St" 
[19] "g Ave" "g Rd"  "g St"  "h Ave" "h Rd"  "h St"  "i Ave" "i Rd"
"i St" 
[28] "j Ave" "j Rd"  "j St"  "k Ave" "k Rd"  "k St"  "l Ave" "l Rd"
"l St" 
[37] "m Ave" "m Rd"  "m St"  "n Ave" "n Rd"  "n St"  "o Ave" "o Rd"
"o St" 
[46] "p Ave" "p Rd"  "p St"  "q Ave" "q Rd"  "q St"  "r Ave" "r Rd"
"r St" 
[55] "s Ave" "s Rd"  "s St"  "t Ave" "t Rd"  "t St"  "u Ave" "u Rd"
"u St" 
[64] "v Ave" "v Rd"  "v St"  "w Ave" "w Rd"  "w St"  "x Ave" "x Rd"
"x St" 
[73] "y Ave" "y Rd"  "y St"  "z Ave" "z Rd"  "z St" 
> ua[!(ua %in% ub)]
 [1] "A Rd"  "A St"  "B Rd"  "C Ave" "C Rd"  "C St"  "D Ave" "D Rd"
"D St" 
[10] "E Ave" "E Rd"  "E St" 

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of A M Lavezzi
Sent: Friday, June 21, 2013 4:56 AM
To: r-help
Subject: [R] matching similar character strings

Hello everybody

I have this problem: I need to match an addresses database F1 with
the
information contained in a toponymic database F2.

The format of F1 is given by three columns and 800 rows, with the
columns being:

A1. Street/Road/Avenue
A2. Name
A3. Number

Consider for instance Avenue J. Kennedy , 3011. In F1 this is:

A1. Avenue
A2. J. Kennedy
A3. 3011

The format of F2 file is instead given by 20000 rows and five
columns:

B1. Street/Road/Avenue
B2. Name
B3. Starting Street Number
B4. Ending Street Number
B5. Census section

So my problem is attributing the  B5 Census section to every
observation of F1 if: A1=B1, A2=B2, and A3 is comprised between B3
and
B4.

The problem is that while the information in A2 is irregularly
recorded, B2 has a given format that is Family name (space) Given
name.

So I could have that while in B2 the information is:

Kennedy John

In A2 it could be:

John Kennedy
JF Kennedy
J. Kennedy

and so on.

Thanks,

Mario

-- 
Andrea Mario Lavezzi
Dipartimento di Scienze Giuridiche, della Societ? e dello Sport
Sezione Diritto e Societ?
Universit? di Palermo
Piazza Bologni 8
90134 Palermo, Italy
tel. ++39 091 23892208
fax ++39 091 6111268
skype: lavezzimario
email: mario.lavezzi (at) unipa.it
web: http://www.unipa.it/~mario.lavezzi

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From yvonnick.noel at uhb.fr  Fri Jun 21 16:55:06 2013
From: yvonnick.noel at uhb.fr (Yvonnick Noel)
Date: Fri, 21 Jun 2013 16:55:06 +0200
Subject: [R] Superpose two QQ-plots (gamma distribution) with lattice
 function qqmath()
Message-ID: <51C4694A.6@uhb.fr>

Hello,

I am trying to superpose on a single panel two QQ plots with the lattice 
qqmath function.

Here is a reproducible example of the problem I am facing:

# Generate data
shape = 8
rate = c(rep(1/4,100),rep(1/3,100))
x = rgamma(200,shape,rate)
groups = gl(2,100,200,labels=LETTERS[1:2])

# Plot
qqmath(~x,groups=groups,panel = "panel.superpose",
distribution = function(x) qgamma(x,shape,rate),
panel.groups = function(x,subscripts,...) {
	panel.qqmath(x,shape=shape,rate=rate[subscripts],...)
	panel.qqmathline(x,shape=shape,rate=rate[subscripts],...)
})

Both data series seem to be reproduced twice, somewhat rescaled.

I don't understand what this mean.

What am I doing wrong?

Thanks a lot for your help,

Yvonnick Noel
University of Brittany, Rennes
Dpt. of Psychology
France


From motyocska at yahoo.com  Fri Jun 21 17:07:39 2013
From: motyocska at yahoo.com (Andras Farkas)
Date: Fri, 21 Jun 2013 08:07:39 -0700 (PDT)
Subject: [R] hdr.den plot colors help
Message-ID: <1371827259.85379.YahooMailClassic@web140403.mail.bf1.yahoo.com>

Dear All,

I have the following code:

a <-rnorm(5000,10,2)
hdr.den(a,prob = c(25, 50, 75,95))

is there a way to change the colors of the horizontal bars representing the given highest density regions from the current white, green, red and black to colors of the shades of grey going from lighter to darker?

appreciate the help,

thanks,

Andras


From suparna.mitra.sm at gmail.com  Fri Jun 21 17:13:33 2013
From: suparna.mitra.sm at gmail.com (Suparna Mitra)
Date: Fri, 21 Jun 2013 23:13:33 +0800
Subject: [R] How to define desired numbers to a vector based on the present
	numbers
Message-ID: <CAFdg=fX6uf-XD8YOnNCFzZmcOEAhL=wt0SaBTLGwCLdfNe_eBg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130621/01039091/attachment.pl>

From ruipbarradas at sapo.pt  Fri Jun 21 17:32:16 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 21 Jun 2013 16:32:16 +0100
Subject: [R] How to define desired numbers to a vector based on the
 present numbers
In-Reply-To: <CAFdg=fX6uf-XD8YOnNCFzZmcOEAhL=wt0SaBTLGwCLdfNe_eBg@mail.gmail.com>
References: <CAFdg=fX6uf-XD8YOnNCFzZmcOEAhL=wt0SaBTLGwCLdfNe_eBg@mail.gmail.com>
Message-ID: <51C47200.60604@sapo.pt>

Hello,

I'm not sure I understand. You want to attribute a color number 1:7 to 
each element of your vector? Maybe the following will do.


x <- scan(text = "
43 43 43 43  0 39 13 39 50 39 39 23 23 32  0 13 32 23 32 23  0 13 13  0
")

cols <- rep(1:7, rle(x[order(x)])$lengths)[order(order(x))]
plot(x, col = cols)


Hope this helps,

Rui Barradas

Em 21-06-2013 16:13, Suparna Mitra escreveu:
> Hello R experts,
>    I want to  define desired numbers to a vector based on the present
> numbers. Can anybody please help me?
> Obviously I found worst ways to do it, but I believe there must be any
> better way.
>
> I have vector as
>> X
>   [1] 43 43 43 43  0 39 13 39 50 39 39 23 23 32  0 13 32 23 32 23  0 13 13  0
> Now I want to colour a plot with unic cols based on this vector. I want to
> baseplot.
> But now the problem in normal col pallet these nos has repetition. Thus I
> tried to
>   library(RColorBrewer)
>> coll<-colorRampPalette(brewer.pal(9, "Set1"))(50)
> and then use this vector as col.
>
> But there also the colours are not enough bright.
>
> So I am trying to set new a vector reading this present vector.
> Obviously I can type out manually as
> coll=c(rep(1,4),0,2 ....
>
> But rather I am trying for some automation with which function or similar
> But still now I am struggling with this.
> Can anybody please help me.
>
> Basic thing is some way to reads the vector and define a new col vector
> from 1:7
>
> Thanks a lot,
> Mitra
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dcarlson at tamu.edu  Fri Jun 21 17:39:13 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Fri, 21 Jun 2013 10:39:13 -0500
Subject: [R] Superpose two QQ-plots (gamma distribution) with lattice
	function qqmath()
In-Reply-To: <51C4694A.6@uhb.fr>
References: <51C4694A.6@uhb.fr>
Message-ID: <01c101ce6e95$7af54580$70dfd080$@tamu.edu>

Your "rate" variable is not a single value, but a vector of 200!.
I'm surprised you get anything at all. You have to pick one rate
value to use to create the values for the x-axis. For example run

> rate <- 1/4

And then run the qqmath() function.

Or, change the rate variable in the ggamma() function to

qgamma(x,shape,1/4).

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Yvonnick Noel
Sent: Friday, June 21, 2013 9:55 AM
To: r-help at r-project.org
Cc: Deepayan.Sarkar at r-project.org
Subject: [R] Superpose two QQ-plots (gamma distribution) with
lattice function qqmath()

Hello,

I am trying to superpose on a single panel two QQ plots with the
lattice 
qqmath function.

Here is a reproducible example of the problem I am facing:

# Generate data
shape = 8
rate = c(rep(1/4,100),rep(1/3,100))
x = rgamma(200,shape,rate)
groups = gl(2,100,200,labels=LETTERS[1:2])

# Plot
qqmath(~x,groups=groups,panel = "panel.superpose",
distribution = function(x) qgamma(x,shape,rate),
panel.groups = function(x,subscripts,...) {
	panel.qqmath(x,shape=shape,rate=rate[subscripts],...)
	panel.qqmathline(x,shape=shape,rate=rate[subscripts],...)
})

Both data series seem to be reproduced twice, somewhat rescaled.

I don't understand what this mean.

What am I doing wrong?

Thanks a lot for your help,

Yvonnick Noel
University of Brittany, Rennes
Dpt. of Psychology
France

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From suparna.mitra.sm at gmail.com  Fri Jun 21 17:40:14 2013
From: suparna.mitra.sm at gmail.com (Suparna Mitra)
Date: Fri, 21 Jun 2013 23:40:14 +0800
Subject: [R] How to define desired numbers to a vector based on the
 present numbers
In-Reply-To: <51C47200.60604@sapo.pt>
References: <CAFdg=fX6uf-XD8YOnNCFzZmcOEAhL=wt0SaBTLGwCLdfNe_eBg@mail.gmail.com>
	<51C47200.60604@sapo.pt>
Message-ID: <CAFdg=fUFCzZe0tqkFJ-88HMdJX1P6VtVMdLR7fwGM1R_Y-XLxw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130621/64327f67/attachment.pl>

From clint at ecy.wa.gov  Fri Jun 21 17:43:26 2013
From: clint at ecy.wa.gov (Clint Bowman)
Date: Fri, 21 Jun 2013 08:43:26 -0700 (PDT)
Subject: [R] How to define desired numbers to a vector based on the
 present numbers
In-Reply-To: <51C47200.60604@sapo.pt>
References: <CAFdg=fX6uf-XD8YOnNCFzZmcOEAhL=wt0SaBTLGwCLdfNe_eBg@mail.gmail.com>
	<51C47200.60604@sapo.pt>
Message-ID: <alpine.LRH.2.03.1306210842100.21582@ecy.wa.gov>

I suspect the OP may want

rep(1:length(unique(x)), rle(x[order(x)])$lengths)[order(order(x))]

to allow for variable numbers of unique values.

Clint

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Fri, 21 Jun 2013, Rui Barradas wrote:

> Hello,
>
> I'm not sure I understand. You want to attribute a color number 1:7 to each 
> element of your vector? Maybe the following will do.
>
>
> x <- scan(text = "
> 43 43 43 43  0 39 13 39 50 39 39 23 23 32  0 13 32 23 32 23  0 13 13  0
> ")
>
> cols <- rep(1:7, rle(x[order(x)])$lengths)[order(order(x))]
> plot(x, col = cols)
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 21-06-2013 16:13, Suparna Mitra escreveu:
>> Hello R experts,
>>    I want to  define desired numbers to a vector based on the present
>> numbers. Can anybody please help me?
>> Obviously I found worst ways to do it, but I believe there must be any
>> better way.
>> 
>> I have vector as
>>> X
>>   [1] 43 43 43 43  0 39 13 39 50 39 39 23 23 32  0 13 32 23 32 23  0 13 13 
>> 0
>> Now I want to colour a plot with unic cols based on this vector. I want to
>> baseplot.
>> But now the problem in normal col pallet these nos has repetition. Thus I
>> tried to
>>   library(RColorBrewer)
>>> coll<-colorRampPalette(brewer.pal(9, "Set1"))(50)
>> and then use this vector as col.
>> 
>> But there also the colours are not enough bright.
>> 
>> So I am trying to set new a vector reading this present vector.
>> Obviously I can type out manually as
>> coll=c(rep(1,4),0,2 ....
>> 
>> But rather I am trying for some automation with which function or similar
>> But still now I am struggling with this.
>> Can anybody please help me.
>> 
>> Basic thing is some way to reads the vector and define a new col vector
>> from 1:7
>> 
>> Thanks a lot,
>> Mitra
>>
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From suparna.mitra.sm at gmail.com  Fri Jun 21 17:46:21 2013
From: suparna.mitra.sm at gmail.com (Suparna Mitra)
Date: Fri, 21 Jun 2013 23:46:21 +0800
Subject: [R] How to define desired numbers to a vector based on the
 present numbers
In-Reply-To: <alpine.LRH.2.03.1306210842100.21582@ecy.wa.gov>
References: <CAFdg=fX6uf-XD8YOnNCFzZmcOEAhL=wt0SaBTLGwCLdfNe_eBg@mail.gmail.com>
	<51C47200.60604@sapo.pt>
	<alpine.LRH.2.03.1306210842100.21582@ecy.wa.gov>
Message-ID: <CAFdg=fXWCEpARBy8O4gLOFq_+O9AM82HiwY0VfndNxPNK=jhgA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130621/080c04e6/attachment.pl>

From ruipbarradas at sapo.pt  Fri Jun 21 17:51:36 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 21 Jun 2013 16:51:36 +0100
Subject: [R] hdr.den plot colors help
In-Reply-To: <1371827259.85379.YahooMailClassic@web140403.mail.bf1.yahoo.com>
References: <1371827259.85379.YahooMailClassic@web140403.mail.bf1.yahoo.com>
Message-ID: <51C47688.8050001@sapo.pt>

Hello,

It's not your first post, you should know to say from which package is 
the function you're using.

As for the question the answer is no, those values are hard coded in the 
source. What you can do is to download the source and change file hdr.den.R

Hope this helps,

Rui Barradas

Em 21-06-2013 16:07, Andras Farkas escreveu:
> Dear All,
>
> I have the following code:
>
> a <-rnorm(5000,10,2)
> hdr.den(a,prob = c(25, 50, 75,95))
>
> is there a way to change the colors of the horizontal bars representing the given highest density regions from the current white, green, red and black to colors of the shades of grey going from lighter to darker?
>
> appreciate the help,
>
> thanks,
>
> Andras
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From motyocska at yahoo.com  Fri Jun 21 17:56:22 2013
From: motyocska at yahoo.com (Andras Farkas)
Date: Fri, 21 Jun 2013 08:56:22 -0700 (PDT)
Subject: [R] hdr.den plot colors help
In-Reply-To: <51C47688.8050001@sapo.pt>
Message-ID: <1371830182.14362.YahooMailClassic@web140403.mail.bf1.yahoo.com>

Rui,

package is hdrcde, and thanks for the input,

Andras

--- On Fri, 6/21/13, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> From: Rui Barradas <ruipbarradas at sapo.pt>
> Subject: Re: [R] hdr.den plot colors help
> To: "Andras Farkas" <motyocska at yahoo.com>
> Cc: r-help at r-project.org
> Date: Friday, June 21, 2013, 11:51 AM
> Hello,
> 
> It's not your first post, you should know to say from which
> package is 
> the function you're using.
> 
> As for the question the answer is no, those values are hard
> coded in the 
> source. What you can do is to download the source and change
> file hdr.den.R
> 
> Hope this helps,
> 
> Rui Barradas
> 
> Em 21-06-2013 16:07, Andras Farkas escreveu:
> > Dear All,
> >
> > I have the following code:
> >
> > a <-rnorm(5000,10,2)
> > hdr.den(a,prob = c(25, 50, 75,95))
> >
> > is there a way to change the colors of the horizontal
> bars representing the given highest density regions from the
> current white, green, red and black to colors of the shades
> of grey going from lighter to darker?
> >
> > appreciate the help,
> >
> > thanks,
> >
> > Andras
> >
> > ______________________________________________
> > R-help at r-project.org
> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained,
> reproducible code.
> >
>


From entropy053 at gmail.com  Fri Jun 21 17:59:15 2013
From: entropy053 at gmail.com (Yasin Gocgun)
Date: Fri, 21 Jun 2013 11:59:15 -0400
Subject: [R] an issue about removing "NA"s from an array
Message-ID: <CAJJuoESgRp44gdCSqMEM_5fuT=Hjn7JJaSYTmnSstpTit5CoMg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130621/8a8396fe/attachment.pl>

From dcarlson at tamu.edu  Fri Jun 21 18:07:29 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Fri, 21 Jun 2013 11:07:29 -0500
Subject: [R] hdr.den plot colors help
In-Reply-To: <1371827259.85379.YahooMailClassic@web140403.mail.bf1.yahoo.com>
References: <1371827259.85379.YahooMailClassic@web140403.mail.bf1.yahoo.com>
Message-ID: <01d001ce6e99$6dbf5370$493dfa50$@tamu.edu>

You should tell us where hdr.den() comes from as it is not one of
the default packages and there are thousands of packages. Some
searching suggests you are using package hdrcde.

Looking at the source code for hdr.den() it appears that the package
author used the default palette in selecting colors. You can't
change the colors directly, but you can change the palette. 

> palette() # Default palette
[1] "black"   "red"     "green3"  "blue"    "cyan"    "magenta"
"yellow" 
[8] "gray"   
> default.colors <- palette() # Save the default palette
> new.colors <- c("black", "dark gray", "light gray", "black",
"cyan", "magenta", "yellow")
> palette(new.colors) # Change the palette
> hdr.den(a,prob = c(25, 50, 75,95))
> palette(default.colors) # Restore the default palette

You could also change the magenta and cyan colors the same way.

------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Andras Farkas
Sent: Friday, June 21, 2013 10:08 AM
To: r-help at r-project.org
Subject: [R] hdr.den plot colors help

Dear All,

I have the following code:

a <-rnorm(5000,10,2)
hdr.den(a,prob = c(25, 50, 75,95))

is there a way to change the colors of the horizontal bars
representing the given highest density regions from the current
white, green, red and black to colors of the shades of grey going
from lighter to darker?

appreciate the help,

thanks,

Andras

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From christian.kampichler at sovon.nl  Fri Jun 21 15:36:46 2013
From: christian.kampichler at sovon.nl (Christian Kampichler)
Date: Fri, 21 Jun 2013 15:36:46 +0200
Subject: [R] Package random forest: can corr.bias be harmful?
Message-ID: <51C456EE.6010508@sovon.nl>

There exists an option corr.bias for making regression analyses with the 
R package randomForest. The manual warns ?Experimental. Use at your own 
risk.? What does corr.bias precisely do and why can it be dangerous to 
use it? As far as I know the bias correction is based on a linear 
regression between the out-of-bag-prediction and the observed values 
which is used for correction of all predictions made by the model, but 
this does not appear so harmful to me.

-- 
Dr. Christian Kampichler
Sovon Dutch Centre for Field Ornithology
PO Box 6521, 6503 GA Nijmegen, The Netherlands
+31 24 7 410 410
www.sovon.nl


From kicco1991 at hotmail.it  Fri Jun 21 15:37:09 2013
From: kicco1991 at hotmail.it (Francesco Miranda)
Date: Fri, 21 Jun 2013 15:37:09 +0200
Subject: [R] Error
Message-ID: <DUB107-W114B57492FF5F348BA1AF0DE8F0@phx.gbl>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130621/5b8e25c2/attachment.pl>

From gunter.berton at gene.com  Fri Jun 21 18:13:51 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 21 Jun 2013 09:13:51 -0700
Subject: [R] an issue about removing "NA"s from an array
In-Reply-To: <CAJJuoESgRp44gdCSqMEM_5fuT=Hjn7JJaSYTmnSstpTit5CoMg@mail.gmail.com>
References: <CAJJuoESgRp44gdCSqMEM_5fuT=Hjn7JJaSYTmnSstpTit5CoMg@mail.gmail.com>
Message-ID: <CACk-te3RTPhdnR9s68wcxhHhY_g4AEPwWN4B1et=ALRFmorEHg@mail.gmail.com>

You really really need to do your homework.

?NA

-- Bert

On Fri, Jun 21, 2013 at 8:59 AM, Yasin Gocgun <entropy053 at gmail.com> wrote:
> Hi,*
>
> *I would like to set the entries of an array that appear as "NA" to a
> certain integer, but did not find a way to do so. The related code is given
> below:
>
> A <- array(-1000 , dim=c(100) );
>
> for(i in 1: 100 ){
>      A[i] =B[i,57] -  B[i,5];
> }
>
> A [ which( A == "NA") ] <- 900;
>
> The "NA"s still appear as the entries of the array A.
>
> Can you tell me what is missing here? (I also tried setting the entries of
> A to character using "as.character" but it did not work)
>
> Thanks,
>
>
> --
> Yasin Gocgun
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From wdunlap at tibco.com  Fri Jun 21 18:16:52 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 21 Jun 2013 16:16:52 +0000
Subject: [R] an issue about removing "NA"s from an array
In-Reply-To: <CAJJuoESgRp44gdCSqMEM_5fuT=Hjn7JJaSYTmnSstpTit5CoMg@mail.gmail.com>
References: <CAJJuoESgRp44gdCSqMEM_5fuT=Hjn7JJaSYTmnSstpTit5CoMg@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C306307@PA-MBX01.na.tibco.com>

Read 'An Introduction to R', found on the R web site.  It is short and worth reading in its entirety.  Section 2.5 on missing values answers your question:

  2.5 Missing values
  
In some cases the components of a vector may not be completely known. When an element or value is "not available" or a "missing value" in the statistical sense, a place within a vector may be reserved for it by assigning it the special value NA. In general any operation on an NA becomes an NA. The motivation for this rule is simply that if the specification of an operation is incomplete, the result cannot be known and hence is not available.

The function is.na(x) gives a logical vector of the same size as x with value TRUE if and only if the corresponding element in x is NA.

     > z <- c(1:3,NA);  ind <- is.na(z)
Notice that the logical expression x == NA is quite different from is.na(x) since NA is not really a value but a marker for a quantity that is not available. Thus x == NA is a vector of the same length as x all of whose values are NA as the logical expression itself is incomplete and hence undecidable.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Yasin Gocgun
> Sent: Friday, June 21, 2013 8:59 AM
> To: r-help at r-project.org
> Subject: [R] an issue about removing "NA"s from an array
> 
> Hi,*
> 
> *I would like to set the entries of an array that appear as "NA" to a
> certain integer, but did not find a way to do so. The related code is given
> below:
> 
> A <- array(-1000 , dim=c(100) );
> 
> for(i in 1: 100 ){
>      A[i] =B[i,57] -  B[i,5];
> }
> 
> A [ which( A == "NA") ] <- 900;
> 
> The "NA"s still appear as the entries of the array A.
> 
> Can you tell me what is missing here? (I also tried setting the entries of
> A to character using "as.character" but it did not work)
> 
> Thanks,
> 
> 
> --
> Yasin Gocgun
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jvadams at usgs.gov  Fri Jun 21 18:16:49 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Fri, 21 Jun 2013 11:16:49 -0500
Subject: [R] Category error resulting in a ylim error
In-Reply-To: <CAPEc57HN9UQLiq3uUoEq8204jWRPx6H_KD4cxvK5uSVsgpqosQ@mail.gmail.com>
References: <CAPEc57HN9UQLiq3uUoEq8204jWRPx6H_KD4cxvK5uSVsgpqosQ@mail.gmail.com>
Message-ID: <CAN5YmCGEmpMbC00zeigc+00DCe+t53QXw4KqhiU1vefkb-SYFA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130621/b65dfe05/attachment.pl>

From smartpink111 at yahoo.com  Fri Jun 21 19:13:57 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 21 Jun 2013 10:13:57 -0700 (PDT)
Subject: [R] How to define desired numbers to a vector based on the
	present numbers
In-Reply-To: <51C47200.60604@sapo.pt>
References: <CAFdg=fX6uf-XD8YOnNCFzZmcOEAhL=wt0SaBTLGwCLdfNe_eBg@mail.gmail.com>
	<51C47200.60604@sapo.pt>
Message-ID: <1371834837.93834.YahooMailNeo@web142603.mail.bf1.yahoo.com>

HI,
May be this also works:
plot(x,col=as.numeric(factor(x)))
A.K.




----- Original Message -----
From: Rui Barradas <ruipbarradas at sapo.pt>
To: Suparna Mitra <suparna.mitra.sm at gmail.com>
Cc: r-help at r-project.org
Sent: Friday, June 21, 2013 11:32 AM
Subject: Re: [R] How to define desired numbers to a vector based on the
 present numbers

Hello,

I'm not sure I understand. You want to attribute a color number 1:7 to 
each element of your vector? Maybe the following will do.


x <- scan(text = "
43 43 43 43? 0 39 13 39 50 39 39 23 23 32? 0 13 32 23 32 23? 0 13 13? 0
")

cols <- rep(1:7, rle(x[order(x)])$lengths)[order(order(x))]
plot(x, col = cols)


Hope this helps,

Rui Barradas

Em 21-06-2013 16:13, Suparna Mitra escreveu:
> Hello R experts,
>? ? I want to? define desired numbers to a vector based on the present
> numbers. Can anybody please help me?
> Obviously I found worst ways to do it, but I believe there must be any
> better way.
>
> I have vector as
>> X
>?  [1] 43 43 43 43? 0 39 13 39 50 39 39 23 23 32? 0 13 32 23 32 23? 0 13 13? 0
> Now I want to colour a plot with unic cols based on this vector. I want to
> baseplot.
> But now the problem in normal col pallet these nos has repetition. Thus I
> tried to
>?  library(RColorBrewer)
>> coll<-colorRampPalette(brewer.pal(9, "Set1"))(50)
> and then use this vector as col.
>
> But there also the colours are not enough bright.
>
> So I am trying to set new a vector reading this present vector.
> Obviously I can type out manually as
> coll=c(rep(1,4),0,2 ....
>
> But rather I am trying for some automation with which function or similar
> But still now I am struggling with this.
> Can anybody please help me.
>
> Basic thing is some way to reads the vector and define a new col vector
> from 1:7
>
> Thanks a lot,
> Mitra
>
> ??? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From petr.pikal at precheza.cz  Fri Jun 21 18:25:50 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 21 Jun 2013 16:25:50 +0000
Subject: [R] Error
In-Reply-To: <DUB107-W114B57492FF5F348BA1AF0DE8F0@phx.gbl>
References: <DUB107-W114B57492FF5F348BA1AF0DE8F0@phx.gbl>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF880280FC93@SRVEXCHMBX.precheza.cz>

Hi

What about delivering further information about data, code, R and OS version. Most probably you are tryind to index some object in cycle above its dimension.

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Francesco Miranda
> Sent: Friday, June 21, 2013 3:37 PM
> To: r-help at r-project.org
> Subject: [R] Error
> 
> <<Error in `[<-` (`* tmp *`, i, j, value = -1.37244): index out of
> bounds>> what kind of error? how to solve it?
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hess.bn at gmail.com  Fri Jun 21 19:07:38 2013
From: hess.bn at gmail.com (Benjamin)
Date: Fri, 21 Jun 2013 13:07:38 -0400
Subject: [R] Package random forest: can corr.bias be harmful?
In-Reply-To: <51C456EE.6010508@sovon.nl>
References: <51C456EE.6010508@sovon.nl>
Message-ID: <CAKdEGU9ck8DWmpkLktuV7afOLue7Dz9hYKeHFc1QaW1v-tAFkQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130621/cf5708c2/attachment.pl>

From jvadams at usgs.gov  Fri Jun 21 21:04:44 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Fri, 21 Jun 2013 14:04:44 -0500
Subject: [R] Category error resulting in a ylim error
In-Reply-To: <CAPEc57FqT=j5UJdU=gYccWeDRgVDys0KfeNFqs_JUGAGTzKP-g@mail.gmail.com>
References: <CAPEc57HN9UQLiq3uUoEq8204jWRPx6H_KD4cxvK5uSVsgpqosQ@mail.gmail.com>
	<CAN5YmCGEmpMbC00zeigc+00DCe+t53QXw4KqhiU1vefkb-SYFA@mail.gmail.com>
	<CAPEc57FqT=j5UJdU=gYccWeDRgVDys0KfeNFqs_JUGAGTzKP-g@mail.gmail.com>
Message-ID: <CAN5YmCH+oEc7wVrwWSp8ZPVkbV=+afmExdRHpGHkf7ajxV4-PQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130621/2ce2bb58/attachment.pl>

From dwinsemius at comcast.net  Fri Jun 21 21:39:00 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 21 Jun 2013 12:39:00 -0700
Subject: [R] Gini coefficient sensitive to "skewness" of Lorenz curve?
In-Reply-To: <51C42D7F.8080801@wu.ac.at>
References: <51C42D7F.8080801@wu.ac.at>
Message-ID: <A2A359CF-BFB9-4E71-8553-E055E9DDC8AD@comcast.net>


On Jun 21, 2013, at 3:39 AM, Stefan Sobernig wrote:

> Dear list,
> 
> I have already posted to sci.stat.consult, however, I was hoping that there might be some experience in the R community on the following question:
> 
>> I am wondering whether anyone has experience with variants of (parametric) Gini coefficients (or alternatives) which allow for reflecting/penalising the skewness of a Lorenz curve?
>> 
>> For my part, I just stumbled across the following:
>> http://www.accessecon.com/Pubs/EB/2010/Volume30/EB-10-V30-I2-P146.pdf
>> 
>> While appealing to me, I did not find any alternatives, nor any reported use of this variant; nor is there any account of its liabilities (e.g., strategies to estimate the parameters).
>> 
> > ...
> >
>> P.S.: My background is not in economics/econometrics or the like, rather i am currently evaluating the use of inequality measures for software measurement. See for some background:
>> http://dx.doi.org/10.1109/ICSM.2011.6080798
> 
> I'd appreciate any hint in this direction!

This is not really the correct place to pose such a question. You might instead read the Posting Guide to see why I say that, and then post to CrossValidated.com

-- 

David Winsemius
Alameda, CA, USA


From motyocska at yahoo.com  Fri Jun 21 21:43:02 2013
From: motyocska at yahoo.com (Andras Farkas)
Date: Fri, 21 Jun 2013 12:43:02 -0700 (PDT)
Subject: [R] overlay 2 dot plots
Message-ID: <1371843782.15064.YahooMailClassic@web140401.mail.bf1.yahoo.com>

Dear All,

wonder if you would provide your insights on the following: the code:

library(lattice)
y <-c(1:58)
x <-runif(58,5,10)
z <-runif(58,8,12)
dataset <-data.frame(y,x)
dotplot(y ~ x, data = dataset)
dataset <-data.frame(y,z)
dotplot(y~z,data = dataset,col="red")

I would like to overlay the two plots, but no success so far, I tryed the add=TRUE command, but does not seem to work with this plot...

appreciate the insights,

Andras


From saptarshi.guha at gmail.com  Fri Jun 21 22:21:08 2013
From: saptarshi.guha at gmail.com (Saptarshi Guha)
Date: Fri, 21 Jun 2013 13:21:08 -0700
Subject: [R] Nulls being coerced : Bug or design?
Message-ID: <CAJDot1osMQUqW4AWEBRZE7RUNk8LCMVWSmB77Y0mVL3_T4hjRA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130621/0219411e/attachment.pl>

From gunter.berton at gene.com  Fri Jun 21 22:37:46 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 21 Jun 2013 13:37:46 -0700
Subject: [R] overlay 2 dot plots
In-Reply-To: <1371843782.15064.YahooMailClassic@web140401.mail.bf1.yahoo.com>
References: <1371843782.15064.YahooMailClassic@web140401.mail.bf1.yahoo.com>
Message-ID: <CACk-te0Q2o5bu4Wr+yMmyfNc7mysCEnuBgi5gyi34Vk2d7z0EQ@mail.gmail.com>

dotplot is a lattice function. "add" is an argument to some base
graphics. Never the twain shall meet. There is no "add" argument to
dotplot -- did you read the lattice Help for dotplot (found under
xyplot)??

I don't understand what you mean by "overlay" dotplots, but lattice
does this via conditioning variables or groups, depending on what you
have in mind.

In any case, it appears to me that you need to first read a tutorial
or book on lattice/trellis graphics before proceeding. Or find someone
local who can help you: afaics, you do not have a clue about how
lattice/trellis graphics works. It's far more than (I) can or should
be communicated on r-help.

Feel free to demonstrate publicly that **I** don't have a clue if I
have misunderstood or misjudged.

Cheers,
Bert


On Fri, Jun 21, 2013 at 12:43 PM, Andras Farkas <motyocska at yahoo.com> wrote:
> Dear All,
>
> wonder if you would provide your insights on the following: the code:
>
> library(lattice)
> y <-c(1:58)
> x <-runif(58,5,10)
> z <-runif(58,8,12)
> dataset <-data.frame(y,x)
> dotplot(y ~ x, data = dataset)
> dataset <-data.frame(y,z)
> dotplot(y~z,data = dataset,col="red")
>
> I would like to overlay the two plots, but no success so far, I tryed the add=TRUE command, but does not seem to work with this plot...
>
> appreciate the insights,
>
> Andras
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From gunter.berton at gene.com  Fri Jun 21 22:53:25 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 21 Jun 2013 13:53:25 -0700
Subject: [R] Nulls being coerced : Bug or design?
In-Reply-To: <CAJDot1osMQUqW4AWEBRZE7RUNk8LCMVWSmB77Y0mVL3_T4hjRA@mail.gmail.com>
References: <CAJDot1osMQUqW4AWEBRZE7RUNk8LCMVWSmB77Y0mVL3_T4hjRA@mail.gmail.com>
Message-ID: <CACk-te06JM2qtCGK_bQve5DaWPBa45Bq4dhyBEn_nLowQyfKYw@mail.gmail.com>

Well, feel free to make up any semantics that you like for a language
you write, but R already has its own and tells you what to expect:

>From ?NULL:

NULL can be indexed (see Extract) in just about any syntactically
legal way: whether is makes sense or not, the result is always NULL.
Objects with value NULL can be changed by replacement operators and
will be coerced to the type of the right-hand side.

Cheers,
Bert

On Fri, Jun 21, 2013 at 1:21 PM, Saptarshi Guha
<saptarshi.guha at gmail.com> wrote:
> Hello,
>
> Consider the following transcript
>
>> x=NULL
>> x$date=10
>> x
> $date
> [1] 10
>
> or
>
>> x=NULL
>> x[10]=10
>> x
>  [1] NA NA NA NA NA NA NA NA NA 10
>
>
> Wouldn't one expect that x remain NULL despite the further additions (i.e
> the x$date, x[10]) etc? Is coercing appropriate here?
>
> Cheers
> Saptarshi
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From dcarlson at tamu.edu  Fri Jun 21 23:00:36 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Fri, 21 Jun 2013 16:00:36 -0500
Subject: [R] overlay 2 dot plots
In-Reply-To: <1371843782.15064.YahooMailClassic@web140401.mail.bf1.yahoo.com>
References: <1371843782.15064.YahooMailClassic@web140401.mail.bf1.yahoo.com>
Message-ID: <020c01ce6ec2$60e38f80$22aaae80$@tamu.edu>

Maybe something like this?

dataset <- data.frame(x=c(y, y), y=c(x, z), g=rep(1:2, each=58))
dotplot(x~y, groups=g, data=dataset)

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Andras Farkas
Sent: Friday, June 21, 2013 2:43 PM
To: r-help at r-project.org
Subject: [R] overlay 2 dot plots

Dear All,

wonder if you would provide your insights on the following: the
code:

library(lattice)
y <-c(1:58)
x <-runif(58,5,10)
z <-runif(58,8,12)
dataset <-data.frame(y,x)
dotplot(y ~ x, data = dataset)
dataset <-data.frame(y,z)
dotplot(y~z,data = dataset,col="red")

I would like to overlay the two plots, but no success so far, I
tryed the add=TRUE command, but does not seem to work with this
plot...

appreciate the insights,

Andras

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Jun 21 23:38:37 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 21 Jun 2013 14:38:37 -0700
Subject: [R] Nulls being coerced : Bug or design?
In-Reply-To: <CAJDot1osMQUqW4AWEBRZE7RUNk8LCMVWSmB77Y0mVL3_T4hjRA@mail.gmail.com>
References: <CAJDot1osMQUqW4AWEBRZE7RUNk8LCMVWSmB77Y0mVL3_T4hjRA@mail.gmail.com>
Message-ID: <11237926-7C90-4F1E-8BB1-514C4CA01643@comcast.net>


On Jun 21, 2013, at 1:21 PM, Saptarshi Guha wrote:

> Hello,
> 
> Consider the following transcript
> 
>> x=NULL
>> x$date=10
>> x
> $date
> [1] 10
> 
> or
> 
>> x=NULL
>> x[10]=10
>> x
> [1] NA NA NA NA NA NA NA NA NA 10
> 
> 
> Wouldn't one expect that x remain NULL despite the further additions (i.e
> the x$date, x[10]) etc? Is coercing appropriate here?
> 

This seems like a bizarre expectation. You really want x to remain NULL until the end of time? Perhaps you meant to say that after creation of a tenth entry for x that you wanted x[1] to remain NULL (which it never was, since it didn't really exist). Or to have the display of missing values to be suppressed by the print function? Or were hoping the creation of an n-th item in x to _not_ create a vector of length n? Or that `x` be different than a multi-valued version of x[n]?

> x=NULL
> x[10]=10
> length(x)
[1] 10
> object.size(x)
168 bytes
> x[1000] <- 1000
> object.size(x)
8040 bytes

So you have apparently not realized that lists in R are actually vectors. .... by design. And the indexing a NULL value gives NULL rather than missing (NA):

x <- NULL

> x
NULL
> x[1]
NULL
> x[2]
NULL
> x
NULL

> x[10]=10
> x[1]
[1] NA

Actually I think the behavior for "[" when indexing is attempted with arguments greater than the length of a list or vector is not at all what I would have expected. That it would have seem to me to have deserved a NULL return:

> x[111000]
[1] NA


-- 

David Winsemius
Alameda, CA, USA


From mackay at northnet.com.au  Sat Jun 22 00:52:39 2013
From: mackay at northnet.com.au (Duncan Mackay)
Date: Sat, 22 Jun 2013 08:52:39 +1000
Subject: [R] overlay 2 dot plots
In-Reply-To: <020c01ce6ec2$60e38f80$22aaae80$@tamu.edu>
References: <1371843782.15064.YahooMailClassic@web140401.mail.bf1.yahoo.com>
	<020c01ce6ec2$60e38f80$22aaae80$@tamu.edu>
Message-ID: <201306212252.r5LMqjfD015654@mail16.tpgi.com.au>

In a similiar manner with additions
  dat <- data.frame(x=x,y=y,z=z)
dotplot(y~z+x,data = dat, pch = 16, type= c("p","g"))

  HTH

Duncan


Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au



At 07:00 22/06/2013, you wrote:
>Maybe something like this?
>
>dataset <- data.frame(x=c(y, y), y=c(x, z), g=rep(1:2, each=58))
>dotplot(x~y, groups=g, data=dataset)
>
>-------------------------------------
>David L Carlson
>Associate Professor of Anthropology
>Texas A&M University
>College Station, TX 77840-4352
>
>
>-----Original Message-----
>From: r-help-bounces at r-project.org
>[mailto:r-help-bounces at r-project.org] On Behalf Of Andras Farkas
>Sent: Friday, June 21, 2013 2:43 PM
>To: r-help at r-project.org
>Subject: [R] overlay 2 dot plots
>
>Dear All,
>
>wonder if you would provide your insights on the following: the
>code:
>
>library(lattice)
>y <-c(1:58)
>x <-runif(58,5,10)
>z <-runif(58,8,12)
>dataset <-data.frame(y,x)
>dotplot(y ~ x, data = dataset)
>dataset <-data.frame(y,z)
>dotplot(y~z,data = dataset,col="red")
>
>I would like to overlay the two plots, but no success so far, I
>tryed the add=TRUE command, but does not seem to work with this
>plot...
>
>appreciate the insights,
>
>Andras
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From rolf.turner at xtra.co.nz  Sat Jun 22 01:04:49 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Sat, 22 Jun 2013 11:04:49 +1200
Subject: [R] Apply a Seasonal ARMA process
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4FFE9F@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4FFE9F@ESINO.regionemarche.intra>
Message-ID: <51C4DC11.5060407@xtra.co.nz>

On 22/06/13 01:48, Stefano Sofia wrote:
> Dear R users,
> I have a seasonal time series of period 4 (my_ts).
> I would like to apply to my_ts a Seasonal ARMA(2,0) process (only the seasonal part), with Seasonal AR coefficients respectively 0.54 and 0.5.
> I tried to use the arima command from the stats package, but this code is not correct:
>
> arima(my_ts, order=c(0,0,0), seasonal=list(order=c(2,0,0), sar=c(0.54, 0.5), period=4), n=220)
>
> The error is:
> "Error in optim(init[mask], armaCSS, method = optim.method, hessian = FALSE: initial value in 'vmmin' not finite".
>
> I am not even sure of the syntax about sar=c(0.54, 0.5).
> I looked for this topic in the R archive, but I have not been able to find an example or a useful hint.
> Could you please help me? Does arima handle seasonal ARMA processes? If yes, how? Is there a better specific package for that?

I am not at all sure what you are trying to do, but I'm pretty sure that 
whatever
it is, arima() is *not* the appropriate tool.  The arima() function is 
used to *fit*
models to time series.  E.g. in your context to *estimate* the 
coefficients of your
seasonal model.  Here you appear to *know* the values of these coefficients
(they are 0.54 and 0.5) so whatever you are trying to do it would seem that
you are not trying to estimate anything.

Perhaps you want to *filter* your time series through a seasonal AR(2) 
filter
with coefficients 0.54 and 0.5?  In this case the function filter() 
might help you.
You might also consider using arima.sim() with argument "innov" equal to 
your
given time series (which you call --- ugh!!! --- "my_ts", using that 
abominable
Micro$oft originating "my this", "my that" convention).

Where on earth did you get that "sar= ..." syntax (of which you quite 
understandably
say you are "unsure") anyhow?  The arima() function has no such argument.

         cheers,

             Rolf Turner


From smartpink111 at yahoo.com  Sat Jun 22 01:23:40 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 21 Jun 2013 16:23:40 -0700 (PDT)
Subject: [R] extracting data coincident with the beginning and end of
	multiple streaks (rle)
Message-ID: <1371857020.19428.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
May be this helps:

###Added more lines of fake data

fn_hp<- read.table(text="
id?????? date????????????? wl_m??? wet??? cuml_day 
585 fn 2012-03-03?? 0.1527048?? 1??????? 1????????????? 
586 fn 2012-03-04?? 0.2121408?? 1??????? 2????????????? 
587 fn 2012-03-05?? 0.1877568?? 1??????? 3????????????? 
588 fn 2012-03-06?? 0.1709928?? 1??????? 4????????????? 
589 fn 2012-03-07?? 0.1642872?? 1??????? 5????????????? 
598 fn 2012-03-16?? 0.0182880?? 0??????? 1????????????? 
599 fn 2012-03-17? -0.0076200?? 0??????? 2????????????? 
600 fn 2012-03-18? -0.0067056?? 0??????? 3????????????? 
601 fn 2012-03-19? -0.0097536?? 0??????? 4????????????? 
602 fn 2012-03-20?? 0.0015240?? 0??????? 5????????????? 
603 fn 2012-03-21? -0.0067056?? 0??????? 6????????????? 
604 fn 2012-03-22?? 0.0003048?? 0??????? 7????????????? 
605 fn 2012-03-23?? 0.0024384?? 0??????? 8????????????? 
606 fn 2012-03-24? -0.0054864?? 0??????? 9
607 fn 2012-03-25? -0.0067056?? 1??????? 1????????????? 
608 fn 2012-03-26?? 0.0003048?? 1??????? 2????????????? 
609 fn 2012-03-27?? 0.0024384?? 1??????? 3????????????? 
610 fn 2012-03-28? -0.0054864?? 1??????? 4
",sep="",header=TRUE,stringsAsFactors=FALSE)
fn_hp1<- fn_hp
fn_hp$DESIRED.col<-NA
fn_hp$IDNew<- cumsum(c(1,abs(diff(fn_hp$cuml_day)))>1)+1
res1<-? unsplit(lapply(split(fn_hp,fn_hp$IDNew),function(x){ x$DESIRED.col[1]<-tail(x$cuml_day,1);x$DESIRED.col[nrow(x)]<- x$DESIRED.col[1];x}),fn_hp$IDNew)[,-7]
res1[!is.na(res1$DESIRED.col),]
#??? id?????? date?????? wl_m wet cuml_day DESIRED.col
#585 fn 2012-03-03? 0.1527048?? 1??????? 1?????????? 5
#589 fn 2012-03-07? 0.1642872?? 1??????? 5?????????? 5
#598 fn 2012-03-16? 0.0182880?? 0??????? 1?????????? 9
#606 fn 2012-03-24 -0.0054864?? 0??????? 9?????????? 9
#607 fn 2012-03-25 -0.0067056?? 1??????? 1?????????? 4
#610 fn 2012-03-28 -0.0054864?? 1??????? 4?????????? 4

#or
fn_hp1$IDNew<-cumsum(c(1,abs(diff(fn_hp1$cuml_day)))>1)+1
library(plyr)
res2<-ddply(fn_hp1,.(IDNew),mutate,DESIRED.col=c(tail(cuml_day,1),rep(NA,length(cuml_day)-2),tail(cuml_day,1)))[,-6]
row.names(res2)<- row.names(fn_hp1)
?res2[!is.na(res2$DESIRED.col),-6]
#??? id?????? date?????? wl_m wet cuml_day
#585 fn 2012-03-03? 0.1527048?? 1??????? 1
#589 fn 2012-03-07? 0.1642872?? 1??????? 5
#598 fn 2012-03-16? 0.0182880?? 0??????? 1
#606 fn 2012-03-24 -0.0054864?? 0??????? 9
#607 fn 2012-03-25 -0.0067056?? 1??????? 1
#610 fn 2012-03-28 -0.0054864?? 1??????? 4

#or
#if the `DESIRED.col` is not needed
res3<- ddply(fn_hp1,.(IDNew),function(x) x[c(1,nrow(x)),])[,-6]
res3
#? id?????? date?????? wl_m wet cuml_day
#1 fn 2012-03-03? 0.1527048?? 1??????? 1
#2 fn 2012-03-07? 0.1642872?? 1??????? 5
#3 fn 2012-03-16? 0.0182880?? 0??????? 1
#4 fn 2012-03-24 -0.0054864?? 0??????? 9
#5 fn 2012-03-25 -0.0067056?? 1??????? 1
#6 fn 2012-03-28 -0.0054864?? 1??????? 4


A.K.


Good day: 

I used rle to calculate the wet and dry duration (cuml_day) of wetlands using the "wet" variable from the sample data below. 

>cum_day<- unlist( lapply( rle(fn_hp$wet)$lengths, seq_len)) ### counts consecutive 1 and 0 ### ? 
>fn_hp<-cbind(fn_hp,cum_day) ### bind cumul. days to org dataframe 

?I would now like to extract the rows of data that correspond to
 the beginning and end of each streak so I can look at both the duration
 of the streak and the date ranges where it occurred (to see if wet 
periods coincide with amphibian breeding periods). 

- An alternative solution would be to add the streak length from rle to each row that was included in the particular streak (DESIRED.col) 

I am a relatively new R user and not sure the best way to approach this. Any insight is appreciated. 
-Jeff 
? ? ? 
? ? ? ?id ? ? ? date ? ? ? ? ? ? ?wl_m ? ?wet ? ?cuml_day ? DESIRED.col
585 fn 2012-03-03 ? 0.1527048 ? 1 ? ? ? ?1 ? ? ? ? ? ? ? ? ? ? ? 5 
586 fn 2012-03-04 ? 0.2121408 ? 1 ? ? ? ?2 ? ? ? ? ? ? ? ? ? ? ? . 
587 fn 2012-03-05 ? 0.1877568 ? 1 ? ? ? ?3 ? ? ? ? ? ? ? ? ? ? ? . 
588 fn 2012-03-06 ? 0.1709928 ? 1 ? ? ? ?4 ? ? ? ? ? ? ? ? ? ? ? . 
589 fn 2012-03-07 ? 0.1642872 ? 1 ? ? ? ?5 ? ? ? ? ? ? ? ? ? ? ? 5 
598 fn 2012-03-16 ? 0.0182880 ? 0 ? ? ? ?1 ? ? ? ? ? ? ? ? ? ? ? 9 
599 fn 2012-03-17 ?-0.0076200 ? 0 ? ? ? ?2 ? ? ? ? ? ? ? ? ? ? ? . 
600 fn 2012-03-18 ?-0.0067056 ? 0 ? ? ? ?3 ? ? ? ? ? ? ? ? ? ? ? . 
601 fn 2012-03-19 ?-0.0097536 ? 0 ? ? ? ?4 ? ? ? ? ? ? ? ? ? ? ? . 
602 fn 2012-03-20 ? 0.0015240 ? 0 ? ? ? ?5 ? ? ? ? ? ? ? ? ? ? ? . 
603 fn 2012-03-21 ?-0.0067056 ? 0 ? ? ? ?6 ? ? ? ? ? ? ? ? ? ? ? . 
604 fn 2012-03-22 ? 0.0003048 ? 0 ? ? ? ?7 ? ? ? ? ? ? ? ? ? ? ? . 
605 fn 2012-03-23 ? 0.0024384 ? 0 ? ? ? ?8 ? ? ? ? ? ? ? ? ? ? ? . 
606 fn 2012-03-24 ?-0.0054864 ? 0 ? ? ? ?9 ? ? ? ? ? ? ? ? ? ? ?9


From jfox at mcmaster.ca  Sat Jun 22 05:36:51 2013
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 21 Jun 2013 23:36:51 -0400
Subject: [R] Levene's test output
In-Reply-To: <51C40AEA.2060602@gmail.com>
References: <51C40AEA.2060602@gmail.com>
Message-ID: <web-462958217@cgpsrv2.cis.mcmaster.ca>

Dear pieter,

On Fri, 21 Jun 2013 10:12:26 +0200
 pieter <dencoussie at gmail.com> wrote:
> Hey,
> I don't really get the output of the performed Levene's test.
> So in short.
> two data sets, one with 75 elements, one with 283.
> And I want to check whether they have the same variance.
> 
> I did a LeveneTest
> And this is the output:
> 
> Levene's Test for Homogeneity of Variance (center = median)
>         Df F value   Pr(>F)
> group   1  10.948 0.001033 **
>        356
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> So I would think that H0 is being rejected? for everything except 99.9%?

0.001033 is the p-value for the null hypothesis of equal variances.

> But what does the 356 mean?

The residual df for the test.

> Is this test performed correctly? 

I certainly hope so.

John

------------------------------------------------
John Fox
Sen. William McMaster Prof. of Social Statistics
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/

> group is a vector with 1's and 2's 
> appointing the two datasets...
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From njessup at tpg.com.au  Sat Jun 22 04:27:39 2013
From: njessup at tpg.com.au (Norman Jessup)
Date: Sat, 22 Jun 2013 12:27:39 +1000
Subject: [R] R  2.11 on Mac OS X
Message-ID: <51C50B9B.2080005@tpg.com.au>

Hello,

I've recently upgraded to R 2.11.1 on Mac OS X 10.8.4.   Now when I 
start R up I get the following message:

Error in identical(call[[1L]], quote(doTryCatch)) :
   7 arguments passed to .Internal(identical) which requires 5
Error in normalizePath(dirname(pkgpath), "/", TRUE) :
   3 arguments passed to .Internal(normalizePath) which requires 1
cannot find system Renviron

I get a similar message with user-defined functions ( i.e "X arguments 
passed when Y defined" ) though the functions appear to work.  This 
problem is also encountered when Rstudio fires up and so it cannot run now.

I did find a post that suggested it may be due to R accessing an old, 
possibly 32 bit library (I used to have 32 and 64 bit R installed and 
they both ran without trouble).  Possibly I need to completely clean out 
the installation and start again?  but I'm not sure precisely where the 
R support files are stored on Macs.  Can anyone give me a pointer and/or 
suggest an alternative fix?

Thank you

-- 
Norman Jessup


From bree.witteveen at alaska.edu  Sat Jun 22 00:18:57 2013
From: bree.witteveen at alaska.edu (Bree W)
Date: Fri, 21 Jun 2013 15:18:57 -0700 (PDT)
Subject: [R] Calculating an index of colocation for a large dataset
Message-ID: <1371853137063-4670084.post@n4.nabble.com>

I have a complicated, multi-part question. My apologies if I do not make
myself clear. I am also a fairly novice R user, so forgive me if this seems
rudimentary. I want to calculate a index of colocation for whale dive data
and prey distribution data. This entails:

Calculating a frequency distribution of whale depth of dive data BY DIVE
into depth bins from prey (fish and zoop) data.
For each dive, calculate the center of gravity (CG) and inertia (I).
For each dive, calculate a global index of colocation (GIC) vs. each prey
type.
I want to be able to write a function (or series of functions) such that I
do not have to separate my data by dive and rerun the functions for each
dive manually.

Example whale data, where number if the dive number (sometimes 40+ dives),
dive is equal to the depth and classification is related to the type of dive
it is. [IMG]http://i41.tinypic.com/33vc5rs.jpg[/IMG]

Depth bins come from a separate data set containing prey information:
[IMG]http://i43.tinypic.com/rjjy4n.jpg[/IMG]

I have the following codes that work for the dive data as a whole, but need
to write a loop or include an apply function such that I can run this for
the data for each dive which is contained in a single file. So, for a whale
with 40 dives, I need 40 whale frequencies, 40 whale CGs, 40 whale Is, etc.
The prey distributionss are the SAME for each dive! Ultimately, I'd like a
table which contains a list of the delta GIC values.

#bin whale dive depths
whale.cut=cut(whale,c(0 ,depths), right=FALSE) 
whale.freq=table(whale.cut) 

# compute CG 
fish.CG=sum(depths*fish)/sum(fish)
whale.CG=sum(depths*whale.freq)/sum(whale.freq)
zoop.CG=sum(depths*zoop)/sum(zoop)

# compute Inertia 
fish.I=sum((depths-fish.CG)^2*fish)/sum(fish)
whale.I=sum((depths-whale.CG)^2*whale.freq)/sum(whale.freq)
zoop.I=sum((depths-zoop.CG)^2*zoop)/sum(zoop)

#compute GIC as per 
# compute delta CG
deltaCG.fish_whale=fish.CG-whale.CG
GIC.fish_whale=
1-((deltaCG.fish_whale)^2/((deltaCG.fish_whale)^2+fish.I+whale.I))
deltaCG.zoop_whale=zoop.CG-whale.CG
GIC.zoop_whale=
1-((deltaCG.zoop_whale)^2/((deltaCG.zoop_whale)^2+zoop.I+whale.I))



--
View this message in context: http://r.789695.n4.nabble.com/Calculating-an-index-of-colocation-for-a-large-dataset-tp4670084.html
Sent from the R help mailing list archive at Nabble.com.


From David.Duffy at qimr.edu.au  Sat Jun 22 05:09:44 2013
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Sat, 22 Jun 2013 13:09:44 +1000
Subject: [R] R-help Digest, Vol 124, Issue 22
In-Reply-To: <mailman.25.1371808808.25939.r-help@r-project.org>
References: <mailman.25.1371808808.25939.r-help@r-project.org>
Message-ID: <alpine.LMD.2.00.1306221258270.20145@orpheus.qimr.edu.au>


"Vallejo, Roger" <Roger.Vallejo at ARS.USDA.GOV> asked:

> I would like to know if we can estimate Rg between two binary traits
> (disease status: alive vs. dead) with the R package.
>
> My data: we have 100 full-sib (FS) families,
> and two random samples (each with n= 200 FS fish) from each FS family
> were evaluated for disease resistance to two different bacterial
> diseases, separately. Both traits are not recorded in the same
> individual; both traits are recorded in different full-sibs from a FS
> family.

Yes. Check out http://glmm.wikidot.com/ and the R-sig-mixed-models list. 
MCMCglmm is the package most explicitly for multivariate
genetic analysis, but given you have only full sibs, there are a quite a 
few choices.


From mackay at northnet.com.au  Sat Jun 22 06:23:49 2013
From: mackay at northnet.com.au (Duncan Mackay)
Date: Sat, 22 Jun 2013 14:23:49 +1000
Subject: [R] Superpose two QQ-plots (gamma distribution) with lattice
 function qqmath()
In-Reply-To: <51C4694A.6@uhb.fr>
References: <51C4694A.6@uhb.fr>
Message-ID: <201306220423.r5M4Nskb015458@mail12.tpg.com.au>

Hi

Following on David's rate argument

try (with modifications of pch and grid)

rate <- 1/4
shape = 8
rate = c(rep(1/4,100),rep(1/3,100))
x = rgamma(200,shape,rate)
groups = gl(2,100,200,labels=LETTERS[1:2])
dat = data.frame(x=x, gp=groups)

qqmath(~ x,  data = dat,
        groups = gp,
        pch = 20,
        type = c("p","g"),
        distribution = function(x) qgamma(x,shape,rate),
        panel = function(x,groups,...) {
                  panel.qqmath(x,groups, ...)
        })

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


At 00:55 22/06/2013, you wrote:
>Hello,
>
>I am trying to superpose on a single panel two QQ plots with the 
>lattice qqmath function.
>
>Here is a reproducible example of the problem I am facing:
>
># Generate data
>shape = 8
>rate = c(rep(1/4,100),rep(1/3,100))
>x = rgamma(200,shape,rate)
>groups = gl(2,100,200,labels=LETTERS[1:2])
>
># Plot
>qqmath(~x,groups=groups,panel = "panel.superpose",
>distribution = function(x) qgamma(x,shape,rate),
>panel.groups = function(x,subscripts,...) {
>         panel.qqmath(x,shape=shape,rate=rate[subscripts],...)
>         panel.qqmathline(x,shape=shape,rate=rate[subscripts],...)
>})
>
>Both data series seem to be reproduced twice, somewhat rescaled.
>
>I don't understand what this mean.
>
>What am I doing wrong?
>
>Thanks a lot for your help,
>
>Yvonnick Noel
>University of Brittany, Rennes
>Dpt. of Psychology
>France
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


From lovelybeartlk at gmail.com  Sat Jun 22 07:36:28 2013
From: lovelybeartlk at gmail.com (lay khoon)
Date: Sat, 22 Jun 2013 15:36:28 +1000
Subject: [R] (no subject)
Message-ID: <CABOx99ZBhfhs5FNYL+9QjNvxC9jhYY_CHTkE2zvgMc39zSn6DA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130622/b6bea003/attachment.pl>

From dwinsemius at comcast.net  Sat Jun 22 10:27:58 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 22 Jun 2013 01:27:58 -0700
Subject: [R] R  2.11 on Mac OS X
In-Reply-To: <51C50B9B.2080005@tpg.com.au>
References: <51C50B9B.2080005@tpg.com.au>
Message-ID: <5F01B7CB-3938-49E6-9D2F-21CC98291175@comcast.net>


On Jun 21, 2013, at 7:27 PM, Norman Jessup wrote:

> Hello,
> 
> I've recently upgraded to R 2.11.1 on Mac OS X 10.8.4.   Now when I start R up I get the following message:
> 
> Error in identical(call[[1L]], quote(doTryCatch)) :
>  7 arguments passed to .Internal(identical) which requires 5
> Error in normalizePath(dirname(pkgpath), "/", TRUE) :
>  3 arguments passed to .Internal(normalizePath) which requires 1
> cannot find system Renviron
> 
> I get a similar message with user-defined functions ( i.e "X arguments passed when Y defined" ) though the functions appear to work.  This problem is also encountered when Rstudio fires up and so it cannot run now.
> 
> I did find a post that suggested it may be due to R accessing an old, possibly 32 bit library (I used to have 32 and 64 bit R installed and they both ran without trouble).  Possibly I need to completely clean out the installation and start again?  but I'm not sure precisely where the R support files are stored on Macs.  Can anyone give me a pointer and/or suggest an alternative fix?

R 2.11.1 is a rather archaic version. The current version is 3.0.1. You seems to have skipped major versions 2.12, 2.13,, 2.14 2.15. I doubt that OSX 10.8.4 was available when 2.11.1 was compiled. There is a mailing list for MacOS versions of R but I doubt there will be much interest in supporting version 2.11.1 on OSX 10.8.4. I suggest you install instead version 3.0.1

-- 

David Winsemius
Alameda, CA, USA


From wjddls2464 at naver.com  Sat Jun 22 11:06:43 2013
From: wjddls2464 at naver.com (=?UTF-8?B?7Ius7KCV7J24?=)
Date: Sat, 22 Jun 2013 18:06:43 +0900 (KST)
Subject: [R] =?utf-8?q?I_have_a_question?=
Message-ID: <e1d8a8d16034fcea58abd97c6e5eb0@tweb05.nm.nhnsystem.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130622/1c0b2a2e/attachment.pl>

From wjddls2464 at naver.com  Sat Jun 22 11:54:28 2013
From: wjddls2464 at naver.com (=?UTF-8?B?7Ius7KCV7J24?=)
Date: Sat, 22 Jun 2013 18:54:28 +0900 (KST)
Subject: [R] =?utf-8?q?I_have_another_question?=
Message-ID: <e3274d6c64d4df924f1cb7492475731b@tweb08.nm.nhnsystem.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130622/a9f39ab5/attachment.pl>

From yvonnick.noel at uhb.fr  Sat Jun 22 13:06:47 2013
From: yvonnick.noel at uhb.fr (Yvonnick Noel)
Date: Sat, 22 Jun 2013 13:06:47 +0200
Subject: [R] Superpose two QQ-plots (gamma distribution) with,
 lattice function qqmath()
In-Reply-To: <mailman.19.1371895207.23183.r-help@r-project.org>
References: <mailman.19.1371895207.23183.r-help@r-project.org>
Message-ID: <51C58547.90402@uhb.fr>

David, Duncan,
> Hi
>
> Following on David's rate argument
>
> try (with modifications of pch and grid)
>
> rate <- 1/4
> shape = 8
> rate = c(rep(1/4,100),rep(1/3,100))

I don't think the problem is related to the rate argument, which can 
well be vectorized, as is the case for a number of arguments in distrib 
functions in R (note that you are redefining it as a vector above).

> x = rgamma(200,shape,rate)
> groups = gl(2,100,200,labels=LETTERS[1:2])
> dat = data.frame(x=x, gp=groups)
>
> qqmath(~ x,  data = dat,
>          groups = gp,
>          pch = 20,
>          type = c("p","g"),
>          distribution = function(x) qgamma(x,shape,rate),
>          panel = function(x,groups,...) {
>                    panel.qqmath(x,groups, ...)
>          })

This works! Thank you very much (I had spent some time on that).

I now try to add a QQ-line but face a new problem. Only one line 
appears, away from the points:
qqmath(~ x,  data = dat,
         groups = gp,
         pch = 20,
         type = c("p","g"),
         distribution = function(x) qgamma(x,shape,rate),
         panel = function(x,groups,...) {
                   panel.qqmath(x,groups, ...)
                   panel.qqmathline(x,groups,...)
         })

Any hint?

Thanks a lot for your help,

Yvonnick


From ruipbarradas at sapo.pt  Sat Jun 22 13:27:53 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 22 Jun 2013 12:27:53 +0100
Subject: [R] I have another question
In-Reply-To: <e3274d6c64d4df924f1cb7492475731b@tweb08.nm.nhnsystem.com>
References: <e3274d6c64d4df924f1cb7492475731b@tweb08.nm.nhnsystem.com>
Message-ID: <51C58A39.2010507@sapo.pt>

Hello,

At an R prompt type

?lgamma
?nlminb

and read the respective help pages.

Hope this helps,

Rui Barradas

Em 22-06-2013 10:54, ??? escreveu:
> Could you tell me what mean is that lgamma, digamma, and nlminb ?
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ruipbarradas at sapo.pt  Sat Jun 22 13:41:29 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 22 Jun 2013 12:41:29 +0100
Subject: [R] I have a question
In-Reply-To: <e1d8a8d16034fcea58abd97c6e5eb0@tweb05.nm.nhnsystem.com>
References: <e1d8a8d16034fcea58abd97c6e5eb0@tweb05.nm.nhnsystem.com>
Message-ID: <51C58D69.2080406@sapo.pt>

Hello,

There's a no homework policy. Please ask your question here:

http://stackoverflow.com/questions/tagged/r

Hope this helps,

Rui Barradas

Em 22-06-2013 10:06, ??? escreveu:
> Hi!
> my name is jeong in Sim.
> Now I'm studying MLE(Maximum Likelyhood Estimation) and MOM(Method of moments).
> I want to compare with the performance of MLE and MOM by making functions and drawing a plot.
> But I don't know how to do . so I want you to show me some R codes.
>
> First of all, I want to know detail R code(which included function) that calculates MOM and MLE.
> And then I want to know how to make a plot to summarize my results.
> Finally, I want to summarize my own simulation results based on 100 simulations with a sample size n=50,parameter values alpha=3, lambda=2, and a random seed 1234.
>
> Thank you, I'll hope your answer as soon as possible.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mackay at northnet.com.au  Sat Jun 22 16:46:57 2013
From: mackay at northnet.com.au (Duncan Mackay)
Date: Sun, 23 Jun 2013 00:46:57 +1000
Subject: [R] Superpose two QQ-plots (gamma distribution)  with,
 lattice function qqmath()
In-Reply-To: <51C58547.90402@uhb.fr>
References: <mailman.19.1371895207.23183.r-help@r-project.org>
	<51C58547.90402@uhb.fr>
Message-ID: <201306221447.r5MEl3F5022300@mail16.tpgi.com.au>

Hi

I think  the answer lies in the allocating the distribution argument 
but I do not know how. Possibly with a prepanel function

Duncan

At 21:06 22/06/2013, you wrote:
>David, Duncan,
>>Hi
>>
>>Following on David's rate argument
>>
>>try (with modifications of pch and grid)
>>
>>rate <- 1/4
>>shape = 8
>>rate = c(rep(1/4,100),rep(1/3,100))
>
>I don't think the problem is related to the rate argument, which can 
>well be vectorized, as is the case for a number of arguments in 
>distrib functions in R (note that you are redefining it as a vector above).
>
>>x = rgamma(200,shape,rate)
>>groups = gl(2,100,200,labels=LETTERS[1:2])
>>dat = data.frame(x=x, gp=groups)
>>
>>qqmath(~ x,  data = dat,
>>          groups = gp,
>>          pch = 20,
>>          type = c("p","g"),
>>          distribution = function(x) qgamma(x,shape,rate),
>>          panel = function(x,groups,...) {
>>                    panel.qqmath(x,groups, ...)
>>          })
>
>This works! Thank you very much (I had spent some time on that).
>
>I now try to add a QQ-line but face a new problem. Only one line 
>appears, away from the points:
>qqmath(~ x,  data = dat,
>         groups = gp,
>         pch = 20,
>         type = c("p","g"),
>         distribution = function(x) qgamma(x,shape,rate),
>         panel = function(x,groups,...) {
>                   panel.qqmath(x,groups, ...)
>                   panel.qqmathline(x,groups,...)
>         })
>
>Any hint?
>
>Thanks a lot for your help,
>
>Yvonnick
>


From motyocska at yahoo.com  Sat Jun 22 17:22:41 2013
From: motyocska at yahoo.com (Andras Farkas)
Date: Sat, 22 Jun 2013 08:22:41 -0700 (PDT)
Subject: [R] overlay 2 dot plots
In-Reply-To: <CACk-te0Q2o5bu4Wr+yMmyfNc7mysCEnuBgi5gyi34Vk2d7z0EQ@mail.gmail.com>
Message-ID: <1371914561.88518.YahooMailClassic@web140406.mail.bf1.yahoo.com>

Bert,

you did judge all right, indeed, I do not have a clue about how lattice/trellis graphics works. With regards to "Feel free to demonstrate publicly that **I** don't have a clue if I have misunderstood or misjudged", thank you, but I will pass on that... I do not feel it is important for me to publicly demonstrate the fact that someone does not know as much about the area of **my** primary interest as **I** do, instead, I would rather teach them... There are others that do a great job at this kind of "public demonstration":-).

by overlaying this is what I meant:

library(lattice)
y <-c(1:58)
x <-runif(58,5,10)
z <-runif(58,8,12)
dataset <-data.frame(y,x,z)

dotplot(y ~ c(x,z), data = dataset,col=c("blue","red"))

thanks for the help,

Cheers,

Andras

--- On Fri, 6/21/13, Bert Gunter <gunter.berton at gene.com> wrote:

> From: Bert Gunter <gunter.berton at gene.com>
> Subject: Re: [R] overlay 2 dot plots
> To: "Andras Farkas" <motyocska at yahoo.com>
> Cc: r-help at r-project.org
> Date: Friday, June 21, 2013, 4:37 PM
> dotplot is a lattice function. "add"
> is an argument to some base
> graphics. Never the twain shall meet. There is no "add"
> argument to
> dotplot -- did you read the lattice Help for dotplot (found
> under
> xyplot)??
> 
> I don't understand what you mean by "overlay" dotplots, but
> lattice
> does this via conditioning variables or groups, depending on
> what you
> have in mind.
> 
> In any case, it appears to me that you need to first read a
> tutorial
> or book on lattice/trellis graphics before proceeding. Or
> find someone
> local who can help you: afaics, you do not have a clue about
> how
> lattice/trellis graphics works. It's far more than (I) can
> or should
> be communicated on r-help.
> 
> Feel free to demonstrate publicly that **I** don't have a
> clue if I
> have misunderstood or misjudged.
> 
> Cheers,
> Bert
> 
> 
> On Fri, Jun 21, 2013 at 12:43 PM, Andras Farkas <motyocska at yahoo.com>
> wrote:
> > Dear All,
> >
> > wonder if you would provide your insights on the
> following: the code:
> >
> > library(lattice)
> > y <-c(1:58)
> > x <-runif(58,5,10)
> > z <-runif(58,8,12)
> > dataset <-data.frame(y,x)
> > dotplot(y ~ x, data = dataset)
> > dataset <-data.frame(y,z)
> > dotplot(y~z,data = dataset,col="red")
> >
> > I would like to overlay the two plots, but no success
> so far, I tryed the add=TRUE command, but does not seem to
> work with this plot...
> >
> > appreciate the insights,
> >
> > Andras
> >
> > ______________________________________________
> > R-help at r-project.org
> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained,
> reproducible code.
> 
> 
> 
> -- 
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> 
> Internal Contact Info:
> Phone: 467-7374
> Website:
> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm
>


From suparna.mitra.sm at gmail.com  Sat Jun 22 18:07:37 2013
From: suparna.mitra.sm at gmail.com (Suparna Mitra)
Date: Sun, 23 Jun 2013 00:07:37 +0800
Subject: [R] metaMDS Error, Nan similar or negative values
Message-ID: <CAFdg=fWeJTPZCiZi91yPHC+kR1J-TQd+T9dHxjzOFH0JY+MCHA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130623/55bd6bf3/attachment.pl>

From dwinsemius at comcast.net  Sat Jun 22 18:20:04 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 22 Jun 2013 09:20:04 -0700
Subject: [R] overlay 2 dot plots
In-Reply-To: <1371914561.88518.YahooMailClassic@web140406.mail.bf1.yahoo.com>
References: <1371914561.88518.YahooMailClassic@web140406.mail.bf1.yahoo.com>
Message-ID: <BAC3DBE1-101A-4077-B4BA-EBA8C0696376@comcast.net>


On Jun 22, 2013, at 8:22 AM, Andras Farkas wrote:

> Bert,
> 
> you did judge all right, indeed, I do not have a clue about how lattice/trellis graphics works. With regards to "Feel free to demonstrate publicly that **I** don't have a clue if I have misunderstood or misjudged", thank you, but I will pass on that... I do not feel it is important for me to publicly demonstrate the fact that someone does not know as much about the area of **my** primary interest as **I** do, instead, I would rather teach them... There are others that do a great job at this kind of "public demonstration":-).
> 
> by overlaying this is what I meant:
> 
> library(lattice)
> y <-c(1:58)
> x <-runif(58,5,10)
> z <-runif(58,8,12)
> dataset <-data.frame(y,x,z)
> 
> dotplot(y ~ c(x,z), data = dataset,col=c("blue","red"))

I think you should wait a bit before doing any more lattice demonstrations. That approach completely obscures the source of hte values from 'x' and 'z' groups. Using y ~ x+z would be much more informative (as advised by Duncan MacKay

-- 
David


> 
> thanks for the help,
> 
> Cheers,
> 
> Andras
> 
> --- On Fri, 6/21/13, Bert Gunter <gunter.berton at gene.com> wrote:
> 
>> From: Bert Gunter <gunter.berton at gene.com>
>> Subject: Re: [R] overlay 2 dot plots
>> To: "Andras Farkas" <motyocska at yahoo.com>
>> Cc: r-help at r-project.org
>> Date: Friday, June 21, 2013, 4:37 PM
>> dotplot is a lattice function. "add"
>> is an argument to some base
>> graphics. Never the twain shall meet. There is no "add"
>> argument to
>> dotplot -- did you read the lattice Help for dotplot (found
>> under
>> xyplot)??
>> 
>> I don't understand what you mean by "overlay" dotplots, but
>> lattice
>> does this via conditioning variables or groups, depending on
>> what you
>> have in mind.
>> 
>> In any case, it appears to me that you need to first read a
>> tutorial
>> or book on lattice/trellis graphics before proceeding. Or
>> find someone
>> local who can help you: afaics, you do not have a clue about
>> how
>> lattice/trellis graphics works. It's far more than (I) can
>> or should
>> be communicated on r-help.
>> 
>> Feel free to demonstrate publicly that **I** don't have a
>> clue if I
>> have misunderstood or misjudged.
>> 
>> Cheers,
>> Bert
>> 
>> 
>> On Fri, Jun 21, 2013 at 12:43 PM, Andras Farkas <motyocska at yahoo.com>
>> wrote:
>>> Dear All,
>>> 
>>> wonder if you would provide your insights on the
>> following: the code:
>>> 
>>> library(lattice)
>>> y <-c(1:58)
>>> x <-runif(58,5,10)
>>> z <-runif(58,8,12)
>>> dataset <-data.frame(y,x)
>>> dotplot(y ~ x, data = dataset)
>>> dataset <-data.frame(y,z)
>>> dotplot(y~z,data = dataset,col="red")
>>> 
>>> I would like to overlay the two plots, but no success
>> so far, I tryed the add=TRUE command, but does not seem to
>> work with this plot...
>>> 
>>> appreciate the insights,
>>> 
>>> Andras
>>> 
>>> ______________________________________________
>>> R-help at r-project.org
>> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained,
>> reproducible code.
>> 
>> 
>> 
>> -- 
>> 
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> 
>> Internal Contact Info:
>> Phone: 467-7374
>> Website:
>> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From lorenzo.isella at gmail.com  Sat Jun 22 21:06:00 2013
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Sat, 22 Jun 2013 21:06:00 +0200
Subject: [R] Sparse Matrices and glmnet
Message-ID: <op.wy3goalzzqkd1e@nirvana>

Dear All,
I am not going to discuss in detail the implementation of a model, but I  
am rather puzzled because, even if I manage to train a model, then I do  
not succeed in applying it to some test data.
I am sure I am making some trivial mistake, but so far I have been banging  
my head against the floor.
When I run the following code



###############################################
library(glmnet)



test <- read.csv("test.csv", header=TRUE)

train <- read.csv("train.csv", header=TRUE)

for (i in seq(dim(train)[2])){

train[[i]] <- as.factor(train[[i]])

}




for (i in seq(dim(test)[2])){

test[[i]] <- as.factor(test[[i]])

}





X = sparse.model.matrix(as.formula(paste("ACTION ~",  
paste(colnames(train[,-1]),
     sep = "", collapse=" +"))), data = train)

  model = cv.glmnet(X, train[,1], family = "binomial")

print("glmnet model completed")



predict(model,newx=test[,2:10], s="lambda.min")

######################################################
I get the error

Error in as.matrix(cbind2(1, newx) %*% nbeta) :
   error in evaluating the argument 'x' in selecting a method for function  
'as.matrix': Error in cbind2(1, newx) %*% nbeta :
   not-yet-implemented method for <data.frame> %*% <dgCMatrix>

However, even converting test to a matrix does not help.
Essentially, I am trying to train a linear model to deal with a set of  
predictors that consist only of categorical variables.

The train and test datasets can be downloaded from

http://db.tt/23DzlIt3


http://db.tt/3GIcNpSE

Any suggestion is welcome.
Cheers

Lorenzo


From kristi.glover at hotmail.com  Sun Jun 23 03:18:11 2013
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Sat, 22 Jun 2013 22:18:11 -0300
Subject: [R] Which is the final model for a Boosted Regression Trees (GBM)?
Message-ID: <BAY154-W910EC50087902868BA095FA890@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130622/c10e863f/attachment.pl>

From gunter.berton at gene.com  Sun Jun 23 07:19:19 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 22 Jun 2013 22:19:19 -0700
Subject: [R] Which is the final model for a Boosted Regression Trees
	(GBM)?
In-Reply-To: <BAY154-W910EC50087902868BA095FA890@phx.gbl>
References: <BAY154-W910EC50087902868BA095FA890@phx.gbl>
Message-ID: <CACk-te0JG=40AE1PMT5VneurCv=i07cj8sPKZzhPY6jzBetv5Q@mail.gmail.com>

You need to read the papers referenced in the Help file. Except in
trivial cases, there are NO simple models that you can fit by hand.
Like many machine learning algorithms.

-- Bert

On Sat, Jun 22, 2013 at 6:18 PM, Kristi Glover
<kristi.glover at hotmail.com> wrote:
> Hi R User,
> I was trying to find a final model in the following example by using the Boosted regression trees (GBM). The program gives the fitted values but I wanted to calculate the fitted value by hand to understand in depth. Would you give moe some hints on what is the final model for this example?
> Thanks
>
> KG
> -------
> The following script I used
> #-----------------------
> library(dismo)
> data(Anguilla_train)
> head(Anguilla_train)
> angaus.tc5.lr01 <- gbm.step(data=Anguilla_train, gbm.x = 3:13, gbm.y = 2,
> +                         family = "bernoulli", tree.complexity = 5,
> +                         learning.rate = 0.01, bag.fraction = 0.5)
>
> names(angaus.tc5.lr01)
>  [1] "initF"                "fit"
>  [3] "train.error"          "valid.error"
>  [5] "oobag.improve"        "trees"
>  [7] "c.splits"             "bag.fraction"
>  [9] "distribution"         "interaction.depth"
> [11] "n.minobsinnode"       "n.trees"
> [13] "nTrain"               "response.name"
> [15] "shrinkage"            "train.fraction"
> [17] "var.levels"           "var.monotone"
> [19] "var.names"            "var.type"
> [21] "verbose"              "data"
> [23] "Terms"                "cv.folds"
> [25] "gbm.call"             "fitted"
> [27] "fitted.vars"          "residuals"
> [29] "contributions"        "self.statistics"
> [31] "cv.statistics"        "weights"
> [33] "trees.fitted"         "training.loss.values"
> [35] "cv.values"            "cv.loss.ses"
> [37] "cv.loss.matrix"       "cv.roc.matrix"
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From dr.timam.sn at gmail.com  Sun Jun 23 01:50:29 2013
From: dr.timam.sn at gmail.com (Dr. T. Imam)
Date: Sun, 23 Jun 2013 09:50:29 +1000
Subject: [R] Legal issue help
Message-ID: <CAB4uz6e6eEpo7tjOo_NLdYhsgWEEwfgQ4D2BVCQ=HdDqwBJ-pA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130623/d1329371/attachment.pl>

From suparna.mitra.sm at gmail.com  Sun Jun 23 10:03:25 2013
From: suparna.mitra.sm at gmail.com (Suparna Mitra)
Date: Sun, 23 Jun 2013 16:03:25 +0800
Subject: [R] Fwd: metaMDS Error, Nan similar or negative values
In-Reply-To: <CAFdg=fWeJTPZCiZi91yPHC+kR1J-TQd+T9dHxjzOFH0JY+MCHA@mail.gmail.com>
References: <CAFdg=fWeJTPZCiZi91yPHC+kR1J-TQd+T9dHxjzOFH0JY+MCHA@mail.gmail.com>
Message-ID: <CAFdg=fWzfTaAZmX6t=ovqM8u9ataOHUG9rgBOYf+6xEJhbYXPw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130623/006a0e3a/attachment.pl>

From sorenh at math.aau.dk  Sun Jun 23 11:54:03 2013
From: sorenh at math.aau.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Sun, 23 Jun 2013 09:54:03 +0000
Subject: [R] Built-in function for extracting mantissa and exponent of a
	numeric
Message-ID: <7E8037094A0C2146AA3E6F94DAE621C34454DE59@AD-EXCHMBX2-1.aau.dk>

Dear all,

Given a number

x<-1.234e12

is there a built-in function for extracting 1.234 and 12 ?

The following "hack" seems clumpsy:

> a<-strsplit(format(x, scientific=T),"e")[[1]]
> a
[1] "1.234" "+12"  
> as.numeric(a[1])
[1] 1.234
> as.integer(a[2])
[1] 12

Regards
S?ren


From ripley at stats.ox.ac.uk  Sun Jun 23 13:05:41 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 23 Jun 2013 12:05:41 +0100
Subject: [R] Built-in function for extracting mantissa and exponent of a
 numeric
In-Reply-To: <7E8037094A0C2146AA3E6F94DAE621C34454DE59@AD-EXCHMBX2-1.aau.dk>
References: <7E8037094A0C2146AA3E6F94DAE621C34454DE59@AD-EXCHMBX2-1.aau.dk>
Message-ID: <51C6D685.8080002@stats.ox.ac.uk>

On 23/06/2013 10:54, S?ren H?jsgaard wrote:
> Dear all,
>
> Given a number
>
> x<-1.234e12
>
> is there a built-in function for extracting 1.234 and 12 ?

No, because that is not how the number is stored (and in fact the value 
stored is a binary fraction with a slightly different value).

> The following "hack" seems clumpsy:

format() is doing a lot of work to produce a decimal approximation to 
'x', including choosing the precision.

It is not clear what you want: if you merely want to express x as a*10^b 
for 1 <= a < 10 then

b <- floor(log10(x))
a <- x/10^b

does the job (but might get values of a very slightly less than 1 or 
above 10, so if you care this might need checking and refinement).

>
>> a<-strsplit(format(x, scientific=T),"e")[[1]]
>> a
> [1] "1.234" "+12"
>> as.numeric(a[1])
> [1] 1.234
>> as.integer(a[2])
> [1] 12
>
> Regards
> S?ren
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch.duncan at gmail.com  Sun Jun 23 13:08:04 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 23 Jun 2013 07:08:04 -0400
Subject: [R] Built-in function for extracting mantissa and exponent of a
 numeric
In-Reply-To: <7E8037094A0C2146AA3E6F94DAE621C34454DE59@AD-EXCHMBX2-1.aau.dk>
References: <7E8037094A0C2146AA3E6F94DAE621C34454DE59@AD-EXCHMBX2-1.aau.dk>
Message-ID: <51C6D714.90309@gmail.com>

On 13-06-23 5:54 AM, S?ren H?jsgaard wrote:
> Dear all,
>
> Given a number
>
> x<-1.234e12
>
> is there a built-in function for extracting 1.234 and 12 ?

I don't think so, but it is not hard to build them from log10:

mantissa <- function(x) {
   if (x == 0) 0
   else {
     log <- log10(abs(x))
     10^(log - floor(log))
   }
}

exponent <- function(x) {
   if (x == 0) 0
   else floor(log10(abs(x)))
}

Duncan Murdoch



>
> The following "hack" seems clumpsy:
>
>> a<-strsplit(format(x, scientific=T),"e")[[1]]
>> a
> [1] "1.234" "+12"
>> as.numeric(a[1])
> [1] 1.234
>> as.integer(a[2])
> [1] 12
>
> Regards
> S?ren
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Sun Jun 23 13:59:07 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 23 Jun 2013 13:59:07 +0200
Subject: [R] Legal issue help
In-Reply-To: <CAB4uz6e6eEpo7tjOo_NLdYhsgWEEwfgQ4D2BVCQ=HdDqwBJ-pA@mail.gmail.com>
References: <CAB4uz6e6eEpo7tjOo_NLdYhsgWEEwfgQ4D2BVCQ=HdDqwBJ-pA@mail.gmail.com>
Message-ID: <51C6E30B.8000902@statistik.tu-dortmund.de>



On 23.06.2013 01:50, Dr. T. Imam wrote:
> Hi,
>
> I am new to this forum, and hopefully am sending the post to the right
> avenue (and in the appropriate format).
>
> I am planning to prepare a (to be commercially sold) book in near future,
> in which I expect to use some screenshots from R (running on Windows), and
> also graphic outputs from some of the packages..
>
> I am just wondering are there any legal requirements (in respect to
> copyright/permission of use issue) involved for such commercial use?.


We do not give legal advice.

Nevertheless, R is licensed under the GPL 2 or GPL 3. You have to look 
up the license situations for the used packages yourself.
Both, the authors of R and the package would probably appreciate if you 
cite the software you used. See ?citation in R.

Best,
Uwe Ligges



> Thank you.
>
> Regards,
> Dr. T. Imam
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ripley at stats.ox.ac.uk  Sun Jun 23 14:24:43 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 23 Jun 2013 13:24:43 +0100
Subject: [R] Legal issue help
In-Reply-To: <51C6E30B.8000902@statistik.tu-dortmund.de>
References: <CAB4uz6e6eEpo7tjOo_NLdYhsgWEEwfgQ4D2BVCQ=HdDqwBJ-pA@mail.gmail.com>
	<51C6E30B.8000902@statistik.tu-dortmund.de>
Message-ID: <51C6E90B.2080501@stats.ox.ac.uk>

On 23/06/2013 12:59, Uwe Ligges wrote:
>
>
> On 23.06.2013 01:50, Dr. T. Imam wrote:
>> Hi,
>>
>> I am new to this forum, and hopefully am sending the post to the right
>> avenue (and in the appropriate format).
>>
>> I am planning to prepare a (to be commercially sold) book in near future,
>> in which I expect to use some screenshots from R (running on Windows),
>> and
>> also graphic outputs from some of the packages..
>>
>> I am just wondering are there any legal requirements (in respect to
>> copyright/permission of use issue) involved for such commercial use?.
>
>
> We do not give legal advice.
>
> Nevertheless, R is licensed under the GPL 2 or GPL 3. You have to look
> up the license situations for the used packages yourself.
> Both, the authors of R and the package would probably appreciate if you
> cite the software you used. See ?citation in R.
>
> Best,
> Uwe Ligges

Correct.

But one other comment.  There are books containing screenshots 
(including old editions of mine) and they do go out-of-date very 
quickly: they will also baffle users of other OSes (possibly including 
other versions of Windows: screenshots from Windows XP look odd to those 
who have never used it).   I would recommend confining them to online 
supplementary material.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ruipbarradas at sapo.pt  Sun Jun 23 14:25:05 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 23 Jun 2013 13:25:05 +0100
Subject: [R] Built-in function for extracting mantissa and exponent of a
 numeric
In-Reply-To: <7E8037094A0C2146AA3E6F94DAE621C34454DE59@AD-EXCHMBX2-1.aau.dk>
References: <7E8037094A0C2146AA3E6F94DAE621C34454DE59@AD-EXCHMBX2-1.aau.dk>
Message-ID: <51C6E921.2070205@sapo.pt>

Hello,

Sorry I forgot to Cc the list.
And I had forgotten the case where x == 0.


extract <- function(x){
	e <- ifelse(x == 0, 0, floor(log10(x)))
	m <- x/10^e
	list(mantissa = m, exponent = e)
}

extract(c(0, 1.234e12, 12345678901234, 123e123))


Hope this helps,

Rui Barradas

Em 23-06-2013 10:54, S?ren H?jsgaard escreveu:
> Dear all,
>
> Given a number
>
> x<-1.234e12
>
> is there a built-in function for extracting 1.234 and 12 ?
>
> The following "hack" seems clumpsy:
>
>> a<-strsplit(format(x, scientific=T),"e")[[1]]
>> a
> [1] "1.234" "+12"
>> as.numeric(a[1])
> [1] 1.234
>> as.integer(a[2])
> [1] 12
>
> Regards
> S?ren
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From aloboaleu at gmail.com  Sun Jun 23 12:51:57 2013
From: aloboaleu at gmail.com (Agustin Lobo)
Date: Sun, 23 Jun 2013 12:51:57 +0200
Subject: [R] Problem with lubridate and decimal seconds
Message-ID: <CALPC6DNNy1_mn=-Fgre-DvuRnXBcBdqaXuGj2T+heUY+L9wyaw@mail.gmail.com>

I get lubridate objects with the same decimal seconds while they are
different in the input char:

require(lubridate)
options("digits.secs"=3)
options("digits.secs")
$digits.secs
[1] 3

dias <- c("140613","140613")
moment <- c("100545.5", "100545.6")
paste(dias,moment)
[1] "140613 100545.5" "140613 100545.6"

but
dmy_hms(paste(dias,moment))
[1] "2013-06-14 10:05:45.5 UTC" "2013-06-14 10:05:45.5 UTC"

is this a bug?

Agus
PS
> sessionInfo()
R version 3.0.0 (2013-04-03)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lubridate_1.3.0

loaded via a namespace (and not attached):
[1] digest_0.6.3  memoise_0.1   plyr_1.8      stringr_0.6.2 tools_3.0.0


--
Agustin Lobo
aloboaleu at gmail.com


From hans-christian.krumholz at uni-ulm.de  Sun Jun 23 16:17:48 2013
From: hans-christian.krumholz at uni-ulm.de (hck)
Date: Sun, 23 Jun 2013 07:17:48 -0700 (PDT)
Subject: [R] 2SLS / TSLS / SEM non-linear
Message-ID: <1371997068977-4670123.post@n4.nabble.com>

Dear all, I try to conduct a SEM / two stage least squares regression with
the following equations: 

First: X ~ IV1 + IV2 * Y
Second: Y ~ a + b X

therein, IV1 and IV2 are the two instruments I would like to use.  the
structure I would like to maintain as the model is derived from economic
theory. My problem here is that I have trouble solving the equations to get
the reduced form so I can run the tsls function of the gmm package (or just
run two regressions using the lm funcation)

Has anybody encountered a similar problem yet? The regular text books such
as Wooldridge, Greene, or Stock and Watson are not much help here.

Thanks and kind regards
HC



--
View this message in context: http://r.789695.n4.nabble.com/2SLS-TSLS-SEM-non-linear-tp4670123.html
Sent from the R help mailing list archive at Nabble.com.


From triutami.iut at gmail.com  Sun Jun 23 18:16:43 2013
From: triutami.iut at gmail.com (Iut Tri Utami)
Date: Sun, 23 Jun 2013 23:16:43 +0700
Subject: [R] need an assistance
In-Reply-To: <CANpQC0kXmoTMRBvg6JCXdDL2a9XqZ6oLxNxys=DBZR5+6PNmgw@mail.gmail.com>
References: <CANpQC0kXmoTMRBvg6JCXdDL2a9XqZ6oLxNxys=DBZR5+6PNmgw@mail.gmail.com>
Message-ID: <CANpQC0nt_ECyDqgCN6Yzh59XP_ezo7_h9nNpYXZqOwYPgBmvfA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130623/79e0a6ec/attachment.pl>

From zilefacelvis at yahoo.com  Sun Jun 23 19:29:04 2013
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Sun, 23 Jun 2013 10:29:04 -0700 (PDT)
Subject: [R] Apply acf  to data frame containing 'NA'
Message-ID: <1372008544.78305.YahooMailNeo@web160601.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130623/745ab73c/attachment.pl>

From smartpink111 at yahoo.com  Sun Jun 23 19:41:54 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 23 Jun 2013 10:41:54 -0700 (PDT)
Subject: [R] Apply acf  to data frame containing 'NA'
In-Reply-To: <1372008544.78305.YahooMailNeo@web160601.mail.bf1.yahoo.com>
References: <1372008544.78305.YahooMailNeo@web160601.mail.bf1.yahoo.com>
Message-ID: <1372009314.82467.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
May be this helps:
set.seed(24)
A <- matrix(sample(c(NA,rnorm(1500)),1500,replace=FALSE),nrow=500)
par(mfrow=c(ncol(A),1))
?lapply(split(A,col(A)),function(x) acf(na.omit(x)))
A.K.




----- Original Message -----
From: Zilefac Elvis <zilefacelvis at yahoo.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Sunday, June 23, 2013 1:29 PM
Subject: [R] Apply acf  to data frame containing 'NA'

Hi,
I have a data frame with each column representing a?separate site.
Following this code, I can apply acf to all columns in A. 'A' contains randomly generated data.

A <- matrix(rnorm(1500),nrow=500)
par(mfrow=c(ncol(A),1))

lapply(split(A,col(A)), acf)

#OR
lapply(split(A,col(A)), function(snow) acf(snow, lag.max=5))


Problem:?Some of my data contains 'NA' in some of the columns. I get this error
"Error in na.fail.default(as.ts(x)) : missing values in object"
How can I resolve this problem?

Thanks.
AE.
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From zilefacelvis at yahoo.com  Sun Jun 23 19:51:32 2013
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Sun, 23 Jun 2013 10:51:32 -0700 (PDT)
Subject: [R] Apply acf  to data frame containing 'NA'
In-Reply-To: <1372009314.82467.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1372008544.78305.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1372009314.82467.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1372009892.48395.YahooMailNeo@web160606.mail.bf1.yahoo.com>

Hi,
Thanks so much for the quick reply.
It worked on your data but failed on mine.
Attached is my data.?
I received this error:
"Error in acf(na.omit(x)) : 'lag.max' must be at least 0
In addition: Warning message:
In split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...) :
? data length is not a multiple of split variable"

AE.


________________________________
 From: arun <smartpink111 at yahoo.com>
To: Zilefac Elvis <zilefacelvis at yahoo.com> 
Cc: R help <r-help at r-project.org> 
Sent: Sunday, June 23, 2013 11:41 AM
Subject: Re: [R] Apply acf  to data frame containing 'NA'
 

Hi,
May be this helps:
set.seed(24)
A <- matrix(sample(c(NA,rnorm(1500)),1500,replace=FALSE),nrow=500)
par(mfrow=c(ncol(A),1))
?lapply(split(A,col(A)),function(x) acf(na.omit(x)))
A.K.




----- Original Message -----
From: Zilefac Elvis <zilefacelvis at yahoo.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Sunday, June 23, 2013 1:29 PM
Subject: [R] Apply acf? to data frame containing 'NA'

Hi,
I have a data frame with each column representing a?separate site.
Following this code, I can apply acf to all columns in A. 'A' contains randomly generated data.

A <- matrix(rnorm(1500),nrow=500)
par(mfrow=c(ncol(A),1))

lapply(split(A,col(A)), acf)

#OR
lapply(split(A,col(A)), function(snow) acf(snow, lag.max=5))


Problem:?Some of my data contains 'NA' in some of the columns. I get this error
"Error in na.fail.default(as.ts(x)) : missing values in object"
How can I resolve this problem?

Thanks.
AE.
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From Achim.Zeileis at uibk.ac.at  Sun Jun 23 19:52:27 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Sun, 23 Jun 2013 19:52:27 +0200 (CEST)
Subject: [R] 2SLS / TSLS / SEM non-linear
In-Reply-To: <1371997068977-4670123.post@n4.nabble.com>
References: <1371997068977-4670123.post@n4.nabble.com>
Message-ID: <alpine.DEB.2.02.1306231951350.27866@paninaro.uibk.ac.at>

On Sun, 23 Jun 2013, hck wrote:

> Dear all, I try to conduct a SEM / two stage least squares regression with
> the following equations:

See ivreg() in package "AER" or tsls() in "sem".

hth,
Z

> First: X ~ IV1 + IV2 * Y
> Second: Y ~ a + b X
>
> therein, IV1 and IV2 are the two instruments I would like to use.  the
> structure I would like to maintain as the model is derived from economic
> theory. My problem here is that I have trouble solving the equations to get
> the reduced form so I can run the tsls function of the gmm package (or just
> run two regressions using the lm funcation)
>
> Has anybody encountered a similar problem yet? The regular text books such
> as Wooldridge, Greene, or Stock and Watson are not much help here.
>
> Thanks and kind regards
> HC
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/2SLS-TSLS-SEM-non-linear-tp4670123.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Sun Jun 23 20:00:22 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 23 Jun 2013 11:00:22 -0700 (PDT)
Subject: [R] Apply acf  to data frame containing 'NA'
In-Reply-To: <1372009892.48395.YahooMailNeo@web160606.mail.bf1.yahoo.com>
References: <1372008544.78305.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1372009314.82467.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1372009892.48395.YahooMailNeo@web160606.mail.bf1.yahoo.com>
Message-ID: <1372010422.81405.YahooMailNeo@web142604.mail.bf1.yahoo.com>

HI,
dat1<- read.csv("AMS3.csv",sep="\t",row.names=1)
pdf("AMS3_acf.pdf")
?lapply(dat1,function(x)acf(na.omit(x)))
dev.off()

A.K.






________________________________
From: Zilefac Elvis <zilefacelvis at yahoo.com>
To: arun <smartpink111 at yahoo.com> 
Cc: R help <r-help at r-project.org> 
Sent: Sunday, June 23, 2013 1:51 PM
Subject: Re: [R] Apply acf??to data frame containing 'NA'



Hi,
Thanks so much for the quick reply.
It worked on your data but failed on mine.
Attached is my data.?
I received this error:
"Error in acf(na.omit(x)) : 'lag.max' must be at least 0
In addition: Warning message:
In split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...) :
? data length is not a multiple of split variable"

AE.


________________________________
From: arun <smartpink111 at yahoo.com>
To: Zilefac Elvis <zilefacelvis at yahoo.com> 
Cc: R help <r-help at r-project.org> 
Sent: Sunday, June 23, 2013 11:41 AM
Subject: Re: [R] Apply acf??to data frame containing 'NA'


Hi,
May be this helps:
set.seed(24)
A <- matrix(sample(c(NA,rnorm(1500)),1500,replace=FALSE),nrow=500)
par(mfrow=c(ncol(A),1))
?lapply(split(A,col(A)),function(x) acf(na.omit(x)))
A.K.




----- Original Message -----
From: Zilefac Elvis <zilefacelvis at yahoo.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Sunday, June 23, 2013 1:29 PM
Subject: [R] Apply acf? to data frame containing 'NA'

Hi,
I have a data frame with each column representing a?separate site.
Following this code, I can apply acf to all columns in A. 'A' contains randomly generated data.

A <- matrix(rnorm(1500),nrow=500)
par(mfrow=c(ncol(A),1))

lapply(split(A,col(A)), acf)

#OR
lapply(split(A,col(A)), function(snow) acf(snow, lag.max=5))


Problem:?Some of my data contains 'NA' in some of the columns. I get this error
"Error in na.fail.default(as.ts(x)) : missing values in object"
How can I resolve this problem?

Thanks.
AE.
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From olga.musayev at gmail.com  Sun Jun 23 20:12:39 2013
From: olga.musayev at gmail.com (Olga Musayev)
Date: Sun, 23 Jun 2013 14:12:39 -0400
Subject: [R] Scaling Statistical
Message-ID: <CA+RDsemNApLYh6VKrRev83e655-NvMYeouHtcz=hUVvYaF0AUw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130623/1237e1bc/attachment.pl>

From dmmtchll at gmail.com  Sun Jun 23 18:31:55 2013
From: dmmtchll at gmail.com (Dave Mitchell)
Date: Sun, 23 Jun 2013 10:31:55 -0600
Subject: [R] environment of lm
Message-ID: <CAJS5vNdUSGEPj09HxgyjnVMB9myM26GMrKNFzPzAb8rw2ex4Tw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130623/95ea8b7f/attachment.pl>

From hannahbarron at trentu.ca  Sun Jun 23 20:04:40 2013
From: hannahbarron at trentu.ca (Hannah Barron)
Date: Sun, 23 Jun 2013 14:04:40 -0400
Subject: [R] Apply acf to data frame containing 'NA'
In-Reply-To: <1372009892.48395.YahooMailNeo@web160606.mail.bf1.yahoo.com>
References: <1372008544.78305.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1372009314.82467.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1372009892.48395.YahooMailNeo@web160606.mail.bf1.yahoo.com>
Message-ID: <CACtd3+crpdFKYaHukMy4e2EU8du2v72++KVZ4hXBxLM3abF_fw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130623/79bde40b/attachment.pl>

From parkeractonruth at gmail.com  Sun Jun 23 20:34:20 2013
From: parkeractonruth at gmail.com (ruth parker)
Date: Sun, 23 Jun 2013 19:34:20 +0100
Subject: [R] Wilcox paired test error message
Message-ID: <CAF1pVf+bCpUHGL=Be6aAfd4fCohn70HayV7JBGm+osZCc6yZow@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130623/786a8b65/attachment.pl>

From gunter.berton at gene.com  Sun Jun 23 21:48:10 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 23 Jun 2013 12:48:10 -0700
Subject: [R] Apply acf to data frame containing 'NA'
In-Reply-To: <1372010422.81405.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1372008544.78305.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1372009314.82467.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1372009892.48395.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<1372010422.81405.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <CACk-te2kMMkLr3pJ-97bCvX+adE+3oY9aNTTHmyww05DOf4yBw@mail.gmail.com>

1. acf already has a na.action argument which should be used instead
of the acf(na.omit(x)) construction.

2. But more to the point, acf(x,na=na.omit)  may very well be complete
nonsense (see ?acf for hints at this). How to handle estimate
covariances with missingness and, more particularly, how to compute
acf's with missings is no easy matter.  I would recommend time with
the literature and/or consulting with a local expert before plunging
into code that, whether or not it runs, can produce wrong results.

Cheers,
Bert

On Sun, Jun 23, 2013 at 11:00 AM, arun <smartpink111 at yahoo.com> wrote:
> HI,
> dat1<- read.csv("AMS3.csv",sep="\t",row.names=1)
> pdf("AMS3_acf.pdf")
>  lapply(dat1,function(x)acf(na.omit(x)))
> dev.off()
>
> A.K.
>
>
>
>
>
>
> ________________________________
> From: Zilefac Elvis <zilefacelvis at yahoo.com>
> To: arun <smartpink111 at yahoo.com>
> Cc: R help <r-help at r-project.org>
> Sent: Sunday, June 23, 2013 1:51 PM
> Subject: Re: [R] Apply acf  to data frame containing 'NA'
>
>
>
> Hi,
> Thanks so much for the quick reply.
> It worked on your data but failed on mine.
> Attached is my data.
> I received this error:
> "Error in acf(na.omit(x)) : 'lag.max' must be at least 0
> In addition: Warning message:
> In split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...) :
>   data length is not a multiple of split variable"
>
> AE.
>
>
> ________________________________
> From: arun <smartpink111 at yahoo.com>
> To: Zilefac Elvis <zilefacelvis at yahoo.com>
> Cc: R help <r-help at r-project.org>
> Sent: Sunday, June 23, 2013 11:41 AM
> Subject: Re: [R] Apply acf  to data frame containing 'NA'
>
>
> Hi,
> May be this helps:
> set.seed(24)
> A <- matrix(sample(c(NA,rnorm(1500)),1500,replace=FALSE),nrow=500)
> par(mfrow=c(ncol(A),1))
>  lapply(split(A,col(A)),function(x) acf(na.omit(x)))
> A.K.
>
>
>
>
> ----- Original Message -----
> From: Zilefac Elvis <zilefacelvis at yahoo.com>
> To: "r-help at r-project.org" <r-help at r-project.org>
> Cc:
> Sent: Sunday, June 23, 2013 1:29 PM
> Subject: [R] Apply acf  to data frame containing 'NA'
>
> Hi,
> I have a data frame with each column representing a separate site.
> Following this code, I can apply acf to all columns in A. 'A' contains randomly generated data.
>
> A <- matrix(rnorm(1500),nrow=500)
> par(mfrow=c(ncol(A),1))
>
> lapply(split(A,col(A)), acf)
>
> #OR
> lapply(split(A,col(A)), function(snow) acf(snow, lag.max=5))
>
>
> Problem: Some of my data contains 'NA' in some of the columns. I get this error
> "Error in na.fail.default(as.ts(x)) : missing values in object"
> How can I resolve this problem?
>
> Thanks.
> AE.
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From wdunlap at tibco.com  Sun Jun 23 22:25:45 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 23 Jun 2013 20:25:45 +0000
Subject: [R] environment of lm
In-Reply-To: <CAJS5vNdUSGEPj09HxgyjnVMB9myM26GMrKNFzPzAb8rw2ex4Tw@mail.gmail.com>
References: <CAJS5vNdUSGEPj09HxgyjnVMB9myM26GMrKNFzPzAb8rw2ex4Tw@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C3068EE@PA-MBX01.na.tibco.com>

Your web site had
  WeightsBreaks <- function(){
    someData <- data.frame(x = rnorm(20, 5, 1),y =  1:20 + runif(20),z =  70:51, weight = 0.05)
    print( ls())
    ModObject <- lm('x~y + z', data = someData, weights = someData$weight)
   }
and I got the result
  > print(WeightsBreaks())
  [1] "someData"
  Error in eval(expr, envir, enclos) : object 'someData' not found
When I remove the quotes around the formula string, from
  lm('x~y + z',...)
to
  lm(x~y + z, ...)
then I get
  > print(WeightsBreaks())
  [1] "someData"
  
  Call:
  lm(formula = x ~ y + z, data = someData, weights = someData$weight)
  
  Coefficients:
  (Intercept)            y            z  
      47.7740      -0.5689      -0.6028  

The object 'x ~ y + z' is a character string, not a formula.  It gets converted into a formula by as.formula by lm() or perhaps by something that lm() calls.  The 'environment of a formula' is the environment in which the formula is created (unless you explicitly change it) so this explains why lm() could not find your stuff.

If you are are constructing your formula string using something like paste(), convert it yourself to a formula by calling as.formula explicitly from the environment where the objects it uses are.
 
Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Dave Mitchell
> Sent: Sunday, June 23, 2013 9:32 AM
> To: r-help at r-project.org
> Subject: [R] environment of lm
> 
> Hello,
> I'm running into what I believe is a scoping issue having to do with the
> environment in which the weights argument is evaluated in lm.  From the lm
> documentation "All of weights, subset and offset are evaluated in the same
> way as variables in formula, that is first in data and then in the
> environment of formula.".  In the code at http://pastebin.com/kqzxxicp I
> have 3 functions identical to each other except for
> 
> WeightsBreaks adds "weights = someData$weight"
> and
> Works uses the <<- assignment operator for someData.
> 
> My interpretation of the quoted documentation above is that lm looks at the
> data argument to find weights, subset and offset and then to the
> environment in which the formula argument lives.  Am I missing something?
> Why is it that lm only sees weights (here someData$weight) when it's in the
> global environment, yet lm sees data (someData in this case) regardless of
> whether it's in the global environment or just local to the function?
> Thanks for your time.
> 
> Dave
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Sun Jun 23 22:30:16 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sun, 23 Jun 2013 16:30:16 -0400
Subject: [R] Wilcox paired test error message
In-Reply-To: <CAF1pVf+bCpUHGL=Be6aAfd4fCohn70HayV7JBGm+osZCc6yZow@mail.gmail.com>
References: <CAF1pVf+bCpUHGL=Be6aAfd4fCohn70HayV7JBGm+osZCc6yZow@mail.gmail.com>
Message-ID: <CAM_vju=JBvp89236gGh147zd=MFtBCKeZCpbLEqgkAYKOTHN3Q@mail.gmail.com>

Hi,

If you're doing exactly as described below, then you need to add the
data argument to wilcox.test so R knows where to find beforesmall and
aftersmall. But if so, that's a rather uninformative error message.

Saraj

On Sun, Jun 23, 2013 at 2:34 PM, ruth parker <parkeractonruth at gmail.com> wrote:
> Hi,
> I've been trying to run a wilcox paired test on some data
>  beforesmall aftersmall
>  [1,]        63.5      512.0
>  [2,]        54.5      237.5
>  [3,]        52.5      161.5
>  [4,]        78.0      153.5
>  [5,]        53.5       68.0
>  [6,]        50.5       65.5
>  [7,]        69.0       52.0
>  [8,]        76.0       59.0
>  [9,]        68.0       66.5
> [10,]        75.5       66.5
> [11,]        67.0       45.5
> [12,]        81.0       54.5
> [13,]        49.0       44.0
> [14,]        51.0       42.5
> [15,]        53.0       34.5
>
> using
> wilcox.test(beforesmall ~ aftersmall,paired=T)
> but I get the error message:
>
> Error in wilcox.test.formula(beforesmall ~ aftersmall, paired = T) :
>   grouping factor must have exactly 2 levels
>
> I don't have any missing values, I have the same amount of data points for
> each group and I've looked everywhere trying to find the answer.
> Please can somebody tell me how to make it work
> thanks
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From smartpink111 at yahoo.com  Sun Jun 23 22:31:38 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 23 Jun 2013 13:31:38 -0700 (PDT)
Subject: [R] Wilcox paired test error message
Message-ID: <1372019498.4185.YahooMailNeo@web142603.mail.bf1.yahoo.com>

HI,
May be this helps:
dat1<- read.table(text="
beforesmall aftersmall
63.5????? 512.0
54.5????? 237.5
52.5????? 161.5
78.0????? 153.5
53.5?????? 68.0
50.5?????? 65.5
69.0?????? 52.0
76.0?????? 59.0
68.0?????? 66.5
75.5?????? 66.5
67.0?????? 45.5
81.0?????? 54.5
49.0?????? 44.0
51.0?????? 42.5
53.0?????? 34.5
",sep="",header=TRUE) 
wilcox.test(dat1$beforesmall,dat1$aftersmall,paired=T)
#
#??? Wilcoxon signed rank test with continuity correction
#
#data:? dat1$beforesmall and dat1$aftersmall
#V = 55, p-value = 0.7982
#alternative hypothesis: true location shift is not equal to 0
#or
library(reshape2)
?dat2<-melt(dat1)
wilcox.test(value~variable,data=dat2,paired=TRUE)
##
#??? Wilcoxon signed rank test with continuity correction
#
#data:? value by variable
#V = 55, p-value = 0.7982
#alternative hypothesis: true location shift is not equal to 0

A.K.


Hi, 
I've been trying to run a wilcox paired test on some data 
?beforesmall aftersmall 
?[1,] ? ? ? ?63.5 ? ? ?512.0 
?[2,] ? ? ? ?54.5 ? ? ?237.5 
?[3,] ? ? ? ?52.5 ? ? ?161.5 
?[4,] ? ? ? ?78.0 ? ? ?153.5 
?[5,] ? ? ? ?53.5 ? ? ? 68.0 
?[6,] ? ? ? ?50.5 ? ? ? 65.5 
?[7,] ? ? ? ?69.0 ? ? ? 52.0 
?[8,] ? ? ? ?76.0 ? ? ? 59.0 
?[9,] ? ? ? ?68.0 ? ? ? 66.5 
[10,] ? ? ? ?75.5 ? ? ? 66.5 
[11,] ? ? ? ?67.0 ? ? ? 45.5 
[12,] ? ? ? ?81.0 ? ? ? 54.5 
[13,] ? ? ? ?49.0 ? ? ? 44.0 
[14,] ? ? ? ?51.0 ? ? ? 42.5 
[15,] ? ? ? ?53.0 ? ? ? 34.5 

using 
wilcox.test(beforesmall ~ aftersmall,paired=T) 
but I get the error message: 

Error in wilcox.test.formula(beforesmall ~ aftersmall, paired = T) : 
? grouping factor must have exactly 2 levels 

I don't have any missing values, I have the same amount of data points for 
each group and I've looked everywhere trying to find the answer. 
Please can somebody tell me how to make it work 
thanks


From wdunlap at tibco.com  Sun Jun 23 22:31:41 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 23 Jun 2013 20:31:41 +0000
Subject: [R] environment of lm
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C3068EE@PA-MBX01.na.tibco.com>
References: <CAJS5vNdUSGEPj09HxgyjnVMB9myM26GMrKNFzPzAb8rw2ex4Tw@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C3068EE@PA-MBX01.na.tibco.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C306904@PA-MBX01.na.tibco.com>

By the way, you could use
   lm(x ~ y + z, data=someData, weights=weight)
instead of
   lm(x ~ y + z, data=someData, weights=someData$weight)
as 'weight' will be looked for in someData before any environment.

(You still don't want to get into the habit of passing formula strings to lm.)

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of William Dunlap
> Sent: Sunday, June 23, 2013 1:26 PM
> To: Dave Mitchell; r-help at r-project.org
> Subject: Re: [R] environment of lm
> 
> Your web site had
>   WeightsBreaks <- function(){
>     someData <- data.frame(x = rnorm(20, 5, 1),y =  1:20 + runif(20),z =  70:51, weight =
> 0.05)
>     print( ls())
>     ModObject <- lm('x~y + z', data = someData, weights = someData$weight)
>    }
> and I got the result
>   > print(WeightsBreaks())
>   [1] "someData"
>   Error in eval(expr, envir, enclos) : object 'someData' not found
> When I remove the quotes around the formula string, from
>   lm('x~y + z',...)
> to
>   lm(x~y + z, ...)
> then I get
>   > print(WeightsBreaks())
>   [1] "someData"
> 
>   Call:
>   lm(formula = x ~ y + z, data = someData, weights = someData$weight)
> 
>   Coefficients:
>   (Intercept)            y            z
>       47.7740      -0.5689      -0.6028
> 
> The object 'x ~ y + z' is a character string, not a formula.  It gets converted into a formula
> by as.formula by lm() or perhaps by something that lm() calls.  The 'environment of a
> formula' is the environment in which the formula is created (unless you explicitly change
> it) so this explains why lm() could not find your stuff.
> 
> If you are are constructing your formula string using something like paste(), convert it
> yourself to a formula by calling as.formula explicitly from the environment where the
> objects it uses are.
> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
> 
> 
> > -----Original Message-----
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> > Of Dave Mitchell
> > Sent: Sunday, June 23, 2013 9:32 AM
> > To: r-help at r-project.org
> > Subject: [R] environment of lm
> >
> > Hello,
> > I'm running into what I believe is a scoping issue having to do with the
> > environment in which the weights argument is evaluated in lm.  From the lm
> > documentation "All of weights, subset and offset are evaluated in the same
> > way as variables in formula, that is first in data and then in the
> > environment of formula.".  In the code at http://pastebin.com/kqzxxicp I
> > have 3 functions identical to each other except for
> >
> > WeightsBreaks adds "weights = someData$weight"
> > and
> > Works uses the <<- assignment operator for someData.
> >
> > My interpretation of the quoted documentation above is that lm looks at the
> > data argument to find weights, subset and offset and then to the
> > environment in which the formula argument lives.  Am I missing something?
> > Why is it that lm only sees weights (here someData$weight) when it's in the
> > global environment, yet lm sees data (someData in this case) regardless of
> > whether it's in the global environment or just local to the function?
> > Thanks for your time.
> >
> > Dave
> >
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From careyshan at gmail.com  Sun Jun 23 22:50:08 2013
From: careyshan at gmail.com (Shane Carey)
Date: Sun, 23 Jun 2013 21:50:08 +0100
Subject: [R] Fault geology xyz to raster
Message-ID: <CA+jRDxD9JO-RsbmKV3A+ceLb3nYy3+iHXfnc+iw_nMrZuyhe=Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130623/a62bdbfd/attachment.pl>

From dwinsemius at comcast.net  Sun Jun 23 22:51:25 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 23 Jun 2013 13:51:25 -0700
Subject: [R] Wilcox paired test error message
In-Reply-To: <CAF1pVf+bCpUHGL=Be6aAfd4fCohn70HayV7JBGm+osZCc6yZow@mail.gmail.com>
References: <CAF1pVf+bCpUHGL=Be6aAfd4fCohn70HayV7JBGm+osZCc6yZow@mail.gmail.com>
Message-ID: <3355C3F6-7001-4EF5-94F6-E98658BA1E81@comcast.net>


On Jun 23, 2013, at 11:34 AM, ruth parker wrote:

> Hi,
> I've been trying to run a wilcox paired test on some data
> beforesmall aftersmall
> [1,]        63.5      512.0
> [2,]        54.5      237.5
> [3,]        52.5      161.5
> [4,]        78.0      153.5
> [5,]        53.5       68.0
> [6,]        50.5       65.5
> [7,]        69.0       52.0
> [8,]        76.0       59.0
> [9,]        68.0       66.5
> [10,]        75.5       66.5
> [11,]        67.0       45.5
> [12,]        81.0       54.5
> [13,]        49.0       44.0
> [14,]        51.0       42.5
> [15,]        53.0       34.5
> 
> using
> wilcox.test(beforesmall ~ aftersmall,paired=T)
> but I get the error message:
> 
> Error in wilcox.test.formula(beforesmall ~ aftersmall, paired = T) :
>  grouping factor must have exactly 2 levels

In this instance, you are working with a matrix, so you need supply the two column vectors explicitly:

----------

wilcox.test( dat[ ,'beforesmall'] , dat[ , 'aftersmall'], paired=T)

------------

And if you are using attach() and haven't told us, then STOP DOING THAT. (It won't work with matrices and it creates confusion among the inexperienced people who use it most often.)
-- 


> I don't have any missing values, I have the same amount of data points for
> each group and I've looked everywhere trying to find the answer.
> Please can somebody tell me how to make it work
> thanks
> 
> 	[[alternative HTML version deleted]]
-- 

David Winsemius
Alameda, CA, USA


From ruipbarradas at sapo.pt  Sun Jun 23 22:54:00 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 23 Jun 2013 21:54:00 +0100
Subject: [R] Scaling Statistical
In-Reply-To: <51C75E45.6030700@sapo.pt>
References: <CA+RDsemNApLYh6VKrRev83e655-NvMYeouHtcz=hUVvYaF0AUw@mail.gmail.com>
	<51C75E45.6030700@sapo.pt>
Message-ID: <51C76068.8050305@sapo.pt>

Hello,

Sorry, I forgot to Cc the list.

Rui Barradas

Em 23-06-2013 21:44, Rui Barradas escreveu:
> Hello,
>
> See if the following does what you want.
>
> lapply(seq_len(obsv), function(i) adf.test(df[df$ID == i, 3]))
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 23-06-2013 19:12, Olga Musayev escreveu:
>> Short question: Is it possible to use statistical tests, like the
>> Augmented
>> Dickey-Fuller test, in functions with for-loops? If not, are there any
>> alternative ways to scale measures?
>>
>> Detailed explanation: I am working with time-series, and I want to flag
>> curves that are not stationary and which display pulses, trends, or level
>> shifts.
>>
>>> df
>>
>> DATE          ID VALUE2012-03-06    1   5.672012-03-07    1
>> 3.452012-03-08    1   4.562012-03-09    1   20.302012-03-10    1
>> 5.102012-03-06    2   5.672012-03-07    2   3.452012-03-08    2
>> 4.562012-03-09    2   5.282012-03-10    2   5.102012-03-06    3
>> 5.672012-03-07    3   7.802012-03-08    3   8.792012-03-09    3
>> 9.432012-03-10    3   10.99
>>
>>   You can see, object 2 is stationary, but 3 exhibits a trend and 1 has a
>> pulse at 3/09.
>>
>> What I want, in pseudo-code:
>>
>> flag<- list()
>> for (i in 1:length(obsv)) {
>>       if adf.test(i) FAIL {
>>             append(flag, i)
>>             }}
>>
>> What I have so far:
>>
>>> library(tseries)
>>> adf.test(df[which(df$ID==1), 3])
>> Augmented Dickey-Fuller Test
>>
>> data:  dataDickey-Fuller = 11.1451, Lag order = 16, p-value = 0.01null
>> hypothesis: non-stationary
>>> adf.test(df[which(df$ID==2), 3])
>> Augmented Dickey-Fuller Test
>>
>> data:  dataDickey-Fuller = 11.1451, Lag order = 16, p-value = 0.99
>> alternative hypothesis: stationary
>>
>>> adf.test(df[which(df$ID==3), 3])Augmented Dickey-Fuller Test
>>
>> data:  dataDickey-Fuller = 11.1451, Lag order = 16, p-value = 0.04null
>> hypothesis: non-stationary
>>
>>   How can I use this output in a for-loop? Thank you in advance!
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From dwinsemius at comcast.net  Sun Jun 23 23:05:55 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 23 Jun 2013 14:05:55 -0700
Subject: [R] Fault geology xyz to raster
In-Reply-To: <CA+jRDxD9JO-RsbmKV3A+ceLb3nYy3+iHXfnc+iw_nMrZuyhe=Q@mail.gmail.com>
References: <CA+jRDxD9JO-RsbmKV3A+ceLb3nYy3+iHXfnc+iw_nMrZuyhe=Q@mail.gmail.com>
Message-ID: <2FFBCFD2-FB72-43AF-803E-08DB8E437253@comcast.net>


On Jun 23, 2013, at 1:50 PM, Shane Carey wrote:

> Hi,
> 
> I have a 3-d geology problem. I have an xyz fault data set. I am able to
> view the data set in R using plot3-d

That cannot be a function name, since it is invalid syntax.

> but cannot create a raster from it. I
> need to create a raster and export so that it can be read in arcscene. Can
> anybody help?

"Create a raster"? You could try to be more vague, but it would be difficult. If you mean a png-formatted screenshot of something you are seeing on an rinteractive device, then:

   ?rgl.snapshot

-- 

David Winsemius
Alameda, CA, USA


From sergio.edfisica at gmail.com  Sun Jun 23 22:54:58 2013
From: sergio.edfisica at gmail.com (=?ISO-8859-1?Q?S=E9rgio_Henrique_almeida_da_silva_ju?=)
Date: Sun, 23 Jun 2013 17:54:58 -0300
Subject: [R] Function in R saving in xls
Message-ID: <CAEuVWs00h6FuKK5RX7JJknGs-eUT_9maHwDoyooRddKdBxcR0w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130623/9785d95a/attachment.pl>

From matteo.ghetta at gmail.com  Sun Jun 23 21:42:15 2013
From: matteo.ghetta at gmail.com (matteo)
Date: Sun, 23 Jun 2013 21:42:15 +0200
Subject: [R] statda package issue
Message-ID: <51C74F97.1080502@gmail.com>

I all,
I'm new on this list, so sorry if I do something wrong. Anyway, I have a 
problem with the installation of the package StatDA.

Typing install.package("StatDA") I receive the error:

ERROR: configuration failed for package ?MBA?
* removing ?/home/matteo/R/i686-pc-linux-gnu-library/3.0/MBA?
Warning in install.packages :
installation of package ?MBA? had non-zero exit status
ERROR: dependency ?MBA? is not available for package ?StatDA?

So I try to install the package MBA, but I receive the error:

configure: error: Boost header files not found. Under linux/Unix try R 
CMD INSTALL MBA_0.0-0.tar.gz 
--configure-args='--with-boost-include=INCLUDE_PATH'
ERROR: configuration failed for package ?MBA?

What does it mean?
Just for info, I work with RStudio on a Ubuntu 12.04 machine.

Cheers

Matteo


From anne.p.dwyer at gmail.com  Sun Jun 23 23:15:10 2013
From: anne.p.dwyer at gmail.com (Anne Dwyer)
Date: Sun, 23 Jun 2013 17:15:10 -0400
Subject: [R] Problem with svm.tune
Message-ID: <CAGMGWAcXLdFiT0k9w7BKxnT6+yoCSRrfu0u3NX6ik-7+H=dWTg@mail.gmail.com>

I am trying to learn to tune a svm model in R.

I'm using the sonar data set used by David Mease in his Google Tech
Talk video. I downloaded the data from his site. There are 130
observations in the training set. I am able to run a svm model. But
when I try to run this command:


tune_svm <-tune.svm(y~., data=x, gamma=10^(-6:-3), cost=10^(1:2))

where y is the categorical response vector for the training set and x
is the training data for x, I get the following error:

Error in model.frame.default(formula, data) : variable lengths differ
(found for 'V1')

I've doublechecked that all the data is the same length. I cleared the
workspace to make sure that I didn't have any other data labeled as x
or y.

Can someone tell me what I am doing wrong here?

Thanks.


From careyshan at gmail.com  Sun Jun 23 23:23:36 2013
From: careyshan at gmail.com (Shane Carey)
Date: Sun, 23 Jun 2013 22:23:36 +0100
Subject: [R] Fault geology xyz to raster
In-Reply-To: <2FFBCFD2-FB72-43AF-803E-08DB8E437253@comcast.net>
References: <CA+jRDxD9JO-RsbmKV3A+ceLb3nYy3+iHXfnc+iw_nMrZuyhe=Q@mail.gmail.com>
	<2FFBCFD2-FB72-43AF-803E-08DB8E437253@comcast.net>
Message-ID: <CA+jRDxAOsOi8x7-XmCscKYZQ-=kvPXuLbcOycSGLUYpqQxV_tA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130623/17a56995/attachment.pl>

From dmmtchll at gmail.com  Sun Jun 23 23:23:59 2013
From: dmmtchll at gmail.com (Dave Mitchell)
Date: Sun, 23 Jun 2013 15:23:59 -0600
Subject: [R] environment of lm
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C306904@PA-MBX01.na.tibco.com>
References: <CAJS5vNdUSGEPj09HxgyjnVMB9myM26GMrKNFzPzAb8rw2ex4Tw@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C3068EE@PA-MBX01.na.tibco.com>
	<E66794E69CFDE04D9A70842786030B931C306904@PA-MBX01.na.tibco.com>
Message-ID: <CAJS5vNfCGymD6ioCOc0iB_SyFfUeNb7-J1S3=YdWJVCJ290jVg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130623/797f68fc/attachment.pl>

From ruipbarradas at sapo.pt  Mon Jun 24 00:04:04 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 23 Jun 2013 23:04:04 +0100
Subject: [R] Function in R saving in xls
In-Reply-To: <CAEuVWs00h6FuKK5RX7JJknGs-eUT_9maHwDoyooRddKdBxcR0w@mail.gmail.com>
References: <CAEuVWs00h6FuKK5RX7JJknGs-eUT_9maHwDoyooRddKdBxcR0w@mail.gmail.com>
Message-ID: <51C770D4.5020904@sapo.pt>

Hello,

To work with xls files, check out package XLConnect. The vignette 
explains how to use it rather well.

Also, don't use attach() It can be confusing and a source for errors.

Hope this helps,

Rui Barradas

Em 23-06-2013 21:54, S?rgio Henrique almeida da silva ju escreveu:
> I created a program that breaks a database in several other banks. But in
> this program I save this several banks in txt so now I'd like save in xls,
> but I don't know how.
>
> I tried for (nm in Nms) write.table(Res[[nm]], paste(nm, 'xls', sep='.'),
> sep="\t",dec=",",col.names=TRUE, row.names=FALSE, quote=TRUE, na="NA")
>
> but it did not work
>
> decup <- function(dados,var){
>
> require(gdata)
>
> dados <- read.xls("dados.xls")
>
> attach(dados)
>
> Res = split(dados, var)
>
> for (nm in Nms) write.table(Res[[nm]], file=paste(nm, 'txt', sep='.'))
>
> for (nm in Nms) zip(paste(nm,'zip',sep='.'),paste(nm,'xls',sep='.'), zip =
> Sys.getenv("R_ZIPCMD", "zip"))
>
> }
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Mon Jun 24 00:34:12 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 23 Jun 2013 15:34:12 -0700
Subject: [R] Function in R saving in xls
In-Reply-To: <CAEuVWs00h6FuKK5RX7JJknGs-eUT_9maHwDoyooRddKdBxcR0w@mail.gmail.com>
References: <CAEuVWs00h6FuKK5RX7JJknGs-eUT_9maHwDoyooRddKdBxcR0w@mail.gmail.com>
Message-ID: <826DEC6C-A895-4AB9-ADF3-942766F091D6@comcast.net>


On Jun 23, 2013, at 1:54 PM, S?rgio Henrique almeida da silva ju wrote:

> I created a program that breaks a database in several other banks. But in
> this program I save this several banks in txt so now I'd like save in xls,
> but I don't know how.
> 
> I tried for (nm in Nms) write.table(Res[[nm]], paste(nm, 'xls', sep='.'),
> sep="\t",dec=",",col.names=TRUE, row.names=FALSE, quote=TRUE, na="NA")
> 
> but it did not work
> 
> decup <- function(dados,var){
> 
> require(gdata)
> 
> dados <- read.xls("dados.xls")
> 
> attach(dados)
> 
> Res = split(dados, var)
> 
> for (nm in Nms) write.table(Res[[nm]], file=paste(nm, 'txt', sep='.'))

So where did `Nms` come from? And what was the error?

You probably need to separated fields with a character that Excel recognizes such as commas, semi-colons, or <tab>s.

-- 
David.


> for (nm in Nms) zip(paste(nm,'zip',sep='.'),paste(nm,'xls',sep='.'), zip =
> Sys.getenv("R_ZIPCMD", "zip"))
> 
> }
> 
> 
> -- 
> S?rgio Henrique Almeida da Silva Junior
> Doutorando em Epidemiologia em Sa?de P?blica
> Escola Nacional de Sa?de P?blica S?rgio Arouca - ENSP/FIOCRUZ
> http://lattes.cnpq.br/1611345552843383
> Tel: (21) 68463637
> http://www.linkedin.com/profile/view?id=250437145&trk=tab_pro
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From njessup at tpg.com.au  Mon Jun 24 04:24:54 2013
From: njessup at tpg.com.au (Norman Jessup)
Date: Mon, 24 Jun 2013 12:24:54 +1000
Subject: [R] R  2.11 on Mac OS X
In-Reply-To: <5F01B7CB-3938-49E6-9D2F-21CC98291175@comcast.net>
References: <51C50B9B.2080005@tpg.com.au>
	<5F01B7CB-3938-49E6-9D2F-21CC98291175@comcast.net>
Message-ID: <51C7ADF6.8000500@tpg.com.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130624/1a9c4d12/attachment.pl>

From dwinsemius at comcast.net  Mon Jun 24 08:11:24 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 23 Jun 2013 23:11:24 -0700
Subject: [R] R  2.11 on Mac OS X
In-Reply-To: <51C7ADF6.8000500@tpg.com.au>
References: <51C50B9B.2080005@tpg.com.au>
	<5F01B7CB-3938-49E6-9D2F-21CC98291175@comcast.net>
	<51C7ADF6.8000500@tpg.com.au>
Message-ID: <6FAA11D6-AB16-4B19-968B-58CCD539F6B8@comcast.net>


On Jun 23, 2013, at 7:24 PM, Norman Jessup wrote:

> David,
> 
> Thank you.  You are correct - I was inadvertently accessing an old version.  Deleting the old and re-installing means I can fire up R V3.0.1 which runs fine.  
> 
> However, I still can't get R Studio to start up, receivng the following message: 
> 
> 
> ERROR r error 4 (R code execution error) [errormsg=Error in identical(call[[1L]], quote(doTryCatch)) :
> 7 arguments passed to .Internal(identical) which requires 5
> , code=local(source("/Applications/RStudio.app/Contents/Resources/R/Tools.R", local=TRUE, echo=FALSE, verbose=FALSE, encoding='UTF-8'))]; OCCURRED AT: core::Error r::exec::<anonymous namespace>::evaluateExpressions(SEXP, SEXP, SEXP *, sexp::Protect *) /Users/rstudio/rstudio/src/cpp/r/RExec.cpp:145
> 
> Even though I re-installed the latest version 0.97.551.  I wonder if there is an old Library or other support file that was not properly replaced?
> 

This isn't the right venue for difficulties with RStudio. They have their own mailing list or forum or whatever.

-- 
David.
> Thank you
> 
> Norman Jessup
>> On Jun 21, 2013, at 7:27 PM, Norman Jessup wrote:
>> 
>> 
>>> Hello,
>>> 
>>> I've recently upgraded to R 2.11.1 on Mac OS X 10.8.4.   Now when I start R up I get the following message:
>>> 
>>> Error in identical(call[[1L]], quote(doTryCatch)) :
>>>  7 arguments passed to .Internal(identical) which requires 5
>>> Error in normalizePath(dirname(pkgpath), "/", TRUE) :
>>>  3 arguments passed to .Internal(normalizePath) which requires 1
>>> cannot find system Renviron
>>> 
>>> I get a similar message with user-defined functions ( i.e "X arguments passed when Y defined" ) though the functions appear to work.  This problem is also encountered when Rstudio fires up and so it cannot run now.
>>> 
>>> I did find a post that suggested it may be due to R accessing an old, possibly 32 bit library (I used to have 32 and 64 bit R installed and they both ran without trouble).  Possibly I need to completely clean out the installation and start again?  but I'm not sure precisely where the R support files are stored on Macs.  Can anyone give me a pointer and/or suggest an alternative fix?
>>> 
>> R 2.11.1 is a rather archaic version. The current version is 3.0.1. You seems to have skipped major versions 2.12, 2.13,, 2.14 2.15. I doubt that OSX 10.8.4 was available when 2.11.1 was compiled. There is a mailing list for MacOS versions of R but I doubt there will be much interest in supporting version 2.11.1 on OSX 10.8.4. I suggest you install instead version 3.0.1
>> 
>> 
> 

David Winsemius
Alameda, CA, USA


From pdalgd at gmail.com  Mon Jun 24 08:22:02 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 24 Jun 2013 08:22:02 +0200
Subject: [R] Wilcox paired test error message
In-Reply-To: <CAM_vju=JBvp89236gGh147zd=MFtBCKeZCpbLEqgkAYKOTHN3Q@mail.gmail.com>
References: <CAF1pVf+bCpUHGL=Be6aAfd4fCohn70HayV7JBGm+osZCc6yZow@mail.gmail.com>
	<CAM_vju=JBvp89236gGh147zd=MFtBCKeZCpbLEqgkAYKOTHN3Q@mail.gmail.com>
Message-ID: <51CFDEFE-14C7-4CDA-A80B-50A3D609A25B@gmail.com>


On Jun 23, 2013, at 22:30 , Sarah Goslee wrote:

> Hi,
> 
> If you're doing exactly as described below, then you need to add the
> data argument to wilcox.test so R knows where to find beforesmall and
> aftersmall. But if so, that's a rather uninformative error message.
> 
> Saraj

Not really, if you use the formula interface, the rhs is supposed to be the grouping, as in 

wilcox.test(extra ~ group, data=sleep, paired=TRUE)

so it's telling you that "aftersmall" does not describe two groups.

(It is unfortunate, though, that we don't have a formula interface to the parallel-vector data layout for paired tests. That is the common case, the sleep data set is a rather rare exception. A formula specification for paired columns has been talked about; something like cbind(before, after) ~ 1 should be workable, but nothing has materialized to date.)

-pd   

> 
> On Sun, Jun 23, 2013 at 2:34 PM, ruth parker <parkeractonruth at gmail.com> wrote:
>> Hi,
>> I've been trying to run a wilcox paired test on some data
>> beforesmall aftersmall
>> [1,]        63.5      512.0
>> [2,]        54.5      237.5
>> [3,]        52.5      161.5
>> [4,]        78.0      153.5
>> [5,]        53.5       68.0
>> [6,]        50.5       65.5
>> [7,]        69.0       52.0
>> [8,]        76.0       59.0
>> [9,]        68.0       66.5
>> [10,]        75.5       66.5
>> [11,]        67.0       45.5
>> [12,]        81.0       54.5
>> [13,]        49.0       44.0
>> [14,]        51.0       42.5
>> [15,]        53.0       34.5
>> 
>> using
>> wilcox.test(beforesmall ~ aftersmall,paired=T)
>> but I get the error message:
>> 
>> Error in wilcox.test.formula(beforesmall ~ aftersmall, paired = T) :
>>  grouping factor must have exactly 2 levels
>> 
>> I don't have any missing values, I have the same amount of data points for
>> each group and I've looked everywhere trying to find the answer.
>> Please can somebody tell me how to make it work
>> thanks
>> 
> 
> -- 
> Sarah Goslee
> http://www.functionaldiversity.org
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jdnewmil at dcn.davis.CA.us  Mon Jun 24 08:29:55 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 23 Jun 2013 23:29:55 -0700
Subject: [R] R  2.11 on Mac OS X
In-Reply-To: <51C7ADF6.8000500@tpg.com.au>
References: <51C50B9B.2080005@tpg.com.au>
	<5F01B7CB-3938-49E6-9D2F-21CC98291175@comcast.net>
	<51C7ADF6.8000500@tpg.com.au>
Message-ID: <04656fd1-b49c-4914-82af-e55f0e37cedd@email.android.com>

RStudio questions belong on the RStudio support website. It is fine software, but it is off-topic here.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Norman Jessup <njessup at tpg.com.au> wrote:

>David,
>
>Thank you.  You are correct - I was inadvertently accessing an old 
>version.  Deleting the old and re-installing means I can fire up R 
>V3.0.1 which runs fine.
>
>However, I still can't get R Studio to start up, receivng the following
>
>message:
>
>
>    ERROR r error 4 (R code execution error) [errormsg=Error in
>    identical(call[[1L]], quote(doTryCatch)) :
>
>    7 arguments passed to .Internal(identical) which requires 5
>
>    ,
>code=local(source("/Applications/RStudio.app/Contents/Resources/R/Tools.R",
>   local=TRUE, echo=FALSE, verbose=FALSE, encoding='UTF-8'))]; OCCURRED
>    AT: core::Error r::exec::<anonymous
>   namespace>::evaluateExpressions(SEXP, SEXP, SEXP *, sexp::Protect *)
>    /Users/rstudio/rstudio/src/cpp/r/RExec.cpp:145
>
>
>
>Even though I re-installed the latest version 0.97.551.  I wonder if 
>there is an old Library or other support file that was not properly 
>replaced?
>
>Thank you
>
>Norman Jessup
>> On Jun 21, 2013, at 7:27 PM, Norman Jessup wrote:
>>
>>> Hello,
>>>
>>> I've recently upgraded to R 2.11.1 on Mac OS X 10.8.4.   Now when I
>start R up I get the following message:
>>>
>>> Error in identical(call[[1L]], quote(doTryCatch)) :
>>>   7 arguments passed to .Internal(identical) which requires 5
>>> Error in normalizePath(dirname(pkgpath), "/", TRUE) :
>>>   3 arguments passed to .Internal(normalizePath) which requires 1
>>> cannot find system Renviron
>>>
>>> I get a similar message with user-defined functions ( i.e "X
>arguments passed when Y defined" ) though the functions appear to work.
>This problem is also encountered when Rstudio fires up and so it cannot
>run now.
>>>
>>> I did find a post that suggested it may be due to R accessing an
>old, possibly 32 bit library (I used to have 32 and 64 bit R installed
>and they both ran without trouble).  Possibly I need to completely
>clean out the installation and start again?  but I'm not sure precisely
>where the R support files are stored on Macs.  Can anyone give me a
>pointer and/or suggest an alternative fix?
>> R 2.11.1 is a rather archaic version. The current version is 3.0.1.
>You seems to have skipped major versions 2.12, 2.13,, 2.14 2.15. I
>doubt that OSX 10.8.4 was available when 2.11.1 was compiled. There is
>a mailing list for MacOS versions of R but I doubt there will be much
>interest in supporting version 2.11.1 on OSX 10.8.4. I suggest you
>install instead version 3.0.1
>>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From raziq_fazli at yahoo.com  Mon Jun 24 09:13:51 2013
From: raziq_fazli at yahoo.com (Fazli Raziq)
Date: Mon, 24 Jun 2013 00:13:51 -0700 (PDT)
Subject: [R] Looping in Matrix
Message-ID: <1372058031.97875.YahooMailNeo@web162905.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130624/83e6b3c5/attachment.pl>

From kulupp at online.de  Mon Jun 24 11:01:41 2013
From: kulupp at online.de (Kulupp)
Date: Mon, 24 Jun 2013 11:01:41 +0200
Subject: [R] Avoiding loops using 'for' and pairwise comparison of columns
Message-ID: <51C80AF5.90505@online.de>

Dear R-experts,

I'd like to avoid the use of very slow 'for'-loops but I don't know how. 
My data look as follows (the original data has 1600 rows and 30 columns):

# data example
c1 <- c(1,1,1,0.25,0,1,1,1,0,1)
c2 <- c(0,0,1,1,0,1,0,1,0.5,1)
c3 <- c(0,1,1,1,0,0.75,1,1,0.5,0)
x <- data.frame(c1,c2,c3)

I need to compare every column with each other and want to know the 
percentage of similar values for each column pair. To calculate the 
percentage of similar values I used the function 'agree' from the 
irr-package. I solved the problem with a loop that is very slow.

library(irr)     # required for the function 'agree'

# empty data frame for the results
a <- as.data.frame(matrix(data=NA, nrow=3, ncol=3))
colnames(a) <- colnames(x)
rownames(a) <- colnames(x)

# the loop to write the data
for (j in 1:ncol(x)){
   for (i in 1:ncol(x)){
     a[i,j] <- agree(cbind(x[,j], x[,i]))$value } }


I would be very pleased to receive your suggestions how to avoid the 
loop. Furthermore the resulting data frame could be displayed as a 
diagonal matrix without duplicates of each pairwise comparison, but I 
don't know how to solve this problem.

Kind regards

Thomas


From nblaser at ispm.unibe.ch  Mon Jun 24 12:18:00 2013
From: nblaser at ispm.unibe.ch (Blaser Nello)
Date: Mon, 24 Jun 2013 12:18:00 +0200
Subject: [R] Avoiding loops using 'for' and pairwise comparison of
	columns
In-Reply-To: <51C80AF5.90505@online.de>
References: <51C80AF5.90505@online.de>
Message-ID: <17EE8C62EA18B84B94C2BA96A143064C01721A7E@mx01.ispm.unibe.ch>

Here's a possible solution to avoid the loop

k <- as.matrix(expand.grid(1:ncol(x),1:ncol(x)))
a1 <- as.data.frame(matrix(sapply(1:nrow(k), function(n)
agree(x[,k[n,]])$value), nrow=ncol(x)))
colnames(a1) <- colnames(x)
rownames(a1) <- colnames(x)

> identical(a, a1)
[1] TRUE

Or if you want to avoid double calculation, 

a2 <- as.data.frame(matrix(0, nrow=ncol(x), ncol=ncol(x)))
colnames(a2) <- colnames(x)
rownames(a2) <- colnames(x)
k <- t(combn(1:ncol(x), 2))
a2[lower.tri(a2)] <- sapply(1:nrow(k), function(n)
agree(x[,k[n,]])$value)
a2 <- a2+diag(100,ncol(x))
a2[upper.tri(a2)] <- t(a2)[upper.tri(a2)]

> identical(a, a2)
[1] TRUE

Best, 
Nello

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
On Behalf Of Kulupp
Sent: Montag, 24. Juni 2013 11:02
To: r-help at r-project.org
Subject: [R] Avoiding loops using 'for' and pairwise comparison of
columns

Dear R-experts,

I'd like to avoid the use of very slow 'for'-loops but I don't know how.

My data look as follows (the original data has 1600 rows and 30
columns):

# data example
c1 <- c(1,1,1,0.25,0,1,1,1,0,1)
c2 <- c(0,0,1,1,0,1,0,1,0.5,1)
c3 <- c(0,1,1,1,0,0.75,1,1,0.5,0)
x <- data.frame(c1,c2,c3)

I need to compare every column with each other and want to know the
percentage of similar values for each column pair. To calculate the
percentage of similar values I used the function 'agree' from the
irr-package. I solved the problem with a loop that is very slow.

library(irr)     # required for the function 'agree'

# empty data frame for the results
a <- as.data.frame(matrix(data=NA, nrow=3, ncol=3))
colnames(a) <- colnames(x)
rownames(a) <- colnames(x)

# the loop to write the data
for (j in 1:ncol(x)){
   for (i in 1:ncol(x)){
     a[i,j] <- agree(cbind(x[,j], x[,i]))$value } }


I would be very pleased to receive your suggestions how to avoid the
loop. Furthermore the resulting data frame could be displayed as a
diagonal matrix without duplicates of each pairwise comparison, but I
don't know how to solve this problem.

Kind regards

Thomas

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Mon Jun 24 12:59:07 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 24 Jun 2013 11:59:07 +0100
Subject: [R] R:  Apply a Seasonal ARMA process
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4FFFC2@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4FFE9F@ESINO.regionemarche.intra>,
	<51C46541.9020204@sapo.pt>
	<8B435C9568170B469AE31E8891E8CC4FFFC2@ESINO.regionemarche.intra>
Message-ID: <51C8267B.5010306@sapo.pt>

Hello,

You have three parameters, two sar and one intercept.

arima(x, order=c(0,0,0), seasonal=list(order=c(2,0,0), period=4),
	transform.pars = FALSE, fixed = c(0.54, 0.5, rep(NA, 1)))


I also believe that the answer you got from Rolf is more to the point.
Try something along the lines he suggested.

Hope this helps,

Rui Barradas

Em 24-06-2013 10:34, Stefano Sofia escreveu:
> Thank you for your tips.
>
> I tried the code that you suggested, but there is a problem with the length of fixed.
> In the help page it is specified that the length of fixed must be total number of parameters.
> But in case of a Seasonal AR(2) model, which is the number of the parameters? I tried with length 4, 6, 8 but there always is the same error.
> And moreover, which is the order of its elements.
> Have you got some final hints about it?
>
> Thank you for your help
>
> Best regards,
>
> Stefano Sofia
>
> ________________________________________
> Da: Rui Barradas [ruipbarradas at sapo.pt]
> Inviato: venerd? 21 giugno 2013 16.37
> A: Stefano Sofia
> Oggetto: Re: [R] Apply a Seasonal ARMA process
>
> Hello,
>
> I think the correct way would be
>
> arima(my_ts, order=c(0,0,0), seasonal=list(order=c(2,0,0), period=4),
> transform.pars = FALSE, fixed = c(0.54, 0.5))
>
> Take a look at the help page for ?arima. You will see the description of
> argument 'fixed'. You will also see that 'n' is not an argument.
>
> Hope this helps,
>
> Rui Barradas
>
> Em 21-06-2013 14:48, Stefano Sofia escreveu:
>> Dear R users,
>> I have a seasonal time series of period 4 (my_ts).
>> I would like to apply to my_ts a Seasonal ARMA(2,0) process (only the seasonal part), with Seasonal AR coefficients respectively 0.54 and 0.5.
>> I tried to use the arima command from the stats package, but this code is not correct:
>>
>> arima(my_ts, order=c(0,0,0), seasonal=list(order=c(2,0,0), sar=c(0.54, 0.5), period=4), n=220)
>>
>> The error is:
>> "Error in optim(init[mask], armaCSS, method = optim.method, hessian = FALSE: initial value in 'vmmin' not finite".
>>
>> I am not even sure of the syntax about sar=c(0.54, 0.5).
>> I looked for this topic in the R archive, but I have not been able to find an example or a useful hint.
>> Could you please help me? Does arima handle seasonal ARMA processes? If yes, how? Is there a better specific package for that?
>>
>> Thank you for your help
>> Stefano Sofia
>>
>>
>> ________________________________
>>
>> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell'art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
>> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>>
>>        [[alternative HTML version deleted]]
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>


From angerusso1980 at gmail.com  Mon Jun 24 13:09:31 2013
From: angerusso1980 at gmail.com (Angel Russo)
Date: Mon, 24 Jun 2013 07:09:31 -0400
Subject: [R] help needed with printing multiple arguments as vectors,
	not matrices
Message-ID: <CALC4TGCXNarcO8dXm_kEDq=6VSspMtCZuTxjakXx2Vg9W3-fpA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130624/0a50a5c3/attachment.pl>

From suparna.mitra.sm at gmail.com  Mon Jun 24 13:33:38 2013
From: suparna.mitra.sm at gmail.com (Suparna Mitra)
Date: Mon, 24 Jun 2013 19:33:38 +0800
Subject: [R] Error with metaMDS
Message-ID: <CAFdg=fWSufe8WggoYo1RjO8uoNeZzhUEk41_MPT2RFJTVKsfOQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130624/f760826c/attachment.pl>

From sarah.goslee at gmail.com  Mon Jun 24 15:21:59 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 24 Jun 2013 09:21:59 -0400
Subject: [R] Wilcox paired test error message
In-Reply-To: <51CFDEFE-14C7-4CDA-A80B-50A3D609A25B@gmail.com>
References: <CAF1pVf+bCpUHGL=Be6aAfd4fCohn70HayV7JBGm+osZCc6yZow@mail.gmail.com>
	<CAM_vju=JBvp89236gGh147zd=MFtBCKeZCpbLEqgkAYKOTHN3Q@mail.gmail.com>
	<51CFDEFE-14C7-4CDA-A80B-50A3D609A25B@gmail.com>
Message-ID: <CAM_vjunSWTfhrGdw2QNTtKMD6nRVLXs3nsC9N7PkpxK219Sj4Q@mail.gmail.com>

G'morning.

On Mon, Jun 24, 2013 at 2:22 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>
> On Jun 23, 2013, at 22:30 , Sarah Goslee wrote:
>
>> Hi,
>>
>> If you're doing exactly as described below, then you need to add the
>> data argument to wilcox.test so R knows where to find beforesmall and
>> aftersmall. But if so, that's a rather uninformative error message.
>>
>> Saraj
>
> Not really, if you use the formula interface, the rhs is supposed to be the grouping, as in
>
> wilcox.test(extra ~ group, data=sleep, paired=TRUE)
>
> so it's telling you that "aftersmall" does not describe two groups.

Yep, sorry. That was actually my first thought, but then I misread the
helpfile.

You do still need the data argument, though. :)

Sarah

> (It is unfortunate, though, that we don't have a formula interface to the parallel-vector data layout for paired tests. That is the common case, the sleep data set is a rather rare exception. A formula specification for paired columns has been talked about; something like cbind(before, after) ~ 1 should be workable, but nothing has materialized to date.)
>
> -pd
>
>>
>> On Sun, Jun 23, 2013 at 2:34 PM, ruth parker <parkeractonruth at gmail.com> wrote:
>>> Hi,
>>> I've been trying to run a wilcox paired test on some data
>>> beforesmall aftersmall
>>> [1,]        63.5      512.0
>>> [2,]        54.5      237.5
>>> [3,]        52.5      161.5
>>> [4,]        78.0      153.5
>>> [5,]        53.5       68.0
>>> [6,]        50.5       65.5
>>> [7,]        69.0       52.0
>>> [8,]        76.0       59.0
>>> [9,]        68.0       66.5
>>> [10,]        75.5       66.5
>>> [11,]        67.0       45.5
>>> [12,]        81.0       54.5
>>> [13,]        49.0       44.0
>>> [14,]        51.0       42.5
>>> [15,]        53.0       34.5
>>>
>>> using
>>> wilcox.test(beforesmall ~ aftersmall,paired=T)
>>> but I get the error message:
>>>
>>> Error in wilcox.test.formula(beforesmall ~ aftersmall, paired = T) :
>>>  grouping factor must have exactly 2 levels
>>>
>>> I don't have any missing values, I have the same amount of data points for
>>> each group and I've looked everywhere trying to find the answer.
>>> Please can somebody tell me how to make it work
>>> thanks
>>>
>>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From sarah.goslee at gmail.com  Mon Jun 24 15:24:59 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 24 Jun 2013 09:24:59 -0400
Subject: [R] Error with metaMDS
In-Reply-To: <CAFdg=fWSufe8WggoYo1RjO8uoNeZzhUEk41_MPT2RFJTVKsfOQ@mail.gmail.com>
References: <CAFdg=fWSufe8WggoYo1RjO8uoNeZzhUEk41_MPT2RFJTVKsfOQ@mail.gmail.com>
Message-ID: <CAM_vju=FVki+ig12S5uibW8-SiKcvd9QF-Tt6w_BGpr9Ds7xzA@mail.gmail.com>

Hi,

What do you expect the dissimilarity between a site with no species
and a site with some species to be?

If you want to use Bray-Curtis dissimilarity, you need to drop the
sites with no species, as the error message suggests.

But if you can answer my first question, you may be able to select a
different dissimilarity metric that matches your expectations
numerically.

Sarah


On Mon, Jun 24, 2013 at 7:33 AM, Suparna Mitra
<suparna.mitra.sm at gmail.com> wrote:
>  H
> ello R-experts,
>   I want to do ordination plots using vegan metaMDS.
> I have a where many cells have zero values.
>
> Data structure:
> X[1:10,1:14]
>        Height.1 Height.2 Height.3 Height.4 Height.5 Height.6 Height.7
> Height.8 Height.9 Height.10 Height.11 Height.12 Height.13
> D30I1A       46        0        0        0        0        0        0
>  0        0         0        39         0        98
> D30I1B       46        0        0        0        0        0        0
>  0        0         0        39         0        98
> D30I1C       70        0        0        0        0        0        0
>  0        0         0         0        85         0
> D30I2A       47        0        0        0        0        0        0
>  0        0         0        49         0       105
> D30I2B       68        0        0        0        0        0        0
>  0        0         0        83         0       214
> D30I2C        0       75        0        0        0        0        0
>  0        0         0         0        83         0
> D30I3A       48        0        0        0        0        0        0
>  0        0         0        42         0       107
> D30I3B       64        0        0        0        0        0        0
>  0        0         0        72         0       177
> D30I3C       72        0        0        0        0        0        0
>  0        0         0         0        96         0
> D30M1A       60        0        0        0        0        0        0
>  0        0         0        74         0       169
>
> Another data structure
>> Genus_data[1:10,1:14]
>      Sample Acanthamoeba Acidianus Aegilops Alphapapillomavirus Asfivirus
> Brassica Buchnera Coprinellus Diaphorobacter Hartmannella Ignicoccus
> 1    HS1_S1            0         0        0                   0         0
>      0        0           0              0            0          0
> 2    HS2_S2            0         1        1                   0         0
>      0        0           0              0            1          0
> 3    HS3_S3            0         0        0                   1         0
>      0        1           1              1            0          0
> 4    HS4_S4            0         0        0                   0         1
>      0        0           0              0            0          0
> 5   HS13_S5            0         0        0                   0         0
>      0        0           0              0            0          0
> 6   HS14_S6            0         0        0                   0         0
>      1        0           0              0            0          0
> 7   HS15_S7            0         0        0                   0         0
>      0        0           0              0            0          0
> 8   HS16_S8            0         0        0                   0         0
>      0        0           0              0            0          1
> 9   HS25_S9            1         0        0                   0         0
>      0        0           0              0            0          0
>
> I am having two different kind of errors for these two data...
> Error 1
>> ord1 <- metaMDS(
>  X
> ="bray")
> Square root transformation
> Wisconsin double standardization
> Error in if (any(dist < -sqrt(.Machine$double.eps))) warning("some
> dissimilarities are negative -- is this intentional?") :
>   missing value where TRUE/FALSE needed
> In addition: Warning messages:
> 1: In distfun(comm, method = distance, ...) :
>   you have empty rows: their dissimilarities may be meaningless in method
> ?bray?
> 2: In distfun(comm, method = distance, ...) : missing values in results
>
> Error 2
> ord.data= metaMDS(data, distance="bray")
> Error in if (any(autotransform, noshare > 0, wascores) && any(comm < 0)) {
> :
>   missing value where TRUE/FALSE needed
> In addition: Warning message:
> In Ops.factor(left, right) : < not meaningful for factors
>
> I searched all the details of metaMDS where it is suggested to avail the
> argument 'zerodist'
> So I tried both
>
> X.dist1 <- metaMDSdist(X, method="bray",zerodist = "ignore")
> X.dist2 <- metaMDSdist(X, method="bray",zerodist = "add")
>
> Can Please help me with this.
> Thanks,
> Mitra
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From jvadams at usgs.gov  Mon Jun 24 16:15:56 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 24 Jun 2013 09:15:56 -0500
Subject: [R] Calculating an index of colocation for a large dataset
In-Reply-To: <1371853137063-4670084.post@n4.nabble.com>
References: <1371853137063-4670084.post@n4.nabble.com>
Message-ID: <CAN5YmCHCgmZDAUZTDkXAB45rm92wRh2Cf=_FyMLUi0E4a+jPVA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130624/f33bc9e1/attachment.pl>

From dizem.uerek at alumni.fh-aachen.de  Mon Jun 24 11:25:21 2013
From: dizem.uerek at alumni.fh-aachen.de (Dzu)
Date: Mon, 24 Jun 2013 02:25:21 -0700 (PDT)
Subject: [R] K-means results understanding!!!
Message-ID: <1372065921588-4670171.post@n4.nabble.com>

Dear  members.

I am having problems to understand the kmeans- results in R. I am applying
kmeans-algorithms to my big data file, and it is producing the results of
the clusters.

Q1) Does anybody knows how to find out in which cluster (I have fixed
numberofclusters = 5 ) which data have been used?
COMMAND
(kmeans.results <- kmeans(mydata,centers =5, iter.max= 1000, nstart =10000))

Q2) When I call kmeans.results I have the following output: 


K-means clustering with 5 clusters of sizes 17, 1, 6, 4, 32

Cluster means:
  [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]     [,11]        [,12]
1    0    0    0    0    0    0    0    0    0     0 0.0000000 0.0008235294
2    0    0    0    0    0    0    0    0    0     0 0.0000000 0.0000000000
3    0    0    0    0    0    0    0    0    0     0 0.0000000 0.0000000000
4    0    0    0    0    0    0    0    0    0     0 0.0000000 0.0040000000
5    0    0    0    0    0    0    0    0    0     0 0.0003125 0.0003750000
         [,13]       [,14]       [,15]       [,16]       [,17]      [,18]
1 0.0008235294 0.001176471 0.005176471 0.012471295 0.041181652 0.10663935
2 0.0000000000 0.000000000 0.000000000 0.000000000 0.169491525 0.61016949
3 0.0000000000 0.000000000 0.000000000 0.002333333 0.006666667 0.07695015
4 0.0030000000 0.001500000 0.001000000 0.017500000 0.029000000 0.06150000
5 0.0015625000 0.003437500 0.010687500 0.046375000 0.100062500 0.14306250
       [,19]     [,20]     [,21]     [,22]      [,23]      [,24]       [,25]
1 0.12946535 1.0017347 0.3360283 0.2455259 0.08565672 0.02553212 0.006000000
2 0.94915254 0.1694915 0.1016949 0.0000000 0.00000000 0.00000000 0.000000000
3 0.09376439 1.3857837 0.2659812 0.1015707 0.03804953 0.02023362 0.007666667
4 0.17100000 0.6665000 0.7860000 0.1860000 0.04650000 0.01450000 0.012000000
5 0.18100000 0.5200625 0.4156875 0.3461250 0.16925000 0.04918750 0.011500000
         [,26]       [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35]
1 0.0005882353 0.001176471     0     0     0     0     0     0     0     0
2 0.0000000000 0.000000000     0     0     0     0     0     0     0     0
3 0.0010000000 0.000000000     0     0     0     0     0     0     0     0
4 0.0000000000 0.000000000     0     0     0     0     0     0     0     0
5 0.0013125000 0.000000000     0     0     0     0     0     0     0     0
  [,36] [,37] [,38] [,39] [,40]
1     0     0     0     0     0
2     0     0     0     0     0
3     0     0     0     0     0
4     0     0     0     0     0
5     0     0     0     0     0

Clustering vector:
 [1] 1 5 5 3 1 5 5 5 5 1 4 1 5 5 5 5 4 5 2 3 5 5 1 5 5 5 5 1 3 1 4 5 5 1 5 5
5 1
[39] 3 1 5 5 3 1 1 1 1 5 5 1 4 1 3 5 5 5 5 5 5 1

Within cluster sum of squares by cluster:
[1] 0.6702803 0.0000000 0.2453294 0.1860180 1.3535263
 (between_SS / total_SS =  76.8 %)

Available components:

[1] "cluster"      "centers"      "totss"        "withinss"    
"tot.withinss"
[6] "betweenss"    "size"        
> 
Q3)I would like to understand which raw data are in which cluster ?  Does
somebody knows how to access the table of raw data which are in the same
cluster ?

Thanks for help
DZU



--
View this message in context: http://r.789695.n4.nabble.com/K-means-results-understanding-tp4670171.html
Sent from the R help mailing list archive at Nabble.com.


From johannes_graumann at web.de  Mon Jun 24 14:03:41 2013
From: johannes_graumann at web.de (Johannes Graumann)
Date: Mon, 24 Jun 2013 15:03:41 +0300
Subject: [R] Tolearance Interval calculation for each point in a data set?
Message-ID: <kq9cig$27a$1@ger.gmane.org>

Hello,

I am looking for tolerance interval related methodologies and found the 
package "tolerance" which will e.g. nicely calculate the 95%/95% tolerance 
limits of a given regression. What I am looking for, however is not only the 
the tolerance limits this calculation defines, but I would like to know for 
each data point in the set which tolerance band is passing through it.

Does anyone know of such methodology and if yes an R implementation?

Thank you for any pointers.

Sincerely, Joh


From jvadams at usgs.gov  Mon Jun 24 16:40:17 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 24 Jun 2013 09:40:17 -0500
Subject: [R] (no subject)
In-Reply-To: <CABOx99ZBhfhs5FNYL+9QjNvxC9jhYY_CHTkE2zvgMc39zSn6DA@mail.gmail.com>
References: <CABOx99ZBhfhs5FNYL+9QjNvxC9jhYY_CHTkE2zvgMc39zSn6DA@mail.gmail.com>
Message-ID: <CAN5YmCEtW3CGE2Air9Qu2iWwKwbi0T6AXGWf1tDhqrtVVykenA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130624/e6ceb0e9/attachment.pl>

From dcarlson at tamu.edu  Mon Jun 24 17:00:40 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 24 Jun 2013 10:00:40 -0500
Subject: [R] K-means results understanding!!!
In-Reply-To: <1372065921588-4670171.post@n4.nabble.com>
References: <1372065921588-4670171.post@n4.nabble.com>
Message-ID: <037e01ce70eb$97ac4cc0$c704e640$@tamu.edu>

You should read the help page

?kmeans

Especially the section labeled "Value" which tells you what kmeans
returns. You will see that the cluster membership is returned as a
vector of integers called "cluster." If you don't know how to access
that from kmeans.results, you haven't read any of the basic
tutorials on R.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Dzu
Sent: Monday, June 24, 2013 4:25 AM
To: r-help at r-project.org
Subject: [R] K-means results understanding!!!

Dear  members.

I am having problems to understand the kmeans- results in R. I am
applying
kmeans-algorithms to my big data file, and it is producing the
results of
the clusters.

Q1) Does anybody knows how to find out in which cluster (I have
fixed
numberofclusters = 5 ) which data have been used?
COMMAND
(kmeans.results <- kmeans(mydata,centers =5, iter.max= 1000, nstart
=10000))

Q2) When I call kmeans.results I have the following output: 


K-means clustering with 5 clusters of sizes 17, 1, 6, 4, 32

Cluster means:
  [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]     [,11]
[,12]
1    0    0    0    0    0    0    0    0    0     0 0.0000000
0.0008235294
2    0    0    0    0    0    0    0    0    0     0 0.0000000
0.0000000000
3    0    0    0    0    0    0    0    0    0     0 0.0000000
0.0000000000
4    0    0    0    0    0    0    0    0    0     0 0.0000000
0.0040000000
5    0    0    0    0    0    0    0    0    0     0 0.0003125
0.0003750000
         [,13]       [,14]       [,15]       [,16]       [,17]
[,18]
1 0.0008235294 0.001176471 0.005176471 0.012471295 0.041181652
0.10663935
2 0.0000000000 0.000000000 0.000000000 0.000000000 0.169491525
0.61016949
3 0.0000000000 0.000000000 0.000000000 0.002333333 0.006666667
0.07695015
4 0.0030000000 0.001500000 0.001000000 0.017500000 0.029000000
0.06150000
5 0.0015625000 0.003437500 0.010687500 0.046375000 0.100062500
0.14306250
       [,19]     [,20]     [,21]     [,22]      [,23]      [,24]
[,25]
1 0.12946535 1.0017347 0.3360283 0.2455259 0.08565672 0.02553212
0.006000000
2 0.94915254 0.1694915 0.1016949 0.0000000 0.00000000 0.00000000
0.000000000
3 0.09376439 1.3857837 0.2659812 0.1015707 0.03804953 0.02023362
0.007666667
4 0.17100000 0.6665000 0.7860000 0.1860000 0.04650000 0.01450000
0.012000000
5 0.18100000 0.5200625 0.4156875 0.3461250 0.16925000 0.04918750
0.011500000
         [,26]       [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34]
[,35]
1 0.0005882353 0.001176471     0     0     0     0     0     0     0
0
2 0.0000000000 0.000000000     0     0     0     0     0     0     0
0
3 0.0010000000 0.000000000     0     0     0     0     0     0     0
0
4 0.0000000000 0.000000000     0     0     0     0     0     0     0
0
5 0.0013125000 0.000000000     0     0     0     0     0     0     0
0
  [,36] [,37] [,38] [,39] [,40]
1     0     0     0     0     0
2     0     0     0     0     0
3     0     0     0     0     0
4     0     0     0     0     0
5     0     0     0     0     0

Clustering vector:
 [1] 1 5 5 3 1 5 5 5 5 1 4 1 5 5 5 5 4 5 2 3 5 5 1 5 5 5 5 1 3 1 4 5
5 1 5 5
5 1
[39] 3 1 5 5 3 1 1 1 1 5 5 1 4 1 3 5 5 5 5 5 5 1

Within cluster sum of squares by cluster:
[1] 0.6702803 0.0000000 0.2453294 0.1860180 1.3535263
 (between_SS / total_SS =  76.8 %)

Available components:

[1] "cluster"      "centers"      "totss"        "withinss"    
"tot.withinss"
[6] "betweenss"    "size"        
> 
Q3)I would like to understand which raw data are in which cluster ?
Does
somebody knows how to access the table of raw data which are in the
same
cluster ?

Thanks for help
DZU



--
View this message in context:
http://r.789695.n4.nabble.com/K-means-results-understanding-tp467017
1.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jvadams at usgs.gov  Mon Jun 24 17:03:03 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 24 Jun 2013 10:03:03 -0500
Subject: [R] help needed with printing multiple arguments as vectors,
	not matrices
In-Reply-To: <CALC4TGCXNarcO8dXm_kEDq=6VSspMtCZuTxjakXx2Vg9W3-fpA@mail.gmail.com>
References: <CALC4TGCXNarcO8dXm_kEDq=6VSspMtCZuTxjakXx2Vg9W3-fpA@mail.gmail.com>
Message-ID: <CAN5YmCExo-KDVxFuBXus25NYGtgEXCNN-E2AWbzaG7SZQ_smfQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130624/5696d790/attachment.pl>

From dizem.uerek at alumni.fh-aachen.de  Mon Jun 24 17:20:36 2013
From: dizem.uerek at alumni.fh-aachen.de (Dzu)
Date: Mon, 24 Jun 2013 08:20:36 -0700 (PDT)
Subject: [R] K-means results understanding!!!
In-Reply-To: <037e01ce70eb$97ac4cc0$c704e640$@tamu.edu>
References: <1372065921588-4670171.post@n4.nabble.com>
	<037e01ce70eb$97ac4cc0$c704e640$@tamu.edu>
Message-ID: <1372087236786-4670187.post@n4.nabble.com>

Hi,
Thanks for reply but I already read the help page I am new in R and did not
understand the output description of kmeans -function. That is why I wanted
to ask some experts in the group.

My point is that I do not understand which data are combined in the specific
cluster?

I tried the following :

(kmeans.results <- kmeans(mydata,centers =4, iter.max= 1000, nstart =10000))
# The output data type is logical , cl1 is the cluster 1

cl1 <- data.frame(as.numeric(kmeans.results$cluster == 1)) 
nbcl1 <- sum (cl1, na.rm = 1)
#output of the number of cl1 logical 1 values is for example 22
#this means there are 22 vectors which are similar 

but when I call  :
mydata[kmeans.results$cluster==1,]
I only get 1 vector not 22 vectors that are in the cluster 1.

I thought in the cluster 1 there are many vectors that are similar based on
kmeans -function. But the output is only one vector!



--
View this message in context: http://r.789695.n4.nabble.com/K-means-results-understanding-tp4670171p4670187.html
Sent from the R help mailing list archive at Nabble.com.


From pdalgd at gmail.com  Mon Jun 24 17:28:06 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 24 Jun 2013 17:28:06 +0200
Subject: [R] Wilcox paired test error message
In-Reply-To: <CAM_vjunSWTfhrGdw2QNTtKMD6nRVLXs3nsC9N7PkpxK219Sj4Q@mail.gmail.com>
References: <CAF1pVf+bCpUHGL=Be6aAfd4fCohn70HayV7JBGm+osZCc6yZow@mail.gmail.com>
	<CAM_vju=JBvp89236gGh147zd=MFtBCKeZCpbLEqgkAYKOTHN3Q@mail.gmail.com>
	<51CFDEFE-14C7-4CDA-A80B-50A3D609A25B@gmail.com>
	<CAM_vjunSWTfhrGdw2QNTtKMD6nRVLXs3nsC9N7PkpxK219Sj4Q@mail.gmail.com>
Message-ID: <6C19DAB6-AA8B-4EC8-93CE-90E90B1B830D@gmail.com>


On Jun 24, 2013, at 15:21 , Sarah Goslee wrote:

> G'morning.
> 
> On Mon, Jun 24, 2013 at 2:22 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>> 
>> On Jun 23, 2013, at 22:30 , Sarah Goslee wrote:
>> 
>>> Hi,
>>> 
>>> If you're doing exactly as described below, then you need to add the
>>> data argument to wilcox.test so R knows where to find beforesmall and
>>> aftersmall. But if so, that's a rather uninformative error message.
>>> 
>>> Saraj
>> 
>> Not really, if you use the formula interface, the rhs is supposed to be the grouping, as in
>> 
>> wilcox.test(extra ~ group, data=sleep, paired=TRUE)
>> 
>> so it's telling you that "aftersmall" does not describe two groups.
> 
> Yep, sorry. That was actually my first thought, but then I misread the
> helpfile.
> 
> You do still need the data argument, though. :)

-- or a preceding attach(), which at least some of us still use occasionally despite its dangers. For paired tests, it doesn't actually work to use data=, you need

with(mydata, t.test(beforesmall, aftersmall, paired=TRUE))

-pd

> 
> Sarah
> 
>> (It is unfortunate, though, that we don't have a formula interface to the parallel-vector data layout for paired tests. That is the common case, the sleep data set is a rather rare exception. A formula specification for paired columns has been talked about; something like cbind(before, after) ~ 1 should be workable, but nothing has materialized to date.)
>> 
>> -pd
>> 
>>> 
>>> On Sun, Jun 23, 2013 at 2:34 PM, ruth parker <parkeractonruth at gmail.com> wrote:
>>>> Hi,
>>>> I've been trying to run a wilcox paired test on some data
>>>> beforesmall aftersmall
>>>> [1,]        63.5      512.0
>>>> [2,]        54.5      237.5
>>>> [3,]        52.5      161.5
>>>> [4,]        78.0      153.5
>>>> [5,]        53.5       68.0
>>>> [6,]        50.5       65.5
>>>> [7,]        69.0       52.0
>>>> [8,]        76.0       59.0
>>>> [9,]        68.0       66.5
>>>> [10,]        75.5       66.5
>>>> [11,]        67.0       45.5
>>>> [12,]        81.0       54.5
>>>> [13,]        49.0       44.0
>>>> [14,]        51.0       42.5
>>>> [15,]        53.0       34.5
>>>> 
>>>> using
>>>> wilcox.test(beforesmall ~ aftersmall,paired=T)
>>>> but I get the error message:
>>>> 
>>>> Error in wilcox.test.formula(beforesmall ~ aftersmall, paired = T) :
>>>> grouping factor must have exactly 2 levels
>>>> 
>>>> I don't have any missing values, I have the same amount of data points for
>>>> each group and I've looked everywhere trying to find the answer.
>>>> Please can somebody tell me how to make it work
>>>> thanks
>>>> 
>>> 
> 
> 
> -- 
> Sarah Goslee
> http://www.functionaldiversity.org
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From angerusso1980 at gmail.com  Mon Jun 24 17:35:49 2013
From: angerusso1980 at gmail.com (Angel Russo)
Date: Mon, 24 Jun 2013 11:35:49 -0400
Subject: [R] help needed with printing multiple arguments as vectors,
	not matrices
In-Reply-To: <CAN5YmCExo-KDVxFuBXus25NYGtgEXCNN-E2AWbzaG7SZQ_smfQ@mail.gmail.com>
References: <CALC4TGCXNarcO8dXm_kEDq=6VSspMtCZuTxjakXx2Vg9W3-fpA@mail.gmail.com>
	<CAN5YmCExo-KDVxFuBXus25NYGtgEXCNN-E2AWbzaG7SZQ_smfQ@mail.gmail.com>
Message-ID: <CALC4TGC9_Nn429qNRCJZMfrjwvCNPRs7bHnQK_NKs8BNraQ22A@mail.gmail.com>

Sample data is as follows (for simplicity assume mat1 and mat2 are the same
matrices). Also attached as an excel file.

I want to get the pairwise interaction fischer test results. Not just the
pvalues but also want to wrote the n00, n01, n10 and n11 in the file as:


ADCK2_mat1 ADCK3_mat2 n00 n01 n10 n11 pvalue



ADCK2_mat1 ADCK4_mat2 n00 n01 n10 n11 pvalue

 GENE SYMBOL Sample-A1-A0SK-01 Sample-A1-A0SO-01 Sample-A1-A0SP-01
Sample-A2-A04P-01 Sample-A2-A04Q-01 Sample-A2-A04U-01 Sample-A2-A0CL-01
Sample-A2-A0CM-01 Sample-A2-A0D0-01 Sample-A2-A0D2-01 Sample-A2-A0ST-01
Sample-A2-A0SX-01 Sample-A2-A0T0-01  ADCK2 0 0 0 0 0 0 0 0 0 1 0 0 0  ADCK3
0 0 0 0 0 1 0 0 1 0 0 1 0  ADCK4 0 0 0 0 0 0 0 0 0 0 0 1 0  ADCK5 1 0 0 0 0
0 0 0 0 0 0 0 1  ADRBK1 0 0 0 0 0 0 0 0 0 0 0 0 0  ADRBK2 0 0 0 0 0 1 0 0 0
0 0 0 0  AKT1 0 0 0 0 0 0 0 0 0 0 0 0 0  AKT2 0 0 0 0 0 0 0 0 0 0 0 1 0
AKT3 0 0 0 0 0 0 0 0 1 0 0 1 0  ALK 0 0 0 0 0 0 0 0 0 0 0 0 0


On Mon, Jun 24, 2013 at 11:03 AM, Adams, Jean <jvadams at usgs.gov> wrote:

> Could you provide an example of mat1 and mat2 as well as an example of the
> output you would like from them.
>
> Your code is very difficult to follow as written.  It will be easier for
> readers of the list to interpret if you use carriage returns rather than
> semi colons, for example ...
>
> fish <- function(x, y) {
> n00 = sum((1-x)*(1-y))
> n01 = sum((1-x)*y)
> n10 = sum(x*(1-y))
>  n11 = sum(x*y)
> a = matrix(c(n00, n01, n10, n11), nrow=2)
> pval = fisher.test(a)$p.value
>  return(pval)
> }
>
> Jean
>
>
> On Mon, Jun 24, 2013 at 6:09 AM, Angel Russo <angerusso1980 at gmail.com>wrote:
>
>> **
>>
>> I am using the following way to get p-values from fiser exact test.
>> However, I do need to print for each pair the values "n00, n01, n10, n11".
>> How can I print that as a table and not a matrix as below along with the
>> p-value? Any help will be greatly appreciated
>>
>>  fish <- function(y, x) {n00 = sum((1-x)*(1-y)); n01 = sum((1-x)*y);
>> n10 = sum(x*(1-y)); n11 = sum(x*y); a = matrix(c(n00, n01, n10, n11),
>> nrow = 2); pval = fisher.test(a)$p.value; return(pval);}
>>
>>  chiArray <- function(x) {  apply(mat1, 1, fish, x); }
>>  sapply(1:nrow(mat2), function(j){chiArray(mat2[j, ]);});
>>  chisq.cna.mut.test <- sapply(1:nrow(mat2), function(j){chiArray(mat2[j,
>> ]);});
>>
>> I want output to be:
>>
>> name1_mat1 name1_mat2 n00 n01 n10 n11 pvalue
>>
>>
>>
>> name1_mat1 name2_mat2 n00 n01 n10 n11 pvalue
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
-------------- next part --------------
GENE SYMBOL	Sample-A1-A0SK-01	Sample-A1-A0SO-01	Sample-A1-A0SP-01	Sample-A2-A04P-01	Sample-A2-A04Q-01	Sample-A2-A04U-01	Sample-A2-A0CL-01	Sample-A2-A0CM-01	Sample-A2-A0D0-01	Sample-A2-A0D2-01	Sample-A2-A0ST-01	Sample-A2-A0SX-01	Sample-A2-A0T0-01
ADCK2	0	0	0	0	0	0	0	0	0	1	0	0	0
ADCK3	0	0	0	0	0	1	0	0	1	0	0	1	0
ADCK4	0	0	0	0	0	0	0	0	0	0	0	1	0
ADCK5	1	0	0	0	0	0	0	0	0	0	0	0	1
ADRBK1	0	0	0	0	0	0	0	0	0	0	0	0	0
ADRBK2	0	0	0	0	0	1	0	0	0	0	0	0	0
AKT1	0	0	0	0	0	0	0	0	0	0	0	0	0
AKT2	0	0	0	0	0	0	0	0	0	0	0	1	0
AKT3	0	0	0	0	0	0	0	0	1	0	0	1	0
ALK	0	0	0	0	0	0	0	0	0	0	0	0	0

From matteo.ghetta at gmail.com  Mon Jun 24 16:36:17 2013
From: matteo.ghetta at gmail.com (matteo)
Date: Mon, 24 Jun 2013 16:36:17 +0200
Subject: [R] extracting submatrix from a bigger one
Message-ID: <51C85961.6090908@gmail.com>

Hi guys,
I'm a newby, so sorry for the easy question.

I have a matrix (459x28) in which a large number of observations are 
repeated (same placed sampled in different times).
One of the columns is refers to the ID of the place of sampling.
What I would like is to extract subset matrix for every point of sampling.

I can do it manually, e.g. x1<-data.frame(dataset[dataset$ID=="x1",])
but is it possible to write a script and let do it to R?
So i got n submatrix of the n ID found in the original columns.

Cheers

Matteo


From dwinsemius at comcast.net  Mon Jun 24 17:51:16 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 24 Jun 2013 08:51:16 -0700
Subject: [R] Looping in Matrix
In-Reply-To: <1372058031.97875.YahooMailNeo@web162905.mail.bf1.yahoo.com>
References: <1372058031.97875.YahooMailNeo@web162905.mail.bf1.yahoo.com>
Message-ID: <4DBFEA04-D19B-4F55-9505-D623923B0F17@comcast.net>


On Jun 24, 2013, at 12:13 AM, Fazli Raziq wrote:

> Hello all,
> 
> I want to construct "Two way Matrix". The Algorithm is like:
> 
> 1)  Data of time with censoring or events
> 2)  Predictor variables (genes)
> 3)  Resample original data in step 1 and 2 by WR
> 4)  Apply Coxph Model to resample data. (Apply Surv function to each Predictor variable, individually)
> 5) 
> Give value 1 if it's P-value is less than 0.05, otherwise 0. Save it in
> the first Column (Column of 0's and 1's) of the Matrix.
> 6)  Iterate the process 1 to 5, 10 times. And make 10 Columns of 0's and 1's.
> 
> 
> I have done the programming for it, but gives problem in Matrix. I cannot post the program, that I made.
> Because it may contain more errors and a little confusing.

This is not an R homework help line.

> 
> Best Regards
> Fazli Raziq
> 	[[alternative HTML version deleted]]
> \\\\\\\\\\\\\\\\\\\\\\\\
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
//////////////////////////////
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From suparna.mitra.sm at gmail.com  Mon Jun 24 18:04:24 2013
From: suparna.mitra.sm at gmail.com (Suparna Mitra)
Date: Tue, 25 Jun 2013 00:04:24 +0800
Subject: [R] Error with metaMDS
In-Reply-To: <CAM_vju=FVki+ig12S5uibW8-SiKcvd9QF-Tt6w_BGpr9Ds7xzA@mail.gmail.com>
References: <CAFdg=fWSufe8WggoYo1RjO8uoNeZzhUEk41_MPT2RFJTVKsfOQ@mail.gmail.com>
	<CAM_vju=FVki+ig12S5uibW8-SiKcvd9QF-Tt6w_BGpr9Ds7xzA@mail.gmail.com>
Message-ID: <CAFdg=fXs22cYzs7h=Bzqo7bgNFXJ1fZ=rUAx=UwPA6rvum4qhg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/6aaff44c/attachment.pl>

From sadali at gmail.com  Mon Jun 24 18:21:55 2013
From: sadali at gmail.com (Sancar Adali)
Date: Mon, 24 Jun 2013 12:21:55 -0400
Subject: [R] renaming of miktex package broke R package building
Message-ID: <CAJHaQhcwYsqUrdOXvvqqzKWfVwTHWqeARe9ezUd+WJgsYhQCpg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130624/5e13c879/attachment.pl>

From ruipbarradas at sapo.pt  Mon Jun 24 18:24:45 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 24 Jun 2013 17:24:45 +0100
Subject: [R] extracting submatrix from a bigger one
In-Reply-To: <51C85961.6090908@gmail.com>
References: <51C85961.6090908@gmail.com>
Message-ID: <51C872CD.7020700@sapo.pt>

Hello,

Try the following.


result <- lapply(unique(dataset$ID), function(uid) dataset[dataset$ID == 
uid, ])
names(result) <- unique(dataset$ID)


Hope this helps,

Rui Barradas

Em 24-06-2013 15:36, matteo escreveu:
> Hi guys,
> I'm a newby, so sorry for the easy question.
>
> I have a matrix (459x28) in which a large number of observations are
> repeated (same placed sampled in different times).
> One of the columns is refers to the ID of the place of sampling.
> What I would like is to extract subset matrix for every point of sampling.
>
> I can do it manually, e.g. x1<-data.frame(dataset[dataset$ID=="x1",])
> but is it possible to write a script and let do it to R?
> So i got n submatrix of the n ID found in the original columns.
>
> Cheers
>
> Matteo
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jvadams at usgs.gov  Mon Jun 24 18:45:22 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 24 Jun 2013 11:45:22 -0500
Subject: [R] Conference on Statistical Practice
Message-ID: <CAN5YmCFT8yUrKqBFJF7UVdhfWF5eHCX2EbMeg3YJrc+iDPRgBw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130624/2437c5f4/attachment.pl>

From bhh at xs4all.nl  Mon Jun 24 18:48:14 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 24 Jun 2013 18:48:14 +0200
Subject: [R] renaming of miktex package broke R package building
In-Reply-To: <CAJHaQhcwYsqUrdOXvvqqzKWfVwTHWqeARe9ezUd+WJgsYhQCpg@mail.gmail.com>
References: <CAJHaQhcwYsqUrdOXvvqqzKWfVwTHWqeARe9ezUd+WJgsYhQCpg@mail.gmail.com>
Message-ID: <EBDFA417-3E69-45F8-901A-2F2EC5593D33@xs4all.nl>


On 24-06-2013, at 18:21, Sancar Adali <sadali at gmail.com> wrote:

> the inconsolata miktex package (inconsolata-zi4 in CTAN) which contains the
> font of the same name was recently updated. It now contains  the file
> zi4.sty instead of inconsolata.sty. When I was building an R package, the
> help(or vignette) file pdf couldn't built , because R couldn't find
> inconsolata.sty.  Any suggestions for a workaround? Could someone file a
> bug report, if appropriate? ( I don't know which R package is involved in
> generating and building  latex files, otherwise I would file it myself)
> 

See this post in the R-devel list.

https://stat.ethz.ch/pipermail/r-devel/2013-June/066850.html


Berend

> --
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From matteo.ghetta at gmail.com  Mon Jun 24 19:03:47 2013
From: matteo.ghetta at gmail.com (matteo)
Date: Mon, 24 Jun 2013 19:03:47 +0200
Subject: [R] extracting submatrix from a bigger one
In-Reply-To: <51C872CD.7020700@sapo.pt>
References: <51C85961.6090908@gmail.com> <51C872CD.7020700@sapo.pt>
Message-ID: <51C87BF3.5090806@gmail.com>

Hi,

> result <- lapply(unique(dataset$ID), function(uid) dataset[dataset$ID 
> == uid, ])
Ok, I have the element result as a list

> names(result) <- unique(dataset$ID)
Nothing happens. I don't have any submatrix...

Matteo


From gunter.berton at gene.com  Mon Jun 24 19:13:39 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 24 Jun 2013 10:13:39 -0700
Subject: [R] extracting submatrix from a bigger one
In-Reply-To: <51C872CD.7020700@sapo.pt>
References: <51C85961.6090908@gmail.com>
	<51C872CD.7020700@sapo.pt>
Message-ID: <CACk-te2H2OW+DKhnrtcd3mH=tN78gY4mqxLUR8pKAfgCoNjJLg@mail.gmail.com>

First of all, is your data structure a matrix or a data frame? They
are different!

Assuming the latter, a shorter version of Rui's answer that avoids
unique() and automatically takes care of names is:

result <- by(dataset, dataset$ID,I)

See ?by, ?tapply, and ?split

-- Bert

On Mon, Jun 24, 2013 at 9:24 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> Try the following.
>
>
> result <- lapply(unique(dataset$ID), function(uid) dataset[dataset$ID ==
> uid, ])
> names(result) <- unique(dataset$ID)
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 24-06-2013 15:36, matteo escreveu:
>>
>> Hi guys,
>> I'm a newby, so sorry for the easy question.
>>
>> I have a matrix (459x28) in which a large number of observations are
>> repeated (same placed sampled in different times).
>> One of the columns is refers to the ID of the place of sampling.
>> What I would like is to extract subset matrix for every point of sampling.
>>
>> I can do it manually, e.g. x1<-data.frame(dataset[dataset$ID=="x1",])
>> but is it possible to write a script and let do it to R?
>> So i got n submatrix of the n ID found in the original columns.
>>
>> Cheers
>>
>> Matteo
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From ruipbarradas at sapo.pt  Mon Jun 24 19:16:05 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 24 Jun 2013 18:16:05 +0100
Subject: [R] extracting submatrix from a bigger one
In-Reply-To: <51C87BF3.5090806@gmail.com>
References: <51C85961.6090908@gmail.com> <51C872CD.7020700@sapo.pt>
	<51C87BF3.5090806@gmail.com>
Message-ID: <51C87ED5.5040801@sapo.pt>

Hello,

You don't have a sub-data.frame, what you have is a list, with each 
element of that list a df. Try to see, for instance, result[[1]]. This 
should be a data.frame corresponding to the first ID.

Rui Barradas

Em 24-06-2013 18:03, matteo escreveu:
> Hi,
>
>> result <- lapply(unique(dataset$ID), function(uid) dataset[dataset$ID
>> == uid, ])
> Ok, I have the element result as a list
>
>> names(result) <- unique(dataset$ID)
> Nothing happens. I don't have any submatrix...
>
> Matteo
>
>


From dwinsemius at comcast.net  Mon Jun 24 19:28:22 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 24 Jun 2013 10:28:22 -0700
Subject: [R] extracting submatrix from a bigger one
In-Reply-To: <51C87BF3.5090806@gmail.com>
References: <51C85961.6090908@gmail.com> <51C872CD.7020700@sapo.pt>
	<51C87BF3.5090806@gmail.com>
Message-ID: <19DF65D9-0726-427C-B843-B67E8650D243@comcast.net>


On Jun 24, 2013, at 10:03 AM, matteo wrote:

> Hi,
> 
>> result <- lapply(unique(dataset$ID), function(uid) dataset[dataset$ID == uid, ])
> Ok, I have the element result as a list
> 
>> names(result) <- unique(dataset$ID)
> Nothing happens. I don't have any submatrix...

> 
> Matteo
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Mon Jun 24 19:30:43 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 24 Jun 2013 10:30:43 -0700
Subject: [R] extracting submatrix from a bigger one
In-Reply-To: <51C87BF3.5090806@gmail.com>
References: <51C85961.6090908@gmail.com> <51C872CD.7020700@sapo.pt>
	<51C87BF3.5090806@gmail.com>
Message-ID: <AB54BB97-AA56-49EF-AEF9-C9607045E8A3@comcast.net>

Sorry for the blank message. The default behavior of the Mac Mail.app spell checker has me confused.

On Jun 24, 2013, at 10:03 AM, matteo wrote:

> Hi,
> 
>> result <- lapply(unique(dataset$ID), function(uid) dataset[dataset$ID == uid, ])
> Ok, I have the element result as a list
> 
>> names(result) <- unique(dataset$ID)
> Nothing happens. I don't have any submatrix...

What were you expecting to happen? You just assigned names to the result. You should be able to execute:

names(result)

Or:

str(result)

> 
-- 

David Winsemius
Alameda, CA, USA


From ruipbarradas at sapo.pt  Mon Jun 24 19:33:18 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 24 Jun 2013 18:33:18 +0100
Subject: [R] extracting submatrix from a bigger one
In-Reply-To: <CACk-te2H2OW+DKhnrtcd3mH=tN78gY4mqxLUR8pKAfgCoNjJLg@mail.gmail.com>
References: <51C85961.6090908@gmail.com> <51C872CD.7020700@sapo.pt>
	<CACk-te2H2OW+DKhnrtcd3mH=tN78gY4mqxLUR8pKAfgCoNjJLg@mail.gmail.com>
Message-ID: <51C882DE.9050409@sapo.pt>

Hello,

I had forgotten the much simpler solutions. The following should do it.

split(dataset, dataset$ID)


Rui Barradas

Em 24-06-2013 18:13, Bert Gunter escreveu:
> First of all, is your data structure a matrix or a data frame? They
> are different!
>
> Assuming the latter, a shorter version of Rui's answer that avoids
> unique() and automatically takes care of names is:
>
> result <- by(dataset, dataset$ID,I)
>
> See ?by, ?tapply, and ?split
>
> -- Bert
>
> On Mon, Jun 24, 2013 at 9:24 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>> Hello,
>>
>> Try the following.
>>
>>
>> result <- lapply(unique(dataset$ID), function(uid) dataset[dataset$ID ==
>> uid, ])
>> names(result) <- unique(dataset$ID)
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Em 24-06-2013 15:36, matteo escreveu:
>>>
>>> Hi guys,
>>> I'm a newby, so sorry for the easy question.
>>>
>>> I have a matrix (459x28) in which a large number of observations are
>>> repeated (same placed sampled in different times).
>>> One of the columns is refers to the ID of the place of sampling.
>>> What I would like is to extract subset matrix for every point of sampling.
>>>
>>> I can do it manually, e.g. x1<-data.frame(dataset[dataset$ID=="x1",])
>>> but is it possible to write a script and let do it to R?
>>> So i got n submatrix of the n ID found in the original columns.
>>>
>>> Cheers
>>>
>>> Matteo
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>


From gunter.berton at gene.com  Mon Jun 24 19:35:44 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 24 Jun 2013 10:35:44 -0700
Subject: [R] extracting submatrix from a bigger one
In-Reply-To: <51C882DE.9050409@sapo.pt>
References: <51C85961.6090908@gmail.com> <51C872CD.7020700@sapo.pt>
	<CACk-te2H2OW+DKhnrtcd3mH=tN78gY4mqxLUR8pKAfgCoNjJLg@mail.gmail.com>
	<51C882DE.9050409@sapo.pt>
Message-ID: <CACk-te1jMBcYGr4nJ_vn0GrpjHDBMaMmQYc8DYPD44wKvchs=w@mail.gmail.com>

Oh yes, that's even better!

-- Bert

On Mon, Jun 24, 2013 at 10:33 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> I had forgotten the much simpler solutions. The following should do it.
>
> split(dataset, dataset$ID)
>
>
> Rui Barradas
>
> Em 24-06-2013 18:13, Bert Gunter escreveu:
>>
>> First of all, is your data structure a matrix or a data frame? They
>> are different!
>>
>> Assuming the latter, a shorter version of Rui's answer that avoids
>> unique() and automatically takes care of names is:
>>
>> result <- by(dataset, dataset$ID,I)
>>
>> See ?by, ?tapply, and ?split
>>
>> -- Bert
>>
>> On Mon, Jun 24, 2013 at 9:24 AM, Rui Barradas <ruipbarradas at sapo.pt>
>> wrote:
>>>
>>> Hello,
>>>
>>> Try the following.
>>>
>>>
>>> result <- lapply(unique(dataset$ID), function(uid) dataset[dataset$ID ==
>>> uid, ])
>>> names(result) <- unique(dataset$ID)
>>>
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>> Em 24-06-2013 15:36, matteo escreveu:
>>>>
>>>>
>>>> Hi guys,
>>>> I'm a newby, so sorry for the easy question.
>>>>
>>>> I have a matrix (459x28) in which a large number of observations are
>>>> repeated (same placed sampled in different times).
>>>> One of the columns is refers to the ID of the place of sampling.
>>>> What I would like is to extract subset matrix for every point of
>>>> sampling.
>>>>
>>>> I can do it manually, e.g. x1<-data.frame(dataset[dataset$ID=="x1",])
>>>> but is it possible to write a script and let do it to R?
>>>> So i got n submatrix of the n ID found in the original columns.
>>>>
>>>> Cheers
>>>>
>>>> Matteo
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>>
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From matteo.ghetta at gmail.com  Mon Jun 24 20:31:55 2013
From: matteo.ghetta at gmail.com (matteo)
Date: Mon, 24 Jun 2013 20:31:55 +0200
Subject: [R] extracting submatrix from a bigger one
In-Reply-To: <CACk-te1jMBcYGr4nJ_vn0GrpjHDBMaMmQYc8DYPD44wKvchs=w@mail.gmail.com>
References: <51C85961.6090908@gmail.com> <51C872CD.7020700@sapo.pt>
	<CACk-te2H2OW+DKhnrtcd3mH=tN78gY4mqxLUR8pKAfgCoNjJLg@mail.gmail.com>
	<51C882DE.9050409@sapo.pt>
	<CACk-te1jMBcYGr4nJ_vn0GrpjHDBMaMmQYc8DYPD44wKvchs=w@mail.gmail.com>
Message-ID: <51C8909B.4020406@gmail.com>

First of all, thanks for all the replies!!
What you have written helps, but is not entirely the answer to my problem.

What I'd have is the creation of new data.frames each of one named with 
the ID of the original dataframe and with all the columns.

For example, in the original dataframe one column (ID) has 5 different 
elements:

ID    value1    value2
x1        10            12
x1        12            22
x1        11            9
x2        15            10
x3        11            11
x3        13            8

I need a command ables to split the dataframe in other smallest and 
separated dataframes, so that they look like

x1 is
ID    value1    value2
x1        10            12
x1        12            22
x1        11            9

x2 is
ID    value1    value2
x2        15            10

and x3 is
ID    value1    value2
x1        10            12
x3        11            11
x3        13            8


Sorry if I'm not able to explain it better and as I said I'm very new to 
R.....

Thanks

Matteo


From smartpink111 at yahoo.com  Mon Jun 24 20:34:47 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 24 Jun 2013 11:34:47 -0700 (PDT)
Subject: [R] Apply acf to data frame containing 'NA'
In-Reply-To: <1372093207.15132.YahooMailNeo@web160605.mail.bf1.yahoo.com>
References: <1372008544.78305.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<1372009314.82467.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1372009892.48395.YahooMailNeo@web160606.mail.bf1.yahoo.com>
	<CACtd3+crpdFKYaHukMy4e2EU8du2v72++KVZ4hXBxLM3abF_fw@mail.gmail.com>
	<1372018319.99860.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1372019412.43341.YahooMailNeo@web160603.mail.bf1.yahoo.com>
	<1372019591.4623.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1372093207.15132.YahooMailNeo@web160605.mail.bf1.yahoo.com>
Message-ID: <1372098887.63699.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Try this:


res1<-do.call(cbind,t(sapply(res,c))[,1]) #get the acf values only.? Assuming that is what you wanted.
?write.csv(res1,"AMSacf.csv",row.names=FALSE)
A.K.





________________________________
From: Zilefac Elvis <zilefacelvis at yahoo.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Monday, June 24, 2013 1:00 PM
Subject: Re: [R] Apply acf to data frame containing 'NA'



Hi AK,
How can I write the 'res' output to file? Attached is my data.

dat1<-AMS1[,-1]
pdf("AMS1_acf.pdf")
res<-lapply(dat1,function(x)acf(x,na.action=na.pass))
dev.off()

I tried something like this: ?data<-as.data.frame(t(sapply(res,c))) but it did not work.
I would like to export the file and store in column mood.

Thanks,
Atem.


________________________________
From: arun <smartpink111 at yahoo.com>
To: Zilefac Elvis <zilefacelvis at yahoo.com> 
Sent: Sunday, June 23, 2013 2:33 PM
Subject: Re: [R] Apply acf to data frame containing 'NA'


HI Atem,
No problem.
Arun






________________________________
From: Zilefac Elvis <zilefacelvis at yahoo.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Sunday, June 23, 2013 4:30 PM
Subject: Re: [R] Apply acf to data frame containing 'NA'



Hi AK,
Thanks so much for the fruitful correction.
AE.


________________________________
From: arun <smartpink111 at yahoo.com>
To: Zilefac Elvis <zilefacelvis at yahoo.com> 
Cc: "barron.hr at gmail.com" <barron.hr at gmail.com> 
Sent: Sunday, June 23, 2013 1:11 PM
Subject: Re: [R] Apply acf to data frame containing 'NA'




HI Atem,





________________________________
From: Hannah Barron <hannahbarron at trentu.ca>
To: Zilefac Elvis <zilefacelvis at yahoo.com> 
Cc: R help <r-help at r-project.org> 
Sent: Sunday, June 23, 2013 2:04 PM
Subject: Re: [R] Apply acf to data frame containing
'NA'

HI,
This makes more sense.? Sorry, I didn't check the ?acf() before I send the reply.

lapply(dat1,function(x)acf(x,na.action=na.pass))

A.K.

Hi,

The acf function requires that you specify how to deal with NAs in your
data. By default, it uses na.fail ("Error in *na.fail.default*(as.ts(x)) :
missing values in object).
Try using na.action=na.pass as an argument.
While this will pass over your NAs, make sure that you understand how that
will affect your results. See the acf R documentation for further
explanation.

Good luck,
H

On Sun, Jun 23, 2013 at 1:51 PM, Zilefac Elvis <zilefacelvis at yahoo.com>wrote:

> Hi,
> Thanks so much for the quick reply.
> It worked on your data but failed on mine.
> Attached is my data.
> I received this error:
> "Error
in acf(na.omit(x)) : 'lag.max' must be at least 0
> In addition: Warning message:
> In split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...) :
>???data length is not a multiple of split variable"
>
> AE.
>
>
> ________________________________
>? From: arun <smartpink111 at yahoo.com>
> To: Zilefac Elvis <zilefacelvis at yahoo.com>
> Cc: R help <r-help at r-project.org>
> Sent: Sunday, June 23, 2013 11:41 AM
> Subject: Re: [R] Apply acf? to data frame containing 'NA'
>
>
> Hi,
> May be this helps:
> set.seed(24)
> A <-
matrix(sample(c(NA,rnorm(1500)),1500,replace=FALSE),nrow=500)
> par(mfrow=c(ncol(A),1))
>? lapply(split(A,col(A)),function(x) acf(na.omit(x)))
> A.K.
>
>
>
>
> ----- Original Message -----
> From: Zilefac Elvis <zilefacelvis at yahoo.com>
> To: "r-help at r-project.org" <r-help at r-project.org>
> Cc:
> Sent: Sunday, June 23, 2013 1:29 PM
> Subject: [R] Apply acf? to data frame containing 'NA'
>
> Hi,
> I have a data frame with each column representing a separate site.
> Following this code, I can apply acf to all columns in A. 'A' contains
> randomly generated data.
>
> A <-
matrix(rnorm(1500),nrow=500)
> par(mfrow=c(ncol(A),1))
>
> lapply(split(A,col(A)), acf)
>
> #OR
> lapply(split(A,col(A)), function(snow) acf(snow, lag.max=5))
>
>
> Problem: Some of my data contains 'NA' in some of the columns. I get this
> error
> "Error
in na.fail.default(as.ts(x)) : missing values in object"
> How can I resolve this problem?
>
> Thanks.
> AE.
>? ???[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From gunter.berton at gene.com  Mon Jun 24 20:42:17 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 24 Jun 2013 11:42:17 -0700
Subject: [R] extracting submatrix from a bigger one
In-Reply-To: <51C8909B.4020406@gmail.com>
References: <51C85961.6090908@gmail.com> <51C872CD.7020700@sapo.pt>
	<CACk-te2H2OW+DKhnrtcd3mH=tN78gY4mqxLUR8pKAfgCoNjJLg@mail.gmail.com>
	<51C882DE.9050409@sapo.pt>
	<CACk-te1jMBcYGr4nJ_vn0GrpjHDBMaMmQYc8DYPD44wKvchs=w@mail.gmail.com>
	<51C8909B.4020406@gmail.com>
Message-ID: <CACk-te2NoP8unOAOUE5ZWdEnBwnpB6DxdF7x5ZaFQFhJuLy9Og@mail.gmail.com>

Inline below...

On Mon, Jun 24, 2013 at 11:31 AM, matteo <matteo.ghetta at gmail.com> wrote:
> First of all, thanks for all the replies!!
> What you have written helps, but is not entirely the answer to my problem.
>
> What I'd have is the creation of new data.frames each of one named with the
> ID of the original dataframe and with all the columns.

No you don't! You want what you were provided, a list of data frames.
Anything you want to do can be done, probably more conveniently, with
that.

Read "An Introduction to R" and learn to work with lists. Being a
newbie is no excuse for not making an effort to learn.

-- Bert



>
> For example, in the original dataframe one column (ID) has 5 different
> elements:
>
> ID    value1    value2
> x1        10            12
> x1        12            22
> x1        11            9
> x2        15            10
> x3        11            11
> x3        13            8
>
> I need a command ables to split the dataframe in other smallest and
> separated dataframes, so that they look like
>
> x1 is
> ID    value1    value2
> x1        10            12
> x1        12            22
> x1        11            9
>
> x2 is
> ID    value1    value2
> x2        15            10
>
> and x3 is
> ID    value1    value2
> x1        10            12
> x3        11            11
> x3        13            8
>
>
> Sorry if I'm not able to explain it better and as I said I'm very new to
> R.....
>
> Thanks
>
> Matteo



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From sarah.goslee at gmail.com  Mon Jun 24 20:43:57 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 24 Jun 2013 14:43:57 -0400
Subject: [R] Error with metaMDS
In-Reply-To: <CAFdg=fXs22cYzs7h=Bzqo7bgNFXJ1fZ=rUAx=UwPA6rvum4qhg@mail.gmail.com>
References: <CAFdg=fWSufe8WggoYo1RjO8uoNeZzhUEk41_MPT2RFJTVKsfOQ@mail.gmail.com>
	<CAM_vju=FVki+ig12S5uibW8-SiKcvd9QF-Tt6w_BGpr9Ds7xzA@mail.gmail.com>
	<CAFdg=fXs22cYzs7h=Bzqo7bgNFXJ1fZ=rUAx=UwPA6rvum4qhg@mail.gmail.com>
Message-ID: <CAM_vjukQzfrYx-Rh=T=23GK3hEfdJhpmiQDiCbWJfN352ZMghQ@mail.gmail.com>

Hi,

On Mon, Jun 24, 2013 at 12:04 PM, Suparna Mitra
<suparna.mitra.sm at gmail.com> wrote:
> Dear Sarah,
>   Thanks for your reply. But I don't have any site where all the species are
> 0.

Well, that's what this says:
> 1: In distfun(comm, method = distance, ...) :
>   you have empty rows: their dissimilarities may be meaningless in method
> ?bray?

> Is there anyway to calculate the dissimilarity between sites where it
> computes only the non-zero species values. Excluding all the zero event will
> result a big loss in species data. I don't want to delete the cases where
> may be 5out of 8 sites have species info, only 3 don't have.

There's no reason to delete those. Bray-Curtis and similar metrics
consider only joint presences, not joint absences. If you have a lot
of sites with no species in common, it can also cause problems. That's
what vegan::stepacross is intended to deal with.

>  Should I replace zero with a very small number. What is the best thing to
> do in such cases?

The best thing to do in such cases is to provide a reproducible
example to R-help. At the very least,
str(X)
str(data) # called in metaMDS() but not described; also, don't call
your data data

and double-check to make sure you don't have any all-zero rows or NA
values in your data.

Sarah

> On 24 June 2013 21:24, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>
>> Hi,
>>
>> What do you expect the dissimilarity between a site with no species
>> and a site with some species to be?
>>
>> If you want to use Bray-Curtis dissimilarity, you need to drop the
>> sites with no species, as the error message suggests.
>>
>> But if you can answer my first question, you may be able to select a
>> different dissimilarity metric that matches your expectations
>> numerically.
>>
>> Sarah
>>
>>
>> On Mon, Jun 24, 2013 at 7:33 AM, Suparna Mitra
>> <suparna.mitra.sm at gmail.com> wrote:
>> >  H
>> > ello R-experts,
>> >   I want to do ordination plots using vegan metaMDS.
>> > I have a where many cells have zero values.
>> >
>> > Data structure:
>> > X[1:10,1:14]
>> >        Height.1 Height.2 Height.3 Height.4 Height.5 Height.6 Height.7
>> > Height.8 Height.9 Height.10 Height.11 Height.12 Height.13
>> > D30I1A       46        0        0        0        0        0        0
>> >  0        0         0        39         0        98
>> > D30I1B       46        0        0        0        0        0        0
>> >  0        0         0        39         0        98
>> > D30I1C       70        0        0        0        0        0        0
>> >  0        0         0         0        85         0
>> > D30I2A       47        0        0        0        0        0        0
>> >  0        0         0        49         0       105
>> > D30I2B       68        0        0        0        0        0        0
>> >  0        0         0        83         0       214
>> > D30I2C        0       75        0        0        0        0        0
>> >  0        0         0         0        83         0
>> > D30I3A       48        0        0        0        0        0        0
>> >  0        0         0        42         0       107
>> > D30I3B       64        0        0        0        0        0        0
>> >  0        0         0        72         0       177
>> > D30I3C       72        0        0        0        0        0        0
>> >  0        0         0         0        96         0
>> > D30M1A       60        0        0        0        0        0        0
>> >  0        0         0        74         0       169
>> >
>> > Another data structure
>> >> Genus_data[1:10,1:14]
>> >      Sample Acanthamoeba Acidianus Aegilops Alphapapillomavirus
>> > Asfivirus
>> > Brassica Buchnera Coprinellus Diaphorobacter Hartmannella Ignicoccus
>> > 1    HS1_S1            0         0        0                   0
>> > 0
>> >      0        0           0              0            0          0
>> > 2    HS2_S2            0         1        1                   0
>> > 0
>> >      0        0           0              0            1          0
>> > 3    HS3_S3            0         0        0                   1
>> > 0
>> >      0        1           1              1            0          0
>> > 4    HS4_S4            0         0        0                   0
>> > 1
>> >      0        0           0              0            0          0
>> > 5   HS13_S5            0         0        0                   0
>> > 0
>> >      0        0           0              0            0          0
>> > 6   HS14_S6            0         0        0                   0
>> > 0
>> >      1        0           0              0            0          0
>> > 7   HS15_S7            0         0        0                   0
>> > 0
>> >      0        0           0              0            0          0
>> > 8   HS16_S8            0         0        0                   0
>> > 0
>> >      0        0           0              0            0          1
>> > 9   HS25_S9            1         0        0                   0
>> > 0
>> >      0        0           0              0            0          0
>> >
>> > I am having two different kind of errors for these two data...
>> > Error 1
>> >> ord1 <- metaMDS(
>> >  X
>> > ="bray")
>> > Square root transformation
>> > Wisconsin double standardization
>> > Error in if (any(dist < -sqrt(.Machine$double.eps))) warning("some
>> > dissimilarities are negative -- is this intentional?") :
>> >   missing value where TRUE/FALSE needed
>> > In addition: Warning messages:
>> > 1: In distfun(comm, method = distance, ...) :
>> >   you have empty rows: their dissimilarities may be meaningless in
>> > method
>> > ?bray?
>> > 2: In distfun(comm, method = distance, ...) : missing values in results
>> >
>> > Error 2
>> > ord.data= metaMDS(data, distance="bray")
>> > Error in if (any(autotransform, noshare > 0, wascores) && any(comm < 0))
>> > {
>> > :
>> >   missing value where TRUE/FALSE needed
>> > In addition: Warning message:
>> > In Ops.factor(left, right) : < not meaningful for factors
>> >
>> > I searched all the details of metaMDS where it is suggested to avail the
>> > argument 'zerodist'
>> > So I tried both
>> >
>> > X.dist1 <- metaMDSdist(X, method="bray",zerodist = "ignore")
>> > X.dist2 <- metaMDSdist(X, method="bray",zerodist = "add")
>> >
>> > Can Please help me with this.
>> > Thanks,
>> > Mitra
>> >
>>



-- 
Sarah Goslee
http://www.functionaldiversity.org


From jvadams at usgs.gov  Mon Jun 24 20:50:33 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 24 Jun 2013 13:50:33 -0500
Subject: [R] help needed with printing multiple arguments as vectors,
	not matrices
In-Reply-To: <CALC4TGC9_Nn429qNRCJZMfrjwvCNPRs7bHnQK_NKs8BNraQ22A@mail.gmail.com>
References: <CALC4TGCXNarcO8dXm_kEDq=6VSspMtCZuTxjakXx2Vg9W3-fpA@mail.gmail.com>
	<CAN5YmCExo-KDVxFuBXus25NYGtgEXCNN-E2AWbzaG7SZQ_smfQ@mail.gmail.com>
	<CALC4TGC9_Nn429qNRCJZMfrjwvCNPRs7bHnQK_NKs8BNraQ22A@mail.gmail.com>
Message-ID: <CAN5YmCEYQ4k9D3jRdfsq93r4D1LfS670LFe2gKyCa9M+CYPC-w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130624/acf392b2/attachment.pl>

From wdunlap at tibco.com  Mon Jun 24 21:01:40 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 24 Jun 2013 19:01:40 +0000
Subject: [R] extracting submatrix from a bigger one
In-Reply-To: <51C8909B.4020406@gmail.com>
References: <51C85961.6090908@gmail.com> <51C872CD.7020700@sapo.pt>
	<CACk-te2H2OW+DKhnrtcd3mH=tN78gY4mqxLUR8pKAfgCoNjJLg@mail.gmail.com>
	<51C882DE.9050409@sapo.pt>
	<CACk-te1jMBcYGr4nJ_vn0GrpjHDBMaMmQYc8DYPD44wKvchs=w@mail.gmail.com>
	<51C8909B.4020406@gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C306DBB@PA-MBX01.na.tibco.com>

> First of all, thanks for all the replies!!
> What you have written helps, but is not entirely the answer to my problem.
> 
> What I'd have is the creation of new data.frames each of one named with
> the ID of the original dataframe and with all the columns.

What was suggested gave you a list of data.frames, each named with the ID .
You can use the syntax list$name or list[["name"]] to refer to a data.frame.
  R> splitData <- split(allData, allData$ID)
  R> splitData$x1
    ID value1 value2
  1 x1     10     12
  2 x1     12     22
  3 x1     11      9
  R> splitData$x2
    ID value1 value2
  4 x2     15     10

You seem to want a function that creates a bunch of data.frames in the
current environment instead of one that creates them in a list created to
hold them.  This is not necessary and actually gets in the way most of the
time.

If you want to refer to 'x1' instead of 'splitData$x1' you can use 'with', as in
  R> with(splitData, mean(x1$value2) - mean(x2$value2))
  [1] 4.333333
instead of the slightly wordier
  R> mean(splitData$x1$value2) - mean(splitData$x2$value2)
  [1] 4.333333

If you want to process each sub-data.frame (these are data.frame, not matrices)
you can use lapply() or sapply() or vapply() on the list
  R> dm <- sapply(splitData, function(x)mean(x$value2) - mean(x$value1))
  R> dm
         x1        x2        x3 
   3.333333 -5.000000 -2.500000
  R> dm["x2"]
  x2 
  -5

If you put all those names into the current environment you stand the chance
of clobbering some other dataset whose name matched one of the entries in
allData$ID.  Also you would have to use some rather ugly code involving get()
and assign() to manipulate the objects.  Learn to love lists.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of matteo
> Sent: Monday, June 24, 2013 11:32 AM
> To: Bert Gunter
> Cc: r-help at r-project.org
> Subject: Re: [R] extracting submatrix from a bigger one
> 
> First of all, thanks for all the replies!!
> What you have written helps, but is not entirely the answer to my problem.
> 
> What I'd have is the creation of new data.frames each of one named with
> the ID of the original dataframe and with all the columns.
> 
> For example, in the original dataframe one column (ID) has 5 different
> elements:
> 
> ID    value1    value2
> x1        10            12
> x1        12            22
> x1        11            9
> x2        15            10
> x3        11            11
> x3        13            8
> 
> I need a command ables to split the dataframe in other smallest and
> separated dataframes, so that they look like
> 
> x1 is
> ID    value1    value2
> x1        10            12
> x1        12            22
> x1        11            9
> 
> x2 is
> ID    value1    value2
> x2        15            10
> 
> and x3 is
> ID    value1    value2
> x1        10            12
> x3        11            11
> x3        13            8
> 
> 
> Sorry if I'm not able to explain it better and as I said I'm very new to
> R.....
> 
> Thanks
> 
> Matteo
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sander1981 at gmail.com  Mon Jun 24 21:00:48 2013
From: sander1981 at gmail.com (Sander van Kuijk)
Date: Mon, 24 Jun 2013 21:00:48 +0200
Subject: [R] Nomogram (rms) for model with shrunk coefficients
Message-ID: <CAHtLaM_r6Mhc8d-6yCKHCAzJGwjmW9FGG7pA3P4PH4T087w5sw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130624/05ed693a/attachment.pl>

From olga.musayev at gmail.com  Mon Jun 24 21:12:44 2013
From: olga.musayev at gmail.com (Olga Musayev)
Date: Mon, 24 Jun 2013 15:12:44 -0400
Subject: [R] Scaling Statistical
In-Reply-To: <51C76068.8050305@sapo.pt>
References: <CA+RDsemNApLYh6VKrRev83e655-NvMYeouHtcz=hUVvYaF0AUw@mail.gmail.com>
	<51C75E45.6030700@sapo.pt> <51C76068.8050305@sapo.pt>
Message-ID: <CA+RDsekXcy_tSPbN7epLcVPvNjcJ+4tyA1vSyGgnnicofLi0-Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130624/55911363/attachment.pl>

From gavin.simpson at ucl.ac.uk  Mon Jun 24 21:16:09 2013
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Mon, 24 Jun 2013 13:16:09 -0600
Subject: [R] Error with metaMDS
In-Reply-To: <CAFdg=fWSufe8WggoYo1RjO8uoNeZzhUEk41_MPT2RFJTVKsfOQ@mail.gmail.com>
References: <CAFdg=fWSufe8WggoYo1RjO8uoNeZzhUEk41_MPT2RFJTVKsfOQ@mail.gmail.com>
Message-ID: <1372101369.20644.42.camel@haul.biol.uregina.ca>

On Mon, 2013-06-24 at 19:33 +0800, Suparna Mitra wrote:
>  H
> ello R-experts,
>   I want to do ordination plots using vegan metaMDS.
> I have a where many cells have zero values.
> 
<snip />
> I am having two different kind of errors for these two data...
> Error 1
> > ord1 <- metaMDS(
>  X
> ="bray")

That is fundamentally wrong - you are setting argument `X` to the
character vector `"bray"`, that is not how you call metaMDS(). Hence I
suspect you didn't bother to include the full code...!

Let's assume you cal actually call metaMDS() correctly...

The first set of warnings (not the error) come `vegdist()`. The first is
from :

if (method > 2 && any(rowSums(x, na.rm = TRUE) == 0))

and hence if you do

which(rowSums(X, na.rm = TRUE) == 0)

you'll see which rows (samples) have no counts at all. The second
warning in the first set comes from

if (any(is.na(d))) 
        warning("missing values in results")

hence by the time vegdist has computed the dissimilarity, those
computation ended up generating one or more `NA` values. Things go
downhill from there as the error generated from within metaMDS() is
because we are comparing the distances with the smallest representable
number and any comparison with `NA` yields `NA` and hence the first
Error you see. We should probably catch that but I don't have a
reproducible example to see why we don't...

> Square root transformation
> Wisconsin double standardization
> Error in if (any(dist < -sqrt(.Machine$double.eps))) warning("some
> dissimilarities are negative -- is this intentional?") :
>   missing value where TRUE/FALSE needed
> In addition: Warning messages:
> 1: In distfun(comm, method = distance, ...) :
>   you have empty rows: their dissimilarities may be meaningless in method
> bray
> 2: In distfun(comm, method = distance, ...) : missing values in results
> 
> Error 2
> ord.data= metaMDS(data, distance="bray")
> Error in if (any(autotransform, noshare > 0, wascores) && any(comm < 0)) {
> :
>   missing value where TRUE/FALSE needed
> In addition: Warning message:
> In Ops.factor(left, right) : < not meaningful for factors

Look at `str(data)` and if any of the columns are factors, change them
to be numeric or find out why R thinks they are factors - it wouldn't
normally convert numeric data to a factor when reading the data in.

What is `data`? You only refer to `Genus_data`.

Please try to be specific about exactly what you did - i.e. include the
actual code.

I suspect the things you try below are pointless as it is not zero
distances that are the problem but sites for which no observations were
recorded.

G

> I searched all the details of metaMDS where it is suggested to avail the
> argument 'zerodist'
> So I tried both
> 
> X.dist1 <- metaMDSdist(X, method="bray",zerodist = "ignore")
> X.dist2 <- metaMDSdist(X, method="bray",zerodist = "add")
> 
> Can Please help me with this.
> Thanks,
> Mitra
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Gavin Simpson, PhD                          [t] +1 306 337 8863
Adjunct Professor, Department of Biology    [f] +1 306 337 2410
Institute of Environmental Change & Society [e] gavin.simpson at uregina.ca
523 Research and Innovation Centre          [tw] @ucfagls
University of Regina
Regina, SK S4S 0A2, Canada


From angerusso1980 at gmail.com  Mon Jun 24 21:38:13 2013
From: angerusso1980 at gmail.com (Angel Russo)
Date: Mon, 24 Jun 2013 15:38:13 -0400
Subject: [R] help needed with printing multiple arguments as vectors,
	not matrices
In-Reply-To: <CAN5YmCEYQ4k9D3jRdfsq93r4D1LfS670LFe2gKyCa9M+CYPC-w@mail.gmail.com>
References: <CALC4TGCXNarcO8dXm_kEDq=6VSspMtCZuTxjakXx2Vg9W3-fpA@mail.gmail.com>
	<CAN5YmCExo-KDVxFuBXus25NYGtgEXCNN-E2AWbzaG7SZQ_smfQ@mail.gmail.com>
	<CALC4TGC9_Nn429qNRCJZMfrjwvCNPRs7bHnQK_NKs8BNraQ22A@mail.gmail.com>
	<CAN5YmCEYQ4k9D3jRdfsq93r4D1LfS670LFe2gKyCa9M+CYPC-w@mail.gmail.com>
Message-ID: <CALC4TGAOOKmP3pT7WicmoOfXd-8wbNxUry-Qz1RvXSWyDa64QA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130624/3a032adc/attachment.pl>

From ruipbarradas at sapo.pt  Mon Jun 24 21:41:52 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 24 Jun 2013 20:41:52 +0100
Subject: [R] Scaling Statistical
In-Reply-To: <CA+RDsekXcy_tSPbN7epLcVPvNjcJ+4tyA1vSyGgnnicofLi0-Q@mail.gmail.com>
References: <CA+RDsemNApLYh6VKrRev83e655-NvMYeouHtcz=hUVvYaF0AUw@mail.gmail.com>
	<51C75E45.6030700@sapo.pt> <51C76068.8050305@sapo.pt>
	<CA+RDsekXcy_tSPbN7epLcVPvNjcJ+4tyA1vSyGgnnicofLi0-Q@mail.gmail.com>
Message-ID: <51C8A100.6030604@sapo.pt>

Hello,

 From the help page for ?adf.test: "The p-values are interpolated from 
Table 4.2, p. 103 of Banerjee et al. (1993)."

I believe it's a problem with your data. Putting a print statement in 
the code for adf.test() gave me the following:


Call:
lm(formula = yt ~ xt1 + 1 + tt + yt1)

Residuals:
ALL 3 residuals are 0: no residual degrees of freedom!

Coefficients: (1 not defined because of singularities)
             Estimate Std. Error t value Pr(>|t|)
(Intercept)  -24.319         NA      NA       NA
xt1           -3.115         NA      NA       NA
tt            18.087         NA      NA       NA
yt1               NA         NA      NA       NA

Residual standard error: NaN on 0 degrees of freedom
Multiple R-squared:      1,     Adjusted R-squared:    NaN
F-statistic:   NaN on 2 and 0 DF,  p-value: NA



And the test statistic becomes NaN (Not a Number). It's computed as 
coefficients[2, 1]/coefficients[2, 2] or -3.115/NA.
So when it tries to interpolate the p-value, the variable 'interpol' is 
equal to NaN and the if test fails.

With a standard error like NA, maybe you don't have enough data points 
to run the tests. (Only 3 residuals, all zero, like seen above.)


Rui Barradas

Em 24-06-2013 20:12, Olga Musayev escreveu:
> Rui-- thanks so much for the help!
>
> I'm getting this error though, which is leaving me stumped:
>
> test<-lapply(ids, function(i) {
>        if(!any(is.na <http://is.na>(df[df$ID==i,3])))
> {adf.test(df[df$ID==i, 3])} else {NA} })
>
>      Error in if (interpol == min(tablep)) warning("p-value smaller than
> printed p-value") else warning("p-value greater than printed p-value") :
>        missing value where TRUE/FALSE needed
>
> Any idea what this could mean?
>
>
>
> On Sun, Jun 23, 2013 at 4:54 PM, Rui Barradas <ruipbarradas at sapo.pt
> <mailto:ruipbarradas at sapo.pt>> wrote:
>
>     Hello,
>
>     Sorry, I forgot to Cc the list.
>
>     Rui Barradas
>
>     Em 23-06-2013 21:44, Rui Barradas escreveu:
>
>         Hello,
>
>         See if the following does what you want.
>
>         lapply(seq_len(obsv), function(i) adf.test(df[df$ID == i, 3]))
>
>
>         Hope this helps,
>
>         Rui Barradas
>
>         Em 23-06-2013 19:12, Olga Musayev escreveu:
>
>             Short question: Is it possible to use statistical tests,
>             like the
>             Augmented
>             Dickey-Fuller test, in functions with for-loops? If not, are
>             there any
>             alternative ways to scale measures?
>
>             Detailed explanation: I am working with time-series, and I
>             want to flag
>             curves that are not stationary and which display pulses,
>             trends, or level
>             shifts.
>
>                 df
>
>
>             DATE          ID VALUE2012-03-06    1   5.672012-03-07    1
>             3.452012-03-08    1   4.562012-03-09    1   20.302012-03-10    1
>             5.102012-03-06    2   5.672012-03-07    2   3.452012-03-08    2
>             4.562012-03-09    2   5.282012-03-10    2   5.102012-03-06    3
>             5.672012-03-07    3   7.802012-03-08    3   8.792012-03-09    3
>             9.432012-03-10    3   10.99
>
>                You can see, object 2 is stationary, but 3 exhibits a
>             trend and 1 has a
>             pulse at 3/09.
>
>             What I want, in pseudo-code:
>
>             flag<- list()
>             for (i in 1:length(obsv)) {
>                    if adf.test(i) FAIL {
>                          append(flag, i)
>                          }}
>
>             What I have so far:
>
>                 library(tseries)
>                 adf.test(df[which(df$ID==1), 3])
>
>             Augmented Dickey-Fuller Test
>
>             data:  dataDickey-Fuller = 11.1451, Lag order = 16, p-value
>             = 0.01null
>             hypothesis: non-stationary
>
>                 adf.test(df[which(df$ID==2), 3])
>
>             Augmented Dickey-Fuller Test
>
>             data:  dataDickey-Fuller = 11.1451, Lag order = 16, p-value
>             = 0.99
>             alternative hypothesis: stationary
>
>                 adf.test(df[which(df$ID==3), 3])Augmented Dickey-Fuller Test
>
>
>             data:  dataDickey-Fuller = 11.1451, Lag order = 16, p-value
>             = 0.04null
>             hypothesis: non-stationary
>
>                How can I use this output in a for-loop? Thank you in
>             advance!
>
>                  [[alternative HTML version deleted]]
>
>             ________________________________________________
>             R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>             https://stat.ethz.ch/mailman/__listinfo/r-help
>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>             PLEASE do read the posting guide
>             http://www.R-project.org/__posting-guide.html
>             <http://www.R-project.org/posting-guide.html>
>             and provide commented, minimal, self-contained, reproducible
>             code.
>
>


From olga.musayev at gmail.com  Mon Jun 24 21:42:56 2013
From: olga.musayev at gmail.com (Olga Musayev)
Date: Mon, 24 Jun 2013 15:42:56 -0400
Subject: [R] Scaling Statistical
In-Reply-To: <51C8A100.6030604@sapo.pt>
References: <CA+RDsemNApLYh6VKrRev83e655-NvMYeouHtcz=hUVvYaF0AUw@mail.gmail.com>
	<51C75E45.6030700@sapo.pt> <51C76068.8050305@sapo.pt>
	<CA+RDsekXcy_tSPbN7epLcVPvNjcJ+4tyA1vSyGgnnicofLi0-Q@mail.gmail.com>
	<51C8A100.6030604@sapo.pt>
Message-ID: <CA+RDsekYc+5UZo688GriLD-Su4zkxOUSyb3c==vMfzWJFji-fQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130624/e0f770da/attachment.pl>

From dkulp at fiksu.com  Mon Jun 24 22:27:23 2013
From: dkulp at fiksu.com (David Kulp)
Date: Mon, 24 Jun 2013 16:27:23 -0400
Subject: [R] Lexical scoping is not what I expect
Message-ID: <F50F8583-AC2A-4E48-BC36-E193663C593A@fiksu.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130624/21e2f979/attachment.pl>

From ruipbarradas at sapo.pt  Mon Jun 24 22:40:47 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 24 Jun 2013 21:40:47 +0100
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <F50F8583-AC2A-4E48-BC36-E193663C593A@fiksu.com>
References: <F50F8583-AC2A-4E48-BC36-E193663C593A@fiksu.com>
Message-ID: <51C8AECF.8040600@sapo.pt>

Hello,

The object 'a' exists if function f() not in the global environment 
where g() is defined. R is in fact going up, but to the global 
environment and not finding 'a'. Try, as an example, the following.



f <- function(x) {
	g <- function(y) { y + a }
	a <- 5
	g(x)
}

f(2)  # 7


Now R is finding 'a'. Because g() exists in the environment of f() (like 
'a' does.)


Hope this helps,

Rui Barradas

Em 24-06-2013 21:27, David Kulp escreveu:
> According to http://cran.r-project.org/doc/contrib/Fox-Companion/appendix-scope.pdf and other examples online, I am to believe that R resolves variables using lexical scoping by following the frames up the call stack.  However, that's not working for me.  For example, the following code, taken from the reference above fails instead of returning 7.  What am I doing wrong?  Thanks!
>
> f <- function(x) { a<-5; g(x) }
> g <- function(y) { y + a }
> f(2)
> Error in g(x) : object 'a' not found
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ggrothendieck at gmail.com  Mon Jun 24 22:44:45 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 24 Jun 2013 16:44:45 -0400
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <F50F8583-AC2A-4E48-BC36-E193663C593A@fiksu.com>
References: <F50F8583-AC2A-4E48-BC36-E193663C593A@fiksu.com>
Message-ID: <CAP01uRkCHCAOpXXXnnWSX0wnB8gLc275e+5n0EpdE0E2fudBDA@mail.gmail.com>

On Mon, Jun 24, 2013 at 4:27 PM, David Kulp <dkulp at fiksu.com> wrote:
> According to http://cran.r-project.org/doc/contrib/Fox-Companion/appendix-scope.pdf and other examples online, I am to believe that R resolves variables using lexical scoping by following the frames up the call stack.  However, that's not working for me.  For example, the following code, taken from the reference above fails instead of returning 7.  What am I doing wrong?  Thanks!
>
> f <- function(x) { a<-5; g(x) }
> g <- function(y) { y + a }
> f(2)
> Error in g(x) : object 'a' not found
>

What you have described is called dynamic scoping. What lexical
scoping is is that it resolves free variables based on where the
function is _defined_, not where it is run and it has nothing to do
with the call stack.  a is a free variable in g and so when g is run R
looks up a in the environment where g was defined which is the global
environment and there is no a there.

--
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From smartpink111 at yahoo.com  Mon Jun 24 22:52:23 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 24 Jun 2013 13:52:23 -0700 (PDT)
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <F50F8583-AC2A-4E48-BC36-E193663C593A@fiksu.com>
References: <F50F8583-AC2A-4E48-BC36-E193663C593A@fiksu.com>
Message-ID: <1372107143.28622.YahooMailNeo@web142605.mail.bf1.yahoo.com>



?f1<- function(x){env<- parent.frame();env$a<-5; g(x)}
f1(2)
#[1] 7
?f1(7)
#[1] 12
?f1(5)
#[1] 10
A.K.



________________________________
From: David Kulp <dkulp at fiksu.com>
To: "r-help at r-project.org" <r-help at r-project.org> 
Sent: Monday, June 24, 2013 4:27 PM
Subject: [R] Lexical scoping is not what I expect


According to http://cran.r-project.org/doc/contrib/Fox-Companion/appendix-scope.pdf and other examples online, I am to believe that R resolves variables using lexical scoping by following the frames up the call stack.? However, that's not working for me.? For example, the following code, taken from the reference above fails instead of returning 7.? What am I doing wrong?? Thanks!

f <- function(x) { a<-5; g(x) }
g <- function(y) { y + a }
f(2)
Error in g(x) : object 'a' not found


??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From rolf.turner at xtra.co.nz  Mon Jun 24 23:05:52 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Tue, 25 Jun 2013 09:05:52 +1200
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <1372107143.28622.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <F50F8583-AC2A-4E48-BC36-E193663C593A@fiksu.com>
	<1372107143.28622.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <51C8B4B0.6090701@xtra.co.nz>



I hope that Robert Gentleman is currently getting a thrill. :-)

[See fortune("lexical scoping").]

     cheers,

         Rolf Turner


From marc_schwartz at me.com  Mon Jun 24 23:10:20 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 24 Jun 2013 16:10:20 -0500
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <F50F8583-AC2A-4E48-BC36-E193663C593A@fiksu.com>
References: <F50F8583-AC2A-4E48-BC36-E193663C593A@fiksu.com>
Message-ID: <151A65FD-DE29-4DEE-8E35-F80B8AF9CF8E@me.com>


On Jun 24, 2013, at 3:27 PM, David Kulp <dkulp at fiksu.com> wrote:

> According to http://cran.r-project.org/doc/contrib/Fox-Companion/appendix-scope.pdf and other examples online, I am to believe that R resolves variables using lexical scoping by following the frames up the call stack.  However, that's not working for me.  For example, the following code, taken from the reference above fails instead of returning 7.  What am I doing wrong?  Thanks!
> 
> f <- function(x) { a<-5; g(x) }
> g <- function(y) { y + a }
> f(2)
> Error in g(x) : object 'a' not found


You need to follow the full example code in John's Appendix:

f <- function (x) x + a

# Here 'a' is being defined in the global environment
a <- 10

# As is 'x' here
x <- 5


# Note that 10 + 5 would be 15,
# 12 is returned showing that x = 2 and not x = 5
# is being use within f()
> f(2)
[1] 12



# Here is where your code starts
# missing the preceding code where 'a' was
# defined globally

f <- function(x) { a<-5; g(x) }


g <- function(y) y + a


# Now it works, showing that 'a <- 5' within f() is not part of the 
# value returned by g(), which is the goal of John's example code :-)
> f(2)
[1] 12


Regards,

Marc Schwartz


From f.harrell at Vanderbilt.Edu  Mon Jun 24 23:41:18 2013
From: f.harrell at Vanderbilt.Edu (Frank Harrell)
Date: Mon, 24 Jun 2013 16:41:18 -0500
Subject: [R] Nomogram (rms) for model with shrunk coefficients
Message-ID: <51C8BCFE.90203@vanderbilt.edu>

You are using an informal shrinkage method.  It is much better to use 
penalized maximum likelihood estimation, built in to lrm.

If you really want to go the informal route, compute the linear 
predictor from your final estimates and use ols( ) to predict that from 
the component variables (you'll get an R^2 of 1.0 so specify sigma= to 
ols) and use nomogram on the result.

Frank


-- 
Frank E Harrell Jr Professor and Chairman      School of Medicine
                    Department of Biostatistics Vanderbilt University


From dwinsemius at comcast.net  Mon Jun 24 23:50:46 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 24 Jun 2013 14:50:46 -0700
Subject: [R] Nomogram (rms) for model with shrunk coefficients
In-Reply-To: <CAHtLaM_r6Mhc8d-6yCKHCAzJGwjmW9FGG7pA3P4PH4T087w5sw@mail.gmail.com>
References: <CAHtLaM_r6Mhc8d-6yCKHCAzJGwjmW9FGG7pA3P4PH4T087w5sw@mail.gmail.com>
Message-ID: <C6979B73-C628-4CB5-99FB-50FBF06FC83F@comcast.net>


On Jun 24, 2013, at 12:00 PM, Sander van Kuijk wrote:

> Dear R-users,
> 
> I have used the nomogram function from the rms package for a logistic
> regresison model made with lrm(). Everything works perfectly (r version
> 2.15.1 on a mac). My question is this: if my final model is not the one
> created by lrm, but I internally validated the model and 'shrunk' the
> regression coefficients and computed a new intercept, how can I build a
> nomogram using that object? Please see the simplified code for details:
> 
> library(rms)
> 
> x1<-rnorm(100,1,1)
> x2<-rnorm(100,1,1)
> y<-rbinom(100,1,0.5)
> 
> d<-data.frame(x1,x2,y)
> 
> attach(d)
> 
> ddist<-datadist(d)
> options(datadist='ddist')
> 
> model<-lrm(y~x1+x2, x=TRUE, y=TRUE, data=d)
> plot(nomogram(model))
> ##Nomogram is printed, as expected
> 
> ##Now the model is internally validated, and regression coefficients are
> penalized
> bootstrap<-validate(model, bw=FALSE, B=100)
> shrinkage<-round(bootstrap[4,5],2)
> final<-round(model$coef*shrinkage, 3)
> final.lp<-cbind(model$x)%*%final[-1]
> final["Intercept"]<-round(lrm.fit(y=d$y, offset=final.lp)$coef,3)
> final.lp<-final[1]+model$x%*%final[-1]
> 

I cannot speak to this with authority...just another interested user. My seat-of-the-pants notion is that the Intercept estimate should move toward the unadjusted odds for the outcome in the population while the coefficients should move toward the Null value. It's not clear to me that your code is accomplshing that goal for the intercept. 

When I replace model$coefficients with final.lp (which has the same overall structure) the change in the plotted version of nomgram shifts too radically to be supportive of the notion that you have properly calculated these values:

> str(final)
 Named num [1:3] 0.015 0.016 0.009
 - attr(*, "names")= chr [1:3] "Intercept" "x1" "x2"

> str(model$coefficients)
 Named num [1:3] -0.2045 0.1603 0.0889
 - attr(*, "names")= chr [1:3] "Intercept" "x1" "x2"

It appears to me that the "Intercept" value has been shifted too far. It should have stayed near zero. Nonetheless, the nomogram function does not throw an error with this code:

> mod2 <- model
> mod2$coefficients <- final
> plot(nomogram(mod2))

But the linear predictor scale is radically shifted. And the "Total Points" scale was compressed inappropriately.
-- 
David.


> ##The object 'final' now contains all model parameters, yet in a different
> fashion than the lrm-created model. Does anyone have an idea how to make
> this compatible again with nomogram()?
> 
> Thanks in advance for any thoughts on it.
> 
> Best wishes,
> Sander
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From mollymdavies at gmail.com  Mon Jun 24 23:53:36 2013
From: mollymdavies at gmail.com (Molly Davies)
Date: Mon, 24 Jun 2013 14:53:36 -0700
Subject: [R] Need help using Rcpp + Rmpi
Message-ID: <CAL5G99OUDXidJgGH+zSY8hknvn4FuXYntM4YxEAVdrj_D4tLgQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130624/5733d6a2/attachment.pl>

From kicco1991 at hotmail.it  Mon Jun 24 22:50:26 2013
From: kicco1991 at hotmail.it (Francesco Miranda)
Date: Mon, 24 Jun 2013 22:50:26 +0200
Subject: [R] packages for input messages
Message-ID: <DUB107-W2479A3013696B6B031D881DE8A0@phx.gbl>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130624/2836bcf8/attachment.pl>

From canamika at gmail.com  Mon Jun 24 23:14:34 2013
From: canamika at gmail.com (Anamika Chaudhuri)
Date: Mon, 24 Jun 2013 17:14:34 -0400
Subject: [R] Running MCMC using R2WinBUGS
Message-ID: <CALv--dYvLEj7wTLauDZyd-iwGtGWKHXzRP0EyvYx1ErPe5J8hg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130624/55976f68/attachment.pl>

From edd at debian.org  Tue Jun 25 00:12:41 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 24 Jun 2013 17:12:41 -0500
Subject: [R] Need help using Rcpp + Rmpi
In-Reply-To: <CAL5G99OUDXidJgGH+zSY8hknvn4FuXYntM4YxEAVdrj_D4tLgQ@mail.gmail.com>
References: <CAL5G99OUDXidJgGH+zSY8hknvn4FuXYntM4YxEAVdrj_D4tLgQ@mail.gmail.com>
Message-ID: <20936.50265.709352.686772@max.nulle.part>


Hi Mollyy,

On 24 June 2013 at 14:53, Molly Davies wrote:
| Hello,
| This might belong in the R-devel category, but I am not a C / C++
| programmer, so I thought I'd start here. I have just written my first R

The convention is that package-specific question go to the package specific
forums. In this case, you should really subscribe to rcpp-devel and post there.

| extension using Rcpp, and it is SO much faster than my best R efforts,
| thank you for such a wonderful package!

On behalf of the team: You are very welcome.

| Instead of writing a separate text | file, I used the following:
| 
| ### begin R ###
| require(Rcpp)
| cppFunction('
| double s2nICm(NumericVector ICvec, int m, double In, double sampleSize) {
|   int n = ICvec.size();
|   double covSum = 0.0;
|   double s2n = 0.0;
|   double ss = sampleSize*sampleSize;
|   for(int i=0; i<=m-1; i++){
|     for(int k=0; k<=i+m; k++){
|       covSum += ICvec[i]*ICvec[k];
|     }
|   }
|   for(int i=m; i<=n-m-1; i++){
|     for(int k=i-m; k<=i+m; k++){
|       covSum += ICvec[i]*ICvec[k];
|     }
|   }
|   for(int i=n-m; i<=n; i++){
|     for(int k=i-m; k<=n; k++){
|       covSum += ICvec[i]*ICvec[k];
|     }
|   }
|   s2n = (In/ss) * covSum;
|   return s2n;
| }
| ')
| ### end R ###
| 
| This works perfectly on my laptop (Macbook air). Now I need to use this
| function as a part of a large simulation on my school's cluster (running
| Sun Grid Engine) using Rmpi. I included the above function in a text file,
| sourced that file in the master and sent the function above to my slaves
| using
| 
| mpi.bcast.Robj2slave(s2nICm)
| 
| I've been trying to get this to work for about a week now, but no luck.
| (The original Rmpi simulation code that included the old, slow R version of
| the function above worked without error). Until recently, I've been getting
| a steady stream of informative error messages that I've forwarded to our
| sys admin - problems with g++, etc. Now I'm not getting any error messages,
| I'm just not getting any results. There may still be a problem with our
| cluster, but I'm wondering if perhaps I'm doing something wrong, too. I'd
| really like to understand how Rcpp and Rmpi interact. Is it OK to call
| cppFunction('...') in the master and then send the resulting R function to
| slaves using mpi.bcast.Robj2slave()? Or do I need to send a text version of
| the cppFunction('...') to each slave and evaluate the text within each
| slave? What's the proper way to use Rcpp within the context of Rmpi? Does
| anyone know of any good resources out there that can help me understand
| what's going on under the hood?

In a nutshell, you need the Rcpp-using code on each node -- that means object
code and all the object code needs. But let's discuss on rcpp-devel.

Cheers, Dirk

| Thanks very much for your time,
| Molly Davies
| Biostatistics Graduate Student
| UC Berkeley
| 
| 	[[alternative HTML version deleted]]
| 
| ______________________________________________
| R-help at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-help
| PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
| and provide commented, minimal, self-contained, reproducible code.

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From sarah.goslee at gmail.com  Tue Jun 25 00:20:13 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 24 Jun 2013 18:20:13 -0400
Subject: [R] packages for input messages
In-Reply-To: <DUB107-W2479A3013696B6B031D881DE8A0@phx.gbl>
References: <DUB107-W2479A3013696B6B031D881DE8A0@phx.gbl>
Message-ID: <CAM_vjunwepXzyKPs5N5WqDaWqw9YyrhT+t6vpoq8bZGFNvpCxg@mail.gmail.com>

It sounds like ?stop is what you're looking for.

Sarah

On Mon, Jun 24, 2013 at 4:50 PM, Francesco Miranda <kicco1991 at hotmail.it> wrote:
> Hello,I was trying to enter commands input messages or error within a routin.for example :  msg (consistency error: at the time ( j : generic time ) the lower quantile is not less than the upper quantile)
> thanks in advanceFrancesco Miranda

-- 
Sarah Goslee
http://www.functionaldiversity.org


From murdoch.duncan at gmail.com  Tue Jun 25 00:44:30 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 24 Jun 2013 18:44:30 -0400
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <F50F8583-AC2A-4E48-BC36-E193663C593A@fiksu.com>
References: <F50F8583-AC2A-4E48-BC36-E193663C593A@fiksu.com>
Message-ID: <51C8CBCE.3040903@gmail.com>

On 13-06-24 4:27 PM, David Kulp wrote:
> According to http://cran.r-project.org/doc/contrib/Fox-Companion/appendix-scope.pdf and other examples online, I am to believe that R resolves variables using lexical scoping by following the frames up the call stack.

You appear to have misread it.  Lexical scoping follows the chain of 
environments where functions were defined.  It ignores the call stack.	

Duncan Murdoch



  However, that's not working for me.  For example, the following code, 
taken from the reference above fails instead of returning 7.  What am I 
doing wrong?  Thanks!
>
> f <- function(x) { a<-5; g(x) }
> g <- function(y) { y + a }
> f(2)
> Error in g(x) : object 'a' not found
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dkulp at fiksu.com  Tue Jun 25 03:22:22 2013
From: dkulp at fiksu.com (David Kulp)
Date: Mon, 24 Jun 2013 18:22:22 -0700 (PDT)
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <51C8CBCE.3040903@gmail.com>
References: <51C8CBCE.3040903@gmail.com>
Message-ID: <1372123341449.dc8da696@Nodemailer>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130624/349e2daa/attachment.pl>

From wdunlap at tibco.com  Tue Jun 25 04:44:44 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 25 Jun 2013 02:44:44 +0000
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <1372123341449.dc8da696@Nodemailer>
References: <51C8CBCE.3040903@gmail.com> <1372123341449.dc8da696@Nodemailer>
Message-ID: <E66794E69CFDE04D9A70842786030B931C306F60@PA-MBX01.na.tibco.com>

> I think it's a difficult concept

If you pass non-global things via the argument list then you don't
have to think about scoping issues so much.  E.g., instead of
  f <- function(x) {
       g <- function(y) { y + a }
       a <- 5
       g(x)
  }
try
   f <- function(x) { a <- 5 ; g(x, a) }
   g <- function(y, a) { y + a }
f(x) will give the same result in both.

In addition, passing data through the argument list makes g() usable
in many functions.  If 'g' uses lexical scoping to find 'a' then you need
to redefine 'g' in every function that uses it.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of David Kulp
> Sent: Monday, June 24, 2013 6:22 PM
> To: Duncan Murdoch
> Cc: r-help at r-project.org
> Subject: Re: [R] Lexical scoping is not what I expect
> 
> Indeed, I misread / misunderstood. I think it's a difficult concept that's hard to explain
> and the example wasn't great. But thanks all for straightening me out!
> ???
> David Kulp
> 
> On Mon, Jun 24, 2013 at 6:44 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
> 
> > On 13-06-24 4:27 PM, David Kulp wrote:
> >> According to http://cran.r-project.org/doc/contrib/Fox-Companion/appendix-
> scope.pdf and other examples online, I am to believe that R resolves variables using
> lexical scoping by following the frames up the call stack.
> > You appear to have misread it.  Lexical scoping follows the chain of
> > environments where functions were defined.  It ignores the call stack.
> > Duncan Murdoch
> >   However, that's not working for me.  For example, the following code,
> > taken from the reference above fails instead of returning 7.  What am I
> > doing wrong?  Thanks!
> >>
> >> f <- function(x) { a<-5; g(x) }
> >> g <- function(y) { y + a }
> >> f(2)
> >> Error in g(x) : object 'a' not found
> >>
> >>
> >> 	[[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> 	[[alternative HTML version deleted]]


From Kirschenbaum.Leif at ssd.loral.com  Tue Jun 25 03:47:59 2013
From: Kirschenbaum.Leif at ssd.loral.com (Leif Kirschenbaum)
Date: Tue, 25 Jun 2013 01:47:59 +0000
Subject: [R] Unique matching of two sets of multidimensional data
Message-ID: <0099ABD4BC918242913DF056851DA1FF53BB0B40@Donphan.world.ssd.loral.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/adbc7383/attachment.pl>

From erinm.hodgess at gmail.com  Tue Jun 25 06:04:02 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Mon, 24 Jun 2013 23:04:02 -0500
Subject: [R]  PERT and/or CPM packages, please?
Message-ID: <CACxE24kO068cOgJttSaDVX1UtYfTrdXCDAfjePE=FREHXzw3pQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130624/2153786f/attachment.pl>

From ion.matees at gmail.com  Tue Jun 25 01:53:08 2013
From: ion.matees at gmail.com (Ion Mateescu)
Date: Mon, 24 Jun 2013 19:53:08 -0400
Subject: [R] Performing stats on group of observations
Message-ID: <CAFqmCDwYFHSTRnaM9R9dJR66fscRx3jao5WtQFQwXnLuRRfv=w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130624/219b3433/attachment.pl>

From erinm.hodgess at gmail.com  Tue Jun 25 06:17:46 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Mon, 24 Jun 2013 23:17:46 -0500
Subject: [R] Performing stats on group of observations
In-Reply-To: <CAFqmCDwYFHSTRnaM9R9dJR66fscRx3jao5WtQFQwXnLuRRfv=w@mail.gmail.com>
References: <CAFqmCDwYFHSTRnaM9R9dJR66fscRx3jao5WtQFQwXnLuRRfv=w@mail.gmail.com>
Message-ID: <CACxE24==BU4W6CGLO9bDFujL0La8jrJovn_WccFCkFB3yqFn=Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130624/e7f79e21/attachment.pl>

From gunter.berton at gene.com  Tue Jun 25 08:07:55 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 24 Jun 2013 23:07:55 -0700
Subject: [R] Performing stats on group of observations
In-Reply-To: <CAFqmCDwYFHSTRnaM9R9dJR66fscRx3jao5WtQFQwXnLuRRfv=w@mail.gmail.com>
References: <CAFqmCDwYFHSTRnaM9R9dJR66fscRx3jao5WtQFQwXnLuRRfv=w@mail.gmail.com>
Message-ID: <CACk-te1ctk0ZKfr7XR1qLYozuaWmKVyp9bBwEN1QF_TepDr66A@mail.gmail.com>

"... trying to figure it out" ??

Not sure what that means.Have you read "An Introduction to R."? If
not, do so now.

In any case, ?ave is made for what you want, I think (simpler than
?by). As in (if df is your data frame):

ave(df$NoFlights,df$Week, FUN= mean)

Or, better yet, using ?with and noting that mean is the default for FUN

with(df,ave(NoFlights,Week))

Cheers,
Bert




On Mon, Jun 24, 2013 at 4:53 PM, Ion Mateescu <ion.matees at gmail.com> wrote:
> This may be a simple problem but I spent most of my day today trying to
> figure it out, as I am not a programmer. I have a dataframe with
> observations from different weeks of the year, numbered. My variable
> "week" has values week1, week4, week9, etc. Not all weeks are represented.
> I need to calculate statistics and compare means for a measured variable
> (no_of_flights) :
>
> Week    NoFlights
> week1    31.00
> week1    31.00
> week1    36.00
> week1    32.00
> week1    30.00
> week1    30.00
> week1    30.00
> week2    31.00
> week2    32.00
> week1    30.00
> week1    31.00
> week1    32.00
> week23    30.00
> week23    35.00
> week57    30.00
> week1    32.00
> week1    33.00
> week1    33.00
> week2    30.00
> week2    33.00
> week1    32.00
> week1    32.00
> week1    33.00
> week23    28.00
>
> Any help is appreciated.
>
> River
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From ali.zolfaghari at gmail.com  Tue Jun 25 09:06:56 2013
From: ali.zolfaghari at gmail.com (Dr. Alireza Zolfaghari)
Date: Tue, 25 Jun 2013 08:06:56 +0100
Subject: [R] SP package
Message-ID: <CAJpFpjUXvw2nV5F4r0NiBk1OOw26p7_hfMCGYyLNVzGCrRSKjg@mail.gmail.com>

Hi list,
I would like to write the function [R_point_in_polygon_sp] in c# as I
found it a very efficiently written code due to its high speed
calculation. I queried the function name by using
sp::point.in.polygon, but could not get source code. Would someone let
me know how to get the source code please?
Thanks
Alireza

-- 
Sent from my mobile device


From nevil.amos at gmail.com  Tue Jun 25 09:14:17 2013
From: nevil.amos at gmail.com (nevil amos)
Date: Tue, 25 Jun 2013 17:14:17 +1000
Subject: [R] return output to console for copying as input
Message-ID: <CAN9eD7==k=MkYQVwq4hnBSsj0sOE26v4N27W50U2Yh-tb6hjLg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/83944fa8/attachment.asc>

From ruipbarradas at sapo.pt  Tue Jun 25 09:28:41 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 25 Jun 2013 08:28:41 +0100
Subject: [R] SP package
In-Reply-To: <CAJpFpjUXvw2nV5F4r0NiBk1OOw26p7_hfMCGYyLNVzGCrRSKjg@mail.gmail.com>
References: <CAJpFpjUXvw2nV5F4r0NiBk1OOw26p7_hfMCGYyLNVzGCrRSKjg@mail.gmail.com>
Message-ID: <51C946A9.6070804@sapo.pt>

Hello,

R is open source. You can download the source code for package sp.

http://cran.r-project.org/web/packages/sp/index.html

Hope this helps,

Rui Barradas

Em 25-06-2013 08:06, Dr. Alireza Zolfaghari escreveu:
> Hi list,
> I would like to write the function [R_point_in_polygon_sp] in c# as I
> found it a very efficiently written code due to its high speed
> calculation. I queried the function name by using
> sp::point.in.polygon, but could not get source code. Would someone let
> me know how to get the source code please?
> Thanks
> Alireza
>


From ruipbarradas at sapo.pt  Tue Jun 25 09:33:22 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 25 Jun 2013 08:33:22 +0100
Subject: [R] return output to console for copying as input
In-Reply-To: <CAN9eD7==k=MkYQVwq4hnBSsj0sOE26v4N27W50U2Yh-tb6hjLg@mail.gmail.com>
References: <CAN9eD7==k=MkYQVwq4hnBSsj0sOE26v4N27W50U2Yh-tb6hjLg@mail.gmail.com>
Message-ID: <51C947C2.1070102@sapo.pt>

Hello,

Maybe ?cat

cat(X, "\n")

(But it doesn't put the vector elements between quotes.)

Hope this helps,

Rui Barradas

Em 25-06-2013 08:14, nevil amos escreveu:
> I want to print a vector of strings to the console formatted as if it were
> input
>
> X<-c("a","b","c")
>> X
> [1] "a" "b" "c"
>
> what I would like to get is
>
> the.function(X)
>> "a","b","c"
>
> what is the function?
>
> cheers
>
> Nevil amos
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From alfonso.carfora at uniparthenope.it  Tue Jun 25 08:03:32 2013
From: alfonso.carfora at uniparthenope.it (alfonso.carfora at uniparthenope.it)
Date: Tue, 25 Jun 2013 08:03:32 +0200
Subject: [R] x-labels in barplots
Message-ID: <20130625080332.125852shjhs4svjo@webmail.uniparthenope.it>

Hi,

I need to generate a barplot in in which the x-labels must to be  
perpendiculars to the x-axis

in my data have a list of probability values correspondings to a list  
of Countries. In the barplot the name of each Country,  under each  
bar, appears parallel to the x axis. Is possibile rotate them so as to  
make them perpendicular to the x-axis

barplot(fig1$Prob,names.arg=fig1$Country,ylab="probabilities",ylim=c(0,0.3))

Thanks
A.C.



******************************************************************************	
IL MERITO DEGLI STUDENTI VIENE RICONOSCIUTO
 
Il 5 per mille all'Universita' degli Studi di Napoli "Parthenope" incrementa le borse di studio agli studenti - codice fiscale 80018240632
http://www.uniparthenope.it/index.php/5xmille 
 
http://www.uniparthenope.it/index.php/it/avvisi-sito-di-ateneo/2943-la-parthenope-premia-il-tuo-voto-di-diploma-ed-il-tuo-imegno-con-i-proventi-del-5-per-mille
 
Questa informativa e' inserita in automatico dal sistema al fine esclusivo della realizzazione dei fini istituzionali dell'ente.


From rguy at 123mail.org  Tue Jun 25 07:59:02 2013
From: rguy at 123mail.org (Rguy)
Date: Tue, 25 Jun 2013 06:59:02 +0100
Subject: [R] Time of day
Message-ID: <CAEorq2OYsHgNQkvwtc-C-ABxQPX7uahsCZAoH9F8sgZ1RCcBew@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/5ceedea3/attachment.ksh>

From kicco1991 at hotmail.it  Tue Jun 25 10:19:58 2013
From: kicco1991 at hotmail.it (Francesco Miranda)
Date: Tue, 25 Jun 2013 10:19:58 +0200
Subject: [R] packages for input messages
In-Reply-To: <CAM_vjunwepXzyKPs5N5WqDaWqw9YyrhT+t6vpoq8bZGFNvpCxg@mail.gmail.com>
References: <DUB107-W2479A3013696B6B031D881DE8A0@phx.gbl>,
	<CAM_vjunwepXzyKPs5N5WqDaWqw9YyrhT+t6vpoq8bZGFNvpCxg@mail.gmail.com>
Message-ID: <DUB107-W42565A06C4D3581CA91A24DE8B0@phx.gbl>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/7c4f3d73/attachment.pl>

From es at enricoschumann.net  Tue Jun 25 10:26:02 2013
From: es at enricoschumann.net (Enrico Schumann)
Date: Tue, 25 Jun 2013 10:26:02 +0200
Subject: [R] return output to console for copying as input
In-Reply-To: <CAN9eD7==k=MkYQVwq4hnBSsj0sOE26v4N27W50U2Yh-tb6hjLg@mail.gmail.com>
	(nevil amos's message of "Tue, 25 Jun 2013 17:14:17 +1000")
References: <CAN9eD7==k=MkYQVwq4hnBSsj0sOE26v4N27W50U2Yh-tb6hjLg@mail.gmail.com>
Message-ID: <87hagm8ulh.fsf@enricoschumann.net>

On Tue, 25 Jun 2013, nevil amos <nevil.amos at gmail.com> writes:

> I want to print a vector of strings to the console formatted as if it were
> input
>
> X<-c("a","b","c")
>> X
> [1] "a" "b" "c"
>
> what I would like to get is
>
> the.function(X)
>>"a","b","c"
>
> what is the function?
>

the.function <- function(x)
    cat(paste0("\"", x, "\"", collapse = ", "), "\n")



-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From ripley at stats.ox.ac.uk  Tue Jun 25 10:33:51 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 25 Jun 2013 09:33:51 +0100
Subject: [R] Time of day
In-Reply-To: <CAEorq2OYsHgNQkvwtc-C-ABxQPX7uahsCZAoH9F8sgZ1RCcBew@mail.gmail.com>
References: <CAEorq2OYsHgNQkvwtc-C-ABxQPX7uahsCZAoH9F8sgZ1RCcBew@mail.gmail.com>
Message-ID: <51C955EF.4000208@stats.ox.ac.uk>

On 25/06/2013 06:59, Rguy wrote:
> Is there a simple way to obtain the time of day in R? I want the time of
> day for computational purposes, not for display. I want to be able to
> create code like the following:
>
> if (time_of_day >= 22:00 & time_of_day <= 06:00) then X otherwise Y

which will not parse and in any case there are no such times.

> I realize I could parse a date/time object and extract the time, but
> hopefully other people have already done this, or there is a
> straightforward representation of time of day in R that I  have not been
> able to find in the documentation.

 > t <- Sys.time()
 > tt <- format(t, "%H:%M")
 > tt <= "22:00" && tt >= "06:00"
[1] TRUE

Note the use of && not &.

> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

PLEASE do: no HTML mail ....



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From es at enricoschumann.net  Tue Jun 25 10:37:38 2013
From: es at enricoschumann.net (Enrico Schumann)
Date: Tue, 25 Jun 2013 10:37:38 +0200
Subject: [R] Time of day
In-Reply-To: <CAEorq2OYsHgNQkvwtc-C-ABxQPX7uahsCZAoH9F8sgZ1RCcBew@mail.gmail.com>
	(rguy@123mail.org's message of "Tue, 25 Jun 2013 06:59:02 +0100")
References: <CAEorq2OYsHgNQkvwtc-C-ABxQPX7uahsCZAoH9F8sgZ1RCcBew@mail.gmail.com>
Message-ID: <87d2ra8u25.fsf@enricoschumann.net>

On Tue, 25 Jun 2013, Rguy <rguy at 123mail.org> writes:

> Is there a simple way to obtain the time of day in R? I want the time of
> day for computational purposes, not for display. I want to be able to
> create code like the following:
>
> if (time_of_day >= 22:00 & time_of_day <= 06:00) then X otherwise Y
                     ^^^^^                  ^^^^^
this will not work: the times need to be something that R understands,
eg, numeric values such as 2200 or character values such as "22:00"

>
> I realize I could parse a date/time object and extract the time, but
> hopefully other people have already done this, or there is a
> straightforward representation of time of day in R that I  have not been
> able to find in the documentation.

strftime(Sys.time(), "%H:%M")

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From bhh at xs4all.nl  Tue Jun 25 10:47:57 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 25 Jun 2013 10:47:57 +0200
Subject: [R] packages for input messages
In-Reply-To: <DUB107-W42565A06C4D3581CA91A24DE8B0@phx.gbl>
References: <DUB107-W2479A3013696B6B031D881DE8A0@phx.gbl>,
	<CAM_vjunwepXzyKPs5N5WqDaWqw9YyrhT+t6vpoq8bZGFNvpCxg@mail.gmail.com>
	<DUB107-W42565A06C4D3581CA91A24DE8B0@phx.gbl>
Message-ID: <61CC94BB-1D2E-4D61-9D92-C39852C68D0A@xs4all.nl>


On 25-06-2013, at 10:19, Francesco Miranda <kicco1991 at hotmail.it> wrote:

> I need something like the writeln in C. I need to make error messages
> 

Does C have a writeln?

Have a look at cat:

?cat

Berend

>> Date: Mon, 24 Jun 2013 18:20:13 -0400
>> Subject: Re: [R] packages for input messages
>> From: sarah.goslee at gmail.com
>> To: kicco1991 at hotmail.it
>> CC: r-help at r-project.org
>> 
>> It sounds like ?stop is what you're looking for.
>> 
>> Sarah
>> 
>> On Mon, Jun 24, 2013 at 4:50 PM, Francesco Miranda <kicco1991 at hotmail.it> wrote:
>>> Hello,I was trying to enter commands input messages or error within a routin.for example :  msg (consistency error: at the time ( j : generic time ) the lower quantile is not less than the upper quantile)
>>> thanks in advanceFrancesco Miranda
>> 
>> -- 
>> Sarah Goslee
>> http://www.functionaldiversity.org
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gundalav at gmail.com  Tue Jun 25 11:09:12 2013
From: gundalav at gmail.com (Gundala Viswanath)
Date: Tue, 25 Jun 2013 18:09:12 +0900
Subject: [R] How to include ifelse condition to adjust QPLOT font size
Message-ID: <CADVKSzwFs3SsjTvkNqOMgVbott6kjeoHz1VfdcHzfkGmK3fV0A@mail.gmail.com>

I have a data which I plot using this code.
Attached is the plot

_BEGIN_
library(ggplot2)
dat.m <- read.delim("http://dpaste.com/1269939/plain/",sep="")
colnames(dat.m) <- c("ensg","mirna_hgc","variable","value")
dat.m.y <- subset(dat.m,dat.m$variable=="y")
qplot(value,data=dat.m.y, geom="bar",  origin=-0.05,
xlim=c(48,101),ylim=c(0,75), facets=variable~.,main="")+
xlab("Value")+
ylab("Frequency")+
theme(legend.position="none")+
stat_bin(aes(label = sprintf("%.01f",
(..count../288)*100)),size=2.5,color="red", vjust=-0.5, angle=0,
geom="text")
__END__

What I wan't to do is to get rid of the barplot labels when the value in red
is 0.0.
How can I go about it?

I tried this but it won't work
stat_bin(aes(label = sprintf("%.01f",
(..count../288)*100)),size=ifelse(dat$m.y>0,2.5,0),color="red", vjust=-0.5,
angle=0, geom="text")
-------------- next part --------------
A non-text attachment was scrubbed...
Name: test.pdf
Type: application/pdf
Size: 41397 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/8257c29b/attachment.pdf>

From gundalav at gmail.com  Tue Jun 25 11:09:12 2013
From: gundalav at gmail.com (Gundala Viswanath)
Date: Tue, 25 Jun 2013 18:09:12 +0900
Subject: [R] How to include ifelse condition to adjust QPLOT font size
Message-ID: <CADVKSzwFs3SsjTvkNqOMgVbott6kjeoHz1VfdcHzfkGmK3fV0A@mail.gmail.com>

I have a data which I plot using this code.
Attached is the plot

_BEGIN_
library(ggplot2)
dat.m <- read.delim("http://dpaste.com/1269939/plain/",sep="")
colnames(dat.m) <- c("ensg","mirna_hgc","variable","value")
dat.m.y <- subset(dat.m,dat.m$variable=="y")
qplot(value,data=dat.m.y, geom="bar",  origin=-0.05,
xlim=c(48,101),ylim=c(0,75), facets=variable~.,main="")+
xlab("Value")+
ylab("Frequency")+
theme(legend.position="none")+
stat_bin(aes(label = sprintf("%.01f",
(..count../288)*100)),size=2.5,color="red", vjust=-0.5, angle=0,
geom="text")
__END__

What I wan't to do is to get rid of the barplot labels when the value in red
is 0.0.
How can I go about it?

I tried this but it won't work
stat_bin(aes(label = sprintf("%.01f",
(..count../288)*100)),size=ifelse(dat$m.y>0,2.5,0),color="red", vjust=-0.5,
angle=0, geom="text")
-------------- next part --------------
A non-text attachment was scrubbed...
Name: test.pdf
Type: application/pdf
Size: 41397 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/8257c29b/attachment-0001.pdf>

From ruipbarradas at sapo.pt  Tue Jun 25 11:21:48 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 25 Jun 2013 10:21:48 +0100
Subject: [R] x-labels in barplots
In-Reply-To: <20130625080332.125852shjhs4svjo@webmail.uniparthenope.it>
References: <20130625080332.125852shjhs4svjo@webmail.uniparthenope.it>
Message-ID: <51C9612C.7010704@sapo.pt>

Hello,

Use graphic parameter las = 2.
See the help for ?par.

Hope this helps,

Rui Barradas

Em 25-06-2013 07:03, alfonso.carfora at uniparthenope.it escreveu:
> Hi,
>
> I need to generate a barplot in in which the x-labels must to be
> perpendiculars to the x-axis
>
> in my data have a list of probability values correspondings to a list of
> Countries. In the barplot the name of each Country,  under each bar,
> appears parallel to the x axis. Is possibile rotate them so as to make
> them perpendicular to the x-axis
>
> barplot(fig1$Prob,names.arg=fig1$Country,ylab="probabilities",ylim=c(0,0.3))
>
>
> Thanks
> A.C.
>
>
>
> ******************************************************************************
>
> IL MERITO DEGLI STUDENTI VIENE RICONOSCIUTO
>
> Il 5 per mille all'Universita' degli Studi di Napoli "Parthenope"
> incrementa le borse di studio agli studenti - codice fiscale 80018240632
> http://www.uniparthenope.it/index.php/5xmille
> http://www.uniparthenope.it/index.php/it/avvisi-sito-di-ateneo/2943-la-parthenope-premia-il-tuo-voto-di-diploma-ed-il-tuo-imegno-con-i-proventi-del-5-per-mille
>
>
> Questa informativa e' inserita in automatico dal sistema al fine
> esclusivo della realizzazione dei fini istituzionali dell'ente.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nicomet80 at gmail.com  Tue Jun 25 11:34:29 2013
From: nicomet80 at gmail.com (Nico Met)
Date: Tue, 25 Jun 2013 11:34:29 +0200
Subject: [R] Fetch and merge from a data set
Message-ID: <CAMMD=S7MEr7S-diHzput4CNrPX2tqG5i7x3w3tL0Uw=rNQ3iCg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/69a040a6/attachment.pl>

From ruipbarradas at sapo.pt  Tue Jun 25 11:43:06 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 25 Jun 2013 10:43:06 +0100
Subject: [R] Fetch and merge from a data set
In-Reply-To: <CAMMD=S7MEr7S-diHzput4CNrPX2tqG5i7x3w3tL0Uw=rNQ3iCg@mail.gmail.com>
References: <CAMMD=S7MEr7S-diHzput4CNrPX2tqG5i7x3w3tL0Uw=rNQ3iCg@mail.gmail.com>
Message-ID: <51C9662A.5050106@sapo.pt>

Hello,

I'm not sure I understand, but it seems as simple as

merge(data1, data)


Hope this helps,

Rui Barradas

Em 25-06-2013 10:34, Nico Met escreveu:
> Dear all,
>
> I would like to fetch a list (data1) of entities from a big data file
> (data) and merged together. for example: data is the file from where I want
> to extract
>
> dput(data)
> structure(list(NAME = structure(c(6L, 6L, 7L, 6L, 6L, 7L, 6L,
> 7L, 3L, 5L, 3L, 3L, 3L, 3L, 4L, 3L, 3L, 4L, 3L, 3L, 3L, 3L, 1L,
> 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L), .Label = c("CDS0008_3",
> "CDS0008_9", "CDS0248_2", "CDS0248_3", "CDS0248_9", "CDS0644",
> "CDS0645"), class = "factor"), QUAL = structure(c(1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("CE",
> "IE", "IL", "NL"), class = "factor"), DIFF = c(-1.3998944145561,
> -3.2771509067793, -3281.07651466667, 8.4344933333332, 1.825,
> -0.584379415213178, -0.842892819141902, -7939.4442483333,
> 0.305343667019102,
> 11.4859716384148, 1242.72166499999, 33.2540033333333, -14.8333333333333,
> 62.8783807080717, 0.323435555555555, 3325.4720195, 33.8787927988058,
> -26.7723700000001, 58.5555555555556, 58.5555555555556, 0.0566947723248923,
> 1.29414722222222, -13.319016665, -18.2, -76.0081565999972, -13.319016665,
> -18.2, -13.319016665, -18.2, -2632.77274125, -42.6985227297727,
> -19.2272727272727, -640.535327886362), PVALUE = c(0.393708851005828,
> 0.213217899579307, 0.59042649939326, 0.874157227673879, 0.953482720079014,
> 0.737143165148719, 0.76195136190783, 0.27992628190224, 0.737143165148719,
> 0.76195136190783, 0.27992628190224, 0.672772547835936, 0.86918514824479,
> 0.86918514824479, 0.794677241773376, 0.67568899695407, 0.0792182671307693,
> 0.53713122011077, 0.298506678908869, 0.343822055403655, 0.962553162399683,
> 0.335590623453015, 0.962553162399683, 0.335590623453015, 0.966426100547593,
> 0.671619043425778, 0.225088848812347, 0.962553162399683, 0.335590623453015,
> 0.17524845367103, 0.205476355179601, 0.229212899348569, 0.739457737437997
> ), MEAD = c(61.997380489015, 38.9012158419308, 42541.899878,
> 644.342793333333, 58.8, 65.4391126224113, 45.1617170900398,
> 37470.3747366666,
> 61.6954795437718, 36.4397768557611, 26367.6229666667, 485.3921,
> 76, 0, 0.871720000000001, 28005.1589441667, 46.2203164422305,
> 713.029716666667, 64, 64, 23.0947770774977, 1.456775, 79.2102758175251,
> 39.5498022382743, 31387.15404, 883.475686666, 180, 76.8751996288758,
> 41.0701371024372, 23960.47775025, 746.3317500025, 104.5, 17488.00655825
> )), .Names = c("NAME", "QUAL", "DIFF", "PVALUE", "MEAD"), class = "data.frame",
> row.names = c(NA,
> 33L))
>
>
> And data1 : subset of entities
>
> dput(data1)
> structure(list(NAME = structure(c(5L, 4L, 2L, 3L, 1L), .Label = c("CDG981",
> "CDS0248_2", "CDS0248_9", "CDS0644", "CDS0645"), class = "factor"),
>      VAL = structure(c(1L, 2L, 5L, 3L, 4L), .Label = c("YU1",
>      "YU2", "YU4", "YU5", "YU7"), class = "factor")), .Names = c("NAME",
> "VAL"), class = "data.frame", row.names = c(NA, 5L))
>
>
> Please help me how can I do it.
>
> Many thanks
>
> Nico
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From nblaser at ispm.unibe.ch  Tue Jun 25 11:58:45 2013
From: nblaser at ispm.unibe.ch (Blaser Nello)
Date: Tue, 25 Jun 2013 11:58:45 +0200
Subject: [R] How to include ifelse condition to adjust QPLOT font size
In-Reply-To: <CADVKSzwFs3SsjTvkNqOMgVbott6kjeoHz1VfdcHzfkGmK3fV0A@mail.gmail.com>
References: <CADVKSzwFs3SsjTvkNqOMgVbott6kjeoHz1VfdcHzfkGmK3fV0A@mail.gmail.com>
Message-ID: <17EE8C62EA18B84B94C2BA96A143064C01721A82@mx01.ispm.unibe.ch>

If you want the size to depend on the data, then size needs to be inside
aes(...). For instance:
stat_bin(aes(label = sprintf("%.01f", (..count../288)*100),
size=ifelse(..count..>0, 2.5, 0)) ,color="red", vjust=-0.5, angle=0,
geom="text")

A better approach would be not to plot the unnecessary things at all.
This should do it:
stat_bin(aes(label = ifelse(..count..>0, sprintf("%.01f",
(..count../288)*100), "")), size=2.5,color="red", vjust=-0.5, angle=0,
geom="text")

Best, 
Nello


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
On Behalf Of Gundala Viswanath
Sent: Dienstag, 25. Juni 2013 11:09
To: r-help at r-project.org; r-help at stat.math.ethz.ch
Subject: [R] How to include ifelse condition to adjust QPLOT font size

I have a data which I plot using this code.
Attached is the plot

_BEGIN_
library(ggplot2)
dat.m <- read.delim("http://dpaste.com/1269939/plain/",sep="")
colnames(dat.m) <- c("ensg","mirna_hgc","variable","value")
dat.m.y <- subset(dat.m,dat.m$variable=="y") qplot(value,data=dat.m.y,
geom="bar",  origin=-0.05, xlim=c(48,101),ylim=c(0,75),
facets=variable~.,main="")+ xlab("Value")+ ylab("Frequency")+
theme(legend.position="none")+ stat_bin(aes(label = sprintf("%.01f",
(..count../288)*100)),size=2.5,color="red", vjust=-0.5, angle=0,
geom="text")
__END__

What I wan't to do is to get rid of the barplot labels when the value in
red is 0.0.
How can I go about it?

I tried this but it won't work
stat_bin(aes(label = sprintf("%.01f",
(..count../288)*100)),size=ifelse(dat$m.y>0,2.5,0),color="red",
vjust=-0.5, angle=0, geom="text")


From nblaser at ispm.unibe.ch  Tue Jun 25 11:58:45 2013
From: nblaser at ispm.unibe.ch (Blaser Nello)
Date: Tue, 25 Jun 2013 11:58:45 +0200
Subject: [R] How to include ifelse condition to adjust QPLOT font size
In-Reply-To: <CADVKSzwFs3SsjTvkNqOMgVbott6kjeoHz1VfdcHzfkGmK3fV0A@mail.gmail.com>
References: <CADVKSzwFs3SsjTvkNqOMgVbott6kjeoHz1VfdcHzfkGmK3fV0A@mail.gmail.com>
Message-ID: <17EE8C62EA18B84B94C2BA96A143064C01721A82@mx01.ispm.unibe.ch>

If you want the size to depend on the data, then size needs to be inside
aes(...). For instance:
stat_bin(aes(label = sprintf("%.01f", (..count../288)*100),
size=ifelse(..count..>0, 2.5, 0)) ,color="red", vjust=-0.5, angle=0,
geom="text")

A better approach would be not to plot the unnecessary things at all.
This should do it:
stat_bin(aes(label = ifelse(..count..>0, sprintf("%.01f",
(..count../288)*100), "")), size=2.5,color="red", vjust=-0.5, angle=0,
geom="text")

Best, 
Nello


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
On Behalf Of Gundala Viswanath
Sent: Dienstag, 25. Juni 2013 11:09
To: r-help at r-project.org; r-help at stat.math.ethz.ch
Subject: [R] How to include ifelse condition to adjust QPLOT font size

I have a data which I plot using this code.
Attached is the plot

_BEGIN_
library(ggplot2)
dat.m <- read.delim("http://dpaste.com/1269939/plain/",sep="")
colnames(dat.m) <- c("ensg","mirna_hgc","variable","value")
dat.m.y <- subset(dat.m,dat.m$variable=="y") qplot(value,data=dat.m.y,
geom="bar",  origin=-0.05, xlim=c(48,101),ylim=c(0,75),
facets=variable~.,main="")+ xlab("Value")+ ylab("Frequency")+
theme(legend.position="none")+ stat_bin(aes(label = sprintf("%.01f",
(..count../288)*100)),size=2.5,color="red", vjust=-0.5, angle=0,
geom="text")
__END__

What I wan't to do is to get rid of the barplot labels when the value in
red is 0.0.
How can I go about it?

I tried this but it won't work
stat_bin(aes(label = sprintf("%.01f",
(..count../288)*100)),size=ifelse(dat$m.y>0,2.5,0),color="red",
vjust=-0.5, angle=0, geom="text")


From nicomet80 at gmail.com  Tue Jun 25 12:00:23 2013
From: nicomet80 at gmail.com (Nico Met)
Date: Tue, 25 Jun 2013 12:00:23 +0200
Subject: [R] Fetch and merge from a data set
In-Reply-To: <51C9662A.5050106@sapo.pt>
References: <CAMMD=S7MEr7S-diHzput4CNrPX2tqG5i7x3w3tL0Uw=rNQ3iCg@mail.gmail.com>
	<51C9662A.5050106@sapo.pt>
Message-ID: <CAMMD=S5BCzoeCh=yME8pSvdqUb_17f4Sc+ds37GTwW-SJt6XAg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/c3a760b8/attachment.pl>

From rainer.schuermann at gmx.net  Tue Jun 25 12:18:20 2013
From: rainer.schuermann at gmx.net (Rainer Schuermann)
Date: Tue, 25 Jun 2013 12:18:20 +0200
Subject: [R] Fetch and merge from a data set
In-Reply-To: <CAMMD=S5BCzoeCh=yME8pSvdqUb_17f4Sc+ds37GTwW-SJt6XAg@mail.gmail.com>
References: <CAMMD=S7MEr7S-diHzput4CNrPX2tqG5i7x3w3tL0Uw=rNQ3iCg@mail.gmail.com>
	<51C9662A.5050106@sapo.pt>
	<CAMMD=S5BCzoeCh=yME8pSvdqUb_17f4Sc+ds37GTwW-SJt6XAg@mail.gmail.com>
Message-ID: <2713681.QfnQn7GHJh@augeatur>

Is 

merge( data[1], data1 )

what you want?




On Tuesday 25 June 2013 12:00:23 Nico Met wrote:
> Many thanks Rui,
> 
> However If I want to extract only first column (data1) from data file, then
> how Can I do it?
> 
> Thanks again
> 
> Nico
> 
> 
> On Tue, Jun 25, 2013 at 11:43 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
> > Hello,
> >
> > I'm not sure I understand, but it seems as simple as
> >
> > merge(data1, data)
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > Em 25-06-2013 10:34, Nico Met escreveu:
> >
> >> Dear all,
> >>
> >> I would like to fetch a list (data1) of entities from a big data file
> >> (data) and merged together. for example: data is the file from where I
> >> want
> >> to extract
> >>
> >> dput(data)
> >> structure(list(NAME = structure(c(6L, 6L, 7L, 6L, 6L, 7L, 6L,
> >> 7L, 3L, 5L, 3L, 3L, 3L, 3L, 4L, 3L, 3L, 4L, 3L, 3L, 3L, 3L, 1L,
> >> 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L), .Label = c("CDS0008_3",
> >> "CDS0008_9", "CDS0248_2", "CDS0248_3", "CDS0248_9", "CDS0644",
> >> "CDS0645"), class = "factor"), QUAL = structure(c(1L, 1L, 1L,
> >> 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L,
> >> 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("CE",
> >> "IE", "IL", "NL"), class = "factor"), DIFF = c(-1.3998944145561,
> >> -3.2771509067793, -3281.07651466667, 8.4344933333332, 1.825,
> >> -0.584379415213178, -0.842892819141902, -7939.4442483333,
> >> 0.305343667019102,
> >> 11.4859716384148, 1242.72166499999, 33.2540033333333, -14.8333333333333,
> >> 62.8783807080717, 0.323435555555555, 3325.4720195, 33.8787927988058,
> >> -26.7723700000001, 58.5555555555556, 58.5555555555556, 0.0566947723248923,
> >> 1.29414722222222, -13.319016665, -18.2, -76.0081565999972, -13.319016665,
> >> -18.2, -13.319016665, -18.2, -2632.77274125, -42.6985227297727,
> >> -19.2272727272727, -640.535327886362), PVALUE = c(0.393708851005828,
> >> 0.213217899579307, 0.59042649939326, 0.874157227673879, 0.953482720079014,
> >> 0.737143165148719, 0.76195136190783, 0.27992628190224, 0.737143165148719,
> >> 0.76195136190783, 0.27992628190224, 0.672772547835936, 0.86918514824479,
> >> 0.86918514824479, 0.794677241773376, 0.67568899695407, 0.0792182671307693,
> >> 0.53713122011077, 0.298506678908869, 0.343822055403655, 0.962553162399683,
> >> 0.335590623453015, 0.962553162399683, 0.335590623453015,
> >> 0.966426100547593,
> >> 0.671619043425778, 0.225088848812347, 0.962553162399683,
> >> 0.335590623453015,
> >> 0.17524845367103, 0.205476355179601, 0.229212899348569, 0.739457737437997
> >> ), MEAD = c(61.997380489015, 38.9012158419308, 42541.899878,
> >> 644.342793333333, 58.8, 65.4391126224113, 45.1617170900398,
> >> 37470.3747366666,
> >> 61.6954795437718, 36.4397768557611, 26367.6229666667, 485.3921,
> >> 76, 0, 0.871720000000001, 28005.1589441667, 46.2203164422305,
> >> 713.029716666667, 64, 64, 23.0947770774977, 1.456775, 79.2102758175251,
> >> 39.5498022382743, 31387.15404, 883.475686666, 180, 76.8751996288758,
> >> 41.0701371024372, 23960.47775025, 746.3317500025, 104.5, 17488.00655825
> >> )), .Names = c("NAME", "QUAL", "DIFF", "PVALUE", "MEAD"), class =
> >> "data.frame",
> >> row.names = c(NA,
> >> 33L))
> >>
> >>
> >> And data1 : subset of entities
> >>
> >> dput(data1)
> >> structure(list(NAME = structure(c(5L, 4L, 2L, 3L, 1L), .Label =
> >> c("CDG981",
> >> "CDS0248_2", "CDS0248_9", "CDS0644", "CDS0645"), class = "factor"),
> >>      VAL = structure(c(1L, 2L, 5L, 3L, 4L), .Label = c("YU1",
> >>      "YU2", "YU4", "YU5", "YU7"), class = "factor")), .Names = c("NAME",
> >> "VAL"), class = "data.frame", row.names = c(NA, 5L))
> >>
> >>
> >> Please help me how can I do it.
> >>
> >> Many thanks
> >>
> >> Nico
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________**________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
> >> PLEASE do read the posting guide http://www.R-project.org/**
> >> posting-guide.html <http://www.R-project.org/posting-guide.html>
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
- - - - -

Der NSA keine Chance: e-mail verschluesseln!
http://www.gpg4win.org/


From rh at knut-krueger.de  Tue Jun 25 12:21:29 2013
From: rh at knut-krueger.de (Knut Krueger)
Date: Tue, 25 Jun 2013 12:21:29 +0200
Subject: [R] any news about resetting last.warning -  warnings()
Message-ID: <51C96F29.9050105@knut-krueger.de>

Hi to all,
I need a possibility do delete the last warning to write the suitable 
warning  (not the last warning from minutes ago)  into a file.
I found a lot of treats but no really solution.

Regards Knut


From sorenh at math.aau.dk  Tue Jun 25 12:50:42 2013
From: sorenh at math.aau.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Tue, 25 Jun 2013 10:50:42 +0000
Subject: [R] Issue with Imports in NAMESPACE
Message-ID: <7E8037094A0C2146AA3E6F94DAE621C34454EC1F@AD-EXCHMBX2-1.aau.dk>

Dear all,
In my gRbase package I have up until now "Depend"-ed on RBGL (from Bioconductor), but good people have convinced me that I should use "Import"-it instead because I only use few functions from RBGL. 

In DESCRIPTION I therefore now have
Imports: Matrix,RBGL

In NAMESPACE I now have
importFrom(RBGL, maxClique, is.triangulated, separates)

The package compiles without complaints, but I have noticed that if I start a fresh R-session, then maxClique etc. from RBGL is NOT available for "interactive use" in my session:
> library(gRbase)
> maxClique
Error: object 'maxClique' not found

1) Is this as it should be? 

2) If yes, is there any other way in which maxClique can be imported for interactive use without Depend-ing the whole RBGL package?

Best regards
S?ren
 


From careyshan at gmail.com  Tue Jun 25 12:58:39 2013
From: careyshan at gmail.com (Shane Carey)
Date: Tue, 25 Jun 2013 11:58:39 +0100
Subject: [R] Calculate geometric mean with tapply
Message-ID: <CA+jRDxAw_PiJ8-z9C=J=r01S1QfWcSJJwUTUD5Y1u8khG9Z=CA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/401ff87f/attachment.pl>

From murdoch.duncan at gmail.com  Tue Jun 25 13:01:43 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 25 Jun 2013 07:01:43 -0400
Subject: [R] Issue with Imports in NAMESPACE
In-Reply-To: <7E8037094A0C2146AA3E6F94DAE621C34454EC1F@AD-EXCHMBX2-1.aau.dk>
References: <7E8037094A0C2146AA3E6F94DAE621C34454EC1F@AD-EXCHMBX2-1.aau.dk>
Message-ID: <51C97897.3070903@gmail.com>

On 13-06-25 6:50 AM, S?ren H?jsgaard wrote:
> Dear all,
> In my gRbase package I have up until now "Depend"-ed on RBGL (from Bioconductor), but good people have convinced me that I should use "Import"-it instead because I only use few functions from RBGL.
>
> In DESCRIPTION I therefore now have
> Imports: Matrix,RBGL
>
> In NAMESPACE I now have
> importFrom(RBGL, maxClique, is.triangulated, separates)
>
> The package compiles without complaints, but I have noticed that if I start a fresh R-session, then maxClique etc. from RBGL is NOT available for "interactive use" in my session:
>> library(gRbase)
>> maxClique
> Error: object 'maxClique' not found
>
> 1) Is this as it should be?
>
> 2) If yes, is there any other way in which maxClique can be imported for interactive use without Depend-ing the whole RBGL package?

The importFrom directive effectively makes local copies of those 
functions in your package (with the usual caveats that copies aren't as 
inefficient as you might think).  If you want to export them, you need 
to add them to the exports list.

Duncan Murdoch


From murdoch.duncan at gmail.com  Tue Jun 25 13:08:32 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 25 Jun 2013 07:08:32 -0400
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <1372123341449.dc8da696@Nodemailer>
References: <51C8CBCE.3040903@gmail.com> <1372123341449.dc8da696@Nodemailer>
Message-ID: <51C97A30.7050802@gmail.com>

On 13-06-24 9:22 PM, David Kulp wrote:
> Indeed, I misread / misunderstood. I think it's a difficult concept
> that's hard to explain and the example wasn't great. But thanks all for
> straightening me out!

It seems like a really natural definition to me, but I'm used to it. 
Once you get used to it you'll probably find it quite easy too.

It may be helpful not to worry about the technical details, just to look 
at the source code defining the function:  if it is defined in a place 
where a variable can be seen, it can see that variable.

Duncan Murdoch

> ?
> David Kulp
>
>
> On Mon, Jun 24, 2013 at 6:44 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>
>     On 13-06-24 4:27 PM, David Kulp wrote:
>      > According to
>     http://cran.r-project.org/doc/contrib/Fox-Companion/appendix-scope.pdf
>     and other examples online, I am to believe that R resolves variables
>     using lexical scoping by following the frames up the call stack.
>
>     You appear to have misread it. Lexical scoping follows the chain of
>     environments where functions were defined. It ignores the call stack.
>
>     Duncan Murdoch
>
>
>
>     However, that's not working for me. For example, the following code,
>     taken from the reference above fails instead of returning 7. What am I
>     doing wrong? Thanks!
>      >
>      > f <- function(x) { a<-5; g(x) }
>      > g <- function(y) { y + a }
>      > f(2)
>      > Error in g(x) : object 'a' not found
>      >
>      >
>      > [[alternative HTML version deleted]]
>      >
>      > ______________________________________________
>      > R-help at r-project.org mailing list
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>      >
>
>


From sorenh at math.aau.dk  Tue Jun 25 13:14:01 2013
From: sorenh at math.aau.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Tue, 25 Jun 2013 11:14:01 +0000
Subject: [R] Issue with Imports in NAMESPACE
In-Reply-To: <51C97897.3070903@gmail.com>
References: <7E8037094A0C2146AA3E6F94DAE621C34454EC1F@AD-EXCHMBX2-1.aau.dk>
	<51C97897.3070903@gmail.com>
Message-ID: <7E8037094A0C2146AA3E6F94DAE621C34454EC96@AD-EXCHMBX2-1.aau.dk>

Dear Duncan,

Excellent, thanks! 

Maybe this is worth a remark in a future version of "Writing R Extensions" (including that those "local copies" are not exported again with exportPattern("^[[:alpha:]]+")). 

Thanks!

S?ren

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: 25. juni 2013 13:02
To: S?ren H?jsgaard
Cc: R hELP (r-help at stat.math.ethz.ch)
Subject: Re: [R] Issue with Imports in NAMESPACE

On 13-06-25 6:50 AM, S?ren H?jsgaard wrote:
> Dear all,
> In my gRbase package I have up until now "Depend"-ed on RBGL (from Bioconductor), but good people have convinced me that I should use "Import"-it instead because I only use few functions from RBGL.
>
> In DESCRIPTION I therefore now have
> Imports: Matrix,RBGL
>
> In NAMESPACE I now have
> importFrom(RBGL, maxClique, is.triangulated, separates)
>
> The package compiles without complaints, but I have noticed that if I start a fresh R-session, then maxClique etc. from RBGL is NOT available for "interactive use" in my session:
>> library(gRbase)
>> maxClique
> Error: object 'maxClique' not found
>
> 1) Is this as it should be?
>
> 2) If yes, is there any other way in which maxClique can be imported for interactive use without Depend-ing the whole RBGL package?

The importFrom directive effectively makes local copies of those functions in your package (with the usual caveats that copies aren't as inefficient as you might think).  If you want to export them, you need to add them to the exports list.

Duncan Murdoch


From ruipbarradas at sapo.pt  Tue Jun 25 13:17:47 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 25 Jun 2013 12:17:47 +0100
Subject: [R] Calculate geometric mean with tapply
In-Reply-To: <CA+jRDxAw_PiJ8-z9C=J=r01S1QfWcSJJwUTUD5Y1u8khG9Z=CA@mail.gmail.com>
References: <CA+jRDxAw_PiJ8-z9C=J=r01S1QfWcSJJwUTUD5Y1u8khG9Z=CA@mail.gmail.com>
Message-ID: <51C97C5B.7090805@sapo.pt>

Hello,

You can write a function gmean and tapply it to your data.


gmean <- function(x, na.rm = FALSE){
	if(na.rm) x <- x[!is.na(x)]
	n <- length(x)
	prod(x)^(1/n)
}

tapply(data$value, data$group, gmean)


Hope this helps,

Rui Barradas

Em 25-06-2013 11:58, Shane Carey escreveu:
> Hi,
>
> I am trying to calculate the geometric mean with tapply. This is the
> formula I am using:
>
> exp(tapply(log(data$value), data$group, mean))
>
>
> However, it returns the arithmetic mean. Any ideas?
>
>
> Thanks
>
>


From murdoch.duncan at gmail.com  Tue Jun 25 13:19:12 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 25 Jun 2013 07:19:12 -0400
Subject: [R] Issue with Imports in NAMESPACE
In-Reply-To: <7E8037094A0C2146AA3E6F94DAE621C34454EC96@AD-EXCHMBX2-1.aau.dk>
References: <7E8037094A0C2146AA3E6F94DAE621C34454EC1F@AD-EXCHMBX2-1.aau.dk>
	<51C97897.3070903@gmail.com>
	<7E8037094A0C2146AA3E6F94DAE621C34454EC96@AD-EXCHMBX2-1.aau.dk>
Message-ID: <51C97CB0.1090500@gmail.com>

On 13-06-25 7:14 AM, S?ren H?jsgaard wrote:
> Dear Duncan,
>
> Excellent, thanks!
>
> Maybe this is worth a remark in a future version of "Writing R Extensions" (including that those "local copies" are not exported again with exportPattern("^[[:alpha:]]+")).

It is mentioned that they can be exported.  The fact that exportPattern 
doesn't see them might be a bug.

Duncan

>
> Thanks!
>
> S?ren
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: 25. juni 2013 13:02
> To: S?ren H?jsgaard
> Cc: R hELP (r-help at stat.math.ethz.ch)
> Subject: Re: [R] Issue with Imports in NAMESPACE
>
> On 13-06-25 6:50 AM, S?ren H?jsgaard wrote:
>> Dear all,
>> In my gRbase package I have up until now "Depend"-ed on RBGL (from Bioconductor), but good people have convinced me that I should use "Import"-it instead because I only use few functions from RBGL.
>>
>> In DESCRIPTION I therefore now have
>> Imports: Matrix,RBGL
>>
>> In NAMESPACE I now have
>> importFrom(RBGL, maxClique, is.triangulated, separates)
>>
>> The package compiles without complaints, but I have noticed that if I start a fresh R-session, then maxClique etc. from RBGL is NOT available for "interactive use" in my session:
>>> library(gRbase)
>>> maxClique
>> Error: object 'maxClique' not found
>>
>> 1) Is this as it should be?
>>
>> 2) If yes, is there any other way in which maxClique can be imported for interactive use without Depend-ing the whole RBGL package?
>
> The importFrom directive effectively makes local copies of those functions in your package (with the usual caveats that copies aren't as inefficient as you might think).  If you want to export them, you need to add them to the exports list.
>
> Duncan Murdoch
>


From careyshan at gmail.com  Tue Jun 25 13:24:51 2013
From: careyshan at gmail.com (Shane Carey)
Date: Tue, 25 Jun 2013 12:24:51 +0100
Subject: [R] Calculate geometric mean with tapply
In-Reply-To: <51C97C5B.7090805@sapo.pt>
References: <CA+jRDxAw_PiJ8-z9C=J=r01S1QfWcSJJwUTUD5Y1u8khG9Z=CA@mail.gmail.com>
	<51C97C5B.7090805@sapo.pt>
Message-ID: <CA+jRDxBpJ5EqANtN0McVyfpkJiNFKavtQmBhqSUWHfE96gv-2Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/3a538249/attachment.pl>

From vera.hinz at wiso.uni-hamburg.de  Tue Jun 25 13:56:20 2013
From: vera.hinz at wiso.uni-hamburg.de (Vera)
Date: Tue, 25 Jun 2013 04:56:20 -0700 (PDT)
Subject: [R] Problem with "dea.boot" under R 3.0.1
In-Reply-To: <1371728348586-4669964.post@n4.nabble.com>
References: <1371728348586-4669964.post@n4.nabble.com>
Message-ID: <1372161380161-4670271.post@n4.nabble.com>

... we used the following syntax:

b.x1a.y1<-dea.boot(x1a,y1,NREP=1000,RTS="vrs", ORIENTATION="in")


Vera



--
View this message in context: http://r.789695.n4.nabble.com/Problem-with-dea-boot-under-R-3-0-1-tp4669964p4670271.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Tue Jun 25 14:33:56 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 25 Jun 2013 05:33:56 -0700 (PDT)
Subject: [R] Fetch and merge from a data set
In-Reply-To: <CAMMD=S5BCzoeCh=yME8pSvdqUb_17f4Sc+ds37GTwW-SJt6XAg@mail.gmail.com>
References: <CAMMD=S7MEr7S-diHzput4CNrPX2tqG5i7x3w3tL0Uw=rNQ3iCg@mail.gmail.com>
	<51C9662A.5050106@sapo.pt>
	<CAMMD=S5BCzoeCh=yME8pSvdqUb_17f4Sc+ds37GTwW-SJt6XAg@mail.gmail.com>
Message-ID: <1372163636.56482.YahooMailNeo@web142606.mail.bf1.yahoo.com>

HI,
Try this:
merge(data,data1["NAME"])

A.K.



----- Original Message -----
From: Nico Met <nicomet80 at gmail.com>
To: Rui Barradas <ruipbarradas at sapo.pt>
Cc: R help <r-help at r-project.org>
Sent: Tuesday, June 25, 2013 6:00 AM
Subject: Re: [R] Fetch and merge from a merge(dat1["NAME"],dat2)
data set

Many thanks Rui,

However If I want to extract only first column (data1) from data file, then
how Can I do it?

Thanks again

Nico


On Tue, Jun 25, 2013 at 11:43 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> I'm not sure I understand, but it seems as simple as
>
> merge(data1, data)
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 25-06-2013 10:34, Nico Met escreveu:
>
>> Dear all,
>>
>> I would like to fetch a list (data1) of entities from a big data file
>> (data) and merged together. for example: data is the file from where I
>> want
>> to extract
>>
>> dput(data)
>> structure(list(NAME = structure(c(6L, 6L, 7L, 6L, 6L, 7L, 6L,
>> 7L, 3L, 5L, 3L, 3L, 3L, 3L, 4L, 3L, 3L, 4L, 3L, 3L, 3L, 3L, 1L,
>> 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L), .Label = c("CDS0008_3",
>> "CDS0008_9", "CDS0248_2", "CDS0248_3", "CDS0248_9", "CDS0644",
>> "CDS0645"), class = "factor"), QUAL = structure(c(1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("CE",
>> "IE", "IL", "NL"), class = "factor"), DIFF = c(-1.3998944145561,
>> -3.2771509067793, -3281.07651466667, 8.4344933333332, 1.825,
>> -0.584379415213178, -0.842892819141902, -7939.4442483333,
>> 0.305343667019102,
>> 11.4859716384148, 1242.72166499999, 33.2540033333333, -14.8333333333333,
>> 62.8783807080717, 0.323435555555555, 3325.4720195, 33.8787927988058,
>> -26.7723700000001, 58.5555555555556, 58.5555555555556, 0.0566947723248923,
>> 1.29414722222222, -13.319016665, -18.2, -76.0081565999972, -13.319016665,
>> -18.2, -13.319016665, -18.2, -2632.77274125, -42.6985227297727,
>> -19.2272727272727, -640.535327886362), PVALUE = c(0.393708851005828,
>> 0.213217899579307, 0.59042649939326, 0.874157227673879, 0.953482720079014,
>> 0.737143165148719, 0.76195136190783, 0.27992628190224, 0.737143165148719,
>> 0.76195136190783, 0.27992628190224, 0.672772547835936, 0.86918514824479,
>> 0.86918514824479, 0.794677241773376, 0.67568899695407, 0.0792182671307693,
>> 0.53713122011077, 0.298506678908869, 0.343822055403655, 0.962553162399683,
>> 0.335590623453015, 0.962553162399683, 0.335590623453015,
>> 0.966426100547593,
>> 0.671619043425778, 0.225088848812347, 0.962553162399683,
>> 0.335590623453015,
>> 0.17524845367103, 0.205476355179601, 0.229212899348569, 0.739457737437997
>> ), MEAD = c(61.997380489015, 38.9012158419308, 42541.899878,
>> 644.342793333333, 58.8, 65.4391126224113, 45.1617170900398,
>> 37470.3747366666,
>> 61.6954795437718, 36.4397768557611, 26367.6229666667, 485.3921,
>> 76, 0, 0.871720000000001, 28005.1589441667, 46.2203164422305,
>> 713.029716666667, 64, 64, 23.0947770774977, 1.456775, 79.2102758175251,
>> 39.5498022382743, 31387.15404, 883.475686666, 180, 76.8751996288758,
>> 41.0701371024372, 23960.47775025, 746.3317500025, 104.5, 17488.00655825
>> )), .Names = c("NAME", "QUAL", "DIFF", "PVALUE", "MEAD"), class =
>> "data.frame",
>> row.names = c(NA,
>> 33L))
>>
>>
>> And data1 : subset of entities
>>
>> dput(data1)
>> structure(list(NAME = structure(c(5L, 4L, 2L, 3L, 1L), .Label =
>> c("CDG981",
>> "CDS0248_2", "CDS0248_9", "CDS0644", "CDS0645"), class = "factor"),
>>? ? ? VAL = structure(c(1L, 2L, 5L, 3L, 4L), .Label = c("YU1",
>>? ? ? "YU2", "YU4", "YU5", "YU7"), class = "factor")), .Names = c("NAME",
>> "VAL"), class = "data.frame", row.names = c(NA, 5L))
>>
>>
>> Please help me how can I do it.
>>
>> Many thanks
>>
>> Nico
>>
>>? ? ? ?  [[alternative HTML version deleted]]
>>
>> ______________________________**________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/**
>> posting-guide.html <http://www.R-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From petr.pikal at precheza.cz  Tue Jun 25 14:50:04 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 25 Jun 2013 12:50:04 +0000
Subject: [R] Calculate geometric mean with tapply
In-Reply-To: <CA+jRDxBpJ5EqANtN0McVyfpkJiNFKavtQmBhqSUWHfE96gv-2Q@mail.gmail.com>
References: <CA+jRDxAw_PiJ8-z9C=J=r01S1QfWcSJJwUTUD5Y1u8khG9Z=CA@mail.gmail.com>
	<51C97C5B.7090805@sapo.pt>
	<CA+jRDxBpJ5EqANtN0McVyfpkJiNFKavtQmBhqSUWHfE96gv-2Q@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802810365@SRVEXCHMBX.precheza.cz>

Hm


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Shane Carey
> Sent: Tuesday, June 25, 2013 1:25 PM
> To: Rui Barradas
> Cc: r-help at r-project.org
> Subject: Re: [R] Calculate geometric mean with tapply
> 
> Thanks for your help, put I've tried that and it still gives me back
> the mean when I use it within tapply for some reason

can we believe it? Data, code please

> set.seed(111)
> x<-rnorm(10)
> mean(x)
[1] -0.6690135
> gmean(x)
[1] 0.4985282
> tapply(vysled$gamapoml, vysled$vzorek, mean)
  vz2   vz4   vz6 
341.0 343.0 332.4 
> tapply(vysled$gamapoml, vysled$vzorek, gmean)
     vz2      vz4      vz6 
340.5418 342.6154 332.2701 
>

I get different result for mean and gmean within tapply my data.

Regards
Petr
> 
> 
> On Tue, Jun 25, 2013 at 12:17 PM, Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
> 
> > Hello,
> >
> > You can write a function gmean and tapply it to your data.
> >
> >
> > gmean <- function(x, na.rm = FALSE){
> >         if(na.rm) x <- x[!is.na(x)]
> >         n <- length(x)
> >         prod(x)^(1/n)
> > }
> >
> > tapply(data$value, data$group, gmean)
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > Em 25-06-2013 11:58, Shane Carey escreveu:
> >
> >  Hi,
> >>
> >> I am trying to calculate the geometric mean with tapply. This is the
> >> formula I am using:
> >>
> >> exp(tapply(log(data$value), data$group, mean))
> >>
> >>
> >> However, it returns the arithmetic mean. Any ideas?
> >>
> >>
> >> Thanks
> >>
> >>
> >>
> 
> 
> --
> Shane
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From albin.blaschka at standortsanalyse.net  Tue Jun 25 15:05:37 2013
From: albin.blaschka at standortsanalyse.net (Albin Blaschka)
Date: Tue, 25 Jun 2013 15:05:37 +0200
Subject: [R] SP package
In-Reply-To: <51C946A9.6070804@sapo.pt>
References: <CAJpFpjUXvw2nV5F4r0NiBk1OOw26p7_hfMCGYyLNVzGCrRSKjg@mail.gmail.com>
	<51C946A9.6070804@sapo.pt>
Message-ID: <51C995A1.2090801@standortsanalyse.net>

Hello,

or, simply input at the R-prompt

point.in.polygon

- without any brackets or so, but with the sp-package loaded...?

HTH,
Albin

Am 25.06.2013 09:28, schrieb Rui Barradas:
> Hello,
>
> R is open source. You can download the source code for package sp.
>
> http://cran.r-project.org/web/packages/sp/index.html
>
> Hope this helps,
>
> Rui Barradas
>
> Em 25-06-2013 08:06, Dr. Alireza Zolfaghari escreveu:
>> Hi list,
>> I would like to write the function [R_point_in_polygon_sp] in c# as I
>> found it a very efficiently written code due to its high speed
>> calculation. I queried the function name by using
>> sp::point.in.polygon, but could not get source code. Would someone let
>> me know how to get the source code please?
>> Thanks
>> Alireza
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
| Albin Blaschka, Mag.rer.nat.
| Etrichstrasse 26, A-5020 Salzburg
| * www.albinblaschka.info * www.thinkanimal.info *
| - It's hard to live in the mountains, hard but not hopeless!


From jvadams at usgs.gov  Tue Jun 25 15:13:25 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 25 Jun 2013 08:13:25 -0500
Subject: [R] Calculating an index of colocation for a large dataset
In-Reply-To: <51C8DFDD.8020402@alaska.edu>
References: <1371853137063-4670084.post@n4.nabble.com>
	<CAN5YmCHCgmZDAUZTDkXAB45rm92wRh2Cf=_FyMLUi0E4a+jPVA@mail.gmail.com>
	<51C8DFDD.8020402@alaska.edu>
Message-ID: <CAN5YmCF4ym3qXnP3U3s6HH3bUXk6bsiD6HhZESWfbfX6a=_1Kg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/a8e2196b/attachment.pl>

From chiefmurphy at gmail.com  Tue Jun 25 15:32:31 2013
From: chiefmurphy at gmail.com (Dan Murphy)
Date: Tue, 25 Jun 2013 06:32:31 -0700
Subject: [R] do.call environment misunderstanding
Message-ID: <CAHgH9_Fdbb7N1DZ91ExF7H0xca1Ngg7egT+XQzfmPprtaKKUHg@mail.gmail.com>

I am having difficulty understanding the envir argument of do.call.
The help page says

envir  an environment within which to evaluate the call.

so I thought that in the following toy example x would be found in the
environment e and f would return 4 via do.call:

> e <- new.env()
> e$x <- 2
> f <- function() x^2
> do.call(f, list(), envir = e)
Error in (function ()  : object 'x' not found

Thanks in advance for clarifying my misunderstanding.

Dan Murphy


From jvadams at usgs.gov  Tue Jun 25 15:34:04 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 25 Jun 2013 08:34:04 -0500
Subject: [R] Unique matching of two sets of multidimensional data
In-Reply-To: <0099ABD4BC918242913DF056851DA1FF53BB0B40@Donphan.world.ssd.loral.com>
References: <0099ABD4BC918242913DF056851DA1FF53BB0B40@Donphan.world.ssd.loral.com>
Message-ID: <CAN5YmCHy68q5-ESpmwf3wpd5_NQD8kqcsJKZ_DfyEz7c4UAW7Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/5e5da037/attachment.pl>

From girijagun at gmail.com  Tue Jun 25 14:35:15 2013
From: girijagun at gmail.com (G Girija)
Date: Tue, 25 Jun 2013 18:05:15 +0530
Subject: [R] error in VaR calculation
Message-ID: <CAOLvsEzofnwHAf8A-CcsKVKSb7Wd_v5FYPia0Zvn82XsJy1-xw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/764842b9/attachment.pl>

From girijagun at gmail.com  Tue Jun 25 14:39:55 2013
From: girijagun at gmail.com (G Girija)
Date: Tue, 25 Jun 2013 18:09:55 +0530
Subject: [R] error in VaR calculation
Message-ID: <CAOLvsExjoCZgPHtJeEZzQvH0qX+ENcsV-SeRC3Fd77xutSAppA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/ebec307e/attachment.pl>

From murdoch.duncan at gmail.com  Tue Jun 25 15:49:05 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 25 Jun 2013 09:49:05 -0400
Subject: [R] do.call environment misunderstanding
In-Reply-To: <CAHgH9_Fdbb7N1DZ91ExF7H0xca1Ngg7egT+XQzfmPprtaKKUHg@mail.gmail.com>
References: <CAHgH9_Fdbb7N1DZ91ExF7H0xca1Ngg7egT+XQzfmPprtaKKUHg@mail.gmail.com>
Message-ID: <51C99FD1.1010802@gmail.com>

On 25/06/2013 9:32 AM, Dan Murphy wrote:
> I am having difficulty understanding the envir argument of do.call.
> The help page says
>
> envir  an environment within which to evaluate the call.
>
> so I thought that in the following toy example x would be found in the
> environment e and f would return 4 via do.call:
>
> > e <- new.env()
> > e$x <- 2
> > f <- function() x^2
> > do.call(f, list(), envir = e)
> Error in (function ()  : object 'x' not found
>
> Thanks in advance for clarifying my misunderstanding.

do.call will construct the expression f(), then evaluate it in e. It 
will try to look up f there, and not finding it, will go to the parent 
environment and find it.

When evaluating the function, the environment in which it was evaluated 
is used for looking up arguments, but f() has none, so e is not used at 
all.  R will use the environment attached to f, which is the global 
environment, since you created f by evaluating its definition there.

To get what you want, you could use the sequence

e <- new.env()
e$x <- 2
f <- function() x^2
environment(f) <- e
f()

An alternative way to do the 3rd and 4th lines is

f <- with(e, function() x^2)

because that would evaluate the creation of f within e.

A third approach (which might be the nicest one, depending on what else 
you are doing) is never to name e:

f <- local({
   x <- 2
   function() x^2
})

Duncan Murdoch


From luke-tierney at uiowa.edu  Tue Jun 25 15:50:23 2013
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Tue, 25 Jun 2013 08:50:23 -0500
Subject: [R] Issue with Imports in NAMESPACE
In-Reply-To: <51C97CB0.1090500@gmail.com>
References: <7E8037094A0C2146AA3E6F94DAE621C34454EC1F@AD-EXCHMBX2-1.aau.dk>
	<51C97897.3070903@gmail.com>
	<7E8037094A0C2146AA3E6F94DAE621C34454EC96@AD-EXCHMBX2-1.aau.dk>
	<51C97CB0.1090500@gmail.com>
Message-ID: <alpine.DEB.2.02.1306250846510.2246@luke-Latitude>

On Tue, 25 Jun 2013, Duncan Murdoch wrote:

> On 13-06-25 7:14 AM, S?ren H?jsgaard wrote:
>> Dear Duncan,
>> 
>> Excellent, thanks!
>> 
>> Maybe this is worth a remark in a future version of "Writing R Extensions" 
>> (including that those "local copies" are not exported again with 
>> exportPattern("^[[:alpha:]]+")).
>
> It is mentioned that they can be exported.  The fact that exportPattern 
> doesn't see them might be a bug.

I don't think it's a bug -- including all imports would usually bring
in way too much.

In general re-exporting is probably not such a great idea since the
help system isn't aware of the import/export chain. I don't know if R
CMD check complains if you don't provide your own help page; if it
doesn't it probably should.  I also don't recall if we have a
mechanism for such a help page on an import/export to just link to the
real page.

Best,

luke


>
> Duncan
>
>> 
>> Thanks!
>> 
>> S?ren
>> 
>> -----Original Message-----
>> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>> Sent: 25. juni 2013 13:02
>> To: S?ren H?jsgaard
>> Cc: R hELP (r-help at stat.math.ethz.ch)
>> Subject: Re: [R] Issue with Imports in NAMESPACE
>> 
>> On 13-06-25 6:50 AM, S?ren H?jsgaard wrote:
>>> Dear all,
>>> In my gRbase package I have up until now "Depend"-ed on RBGL (from 
>>> Bioconductor), but good people have convinced me that I should use 
>>> "Import"-it instead because I only use few functions from RBGL.
>>> 
>>> In DESCRIPTION I therefore now have
>>> Imports: Matrix,RBGL
>>> 
>>> In NAMESPACE I now have
>>> importFrom(RBGL, maxClique, is.triangulated, separates)
>>> 
>>> The package compiles without complaints, but I have noticed that if I 
>>> start a fresh R-session, then maxClique etc. from RBGL is NOT available 
>>> for "interactive use" in my session:
>>>> library(gRbase)
>>>> maxClique
>>> Error: object 'maxClique' not found
>>> 
>>> 1) Is this as it should be?
>>> 
>>> 2) If yes, is there any other way in which maxClique can be imported for 
>>> interactive use without Depend-ing the whole RBGL package?
>> 
>> The importFrom directive effectively makes local copies of those functions 
>> in your package (with the usual caveats that copies aren't as inefficient 
>> as you might think).  If you want to export them, you need to add them to 
>> the exports list.
>> 
>> Duncan Murdoch
>> 
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From mtmorgan at fhcrc.org  Tue Jun 25 15:53:20 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 25 Jun 2013 15:53:20 +0200
Subject: [R] Issue with Imports in NAMESPACE
In-Reply-To: <51C97CB0.1090500@gmail.com>
References: <7E8037094A0C2146AA3E6F94DAE621C34454EC1F@AD-EXCHMBX2-1.aau.dk>
	<51C97897.3070903@gmail.com>
	<7E8037094A0C2146AA3E6F94DAE621C34454EC96@AD-EXCHMBX2-1.aau.dk>
	<51C97CB0.1090500@gmail.com>
Message-ID: <51C9A0D0.9020004@fhcrc.org>

On 06/25/2013 01:19 PM, Duncan Murdoch wrote:
> On 13-06-25 7:14 AM, S?ren H?jsgaard wrote:
>> Dear Duncan,
>>
>> Excellent, thanks!
>>
>> Maybe this is worth a remark in a future version of "Writing R Extensions"
>> (including that those "local copies" are not exported again with
>> exportPattern("^[[:alpha:]]+")).
>
> It is mentioned that they can be exported.  The fact that exportPattern doesn't
> see them might be a bug.

In some ways I would have expected R CMD check to complain that maxClique was 
not documented, because after all the user can have access to maxClique (after 
library(gRbase)) but not have access to it's documentation

 > library(PkgA) ## Imports: RBGL; importFrom(RBGL, maxClique); export(maxClique)
 > ?maxClique
No documentation for 'maxClique' in specified packages and libraries:
you could try '??maxClique'
 > R.version.string
[1] "R Under development (unstable) (2013-06-25 r63053)"

Personally, if the intention is to make functionality of RBGL available to the 
end user (even a small part) then I would have Depends: RBGL. Regardless of 
whether RBGL appears in the Depends: or Imports: field of the DESCRIPTION, I
would have import'ed maxClique into the gRbase name space (so that function 
resolution occurs correctly within the package, even when gRbase is import'ed 
into another package). Having two apparent ways of arriving at the same function 
(gRbase::maxClique, RBGL::maxClique) seems to be inviting confusion.

Martin

>
> Duncan
>
>>
>> Thanks!
>>
>> S?ren
>>
>> -----Original Message-----
>> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>> Sent: 25. juni 2013 13:02
>> To: S?ren H?jsgaard
>> Cc: R hELP (r-help at stat.math.ethz.ch)
>> Subject: Re: [R] Issue with Imports in NAMESPACE
>>
>> On 13-06-25 6:50 AM, S?ren H?jsgaard wrote:
>>> Dear all,
>>> In my gRbase package I have up until now "Depend"-ed on RBGL (from
>>> Bioconductor), but good people have convinced me that I should use
>>> "Import"-it instead because I only use few functions from RBGL.
>>>
>>> In DESCRIPTION I therefore now have
>>> Imports: Matrix,RBGL
>>>
>>> In NAMESPACE I now have
>>> importFrom(RBGL, maxClique, is.triangulated, separates)
>>>
>>> The package compiles without complaints, but I have noticed that if I start a
>>> fresh R-session, then maxClique etc. from RBGL is NOT available for
>>> "interactive use" in my session:
>>>> library(gRbase)
>>>> maxClique
>>> Error: object 'maxClique' not found
>>>
>>> 1) Is this as it should be?
>>>
>>> 2) If yes, is there any other way in which maxClique can be imported for
>>> interactive use without Depend-ing the whole RBGL package?
>>
>> The importFrom directive effectively makes local copies of those functions in
>> your package (with the usual caveats that copies aren't as inefficient as you
>> might think).  If you want to export them, you need to add them to the exports
>> list.
>>
>> Duncan Murdoch
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From careyshan at gmail.com  Tue Jun 25 15:59:25 2013
From: careyshan at gmail.com (Shane Carey)
Date: Tue, 25 Jun 2013 14:59:25 +0100
Subject: [R] Calculate geometric mean with tapply
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802810365@SRVEXCHMBX.precheza.cz>
References: <CA+jRDxAw_PiJ8-z9C=J=r01S1QfWcSJJwUTUD5Y1u8khG9Z=CA@mail.gmail.com>
	<51C97C5B.7090805@sapo.pt>
	<CA+jRDxBpJ5EqANtN0McVyfpkJiNFKavtQmBhqSUWHfE96gv-2Q@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802810365@SRVEXCHMBX.precheza.cz>
Message-ID: <CA+jRDxAKOtAke09A-ycVYHtPjxsNz9dVJkSHkfocYUF_kiYg2w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/941923cd/attachment.pl>

From sorenh at math.aau.dk  Tue Jun 25 16:03:05 2013
From: sorenh at math.aau.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Tue, 25 Jun 2013 14:03:05 +0000
Subject: [R] Issue with Imports in NAMESPACE
In-Reply-To: <alpine.DEB.2.02.1306250846510.2246@luke-Latitude>
References: <7E8037094A0C2146AA3E6F94DAE621C34454EC1F@AD-EXCHMBX2-1.aau.dk>
	<51C97897.3070903@gmail.com>
	<7E8037094A0C2146AA3E6F94DAE621C34454EC96@AD-EXCHMBX2-1.aau.dk>
	<51C97CB0.1090500@gmail.com>
	<alpine.DEB.2.02.1306250846510.2246@luke-Latitude>
Message-ID: <7E8037094A0C2146AA3E6F94DAE621C34454EE46@AD-EXCHMBX2-1.aau.dk>

R CMD check does complain and I had to add \alias{maxClique} in an .Rd file (I did it this way to prevent downstream packages from failing).
Regards
S?ren


-----Original Message-----
From: luke-tierney at uiowa.edu [mailto:luke-tierney at uiowa.edu] 
Sent: 25. juni 2013 15:50
To: Duncan Murdoch
Cc: S?ren H?jsgaard; R hELP (r-help at stat.math.ethz.ch)
Subject: Re: [R] Issue with Imports in NAMESPACE

On Tue, 25 Jun 2013, Duncan Murdoch wrote:

> On 13-06-25 7:14 AM, S?ren H?jsgaard wrote:
>> Dear Duncan,
>> 
>> Excellent, thanks!
>> 
>> Maybe this is worth a remark in a future version of "Writing R Extensions" 
>> (including that those "local copies" are not exported again with 
>> exportPattern("^[[:alpha:]]+")).
>
> It is mentioned that they can be exported.  The fact that 
> exportPattern doesn't see them might be a bug.

I don't think it's a bug -- including all imports would usually bring in way too much.

In general re-exporting is probably not such a great idea since the help system isn't aware of the import/export chain. I don't know if R CMD check complains if you don't provide your own help page; if it doesn't it probably should.  I also don't recall if we have a mechanism for such a help page on an import/export to just link to the real page.

Best,

luke


>
> Duncan
>
>> 
>> Thanks!
>> 
>> S?ren
>> 
>> -----Original Message-----
>> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>> Sent: 25. juni 2013 13:02
>> To: S?ren H?jsgaard
>> Cc: R hELP (r-help at stat.math.ethz.ch)
>> Subject: Re: [R] Issue with Imports in NAMESPACE
>> 
>> On 13-06-25 6:50 AM, S?ren H?jsgaard wrote:
>>> Dear all,
>>> In my gRbase package I have up until now "Depend"-ed on RBGL (from 
>>> Bioconductor), but good people have convinced me that I should use 
>>> "Import"-it instead because I only use few functions from RBGL.
>>> 
>>> In DESCRIPTION I therefore now have
>>> Imports: Matrix,RBGL
>>> 
>>> In NAMESPACE I now have
>>> importFrom(RBGL, maxClique, is.triangulated, separates)
>>> 
>>> The package compiles without complaints, but I have noticed that if 
>>> I start a fresh R-session, then maxClique etc. from RBGL is NOT 
>>> available for "interactive use" in my session:
>>>> library(gRbase)
>>>> maxClique
>>> Error: object 'maxClique' not found
>>> 
>>> 1) Is this as it should be?
>>> 
>>> 2) If yes, is there any other way in which maxClique can be imported 
>>> for interactive use without Depend-ing the whole RBGL package?
>> 
>> The importFrom directive effectively makes local copies of those 
>> functions in your package (with the usual caveats that copies aren't 
>> as inefficient as you might think).  If you want to export them, you 
>> need to add them to the exports list.
>> 
>> Duncan Murdoch
>> 
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

--
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From bogaso.christofer at gmail.com  Tue Jun 25 16:28:21 2013
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Tue, 25 Jun 2013 19:58:21 +0530
Subject: [R] A question on vector
Message-ID: <CA+dpOJkry8hP2-GBsTPbhxiz9v=jiYvnSLFyq_Y-R2UynTT6uA@mail.gmail.com>

Hello again,

I have found that, in a vector if many elements have same names then
calling those elements with their names does not look complete. Here
is 1 example:

My_Vector <- c("a" = 'a', "a" = 'b')


then,

> My_Vector['a']
  a
"a"


I was expecting both elements should be shown up.

Is there any mechanism to force R do that?

Thanks and regards,


From dcarlson at tamu.edu  Tue Jun 25 16:47:58 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Tue, 25 Jun 2013 09:47:58 -0500
Subject: [R] A question on vector
In-Reply-To: <CA+dpOJkry8hP2-GBsTPbhxiz9v=jiYvnSLFyq_Y-R2UynTT6uA@mail.gmail.com>
References: <CA+dpOJkry8hP2-GBsTPbhxiz9v=jiYvnSLFyq_Y-R2UynTT6uA@mail.gmail.com>
Message-ID: <053601ce71b2$fbcfcca0$f36f65e0$@tamu.edu>

My_Vector[names(My_Vector)=="a"]

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Christofer Bogaso
Sent: Tuesday, June 25, 2013 9:28 AM
To: r-help
Subject: [R] A question on vector

Hello again,

I have found that, in a vector if many elements have same names then
calling those elements with their names does not look complete. Here
is 1 example:

My_Vector <- c("a" = 'a', "a" = 'b')


then,

> My_Vector['a']
  a
"a"


I was expecting both elements should be shown up.

Is there any mechanism to force R do that?

Thanks and regards,

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From josh.m.ulrich at gmail.com  Tue Jun 25 16:48:37 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Tue, 25 Jun 2013 09:48:37 -0500
Subject: [R] error in VaR calculation
In-Reply-To: <CAOLvsEzofnwHAf8A-CcsKVKSb7Wd_v5FYPia0Zvn82XsJy1-xw@mail.gmail.com>
References: <CAOLvsEzofnwHAf8A-CcsKVKSb7Wd_v5FYPia0Zvn82XsJy1-xw@mail.gmail.com>
Message-ID: <CAPPM_gQyj6tyrgN=uUi6fP=Tsxs+PC98c+XGbJGZWf7v+FFG3A@mail.gmail.com>

r != R (you mis-typed the first argument to VaR).  This works:

library(PerformanceAnalytics)
data(sample_matrix)
x <- Return.calculate(as.xts(sample_matrix))
VaR(R=x, p=0.99, method="historical")

Best,
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


On Tue, Jun 25, 2013 at 7:35 AM, G Girija <girijagun at gmail.com> wrote:
> The code is as follows:
>
>
>
> monthreturns<-read.zoo('monthlyReturn date.csv',sep=",",header=T)
>
> monthreturns<-as.xts(monthreturns,order.by
> =index(monthreturns),frequency=NULL)*W0
>
> head(monthreturns)
>
> dim(monthreturns)
>
>
>
> portnames<-c('acc','cipla','cmc','idbi','ifci')  ----portfolio names (5
> stocks)
>
> mu.vec<-c(0.1,0.2,0.2,0.4,0.1)
>
> names(mu.vec)<-portnames
>
> covmatr<-cov(monthreturns,use='complete')
>
> sigma.matr<-sqrt(covmatr)
>
> head(sigma.matr)
>
> dim(sigma.matr)
>
>
>
> library(PerformanceAnalytics)
>
> VaR(r=monnthreturns,p=0.99,method='historical',mu=mu.vec,sigma=sigma.matr,weights=NULL)*W0
>
>
>
> *But here I am getting the following error: *
>
>>
> VaR(r=monnthreturns,p=0.99,method='historical',mu=mu.vec,sigma=sigma.matr,weights=NULL)*W0
>
> Error in VaR(r = monnthreturns, p = 0.99, method = "historical", mu =
> mu.vec,  :
>
>   number of items in weights not equal to number of items in the mean vector
>
> * *
>
> *could anyone help*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From careyshan at gmail.com  Tue Jun 25 16:53:59 2013
From: careyshan at gmail.com (Shane Carey)
Date: Tue, 25 Jun 2013 15:53:59 +0100
Subject: [R] creat raster from XYZ
Message-ID: <CA+jRDxD=x+CHu_LC=w2XyjSdX=y9y+Ys99wXJPA4kb5OgkdmnQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/b57762bd/attachment.pl>

From smartpink111 at yahoo.com  Tue Jun 25 17:13:50 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 25 Jun 2013 08:13:50 -0700 (PDT)
Subject: [R] Calculate geometric mean with tapply
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802810365@SRVEXCHMBX.precheza.cz>
References: <CA+jRDxAw_PiJ8-z9C=J=r01S1QfWcSJJwUTUD5Y1u8khG9Z=CA@mail.gmail.com>
	<51C97C5B.7090805@sapo.pt>
	<CA+jRDxBpJ5EqANtN0McVyfpkJiNFKavtQmBhqSUWHfE96gv-2Q@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802810365@SRVEXCHMBX.precheza.cz>
Message-ID: <1372173230.54328.YahooMailNeo@web142603.mail.bf1.yahoo.com>

May be this also works:

?exp(mean(log(abs(x))))
#[1] 0.4985282
A.K.



----- Original Message -----
From: PIKAL Petr <petr.pikal at precheza.cz>
To: Shane Carey <careyshan at gmail.com>
Cc: "r-help at r-project.org" <r-help at r-project.org>
Sent: Tuesday, June 25, 2013 8:50 AM
Subject: Re: [R] Calculate geometric mean with tapply

Hm


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Shane Carey
> Sent: Tuesday, June 25, 2013 1:25 PM
> To: Rui Barradas
> Cc: r-help at r-project.org
> Subject: Re: [R] Calculate geometric mean with tapply
> 
> Thanks for your help, put I've tried that and it still gives me back
> the mean when I use it within tapply for some reason

can we believe it? Data, code please

> set.seed(111)
> x<-rnorm(10)
> mean(x)
[1] -0.6690135
> gmean(x)
[1] 0.4985282
> tapply(vysled$gamapoml, vysled$vzorek, mean)
? vz2?  vz4?  vz6 
341.0 343.0 332.4 
> tapply(vysled$gamapoml, vysled$vzorek, gmean)
? ?  vz2? ? ? vz4? ? ? vz6 
340.5418 342.6154 332.2701 
>

I get different result for mean and gmean within tapply my data.

Regards
Petr
> 
> 
> On Tue, Jun 25, 2013 at 12:17 PM, Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
> 
> > Hello,
> >
> > You can write a function gmean and tapply it to your data.
> >
> >
> > gmean <- function(x, na.rm = FALSE){
> >? ? ? ?  if(na.rm) x <- x[!is.na(x)]
> >? ? ? ?  n <- length(x)
> >? ? ? ?  prod(x)^(1/n)
> > }
> >
> > tapply(data$value, data$group, gmean)
> >
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > Em 25-06-2013 11:58, Shane Carey escreveu:
> >
> >? Hi,
> >>
> >> I am trying to calculate the geometric mean with tapply. This is the
> >> formula I am using:
> >>
> >> exp(tapply(log(data$value), data$group, mean))
> >>
> >>
> >> However, it returns the arithmetic mean. Any ideas?
> >>
> >>
> >> Thanks
> >>
> >>
> >>
> 
> 
> --
> Shane
> 
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ripley at stats.ox.ac.uk  Tue Jun 25 17:36:08 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 25 Jun 2013 16:36:08 +0100
Subject: [R] Issue with Imports in NAMESPACE
In-Reply-To: <alpine.DEB.2.02.1306250846510.2246@luke-Latitude>
References: <7E8037094A0C2146AA3E6F94DAE621C34454EC1F@AD-EXCHMBX2-1.aau.dk>
	<51C97897.3070903@gmail.com>
	<7E8037094A0C2146AA3E6F94DAE621C34454EC96@AD-EXCHMBX2-1.aau.dk>
	<51C97CB0.1090500@gmail.com>
	<alpine.DEB.2.02.1306250846510.2246@luke-Latitude>
Message-ID: <51C9B8E8.6030008@stats.ox.ac.uk>

On 25/06/2013 14:50, luke-tierney at uiowa.edu wrote:
> On Tue, 25 Jun 2013, Duncan Murdoch wrote:
>
>> On 13-06-25 7:14 AM, S?ren H?jsgaard wrote:
>>> Dear Duncan,
>>>
>>> Excellent, thanks!
>>>
>>> Maybe this is worth a remark in a future version of "Writing R
>>> Extensions" (including that those "local copies" are not exported
>>> again with exportPattern("^[[:alpha:]]+")).
>>
>> It is mentioned that they can be exported.  The fact that
>> exportPattern doesn't see them might be a bug.
>
> I don't think it's a bug -- including all imports would usually bring
> in way too much.

Not least as most packages import way too much (they import whole 
packages unselectively).

Namespace scoping helps a lot with code in packages, but not with code 
in examples and demos.  I believe that if you want to use maxClique from 
RBGL other than in the package's own functions you should either use 
RBGL::maxclique or put RBGL on the search path: but I don't think gRbase 
should do it for you.

> In general re-exporting is probably not such a great idea since the
> help system isn't aware of the import/export chain. I don't know if R
> CMD check complains if you don't provide your own help page; if it

It does, as S?ren found out when he submitted to CRAN.

> doesn't it probably should.  I also don't recall if we have a
> mechanism for such a help page on an import/export to just link to the
> real page.

We do, the \link[RBGL]{maxClique} form.

>
> Best,
>
> luke
>
>
>>
>> Duncan
>>
>>>
>>> Thanks!
>>>
>>> S?ren
>>>
>>> -----Original Message-----
>>> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>>> Sent: 25. juni 2013 13:02
>>> To: S?ren H?jsgaard
>>> Cc: R hELP (r-help at stat.math.ethz.ch)
>>> Subject: Re: [R] Issue with Imports in NAMESPACE
>>>
>>> On 13-06-25 6:50 AM, S?ren H?jsgaard wrote:
>>>> Dear all,
>>>> In my gRbase package I have up until now "Depend"-ed on RBGL (from
>>>> Bioconductor), but good people have convinced me that I should use
>>>> "Import"-it instead because I only use few functions from RBGL.
>>>>
>>>> In DESCRIPTION I therefore now have
>>>> Imports: Matrix,RBGL
>>>>
>>>> In NAMESPACE I now have
>>>> importFrom(RBGL, maxClique, is.triangulated, separates)
>>>>
>>>> The package compiles without complaints, but I have noticed that if
>>>> I start a fresh R-session, then maxClique etc. from RBGL is NOT
>>>> available for "interactive use" in my session:
>>>>> library(gRbase)
>>>>> maxClique
>>>> Error: object 'maxClique' not found
>>>>
>>>> 1) Is this as it should be?
>>>>
>>>> 2) If yes, is there any other way in which maxClique can be imported
>>>> for interactive use without Depend-ing the whole RBGL package?
>>>
>>> The importFrom directive effectively makes local copies of those
>>> functions in your package (with the usual caveats that copies aren't
>>> as inefficient as you might think).  If you want to export them, you
>>> need to add them to the exports list.
>>>
>>> Duncan Murdoch
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jacqueline.oehri at gmx.ch  Tue Jun 25 16:25:59 2013
From: jacqueline.oehri at gmx.ch (Jacqueline Oehri)
Date: Tue, 25 Jun 2013 16:25:59 +0200
Subject: [R] Fwd: Questions about working with a dataframe
References: <F3CACAB8-6537-424A-8BBC-1DD2E5B09985@gmx.ch>
Message-ID: <F1F87788-648E-4D2F-A490-57D0EBC416A5@gmx.ch>



> Dear R-Users, 
> I hope this is the right e-mail adress to post questions about Programming in R, and I hope somebody of you can help me with the troubles I have :)
> 
> 
> 1) First Question:
> 
> I have a dataframe called "WWA" (its attached to this e-mail
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: WWA.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/f8a2e152/attachment-0001.txt>
-------------- next part --------------
> ). It looks a little bit like the following one:
> 
> 
> testcoordID testcommunity testaltitude     testSpeciesName
> 1      503146       Bournes        523.2     Bellis perennis
> 2      503146       Bournes        321.5 Cynosurus cristatus
> 3      557154       Bournes        654.1   Festuca pratensis
> 4      557154         Aigle        938.6     Bellis perennis
> 5      569226         Aigle        401.3     Bellis perennis
> 6      599246         Aigle        765.9   Prunella vulgaris
> 
> ((I programmed this little one like this: 
> testcoordID <-c(as.integer("503146"),as.integer("503146"),as.integer("557154"),as.integer("557154"),as.integer("569226"),as.integer("599246"))
> testcommunity <-factor(c("Bournes","Bournes","Bournes", "Aigle", "Aigle", "Aigle"))
> testaltitude <- c(523.2,321.5,654.1,938.6,401.3,765.9)
> testSpeciesName <-c( "Bellis perennis",
>                      "Cynosurus cristatus",
>                      "Festuca pratensis",
>                     "Bellis perennis",
>                     "Bellis perennis",
>                      "Prunella vulgaris")
> testframe <- data.frame(testcoordID,testcommunity,testaltitude, testSpeciesName))
> 
> 
> 
> I needed to manipulate WWA in Excel, therefore i wrote
> it as a text-file:
> 
>> write.table(WWA, "WWA.txt", col.names=T, row.names=F, sep= ";", quote =T)
> 
> Then I manipulated the WWA.txt in Excel and saved it as "noWWA.csv"(
-------------- next part --------------
> ) and re-importet it under the new name "oWWA" in R:
> 
>> oWWA <- read.csv("~/Desktop/NCCR master projekt/BDM Beschreibungen/BDM Daten/noWWA.csv", header=TRUE, sep=";")
> 
> What i need to do with this "WWA" or "oWWA"is finally to create a list (or a dataframe but this is not possible i think), that shows for each coordinateID ("testcoordID") the species Names occuring at this place:
> 
>> species_per_coordID1<- tapply((WWA$speciesName), WWA$coordID, list)
>> species_per_coordID2 <- split(WWA$speciesName, WWA$coordID)
> 
> ---> now my Question: This works very well with the WWA table, but not with the oWWA!! I think i changed something in the dataframe by converting it to a .txt file and than back to a .csv;
> But does anybody know why it works with WWA and not with oWWA? how can I treat the WWA dataframe in Excel without changing any format of it?
> 
> 
> Thaanks a lot for any help or suggestions!!!!!
> 
> Have a nice day, 
> 
> Kind regards Jacqueline
> 


From mikeumo at gmail.com  Tue Jun 25 17:42:56 2013
From: mikeumo at gmail.com (Mikhail Umorin)
Date: Tue, 25 Jun 2013 08:42:56 -0700 (PDT)
Subject: [R] having trouble installing RDieHarder
Message-ID: <6697667.GuiTr1ZJCh@localhost>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/f261a5dc/attachment.pl>

From careyshan at gmail.com  Tue Jun 25 17:46:57 2013
From: careyshan at gmail.com (Shane Carey)
Date: Tue, 25 Jun 2013 16:46:57 +0100
Subject: [R] Calculate geometric mean with tapply
In-Reply-To: <1372173230.54328.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <CA+jRDxAw_PiJ8-z9C=J=r01S1QfWcSJJwUTUD5Y1u8khG9Z=CA@mail.gmail.com>
	<51C97C5B.7090805@sapo.pt>
	<CA+jRDxBpJ5EqANtN0McVyfpkJiNFKavtQmBhqSUWHfE96gv-2Q@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802810365@SRVEXCHMBX.precheza.cz>
	<1372173230.54328.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <CA+jRDxCoNTKwf680myZhe4X=Z9Z7M7eTa+O4OwJRWD9Y6z5=3g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/9b8658bd/attachment.pl>

From chiefmurphy at gmail.com  Tue Jun 25 17:56:04 2013
From: chiefmurphy at gmail.com (Dan Murphy)
Date: Tue, 25 Jun 2013 08:56:04 -0700
Subject: [R] do.call environment misunderstanding
In-Reply-To: <51C99FD1.1010802@gmail.com>
References: <CAHgH9_Fdbb7N1DZ91ExF7H0xca1Ngg7egT+XQzfmPprtaKKUHg@mail.gmail.com>
	<51C99FD1.1010802@gmail.com>
Message-ID: <CAHgH9_GCURDgUQ=qkP-sijw5XabjHAqfFf2WNM72FRXSriKK+Q@mail.gmail.com>

So the trick is to put the function f into e and define its environment to be e:
> e <- new.env()
> e$f <- function() x^2
> environment(e$f) <- e
> e$x <- 2
> do.call("f", list(), envir = e)
[1] 4

Thanks, Duncan.

On Tue, Jun 25, 2013 at 6:49 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 25/06/2013 9:32 AM, Dan Murphy wrote:
>>
>> I am having difficulty understanding the envir argument of do.call.
>> The help page says
>>
>> envir  an environment within which to evaluate the call.
>>
>> so I thought that in the following toy example x would be found in the
>> environment e and f would return 4 via do.call:
>>
>> > e <- new.env()
>> > e$x <- 2
>> > f <- function() x^2
>> > do.call(f, list(), envir = e)
>> Error in (function ()  : object 'x' not found
>>
>> Thanks in advance for clarifying my misunderstanding.
>
>
> do.call will construct the expression f(), then evaluate it in e. It will
> try to look up f there, and not finding it, will go to the parent
> environment and find it.
>
> When evaluating the function, the environment in which it was evaluated is
> used for looking up arguments, but f() has none, so e is not used at all.  R
> will use the environment attached to f, which is the global environment,
> since you created f by evaluating its definition there.
>
> To get what you want, you could use the sequence
>
>
> e <- new.env()
> e$x <- 2
> f <- function() x^2
> environment(f) <- e
> f()
>
> An alternative way to do the 3rd and 4th lines is
>
> f <- with(e, function() x^2)
>
> because that would evaluate the creation of f within e.
>
> A third approach (which might be the nicest one, depending on what else you
> are doing) is never to name e:
>
> f <- local({
>   x <- 2
>   function() x^2
> })
>
> Duncan Murdoch


From jrkrideau at inbox.com  Tue Jun 25 17:57:11 2013
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 25 Jun 2013 07:57:11 -0800
Subject: [R] Fwd: Questions about working with a dataframe
In-Reply-To: <F1F87788-648E-4D2F-A490-57D0EBC416A5@gmx.ch>
References: <f3cacab8-6537-424a-8bbc-1dd2e5b09985@gmx.ch>
Message-ID: <F90BBB3F8FB.00000235jrkrideau@inbox.com>

Hi, welcome to R

Try using the function str() on both files so str(WWA) and str(oWWA) and compare the structures that you get.  Probably one of the varables you defined when creating the original WWA data set has changed from a character variable to a factor or vis versa.

It is a good idea to use dput to supply sample data here.

So dput(WWA) and paste the results into the email and repeat with the other data set.  Then readers can paste the actual data sets into R and work on them directly.  

If the str() approach does not give you enough information please paste in the dput results in your next email.

Good luck

John Kane
Kingston ON Canada


> -----Original Message-----
> From: jacqueline.oehri at gmx.ch
> Sent: Tue, 25 Jun 2013 16:25:59 +0200
> To: r-help at r-project.org
> Subject: [R] Fwd: Questions about working with a dataframe
> 
> 
> 
>> Dear R-Users,
>> I hope this is the right e-mail adress to post questions about
>> Programming in R, and I hope somebody of you can help me with the
>> troubles I have :)
>> 
>> 
>> 1) First Question:
>> 
>> I have a dataframe called "WWA" (its attached to this e-mail
>> ). It looks a little bit like the following one:
>> 
>> 
>> testcoordID testcommunity testaltitude     testSpeciesName
>> 1      503146       Bournes        523.2     Bellis perennis
>> 2      503146       Bournes        321.5 Cynosurus cristatus
>> 3      557154       Bournes        654.1   Festuca pratensis
>> 4      557154         Aigle        938.6     Bellis perennis
>> 5      569226         Aigle        401.3     Bellis perennis
>> 6      599246         Aigle        765.9   Prunella vulgaris
>> 
>> ((I programmed this little one like this:
>> testcoordID
>> <-c(as.integer("503146"),as.integer("503146"),as.integer("557154"),as.integer("557154"),as.integer("569226"),as.integer("599246"))
>> testcommunity <-factor(c("Bournes","Bournes","Bournes", "Aigle",
>> "Aigle", "Aigle"))
>> testaltitude <- c(523.2,321.5,654.1,938.6,401.3,765.9)
>> testSpeciesName <-c( "Bellis perennis",
>>                      "Cynosurus cristatus",
>>                      "Festuca pratensis",
>>                     "Bellis perennis",
>>                     "Bellis perennis",
>>                      "Prunella vulgaris")
>> testframe <- data.frame(testcoordID,testcommunity,testaltitude,
>> testSpeciesName))
>> 
>> 
>> 
>> I needed to manipulate WWA in Excel, therefore i wrote
>> it as a text-file:
>> 
>>> write.table(WWA, "WWA.txt", col.names=T, row.names=F, sep= ";", quote
>>> =T)
>> 
>> Then I manipulated the WWA.txt in Excel and saved it as "noWWA.csv"(
>> ) and re-importet it under the new name "oWWA" in R:
>> 
>>> oWWA <- read.csv("~/Desktop/NCCR master projekt/BDM Beschreibungen/BDM
>>> Daten/noWWA.csv", header=TRUE, sep=";")
>> 
>> What i need to do with this "WWA" or "oWWA"is finally to create a list
>> (or a dataframe but this is not possible i think), that shows for each
>> coordinateID ("testcoordID") the species Names occuring at this place:
>> 
>>> species_per_coordID1<- tapply((WWA$speciesName), WWA$coordID, list)
>>> species_per_coordID2 <- split(WWA$speciesName, WWA$coordID)
>> 
>> ---> now my Question: This works very well with the WWA table, but not
>> with the oWWA!! I think i changed something in the dataframe by
>> converting it to a .txt file and than back to a .csv;
>> But does anybody know why it works with WWA and not with oWWA? how can I
>> treat the WWA dataframe in Excel without changing any format of it?
>> 
>> 
>> Thaanks a lot for any help or suggestions!!!!!
>> 
>> Have a nice day,
>> 
>> Kind regards Jacqueline
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at http://www.inbox.com/smileys
Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk? and most webmails


From ronglli at cn.ibm.com  Tue Jun 25 17:52:02 2013
From: ronglli at cn.ibm.com (Rong lI Li)
Date: Tue, 25 Jun 2013 23:52:02 +0800
Subject: [R] How can C++ read the R object written into socket with saveRDS
	or save
Message-ID: <OF396F33FA.8A573204-ON48257B95.0055E30F-48257B95.00573B1B@cn.ibm.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/00022d4d/attachment.pl>

From dwinsemius at comcast.net  Tue Jun 25 18:09:15 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 25 Jun 2013 09:09:15 -0700
Subject: [R] Fwd: Questions about working with a dataframe
In-Reply-To: <F90BBB3F8FB.00000235jrkrideau@inbox.com>
References: <f3cacab8-6537-424a-8bbc-1dd2e5b09985@gmx.ch>
	<F90BBB3F8FB.00000235jrkrideau@inbox.com>
Message-ID: <4251C1A6-D423-45B4-8684-531D7C36670B@comcast.net>


On Jun 25, 2013, at 8:57 AM, John Kane wrote:

> Hi, welcome to R
> 
> Try using the function str() on both files so str(WWA) and str(oWWA) and compare the structures that you get.  Probably one of the varables you defined when creating the original WWA data set has changed from a character variable to a factor or vis versa.
> 
> It is a good idea to use dput to supply sample data here.
> 
> So dput(WWA) and paste the results into the email and repeat with the other data set.  Then readers can paste the actual data sets into R and work on them directly.  

In this case I think it would be much more courteous to include:

dput(head(WWA)) 
dput(head(oWWA))

... in light of the attached 5MB file in that email. 

I apologize to the other list readers for approving it in the moderation queue. It should ahve been rejected, but my excuse is that the moderation viewer doesn't always highlight all aspects of hte postings being viewed that should be highlighted.

-- 
David.
> If the str() approach does not give you enough information please paste in the dput results in your next email.
> 
> Good luck
> 
> John Kane
> Kingston ON Canada
> 
> 
>> -----Original Message-----
>> From: jacqueline.oehri at gmx.ch
>> Sent: Tue, 25 Jun 2013 16:25:59 +0200
>> To: r-help at r-project.org
>> Subject: [R] Fwd: Questions about working with a dataframe
>> 
>> 
>> 
>>> Dear R-Users,
>>> I hope this is the right e-mail adress to post questions about
>>> Programming in R, and I hope somebody of you can help me with the
>>> troubles I have :)
>>> 
>>> 
>>> 1) First Question:
>>> 
>>> I have a dataframe called "WWA" (its attached to this e-mail
>>> ). It looks a little bit like the following one:
>>> 
>>> 
>>> testcoordID testcommunity testaltitude     testSpeciesName
>>> 1      503146       Bournes        523.2     Bellis perennis
>>> 2      503146       Bournes        321.5 Cynosurus cristatus
>>> 3      557154       Bournes        654.1   Festuca pratensis
>>> 4      557154         Aigle        938.6     Bellis perennis
>>> 5      569226         Aigle        401.3     Bellis perennis
>>> 6      599246         Aigle        765.9   Prunella vulgaris
>>> 
>>> ((I programmed this little one like this:
>>> testcoordID
>>> <-c(as.integer("503146"),as.integer("503146"),as.integer("557154"),as.integer("557154"),as.integer("569226"),as.integer("599246"))
>>> testcommunity <-factor(c("Bournes","Bournes","Bournes", "Aigle",
>>> "Aigle", "Aigle"))
>>> testaltitude <- c(523.2,321.5,654.1,938.6,401.3,765.9)
>>> testSpeciesName <-c( "Bellis perennis",
>>>                     "Cynosurus cristatus",
>>>                     "Festuca pratensis",
>>>                    "Bellis perennis",
>>>                    "Bellis perennis",
>>>                     "Prunella vulgaris")
>>> testframe <- data.frame(testcoordID,testcommunity,testaltitude,
>>> testSpeciesName))
>>> 
>>> 
>>> 
>>> I needed to manipulate WWA in Excel, therefore i wrote
>>> it as a text-file:
>>> 
>>>> write.table(WWA, "WWA.txt", col.names=T, row.names=F, sep= ";", quote
>>>> =T)
>>> 
>>> Then I manipulated the WWA.txt in Excel and saved it as "noWWA.csv"(
>>> ) and re-importet it under the new name "oWWA" in R:
>>> 
>>>> oWWA <- read.csv("~/Desktop/NCCR master projekt/BDM Beschreibungen/BDM
>>>> Daten/noWWA.csv", header=TRUE, sep=";")
>>> 
>>> What i need to do with this "WWA" or "oWWA"is finally to create a list
>>> (or a dataframe but this is not possible i think), that shows for each
>>> coordinateID ("testcoordID") the species Names occuring at this place:
>>> 
>>>> species_per_coordID1<- tapply((WWA$speciesName), WWA$coordID, list)
>>>> species_per_coordID2 <- split(WWA$speciesName, WWA$coordID)
>>> 
>>> ---> now my Question: This works very well with the WWA table, but not
>>> with the oWWA!! I think i changed something in the dataframe by
>>> converting it to a .txt file and than back to a .csv;
>>> But does anybody know why it works with WWA and not with oWWA? how can I
>>> treat the WWA dataframe in Excel without changing any format of it?
>>> 
>>> 
>>> Thaanks a lot for any help or suggestions!!!!!
>>> 
>>> Have a nice day,
>>> 
>>> Kind regards Jacqueline
>>> 


David Winsemius
Alameda, CA, USA


From kimbet3 at yahoo.com  Tue Jun 25 18:07:18 2013
From: kimbet3 at yahoo.com (bett kimutai)
Date: Tue, 25 Jun 2013 09:07:18 -0700 (PDT)
Subject: [R] Loops
In-Reply-To: <1372168090.49111.YahooMailNeo@web142405.mail.bf1.yahoo.com>
References: <1372141324.57953.YahooMailNeo@web142405.mail.bf1.yahoo.com>
	<1372168090.49111.YahooMailNeo@web142405.mail.bf1.yahoo.com>
Message-ID: <1372176438.6229.YahooMailNeo@web142405.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/5a417d56/attachment.pl>

From jrkrideau at inbox.com  Tue Jun 25 18:12:05 2013
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 25 Jun 2013 08:12:05 -0800
Subject: [R] Fwd: Questions about working with a dataframe
In-Reply-To: <4251C1A6-D423-45B4-8684-531D7C36670B@comcast.net>
References: <f90bbb3f8fb.00000235jrkrideau@inbox.com>
	<f3cacab8-6537-424a-8bbc-1dd2e5b09985@gmx.ch>
Message-ID: <F92D07D9646.0000026Fjrkrideau@inbox.com>


Ouch. My apologies David, after reading the message I didn't bother to look at the txt file.
John Kane
Kingston ON Canada


> -----Original Message-----
> From: dwinsemius at comcast.net
> Sent: Tue, 25 Jun 2013 09:09:15 -0700
> To: jrkrideau at inbox.com
> Subject: Re: [R] Fwd: Questions about working with a dataframe
> 
> 
> On Jun 25, 2013, at 8:57 AM, John Kane wrote:
> 
>> Hi, welcome to R
>> 
>> Try using the function str() on both files so str(WWA) and str(oWWA) and
>> compare the structures that you get.  Probably one of the varables you
>> defined when creating the original WWA data set has changed from a
>> character variable to a factor or vis versa.
>> 
>> It is a good idea to use dput to supply sample data here.
>> 
>> So dput(WWA) and paste the results into the email and repeat with the
>> other data set.  Then readers can paste the actual data sets into R and
>> work on them directly.
> 
> In this case I think it would be much more courteous to include:
> 
> dput(head(WWA))
> dput(head(oWWA))
> 
> ... in light of the attached 5MB file in that email.
> 
> I apologize to the other list readers for approving it in the moderation
> queue. It should ahve been rejected, but my excuse is that the moderation
> viewer doesn't always highlight all aspects of hte postings being viewed
> that should be highlighted.
> 
> --
> David.
>> If the str() approach does not give you enough information please paste
>> in the dput results in your next email.
>> 
>> Good luck
>> 
>> John Kane
>> Kingston ON Canada
>> 
>> 
>>> -----Original Message-----
>>> From: jacqueline.oehri at gmx.ch
>>> Sent: Tue, 25 Jun 2013 16:25:59 +0200
>>> To: r-help at r-project.org
>>> Subject: [R] Fwd: Questions about working with a dataframe
>>> 
>>> 
>>> 
>>>> Dear R-Users,
>>>> I hope this is the right e-mail adress to post questions about
>>>> Programming in R, and I hope somebody of you can help me with the
>>>> troubles I have :)
>>>> 
>>>> 
>>>> 1) First Question:
>>>> 
>>>> I have a dataframe called "WWA" (its attached to this e-mail
>>>> ). It looks a little bit like the following one:
>>>> 
>>>> 
>>>> testcoordID testcommunity testaltitude     testSpeciesName
>>>> 1      503146       Bournes        523.2     Bellis perennis
>>>> 2      503146       Bournes        321.5 Cynosurus cristatus
>>>> 3      557154       Bournes        654.1   Festuca pratensis
>>>> 4      557154         Aigle        938.6     Bellis perennis
>>>> 5      569226         Aigle        401.3     Bellis perennis
>>>> 6      599246         Aigle        765.9   Prunella vulgaris
>>>> 
>>>> ((I programmed this little one like this:
>>>> testcoordID
>>>> <-c(as.integer("503146"),as.integer("503146"),as.integer("557154"),as.integer("557154"),as.integer("569226"),as.integer("599246"))
>>>> testcommunity <-factor(c("Bournes","Bournes","Bournes", "Aigle",
>>>> "Aigle", "Aigle"))
>>>> testaltitude <- c(523.2,321.5,654.1,938.6,401.3,765.9)
>>>> testSpeciesName <-c( "Bellis perennis",
>>>>                     "Cynosurus cristatus",
>>>>                     "Festuca pratensis",
>>>>                    "Bellis perennis",
>>>>                    "Bellis perennis",
>>>>                     "Prunella vulgaris")
>>>> testframe <- data.frame(testcoordID,testcommunity,testaltitude,
>>>> testSpeciesName))
>>>> 
>>>> 
>>>> 
>>>> I needed to manipulate WWA in Excel, therefore i wrote
>>>> it as a text-file:
>>>> 
>>>>> write.table(WWA, "WWA.txt", col.names=T, row.names=F, sep= ";", quote
>>>>> =T)
>>>> 
>>>> Then I manipulated the WWA.txt in Excel and saved it as "noWWA.csv"(
>>>> ) and re-importet it under the new name "oWWA" in R:
>>>> 
>>>>> oWWA <- read.csv("~/Desktop/NCCR master projekt/BDM
>>>>> Beschreibungen/BDM
>>>>> Daten/noWWA.csv", header=TRUE, sep=";")
>>>> 
>>>> What i need to do with this "WWA" or "oWWA"is finally to create a list
>>>> (or a dataframe but this is not possible i think), that shows for each
>>>> coordinateID ("testcoordID") the species Names occuring at this place:
>>>> 
>>>>> species_per_coordID1<- tapply((WWA$speciesName), WWA$coordID, list)
>>>>> species_per_coordID2 <- split(WWA$speciesName, WWA$coordID)
>>>> 
>>>> ---> now my Question: This works very well with the WWA table, but not
>>>> with the oWWA!! I think i changed something in the dataframe by
>>>> converting it to a .txt file and than back to a .csv;
>>>> But does anybody know why it works with WWA and not with oWWA? how can
>>>> I
>>>> treat the WWA dataframe in Excel without changing any format of it?
>>>> 
>>>> 
>>>> Thaanks a lot for any help or suggestions!!!!!
>>>> 
>>>> Have a nice day,
>>>> 
>>>> Kind regards Jacqueline
>>>> 
> 
> 
> David Winsemius
> Alameda, CA, USA
>

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From jrkrideau at inbox.com  Tue Jun 25 18:34:19 2013
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 25 Jun 2013 08:34:19 -0800
Subject: [R] how to add any extra word to existing column heading in R
In-Reply-To: <CAFdg=fWAqD5qz=dsLAcqs4kBXm1vcAR8F914-HFNVBHL8DPd4A@mail.gmail.com>
Message-ID: <F95EB98D7EE.000002B5jrkrideau@inbox.com>

names(height)  <-  paste0(names(height),".D1")

It would be better if you supplied the data using dput()

Have a lookt at https://github.com/hadley/devtools/wiki/Reproducibility for some suggestions on forming a good question.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: suparna.mitra.sm at gmail.com
> Sent: Thu, 20 Jun 2013 12:56:24 +0800
> To: r-help at r-project.org
> Subject: [R] how to add any extra word to existing column heading in R
> 
> Hello R experts,
>   I want to add some extra words to number to existing column header. Can
> anybody tell me how to do that.
> 
> e.g. if I have a data.frame
>       Height.1 Height.2 Height.6 Height.8 Height.10 Height.11 Height.17
> Height.20 Height.22 Height.31
> MBR1        74       72        0      104         0       250       144
>     0         0         0
> MBR2         0       94        0      150         0       250       158
>     0         0         0
> MBR3        93      167        0      199         0       250       208
>     0         0         0
> MBR4       146      106        0      165         0       250       135
>     0         0         0
> MBR5       149      106        0        0         0       250       141
>     0         0         0
> MBR6       120        0        0       97         0       250       175
>     0         0         0
> MBR7       120        0        0       76       145       250       130
>     0         0        79
> MBR8        89       70        0      114         0       250       211
>     0         0         0
> 
> I want to rename the heading as
> 
>       Height.1.D1 Height.2.D1 Height.6.D1 Height.8.D1 Height.10.D1
> Height.11.D1 Height.17.D1 Height.20.D1 Height.22.D1 Height.31.D1
> MBR1        74       72        0      104         0       250       144
>     0         0         0
> MBR2         0       94        0      150         0       250       158
>     0         0         0
> MBR3        93      167        0      199         0       250       208
>     0         0         0
> MBR4       146      106        0      165         0       250       135
>     0         0         0
> MBR5       149      106        0        0         0       250       141
>     0         0         0
> MBR6       120        0        0       97         0       250       175
>     0         0         0
> MBR7       120        0        0       76       145       250       130
>     0         0        79
> MBR8        89       70        0      114         0       250       211
>     0         0         0
> MBR9       168        0        0        0         0       250       137
>     0         0         0
> MBR11       78       68        0      117         0       250       161
>     0        49         0
> 
> Any help will be really great.
> Thanks,
> Mitra
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From murdoch.duncan at gmail.com  Tue Jun 25 18:54:14 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 25 Jun 2013 12:54:14 -0400
Subject: [R] do.call environment misunderstanding
In-Reply-To: <CAHgH9_GCURDgUQ=qkP-sijw5XabjHAqfFf2WNM72FRXSriKK+Q@mail.gmail.com>
References: <CAHgH9_Fdbb7N1DZ91ExF7H0xca1Ngg7egT+XQzfmPprtaKKUHg@mail.gmail.com>
	<51C99FD1.1010802@gmail.com>
	<CAHgH9_GCURDgUQ=qkP-sijw5XabjHAqfFf2WNM72FRXSriKK+Q@mail.gmail.com>
Message-ID: <51C9CB36.9070605@gmail.com>

On 25/06/2013 11:56 AM, Dan Murphy wrote:
> So the trick is to put the function f into e and define its environment to be e:

Putting f into e, and defining the environment of f to be e solve 
different problems.  Your toy example has both problems so it's a 
reasonable solution there, but most real examples don't, so I wouldn't 
think of those two solutions as being connected.

Duncan Murdoch

> > e <- new.env()
> > e$f <- function() x^2
> > environment(e$f) <- e
> > e$x <- 2
> > do.call("f", list(), envir = e)
> [1] 4
>
> Thanks, Duncan.
>
> On Tue, Jun 25, 2013 at 6:49 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
> > On 25/06/2013 9:32 AM, Dan Murphy wrote:
> >>
> >> I am having difficulty understanding the envir argument of do.call.
> >> The help page says
> >>
> >> envir  an environment within which to evaluate the call.
> >>
> >> so I thought that in the following toy example x would be found in the
> >> environment e and f would return 4 via do.call:
> >>
> >> > e <- new.env()
> >> > e$x <- 2
> >> > f <- function() x^2
> >> > do.call(f, list(), envir = e)
> >> Error in (function ()  : object 'x' not found
> >>
> >> Thanks in advance for clarifying my misunderstanding.
> >
> >
> > do.call will construct the expression f(), then evaluate it in e. It will
> > try to look up f there, and not finding it, will go to the parent
> > environment and find it.
> >
> > When evaluating the function, the environment in which it was evaluated is
> > used for looking up arguments, but f() has none, so e is not used at all.  R
> > will use the environment attached to f, which is the global environment,
> > since you created f by evaluating its definition there.
> >
> > To get what you want, you could use the sequence
> >
> >
> > e <- new.env()
> > e$x <- 2
> > f <- function() x^2
> > environment(f) <- e
> > f()
> >
> > An alternative way to do the 3rd and 4th lines is
> >
> > f <- with(e, function() x^2)
> >
> > because that would evaluate the creation of f within e.
> >
> > A third approach (which might be the nicest one, depending on what else you
> > are doing) is never to name e:
> >
> > f <- local({
> >   x <- 2
> >   function() x^2
> > })
> >
> > Duncan Murdoch


From puja.stats at gmail.com  Tue Jun 25 18:46:35 2013
From: puja.stats at gmail.com (puja makkar)
Date: Tue, 25 Jun 2013 11:46:35 -0500
Subject: [R] confidence interval in rpart
Message-ID: <CAC3hcJiwzkgq9gKWS1Hc_y+qMDEDj6p=01zQR_7S2WX6_YR9EA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/f33e40e0/attachment.pl>

From murdoch.duncan at gmail.com  Tue Jun 25 19:07:29 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 25 Jun 2013 13:07:29 -0400
Subject: [R] Issue with Imports in NAMESPACE
In-Reply-To: <51C9CD58.8020809@gmail.com>
References: <7E8037094A0C2146AA3E6F94DAE621C34454EC1F@AD-EXCHMBX2-1.aau.dk>
	<51C97897.3070903@gmail.com>
	<7E8037094A0C2146AA3E6F94DAE621C34454EC96@AD-EXCHMBX2-1.aau.dk>
	<51C9CD58.8020809@gmail.com>
Message-ID: <51C9CE51.4070100@gmail.com>

On 25/06/2013 1:03 PM, Duncan Murdoch wrote:
> On 25/06/2013 7:14 AM, S?ren H?jsgaard wrote:
> > Dear Duncan,
> >
> > Excellent, thanks!
> >
> > Maybe this is worth a remark in a future version of "Writing R Extensions" (including that those "local copies" are not exported again with exportPattern("^[[:alpha:]]+")).
>
> Yes, from the followup discussion it's clear that this is desired
> behaviour, so I'll add that.

No I won't:  Brian Ripley got there first.

Duncan Murdoch
>
> Duncan
> >
> > Thanks!
> >
> > S?ren
> >
> > -----Original Message-----
> > From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> > Sent: 25. juni 2013 13:02
> > To: S?ren H?jsgaard
> > Cc: R hELP (r-help at stat.math.ethz.ch)
> > Subject: Re: [R] Issue with Imports in NAMESPACE
> >
> > On 13-06-25 6:50 AM, S?ren H?jsgaard wrote:
> > > Dear all,
> > > In my gRbase package I have up until now "Depend"-ed on RBGL (from Bioconductor), but good people have convinced me that I should use "Import"-it instead because I only use few functions from RBGL.
> > >
> > > In DESCRIPTION I therefore now have
> > > Imports: Matrix,RBGL
> > >
> > > In NAMESPACE I now have
> > > importFrom(RBGL, maxClique, is.triangulated, separates)
> > >
> > > The package compiles without complaints, but I have noticed that if I start a fresh R-session, then maxClique etc. from RBGL is NOT available for "interactive use" in my session:
> > >> library(gRbase)
> > >> maxClique
> > > Error: object 'maxClique' not found
> > >
> > > 1) Is this as it should be?
> > >
> > > 2) If yes, is there any other way in which maxClique can be imported for interactive use without Depend-ing the whole RBGL package?
> >
> > The importFrom directive effectively makes local copies of those functions in your package (with the usual caveats that copies aren't as inefficient as you might think).  If you want to export them, you need to add them to the exports list.
> >
> > Duncan Murdoch
>


From murdoch.duncan at gmail.com  Tue Jun 25 19:03:20 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 25 Jun 2013 13:03:20 -0400
Subject: [R] Issue with Imports in NAMESPACE
In-Reply-To: <7E8037094A0C2146AA3E6F94DAE621C34454EC96@AD-EXCHMBX2-1.aau.dk>
References: <7E8037094A0C2146AA3E6F94DAE621C34454EC1F@AD-EXCHMBX2-1.aau.dk>
	<51C97897.3070903@gmail.com>
	<7E8037094A0C2146AA3E6F94DAE621C34454EC96@AD-EXCHMBX2-1.aau.dk>
Message-ID: <51C9CD58.8020809@gmail.com>

On 25/06/2013 7:14 AM, S?ren H?jsgaard wrote:
> Dear Duncan,
>
> Excellent, thanks!
>
> Maybe this is worth a remark in a future version of "Writing R Extensions" (including that those "local copies" are not exported again with exportPattern("^[[:alpha:]]+")).

Yes, from the followup discussion it's clear that this is desired 
behaviour, so I'll add that.

Duncan
>
> Thanks!
>
> S?ren
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: 25. juni 2013 13:02
> To: S?ren H?jsgaard
> Cc: R hELP (r-help at stat.math.ethz.ch)
> Subject: Re: [R] Issue with Imports in NAMESPACE
>
> On 13-06-25 6:50 AM, S?ren H?jsgaard wrote:
> > Dear all,
> > In my gRbase package I have up until now "Depend"-ed on RBGL (from Bioconductor), but good people have convinced me that I should use "Import"-it instead because I only use few functions from RBGL.
> >
> > In DESCRIPTION I therefore now have
> > Imports: Matrix,RBGL
> >
> > In NAMESPACE I now have
> > importFrom(RBGL, maxClique, is.triangulated, separates)
> >
> > The package compiles without complaints, but I have noticed that if I start a fresh R-session, then maxClique etc. from RBGL is NOT available for "interactive use" in my session:
> >> library(gRbase)
> >> maxClique
> > Error: object 'maxClique' not found
> >
> > 1) Is this as it should be?
> >
> > 2) If yes, is there any other way in which maxClique can be imported for interactive use without Depend-ing the whole RBGL package?
>
> The importFrom directive effectively makes local copies of those functions in your package (with the usual caveats that copies aren't as inefficient as you might think).  If you want to export them, you need to add them to the exports list.
>
> Duncan Murdoch


From hanson at depauw.edu  Tue Jun 25 20:13:08 2013
From: hanson at depauw.edu (Bryan Hanson)
Date: Tue, 25 Jun 2013 14:13:08 -0400
Subject: [R] Issue with Imports in NAMESPACE
In-Reply-To: <51C9CD58.8020809@gmail.com>
References: <7E8037094A0C2146AA3E6F94DAE621C34454EC1F@AD-EXCHMBX2-1.aau.dk>
	<51C97897.3070903@gmail.com>
	<7E8037094A0C2146AA3E6F94DAE621C34454EC96@AD-EXCHMBX2-1.aau.dk>
	<51C9CD58.8020809@gmail.com>
Message-ID: <0A27C80E-14FD-47C9-AE50-2EDB6F39F20E@depauw.edu>

By chance is any of this related to what I'll call the 'depends relay' discussed in this SO post?

http://stackoverflow.com/a/8638902/633251 (see the 'caveat' to Josh O'Brien's answer, which also links back to another answer by Martin Morgan).

This issue has happened to me and the symptoms are exactly as Soren originally reported them on this thread  (try to do the 'right' thing but be thwarted).

Bryan

On Jun 25, 2013, at 1:03 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 25/06/2013 7:14 AM, S?ren H?jsgaard wrote:
>> Dear Duncan,
>> 
>> Excellent, thanks!
>> 
>> Maybe this is worth a remark in a future version of "Writing R Extensions" (including that those "local copies" are not exported again with exportPattern("^[[:alpha:]]+")).
> 
> Yes, from the followup discussion it's clear that this is desired behaviour, so I'll add that.
> 
> Duncan
>> 
>> Thanks!
>> 
>> S?ren
>> 
>> -----Original Message-----
>> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
>> Sent: 25. juni 2013 13:02
>> To: S?ren H?jsgaard
>> Cc: R hELP (r-help at stat.math.ethz.ch)
>> Subject: Re: [R] Issue with Imports in NAMESPACE
>> 
>> On 13-06-25 6:50 AM, S?ren H?jsgaard wrote:
>> > Dear all,
>> > In my gRbase package I have up until now "Depend"-ed on RBGL (from Bioconductor), but good people have convinced me that I should use "Import"-it instead because I only use few functions from RBGL.
>> >
>> > In DESCRIPTION I therefore now have
>> > Imports: Matrix,RBGL
>> >
>> > In NAMESPACE I now have
>> > importFrom(RBGL, maxClique, is.triangulated, separates)
>> >
>> > The package compiles without complaints, but I have noticed that if I start a fresh R-session, then maxClique etc. from RBGL is NOT available for "interactive use" in my session:
>> >> library(gRbase)
>> >> maxClique
>> > Error: object 'maxClique' not found
>> >
>> > 1) Is this as it should be?
>> >
>> > 2) If yes, is there any other way in which maxClique can be imported for interactive use without Depend-ing the whole RBGL package?
>> 
>> The importFrom directive effectively makes local copies of those functions in your package (with the usual caveats that copies aren't as inefficient as you might think).  If you want to export them, you need to add them to the exports list.
>> 
>> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ned at alteryx.com  Tue Jun 25 19:35:24 2013
From: ned at alteryx.com (Ned Harding)
Date: Tue, 25 Jun 2013 17:35:24 +0000
Subject: [R] R CMD BATCH Unicode
Message-ID: <92A981B3677AE44384E1ABE4B16D87244E46404B@MAIL1BDVM01.extendthereach.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/6dcf26f9/attachment.pl>

From k.askland at gmail.com  Tue Jun 25 20:34:00 2013
From: k.askland at gmail.com (kathleen askland)
Date: Tue, 25 Jun 2013 14:34:00 -0400
Subject: [R] Stopping execution of running program in R
Message-ID: <CAFpPP=y1rLMrtfSM3x2Ux6mifJN+NJN2sCQUM_P0CWo602_qyA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/007bfd74/attachment.pl>

From GITTEBA at HUM-GEN.AU.DK  Tue Jun 25 20:49:07 2013
From: GITTEBA at HUM-GEN.AU.DK (Gitte Brinch Andersen)
Date: Tue, 25 Jun 2013 18:49:07 +0000
Subject: [R] Heatmap with error message: `x' must be a numeric matrix
Message-ID: <F18DFC4F-FAF6-48AD-A48D-A3166192C1E6@hum-gen.au.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/f8b87e80/attachment.pl>

From ned at alteryx.com  Tue Jun 25 21:35:46 2013
From: ned at alteryx.com (Ned Harding)
Date: Tue, 25 Jun 2013 19:35:46 +0000
Subject: [R] R CMD BATCH Unicode
In-Reply-To: <92A981B3677AE44384E1ABE4B16D87244E46404B@MAIL1BDVM01.extendthereach.com>
References: <92A981B3677AE44384E1ABE4B16D87244E46404B@MAIL1BDVM01.extendthereach.com>
Message-ID: <92A981B3677AE44384E1ABE4B16D87244E4643C0@MAIL1BDVM01.extendthereach.com>

Just to clarify: The encoding didn't come through in the email.  print("????????????") is meant to be a bunch of random greek characters.

Ned.

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Ned Harding
Sent: Tuesday, June 25, 2013 11:35 AM
To: r-help at r-project.org
Subject: [R] R CMD BATCH Unicode

Hey,

I am looking for some help using Unicode with R CMD BATCH on windows.  In particular I would like my input and output files to be UTF-8 encoded.  My command line looks like this:

r CMD BATCH --encoding=UTF-8 in.txt out.txt

in.txt is utf-8 encoded and contains:

print("????????????")

out.txt gets:

+ <ERROR: re-encoding failure from encoding 'UTF-8'>

What is the proper way to specify encoding on the command line?

Thanks in advance,

Ned.

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Jun 25 21:47:10 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 25 Jun 2013 15:47:10 -0400
Subject: [R] Stopping execution of running program in R
In-Reply-To: <CAFpPP=y1rLMrtfSM3x2Ux6mifJN+NJN2sCQUM_P0CWo602_qyA@mail.gmail.com>
References: <CAFpPP=y1rLMrtfSM3x2Ux6mifJN+NJN2sCQUM_P0CWo602_qyA@mail.gmail.com>
Message-ID: <51C9F3BE.6090003@gmail.com>

On 25/06/2013 2:34 PM, kathleen askland wrote:
> Hello,
> Can anyone tell me how I can stop execution of a running program in R. I am
> using Revolution R Enterprise v. 6.2. There is no STOP button and both ESC
> and Ctrl+C do not work.
> Thank you for your suggestions.

You will need to ask Revolution that in their support forums.   We don't 
support their build here.

Duncan Murdoch
> Kathleen
>
> ---
> Kathleen Askland, MD
> Assistant Professor
> Department of Psychiatry & Human Behavior
> The Warren Alpert School of Medicine
> Brown University/Butler Hospital
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Tue Jun 25 21:51:20 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 25 Jun 2013 20:51:20 +0100
Subject: [R] Heatmap with error message: `x' must be a numeric matrix
In-Reply-To: <F18DFC4F-FAF6-48AD-A48D-A3166192C1E6@hum-gen.au.dk>
References: <F18DFC4F-FAF6-48AD-A48D-A3166192C1E6@hum-gen.au.dk>
Message-ID: <51C9F4B8.509@sapo.pt>

Hello,

Your data has commas as decimal points, R uses the period. So the data 
is read in as strings, not numbers. You can change this by using 
argument 'dec' of read.table:

?read.table
read.table(...etc..., dec = ",")


Or you can replace the commas with periods:


data[] <- sapply(data, function(x) as.numeric(sub(",", "\\.", x)))

data1 <- as.matrix(data)
heatmap.2(...)  # No errors


Hope this helps,

Rui Barradas

Em 25-06-2013 19:49, Gitte Brinch Andersen escreveu:
> Hi
>
> I am trying to do a heatmap, but I can't see what I am doing wrong. I get the error message: `x' must be a numeric matrix, but as far as I know I have changed my data into a matrix.
>
> The dataset I have in my example of my run is only a small part. I have around 1000 rows in total. I have checked that none of the rows contains any letters etc, and I have removed the rows where some of the samples contain NA. So I can't see why the numbers aren't numeric.
>
> I have tried to change the numbers to contain dots instead of commas, but this still gives me the same error.
>
> I hope someone can give me a hint to what I am doing wrong!
>
> I am still very new to R, and apologize in advance if this is just some simple stupid mistake.
>
> My R run is this:
>
> #Load in data
>> data<-read.table("/Users/gban/Desktop/Probes_for_heatmap_35_meth_diff_both_hypo_and_hypermeth_Gene&probenames.txt",sep="\t",header=TRUE,row.names=1)
>
>
>
> # Throw out rows with missing values.
>> data = na.omit(data)
>
>
>
>> data
>                                    OS_Tumor1_08_14985_2_3 OS_Tumor2_08_226869_1
> CHST3_cg04268405_1                           0,950380605            0,76433753
> DLX5_cg19962750_2                             0,93111825           0,753845234
> ZIC4_cg12892506_3                            0,860337466           0,696149332
> DLX5_cg05597836_4                            0,906981714           0,664148911
> ARHGEF7_cg09129334_6                          0,88102921           0,726231077
> ZIC4_cg02387803_7                            0,770987986           0,568085839
> ZIC4_cg05855917_8                            0,880514891           0,681148663
> DLX5_cg13286614_9                            0,855132688           0,592368469
> ZIC4_cg04556126_10                           0,907405655           0,718858033
> LOC145845_cg25718467_11                      0,893492688           0,793191968
> ZIC4_cg08393041_12                           0,911133787           0,678042743
> SNED1_cg03785076_13                          0,862060883            0,70294155
> C10orf116_cg01004363_14                      0,858555164           0,553920222
> DLX5_cg20250426_15                           0,903165828            0,64976206
> EPHX3_cg16184495_16                          0,927538308           0,519523714
> SNED1_cg21304158_17                          0,762270611           0,647588457
> EN1_cg12418535_19                            0,790529679           0,318880892
> RTKN_cg00689340_20                           0,941714187           0,675243565
> SNED1_cg16937168_21                          0,894421593           0,821448724
> CD93_cg12873119_22                            0,86949625           0,676389091
> RRN3P2_cg00525931_23                         0,862670615           0,855822961
> GPBAR1_cg18581950_24                         0,800216557           0,810012301
> SPARCL1_cg15552249_25                        0,815666773           0,837099021
> HOXD12_cg23130254_26                         0,840109076           0,502896181
> ZIC4_cg08889797_27                           0,779606392           0,591615859
> ESRP2_cg06723863_28                          0,655488067            0,47819514
> ZIC4_cg16790847_29                           0,735676228           0,611372155
> PFDN5_cg16309127_30                          0,753348167           0,630504254
> ARHGEF7_cg05776861_31                        0,951737748           0,926613919
> TBX15_cg24720355_32                          0,906521431           0,364984479
> FER1L5_cg01876130_33                         0,601084686           0,805388591
> HOXD12_cg18022224_34                         0,865974739           0,543178066
> DLX6AS_cg26251506_35                         0,804479354           0,538022928
> GSTM5_cg05376982_36                          0,733426641           0,552089202
> ZIC4_cg12976081_37                           0,464939006           0,551218578
> HOXB4_cg02132714_38                          0,798491712           0,718121432
> HOXD10_cg17489939_39                         0,970868858           0,790134913
> C10orf116_cg12261786_40                      0,727394677           0,573072856
> SPARCL1_cg19466563_41                         0,79754226           0,722582785
> HOXD12_cg03964958_42                         0,778450531           0,679889139
> HOXA5_cg09549073_43                            0,4652904           0,377825589
> ZIC4_cg00334063_44                           0,783052842           0,634682328
> TBX15_cg16990168_45                          0,893463329           0,235197972
>
> #Load gplot package
>> library(gplots)
>
> #Make the data into a matrix
>> data1<-as.matrix(data)
>
>> data1
>
>                                    OS_Tumor1_08_14985_2_3 OS_Tumor2_08_226869_1
> CHST3_cg04268405_1                "0,950380605"          "0,76433753"
> DLX5_cg19962750_2                 "0,93111825"           "0,753845234"
> ZIC4_cg12892506_3                 "0,860337466"          "0,696149332"
> DLX5_cg05597836_4                 "0,906981714"          "0,664148911"
> ARHGEF7_cg09129334_6              "0,88102921"           "0,726231077"
> ZIC4_cg02387803_7                 "0,770987986"          "0,568085839"
> ZIC4_cg05855917_8                 "0,880514891"          "0,681148663"
> DLX5_cg13286614_9                 "0,855132688"          "0,592368469"
> ZIC4_cg04556126_10                "0,907405655"          "0,718858033"
> LOC145845_cg25718467_11           "0,893492688"          "0,793191968"
> ZIC4_cg08393041_12                "0,911133787"          "0,678042743"
> SNED1_cg03785076_13               "0,862060883"          "0,70294155"
> C10orf116_cg01004363_14           "0,858555164"          "0,553920222"
> DLX5_cg20250426_15                "0,903165828"          "0,64976206"
> EPHX3_cg16184495_16               "0,927538308"          "0,519523714"
> SNED1_cg21304158_17               "0,762270611"          "0,647588457"
> EN1_cg12418535_19                 "0,790529679"          "0,318880892"
> RTKN_cg00689340_20                "0,941714187"          "0,675243565"
> SNED1_cg16937168_21               "0,894421593"          "0,821448724"
> CD93_cg12873119_22                "0,86949625"           "0,676389091"
> RRN3P2_cg00525931_23              "0,862670615"          "0,855822961"
> GPBAR1_cg18581950_24              "0,800216557"          "0,810012301"
> SPARCL1_cg15552249_25             "0,815666773"          "0,837099021"
> HOXD12_cg23130254_26              "0,840109076"          "0,502896181"
> ZIC4_cg08889797_27                "0,779606392"          "0,591615859"
> ESRP2_cg06723863_28               "0,655488067"          "0,47819514"
> ZIC4_cg16790847_29                "0,735676228"          "0,611372155"
> PFDN5_cg16309127_30               "0,753348167"          "0,630504254"
> ARHGEF7_cg05776861_31             "0,951737748"          "0,926613919"
> TBX15_cg24720355_32               "0,906521431"          "0,364984479"
> FER1L5_cg01876130_33              "0,601084686"          "0,805388591"
> HOXD12_cg18022224_34              "0,865974739"          "0,543178066"
> DLX6AS_cg26251506_35              "0,804479354"          "0,538022928"
> GSTM5_cg05376982_36               "0,733426641"          "0,552089202"
> ZIC4_cg12976081_37                "0,464939006"          "0,551218578"
> HOXB4_cg02132714_38               "0,798491712"          "0,718121432"
> HOXD10_cg17489939_39              "0,970868858"          "0,790134913"
> C10orf116_cg12261786_40           "0,727394677"          "0,573072856"
> SPARCL1_cg19466563_41             "0,79754226"           "0,722582785"
> HOXD12_cg03964958_42              "0,778450531"          "0,679889139"
> HOXA5_cg09549073_43               "0,4652904"            "0,377825589"
> ZIC4_cg00334063_44                "0,783052842"          "0,634682328"
> TBX15_cg16990168_45               "0,893463329"          "0,235197972"
>
> heatmap.2(data1, col=redgreen(75), scale="row", key=T, keysize=1.5,density.info="none", trace="none",cexCol=0.9, labRow=NA)
> Fejl i heatmap.2(data1, col = redgreen(75), scale = "row", key = T,  :
>    `x' must be a numeric matrix
>
> Many thanks!
>
> Kind regards
>
> Gitte Brinch Andersen
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From chrisaa at med.umich.edu  Tue Jun 25 22:07:45 2013
From: chrisaa at med.umich.edu (Andrews, Chris)
Date: Tue, 25 Jun 2013 20:07:45 +0000
Subject: [R] censor=FALSE and id options in survfit.coxph
Message-ID: <30411786F64EEF46856EFBA2CD917799E06093@UHEXMBSPR03.umhs.med.umich.edu>

Terry,

I recently noticed the censor argument of survfit.  For some analyses it greatly reduces the size of the resulting object, which is a nice feature.  

However, when combined with the id argument, only 1 prediction is made.  Predictions can be made individually but I'd prefer to do them all at once if that change can be made.

Chris

#####################################
# CODE
# create data

set.seed(20130625)
n <- 100 # sample size
x <- rbinom(n, 1, 0.5) # covariate
z <- rep(0, n) # start time
y <- rexp(n, exp(x)) # event time
e <- y < 2 # censor at 2
y <- pmin(y, 2) # observation time
dat <- data.frame(x,z,y,e)


# fit cox model with start/stop format
library(survival)
mod <- coxph(Surv(z, y, e)~x, data=dat)
summary(mod)

# create prediction dataset with 3 individuals with
# x = 0 on (0,2)
# x = 1 on (0,2)
# x = 0 on (0,1) and x = 1 on (1,2)
datnew <- data.frame(x=c(0,1,0,1), z=c(0,0,0,1), y=c(2,2,1,2), e=rep(0,4), id=c(1,2,3,3))
datnew

# as expected
modsf1 <- survfit(mod, newdata=datnew, id=id)
modsf1

# not as expected 
modsf2 <- survfit(mod, newdata=datnew, id=id, censor=FALSE)
modsf2

# for comparison
modsf3 <- survfit(mod, newdata=datnew[1:2,])
modsf3

# appears to work when individual=FALSE (id not specified)
modsf4 <- survfit(mod, newdata=datnew[1:2,], censor=FALSE)
modsf4

# visually
par(mfrow=c(2,2))
plot(modsf1, col=1:3, lty=1:3, conf.int=FALSE)
plot(modsf2, col=1:3, lty=1:3, conf.int=FALSE)
plot(modsf3, col=1:2, lty=1:2, conf.int=FALSE)
plot(modsf4, col=1:2, lty=1:2, conf.int=FALSE)


# Can be done individually
modsf2a <- survfit(mod, newdata=datnew[1,], id=id, censor=FALSE)
modsf2a
modsf2b <- survfit(mod, newdata=datnew[2,], id=id, censor=FALSE)
modsf2b
modsf2c <- survfit(mod, newdata=datnew[3:4,], id=id, censor=FALSE)
modsf2c

# one at a time
par(mfrow=c(1,1))
plot(modsf2a, col=1, lty=1, conf.int=FALSE)
lines(modsf2b, col=2, lty=2, conf.int=FALSE)
lines(modsf2c, col=3, lty=3, conf.int=FALSE)

#####################################
# OUTPUT


> # create data
> 
> set.seed(20130625)

> n <- 100 # sample size

> x <- rbinom(n, 1, 0.5) # covariate

> z <- rep(0, n) # start time

> y <- rexp(n, exp(x)) # event time

> e <- y < 2 # censor at 2

> y <- pmin(y, 2) # observation time

> dat <- data.frame(x,z,y,e)

> # fit cox model with start/stop format
> library(survival)

> mod <- coxph(Surv(z, y, e)~x, data=dat)

> summary(mod)
Call:
coxph(formula = Surv(z, y, e) ~ x, data = dat)

  n= 100, number of events= 98 

    coef exp(coef) se(coef)     z Pr(>|z|)    
x 0.7162    2.0466   0.2091 3.425 0.000614 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

  exp(coef) exp(-coef) lower .95 upper .95
x     2.047     0.4886     1.359     3.083

Concordance= 0.601  (se = 0.029 )
Rsquare= 0.109   (max possible= 0.999 )
Likelihood ratio test= 11.58  on 1 df,   p=0.0006666
Wald test            = 11.73  on 1 df,   p=0.0006137
Score (logrank) test = 12.18  on 1 df,   p=0.0004831


> # create prediction dataset with 3 individuals with
> # x = 0 on (0,2)
> # x = 1 on (0,2)
> # x = 0 on (0,1) and x = 1 on (1,2)
> datnew <- data.fra .... [TRUNCATED] 

> datnew
  x z y e id
1 0 0 2 0  1
2 1 0 2 0  2
3 0 0 1 0  3
4 1 1 2 0  3

> # as expected
> modsf1 <- survfit(mod, newdata=datnew, id=id)

> modsf1
Call: survfit(formula = mod, newdata = datnew, id = id)

     records n.max n.start events median 0.95LCL 0.95UCL
0        100   100     100     98  0.663   0.457   0.948
<NA>     100   100     100     98  0.333   0.288   0.457
<NA>     100   100     100     98  0.663   0.457   0.948

> # not as expected 
> modsf2 <- survfit(mod, newdata=datnew, id=id, censor=FALSE)

> modsf2
Call: survfit(formula = mod, newdata = datnew, censor = FALSE, id = id)

records   n.max n.start  events  median 0.95LCL 0.95UCL 
100.000 100.000 100.000 294.000   0.663   0.457   0.948 

> # for comparison
> modsf3 <- survfit(mod, newdata=datnew[1:2,])

> modsf3
Call: survfit(formula = mod, newdata = datnew[1:2, ])

     records n.max n.start events median 0.95LCL 0.95UCL
[1,]     100   100     100     98  0.663   0.457   0.948
[2,]     100   100     100     98  0.333   0.288   0.457

> # appears to work when individual=FALSE (id not specified)
> modsf4 <- survfit(mod, newdata=datnew[1:2,], censor=FALSE)

> modsf4
Call: survfit(formula = mod, newdata = datnew[1:2, ], censor = FALSE)

     records n.max n.start events median 0.95LCL 0.95UCL
[1,]     100   100     100     98  0.663   0.457   0.948
[2,]     100   100     100     98  0.333   0.288   0.457

> modsf2a <- survfit(mod, newdata=datnew[1,], id=id, censor=FALSE)
> modsf2a
Call: survfit(formula = mod, newdata = datnew[1, ], censor = FALSE, 
    id = id)

records   n.max n.start  events  median 0.95LCL 0.95UCL 
100.000 100.000 100.000  98.000   0.663   0.457   0.948 
> modsf2b <- survfit(mod, newdata=datnew[2,], id=id, censor=FALSE)
> modsf2b
Call: survfit(formula = mod, newdata = datnew[2, ], censor = FALSE, 
    id = id)

records   n.max n.start  events  median 0.95LCL 0.95UCL 
100.000 100.000 100.000  98.000   0.333   0.288   0.457 
> modsf2c <- survfit(mod, newdata=datnew[3:4,], id=id, censor=FALSE)
> modsf2c
Call: survfit(formula = mod, newdata = datnew[3:4, ], censor = FALSE, 
    id = id)

records   n.max n.start  events  median 0.95LCL 0.95UCL 
100.000 100.000 100.000  98.000   0.663   0.457   0.948 

**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues 


From ivanovruporvrich at yahoo.com  Tue Jun 25 21:40:50 2013
From: ivanovruporvrich at yahoo.com (Ivanov Ruporvrich)
Date: Tue, 25 Jun 2013 20:40:50 +0100 (BST)
Subject: [R] Correct scaling of axis in persp3d plot
Message-ID: <1372189250.21293.YahooMailNeo@web171501.mail.ir2.yahoo.com>

Hi,
I want to format my axis in my persp3d plot.

With my data, which I attached I created a persp3d plot with the following code, which I summarized from different code snippets I found:

library(rugarch)library(rgl)library(fGarch)fd <-as.data.frame(modelfit,which ='density')color <-rgb(85,141,85,maxColorValue=255)x <-seq(-0.2,0.2,length=100)y <-c(1:2318)f <-function(s,t){dged(s,mean=fd[t,'Mu'],sd=fd[t,'Sigma'],nu=fd[t,'Shape'])}z <-outer(x,y,f)persp3d(x,y,z,theta=50,phi=25,expand=0.75,col=color,ticktype="detailed",xlab="",ylab="time",zlab="",axes=TRUE,axes=FALSE)

axes3d(c('x--','z'))axis3d(edge='y+-',at =seq(500,2000,by=500),labels =rownames(fd)[seq(500,2000,by=500)])

My first question is:
Currently I have four date ticks on my axis, but what I don't like is, that in my data, 
the starting date is in 2004, but the plots look like, as if the starting year
would be 2006. So I would like to have the starting year on the axis, but I don't
know how to implement this (my R programming skills are limited)?

So e.g. I would like to have always the beginning of each year, 2004, 2005, 2006, 2007, 2008, 
2009, 2010, 2011 , 2012 or if this does not fit at leas I would like to
have the beginning of the years 2004,2006,2008,2010,2012 so each second year.

My second question is:
I would like to have a colored surface. So I would like to have e.g. the spikes of the surface in red (values 
which are very larger) and lower values e.g. in green with a nice smooth transition between, e.g.
values in the middle in yellow. So the coloring should depend on the z values. I tried the following, but it does not 
give nice results:

nrz <- nrow(z)
ncz <- ncol(z)
jet.colors <- colorRampPalette( c("#ffcccc", "#cc0000") ) 
# Generate the desired number of colors from this palette
nbcol <- 100
color <- jet.colors(nbcol)

# Compute the z-value at the facet centres
zfacet <- z[-1, -1] + z[-1, -ncz] + z[-nrz, -1] + z[-nrz, -ncz]
# Recode facet z-values into color indices
facetcol <- cut(zfacet, nbcol)

persp3d(x, y, z, theta=50, phi=25, expand=0.75, col=color[facetcol],
ticktype="detailed", xlab="", ylab="time", zlab="",axes=TRUE)

Thanks a lot for your help,
Ivanov

From kimbet3 at yahoo.com  Tue Jun 25 22:31:45 2013
From: kimbet3 at yahoo.com (bett kimutai)
Date: Tue, 25 Jun 2013 13:31:45 -0700 (PDT)
Subject: [R] Loops
In-Reply-To: <1372176438.6229.YahooMailNeo@web142405.mail.bf1.yahoo.com>
References: <1372141324.57953.YahooMailNeo@web142405.mail.bf1.yahoo.com>
	<1372168090.49111.YahooMailNeo@web142405.mail.bf1.yahoo.com>
	<1372176438.6229.YahooMailNeo@web142405.mail.bf1.yahoo.com>
Message-ID: <1372192305.23908.YahooMailNeo@web142406.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/fb1ee4bb/attachment.pl>

From bree.witteveen at alaska.edu  Wed Jun 26 00:00:38 2013
From: bree.witteveen at alaska.edu (Bree W)
Date: Tue, 25 Jun 2013 15:00:38 -0700 (PDT)
Subject: [R] Calculating an index of colocation for a large dataset
In-Reply-To: <CAN5YmCF4ym3qXnP3U3s6HH3bUXk6bsiD6HhZESWfbfX6a=_1Kg@mail.gmail.com>
References: <1371853137063-4670084.post@n4.nabble.com>
	<CAN5YmCHCgmZDAUZTDkXAB45rm92wRh2Cf=_FyMLUi0E4a+jPVA@mail.gmail.com>
	<CAN5YmCF4ym3qXnP3U3s6HH3bUXk6bsiD6HhZESWfbfX6a=_1Kg@mail.gmail.com>
Message-ID: <1372197638550-4670325.post@n4.nabble.com>

My apologies for cross-posting and for failing to reply to r-help. I'll get
the hang of it.

This code seems to be getting me quite close, but I've encountered the
following error. 

Error in compute(dat, depths, fish, zoop) : attempt to apply non-function



--
View this message in context: http://r.789695.n4.nabble.com/Calculating-an-index-of-colocation-for-a-large-dataset-tp4670084p4670325.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Wed Jun 26 00:23:39 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 25 Jun 2013 15:23:39 -0700
Subject: [R] Correct scaling of axis in persp3d plot
In-Reply-To: <1372189250.21293.YahooMailNeo@web171501.mail.ir2.yahoo.com>
References: <1372189250.21293.YahooMailNeo@web171501.mail.ir2.yahoo.com>
Message-ID: <9EB6C747-1762-4907-9B38-53BC194F69A5@comcast.net>


On Jun 25, 2013, at 12:40 PM, Ivanov Ruporvrich wrote:

> Hi,
> I want to format my axis in my persp3d plot.
> 
> With my data, which I attached

You may have attached it ... but you probably didn't read the information about what would be accepted by the mail server. Read the listinfo page linked at the bottom of every posting to Rhelp.

> I created a persp3d plot with the following code, which I summarized from different code snippets I found:
> 
> library(rugarch)library(rgl)library(fGarch)

> fd <-as.data.frame(modelfit,which ='density')

Missing <CR>'s added to note that 'modelfit' was never created by the code posted to R-help.

> color <-rgb(85,141,85,maxColorValue=255)x <-seq(-0.2,0.2,length=100)y <-c(1:2318)f <-function(s,t){dged(s,mean=fd[t,'Mu'],sd=fd[t,'Sigma'],nu=fd[t,'Shape'])}z <-outer(x,y,f)persp3d(x,y,z,theta=50,phi=25,expand=0.75,col=color,ticktype="detailed",xlab="",ylab="time",zlab="",axes=TRUE,axes=FALSE)

Missing carriage returns are probably inhibiting people from reading this. 

> 
> axes3d(c('x--','z'))axis3d(edge='y+-',at =seq(500,2000,by=500),labels =rownames(fd)[seq(500,2000,by=500)])
> 
> My first question is:
> Currently I have four date ticks on my axis, but what I don't like is, that in my data, 
> the starting date is in 2004, but the plots look like, as if the starting year
> would be 2006. So I would like to have the starting year on the axis, but I don't
> know how to implement this (my R programming skills are limited)?
> 
> So e.g. I would like to have always the beginning of each year, 2004, 2005, 2006, 2007, 2008, 
> 2009, 2010, 2011 , 2012 or if this does not fit at leas I would like to
> have the beginning of the years 2004,2006,2008,2010,2012 so each second year.
> 
> My second question is:
> I would like to have a colored surface. So I would like to have e.g. the spikes of the surface in red (values 
> which are very larger) and lower values e.g. in green with a nice smooth transition between, e.g.
> values in the middle in yellow. So the coloring should depend on the z values. I tried the following, but it does not 
> give nice results:
> 
> nrz <- nrow(z)
> ncz <- ncol(z)
> jet.colors <- 

If you wanted a transition from red to green, then why use those values that go from pale red to dark red? Shouldn't it be:

 mycols <- colorRampPalette( c("#ff0000", "#00ff00") ) 

Or:

mycols <- colorRampPalette( c("#00ff00", "#ff0000") )

> # Generate the desired number of colors from this palette
> nbcol <- 100
> color <- jet.colors(nbcol)
> 
> # Compute the z-value at the facet centres
> zfacet <- z[-1, -1] + z[-1, -ncz] + z[-nrz, -1] + z[-nrz, -ncz]

That looks wrong. Appears you are using code from the example in ?persp rather than using the z values appropriate to persp3d.

> # Recode facet z-values into color indices
> facetcol <- cut(zfacet, nbcol)
> 
> persp3d(x, y, z, theta=50, phi=25, expand=0.75, col=color[facetcol],
> ticktype="detailed", xlab="", ylab="time", zlab="",axes=TRUE)
> 
> Thanks a lot for your help,
> Ivanov
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From sjkiss at gmail.com  Wed Jun 26 00:33:48 2013
From: sjkiss at gmail.com (Simon Kiss)
Date: Tue, 25 Jun 2013 18:33:48 -0400
Subject: [R] Psych package: Error in biplot.psych(sample.mod) : Biplot
	requires factor/component scores:
Message-ID: <88EDBE45-0F1E-499E-A5A9-676F96819D03@gmail.com>

Hello: I'm trying to construct a biplot from the psych package. The underlying data frame looks just like sample.data, below. I turned it into a polychoric correlation matrix sample.cor, below, as it is derived from a series of Likert (ordinal) items. All are positive, I just used negative numbers in this dataset to get two separate factors.  I created a PCA from sample.cor$rho, specifying that scores were to be kept via scores=TRUE, but the command, biplot.psych(sample.mod) returns the error message: Error in biplot.psych, Biplot requires factor/component scores.
But it seems from the help documentation, that one really only has to use the command biplot(mod) to get the plot.
Can someone please advise?
Yours, Simon Kiss


#Sample data
sample.data<-data.frame(var1=sample(c(0,0.33, 0.66, 1), size=100, replace=TRUE), var2=sample(c(0,0.33, 0.66, 1), size=100, replace=TRUE), var3=sample(c(0,-0.33, -0.66, -1), size=100, replace=TRUE), var4=sample(c(0,-0.33,-0.66,-1), size=100, replace=TRUE))

#Correlation Matrix
sample.cor<-polychoric(sample.data, polycor=TRUE)
#Principal Components Analysis
sample.mod<-principal(sample.cor$rho, nfactors=2,scores=TRUE,covar=TRUE)
#Draw Biplot
biplot.psych(sample.mod)

#error
Error in biplot.psych(sample.mod) : 
  Biplot requires factor/component scores:


From Jason.Law at portlandoregon.gov  Wed Jun 26 00:32:17 2013
From: Jason.Law at portlandoregon.gov (Law, Jason)
Date: Tue, 25 Jun 2013 15:32:17 -0700
Subject: [R] Loops
In-Reply-To: <1372192305.23908.YahooMailNeo@web142406.mail.bf1.yahoo.com>
References: <1372141324.57953.YahooMailNeo@web142405.mail.bf1.yahoo.com>
	<1372168090.49111.YahooMailNeo@web142405.mail.bf1.yahoo.com>
	<1372176438.6229.YahooMailNeo@web142405.mail.bf1.yahoo.com>
	<1372192305.23908.YahooMailNeo@web142406.mail.bf1.yahoo.com>
Message-ID: <0EFBC7C31DB4F24F8CAC48136A1762D70184E52CAF09@MAIL2.rose.portland.local>

Not sure what you're trying to do, but it looks like most of what you're attempting to do in the code can be done just using vectors rather than loops, at least the inner loop.  For example:

k <- 1.15
l <- exp((1 / k) * (7.16 - 0.44 + 0.12 - 0.016))
z <- (log(1 / p) * l)^k

See ifelse for how to do the if tests on a vector.  In addition, much of the code in your loops doesn't vary with the loop indices and can be moved outside your loop (e.g., setting k = 1.15).  If you really want/need to use loops, you'll have to initialize the vectors/matrices within your loop with some value:

z <- numeric(1000)

Finally, you have some plain syntax errors: 

p[i]=[i+1].

That's not valid R code; '[' is the extraction operator, see help('[').  I'm not sure what you're trying to do there.  Perhaps:

p[i] <- p[i + 1]

HTH,

Jason Law



-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of bett kimutai
Sent: Tuesday, June 25, 2013 1:32 PM
To: r-help at r-project.org
Subject: [R] Loops

Dear All,


I? have spent most of my time trying to figure out how to simulate the number of breaks in a pipe using Monte Carlo simulation.
i have 20,000 individual pipes that i have to run, and for each pipe i have to run 1000 times while checking some conditions and therefore, i have to use a nested loop.
what i would like to have as a final result is a matrix table with with all the individual pipe elements and the simulated runs here is the loop that i tried to create x=20000 y=matrix(x, z)
p=runif(1000)
for(j in 1:20000) {
for(i in 1:1000) {
?? ??? k=1.15
??? l=exp((1/k)*(7.16-0.44+0.12-0.016))
??? ??? ??? 
??? z[i]=(log(1/p[i])*l)^k

??? if (z[i] <=684)
??? {
??? ??? k1=0.504
??? ??? l1=exp((1/k)*(8.01-1.5+0.35+0.45))
??? ??? z1[i]=(log(1/p[i])*l1)^k1
??? if (z1[i] <=684)
??? {
??? ??? ??? ??? k2=0.43
??? ??? l2=exp((1/k2)*(9.55-2.45+0.40+0.65))
??? ??? z2[i]=(log(1/p[i])*l2)^k2
??? ??????????? p[i]=[i+1]
??? ??? ??? ??? break()
??? ??? ??? }
??? ??? }
??? }
x[ j ]=[ j+1 ]
}
the last column of the table,? in addition to the simulated runs, i would like to have the summary of the means (for z<=684) of individual row as this means will give me the number of breaks.
i will really appreciate if anyone who can help me figure out how to go about this. pardon me, I am new to R and programming.



Thank you in Advance,

Eliab
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From dr.timam.sn at gmail.com  Wed Jun 26 00:58:48 2013
From: dr.timam.sn at gmail.com (Dr. T. Imam)
Date: Wed, 26 Jun 2013 08:58:48 +1000
Subject: [R] Legal issue help
In-Reply-To: <51C6E90B.2080501@stats.ox.ac.uk>
References: <CAB4uz6e6eEpo7tjOo_NLdYhsgWEEwfgQ4D2BVCQ=HdDqwBJ-pA@mail.gmail.com>
	<51C6E30B.8000902@statistik.tu-dortmund.de>
	<51C6E90B.2080501@stats.ox.ac.uk>
Message-ID: <CAB4uz6fmWVMfmbqqEx53M4m8dxUDsBgBO02V2PS_JU1bFsfeZw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130626/ef79fabe/attachment.pl>

From chiefmurphy at gmail.com  Wed Jun 26 03:05:10 2013
From: chiefmurphy at gmail.com (Dan Murphy)
Date: Tue, 25 Jun 2013 18:05:10 -0700
Subject: [R] do.call environment misunderstanding
In-Reply-To: <51C9CB36.9070605@gmail.com>
References: <CAHgH9_Fdbb7N1DZ91ExF7H0xca1Ngg7egT+XQzfmPprtaKKUHg@mail.gmail.com>
	<51C99FD1.1010802@gmail.com>
	<CAHgH9_GCURDgUQ=qkP-sijw5XabjHAqfFf2WNM72FRXSriKK+Q@mail.gmail.com>
	<51C9CB36.9070605@gmail.com>
Message-ID: <CAHgH9_F4A5VehfnkkEAexzNTPL93QTGtN751Tk3D_7avwi-X3A@mail.gmail.com>

My problem is to evaluate a function/model whose definition and
parameters (I'll put x into the arguments) and other data are saved by
someone else in an Rdata file, but I don't know the function name,
definition or data. Nevertheless, I need to save whatever functional
values/model solutions are so determined and to compare and contrast
solutions of same and similar problems over time. Environments seemed
to hold promise, but understanding the relationship between f and e
was my first hurdle. Thanks again.

On Tue, Jun 25, 2013 at 9:54 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 25/06/2013 11:56 AM, Dan Murphy wrote:
>>
>> So the trick is to put the function f into e and define its environment to
>> be e:
>
>
> Putting f into e, and defining the environment of f to be e solve different
> problems.  Your toy example has both problems so it's a reasonable solution
> there, but most real examples don't, so I wouldn't think of those two
> solutions as being connected.
>
> Duncan Murdoch
>
>
>> > e <- new.env()
>> > e$f <- function() x^2
>> > environment(e$f) <- e
>> > e$x <- 2
>> > do.call("f", list(), envir = e)
>> [1] 4
>>
>> Thanks, Duncan.
>>
>> On Tue, Jun 25, 2013 at 6:49 AM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>> > On 25/06/2013 9:32 AM, Dan Murphy wrote:
>> >>
>> >> I am having difficulty understanding the envir argument of do.call.
>> >> The help page says
>> >>
>> >> envir  an environment within which to evaluate the call.
>> >>
>> >> so I thought that in the following toy example x would be found in the
>> >> environment e and f would return 4 via do.call:
>> >>
>> >> > e <- new.env()
>> >> > e$x <- 2
>> >> > f <- function() x^2
>> >> > do.call(f, list(), envir = e)
>> >> Error in (function ()  : object 'x' not found
>> >>
>> >> Thanks in advance for clarifying my misunderstanding.
>> >
>> >
>> > do.call will construct the expression f(), then evaluate it in e. It
>> > will
>> > try to look up f there, and not finding it, will go to the parent
>> > environment and find it.
>> >
>> > When evaluating the function, the environment in which it was evaluated
>> > is
>> > used for looking up arguments, but f() has none, so e is not used at
>> > all.  R
>> > will use the environment attached to f, which is the global environment,
>> > since you created f by evaluating its definition there.
>> >
>> > To get what you want, you could use the sequence
>> >
>> >
>> > e <- new.env()
>> > e$x <- 2
>> > f <- function() x^2
>> > environment(f) <- e
>> > f()
>> >
>> > An alternative way to do the 3rd and 4th lines is
>> >
>> > f <- with(e, function() x^2)
>> >
>> > because that would evaluate the creation of f within e.
>> >
>> > A third approach (which might be the nicest one, depending on what else
>> > you
>> > are doing) is never to name e:
>> >
>> > f <- local({
>> >   x <- 2
>> >   function() x^2
>> > })
>> >
>> > Duncan Murdoch
>
>


From sjackman at gmail.com  Wed Jun 26 02:07:53 2013
From: sjackman at gmail.com (Shaun Jackman)
Date: Tue, 25 Jun 2013 17:07:53 -0700
Subject: [R] Comparing each level of a factor to the global mean
Message-ID: <CADX6M3rzg9ryM62eRLzci8WtfXLPcxMMa_yV_QEc3Q7C1d9j7A@mail.gmail.com>

Hi,

I've used `lm` to create a linear model of a continuous variable
against a factor variable with four levels using an example R data set
(see below). By default, it uses a treatment contrast matrix that
compares each level of the factor variable with the first reference
level (three comparisons in total). I'd like to compare each level
with the global mean (four comparisons in total), and produce a table
similar to `summary.lm`. How do I go about this?

```r
model <- lm(weight ~ Diet, ChickWeight)
summary(model)
```

Thanks,
Shaun


From kimbet3 at yahoo.com  Wed Jun 26 03:16:49 2013
From: kimbet3 at yahoo.com (bett kimutai)
Date: Tue, 25 Jun 2013 18:16:49 -0700 (PDT)
Subject: [R] Loops
In-Reply-To: <0EFBC7C31DB4F24F8CAC48136A1762D70184E52CAF09@MAIL2.rose.portland.local>
References: <1372141324.57953.YahooMailNeo@web142405.mail.bf1.yahoo.com>
	<1372168090.49111.YahooMailNeo@web142405.mail.bf1.yahoo.com>
	<1372176438.6229.YahooMailNeo@web142405.mail.bf1.yahoo.com>
	<1372192305.23908.YahooMailNeo@web142406.mail.bf1.yahoo.com>
	<0EFBC7C31DB4F24F8CAC48136A1762D70184E52CAF09@MAIL2.rose.portland.local>
Message-ID: <1372209409.55763.YahooMailNeo@web142401.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130625/ea38b8ce/attachment.pl>

From dwinsemius at comcast.net  Wed Jun 26 03:24:02 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 25 Jun 2013 18:24:02 -0700
Subject: [R] do.call environment misunderstanding
In-Reply-To: <CAHgH9_F4A5VehfnkkEAexzNTPL93QTGtN751Tk3D_7avwi-X3A@mail.gmail.com>
References: <CAHgH9_Fdbb7N1DZ91ExF7H0xca1Ngg7egT+XQzfmPprtaKKUHg@mail.gmail.com>
	<51C99FD1.1010802@gmail.com>
	<CAHgH9_GCURDgUQ=qkP-sijw5XabjHAqfFf2WNM72FRXSriKK+Q@mail.gmail.com>
	<51C9CB36.9070605@gmail.com>
	<CAHgH9_F4A5VehfnkkEAexzNTPL93QTGtN751Tk3D_7avwi-X3A@mail.gmail.com>
Message-ID: <44C5A92B-2E1F-40CA-B3CC-93B47C615A36@comcast.net>


On Jun 25, 2013, at 6:05 PM, Dan Murphy wrote:

> My problem is to evaluate a function/model whose definition and
> parameters (I'll put x into the arguments) and other data are saved by
> someone else in an Rdata file, but I don't know the function name,
> definition or data. Nevertheless, I need to save whatever functional
> values/model solutions are so determined and to compare and contrast
> solutions of same and similar problems over time. Environments seemed
> to hold promise, but understanding the relationship between f and e
> was my first hurdle. Thanks again.
> 

The load() function has an optional 'envir' parameter. Then you can just use ls().

> xx <- pi; f <- function() print(xx) 
> save(xx, f,  file= "test.RData")
> rm(list=c('xx','f') 
+ )
> load("test.RData", envir=env)
> ls(env)
[1] "f"  "xx"
> find('f')
character(0)
> grep("f", ls(envir=env, all.names=TRUE))
[1] 1
> grep("f", ls(envir=env))
[1] 1
> apropos("f", where=env)
Error in if (where) structure(li, names = rep.int(i, length(li))) else li : 
  argument is not interpretable as logical
In addition: Warning message:
In if (where) structure(li, names = rep.int(i, length(li))) else li :
  the condition has length > 1 and only the first element will be used
> grep("xx", ls(envir=env))
[1] 2

-- 
David.
> On Tue, Jun 25, 2013 at 9:54 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 25/06/2013 11:56 AM, Dan Murphy wrote:
>>> 
>>> So the trick is to put the function f into e and define its environment to
>>> be e:
>> 
>> 
>> Putting f into e, and defining the environment of f to be e solve different
>> problems.  Your toy example has both problems so it's a reasonable solution
>> there, but most real examples don't, so I wouldn't think of those two
>> solutions as being connected.
>> 
>> Duncan Murdoch
>> 
>> 
>>>> e <- new.env()
>>>> e$f <- function() x^2
>>>> environment(e$f) <- e
>>>> e$x <- 2
>>>> do.call("f", list(), envir = e)
>>> [1] 4
>>> 
>>> Thanks, Duncan.
>>> 
>>> On Tue, Jun 25, 2013 at 6:49 AM, Duncan Murdoch
>>> <murdoch.duncan at gmail.com> wrote:
>>>> On 25/06/2013 9:32 AM, Dan Murphy wrote:
>>>>> 
>>>>> I am having difficulty understanding the envir argument of do.call.
>>>>> The help page says
>>>>> 
>>>>> envir  an environment within which to evaluate the call.
>>>>> 
>>>>> so I thought that in the following toy example x would be found in the
>>>>> environment e and f would return 4 via do.call:
>>>>> 
>>>>>> e <- new.env()
>>>>>> e$x <- 2
>>>>>> f <- function() x^2
>>>>>> do.call(f, list(), envir = e)
>>>>> Error in (function ()  : object 'x' not found
>>>>> 
>>>>> Thanks in advance for clarifying my misunderstanding.
>>>> 
>>>> 
>>>> do.call will construct the expression f(), then evaluate it in e. It
>>>> will
>>>> try to look up f there, and not finding it, will go to the parent
>>>> environment and find it.
>>>> 
>>>> When evaluating the function, the environment in which it was evaluated
>>>> is
>>>> used for looking up arguments, but f() has none, so e is not used at
>>>> all.  R
>>>> will use the environment attached to f, which is the global environment,
>>>> since you created f by evaluating its definition there.
>>>> 
>>>> To get what you want, you could use the sequence
>>>> 
>>>> 
>>>> e <- new.env()
>>>> e$x <- 2
>>>> f <- function() x^2
>>>> environment(f) <- e
>>>> f()
>>>> 
>>>> An alternative way to do the 3rd and 4th lines is
>>>> 
>>>> f <- with(e, function() x^2)
>>>> 
>>>> because that would evaluate the creation of f within e.
>>>> 
>>>> A third approach (which might be the nicest one, depending on what else
>>>> you
>>>> are doing) is never to name e:
>>>> 
>>>> f <- local({
>>>>  x <- 2
>>>>  function() x^2
>>>> })
>>>> 
>>>> Duncan Murdoch
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ripley at stats.ox.ac.uk  Wed Jun 26 08:44:35 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 26 Jun 2013 07:44:35 +0100
Subject: [R] R CMD BATCH Unicode
In-Reply-To: <92A981B3677AE44384E1ABE4B16D87244E4643C0@MAIL1BDVM01.extendthereach.com>
References: <92A981B3677AE44384E1ABE4B16D87244E46404B@MAIL1BDVM01.extendthereach.com>
	<92A981B3677AE44384E1ABE4B16D87244E4643C0@MAIL1BDVM01.extendthereach.com>
Message-ID: <51CA8DD3.3090107@stats.ox.ac.uk>

On 25/06/2013 20:35, Ned Harding wrote:
> Just to clarify: The encoding didn't come through in the email.  print("????????????") is meant to be a bunch of random greek characters.

In that case the message is likely correct.  You failed to give us the 
'at a minimum information' required by the posting guide, but you can 
only have input scripts in the locale encoding (and there are no UTF-8 
locales on Windows).  So unless you were in a Greek locale, the 
re-encoding should have failed.

> Ned.
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Ned Harding
> Sent: Tuesday, June 25, 2013 11:35 AM
> To: r-help at r-project.org
> Subject: [R] R CMD BATCH Unicode
>
> Hey,
>
> I am looking for some help using Unicode with R CMD BATCH on windows.  In particular I would like my input and output files to be UTF-8 encoded.  My command line looks like this:
>
> r CMD BATCH --encoding=UTF-8 in.txt out.txt
>
> in.txt is utf-8 encoded and contains:
>
> print("????????????")
>
> out.txt gets:
>
> + <ERROR: re-encoding failure from encoding 'UTF-8'>
>
> What is the proper way to specify encoding on the command line?
>
> Thanks in advance,
>
> Ned.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Please do, and note what it says about HTML mail, too.



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pdalgd at gmail.com  Wed Jun 26 09:08:54 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 26 Jun 2013 09:08:54 +0200
Subject: [R] Heatmap with error message: `x' must be a numeric matrix
In-Reply-To: <51C9F4B8.509@sapo.pt>
References: <F18DFC4F-FAF6-48AD-A48D-A3166192C1E6@hum-gen.au.dk>
	<51C9F4B8.509@sapo.pt>
Message-ID: <B257C20C-EEE7-46FC-97C0-7D503BEFB614@gmail.com>


On Jun 25, 2013, at 21:51 , Rui Barradas wrote:

> Hello,
> 
> Your data has commas as decimal points, R uses the period. So the data is read in as strings, not numbers. You can change this by using argument 'dec' of read.table:
> 
> ?read.table
> read.table(...etc..., dec = ",")
> 
> 
> Or you can replace the commas with periods:
> 

Or use read.delim2(). That is what it is for.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From petr.pikal at precheza.cz  Wed Jun 26 09:51:12 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 26 Jun 2013 07:51:12 +0000
Subject: [R] Loops
In-Reply-To: <1372209409.55763.YahooMailNeo@web142401.mail.bf1.yahoo.com>
References: <1372141324.57953.YahooMailNeo@web142405.mail.bf1.yahoo.com>
	<1372168090.49111.YahooMailNeo@web142405.mail.bf1.yahoo.com>
	<1372176438.6229.YahooMailNeo@web142405.mail.bf1.yahoo.com>
	<1372192305.23908.YahooMailNeo@web142406.mail.bf1.yahoo.com>
	<0EFBC7C31DB4F24F8CAC48136A1762D70184E52CAF09@MAIL2.rose.portland.local>
	<1372209409.55763.YahooMailNeo@web142401.mail.bf1.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802810554@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of bett kimutai
> Sent: Wednesday, June 26, 2013 3:17 AM
> To: Law, Jason; r-help at r-project.org
> Subject: Re: [R] Loops
> 
> Thanks for you response. The issue is that I need to run a thousand
> simulations for each pipe (20000) and then get an average of the values
> that are below the condition I have set. When I ran the code, I only
> get just a thousand values meaning it gives me values for a single

How do you get result with syntax error code? 

Anyway did you give a chance to help provided by Jason? If I understand your code, you have three "k" values based on them you compute three "l" values with a differnt constant each time. Based on this you can get

> k<-c(1.15, .504, .43) 
> (7.16-0.44+0.12-0.016)
[1] 6.824
> (8.01-1.5+0.35+0.45)
[1] 7.31
> 9.55-2.45+0.40+0.65
[1] 8.15
> m<-c(6.824,7.31,8.15)
> l=exp((1/k)*(m))
> l
[1] 3.776293e+02 1.990643e+06 1.703709e+08

then you want to get z vector in 3 steps

z <- (log(1/p)*l[1])^k[1]
z[z<=684] <-  (log(1/p)*l[2])^k[2]
z[z<=684] <-  (log(1/p)*l[3])^k[3]

you maybe want to subset also p

and you need top repeat this 1000 times probably in loop to populate resulting matrix.

Anyyway some example of data and working code would be helpful.

Regards
Petr


> pipe. How can I rectify my loop to run for all the pipes and then
> create a table to hold these values. Sorry for the syntax errors,
> I?guess I will get them with time.
> 
> 
> thanks again..
> 
> ________________________________
>  From: "Law, Jason" <Jason.Law at portlandoregon.gov>
> 
> ect.org>
> Sent: Tuesday, June 25, 2013 3:32 PM
> Subject: RE: [R] Loops
> 
> 
> Not sure what you're trying to do, but it looks like most of what
> you're attempting to do in the code can be done just using vectors
> rather than loops, at least the inner loop.? For example:
> 
> k <- 1.15
> l <- exp((1 / k) * (7.16 - 0.44 + 0.12 - 0.016))
> z <- (log(1 / p) * l)^k
> 
> See ifelse for how to do the if tests on a vector.? In addition, much
> of the code in your loops doesn't vary with the loop indices and can be
> moved outside your loop (e.g., setting k = 1.15).? If you really
> want/need to use loops, you'll have to initialize the vectors/matrices
> within your loop with some value:
> 
> z <- numeric(1000)
> 
> Finally, you have some plain syntax errors:
> 
> p[i]=[i+1].
> 
> That's not valid R code; '[' is the extraction operator, see
> help('[').? I'm not sure what you're trying to do there.? Perhaps:
> 
> p[i] <- p[i + 1]
> 
> HTH,
> 
> Jason Law
> 
> 
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of bett kimutai
> Sent: Tuesday, June 25, 2013 1:32 PM
> To: r-help at r-project.org
> Subject: [R] Loops
> 
> Dear All,
> 
> 
> I? have spent most of my time trying to figure out how to simulate the
> number of breaks in a pipe using Monte Carlo simulation.
> i have 20,000 individual pipes that i have to run, and for each pipe i
> have to run 1000 times while checking some conditions and therefore, i
> have to use a nested loop.
> what i would like to have as a final result is a matrix table with with
> all the individual pipe elements and the simulated runs here is the
> loop that i tried to create x=20000 y=matrix(x, z)
> p=runif(1000)
> for(j in 1:20000) {
> for(i in 1:1000) {
> ?? ??? k=1.15
> ??? l=exp((1/k)*(7.16-0.44+0.12-0.016))
> 
> ??? z[i]=(log(1/p[i])*l)^k
> 
> ??? if (z[i] <=684)
> ??? {
> ??? ??? k1=0.504
> ??? ??? l1=exp((1/k)*(8.01-1.5+0.35+0.45))
> ??? ??? z1[i]=(log(1/p[i])*l1)^k1
> ??? if (z1[i] <=684)
> ??? {
> ??? ??? ??? ??? k2=0.43
> ??? ??? l2=exp((1/k2)*(9.55-2.45+0.40+0.65))
> ??? ??? z2[i]=(log(1/p[i])*l2)^k2
> ??? ??????????? p[i]=[i+1]
> ??? ??? ??? ??? break()
> ??? ??? ??? }
> ??? ??? }
> ??? }
> x[ j ]=[ j+1 ]
> }
> the last column of the table,? in addition to the simulated runs, i
> would like to have the summary of the means (for z<=684) of individual
> row as this means will give me the number of breaks.
> i will really appreciate if anyone who can help me figure out how to go
> about this. pardon me, I am new to R and programming.
> 
> 
> 
> Thank you in Advance,
> 
> Eliab
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ??? [[alternative HTML version deleted]]
> 	[[alternative HTML version deleted]]


From sachin.abeywardana at gmail.com  Wed Jun 26 10:03:09 2013
From: sachin.abeywardana at gmail.com (Sachinthaka Abeywardana)
Date: Wed, 26 Jun 2013 18:03:09 +1000
Subject: [R] match rows of R
Message-ID: <CAGuusR9dC_uV9McEFkz_g3GABrsKPHA7WrZD4o2aEXtXbDiwKA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130626/c44c904b/attachment.pl>

From johannesradinger at gmail.com  Wed Jun 26 10:15:48 2013
From: johannesradinger at gmail.com (Johannes Radinger)
Date: Wed, 26 Jun 2013 10:15:48 +0200
Subject: [R] Margins in dcast (reshape2)
Message-ID: <CABsGe_wSxRSsSY+SQhoiS5dMV7U77obw5Jv2h7mHufDwoRc0Vg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130626/bc8a9e9c/attachment.pl>

From bhh at xs4all.nl  Wed Jun 26 10:17:40 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 26 Jun 2013 10:17:40 +0200
Subject: [R] match rows of R
In-Reply-To: <CAGuusR9dC_uV9McEFkz_g3GABrsKPHA7WrZD4o2aEXtXbDiwKA@mail.gmail.com>
References: <CAGuusR9dC_uV9McEFkz_g3GABrsKPHA7WrZD4o2aEXtXbDiwKA@mail.gmail.com>
Message-ID: <95C8D325-4FD8-4167-B968-223558405C71@xs4all.nl>


On 26-06-2013, at 10:03, Sachinthaka Abeywardana <sachin.abeywardana at gmail.com> wrote:

> Hi all,
> 
> What would be an efficient way to match rows of a matrix to a vector?
> 
> ex:
> 
> m<-matrix(1:9, nrow=3)
> 
> m     [,1] [,2] [,3]
> [1,]    1    4    7
> [2,]    2    5    8
> [3,]    3    6    9
> 
> #################################
> which(m==c(2,5,8))        # I want this to return 2
> ######################

Something like this:

matroweqv <- function(m,v) which(t(m)==v, arr.ind=TRUE)[,2][1]

matroweqv(m,c(2,5,8))
# [1] 2


Berend


From yuliya.rmail at gmail.com  Wed Jun 26 10:30:15 2013
From: yuliya.rmail at gmail.com (Yuliya Matveyeva)
Date: Wed, 26 Jun 2013 12:30:15 +0400
Subject: [R] match rows of R
In-Reply-To: <CAGuusR9dC_uV9McEFkz_g3GABrsKPHA7WrZD4o2aEXtXbDiwKA@mail.gmail.com>
References: <CAGuusR9dC_uV9McEFkz_g3GABrsKPHA7WrZD4o2aEXtXbDiwKA@mail.gmail.com>
Message-ID: <CAOE1P1GWiSQb9P5ARsVziMWDHhzgA6dZROiuezYGvn-=htQ9Ag@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130626/2218f8e5/attachment.pl>

From johannesradinger at gmail.com  Wed Jun 26 10:36:43 2013
From: johannesradinger at gmail.com (Johannes Radinger)
Date: Wed, 26 Jun 2013 10:36:43 +0200
Subject: [R] Error when using median as aggregation function in dcast
Message-ID: <CABsGe_xLxVx4kiv0M6iJ+OOHZ8VSb0D-BLEuq9-gWe=1-SzDeA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130626/4c188881/attachment.pl>

From ivanovruporvrich at yahoo.com  Wed Jun 26 10:45:22 2013
From: ivanovruporvrich at yahoo.com (Ivanov Ruporvrich)
Date: Wed, 26 Jun 2013 09:45:22 +0100 (BST)
Subject: [R] Correct scaling of axis in persp3d plot
In-Reply-To: <9EB6C747-1762-4907-9B38-53BC194F69A5@comcast.net>
References: <1372189250.21293.YahooMailNeo@web171501.mail.ir2.yahoo.com>
	<9EB6C747-1762-4907-9B38-53BC194F69A5@comcast.net>
Message-ID: <1372236322.12817.YahooMailNeo@web171501.mail.ir2.yahoo.com>

I uploaded the data here: http://uploadeasy.net/upload/p4d81.rar

As I said, I know my color example is wrong, that's why I am looking for a correct solution,
also, I would be interested in how I can get a better axis, as I described the problem.

Thanks a lot for your help,
Ivanov




----- Urspr?ngliche Message -----
Von: David Winsemius <dwinsemius at comcast.net>
An: Ivanov Ruporvrich <ivanovruporvrich at yahoo.com>
CC: "r-help at r-project.org" <r-help at r-project.org>
Gesendet: 0:23 Mittwoch, 26.Juni 2013
Betreff: Re: [R] Correct scaling of axis in persp3d plot


On Jun 25, 2013, at 12:40 PM, Ivanov Ruporvrich wrote:

> Hi,
> I want to format my axis in my persp3d plot.
> 
> With my data, which I attached

You may have attached it ... but you probably didn't read the information about what would be accepted by the mail server. Read the listinfo page linked at the bottom of every posting to Rhelp.

> I created a persp3d plot with the following code, which I summarized from different code snippets I found:
> 
> library(rugarch)library(rgl)library(fGarch)

> fd <-as.data.frame(modelfit,which ='density')

Missing <CR>'s added to note that 'modelfit' was never created by the code posted to R-help.

> color <-rgb(85,141,85,maxColorValue=255)x <-seq(-0.2,0.2,length=100)y <-c(1:2318)f <-function(s,t){dged(s,mean=fd[t,'Mu'],sd=fd[t,'Sigma'],nu=fd[t,'Shape'])}z <-outer(x,y,f)persp3d(x,y,z,theta=50,phi=25,expand=0.75,col=color,ticktype="detailed",xlab="",ylab="time",zlab="",axes=TRUE,axes=FALSE)

Missing carriage returns are probably inhibiting people from reading this. 

> 
> axes3d(c('x--','z'))axis3d(edge='y+-',at =seq(500,2000,by=500),labels =rownames(fd)[seq(500,2000,by=500)])
> 
> My first question is:
> Currently I have four date ticks on my axis, but what I don't like is, that in my data, 
> the starting date is in 2004, but the plots look like, as if the starting year
> would be 2006. So I would like to have the starting year on the axis, but I don't
> know how to implement this (my R programming skills are limited)?
> 
> So e.g. I would like to have always the beginning of each year, 2004, 2005, 2006, 2007, 2008, 
> 2009, 2010, 2011 , 2012 or if this does not fit at leas I would like to
> have the beginning of the years 2004,2006,2008,2010,2012 so each second year.
> 
> My second question is:
> I would like to have a colored surface. So I would like to have e.g. the spikes of the surface in red (values 
> which are very larger) and lower values e.g. in green with a nice smooth transition between, e.g.
> values in the middle in yellow. So the coloring should depend on the z values. I tried the following, but it does not 
> give nice results:
> 
> nrz <- nrow(z)
> ncz <- ncol(z)
> jet.colors <- 

If you wanted a transition from red to green, then why use those values that go from pale red to dark red? Shouldn't it be:

mycols <- colorRampPalette( c("#ff0000", "#00ff00") ) 

Or:

mycols <- colorRampPalette( c("#00ff00", "#ff0000") )

> # Generate the desired number of colors from this palette
> nbcol <- 100
> color <- jet.colors(nbcol)
> 
> # Compute the z-value at the facet centres
> zfacet <- z[-1, -1] + z[-1, -ncz] + z[-nrz, -1] + z[-nrz, -ncz]

That looks wrong. Appears you are using code from the example in ?persp rather than using the z values appropriate to persp3d.

> # Recode facet z-values into color indices
> facetcol <- cut(zfacet, nbcol)
> 
> persp3d(x, y, z, theta=50, phi=25, expand=0.75, col=color[facetcol],
> ticktype="detailed", xlab="", ylab="time", zlab="",axes=TRUE)
> 
> Thanks a lot for your help,
> Ivanov
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA



From bhh at xs4all.nl  Wed Jun 26 11:13:52 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 26 Jun 2013 11:13:52 +0200
Subject: [R] match rows of R
In-Reply-To: <CAOE1P1GWiSQb9P5ARsVziMWDHhzgA6dZROiuezYGvn-=htQ9Ag@mail.gmail.com>
References: <CAGuusR9dC_uV9McEFkz_g3GABrsKPHA7WrZD4o2aEXtXbDiwKA@mail.gmail.com>
	<CAOE1P1GWiSQb9P5ARsVziMWDHhzgA6dZROiuezYGvn-=htQ9Ag@mail.gmail.com>
Message-ID: <E76E37DB-18B2-4C7C-9258-0041965B1E2D@xs4all.nl>


On 26-06-2013, at 10:30, Yuliya Matveyeva <yuliya.rmail at gmail.com> wrote:

> I suggest using vectorization :
> 
> find_row <- function(m,v) { which(!(abs(rowSums(m - rep(v, each = nrow(m)))
> )) > 0) }
> 
> The function matroweqv mentioned above would give any row with the first
> element equal to the first element in vector v.

Correct.
This version should be better

matroweqv <- function(m,v) {
    z <- which(t(m)==v, arr.ind=TRUE,useNames=FALSE)
    if(dim(z)[1]==0) return(NA) else if(all(z[,2]==z[1,2])) return(z[1,2])  else return(NA)
}                     

Instead of NA one could also return -1 if no row equals the vector.

Berend


> The function find_row matches each row of the matrix as a whole to the
> vector v.
> 
> 
> 2013/6/26 Sachinthaka Abeywardana <sachin.abeywardana at gmail.com>
> 
>> Hi all,
>> 
>> What would be an efficient way to match rows of a matrix to a vector?
>> 
>> ex:
>> 
>> m<-matrix(1:9, nrow=3)
>> 
>> m     [,1] [,2] [,3]
>> [1,]    1    4    7
>> [2,]    2    5    8
>> [3,]    3    6    9
>> 
>> #################################
>> which(m==c(2,5,8))        # I want this to return 2
>> ######################
>> 
>> Thanks,
>> Sachin
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> 
> -- 
> Sincerely yours,
> Yulia Matveyeva,
> Department of Statistical Modelling,
> Faculty of Mathematics and Mechanics,
> St Petersburg State University, Russia
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Wed Jun 26 11:23:34 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 26 Jun 2013 11:23:34 +0200
Subject: [R] Psych package: Error in biplot.psych(sample.mod) : Biplot
	requires factor/component scores:
In-Reply-To: <88EDBE45-0F1E-499E-A5A9-676F96819D03@gmail.com>
References: <88EDBE45-0F1E-499E-A5A9-676F96819D03@gmail.com>
Message-ID: <AA97DC4D-B7AB-4563-8272-FDFBB7739FC2@gmail.com>


On Jun 26, 2013, at 00:33 , Simon Kiss wrote:

> Hello: I'm trying to construct a biplot from the psych package. The underlying data frame looks just like sample.data, below. I turned it into a polychoric correlation matrix sample.cor, below, as it is derived from a series of Likert (ordinal) items. All are positive, I just used negative numbers in this dataset to get two separate factors.  I created a PCA from sample.cor$rho, specifying that scores were to be kept via scores=TRUE, but the command, biplot.psych(sample.mod) returns the error message: Error in biplot.psych, Biplot requires factor/component scores.
> But it seems from the help documentation, that one really only has to use the command biplot(mod) to get the plot.
> Can someone please advise?
> Yours, Simon Kiss


I'm not familiar with the psych package, but biplots can't generally be constructed from an analysis that is based on the correlation matrix alone (as opposed to using the original data). I would expect that the scores=TRUE has no effect since principal() is given no access to the original data. 

It is not clear to me how to compute individual scores in a PCA based on polychoric correlations. (Someone might have figured out a way, but it is non-obvious.)


> #Sample data
> sample.data<-data.frame(var1=sample(c(0,0.33, 0.66, 1), size=100, replace=TRUE), var2=sample(c(0,0.33, 0.66, 1), size=100, replace=TRUE), var3=sample(c(0,-0.33, -0.66, -1), size=100, replace=TRUE), var4=sample(c(0,-0.33,-0.66,-1), size=100, replace=TRUE))
> 
> #Correlation Matrix
> sample.cor<-polychoric(sample.data, polycor=TRUE)
> #Principal Components Analysis
> sample.mod<-principal(sample.cor$rho, nfactors=2,scores=TRUE,covar=TRUE)
> #Draw Biplot
> biplot.psych(sample.mod)
> 
> #error
> Error in biplot.psych(sample.mod) : 
>  Biplot requires factor/component scores:
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From S.Ellison at lgcgroup.com  Wed Jun 26 12:57:24 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Wed, 26 Jun 2013 11:57:24 +0100
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <51C97A30.7050802@gmail.com>
References: <51C8CBCE.3040903@gmail.com> <1372123341449.dc8da696@Nodemailer>
	<51C97A30.7050802@gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED4AC9F091C5@GOLD.corp.lgc-group.com>

 

> -----Original Message-----
> It may be helpful not to worry about the technical details, 
> just to look at the source code defining the function:  if it 
> is defined in a place where a variable can be seen, it can 
> see that variable.

I too find R's lexical scoping rules straightforward.
However, I'd say that if your code relies on lexical scoping to find something, you should probably rewrite your code.

The number of times I've seen new R users get unexpected results because they haven't noticed that their function is referencing a parent environment instead of a locally defined variable or argument is past counting.

Of course there are times when it's useful and sensible to have globally defined variables that can be accessed within a function. But they are very rare; as a default, I'd recommend avoiding it if at all possible. If your function needs something from outside, pass it as an argument.



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From istazahn at gmail.com  Wed Jun 26 13:12:17 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 26 Jun 2013 07:12:17 -0400
Subject: [R] Margins in dcast (reshape2)
In-Reply-To: <CABsGe_wSxRSsSY+SQhoiS5dMV7U77obw5Jv2h7mHufDwoRc0Vg@mail.gmail.com>
References: <CABsGe_wSxRSsSY+SQhoiS5dMV7U77obw5Jv2h7mHufDwoRc0Vg@mail.gmail.com>
Message-ID: <CA+vqiLG2V2wS=6g=3CQz_5Rs5XTtQRe4j-6iNy12CXMg96D9qQ@mail.gmail.com>

Hi Johannes,

I think the documentation is wrong. The Readme at
https://github.com/hadley/reshape says grand_row and grand_col have
been dropped. You should submit a bug report at
https://github.com/hadley/reshape/issues describing the documentation
problem.

Best,
Ista

On Wed, Jun 26, 2013 at 4:15 AM, Johannes Radinger
<johannesradinger at gmail.com> wrote:
> Hi,
>
>
> I'd like to get mean values for the margins of my casted data.frame.
> For the casting I am using dcast() from reshape2. However, when I set
> the margins parameter (margins=c("grand\_row")) I get following error
> concerning
> an unrecognized escape character '\_'. So what is the correct command
> to get the outermost margins only in reshape2?
>
> /johannes
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Wed Jun 26 13:35:55 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 26 Jun 2013 07:35:55 -0400
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED4AC9F091C5@GOLD.corp.lgc-group.com>
References: <51C8CBCE.3040903@gmail.com> <1372123341449.dc8da696@Nodemailer>
	<51C97A30.7050802@gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED4AC9F091C5@GOLD.corp.lgc-group.com>
Message-ID: <51CAD21B.4020303@gmail.com>

On 13-06-26 6:57 AM, S Ellison wrote:
>
>
>> -----Original Message-----
>> It may be helpful not to worry about the technical details,
>> just to look at the source code defining the function:  if it
>> is defined in a place where a variable can be seen, it can
>> see that variable.
>
> I too find R's lexical scoping rules straightforward.
> However, I'd say that if your code relies on lexical scoping to find something, you should probably rewrite your code.
>
> The number of times I've seen new R users get unexpected results because they haven't noticed that their function is referencing a parent environment instead of a locally defined variable or argument is past counting.
>
> Of course there are times when it's useful and sensible to have globally defined variables that can be accessed within a function. But they are very rare; as a default, I'd recommend avoiding it if at all possible. If your function needs something from outside, pass it as an argument.
>

I would say the meaning of "probably" in your 2nd sentence depends quite 
a bit on the user.  For beginners, it's "almost certainly".  For people 
who are comfortable with the concept, it's just "maybe".

I would agree that in most cases the only global objects that functions 
should reference are other functions, but small nested functions are 
quite safe, and it's sometimes useful to create functions in a local 
environment so they have persistent memory.

Duncan Murdoch


From nicomet80 at gmail.com  Wed Jun 26 13:37:44 2013
From: nicomet80 at gmail.com (Nico Met)
Date: Wed, 26 Jun 2013 13:37:44 +0200
Subject: [R] Transpose of the rows
Message-ID: <CAMMD=S5Evy1jUbhewB2C6=9pNwX5fPU3PYWJr7yzqRenWT3huA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130626/f3e54426/attachment.pl>

From smartpink111 at yahoo.com  Wed Jun 26 14:13:31 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 26 Jun 2013 05:13:31 -0700 (PDT)
Subject: [R] Transpose of the rows
In-Reply-To: <CAMMD=S5Evy1jUbhewB2C6=9pNwX5fPU3PYWJr7yzqRenWT3huA@mail.gmail.com>
References: <CAMMD=S5Evy1jUbhewB2C6=9pNwX5fPU3PYWJr7yzqRenWT3huA@mail.gmail.com>
Message-ID: <1372248811.70249.YahooMailNeo@web142606.mail.bf1.yahoo.com>

?dta[,3]<-as.numeric(as.character(gsub(",",".",dta[,3])))
library(reshape2)

? dcast(dta,id~name,value.var="value")
#??????????? id?? AreaCycl?? AreaEmer?? AreaMax? HeightMax nrfilledseed
#1 TN00016-003A -1.3998944 -3.2771509 -3281.077?? 8.434493??????? 1.825
#2 TN00016-014A -0.5843794 -0.8428928 -7939.444 -13.594147?????? 12.200
#3 TN00031-014A? 0.8001962? 0.1741609 -1200.824 -25.868973?????????? NA

A.K.


----- Original Message -----
From: Nico Met <nicomet80 at gmail.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Wednesday, June 26, 2013 7:37 AM
Subject: [R] Transpose of the rows

Dear R users,

I am using a big data matrix and need to transpose rows (formatting of
input matrix). I would like write a general code for this example.

for example: my input file is "dta"

dput(dta)
structure(list(id = structure(c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
2L, 2L, 3L, 3L, 3L, 3L), .Label = c("TN00016-003A", "TN00016-014A",
"TN00031-014A"), class = "factor"), name = structure(c(1L, 2L,
3L, 4L, 5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L), .Label = c("AreaCycl",
"AreaEmer", "AreaMax", "HeightMax", "nrfilledseed"), class = "factor"),
? ? value = structure(c(3L, 7L, 8L, 14L, 12L, 1L, 2L, 9L, 5L,
? ? 13L, 11L, 10L, 4L, 6L), .Label = c("-0,584379415", "-0,842892819",
? ? "-1,399894415", "-1200,824457", "-13,59414667", "-25,86897333",
? ? "-3,277150907", "-3281,076515", "-7939,444248", "0,174160882",
? ? "0,800196212", "1,825", "12,2", "8,434493333"), class = "factor")),
.Names = c("id",
"name", "value"), class = "data.frame", row.names = c(NA, -14L
))

And output should look like this:

dput(dta1)
structure(list(id = structure(1:3, .Label = c("TN00016-003A",
"TN00016-014A", "TN00031-014A"), class = "factor"), AreaCycl = structure(c(
2L,
1L, 3L), .Label = c("-0,584379415", "-1,399894415", "0,800196212"
), class = "factor"), AreaEmer = structure(c(2L, 1L, 3L), .Label = c(
"-0,842892819",
"-3,277150907", "0,174160882"), class = "factor"), AreaMax = structure(c(
2L,
3L, 1L), .Label = c("-1200,824457", "-3281,076515", "-7939,444248"
), class = "factor"), HeightMax = structure(c(3L, 1L, 2L), .Label = c(
"-13,59414667",
"-25,86897333", "8,434493333"), class = "factor"), nrfilledseed = structure(
c(1L,
2L, NA), .Label = c("1,825", "12,2"), class = "factor")), .Names = c("id",
"AreaCycl", "AreaEmer", "AreaMax", "HeightMax", "nrfilledseed"
), class = "data.frame", row.names = c(NA, -3L))

Thanks for your help.

Nico

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Wed Jun 26 14:20:07 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 26 Jun 2013 05:20:07 -0700 (PDT)
Subject: [R] Error when using median as aggregation function in dcast
In-Reply-To: <CABsGe_xLxVx4kiv0M6iJ+OOHZ8VSb0D-BLEuq9-gWe=1-SzDeA@mail.gmail.com>
References: <CABsGe_xLxVx4kiv0M6iJ+OOHZ8VSb0D-BLEuq9-gWe=1-SzDeA@mail.gmail.com>
Message-ID: <1372249207.1502.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
Please check this link:
http://stackoverflow.com/questions/4835202/error-with-custom-aggregate-function-for-a-cast-call-in-r-reshape2
A.K.




----- Original Message -----
From: Johannes Radinger <johannesradinger at gmail.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Wednesday, June 26, 2013 4:36 AM
Subject: [R] Error when using median as aggregation function in dcast

Hi,


I am trying to calculated various summary statistics using the dcast
function
of reshape2. This works perfectly for getting the mean, sum, length, sd. But
when I want to calculate the median I get an error. I tried it with and
without removing
NAs:

my_median <- function(x) median(x, na.rm = FALSE)
median_df <- dcast(patch_stats_dfm,formula=species~input+barriers,my_median)

Error in vapply(indices, fun, .default) : values must be type 'integer',
but FUN(X[[1]]) result is type 'double'

What does this error mean and what is causing the error, resp. how can I
solve the problem and
get a median?

/Johannes

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From nblaser at ispm.unibe.ch  Wed Jun 26 14:20:22 2013
From: nblaser at ispm.unibe.ch (Blaser Nello)
Date: Wed, 26 Jun 2013 14:20:22 +0200
Subject: [R] Transpose of the rows
In-Reply-To: <CAMMD=S5Evy1jUbhewB2C6=9pNwX5fPU3PYWJr7yzqRenWT3huA@mail.gmail.com>
References: <CAMMD=S5Evy1jUbhewB2C6=9pNwX5fPU3PYWJr7yzqRenWT3huA@mail.gmail.com>
Message-ID: <17EE8C62EA18B84B94C2BA96A143064C01721A85@mx01.ispm.unibe.ch>

reshape(dta, idvar="id", timevar="name", direction="wide")


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
On Behalf Of Nico Met
Sent: Mittwoch, 26. Juni 2013 13:38
To: R help
Subject: [R] Transpose of the rows

Dear R users,

I am using a big data matrix and need to transpose rows (formatting of
input matrix). I would like write a general code for this example.

for example: my input file is "dta"

 dput(dta)
structure(list(id = structure(c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,
3L, 3L, 3L, 3L), .Label = c("TN00016-003A", "TN00016-014A",
"TN00031-014A"), class = "factor"), name = structure(c(1L, 2L, 3L, 4L,
5L, 1L, 2L, 3L, 4L, 5L, 1L, 2L, 3L, 4L), .Label = c("AreaCycl",
"AreaEmer", "AreaMax", "HeightMax", "nrfilledseed"), class = "factor"),
    value = structure(c(3L, 7L, 8L, 14L, 12L, 1L, 2L, 9L, 5L,
    13L, 11L, 10L, 4L, 6L), .Label = c("-0,584379415", "-0,842892819",
    "-1,399894415", "-1200,824457", "-13,59414667", "-25,86897333",
    "-3,277150907", "-3281,076515", "-7939,444248", "0,174160882",
    "0,800196212", "1,825", "12,2", "8,434493333"), class = "factor")),
...Names = c("id", "name", "value"), class = "data.frame", row.names =
c(NA, -14L
))

And output should look like this:

dput(dta1)
structure(list(id = structure(1:3, .Label = c("TN00016-003A",
"TN00016-014A", "TN00031-014A"), class = "factor"), AreaCycl =
structure(c( 2L, 1L, 3L), .Label = c("-0,584379415", "-1,399894415",
"0,800196212"
), class = "factor"), AreaEmer = structure(c(2L, 1L, 3L), .Label = c(
"-0,842892819", "-3,277150907", "0,174160882"), class = "factor"),
AreaMax = structure(c( 2L, 3L, 1L), .Label = c("-1200,824457",
"-3281,076515", "-7939,444248"
), class = "factor"), HeightMax = structure(c(3L, 1L, 2L), .Label = c(
"-13,59414667", "-25,86897333", "8,434493333"), class = "factor"),
nrfilledseed = structure( c(1L, 2L, NA), .Label = c("1,825", "12,2"),
class = "factor")), .Names = c("id", "AreaCycl", "AreaEmer", "AreaMax",
"HeightMax", "nrfilledseed"
), class = "data.frame", row.names = c(NA, -3L))

Thanks for your help.

Nico

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jvadams at usgs.gov  Wed Jun 26 14:50:34 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 26 Jun 2013 07:50:34 -0500
Subject: [R] Comparing each level of a factor to the global mean
In-Reply-To: <CADX6M3rzg9ryM62eRLzci8WtfXLPcxMMa_yV_QEc3Q7C1d9j7A@mail.gmail.com>
References: <CADX6M3rzg9ryM62eRLzci8WtfXLPcxMMa_yV_QEc3Q7C1d9j7A@mail.gmail.com>
Message-ID: <CAN5YmCHK0-txj28HOiP8SwjjRGZPTZ47yDezP25HsR=pq4h4pA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130626/b56c14d4/attachment.pl>

From jvadams at usgs.gov  Wed Jun 26 15:08:28 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 26 Jun 2013 08:08:28 -0500
Subject: [R] Calculating an index of colocation for a large dataset
In-Reply-To: <1372197638550-4670325.post@n4.nabble.com>
References: <1371853137063-4670084.post@n4.nabble.com>
	<CAN5YmCHCgmZDAUZTDkXAB45rm92wRh2Cf=_FyMLUi0E4a+jPVA@mail.gmail.com>
	<CAN5YmCF4ym3qXnP3U3s6HH3bUXk6bsiD6HhZESWfbfX6a=_1Kg@mail.gmail.com>
	<1372197638550-4670325.post@n4.nabble.com>
Message-ID: <CAN5YmCF01f102i+8akZC0D8UjnktCHQJ_x=weaz56uHWTmY-8g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130626/e31516ff/attachment.pl>

From simone.gabbriellini at gmail.com  Wed Jun 26 17:19:35 2013
From: simone.gabbriellini at gmail.com (Simone Gabbriellini)
Date: Wed, 26 Jun 2013 17:19:35 +0200
Subject: [R] help with plotmeans (gplots)
Message-ID: <CAEy8Jr2A8LwM0HrmnwvYH5Ge70p_w0A8aX-LnpkYX3ajDCVi4A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130626/82c3e2c8/attachment.pl>

From jrkrideau at inbox.com  Wed Jun 26 17:34:59 2013
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 26 Jun 2013 07:34:59 -0800
Subject: [R] Fwd: Questions about working with a dataframe
In-Reply-To: <trinity-3fc25609-b1e9-440b-8527-7e4ca46833be-1372238321822@3capp-gmx-bs34>
References: <f90bbb3f8fb.00000235jrkrideau@inbox.com>
	<4251c1a6-d423-45b4-8684-531d7c36670b@comcast.net>
	<f3cacab8-6537-424a-8bbc-1dd2e5b09985@gmx.ch>
Message-ID: <056CC4A37ED.00001168jrkrideau@inbox.com>

It is always better when dealing with R to use plain text. HTML messes things up badly sometimes and it is also a good idea to reply to the R-help list rather than individual respondents.? You can get more responses if the problem continues and if either of us were away then it might be weeks before we managed to reply

Other responses in line

John Kane
Kingston ON Canada

-----Original Message-----
From: jacqueline.oehri at gmx.ch
Sent: Wed, 26 Jun 2013 11:18:41 +0200 (CEST)
To: dwinsemius at comcast.net, jrkrideau at inbox.com, r-help at r-project.org
Subject: Aw: Re: [R] Fwd: Questions about working with a dataframe

Dear Mr. Kane and dear Mr. Winsemius

Thanks a lot for your quick answers and good recommendations!!! And I apologise for attaching such a big file before!!

I think I could solve the problem;

Maybe you can tell me if its right what I have done?

As John said, the str(WWA) and str(oWWA) gave different outputs for "WWA$speciesName":

> class(WWA$speciesName)
 [1] "character"

> class(oWWA$speciesName)
 [1] "factor"

What I did is this:

> oWWA$speciesName <-as.character(oWWA$speciesName)

and now I've got:

> class(oWWA$speciesName)
 [1] "character"

and the function I wanted to use works well:

> Sp_per_coordID_oWWA <-tapply((oWWA$speciesName), oWWA$coordID, list)

-->Question: Do you think I did this right and this didn't mess up the structure of the dataset? As far as I can see, I see no problem but I m not so experienced as you are!

.Yes, I think you found the problem.? It is always a good idea to use str() when reading in a csv file and even when doing data transformations with R as things can change in sometimes unexpected ways.

You might also want to look at "stringsAsFactors" which is either TRUE or FALSE.? For historical reasons, what I cannot remember, R often reads in repetitive strings as Factors rather than Characters.

Thank you very very much for your answers!!! It helped me a lot!!

-->second Question: I had problems with using dput(head(WWA)), because I think its still too big, so that I m not able to post all the output from "dput(head(WWA)))", even when i subsetted it first to only three rows:

> WWAsubset <-WWA[c(1:3),]
 > dput(head(WWAsubset))

(see after str(WWA) and str(oWWA)

Yes you can set the number of lines of output with something like dput(head(dat1, 10)) which would output the first 10 lines of the data.frame dat1.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From darrenwhitehead_ at hotmail.com  Wed Jun 26 13:39:30 2013
From: darrenwhitehead_ at hotmail.com (Darren Andrew Whitehead)
Date: Wed, 26 Jun 2013 13:39:30 +0200
Subject: [R] Generalised Linear models in R-Studio
Message-ID: <DUB113-W728379A6BE3F185057EFEF1740@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130626/2421f450/attachment.pl>

From jen_t1ckner at hotmail.com  Wed Jun 26 10:17:33 2013
From: jen_t1ckner at hotmail.com (Jennifer Tickner)
Date: Wed, 26 Jun 2013 08:17:33 +0000
Subject: [R] Creating a matrix with an unknown variable
Message-ID: <DUB117-W882ADEBD88C5CE42D84137C5740@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130626/912eeb72/attachment.pl>

From jacqueline.oehri at gmx.ch  Wed Jun 26 11:18:41 2013
From: jacqueline.oehri at gmx.ch (Jacqueline Oehri)
Date: Wed, 26 Jun 2013 11:18:41 +0200 (CEST)
Subject: [R] Fwd: Questions about working with a dataframe
In-Reply-To: <4251C1A6-D423-45B4-8684-531D7C36670B@comcast.net>
References: <f3cacab8-6537-424a-8bbc-1dd2e5b09985@gmx.ch>
	<F90BBB3F8FB.00000235jrkrideau@inbox.com>,
	<4251C1A6-D423-45B4-8684-531D7C36670B@comcast.net>
Message-ID: <trinity-3fc25609-b1e9-440b-8527-7e4ca46833be-1372238321822@3capp-gmx-bs34>



   Dear Mr. Kane and dear Mr. Winsemius

   Thanks  a lot for your quick answers and good recommendations!!! And I
   apologise for attaching such a big file before!!
   I think I could solve the problem;
   Maybe you can tell me if its right what I have done?

   As  John  said,  the str(WWA) and str(oWWA) gave different outputs for
   "WWA$speciesName":

   > class(WWA$speciesName)
   [1] "character"
   > class(oWWA$speciesName)
   [1] "factor"

   What I did is this:
   > oWWA$speciesName <-as.character(oWWA$speciesName)
   and now I've got:
   > class(oWWA$speciesName)
   [1] "character"
   and the function I wanted to use works well:
   > Sp_per_coordID_oWWA <-tapply((oWWA$speciesName), oWWA$coordID, list)

   -->Question: Do you think I did this right and this didn't mess up the
   structure of the dataset? As far as I can see, I see no problem but I m not
   so experienced as you are!

   Thank you very very much for your answers!!! It helped me a lot!!

   -->second Question: I had problems with using dput(head(WWA)), because I
   think its still too big, so that I m not able to post all the output from
   "dput(head(WWA)))", even when i subsetted it first to only three rows:

   > WWAsubset <-WWA[c(1:3),]
   > dput(head(WWAsubset))

   (see after str(WWA) and str(oWWA)



   str(WWA)
   'data.frame':  33523 obs. of  14 variables:
   $ coordID            : int  533162 533162 533162 533162 533162 533162 533162
   533162 533162 533162 ...
   $ community          : Factor w/ 1115 levels "Aadorf","Aarau",..: 143 143
   143 143 143 143 143 143 143 143 ...
   $ canton             : Factor w/ 26 levels "AG","AI","AR",..: 23 23 23 23 23
   23 23 23 23 23 ...
   $ BGR                : Factor w/ 6 levels "Alpennordflanke",..: 4 4 4 4 4 4
   4 4 4 4 ...
   $ altitude           : num  565 565 565 565 565 ...
   $ year               : int  2003 2003 2003 2003 2003 2003 2003 2003 2003
   2003 ...
   $ observer           : Factor w/ 37 levels "","Al-Jabaji Dunia",..: 19 19 19
   19 19 19 19 19 19 19 ...
   $ speciesID          : int  1453 2757 2759 2736 2612 2602 2674 1949 1369
   1641 ...
   $ speciesName        : chr  "Aegopodium podagraria" "Agrostis capillaris"
   "Agrostis stolonifera" "Arrhenatherum elatius" ...
   $ Beschreibung_unbest: Factor w/ 4712 levels ""," ","   ","  -",..: 1 1 1 1
   1 1 1 1 1 1 ...
   $ land_use           : Factor w/ 8 levels "","Aecker","Alpweiden",..: 8 8 8
   8 8 8 8 8 8 8 ...
   $ realcoord_X        : num  533000 533000 533000 533000 533000 533000 533000
   533000 533000 533000 ...
   $ realcoord_Y        : num  162000 162000 162000 162000 162000 162000 162000
   162000 162000 162000 ...
   $  NCCR_land_use       :  chr   "will_be_assigned"  "will_be_assigned"
   "will_be_assigned" "will_be_assigned" ...

   str(oWWA)
   'data.frame':  33523 obs. of  14 variables:
   $ coordID            : int  533162 533162 533162 533162 533162 533162 533162
   533162 533162 533162 ...
   $ community          : Factor w/ 396 levels "Aarburg","Adelboden",..: 51 51
   51 51 51 51 51 51 51 51 ...
   $ canton             : Factor w/ 25 levels "AG","AI","AR",..: 22 22 22 22 22
   22 22 22 22 22 ...
   $ BGR                : Factor w/ 6 levels "Alpennordflanke",..: 4 4 4 4 4 4
   4 4 4 4 ...
   $ altitude           : num  565 565 565 565 565 ...
   $ year               : int  2003 2003 2003 2003 2003 2003 2003 2003 2003
   2003 ...
   $ observer           : Factor w/ 26 levels "Al-Jabaji Dunia",..: 13 13 13 13
   13 13 13 13 13 13 ...
   $ speciesID          : int  1453 2757 2759 2736 2612 2602 2674 1949 1369
   1641 ...
   $ speciesName        : Factor w/ 886 levels "","Abies alba",..: 18 24 29 84
   124 126 267 360 397 402 ...
   $ Beschreibung_unbest: Factor w/ 1336 levels ""," "," ("," -",..: 1 1 1 1 1
   1 1 1 1 1 ...
   $ land_use           : Factor w/ 2 levels "Alpweiden","Wiesen, Weiden": 2 2
   2 2 2 2 2 2 2 2 ...
   $ realcoord_X        : int  533000 533000 533000 533000 533000 533000 533000
   533000 533000 533000 ...
   $ realcoord_Y        : int  162000 162000 162000 162000 162000 162000 162000
   162000 162000 162000 ...
   $ NCCR_land_use      : Factor w/ 1 level "will_be_assigned": 1 1 1 1 1 1 1 1
   1 1 ...


   dWWAsubset <-

   "Cf sempervivum  zierpflanze", "Cf Senecio", "cf Senecio jacobea f petite
   cr\x8enel\x8ee pennatipartite glabre",
       "Cf Senecio jacobea f. longuement petiol\x8ee, ovale cr\x8enel\x8ee
   dent\x8ee",
       "cf senecio sp (Fein wirtelige Bl\x8atter)", "cf Senecio vulgaris",
       "cf sepium", "Cf sepium", "cf sepium, avec stipule ? glande",
       "cf serpentina", "Cf serpyllifolia", "cf serriola f \x88 \x8epines sur
   nervure dorsale ",
       "cf serrulata", "cf Seseli libanotis fol glauque dessous",
       "cf Sesleria caerulea", "cf Setaria viridis", "cf Sherardia arvensis cf
   Galium molugo agg",
       "Cf sibirica kultiviert", "Cf silaum silaus feuilles tres decoupees pas
   de fleurs",
       "cf Silene dioica", "Cf silene dioica", "Cf Silene dioica",
        "cf  silene  dioica  cf  knautia asteracea? Rosette ", "cf Silene
   flos-cuculi",
       "cf Silene nutans", "Cf Silene nutans (pousse v\x8eg\x8etatif)",
       "cf Silene rupestris", "Cf Silene sp ", "cf Silene vulgaris",
       "Cf sinapis", "cf Sinapis arvensis", "cf Sinapis arvensis, +- Keimling",
       "cf Sinapis arvensis, cf Raphanus raphanistrum", "cf Sinapis sp cf
   brassicac\xe9es F roncin\xe9es poilues, vert fonc\xe9  ",
       "cf Sisymbrium austriacum", "Cf Solanum ou Circaea lutetiana",
        "cf Soldanella pusilla", "Cf solidago", "cf Solidago canadensis f
   alternes allong\x8ees en p\x8etiole cili\x8ees \x88 la base",
       "cf Solidago virgaurea", "cf solidago virgaurea  feuiles dentees longu.
   petiolee herbier",
       "cf solidago virgaurea, ev gigantea", "Cf sonchus", "cf sonchus  rosette
   pas piquante",
       "Cf sonchus (winzig)", "Cf Sonchus arvensis. Zu klein", "cf Sonchus sp",
       "cf Sonchus sp f un peu poilue ", "Cf sorbus aria", "Cf Sorbus aria.
   Zerfressen",
       "Cf sorbus aucuparia", "cf Sorbus aucuparia; Zweiblattstadium",
       "cf spadiceum", "Cf sphaerocephalon", "cf spicata", "cf spicatum",
        "Cf spicatum", "Cf spicatum ", "Cf spicatum (bl\x9fht noch nicht,
   knospen erscheinen weiss. In der Umgebg der Fl\x8ache P. Ovatum o. Bl\x9fht
   P. Spic auch manchmal dunk",
       "cf spinosa, f et p\x8etiole poilus", "cf spinosissimum",
       "Cf spinulosa (helle spreuschuppen)", "Cf stachys sylvatica odeur fetide
   f long pet crenelees petiole a long poil etale argente",
       "Cf stellaria graminea", "Cf stellaria med", "cf Stellaria media",
       "cf Stellaria media  noch zu klein-oder cerastium f.", "Cf Stellaria
   media / Moehringia trinervia",
       "Cf stellaria media plantule a 4 f", "cf Stellaria media, tige ? poils
   tout autour",
       "cf Stellaria media; s. klein", "Cf sterilis", "cf stolonifera",
       "Cf stolonifera", "Cf stolonifera ", "cf stolonifera  cf capillaris",
       "cf stolonifera (oberird ausl\x8aufer)", "cf stolonifera cf gigantea",
       "cf stolonifera, allerdings nur kleine Ausl\x8aufer", "cf stricta",
        "cf subcoriacea", "cf sudetica", "cf sudetica cf alpina (binz) cf
   campestris agg",
       "cf supina", "Cf supina", "Cf supina (couvre le sentier)",
       "cf supinum", "Cf supinum", "Cf sylva", "cf sylvatica", "Cf sylvatica",
       "Cf sylvatica ", "Cf sylvatica (feuilles larges de 7mm)",
       "Cf sylvatica / arvensis, rosettes ", "cf sylvatica cf decumbens cf
   alpestris",
       "cf sylvatica cf pilosa", "cf sylvatica cf pilosa Rem: F. Barbues ,sur
   la souche ",
       "cf sylvaticum", "Cf sylvaticum", "Cf sylvaticum, folioles pubescentes
   avec poils glanduleux rouge",
        "Cf sylvestr.is", "Cf sylvestris (zu klein)", "Cf sylvestris sans
   epine",
       "Cf sylvestris/hetero pousse", "cf sylvestris/hetero, pousse",
       "cf Tamus communis cf  Maianthemum bifolium f. en coeur lisse",
       "cf Taraxacum", "Cf taraxacum", "Cf Taraxacum od. Leontodon",
       "cf Taraxacum oder crepis aura", "Cf taraxacum off", "Cf Taraxacum off",
       "Cf taraxacum off (pfl-ritze)", "Cf taraxacum off, ev. Auch crepis
   capillaris (winzig)",
       "cf Taraxacum officinale", "Cf taraxacum officinale", "Cf Taraxacum
   officinale",
        "Cf  Taraxacum  officinale  f.  en rosette", "cf Taxus baccata cf
   Metasequoia glyptostroboides ",
        "cf tenuifolia", "cf tetragonum", "Cf tetragonum", "Cf tetragonum
   stigmate en massue calice sans poils glanduleux f sessiles",
       "Cf tetrahit", "cf tetrahit cf bifida", "cf thalii", "cf thapsus",
       "Cf thapsus (rosette)", "cf Thesium/Linum", "cf Thlaspi od. ev.  Fourrea
   alpina , erst 2 cm hoch, bei 2. Aufn. nicht gef.",
       "cf Thlaspi rotundifolia", "Cf thomasiana", "Cf tomentosa",
        "Cf  tomentosa  /  feuilles fines et glaucesente", "Cf torminalis
   Jungpflanze",
       "cf trachelium", "Cf trachelium/rapunculoides", "Cf tragopogon",
       "cf Tragopogon pratensis", "cf tragopogon pratensis       ",
       "cf Tragopogon pratensis f lin\x8eaire avec nervure m\x8ediane blanche",
       "cf Tragopogon sp", "cf Tragopogon sp f longue lin\x8eaire obovale,
   nervure centrale blanche longs cils peu nombreux",
       "Cf traunsteinera globosa", "Cf traunsteinera vegetatif",
       "cf Trifolium dubium", "Cf Trifolium dubium", "cf Trifolium pratense",
        "Cf  trifolium pratense", "cf Trifolium repens", "Cf Trifolium sp
   (tr\x8fs petit)",
       "Cf Trifolium sp f \x88 3 folioles", "cf tripleurospermum perforatum",
       "cf Tripleurospermum perforatum", "Cf Tripleurospermum perforatum",
       "cf tripteris", "Cf trisetum flavescens", "Cf Trisetum flavescens",
       "Cf trisetum flavescens  (beh blattscheide) o brachyp pinn",
       "cf Trisetum flavescens cf Bromus hordaceus (pr\x8esent ds la coupe) ou
   autres...",
        "cf  trisetum flavescens et/ou cf bromus hordaceus", "cf Trisetum
   flavescens f poilue  lig courte ~1mm",
       "Cf trisetum flavescens, zu klein,  behaarte blattscheide",
       "Cf Triticale r\x8esurgence d'un culture pr\x8ec\x8edente",
       "cf triticosecale", "cf triticum sp Kultur", "cf Triticum sp kultur
   blattoberseite behaart ",
       "cf Triticum, frisch ausgetrieben", "cf Tritosecale \xe9pillets \xe0
   longues ar",
       "cf trivialis", "Cf trivialis", "cf trivialis cf nemoralis",
       "cf trivialis ligule courte, f avec trace de ski, diff\x8erent de Poa
   annua ",
       "cf trivialis ligule pointue f un peu brillante dessous, traces de ski",
       "cf trivialis, cf pratensis ou autre", "cf trollius europaeus",
       "cf tuberosa", "Cf uliginosum", "Cf ulmus glabra (klein)",
       "Cf umbelliformis", "Cf umbelliformis (vegetatif)", "cf uniflorum",
        "Cf  uniflorum",  "cf  uniflorum, wegen dem Silikat eher nicht C.
   latifolium",
       "cf uniflorum/pedunculatum", "cf uniflorus", "Cf uniflorus",
       "cf urbanum", "Cf urbanum", "Cf urbanum (sehr runde vorderlappen)",
       "cf urbanum cf rivulare", "cf urbanum\\rivale, steril", "cf Vaccinium
   myrtillus",
       "Cf vaccinium vitis idaea", "Cf Valerianella sp", "cf varia",
       "Cf varia (vegetativ)", "Cf varia bzw. sativa s.l.", "cf varia f Glabre
   ligule 1mm gaine pourpres",
       "Cf verbascum", "Cf verbascum nigrum/lychnitis", "Cf verbascum sp.",
       "cf Verbena officinalis, f cr?nel?e un peu obovale", "cf veris",
        "Cf veris", "Cf veris / sterile", "Cf veris cf ela", "cf veris cf
   elatior",
       "Cf veris cf elatior", "Cf veris herbier", "cf verna", "Cf verna",
       "cf verna/orbicularis", "Cf veronica", "cf Veronica arvense, nur vier
   sehr kleine Bl\x8atter",
       "Cf veronica chamaedrys", "cf Veronica fruticans Tige un peu liqneuse
   \x88 la base",
       "Cf veronica hederifolia", "cf Veronica officinalis", "Cf veronica
   officinalis",
       "cf Veronica persica", "Cf veronica persica", "Cf veronica serp.",
       "Cf Veronica serpylifolia", "Cf veronica serpyllifolia, gestielt, boden
   anliegend (klein)",
       "Cf veronica sp. B behaart noch sehr klein", "cf Veronica teucrium",
       "cf Veronica urticifolia", "cf veronica urticifolia 1.blattpaar stark
   gez\x8ahnt",
       "cf versicolor", "Cf versicolor", "Cf verticillata", "cf verum",
       "cf verum, f un peu r?volut?es et fines", "cf vesca cf x magna (jardin)
   ",
       "Cf vesicaria", "cf viburnum lantana (10cm)", "cf Vicia hirsuta ",
       "Cf Vicia sativa", "cf Vicia sp cf Lathyrus sp", "Cf villarii",
       "Cf villosa", "Cf villosa ou arundinacea", "Cf villosa pas en fleurs",
       "cf villosa, bei Bl.h. behaart, mit Achsenforts., Gr. gekniet,  wenig l.
   als D.sp",
       "cf villosum", "Cf villosum", "cf villosum ", "Cf villosum / pilosum",
       "Cf villosum 1 rosette st\x8erile", "cf villosum/morisianum",
        "Cf vineale", "Cf viola biflora", "cf Viola calcarata", "cf Viola
   riviniana/reichenbachiana",
       "Cf viola sp", "cf Viola sp cf Campanula sp F longuement p\x8etiol\x8ee
   ovale en coeur ",
       "cf Viola sp f reniforme", "cf Viola tricolor", "cf Viola triolor",
       "cf violacea", "Cf violacea", "cf violacea/halleri vegetatif",
       "Cf violacea/rubra (les 2 sp?)", "Cf viridis", "cf vulgaris",
       "Cf vulgaris", "cf vulgaris sind das die rosen?", "cf waldsteiniana",
        "cf  walleriana", "Cf x chenaultii", "cf x intermedia f en coeur,
   bract\x8ees tr\x8fs courtes et pas toujours pr\x8esentes",
       "Cf xylosteum", "Cf-officinalis", "Cf-ovina", "cf.", "Cf.",
       "cf.  alpina", "Cf.  Draba; mit Sternhaaren an ovalen, ganzrandigen
   blaettern",
       "cf. Acer pseudoplatanus, Juv.", "cf. acetosa", "cf. aconitifolium, ev.
   platanifolium",
       "cf. aconitifolius ou platanifolius", "Cf. Acris b. Behaart",
       "Cf. acris evtl. repens junge pfl", "cf. acuminata", "cf. Adoxa od.
   Corydalis",
       "Cf. Agropyron caninum", "Cf. Agrostis", "Cf. Agrostis alpina",
       "Cf. Agrostis capillaris", "Cf. Agrostis rupestris", "cf. Agrostis sp.",
       "cf. Agrostis stolonifera", "cf. alectorolophus", "Cf. Alectorolophus",
       "cf. Alopecurus pratensis", "Cf. Alopecurus pratensis", "Cf. Alpestre",
       "Cf. alpestre; zwischen grossen felsen", "cf. alpestris ou acetosa",
       "Cf. alpina", "Cf. Alpina", "cf. alpinum", "Cf. alpinum",
       "cf. angustifolia", "cf. anisophyllon", "Cf. anisophyllon",
       "Cf. anisophyllum od. mollugo agg.", "Cf. anisophylum", "cf. annua",
        "cf.  Anthoxantum",  "cf. Anthriscus sylvestris", "cf. Anthriscus
   sylvestris juv.",
       "cf. Apiaceae, 1 feuille jeune (10 cm)", "Cf. appendiculata",
       "cf. Arabis", "Cf. Arabis hirsuta", "Cf. Arrhenatherum",
       "cf. arundinacea", "Cf. arundinacea", "Cf. Arvense", "cf. arvensis",
       "cf. Arvensis", "Cf. arvensis", "cf. asper", "Cf. asper",
       "cf. asper juv.", "Cf. aster bellidiastrum", "Cf. Astragalus",
       "Cf. Athyrium", "cf. Athyrium f.f.", "cf. Athyrium, petite",
       "cf. aureum ou hirsutum", "cf. australis", "Cf. Aviculare",
       "cf. avium", "Cf. Avium", "cf. Avium, Jungpfl. 5cm", "Cf. Badium",
       "Cf. benekenii", "cf. berchtoldii", "cf. Beta vulgaris",
       "cf. betonicifolium", "Cf. Betonicifolium", "cf. biennis",
       "cf. biennis, borstig behaart", "cf. Biscutella laevigata",
        "cf. blitum", "Cf. Blitum", "Cf. Brachypodium", "cf. Brachypodium
   sylvaticum",
       "Cf. brachypodium sylvaticum", "Cf. Brachypodium sylvaticum",
       "Cf. Brauneana ....", "cf. brauneana trifoliee poilue", "Cf. brizoides
   od. remota",
        "Cf.  Bromus",  "cf. Bromus hordaceus St. behaart", "cf. Buddleja
   davidii",
       "Cf. Caerulea", "Cf. Calamagrostis", "Cf. campanula", "Cf. campanula
   cochleariifolia",
       "cf. campanulaceae, herzf b mit weissem zahn, kurzbewimpert, b spatelf",
       "Cf. Campestre oder malva", "cf. campestre, juv., Keimblaetter und 2
   Blaetter",
       "cf. campestris/spicata", "cf. canadensis", "cf. canescens",
       "cf. canina", "Cf. canina", "cf. canina aggr.", "cf. canina juv. ,
   jedoch gerade stacheln",
       "cf. canina s.l", "cf. canina s.l.", "cf. capillaris", "cf. capillaris
   ou stolonifera",
       "Cf. caprea", "cf. caprea od. cinerea", "Cf. Capsella", "Cf. Cardamine",
       "Cf. Cardus defloratus", "Cf. Carduus/Cirsium (noch sehr klein)",
       "cf. Carex ericetorum ", "cf. Carpinus betulus ou Ostrya carpinifolia",
       "cf. carthusiana", "cf. Carthusiana", "Cf. carthusiana",
       "Cf. Carthusiana", "Cf. Carthusianorum", "Cf. Carum carvi , feuilles
   glabres, kein Anthriscus",
        "cf.  Caryophyllaceae  a  feuilles  oppos\x8ees,  poilue.",  "cf.
   caryophyllea",
       "Cf. Caryophyllea", "Cf. catharticus", "cf. Centaurea; F. subenti\x8fres
   poilues",
       "Cf. Cephalantera", "Cf. Cephalanthera", "cf. cerasifera juv.",
       "cf. cespitosa", "cf. chaixii", "Cf. chenopodium / atriplex, kleine
   pflanze",
       "cf. Ciliata", "cf. Ciliata oder ...", "Cf. cinerea", "Cf. Cinerea o.
   Caprea",
         "Cf.  Cirsium  spinosissimum",  "Cf.  clinopodium  vulg.",  "cf.
   cochlearifolia",
       "Cf. Coeloglossum viride", "cf. collina", "cf. columbaria",
       "cf. columbinum", "cf. convolvulus", "cf. Conyza canadensis",
       "cf. conyzifolia ou Hipochaeris uniflora?", "Cf. cordata",
       "Cf. corylus", "cf. Cotyledon", "cf. Crepis aurea", "Cf. Crepis aurea",
       "Cf. Crepis oder Picris", "Cf. Crepis paludosa", "Cf. Crepis. 2 Blueten.
   Blaetter wie Taraxacum",
       "Cf. Cynosurus cristatus", "Cf. cystopteris fragilis, knapp innerhalb
   der af",
       "Cf. Dactylorhiza sp. B gefleckt.", "cf. dammeri", "cf. decumbens",
       "cf. Digitaria sanguinalis", "cf. digitata", "Cf. digitata",
        "Cf. Digitata", "Cf. dilatata", "Cf. Dilatata", "Cf. dilatata od.
   filix-mas",
        "cf.  dissectum",  "cf.  distentifolium",  "cf. distentifolium ou
   filix-femina",
       "cf. distentifolium, immature", "Cf. divaricata", "Cf. dryopteris",
       "Cf. Dryopteris", "Cf. dryopteris dilatata", "Cf. dryopteris f. - m.",
       "cf. dubium", "cf. Dulcis. Druesen rot/rund", "cf. dyopteris felix-mas",
       "Cf. Echinata", "Cf. Echinochloa", "cf. effusus /conglomeratus juv.",
       "cf. elatior", "Cf. elatior", "Cf. Elatior", "Cf. erectus",
       "cf. Erigeron oder Centaurea jacea.", "Cf. euonymus europaea",
       "Cf. exscapa", "Cf. festuca altissima", "Cf. festuca gigantea",
       "Cf. Festuca halleri oder Agrostis", "cf. Festuca rubra",
       "Cf. Festuca rubra", "cf. Festuca rubra, juv.", "cf. feuille petites,
   plante non bien d\x8evelopp\x8ee",
       "cf. feuilles encore trop jeune", "cf. feuilles oppos\x8ees, poilues et
   dent\x8ees",
       "cf. feuilles poilues de type pilosella", "cf. filiformis",
       "cf. filiformis juvenil", "Cf. Filiformis veg", "cf. filix-femina",
       "Cf. filix-mas", "Cf. Flaeche ungemein trocken", "cf. flexuosa",
       "cf. fontana", "cf. fontana ou corniculata", "cf. fontanum",
        "Cf. fontanum", "cf. fontanum subsp. vulgare", "Cf. fragilis s.l.
   jungpfl",
       "Cf. Frangula", "Cf. frangula alnus od. rhamnus", "Cf. Galeobdolon",
       "Cf. Galeopsis", "cf. Galeopsis ladanum", "cf. Galeopsis tetrahit",
       "cf. gaudinii ou latifolium", "cf. gigantea", "Cf. Gigantea",
       "cf. gigantea /canadensis juv.", "cf. glomeratum", "Cf. Glomeratum",
        "Cf. Glyceria", "Cf. Graminea", "Cf. Gymnadenia", "cf. Helianthus
   annuus",
       "cf. helveticum 1 seule feuille minuscule", "cf. heterophylla",
       "cf. Hieracium murorum aggr.", "Cf. Hipocrepis comosa", "cf. hirsuta",
       "cf. hirsuta ", "Cf. hirsuta od. pratensis", "Cf. hirsutum",
       "cf. holosteoides", "cf. hoppeanum", "cf. hoppeanum ev. H. pilosella",
       "Cf. Hordelymus europaeus", "cf. hostiana", "cf. humilis mais assez
   sur",
       "Cf. Hybridum", "cf. Hypochoeris radicata", "Cf. ideaus",
       "cf. impatiens  ", "cf. incana ou glutinosa, je pensais la revoir plus
   d\x8evelopp\x8ee...",
       "cf. Iris", "cf. ischaemum", "cf. je dirai encore aquilegiifolium mais
   les feuilles sont trop petites.",
       "cf. Juncus tenuis", "cf. KK, petite touffe dans une zone perturb\x8ee",
       "cf. lactucella", "Cf. laevigata", "cf. laevigata, spec.",
       "Cf. Lamium galeoptolon", "cf. latifolium", "cf. Leontodon helveticus",
       "Cf. leontodon helveticus", "cf. leontodon ou taraxacum",
       "cf. Leptoceras", "Cf. liguliflorae, leicht fiedert st.b.",
       "cf. Liguliflorae, steife b, rosette eng am boden, herbar",
       "Cf. ligusticum", "Cf. Ligusticum", "Cf. Ligusticum mutellina",
       "Cf. Lilia evtl. Muscari", "Cf. liliaceae b. fleischig 6mm ",
       "Cf. listera ovata, rtg. sued, eher aussen", "cf. locusta",
       "Cf. Lolium perenne", "Cf. lonicera  sp.", "Cf. Lucida",
       "cf. lupulina. Petite mais en tout cas pas Melilotus", "Cf. Luzuloides",
       "cf. macrorrhizum", "Cf. maculata", "Cf. Maculata", "Cf. maculatum",
       "cf. maculatum s.str.", "cf. mais assez sur", "cf. maxima",
       "Cf. minor", "cf. minus", "Cf. moeringia trinerva", "Cf. monogyna",
       "Cf. Mont-tetr", "Cf. montana", "Cf. Montana", "Cf. Montana od. Tript.",
       "cf. montanum", "Cf. montanum", "Cf. Montanum", "Cf. montanum. Auf
   Fels",
       "cf. montanus", "cf. montanus, 3-teilige b, rtg. w", "Cf. mougeotii",
       "Cf. Multif. Oder Festuca prat.", "Cf. Muricata abgemaeht",
       "cf. muricata, herbar", "cf. murorum", "cf. mutellinoides",
       "Cf. napus", "cf. nemoralis", "Cf. nemoralis", "cf. nemorosa",
       "Cf. nemorosus", "cf. neumanniana", "Cf. nigra", "Cf. Nivalis",
       "cf. nutans 2 seules feuilles", "cf. obscura", "cf. odorata",
       "Cf. odorata", "Cf. Odorata/riviniana", "Cf. Officinale",
       "cf. officinalis", "cf. oleraceum", "cf. oleraceus", "cf. ornithopoda",
       "Cf. Ornitopoda", "cf. Ostrya carpinifolia", "cf. ou multiflora",
       "Cf. Ovata", "Cf. ovatum", "cf. ovina", "Cf. ovina", "Cf. padus",
       "Cf. Panicea/flacca", "cf. paniculata", "cf. parviflorum",
        "Cf.  perforatum",  "cf.  perforatum,  tr\x8fs jeune, encore sans
   ponctuactions",
       "Cf. Persica", "cf. personata", "cf. petraeus", "Cf. petrea",
       "cf. Peucedanum ostrhuthium", "Cf. Phleum", "Cf. Phleum pratensis",
       "cf. pilosella", "cf. pilosella ou hoppeanum", "cf. pilulifera",
       "cf. pilulifera ou similaires, rosettes tr\x8fs petites",
       "Cf. platanifolius", "Cf. Platanoides, 2 Arten also", "cf. platanoides,
   juv.",
       "Cf. Platanthera", "cf. Plathanthera, 2 schmale Blaetter",
       "cf. platypyllos jungpfl. mit 3 blaettern", "Cf. Poa chaixii",
        "Cf.  Poa hybrida oder P.  Remota", "cf. Poa nemoralis", "Cf. Poa
   nemoralis",
       "Cf. Poa od. Agropyron", "Cf. poa, ev. laxa, sehr jung",
       "Cf. Poligonatum multiflorum", "cf. Polypodium vulgare, petite",
       "cf. polyspermum", "cf. portenschlagiana", "Cf. pratense",
       "cf. pratense ", "cf. pratensis", "cf. Pratensis", "Cf. Pratensis",
       "cf. pratensis juv.", "cf. pratensis, \x85hrchen kahl, \x80hrchen ohne
   Granne",
        "Cf.  pratensis,  hangwaerts  in  salix",  "cf. procumbens", "cf.
   pseudoplatanus",
        "cf.  pseudoplatanus  juv.", "Cf. Pseudorchis", "cf. pubescens ou
   tetrahit",
        "cf.  pumilum",  "cf.  pumilum ev. anisophyllon", "cf. pumilum ou
   anisophyllon",
       "cf. pumilum ou rotundifolium", "cf. pumilum. Poils sous la base des
   verticilles.",
       "cf. purpurea", "cf. pusilla", "Cf. pusilla, knapp innerhalb af",
       "cf. pusillum /molle", "Cf. Pyrenaicum", "cf. Quercus pubescens. Sans
   feuilles",
       "cf. rapunculus", "cf. reichenbachiana", "Cf. reichenbachiana",
       "Cf. reichenbachiana juv.", "cf. reichenbachiana ou canina",
        "cf. Remota", "cf. repens", "cf. repens juv.", "cf. rhaeticum, f.
   dent\x8ees au bord",
       "Cf. Rhoeas", "Cf. rivale", "cf. riviniana", "cf. riviniana. Pas tr\x8fs
   sur mais presque",
       "cf. robur", "Cf. robur", "Cf. Robur", "Cf. robur jung",
       "Cf. robur Jungpfl.", "Cf. robur jungpflanze", "Cf. robur Jungpflanze",
       "Cf. robur jungwuchs", "cf. robur, petit", "Cf. robur. sehr klein",
       "cf. rosaceae", "cf. roseum", "Cf. Rostkoviana", "Cf. Rot. 2 behaarte
   Leiszen",
       "Cf. Rotundifolia", "cf. rubra", "cf. Rubus idaeus", "Cf. rupestris",
       "cf. Salicifolius Strauch kultiviert", "Cf. sanguinea od. obtusifolius",
       "cf. sativa", "Cf. saxatilis", "cf. Saxifraga aizoides; Sedum-aehnliche
   blaetter",
       "Cf. Scheuchzeri", "Cf. Schrad", "Cf. Scorpioides/nemo.",
       "cf. sempervirens", "Cf. Sempervirens", "cf. senecio vulgaris, fiedert
   b",
       "cf. sepium", "cf. sepium, evtl. angustifolia, juv.", "Cf. Sesleria",
       "Cf. sesleria caerulea", "Cf. Setaria", "cf. sibirica", "Cf. Silene
   flos-cuculi",
        "Cf.  Silene nutans aber die Blaetter sind gestielt", "cf. Silene
   rupestris",
       "Cf. silene vulgaris", "Cf. Spic gedr\x8angte \x8ahren",
       "cf. spicatum", "Cf. spicatum", "cf. spurium", "Cf. stachys sylv. ?",
       "Cf. stellaria media", "Cf. Stellaria media", "cf. Stellaria media
   aggr.",
       "cf. stolonifera", "Cf. stolonifera", "Cf. Stolonifera",
       "Cf. Subcor", "cf. supina", "cf. supina o annua", "Cf. supinum",
       "Cf. Supinum", "cf. sylvatica", "Cf. sylvatica", "Cf. Sylvatica",
       "cf. sylvaticum", "Cf. sylvaticum", "cf. sylvestris", "Cf. taraxacum",
       "Cf. Taraxacum", "Cf. Taraxacum off", "cf. thalii", "Cf. Thapsus",
       "cf. thlaspi montanum od. perfoliatum", "cf. tr\x8fs petite mais il y a
   des asperula taurina \x88 10 m\x8ftres",
       "cf. trachelium", "Cf. Trisetum", "cf. trivialis", "cf. tuberosus",
       "cf. varia", "cf. Varia", "Cf. veris od.  elatior", "cf. veris s.str.",
       "Cf. Veronica montana", "cf. versicolor", "Cf. Vicia zart mit Endranke",
       "cf. villarsii", "cf. villosa", "cf. villosa ou ev. arundinacea",
       "cf. villosa, habitus different de l'autre, elle y est aussi dans les
   parages...",
       "cf. violacea", "cf. violacea aggr.", "Cf. Viridis", "cf. vulgaris",
       "Cf., B. Ganz", "Cf., B. Lederig", "cf., gegenst. B.", "cf., stolons pas
   trop clairs",
       "cf., verdrehte B.", "cf., vergilbt", "Cf.. Clematis", "Cf.calamagrostis
   lanceolata",
       "Cf.elatior", "Cf.nigra", "Cf.obscura", "Cf.stolonifera",
        "Cfl  pendulina",  "chamaebuxus", "chamaebuxus petit ligneux sous
   hippocrepis",
       "Chamaedrys", "Chamomille", "Champ d orge", "cheiri, gartenform",
       "Chenopodiaceae", "chenopodiacee ou polygonacee cf Rumex sp",
       "Chl bif", "Cirsium od. Sonchus. Zu klein", "Cirsium ole oder Carduus",
       "clinopodium vulgare", "Clusii / acaulis, steife b", "Coeloglossum /
   leucorchis",
       "Columb./dissectum", "communis", "Communis", "Compositablatt",
       "Cones petits", "Conyza canadensis", "Conyza canadensis oder Erigeron
   annuus",
       "Cornus spec. evtl verwilderte c. alba pfl. nur mit zwei kl. blaettern",
       "Cotyl\x8edones + 2 feuilles", "Cotyledon", "crantzii", "Crepis aurea",
       "Crepis biennis", "Crepis od. Taraxacum", "Crocus", "Cult",
       "cult.", "Cult.", "Cult. Bette a tondre jaune", "cultiv\x8e",
       "Cultiv\x8e", "cultiv\x8e probablement L. vulgare", "cultiv\x8ee",
       "cultivar", "Cultivar a f panachess", "cultivar sp.", "cultivar, avec
   ligne claire au milieu de la feuille. sp.",
       "cultivar, bleu", "cultivar, diff. variet\x8es", "cultivar, feuilles
   charnues",
       "cultivar, jaune", "cultivar, peut-\x90tre narcissus ou similaire",
       "Cultive", "Cultiv?", "Cultive ", "Cultivee", "cultivee ",
        "Cultivee  ",  "culture", "Culture", "culture actuelle", "Culture
   actuelle",
       "Culture de cette ann\xe9e", "Culture principale", "Culture principale
   2007",
       "Cynosurus cristatus", "Dact. od. Orchis. B. gefleckt.",
       "Dactylorhiza mac (1 K\xfcmmerblatt)", "dalmaticum", "Dans les dalles f
   opp poilues",
       "Das andere", "dasyphyllum/atratum", "Datenvalidierung: als Allium
   sphaerocephalon bestimmt (unklar)",
       "Datenvalidierung: als Dipsacus fullonum bestimmt (evtl. falsch)",
       "Datenvalidierung: als Galium boreale bestimmt (unklar)",
       "Datenvalidierung: als Sedum alpestre bestimmt (unklar)",
       "Deux feuilles", "Deux petites feuilles ", "deux petites feuilles non
   retrouv\x8ees, cf. officinale aggr.",
       "Dgr\x9fn. schmale b, wie ornithopoda", "Dicht behaart mit einfachen
   Haaren. Ev. auch Myosotis spec.",
        "Dichte Polster von gelbgr\x9fnen gl\x8anzenden Borstbl\x8attern,
   violette Blattscheiden",
       "Dicke b aizon bifolia? Thlaspi rotundifol", "Die roten",
       "Digitalis Gartenform rosa", "Digitaria oder Setaria", "Dil. Od. Cart.
   Schuppen gleichm. Braun",
       "dilatata oder expansa", "dilatata/carthusiana.  Sehr klein. Unter
   Stein.",
       "Dinkel", "dioica", "disegno... V\x8erif., cf. potentilla erecta?",
       "Diss-col", "Distelartige b, ev. sonchus; richtung westtanne aussen",
       "Distelblatt", "Distelblatt kraeftige gelbe Randstacheln",
       "Distelblatt, US +- weissfilzig, ungeteilt; Art in naeherer Umgebung
   vorhanden",
       "Disticha", "Domestica", "Dr\x9fsig", "Drei verschiedene cultivar",
       "Druesenlos", "Dryopteris f. m.", "Dryopteris filix-mas",
       "dtl. Blattoehrchen, diese kahl. Blatt-US glatt, glaenzend, OS dtl. fein
   gerieft. Alternative: Festuca pratensis",
       "dubia", "Dulcis ou verrucosa", "Dunkelgr\x9fn ledrig behaart leicht
   gezackt",
       "Durch gift gesch\x8adigt, cf Acer pseudoplatanus", "Durchwuchs",
       "E. cf montanum. 3wirtelig Zu klein", "Ecorce grise plante",
       "effusus/filiformis", "eher feine, lange Bl\x8atter, glauc, Scheiden
   r\x9atlich",
        "Ein Blatt, unter junger flacher Fichte", "Ein hochblatt gezackte
   blaetter",
       "einfach gefiedert, aber noch sehr jung", "Einige Bl\x8atter, ev. V.
   canina s.l.",
       "Einzelblatt, klein; cf Aquilegia atrata", "Einzelne Rosettenbl\x8a. wie
   Carex ericetorum. Blattscheiden rotbraun wenig faserig",
       "Elata / nigra", "elatior oder veris", "Elatius", "En germination f.
   ovale pointue dentee cf prunus cf frax ",
       "Encore tr\x8fs jeune.", "Endresii", "Entre les dalles",
       "Entwede sorbus auc oder frax (auf stumpf, winzig)", "entweder breites
   Agrostis oder Calamagrostis",
        "Epilobium",  "Epilobium. Sehr klein", "Ericetorum ohne gr\x9fnen
   mittelstreifen",
       "Erigeron/Aster sp", "Erst junge Triebe, Blattscheiden etwas behaart",
        "erste, s. kleine Blaetter, wie Cerastium aber kahl; cf Stellaria
   graminea?",
       "esculentum", "esp\x8fce ornamentale", "Esp\x8fce plant\x8ee",
       "etwas spitz/grannig, druesenlos", "Euphrasia / Rhinanthus sp",
       "Ev Agropyron. Bh nicht kurz genug", "Ev alopecurus prat",
       "Ev Alopecurus. Nur vegetativ", "Ev Anthoxanthum. Zu klein",
       "Ev calamagrostis varia (zu mickrig)", "Ev capsella b-p (zu klein)",
       "ev caryophyllea, herbar", "Ev cerastium", "ev cynosurus",
       "ev cystopteris, verm aber junger dryopteris", "ev Kleiner oreopteris
   limbosperma",
       "Ev lamium purpureum (zu klein)", "Ev Malva. Zu klein, vor Bank",
       "Ev nelke", "Ev pallescens", "Ev Panicum. Abst beh. Mit Bh lang. Blst
   wie Digit. ",
       "Ev poa trivialis (zu klein)", "Ev Sonchus. Zu klein", "Ev. Alopecurus.
   Zu klein",
       "Ev. arrhenatherum", "Ev. Arum od. Allium urs.", "ev. auch ornithpoda",
       "Ev. auch Poa trivialis", "Ev. C. muricata.", "ev. chenopodium",
       "Ev. Fallopia", "ev. Gartenform", "ev. Hordelymus europaeus oder Milium
   effusum",
       "Ev. Medicago-klein gelb", "Ev. Setaria. Zu klein", "Ev. Valeriana
   tripteris o mycelis muralis",
       "evt. auch Bastard mit A. canina. an den knoten wurzelnd, rel. kurzes
   blatth.",
       "evt. auch colchicum", "evt. auch F. violacea", "evt. Conyza",
       "evt. Glechoma hed. Oder lamium gal., evt auch efeu", "Evt. Iris. 3
   kantiger stiel",
       "evt. prenanthes purpurea", "Evtl Kulturpflanze", "evtl. Eingabefehler
   CORA statt CROA",
       "evtl. kirsche", "evtl. P. integrifolia x latifolia (nach K. Koenig)",
       "Evtl. Setaria spec.", "Existe dans le secteur  i", "Exotique",
       "extrem klein, cf mollugo", "F", "F . glabres", "f ? bords poilus",
       "F a double pli", "F a poils sur face sup vert un peu bleute entre les
   dalles",
       "F alterne ovale enti\x8fre \x8eventuellement petit arbre",
       "F alterne un peu dent\x8ee, glauque pruineuse dessous",
       "F assez longue, plane, ligule tr\x8fs courte, cf Agrostis capillaris",
       "F av qgs dents espacees", "F avec poils epars sous le limbe mais pas
   holcus",
       "F avec qqs epines", "F bleu gris plt tapissante", "F bleutees dessous
   dentees",
       "F c\xf6mposees", "F canaliculees brillantes longues av epaulettes ",
       "F dent\x8ee attenu\x8ee vert fonc\x8e", "F dent\x8ee ovale alterne un
   peu glauque dessous",
        "F  dent\x8ee  p\x8etiol\x8ee", "F dent\x8ee, bord\x8ee de rouge,
   p\x8etiole court, stipule ",
       "f en coeur", "F en coeur poilue, p\x8etiol\x8ee", "F en c?ur sans
   stipule, pas viola mais y ressemble",
       "f en coeur, cr?nel?e, glabre \vpas Glechoma hederacea",
       "F en rosette basale cf Sonchus sp f \x88 bords un peu ondul\x8es face
   sup poilue ",
        "F enti\x8fre ronde att\x8enu\x8ee en p\x8etiole   ", "F entieres
   allongees long petiole poils simples",
       "F genre Apiaceae ou Fumaria", "F genre Matricaria f genre Achillea",
       "F genre Taraxacum, mais poilue", "F glabres trilobees",
       "F glauques", "F lin\x8eaire glauque verticilli\x8ee par 4",
       "F opp dentees en scie prouient psut etre des plants jetes dans la
   decharge yoisine",
        "F  oppos  glabres entieres", "F oppos\x8ees poilues (cf Lonicera
   xylosteum)",
       "F opposee decuss\x8ee un peu ronde", "F ovale \x88 bord entier cf Buxus
   sp",
       "F p\x8etiolee poilues un peu d\x8ecoup\x8ee", "F palmatilob\x8ee pl
   tr\x8fs petite",
       "F petite ronde cr\x8enel\x8ee petiole poilu", "F petite spatul\x8ee
   glauque",
        "F petite, poilue ronde p\x8etiol\x8ee ", "F petites", "F petites
   opposee poilues entieres tige ramifiee",
        "F  poilue, fol dent\xe9es sessiles cf Pimpinella sp cf Pastinaca
   sativa",
       "f poilues dent\x8ees, un peu en coeur \x88 la base", "f poilues sans
   glandes, ligule courte un peu lacini?e",
       "F pointue longuement p\x8etiol\x8ee enti\x8fre ", "f raiche poilue,
   ovale pointue comme pulmunaria, mais plus petite.",
       "F s\x8etac\x8ee, ligule ~0.5 mm", "F s?tac?e glabre, cf Festuca rubra",
       "F sillonn?e, sans oreillette, ligule tronqu?e, ~1mm,",
       "f subcylindrique fistuleuse", "f tr\x8fs fine, cireuse, stolons, cf
   Festuca rubra",
       "F tr?s fine s?tac?e, poilues", "F tres poilues", "F un peu brillante
   dessous striee lig tres courte pas d'oreill cf cyn cris ",
       "F un peu comme poiystichum probabl exotique", "F unique un peu ronde",
       "f vert clair poilues", "F.", "f. 4-5 mm de large", "F. dent\x8ees
   poilues ressemble \x88 un petit lamium",
       "f. fines, semblable \x88 Festuca mais scl\x8erenchyme qui traverse
   (microphotographie faite)",
       "F. oppos\x8ee-d\x8ecuss\x8ee,  lin\x8eaire-lanceol\x8ee, glabre tige
   quadrangulaire.",
       "f. ovales en rosette", "F. Petiole crenelee dentee f. Alterne glauque
   pruineuse dessous",
       "F. petite, forme comme Acer pseudoplatanus, mais p\x8etiole poilu, lobe
   dent\x8e.",
       "F. Plate mais carenee ligule 1-2mm", "F. poilue grande rude",
       "F. Poilues", "f. poilues plus ou moin cord\x8ees", "f. rhomboidale
   allong\x8ee, glauque dessous, glabre",
       "F. rugueuses \x88 poils rudes, ressemblant \x88 celles de Cynoglossum
   officilale (tr\x8fs poilues) mais je doute que c'est cette esp\x8fce...",
       "f. sans glandes mais pas E. pilosa. Probablement E. barrelieri...",
       "F. Tachees de noir", "Fabaceae", "Fast ganzrandiges blatt, breitbl.
   Behaart, graublau",
       "Fast rund, kahl, sehr d\x9fnner langer Blattstiel", "fast tot",
       "Fein", "Fein get,  dilatata / expansa", "fein geteilte b",
       "fein niederliegend", "fein, cf Avenella flexuosa ", "Fein, glauk",
       "fein, Jungpflanzen", "fein, mit kurzem B.htch", "fein, mit rauhem
   Rand",
       "Feine Borstenbl\x8atter, in Rasenansaat", "Feine gefaltete b",
       "Feine Grasscheiden", "Feine Luzula, nur Blattrosette, ev. auch junge
   Luzula sylvatica",
       "feine Rispe, aber Blattscheide  kahl", "Feine rollblaetter, cf festuca
   rubra",
        "Feines  Gras,  Blattscheiden  locker behaart", "Felicite (zucht)
   chinarose",
        "ferruginea/sempervirens", "Festuca cf violacea feuilles fines et
   longues",
        "Festuca  halleri",  "festuca  prat  o  lolium multifl", "Festuca
   pratense/Lolium multiflorum, Blatt gerollt, Oehrch. glaenzend",
       "Festuca pratensis (klein)", "Festuca pratensis od. Lolium multiflorum",
       "Festuca pratensis oder Lolium multiflorum", "Festuca violacea",
       "feuillage panache", "Feuille palmatilobee a lobes arrondis",
       "Feuilles", "feuilles \x88 nervation parall\x8fle, bord entier, \xb1
   lanc\x8eol\x8ees",
       "Feuilles au printemps fruit en aout ", "Feuilles bas du releve",
       "Feuilles brillantes fleurs jaunes et oranges", "Feuilles en rosettes
   spatulees",
       "feuilles en W", "Feuilles env. 4 mm de large, ligule 1 mm",
       "Feuilles glabres", "Feuilles larges", "feuilles petites",
       "Feuilles peu poilues", "Feuilles poilues", "Feuilles poilues dessous
   blanchatres",
       "Feuilles poilues en surface avec oreillettee", "Feuilles ressembant a
   crataegus mais tres petites cultivee",
       "Feuilles sans restes de fleurs ni fruits", "feuilles tr\x8fs fines, 3
   vaisseaux, sclerenchime continu: probablement F. duriuscula auct.",
       "feuilles vert fonc\x8e, poilues, cord\x8ees", "Feuilles vert fonce tres
   repandu dans le qazon",
       "Ff. brassicaceae", "filiformis/persica", "Filix-femina",
        "filix-mas",  "Filzige  B,  grosse rosette, B gesam", "flach, mit
   Kahnspitze, gefaltet ",
       "Flache BS", "Fleischige B., behaarte Blattguende", "Fleurs jaunes",
       "flexuosa", "foglie piccole scure coriacee", "fontana/dillenii",
        "fontaneum?",  "Fontanum",  "Forme  a  inflo atrophiee verific au
   binoculaire",
        "Forsythia  x  intermedia",  "Fragaria sp. Gartenform", "Fraxinus
   excelsior",
       "Fraxinus exelsior, zwei keimbl. und zwei weitere kleine blaetter",
       "frisch angesaetes Getreide, scheint eher nicht Hordeum zu sein",
       "Fruit non charnu, stolons", "Fuchsii", "Futterr\x9fbe",
       "Gaine aplat'e", "Gaine aplatie", "Gaines aplatiee", "Gaines poilues et
   f comme deschampsia",
        "gaines poilues ligule tr\x8fs courte jeune F enroul\x8ee er sans
   oreillette",
       "gaines poilues, ligule et oreillettes! cf. Brachypodium sp.",
       "Galanthus nivalis", "galeobdolon", "Galeopsis od. Lamium. Zu klein.",
       "Galium sp; vierblaettrig, unter Baumstanm", "Ganz jung",
       "ganz kleines B.", "Garten-variante", "Gartenart", "Gartenexot",
       "gartenform", "Gartenform", "Gartenform?", "Gartenpflanze",
        "Gartenpflanze,  vermutl. blaubl\x9fhend", "Gartensaat", "Gattung
   unsicher",
       "Geb?sch sp, cf Prunus", "Gedrehtes B cf alopecurus pratensis",
       "Gefleckte B. , cf dactyllhoriza maculata", "gefleckte Blaetter",
        "Gefleckte  Orchideenblaetter",  "Gefleckter  Stengel.  Gaenzlich
   abgefressen.",
       "Gegenst b, bl einzeln in b.achseln, cf serpyllifolia / peregrina ",
       "Gegenst ganzr b, behaart, knapp unterhalb knappdraussen-fraxinus, an
   stein",
       "Gegenst, runder St", "Gegenst\x8andig, gekerbt, evt.  Veronica",
        "Gegenstaendige  ganzrandige ovale blaetter, aber nicht Saxifraga
   oppositifolia",
       "Gekerbter blattrand, cf campanula", "genipi", "genre chamomille",
        "Gentiana  2",  "geoehrt  und  behaart", "gepflanzt", "Gepflanzt,
   Gartenform?",
       "Gepflanzt, nicht einheimisch", "Gepresst", "germanica",
       "Gerollt geoehrt behaart", "Gerollt, kahl,,,", "gerollte b",
       "Gerste", "Gespritzt. Entweder k\x9fmmerliche Capsella bursa-pastoris
   oder Cerastium fontanum.",
       "Getreide angebaut", "Getreide? Zu klein", "Gez\x8ahnt, evt. ranunculus
   acris",
       "Gezahnte B 1.7m richtung hochspannungsmast", "Glabre f larges 4mm",
       "Glabre ligule pas d oreillettes", "glabre, cf. canina aggr., sans
   fruits",
        "Glandulifera  (s.  Klein)",  "glauc,  mit  kr\x8aftiger  Ligula,
   breitbl\x8attrig, \x8ahnlich Dactylis, aber +- rund",
        "glauca var conica", "Glauque \x88 oreilettes poilues", "Glechoma
   \x8ahnlich",
        "Glechoma  hederacea",  "Glechoma.  Sehr klein", "globularifolium
   v\x8eg\x8etatif",
       "Glyceria fluitans s.l.", "gr\x9aber, Bl\x8atter und v.a. Blattscheide
   dicht kurz weich behaart, Ligula 0,5 mm",
       "Gr\x9fner stiel, oder junge D. Filix-mas, an der tanne vis a vis AFZ",
       "Graines germees", "Grande oreillette poilue ligule 2mm tronqu\x8ee
   blanche cf Triticum aestivum",
       "Grande sans spores", "Gras mit borstenfoermigen Blaettern",
       "Gras mit kz, behaarten Bl\xe4ttern; wenig Expl.", "Gras zu jung",
        "Gras,  etwas  blaugr\x9fn,  kahl, rel. breite Bl\x8atter, langes
   Blatth\x8autchen",
        "Grasartige Blaetter, blauviolettgruen, etwas steif", "Grasartige
   Blaetter, etwas blaugruen, US bereift",
       "Grasige, kurze, leicht gekruemmte Blaetter - cf. Minuartia recurva /
   verna",
       "Grasscheiden kurz, abgefressen", "Groessere Aerchen, Auslaeufer",
       "Gross", "Gross. Nur vegetativ", "Grossbl\x8attrig", "Grossblaetterig,
   laenglich  verkehrt eifoermig, v.a. auf Hauptnerv US behaart; ev. auch
   Hypochaeris uniflora",
       "grossbluetig", "grossbluetig, druesenlos; cf alpina", "Grosse b, nur
   auf nerven behaart, cf sylvaticum",
       "grosse B. \x8ahnl. Chae. hirs. aber feiner", "Grosse Blattrosetten, ev.
   auchvon Gartenpflanze",
       "Grosse ganzrandige dunkelgruene blaetter", "Grosse, ganzr. b, stark und
   weich behaart, einfache haare; gegenst",
       "Grosses, untypisches Blatt", "Grundst b borstenf\x9armig, cf avenella",
       "Grundst b spatelf, herbar", "Grundst b.rosette, einf haare, teils
   leicht gez, cf. asteraceae, ev. erigeron",
       "Grundstaendige Blaetter rundlich, gestielt; cf. Campanula scheuchzeri",
       "Grunstaendige blaetter in rosette, spatelfoermig, unbehaart; waechst in
   polstern von silene",
       "Gurke o. K\x9frbis", "Gypsophila muralis", "H\xfcllspelzen wie Ph.
   prat., aber Rispe nur 3cm lg. . ",
       "haare am Blattgrund  cf bromethie", "haarig", "Haarig",
       "Haarig annuell", "Haarig kurz dunkelgrun, c.f. alpinum",
       "Haarige rosette mit auslaufern", "Habitus her G. pumilum, Alternative:
   G. anisophyllon",
       "Habitus wie E. Montanum, aber keine geteilte narbe. Aber auch keine
   deutl. Rippen",
       "Habitus wie G. verna, Bl\x8atter aber<1cm lang", "halleri/ovina",
       "Halme geknickt aufsteigend, Knoten z.T. mit Blatttrieben, ohne Wurzeln.
   Alternative: A. stolonifera",
        "Hampe  florale  s\x8fche  ramifi\x8ee", "Hellgr. weiche B. Salix
   appendiculata?",
       "Hellgr\x9fn klein", "Helveticus", "Heracleum sphondylium/Adenostyles",
       "herbar", "Herbar", "Herzf\x9armige Bl\x8atter", "Hgr sehr fein",
       "hirsutum", "Hispanica", "Hispidus", "Hispidus / incanus, herbar",
       "hoch, glauc, trotzdem rubra?", "hochwahrscheinlich kultiviert",
       "Hochwahrscheinlich kultiviert f comme oreopteris", "Holcus lanatus o.
   Bromus hordeacus",
       "Holcus? ", "holost/glomeratum eine kleine pflanze", "Holzpfl. cf.
   Prunus",
       "hordeaceus oder racemosus", "Hordelymus europaeus", "Horst",
       "Horstig, Blaetter gerollt", "Horstiges Gras", "Huperzia selago juv.",
       "huperzia selago oder lycopodium annotinum", "Hyb?", "Hybrid",
       "hybrid petrae-robur", "Hybride", "Hybride rosa bluehend",
       "Hybride, gepfanzt oder verwildert", "Im Juli schon verbl\x9fht",
       "Im moment gej\x8atet", "Im ob. Teil stark dr\x9fsig, Bl\x9ften ca. 4mm
   lang, Deckbl\x8atter dicht",
       "im obst garten", "Impatiens parviflora", "In Ansaat mit Phacelia",
       "In Felsspalte", "In pflasterritze", "In zwstr unten, breite, behaarte
   bl\x8auliche b",
       "In zwstr unten, cf ligusticum", "inconnue f. poilues, devant Vitis",
       "Inflorescence = petite panicule peu ramifiee differente de toutes les
   autres Graminees du relevr",
       "Internodien lang, Blaetter eher schlank und langsam zugespitzt",
       "irgendeine R\x9fbenart als Zwischenkultur", "J'avais mis Avenella
   flexuosa mais la coupe de la feuille n'est pas d'Avenella. Feuilles tr\x8fs
   lisses, capillaires avec 7 nervures et 9 faisceaux de scl\x8erenchyme. Ce
   n'est pas \x88 mon avis une Festuca et ne parait non plus une Agrostis
   rupestris...",
       "j'avais mis brachypetalum subsp. toneranum mais je ne crois plus \x88
   \x8da...",
       "j'avais not\x8e un lanatus mais j'ai eu un doute au deuxi\x8fme passage
   car vu un mollis. Peut-\x90tre il y a les deux",
       "J\x9fngstes b gerollt, blaugr\x9fn, breite b, krallen, b nur schwach
   gefurcht, oben matt, unten gl\x8anzend festuca?",
       "J\xd5avais mis V. alba s.l. en 2001 mais je crois que c?tait d\x8ej\x88
   odorata! Poils dirig\x8es en bas et stipules avec poils glanduleux.",
       "Jacobaea-eruci", "Jeunes pousses, f rondes dent\x8ees, p\x8etioles
   glanduleux et aiguillons",
       "Jung", "Jung veg", "Junge Pfl., <2cm, Bl\x8atter st. behaart, Haare
   gegliedert, US violett, mit Dr\x9fsenkratern wie O. vulgare.",
       "Junge rosette", "Jungpfl.", "Jungpfl. 1.Bpaar eifg spitz, gesaegt cf.
   Campanula",
        "Jungpfl/keim'  so  gut wie sicher", "Jungpflanze", "Jungpflanze,
   unbestimmbar",
       "Jungrosette", "Jupfl.", "Juv", "juv.", "Juv.", "juv., Keimblatt.+ 2
   Bl?tter",
       "juv., schmale ganzrandige Blaetter", "Juvenil", "juvenil, blaetter fast
   bis zum grund geteilt",
       "Juvenil, verwildert, nicht C. salicifolius", "K Cf Veronica. Zu klein.
   Nur vegetativ",
       "k cf.", "k cf. feuilles poilues", "k petite plantule", "K Zu klein. Cf
   Euphorbia spp.",
       "k, poilue, petite feuilles", "K\x9fmmerex", "k\x9fmmerex.",
       "K\x9fmmerex.", "K\x9fmmerliches Bl\x8attchen", "Kahl", "Kahl blaugrau
   bereift",
       "kahl, lg. Stiel, .bitter", "Kahle Blaetter", "Kahler kelch",
        "Kahles  grosses  Blattpaar,  ca.  4 cm ueber Boden. Alternative:
   Platanthera spec.",
       "Kartoffelacker", "kaum Blattht., Stengel leicht abgefl., s. lange B.
   kurze Kahnspitze",
        "Keimbl.  + 2 kaum entw. bl. frax/acer", "Keimbl. + 2. Blattpaar,
   weissscchuelferig, zahlr. Expl.",
       "Keimbl. Etwas herzfoermig, Primaerblatt mit geschweiftem Rand (cf.
   VERONICA)",
       "Keimbl. u. 2 sehr kl. behaarte bl.", "Keimbl\xe4tter und 1 weiteres
   Blatt",
       "Keimblaetter fuenflappig, erste Blaetter am entfalten",
       "Keimblaetter mit Blaeschenstruktur, wie bei Chenop. album, aber erste
   junge Bl?tter mit Sternhaaren, bereits vergilbt.",
       "Keimblatt und ein Blatt", "Keimling", "Keimling Gartenart",
       "Keimling mit 2 Blaettern", "Keimling sp mit zwei kleine B.",
        "Keimling  sp;  Zweiblattst.,  2 mm, cf Lamiaceae", "Keimling sp;
   Zweiblattst., ev. Busch?",
        "Keimling, \"Rosette\" mit 2 B", "keimling, bluehende s. Asper in
   umgebung vorganden (s. Oler. Nicht gesehen",
       "Keimling, cf Caryophyllaceae", "Keimling, rote Bl\x8a",
       "keimling/jungpfl.", "Kein bes. Merkmale", "kein Poa, kraeftige Rillen,
   B.htchen. ca. 1-2 mm, keine Oehrch.",
        "keine  Doppelrille, B.htch. lang, zugespitzt, Nerven dick, keine
   B.\xf6hrchen",
        "Keine  eindeutigen Mwrkmale wie Staubbeutel vorhanden", "Kelchb.
   abgerundet",
       "Kelchborsten am grunde etwas abgeflacht,  habitus aber eher von s.
   Columbaria",
       "Kelchzipfel lg. lanzettlich mit spitzen Buchten, am Rand glatt, z.T.
   ungleich; Fr.knoten ca. 2 mm gestielt; Wuchs gedrungen",
        "KK  esp\x8fce  tr\x8fs  poilue.   G.  pumilum ou moins encore un
   anysophyllon. Il se trouve dans du Festucion variae",
        "KK,  une seule feuille! pas beaucoup. Je pensais \x88 une banale
   tuberosa...",
       "Kl.  Rosette", "kl. B.\x9ahrchen", "Kl. Bl\x8atter, am Rand bewimpert",
       "Kl. breite Bl\x8attchen am Grund, ev. auch G. anisophyllon",
       "Kl. Cardamine- Blatt", "Kl. Carex-Pfl\x8anzchen", "Kl. gg.st\x8andige
   Bl\x8atter (3-5mm lg.), mit einigen kurzen Borsten v.a. am Stiel.",
       "Kl. Horst", "kl. junge Pfl\xe4nzchen; kahl; Bl\xe4tter wechselst., ca.
   5mm lg.,spitzoval, dtl. gestielt",
       "kl. Ligula, leicht behaarte B.scheide und B, keine Oehrchen",
       "Kl. Pfl\xe4nzchen; Blattform ca. 2:1, OS locker, US dtl. behaart",
       "Kl. Pfl\xe4nzchwn mit typ. Blattspitze. Ev. auch junge L. sylvatica",
       "Kl. Pflanze mit Fruechten. Unklar, ev. auch C. flexuosa.",
        "Kl.  Pflanze, ca. 10cm. Blaetter eher rundlich, aber typ. scharf
   gezaehnt.",
        "Kl.  Rosette auf Viehweglein", "Kl. Rosette, Blaetter mit 1 Paar
   Seitennerven, kurz abstehenf behaart",
         "kl.   Rosette,   cf  Gentiana  sp,  B.rand  rel.  glatt",  "kl.
   Rosette,fleischig, am B.rand sehr viele scharfe Zaehnchen/Papillen",
       "Kl. Rosetten, dunkelgrun. Bl\x8atter spatelfoermig, fast kahl, Stiel
   etwas violett",
        "Kl.  spitzovale, wechselst. Bl\xe4tter", "Kl. verholzte Pflanze;
   Blaetter rundlich, ca. 7-10mm, seicht gezaehnt, Rand auf US wukstig",
       "Kl. weisse Bl\x9ften, +- ohne Rosette, Fluegel max. 4mm lg. Ev. auch P.
   alpestris",
       "Kl., behaarte Rosette", "kl.B.htchen, Blattoehrchen", "Klein",
       "Klein im pflaster", "Klein u trocken", "klein unten behaart",
       "Klein, cf. collinum, frucht ohne dr\x9fsen, st auch, kr.b. ca. 6 mm",
        "klein,  eher  nicht  minima", "Klein, gegenst. B, evt. ligustrum
   vulgare",
       "klein, hellgr\x9fn, Bl\x8atter ca 3 mm breit, gefaltet",
       "klein, nicht salisburg.", "Klein, nur einfacges breites Endteilblatt",
        "Klein,  rund",  "Klein,  wechselst.,  kahl", "Klein. Lamium oder
   Galeopsis",
       "kleinb\xe4ttrig", "Kleinbl\x9ftig", "kleinbl\x9ftig, nicht dr\x9fsig",
       "kleinbluetig, druesenlos", "Kleinblutig, gelb.winziges ex.",
       "Kleine b", "kleine B., cf Solidago minuta", "kleine B.; cf Leontodon
   sp",
       "kleine Blaetter", "Kleine Blaetter, dicht kurz behaart",
        "kleine  Blattrosette",  "Kleine  dichte  Blattrosette",  "Kleine
   Grundblaetter, ungeteilt; Stengelbl. abgefallen; mit Fruchtstand. Moegliche
   Alternative: C. resedifolia",
       "Kleine Horste, nur wenige cm gross, ev. Festuca spec.",
       "Kleine lila Bl\x9ften", "Kleine Pflanze, relativ schmale Blaetter;
   kurzes Blatthaeutchen",
       "kleine Rosette mit ca. 4 gest., unget., unterseits etwas filzigen B.,
   erst 2 cm ",
       "kleine Rosette sp", "Kleiner junger Farn", "Kleiner Keimling",
       "Kleiner strauch, herbar", "Kleiner, feiner Horst. Abgefressen.",
       "kleines Blatt, cf Campanula cochlearifolia", "Kleines dreiteiliges
   Blatt, Rand gezaehnt",
       "Kleines junges Distelblatt; C. arvense in der Umgebung zahlreich",
       "kleines, kriechendes Kraut mit dgr\x9fnen B", "kleinste Blattrosette,
   cf hispidus/helveticus",
       "kleinste Rumex-Bl\x8attchen", "Kmlg. Ev Poa trivialis",
       "Kompostbehaelter", "Korkenzieherform", "Kospen mit kurzem sporn",
       "Krause minze \"fris\x8ee\"", "Krueppel", "Kult", "kult.",
        "Kult.",  "Kultivar", "kultiviert", "Kultiviert", "Kultiviert und
   verwildert",
       "kultiviert, Keimblaetter plus 2 Folgeblaetter", "kultivierte Zierrose",
       "kultur", "Kultur", "Kulturpflanze ?", "kulturrelikt", "Kulturrelikt",
       "Kulturrelikt (Vorjahreskultur)", "Kurzes blatth\x8autchen, wurzelt aber
   an den knoten (oberird. Ausl\x8aufer)",
       "L", "L\x8angliche Bl\x8atter,vorne etwas breiter", "L\x8angliches
   Blatt, cf. Asteraceae",
       "Laengl.-lanzettliches Blatt", "Laengliche, spatelfoermige Blaetter,
   fast kahl, ca. 4 cm lang. Keine Vermutung",
        "Lamiaceae  lanzettl.  blaetter",  "Lamium oder Stachis", "Lamium
   purpureum",
        "Lange  gras\x8ahnliche  Bl\x8atter",  "Lange schmale Bl\x8atter,
   Bl.h\x8autchen ca. 2mm lang",
       "Lange schmale Blaetter", "Lange schmale rinnige Orchideenblaetter",
       "lange, schmale, rauhe Blaetter", "langes B.htch., ungeoehrt",
       "Langes Bh\x8autchen", "langgezogen gestielt", "Langliche bl\x8atter cf
   crepis aurea",
       "Lanzettl. Bl.", "Lanzettlich, lang gestielt, blattstiel und. B. Schw.
   Behaart, cf conyza",
        "Lanzettliche  Blaetter, ca. 3cm .lang; beidseits  rel. dicht mit
   gelblichen mehrzelligen Druesenhaaren",
       "Latifolium, une foliole dans l'AFZ", "laurocerasus", "lawsoniana",
       "laxa/minor", "laxa/minor; eher laxa aber Rispe +- rund",
       "leicht behaarte B.scheiden, B.htch. 1-2 mm, starke Nerven, rauher
   Rand",
       "leicht behaarte Oehrchen, sonst aehnl. Agropyron", "leider unklar ob
   Triticum aestivum oder Triticale",
       "Leontodon helveticus", "Leontodon od. Hieracium", "leontodon ou Crepis
   ou ...",
         "Lepidium  virginicum",  "Leucanthemum  vulgare,  pousse",  "lg.
   borstenf\xf6rmige Bl\xe4tter",
       "Lg. gras", "Lg. l\xf6ffelf\xf6rmige Bl\xe4tter, wenig behaart",
       "Lg. spatelfoermige Blaetter, steif weiss behaart, mit dtl. Nerven",
       "Lig frangee f glabres", "Ligule courte env. 0.5mm leg. Dentee f. Un peu
   glauque",
       "ligule courte, cf. pratensis", "Ligule f glabre sans oreillette",
       "Ligule frangee", "Ligule poilue", "Ligule ultra courte, touffe de poils
   raz derriere la gaine, f. un peu torsad\x8ees scabres et pointues.",
       "Liliaceae sp. ou Orchidaceae", "Limbe finissant en capuchon ligule tres
   courte f vert vif",
       "Limbe longuement cilie", "Linum catharticum oder Hypericum sp",
       "Lloydia serotina", "Lobes pointut", "Lockere Rispe, allseitswendig",
       "Loewenzahnaehnliche Blaetter", "Lolium multifl oder festuca prat",
       "Lolium multiflorum o. Festuca pratensis", "Lolium perenne sehr kl..
   pfl.",
       "Lolium sp., wohl Bastard perenne x multiflor.", "Lolium?",
       "Long stolon souterrain ni poa ni agrostis ni festuca", "Longs poils
   jamais glanduleux",
       "Longs stolons et gaines rouges deja determine au printemps a verifier",
       "Lutea / alpinopilosa", "luzuloideshia", "Lychnis flos-cuculi",
       "Lysimachia punctata juv. oder Origanum juv.", "Lysimachia?",
       "Lythrumartig(ziemlich klein) gepresst)", "m", "macrophylla",
       "magelanica var ricatonii", "Mais", "Maisfeld", "mauvaise odeur",
       "Max 3cm hoch", "Medicago / Trifolium", "Medicago sp f. genre tr\x8ffle
   mucron\x8ee",
       "Mehlig", "mehrbl\x9ftig mit St. B. Stengel mit drei Haartypen, B. auch
   dr\x9fsig",
       "Mehrere jungpflanzen>keimlingstadium", "mezereum (jeune plante avec 4
   feuilles)",
       "Milch, kahl, B. Ganzrandig", "minima", "Minuscule mais differente des
   especes deja presentes",
       "Misuriensis", "Mit  Dr\x9fsen", "mit auslaeufer, cf. gigantea",
       "mit B.htch, breite B", "Mit Borstbl\x8attern, etwas rauh",
       "Mit deutlicher mittelrippe (evt. Hieracium)", "Mit Dr\x9faen",
       "Mit dunkler mitte bei Schuppe. Nicht f.  M!", "Mit flecken",
       "Mit Oehrchen, Bl.oberseite rauh, Bl.unterseite gl\x8anzend, junge
   Bl\x8atter gerollt",
       "mit Rosette, klein", "Mit stengelbl\x8attern", "Mit weissen blumen",
       "Mit zerfressenen Bl\x8attern,langem,d\x9fnnem Stengel.",
       "mite/minus", "Moehringia trinervia", "Molle/pyrenaicum",
       "montana", "montanum", "Montanum", "Montanus", "multiflorum",
       "Muricata od pallescens", "mutellina", "Mutellina oder mutellinoides",
       "Myosotis", "Myosotis arvensis", "Myosotis o cerastium",
       "Myosotis. Gartenform", "Myosotis/Pulmonaria", "Nahe zentrum b. kahl b.
   Hautchen kurz cf. Melica",
       "Narcissus/leucojum-nurnoch fruechte vorhanden", "Nasturtium",
       "Neben V. thomasiana vermtl. noch 2. Art: Pfl. klein, fast kahl, insb.
   Fruechte. ",
       "Nebenbl\x8atter l\x8anglich lanzettlich. Alternative: P. crantzii",
       "Nervation diff de taraxacum", "nicht behaarte Blueten",
        "Nicht  bl\x9fhend",  "nicht dentaria flexuosa?", "Nicht dentaria
   flexuosa?",
       "nicht Poa", "Nicht punktiert, cf maculatum", "Nie im bl\xfchenden
   Zustand gesehen",
       "Nigra alpigena", "Nigra od. Xylosteum ", "Noch kl. Rosetten",
       "noch nicht aufgebl\x9fht, helle knospen l\x8angliche, ungefleckte B.",
       "Noch sehr jung", "Noch sehr klein", "Noch wenig entwickelt",
       "non identifi\x8ee, f. oppos\x8ees enti\x8fres. Petite",
       "non identifi\x8ee, gaines stri\x8ees de rouge", "non poa Gaine aplatie
   glabre limbe auec longs poils ligule subnulle",
       "non retrouv\x8e au deuxi\x8fme passage pour mieux l'identifier",
       "Nur 1 blatt", "Nur 1 Blatt", "Nur 1 Blatt mit \x8ahnlichem Habitus",
       "Nur 1 Blatt, US auf Nerven und Rand kurz borstig behaart",
       "Nur 1 kleine Pflanze", "Nur 1 Pflanze, Rosettenblatter mit langen
   weissen Haaren (v.a. am Rand)",
        "nur  2 Blaetter, dicklich, dunkelgruen; dicht behaart, Haare mit
   Fuesschen; Seitennerven fast unsichtbar",
       "Nur 8cm hoch", "Nur alter Fruchtstand mt 3 Klappen, ca. 5cm hoch",


   Thanks a lot!!!! I wish you a very nice day!!! kind regards Jacqueline
   Gesendet: Dienstag, 25. Juni 2013 um 18:09 Uhr
   Von: "David Winsemius" <dwinsemius at comcast.net>
   An: "John Kane" <jrkrideau at inbox.com>
   Cc: "Jacqueline Oehri" <jacqueline.oehri at gmx.ch>, r-help at r-project.org
   Betreff: Re: [R] Fwd: Questions about working with a dataframe
   On Jun 25, 2013, at 8:57 AM, John Kane wrote:
   > Hi, welcome to R
   >
   > Try using the function str() on both files so str(WWA) and str(oWWA) and
   compare  the structures that you get. Probably one of the varables you
   defined when creating the original WWA data set has changed from a character
   variable to a factor or vis versa.
   >
   > It is a good idea to use dput to supply sample data here.
   >
   > So dput(WWA) and paste the results into the email and repeat with the
   other data set. Then readers can paste the actual data sets into R and work
   on them directly.
   In this case I think it would be much more courteous to include:
   dput(head(WWA))
   dput(head(oWWA))
   ... in light of the attached 5MB file in that email.
   I apologize to the other list readers for approving it in the moderation
   queue. It should ahve been rejected, but my excuse is that the moderation
   viewer doesn't always highlight all aspects of hte postings being viewed
   that should be highlighted.
   --
   David.
   > If the str() approach does not give you enough information please paste in
   the dput results in your next email.
   >
   > Good luck
   >
   > John Kane
   > Kingston ON Canada
   >
   >
   >> -----Original Message-----
   >> From: jacqueline.oehri at gmx.ch
   >> Sent: Tue, 25 Jun 2013 16:25:59 +0200
   >> To: r-help at r-project.org
   >> Subject: [R] Fwd: Questions about working with a dataframe
   >>
   >>
   >>
   >>> Dear R-Users,
   >>> I hope this is the right e-mail adress to post questions about
   >>> Programming in R, and I hope somebody of you can help me with the
   >>> troubles I have :)
   >>>
   >>>
   >>> 1) First Question:
   >>>
   >>> I have a dataframe called "WWA" (its attached to this e-mail
   >>> ). It looks a little bit like the following one:
   >>>
   >>>
   >>> testcoordID testcommunity testaltitude testSpeciesName
   >>> 1 503146 Bournes 523.2 Bellis perennis
   >>> 2 503146 Bournes 321.5 Cynosurus cristatus
   >>> 3 557154 Bournes 654.1 Festuca pratensis
   >>> 4 557154 Aigle 938.6 Bellis perennis
   >>> 5 569226 Aigle 401.3 Bellis perennis
   >>> 6 599246 Aigle 765.9 Prunella vulgaris
   >>>
   >>> ((I programmed this little one like this:
   >>> testcoordID
   >>>
   <-c(as.integer("503146"),as.integer("503146"),as.integer("557154"),as.intege
   r("557154"),as.integer("569226"),as.integer("599246"))
   >>> testcommunity <-factor(c("Bournes","Bournes","Bournes", "Aigle",
   >>> "Aigle", "Aigle"))
   >>> testaltitude <- c(523.2,321.5,654.1,938.6,401.3,765.9)
   >>> testSpeciesName <-c( "Bellis perennis",
   >>> "Cynosurus cristatus",
   >>> "Festuca pratensis",
   >>> "Bellis perennis",
   >>> "Bellis perennis",
   >>> "Prunella vulgaris")
   >>> testframe <- data.frame(testcoordID,testcommunity,testaltitude,
   >>> testSpeciesName))
   >>>
   >>>
   >>>
   >>> I needed to manipulate WWA in Excel, therefore i wrote
   >>> it as a text-file:
   >>>
   >>>> write.table(WWA, "WWA.txt", col.names=T, row.names=F, sep= ";", quote
   >>>> =T)
   >>>
   >>> Then I manipulated the WWA.txt in Excel and saved it as "noWWA.csv"(
   >>> ) and re-importet it under the new name "oWWA" in R:
   >>>
   >>>> oWWA <- read.csv("~/Desktop/NCCR master projekt/BDM Beschreibungen/BDM
   >>>> Daten/noWWA.csv", header=TRUE, sep=";")
   >>>
   >>> What i need to do with this "WWA" or "oWWA"is finally to create a list
   >>> (or a dataframe but this is not possible i think), that shows for each
   >>> coordinateID ("testcoordID") the species Names occuring at this place:
   >>>
   >>>> species_per_coordID1<- tapply((WWA$speciesName), WWA$coordID, list)
   >>>> species_per_coordID2 <- split(WWA$speciesName, WWA$coordID)
   >>>
   >>> ---> now my Question: This works very well with the WWA table, but not
   >>> with the oWWA!! I think i changed something in the dataframe by
   >>> converting it to a .txt file and than back to a .csv;
   >>> But does anybody know why it works with WWA and not with oWWA? how can I
   >>> treat the WWA dataframe in Excel without changing any format of it?
   >>>
   >>>
   >>> Thaanks a lot for any help or suggestions!!!!!
   >>>
   >>> Have a nice day,
   >>>
   >>> Kind regards Jacqueline
   >>>
   David Winsemius
   Alameda, CA, USA

From jacqueline.oehri at gmail.com  Wed Jun 26 11:36:42 2013
From: jacqueline.oehri at gmail.com (Jacqueline Oehri)
Date: Wed, 26 Jun 2013 11:36:42 +0200
Subject: [R] 2nd question about adding an additional variable along certain
 criteria in a dataframe
Message-ID: <CAPpYjvt9kvLHhWeS4hdhbEBmw_hgjhsEdSQT9yGbT7K82UZzBw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130626/17fe6708/attachment.pl>

From careyshan at gmail.com  Wed Jun 26 17:48:34 2013
From: careyshan at gmail.com (Shane Carey)
Date: Wed, 26 Jun 2013 16:48:34 +0100
Subject: [R] XYZ data
Message-ID: <CA+jRDxAJ-3+uY4rhVS5mPmPyM3-catgefpzqMGVoBp5dATQGgw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130626/b06d2250/attachment.pl>

From sarah.goslee at gmail.com  Wed Jun 26 17:49:35 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 26 Jun 2013 11:49:35 -0400
Subject: [R] 2nd question about adding an additional variable along
 certain criteria in a dataframe
In-Reply-To: <CAPpYjvt9kvLHhWeS4hdhbEBmw_hgjhsEdSQT9yGbT7K82UZzBw@mail.gmail.com>
References: <CAPpYjvt9kvLHhWeS4hdhbEBmw_hgjhsEdSQT9yGbT7K82UZzBw@mail.gmail.com>
Message-ID: <CAM_vjukmMmSK9Ef_ecf2VAeFsQzkSvRbu1m_1E-BbPbcuBHKmQ@mail.gmail.com>

Hi,

Using your testframe and testvector (and thank you for the convenient
reproducible example):

# I used NA instead of "to be assigned"
testframe <- data.frame(testframe, landuse = "NA", stringsAsFactors=FALSE)

# checks membership in testvector
testframe[testframe$testcoordID %in% testvector, "landuse"] <- "gfgh"


Sarah

On Wed, Jun 26, 2013 at 5:36 AM, Jacqueline Oehri
<jacqueline.oehri at gmail.com> wrote:
> Hello everybody,
>
> I have a question concerning the work with my dataframe and i hope some of
> you can help me out:
>
> I have A data frame called "WWA" that looks like the "testframe"
> underneath:
>
> Additionally, i have a testvector, containing coordinate IDs:
> testvector <-c("503146","551154","557154")
>
>> testframe:
>
>        testcoordID  testcommunity  testaltitude    testSpeciesName
> 1      503146       Bournes        523.2           Bellis perennis
> 2      503146       Bournes        321.5           Cynosurus cristatus
> 3      557154       Bournes        654.1          Festuca pratensis
> 4      557154         Aigle        938.6          Bellis perennis
> 5      569226         Aigle        401.3          Bellis perennis
> 6      599246         Aigle        765.9          Prunella vulgaris
>
> I added an additional collumn:
>
>> testframe$testNCCR_land_use <- c("to be assigned")
>> testframe
>
> testcoordID testcommunity testaltitude     testSpeciesName
> testNCCR_land_use
> 1      503146       Bournes        523.2          Bellis
> perennis            to be assigned
> 2      503146       Bournes        321.5          Cynosurus cristatus   to
> be assigned
> 3      557154       Bournes        654.1          Festuca pratensis
> to be assigned
> 4      557154         Aigle           938.6           Bellis
> perennis            to be assigned
> 5      569226         Aigle           401.3           Bellis
> perennis            to be assigned
> 6      599246         Aigle           765.9           Prunella
> vulgaris         to be assigned
>
>
>
> -->QUESTION:
>  Now I need to compute a function, that checks for the coordID in every
> row, if the respective coordinateID is contained in the test-vector or not!
>
> 1) If the coordID in the row is contained in the testvector --> It should
> assign the name "gfgh" into the "testNCCR-land_use_collumn to this row!
>
> 2)If the coordID in the row is not contained in the testvector--> there
> should be done nothing and there will still be "to be assigned" in the
> testNCCR_land_use column.
>
> I tried something like this but it didnt work: Can somebody help me out?
> It says: "Error, trial to use a non-function" or something like this..
>
>
> for (i in 1:6(testframe)){
> +   if ((length(intersect(testvector, testframe$testcoordID[i]))) == 1){
> +     testframe$testNCCR_land_use[i]<-("testgfgh")}
> + }
> Fehler: Versuch eine Nicht-Funktion anzuwenden
>
>
> Thank you veery much for your help!!!!
>
>
>
> (I built the testframe up like this:
>
> testcoordID <-
> c(as.integer("503146"),as.integer("503146"),as.integer("557154"),as.integer("557154"),as.integer("569226"),as.integer("599246"))
> testcommunity <-factor(c("Bournes","Bournes","Bournes", "Aigle", "Aigle",
> "Aigle"))
> testaltitude <- c(523.2,321.5,654.1,938.6,401.3,765.9)
> testSpeciesName <-c( "Bellis perennis",
>                     "Cynosurus cristatus",
>                     "Festuca pratensis",
>                    "Bellis perennis",
>                    "Bellis perennis",
>                     "Prunella vulgaris")
> testframe <- data.frame(testcoordID,testcommunity,testaltitude,
> testSpeciesName)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org


From nblaser at ispm.unibe.ch  Wed Jun 26 17:50:16 2013
From: nblaser at ispm.unibe.ch (Blaser Nello)
Date: Wed, 26 Jun 2013 17:50:16 +0200
Subject: [R] help with plotmeans (gplots)
In-Reply-To: <CAEy8Jr2A8LwM0HrmnwvYH5Ge70p_w0A8aX-LnpkYX3ajDCVi4A@mail.gmail.com>
References: <CAEy8Jr2A8LwM0HrmnwvYH5Ge70p_w0A8aX-LnpkYX3ajDCVi4A@mail.gmail.com>
Message-ID: <17EE8C62EA18B84B94C2BA96A143064C01721A86@mx01.ispm.unibe.ch>

The formula in plotmeans compares vectors. This should work:

data <- unlist(data)
times <- rep(1:15, 100)
plotmeans(data~times)

Best, 
Nello

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
On Behalf Of Simone Gabbriellini
Sent: Mittwoch, 26. Juni 2013 17:20
To: r-help at r-project.org
Subject: [R] help with plotmeans (gplots)

Dear List,

I have replicated an experiment 100 times. Each experiment lasts for 15
iteration. Thus I have collected results into a data.frame with 100
columns (one column for each experiment) and 15 rows (one row for each
iteration).

I would like to plot mean values at each iteration using plotmeans, but
I am unable to understand the syntax I should use. I tried:

times<-as.factor(seq(1,15))

plotmeans(data~times)


with no luck... what should I tell to plotmeans in order to evaluate my
dataset?


Best regards,

Simone

--
Simone Gabbriellini, PhD

PostDoc at DISI, University of Bologna
mobile: +39 340 39 75 626
email: simone.gabbriellini at unibo.it
academia.edu: http://goo.gl/7pq62

DigitalBrains srl
Amministratore
mobile: +39 340 39 75 626
email: simone.gabbriellini at digitalbrains.it
home: www.digitalbrains.it

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Wed Jun 26 18:02:26 2013
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 26 Jun 2013 08:02:26 -0800
Subject: [R] XYZ data
In-Reply-To: <CA+jRDxAJ-3+uY4rhVS5mPmPyM3-catgefpzqMGVoBp5dATQGgw@mail.gmail.com>
Message-ID: <05AA1FB4006.000011CBjrkrideau@inbox.com>

 mm  <-  1:10
nn  <- mm + .001

John Kane
Kingston ON Canada


> -----Original Message-----
> From: careyshan at gmail.com
> Sent: Wed, 26 Jun 2013 16:48:34 +0100
> To: r-help at r-project.org
> Subject: [R] XYZ data
> 
> I have x, y, z data. The x, y fields dont change but Z does. How do I add
> a
> very small number onto the end of each x, y data point.
> 
> For example:
> 
> Original (X)              Original (Y)                 Original (Z)
> 15                               20                              30
> 15                               20                              40
> 
> 
> 
> 
> New (X)              New (Y)                 New (Z)
> 15.00001             20.000001              30
> 15.00002             20.000002              40
> 
> 
> Thanks
> --
> Shane
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From nblaser at ispm.unibe.ch  Wed Jun 26 18:02:56 2013
From: nblaser at ispm.unibe.ch (Blaser Nello)
Date: Wed, 26 Jun 2013 18:02:56 +0200
Subject: [R] Creating a matrix with an unknown variable
In-Reply-To: <DUB117-W882ADEBD88C5CE42D84137C5740@phx.gbl>
References: <DUB117-W882ADEBD88C5CE42D84137C5740@phx.gbl>
Message-ID: <17EE8C62EA18B84B94C2BA96A143064C01721A87@mx01.ispm.unibe.ch>

You have to define a function. For instance:

Afct <- function(delta){
	D <- c(-1, -2/3, -1/3, 0, 1/3, 2/3, 1) 
	Dmat <- matrix(D, nrow=7, ncol=7)
	Smat <- Dmat-t(Dmat)
	A <- exp(-(Smat/delta)^2)
	return(A) 
}
Afct(2)

Also try to avoid loops...

Best, 
Nello

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
On Behalf Of Jennifer Tickner
Sent: Mittwoch, 26. Juni 2013 10:18
To: r-help at r-project.org
Subject: [R] Creating a matrix with an unknown variable

Hi all 

I'm trying to create a matrix, A, with an unknown variable delta. The
code I have so far is: 

D<-c(-1, -2/3, -1/3, 0, 1/3, 2/3, 1) 
A<-matrix(NA,nrow=7,ncol=7) 
for (i in 1:7) 
{ 
for (j in 1:7) 
{ 
A[i,j]<-exp(-((D[i]-D[j])/delta)^2) 
} 
} 
Of course, R comes up with an error message because delta is not yet
defined, but works if I plug in a value for delta. However, I want R to
use the term delta in the matrix A, because I'm trying to estimate delta
in another equation that is written in terms of A. Can anyone help? 

Many thanks 
Jen  		 	   		  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Wed Jun 26 18:07:05 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Wed, 26 Jun 2013 11:07:05 -0500
Subject: [R] help with plotmeans (gplots)
In-Reply-To: <CAEy8Jr2A8LwM0HrmnwvYH5Ge70p_w0A8aX-LnpkYX3ajDCVi4A@mail.gmail.com>
References: <CAEy8Jr2A8LwM0HrmnwvYH5Ge70p_w0A8aX-LnpkYX3ajDCVi4A@mail.gmail.com>
Message-ID: <071d01ce7287$33d21340$9b7639c0$@tamu.edu>

Your data is probably not arranged correctly. See if this works for
your data:

> # Creating a reproducible example
> set.seed(42)
> dat <- matrix(rnorm(100*15, 5, 5)+rep(1:15, each=100), 15, 100,
byrow=TRUE)
> str(dat)
 num [1:15, 1:100] 12.85 13 -2 8.98 16.67 ...
> require(gplots)
> # Rearranging dat as a data.frame with a time variable (1 to 15)
and the experimental value (val)
> # See the result of str(dat2) below for the structure
> dat2 <- data.frame(time=rep(1:15, each=100),
val=as.vector(t(dat)))
> str(dat2)
'data.frame':   1500 obs. of  2 variables:
 $ time: int  1 1 1 1 1 1 1 1 1 1 ...
 $ val : num  12.85 3.18 7.82 9.16 8.02 ...
> plotmeans(val~time, dat2, n.label=FALSE)

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Simone
Gabbriellini
Sent: Wednesday, June 26, 2013 10:20 AM
To: r-help at r-project.org
Subject: [R] help with plotmeans (gplots)

Dear List,

I have replicated an experiment 100 times. Each experiment lasts for
15
iteration. Thus I have collected results into a data.frame with 100
columns
(one column for each experiment) and 15 rows (one row for each
iteration).

I would like to plot mean values at each iteration using plotmeans,
but I
am unable to understand the syntax I should use. I tried:

times<-as.factor(seq(1,15))

plotmeans(data~times)


with no luck... what should I tell to plotmeans in order to evaluate
my
dataset?


Best regards,

Simone

-- 
Simone Gabbriellini, PhD

PostDoc at DISI, University of Bologna
mobile: +39 340 39 75 626
email: simone.gabbriellini at unibo.it
academia.edu: http://goo.gl/7pq62

DigitalBrains srl
Amministratore
mobile: +39 340 39 75 626
email: simone.gabbriellini at digitalbrains.it
home: www.digitalbrains.it

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From clint at ecy.wa.gov  Wed Jun 26 18:16:21 2013
From: clint at ecy.wa.gov (Clint Bowman)
Date: Wed, 26 Jun 2013 09:16:21 -0700 (PDT)
Subject: [R] XYZ data
In-Reply-To: <05AA1FB4006.000011CBjrkrideau@inbox.com>
References: <05AA1FB4006.000011CBjrkrideau@inbox.com>
Message-ID: <alpine.LRH.2.03.1306260914580.1649@ecy.wa.gov>

John,

That still leaves a string of identical numbers in the vector.

Shane,

?jitter

perhaps jitter(X,1,0.0001)

Clint

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Wed, 26 Jun 2013, John Kane wrote:

> mm  <-  1:10
> nn  <- mm + .001
>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: careyshan at gmail.com
>> Sent: Wed, 26 Jun 2013 16:48:34 +0100
>> To: r-help at r-project.org
>> Subject: [R] XYZ data
>>
>> I have x, y, z data. The x, y fields dont change but Z does. How do I add
>> a
>> very small number onto the end of each x, y data point.
>>
>> For example:
>>
>> Original (X)              Original (Y)                 Original (Z)
>> 15                               20                              30
>> 15                               20                              40
>>
>>
>>
>>
>> New (X)              New (Y)                 New (Z)
>> 15.00001             20.000001              30
>> 15.00002             20.000002              40
>>
>>
>> Thanks
>> --
>> Shane
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From noreilly at stat.rutgers.edu  Wed Jun 26 17:40:50 2013
From: noreilly at stat.rutgers.edu (Neville O'Reilly)
Date: Wed, 26 Jun 2013 11:40:50 -0400 (EDT)
Subject: [R] Ifelse leading to inconsistent result
In-Reply-To: <55b417d5-9a88-4ba0-84e5-9abd6ad5b28a@email1>
Message-ID: <9e5ec435-5c64-40a6-9c35-0652b9351740@email1>

I have used ifelse in count variables to count the number of times in a simulation the values of a vector of logprice fall within mutually exclusive ranges. However, there is a double count in the result i.e. i am getting output indicating values falling in mutually exclusive ranges. Here is the code and result
R script
niter = 1e5 # number of iterations is 10^5
CountLoss = rep(0,niter)
CountProf = rep (0,niter)
set.seed(2009) # enables reproducibility of result if script run again"
for (i in 1:niter)
{
  r = rnorm(100,mean=.05/253,
            sd=.23/sqrt(253)) # generate 100 random normal numbers
  logPrice = log(1e6) + cumsum(r) #vector of 100 days log prices
  maxlogP = max(logPrice) # max price over next 100 days
  minlogP = min(logPrice)
  CountLoss[i] <- ifelse (minlogP < log(950000), 1, ifelse (maxlogP > log (1000000), 0, 1))
  CountProf[i] <- ifelse (maxlogP < log (1100000),0,1)
}
sum(CountLoss)
mean(CountLoss) # fraction of times out of niter that stock is sold for a loss in a 100 day period
sum(CountProf)
mean(CountProf) # fraction of times out of niter that stock is sold for a profit in a 100 day period

Output
sum(CountLoss)
[1] 64246
> mean(CountLoss) # fraction of times out of niter that stock is sold for a loss in a 100 day period
[1] 0.64246
> sum(CountProf)
[1] 51857
> mean(CountProf) # fraction of times out of niter that stock is sold for a profit in a 100 day period
[1] 0.51857

CountLoss and CountProf should sum to less than the number of interations. When I troubleshoot by reducing the number of iterations and that size of the logprice, I can't reproduce the contradicion.


From careyshan at gmail.com  Wed Jun 26 18:29:13 2013
From: careyshan at gmail.com (Shane Carey)
Date: Wed, 26 Jun 2013 17:29:13 +0100
Subject: [R] XYZ data
In-Reply-To: <alpine.LRH.2.03.1306260914580.1649@ecy.wa.gov>
References: <05AA1FB4006.000011CBjrkrideau@inbox.com>
	<alpine.LRH.2.03.1306260914580.1649@ecy.wa.gov>
Message-ID: <CA+jRDxBoqG30CuuR57YN1ZU6+QdPO6oBO=Evus+_vokUvF=M=Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130626/2e4028e8/attachment.pl>

From dcarlson at tamu.edu  Wed Jun 26 18:29:20 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Wed, 26 Jun 2013 11:29:20 -0500
Subject: [R] Creating a matrix with an unknown variable
In-Reply-To: <17EE8C62EA18B84B94C2BA96A143064C01721A87@mx01.ispm.unibe.ch>
References: <DUB117-W882ADEBD88C5CE42D84137C5740@phx.gbl>
	<17EE8C62EA18B84B94C2BA96A143064C01721A87@mx01.ispm.unibe.ch>
Message-ID: <071f01ce728a$4fae4f40$ef0aedc0$@tamu.edu>

Another approach passing both D and delta:

> Afct <- function(D, delta) exp(-(outer(D, D, "-")/delta)^2)
> D <- c(-1, -2/3, -1/3, 0, 1/3, 2/3, 1)
> Delta <- 2
> Afct(D, delta)

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Blaser Nello
Sent: Wednesday, June 26, 2013 11:03 AM
To: Jennifer Tickner; r-help at r-project.org
Subject: Re: [R] Creating a matrix with an unknown variable

You have to define a function. For instance:

Afct <- function(delta){
	D <- c(-1, -2/3, -1/3, 0, 1/3, 2/3, 1) 
	Dmat <- matrix(D, nrow=7, ncol=7)
	Smat <- Dmat-t(Dmat)
	A <- exp(-(Smat/delta)^2)
	return(A) 
}
Afct(2)

Also try to avoid loops...

Best, 
Nello

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org]
On Behalf Of Jennifer Tickner
Sent: Mittwoch, 26. Juni 2013 10:18
To: r-help at r-project.org
Subject: [R] Creating a matrix with an unknown variable

Hi all 

I'm trying to create a matrix, A, with an unknown variable delta.
The
code I have so far is: 

D<-c(-1, -2/3, -1/3, 0, 1/3, 2/3, 1) 
A<-matrix(NA,nrow=7,ncol=7) 
for (i in 1:7) 
{ 
for (j in 1:7) 
{ 
A[i,j]<-exp(-((D[i]-D[j])/delta)^2) 
} 
} 
Of course, R comes up with an error message because delta is not yet
defined, but works if I plug in a value for delta. However, I want R
to
use the term delta in the matrix A, because I'm trying to estimate
delta
in another equation that is written in terms of A. Can anyone help? 

Many thanks 
Jen  		 	   		  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ned at alteryx.com  Wed Jun 26 18:41:17 2013
From: ned at alteryx.com (Ned Harding)
Date: Wed, 26 Jun 2013 16:41:17 +0000
Subject: [R] R CMD BATCH Unicode
In-Reply-To: <51CA8DD3.3090107@stats.ox.ac.uk>
References: <92A981B3677AE44384E1ABE4B16D87244E46404B@MAIL1BDVM01.extendthereach.com>
	<92A981B3677AE44384E1ABE4B16D87244E4643C0@MAIL1BDVM01.extendthereach.com>
	<51CA8DD3.3090107@stats.ox.ac.uk>
Message-ID: <92A981B3677AE44384E1ABE4B16D87244E46715C@MAIL1BDVM01.extendthereach.com>

So just to clarify - there is no way to use R CMD BATCH on windows with Unicode?  Any advice of how to use R in a batch mode with Unicode inputs and outputs?

Ned.

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Prof Brian Ripley
Sent: Wednesday, June 26, 2013 12:45 AM
To: r-help at r-project.org
Subject: Re: [R] R CMD BATCH Unicode

On 25/06/2013 20:35, Ned Harding wrote:
> Just to clarify: The encoding didn't come through in the email.  print("????????????") is meant to be a bunch of random greek characters.

In that case the message is likely correct.  You failed to give us the 'at a minimum information' required by the posting guide, but you can only have input scripts in the locale encoding (and there are no UTF-8 locales on Windows).  So unless you were in a Greek locale, the re-encoding should have failed.

> Ned.
>
> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Ned Harding
> Sent: Tuesday, June 25, 2013 11:35 AM
> To: r-help at r-project.org
> Subject: [R] R CMD BATCH Unicode
>
> Hey,
>
> I am looking for some help using Unicode with R CMD BATCH on windows.  In particular I would like my input and output files to be UTF-8 encoded.  My command line looks like this:
>
> r CMD BATCH --encoding=UTF-8 in.txt out.txt
>
> in.txt is utf-8 encoded and contains:
>
> print("????????????")
>
> out.txt gets:
>
> + <ERROR: re-encoding failure from encoding 'UTF-8'>
>
> What is the proper way to specify encoding on the command line?
>
> Thanks in advance,
>
> Ned.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Please do, and note what it says about HTML mail, too.



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From clint at ecy.wa.gov  Wed Jun 26 18:46:37 2013
From: clint at ecy.wa.gov (Clint Bowman)
Date: Wed, 26 Jun 2013 09:46:37 -0700 (PDT)
Subject: [R] XYZ data
In-Reply-To: <CA+jRDxBoqG30CuuR57YN1ZU6+QdPO6oBO=Evus+_vokUvF=M=Q@mail.gmail.com>
References: <05AA1FB4006.000011CBjrkrideau@inbox.com>
	<alpine.LRH.2.03.1306260914580.1649@ecy.wa.gov>
	<CA+jRDxBoqG30CuuR57YN1ZU6+QdPO6oBO=Evus+_vokUvF=M=Q@mail.gmail.com>
Message-ID: <alpine.LRH.2.03.1306260945240.1649@ecy.wa.gov>

perhaps

x<-x+0.00001*seq(1,length(x))

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Wed, 26 Jun 2013, Shane Carey wrote:

> Nope, neither work. :-(
> 
> 
> On Wed, Jun 26, 2013 at 5:16 PM, Clint Bowman <clint at ecy.wa.gov> wrote:
>       John,
>
>       That still leaves a string of identical numbers in the vector.
>
>       Shane,
>
>       ?jitter
>
>       perhaps jitter(X,1,0.0001)
>
>       Clint
>
>       Clint Bowman ? ? ? ? ? ? ? ? ? ?INTERNET: ? ? ? clint at ecy.wa.gov
>       Air Quality Modeler ? ? ? ? ? ? INTERNET: ? ? ? clint at math.utah.edu
>       Department of Ecology ? ? ? ? ? VOICE: ? ? ? ? ?(360) 407-6815
>       PO Box 47600 ? ? ? ? ? ? ? ? ? ?FAX: ? ? ? ? ? ?(360) 407-7534
>       Olympia, WA 98504-7600
>
>       ? ? ? ? USPS: ? ? ? ? ? PO Box 47600, Olympia, WA 98504-7600
>       ? ? ? ? Parcels: ? ? ? ?300 Desmond Drive, Lacey, WA 98503-1274
>
>       On Wed, 26 Jun 2013, John Kane wrote:
>
>             mm ?<- ?1:10
>             nn ?<- mm + .001
>
>             John Kane
>             Kingston ON Canada
> 
>
>                   -----Original Message-----
>                   From: careyshan at gmail.com
>                   Sent: Wed, 26 Jun 2013 16:48:34 +0100
>                   To: r-help at r-project.org
>                   Subject: [R] XYZ data
>
>                   I have x, y, z data. The x, y fields dont change but Z does. How do I add
>                   a
>                   very small number onto the end of each x, y data point.
>
>                   For example:
>
>                   Original (X) ? ? ? ? ? ? ?Original (Y) ? ? ? ? ? ? ? ? Original (Z)
>                   15 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 20 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?30
>                   15 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 20 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?40
> 
> 
> 
>
>                   New (X) ? ? ? ? ? ? ?New (Y) ? ? ? ? ? ? ? ? New (Z)
>                   15.00001 ? ? ? ? ? ? 20.000001 ? ? ? ? ? ? ?30
>                   15.00002 ? ? ? ? ? ? 20.000002 ? ? ? ? ? ? ?40
> 
>
>                   Thanks
>                   --
>                   Shane
>
>                   ? ? ? ? [[alternative HTML version deleted]]
>
>                   ______________________________________________
>                   R-help at r-project.org mailing list
>                   https://stat.ethz.ch/mailman/listinfo/r-help
>                   PLEASE do read the posting guide
>                   http://www.R-project.org/posting-guide.html
>                   and provide commented, minimal, self-contained, reproducible code.
> 
>
>             ____________________________________________________________
>             FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>
>             ______________________________________________
>             R-help at r-project.org mailing list
>             https://stat.ethz.ch/mailman/listinfo/r-help
>             PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>             and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> 
> --
> Shane
> 
>

From smartpink111 at yahoo.com  Wed Jun 26 18:51:18 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 26 Jun 2013 09:51:18 -0700 (PDT)
Subject: [R] XYZ data
Message-ID: <1372265478.46075.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Not sure whether there is any pattern in adding the small number.
dat1<- read.table(text="
X????????????? Y???????????????? Z
15?????????????????????????????? 20????????????????????????????? 30
15?????????????????????????????? 20????????????????????????????? 40
",sep="",header=TRUE)
dat1[,1:2]<-do.call(rbind,lapply(seq_len(nrow(dat1)),function(i) dat1[i,1:2]+0.00001*i) )
dat1
#???????? X??????? Y? Z
#1 15.00001 20.00001 30
#2 15.00002 20.00002 40

A.K.



I have x, y, z data. The x, y fields dont change but Z does. How do I add a 
very small number onto the end of each x, y data point. 

For example: 

Original (X) ? ? ? ? ? ? ?Original (Y) ? ? ? ? ? ? ? ? Original (Z) 
15 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 20 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?30 
15 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 20 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?40 




New (X) ? ? ? ? ? ? ?New (Y) ? ? ? ? ? ? ? ? New (Z) 
15.00001 ? ? ? ? ? ? 20.000001 ? ? ? ? ? ? ?30 
15.00002 ? ? ? ? ? ? 20.000002 ? ? ? ? ? ? ?40 


Thanks 
-- 
Shane 



From murdoch.duncan at gmail.com  Wed Jun 26 18:55:17 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 26 Jun 2013 12:55:17 -0400
Subject: [R] Ifelse leading to inconsistent result
In-Reply-To: <9e5ec435-5c64-40a6-9c35-0652b9351740@email1>
References: <9e5ec435-5c64-40a6-9c35-0652b9351740@email1>
Message-ID: <51CB1CF5.105@gmail.com>

On 26/06/2013 11:40 AM, Neville O'Reilly wrote:
> I have used ifelse in count variables to count the number of times in a simulation the values of a vector of logprice fall within mutually exclusive ranges. However, there is a double count in the result i.e. i am getting output indicating values falling in mutually exclusive ranges. Here is the code and result
> R script
> niter = 1e5 # number of iterations is 10^5
> CountLoss = rep(0,niter)
> CountProf = rep (0,niter)
> set.seed(2009) # enables reproducibility of result if script run again"
> for (i in 1:niter)
> {
>    r = rnorm(100,mean=.05/253,
>              sd=.23/sqrt(253)) # generate 100 random normal numbers
>    logPrice = log(1e6) + cumsum(r) #vector of 100 days log prices
>    maxlogP = max(logPrice) # max price over next 100 days
>    minlogP = min(logPrice)
>    CountLoss[i] <- ifelse (minlogP < log(950000), 1, ifelse (maxlogP > log (1000000), 0, 1))
>    CountProf[i] <- ifelse (maxlogP < log (1100000),0,1)
> }
> sum(CountLoss)
> mean(CountLoss) # fraction of times out of niter that stock is sold for a loss in a 100 day period
> sum(CountProf)
> mean(CountProf) # fraction of times out of niter that stock is sold for a profit in a 100 day period
>
> Output
> sum(CountLoss)
> [1] 64246
> > mean(CountLoss) # fraction of times out of niter that stock is sold for a loss in a 100 day period
> [1] 0.64246
> > sum(CountProf)
> [1] 51857
> > mean(CountProf) # fraction of times out of niter that stock is sold for a profit in a 100 day period
> [1] 0.51857
>
> CountLoss and CountProf should sum to less than the number of interations. When I troubleshoot by reducing the number of iterations and that size of the logprice, I can't reproduce the contradicion.

I don't see a contradiction.  Both CountLoss and CountProf are less than 
niter.  The logic of your test doesn't imply that sum(CountLoss) + 
sum(CountProf) should be less than niter; e.g. a case where minlogP is 
less than log(950000) and maxlogP > log(1100000) would be counted in both.

Duncan Murdoch


From pdalgd at gmail.com  Wed Jun 26 18:59:17 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 26 Jun 2013 18:59:17 +0200
Subject: [R] Ifelse leading to inconsistent result
In-Reply-To: <9e5ec435-5c64-40a6-9c35-0652b9351740@email1>
References: <9e5ec435-5c64-40a6-9c35-0652b9351740@email1>
Message-ID: <9AB58A4D-483B-4630-A371-5A9B886C35BB@gmail.com>


On Jun 26, 2013, at 17:40 , Neville O'Reilly wrote:

> I have used ifelse in count variables to count the number of times in a simulation the values of a vector of logprice fall within mutually exclusive ranges. However, there is a double count in the result i.e. i am getting output indicating values falling in mutually exclusive ranges. Here is the code and result
> R script

Don't use ifelse, it just confuses the logic.

As far as I can tell, the code is equivalent (except for integer conversion) to

 CountLoss[i] <- (minlogP < log(950000)) | (maxlogP <= log (1000000))
 CountProf[i] <- (maxlogP >= log (1100000))

and that doesn't look mutually exclusive to me. 

> niter = 1e5 # number of iterations is 10^5
> CountLoss = rep(0,niter)
> CountProf = rep (0,niter)
> set.seed(2009) # enables reproducibility of result if script run again"
> for (i in 1:niter)
> {
>  r = rnorm(100,mean=.05/253,
>            sd=.23/sqrt(253)) # generate 100 random normal numbers
>  logPrice = log(1e6) + cumsum(r) #vector of 100 days log prices
>  maxlogP = max(logPrice) # max price over next 100 days
>  minlogP = min(logPrice)
>  CountLoss[i] <- ifelse (minlogP < log(950000), 1, ifelse (maxlogP > log (1000000), 0, 1))
>  CountProf[i] <- ifelse (maxlogP < log (1100000),0,1)
> }
> sum(CountLoss)
> mean(CountLoss) # fraction of times out of niter that stock is sold for a loss in a 100 day period
> sum(CountProf)
> mean(CountProf) # fraction of times out of niter that stock is sold for a profit in a 100 day period
> 
> Output
> sum(CountLoss)
> [1] 64246
>> mean(CountLoss) # fraction of times out of niter that stock is sold for a loss in a 100 day period
> [1] 0.64246
>> sum(CountProf)
> [1] 51857
>> mean(CountProf) # fraction of times out of niter that stock is sold for a profit in a 100 day period
> [1] 0.51857
> 
> CountLoss and CountProf should sum to less than the number of interations. When I troubleshoot by reducing the number of iterations and that size of the logprice, I can't reproduce the contradicion.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jdnewmil at dcn.davis.CA.us  Wed Jun 26 19:05:53 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 26 Jun 2013 10:05:53 -0700
Subject: [R] R CMD BATCH Unicode
In-Reply-To: <92A981B3677AE44384E1ABE4B16D87244E46715C@MAIL1BDVM01.extendthereach.com>
References: <92A981B3677AE44384E1ABE4B16D87244E46404B@MAIL1BDVM01.extendthereach.com>
	<92A981B3677AE44384E1ABE4B16D87244E4643C0@MAIL1BDVM01.extendthereach.com>
	<51CA8DD3.3090107@stats.ox.ac.uk>
	<92A981B3677AE44384E1ABE4B16D87244E46715C@MAIL1BDVM01.extendthereach.com>
Message-ID: <ae83ec2a-2914-4d5e-93ed-01ecef2f3a0d@email.android.com>

Just because the subject mentions R doesn't mean it is on topic here. This is more related to Windows than R. I recommend studying windows documentation for awhile. A quick search turned up a number of discussions on the web, including http://stackoverflow.com/questions/1035388/unicode-output-on-windows-command-line.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Ned Harding <ned at alteryx.com> wrote:

>So just to clarify - there is no way to use R CMD BATCH on windows with
>Unicode?  Any advice of how to use R in a batch mode with Unicode
>inputs and outputs?
>
>Ned.
>
>-----Original Message-----
>From: r-help-bounces at r-project.org
>[mailto:r-help-bounces at r-project.org] On Behalf Of Prof Brian Ripley
>Sent: Wednesday, June 26, 2013 12:45 AM
>To: r-help at r-project.org
>Subject: Re: [R] R CMD BATCH Unicode
>
>On 25/06/2013 20:35, Ned Harding wrote:
>> Just to clarify: The encoding didn't come through in the email. 
>print("????????????") is meant to be a bunch of random greek
>characters.
>
>In that case the message is likely correct.  You failed to give us the
>'at a minimum information' required by the posting guide, but you can
>only have input scripts in the locale encoding (and there are no UTF-8
>locales on Windows).  So unless you were in a Greek locale, the
>re-encoding should have failed.
>
>> Ned.
>>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org 
>> [mailto:r-help-bounces at r-project.org] On Behalf Of Ned Harding
>> Sent: Tuesday, June 25, 2013 11:35 AM
>> To: r-help at r-project.org
>> Subject: [R] R CMD BATCH Unicode
>>
>> Hey,
>>
>> I am looking for some help using Unicode with R CMD BATCH on windows.
>In particular I would like my input and output files to be UTF-8
>encoded.  My command line looks like this:
>>
>> r CMD BATCH --encoding=UTF-8 in.txt out.txt
>>
>> in.txt is utf-8 encoded and contains:
>>
>> print("????????????")
>>
>> out.txt gets:
>>
>> + <ERROR: re-encoding failure from encoding 'UTF-8'>
>>
>> What is the proper way to specify encoding on the command line?
>>
>> Thanks in advance,
>>
>> Ned.
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>Please do, and note what it says about HTML mail, too.


From dcarlson at tamu.edu  Wed Jun 26 19:15:06 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Wed, 26 Jun 2013 12:15:06 -0500
Subject: [R] Ifelse leading to inconsistent result
In-Reply-To: <9e5ec435-5c64-40a6-9c35-0652b9351740@email1>
References: <55b417d5-9a88-4ba0-84e5-9abd6ad5b28a@email1>
	<9e5ec435-5c64-40a6-9c35-0652b9351740@email1>
Message-ID: <072a01ce7290$b47e5b80$1d7b1280$@tamu.edu>

I don't see that you have set up mutually exclusive ranges. If we
modify your code so save the maxlogP and minlogP values:

niter = 1e5 # number of iterations is 10^5
CountLoss = rep(0,niter)
CountProf = rep (0,niter)
maxlogP <- rep(0, ninter)
minlogP <- rep(0, ninter)
set.seed(2009) # enables reproducibility of result if script run
again"
for (i in 1:niter)
{
  r = rnorm(100,mean=.05/253,
            sd=.23/sqrt(253)) # generate 100 random normal numbers
  logPrice = log(1e6) + cumsum(r) #vector of 100 days log prices
  maxlogP[i] = max(logPrice) # max price over next 100 days
  minlogP[i] = min(logPrice)
  CountLoss[i] <- ifelse (minlogP[i] < log(950000), 1, ifelse
(maxlogP[i] > log (1000000), 0, 1))
  CountProf[i] <- ifelse (maxlogP[i] < log (1100000),0,1)
}
both <- which(CountLoss+CountProf>1)
length(both)
# 18484
head(both)
# [1]  1  5  9 12 15 25
ifelse (minlogP[1] < log(950000), 1, ifelse (maxlogP[1] > log
(1000000), 0, 1))
# [1] 1
ifelse (maxlogP[1] < log(1100000),0,1)
# [1] 1
exp(maxlogP[1])
# [1] 1204589
exp(minlogP[1])
# [1] 932747.5

Your first simulation meets both criteria along 18483 others!

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Neville O'Reilly
Sent: Wednesday, June 26, 2013 10:41 AM
To: r-help at r-project.org
Subject: [R] Ifelse leading to inconsistent result

I have used ifelse in count variables to count the number of times
in a simulation the values of a vector of logprice fall within
mutually exclusive ranges. However, there is a double count in the
result i.e. i am getting output indicating values falling in
mutually exclusive ranges. Here is the code and result
R script
niter = 1e5 # number of iterations is 10^5
CountLoss = rep(0,niter)
CountProf = rep (0,niter)
set.seed(2009) # enables reproducibility of result if script run
again"
for (i in 1:niter)
{
  r = rnorm(100,mean=.05/253,
            sd=.23/sqrt(253)) # generate 100 random normal numbers
  logPrice = log(1e6) + cumsum(r) #vector of 100 days log prices
  maxlogP = max(logPrice) # max price over next 100 days
  minlogP = min(logPrice)
  CountLoss[i] <- ifelse (minlogP < log(950000), 1, ifelse (maxlogP
> log (1000000), 0, 1))
  CountProf[i] <- ifelse (maxlogP < log (1100000),0,1)
}
sum(CountLoss)
mean(CountLoss) # fraction of times out of niter that stock is sold
for a loss in a 100 day period
sum(CountProf)
mean(CountProf) # fraction of times out of niter that stock is sold
for a profit in a 100 day period

Output
sum(CountLoss)
[1] 64246
> mean(CountLoss) # fraction of times out of niter that stock is
sold for a loss in a 100 day period
[1] 0.64246
> sum(CountProf)
[1] 51857
> mean(CountProf) # fraction of times out of niter that stock is
sold for a profit in a 100 day period
[1] 0.51857

CountLoss and CountProf should sum to less than the number of
interations. When I troubleshoot by reducing the number of
iterations and that size of the logprice, I can't reproduce the
contradicion.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From noreilly at stat.rutgers.edu  Wed Jun 26 19:18:04 2013
From: noreilly at stat.rutgers.edu (Neville O'Reilly)
Date: Wed, 26 Jun 2013 13:18:04 -0400 (EDT)
Subject: [R] Ifelse leading to inconsistent result
In-Reply-To: <072a01ce7290$b47e5b80$1d7b1280$@tamu.edu>
Message-ID: <185d1c3c-6af5-4651-a395-dbb4ed6582c3@email1>

You are right, I inadvertently deleted part of the script - so I ended up with non-mutually exclusive regions. My apologies


Neville O'Reilly, Ph.D 
Associate Director, Financial Statistics & Risk Management, 
Rm 479 Hill Center, Rutgers University, 110 Freylinghuysen Rd., 
Piscataway, NJ 08854. 
848-445-7669 
http://fsrm.rutgers.edu/ 

----- Original Message -----
From: "David Carlson" <dcarlson at tamu.edu>
To: "Neville O'Reilly" <noreilly at stat.rutgers.edu>, r-help at r-project.org
Sent: Wednesday, June 26, 2013 1:15:06 PM
Subject: RE: [R] Ifelse leading to inconsistent result

I don't see that you have set up mutually exclusive ranges. If we
modify your code so save the maxlogP and minlogP values:

niter = 1e5 # number of iterations is 10^5
CountLoss = rep(0,niter)
CountProf = rep (0,niter)
maxlogP <- rep(0, ninter)
minlogP <- rep(0, ninter)
set.seed(2009) # enables reproducibility of result if script run
again"
for (i in 1:niter)
{
  r = rnorm(100,mean=.05/253,
            sd=.23/sqrt(253)) # generate 100 random normal numbers
  logPrice = log(1e6) + cumsum(r) #vector of 100 days log prices
  maxlogP[i] = max(logPrice) # max price over next 100 days
  minlogP[i] = min(logPrice)
  CountLoss[i] <- ifelse (minlogP[i] < log(950000), 1, ifelse
(maxlogP[i] > log (1000000), 0, 1))
  CountProf[i] <- ifelse (maxlogP[i] < log (1100000),0,1)
}
both <- which(CountLoss+CountProf>1)
length(both)
# 18484
head(both)
# [1]  1  5  9 12 15 25
ifelse (minlogP[1] < log(950000), 1, ifelse (maxlogP[1] > log
(1000000), 0, 1))
# [1] 1
ifelse (maxlogP[1] < log(1100000),0,1)
# [1] 1
exp(maxlogP[1])
# [1] 1204589
exp(minlogP[1])
# [1] 932747.5

Your first simulation meets both criteria along 18483 others!

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Neville O'Reilly
Sent: Wednesday, June 26, 2013 10:41 AM
To: r-help at r-project.org
Subject: [R] Ifelse leading to inconsistent result

I have used ifelse in count variables to count the number of times
in a simulation the values of a vector of logprice fall within
mutually exclusive ranges. However, there is a double count in the
result i.e. i am getting output indicating values falling in
mutually exclusive ranges. Here is the code and result
R script
niter = 1e5 # number of iterations is 10^5
CountLoss = rep(0,niter)
CountProf = rep (0,niter)
set.seed(2009) # enables reproducibility of result if script run
again"
for (i in 1:niter)
{
  r = rnorm(100,mean=.05/253,
            sd=.23/sqrt(253)) # generate 100 random normal numbers
  logPrice = log(1e6) + cumsum(r) #vector of 100 days log prices
  maxlogP = max(logPrice) # max price over next 100 days
  minlogP = min(logPrice)
  CountLoss[i] <- ifelse (minlogP < log(950000), 1, ifelse (maxlogP
> log (1000000), 0, 1))
  CountProf[i] <- ifelse (maxlogP < log (1100000),0,1)
}
sum(CountLoss)
mean(CountLoss) # fraction of times out of niter that stock is sold
for a loss in a 100 day period
sum(CountProf)
mean(CountProf) # fraction of times out of niter that stock is sold
for a profit in a 100 day period

Output
sum(CountLoss)
[1] 64246
> mean(CountLoss) # fraction of times out of niter that stock is
sold for a loss in a 100 day period
[1] 0.64246
> sum(CountProf)
[1] 51857
> mean(CountProf) # fraction of times out of niter that stock is
sold for a profit in a 100 day period
[1] 0.51857

CountLoss and CountProf should sum to less than the number of
interations. When I troubleshoot by reducing the number of
iterations and that size of the logprice, I can't reproduce the
contradicion.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ned at alteryx.com  Wed Jun 26 19:39:34 2013
From: ned at alteryx.com (Ned Harding)
Date: Wed, 26 Jun 2013 17:39:34 +0000
Subject: [R] R CMD BATCH Unicode
In-Reply-To: <ae83ec2a-2914-4d5e-93ed-01ecef2f3a0d@email.android.com>
References: <92A981B3677AE44384E1ABE4B16D87244E46404B@MAIL1BDVM01.extendthereach.com>
	<92A981B3677AE44384E1ABE4B16D87244E4643C0@MAIL1BDVM01.extendthereach.com>
	<51CA8DD3.3090107@stats.ox.ac.uk>
	<92A981B3677AE44384E1ABE4B16D87244E46715C@MAIL1BDVM01.extendthereach.com>
	<ae83ec2a-2914-4d5e-93ed-01ecef2f3a0d@email.android.com>
Message-ID: <92A981B3677AE44384E1ABE4B16D87244E4672F2@MAIL1BDVM01.extendthereach.com>

I have no problems with the windows command line.  I don't need any Unicode there.  It really is an internal R question because of the way R is reading and writing the input and output files.  

Ned.

-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us] 
Sent: Wednesday, June 26, 2013 11:06 AM
To: Ned Harding; Prof Brian Ripley; r-help at r-project.org
Subject: Re: [R] R CMD BATCH Unicode

Just because the subject mentions R doesn't mean it is on topic here. This is more related to Windows than R. I recommend studying windows documentation for awhile. A quick search turned up a number of discussions on the web, including http://stackoverflow.com/questions/1035388/unicode-output-on-windows-command-line.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.

Ned Harding <ned at alteryx.com> wrote:

>So just to clarify - there is no way to use R CMD BATCH on windows with 
>Unicode?  Any advice of how to use R in a batch mode with Unicode 
>inputs and outputs?
>
>Ned.
>
>-----Original Message-----
>From: r-help-bounces at r-project.org
>[mailto:r-help-bounces at r-project.org] On Behalf Of Prof Brian Ripley
>Sent: Wednesday, June 26, 2013 12:45 AM
>To: r-help at r-project.org
>Subject: Re: [R] R CMD BATCH Unicode
>
>On 25/06/2013 20:35, Ned Harding wrote:
>> Just to clarify: The encoding didn't come through in the email. 
>print("????????????") is meant to be a bunch of random greek 
>characters.
>
>In that case the message is likely correct.  You failed to give us the 
>'at a minimum information' required by the posting guide, but you can 
>only have input scripts in the locale encoding (and there are no UTF-8 
>locales on Windows).  So unless you were in a Greek locale, the 
>re-encoding should have failed.
>
>> Ned.
>>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org
>> [mailto:r-help-bounces at r-project.org] On Behalf Of Ned Harding
>> Sent: Tuesday, June 25, 2013 11:35 AM
>> To: r-help at r-project.org
>> Subject: [R] R CMD BATCH Unicode
>>
>> Hey,
>>
>> I am looking for some help using Unicode with R CMD BATCH on windows.
>In particular I would like my input and output files to be UTF-8 
>encoded.  My command line looks like this:
>>
>> r CMD BATCH --encoding=UTF-8 in.txt out.txt
>>
>> in.txt is utf-8 encoded and contains:
>>
>> print("????????????")
>>
>> out.txt gets:
>>
>> + <ERROR: re-encoding failure from encoding 'UTF-8'>
>>
>> What is the proper way to specify encoding on the command line?
>>
>> Thanks in advance,
>>
>> Ned.
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>Please do, and note what it says about HTML mail, too.


From akimeli at vub.ac.be  Wed Jun 26 19:48:06 2013
From: akimeli at vub.ac.be (amon)
Date: Wed, 26 Jun 2013 10:48:06 -0700 (PDT)
Subject: [R] Fitting a negative Gompertz model to data
Message-ID: <1372268886156-4670394.post@n4.nabble.com>

Hi,
First: i have looked through previous posts but could get one related to my
problem!
I am trying to fit a negative gompertz curve in my data seems alright but
the curve doesn't bend at the left (max asymptote)...see  graph attached.

Here is my code;

EProb=read.table("ProbF.txt",header=TRUE)
attach(EProb)
EProb

plot(mHWLrelMSL,Prob, ylab="Exceedance probability, P (%)",xlab="mHWL (m rel
Sea level)", xlim=c(-1.0,1.5), cex=1, pch=1, col="blue")

#####################  ## Modified Negative Gompertz ....: Y = a*
exp(b*(1-exp(c*X)))

gm <- nls(Prob~ a*exp(b*(1-exp(c*mHWLrelMSL))), start=list(a=117.6234567153,
b=-60.3, c=-0.2))
summary(gm)

xfit= seq(min(mHWLrelMSL),max(mHWLrelMSL), by=0.01)

param= coef(summary(gm))[,1]
A=param [1]
B=param [2]
C=param [3]

yfit = A*exp(B*(1-exp(C*xfit)))         
lines(spline(xfit,yfit),col="red",lwd=3)

####parent text file

Prob.txt <http://r.789695.n4.nabble.com/file/n4670394/Prob.txt>  

###output graph

<http://r.789695.n4.nabble.com/file/n4670394/regression2606.png> 

Thanks in advance.

Amon
akimeli at vub.ac.be




--
View this message in context: http://r.789695.n4.nabble.com/Fitting-a-negative-Gompertz-model-to-data-tp4670394.html
Sent from the R help mailing list archive at Nabble.com.


From kimbet3 at yahoo.com  Wed Jun 26 21:00:09 2013
From: kimbet3 at yahoo.com (bett kimutai)
Date: Wed, 26 Jun 2013 12:00:09 -0700
Subject: [R] Thought you'd find this interesting
Message-ID: <0.0.0.3EF.1CE729F610224A0.0@vmta03.monkeyinferno.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130626/75635e47/attachment.pl>

From smartpink111 at yahoo.com  Wed Jun 26 21:26:21 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 26 Jun 2013 12:26:21 -0700 (PDT)
Subject: [R] match rows of R
In-Reply-To: <CAGuusR9dC_uV9McEFkz_g3GABrsKPHA7WrZD4o2aEXtXbDiwKA@mail.gmail.com>
References: <CAGuusR9dC_uV9McEFkz_g3GABrsKPHA7WrZD4o2aEXtXbDiwKA@mail.gmail.com>
Message-ID: <1372274781.6758.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Try:
?roweqv<- function(m,v) which(!is.na(match(interaction(as.data.frame(m),drop=TRUE),paste(v,collapse="."))))
v<- c(2,5,8)
roweqv(m,v)
#[1] 2


set.seed(24)
m1<-matrix(sample(1:15,3e5,replace=TRUE),ncol=3)
v1<- c(10,12,4)

?system.time(res<- roweqv(m1,v1))
? # user? system elapsed 
? #0.132?? 0.000?? 0.130 
res
# [1]???? 5?? 381? 2760? 3793? 9667 16881 18866 21219 24961 36220 38366 54382
#[13] 54951 55825 57167 67636 70713 71087 73284 82797 83255 85748 86216 86690
#[25] 93120 95399 96370

head(m1[res,])
#???? [,1] [,2] [,3]
#[1,]?? 10?? 12??? 4
#[2,]?? 10?? 12??? 4
#[3,]?? 10?? 12??? 4
#[4,]?? 10?? 12??? 4
#[5,]?? 10?? 12??? 4
#[6,]?? 10?? 12??? 4

v2<- c(20,5,4)
roweqv(m1,v2)
#integer(0)

A.K.
----- Original Message -----
From: Sachinthaka Abeywardana <sachin.abeywardana at gmail.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Wednesday, June 26, 2013 4:03 AM
Subject: [R] match rows of R

Hi all,

What would be an efficient way to match rows of a matrix to a vector?

ex:

m<-matrix(1:9, nrow=3)

m? ?  [,1] [,2] [,3]
[1,]? ? 1? ? 4? ? 7
[2,]? ? 2? ? 5? ? 8
[3,]? ? 3? ? 6? ? 9

#################################
which(m==c(2,5,8))? ? ? ? # I want this to return 2
######################

Thanks,
Sachin

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Wed Jun 26 21:44:40 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 26 Jun 2013 12:44:40 -0700 (PDT)
Subject: [R] match rows of R
In-Reply-To: <1372274781.6758.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <CAGuusR9dC_uV9McEFkz_g3GABrsKPHA7WrZD4o2aEXtXbDiwKA@mail.gmail.com>
	<1372274781.6758.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1372275880.1585.YahooMailNeo@web142601.mail.bf1.yahoo.com>

This might also work:

roweqv2<- function(m,v){indx<-1+Reduce("+",lapply(seq_len(ncol(m)),function(i) (2^i)*(m[,i]==v[i])))
??? ??? ??? ?which(indx==max(indx))}??? 

roweqv2(m,v)
#[1] 2
?system.time(res2<-roweqv2(m1,v1))
#?? user? system elapsed 
? #0.008?? 0.000?? 0.008 
?identical(res,res2)
#[1] TRUE

#On a bigger dataset


set.seed(248)
?m1<-matrix(sample(1:15,3e7,replace=TRUE),ncol=3)
?v1<- c(10,12,4)
?system.time(res<- roweqv(m1,v1))
#?? user? system elapsed 
# 12.404?? 1.248? 13.677 
? system.time(res2<-roweqv2(m1,v1))
#?? user? system elapsed 
?# 0.760?? 0.312?? 1.076 

identical(res,res2)
#[1] TRUE


A.K.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Sachinthaka Abeywardana <sachin.abeywardana at gmail.com>
Cc: R help <r-help at r-project.org>
Sent: Wednesday, June 26, 2013 3:26 PM
Subject: Re: [R] match rows of R

Hi,
Try:
?roweqv<- function(m,v) which(!is.na(match(interaction(as.data.frame(m),drop=TRUE),paste(v,collapse="."))))
v<- c(2,5,8)
roweqv(m,v)
#[1] 2


set.seed(24)
m1<-matrix(sample(1:15,3e5,replace=TRUE),ncol=3)
v1<- c(10,12,4)

?system.time(res<- roweqv(m1,v1))
? # user? system elapsed 
? #0.132?? 0.000?? 0.130 
res
# [1]???? 5?? 381? 2760? 3793? 9667 16881 18866 21219 24961 36220 38366 54382
#[13] 54951 55825 57167 67636 70713 71087 73284 82797 83255 85748 86216 86690
#[25] 93120 95399 96370

head(m1[res,])
#???? [,1] [,2] [,3]
#[1,]?? 10?? 12??? 4
#[2,]?? 10?? 12??? 4
#[3,]?? 10?? 12??? 4
#[4,]?? 10?? 12??? 4
#[5,]?? 10?? 12??? 4
#[6,]?? 10?? 12??? 4

v2<- c(20,5,4)
roweqv(m1,v2)
#integer(0)

A.K.
----- Original Message -----
From: Sachinthaka Abeywardana <sachin.abeywardana at gmail.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Wednesday, June 26, 2013 4:03 AM
Subject: [R] match rows of R

Hi all,

What would be an efficient way to match rows of a matrix to a vector?

ex:

m<-matrix(1:9, nrow=3)

m? ?? [,1] [,2] [,3]
[1,]? ? 1? ? 4? ? 7
[2,]? ? 2? ? 5? ? 8
[3,]? ? 3? ? 6? ? 9

#################################
which(m==c(2,5,8))? ? ? ? # I want this to return 2
######################

Thanks,
Sachin

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From anika.masters at gmail.com  Thu Jun 27 00:14:11 2013
From: anika.masters at gmail.com (Anika Masters)
Date: Wed, 26 Jun 2013 15:14:11 -0700
Subject: [R] pasting columns of a dataframe together
Message-ID: <CAOQRPaanx77m=YBkyPQXKTagSPEW3OHk+o+YjFQCiE_8LkQDhA@mail.gmail.com>

I want  to "paste" the contents of the first column of a dataframe
with all the columns of the same dataframe.



What is a "good" way to do this, perhaps something more elegant than
what I have below.  (My actual dataframe has ~400 columns and ~35000
rows.)



example1:

mydf <- data.frame( matrix(data=1:15, nrow=5, ncol=3) )

mydf2 <- mydf

temp2 <- paste(unlist(mydf[,1]) , unlist(mydf), sep="_")

mydf2[ ,] <- temp2



example2:

mydf2 <- mydf



for(i in 1:ncol(mydf2) ) {

mydf2[i] <- paste( mydf[,1], mydf[ ,i], sep='_')

}


From anika.masters at gmail.com  Thu Jun 27 00:21:50 2013
From: anika.masters at gmail.com (Anika Masters)
Date: Wed, 26 Jun 2013 15:21:50 -0700
Subject: [R] pasting columns of a dataframe together
In-Reply-To: <CAOQRPaanx77m=YBkyPQXKTagSPEW3OHk+o+YjFQCiE_8LkQDhA@mail.gmail.com>
References: <CAOQRPaanx77m=YBkyPQXKTagSPEW3OHk+o+YjFQCiE_8LkQDhA@mail.gmail.com>
Message-ID: <CAOQRPabSEZbnVf-k0tEjXxRof=UOg=4uDT=bO+RpGpg_QanVVw@mail.gmail.com>

Given the size of my dataframe (>400 columns, >35000 rows), I should
have clarified that speed and efficiency is perhaps as important as
"elegance", and I'd like to use the examples to learn about any
corrections and improvements I can make in the examples I provided.
Thanks for any help you can offer. (I am using R x64 2.15.2 on Windows
7.)

On Wed, Jun 26, 2013 at 3:14 PM, Anika Masters <anika.masters at gmail.com> wrote:
> I want  to "paste" the contents of the first column of a dataframe
> with all the columns of the same dataframe.
>
>
>
> What is a "good" way to do this, perhaps something more elegant than
> what I have below.  (My actual dataframe has ~400 columns and ~35000
> rows.)
>
>
>
> example1:
>
> mydf <- data.frame( matrix(data=1:15, nrow=5, ncol=3) )
>
> mydf2 <- mydf
>
> temp2 <- paste(unlist(mydf[,1]) , unlist(mydf), sep="_")
>
> mydf2[ ,] <- temp2
>
>
>
> example2:
>
> mydf2 <- mydf
>
>
>
> for(i in 1:ncol(mydf2) ) {
>
> mydf2[i] <- paste( mydf[,1], mydf[ ,i], sep='_')
>
> }


From gunter.berton at gene.com  Thu Jun 27 00:45:13 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 26 Jun 2013 15:45:13 -0700
Subject: [R] pasting columns of a dataframe together
In-Reply-To: <CAOQRPabSEZbnVf-k0tEjXxRof=UOg=4uDT=bO+RpGpg_QanVVw@mail.gmail.com>
References: <CAOQRPaanx77m=YBkyPQXKTagSPEW3OHk+o+YjFQCiE_8LkQDhA@mail.gmail.com>
	<CAOQRPabSEZbnVf-k0tEjXxRof=UOg=4uDT=bO+RpGpg_QanVVw@mail.gmail.com>
Message-ID: <CACk-te1K=qbvbMvLD=QjpsziKWqCM=ZQzKjzSdypzRM7R3642w@mail.gmail.com>

Anika:

1. You do realize that all columns of your result will be character
(even if they started out as numeric).

2. That being the case, all your data frame columns can be considered
to be character to begin with.

3. That being the case, convert your data frame to a matrix: mdf <-
as.matrix(df)

4. Then since, paste() is vectorized and recycles:

d <- dim(mdf)
mdf<- paste(mdf[,1],mdf)
dim(mdf) <- d

Cheers,
Bert

On Wed, Jun 26, 2013 at 3:21 PM, Anika Masters <anika.masters at gmail.com> wrote:
> Given the size of my dataframe (>400 columns, >35000 rows), I should
> have clarified that speed and efficiency is perhaps as important as
> "elegance", and I'd like to use the examples to learn about any
> corrections and improvements I can make in the examples I provided.
> Thanks for any help you can offer. (I am using R x64 2.15.2 on Windows
> 7.)
>
> On Wed, Jun 26, 2013 at 3:14 PM, Anika Masters <anika.masters at gmail.com> wrote:
>> I want  to "paste" the contents of the first column of a dataframe
>> with all the columns of the same dataframe.
>>
>>
>>
>> What is a "good" way to do this, perhaps something more elegant than
>> what I have below.  (My actual dataframe has ~400 columns and ~35000
>> rows.)
>>
>>
>>
>> example1:
>>
>> mydf <- data.frame( matrix(data=1:15, nrow=5, ncol=3) )
>>
>> mydf2 <- mydf
>>
>> temp2 <- paste(unlist(mydf[,1]) , unlist(mydf), sep="_")
>>
>> mydf2[ ,] <- temp2
>>
>>
>>
>> example2:
>>
>> mydf2 <- mydf
>>
>>
>>
>> for(i in 1:ncol(mydf2) ) {
>>
>> mydf2[i] <- paste( mydf[,1], mydf[ ,i], sep='_')
>>
>> }
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From simon.urbanek at r-project.org  Thu Jun 27 00:58:37 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 26 Jun 2013 18:58:37 -0400
Subject: [R] [Rd] How can C++ read the R object written into socket with
	saveRDS or save
In-Reply-To: <OF396F33FA.8A573204-ON48257B95.0055E30F-48257B95.00573B1B@cn.ibm.com>
References: <OF396F33FA.8A573204-ON48257B95.0055E30F-48257B95.00573B1B@cn.ibm.com>
Message-ID: <8EA205C5-7C93-44DD-B6C2-D776B061E14E@r-project.org>

On Jun 25, 2013, at 11:52 AM, Rong lI Li wrote:

> 
> Hi, all,
> 
> Recently, I met one issue when using socket between R & C++ to transmit R
> object. Would you pls help give me some suggestions? Many thanks!
> 
> [Background]:
> I create a socket connection between R & C++ binary first, and then, want
> to use saveRDS() or save() in R to save the object into connection
> directly. So that the C++ binary can read the object, and send it to
> another remote R.
> 
> [What I did so far]:
> 1. I used socketConnection in R and listen/accept in C++, to establish one
> blocking socket.
> 2. I used saveRDS to save the R object into socket directly
> 3. I want to use "recv()" in C++ to receive the R object.
> 
> [Issues I met]:
> I found actually, the saveRDS writes the R object with XDR format. I could
> not know how many bytes are sent into socket, when calling saveRDS to save
> R object. So in the C++ binary, I could not know exactly how many bytes I
> should receive from the socket. It is not safe for me, to always use a
> pre-defined buffer size to read from the socket.
> 
> Any suggestions for this? Are there safe way for me to read the R object
> from the socket?

There is nothing preventing you from adding a frame with the size of the serialization - that is what Rserve does (mentioned earlier by Dirk - it even has a C++ client ...): it uses a fixed-size header that specifies the kind of payload and its length, then the serialization follows in the payload. That way you only need to read a fixed header.

Cheers,
Simon


> I do not do any conversion with the received data, and only need to
> transfer them into a remote R to do the function execution.
> 
> =====================
> 
> Rong "Jessica", Li (????)
> Platform Symphony TET, CSTL, IBM Systems &Technology Group, Development
> Tel:86-10-82451010  Email:ronglli at cn.ibm.com
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From amackey at virginia.edu  Thu Jun 27 02:04:38 2013
From: amackey at virginia.edu (Aaron Mackey)
Date: Wed, 26 Jun 2013 20:04:38 -0400
Subject: [R] XYZ data
In-Reply-To: <CA+jRDxBoqG30CuuR57YN1ZU6+QdPO6oBO=Evus+_vokUvF=M=Q@mail.gmail.com>
References: <05AA1FB4006.000011CBjrkrideau@inbox.com>
	<alpine.LRH.2.03.1306260914580.1649@ecy.wa.gov>
	<CA+jRDxBoqG30CuuR57YN1ZU6+QdPO6oBO=Evus+_vokUvF=M=Q@mail.gmail.com>
Message-ID: <CAErFSoic6Y=5asbvhEt0-vFb7vSdx7Q=7MMFPUOnE59OQd5dLA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130626/7a3c1d7e/attachment.pl>

From dwinsemius at comcast.net  Thu Jun 27 02:53:12 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 26 Jun 2013 17:53:12 -0700
Subject: [R] XYZ data
In-Reply-To: <CAErFSoic6Y=5asbvhEt0-vFb7vSdx7Q=7MMFPUOnE59OQd5dLA@mail.gmail.com>
References: <05AA1FB4006.000011CBjrkrideau@inbox.com>
	<alpine.LRH.2.03.1306260914580.1649@ecy.wa.gov>
	<CA+jRDxBoqG30CuuR57YN1ZU6+QdPO6oBO=Evus+_vokUvF=M=Q@mail.gmail.com>
	<CAErFSoic6Y=5asbvhEt0-vFb7vSdx7Q=7MMFPUOnE59OQd5dLA@mail.gmail.com>
Message-ID: <CFA61B62-7465-4219-946A-058865FF927A@comcast.net>


On Jun 26, 2013, at 5:04 PM, Aaron Mackey wrote:

> for plotting purposes, I typically jitter() the x's and y's to see the
> otherwise overlapping data points

That is one method for relatively sparse data. Also availble are the use of transparent colors, 2d-density estimators, and binned hex plots.

> -Aaron
> 
> On Wed, Jun 26, 2013 at 12:29 PM, Shane Carey <careyshan at gmail.com> wrote:
> 
>> Nope, neither work. :-(

Well, they "worked" ... :-( ... but you have not define "what you wanted".

Please read the Posting Guide (and the linked material that details how to ask questions that "work".
-- 
David.
>> 
>> 
>> On Wed, Jun 26, 2013 at 5:16 PM, Clint Bowman <clint at ecy.wa.gov> wrote:
>> 
>>> John,
>>> 
>>> That still leaves a string of identical numbers in the vector.
>>> 
>>> Shane,
>>> 
>>> ?jitter
>>> 
>>> perhaps jitter(X,1,0.0001)
>>> 
>>> Clint
>>> 
>>> Clint Bowman                    INTERNET:       clint at ecy.wa.gov
>>> Air Quality Modeler             INTERNET:       clint at math.utah.edu
>>> Department of Ecology           VOICE:          (360) 407-6815
>>> PO Box 47600                    FAX:            (360) 407-7534
>>> Olympia, WA 98504-7600
>>> 
>>>        USPS:           PO Box 47600, Olympia, WA 98504-7600
>>>        Parcels:        300 Desmond Drive, Lacey, WA 98503-1274
>>> 
>>> On Wed, 26 Jun 2013, John Kane wrote:
>>> 
>>> mm  <-  1:10
>>>> nn  <- mm + .001
>>>> 
>>>> John Kane
>>>> Kingston ON Canada
>>>> 
>>>> 
>>>> -----Original Message-----
>>>>> From: careyshan at gmail.com
>>>>> Sent: Wed, 26 Jun 2013 16:48:34 +0100
>>>>> To: r-help at r-project.org
>>>>> Subject: [R] XYZ data
>>>>> 
>>>>> I have x, y, z data. The x, y fields dont change but Z does. How do I
>> add
>>>>> a
>>>>> very small number onto the end of each x, y data point.
>>>>> 
>>>>> For example:
>>>>> 
>>>>> Original (X)              Original (Y)                 Original (Z)
>>>>> 15                               20                              30
>>>>> 15                               20                              40
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> New (X)              New (Y)                 New (Z)
>>>>> 15.00001             20.000001              30
>>>>> 15.00002             20.000002              40
>>>>> 
>>>>> 
>>>>> Thanks
>>>>> --
>>>>> Shane
>>>>> 
>>>>>        [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________**________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/**listinfo/r-help<
>> https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/**posting-guide.html<
>> http://www.R-project.org/posting-guide.html>
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>> 
>>>> ______________________________**______________________________
>>>> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>>>> 
>>>> ______________________________**________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/**listinfo/r-help<
>> https://stat.ethz.ch/mailman/listinfo/r-help>
>>>> PLEASE do read the posting guide http://www.R-project.org/**
>>>> posting-guide.html <http://www.R-project.org/posting-guide.html>
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> 
>> 
>> 
>> --
>> Shane
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From gregk at alphabetaworks.com  Thu Jun 27 02:28:09 2013
From: gregk at alphabetaworks.com (gregk)
Date: Wed, 26 Jun 2013 17:28:09 -0700 (PDT)
Subject: [R] How to avoid overlapping labels
In-Reply-To: <1361468179145-4659294.post@n4.nabble.com>
References: <1361468179145-4659294.post@n4.nabble.com>
Message-ID: <1372292889073-4670409.post@n4.nabble.com>

I ran into a similar problem and wrote a basic package that uses force field
simulation to adjust object location. While much improvement is possible,
including integration with ggplot, etc. it seems to get the task
accomplished. The following illustrates the functionality.  If someone runs
into the issue and searches for an answer, hopefully this will be of some
assistance:

    install.packages("FField")
    library(FField)
    FFieldPtRepDemo()

<http://r.789695.n4.nabble.com/file/n4670409/plot_zoom.png> 



--
View this message in context: http://r.789695.n4.nabble.com/How-to-avoid-overlapping-labels-tp4659294p4670409.html
Sent from the R help mailing list archive at Nabble.com.


From ashz at walla.co.il  Wed Jun 26 23:37:43 2013
From: ashz at walla.co.il (ashz)
Date: Wed, 26 Jun 2013 14:37:43 -0700 (PDT)
Subject: [R] Image Gray Level Co-occurrence Matrix in R
Message-ID: <1372282663774-4670401.post@n4.nabble.com>

Hi, 
  
I've been looking for Image Processing packages without success. I am mainly
interested in image Gray Level Co-occurrence Matrix (GLCM) parameters like
Contrast, Correlation, Energy, Homogeneity. 

Is there a package that can do it? Any ideas, comments, etc are welcome.

Thanks.




--
View this message in context: http://r.789695.n4.nabble.com/Image-Gray-Level-Co-occurrence-Matrix-in-R-tp4670401.html
Sent from the R help mailing list archive at Nabble.com.


From armel.kaptue at sdstate.edu  Thu Jun 27 05:24:30 2013
From: armel.kaptue at sdstate.edu (Kaptue Tchuente, Armel)
Date: Thu, 27 Jun 2013 03:24:30 +0000
Subject: [R] unable to install rPython
Message-ID: <9879AF1F439EF943BDEE22D3AAA5C3F683FCCB8C@sdsu-ex01.jacks.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130627/a5496a42/attachment.pl>

From dwadhwan at yahoo.com  Thu Jun 27 04:37:34 2013
From: dwadhwan at yahoo.com (dinesh wadhwani)
Date: Wed, 26 Jun 2013 19:37:34 -0700 (PDT)
Subject: [R] Fw: Remove from mailing list
In-Reply-To: <1372299547.87382.YahooMailNeo@web140002.mail.bf1.yahoo.com>
References: <165157.38617.bm@smtp214.mail.gq1.yahoo.com>
	<51CB698D.1090309@optonline.net>
	<1372299547.87382.YahooMailNeo@web140002.mail.bf1.yahoo.com>
Message-ID: <1372300654.94153.YahooMailNeo@web140006.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130626/934c3dde/attachment.pl>

From dwinsemius at comcast.net  Thu Jun 27 07:28:08 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 26 Jun 2013 22:28:08 -0700
Subject: [R] Fw: Remove from mailing list
In-Reply-To: <1372300654.94153.YahooMailNeo@web140006.mail.bf1.yahoo.com>
References: <165157.38617.bm@smtp214.mail.gq1.yahoo.com>
	<51CB698D.1090309@optonline.net>
	<1372299547.87382.YahooMailNeo@web140002.mail.bf1.yahoo.com>
	<1372300654.94153.YahooMailNeo@web140006.mail.bf1.yahoo.com>
Message-ID: <3CA94A4A-54FE-4490-839B-81420E78ACB1@comcast.net>


On Jun 26, 2013, at 7:37 PM, dinesh wadhwani wrote:

> This has bounced back twice already - would help if anybody cna remove me from the list and close my account. I have been deleting 100s of emails daily from my yahoo inbox becaue i cannot get them to stop, even after i canceld  my account.
> 
> my currnet status is that i have an account, but have not subscribed via email. please help.
> 

I replied privately to Mr Wadhwani just now. 

-- 
David.

> 
> ----- Forwarded Message -----
> From: dinesh wadhwani <dwadhwan at yahoo.com>
> To: "r-help-owner at r-project.org" <r-help-owner at r-project.org> 
> Sent: Wednesday, June 26, 2013 10:19 PM
> Subject: Fw: Remove from mailing list
> 
> 
> 
> Please help - I have tried several time and ways to stop these emails but keep getting them.
> 
> 
> ----- Forwarded Message -----
> From: Chuck Cleland <ccleland at optonline.net>
> To: Dinesh Wadhwani <dwadhwan at yahoo.com> 
> Sent: Wednesday, June 26, 2013 6:22 PM
> Subject: Re: Remove from mailing list
> 
> 
> 
> Hi Dinesh,
> 
>   I am not able to check the subscription list myself to see what might be happening.  I suggest sending another message to r-help-owner at r-project.org in which you describe in detail the steps you took to unsubscribe or otherwise turn off R-help mail.  Others who receive email at that address may be able to track down the problem.
> 
> Chuck
> 
> 
> On 6/26/2013 12:30 PM, Dinesh Wadhwani wrote:
> 
> Yes, I tried that when I was active. I am no longer active, so my email address is not recognized. I even tried opening a new junk gmail address and updated my email address to that, but I am still getting emails in my yahoo in box.
>> From: Chuck Cleland
>> Sent: 6/26/2013 11:59 AM
>> To: Dinesh Wadhwani
>> Cc: r-help-owner at r-project.org
>> Subject: Re: Remove from mailing list
>> 
>> Hello Dinesh,
>> 
>>   Did you go to http://www.r-project.org/mail.html and then enter your subscription email address near the bottom where it says:
>> 
>> "To unsubscribe from R-help, get a password reminder, or change your subscription options enter your subscription email address:" 
>> 
>>   Once you log in there, you should be able to
> unsubscribed, stop delivery, or turn on digest mode, among other configuration options.
>> 
>>   Was this among the ways that you tried?
>> 
>>   I hope this helps.
>> 
>> Chuck Cleland
>> 
>> 
>> On 6/26/2013 11:41 AM, Dinesh Wadhwani wrote:
>> 
>> Hi,
>>> 
>>> I have tried several different times and ways to stop getting emails when anyone posts to the r-help list and have been unable to get it to work. Can you please help?
>>> 
>>> My yahoo inbox keeps getting flooded with these posts and every reply and I am getting these even after closing my account. 
>>> 
>>> Thanks,
>>> Dinesh
>>> 
>> 
>> -- 
> Chuck Cleland, Ph.D.
> Senior Research Scientist
> NYU College of Nursing 
> 726 Broadway, 10th floor
> New York, NY 10003
> tel: (212) 992-9417 (Tu, W, Th)
> tel: (732) 512-0171 (M, F) 
> 
> -- 
> Chuck Cleland, Ph.D.
> Senior Research Scientist
> NYU College of Nursing 
> 726 Broadway, 10th floor
> New York, NY 10003
> tel: (212) 992-9417 (Tu, W, Th)
> tel: (732) 512-0171 (M, F) 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From kridox at ymail.com  Thu Jun 27 07:30:35 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 27 Jun 2013 14:30:35 +0900
Subject: [R] unable to install rPython
In-Reply-To: <9879AF1F439EF943BDEE22D3AAA5C3F683FCCB8C@sdsu-ex01.jacks.local>
References: <9879AF1F439EF943BDEE22D3AAA5C3F683FCCB8C@sdsu-ex01.jacks.local>
Message-ID: <51CBCDFB.30407@ymail.com>

Hello,

You need to install python-devel.

Regards,
Pascal


On 27/06/2013 12:24, Kaptue Tchuente, Armel wrote:
> Hello everyone,
> I try without success to install the package rPython
> I get the message
> -----------------------------------------------------------------------
> * installing *source* package ?rPython? ...
> could not locate python-config
> ERROR: configuration failed for package ?rPython?
> * removing ?/home/armel/R/x86_64-pc-linux-gnu-library/2.14/rPython?
>
> The downloaded packages are in
>      ?/tmp/RtmpcjMbGS/downloaded_packages?
> Warning message:
> In install.packages("rPython", repos = "http://www.datanalytics.com/R") :
>    installation of package ?rPython? had non-zero exit status
> ----------------------------------------------------------------------------
> Any help will be very much appreciated
>
> Armel
>
>
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.CA.us  Thu Jun 27 08:45:24 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 26 Jun 2013 23:45:24 -0700
Subject: [R] R CMD BATCH Unicode
In-Reply-To: <92A981B3677AE44384E1ABE4B16D87244E4672F2@MAIL1BDVM01.extendthereach.com>
References: <92A981B3677AE44384E1ABE4B16D87244E46404B@MAIL1BDVM01.extendthereach.com>
	<92A981B3677AE44384E1ABE4B16D87244E4643C0@MAIL1BDVM01.extendthereach.com>
	<51CA8DD3.3090107@stats.ox.ac.uk>
	<92A981B3677AE44384E1ABE4B16D87244E46715C@MAIL1BDVM01.extendthereach.com>
	<ae83ec2a-2914-4d5e-93ed-01ecef2f3a0d@email.android.com>
	<92A981B3677AE44384E1ABE4B16D87244E4672F2@MAIL1BDVM01.extendthereach.com>
Message-ID: <f511b06c-73d2-4f87-8e09-3f0f529d1466@email.android.com>

Well, I admit that I don't mess with this stuff much, but it worked fine for me in a simple test as long as I viewed the output with an editor or console that understood UTF-8, so I dispute your assertion that this is a problem internal to R. (I needed no special arguments to R for it to work either.)
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Ned Harding <ned at alteryx.com> wrote:

>I have no problems with the windows command line.  I don't need any
>Unicode there.  It really is an internal R question because of the way
>R is reading and writing the input and output files.  
>
>Ned.
>
>-----Original Message-----
>From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us] 
>Sent: Wednesday, June 26, 2013 11:06 AM
>To: Ned Harding; Prof Brian Ripley; r-help at r-project.org
>Subject: Re: [R] R CMD BATCH Unicode
>
>Just because the subject mentions R doesn't mean it is on topic here.
>This is more related to Windows than R. I recommend studying windows
>documentation for awhile. A quick search turned up a number of
>discussions on the web, including
>http://stackoverflow.com/questions/1035388/unicode-output-on-windows-command-line.
>---------------------------------------------------------------------------
>Jeff Newmiller                        The     .....       .....  Go
>Live...
>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>                                     Live:   OO#.. Dead: OO#..  Playing
>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>/Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>---------------------------------------------------------------------------
>Sent from my phone. Please excuse my brevity.
>
>Ned Harding <ned at alteryx.com> wrote:
>
>>So just to clarify - there is no way to use R CMD BATCH on windows
>with 
>>Unicode?  Any advice of how to use R in a batch mode with Unicode 
>>inputs and outputs?
>>
>>Ned.
>>
>>-----Original Message-----
>>From: r-help-bounces at r-project.org
>>[mailto:r-help-bounces at r-project.org] On Behalf Of Prof Brian Ripley
>>Sent: Wednesday, June 26, 2013 12:45 AM
>>To: r-help at r-project.org
>>Subject: Re: [R] R CMD BATCH Unicode
>>
>>On 25/06/2013 20:35, Ned Harding wrote:
>>> Just to clarify: The encoding didn't come through in the email. 
>>print("????????????") is meant to be a bunch of random greek 
>>characters.
>>
>>In that case the message is likely correct.  You failed to give us the
>
>>'at a minimum information' required by the posting guide, but you can 
>>only have input scripts in the locale encoding (and there are no UTF-8
>
>>locales on Windows).  So unless you were in a Greek locale, the 
>>re-encoding should have failed.
>>
>>> Ned.
>>>
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org
>>> [mailto:r-help-bounces at r-project.org] On Behalf Of Ned Harding
>>> Sent: Tuesday, June 25, 2013 11:35 AM
>>> To: r-help at r-project.org
>>> Subject: [R] R CMD BATCH Unicode
>>>
>>> Hey,
>>>
>>> I am looking for some help using Unicode with R CMD BATCH on
>windows.
>>In particular I would like my input and output files to be UTF-8 
>>encoded.  My command line looks like this:
>>>
>>> r CMD BATCH --encoding=UTF-8 in.txt out.txt
>>>
>>> in.txt is utf-8 encoded and contains:
>>>
>>> print("????????????")
>>>
>>> out.txt gets:
>>>
>>> + <ERROR: re-encoding failure from encoding 'UTF-8'>
>>>
>>> What is the proper way to specify encoding on the command line?
>>>
>>> Thanks in advance,
>>>
>>> Ned.
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>Please do, and note what it says about HTML mail, too.


From mestre.frederico at gmail.com  Thu Jun 27 10:19:10 2013
From: mestre.frederico at gmail.com (Frederico Mestre)
Date: Thu, 27 Jun 2013 09:19:10 +0100
Subject: [R] filling list of data frames
Message-ID: <012101ce730f$012e0560$038a1020$@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130627/1e53e153/attachment.pl>

From wewolski at gmail.com  Thu Jun 27 10:24:27 2013
From: wewolski at gmail.com (Witold E Wolski)
Date: Thu, 27 Jun 2013 10:24:27 +0200
Subject: [R] create index for tapply or by
Message-ID: <CAAjnpdgwrs4bMKH4-o7G1GdRoW9nYwi2pAAW5dj0HKKgh6DbSA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130627/98a11dbe/attachment.pl>

From ruipbarradas at sapo.pt  Thu Jun 27 10:43:31 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 27 Jun 2013 09:43:31 +0100
Subject: [R] create index for tapply or by
In-Reply-To: <CAAjnpdgwrs4bMKH4-o7G1GdRoW9nYwi2pAAW5dj0HKKgh6DbSA@mail.gmail.com>
References: <CAAjnpdgwrs4bMKH4-o7G1GdRoW9nYwi2pAAW5dj0HKKgh6DbSA@mail.gmail.com>
Message-ID: <51CBFB33.7020004@sapo.pt>

Hello,

Try using ?cut


y2 <- cut(x, breaks)
by(x, y2, sum)


Hope this helps,

Rui Barradas

Em 27-06-2013 09:24, Witold E Wolski escreveu:
> Is there a build in function to create an index for tapply or by given a
> a numeric vector x an a vector of breaks?
>
> What I want to do is:
>
> x <- 1:100
> breaks <- c(0,10,20,50,99,110)
>
> y <- rep(0,length(x))
> for(i in 2:length(breaks)){
>    y[which(x>breaks[i-1] & x <= breaks[i])] <- i
> }
>
> by(x,y,sum)
>
> but I find the code especially th for loop unneRving.
>
>


From Gerrit.Eichner at math.uni-giessen.de  Thu Jun 27 10:43:57 2013
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Thu, 27 Jun 2013 10:43:57 +0200 (MEST)
Subject: [R] create index for tapply or by
In-Reply-To: <CAAjnpdgwrs4bMKH4-o7G1GdRoW9nYwi2pAAW5dj0HKKgh6DbSA@mail.gmail.com>
References: <CAAjnpdgwrs4bMKH4-o7G1GdRoW9nYwi2pAAW5dj0HKKgh6DbSA@mail.gmail.com>
Message-ID: <Pine.SOC.4.64.1306271043010.14748@solcom.hrz.uni-giessen.de>

Hi, Witold,

take a look at

?findIntervals

It might give want you need.

  Hth  --  Gerrit

On Thu, 27 Jun 2013, Witold E Wolski wrote:

> Is there a build in function to create an index for tapply or by given a
> a numeric vector x an a vector of breaks?
>
> What I want to do is:
>
> x <- 1:100
> breaks <- c(0,10,20,50,99,110)
>
> y <- rep(0,length(x))
> for(i in 2:length(breaks)){
>  y[which(x>breaks[i-1] & x <= breaks[i])] <- i
> }
>
> by(x,y,sum)
>
> but I find the code especially th for loop unneRving.
>
>
> -- 
> Witold Eryk Wolski
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Thu Jun 27 11:57:20 2013
From: jholtman at gmail.com (Jim Holtman)
Date: Thu, 27 Jun 2013 05:57:20 -0400
Subject: [R] filling list of data frames
In-Reply-To: <012101ce730f$012e0560$038a1020$@gmail.com>
References: <012101ce730f$012e0560$038a1020$@gmail.com>
Message-ID: <C22B9DAF-3E09-40A6-9148-C5C764D48158@gmail.com>

You might want to use Rprof to profile your code to understand where the time is going; it might be in the function you are callingband therefore the "for" loop might not be the issue.

Sent from my iPad

On Jun 27, 2013, at 4:19, "Frederico Mestre" <mestre.frederico at gmail.com> wrote:

> Hello:
> 
> 
> 
> I have a list of data frames, built like this: the second df is a result of
> a function applied to the first, and so on.
> 
> 
> 
> So the ith df is always dependent on the (i-1)th df. I've been doing this
> using for loops. However I think I have too many for loops which is making
> my code run slowly.
> 
> 
> 
> Is there any workaround  this? How can I avoid the use of for loops?
> 
> 
> 
> As an example:
> 
> 
> 
> output.list <- as.list(rep("", 100))#creation of a list
> 
> 
> 
> output.list[[1]] <- df1#first position
> 
> 
> 
> 
> 
> for(I in 2:100){#following positions
> 
> 
> 
> df0 <- output.list[[i-1]]
> 
> 
> 
> df0_1 <- f1(df0)#function applied to the previous df
> 
> 
> 
> output.list[[i]] <- df0_1#new df
> 
> 
> 
> }
> 
> 
> 
> thanks,
> 
> 
> 
> Frederico 
> 
> 
> 
> 
> 
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From GITTEBA at HUM-GEN.AU.DK  Thu Jun 27 12:12:02 2013
From: GITTEBA at HUM-GEN.AU.DK (Gitte Brinch Andersen)
Date: Thu, 27 Jun 2013 10:12:02 +0000
Subject: [R] Change font size in Cluster analysis
Message-ID: <9A0C15FE-41B9-4F79-9DAA-CB1C39272BCF@hum-gen.au.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130627/bcc03d2d/attachment.pl>

From simone.gabbriellini at gmail.com  Thu Jun 27 12:43:48 2013
From: simone.gabbriellini at gmail.com (Simone Gabbriellini)
Date: Thu, 27 Jun 2013 12:43:48 +0200
Subject: [R] help with plotmeans (gplots)
In-Reply-To: <071d01ce7287$33d21340$9b7639c0$@tamu.edu>
References: <CAEy8Jr2A8LwM0HrmnwvYH5Ge70p_w0A8aX-LnpkYX3ajDCVi4A@mail.gmail.com>
	<071d01ce7287$33d21340$9b7639c0$@tamu.edu>
Message-ID: <CAEy8Jr3k=S4E8uGP1u0WF=KVcDOSbd=SoCQ=nSmzwnGJY6mRYg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130627/c9a6947c/attachment.pl>

From ripley at stats.ox.ac.uk  Thu Jun 27 13:01:46 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 27 Jun 2013 12:01:46 +0100
Subject: [R] Change font size in Cluster analysis
In-Reply-To: <9A0C15FE-41B9-4F79-9DAA-CB1C39272BCF@hum-gen.au.dk>
References: <9A0C15FE-41B9-4F79-9DAA-CB1C39272BCF@hum-gen.au.dk>
Message-ID: <51CC1B9A.6050708@stats.ox.ac.uk>

Your example is not reproducible (see the posting guide), but using 
example(hclust)

hc <- hclust(dist(USArrests), "ave")
plot(hc)
plot(hc, cex = 0.3)

the second has much smaller case names.

On 27/06/2013 11:12, Gitte Brinch Andersen wrote:
> Hello
>
> I have done a cluster analysis, and I would like to change the font size of my sample names. I have tried using cex, but this doesn't work/change anything. I have tried to specify it with cex.main, cex.lab, cex.axis and cex.sub, and can change all other names in the picture but my sample names.
> I can't see what I am doing wrong.
>
> I hope somebody can help me, and I apologize for this probably very simple question/mistake.
>
> I have around 1000 rows and 50 columns, but have only included a few in my example.
>
> Thank you in advance!
>
> Kind regards
>
> Gitte Andersen
>
>
> #Read in data
> data<-read.table("/Users/gban/Desktop/Heatmap/Heatmap with selected genes/Probes_for_heatmap_35_meth_diff_both_hypo_and_hypermeth_Gene&probenames.txt",sep="\t",dec=",",header=TRUE,row.names=1)
>
> data
>                                    OS_Tumor1_08_14985_2_3 OS_Tumor2_08_226869_1
> CHST3_cg04268405_1                            0.95038060            0.76433753
> DLX5_cg19962750_2                             0.93111825            0.75384523
> ZIC4_cg12892506_3                             0.86033747            0.69614933
> DLX5_cg05597836_4                             0.90698171            0.66414891
>
>
>
> #Turn the data into a matrix, and transpose to get the columns to be clustered
> Data_matrix<-as.matrix(t(data))
>
> Data_matrix
>                              CHST3_cg04268405_1 DLX5_cg19962750_2
> OS_Tumor1_08_14985_2_3               0.9503806         0.9311183
> OS_Tumor2_08_226869_1                0.7643375         0.7538452
> OS_Tumor3_10_201917_2_3              0.7109182         0.7778035
> OS_Tumor4_00_2395                    0.7772400         0.6769241
> OS_Tumor5_02_2669                    0.9638739         0.9023436
> OS_Tumor6_02_4738                    0.9028490         0.9586764
> OS_Tumor7_02_4850                    0.8786524         0.8872261
> OS_Tumor8_02_6935                    0.8434550         0.7180251
> OS_Tumor9_03_1430                    0.7494400         0.9190213
> OS_Tumor10_03_1701                   0.9148253         0.7692125
> OS_Tumor11_03_220                    0.9270112         0.8607459
> OS_Tumor12_03_2558                   0.9344832         0.5013390
> OS_Tumor13_03_373                    0.9549153         0.9559071
> OS_Tumor14_03_82                     0.9117558         0.3993953
> OS_Tumor15_06_22319                  0.9580999         0.9645215
> OS_Tumor16_07_16581                  0.6213243         0.9033265
> OS_Tumor17_07_28523                  0.9064597         0.4421651
> OS_Tumor18_07_3212                   0.6439032         0.4344106
> OS_Tumor19_07_6990                   0.9350585         0.9238712
> OS_Tumor20_07_6990sample2            0.9526839         0.9027684
> OS_Tumor21_07_7724                   0.9338156         0.8335415
> OS_Tumor22_08_10238                  0.9028336         0.8529122
> OS_Tumor23_08_14985Sample2           0.9609952         0.9478541
> OS_Tumor24_08_16592                  0.9168102         0.9138002
> OS_Tumor25_08_21197                  0.9148711         0.9109843
> OS_Tumor26_08_21197Sample2           0.9583610         0.8830407
> OS_Tumor27_08_222863                 0.9478853         0.8395278
> OS_Tumor28_08_225814                 0.9451414         0.9407933
> OS_Tumor29_08_226869Sample2          0.9028336         0.8337000
> OS_Tumor30_08_230660                 0.9599117         0.9363075
> OS_Tumor31_08_4485                   0.8247909         0.8336728
> OS_Tumor32_09_214654                 0.9531564         0.8957473
> OS_Tumor33_09_214654Sample2          0.9552210         0.9034464
> OS_Tumor34_10_200150                 0.9332627         0.8551589
> OS_Tumor35_10_201917                 0.9397219         0.9470733
> OS_Tumor36_10_201917Sample2          0.9607446         0.9523402
> OS_Tumor37_10_202221                 0.9264254         0.9413189
> OS_Tumor38_10_204294                 0.8388658         0.8956207
> OS_Tumor39_10_204294Sample2          0.8071109         0.8474199
> OS_Tumor40_10_205933                 0.8788835         0.4950936
> OS_Tumor41_10_225662                 0.9334545         0.8910134
> OS_Tumor42_10_229129                 0.5872184         0.8394597
> OS_Tumor43_11_236261                 0.9015548         0.9293858
> OS_Tumor44_12_211561                 0.6793692         0.1856015
> Normalbone.3.                        0.1636323         0.1222070
> Normalbone.UA.                       0.1934500         0.1303734
> Normalbone.UA2.                      0.1737224         0.1604758
> CRL_11372                            0.9779593         0.2533844
> CRL_1427                             0.9598825         0.8862426
> CRL_1543                             0.9283976         0.7198934
> CRL_2098                             0.9325895         0.6360936
> Ho_f.4610                            0.9370865         0.6279557
> HTB_85                               0.9441092         0.1037401
> HTB_96                               0.9511175         0.9160013
>                              ZIC4_cg12892506_3 DLX5_cg05597836_4
> OS_Tumor1_08_14985_2_3             0.86033747        0.90698171
> OS_Tumor2_08_226869_1              0.69614933        0.66414891
> OS_Tumor3_10_201917_2_3            0.58728927        0.65086446
> OS_Tumor4_00_2395                  0.41747130        0.45464648
> OS_Tumor5_02_2669                  0.74259213        0.88244165
> OS_Tumor6_02_4738                  0.79690018        0.93691928
> OS_Tumor7_02_4850                  0.05513471        0.91753824
> OS_Tumor8_02_6935                  0.70742299        0.77802530
> OS_Tumor9_03_1430                  0.84563086        0.87202952
> OS_Tumor10_03_1701                 0.81318017        0.72446802
> OS_Tumor11_03_220                  0.72489087        0.80580733
> OS_Tumor12_03_2558                 0.06656780        0.14739011
> OS_Tumor13_03_373                  0.94011867        0.95742989
> OS_Tumor14_03_82                   0.52129769        0.54734874
> OS_Tumor15_06_22319                0.93025191        0.94392535
> OS_Tumor16_07_16581                0.67236887        0.88546907
> OS_Tumor17_07_28523                0.25764851        0.45550666
> OS_Tumor18_07_3212                 0.33624514        0.18623351
> OS_Tumor19_07_6990                 0.82904776        0.88946081
> OS_Tumor20_07_6990sample2          0.76836030        0.82519665
> OS_Tumor21_07_7724                 0.90314315        0.71810973
> OS_Tumor22_08_10238                0.83715782        0.86426252
> OS_Tumor23_08_14985Sample2         0.82588214        0.90655043
> OS_Tumor24_08_16592                0.77582828        0.83500490
> OS_Tumor25_08_21197                0.90274785        0.96119490
> OS_Tumor26_08_21197Sample2         0.87385578        0.83341529
> OS_Tumor27_08_222863               0.72588195        0.59849569
> OS_Tumor28_08_225814               0.87931232        0.89657489
> OS_Tumor29_08_226869Sample2        0.86379063        0.88825605
> OS_Tumor30_08_230660               0.92495563        0.95137547
> OS_Tumor31_08_4485                 0.84465179        0.66948504
> OS_Tumor32_09_214654               0.92036441        0.71915709
> OS_Tumor33_09_214654Sample2        0.93955431        0.46490552
> OS_Tumor34_10_200150               0.80337813        0.82519665
> OS_Tumor35_10_201917               0.87734686        0.91265824
> OS_Tumor36_10_201917Sample2        0.93627004        0.94319232
> OS_Tumor37_10_202221               0.93107776        0.96075927
> OS_Tumor38_10_204294               0.85892154        0.94595920
> OS_Tumor39_10_204294Sample2        0.69839075        0.76396555
> OS_Tumor40_10_205933               0.25850129        0.43418918
> OS_Tumor41_10_225662               0.71442683        0.88154146
> OS_Tumor42_10_229129               0.42328977        0.77763541
> OS_Tumor43_11_236261               0.82946721        0.87242385
> OS_Tumor44_12_211561               0.84785994        0.12366988
> Normalbone.3.                      0.06840225        0.08229536
> Normalbone.UA.                     0.07383344        0.12502117
> Normalbone.UA2.                    0.07741817        0.09563505
> CRL_11372                          0.05409689        0.13815797
> CRL_1427                           0.91730069        0.92421230
> CRL_1543                           0.77789918        0.94650563
> CRL_2098                           0.91524115        0.50725942
> Ho_f.4610                          0.05736418        0.51843963
> HTB_85                             0.95464468        0.05260867
> HTB_96                             0.88410529        0.92872206
>
>
> #Calculate the distance
> Data_dist<-dist(Data_matrix)
>
> #Make the cluster
> Data_clust<-hclust(Data_dist,method="ward")
>
> #Save the plot as a pdf file
> pdf(file="Cluster_Probes_From_genes_morethan_2_probes_and_morethan_30_methdiff.pdf")
>
> #Plot the cluster
> plot(Data_clust, cex=0.5)
>
> dev.off() #Ends the pdf saving.
>
> Gitte Brinch Andersen
>
> Kandidat-Ph.d. studerende
> Biomedicinsk Institut
> Wilhelm Meyers All? 4
> Aarhus Universitet
> DK-8000 Aarhus C
>
> Mobil: +45 30433317
> E-mail: gitteba at hum-gen.au.dk<mailto:gitteba at hum-gen.au.dk>
>
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From careyshan at gmail.com  Thu Jun 27 13:32:12 2013
From: careyshan at gmail.com (Shane Carey)
Date: Thu, 27 Jun 2013 12:32:12 +0100
Subject: [R] Combining levels
Message-ID: <CA+jRDxAvUwiWNi5uz6fHv_Gc4hhp1wMAv-WHhQ8QLo7vx4tUrw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130627/0aa13b35/attachment.pl>

From mdsumner at gmail.com  Thu Jun 27 13:40:07 2013
From: mdsumner at gmail.com (Michael Sumner)
Date: Thu, 27 Jun 2013 21:40:07 +1000
Subject: [R] creat raster from XYZ
In-Reply-To: <CA+jRDxD=x+CHu_LC=w2XyjSdX=y9y+Ys99wXJPA4kb5OgkdmnQ@mail.gmail.com>
References: <CA+jRDxD=x+CHu_LC=w2XyjSdX=y9y+Ys99wXJPA4kb5OgkdmnQ@mail.gmail.com>
Message-ID: <CAAcGz98p1ezbbxj+g3gPU-4a2f+Qra8ch7K7L7Z4QMpXfy0Agw@mail.gmail.com>

On Wed, Jun 26, 2013 at 12:53 AM, Shane Carey <careyshan at gmail.com> wrote:
> Hi,
>
> I have a data set consisting of XYZ data. the dimensions are 22427 rows by
> 3 columns.
>
> I try to use rasterFromXYZ from the raster package but I get the following
> error:
>
>  Error in rasterFromXYZ(DATA) : x cell sizes are not regular
>
> Any help would be appreciated.

No problem.

library(raster)
?rasterFromXYZ


>
> Thanks
>
> --
> Shane
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Michael Sumner
Hobart, Australia
e-mail: mdsumner at gmail.com


From therneau at mayo.edu  Thu Jun 27 14:18:48 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Thu, 27 Jun 2013 07:18:48 -0500
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <mailman.33.1372327212.5917.r-help@r-project.org>
References: <mailman.33.1372327212.5917.r-help@r-project.org>
Message-ID: <51CC2DA8.7020904@mayo.edu>

I second Ellison sentiments of "almost never".  One main reason is readability on later 
viewing.
Yes, as Duncan says global variables can sometimes be handy and make functions quick to 
write, but using a formal argument in the call is always clearer.

Terry Therneau

On 06/27/2013 05:00 AM, r-help-request at r-project.org wrote:
> On 13-06-26 6:57 AM, S Ellison wrote:
>> >
>> >
>>> >>  -----Original Message-----
>>> >>  It may be helpful not to worry about the technical details,
>>> >>  just to look at the source code defining the function:  if it
>>> >>  is defined in a place where a variable can be seen, it can
>>> >>  see that variable.
>> >
>> >  I too find R's lexical scoping rules straightforward.
>> >  However, I'd say that if your code relies on lexical scoping to find something, you should probably rewrite your code.
>> >
>> >  The number of times I've seen new R users get unexpected results because they haven't noticed that their function is referencing a parent environment instead of a locally defined variable or argument is past counting.
>> >
>> >  Of course there are times when it's useful and sensible to have globally defined variables that can be accessed within a function. But they are very rare; as a default, I'd recommend avoiding it if at all possible. If your function needs something from outside, pass it as an argument.
>> >
> I would say the meaning of "probably" in your 2nd sentence depends quite
> a bit on the user.  For beginners, it's "almost certainly".  For people
> who are comfortable with the concept, it's just "maybe".
>
> I would agree that in most cases the only global objects that functions
> should reference are other functions, but small nested functions are
> quite safe, and it's sometimes useful to create functions in a local
> environment so they have persistent memory.
>
> Duncan Murdoch
>


From murdoch.duncan at gmail.com  Thu Jun 27 14:24:21 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 27 Jun 2013 08:24:21 -0400
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <51CC2DA8.7020904@mayo.edu>
References: <mailman.33.1372327212.5917.r-help@r-project.org>
	<51CC2DA8.7020904@mayo.edu>
Message-ID: <51CC2EF5.2090501@gmail.com>

On 13-06-27 8:18 AM, Terry Therneau wrote:
> I second Ellison sentiments of "almost never".  One main reason is readability on later
> viewing.
> Yes, as Duncan says global variables can sometimes be handy and make functions quick to
> write, but using a formal argument in the call is always clearer.

I didn't say that.  I said that in most cases global variables other 
than functions should not be used.

I would generalize that a little:  global constants are okay, changing 
globals is usually a bad idea.

Duncan Murdoch


>
> Terry Therneau
>
> On 06/27/2013 05:00 AM, r-help-request at r-project.org wrote:
>> On 13-06-26 6:57 AM, S Ellison wrote:
>>>>
>>>>
>>>>>>   -----Original Message-----
>>>>>>   It may be helpful not to worry about the technical details,
>>>>>>   just to look at the source code defining the function:  if it
>>>>>>   is defined in a place where a variable can be seen, it can
>>>>>>   see that variable.
>>>>
>>>>   I too find R's lexical scoping rules straightforward.
>>>>   However, I'd say that if your code relies on lexical scoping to find something, you should probably rewrite your code.
>>>>
>>>>   The number of times I've seen new R users get unexpected results because they haven't noticed that their function is referencing a parent environment instead of a locally defined variable or argument is past counting.
>>>>
>>>>   Of course there are times when it's useful and sensible to have globally defined variables that can be accessed within a function. But they are very rare; as a default, I'd recommend avoiding it if at all possible. If your function needs something from outside, pass it as an argument.
>>>>
>> I would say the meaning of "probably" in your 2nd sentence depends quite
>> a bit on the user.  For beginners, it's "almost certainly".  For people
>> who are comfortable with the concept, it's just "maybe".
>>
>> I would agree that in most cases the only global objects that functions
>> should reference are other functions, but small nested functions are
>> quite safe, and it's sometimes useful to create functions in a local
>> environment so they have persistent memory.
>>
>> Duncan Murdoch
>>


From therneau at mayo.edu  Thu Jun 27 14:29:14 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Thu, 27 Jun 2013 07:29:14 -0500
Subject: [R] censor=FALSE and id options in survfit.coxph
In-Reply-To: <mailman.27.1372240808.631.r-help@r-project.org>
References: <mailman.27.1372240808.631.r-help@r-project.org>
Message-ID: <51CC301A.2040402@mayo.edu>

Yes, it is a bug.  Thanks for providing a complete example.  I'll look into it, but leave 
for a week's vacation in a couple of hours and have some other pressing tasks.

Terry T.


Terry,

I recently noticed the censor argument of survfit.  For some analyses it greatly reduces the size of the resulting object, which is a nice feature.

However, when combined with the id argument, only 1 prediction is made.  Predictions can be made individually but I'd prefer to do them all at once if that change can be made.

Chris


From therneau at mayo.edu  Thu Jun 27 14:51:28 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Thu, 27 Jun 2013 07:51:28 -0500
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <51CC2EF5.2090501@gmail.com>
References: <mailman.33.1372327212.5917.r-help@r-project.org>
	<51CC2DA8.7020904@mayo.edu> <51CC2EF5.2090501@gmail.com>
Message-ID: <51CC3550.1050602@mayo.edu>

Duncan,
"I disagree with Duncan" was not at all the intent of my note, but on rereading it does 
have that flavor.  Chastisement accepted.  Due to the documentation angle I'd simply 
change your original "maybe" to "sometimes maybe".  A bit more caution but the same message.
Terry T.


On 06/27/2013 07:24 AM, Duncan Murdoch wrote:
> On 13-06-27 8:18 AM, Terry Therneau wrote:
>> I second Ellison sentiments of "almost never".  One main reason is readability on later
>> viewing.
>> Yes, as Duncan says global variables can sometimes be handy and make functions quick to
>> write, but using a formal argument in the call is always clearer.
>
> I didn't say that.  I said that in most cases global variables other than functions 
> should not be used.
>
> I would generalize that a little:  global constants are okay, changing globals is 
> usually a bad idea.
>
> Duncan Murdoch
>
>
>>
>> Terry Therneau
>>
>> On 06/27/2013 05:00 AM, r-help-request at r-project.org wrote:
>>> On 13-06-26 6:57 AM, S Ellison wrote:
>>>>>
>>>>>
>>>>>>>   -----Original Message-----
>>>>>>>   It may be helpful not to worry about the technical details,
>>>>>>>   just to look at the source code defining the function:  if it
>>>>>>>   is defined in a place where a variable can be seen, it can
>>>>>>>   see that variable.
>>>>>
>>>>>   I too find R's lexical scoping rules straightforward.
>>>>>   However, I'd say that if your code relies on lexical scoping to find something, 
>>>>> you should probably rewrite your code.
>>>>>
>>>>>   The number of times I've seen new R users get unexpected results because they 
>>>>> haven't noticed that their function is referencing a parent environment instead of a 
>>>>> locally defined variable or argument is past counting.
>>>>>
>>>>>   Of course there are times when it's useful and sensible to have globally defined 
>>>>> variables that can be accessed within a function. But they are very rare; as a 
>>>>> default, I'd recommend avoiding it if at all possible. If your function needs 
>>>>> something from outside, pass it as an argument.
>>>>>
>>> I would say the meaning of "probably" in your 2nd sentence depends quite
>>> a bit on the user.  For beginners, it's "almost certainly".  For people
>>> who are comfortable with the concept, it's just "maybe".
>>>
>>> I would agree that in most cases the only global objects that functions
>>> should reference are other functions, but small nested functions are
>>> quite safe, and it's sometimes useful to create functions in a local
>>> environment so they have persistent memory.
>>>
>>> Duncan Murdoch
>>>
>


From smartpink111 at yahoo.com  Thu Jun 27 14:57:09 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 27 Jun 2013 05:57:09 -0700 (PDT)
Subject: [R] Combining levels
In-Reply-To: <CA+jRDxAgv-_C-bzW=G3iD4QYNEAm5ZxDQBgjzxBBe=iToa85uw@mail.gmail.com>
References: <CA+jRDxAvUwiWNi5uz6fHv_Gc4hhp1wMAv-WHhQ8QLo7vx4tUrw@mail.gmail.com>
	<1372334098.78672.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CA+jRDxDwaEHYo3Dcf9nSwMo4FkL9Aai0ABA5Ly2V-OVT=A8K4Q@mail.gmail.com>
	<1372335673.5443.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CA+jRDxAgv-_C-bzW=G3iD4QYNEAm5ZxDQBgjzxBBe=iToa85uw@mail.gmail.com>
Message-ID: <1372337829.66288.YahooMailNeo@web142605.mail.bf1.yahoo.com>



Hi,
May be this helps:

Data1<-read.table(text='
TYPE??????????????????????????????????????????????? VALUE
"Residential-future"??????????????????????????????? 2.2
"Open space-managed"??????????????????????? 1.4
"Mixed use"?????????????????????????????????????????? 5.2
"Residential-existing"??????????????????????????? 4.2
"Residential-existing"??????????????????????????? 7.1
"Residential-future"?????????????????????????????? 5.2
"Residential-existing"??????????????????????????? 1.2
"mixed use"??????????????????????????????????????????? 4.5
',sep="",header=TRUE)


library(reshape)

?Data1[,1]<-combine_factor(Data1[,1],c(2,2,3,4,5))


levels(Data1[,1])
#[1] "Mixed use"??????????? "Open space-managed"?? "Residential-existing"
#[4] "Residential-future"? 
Data1[,1]
#[1] Residential-future?? Open space-managed?? Mixed use?????????? 
#[4] Residential-existing Residential-existing Residential-future? 
#[7] Residential-existing Mixed use?????????? 
#4 Levels: Mixed use Open space-managed ... Residential-future
A.K.
________________________________
From: Shane Carey <careyshan at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Thursday, June 27, 2013 8:27 AM
Subject: Re: [R] Combining levels



Sorry, this is what it should be:

DATA=

TYPE ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?VALUE
Residential - future" ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?2.2
"Open space - managed" ? ? ? ? ? ? ? ? ? ? ? ?1.4
"Mixed use" ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 5.2
"Residential - existing" ? ? ? ? ? ? ? ? ? ? ? ? ? ?4.2
"Residential - existing" ? ? ? ? ? ? ? ? ? ? ? ? ? ?7.1
"Residential - future" ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 5.2
"Residential - existing" ? ? ? ? ? ? ? ? ? ? ? ? ? ?1.2
"mixed use" ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?4.5


Which gives me these levels=
Levels: Mixed use Open space - managed Residential - existing Residential - future, mixed use


I need to combine mixed use and Mixed use into one category


Thank you very much. I really appreciate your help.
Thanks again



On Thu, Jun 27, 2013 at 1:21 PM, arun <smartpink111 at yahoo.com> wrote:


>
>HI,
>Tx for the email.? Could you also show the expected result?
>
>
>
>
>
>
>________________________________
>From: Shane Carey <careyshan at gmail.com>
>To: arun <smartpink111 at yahoo.com>
>Sent: Thursday, June 27, 2013 8:18 AM
>Subject: Re: [R] Combining levels
>
>
>
>
>Hi,
>
>DATA<-c("Residential - future" , "Open space - managed", "Mixed use","Residential - existing", "Residential - existing", "Residential - future","Residential - existing","mixed use")
>
>And I need to combine Mixed-use and mixed use
>
>Thank you
>
>
>
>On Thu, Jun 27, 2013 at 12:54 PM, arun <smartpink111 at yahoo.com> wrote:
>
>Hi,
>>It is difficult to test without a reproducible example.? Also, it would be useful to know your expected output.
>>I understand ?combine_factor is from library(reshape).
>>A.K.
>>
>>
>>
>>
>>
>>----- Original Message -----
>>From: Shane Carey <careyshan at gmail.com>
>>To: "r-help at r-project.org" <r-help at r-project.org>
>>Cc:
>>Sent: Thursday, June 27, 2013 7:32 AM
>>Subject: [R] Combining levels
>>
>>Hi,
>>
>>I am trying to combine two levels and leave all other levels unchnaged. I
>>have tried doing the following:
>>
>>combine_factor(DATA$Land_zone, c("mix use","Mixed use"))
>>
>>but it just returns NA.
>>
>>Thanks
>>
>>--
>>Shane
>>
>>??? [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>
>--
>Shane
>


-- 
Shane


From ned at alteryx.com  Thu Jun 27 15:11:00 2013
From: ned at alteryx.com (Ned Harding)
Date: Thu, 27 Jun 2013 13:11:00 +0000
Subject: [R] R CMD BATCH Unicode
In-Reply-To: <f511b06c-73d2-4f87-8e09-3f0f529d1466@email.android.com>
References: <92A981B3677AE44384E1ABE4B16D87244E46404B@MAIL1BDVM01.extendthereach.com>
	<92A981B3677AE44384E1ABE4B16D87244E4643C0@MAIL1BDVM01.extendthereach.com>
	<51CA8DD3.3090107@stats.ox.ac.uk>
	<92A981B3677AE44384E1ABE4B16D87244E46715C@MAIL1BDVM01.extendthereach.com>
	<ae83ec2a-2914-4d5e-93ed-01ecef2f3a0d@email.android.com>
	<92A981B3677AE44384E1ABE4B16D87244E4672F2@MAIL1BDVM01.extendthereach.com>
	<f511b06c-73d2-4f87-8e09-3f0f529d1466@email.android.com>
Message-ID: <92A981B3677AE44384E1ABE4B16D87244E467C8B@MAIL1BDVM01.extendthereach.com>

The problem isn't so much getting the output to work.  I can get that to work too.  The problem is that R doesn't know what the encoding is, so things like graphs fail.

-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us] 
Sent: Thursday, June 27, 2013 12:45 AM
To: Ned Harding; Prof Brian Ripley; r-help at r-project.org
Subject: RE: [R] R CMD BATCH Unicode

Well, I admit that I don't mess with this stuff much, but it worked fine for me in a simple test as long as I viewed the output with an editor or console that understood UTF-8, so I dispute your assertion that this is a problem internal to R. (I needed no special arguments to R for it to work either.)
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.

Ned Harding <ned at alteryx.com> wrote:

>I have no problems with the windows command line.  I don't need any 
>Unicode there.  It really is an internal R question because of the way 
>R is reading and writing the input and output files.
>
>Ned.
>
>-----Original Message-----
>From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us]
>Sent: Wednesday, June 26, 2013 11:06 AM
>To: Ned Harding; Prof Brian Ripley; r-help at r-project.org
>Subject: Re: [R] R CMD BATCH Unicode
>
>Just because the subject mentions R doesn't mean it is on topic here.
>This is more related to Windows than R. I recommend studying windows 
>documentation for awhile. A quick search turned up a number of 
>discussions on the web, including 
>http://stackoverflow.com/questions/1035388/unicode-output-on-windows-command-line.
>---------------------------------------------------------------------------
>Jeff Newmiller                        The     .....       .....  Go
>Live...
>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>                                     Live:   OO#.. Dead: OO#..  Playing
>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>/Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>-----------------------------------------------------------------------
>---- Sent from my phone. Please excuse my brevity.
>
>Ned Harding <ned at alteryx.com> wrote:
>
>>So just to clarify - there is no way to use R CMD BATCH on windows
>with
>>Unicode?  Any advice of how to use R in a batch mode with Unicode 
>>inputs and outputs?
>>
>>Ned.
>>
>>-----Original Message-----
>>From: r-help-bounces at r-project.org
>>[mailto:r-help-bounces at r-project.org] On Behalf Of Prof Brian Ripley
>>Sent: Wednesday, June 26, 2013 12:45 AM
>>To: r-help at r-project.org
>>Subject: Re: [R] R CMD BATCH Unicode
>>
>>On 25/06/2013 20:35, Ned Harding wrote:
>>> Just to clarify: The encoding didn't come through in the email. 
>>print("????????????") is meant to be a bunch of random greek 
>>characters.
>>
>>In that case the message is likely correct.  You failed to give us the
>
>>'at a minimum information' required by the posting guide, but you can 
>>only have input scripts in the locale encoding (and there are no UTF-8
>
>>locales on Windows).  So unless you were in a Greek locale, the 
>>re-encoding should have failed.
>>
>>> Ned.
>>>
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org
>>> [mailto:r-help-bounces at r-project.org] On Behalf Of Ned Harding
>>> Sent: Tuesday, June 25, 2013 11:35 AM
>>> To: r-help at r-project.org
>>> Subject: [R] R CMD BATCH Unicode
>>>
>>> Hey,
>>>
>>> I am looking for some help using Unicode with R CMD BATCH on
>windows.
>>In particular I would like my input and output files to be UTF-8 
>>encoded.  My command line looks like this:
>>>
>>> r CMD BATCH --encoding=UTF-8 in.txt out.txt
>>>
>>> in.txt is utf-8 encoded and contains:
>>>
>>> print("????????????")
>>>
>>> out.txt gets:
>>>
>>> + <ERROR: re-encoding failure from encoding 'UTF-8'>
>>>
>>> What is the proper way to specify encoding on the command line?
>>>
>>> Thanks in advance,
>>>
>>> Ned.
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>Please do, and note what it says about HTML mail, too.


From murdoch.duncan at gmail.com  Thu Jun 27 15:26:54 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 27 Jun 2013 09:26:54 -0400
Subject: [R] R CMD BATCH Unicode
In-Reply-To: <92A981B3677AE44384E1ABE4B16D87244E467C8B@MAIL1BDVM01.extendthereach.com>
References: <92A981B3677AE44384E1ABE4B16D87244E46404B@MAIL1BDVM01.extendthereach.com>
	<92A981B3677AE44384E1ABE4B16D87244E4643C0@MAIL1BDVM01.extendthereach.com>
	<51CA8DD3.3090107@stats.ox.ac.uk>
	<92A981B3677AE44384E1ABE4B16D87244E46715C@MAIL1BDVM01.extendthereach.com>
	<ae83ec2a-2914-4d5e-93ed-01ecef2f3a0d@email.android.com>
	<92A981B3677AE44384E1ABE4B16D87244E4672F2@MAIL1BDVM01.extendthereach.com>
	<f511b06c-73d2-4f87-8e09-3f0f529d1466@email.android.com>
	<92A981B3677AE44384E1ABE4B16D87244E467C8B@MAIL1BDVM01.extendthereach.com>
Message-ID: <51CC3D9E.1080707@gmail.com>

On 27/06/2013 9:11 AM, Ned Harding wrote:
> The problem isn't so much getting the output to work.  I can get that to work too.  The problem is that R doesn't know what the encoding is, so things like graphs fail.

I think the solution is pretty clear:  don't expect R CMD BATCH to 
accept non-native encodings.  A workaround would be to write a purely 
ASCII file that you give to R CMD BATCH; it reads the real script and 
executes it.

Duncan Murdoch

>
> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us]
> Sent: Thursday, June 27, 2013 12:45 AM
> To: Ned Harding; Prof Brian Ripley; r-help at r-project.org
> Subject: RE: [R] R CMD BATCH Unicode
>
> Well, I admit that I don't mess with this stuff much, but it worked fine for me in a simple test as long as I viewed the output with an editor or console that understood UTF-8, so I dispute your assertion that this is a problem internal to R. (I needed no special arguments to R for it to work either.)
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> Ned Harding <ned at alteryx.com> wrote:
>
> >I have no problems with the windows command line.  I don't need any
> >Unicode there.  It really is an internal R question because of the way
> >R is reading and writing the input and output files.
> >
> >Ned.
> >
> >-----Original Message-----
> >From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us]
> >Sent: Wednesday, June 26, 2013 11:06 AM
> >To: Ned Harding; Prof Brian Ripley; r-help at r-project.org
> >Subject: Re: [R] R CMD BATCH Unicode
> >
> >Just because the subject mentions R doesn't mean it is on topic here.
> >This is more related to Windows than R. I recommend studying windows
> >documentation for awhile. A quick search turned up a number of
> >discussions on the web, including
> >http://stackoverflow.com/questions/1035388/unicode-output-on-windows-command-line.
> >---------------------------------------------------------------------------
> >Jeff Newmiller                        The     .....       .....  Go
> >Live...
> >DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> >Go...
> >                                     Live:   OO#.. Dead: OO#..  Playing
> >Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >/Software/Embedded Controllers)               .OO#.       .OO#.
> >rocks...1k
> >-----------------------------------------------------------------------
> >---- Sent from my phone. Please excuse my brevity.
> >
> >Ned Harding <ned at alteryx.com> wrote:
> >
> >>So just to clarify - there is no way to use R CMD BATCH on windows
> >with
> >>Unicode?  Any advice of how to use R in a batch mode with Unicode
> >>inputs and outputs?
> >>
> >>Ned.
> >>
> >>-----Original Message-----
> >>From: r-help-bounces at r-project.org
> >>[mailto:r-help-bounces at r-project.org] On Behalf Of Prof Brian Ripley
> >>Sent: Wednesday, June 26, 2013 12:45 AM
> >>To: r-help at r-project.org
> >>Subject: Re: [R] R CMD BATCH Unicode
> >>
> >>On 25/06/2013 20:35, Ned Harding wrote:
> >>> Just to clarify: The encoding didn't come through in the email.
> >>print("????????????") is meant to be a bunch of random greek
> >>characters.
> >>
> >>In that case the message is likely correct.  You failed to give us the
> >
> >>'at a minimum information' required by the posting guide, but you can
> >>only have input scripts in the locale encoding (and there are no UTF-8
> >
> >>locales on Windows).  So unless you were in a Greek locale, the
> >>re-encoding should have failed.
> >>
> >>> Ned.
> >>>
> >>> -----Original Message-----
> >>> From: r-help-bounces at r-project.org
> >>> [mailto:r-help-bounces at r-project.org] On Behalf Of Ned Harding
> >>> Sent: Tuesday, June 25, 2013 11:35 AM
> >>> To: r-help at r-project.org
> >>> Subject: [R] R CMD BATCH Unicode
> >>>
> >>> Hey,
> >>>
> >>> I am looking for some help using Unicode with R CMD BATCH on
> >windows.
> >>In particular I would like my input and output files to be UTF-8
> >>encoded.  My command line looks like this:
> >>>
> >>> r CMD BATCH --encoding=UTF-8 in.txt out.txt
> >>>
> >>> in.txt is utf-8 encoded and contains:
> >>>
> >>> print("????????????")
> >>>
> >>> out.txt gets:
> >>>
> >>> + <ERROR: re-encoding failure from encoding 'UTF-8'>
> >>>
> >>> What is the proper way to specify encoding on the command line?
> >>>
> >>> Thanks in advance,
> >>>
> >>> Ned.
> >>>
> >>> 	[[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>Please do, and note what it says about HTML mail, too.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Thu Jun 27 16:17:12 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 27 Jun 2013 07:17:12 -0700 (PDT)
Subject: [R] multiple csv files for T-test
Message-ID: <1372342632.22771.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
May be this helps:
#You can use ?read.csv() to read the two files.

set.seed(24)
dat1<- as.data.frame(matrix(sample(20:40,40,replace=TRUE),ncol=4))
set.seed(285)
dat2<- as.data.frame(matrix(sample(35:60,40,replace=TRUE),ncol=4))
sapply(colnames(dat1),function(i) t.test(dat1[,i],dat2[,i],paired=TRUE)$p.value)
#????????? V1?????????? V2?????????? V3?????????? V4 
#3.202629e-05 6.510644e-04 6.215225e-04 3.044760e-04 

A.K.

Hi 
I am fairly new to R so if this is a stupid question please forgive me. 

I have a CSV file with multiple parameters (50). ?I have another
 CSV file with the same parameters after treatment. ?Is there a way I 
can read these two files into R and do multiple paired T-test as all the
 parameters are in the same columns in each file? 

Thanks in advance


From dimitri.liakhovitski at gmail.com  Thu Jun 27 16:37:22 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 27 Jun 2013 10:37:22 -0400
Subject: [R] choicemodelr is misbehaving under R3.0
Message-ID: <CAN2xGJYjEe-r6ynVw35WJnDscQt4O_aAvWAggdZkVXxVvAV+CQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130627/83f155dd/attachment.pl>

From suparna.mitra.sm at gmail.com  Thu Jun 27 09:34:37 2013
From: suparna.mitra.sm at gmail.com (Suparna Mitra)
Date: Thu, 27 Jun 2013 15:34:37 +0800
Subject: [R] Changing legend to fill colour in ggplot
Message-ID: <CAFdg=fWJuCY2dwyJzq4ocRccrUHfmAWZ7KTr9y2yJSC54iKBSA@mail.gmail.com>

Hello R experts,
  I am having a problem to edit legend in ggplot using four variables.

My data structure is :
str(df)
'data.frame': 10 obs. of  6 variables:
 $ id                        : Factor w/ 2 levels "639A","640": 1 1 1 1 1 2
2 2 2 2
 $ species                   : Factor w/ 5 levels "acinetobacter_sp",..: 2
5 1 4 3 2 5 1 4 3
 $ genome_coverage_bp        : int  8196 3405 8625 22568 2128 6100 1841
3914 8487 1064
 $ genome_length             : int  3571237 2541445 3912725 3479613 5460977
3571237 2541445 3912725 3479613 5460977
 $ genome_coverage_percentage: Factor w/ 10 levels "0.02%","0.04%",..: 8 5
7 10 2 6 3 4 9 1
 $ avg_depth_coverage        : num  121.96 2.81 19.84 399.63 1.64 ...


Now what I did is
p=ggplot(df,aes(genome_coverage_percentage,avg_depth_coverage))+geom_point(aes(colour
= species,shape = factor(id)))
p+scale_shape_discrete(name  ="",labels=c("Patient 1", "Patient 2"))
That creats the plot below.
But I want to change the circles of legend in fill colour. So that it
doesn't look like it is only from Patient 1, as that also has circle.
Can anybody help me please?

Thanks a lot in advance :)
Mitra
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot-5species.pdf
Type: application/pdf
Size: 181335 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130627/5db5ef7c/attachment.pdf>

From meesters at aesku-kipp.com  Thu Jun 27 10:48:45 2013
From: meesters at aesku-kipp.com (Meesters, Aesku.Kipp Institute)
Date: Thu, 27 Jun 2013 08:48:45 +0000
Subject: [R] corrgram with two datasets
Message-ID: <2EDC7C2789E5934CAA9AF5E96A27F65C104D4FA9@AESKU-EXCH01.AESKU.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130627/351ff4be/attachment.pl>

From yuliya.rmail at gmail.com  Thu Jun 27 10:49:51 2013
From: yuliya.rmail at gmail.com (Yuliya Matveyeva)
Date: Thu, 27 Jun 2013 12:49:51 +0400
Subject: [R] party ctree : getting a one-node tree
Message-ID: <CAOE1P1E2xFMf8NDp+pTZSU=yuZS-7w30Vs_NuHAqc99SZu+3ew@mail.gmail.com>

Dear useRs,

 I am currently using the ctree function (package "party") and am stuck at
the problem of getting a one-node tree (a tree with no splits consisting of
the root only) even if I maximally loosen all the stopping criteria
(mincriterion = 0, minbucket = 0, minsplit = 0).

 In order to check that in my data there really is no variable that would
not be considered independent of the response variable, I have found the
package "coin" written by the same authors as the package "party", where
the Strasser-Weber tests (used inside the ctree function) are accessible as
separate functions (while they are incapsulated in the package "party").

 But to my surprise running the tests from that package manually brings me
to finding many variables for which the hypothesis of independence is
rejected with a very-very small p-value (less than 2e-16). So this brings
me to thinking that even with the Bonferroni corrections I should still be
getting some splits in my ctree (having ~90 variables makes the Bonferroni
sig.level = ~0.01, given that the overall sig.level is 1 (maximal)).
So I am really confused... I would be really grateful if anyone could
please help me untangle this confusion...

I was not able to generate a small data-matrix to get the results as
described above. And my original data is rather big (9000 rows + 90
variables).

Here is my code :
---------------------------
f_data <- "feature_matrix.txt-dummies-df1";

library(party)
# ///////////////////////////////////
df <- read.table(file = f_data, sep = "*", header = F,
colClasses = "character");

ids <- df[,1]; weights1 <- as.integer(df[,2]); df <- df[,-c(1,2)]
for (i in 1:ncol(df)) {  df[,i] <- as.numeric(df[,i]); }
colnames(df)[ncol(df)] <- "dep_var";

# ------- delete variables with zero-variance ---------
vars_to_delete <- c();
for (i in 1:ncol(df)) {
 if (!(var(df[,i]) > 0)) {
     vars_to_delete <- c(vars_to_delete, i);
 }
}
df <- df[,-vars_to_delete];
# --------------------------------------------------------------------

signif_level1 <- 1
mincriterion1 <- 1 - signif_level1;
minbucket1 <- 0
teststat1 <- "quad"
testtype1 <- "Bonferroni"

system.time({ ctree.2 <- ctree(dep_var ~ ., data = df, weights = weights1,
controls = ctree_control(minbucket = minbucket1, minsplit = 2*minbucket1,
maxdepth = 0,
mincriterion = mincriterion1,
teststat = teststat1, testtype = testtype1,
savesplitstats = TRUE)) })
ctree.2

// here I get a tree with one node that is the root

# --------------------------------------------------------------------

library(coin)
p <- new("IndependenceProblem",
x = df[,colnames(df) != "dep_var"], y = df[,"dep_var", drop = F],
weights = weights1)
s <- independence_test(p,
teststat = teststat1, distribution = "asymptotic", alternative =
"two.sided" )
s

vars <- colnames(df); vars <- vars[vars != "dep_var"]
test_pvalues <- list()
for (v in vars) {
p <- new("IndependenceProblem",
 x = df[,v, drop=F], y = df[,"dep_var", drop = F],
 weights = weights1)
s <- independence_test(p,
teststat = teststat1, distribution = "asymptotic", alternative =
"two.sided" )
test_pvalues[[v]] <- pvalue(s)
}
test_pvalues

// here I get several p-values that are zero

-- 
Sincerely yours,
Yulia Matveeva

From jacqueline.oehri at gmx.ch  Thu Jun 27 12:00:43 2013
From: jacqueline.oehri at gmx.ch (Jacqueline Oehri)
Date: Thu, 27 Jun 2013 12:00:43 +0200 (CEST)
Subject: [R] Fwd: Questions about working with a dataframe
In-Reply-To: <056CC4A37ED.00001168jrkrideau@inbox.com>
References: <f90bbb3f8fb.00000235jrkrideau@inbox.com>
	<4251c1a6-d423-45b4-8684-531d7c36670b@comcast.net>
	<f3cacab8-6537-424a-8bbc-1dd2e5b09985@gmx.ch>,
	<056CC4A37ED.00001168jrkrideau@inbox.com>
Message-ID: <trinity-7e331cae-4a71-40b3-804a-dd0adc8fae9c-1372327243242@3capp-gmx-bs23>

Dear Mr. Kane

Thank you very much for your recommendations!!! And I apologise for all circumstances!! I will do so as you said in the future!

Have a nice day,

Best wishes Jacqueline
?

Gesendet:?Mittwoch, 26. Juni 2013 um 17:34 Uhr
Von:?"John Kane" <jrkrideau at inbox.com>
An:?"Jacqueline Oehri" <jacqueline.oehri at gmx.ch>, "David Winsemius" <dwinsemius at comcast.net>, r-help at r-project.org
Betreff:?RE: Aw: Re: [R] Fwd: Questions about working with a dataframe
It is always better when dealing with R to use plain text. HTML messes things up badly sometimes and it is also a good idea to reply to the R-help list rather than individual respondents.? You can get more responses if the problem continues and if either of us were away then it might be weeks before we managed to reply

Other responses in line

John Kane
Kingston ON Canada

-----Original Message-----
From: jacqueline.oehri at gmx.ch
Sent: Wed, 26 Jun 2013 11:18:41 +0200 (CEST)
To: dwinsemius at comcast.net, jrkrideau at inbox.com, r-help at r-project.org
Subject: Aw: Re: [R] Fwd: Questions about working with a dataframe

Dear Mr. Kane and dear Mr. Winsemius

Thanks a lot for your quick answers and good recommendations!!! And I apologise for attaching such a big file before!!

I think I could solve the problem;

Maybe you can tell me if its right what I have done?

As John said, the str(WWA) and str(oWWA) gave different outputs for "WWA$speciesName":

> class(WWA$speciesName)
[1] "character"

> class(oWWA$speciesName)
[1] "factor"

What I did is this:

> oWWA$speciesName <-as.character(oWWA$speciesName)

and now I've got:

> class(oWWA$speciesName)
[1] "character"

and the function I wanted to use works well:

> Sp_per_coordID_oWWA <-tapply((oWWA$speciesName), oWWA$coordID, list)

-->Question: Do you think I did this right and this didn't mess up the structure of the dataset? As far as I can see, I see no problem but I m not so experienced as you are!

.Yes, I think you found the problem.? It is always a good idea to use str() when reading in a csv file and even when doing data transformations with R as things can change in sometimes unexpected ways.

You might also want to look at "stringsAsFactors" which is either TRUE or FALSE.? For historical reasons, what I cannot remember, R often reads in repetitive strings as Factors rather than Characters.

Thank you very very much for your answers!!! It helped me a lot!!

-->second Question: I had problems with using dput(head(WWA)), because I think its still too big, so that I m not able to post all the output from "dput(head(WWA)))", even when i subsetted it first to only three rows:

> WWAsubset <-WWA[c(1:3),]
> dput(head(WWAsubset))

(see after str(WWA) and str(oWWA)

Yes you can set the number of lines of output with something like dput(head(dat1, 10)) which would output the first 10 lines of the data.frame dat1.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


?


From bawonpon at hotmail.com  Thu Jun 27 12:17:27 2013
From: bawonpon at hotmail.com (bawonpon chonipat)
Date: Thu, 27 Jun 2013 17:17:27 +0700
Subject: [R] LSD comparison
Message-ID: <BLU169-W86FA0A93737C3DCD21DC9BCB750@phx.gbl>

Dear Sir
 
I'm a student in the university and just start to use R for agricultural research analysis.
I know my question is an old question, but I don't find any clear explanation about  my problem via internet.
I'm sorry if my email is disturbing all of you.
 
I install R with version 3.0.1 and no problem with anova analysis, my problem is I can't perfprm LSD comparison, it is appearing "Error: could not find function "LSD.test"
I think I'm already installed "agricolae package" on my system. I attach some picture as shown on my screen.
if possible please guide me  how to solve the problem. (how to check if agricolae package is completely installed?)
 
Thanks you very much for reading
 
 		 	   		  

From y_refai at hotmail.com  Thu Jun 27 22:02:45 2013
From: y_refai at hotmail.com (Yasmine Refai)
Date: Thu, 27 Jun 2013 13:02:45 -0700
Subject: [R] Data Package Query
In-Reply-To: <1371725996.86004.YahooMailNeo@web122106.mail.ne1.yahoo.com>
References: <1371633615.23367.YahooMailNeo@web160101.mail.bf1.yahoo.com>
	<1371711263.96641.YahooMailNeo@web122105.mail.ne1.yahoo.com>
	<1371725996.86004.YahooMailNeo@web122106.mail.ne1.yahoo.com>
Message-ID: <DUB405-EAS306523EF12F1C6C0F82988D90750@phx.gbl>

Hello,

When i type in the below syntax:
Data (name of the data set)

I get an error message specifying that the "data" package is not found.

Please note that i installed all packages having the word "data"  included in them and loaded all these packages.

Please advice.

Regards!

From tcmuigai at gmail.com  Thu Jun 27 13:14:40 2013
From: tcmuigai at gmail.com (Charles Thuo)
Date: Thu, 27 Jun 2013 14:14:40 +0300
Subject: [R] "actuar" package query.
Message-ID: <CAAJc=rM2sBBOVpkFeFKfVSL7+Du4s0F7Y7ifZc7UciYwLc=jaQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130627/fc8f32c7/attachment.pl>

From meesters at aesku-kipp.com  Thu Jun 27 13:47:45 2013
From: meesters at aesku-kipp.com (Meesters, Aesku.Kipp Institute)
Date: Thu, 27 Jun 2013 11:47:45 +0000
Subject: [R] Change font size in Cluster analysis
In-Reply-To: <9A0C15FE-41B9-4F79-9DAA-CB1C39272BCF@hum-gen.au.dk>
References: <9A0C15FE-41B9-4F79-9DAA-CB1C39272BCF@hum-gen.au.dk>
Message-ID: <2EDC7C2789E5934CAA9AF5E96A27F65C104D57FB@AESKU-EXCH01.AESKU.local>

Gitte, in addition to Brian Ripley's answer: Will you be able to read all those labels anyway? And: Have you considered using heatmap.2 (gplots package)? It's a little denser than your approach and lets you in control of the clustering function (defaults are the same as in your example). You would gain the option to display only those labels which you want to show.
________________________________________
From: r-help-bounces at r-project.org [r-help-bounces at r-project.org] on behalf of Gitte Brinch Andersen [GITTEBA at HUM-GEN.AU.DK]
Sent: 27 June 2013 12:12
To: r-help at r-project.org
Subject: [R] Change font size in Cluster analysis

Hello

I have done a cluster analysis, and I would like to change the font size of my sample names. I have tried using cex, but this doesn't work/change anything. I have tried to specify it with cex.main, cex.lab, cex.axis and cex.sub, and can change all other names in the picture but my sample names.
I can't see what I am doing wrong.

I hope somebody can help me, and I apologize for this probably very simple question/mistake.

I have around 1000 rows and 50 columns, but have only included a few in my example.

Thank you in advance!

Kind regards

Gitte Andersen


#Read in data
data<-read.table("/Users/gban/Desktop/Heatmap/Heatmap with selected genes/Probes_for_heatmap_35_meth_diff_both_hypo_and_hypermeth_Gene&probenames.txt",sep="\t",dec=",",header=TRUE,row.names=1)

data
                                  OS_Tumor1_08_14985_2_3 OS_Tumor2_08_226869_1
CHST3_cg04268405_1                            0.95038060            0.76433753
DLX5_cg19962750_2                             0.93111825            0.75384523
ZIC4_cg12892506_3                             0.86033747            0.69614933
DLX5_cg05597836_4                             0.90698171            0.66414891



#Turn the data into a matrix, and transpose to get the columns to be clustered
Data_matrix<-as.matrix(t(data))

Data_matrix
                            CHST3_cg04268405_1 DLX5_cg19962750_2
OS_Tumor1_08_14985_2_3               0.9503806         0.9311183
OS_Tumor2_08_226869_1                0.7643375         0.7538452
OS_Tumor3_10_201917_2_3              0.7109182         0.7778035
OS_Tumor4_00_2395                    0.7772400         0.6769241
OS_Tumor5_02_2669                    0.9638739         0.9023436
OS_Tumor6_02_4738                    0.9028490         0.9586764
OS_Tumor7_02_4850                    0.8786524         0.8872261
OS_Tumor8_02_6935                    0.8434550         0.7180251
OS_Tumor9_03_1430                    0.7494400         0.9190213
OS_Tumor10_03_1701                   0.9148253         0.7692125
OS_Tumor11_03_220                    0.9270112         0.8607459
OS_Tumor12_03_2558                   0.9344832         0.5013390
OS_Tumor13_03_373                    0.9549153         0.9559071
OS_Tumor14_03_82                     0.9117558         0.3993953
OS_Tumor15_06_22319                  0.9580999         0.9645215
OS_Tumor16_07_16581                  0.6213243         0.9033265
OS_Tumor17_07_28523                  0.9064597         0.4421651
OS_Tumor18_07_3212                   0.6439032         0.4344106
OS_Tumor19_07_6990                   0.9350585         0.9238712
OS_Tumor20_07_6990sample2            0.9526839         0.9027684
OS_Tumor21_07_7724                   0.9338156         0.8335415
OS_Tumor22_08_10238                  0.9028336         0.8529122
OS_Tumor23_08_14985Sample2           0.9609952         0.9478541
OS_Tumor24_08_16592                  0.9168102         0.9138002
OS_Tumor25_08_21197                  0.9148711         0.9109843
OS_Tumor26_08_21197Sample2           0.9583610         0.8830407
OS_Tumor27_08_222863                 0.9478853         0.8395278
OS_Tumor28_08_225814                 0.9451414         0.9407933
OS_Tumor29_08_226869Sample2          0.9028336         0.8337000
OS_Tumor30_08_230660                 0.9599117         0.9363075
OS_Tumor31_08_4485                   0.8247909         0.8336728
OS_Tumor32_09_214654                 0.9531564         0.8957473
OS_Tumor33_09_214654Sample2          0.9552210         0.9034464
OS_Tumor34_10_200150                 0.9332627         0.8551589
OS_Tumor35_10_201917                 0.9397219         0.9470733
OS_Tumor36_10_201917Sample2          0.9607446         0.9523402
OS_Tumor37_10_202221                 0.9264254         0.9413189
OS_Tumor38_10_204294                 0.8388658         0.8956207
OS_Tumor39_10_204294Sample2          0.8071109         0.8474199
OS_Tumor40_10_205933                 0.8788835         0.4950936
OS_Tumor41_10_225662                 0.9334545         0.8910134
OS_Tumor42_10_229129                 0.5872184         0.8394597
OS_Tumor43_11_236261                 0.9015548         0.9293858
OS_Tumor44_12_211561                 0.6793692         0.1856015
Normalbone.3.                        0.1636323         0.1222070
Normalbone.UA.                       0.1934500         0.1303734
Normalbone.UA2.                      0.1737224         0.1604758
CRL_11372                            0.9779593         0.2533844
CRL_1427                             0.9598825         0.8862426
CRL_1543                             0.9283976         0.7198934
CRL_2098                             0.9325895         0.6360936
Ho_f.4610                            0.9370865         0.6279557
HTB_85                               0.9441092         0.1037401
HTB_96                               0.9511175         0.9160013
                            ZIC4_cg12892506_3 DLX5_cg05597836_4
OS_Tumor1_08_14985_2_3             0.86033747        0.90698171
OS_Tumor2_08_226869_1              0.69614933        0.66414891
OS_Tumor3_10_201917_2_3            0.58728927        0.65086446
OS_Tumor4_00_2395                  0.41747130        0.45464648
OS_Tumor5_02_2669                  0.74259213        0.88244165
OS_Tumor6_02_4738                  0.79690018        0.93691928
OS_Tumor7_02_4850                  0.05513471        0.91753824
OS_Tumor8_02_6935                  0.70742299        0.77802530
OS_Tumor9_03_1430                  0.84563086        0.87202952
OS_Tumor10_03_1701                 0.81318017        0.72446802
OS_Tumor11_03_220                  0.72489087        0.80580733
OS_Tumor12_03_2558                 0.06656780        0.14739011
OS_Tumor13_03_373                  0.94011867        0.95742989
OS_Tumor14_03_82                   0.52129769        0.54734874
OS_Tumor15_06_22319                0.93025191        0.94392535
OS_Tumor16_07_16581                0.67236887        0.88546907
OS_Tumor17_07_28523                0.25764851        0.45550666
OS_Tumor18_07_3212                 0.33624514        0.18623351
OS_Tumor19_07_6990                 0.82904776        0.88946081
OS_Tumor20_07_6990sample2          0.76836030        0.82519665
OS_Tumor21_07_7724                 0.90314315        0.71810973
OS_Tumor22_08_10238                0.83715782        0.86426252
OS_Tumor23_08_14985Sample2         0.82588214        0.90655043
OS_Tumor24_08_16592                0.77582828        0.83500490
OS_Tumor25_08_21197                0.90274785        0.96119490
OS_Tumor26_08_21197Sample2         0.87385578        0.83341529
OS_Tumor27_08_222863               0.72588195        0.59849569
OS_Tumor28_08_225814               0.87931232        0.89657489
OS_Tumor29_08_226869Sample2        0.86379063        0.88825605
OS_Tumor30_08_230660               0.92495563        0.95137547
OS_Tumor31_08_4485                 0.84465179        0.66948504
OS_Tumor32_09_214654               0.92036441        0.71915709
OS_Tumor33_09_214654Sample2        0.93955431        0.46490552
OS_Tumor34_10_200150               0.80337813        0.82519665
OS_Tumor35_10_201917               0.87734686        0.91265824
OS_Tumor36_10_201917Sample2        0.93627004        0.94319232
OS_Tumor37_10_202221               0.93107776        0.96075927
OS_Tumor38_10_204294               0.85892154        0.94595920
OS_Tumor39_10_204294Sample2        0.69839075        0.76396555
OS_Tumor40_10_205933               0.25850129        0.43418918
OS_Tumor41_10_225662               0.71442683        0.88154146
OS_Tumor42_10_229129               0.42328977        0.77763541
OS_Tumor43_11_236261               0.82946721        0.87242385
OS_Tumor44_12_211561               0.84785994        0.12366988
Normalbone.3.                      0.06840225        0.08229536
Normalbone.UA.                     0.07383344        0.12502117
Normalbone.UA2.                    0.07741817        0.09563505
CRL_11372                          0.05409689        0.13815797
CRL_1427                           0.91730069        0.92421230
CRL_1543                           0.77789918        0.94650563
CRL_2098                           0.91524115        0.50725942
Ho_f.4610                          0.05736418        0.51843963
HTB_85                             0.95464468        0.05260867
HTB_96                             0.88410529        0.92872206


#Calculate the distance
Data_dist<-dist(Data_matrix)

#Make the cluster
Data_clust<-hclust(Data_dist,method="ward")

#Save the plot as a pdf file
pdf(file="Cluster_Probes_From_genes_morethan_2_probes_and_morethan_30_methdiff.pdf")

#Plot the cluster
plot(Data_clust, cex=0.5)

dev.off() #Ends the pdf saving.

Gitte Brinch Andersen

Kandidat-Ph.d. studerende
Biomedicinsk Institut
Wilhelm Meyers All? 4
Aarhus Universitet
DK-8000 Aarhus C

Mobil: +45 30433317
E-mail: gitteba at hum-gen.au.dk<mailto:gitteba at hum-gen.au.dk>



        [[alternative HTML version deleted]]



From zhaoran1124 at gmail.com  Thu Jun 27 13:57:48 2013
From: zhaoran1124 at gmail.com (Zhaoran Zhou)
Date: Thu, 27 Jun 2013 14:57:48 +0300
Subject: [R] are there any package for clustering the microarray data?
Message-ID: <CAFtVAjF1hFkdo=eGgXwmdBi30+SCrsuBZRKV_TQ57Tz6Ec=fZQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130627/7672b1ac/attachment.pl>

From billabong89 at web.de  Thu Jun 27 17:01:40 2013
From: billabong89 at web.de (Nico Bl)
Date: Thu, 27 Jun 2013 08:01:40 -0700 (PDT)
Subject: [R] combine attributes
Message-ID: <1372345300777-4670440.post@n4.nabble.com>

hello,

i have to do a sna for a seminar.

i have a csv.data with acteurs. i can identify a cooperation between acteurs
with an ID in the csc.data. 
Is the ID equal with another acteur, so they have an cooperation.

furthermore i have an information about the acteurs in the csv.data. there
are three types of acteurs in this network: an economy-acteur,
univeristy-acteur and techincal college-acteur.

Now i want to know, the percentage or the absolute number of the type of
cooperation between:
university to economy
university to technical college
university to university and
economy to technical college

in other words: which type of acteur cooperates with which type of acteur.

Can anybody help me? Iam a beginner with this programm and i need a step by
step entry / explanation for the correct r-codes.

Thanks!



--
View this message in context: http://r.789695.n4.nabble.com/combine-attributes-tp4670440.html
Sent from the R help mailing list archive at Nabble.com.


From rmh at temple.edu  Thu Jun 27 17:45:36 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 27 Jun 2013 11:45:36 -0400
Subject: [R] Data Package Query
In-Reply-To: <DUB405-EAS306523EF12F1C6C0F82988D90750@phx.gbl>
References: <1371633615.23367.YahooMailNeo@web160101.mail.bf1.yahoo.com>
	<1371711263.96641.YahooMailNeo@web122105.mail.ne1.yahoo.com>
	<1371725996.86004.YahooMailNeo@web122106.mail.ne1.yahoo.com>
	<DUB405-EAS306523EF12F1C6C0F82988D90750@phx.gbl>
Message-ID: <CAGx1TMCfTXDfBkomkboC25wk0ayLc=ttxwNRmYtj-rgaddPt4w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130627/b099a305/attachment.pl>

From dcarlson at tamu.edu  Thu Jun 27 18:03:17 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Thu, 27 Jun 2013 11:03:17 -0500
Subject: [R] Data Package Query
In-Reply-To: <DUB405-EAS306523EF12F1C6C0F82988D90750@phx.gbl>
References: <1371633615.23367.YahooMailNeo@web160101.mail.bf1.yahoo.com>	<1371711263.96641.YahooMailNeo@web122105.mail.ne1.yahoo.com>	<1371725996.86004.YahooMailNeo@web122106.mail.ne1.yahoo.com>
	<DUB405-EAS306523EF12F1C6C0F82988D90750@phx.gbl>
Message-ID: <084201ce734f$d64e0110$82ea0330$@tamu.edu>

You need to copy the lines you have typed in to R and send them
exactly. The only way I get an error message like the one you
indicate is with the following:

> library(data)
Error in library(data) : there is no package called 'data'
>

There is no Data function in R so if you typed that you would get

> Data(Titanic)
Error: could not find function "Data"

So what did you really type?

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Yasmine Refai
Sent: Thursday, June 27, 2013 3:03 PM
To: r-help at R-project.org
Subject: [R] Data Package Query

Hello,

When i type in the below syntax:
Data (name of the data set)

I get an error message specifying that the "data" package is not
found.

Please note that i installed all packages having the word "data"
included in them and loaded all these packages.

Please advice.

Regards!
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From h.wickham at gmail.com  Thu Jun 27 17:32:08 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 27 Jun 2013 17:32:08 +0200
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED4AC9F091C5@GOLD.corp.lgc-group.com>
References: <51C8CBCE.3040903@gmail.com> <1372123341449.dc8da696@Nodemailer>
	<51C97A30.7050802@gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED4AC9F091C5@GOLD.corp.lgc-group.com>
Message-ID: <CABdHhvEtL0s87GSnn8MFyHtz2CdC-_65iJ6U19mfgs3YkYSC+A@mail.gmail.com>

> I too find R's lexical scoping rules straightforward.
> However, I'd say that if your code relies on lexical scoping to find something, you should probably rewrite your code.

Except of course that almost every function relies on lexical scoping
to some extent!

Do you want:

f <- function(a, b) a + b

or

f <- function(a, b, plus) plus(a, b)

?

;)

Hadley


--
Chief Scientist, RStudio
http://had.co.nz/


From keren at math.montana.edu  Thu Jun 27 18:07:15 2013
From: keren at math.montana.edu (ilai)
Date: Thu, 27 Jun 2013 10:07:15 -0600
Subject: [R] corrgram with two datasets
In-Reply-To: <2EDC7C2789E5934CAA9AF5E96A27F65C104D4FA9@AESKU-EXCH01.AESKU.local>
References: <2EDC7C2789E5934CAA9AF5E96A27F65C104D4FA9@AESKU-EXCH01.AESKU.local>
Message-ID: <CAK4FJ1CtL+jrstsrjzkQgk1PROt2_=fKqZWU7_aQK3hjAS28Xw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130627/ca48d960/attachment.pl>

From jrkrideau at inbox.com  Thu Jun 27 16:55:56 2013
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 27 Jun 2013 06:55:56 -0800
Subject: [R] XYZ data
In-Reply-To: <alpine.LRH.2.03.1306260914580.1649@ecy.wa.gov>
References: <05aa1fb4006.000011cbjrkrideau@inbox.com>
Message-ID: <11A81FB3AF8.00000A9Bjrkrideau@inbox.com>

You're right. I was in a hurry and misread the question

John Kane
Kingston ON Canada


> -----Original Message-----
> From: clint at ecy.wa.gov
> Sent: Wed, 26 Jun 2013 09:16:21 -0700 (PDT)
> To: jrkrideau at inbox.com
> Subject: Re: [R] XYZ data
> 
> John,
> 
> That still leaves a string of identical numbers in the vector.
> 
> Shane,
> 
> ?jitter
> 
> perhaps jitter(X,1,0.0001)
> 
> Clint
> 
> Clint Bowman			INTERNET:	clint at ecy.wa.gov
> Air Quality Modeler		INTERNET:	clint at math.utah.edu
> Department of Ecology		VOICE:		(360) 407-6815
> PO Box 47600			FAX:		(360) 407-7534
> Olympia, WA 98504-7600
> 
>          USPS:           PO Box 47600, Olympia, WA 98504-7600
>          Parcels:        300 Desmond Drive, Lacey, WA 98503-1274
> 
> On Wed, 26 Jun 2013, John Kane wrote:
> 
>> mm  <-  1:10
>> nn  <- mm + .001
>> 
>> John Kane
>> Kingston ON Canada
>> 
>> 
>>> -----Original Message-----
>>> From: careyshan at gmail.com
>>> Sent: Wed, 26 Jun 2013 16:48:34 +0100
>>> To: r-help at r-project.org
>>> Subject: [R] XYZ data
>>> 
>>> I have x, y, z data. The x, y fields dont change but Z does. How do I
>>> add
>>> a
>>> very small number onto the end of each x, y data point.
>>> 
>>> For example:
>>> 
>>> Original (X)              Original (Y)                 Original (Z)
>>> 15                               20                              30
>>> 15                               20                              40
>>> 
>>> 
>>> 
>>> 
>>> New (X)              New (Y)                 New (Z)
>>> 15.00001             20.000001              30
>>> 15.00002             20.000002              40
>>> 
>>> 
>>> Thanks
>>> --
>>> Shane
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ____________________________________________________________
>> FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From ruipbarradas at sapo.pt  Thu Jun 27 18:43:46 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 27 Jun 2013 17:43:46 +0100
Subject: [R] LSD comparison
In-Reply-To: <BLU169-W86FA0A93737C3DCD21DC9BCB750@phx.gbl>
References: <BLU169-W86FA0A93737C3DCD21DC9BCB750@phx.gbl>
Message-ID: <51CC6BC2.1020800@sapo.pt>

Hello,

After installing the package (just once) you have to load it in the R
session (every time you start a session that will use it.) You do this 
with the following command.

library(agricolae)  # load the package

Hope this helps,

Rui Barradas

Em 27-06-2013 11:17, bawonpon chonipat escreveu:
> Dear Sir
>
> I'm a student in the university and just start to use R for agricultural research analysis.
> I know my question is an old question, but I don't find any clear explanation about  my problem via internet.
> I'm sorry if my email is disturbing all of you.
>
> I install R with version 3.0.1 and no problem with anova analysis, my problem is I can't perfprm LSD comparison, it is appearing "Error: could not find function "LSD.test"
> I think I'm already installed "agricolae package" on my system. I attach some picture as shown on my screen.
> if possible please guide me  how to solve the problem. (how to check if agricolae package is completely installed?)
>
> Thanks you very much for reading
>
>   		 	   		
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.CA.us  Thu Jun 27 18:47:06 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 27 Jun 2013 09:47:06 -0700
Subject: [R] Data Package Query
In-Reply-To: <DUB405-EAS306523EF12F1C6C0F82988D90750@phx.gbl>
References: <1371633615.23367.YahooMailNeo@web160101.mail.bf1.yahoo.com>
	<1371711263.96641.YahooMailNeo@web122105.mail.ne1.yahoo.com>
	<1371725996.86004.YahooMailNeo@web122106.mail.ne1.yahoo.com>
	<DUB405-EAS306523EF12F1C6C0F82988D90750@phx.gbl>
Message-ID: <a12164e5-fef5-4963-8159-e891210e7dbc@email.android.com>

"data" is a base function (so you should not have to load any packages to use it), and it is not capitalized. Depending on the particular data set you want the data function to load, you may need to load the package that contains that data set.

A common error by beginners (which may or may not be your problem in this case) is to create a variable called "data". Unfortunately this hides the function named "data" and from that time forward that R session doesn't work when you type example code that uses the data function. If this is your problem, the best solution is to restart R and do your analysis from the beginning using a different variable name than "data". (This is why keeping your working code in a separate text file is standard operating procedure.)

Note that I am guessing here... the Posting Guide asks you to give a reproducible example so we don't have to guess what you have done.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Yasmine Refai <y_refai at hotmail.com> wrote:

>Hello,
>
>When i type in the below syntax:
>Data (name of the data set)
>
>I get an error message specifying that the "data" package is not found.
>
>Please note that i installed all packages having the word "data" 
>included in them and loaded all these packages.
>
>Please advice.
>
>Regards!
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bt_jannis at yahoo.de  Thu Jun 27 19:26:40 2013
From: bt_jannis at yahoo.de (Jannis)
Date: Thu, 27 Jun 2013 19:26:40 +0200
Subject: [R] multivariate version of aggregate
Message-ID: <51CC75D0.2010605@yahoo.de>

Dear List members,


i am seeking a multivariate version of aggregate. I want to compute, fro 
example the correlation between subsets of two vectors. In aggregate, i 
can only supply one vector with indices for subsets. Is  there ready 
function for this or do i need to program my own?


Cheers
Jannis


From dwinsemius at comcast.net  Thu Jun 27 19:46:41 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 27 Jun 2013 10:46:41 -0700
Subject: [R] "actuar" package query.
In-Reply-To: <CAAJc=rM2sBBOVpkFeFKfVSL7+Du4s0F7Y7ifZc7UciYwLc=jaQ@mail.gmail.com>
References: <CAAJc=rM2sBBOVpkFeFKfVSL7+Du4s0F7Y7ifZc7UciYwLc=jaQ@mail.gmail.com>
Message-ID: <0BAE687B-A6DE-4C1C-AE35-EFE292C60A00@comcast.net>


On Jun 27, 2013, at 4:14 AM, Charles Thuo wrote:

> I run the following in the "actuar" package  while trying to discretize the
> lognormal distribution  which i had fitted using the "fitdistrplus" package.
> 
> fx <- discretize(plnorm(11.69,2.1),from = 0, to = 22, step = 0.5, method =
> "upper")
> Error in discretize(plnorm(11.69, 2.1), from = 0, to = 22, step = 0.5,  :
>  'cdf' must be a function or an expression containing 'x'
> 
> Because of this error am unable to fit a compound distribution between the
> negative binomial and lognormal.  Is there another way besides using
> "actuar".

The error is being thrown because you are not calling discretize with a function as its first argument. You are giving it a single value. 
 Try:

fx <- discretize( plnorm( x , 2.1), from = 0, to = 22, step = 0.5, method ="upper")

You could also continue to emulate the first example on help(discretize)

library(actuar)
x <- seq(0, 22, 0.5)
fu <- discretize(plnorm(x, 2.1), from = 0, to = 22, step = 0.5, method ="upper")
fl <- discretize(plnorm(x, 2.1), from = 0, to = 22, step = 0.5, method ="lower")
curve(plnorm(x, 2.1), xlim = c(0, 22))
par(col = "blue")
plot(stepfun(head(x, -1), diffinv(fu)), pch = 19, add = TRUE)
par(col = "green")
plot(stepfun(x, diffinv(fl)), pch = 19, add = TRUE)
par(col = "black")

> I have just started using actuar. Kindly assist.

Nothing to do with 'actuar' per se. The same error would ahveoccured with any R function that expects a function as its first argument.

-- 

David Winsemius
Alameda, CA, USA


From smartpink111 at yahoo.com  Thu Jun 27 19:47:56 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 27 Jun 2013 10:47:56 -0700 (PDT)
Subject: [R] multiple csv files for T-test
In-Reply-To: <1372342632.22771.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1372342632.22771.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1372355276.21134.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
I used as.data.frame(matrix(...)) just to create an example dataset.? In your case, you don't need to do that.? Using the same example:

set.seed(24)
dat1<- as.data.frame(matrix(sample(20:40,40,replace=TRUE),ncol=4))
set.seed(285)
dat2<- as.data.frame(matrix(sample(35:60,40,replace=TRUE),ncol=4))

write.csv(dat1,"file1.csv",row.names=FALSE)
write.csv(dat2,"file2.csv",row.names=FALSE)
data1<- read.csv("file1.csv")
data2<- read.csv("file2.csv")

###Your code:
?dat1New<- as.data.frame(matrix(data1))? 
?dat2New<- as.data.frame(matrix(data2)) 
###It is always useful to check ?str() 


str(dat1New)
#'data.frame':??? 4 obs. of? 1 variable:
# $ V1:List of 4
?# ..$ : int? 26 24 34 30 33 39 25 36 36 25
? #..$ : int? 32 27 34 34 26 38 24 20 30 22
?# ..$ : int? 21 31 35 22 24 34 21 32 33 20
?#..$ : int? 26 25 27 23 39 24 35 33 34 40



?dat1New
#????????????????????????????????????? V1
#1 26, 24, 34, 30, 33, 39, 25, 36, 36, 25
#2 32, 27, 34, 34, 26, 38, 24, 20, 30, 22
#3 21, 31, 35, 22, 24, 34, 21, 32, 33, 20
#4 26, 25, 27, 23, 39, 24, 35, 33, 34, 40
?dat2New
#????????????????????????????????????? V1
#1 53, 40, 47, 57, 57, 53, 35, 42, 53, 41
#2 54, 37, 43, 40, 57, 42, 37, 53, 60, 39
#3 54, 60, 46, 50, 35, 41, 58, 45, 36, 53
#4 52, 56, 44, 40, 38, 53, 47, 46, 60, 50
?sapply(colnames(dat1New),function(i) t.test(dat1New[,i],dat2New[,i],paired=TRUE)$p.value) 
#Error in x - y : non-numeric argument to binary operator


##Just using data1 and data2

sapply(colnames(data1),function(i) t.test(data1[,i],data2[,i],paired=TRUE)$p.value) 
#????????? V1?????????? V2?????????? V3?????????? V4 
#3.202629e-05 6.510644e-04 6.215225e-04 3.044760e-04 


#or using dat1New and dat2New
sapply(seq_along(dat1New$V1),function(i) t.test(dat1New$V1[[i]],dat2New$V1[[i]],paired=TRUE)$p.value)
#[1] 3.202629e-05 6.510644e-04 6.215225e-04 3.044760e-04



A.K.



thanks for the reply, I am getting the following error 
Error in x - y : non-numeric argument to binary operator 

This is what I enter below 

> data1 <-read.csv("file1.csv") 
> data2 <-read.csv("file2.csv") 
> dat1<- as.data.frame(matrix(data1)) 
> dat2<- as.data.frame(matrix(data2)) 
> sapply(colnames(dat1),function(i) t.test(dat1[,i],dat2[,i],paired=TRUE)$p.value) 

As far as I can see all my values are numeric...? 


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Thursday, June 27, 2013 10:17 AM
Subject: Re: multiple csv files for T-test

Hi,
May be this helps:
#You can use ?read.csv() to read the two files.

set.seed(24)
dat1<- as.data.frame(matrix(sample(20:40,40,replace=TRUE),ncol=4))
set.seed(285)
dat2<- as.data.frame(matrix(sample(35:60,40,replace=TRUE),ncol=4))
sapply(colnames(dat1),function(i) t.test(dat1[,i],dat2[,i],paired=TRUE)$p.value)
#????????? V1?????????? V2?????????? V3?????????? V4 
#3.202629e-05 6.510644e-04 6.215225e-04 3.044760e-04 

A.K.

Hi 
I am fairly new to R so if this is a stupid question please forgive me. 

I have a CSV file with multiple parameters (50). ?I have another
CSV file with the same parameters after treatment. ?Is there a way I 
can read these two files into R and do multiple paired T-test as all the
parameters are in the same columns in each file? 

Thanks in advance


From dcarlson at tamu.edu  Thu Jun 27 20:23:36 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Thu, 27 Jun 2013 13:23:36 -0500
Subject: [R] Data Package Query
In-Reply-To: <DUB118-DS14C88AAABD5F3F04A0B3B390750@phx.gbl>
References: <DUB118-DS14C88AAABD5F3F04A0B3B390750@phx.gbl>
Message-ID: <087901ce7363$702a4ce0$507ee6a0$@tamu.edu>

You can specify a package that exists, for example, datasets. You
can use the data() function instead of the Data() function which
does not exist. You could read one of the many, fine tutorials about
R:

http://cran.r-project.org/other-docs.html

David

-----Original Message-----
From: Yasmine Refai [mailto:y_refai at hotmail.com] 
Sent: Thursday, June 27, 2013 11:11 AM
To: David Carlson 
Subject: Re: [R] Data Package Query

The same lines as what you typed below and I am getting the same
error as what you mentioned below. So what I can do to overcome that
problem?
Sent using BlackBerryR from mobinil

-----Original Message-----
From: David Carlson <dcarlson at tamu.edu>
Date: Thu, 27 Jun 2013 16:03:17 
To: <y_refai at hotmail.com>; <r-help at r-project.org>
Subject: RE: [R] Data Package Query


You need to copy the lines you have typed in to R and send them
exactly. The only way I get an error message like the one you
indicate is with the following:

> library(data)
Error in library(data) : there is no package called 'data'
>

There is no Data function in R so if you typed that you would get

> Data(Titanic)
Error: could not find function "Data"

So what did you really type?

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Yasmine Refai
Sent: Thursday, June 27, 2013 3:03 PM
To: r-help at R-project.org
Subject: [R] Data Package Query

Hello,

When i type in the below syntax:
Data (name of the data set)

I get an error message specifying that the "data" package is not
found.

Please note that i installed all packages having the word "data"
included in them and loaded all these packages.

Please advice.

Regards!
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From anika.masters at gmail.com  Thu Jun 27 20:26:07 2013
From: anika.masters at gmail.com (Anika Masters)
Date: Thu, 27 Jun 2013 11:26:07 -0700
Subject: [R] when to use & pros/cons of dataframe vs. matrix?
Message-ID: <CAOQRPaas0YJ1XvKTaRj7d5G1osWMiWR8RCnq55p1B_3R1rtK5A@mail.gmail.com>

When "should" I use a dataframe vs. a matrix?  What are the pros and cons?
If I have data of all the same type, am I usually better off using a
matrix and not a dataframe?
What are the advantages if any of using a dataframe vs. a matrix?
(rownames and column names perhaps?)


From dmck at u.washington.edu  Thu Jun 27 20:32:54 2013
From: dmck at u.washington.edu (Don McKenzie)
Date: Thu, 27 Jun 2013 11:32:54 -0700
Subject: [R] when to use & pros/cons of dataframe vs. matrix?
In-Reply-To: <CAOQRPaas0YJ1XvKTaRj7d5G1osWMiWR8RCnq55p1B_3R1rtK5A@mail.gmail.com>
References: <CAOQRPaas0YJ1XvKTaRj7d5G1osWMiWR8RCnq55p1B_3R1rtK5A@mail.gmail.com>
Message-ID: <34DE058D-65AF-4DD0-9AF6-1AD467A46DBA@u.washington.edu>

Anika -- these are good questions and many on the list could  
expatiate on them.  These erudite people are also busy, however, and  
that is why the R-news posting guide suggests that you study an  
introductory book on R before asking general questions.

On 27-Jun-13, at 11:26 AM, Anika Masters wrote:

> When "should" I use a dataframe vs. a matrix?  What are the pros  
> and cons?
> If I have data of all the same type, am I usually better off using a
> matrix and not a dataframe?
> What are the advantages if any of using a dataframe vs. a matrix?
> (rownames and column names perhaps?)
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html
> and provide commented, minimal, self-contained, reproducible code.





Don McKenzie, Research Ecologist
Pacific Wildland Fire Sciences Lab
US Forest Service
phone: 206-732-7824

Affiliate Professor
School of Environmental and Forest Sciences
University of Washington


From smartpink111 at yahoo.com  Thu Jun 27 20:41:11 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 27 Jun 2013 11:41:11 -0700 (PDT)
Subject: [R] when to use & pros/cons of dataframe vs. matrix?
In-Reply-To: <CAOQRPaas0YJ1XvKTaRj7d5G1osWMiWR8RCnq55p1B_3R1rtK5A@mail.gmail.com>
References: <CAOQRPaas0YJ1XvKTaRj7d5G1osWMiWR8RCnq55p1B_3R1rtK5A@mail.gmail.com>
Message-ID: <1372358471.34081.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
set.seed(24)
dat1<-data.frame(X=sample(letters,20,replace=TRUE),Y=sample(1:40,20,replace=TRUE),stringsAsFactors=FALSE)
mat1<-as.matrix(dat1)
?sapply(dat1,class)
#????????? X?????????? Y 
#"character"?? "integer" 

sapply(split(mat1,col(mat1)),class)
#????????? 1?????????? 2 
#"character" "character" 
str(as.data.frame(mat1))
#'data.frame':??? 20 obs. of? 2 variables:
# $ X: Factor w/ 14 levels "b","d","f","g",..: 5 3 11 8 10 14 5 12 13 4 ...
# $ Y: Factor w/ 14 levels "10","13","15",..: 12 5 9 13 14 8 12 6 7 4 ...

If you have data of the same type, matrix would be faster when compared to data.frame.
set.seed(245)
mat2<- matrix(sample(1:50,3*1e7,replace=TRUE),ncol=3)

dat2<- as.data.frame(mat2)
system.time(res1<- rowSums(mat2))
#?? user? system elapsed 
#? 0.132?? 0.016?? 0.201 
?system.time(res2<- rowSums(dat2))
#?? user? system elapsed 
#? 0.376?? 0.056?? 0.447 
?identical(res1,res2)
#[1] TRUE


A.K.



----- Original Message -----
From: Anika Masters <anika.masters at gmail.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Thursday, June 27, 2013 2:26 PM
Subject: [R] when to use & pros/cons of dataframe vs. matrix?

When "should" I use a dataframe vs. a matrix?? What are the pros and cons?
If I have data of all the same type, am I usually better off using a
matrix and not a dataframe?
What are the advantages if any of using a dataframe vs. a matrix?
(rownames and column names perhaps?)

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From anika.masters at gmail.com  Thu Jun 27 21:00:30 2013
From: anika.masters at gmail.com (Anika Masters)
Date: Thu, 27 Jun 2013 12:00:30 -0700
Subject: [R] using "rollapply" to calculate a moving sum or running sum?
Message-ID: <CAOQRPaYHFuy42bC+ge5oVgYBLxHgf-9_znCdX9bbgOCkKG9ucw@mail.gmail.com>

#using "rollapply" to calculate a moving sum or running sum?

#I am tryign to use rollapply to calcualte a moving sum? #I tried
rollapply and get the error message
#"Error in seq.default(start.at, NROW(data), by = by) :
#  wrong sign in 'by' argument"

#example:

mymatrix <- ( matrix(data=1:100, nrow=5, ncol=20) )
mymatrix_cumsum  <- ( matrix(data=NA, nrow=5, ncol=20) )
w=12
for(i in 1: (ncol(mymatrix)-w+1) ) {
mymatrix_cumsum[ , i]  <- apply(X=mymatrix[, i:(i+w-1)] , MARGIN=1,
FUN=sum, na.rm=T)
}

#How might I use the "rollapply" function instead?

rollapply(mymatrix, 12, sum)

rollapply(data = mymatrix, width = 12, FUN=sum, by.column =T, fill =
NA, partial = FALSE, align = "left" )


From spencer.graves at structuremonitoring.com  Thu Jun 27 21:14:47 2013
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Thu, 27 Jun 2013 12:14:47 -0700
Subject: [R] Write an Excel workbook?
Message-ID: <51CC8F27.60200@structuremonitoring.com>

Hello:


Is there a fully transportable way to write an Excel workbook?


The "writeFindFn2xls" function in the "sos" package attempts to write 
search results to an Excel workbook consisting of (1) a summary of the 
packages identified in the search, (2) the individual help pages found, 
and (3) the search that produced 1 and 2. Unfortunately, for some time 
now, it only works with 32-bit R; the 64-bit R writes this information 
to three separate csv files.


The current code first tries WriteXLS{WriteXLS}. Unfortunately, this 
fails on my computer, because it can't find the Perl module 
"Text::CSV_XS". I don't see an easy fix to this.


If WriteXLS fails, the code then tries odbcConnectExcel{ODBC}. From 
this, I get, "odbcConnectExcel is only usable with 32-bit Windows". 
That's OK, but it means that I need to run all my searches on 32-bit R, 
and I usually use 64-bit R.


I tried write.xls{dataframes2xls}. This put quotes around everything, 
which I found unacceptable.


findFn('write.xls') identified a function by that name in the "marray" 
package. Unfortunately, install.packages("marray") produced, "Warning 
message: package ?marray? is not available (for R version 3.0.1)" 
"???xls" failed to produce anything else that looked to me like it would 
write a complete workbook.


Suggestions?
Thanks,
Spencer Graves


 > sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats graphics grDevices utils datasets methods base

other attached packages:
[1] RODBC_1.3-6 WriteXLS_2.3.1 sos_1.3-7 brew_1.0-6


From dcarlson at tamu.edu  Thu Jun 27 21:22:09 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Thu, 27 Jun 2013 14:22:09 -0500
Subject: [R] multivariate version of aggregate
In-Reply-To: <51CC75D0.2010605@yahoo.de>
References: <51CC75D0.2010605@yahoo.de>
Message-ID: <087b01ce736b$9e1c1ae0$da5450a0$@tamu.edu>

You can pass a matrix to by()

> set.seed(42)
> dat <- data.frame(x=runif(50)*20, y=runif(50)*20,
g=rep(LETTERS[1:2], each=25))
> as.vector(by(dat[,1:2], dat$g, function(x) cor(x)[1,2]))
[1] -0.05643063  0.16465040

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Jannis
Sent: Thursday, June 27, 2013 12:27 PM
To: r-help
Subject: [R] multivariate version of aggregate

Dear List members,


i am seeking a multivariate version of aggregate. I want to compute,
fro 
example the correlation between subsets of two vectors. In
aggregate, i 
can only supply one vector with indices for subsets. Is  there ready

function for this or do i need to program my own?


Cheers
Jannis

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From djandrija at gmail.com  Thu Jun 27 21:37:09 2013
From: djandrija at gmail.com (andrija djurovic)
Date: Thu, 27 Jun 2013 21:37:09 +0200
Subject: [R] Write an Excel workbook?
In-Reply-To: <51CC8F27.60200@structuremonitoring.com>
References: <51CC8F27.60200@structuremonitoring.com>
Message-ID: <CABcwgRTGLHomdyEvY2UbLUjGGnJ9OUwLcoyr1Yqj3ViAyPBMNw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130627/1a3e193a/attachment.pl>

From 538280 at gmail.com  Thu Jun 27 21:43:43 2013
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 27 Jun 2013 13:43:43 -0600
Subject: [R] multivariate version of aggregate
In-Reply-To: <51CC75D0.2010605@yahoo.de>
References: <51CC75D0.2010605@yahoo.de>
Message-ID: <CAFEqCdzxzY+W2o=xSp=i9nPODbvaKE4E3rxazPMyq9DTbUZoGg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130627/b4cd3ad8/attachment.pl>

From smartpink111 at yahoo.com  Thu Jun 27 20:05:05 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 27 Jun 2013 11:05:05 -0700 (PDT)
Subject: [R] LSD comparison
Message-ID: <1372356305.29901.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,Without any reproducible example or code, it is difficult to understand the problem.? Did you load the package?
Using the example in ?LSD.test()
library(agricolae)
data(sweetpotato)
????? model<-aov(yield~virus, data=sweetpotato)
????? out <- LSD.test(model,"virus", p.adj="bonferroni",
????? main="Yield of sweetpotato\ndealt with different virus")

Study: Yield of sweetpotato
dealt with different virus

LSD t Test for yield 
P value adjustment method: bonferroni 

Mean Square Error:? 22.48917 

virus,? means and individual ( 95 %) CI

????? yield? std.err r?????? LCL????? UCL Min. Max.
cc 24.40000 2.084067 3 19.594134 29.20587 21.7 28.5
fc 12.86667 1.246774 3? 9.991602 15.74173 10.6 14.9
ff 36.33333 4.233727 3 26.570341 46.09633 28.0 41.8
oo 36.90000 2.482606 3 31.175100 42.62490 32.1 40.4

alpha: 0.05 ; Df Error: 8
Critical Value of t: 3.478879 

Least Significant Difference 13.4704
Means with the same letter are not significantly different.

Groups, Treatments and means
a ??? ?oo ??? ?36.9 
a ??? ?ff ??? ?36.33 
ab ??? ?cc ??? ?24.4 
b ??? ?fc ??? ?12.87 

sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
?[1] LC_CTYPE=en_CA.UTF-8?????? LC_NUMERIC=C????????????? 
?[3] LC_TIME=en_CA.UTF-8??????? LC_COLLATE=en_CA.UTF-8??? 
?[5] LC_MONETARY=en_CA.UTF-8??? LC_MESSAGES=en_CA.UTF-8?? 
?[7] LC_PAPER=C???????????????? LC_NAME=C???????????????? 
?[9] LC_ADDRESS=C?????????????? LC_TELEPHONE=C??????????? 
[11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C?????? 

attached base packages:
[1] stats???? graphics? grDevices utils???? datasets? methods?? base???? 

other attached packages:
[1] agricolae_1.1-4 stringr_0.6.2?? reshape2_1.2.2 

loaded via a namespace (and not attached):
[1] plyr_1.8??? tcltk_3.0.1 tools_3.0.1

A.K.


Dear Sir 
? 
I'm a student in the university and just start to use R for agricultural research analysis. 
I know my question is an old question, but I don't find any clear explanation about ?my problem via internet. 
I'm sorry if my email is disturbing all of you. 
? 
I install R with version 3.0.1 and no problem with anova analysis, 
my problem is I can't perfprm LSD comparison, it is appearing "Error: 
could not find function "LSD.test" 
I think I'm already installed "agricolae package" on my system. I attach some picture as shown on my screen. 
if possible please guide me ?how to solve the problem. (how to check if agricolae package is completely installed?) 
? 
Thanks you very much for reading


From ruipbarradas at sapo.pt  Thu Jun 27 21:51:08 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 27 Jun 2013 20:51:08 +0100
Subject: [R] multivariate version of aggregate
In-Reply-To: <087b01ce736b$9e1c1ae0$da5450a0$@tamu.edu>
References: <51CC75D0.2010605@yahoo.de>
	<087b01ce736b$9e1c1ae0$da5450a0$@tamu.edu>
Message-ID: <51CC97AC.4010903@sapo.pt>

Hello,

Or use ?sapply.

sapply(split(dat[1:2], dat[3]), function(x) cor(x[1], x[2]))


Hope this helps,

Rui Barradas

Em 27-06-2013 20:22, David Carlson escreveu:
> You can pass a matrix to by()
>
>> set.seed(42)
>> dat <- data.frame(x=runif(50)*20, y=runif(50)*20,
> g=rep(LETTERS[1:2], each=25))
>> as.vector(by(dat[,1:2], dat$g, function(x) cor(x)[1,2]))
> [1] -0.05643063  0.16465040
>
> -------------------------------------
> David L Carlson
> Associate Professor of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: r-help-bounces at r-project.org
> [mailto:r-help-bounces at r-project.org] On Behalf Of Jannis
> Sent: Thursday, June 27, 2013 12:27 PM
> To: r-help
> Subject: [R] multivariate version of aggregate
>
> Dear List members,
>
>
> i am seeking a multivariate version of aggregate. I want to compute,
> fro
> example the correlation between subsets of two vectors. In
> aggregate, i
> can only supply one vector with indices for subsets. Is  there ready
>
> function for this or do i need to program my own?
>
>
> Cheers
> Jannis
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From marc_schwartz at me.com  Thu Jun 27 21:58:47 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 27 Jun 2013 14:58:47 -0500
Subject: [R] Write an Excel workbook?
In-Reply-To: <51CC8F27.60200@structuremonitoring.com>
References: <51CC8F27.60200@structuremonitoring.com>
Message-ID: <A7866931-D56A-4CE9-B7B5-119855F96D1C@me.com>


On Jun 27, 2013, at 2:14 PM, Spencer Graves <spencer.graves at structuremonitoring.com> wrote:

> Hello:
> 
> 
> Is there a fully transportable way to write an Excel workbook?
> 
> 
> The "writeFindFn2xls" function in the "sos" package attempts to write search results to an Excel workbook consisting of (1) a summary of the packages identified in the search, (2) the individual help pages found, and (3) the search that produced 1 and 2. Unfortunately, for some time now, it only works with 32-bit R; the 64-bit R writes this information to three separate csv files.
> 
> 
> The current code first tries WriteXLS{WriteXLS}. Unfortunately, this fails on my computer, because it can't find the Perl module "Text::CSV_XS". I don't see an easy fix to this.
> 
> 
> If WriteXLS fails, the code then tries odbcConnectExcel{ODBC}. From this, I get, "odbcConnectExcel is only usable with 32-bit Windows". That's OK, but it means that I need to run all my searches on 32-bit R, and I usually use 64-bit R.
> 
> 
> I tried write.xls{dataframes2xls}. This put quotes around everything, which I found unacceptable.
> 
> 
> findFn('write.xls') identified a function by that name in the "marray" package. Unfortunately, install.packages("marray") produced, "Warning message: package ?marray? is not available (for R version 3.0.1)" "???xls" failed to produce anything else that looked to me like it would write a complete workbook.
> 
> 
> Suggestions?
> Thanks,
> Spencer Graves



The problem that you will likely run into Spencer, is that most cross-OS solutions for R will likely require Perl (as in the case of my WriteXLS package), Python or Java as in the case of some of the others, like XLConnect. Java, while perhaps the easiest of the cross-OS solutions, may be problematic from a security standpoint, if the user's computer has had Java removed or disabled (not just the browser plug-in, but the JRE itself).

In the case of WriteXLS, the solution to the missing Perl module(s) is defined in the INSTALL file that is included in the package:

  http://cran.r-project.org/web/packages/WriteXLS/INSTALL

As noted there and as you find above, the typical missing module is Text::CSV_XS (because it contains C code requiring compilation), with the exception of (as of the last time I checked) the ActiveState Perl distribution. The ActiveState distribution includes pre-compiled binaries of the Perl modules for the target OS's, which obviates the need for the user to have C related development tools installed locally.

Regards,

Marc Schwartz


From ruipbarradas at sapo.pt  Thu Jun 27 22:03:35 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 27 Jun 2013 21:03:35 +0100
Subject: [R] when to use & pros/cons of dataframe vs. matrix?
In-Reply-To: <CAOQRPaas0YJ1XvKTaRj7d5G1osWMiWR8RCnq55p1B_3R1rtK5A@mail.gmail.com>
References: <CAOQRPaas0YJ1XvKTaRj7d5G1osWMiWR8RCnq55p1B_3R1rtK5A@mail.gmail.com>
Message-ID: <51CC9A97.6000002@sapo.pt>

Hello,

Arun's answer shows that matrices are faster. If your data is all of the 
same type, then this might be a point for matrices.
data.frames are better for modeling. You can use the formula interface 
to the many modeling functions. For instance, the example below is _not_ 
possible with a matrix.


set.seed(1234)
dat <- data.frame(x = rnorm(100), A = sample(letters[1:4], 100, TRUE), y 
= rnorm(100))

model <- lm(y ~ x + A, data = dat) # not possible with matrix

#predict.lm needs data.frames
newdat <- data.frame(x = c(1,3,4), A = rep("a",3))
predict(model, new = newdat)


There are many other examples like this one. If you are doing data 
modeling, use data frames.

Hope this helps,

Rui Barradas

Em 27-06-2013 19:26, Anika Masters escreveu:
> When "should" I use a dataframe vs. a matrix?  What are the pros and cons?
> If I have data of all the same type, am I usually better off using a
> matrix and not a dataframe?
> What are the advantages if any of using a dataframe vs. a matrix?
> (rownames and column names perhaps?)
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ute at imf.au.dk  Thu Jun 27 21:52:27 2013
From: ute at imf.au.dk (Ute Hahn)
Date: Thu, 27 Jun 2013 12:52:27 -0700 (PDT)
Subject: [R] Inhomogeneous, univariate, O-Ring Statistic
In-Reply-To: <CAHqXSKPStZ8pJrSOuWCJY4sRXDRS7FRiZD3_rq396bz62phSHw@mail.gmail.com>
References: <CAHqXSKPStZ8pJrSOuWCJY4sRXDRS7FRiZD3_rq396bz62phSHw@mail.gmail.com>
Message-ID: <1372362747905-4670479.post@n4.nabble.com>

Hi J Ely,

This would very much depend on how an O-ring statistic for inhomogeneous
point patterns is defined. The formula in Wiegand and Moloney (2004),
O(r)=g(r)*lambda, straightforwardly only makes sense for a homogeneous
pattern, where the intensity lambda is a constant. Is there an "official"
definition of O(r) for inhomogeneous point patterns out there?

Cheers,

Ute



--
View this message in context: http://r.789695.n4.nabble.com/Inhomogeneous-univariate-O-Ring-Statistic-tp4668128p4670479.html
Sent from the R help mailing list archive at Nabble.com.


From jdnewmil at dcn.davis.CA.us  Thu Jun 27 22:20:37 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 27 Jun 2013 13:20:37 -0700
Subject: [R] [SPAM?]  Re:  Data Package Query
In-Reply-To: <DUB405-EAS318C4DA5ACC552077A8D7C690750@phx.gbl>
References: <1371633615.23367.YahooMailNeo@web160101.mail.bf1.yahoo.com>
	<1371711263.96641.YahooMailNeo@web122105.mail.ne1.yahoo.com>
	<1371725996.86004.YahooMailNeo@web122106.mail.ne1.yahoo.com>
	<DUB405-EAS306523EF12F1C6C0F82988D90750@phx.gbl>
	<a12164e5-fef5-4963-8159-e891210e7dbc@email.android.com>
	<DUB405-EAS318C4DA5ACC552077A8D7C690750@phx.gbl>
Message-ID: <c96183b3-ae0d-4a1c-8bd7-28e54a53b449@email.android.com>

Please reply to all so the thread stays on the mailing list for all to see (and correct if wrong information is given).

Regarding your code below, either you are missing a library statement to load a package that contains this "trial" data, or you are intending to read in your own data set but are not yet aware of how that is done.

I could find no package containing a data set named "trial" (but I might have missed one). 

If you have some data of your own, then the data function is almost certainly not the right tool for the job. A PDF document called "R Data Import/Export" is supplied with R that can get you started. There are also various intro books available.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Yasmine Refai <y_refai at hotmail.com> wrote:

>Unfortunately, i have no variable called "data". The below is the
>syntax i am running:
>data(trial)
>fit<-logistf(data=trial, y=x1+x2+x3)
>
>Sorry for the disturbance.
>
>Regards!
>
>On Jun 27, 2013, at 9:47 AM, "Jeff Newmiller"
><jdnewmil at dcn.davis.CA.us> wrote:
>
>> "data" is a base function (so you should not have to load any
>packages to use it), and it is not capitalized. Depending on the
>particular data set you want the data function to load, you may need to
>load the package that contains that data set.
>> 
>> A common error by beginners (which may or may not be your problem in
>this case) is to create a variable called "data". Unfortunately this
>hides the function named "data" and from that time forward that R
>session doesn't work when you type example code that uses the data
>function. If this is your problem, the best solution is to restart R
>and do your analysis from the beginning using a different variable name
>than "data". (This is why keeping your working code in a separate text
>file is standard operating procedure.)
>> 
>> Note that I am guessing here... the Posting Guide asks you to give a
>reproducible example so we don't have to guess what you have done.
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                      Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>
>> Sent from my phone. Please excuse my brevity.
>> 
>> Yasmine Refai <y_refai at hotmail.com> wrote:
>> 
>>> Hello,
>>> 
>>> When i type in the below syntax:
>>> Data (name of the data set)
>>> 
>>> I get an error message specifying that the "data" package is not
>found.
>>> 
>>> Please note that i installed all packages having the word "data" 
>>> included in them and loaded all these packages.
>>> 
>>> Please advice.
>>> 
>>> Regards!
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>


From mdsumner at gmail.com  Thu Jun 27 22:22:42 2013
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 28 Jun 2013 06:22:42 +1000
Subject: [R] creat raster from XYZ
In-Reply-To: <CA+jRDxBH590JMZ9apNps9qHLGABWkPNztpgJ6BFLy8ahD0UtLQ@mail.gmail.com>
References: <CA+jRDxD=x+CHu_LC=w2XyjSdX=y9y+Ys99wXJPA4kb5OgkdmnQ@mail.gmail.com>
	<CAAcGz98p1ezbbxj+g3gPU-4a2f+Qra8ch7K7L7Z4QMpXfy0Agw@mail.gmail.com>
	<CA+jRDxBH590JMZ9apNps9qHLGABWkPNztpgJ6BFLy8ahD0UtLQ@mail.gmail.com>
Message-ID: <CAAcGz9_Q4ve+E5CfGtzrn+y2vAraGxyLGjUngrkD3Uc+ot4-8g@mail.gmail.com>

On Fri, Jun 28, 2013 at 1:41 AM, Shane Carey <careyshan at gmail.com> wrote:
> Hi Michael,
>
> I tried this but it would not work. I get an error stating that  x cell
> sizes are not regular.
> Any ideas?
>

The function is reporting that your data don't fall on a grid, you'll
need to figure out why that is the case, or if it is not the case why
you think it should be (plotting the points is a good start).
rasterFromXYZ has some arguments for controlling the tolerance of
numeric error for the grid interpretation (tables or coordinates
stored in text are a bad way to store such data, since you can
introduce innacuracies in the coordinate values and the vast majority
of them are redudant if it's really a grid).

The function's help also points you to rasterize() which is for
converting irregular data to a grid, but this is a very broad and
complicated modelling topic, depending on your domain. I would trace
the origins of your file back to where it's supposed to be a real grid
and demand a decent raster format that is efficient and unambiguous
before exploring that.

R-Sig-Geo is a mailing list more suited to this topic, and is where
the geo-geeks hang out. You should review the guidelines for that
mailing list (and this one).

Cheers, Mike.

>
>
>
> On Thu, Jun 27, 2013 at 12:40 PM, Michael Sumner <mdsumner at gmail.com> wrote:
>>
>> On Wed, Jun 26, 2013 at 12:53 AM, Shane Carey <careyshan at gmail.com> wrote:
>> > Hi,
>> >
>> > I have a data set consisting of XYZ data. the dimensions are 22427 rows
>> > by
>> > 3 columns.
>> >
>> > I try to use rasterFromXYZ from the raster package but I get the
>> > following
>> > error:
>> >
>> >  Error in rasterFromXYZ(DATA) : x cell sizes are not regular
>> >
>> > Any help would be appreciated.
>>
>> No problem.
>>
>> library(raster)
>> ?rasterFromXYZ
>>
>>
>> >
>> > Thanks
>> >
>> > --
>> > Shane
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Michael Sumner
>> Hobart, Australia
>> e-mail: mdsumner at gmail.com
>
>
>
>
> --
> Shane



-- 
Michael Sumner
Hobart, Australia
e-mail: mdsumner at gmail.com


From jvadams at usgs.gov  Thu Jun 27 22:39:13 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 27 Jun 2013 15:39:13 -0500
Subject: [R] using "rollapply" to calculate a moving sum or running sum?
In-Reply-To: <CAOQRPaYHFuy42bC+ge5oVgYBLxHgf-9_znCdX9bbgOCkKG9ucw@mail.gmail.com>
References: <CAOQRPaYHFuy42bC+ge5oVgYBLxHgf-9_znCdX9bbgOCkKG9ucw@mail.gmail.com>
Message-ID: <CAN5YmCG1VEKt0RpTZ5LQ_qXoHOcWTP5tn9KgZFKhqK6n_iBpcg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130627/1d12a5f4/attachment.pl>

From ggrothendieck at gmail.com  Thu Jun 27 23:37:24 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 27 Jun 2013 17:37:24 -0400
Subject: [R] using "rollapply" to calculate a moving sum or running sum?
In-Reply-To: <CAOQRPaYHFuy42bC+ge5oVgYBLxHgf-9_znCdX9bbgOCkKG9ucw@mail.gmail.com>
References: <CAOQRPaYHFuy42bC+ge5oVgYBLxHgf-9_znCdX9bbgOCkKG9ucw@mail.gmail.com>
Message-ID: <CAP01uR=1cssvafeSE+i=U3Mkq0HtmnQkeRT0cs5Q=gBUeJ862Q@mail.gmail.com>

On Thu, Jun 27, 2013 at 3:00 PM, Anika Masters <anika.masters at gmail.com> wrote:
> #using "rollapply" to calculate a moving sum or running sum?
>
> #I am tryign to use rollapply to calcualte a moving sum? #I tried
> rollapply and get the error message
> #"Error in seq.default(start.at, NROW(data), by = by) :
> #  wrong sign in 'by' argument"
>
> #example:
>
> mymatrix <- ( matrix(data=1:100, nrow=5, ncol=20) )
> mymatrix_cumsum  <- ( matrix(data=NA, nrow=5, ncol=20) )
> w=12
> for(i in 1: (ncol(mymatrix)-w+1) ) {
> mymatrix_cumsum[ , i]  <- apply(X=mymatrix[, i:(i+w-1)] , MARGIN=1,
> FUN=sum, na.rm=T)
> }
>
> #How might I use the "rollapply" function instead?
>
> rollapply(mymatrix, 12, sum)
>
> rollapply(data = mymatrix, width = 12, FUN=sum, by.column =T, fill =
> NA, partial = FALSE, align = "left" )

rollapply works column at a time (not row at a time) so try this:

 t( rollapply( t(mymatrix), 12, sum ) )

--
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From smartpink111 at yahoo.com  Thu Jun 27 23:41:22 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 27 Jun 2013 14:41:22 -0700 (PDT)
Subject: [R] using "rollapply" to calculate a moving sum or running sum?
In-Reply-To: <CAOQRPaYHFuy42bC+ge5oVgYBLxHgf-9_znCdX9bbgOCkKG9ucw@mail.gmail.com>
References: <CAOQRPaYHFuy42bC+ge5oVgYBLxHgf-9_znCdX9bbgOCkKG9ucw@mail.gmail.com>
Message-ID: <1372369282.27910.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Try:
library(zoo)

rollapply(t(mymatrix),width=12,FUN=sum,by.column=T,fill=NA,partial=FALSE,align="left")
?# ??? [,1] [,2] [,3] [,4] [,5]
?#[1,]? 342? 354? 366? 378? 390
?#[2,]? 402? 414? 426? 438? 450
?#[3,]? 462? 474? 486? 498? 510
?#[4,]? 522? 534? 546? 558? 570
?#[5,]? 582? 594? 606? 618? 630
?#[6,]? 642? 654? 666? 678? 690
?#[7,]? 702? 714? 726? 738? 750
?#[8,]? 762? 774? 786? 798? 810
?#[9,]? 822? 834? 846? 858? 870
#[10,]?? NA?? NA?? NA?? NA?? NA
#[11,]?? NA?? NA?? NA?? NA?? NA
#[12,]?? NA?? NA?? NA?? NA?? NA
#[13,]?? NA?? NA?? NA?? NA?? NA
#[14,]?? NA?? NA?? NA?? NA?? NA
#[15,]?? NA?? NA?? NA?? NA?? NA
#[16,]?? NA?? NA?? NA?? NA?? NA
#[17,]?? NA?? NA?? NA?? NA?? NA
#[18,]?? NA?? NA?? NA?? NA?? NA
#[19,]?? NA?? NA?? NA?? NA?? NA
#[20,]?? NA?? NA?? NA?? NA?? NA
A.K.



----- Original Message -----
From: Anika Masters <anika.masters at gmail.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Thursday, June 27, 2013 3:00 PM
Subject: [R] using "rollapply" to calculate a moving sum or running sum?

#using "rollapply" to calculate a moving sum or running sum?

#I am tryign to use rollapply to calcualte a moving sum? #I tried
rollapply and get the error message
#"Error in seq.default(start.at, NROW(data), by = by) :
#? wrong sign in 'by' argument"

#example:

mymatrix <- ( matrix(data=1:100, nrow=5, ncol=20) )
mymatrix_cumsum? <- ( matrix(data=NA, nrow=5, ncol=20) )
w=12
for(i in 1: (ncol(mymatrix)-w+1) ) {
mymatrix_cumsum[ , i]? <- apply(X=mymatrix[, i:(i+w-1)] , MARGIN=1,
FUN=sum, na.rm=T)
}

#How might I use the "rollapply" function instead?

rollapply(mymatrix, 12, sum)

rollapply(data = mymatrix, width = 12, FUN=sum, by.column =T, fill =
NA, partial = FALSE, align = "left" )

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Thu Jun 27 23:53:56 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 27 Jun 2013 14:53:56 -0700 (PDT)
Subject: [R] multivariate version of aggregate
In-Reply-To: <087b01ce736b$9e1c1ae0$da5450a0$@tamu.edu>
References: <51CC75D0.2010605@yahoo.de>
	<087b01ce736b$9e1c1ae0$da5450a0$@tamu.edu>
Message-ID: <1372370036.81078.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
May be this also helps:
library(data.table)
dt1<- data.table(dat)
dt1[,cor(x,y),by=g]
#?? g????????? V1
#1: A -0.05643063
#2: B? 0.16465040
dt1[,cor(x,y),by=g]$V1
#[1] -0.05643063? 0.16465040

A.K.

----- Original Message -----
From: David Carlson <dcarlson at tamu.edu>
To: 'Jannis' <bt_jannis at yahoo.de>; 'r-help' <r-help at r-project.org>
Cc: 
Sent: Thursday, June 27, 2013 3:22 PM
Subject: Re: [R] multivariate version of aggregate

You can pass a matrix to by()

> set.seed(42)
> dat <- data.frame(x=runif(50)*20, y=runif(50)*20,
g=rep(LETTERS[1:2], each=25))
> as.vector(by(dat[,1:2], dat$g, function(x) cor(x)[1,2]))
[1] -0.05643063? 0.16465040

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Jannis
Sent: Thursday, June 27, 2013 12:27 PM
To: r-help
Subject: [R] multivariate version of aggregate

Dear List members,


i am seeking a multivariate version of aggregate. I want to compute,
fro 
example the correlation between subsets of two vectors. In
aggregate, i 
can only supply one vector with indices for subsets. Is? there ready

function for this or do i need to program my own?


Cheers
Jannis

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Fri Jun 28 00:19:23 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 27 Jun 2013 15:19:23 -0700 (PDT)
Subject: [R] matrix data generation under 2 loops
Message-ID: <1372371563.37071.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
May be this helps:
res1<-as.matrix(transform(expand.grid(k1=0.3*(1:10),k2=1:10),k3=k1*k2))

A.K.


Dear all, 

I'm trying to generate a matrix dataset following 2 loops analysis, such as the follows: 

for (i in 1:10) ?{ 

k1 <- 0.3 x i 

for (j in 1:10) ?{ 

k2 <- j 

k3 <- k1*k2 

.... 

}} 

I would like to generate a dataset with each row containing k1, 
k2, and corresponding k3. As there's 100 combination of k1 and k2, so 
there would be 100 rows data. ?how could I do it? 

Thanks for the help. 

York


From rolf.turner at xtra.co.nz  Fri Jun 28 00:29:21 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Fri, 28 Jun 2013 10:29:21 +1200
Subject: [R] Data Package Query
In-Reply-To: <a12164e5-fef5-4963-8159-e891210e7dbc@email.android.com>
References: <1371633615.23367.YahooMailNeo@web160101.mail.bf1.yahoo.com>
	<1371711263.96641.YahooMailNeo@web122105.mail.ne1.yahoo.com>
	<1371725996.86004.YahooMailNeo@web122106.mail.ne1.yahoo.com>
	<DUB405-EAS306523EF12F1C6C0F82988D90750@phx.gbl>
	<a12164e5-fef5-4963-8159-e891210e7dbc@email.android.com>
Message-ID: <51CCBCC1.6040508@xtra.co.nz>

On 28/06/13 04:47, Jeff Newmiller wrote:

     <SNIP>
> A common error by beginners (which may or may not be your problem in this case) is to create a variable called "data". Unfortunately this hides the function named "data" and from that time forward that R session doesn't work when you type example code that uses the data function.

     <SNIP>

This is simply not true.  I believe it *used* to be true, sometime 
waaaaayyyy back,
but hasn't been true for years.  The R language is much cleverer now.  
If there
is a function "melvin()" somewhere on the search path and also a data object
"melvin" (earlier on the search path) then doing

     melvin(<whatever>)

will correctly call the function melvin() with no complaints.  The R 
language
"can tell" by the parentheses that you mean the *function* melvin and 
not the
data object "melvin".

E.g.

     data <- 42
     require(akima)
     akima
     Error: object 'akima' not found
     data(akima)  # No error message, nor nothin'!
     akima
     # The data set "akima" is displayed.

All that being said it is ***BAD PRACTICE***, just in terms of 
comprehensibility
and avoiding confusion, to give a data set set the same name as a function
(either built in, or one of your own).

     fortune("dog")

is relevant.

     cheers,

         Rolf Turner


From sjackman at gmail.com  Fri Jun 28 00:47:25 2013
From: sjackman at gmail.com (Shaun Jackman)
Date: Thu, 27 Jun 2013 15:47:25 -0700
Subject: [R] Comparing each level of a factor to the global mean
In-Reply-To: <CAN5YmCHK0-txj28HOiP8SwjjRGZPTZ47yDezP25HsR=pq4h4pA@mail.gmail.com>
References: <CADX6M3rzg9ryM62eRLzci8WtfXLPcxMMa_yV_QEc3Q7C1d9j7A@mail.gmail.com>
	<CAN5YmCHK0-txj28HOiP8SwjjRGZPTZ47yDezP25HsR=pq4h4pA@mail.gmail.com>
Message-ID: <CADX6M3qZFSAQ0nAypJnzMUtQ0jfDGmPdvHcoEbeFSy6KK1=COg@mail.gmail.com>

Hi Jean,

contr.treatment(4) shows what the default contrast matrix looks like
for a factor with 4 levels. What function do I use to create a
contrast matrix to compare each level with the global mean (four
comparisons in total), and produce a table similar to `summary.lm`?

Thanks,
Shaun


On 26 June 2013 05:50, Adams, Jean <jvadams at usgs.gov> wrote:
> Shaun,
>
> See the help on contrasts ...
>      ?contr.treatment
>
> Jean
>
>
> On Tue, Jun 25, 2013 at 7:07 PM, Shaun Jackman <sjackman at gmail.com> wrote:
>>
>> Hi,
>>
>> I've used `lm` to create a linear model of a continuous variable
>> against a factor variable with four levels using an example R data set
>> (see below). By default, it uses a treatment contrast matrix that
>> compares each level of the factor variable with the first reference
>> level (three comparisons in total). I'd like to compare each level
>> with the global mean (four comparisons in total), and produce a table
>> similar to `summary.lm`. How do I go about this?
>>
>> ```r
>> model <- lm(weight ~ Diet, ChickWeight)
>> summary(model)
>> ```
>>
>> Thanks,
>> Shaun
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From paxkn at nottingham.ac.uk  Fri Jun 28 02:24:01 2013
From: paxkn at nottingham.ac.uk (beginner)
Date: Thu, 27 Jun 2013 17:24:01 -0700 (PDT)
Subject: [R] Scatter plot with error bars
Message-ID: <1372379041952-4670502.post@n4.nabble.com>

Hi

I would like to plot multiple data sets on a scatter plot with error bars.
To do this I write the following code:

install.packages("Hmisc")
library(Hmisc)

x1<-data1[,1]
y1<-data1[,2]
x2<-data2[,1]
y2<-data2[,2]
x3<-data3[,1]
y3<-data3[,2]

SD1<-data1[,3]
SD2<-data2[,3]
SD3<-data3[,4]

delta<-runif(5)
errbar(x1,y1,y1+SD1, y1-SD1, col="red",pch=19)
lines(x1,y1,col="red", pch=19, lty=3)
errbar(x2,y2,y2+SD2, y2-SD2, col="green",pch=19)
lines(x2,y2,col="green", pch=19, lty=3)
errbar(x3,y3,y3+SD3, y3-SD3, col="blue",pch=19)
lines(x3,y3,col="blue", pch=19, lty=3)

However, with this code I can obtain only the scatter plot for x1, y1, but
not for the other data sets. Could you please let me know how should I
modify the code presented above ?

In other situations, when I try to make a scatter plot of several data sets
without error bars, I usually use points () function. 
However it does not work in the presented case... 

I would be very grateful for your help. 



--
View this message in context: http://r.789695.n4.nabble.com/Scatter-plot-with-error-bars-tp4670502.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Fri Jun 28 03:08:56 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 27 Jun 2013 18:08:56 -0700
Subject: [R] Comparing each level of a factor to the global mean
In-Reply-To: <CADX6M3qZFSAQ0nAypJnzMUtQ0jfDGmPdvHcoEbeFSy6KK1=COg@mail.gmail.com>
References: <CADX6M3rzg9ryM62eRLzci8WtfXLPcxMMa_yV_QEc3Q7C1d9j7A@mail.gmail.com>
	<CAN5YmCHK0-txj28HOiP8SwjjRGZPTZ47yDezP25HsR=pq4h4pA@mail.gmail.com>
	<CADX6M3qZFSAQ0nAypJnzMUtQ0jfDGmPdvHcoEbeFSy6KK1=COg@mail.gmail.com>
Message-ID: <874969B5-73B2-4089-9F6D-702509F1A6F1@comcast.net>


On Jun 27, 2013, at 3:47 PM, Shaun Jackman wrote:

> Hi Jean,
> 
> contr.treatment(4) shows what the default contrast matrix looks like
> for a factor with 4 levels. What function do I use to create a
> contrast matrix to compare each level with the global mean (four
> comparisons in total), and produce a table similar to `summary.lm`?
> 

I believe you asking for "contr.sum" although I think there might be some differences between how it operates and what you are expressing as your expectations.

> contrasts(ChickWeight$Diet) <- contr.sum(4)
> model <- lm(weight ~ Diet, ChickWeight)
> summary(model)

Call:
lm(formula = weight ~ Diet, data = ChickWeight)

Residuals:
    Min      1Q  Median      3Q     Max 
-103.95  -53.65  -13.64   40.38  230.05 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  125.869      2.986  42.150  < 2e-16 ***
Diet1        -23.223      4.454  -5.214 2.59e-07 ***
Diet2         -3.252      5.380  -0.604  0.54576    
Diet3         17.081      5.380   3.175  0.00158 ** 
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 69.33 on 574 degrees of freedom
Multiple R-squared:  0.05348,	Adjusted R-squared:  0.04853 
F-statistic: 10.81 on 3 and 574 DF,  p-value: 6.433e-07

> mean(ChickWeight$weight)
[1] 121.8183
> table(ChickWeight$Diet)

  1   2   3   4 
220 120 120 118 

So in an unbalanced data situation, the Intercept is only approximately the grand mean.

To see what you are requesting in the summary you can an offset from the mean and use the Intercept suppression syntax:

> model <- lm(weight ~ Diet+0+offset(rep(mean(ChickWeight$weight), nrow(ChickWeight) )), ChickWeight)
> summary(model)

Call:
lm(formula = weight ~ Diet + 0 + offset(rep(mean(ChickWeight$weight), 
    nrow(ChickWeight))), data = ChickWeight)

Residuals:
    Min      1Q  Median      3Q     Max 
-103.95  -53.65  -13.64   40.38  230.05 

Coefficients:
      Estimate Std. Error t value Pr(>|t|)    
Diet1 -19.1729     4.6740  -4.102 4.69e-05 ***
Diet2   0.7983     6.3286   0.126 0.899660    
Diet3  21.1317     6.3286   3.339 0.000895 ***
Diet4  13.4444     6.3820   2.107 0.035584 *  
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 69.33 on 574 degrees of freedom
Multiple R-squared:  0.7599,	Adjusted R-squared:  0.7583 
F-statistic: 454.3 on 4 and 574 DF,  p-value: < 2.2e-16

Notice this does estimate waht you requested, but I think it is more due to the use of an offset than to the choice of contrasts.

> with(ChickWeight, tapply(weight, Diet, function(categ) mean(categ)- mean(weight) ) )
          1           2           3           4 
-19.1728846   0.7983276  21.1316609  13.4443728 


I'm very worried this might be inferentially suspect, since the degrees of freedom and the anava F statistic are different than the usual methods.
-- 
David.

> Thanks,
> Shaun
> 
> 
> On 26 June 2013 05:50, Adams, Jean <jvadams at usgs.gov> wrote:
>> Shaun,
>> 
>> See the help on contrasts ...
>>     ?contr.treatment
>> 
>> Jean
>> 
>> 
>> On Tue, Jun 25, 2013 at 7:07 PM, Shaun Jackman <sjackman at gmail.com> wrote:
>>> 
>>> Hi,
>>> 
>>> I've used `lm` to create a linear model of a continuous variable
>>> against a factor variable with four levels using an example R data set
>>> (see below). By default, it uses a treatment contrast matrix that
>>> compares each level of the factor variable with the first reference
>>> level (three comparisons in total). I'd like to compare each level
>>> with the global mean (four comparisons in total), and produce a table
>>> similar to `summary.lm`. How do I go about this?
>>> 
>>> ```r
>>> model <- lm(weight ~ Diet, ChickWeight)
>>> summary(model)
>>> ```
>>> 
>>> Thanks,
>>> Shaun
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From kuma0177 at gmail.com  Fri Jun 28 00:12:36 2013
From: kuma0177 at gmail.com (Piyush Kumar)
Date: Thu, 27 Jun 2013 15:12:36 -0700
Subject: [R] Step wave Detection using R
Message-ID: <CAGAqBuz7x=dQoPAYW-rjQcWOh8o85s_+etG-1DYXYN_Ow1McQA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130627/636f3fda/attachment.pl>

From armel.kaptue at sdstate.edu  Fri Jun 28 05:04:33 2013
From: armel.kaptue at sdstate.edu (Kaptue Tchuente, Armel)
Date: Fri, 28 Jun 2013 03:04:33 +0000
Subject: [R] How to create a function returning an array ?
Message-ID: <9879AF1F439EF943BDEE22D3AAA5C3F683FCFE9E@sdsu-ex01.jacks.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130628/07c3fe4f/attachment.pl>

From dwinsemius at comcast.net  Fri Jun 28 05:38:59 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 27 Jun 2013 20:38:59 -0700
Subject: [R] How to create a function returning an array ?
In-Reply-To: <9879AF1F439EF943BDEE22D3AAA5C3F683FCFE9E@sdsu-ex01.jacks.local>
References: <9879AF1F439EF943BDEE22D3AAA5C3F683FCFE9E@sdsu-ex01.jacks.local>
Message-ID: <B84290A7-2D2F-482A-9A55-BFBF10B354F5@comcast.net>


On Jun 27, 2013, at 8:04 PM, Kaptue Tchuente, Armel wrote:

> Hi there,
> 
> I would like to know how to change the line "img=as.single(rnorm(m)))" such that instead of being a vector of length m as it is now, img is an array of dimension c=(n,m,o) for instance
> 
> ---------------------------------
> read_ts<-function(n,m,o,img) {
>   out<-.Fortran("read_ts",
>                as.integer(n),
>                as.integer(m),
>                as.integer(o),
>                img=as.single(rnorm(n)))
>   return(out$img)
> ------------------------------------------
> 

Well, assuming that  the 'out$img' object has a R-length of n*m*o , wouldn't if be simpler to just change the return call to:

return( array( out$img, dim=c(n,m,o) )

I don't think you wnat start naming your dimension vectors "c".

-- 
David Winsemius
Alameda, CA, USA


From suparna.mitra.sm at gmail.com  Fri Jun 28 07:25:59 2013
From: suparna.mitra.sm at gmail.com (Suparna Mitra)
Date: Fri, 28 Jun 2013 13:25:59 +0800
Subject: [R] Changing legend to fill colour in ggplot
Message-ID: <CAFdg=fW3-X3p8PJwRTzt7E8F6wag1Kxs7fNAtxfd27kpFyaK7w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130628/ece4b97d/attachment.pl>

From canamika at gmail.com  Fri Jun 28 04:05:40 2013
From: canamika at gmail.com (Anamika Chaudhuri)
Date: Thu, 27 Jun 2013 22:05:40 -0400
Subject: [R] Add constraints to rbinom
Message-ID: <CALv--dbHvmMRgDobxhY8y1uAzUapKrS5ADiSNhcY5Le1OHLawA@mail.gmail.com>

Hi:

I am trying to generate Beta-Binomial random variables and then
calculate Binomial exact confidence intervals to the rate..I was
wondering if I needed to add a constraint such that x<=n to it, how do
I go about it. The reason is I am getting data where x>n which is
giving a rate>1. Heres my code:

set.seed(111)
k<-63
x<-NULL
p<-rbeta(k,3,3)# so that the mean nausea rate is alpha/(alpha+beta)
min<-10
max<-60
n<-as.integer(runif(k,min,max))
for(i in 1:k)
x<-cbind(x,rbinom(300,n,p[i]))
x<-t(x)
rate<-t(t(x)/n)
se_rate<-sqrt(rate*(1-rate)/n)



# Exact Confidence Interval

l_cl_exact<-qbeta(.025,x,n-x+1)
u_cl_exact<-qbeta(.975,x+1,n-x)

for (i in 1:63){

for (j in 1:300)
{

if (x[i,j]==0)
{
l_cl_exact[i,j]<-0
u_cl_exact[i,j]<-u_cl_exact[i,j]
}
else if (x[i,j]==n[i])
{
l_cl_exact[i,j]<-l_cl_exact[i,j]
u_cl_exact[i,j]<-1
}
else
l_cl_exact[i,j]<-l_cl_exact[i,j]
u_cl_exact[i,j]<-u_cl_exact[i,j]

#print(c(i,j))

}
}


Really appreciate any help.
Thanks
Anamika


From nblaser at ispm.unibe.ch  Fri Jun 28 08:41:52 2013
From: nblaser at ispm.unibe.ch (Blaser Nello)
Date: Fri, 28 Jun 2013 08:41:52 +0200
Subject: [R] Scatter plot with error bars
In-Reply-To: <1372379041952-4670502.post@n4.nabble.com>
References: <1372379041952-4670502.post@n4.nabble.com>
Message-ID: <17EE8C62EA18B84B94C2BA96A143064C01721A88@mx01.ispm.unibe.ch>

Are you sure, you want to calculate 68% confidence intervals? 

Use the add-argument in ?errorbar to add to the previous plot.
errbar(x2,y2,y2+1.96*SD2, y2-1.96*SD2, col="green",pch=19, add=TRUE)

Best, 
Nello

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
On Behalf Of beginner
Sent: Freitag, 28. Juni 2013 02:24
To: r-help at r-project.org
Subject: [R] Scatter plot with error bars

Hi

I would like to plot multiple data sets on a scatter plot with error
bars.
To do this I write the following code:

install.packages("Hmisc")
library(Hmisc)

x1<-data1[,1]
y1<-data1[,2]
x2<-data2[,1]
y2<-data2[,2]
x3<-data3[,1]
y3<-data3[,2]

SD1<-data1[,3]
SD2<-data2[,3]
SD3<-data3[,4]

delta<-runif(5)
errbar(x1,y1,y1+SD1, y1-SD1, col="red",pch=19) lines(x1,y1,col="red",
pch=19, lty=3) errbar(x2,y2,y2+SD2, y2-SD2, col="green",pch=19)
lines(x2,y2,col="green", pch=19, lty=3) errbar(x3,y3,y3+SD3, y3-SD3,
col="blue",pch=19) lines(x3,y3,col="blue", pch=19, lty=3)

However, with this code I can obtain only the scatter plot for x1, y1,
but not for the other data sets. Could you please let me know how should
I modify the code presented above ?

In other situations, when I try to make a scatter plot of several data
sets without error bars, I usually use points () function. 
However it does not work in the presented case... 

I would be very grateful for your help. 



--
View this message in context:
http://r.789695.n4.nabble.com/Scatter-plot-with-error-bars-tp4670502.htm
l
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bt_jannis at yahoo.de  Fri Jun 28 10:31:10 2013
From: bt_jannis at yahoo.de (Jannis)
Date: Fri, 28 Jun 2013 10:31:10 +0200
Subject: [R] multivariate version of aggregate
In-Reply-To: <CAFEqCdzxzY+W2o=xSp=i9nPODbvaKE4E3rxazPMyq9DTbUZoGg@mail.gmail.com>
References: <51CC75D0.2010605@yahoo.de>
	<CAFEqCdzxzY+W2o=xSp=i9nPODbvaKE4E3rxazPMyq9DTbUZoGg@mail.gmail.com>
Message-ID: <51CD49CE.3000406@yahoo.de>

Yes, I had a look at that function. From the documentation, however, it 
did not get clear to me how to split the dataframe into subsets of rows 
based on an index argument. Like:


testframe <- data.frame(a=rnorm(100), b = rnorm(100))
indices      <- rep(c(1,2), each = 50)


results <- ddply(.data = testframe, INDICES= indices, .fun = function(x) 
corr(x[,1], x[,2]))

Where the last command would yield the correlations between column 1 and 
2 of the first 50 and of the last 50 values.

Any ideas?

Jannis

On 27.06.2013 21:43, Greg Snow wrote:
> Look at the plyr package, probably the ddply function in that package.  You
> can write your own function to do whatever you want on the pieces of the
> split apart object.  Correlation between a specified pair of columns would
> be simple.
>
>
> On Thu, Jun 27, 2013 at 11:26 AM, Jannis <bt_jannis at yahoo.de> wrote:
>
>> Dear List members,
>>
>>
>> i am seeking a multivariate version of aggregate. I want to compute, fro
>> example the correlation between subsets of two vectors. In aggregate, i can
>> only supply one vector with indices for subsets. Is  there ready function
>> for this or do i need to program my own?
>>
>>
>> Cheers
>> Jannis
>>
>> ______________________________**________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/**
>> posting-guide.html <http://www.R-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


From ruipbarradas at sapo.pt  Fri Jun 28 11:00:51 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 28 Jun 2013 10:00:51 +0100
Subject: [R] multivariate version of aggregate
In-Reply-To: <51CD49CE.3000406@yahoo.de>
References: <51CC75D0.2010605@yahoo.de>
	<CAFEqCdzxzY+W2o=xSp=i9nPODbvaKE4E3rxazPMyq9DTbUZoGg@mail.gmail.com>
	<51CD49CE.3000406@yahoo.de>
Message-ID: <51CD50C3.4060605@sapo.pt>

Hello,

You can solve your problem using only base R, with no need for an 
external package. The two instrucitons below are two ways of doing the same.



sapply(split(testframe, indices), function(x) cor(x[, 1], x[, 2]))

as.vector(by(testframe, indices, function(x) cor(x[, 1], x[, 2])))



Hope this helps,

Rui Barradas

Em 28-06-2013 09:31, Jannis escreveu:
> Yes, I had a look at that function. From the documentation, however, it
> did not get clear to me how to split the dataframe into subsets of rows
> based on an index argument. Like:
>
>
> testframe <- data.frame(a=rnorm(100), b = rnorm(100))
> indices      <- rep(c(1,2), each = 50)
>
>
> results <- ddply(.data = testframe, INDICES= indices, .fun = function(x)
> corr(x[,1], x[,2]))
>
> Where the last command would yield the correlations between column 1 and
> 2 of the first 50 and of the last 50 values.
>
> Any ideas?
>
> Jannis
>
> On 27.06.2013 21:43, Greg Snow wrote:
>> Look at the plyr package, probably the ddply function in that
>> package.  You
>> can write your own function to do whatever you want on the pieces of the
>> split apart object.  Correlation between a specified pair of columns
>> would
>> be simple.
>>
>>
>> On Thu, Jun 27, 2013 at 11:26 AM, Jannis <bt_jannis at yahoo.de> wrote:
>>
>>> Dear List members,
>>>
>>>
>>> i am seeking a multivariate version of aggregate. I want to compute, fro
>>> example the correlation between subsets of two vectors. In aggregate,
>>> i can
>>> only supply one vector with indices for subsets. Is  there ready
>>> function
>>> for this or do i need to program my own?
>>>
>>>
>>> Cheers
>>> Jannis
>>>
>>> ______________________________**________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>>>
>>> PLEASE do read the posting guide http://www.R-project.org/**
>>> posting-guide.html <http://www.R-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bt_jannis at yahoo.de  Fri Jun 28 12:38:18 2013
From: bt_jannis at yahoo.de (Jannis)
Date: Fri, 28 Jun 2013 12:38:18 +0200
Subject: [R] multivariate version of aggregate
In-Reply-To: <51CD50C3.4060605@sapo.pt>
References: <51CC75D0.2010605@yahoo.de>
	<CAFEqCdzxzY+W2o=xSp=i9nPODbvaKE4E3rxazPMyq9DTbUZoGg@mail.gmail.com>
	<51CD49CE.3000406@yahoo.de> <51CD50C3.4060605@sapo.pt>
Message-ID: <51CD679A.3030600@yahoo.de>

Thanks a lot to everybody who responded! My solution now looks similar 
to Ruis and Davids suggestions.


Jannis


On 28.06.2013 11:00, Rui Barradas wrote:
> Hello,
>
> You can solve your problem using only base R, with no need for an 
> external package. The two instrucitons below are two ways of doing the 
> same.
>
>
>
> sapply(split(testframe, indices), function(x) cor(x[, 1], x[, 2]))
>
> as.vector(by(testframe, indices, function(x) cor(x[, 1], x[, 2])))
>
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 28-06-2013 09:31, Jannis escreveu:
>> Yes, I had a look at that function. From the documentation, however, it
>> did not get clear to me how to split the dataframe into subsets of rows
>> based on an index argument. Like:
>>
>>
>> testframe <- data.frame(a=rnorm(100), b = rnorm(100))
>> indices      <- rep(c(1,2), each = 50)
>>
>>
>> results <- ddply(.data = testframe, INDICES= indices, .fun = function(x)
>> corr(x[,1], x[,2]))
>>
>> Where the last command would yield the correlations between column 1 and
>> 2 of the first 50 and of the last 50 values.
>>
>> Any ideas?
>>
>> Jannis
>>
>> On 27.06.2013 21:43, Greg Snow wrote:
>>> Look at the plyr package, probably the ddply function in that
>>> package.  You
>>> can write your own function to do whatever you want on the pieces of 
>>> the
>>> split apart object.  Correlation between a specified pair of columns
>>> would
>>> be simple.
>>>
>>>
>>> On Thu, Jun 27, 2013 at 11:26 AM, Jannis <bt_jannis at yahoo.de> wrote:
>>>
>>>> Dear List members,
>>>>
>>>>
>>>> i am seeking a multivariate version of aggregate. I want to 
>>>> compute, fro
>>>> example the correlation between subsets of two vectors. In aggregate,
>>>> i can
>>>> only supply one vector with indices for subsets. Is  there ready
>>>> function
>>>> for this or do i need to program my own?
>>>>
>>>>
>>>> Cheers
>>>> Jannis
>>>>
>>>> ______________________________**________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help> 
>>>>
>>>>
>>>> PLEASE do read the posting guide http://www.R-project.org/**
>>>> posting-guide.html <http://www.R-project.org/posting-guide.html>
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From paxkn at nottingham.ac.uk  Fri Jun 28 14:14:28 2013
From: paxkn at nottingham.ac.uk (beginner)
Date: Fri, 28 Jun 2013 05:14:28 -0700 (PDT)
Subject: [R] Scatter plot with error bars
In-Reply-To: <17EE8C62EA18B84B94C2BA96A143064C01721A88@mx01.ispm.unibe.ch>
References: <1372379041952-4670502.post@n4.nabble.com>
	<17EE8C62EA18B84B94C2BA96A143064C01721A88@mx01.ispm.unibe.ch>
Message-ID: <1372421668958-4670530.post@n4.nabble.com>

Thank you very much for your help !



--
View this message in context: http://r.789695.n4.nabble.com/Scatter-plot-with-error-bars-tp4670502p4670530.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Fri Jun 28 14:15:22 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 28 Jun 2013 05:15:22 -0700 (PDT)
Subject: [R] multivariate version of aggregate
In-Reply-To: <51CD49CE.3000406@yahoo.de>
References: <51CC75D0.2010605@yahoo.de>
	<CAFEqCdzxzY+W2o=xSp=i9nPODbvaKE4E3rxazPMyq9DTbUZoGg@mail.gmail.com>
	<51CD49CE.3000406@yahoo.de>
Message-ID: <1372421722.54228.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
?set.seed(45)
?testframe <- data.frame(a=rnorm(100), b = rnorm(100))
?indices????? <- rep(c(1,2), each = 50)
library(plyr)

ddply(testframe,.(indices),summarize, Cor1=cor(a,b))

#? indices???????? Cor1
#1?????? 1? 0.002770524
#2?????? 2 -0.101738888


A.K.


----- Original Message -----
From: Jannis <bt_jannis at yahoo.de>
To: Greg Snow <538280 at gmail.com>
Cc: r-help <r-help at r-project.org>
Sent: Friday, June 28, 2013 4:31 AM
Subject: Re: [R] multivariate version of aggregate

Yes, I had a look at that function. From the documentation, however, it 
did not get clear to me how to split the dataframe into subsets of rows 
based on an index argument. Like:


testframe <- data.frame(a=rnorm(100), b = rnorm(100))
indices? ? ? <- rep(c(1,2), each = 50)


results <- ddply(.data = testframe, INDICES= indices, .fun = function(x) 
corr(x[,1], x[,2]))

Where the last command would yield the correlations between column 1 and 
2 of the first 50 and of the last 50 values.

Any ideas?

Jannis

On 27.06.2013 21:43, Greg Snow wrote:
> Look at the plyr package, probably the ddply function in that package.? You
> can write your own function to do whatever you want on the pieces of the
> split apart object.? Correlation between a specified pair of columns would
> be simple.
>
>
> On Thu, Jun 27, 2013 at 11:26 AM, Jannis <bt_jannis at yahoo.de> wrote:
>
>> Dear List members,
>>
>>
>> i am seeking a multivariate version of aggregate. I want to compute, fro
>> example the correlation between subsets of two vectors. In aggregate, i can
>> only supply one vector with indices for subsets. Is? there ready function
>> for this or do i need to program my own?
>>
>>
>> Cheers
>> Jannis
>>
>> ______________________________**________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/**
>> posting-guide.html <http://www.R-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Fri Jun 28 14:57:01 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 28 Jun 2013 05:57:01 -0700 (PDT)
Subject: [R] multiple csv files for T-test
In-Reply-To: <1372355276.21134.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1372342632.22771.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<1372355276.21134.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1372424221.63092.YahooMailNeo@web142606.mail.bf1.yahoo.com>

HI,
According to ?t.test() documentation
If ?paired? is ?TRUE? then both ?x? and ?y? must be specified and
???? they must be the same length.? Missing values are silently removed
???? (in pairs if ?paired? is ?TRUE?)

#Example with missing values
set.seed(24)
dat1<- as.data.frame(matrix(sample(c(NA,20:40),40,replace=TRUE),ncol=4))
set.seed(285)
dat2<- as.data.frame(matrix(sample(c(NA,35:60),40,replace=TRUE),ncol=4)) 

?sapply(colnames(dat1),function(i) t.test(dat1[,i],dat2[,i],paired=TRUE)$p.value) 
#????????? V1?????????? V2?????????? V3?????????? V4 
#7.004488e-05 1.374986e-03 6.666004e-04 3.749257e-04 


#Removing missing values and then do the test
sapply(colnames(dat1),function(i) {x1<-na.omit(cbind(dat1[,i],dat2[,i]));t.test(x1[,1],x1[,2],paired=TRUE)$p.value}) 
#????????? V1?????????? V2?????????? V3?????????? V4 
#7.004488e-05 1.374986e-03 6.666004e-04 3.749257e-04 

A.K.




thanks very much, you're help is much appreciated. 

Just another small question, what's the best way to deal with missing data? ?If i want to do a paired t-test? 


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Thursday, June 27, 2013 1:47 PM
Subject: Re: multiple csv files for T-test

Hi,
I used as.data.frame(matrix(...)) just to create an example dataset.? In your case, you don't need to do that.? Using the same example:

set.seed(24)
dat1<- as.data.frame(matrix(sample(20:40,40,replace=TRUE),ncol=4))
set.seed(285)
dat2<- as.data.frame(matrix(sample(35:60,40,replace=TRUE),ncol=4))

write.csv(dat1,"file1.csv",row.names=FALSE)
write.csv(dat2,"file2.csv",row.names=FALSE)
data1<- read.csv("file1.csv")
data2<- read.csv("file2.csv")

###Your code:
?dat1New<- as.data.frame(matrix(data1))? 
?dat2New<- as.data.frame(matrix(data2)) 
###It is always useful to check ?str() 


str(dat1New)
#'data.frame':??? 4 obs. of? 1 variable:
# $ V1:List of 4
?# ..$ : int? 26 24 34 30 33 39 25 36 36 25
? #..$ : int? 32 27 34 34 26 38 24 20 30 22
?# ..$ : int? 21 31 35 22 24 34 21 32 33 20
?#..$ : int? 26 25 27 23 39 24 35 33 34 40



?dat1New
#????????????????????????????????????? V1
#1 26, 24, 34, 30, 33, 39, 25, 36, 36, 25
#2 32, 27, 34, 34, 26, 38, 24, 20, 30, 22
#3 21, 31, 35, 22, 24, 34, 21, 32, 33, 20
#4 26, 25, 27, 23, 39, 24, 35, 33, 34, 40
?dat2New
#????????????????????????????????????? V1
#1 53, 40, 47, 57, 57, 53, 35, 42, 53, 41
#2 54, 37, 43, 40, 57, 42, 37, 53, 60, 39
#3 54, 60, 46, 50, 35, 41, 58, 45, 36, 53
#4 52, 56, 44, 40, 38, 53, 47, 46, 60, 50
?sapply(colnames(dat1New),function(i) t.test(dat1New[,i],dat2New[,i],paired=TRUE)$p.value) 
#Error in x - y : non-numeric argument to binary operator


##Just using data1 and data2

sapply(colnames(data1),function(i) t.test(data1[,i],data2[,i],paired=TRUE)$p.value) 
#????????? V1?????????? V2?????????? V3?????????? V4 
#3.202629e-05 6.510644e-04 6.215225e-04 3.044760e-04 


#or using dat1New and dat2New
sapply(seq_along(dat1New$V1),function(i) t.test(dat1New$V1[[i]],dat2New$V1[[i]],paired=TRUE)$p.value)
#[1] 3.202629e-05 6.510644e-04 6.215225e-04 3.044760e-04



A.K.



thanks for the reply, I am getting the following error 
Error in x - y : non-numeric argument to binary operator 

This is what I enter below 

> data1 <-read.csv("file1.csv") 
> data2 <-read.csv("file2.csv") 
> dat1<- as.data.frame(matrix(data1)) 
> dat2<- as.data.frame(matrix(data2)) 
> sapply(colnames(dat1),function(i) t.test(dat1[,i],dat2[,i],paired=TRUE)$p.value) 

As far as I can see all my values are numeric...? 


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Thursday, June 27, 2013 10:17 AM
Subject: Re: multiple csv files for T-test

Hi,
May be this helps:
#You can use ?read.csv() to read the two files.

set.seed(24)
dat1<- as.data.frame(matrix(sample(20:40,40,replace=TRUE),ncol=4))
set.seed(285)
dat2<- as.data.frame(matrix(sample(35:60,40,replace=TRUE),ncol=4))
sapply(colnames(dat1),function(i) t.test(dat1[,i],dat2[,i],paired=TRUE)$p.value)
#????????? V1?????????? V2?????????? V3?????????? V4 
#3.202629e-05 6.510644e-04 6.215225e-04 3.044760e-04 

A.K.

Hi 
I am fairly new to R so if this is a stupid question please forgive me. 

I have a CSV file with multiple parameters (50). ?I have another
CSV file with the same parameters after treatment. ?Is there a way I 
can read these two files into R and do multiple paired T-test as all the
parameters are in the same columns in each file? 

Thanks in advance


From jrkrideau at inbox.com  Fri Jun 28 15:09:57 2013
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 28 Jun 2013 05:09:57 -0800
Subject: [R] Changing legend to fill colour in ggplot
In-Reply-To: <CAFdg=fW3-X3p8PJwRTzt7E8F6wag1Kxs7fNAtxfd27kpFyaK7w@mail.gmail.com>
Message-ID: <1D4DE595359.00000692jrkrideau@inbox.com>

 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

While the str() data is useful it is much better to provide real sample data.  Use dput() to supply it.

 If it is a large file send a sample head(dput(df, "somenumber)) with somenumber just enough to provide a representative sample.

We currrently have no idea of what the graph looks like as the R-help list strips that out .With the actual data a reader can just copy it and your code into R and see exactly what you are getting.

Please don't post in HTML. Plain text is much easier to read, the HTML gets dropped and any formating goes to pot.

I think the actual answer is probably straight forward but we really should have the data

Thanks

John Kane
Kingston ON Canada


> -----Original Message-----
> From: suparna.mitra.sm at gmail.com
> Sent: Fri, 28 Jun 2013 13:25:59 +0800
> To: r-help at r-project.org
> Subject: [R] Changing legend to fill colour in ggplot
> 
> Hello R experts,
>   I am having a problem to edit legend in ggplot using four variables.
> 
> My data structure is :
> str(df)
> 'data.frame': 10 obs. of  6 variables:
>  $ id                        : Factor w/ 2 levels "639A","640": 1 1 1 1 1
> 2
> 2 2 2 2
>  $ species                   : Factor w/ 5 levels "acinetobacter_sp",..:
> 2
> 5 1 4 3 2 5 1 4 3
>  $ genome_coverage_bp        : int  8196 3405 8625 22568 2128 6100 1841
> 3914 8487 1064
>  $ genome_length             : int  3571237 2541445 3912725 3479613
> 5460977
> 3571237 2541445 3912725 3479613 5460977
>  $ genome_coverage_percentage: Factor w/ 10 levels "0.02%","0.04%",..: 8
> 5
> 7 10 2 6 3 4 9 1
>  $ avg_depth_coverage        : num  121.96 2.81 19.84 399.63 1.64 ...
> 
> 
> Now what I did is
> p=ggplot(df,aes(genome_coverage_percentage,avg_depth_coverage))+geom_point(aes(colour
> = species,shape = factor(id)))
> p+scale_shape_discrete(name  ="",labels=c("Patient 1", "Patient 2"))
> That creats the plot below.
> But I want to change the circles of legend in fill colour. So that it
> doesn't look like it is only from Patient 1, as that also has circle.
> Can anybody help me please?
> 
> Thanks a lot in advance :)
>  Mitra
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From dimitri.liakhovitski at gmail.com  Fri Jun 28 15:11:40 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Fri, 28 Jun 2013 09:11:40 -0400
Subject: [R] choicemodelr is misbehaving under R3.0
In-Reply-To: <CAN2xGJYjEe-r6ynVw35WJnDscQt4O_aAvWAggdZkVXxVvAV+CQ@mail.gmail.com>
References: <CAN2xGJYjEe-r6ynVw35WJnDscQt4O_aAvWAggdZkVXxVvAV+CQ@mail.gmail.com>
Message-ID: <CAN2xGJbbewMwm36z25-Ux_5d=_1mJ_A2y75YACEV__w4kH5zXw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130628/3a9d4aa2/attachment.pl>

From murdoch.duncan at gmail.com  Fri Jun 28 15:16:07 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 28 Jun 2013 09:16:07 -0400
Subject: [R] How to create a function returning an array ?
In-Reply-To: <B84290A7-2D2F-482A-9A55-BFBF10B354F5@comcast.net>
References: <9879AF1F439EF943BDEE22D3AAA5C3F683FCFE9E@sdsu-ex01.jacks.local>
	<B84290A7-2D2F-482A-9A55-BFBF10B354F5@comcast.net>
Message-ID: <51CD8C97.5060806@gmail.com>

On 27/06/2013 11:38 PM, David Winsemius wrote:
> On Jun 27, 2013, at 8:04 PM, Kaptue Tchuente, Armel wrote:
>
> > Hi there,
> >
> > I would like to know how to change the line "img=as.single(rnorm(m)))" such that instead of being a vector of length m as it is now, img is an array of dimension c=(n,m,o) for instance
> >
> > ---------------------------------
> > read_ts<-function(n,m,o,img) {
> >   out<-.Fortran("read_ts",
> >                as.integer(n),
> >                as.integer(m),
> >                as.integer(o),
> >                img=as.single(rnorm(n)))
> >   return(out$img)
> > ------------------------------------------
> >
>
> Well, assuming that  the 'out$img' object has a R-length of n*m*o , wouldn't if be simpler to just change the return call to:

In fact, out$img has a length of n, same as on input.  .Fortran won't 
change the length of its arguments.

Duncan Murdoch

>
> return( array( out$img, dim=c(n,m,o) )
>
> I don't think you wnat start naming your dimension vectors "c".
>


From jrkrideau at inbox.com  Fri Jun 28 15:22:53 2013
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 28 Jun 2013 05:22:53 -0800
Subject: [R] choicemodelr is misbehaving under R3.0
In-Reply-To: <CAN2xGJbbewMwm36z25-Ux_5d=_1mJ_A2y75YACEV__w4kH5zXw@mail.gmail.com>
References: <can2xgjyjee-r6ynvw35wjndscqt4o_aavwaggdzkvxxvvav+cq@mail.gmail.com>
Message-ID: <1D6ACF33362.000006B4jrkrideau@inbox.com>

I have encountered what looks to be a problem with ggpairs in ggally. No idea it is from 3.0 as I had never used ggpairs before update to 3.0 but it sounds a bit similar
http://support.rstudio.org/help/discussions/problems/6796-ggpairs-in-ggally-very-slow-in-rstudio-and-may-cause-a-crash

John Kane
Kingston ON Canada


> -----Original Message-----
> From: dimitri.liakhovitski at gmail.com
> Sent: Fri, 28 Jun 2013 09:11:40 -0400
> To: r-help at r-project.org, jcolias at decisionanalyst.com, info at rstudio.com
> Subject: Re: [R] choicemodelr is misbehaving under R3.0
> 
> Dear R-studio and R colleagues,
> 
> I've interacted with the authors of the package "ChoiceModelR" and it
> looks
> like there is a problem in the way RStudio interacts with R3.0.
> 
> At least the package ChoiceModelR works just fine under both R gui and
> Rstudio when R version is < 3.0
> When R3.0 is tested - and only R gui is used, the package works just
> fine.
> However, when RStudio is used with R3.0 then the computations by
> ChoiceModelR take hours instead of minutes. The problem has been
> replicated
> with different Windows 7 PCs (32 and 64 bits) and even with a Linux
> computer.
> 
> We are not sure if the same kind of problem exists for other R packages -
> when one uses RStudio in combination with R3.0.
> 
> Could you please look into it? Thank you very much!
> 
> Dimitri
> 
> 
> 
> 
> On Thu, Jun 27, 2013 at 10:37 AM, Dimitri Liakhovitski <
> dimitri.liakhovitski at gmail.com> wrote:
> 
>> Hi John (and other authors of ChoiceModelR package),
>> 
>> I am experiencing a weird thing when using the function choicemodelr
>> under
>> R3.0.1.
>> Before I updated to R3.0, I had used choicemodelr unde R2.15. It was
>> always as fast or faster than exactly the same task in Sawtooth
>> software.
>> Now, I've tried to run it under R3.0.1. It seems to be doing the job.
>> But
>> something is slowing it down dramatically. In the beginning, it showed
>> time
>> left for estimation as 14 min. But then time passed and the time left
>> increased(!) instead of decreasing. My whole run took 1.8 hours. I've
>> run
>> the same thing in Sawtooth - it took 13 min.
>> I replicated the same result under different conditions (restarted my
>> PC,
>> had no other stuff running).
>> 
>> My PC is a 64-bit PC (Windows).
>> Then I asked a colleague who also has R3.0 on his PC to run my code. His
>> PC is a 32-bit one (Windows). Same thing happened to him. It showed time
>> left as 14 min in the beginning and then the time left started growing.
>> Then, I asked a colleague who has R2.15 (on a 32-bit Windows machine) to
>> run my code. It took him 12 minutes!
>> 
>> So, something is going on with ChoiceModelR unde R3.0
>> 
>> 
>> Thanks for looking into it.
>> --
>> Dimitri Liakhovitski
>> 
> 
> 
> 
> --
> Dimitri Liakhovitski
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From S.Ellison at LGCGroup.com  Fri Jun 28 15:28:33 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 28 Jun 2013 14:28:33 +0100
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <CABdHhvEtL0s87GSnn8MFyHtz2CdC-_65iJ6U19mfgs3YkYSC+A@mail.gmail.com>
References: <51C8CBCE.3040903@gmail.com> <1372123341449.dc8da696@Nodemailer>
	<51C97A30.7050802@gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED4AC9F091C5@GOLD.corp.lgc-group.com>
	<CABdHhvEtL0s87GSnn8MFyHtz2CdC-_65iJ6U19mfgs3YkYSC+A@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED4AC9F09BD9@GOLD.corp.lgc-group.com>

 
> > I too find R's lexical scoping rules straightforward.
> > However, I'd say that if your code relies on lexical 
> > scoping to find something, you should probably rewrite your code.
> 
> Except of course that almost every function relies on lexical 
> scoping to some extent!

This could get messy, because a) that's true and b) it actually leads to some genuine risks when 'globals' get redefined or masked*. 

How about I amend the assertion to "if your code relies on lexical scoping to find a variable you defined, you should probably rewrite your code."
and leave it at that, subject to some common sense about whether you know what you're doing?

Steve E


*Example
> sin.deg  <- function(deg) sin(deg * pi/180)
> sin.deg(45)
[1] 0.7071068
	#looks about right 

> pi <- 3.2       #Indiana General Assembly bill #247, 1897. 
> sin.deg(45)
[1] 0.7173561
	#oops ...  


		

*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From murdoch.duncan at gmail.com  Fri Jun 28 15:40:18 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 28 Jun 2013 09:40:18 -0400
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED4AC9F09BD9@GOLD.corp.lgc-group.com>
References: <51C8CBCE.3040903@gmail.com> <1372123341449.dc8da696@Nodemailer>
	<51C97A30.7050802@gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED4AC9F091C5@GOLD.corp.lgc-group.com>
	<CABdHhvEtL0s87GSnn8MFyHtz2CdC-_65iJ6U19mfgs3YkYSC+A@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED4AC9F09BD9@GOLD.corp.lgc-group.com>
Message-ID: <51CD9242.2090707@gmail.com>

On 28/06/2013 9:28 AM, S Ellison wrote:
>   
> > > I too find R's lexical scoping rules straightforward.
> > > However, I'd say that if your code relies on lexical
> > > scoping to find something, you should probably rewrite your code.
> >
> > Except of course that almost every function relies on lexical
> > scoping to some extent!
>
> This could get messy, because a) that's true and b) it actually leads to some genuine risks when 'globals' get redefined or masked*.
>
> How about I amend the assertion to "if your code relies on lexical scoping to find a variable you defined, you should probably rewrite your code."
> and leave it at that, subject to some common sense about whether you know what you're doing?

That still isn't right, because users should feel free to define 
functions and call them from their other functions.

I think who defined it isn't the issue, the issue is whether it might 
change unexpectedly.  The user owns globalenv().  The package author 
owns the package namespace.  So packages should almost never read or 
write things directly from/to globalenv() (the user might change them), 
but they can create their own private environments and write there.

Where it gets a little less clear is when the user writes a function.  I 
would say functions should never write directly to globalenv(), but it's 
perfectly fine to reference constants there (like other functions 
written by the user).  Referencing things there that change is the risky 
thing.

Duncan Murdoch


>
> Steve E
>
>
> *Example
> > sin.deg  <- function(deg) sin(deg * pi/180)
> > sin.deg(45)
> [1] 0.7071068
> 	#looks about right
>
> > pi <- 3.2       #Indiana General Assembly bill #247, 1897.
> > sin.deg(45)
> [1] 0.7173561
> 	#oops ...
>
>
> 		
>
> *******************************************************************
> This email and any attachments are confidential. Any use...{{dropped:8}}
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Fri Jun 28 16:03:05 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 28 Jun 2013 07:03:05 -0700 (PDT)
Subject: [R] Help with tables
Message-ID: <1372428185.19253.YahooMailNeo@web142605.mail.bf1.yahoo.com>

HI,
May be this helps:
dat1<- read.table(text="
date1 time????????????????? date??????? timeSec topic pupilId correct
02/01/2013 14:58 02/01/2013 140323 fdp.fdp 40 TRUE
02/01/2013 14:59 02/01/2013 140372 fdp.fdp 150 TRUE
03/01/2013 11:23 03/01/2013 213833 fdp.percentage_calc_foundation 15 TRUE
03/01/2013 11:23 03/01/2013 213839 fdp.percentage_calc_foundation 57 TRUE
03/01/2013 11:24 03/01/2013 213845 fdp.percentage_calc_foundation 92 TRUE
03/01/2013 11:24 03/01/2013 213852 fdp.percentage_calc_foundation 65 TRUE
03/01/2013 11:24 03/01/2013 213855 fdp.percentage_calc_foundation 111 TRUE
03/01/2013 11:24 03/01/2013 213860 fdp.percentage_calc_foundation 34 TRUE
03/01/2013 11:24 03/01/2013 213864 fdp.percentage_calc_foundation 109 FALSE
03/01/2013 11:24 03/01/2013 213868 fdp.percentage_calc_foundation 148 FALSE
03/01/2013 11:24 03/01/2013 213877 fdp.percentage_calc_foundation 69 FALSE
03/01/2013 11:24 03/01/2013 213878 fdp.percentage_calc_foundation 61 TRUE
03/01/2013 11:24 03/01/2013 213878 fdp.percentage_calc_foundation 11 TRUE
03/01/2013 11:24 03/01/2013 213879 algebra.core.formulae 134 TRUE
03/01/2013 11:24 03/01/2013 213881 fdp.percentage_calc_foundation 63 TRUE
03/01/2013 11:24 03/01/2013 213886 fdp.percentage_calc_foundation 40 TRUE
03/01/2013 11:24 03/01/2013 213887 algebra.core.formulae 68 TRUE
03/01/2013 11:24 03/01/2013 213898 fdp.percentage_calc_foundation 109 TRUE
03/01/2013 11:24 03/01/2013 213899 algebra.core.formulae 111 TRUE
03/01/2013 11:25 03/01/2013 213901 algebra.core.formulae 101 FALSE
03/01/2013 11:25 03/01/2013 213924 fdp.percentage_calc_foundation 150 TRUE
03/01/2013 11:25 03/01/2013 213958 fdp.percentage_calc_foundation 77 TRUE
03/01/2013 11:25 03/01/2013 213959 fdp.percentage_calc_foundation 134 TRUE
03/01/2013 11:26 03/01/2013 213961 algebra.core.formulae 150 TRUE
03/01/2013 11:26 03/01/2013 214007 algebra.core.formulae 114 TRUE
03/01/2013 11:26 03/01/2013 214008 fdp.percentage_calc_foundation 55 FALSE
03/01/2013 11:26 03/01/2013 214009 fdp.percentage_calc_foundation 67 TRUE
03/01/2013 11:26 03/01/2013 214010 fdp.percentage_calc_foundation 24 TRUE
03/01/2013 11:26 03/01/2013 214014 algebra.core.formulae 114 TRUE
03/01/2013 11:26 03/01/2013 214014 algebra.core.equations 55 TRUE
03/01/2013 11:26 03/01/2013 214015 algebra.core.formulae 97 TRUE
03/01/2013 11:26 03/01/2013 214015 fdp.percentage_calc_foundation 154 FALSE
03/01/2013 11:26 03/01/2013 214017 algebra.core.formulae 21 FALSE
03/01/2013 11:26 03/01/2013 214017 fdp.percentage_calc_foundation 24 TRUE
03/01/2013 11:26 03/01/2013 214019 fdp.percentage_calc_foundation 149 TRUE
03/01/2013 11:26 03/01/2013 214019 fdp.percentage_calc_foundation 119 TRUE
03/01/2013 11:27 03/01/2013 214022 algebra.core.formulae 21 TRUE
03/01/2013 11:27 03/01/2013 214023 algebra.core.formulae 103 TRUE
03/01/2013 11:27 03/01/2013 214023 fdp.percentage_calc_foundation 55 TRUE
03/01/2013 11:27 03/01/2013 214024 fdp.percentage_calc_foundation 24 TRUE
03/01/2013 11:27 03/01/2013 214026 algebra.core.formulae 149 TRUE
03/01/2013 11:27 03/01/2013 214026 fdp.percentage_calc_foundation 154 TRUE
03/01/2013 11:27 03/01/2013 214027 algebra.core.formulae 24 TRUE
03/01/2013 11:27 03/01/2013 214078 algebra.core.equations 67 FALSE
03/01/2013 11:28 03/01/2013 214085 fdp.percentage_calc_foundation 119 TRUE
03/01/2013 11:28 03/01/2013 214085 fdp.percentage_calc_foundation 55 FALSE
03/01/2013 11:28 03/01/2013 214085 fdp.percentage_calc_foundation 149 TRUE
03/01/2013 11:28 03/01/2013 214086 algebra.core.formulae 67 FALSE
03/01/2013 11:29 03/01/2013 214169 algebra.core.formulae 92 TRUE
03/01/2013 11:29 03/01/2013 214172 algebra.core.formulae 15 TRUE
03/01/2013 11:29 03/01/2013 214172 algebra.core.equations 119 TRUE
03/01/2013 11:29 03/01/2013 214173 algebra.core.formulae 46 TRUE
03/01/2013 11:29 03/01/2013 214173 fdp.percentage_calc_foundation 146 TRUE
",sep="",header=TRUE,stringsAsFactors=FALSE)
?dat2<- data.frame(timestamp=as.POSIXct(paste(dat1[,1],dat1[,2]),format="%m/%d/%Y %H:%M"), dat1[,-c(1:2)])

?library(xts)
xt1<- xts(dat2[,-1],dat2[,1])

library(stringr)

##1st part
?nrow(xt1["2013-03-01 11:15/2013-03-01 11:28"])
#[1] 46

##2nd part
table(xt1["2013-03-01 11:15/2013-03-01 11:28","topic"])
#
#??????? algebra.core.equations????????? algebra.core.formulae 
#???????????????????????????? 2???????????????????????????? 14 
#fdp.percentage_calc_foundation 
#??????????????????????????? 30 


###3rd question 

Subxt1<-xt1["2013-03-01 11:15/2013-03-01 11:28"]
#Based on number of correct responses
vec1<-sort(with(Subxt1,tapply(as.logical(str_trim(correct)),list(pupilId),sum)))
head(vec1,3)
#101 148? 69 
#? 0?? 0?? 0 
?tail(vec1,3)
# 55 149? 24 
#? 2?? 3?? 4 

#Based on proportion of correct responses
vec2<-with(Subxt1,tapply(as.logical(str_trim(correct)),list(pupilId),length))
vec2New<- vec2[names(vec1)]
?vec3<-sort(vec1/vec2New)
?head(vec3,3)
#101 148? 69 
#? 0?? 0?? 0 
?tail(vec3,3)
#150 149? 24 
#? 1?? 1?? 1 

A.K.



For date 03/01/2013 I need to find how many responses I have between 
11.15 and 11.28. How do I go about producing another table just between 
that specified period and find the number of responses? (each input is a response) 

For this range I need to count how many different topics I have.
 The problem with the topic is that it is not a number, therefore I am 
not sure how to investigate it?? 

Finally, I need to find the 3 strongest and 3 weakest pupils in that same range on the proportion of correct responses given. 

Any help would be extremely appreciated!!! 

Table I have: 
timestamp	 ? ? ? ? ? ? ? ? ? date	 ? ? ? ?timeSec	 topic pupilId	correct 
02/01/2013 14:58	02/01/2013	140323	fdp.fdp	40	TRUE 
02/01/2013 14:59	02/01/2013	140372	fdp.fdp	150	TRUE 
03/01/2013 11:23	03/01/2013	213833	fdp.percentage_calc_foundation	15	TRUE 
03/01/2013 11:23	03/01/2013	213839	fdp.percentage_calc_foundation	57	TRUE 
03/01/2013 11:24	03/01/2013	213845	fdp.percentage_calc_foundation	92	TRUE 
03/01/2013 11:24	03/01/2013	213852	fdp.percentage_calc_foundation	65	TRUE 
03/01/2013 11:24	03/01/2013	213855	fdp.percentage_calc_foundation	111	TRUE 
03/01/2013 11:24	03/01/2013	213860	fdp.percentage_calc_foundation	34	TRUE 
03/01/2013 11:24	03/01/2013	213864	fdp.percentage_calc_foundation	109	FALSE 
03/01/2013 11:24	03/01/2013	213868	fdp.percentage_calc_foundation	148	FALSE 
03/01/2013 11:24	03/01/2013	213877	fdp.percentage_calc_foundation	69	FALSE 
03/01/2013 11:24	03/01/2013	213878	fdp.percentage_calc_foundation	61	TRUE 
03/01/2013 11:24	03/01/2013	213878	fdp.percentage_calc_foundation	11	TRUE 
03/01/2013 11:24	03/01/2013	213879	algebra.core.formulae	134	TRUE 
03/01/2013 11:24	03/01/2013	213881	fdp.percentage_calc_foundation	63	TRUE 
03/01/2013 11:24	03/01/2013	213886	fdp.percentage_calc_foundation	40	TRUE 
03/01/2013 11:24	03/01/2013	213887	algebra.core.formulae	68	TRUE 
03/01/2013 11:24	03/01/2013	213898	fdp.percentage_calc_foundation	109	TRUE 
03/01/2013 11:24	03/01/2013	213899	algebra.core.formulae	111	TRUE 
03/01/2013 11:25	03/01/2013	213901	algebra.core.formulae	101	FALSE 
03/01/2013 11:25	03/01/2013	213924	fdp.percentage_calc_foundation	150	TRUE 
03/01/2013 11:25	03/01/2013	213958	fdp.percentage_calc_foundation	77	TRUE 
03/01/2013 11:25	03/01/2013	213959	fdp.percentage_calc_foundation	134	TRUE 
03/01/2013 11:26	03/01/2013	213961	algebra.core.formulae	150	TRUE 
03/01/2013 11:26	03/01/2013	214007	algebra.core.formulae	114	TRUE 
03/01/2013 11:26	03/01/2013	214008	fdp.percentage_calc_foundation	55	FALSE 
03/01/2013 11:26	03/01/2013	214009	fdp.percentage_calc_foundation	67	TRUE 
03/01/2013 11:26	03/01/2013	214010	fdp.percentage_calc_foundation	24	TRUE 
03/01/2013 11:26	03/01/2013	214014	algebra.core.formulae	114	TRUE 
03/01/2013 11:26	03/01/2013	214014	algebra.core.equations	55	TRUE 
03/01/2013 11:26	03/01/2013	214015	algebra.core.formulae	97	TRUE 
03/01/2013 11:26	03/01/2013	214015	fdp.percentage_calc_foundation	154	FALSE 
03/01/2013 11:26	03/01/2013	214017	algebra.core.formulae	21	FALSE 
03/01/2013 11:26	03/01/2013	214017	fdp.percentage_calc_foundation	24	TRUE 
03/01/2013 11:26	03/01/2013	214019	fdp.percentage_calc_foundation	149	TRUE 
03/01/2013 11:26	03/01/2013	214019	fdp.percentage_calc_foundation	119	TRUE 
03/01/2013 11:27	03/01/2013	214022	algebra.core.formulae	21	TRUE 
03/01/2013 11:27	03/01/2013	214023	algebra.core.formulae	103	TRUE 
03/01/2013 11:27	03/01/2013	214023	fdp.percentage_calc_foundation	55	TRUE 
03/01/2013 11:27	03/01/2013	214024	fdp.percentage_calc_foundation	24	TRUE 
03/01/2013 11:27	03/01/2013	214026	algebra.core.formulae	149	TRUE 
03/01/2013 11:27	03/01/2013	214026	fdp.percentage_calc_foundation	154	TRUE 
03/01/2013 11:27	03/01/2013	214027	algebra.core.formulae	24	TRUE 
03/01/2013 11:27	03/01/2013	214078	algebra.core.equations	67	FALSE 
03/01/2013 11:28	03/01/2013	214085	fdp.percentage_calc_foundation	119	TRUE 
03/01/2013 11:28	03/01/2013	214085	fdp.percentage_calc_foundation	55	FALSE 
03/01/2013 11:28	03/01/2013	214085	fdp.percentage_calc_foundation	149	TRUE 
03/01/2013 11:28	03/01/2013	214086	algebra.core.formulae	67	FALSE 
03/01/2013 11:29	03/01/2013	214169	algebra.core.formulae	92	TRUE 
03/01/2013 11:29	03/01/2013	214172	algebra.core.formulae	15	TRUE 
03/01/2013 11:29	03/01/2013	214172	algebra.core.equations	119	TRUE 
03/01/2013 11:29	03/01/2013	214173	algebra.core.formulae	46	TRUE 
03/01/2013 11:29	03/01/2013	214173	fdp.percentage_calc_foundation	146	TRUE


From jdnewmil at dcn.davis.CA.us  Fri Jun 28 16:08:11 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 28 Jun 2013 07:08:11 -0700
Subject: [R] Data Package Query
In-Reply-To: <DUB118-W294EB3D6BB0340234B135190760@phx.gbl>
References: <1371633615.23367.YahooMailNeo@web160101.mail.bf1.yahoo.com>
	<1371711263.96641.YahooMailNeo@web122105.mail.ne1.yahoo.com>
	<1371725996.86004.YahooMailNeo@web122106.mail.ne1.yahoo.com>
	<DUB405-EAS306523EF12F1C6C0F82988D90750@phx.gbl>
	<a12164e5-fef5-4963-8159-e891210e7dbc@email.android.com>,
	<51CCBCC1.6040508@xtra.co.nz>
	<DUB118-W294EB3D6BB0340234B135190760@phx.gbl>
Message-ID: <fb716205-0c3a-4af3-baa3-ecfe3086ccd3@email.android.com>

You need to learn to execute one statement at a time in order to debug this yourself. Copy and paste is your friend. Hint: I already told you that the data function is inappropriate if the data does not come from a package.

You should be learning to use the str(), head(), and ls() functions to explore your R in-memory environment, and use the built-in help system with the question mark ("?str") or the help.search() and RSiteSearch() functions.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Yasmine Refai <y_refai at hotmail.com> wrote:

>hello,
> 
>please advice what is wrong at the below syntax:
>"Trial<-read.table("Trial.txt",header=TRUE)
>Trial
>save.image(file="Trial.RData")
>data(Trial)
>fit<-logistf(data=Trial, y~x1+x2)
>"
> 
>and here is the error I get:
>"Warning message:
>In data(Trial) : data set ?Trial? not found
>"
> 
>regards,
>yasmine
>
> 
>> Date: Fri, 28 Jun 2013 10:29:21 +1200
>> From: rolf.turner at xtra.co.nz
>> To: jdnewmil at dcn.davis.ca.us
>> CC: y_refai at hotmail.com; r-help at r-project.org
>> Subject: Re: [R] Data Package Query
>> 
>> On 28/06/13 04:47, Jeff Newmiller wrote:
>> 
>>      <SNIP>
>> > A common error by beginners (which may or may not be your problem
>in this case) is to create a variable called "data". Unfortunately this
>hides the function named "data" and from that time forward that R
>session doesn't work when you type example code that uses the data
>function.
>> 
>>      <SNIP>
>> 
>> This is simply not true.  I believe it *used* to be true, sometime 
>> waaaaayyyy back,
>> but hasn't been true for years.  The R language is much cleverer now.
> 
>> If there
>> is a function "melvin()" somewhere on the search path and also a data
>object
>> "melvin" (earlier on the search path) then doing
>> 
>>      melvin(<whatever>)
>> 
>> will correctly call the function melvin() with no complaints.  The R 
>> language
>> "can tell" by the parentheses that you mean the *function* melvin and
>
>> not the
>> data object "melvin".
>> 
>> E.g.
>> 
>>      data <- 42
>>      require(akima)
>>      akima
>>      Error: object 'akima' not found
>>      data(akima)  # No error message, nor nothin'!
>>      akima
>>      # The data set "akima" is displayed.
>> 
>> All that being said it is ***BAD PRACTICE***, just in terms of 
>> comprehensibility
>> and avoiding confusion, to give a data set set the same name as a
>function
>> (either built in, or one of your own).
>> 
>>      fortune("dog")
>> 
>> is relevant.
>> 
>>      cheers,
>> 
>>          Rolf Turner
>> 
>


From armel.kaptue at sdstate.edu  Fri Jun 28 16:18:50 2013
From: armel.kaptue at sdstate.edu (Kaptue Tchuente, Armel)
Date: Fri, 28 Jun 2013 14:18:50 +0000
Subject: [R] How to create a function returning an array ?
In-Reply-To: <51CD8C97.5060806@gmail.com>
References: <9879AF1F439EF943BDEE22D3AAA5C3F683FCFE9E@sdsu-ex01.jacks.local>
	<B84290A7-2D2F-482A-9A55-BFBF10B354F5@comcast.net>
	<51CD8C97.5060806@gmail.com>
Message-ID: <9879AF1F439EF943BDEE22D3AAA5C3F683FD013D@sdsu-ex01.jacks.local>

@ Duncan, I have already used the syntax that you proposed before asking for help by writing something like 
> read_ts<-function(n,m,img) {
>  out<-.Fortran("read_ts",
>                as.integer(n),
>                as.integer(m),
>                img=as.single(rnorm(n*m)))
> return(out$img)
> alpha<-read_ts(n,m)
> dim(alpha)<-c(n*m)
> alpha<-t(alpha)
My worry with this syntax is that (i) the program is not very efficient because n and m are very big and these two additional instructions (dim(alpha)<-c(n*m and alpha<-t(alpha) can be skipped just by directly declaring img as an array in fortran instead of a vector and (ii) the syntax will become more complex dealing with a multidimensional array instead of a matrix as in this example.
And this is why I'm looking for the correct instruction to declare img as an array instead of a vector.

Armel

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Friday, June 28, 2013 8:16 AM
To: David Winsemius
Cc: Kaptue Tchuente, Armel; r-help at r-project.org
Subject: Re: [R] How to create a function returning an array ?

On 27/06/2013 11:38 PM, David Winsemius wrote:
> On Jun 27, 2013, at 8:04 PM, Kaptue Tchuente, Armel wrote:
>
> > Hi there,
> >
> > I would like to know how to change the line 
> > "img=as.single(rnorm(m)))" such that instead of being a vector of 
> > length m as it is now, img is an array of dimension c=(n,m,o) for 
> > instance
> >
> > ---------------------------------
> > read_ts<-function(n,m,o,img) {
> >   out<-.Fortran("read_ts",
> >                as.integer(n),
> >                as.integer(m),
> >                as.integer(o),
> >                img=as.single(rnorm(n)))
> >   return(out$img)
> > ------------------------------------------
> >
>
> Well, assuming that  the 'out$img' object has a R-length of n*m*o , wouldn't if be simpler to just change the return call to:

In fact, out$img has a length of n, same as on input.  .Fortran won't change the length of its arguments.

Duncan Murdoch

>
> return( array( out$img, dim=c(n,m,o) )
>
> I don't think you wnat start naming your dimension vectors "c".
>


From murdoch.duncan at gmail.com  Fri Jun 28 16:29:43 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 28 Jun 2013 10:29:43 -0400
Subject: [R] How to create a function returning an array ?
In-Reply-To: <9879AF1F439EF943BDEE22D3AAA5C3F683FD013D@sdsu-ex01.jacks.local>
References: <9879AF1F439EF943BDEE22D3AAA5C3F683FCFE9E@sdsu-ex01.jacks.local>
	<B84290A7-2D2F-482A-9A55-BFBF10B354F5@comcast.net>
	<51CD8C97.5060806@gmail.com>
	<9879AF1F439EF943BDEE22D3AAA5C3F683FD013D@sdsu-ex01.jacks.local>
Message-ID: <51CD9DD7.1040908@gmail.com>

On 28/06/2013 10:18 AM, Kaptue Tchuente, Armel wrote:
> @ Duncan, I have already used the syntax that you proposed before asking for help by writing something like
> > read_ts<-function(n,m,img) {
> >  out<-.Fortran("read_ts",
> >                as.integer(n),
> >                as.integer(m),
> >                img=as.single(rnorm(n*m)))
> > return(out$img)
> > alpha<-read_ts(n,m)
> > dim(alpha)<-c(n*m)
> > alpha<-t(alpha)
> My worry with this syntax is that (i) the program is not very efficient because n and m are very big and these two additional instructions (dim(alpha)<-c(n*m and alpha<-t(alpha) can be skipped just by directly declaring img as an array in fortran instead of a vector and (ii) the syntax will become more complex dealing with a multidimensional array instead of a matrix as in this example.
> And this is why I'm looking for the correct instruction to declare img as an array instead of a vector.

There are several typos in your code above, but I think your intention 
is clear.

You can do what you are asking for, but not with .Fortran.  It only 
handles vectors for input and output.  You'll need to use .Call (which 
means writing in C or C++).  If you're familiar with C++, using Rcpp is 
probably the easiest way to do this.  If not, I'd rewrite the Fortran 
code to avoid the need for the transpose at the end, and do

dim(out$img) <- c(n,m)
return(out$img)

within your read_ts function.  I think this is reasonably efficient.

Duncan Murdoch


>
> Armel
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Friday, June 28, 2013 8:16 AM
> To: David Winsemius
> Cc: Kaptue Tchuente, Armel; r-help at r-project.org
> Subject: Re: [R] How to create a function returning an array ?
>
> On 27/06/2013 11:38 PM, David Winsemius wrote:
> > On Jun 27, 2013, at 8:04 PM, Kaptue Tchuente, Armel wrote:
> >
> > > Hi there,
> > >
> > > I would like to know how to change the line
> > > "img=as.single(rnorm(m)))" such that instead of being a vector of
> > > length m as it is now, img is an array of dimension c=(n,m,o) for
> > > instance
> > >
> > > ---------------------------------
> > > read_ts<-function(n,m,o,img) {
> > >   out<-.Fortran("read_ts",
> > >                as.integer(n),
> > >                as.integer(m),
> > >                as.integer(o),
> > >                img=as.single(rnorm(n)))
> > >   return(out$img)
> > > ------------------------------------------
> > >
> >
> > Well, assuming that  the 'out$img' object has a R-length of n*m*o , wouldn't if be simpler to just change the return call to:
>
> In fact, out$img has a length of n, same as on input.  .Fortran won't change the length of its arguments.
>
> Duncan Murdoch
>
> >
> > return( array( out$img, dim=c(n,m,o) )
> >
> > I don't think you wnat start naming your dimension vectors "c".
> >
>


From armel.kaptue at sdstate.edu  Fri Jun 28 16:46:56 2013
From: armel.kaptue at sdstate.edu (Kaptue Tchuente, Armel)
Date: Fri, 28 Jun 2013 14:46:56 +0000
Subject: [R] How to create a function returning an array ?
In-Reply-To: <51CD9DD7.1040908@gmail.com>
References: <9879AF1F439EF943BDEE22D3AAA5C3F683FCFE9E@sdsu-ex01.jacks.local>
	<B84290A7-2D2F-482A-9A55-BFBF10B354F5@comcast.net>
	<51CD8C97.5060806@gmail.com>
	<9879AF1F439EF943BDEE22D3AAA5C3F683FD013D@sdsu-ex01.jacks.local>
	<51CD9DD7.1040908@gmail.com>
Message-ID: <9879AF1F439EF943BDEE22D3AAA5C3F683FD017D@sdsu-ex01.jacks.local>

Please could you explain what you mean by several typos in my code?

Anyway, it works very well and keep in minds that here I just wrote a very simple code to illustrate what I really want since in the reality, the program is more complex than what you see.
May be I'm wrong but I also prefer to call this fortran function because I realized that (i) R is not very efficient for large data sets reading and processing and (ii) the speed of execution in Fortran is faster than in C.

Armel

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Friday, June 28, 2013 9:30 AM
To: Kaptue Tchuente, Armel
Cc: r-help at r-project.org
Subject: Re: [R] How to create a function returning an array ?

On 28/06/2013 10:18 AM, Kaptue Tchuente, Armel wrote:
> @ Duncan, I have already used the syntax that you proposed before 
> asking for help by writing something like
> > read_ts<-function(n,m,img) {
> >  out<-.Fortran("read_ts",
> >                as.integer(n),
> >                as.integer(m),
> >                img=as.single(rnorm(n*m)))
> > return(out$img)
> > alpha<-read_ts(n,m)
> > dim(alpha)<-c(n*m)
> > alpha<-t(alpha)
> My worry with this syntax is that (i) the program is not very efficient because n and m are very big and these two additional instructions (dim(alpha)<-c(n*m and alpha<-t(alpha) can be skipped just by directly declaring img as an array in fortran instead of a vector and (ii) the syntax will become more complex dealing with a multidimensional array instead of a matrix as in this example.
> And this is why I'm looking for the correct instruction to declare img as an array instead of a vector.

There are several typos in your code above, but I think your intention is clear.

You can do what you are asking for, but not with .Fortran.  It only handles vectors for input and output.  You'll need to use .Call (which means writing in C or C++).  If you're familiar with C++, using Rcpp is probably the easiest way to do this.  If not, I'd rewrite the Fortran code to avoid the need for the transpose at the end, and do

dim(out$img) <- c(n,m)
return(out$img)

within your read_ts function.  I think this is reasonably efficient.

Duncan Murdoch


>
> Armel
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Friday, June 28, 2013 8:16 AM
> To: David Winsemius
> Cc: Kaptue Tchuente, Armel; r-help at r-project.org
> Subject: Re: [R] How to create a function returning an array ?
>
> On 27/06/2013 11:38 PM, David Winsemius wrote:
> > On Jun 27, 2013, at 8:04 PM, Kaptue Tchuente, Armel wrote:
> >
> > > Hi there,
> > >
> > > I would like to know how to change the line 
> > > "img=as.single(rnorm(m)))" such that instead of being a vector of 
> > > length m as it is now, img is an array of dimension c=(n,m,o) for 
> > > instance
> > >
> > > ---------------------------------
> > > read_ts<-function(n,m,o,img) {
> > >   out<-.Fortran("read_ts",
> > >                as.integer(n),
> > >                as.integer(m),
> > >                as.integer(o),
> > >                img=as.single(rnorm(n)))
> > >   return(out$img)
> > > ------------------------------------------
> > >
> >
> > Well, assuming that  the 'out$img' object has a R-length of n*m*o , wouldn't if be simpler to just change the return call to:
>
> In fact, out$img has a length of n, same as on input.  .Fortran won't change the length of its arguments.
>
> Duncan Murdoch
>
> >
> > return( array( out$img, dim=c(n,m,o) )
> >
> > I don't think you wnat start naming your dimension vectors "c".
> >
>


From murdoch.duncan at gmail.com  Fri Jun 28 16:53:25 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 28 Jun 2013 10:53:25 -0400
Subject: [R] How to create a function returning an array ?
In-Reply-To: <9879AF1F439EF943BDEE22D3AAA5C3F683FD017D@sdsu-ex01.jacks.local>
References: <9879AF1F439EF943BDEE22D3AAA5C3F683FCFE9E@sdsu-ex01.jacks.local>
	<B84290A7-2D2F-482A-9A55-BFBF10B354F5@comcast.net>
	<51CD8C97.5060806@gmail.com>
	<9879AF1F439EF943BDEE22D3AAA5C3F683FD013D@sdsu-ex01.jacks.local>
	<51CD9DD7.1040908@gmail.com>
	<9879AF1F439EF943BDEE22D3AAA5C3F683FD017D@sdsu-ex01.jacks.local>
Message-ID: <51CDA365.7040907@gmail.com>

On 28/06/2013 10:46 AM, Kaptue Tchuente, Armel wrote:
> Please could you explain what you mean by several typos in my code?

1. img is passed as an argument, but never used.
2. There is no closing brace on the function body.
3.  You set the dimension to n*m, when I believe you wanted c(n, m).

Duncan Murdoch

>
> Anyway, it works very well and keep in minds that here I just wrote a very simple code to illustrate what I really want since in the reality, the program is more complex than what you see.
> May be I'm wrong but I also prefer to call this fortran function because I realized that (i) R is not very efficient for large data sets reading and processing and (ii) the speed of execution in Fortran is faster than in C.
>
> Armel
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Friday, June 28, 2013 9:30 AM
> To: Kaptue Tchuente, Armel
> Cc: r-help at r-project.org
> Subject: Re: [R] How to create a function returning an array ?
>
> On 28/06/2013 10:18 AM, Kaptue Tchuente, Armel wrote:
> > @ Duncan, I have already used the syntax that you proposed before
> > asking for help by writing something like
> > > read_ts<-function(n,m,img) {
> > >  out<-.Fortran("read_ts",
> > >                as.integer(n),
> > >                as.integer(m),
> > >                img=as.single(rnorm(n*m)))
> > > return(out$img)
> > > alpha<-read_ts(n,m)
> > > dim(alpha)<-c(n*m)
> > > alpha<-t(alpha)
> > My worry with this syntax is that (i) the program is not very efficient because n and m are very big and these two additional instructions (dim(alpha)<-c(n*m and alpha<-t(alpha) can be skipped just by directly declaring img as an array in fortran instead of a vector and (ii) the syntax will become more complex dealing with a multidimensional array instead of a matrix as in this example.
> > And this is why I'm looking for the correct instruction to declare img as an array instead of a vector.
>
> There are several typos in your code above, but I think your intention is clear.
>
> You can do what you are asking for, but not with .Fortran.  It only handles vectors for input and output.  You'll need to use .Call (which means writing in C or C++).  If you're familiar with C++, using Rcpp is probably the easiest way to do this.  If not, I'd rewrite the Fortran code to avoid the need for the transpose at the end, and do
>
> dim(out$img) <- c(n,m)
> return(out$img)
>
> within your read_ts function.  I think this is reasonably efficient.
>
> Duncan Murdoch
>
>
> >
> > Armel
> >
> > -----Original Message-----
> > From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> > Sent: Friday, June 28, 2013 8:16 AM
> > To: David Winsemius
> > Cc: Kaptue Tchuente, Armel; r-help at r-project.org
> > Subject: Re: [R] How to create a function returning an array ?
> >
> > On 27/06/2013 11:38 PM, David Winsemius wrote:
> > > On Jun 27, 2013, at 8:04 PM, Kaptue Tchuente, Armel wrote:
> > >
> > > > Hi there,
> > > >
> > > > I would like to know how to change the line
> > > > "img=as.single(rnorm(m)))" such that instead of being a vector of
> > > > length m as it is now, img is an array of dimension c=(n,m,o) for
> > > > instance
> > > >
> > > > ---------------------------------
> > > > read_ts<-function(n,m,o,img) {
> > > >   out<-.Fortran("read_ts",
> > > >                as.integer(n),
> > > >                as.integer(m),
> > > >                as.integer(o),
> > > >                img=as.single(rnorm(n)))
> > > >   return(out$img)
> > > > ------------------------------------------
> > > >
> > >
> > > Well, assuming that  the 'out$img' object has a R-length of n*m*o , wouldn't if be simpler to just change the return call to:
> >
> > In fact, out$img has a length of n, same as on input.  .Fortran won't change the length of its arguments.
> >
> > Duncan Murdoch
> >
> > >
> > > return( array( out$img, dim=c(n,m,o) )
> > >
> > > I don't think you wnat start naming your dimension vectors "c".
> > >
> >
>


From jfox at mcmaster.ca  Fri Jun 28 16:54:23 2013
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 28 Jun 2013 10:54:23 -0400
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <51CD9242.2090707@gmail.com>
References: <51C8CBCE.3040903@gmail.com>
	<1372123341449.dc8da696@Nodemailer>	<51C97A30.7050802@gmail.com>	<A4E5A0B016B8CB41A485FC629B633CED4AC9F091C5@GOLD.corp.lgc-group.com>	<CABdHhvEtL0s87GSnn8MFyHtz2CdC-_65iJ6U19mfgs3YkYSC+A@mail.gmail.com>	<A4E5A0B016B8CB41A485FC629B633CED4AC9F09BD9@GOLD.corp.lgc-group.com>
	<51CD9242.2090707@gmail.com>
Message-ID: <001701ce740f$61154b40$233fe1c0$@mcmaster.ca>

Dear Duncan and Steve,

Since Steve's example raises it, I've never understood why it's legal to
change the built-in global "constants" in R, including T and F. That just
seems to me to set a trap for users. Why not treat these as reserved
symbols, like TRUE, Inf, etc.?

Best,
 John

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Duncan Murdoch
> Sent: Friday, June 28, 2013 9:40 AM
> To: S Ellison
> Cc: r-help at r-project.org
> Subject: Re: [R] Lexical scoping is not what I expect
> 
> On 28/06/2013 9:28 AM, S Ellison wrote:
> >
> > > > I too find R's lexical scoping rules straightforward.
> > > > However, I'd say that if your code relies on lexical
> > > > scoping to find something, you should probably rewrite your code.
> > >
> > > Except of course that almost every function relies on lexical
> > > scoping to some extent!
> >
> > This could get messy, because a) that's true and b) it actually leads
> to some genuine risks when 'globals' get redefined or masked*.
> >
> > How about I amend the assertion to "if your code relies on lexical
> scoping to find a variable you defined, you should probably rewrite
> your code."
> > and leave it at that, subject to some common sense about whether you
> know what you're doing?
> 
> That still isn't right, because users should feel free to define
> functions and call them from their other functions.
> 
> I think who defined it isn't the issue, the issue is whether it might
> change unexpectedly.  The user owns globalenv().  The package author
> owns the package namespace.  So packages should almost never read or
> write things directly from/to globalenv() (the user might change them),
> but they can create their own private environments and write there.
> 
> Where it gets a little less clear is when the user writes a function.
> I
> would say functions should never write directly to globalenv(), but
> it's
> perfectly fine to reference constants there (like other functions
> written by the user).  Referencing things there that change is the
> risky
> thing.
> 
> Duncan Murdoch
> 
> 
> >
> > Steve E
> >
> >
> > *Example
> > > sin.deg  <- function(deg) sin(deg * pi/180)
> > > sin.deg(45)
> > [1] 0.7071068
> > 	#looks about right
> >
> > > pi <- 3.2       #Indiana General Assembly bill #247, 1897.
> > > sin.deg(45)
> > [1] 0.7173561
> > 	#oops ...
> >
> >
> >
> >
> > *******************************************************************
> > This email and any attachments are confidential. Any
> use...{{dropped:8}}
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Fri Jun 28 17:07:10 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 28 Jun 2013 11:07:10 -0400
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <001701ce740f$61154b40$233fe1c0$@mcmaster.ca>
References: <51C8CBCE.3040903@gmail.com>
	<1372123341449.dc8da696@Nodemailer>	<51C97A30.7050802@gmail.com>	<A4E5A0B016B8CB41A485FC629B633CED4AC9F091C5@GOLD.corp.lgc-group.com>	<CABdHhvEtL0s87GSnn8MFyHtz2CdC-_65iJ6U19mfgs3YkYSC+A@mail.gmail.com>	<A4E5A0B016B8CB41A485FC629B633CED4AC9F09BD9@GOLD.corp.lgc-group.com>
	<51CD9242.2090707@gmail.com>
	<001701ce740f$61154b40$233fe1c0$@mcmaster.ca>
Message-ID: <51CDA69E.5010403@gmail.com>

On 28/06/2013 10:54 AM, John Fox wrote:
> Dear Duncan and Steve,
>
> Since Steve's example raises it, I've never understood why it's legal to
> change the built-in global "constants" in R, including T and F. That just
> seems to me to set a trap for users. Why not treat these as reserved
> symbols, like TRUE, Inf, etc.?

If we weren't allowed to change T and F, would we be allowed to change 
other "constants", like functions mean or max? If we couldn't change 
anything defined in the base package, would we be allowed to change 
things defined in other packages like stats or utils or graphics?  I 
think it's simply a matter of setting the line somewhere, and R has 
chosen to set it in the most permissive place that's reasonable.  It 
assumes that its users know what they are doing.

Why not allow changes to TRUE or Inf?   TRUE is a constant, whereas T is 
a variable containing TRUE.  Inf is also a constant, corresponding to a 
length one vector containing that value.  Those are treated by the 
parser like 2 or "hello".  It would be really bad if someone could 
change the meaning of 2 (though I hear some old Fortran compilers 
allowed that), but is it really so bad to allow someone to define their 
own plot function, or temperature variable named T?

Duncan Murdoch
>
> Best,
>   John
>
> > -----Original Message-----
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> > project.org] On Behalf Of Duncan Murdoch
> > Sent: Friday, June 28, 2013 9:40 AM
> > To: S Ellison
> > Cc: r-help at r-project.org
> > Subject: Re: [R] Lexical scoping is not what I expect
> >
> > On 28/06/2013 9:28 AM, S Ellison wrote:
> > >
> > > > > I too find R's lexical scoping rules straightforward.
> > > > > However, I'd say that if your code relies on lexical
> > > > > scoping to find something, you should probably rewrite your code.
> > > >
> > > > Except of course that almost every function relies on lexical
> > > > scoping to some extent!
> > >
> > > This could get messy, because a) that's true and b) it actually leads
> > to some genuine risks when 'globals' get redefined or masked*.
> > >
> > > How about I amend the assertion to "if your code relies on lexical
> > scoping to find a variable you defined, you should probably rewrite
> > your code."
> > > and leave it at that, subject to some common sense about whether you
> > know what you're doing?
> >
> > That still isn't right, because users should feel free to define
> > functions and call them from their other functions.
> >
> > I think who defined it isn't the issue, the issue is whether it might
> > change unexpectedly.  The user owns globalenv().  The package author
> > owns the package namespace.  So packages should almost never read or
> > write things directly from/to globalenv() (the user might change them),
> > but they can create their own private environments and write there.
> >
> > Where it gets a little less clear is when the user writes a function.
> > I
> > would say functions should never write directly to globalenv(), but
> > it's
> > perfectly fine to reference constants there (like other functions
> > written by the user).  Referencing things there that change is the
> > risky
> > thing.
> >
> > Duncan Murdoch
> >
> >
> > >
> > > Steve E
> > >
> > >
> > > *Example
> > > > sin.deg  <- function(deg) sin(deg * pi/180)
> > > > sin.deg(45)
> > > [1] 0.7071068
> > > 	#looks about right
> > >
> > > > pi <- 3.2       #Indiana General Assembly bill #247, 1897.
> > > > sin.deg(45)
> > > [1] 0.7173561
> > > 	#oops ...
> > >
> > >
> > >
> > >
> > > *******************************************************************
> > > This email and any attachments are confidential. Any
> > use...{{dropped:8}}
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


From ripley at stats.ox.ac.uk  Fri Jun 28 17:16:20 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 28 Jun 2013 16:16:20 +0100
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <001701ce740f$61154b40$233fe1c0$@mcmaster.ca>
References: <51C8CBCE.3040903@gmail.com>
	<1372123341449.dc8da696@Nodemailer>	<51C97A30.7050802@gmail.com>	<A4E5A0B016B8CB41A485FC629B633CED4AC9F091C5@GOLD.corp.lgc-group.com>	<CABdHhvEtL0s87GSnn8MFyHtz2CdC-_65iJ6U19mfgs3YkYSC+A@mail.gmail.com>	<A4E5A0B016B8CB41A485FC629B633CED4AC9F09BD9@GOLD.corp.lgc-group.com>
	<51CD9242.2090707@gmail.com>
	<001701ce740f$61154b40$233fe1c0$@mcmaster.ca>
Message-ID: <51CDA8C4.7080107@stats.ox.ac.uk>

On 28/06/2013 15:54, John Fox wrote:
> Dear Duncan and Steve,
>
> Since Steve's example raises it, I've never understood why it's legal to
> change the built-in global "constants" in R, including T and F. That just
> seems to me to set a trap for users. Why not treat these as reserved
> symbols, like TRUE, Inf, etc.?

Because people wanted to use them as names of things.  Maybe a T (not t) 
statistic.

And BTW, you can change the value of T for yourself, but you will not 
change it for any package code, including R itself, since the base 
namespace is ahead of the workspace in namespace scoping.  Because of 
that, it is years since I have seen anyone actually trip themselves up 
over this.

>
> Best,
>   John
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Duncan Murdoch
>> Sent: Friday, June 28, 2013 9:40 AM
>> To: S Ellison
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Lexical scoping is not what I expect
>>
>> On 28/06/2013 9:28 AM, S Ellison wrote:
>>>
>>>>> I too find R's lexical scoping rules straightforward.
>>>>> However, I'd say that if your code relies on lexical
>>>>> scoping to find something, you should probably rewrite your code.
>>>>
>>>> Except of course that almost every function relies on lexical
>>>> scoping to some extent!
>>>
>>> This could get messy, because a) that's true and b) it actually leads
>> to some genuine risks when 'globals' get redefined or masked*.
>>>
>>> How about I amend the assertion to "if your code relies on lexical
>> scoping to find a variable you defined, you should probably rewrite
>> your code."
>>> and leave it at that, subject to some common sense about whether you
>> know what you're doing?
>>
>> That still isn't right, because users should feel free to define
>> functions and call them from their other functions.
>>
>> I think who defined it isn't the issue, the issue is whether it might
>> change unexpectedly.  The user owns globalenv().  The package author
>> owns the package namespace.  So packages should almost never read or
>> write things directly from/to globalenv() (the user might change them),
>> but they can create their own private environments and write there.
>>
>> Where it gets a little less clear is when the user writes a function.
>> I
>> would say functions should never write directly to globalenv(), but
>> it's
>> perfectly fine to reference constants there (like other functions
>> written by the user).  Referencing things there that change is the
>> risky
>> thing.
>>
>> Duncan Murdoch
>>
>>
>>>
>>> Steve E
>>>
>>>
>>> *Example
>>>> sin.deg  <- function(deg) sin(deg * pi/180)
>>>> sin.deg(45)
>>> [1] 0.7071068
>>> 	#looks about right
>>>
>>>> pi <- 3.2       #Indiana General Assembly bill #247, 1897.
>>>> sin.deg(45)
>>> [1] 0.7173561
>>> 	#oops ...
>>>
>>>
>>>
>>>
>>> *******************************************************************
>>> This email and any attachments are confidential. Any
>> use...{{dropped:8}}
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From armel.kaptue at sdstate.edu  Fri Jun 28 17:21:46 2013
From: armel.kaptue at sdstate.edu (Kaptue Tchuente, Armel)
Date: Fri, 28 Jun 2013 15:21:46 +0000
Subject: [R] How to create a function returning an array ?
In-Reply-To: <51CDA365.7040907@gmail.com>
References: <9879AF1F439EF943BDEE22D3AAA5C3F683FCFE9E@sdsu-ex01.jacks.local>
	<B84290A7-2D2F-482A-9A55-BFBF10B354F5@comcast.net>
	<51CD8C97.5060806@gmail.com>
	<9879AF1F439EF943BDEE22D3AAA5C3F683FD013D@sdsu-ex01.jacks.local>
	<51CD9DD7.1040908@gmail.com>
	<9879AF1F439EF943BDEE22D3AAA5C3F683FD017D@sdsu-ex01.jacks.local>
	<51CDA365.7040907@gmail.com>
Message-ID: <9879AF1F439EF943BDEE22D3AAA5C3F683FD01AA@sdsu-ex01.jacks.local>

Your comments #2 and 3 are correct.
The closing brace is missing and. Normally the end of the pr after the instruction 
For the comment #1 relate to the declaration img, I don't know if there is another way to import data from fortran in R.

Armel

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Friday, June 28, 2013 9:53 AM
To: Kaptue Tchuente, Armel
Cc: r-help at r-project.org
Subject: Re: [R] How to create a function returning an array ?

On 28/06/2013 10:46 AM, Kaptue Tchuente, Armel wrote:
> Please could you explain what you mean by several typos in my code?

1. img is passed as an argument, but never used.
2. There is no closing brace on the function body.
3.  You set the dimension to n*m, when I believe you wanted c(n, m).

Duncan Murdoch

>
> Anyway, it works very well and keep in minds that here I just wrote a very simple code to illustrate what I really want since in the reality, the program is more complex than what you see.
> May be I'm wrong but I also prefer to call this fortran function because I realized that (i) R is not very efficient for large data sets reading and processing and (ii) the speed of execution in Fortran is faster than in C.
>
> Armel
>
> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Friday, June 28, 2013 9:30 AM
> To: Kaptue Tchuente, Armel
> Cc: r-help at r-project.org
> Subject: Re: [R] How to create a function returning an array ?
>
> On 28/06/2013 10:18 AM, Kaptue Tchuente, Armel wrote:
> > @ Duncan, I have already used the syntax that you proposed before 
> > asking for help by writing something like
> > > read_ts<-function(n,m,img) {
> > >  out<-.Fortran("read_ts",
> > >                as.integer(n),
> > >                as.integer(m),
> > >                img=as.single(rnorm(n*m)))
> > > return(out$img)
> > > alpha<-read_ts(n,m)
> > > dim(alpha)<-c(n*m)
> > > alpha<-t(alpha)
> > My worry with this syntax is that (i) the program is not very efficient because n and m are very big and these two additional instructions (dim(alpha)<-c(n*m and alpha<-t(alpha) can be skipped just by directly declaring img as an array in fortran instead of a vector and (ii) the syntax will become more complex dealing with a multidimensional array instead of a matrix as in this example.
> > And this is why I'm looking for the correct instruction to declare img as an array instead of a vector.
>
> There are several typos in your code above, but I think your intention is clear.
>
> You can do what you are asking for, but not with .Fortran.  It only 
> handles vectors for input and output.  You'll need to use .Call (which 
> means writing in C or C++).  If you're familiar with C++, using Rcpp 
> is probably the easiest way to do this.  If not, I'd rewrite the 
> Fortran code to avoid the need for the transpose at the end, and do
>
> dim(out$img) <- c(n,m)
> return(out$img)
>
> within your read_ts function.  I think this is reasonably efficient.
>
> Duncan Murdoch
>
>
> >
> > Armel
> >
> > -----Original Message-----
> > From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> > Sent: Friday, June 28, 2013 8:16 AM
> > To: David Winsemius
> > Cc: Kaptue Tchuente, Armel; r-help at r-project.org
> > Subject: Re: [R] How to create a function returning an array ?
> >
> > On 27/06/2013 11:38 PM, David Winsemius wrote:
> > > On Jun 27, 2013, at 8:04 PM, Kaptue Tchuente, Armel wrote:
> > >
> > > > Hi there,
> > > >
> > > > I would like to know how to change the line 
> > > > "img=as.single(rnorm(m)))" such that instead of being a vector 
> > > > of length m as it is now, img is an array of dimension c=(n,m,o) 
> > > > for instance
> > > >
> > > > ---------------------------------
> > > > read_ts<-function(n,m,o,img) {
> > > >   out<-.Fortran("read_ts",
> > > >                as.integer(n),
> > > >                as.integer(m),
> > > >                as.integer(o),
> > > >                img=as.single(rnorm(n)))
> > > >   return(out$img)
> > > > ------------------------------------------
> > > >
> > >
> > > Well, assuming that  the 'out$img' object has a R-length of n*m*o , wouldn't if be simpler to just change the return call to:
> >
> > In fact, out$img has a length of n, same as on input.  .Fortran won't change the length of its arguments.
> >
> > Duncan Murdoch
> >
> > >
> > > return( array( out$img, dim=c(n,m,o) )
> > >
> > > I don't think you wnat start naming your dimension vectors "c".
> > >
> >
>


From jfox at mcmaster.ca  Fri Jun 28 17:23:49 2013
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 28 Jun 2013 11:23:49 -0400
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <51CDA69E.5010403@gmail.com>
References: <51C8CBCE.3040903@gmail.com>
	<1372123341449.dc8da696@Nodemailer>	<51C97A30.7050802@gmail.com>	<A4E5A0B016B8CB41A485FC629B633CED4AC9F091C5@GOLD.corp.lgc-group.com>	<CABdHhvEtL0s87GSnn8MFyHtz2CdC-_65iJ6U19mfgs3YkYSC+A@mail.gmail.com>	<A4E5A0B016B8CB41A485FC629B633CED4AC9F09BD9@GOLD.corp.lgc-group.com>
	<51CD9242.2090707@gmail.com>
	<001701ce740f$61154b40$233fe1c0$@mcmaster.ca>
	<51CDA69E.5010403@gmail.com>
Message-ID: <001f01ce7413$7da48e20$78edaa60$@mcmaster.ca>

Dear Duncan,

I think that it's reasonable to make a distinction between symbols
representing functions and those representing built-in constants, even if,
as in the case of pi and T (and letters, etc.), the latter are technically
implemented as variables. 

Although it may be natural to use the variable T for temperature or F for an
F-value (or pi for what?), nothing fundamental is gained by the ability to
do so (one could use temp or fvalue or Pi), while in the case of a function,
one can consciously mask, e.g., the standard mean(). I'm not sure that it's
generally wise for users to redefine functions like mean(), but I can see a
use for the ability to do that.

Please don't feel the need to reply if you don't wish to -- this isn't in my
opinion an important issue.

Best,
 John

> -----Original Message-----
> From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Sent: Friday, June 28, 2013 11:07 AM
> To: John Fox
> Cc: 'S Ellison'; r-help at r-project.org
> Subject: Re: [R] Lexical scoping is not what I expect
> 
> On 28/06/2013 10:54 AM, John Fox wrote:
> > Dear Duncan and Steve,
> >
> > Since Steve's example raises it, I've never understood why it's legal
> to
> > change the built-in global "constants" in R, including T and F. That
> just
> > seems to me to set a trap for users. Why not treat these as reserved
> > symbols, like TRUE, Inf, etc.?
> 
> If we weren't allowed to change T and F, would we be allowed to change
> other "constants", like functions mean or max? If we couldn't change
> anything defined in the base package, would we be allowed to change
> things defined in other packages like stats or utils or graphics?  I
> think it's simply a matter of setting the line somewhere, and R has
> chosen to set it in the most permissive place that's reasonable.  It
> assumes that its users know what they are doing.
> 
> Why not allow changes to TRUE or Inf?   TRUE is a constant, whereas T
> is
> a variable containing TRUE.  Inf is also a constant, corresponding to a
> length one vector containing that value.  Those are treated by the
> parser like 2 or "hello".  It would be really bad if someone could
> change the meaning of 2 (though I hear some old Fortran compilers
> allowed that), but is it really so bad to allow someone to define their
> own plot function, or temperature variable named T?
> 
> Duncan Murdoch
> >
> > Best,
> >   John
> >
> > > -----Original Message-----
> > > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> > > project.org] On Behalf Of Duncan Murdoch
> > > Sent: Friday, June 28, 2013 9:40 AM
> > > To: S Ellison
> > > Cc: r-help at r-project.org
> > > Subject: Re: [R] Lexical scoping is not what I expect
> > >
> > > On 28/06/2013 9:28 AM, S Ellison wrote:
> > > >
> > > > > > I too find R's lexical scoping rules straightforward.
> > > > > > However, I'd say that if your code relies on lexical
> > > > > > scoping to find something, you should probably rewrite your
> code.
> > > > >
> > > > > Except of course that almost every function relies on lexical
> > > > > scoping to some extent!
> > > >
> > > > This could get messy, because a) that's true and b) it actually
> leads
> > > to some genuine risks when 'globals' get redefined or masked*.
> > > >
> > > > How about I amend the assertion to "if your code relies on
> lexical
> > > scoping to find a variable you defined, you should probably rewrite
> > > your code."
> > > > and leave it at that, subject to some common sense about whether
> you
> > > know what you're doing?
> > >
> > > That still isn't right, because users should feel free to define
> > > functions and call them from their other functions.
> > >
> > > I think who defined it isn't the issue, the issue is whether it
> might
> > > change unexpectedly.  The user owns globalenv().  The package
> author
> > > owns the package namespace.  So packages should almost never read
> or
> > > write things directly from/to globalenv() (the user might change
> them),
> > > but they can create their own private environments and write there.
> > >
> > > Where it gets a little less clear is when the user writes a
> function.
> > > I
> > > would say functions should never write directly to globalenv(), but
> > > it's
> > > perfectly fine to reference constants there (like other functions
> > > written by the user).  Referencing things there that change is the
> > > risky
> > > thing.
> > >
> > > Duncan Murdoch
> > >
> > >
> > > >
> > > > Steve E
> > > >
> > > >
> > > > *Example
> > > > > sin.deg  <- function(deg) sin(deg * pi/180)
> > > > > sin.deg(45)
> > > > [1] 0.7071068
> > > > 	#looks about right
> > > >
> > > > > pi <- 3.2       #Indiana General Assembly bill #247, 1897.
> > > > > sin.deg(45)
> > > > [1] 0.7173561
> > > > 	#oops ...
> > > >
> > > >
> > > >
> > > >
> > > >
> *******************************************************************
> > > > This email and any attachments are confidential. Any
> > > use...{{dropped:8}}
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-
> project.org/posting-
> > > guide.html
> > > > and provide commented, minimal, self-contained, reproducible
> code.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-
> > > guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >


From a.letertre at invs.sante.fr  Fri Jun 28 17:44:05 2013
From: a.letertre at invs.sante.fr (LE TERTRE Alain)
Date: Fri, 28 Jun 2013 17:44:05 +0200
Subject: [R] use of formula in survey analysis with replicated weights
Message-ID: <5FEDEC23F91D10488A5A20D87940D6EFE2B4D81B43@PRDEXCH2K7.ivs.local>

Hi there,
I would like to use a formula inside a call to withReplicates in a survey analysis.
If the initial call with formula expressed inside the function works as expected, defining the formula outside gives an error message.
See example below, adapted from survey:withReplicates help page.

library(survey)
library(quantreg)

data(api)
## one-stage cluster sample
dclus1<-svydesign( id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc)
## convert to bootstrap
bclus1<-as.svrepdesign( dclus1, type="bootstrap", replicates=100)

## median regression
withReplicates( bclus1, quote( coef( rq( api00~api99, tau=0.5, weights=.weights))))
               theta     SE
(Intercept) 87.78505 18.850
api99        0.91589  0.028

# Defining formula outside
Myformula <- as.formula( " api00~api99")
# Rerun the same analysis
withReplicates( bclus1, quote( coef( rq( formula= Myformula, tau=0.5, weights=.weights))))
Erreur dans eval(expr, envir, enclos) : objet 'api00' introuvable

# I suspect the evaluation not done in the right environment. 
#If you specify with data option in rq, the initial dataframe, formula is then correctly evaluated but .weights are not found.

withReplicates( bclus1, quote( coef( rq( formula= Myformula, tau=0.5, weights=.weights, data=apiclus1 ))))
Erreur dans eval(expr, envir, enclos) : objet '.weights' introuvable

Any help greatly appreciated

O__ ---- Alain Le Tertre
 c/ /'_ --- Institut de Veille Sanitaire (InVS)/ D?partement Sant? Environnement
(*) \(*) -- Responsable de l'unit? Statistiques & Outils
~~~~~~~~~~ - 12 rue du val d'Osne
94415 Saint Maurice cedex FRANCE
Voice: 33 1 41 79 67 62 Fax: 33 1 41 79 67 68
email: a.letertre at invs.sante.fr
 


From jfox at mcmaster.ca  Fri Jun 28 17:59:51 2013
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 28 Jun 2013 11:59:51 -0400
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <51CDA8C4.7080107@stats.ox.ac.uk>
References: <51C8CBCE.3040903@gmail.com>	<1372123341449.dc8da696@Nodemailer>	<51C97A30.7050802@gmail.com>	<A4E5A0B016B8CB41A485FC629B633CED4AC9F091C5@GOLD.corp.lgc-group.com>	<CABdHhvEtL0s87GSnn8MFyHtz2CdC-_65iJ6U19mfgs3YkYSC+A@mail.gmail.com>	<A4E5A0B016B8CB41A485FC629B633CED4AC9F09BD9@GOLD.corp.lgc-group.com>	<51CD9242.2090707@gmail.com>	<001701ce740f$61154b40$233fe1c0$@mcmaster.ca>
	<51CDA8C4.7080107@stats.ox.ac.uk>
Message-ID: <002101ce7418$868b3430$93a19c90$@mcmaster.ca>

Dear Brian,

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Prof Brian Ripley
> Sent: Friday, June 28, 2013 11:16 AM
> To: r-help at r-project.org
> Subject: Re: [R] Lexical scoping is not what I expect
> 
> On 28/06/2013 15:54, John Fox wrote:
> > Dear Duncan and Steve,
> >
> > Since Steve's example raises it, I've never understood why it's legal
> to
> > change the built-in global "constants" in R, including T and F. That
> just
> > seems to me to set a trap for users. Why not treat these as reserved
> > symbols, like TRUE, Inf, etc.?
> 
> Because people wanted to use them as names of things.  Maybe a T (not
> t)
> statistic.
> 
> And BTW, you can change the value of T for yourself, but you will not
> change it for any package code, including R itself, since the base
> namespace is ahead of the workspace in namespace scoping.  Because of
> that, it is years since I have seen anyone actually trip themselves up
> over this.

I was unaware that the base namespace is ahead of the workspace in this
context, and that effectively answers my objection.

Thanks,
 John

> 
> >
> > Best,
> >   John
> >
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> >> project.org] On Behalf Of Duncan Murdoch
> >> Sent: Friday, June 28, 2013 9:40 AM
> >> To: S Ellison
> >> Cc: r-help at r-project.org
> >> Subject: Re: [R] Lexical scoping is not what I expect
> >>
> >> On 28/06/2013 9:28 AM, S Ellison wrote:
> >>>
> >>>>> I too find R's lexical scoping rules straightforward.
> >>>>> However, I'd say that if your code relies on lexical
> >>>>> scoping to find something, you should probably rewrite your code.
> >>>>
> >>>> Except of course that almost every function relies on lexical
> >>>> scoping to some extent!
> >>>
> >>> This could get messy, because a) that's true and b) it actually
> leads
> >> to some genuine risks when 'globals' get redefined or masked*.
> >>>
> >>> How about I amend the assertion to "if your code relies on lexical
> >> scoping to find a variable you defined, you should probably rewrite
> >> your code."
> >>> and leave it at that, subject to some common sense about whether
> you
> >> know what you're doing?
> >>
> >> That still isn't right, because users should feel free to define
> >> functions and call them from their other functions.
> >>
> >> I think who defined it isn't the issue, the issue is whether it
> might
> >> change unexpectedly.  The user owns globalenv().  The package author
> >> owns the package namespace.  So packages should almost never read or
> >> write things directly from/to globalenv() (the user might change
> them),
> >> but they can create their own private environments and write there.
> >>
> >> Where it gets a little less clear is when the user writes a
> function.
> >> I
> >> would say functions should never write directly to globalenv(), but
> >> it's
> >> perfectly fine to reference constants there (like other functions
> >> written by the user).  Referencing things there that change is the
> >> risky
> >> thing.
> >>
> >> Duncan Murdoch
> >>
> >>
> >>>
> >>> Steve E
> >>>
> >>>
> >>> *Example
> >>>> sin.deg  <- function(deg) sin(deg * pi/180)
> >>>> sin.deg(45)
> >>> [1] 0.7071068
> >>> 	#looks about right
> >>>
> >>>> pi <- 3.2       #Indiana General Assembly bill #247, 1897.
> >>>> sin.deg(45)
> >>> [1] 0.7173561
> >>> 	#oops ...
> >>>
> >>>
> >>>
> >>>
> >>> *******************************************************************
> >>> This email and any attachments are confidential. Any
> >> use...{{dropped:8}}
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ivo.welch at anderson.ucla.edu  Fri Jun 28 19:15:19 2013
From: ivo.welch at anderson.ucla.edu (ivo welch)
Date: Fri, 28 Jun 2013 10:15:19 -0700
Subject: [R] R Benchmarks
Message-ID: <CAPr7RtX6JiQ7jV65uM1dcQ2AARDmq56-ADfousAXMNygYv21hg@mail.gmail.com>

Dear R group:

I just bought a Haswell i7-4770k machine, so I went through the
trouble of creating a small website with some comparative benchmarks.
I also made it easy for others to contribute benchmarks.  if you are
interested, it's all at http://R.ivo-welch.info/ .  enjoy.

/iaw
----
Ivo Welch (ivo.welch at gmail.com)


From nalimilan at club.fr  Fri Jun 28 19:20:35 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Fri, 28 Jun 2013 19:20:35 +0200
Subject: [R] use of formula in survey analysis with replicated weights
In-Reply-To: <5FEDEC23F91D10488A5A20D87940D6EFE2B4D81B43@PRDEXCH2K7.ivs.local>
References: <5FEDEC23F91D10488A5A20D87940D6EFE2B4D81B43@PRDEXCH2K7.ivs.local>
Message-ID: <1372440035.3258.72.camel@milan>

Le vendredi 28 juin 2013 ? 17:44 +0200, LE TERTRE Alain a ?crit :
> Hi there,
> I would like to use a formula inside a call to withReplicates in a survey analysis.
> If the initial call with formula expressed inside the function works as expected, defining the formula outside gives an error message.
> See example below, adapted from survey:withReplicates help page.
> 
> library(survey)
> library(quantreg)
> 
> data(api)
> ## one-stage cluster sample
> dclus1<-svydesign( id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc)
> ## convert to bootstrap
> bclus1<-as.svrepdesign( dclus1, type="bootstrap", replicates=100)
> 
> ## median regression
> withReplicates( bclus1, quote( coef( rq( api00~api99, tau=0.5, weights=.weights))))
>                theta     SE
> (Intercept) 87.78505 18.850
> api99        0.91589  0.028
> 
> # Defining formula outside
> Myformula <- as.formula( " api00~api99")
> # Rerun the same analysis
> withReplicates( bclus1, quote( coef( rq( formula= Myformula, tau=0.5, weights=.weights))))
> Erreur dans eval(expr, envir, enclos) : objet 'api00' introuvable
> 
> # I suspect the evaluation not done in the right environment. 
> #If you specify with data option in rq, the initial dataframe, formula is then correctly evaluated but .weights are not found.
> 
> withReplicates( bclus1, quote( coef( rq( formula= Myformula, tau=0.5, weights=.weights, data=apiclus1 ))))
> Erreur dans eval(expr, envir, enclos) : objet '.weights' introuvable
> 
> Any help greatly appreciated
Here is a workaround:
Myformula <- "api00 ~ api99"

withReplicates(bclus1, quote(coef(rq(formula(Myformula), tau=0.5, weights=.weights))))

This solution makes sure the formula uses the environment where the
weights are available. If you call as.formula() from outside the
function, it will use the global environment. If you pass a character
string, it will be converted to a formula object deep in a function and
will thus use an environment where the weights are not be available
either.

Note that the same problem happens when using lm().


Regards

> O__ ---- Alain Le Tertre
>  c/ /'_ --- Institut de Veille Sanitaire (InVS)/ D?partement Sant? Environnement
> (*) \(*) -- Responsable de l'unit? Statistiques & Outils
> ~~~~~~~~~~ - 12 rue du val d'Osne
> 94415 Saint Maurice cedex FRANCE
> Voice: 33 1 41 79 67 62 Fax: 33 1 41 79 67 68
> email: a.letertre at invs.sante.fr
>  
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From diggsb at ohsu.edu  Fri Jun 28 20:51:06 2013
From: diggsb at ohsu.edu (Brian Diggs)
Date: Fri, 28 Jun 2013 11:51:06 -0700
Subject: [R] Changing legend to fill colour in ggplot
References: <CAFdg=fWJuCY2dwyJzq4ocRccrUHfmAWZ7KTr9y2yJSC54iKBSA@mail.gmail.com>
Message-ID: <E5BA65CAFB491A4DBB1370F6C97216550744586DCE@EX-MB05.ohsu.edu>

On 6/27/2013 12:34 AM, Suparna Mitra wrote:
> Hello R experts,
>    I am having a problem to edit legend in ggplot using four variables.
>
> My data structure is :
> str(df)
> 'data.frame': 10 obs. of  6 variables:
>   $ id                        : Factor w/ 2 levels "639A","640": 1 1 1 1 1 2
> 2 2 2 2
>   $ species                   : Factor w/ 5 levels "acinetobacter_sp",..: 2
> 5 1 4 3 2 5 1 4 3
>   $ genome_coverage_bp        : int  8196 3405 8625 22568 2128 6100 1841
> 3914 8487 1064
>   $ genome_length             : int  3571237 2541445 3912725 3479613 5460977
> 3571237 2541445 3912725 3479613 5460977
>   $ genome_coverage_percentage: Factor w/ 10 levels "0.02%","0.04%",..: 8 5
> 7 10 2 6 3 4 9 1
>   $ avg_depth_coverage        : num  121.96 2.81 19.84 399.63 1.64 ...
>
>
> Now what I did is
> p=ggplot(df,aes(genome_coverage_percentage,avg_depth_coverage))+geom_point(aes(colour
> = species,shape = factor(id)))
> p+scale_shape_discrete(name  ="",labels=c("Patient 1", "Patient 2"))
> That creats the plot below.
> But I want to change the circles of legend in fill colour. So that it
> doesn't look like it is only from Patient 1, as that also has circle.
> Can anybody help me please?

You can change the default aesthetics displayed in the legend using the 
override.aes argument to guide_legend.

scale_colour_discrete(guide=guide_legend(override.aes=aes(shape=15)))

Also, when giving data, especially a data set this small, give the 
output of dput(df) as that gives the complete data in a format that can 
be used to recreate it exactly in someoneelse's session. If I had that, 
I would test this to make sure it looks right.

> Thanks a lot in advance :)
> Mitra
>
>
>


-- 
Brian S. Diggs, PhD
Senior Research Associate, Department of Surgery
Oregon Health & Science University


From a.letertre at invs.sante.fr  Fri Jun 28 23:10:00 2013
From: a.letertre at invs.sante.fr (LE TERTRE Alain)
Date: Fri, 28 Jun 2013 23:10:00 +0200
Subject: [R] RE : use of formula in survey analysis with replicated weights
In-Reply-To: <1372440035.3258.72.camel@milan>
References: <5FEDEC23F91D10488A5A20D87940D6EFE2B4D81B43@PRDEXCH2K7.ivs.local>,
	<1372440035.3258.72.camel@milan>
Message-ID: <5FEDEC23F91D10488A5A20D87940D6EFE2B4B05389@PRDEXCH2K7.ivs.local>

Thanks for the workaround and the explanation

Alain
________________________________________
De : Milan Bouchet-Valat [nalimilan at club.fr]
Date d'envoi : vendredi 28 juin 2013 19:20
? : LE TERTRE Alain
Cc : 'R-help at r-project.org'
Objet : Re: [R] use of formula in survey analysis with replicated weights

Le vendredi 28 juin 2013 ? 17:44 +0200, LE TERTRE Alain a ?crit :
> Hi there,
> I would like to use a formula inside a call to withReplicates in a survey analysis.
> If the initial call with formula expressed inside the function works as expected, defining the formula outside gives an error message.
> See example below, adapted from survey:withReplicates help page.
>
> library(survey)
> library(quantreg)
>
> data(api)
> ## one-stage cluster sample
> dclus1<-svydesign( id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc)
> ## convert to bootstrap
> bclus1<-as.svrepdesign( dclus1, type="bootstrap", replicates=100)
>
> ## median regression
> withReplicates( bclus1, quote( coef( rq( api00~api99, tau=0.5, weights=.weights))))
>                theta     SE
> (Intercept) 87.78505 18.850
> api99        0.91589  0.028
>
> # Defining formula outside
> Myformula <- as.formula( " api00~api99")
> # Rerun the same analysis
> withReplicates( bclus1, quote( coef( rq( formula= Myformula, tau=0.5, weights=.weights))))
> Erreur dans eval(expr, envir, enclos) : objet 'api00' introuvable
>
> # I suspect the evaluation not done in the right environment.
> #If you specify with data option in rq, the initial dataframe, formula is then correctly evaluated but .weights are not found.
>
> withReplicates( bclus1, quote( coef( rq( formula= Myformula, tau=0.5, weights=.weights, data=apiclus1 ))))
> Erreur dans eval(expr, envir, enclos) : objet '.weights' introuvable
>
> Any help greatly appreciated
Here is a workaround:
Myformula <- "api00 ~ api99"

withReplicates(bclus1, quote(coef(rq(formula(Myformula), tau=0.5, weights=.weights))))

This solution makes sure the formula uses the environment where the
weights are available. If you call as.formula() from outside the
function, it will use the global environment. If you pass a character
string, it will be converted to a formula object deep in a function and
will thus use an environment where the weights are not be available
either.

Note that the same problem happens when using lm().


Regards

> O__ ---- Alain Le Tertre
>  c/ /'_ --- Institut de Veille Sanitaire (InVS)/ D?partement Sant? Environnement
> (*) \(*) -- Responsable de l'unit? Statistiques & Outils
> ~~~~~~~~~~ - 12 rue du val d'Osne
> 94415 Saint Maurice cedex FRANCE
> Voice: 33 1 41 79 67 62 Fax: 33 1 41 79 67 68
> email: a.letertre at invs.sante.fr
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From juliosergio at gmail.com  Fri Jun 28 23:58:04 2013
From: juliosergio at gmail.com (Julio Sergio)
Date: Fri, 28 Jun 2013 21:58:04 +0000
Subject: [R] Transforming boolean subsetting into index subsetting
Message-ID: <loom.20130628T234000-565@post.gmane.org>

One of the techniques to subset, a vector for instance, is the following:

  V <- c(18, 8, 5, 41, 8, 7)
  V
  ## [1] 18  8  5 41  8  7
  ( I <- abs(V - 9) <= 3 )
  ## [1] FALSE  TRUE FALSE FALSE  TRUE  TRUE
  V[I]
  ## [1] 8 8 7

However, sometimes we are interested in the indexes of the elements where the 
condition holds. Is there an easy way to transform the I vector into an 
indexes vector similar to:  I == c(2,5,6) ?

I know that I can traverse the I vector with a for() loop collecting the 
indexes, I just wonder if such an operation can be avoided.

Thanks,

  -Sergio.


From pdalgd at gmail.com  Sat Jun 29 00:10:34 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 29 Jun 2013 00:10:34 +0200
Subject: [R] Transforming boolean subsetting into index subsetting
In-Reply-To: <loom.20130628T234000-565@post.gmane.org>
References: <loom.20130628T234000-565@post.gmane.org>
Message-ID: <D57BD2B4-E958-4F7D-BF9E-83E0CFEA1A6E@gmail.com>


On Jun 28, 2013, at 23:58 , Julio Sergio wrote:

> One of the techniques to subset, a vector for instance, is the following:
> 
>  V <- c(18, 8, 5, 41, 8, 7)
>  V
>  ## [1] 18  8  5 41  8  7
>  ( I <- abs(V - 9) <= 3 )
>  ## [1] FALSE  TRUE FALSE FALSE  TRUE  TRUE
>  V[I]
>  ## [1] 8 8 7
> 
> However, sometimes we are interested in the indexes of the elements where the 
> condition holds. Is there an easy way to transform the I vector into an 
> indexes vector similar to:  I == c(2,5,6) ?
> 
> I know that I can traverse the I vector with a for() loop collecting the 
> indexes, I just wonder if such an operation can be avoided.
> 

which(I)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From gunter.berton at gene.com  Sat Jun 29 02:00:59 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 28 Jun 2013 17:00:59 -0700
Subject: [R] Transforming boolean subsetting into index subsetting
In-Reply-To: <loom.20130628T234000-565@post.gmane.org>
References: <loom.20130628T234000-565@post.gmane.org>
Message-ID: <CACk-te38jf-X77MQwo-bXwOn0M63=SekPqxKrv3VdA3zamROcg@mail.gmail.com>

?which

-- Bert

On Fri, Jun 28, 2013 at 2:58 PM, Julio Sergio <juliosergio at gmail.com> wrote:
> One of the techniques to subset, a vector for instance, is the following:
>
>   V <- c(18, 8, 5, 41, 8, 7)
>   V
>   ## [1] 18  8  5 41  8  7
>   ( I <- abs(V - 9) <= 3 )
>   ## [1] FALSE  TRUE FALSE FALSE  TRUE  TRUE
>   V[I]
>   ## [1] 8 8 7
>
> However, sometimes we are interested in the indexes of the elements where the
> condition holds. Is there an easy way to transform the I vector into an
> indexes vector similar to:  I == c(2,5,6) ?
>
> I know that I can traverse the I vector with a for() loop collecting the
> indexes, I just wonder if such an operation can be avoided.
>
> Thanks,
>
>   -Sergio.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From wdunlap at tibco.com  Sat Jun 29 03:00:09 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 29 Jun 2013 01:00:09 +0000
Subject: [R] Transforming boolean subsetting into index subsetting
In-Reply-To: <CACk-te38jf-X77MQwo-bXwOn0M63=SekPqxKrv3VdA3zamROcg@mail.gmail.com>
References: <loom.20130628T234000-565@post.gmane.org>
	<CACk-te38jf-X77MQwo-bXwOn0M63=SekPqxKrv3VdA3zamROcg@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C308855@PA-MBX01.na.tibco.com>

And there is no real magic in which().  You already know that
   V[I]
where 'I' is a logical vector the length of 'V' extracts the values
in 'V' corresponding to the TRUE's in 'I'.  Replace 'V' with the vector
made by seq_along(I), (== 1, 2, ..., length(I)), and you have the
essentials of which(I).

which(I) does add an extra twist - it considers missing values in I to be the
same as FALSE's:
   seq_along(I)[ !is.na(I) & I ]

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Bert Gunter
> Sent: Friday, June 28, 2013 5:01 PM
> To: Julio Sergio
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Transforming boolean subsetting into index subsetting
> 
> ?which
> 
> -- Bert
> 
> On Fri, Jun 28, 2013 at 2:58 PM, Julio Sergio <juliosergio at gmail.com> wrote:
> > One of the techniques to subset, a vector for instance, is the following:
> >
> >   V <- c(18, 8, 5, 41, 8, 7)
> >   V
> >   ## [1] 18  8  5 41  8  7
> >   ( I <- abs(V - 9) <= 3 )
> >   ## [1] FALSE  TRUE FALSE FALSE  TRUE  TRUE
> >   V[I]
> >   ## [1] 8 8 7
> >
> > However, sometimes we are interested in the indexes of the elements where the
> > condition holds. Is there an easy way to transform the I vector into an
> > indexes vector similar to:  I == c(2,5,6) ?
> >
> > I know that I can traverse the I vector with a for() loop collecting the
> > indexes, I just wonder if such an operation can be avoided.
> >
> > Thanks,
> >
> >   -Sergio.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> --
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> 
> Internal Contact Info:
> Phone: 467-7374
> Website:
> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-
> biostatistics/pdb-ncb-home.htm
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rolf.turner at xtra.co.nz  Sat Jun 29 03:30:44 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Sat, 29 Jun 2013 13:30:44 +1200
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <001701ce740f$61154b40$233fe1c0$@mcmaster.ca>
References: <51C8CBCE.3040903@gmail.com>
	<1372123341449.dc8da696@Nodemailer>	<51C97A30.7050802@gmail.com>	<A4E5A0B016B8CB41A485FC629B633CED4AC9F091C5@GOLD.corp.lgc-group.com>	<CABdHhvEtL0s87GSnn8MFyHtz2CdC-_65iJ6U19mfgs3YkYSC+A@mail.gmail.com>	<A4E5A0B016B8CB41A485FC629B633CED4AC9F09BD9@GOLD.corp.lgc-group.com>
	<51CD9242.2090707@gmail.com>
	<001701ce740f$61154b40$233fe1c0$@mcmaster.ca>
Message-ID: <51CE38C4.7020601@xtra.co.nz>

On 29/06/13 02:54, John Fox wrote:
> Dear Duncan and Steve,
>
> Since Steve's example raises it, I've never understood why it's legal to
> change the built-in global "constants" in R, including T and F. That just
> seems to me to set a trap for users. Why not treat these as reserved
> symbols, like TRUE, Inf, etc.?

I rather enjoy being able to set

     pi <- 3

:-)

     cheers,

         Rolf Turner


From xie at yihui.name  Sat Jun 29 04:11:36 2013
From: xie at yihui.name (Yihui Xie)
Date: Fri, 28 Jun 2013 19:11:36 -0700
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <51CE38C4.7020601@xtra.co.nz>
References: <51C8CBCE.3040903@gmail.com> <1372123341449.dc8da696@Nodemailer>
	<51C97A30.7050802@gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED4AC9F091C5@GOLD.corp.lgc-group.com>
	<CABdHhvEtL0s87GSnn8MFyHtz2CdC-_65iJ6U19mfgs3YkYSC+A@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED4AC9F09BD9@GOLD.corp.lgc-group.com>
	<51CD9242.2090707@gmail.com>
	<001701ce740f$61154b40$233fe1c0$@mcmaster.ca>
	<51CE38C4.7020601@xtra.co.nz>
Message-ID: <CANROs4fvS25TmLpVmx7r1v_V=PDho3CPZVoaEQ88Axf+BwiUNA@mail.gmail.com>

I just realized this was also possible:

> assign('TRUE', FALSE)
> TRUE
[1] TRUE
> get('TRUE')
[1] FALSE

but it is probably a different story.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 206-667-4385 Web: http://yihui.name
Fred Hutchinson Cancer Research Center, Seattle


On Fri, Jun 28, 2013 at 6:30 PM, Rolf Turner <rolf.turner at xtra.co.nz> wrote:
> On 29/06/13 02:54, John Fox wrote:
>>
>> Dear Duncan and Steve,
>>
>> Since Steve's example raises it, I've never understood why it's legal to
>> change the built-in global "constants" in R, including T and F. That just
>> seems to me to set a trap for users. Why not treat these as reserved
>> symbols, like TRUE, Inf, etc.?
>
>
> I rather enjoy being able to set
>
>     pi <- 3
>
> :-)
>
>     cheers,
>
>         Rolf Turner


From f.harrell at Vanderbilt.Edu  Sat Jun 29 05:55:29 2013
From: f.harrell at Vanderbilt.Edu (Frank Harrell)
Date: Fri, 28 Jun 2013 22:55:29 -0500
Subject: [R] Quantile Regression/(package (quantreg))
Message-ID: <51CE5AB1.5010307@vanderbilt.edu>

Mike,

Do something like:

require(rms)
dd <- datadist(mydatarame); options(datadist='dd')
f <- Rq(y ~ rcs(age,4)*sex, tau=.5)  # use rq function in quantreg
summary(f)  # inter-quartile-range differences in medians of y (b/c tau=.5)
plot(Predict(f, age, sex))   # show age effect on median as a continuous 
variable

For more help type ?summary.rms and ?Predict

Frank

------------

When performing quantile regression (r package I used quantreg), the 
value of the quantile refers to the quantile value of the dependent 
variable.
Typically when trying to predict, since the information we have are the 
independent variables, I am interested in trying to estimate the 
coefficients based on the quantile values of the independent variables' 
distribution. So that I can get an understanding, for certain ranges of 
the predictor/independent variable values, the (target/dependent 
variable) has (a certain level of exposure to the 
predictors)/(coefficients).
Is there any way I can achieve that?

Just in case, if I am incorrect about my understanding on the way 
quantiles are interpreted when using the package quantreg, please let me 
know.

Thanks
Mike
-- 
Frank E Harrell Jr Professor and Chairman      School of Medicine
                    Department of Biostatistics Vanderbilt University


From csima.g at met.hu  Fri Jun 28 13:27:29 2013
From: csima.g at met.hu (Csima Gabriella)
Date: Fri, 28 Jun 2013 11:27:29 +0000 (GMT+00:00)
Subject: [R] KalmanForecast (stats)
In-Reply-To: <2567036.28410.1372418702794.JavaMail.root@blade10.met.hu>
Message-ID: <7894370.28427.1372418849775.JavaMail.root@blade10.met.hu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130628/c69bb731/attachment.pl>

From tcmuigai at gmail.com  Fri Jun 28 12:59:00 2013
From: tcmuigai at gmail.com (Charles Thuo)
Date: Fri, 28 Jun 2013 13:59:00 +0300
Subject: [R] "actuar" package query
Message-ID: <CAAJc=rMST_ufo1upgbOHPvafBbxD5STceRwokRoeS0MxMumEVg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130628/87c1372e/attachment.pl>

From zhaoran1124 at gmail.com  Fri Jun 28 14:30:44 2013
From: zhaoran1124 at gmail.com (Zhaoran Zhou)
Date: Fri, 28 Jun 2013 15:30:44 +0300
Subject: [R] what is the difference between the function "expand.grid" and
	"data.frame"?
Message-ID: <CAFtVAjGGBtn9BLJ-hehwv6cwY9MrAS_i2ZOQT3O8ZTJR0vRnNQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130628/2b2b698b/attachment.pl>

From y_refai at hotmail.com  Fri Jun 28 14:31:11 2013
From: y_refai at hotmail.com (Yasmine Refai)
Date: Fri, 28 Jun 2013 12:31:11 +0000
Subject: [R] Data Package Query
In-Reply-To: <51CCBCC1.6040508@xtra.co.nz>
References: <1371633615.23367.YahooMailNeo@web160101.mail.bf1.yahoo.com>
	<1371711263.96641.YahooMailNeo@web122105.mail.ne1.yahoo.com>
	<1371725996.86004.YahooMailNeo@web122106.mail.ne1.yahoo.com>
	<DUB405-EAS306523EF12F1C6C0F82988D90750@phx.gbl>
	<a12164e5-fef5-4963-8159-e891210e7dbc@email.android.com>,
	<51CCBCC1.6040508@xtra.co.nz>
Message-ID: <DUB118-W294EB3D6BB0340234B135190760@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130628/501af93b/attachment.pl>

From gregk at alphabetaworks.com  Fri Jun 28 16:17:42 2013
From: gregk at alphabetaworks.com (gregk)
Date: Fri, 28 Jun 2013 07:17:42 -0700 (PDT)
Subject: [R] How to avoid overlapping labels
In-Reply-To: <1372423625472-4670534.post@n4.nabble.com>
References: <1361468179145-4659294.post@n4.nabble.com>
	<1372292889073-4670409.post@n4.nabble.com>
	<1372423625472-4670534.post@n4.nabble.com>
Message-ID: <CAOOTJ4xYdQrjALAiwyj4P6LROcGjosnzary4nStU1-8ZnKfycQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130628/6efc4e37/attachment.pl>

From jcolias at decisionanalyst.com  Fri Jun 28 18:14:47 2013
From: jcolias at decisionanalyst.com (John Colias)
Date: Fri, 28 Jun 2013 11:14:47 -0500
Subject: [R] choicemodelr is misbehaving under R3.0
In-Reply-To: <CAN2xGJbbewMwm36z25-Ux_5d=_1mJ_A2y75YACEV__w4kH5zXw@mail.gmail.com>
References: <CAN2xGJYjEe-r6ynVw35WJnDscQt4O_aAvWAggdZkVXxVvAV+CQ@mail.gmail.com>
	<CAN2xGJbbewMwm36z25-Ux_5d=_1mJ_A2y75YACEV__w4kH5zXw@mail.gmail.com>
Message-ID: <CA+ESTVAr6aevqZx56wyqjVA_40n2FXFAwc-WY-EkAOqbQsUVRA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130628/c6abf3b3/attachment.pl>

From dsh at business.aau.dk  Fri Jun 28 16:50:59 2013
From: dsh at business.aau.dk (Daniel Stefan Hain)
Date: Fri, 28 Jun 2013 14:50:59 +0000
Subject: [R] Vertex names by creating a network object via an edgelist
 [package: network]
Message-ID: <5C7C94834D71E144B9351830389C46BCFCDFE9DF@ad-exchmbx2-2.aau.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130628/1d9a5664/attachment.pl>

From michel.arnaud at cirad.fr  Sat Jun 29 11:26:09 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Sat, 29 Jun 2013 11:26:09 +0200
Subject: [R] To transform a dataframe
Message-ID: <51CEA831.3040807@cirad.fr>

Hello

I would like to transform the dataframe df1 into df2 (ie copy the data 
from several lines for a men/women to only one line by individu men/women)

dput(df1)
structure(list(Mat = c(934L, 934L, 934L, 935L, 935L, 936L, 936L,
936L, 936L, 937L, 937L, 937L, 937L), Nom = structure(c(2L, 2L,
2L, 3L, 3L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L), .Label = c("TTTT",
"XXXX", "YYYY", "ZZZZ"), class = "factor"), Sexe = structure(c(1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "Masculin", 
class = "factor"),
     Cat = c(6L, 7L, 8L, 7L, 8L, 6L, 7L, 8L, 9L, 3L, 4L, 6L, 7L
     ), D?but = structure(c(5L, 7L, 2L, 12L, 8L, 3L, 4L, 10L,
     11L, 13L, 1L, 6L, 9L), .Label = c("01/01/1990", "01/01/2011",
     "01/02/1986", "01/02/1990", "01/07/1986", "01/07/1993", "01/07/1994",
     "01/07/1996", "01/10/2003", "01/11/2002", "01/11/2011", "13/01/1986",
     "23/01/1986"), class = "factor"), Fin = structure(c(2L, 9L,
     10L, 3L, 10L, 5L, 6L, 7L, 10L, 8L, 1L, 4L, 10L), .Label = 
c("30/06/1993",
     "30/06/1994", "30/06/1996", "30/09/2003", "31/01/1990", "31/10/2002",
     "31/10/2011", "31/12/1989", "31/12/2010", "31/12/4712"), class = 
"factor")), .Names = c("Mat",
"Nom", "Sexe", "Cat", "D?but", "Fin"), class = "data.frame", row.names = 
c(NA,
-13L))


dput(df2)
structure(list(Mat = 934:937, Nom = structure(c(2L, 3L, 4L, 1L
), .Label = c("TTTT", "XXXX", "YYYY", "ZZZZ"), class = "factor"),
     Sexe = structure(c(1L, 1L, 1L, 1L), .Label = "Masculin", class = 
"factor"),
     Cat4 = c(NA, NA, NA, 4L), D?but4 = structure(c(1L, 1L, 1L,
     2L), .Label = c("", "01/01/1990"), class = "factor"), Fin4 = 
structure(c(1L,
     1L, 1L, 2L), .Label = c("", "30/06/1993"), class = "factor"),
     Cat5 = c(NA, NA, NA, NA), D?but5 = c(NA, NA, NA, NA), Fin5 = c(NA,
     NA, NA, NA), Cat6 = c(6L, NA, 6L, 6L), D?but6 = structure(c(3L,
     1L, 2L, 4L), .Label = c("", "01/02/1986", "01/07/1986", "01/07/1993"
     ), class = "factor"), Fin6 = structure(c(2L, 1L, 4L, 3L), .Label = 
c("",
     "30/06/1994", "30/09/2003", "31/01/1990"), class = "factor"),
     Cat7 = c(7L, 7L, 7L, 7L), D?but7 = structure(c(2L, 4L, 1L,
     3L), .Label = c("01/02/1990", "01/07/1994", "01/10/2003",
     "13/01/1986"), class = "factor"), Fin7 = structure(c(3L,
     1L, 2L, 4L), .Label = c("30/06/1996", "31/10/2002", "31/12/2010",
     "31/12/4712"), class = "factor"), Cat8 = c(8L, 8L, 8L, NA
     ), D?but8 = structure(c(2L, 3L, 4L, 1L), .Label = c("", "01/01/2011",
     "01/07/1996", "01/11/2002"), class = "factor"), Fin8 = structure(c(3L,
     3L, 2L, 1L), .Label = c("", "31/10/2011", "31/12/4712"), class = 
"factor"),
     Cat9 = c(NA, NA, 9L, NA), D?but9 = structure(c(1L, 1L, 2L,
     1L), .Label = c("", "01/11/2011"), class = "factor"), Fin9 = 
structure(c(1L,
     1L, 2L, 1L), .Label = c("", "31/12/4712"), class = "factor")), 
.Names = c("Mat",
"Nom", "Sexe", "Cat4", "D?but4", "Fin4", "Cat5", "D?but5", "Fin5",
"Cat6", "D?but6", "Fin6", "Cat7", "D?but7", "Fin7", "Cat8", "D?but8",
"Fin8", "Cat9", "D?but9", "Fin9"), class = "data.frame", row.names = c(NA,
-4L))


Any idea ?
Thank you

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From jholtman at gmail.com  Sat Jun 29 12:49:38 2013
From: jholtman at gmail.com (Jim Holtman)
Date: Sat, 29 Jun 2013 06:49:38 -0400
Subject: [R] Transforming boolean subsetting into index subsetting
In-Reply-To: <loom.20130628T234000-565@post.gmane.org>
References: <loom.20130628T234000-565@post.gmane.org>
Message-ID: <BA7BE3BE-89F4-4E4E-9B9B-11D09FA16452@gmail.com>

which ( abs(V - 9) <= 3 )

Sent from my iPad

On Jun 28, 2013, at 17:58, Julio Sergio <juliosergio at gmail.com> wrote:

> One of the techniques to subset, a vector for instance, is the following:
> 
>  V <- c(18, 8, 5, 41, 8, 7)
>  V
>  ## [1] 18  8  5 41  8  7
>  ( I <- abs(V - 9) <= 3 )
>  ## [1] FALSE  TRUE FALSE FALSE  TRUE  TRUE
>  V[I]
>  ## [1] 8 8 7
> 
> However, sometimes we are interested in the indexes of the elements where the 
> condition holds. Is there an easy way to transform the I vector into an 
> indexes vector similar to:  I == c(2,5,6) ?
> 
> I know that I can traverse the I vector with a for() loop collecting the 
> indexes, I just wonder if such an operation can be avoided.
> 
> Thanks,
> 
>  -Sergio.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Sat Jun 29 12:57:59 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 29 Jun 2013 11:57:59 +0100
Subject: [R] To transform a dataframe
In-Reply-To: <51CEA831.3040807@cirad.fr>
References: <51CEA831.3040807@cirad.fr>
Message-ID: <51CEBDB7.5020907@sapo.pt>

Hello,

The following does what you want but the order of columns is different.


reshape(df1, v.names = c("Cat", "D?but", "Fin"),
	idvar = "Mat", timevar = "Cat", direction = "wide")


Hope this helps,

Rui Barradas

Em 29-06-2013 10:26, Arnaud Michel escreveu:
> Hello
>
> I would like to transform the dataframe df1 into df2 (ie copy the data
> from several lines for a men/women to only one line by individu men/women)
>
> dput(df1)
> structure(list(Mat = c(934L, 934L, 934L, 935L, 935L, 936L, 936L,
> 936L, 936L, 937L, 937L, 937L, 937L), Nom = structure(c(2L, 2L,
> 2L, 3L, 3L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L), .Label = c("TTTT",
> "XXXX", "YYYY", "ZZZZ"), class = "factor"), Sexe = structure(c(1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "Masculin",
> class = "factor"),
>      Cat = c(6L, 7L, 8L, 7L, 8L, 6L, 7L, 8L, 9L, 3L, 4L, 6L, 7L
>      ), D?but = structure(c(5L, 7L, 2L, 12L, 8L, 3L, 4L, 10L,
>      11L, 13L, 1L, 6L, 9L), .Label = c("01/01/1990", "01/01/2011",
>      "01/02/1986", "01/02/1990", "01/07/1986", "01/07/1993", "01/07/1994",
>      "01/07/1996", "01/10/2003", "01/11/2002", "01/11/2011", "13/01/1986",
>      "23/01/1986"), class = "factor"), Fin = structure(c(2L, 9L,
>      10L, 3L, 10L, 5L, 6L, 7L, 10L, 8L, 1L, 4L, 10L), .Label =
> c("30/06/1993",
>      "30/06/1994", "30/06/1996", "30/09/2003", "31/01/1990", "31/10/2002",
>      "31/10/2011", "31/12/1989", "31/12/2010", "31/12/4712"), class =
> "factor")), .Names = c("Mat",
> "Nom", "Sexe", "Cat", "D?but", "Fin"), class = "data.frame", row.names =
> c(NA,
> -13L))
>
>
> dput(df2)
> structure(list(Mat = 934:937, Nom = structure(c(2L, 3L, 4L, 1L
> ), .Label = c("TTTT", "XXXX", "YYYY", "ZZZZ"), class = "factor"),
>      Sexe = structure(c(1L, 1L, 1L, 1L), .Label = "Masculin", class =
> "factor"),
>      Cat4 = c(NA, NA, NA, 4L), D?but4 = structure(c(1L, 1L, 1L,
>      2L), .Label = c("", "01/01/1990"), class = "factor"), Fin4 =
> structure(c(1L,
>      1L, 1L, 2L), .Label = c("", "30/06/1993"), class = "factor"),
>      Cat5 = c(NA, NA, NA, NA), D?but5 = c(NA, NA, NA, NA), Fin5 = c(NA,
>      NA, NA, NA), Cat6 = c(6L, NA, 6L, 6L), D?but6 = structure(c(3L,
>      1L, 2L, 4L), .Label = c("", "01/02/1986", "01/07/1986", "01/07/1993"
>      ), class = "factor"), Fin6 = structure(c(2L, 1L, 4L, 3L), .Label =
> c("",
>      "30/06/1994", "30/09/2003", "31/01/1990"), class = "factor"),
>      Cat7 = c(7L, 7L, 7L, 7L), D?but7 = structure(c(2L, 4L, 1L,
>      3L), .Label = c("01/02/1990", "01/07/1994", "01/10/2003",
>      "13/01/1986"), class = "factor"), Fin7 = structure(c(3L,
>      1L, 2L, 4L), .Label = c("30/06/1996", "31/10/2002", "31/12/2010",
>      "31/12/4712"), class = "factor"), Cat8 = c(8L, 8L, 8L, NA
>      ), D?but8 = structure(c(2L, 3L, 4L, 1L), .Label = c("", "01/01/2011",
>      "01/07/1996", "01/11/2002"), class = "factor"), Fin8 = structure(c(3L,
>      3L, 2L, 1L), .Label = c("", "31/10/2011", "31/12/4712"), class =
> "factor"),
>      Cat9 = c(NA, NA, 9L, NA), D?but9 = structure(c(1L, 1L, 2L,
>      1L), .Label = c("", "01/11/2011"), class = "factor"), Fin9 =
> structure(c(1L,
>      1L, 2L, 1L), .Label = c("", "31/12/4712"), class = "factor")),
> .Names = c("Mat",
> "Nom", "Sexe", "Cat4", "D?but4", "Fin4", "Cat5", "D?but5", "Fin5",
> "Cat6", "D?but6", "Fin6", "Cat7", "D?but7", "Fin7", "Cat8", "D?but8",
> "Fin8", "Cat9", "D?but9", "Fin9"), class = "data.frame", row.names = c(NA,
> -4L))
>
>
> Any idea ?
> Thank you
>


From jrkrideau at inbox.com  Sat Jun 29 15:05:28 2013
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 29 Jun 2013 05:05:28 -0800
Subject: [R] Data Package Query
In-Reply-To: <DUB118-W294EB3D6BB0340234B135190760@phx.gbl>
References: <a12164e5-fef5-4963-8159-e891210e7dbc@email.android.com>
	<1371725996.86004.yahoomailneo@web122106.mail.ne1.yahoo.com>
	<dub405-eas306523ef12f1c6c0f82988d90750@phx.gbl>
	<1371711263.96641.yahoomailneo@web122105.mail.ne1.yahoo.com>
	<1371633615.23367.yahoomailneo@web160101.mail.bf1.yahoo.com>
	<51ccbcc1.6040508@xtra.co.nz>
Message-ID: <29D67F767D9.000002A6jrkrideau@inbox.com>


I don't know what you think data(Trial) is doing but what it in fact is doing is trying to load a stored data set called Trial and it does not exist.  Have a look at ?data to see what I mean.

In your program data(Trial) is redundant, well actually closer to meaningless. 

Trial is already loaded since you created it in the read statement

John Kane
Kingston ON Canada


> -----Original Message-----
> From: y_refai at hotmail.com
> Sent: Fri, 28 Jun 2013 12:31:11 +0000
> To: rolf.turner at xtra.co.nz, jdnewmil at dcn.davis.ca.us
> Subject: Re: [R] Data Package Query
> 
> hello,
> 
> please advice what is wrong at the below syntax:
> "Trial<-read.table("Trial.txt",header=TRUE)
> Trial
> save.image(file="Trial.RData")
> data(Trial)
> fit<-logistf(data=Trial, y~x1+x2)
> "
> 
> and here is the error I get:
> "Warning message:
> In data(Trial) : data set ?Trial? not found
> "
> 
> regards,
> yasmine
> 
> 
>> Date: Fri, 28 Jun 2013 10:29:21 +1200
>> From: rolf.turner at xtra.co.nz
>> To: jdnewmil at dcn.davis.ca.us
>> CC: y_refai at hotmail.com; r-help at r-project.org
>> Subject: Re: [R] Data Package Query
>> 
>> On 28/06/13 04:47, Jeff Newmiller wrote:
>> 
>>      <SNIP>
>>> A common error by beginners (which may or may not be your problem in
>>> this case) is to create a variable called "data". Unfortunately this
>>> hides the function named "data" and from that time forward that R
>>> session doesn't work when you type example code that uses the data
>>> function.
>> 
>>      <SNIP>
>> 
>> This is simply not true.  I believe it *used* to be true, sometime
>> waaaaayyyy back,
>> but hasn't been true for years.  The R language is much cleverer now.
>> If there
>> is a function "melvin()" somewhere on the search path and also a data
>> object
>> "melvin" (earlier on the search path) then doing
>> 
>>      melvin(<whatever>)
>> 
>> will correctly call the function melvin() with no complaints.  The R
>> language
>> "can tell" by the parentheses that you mean the *function* melvin and
>> not the
>> data object "melvin".
>> 
>> E.g.
>> 
>>      data <- 42
>>      require(akima)
>>      akima
>>      Error: object 'akima' not found
>>      data(akima)  # No error message, nor nothin'!
>>      akima
>>      # The data set "akima" is displayed.
>> 
>> All that being said it is ***BAD PRACTICE***, just in terms of
>> comprehensibility
>> and avoiding confusion, to give a data set set the same name as a
>> function
>> (either built in, or one of your own).
>> 
>>      fortune("dog")
>> 
>> is relevant.
>> 
>>      cheers,
>> 
>>          Rolf Turner
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From istazahn at gmail.com  Sat Jun 29 15:08:22 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Sat, 29 Jun 2013 09:08:22 -0400
Subject: [R] what is the difference between the function "expand.grid"
	and "data.frame"?
In-Reply-To: <CAFtVAjGGBtn9BLJ-hehwv6cwY9MrAS_i2ZOQT3O8ZTJR0vRnNQ@mail.gmail.com>
References: <CAFtVAjGGBtn9BLJ-hehwv6cwY9MrAS_i2ZOQT3O8ZTJR0vRnNQ@mail.gmail.com>
Message-ID: <CA+vqiLFrp73g0BmSoA9mt6K+YQHoAkZu380r6MHFrBqMjsG_9Q@mail.gmail.com>

Why don't you try it and see?

data.frame(x=1:5, y=letters[1:5])
expand.grid(x=1:5, y=letters[1:5])

?data.frame
?expand.grid

On Fri, Jun 28, 2013 at 8:30 AM, Zhaoran Zhou <zhaoran1124 at gmail.com> wrote:
> Hello everyone,
>
> i found that both of the 2 functions ("expand.grid" and "data.frame") can
> be used to produce data frame. are there any difference between them?
>
> thanks for your help!
>
> zhaoran
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Sat Jun 29 15:10:19 2013
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 29 Jun 2013 05:10:19 -0800
Subject: [R] what is the difference between the function "expand.grid"
 and "data.frame"?
In-Reply-To: <CAFtVAjGGBtn9BLJ-hehwv6cwY9MrAS_i2ZOQT3O8ZTJR0vRnNQ@mail.gmail.com>
Message-ID: <29E15DEBCB1.000002A9jrkrideau@inbox.com>

Just have a look at the two help pages ?expand.grid and ?data.frame.

R experts will wince but I believe that you can think of a data.frame as one type of R object and expand.grid as one very specialized way to create a data.frame. 

I guess you can say one is an object and the other is a function to create such an object.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: zhaoran1124 at gmail.com
> Sent: Fri, 28 Jun 2013 15:30:44 +0300
> To: r-help at r-project.org
> Subject: [R] what is the difference between the function "expand.grid"
> and "data.frame"?
> 
> Hello everyone,
> 
> i found that both of the 2 functions ("expand.grid" and "data.frame") can
> be used to produce data frame. are there any difference between them?
> 
> thanks for your help!
> 
> zhaoran
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From kridox at ymail.com  Sat Jun 29 15:22:13 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Sat, 29 Jun 2013 22:22:13 +0900
Subject: [R] what is the difference between the function "expand.grid"
	and "data.frame"?
In-Reply-To: <CAFtVAjGGBtn9BLJ-hehwv6cwY9MrAS_i2ZOQT3O8ZTJR0vRnNQ@mail.gmail.com>
References: <CAFtVAjGGBtn9BLJ-hehwv6cwY9MrAS_i2ZOQT3O8ZTJR0vRnNQ@mail.gmail.com>
Message-ID: <CAAcyNCyiMbDPnMfnhZ5b-aGz5Dcy-n+pyOv3bY2ZEzQprsSP6Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130629/233ea692/attachment.pl>

From wdunlap at tibco.com  Sat Jun 29 16:25:13 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 29 Jun 2013 14:25:13 +0000
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <CANROs4fvS25TmLpVmx7r1v_V=PDho3CPZVoaEQ88Axf+BwiUNA@mail.gmail.com>
References: <51C8CBCE.3040903@gmail.com> <1372123341449.dc8da696@Nodemailer>
	<51C97A30.7050802@gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED4AC9F091C5@GOLD.corp.lgc-group.com>
	<CABdHhvEtL0s87GSnn8MFyHtz2CdC-_65iJ6U19mfgs3YkYSC+A@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED4AC9F09BD9@GOLD.corp.lgc-group.com>
	<51CD9242.2090707@gmail.com>	<001701ce740f$61154b40$233fe1c0$@mcmaster.ca>
	<51CE38C4.7020601@xtra.co.nz>
	<CANROs4fvS25TmLpVmx7r1v_V=PDho3CPZVoaEQ88Axf+BwiUNA@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C3088FF@PA-MBX01.na.tibco.com>

> > assign('TRUE', FALSE)
> > TRUE
> [1] TRUE
> > get('TRUE')
> [1] FALSE
> 
> but it is probably a different story.

The parser converts the text
   TRUE
to the value true, not to the name 'TRUE', just as it converts the text
   1
to the value one, not the name '1', before handing off the parse tree
to the evaluator, so scoping rules are not relevant.  You can also use
backquotes to force the TRUE or 1 to be interpreted as names so that
scoping rules are used.

  R> class(parse(text="TRUE")[[1]])
  [1] "logical"
  R> class(parse(text="`TRUE`")[[1]])
  [1] "name"
  R> class(parse(text="1")[[1]])
  [1] "numeric"
  R> class(parse(text="`1`")[[1]])
  [1] "name"

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Yihui Xie
> Sent: Friday, June 28, 2013 7:12 PM
> To: Rolf Turner
> Cc: r-help at r-project.org; John Fox
> Subject: Re: [R] Lexical scoping is not what I expect
> 
> I just realized this was also possible:
> 
> > assign('TRUE', FALSE)
> > TRUE
> [1] TRUE
> > get('TRUE')
> [1] FALSE
> 
> but it is probably a different story.
> 
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Phone: 206-667-4385 Web: http://yihui.name
> Fred Hutchinson Cancer Research Center, Seattle
> 
> 
> On Fri, Jun 28, 2013 at 6:30 PM, Rolf Turner <rolf.turner at xtra.co.nz> wrote:
> > On 29/06/13 02:54, John Fox wrote:
> >>
> >> Dear Duncan and Steve,
> >>
> >> Since Steve's example raises it, I've never understood why it's legal to
> >> change the built-in global "constants" in R, including T and F. That just
> >> seems to me to set a trap for users. Why not treat these as reserved
> >> symbols, like TRUE, Inf, etc.?
> >
> >
> > I rather enjoy being able to set
> >
> >     pi <- 3
> >
> > :-)
> >
> >     cheers,
> >
> >         Rolf Turner
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sat Jun 29 17:17:08 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 29 Jun 2013 08:17:08 -0700 (PDT)
Subject: [R] To transform a dataframe
In-Reply-To: <51CEA831.3040807@cirad.fr>
References: <51CEA831.3040807@cirad.fr>
Message-ID: <1372519028.84156.YahooMailNeo@web142605.mail.bf1.yahoo.com>

HI,
Not sure why df2 didn't include Cat3, Debut3, Fin3, instead included columns with all missing values (Cat5, Debut5, Fin5).

library(plyr)
library(reshape2)
df1New<-ddply(df1,.(Mat),transform,castCat=paste0("Cat",Cat),castD?but=paste0("D?but",Cat),castFin=paste0("Fin",Cat))
res<- join_all(list(dcast(df1New,Mat+Nom+Sexe~castCat,value.var="Cat"),dcast(df1New,Mat+Nom+Sexe~castD?but,value.var="D?but"), dcast(df1New,Mat+Nom+Sexe~castFin,value.var="Fin")),by=c("Mat","Nom","Sexe"))
?indx<-grepl("Mat|Nom|Sexe",colnames(res))
?res1<-cbind(res[indx],res[!indx][order(as.numeric(gsub("[[:alpha:]]","",colnames(res)[!indx])))])
res1
#? Mat? Nom???? Sexe Cat3???? D?but3?????? Fin3 Cat4???? D?but4?????? Fin4 Cat6
#1 934 XXXX Masculin?? NA?????? <NA>?????? <NA>?? NA?????? <NA>?????? <NA>??? 6
#2 935 YYYY Masculin?? NA?????? <NA>?????? <NA>?? NA?????? <NA>?????? <NA>?? NA
#3 936 ZZZZ Masculin?? NA?????? <NA>?????? <NA>?? NA?????? <NA>?????? <NA>??? 6
#4 937 TTTT Masculin??? 3 23/01/1986 31/12/1989??? 4 01/01/1990 30/06/1993??? 6
?# ??? D?but6?????? Fin6 Cat7???? D?but7?????? Fin7 Cat8???? D?but8?????? Fin8
#1 01/07/1986 30/06/1994??? 7 01/07/1994 31/12/2010??? 8 01/01/2011 31/12/4712
#2?????? <NA>?????? <NA>??? 7 13/01/1986 30/06/1996??? 8 01/07/1996 31/12/4712
#3 01/02/1986 31/01/1990??? 7 01/02/1990 31/10/2002??? 8 01/11/2002 31/10/2011
#4 01/07/1993 30/09/2003??? 7 01/10/2003 31/12/4712?? NA?????? <NA>?????? <NA>
?# Cat9???? D?but9?????? Fin9
#1?? NA?????? <NA>?????? <NA>
#2?? NA?????? <NA>?????? <NA>
#3??? 9 01/11/2011 31/12/4712
#4?? NA?????? <NA>?????? <NA>
A.K.



----- Original Message -----
From: Arnaud Michel <michel.arnaud at cirad.fr>
To: r-help at r-project.org
Cc: 
Sent: Saturday, June 29, 2013 5:26 AM
Subject: [R] To transform a dataframe

Hello

I would like to transform the dataframe df1 into df2 (ie copy the data 
from several lines for a men/women to only one line by individu men/women)

dput(df1)
structure(list(Mat = c(934L, 934L, 934L, 935L, 935L, 936L, 936L,
936L, 936L, 937L, 937L, 937L, 937L), Nom = structure(c(2L, 2L,
2L, 3L, 3L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L), .Label = c("TTTT",
"XXXX", "YYYY", "ZZZZ"), class = "factor"), Sexe = structure(c(1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "Masculin", 
class = "factor"),
? ?  Cat = c(6L, 7L, 8L, 7L, 8L, 6L, 7L, 8L, 9L, 3L, 4L, 6L, 7L
? ?  ), D?but = structure(c(5L, 7L, 2L, 12L, 8L, 3L, 4L, 10L,
? ?  11L, 13L, 1L, 6L, 9L), .Label = c("01/01/1990", "01/01/2011",
? ?  "01/02/1986", "01/02/1990", "01/07/1986", "01/07/1993", "01/07/1994",
? ?  "01/07/1996", "01/10/2003", "01/11/2002", "01/11/2011", "13/01/1986",
? ?  "23/01/1986"), class = "factor"), Fin = structure(c(2L, 9L,
? ?  10L, 3L, 10L, 5L, 6L, 7L, 10L, 8L, 1L, 4L, 10L), .Label = 
c("30/06/1993",
? ?  "30/06/1994", "30/06/1996", "30/09/2003", "31/01/1990", "31/10/2002",
? ?  "31/10/2011", "31/12/1989", "31/12/2010", "31/12/4712"), class = 
"factor")), .Names = c("Mat",
"Nom", "Sexe", "Cat", "D?but", "Fin"), class = "data.frame", row.names = 
c(NA,
-13L))


dput(df2)
structure(list(Mat = 934:937, Nom = structure(c(2L, 3L, 4L, 1L
), .Label = c("TTTT", "XXXX", "YYYY", "ZZZZ"), class = "factor"),
? ?  Sexe = structure(c(1L, 1L, 1L, 1L), .Label = "Masculin", class = 
"factor"),
? ?  Cat4 = c(NA, NA, NA, 4L), D?but4 = structure(c(1L, 1L, 1L,
? ?  2L), .Label = c("", "01/01/1990"), class = "factor"), Fin4 = 
structure(c(1L,
? ?  1L, 1L, 2L), .Label = c("", "30/06/1993"), class = "factor"),
? ?  Cat5 = c(NA, NA, NA, NA), D?but5 = c(NA, NA, NA, NA), Fin5 = c(NA,
? ?  NA, NA, NA), Cat6 = c(6L, NA, 6L, 6L), D?but6 = structure(c(3L,
? ?  1L, 2L, 4L), .Label = c("", "01/02/1986", "01/07/1986", "01/07/1993"
? ?  ), class = "factor"), Fin6 = structure(c(2L, 1L, 4L, 3L), .Label = 
c("",
? ?  "30/06/1994", "30/09/2003", "31/01/1990"), class = "factor"),
? ?  Cat7 = c(7L, 7L, 7L, 7L), D?but7 = structure(c(2L, 4L, 1L,
? ?  3L), .Label = c("01/02/1990", "01/07/1994", "01/10/2003",
? ?  "13/01/1986"), class = "factor"), Fin7 = structure(c(3L,
? ?  1L, 2L, 4L), .Label = c("30/06/1996", "31/10/2002", "31/12/2010",
? ?  "31/12/4712"), class = "factor"), Cat8 = c(8L, 8L, 8L, NA
? ?  ), D?but8 = structure(c(2L, 3L, 4L, 1L), .Label = c("", "01/01/2011",
? ?  "01/07/1996", "01/11/2002"), class = "factor"), Fin8 = structure(c(3L,
? ?  3L, 2L, 1L), .Label = c("", "31/10/2011", "31/12/4712"), class = 
"factor"),
? ?  Cat9 = c(NA, NA, 9L, NA), D?but9 = structure(c(1L, 1L, 2L,
? ?  1L), .Label = c("", "01/11/2011"), class = "factor"), Fin9 = 
structure(c(1L,
? ?  1L, 2L, 1L), .Label = c("", "31/12/4712"), class = "factor")), 
.Names = c("Mat",
"Nom", "Sexe", "Cat4", "D?but4", "Fin4", "Cat5", "D?but5", "Fin5",
"Cat6", "D?but6", "Fin6", "Cat7", "D?but7", "Fin7", "Cat8", "D?but8",
"Fin8", "Cat9", "D?but9", "Fin9"), class = "data.frame", row.names = c(NA,
-4L))


Any idea ?
Thank you

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From hans-christian.krumholz at uni-ulm.de  Sat Jun 29 17:19:04 2013
From: hans-christian.krumholz at uni-ulm.de (hck)
Date: Sat, 29 Jun 2013 08:19:04 -0700 (PDT)
Subject: [R] 2SLS / TSLS / SEM non-linear
In-Reply-To: <alpine.DEB.2.02.1306231951350.27866@paninaro.uibk.ac.at>
References: <1371997068977-4670123.post@n4.nabble.com>
	<alpine.DEB.2.02.1306231951350.27866@paninaro.uibk.ac.at>
Message-ID: <1372519144070-4670595.post@n4.nabble.com>

The challenge is to firstly calculate the reduced form. As far as I know, the
SEM package does not do this automatically. Am I correct?





--
View this message in context: http://r.789695.n4.nabble.com/2SLS-TSLS-SEM-non-linear-tp4670123p4670595.html
Sent from the R help mailing list archive at Nabble.com.


From jfox at mcmaster.ca  Sat Jun 29 18:18:53 2013
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 29 Jun 2013 12:18:53 -0400
Subject: [R] 2SLS / TSLS / SEM non-linear
In-Reply-To: <1372519144070-4670595.post@n4.nabble.com>
References: <1371997068977-4670123.post@n4.nabble.com>	<alpine.DEB.2.02.1306231951350.27866@paninaro.uibk.ac.at>
	<1372519144070-4670595.post@n4.nabble.com>
Message-ID: <000101ce74e4$59393550$0bab9ff0$@mcmaster.ca>

Dear Hans-Christian

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of hck
> Sent: Saturday, June 29, 2013 11:19 AM
> To: r-help at r-project.org
> Subject: Re: [R] 2SLS / TSLS / SEM non-linear
> 
> The challenge is to firstly calculate the reduced form. As far as I
> know, the
> SEM package does not do this automatically. Am I correct?
> 

Right. If you look at the code in sem:::tsls.default, you'll see that it
formulates and solves the 2SLS estimating equations directly (using a
Cholesky decomposition). Moreover, tsls() is for linear structural
equations.

Best,
 John

-----------------------------------------------
John Fox
Senator McMaster Professor of Social Statistics
Department of Sociology
McMaster University
Hamilton, Ontario, Canada


> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/2SLS-TSLS-
> SEM-non-linear-tp4670123p4670595.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Sat Jun 29 18:29:35 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Sat, 29 Jun 2013 16:29:35 +0000
Subject: [R] filling list of data frames
In-Reply-To: <012101ce730f$012e0560$038a1020$@gmail.com>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A5219146F136@PRDEXMBX-08.the-lab.llnl.gov>

You might gain some speed by not creating df0 and df0_1:

for (i in 2:100)  output.list[[i]] <- f1(output.list[[i-1]])

You can also look at the structure of the data frames. For example, if
some of the elements in the data frames are factors but don't need to be
factors, you might gain by preventing them from being factors.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 6/27/13 1:19 AM, "Frederico Mestre" <mestre.frederico at gmail.com> wrote:

>Hello:
>
> 
>
>I have a list of data frames, built like this: the second df is a result
>of
>a function applied to the first, and so on.
>
> 
>
>So the ith df is always dependent on the (i-1)th df. I've been doing this
>using for loops. However I think I have too many for loops which is making
>my code run slowly.
>
> 
>
>Is there any workaround  this? How can I avoid the use of for loops?
>
> 
>
>As an example:
>
> 
>
>output.list <- as.list(rep("", 100))#creation of a list
>
> 
>
>output.list[[1]] <- df1#first position
>
> 
>
> 
>
>for(I in 2:100){#following positions
>
> 
>
>df0 <- output.list[[i-1]]
>
> 
>
>df0_1 <- f1(df0)#function applied to the previous df
>
> 
>
>output.list[[i]] <- df0_1#new df
>
> 
>
>}
>
> 
>
>thanks,
>
> 
>
>Frederico 
>
> 
>
> 
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pauljohn32 at gmail.com  Sat Jun 29 18:58:28 2013
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Sat, 29 Jun 2013 11:58:28 -0500
Subject: [R] 2SLS / TSLS / SEM non-linear
In-Reply-To: <000101ce74e4$59393550$0bab9ff0$@mcmaster.ca>
References: <1371997068977-4670123.post@n4.nabble.com>
	<alpine.DEB.2.02.1306231951350.27866@paninaro.uibk.ac.at>
	<1372519144070-4670595.post@n4.nabble.com>
	<000101ce74e4$59393550$0bab9ff0$@mcmaster.ca>
Message-ID: <CAErODj-Qdr_jAZeq2K2vXH865=qRCeRniU7k9UFfMXHNthq9gA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130629/5826bdbb/attachment.pl>

From tarqmag at yahoo.com.br  Sat Jun 29 20:27:37 2013
From: tarqmag at yahoo.com.br (Tarquinio magalhaes)
Date: Sat, 29 Jun 2013 11:27:37 -0700 (PDT)
Subject: [R] Weighted SUR/NSUR
Message-ID: <1372530457.13427.YahooMailNeo@web164006.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130629/a35e465d/attachment.pl>

From leandromarino at leandromarino.com.br  Sun Jun 30 01:01:43 2013
From: leandromarino at leandromarino.com.br (Leandro Marino)
Date: Sat, 29 Jun 2013 20:01:43 -0300
Subject: [R] RMySQL problems in ubuntu 12.04.2
Message-ID: <CAKSaaFkPpUM9iRVz=DXh3ZrSn_+72f2TYJ-BJJyUx6umCDRO8g@mail.gmail.com>

Um texto embutido e sem conjunto de caracteres especificado foi limpo...
Nome: n?o dispon?vel
Url: <https://stat.ethz.ch/pipermail/r-help/attachments/20130629/8fc32f99/attachment.pl>

From leandromarino at leandromarino.com.br  Sun Jun 30 01:04:34 2013
From: leandromarino at leandromarino.com.br (Leandro Marino)
Date: Sat, 29 Jun 2013 20:04:34 -0300
Subject: [R] RMySQL problems in ubuntu 12.04.2
In-Reply-To: <CAKSaaFkPpUM9iRVz=DXh3ZrSn_+72f2TYJ-BJJyUx6umCDRO8g@mail.gmail.com>
References: <CAKSaaFkPpUM9iRVz=DXh3ZrSn_+72f2TYJ-BJJyUx6umCDRO8g@mail.gmail.com>
Message-ID: <CAKSaaFmYON+qmY4RATZnii0_-mJnGf+DGL8VCaXfiZm=EsD4xQ@mail.gmail.com>

Um texto embutido e sem conjunto de caracteres especificado foi limpo...
Nome: n?o dispon?vel
Url: <https://stat.ethz.ch/pipermail/r-help/attachments/20130629/19dd2ead/attachment.pl>

From marius.hofert at math.ethz.ch  Sun Jun 30 01:08:47 2013
From: marius.hofert at math.ethz.ch (Marius Hofert)
Date: Sun, 30 Jun 2013 01:08:47 +0200
Subject: [R] How to construct a 'proper' Q-Q line in log-log space?
Message-ID: <CAM3-KjbHVmha4yYH561JmPsGJO31Qqe1hMP=i-sysoC+svtKHA@mail.gmail.com>

Dear expeRts,

I would like to create a Q-Q plot including a Q-Q line for Gamma
distributed data.
The specialty is that it should be in log-log scale. For Q-Q line in
log-log scale,
I discovered the argument 'untf' of abline. As you can see in 2), this
works fine.
But for 3) it does not provide the correct line.

How would one add a Q-Q line to a Q-Q plot in log-log scale?

Cheers,

Marius


th <- 0.5
n <- 250
set.seed(271)
x <- rgamma(n, shape=th)
qF <- function(p) qgamma(p, shape=th)

## 1) Q-Q plot in normal space
plot(qF(ppoints(n)), sort(x))
qqline(y=sort(x), distribution=qF) # fine

## 2) Q-Q plot in log-x space
plot(qF(ppoints(n)), sort(x), log="x")
qqline(y=sort(x), distribution=qF, untf=TRUE) # fine

## 3) Q-Q plot in log-log space
plot(qF(ppoints(n)), sort(x), log="xy")
qqline(y=sort(x), distribution=qF, untf=TRUE) # => wrong!
qqline(y=sort(log(x)), distribution=function(p) log(qF(p)), col="red")
# almost, but not as 'green' below

## 4) Q-Q plot of log values directly
plot(log(qF(ppoints(n))), sort(log(x)))
qqline(y=sort(log(x)), distribution=function(p) log(qF(p)), untf=TRUE,
col="green") # fine


From 538280 at gmail.com  Sun Jun 30 05:58:48 2013
From: 538280 at gmail.com (Greg Snow)
Date: Sat, 29 Jun 2013 21:58:48 -0600
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <51CE38C4.7020601@xtra.co.nz>
References: <51C8CBCE.3040903@gmail.com> <1372123341449.dc8da696@Nodemailer>
	<51C97A30.7050802@gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED4AC9F091C5@GOLD.corp.lgc-group.com>
	<CABdHhvEtL0s87GSnn8MFyHtz2CdC-_65iJ6U19mfgs3YkYSC+A@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED4AC9F09BD9@GOLD.corp.lgc-group.com>
	<51CD9242.2090707@gmail.com>
	<001701ce740f$61154b40$233fe1c0$@mcmaster.ca>
	<51CE38C4.7020601@xtra.co.nz>
Message-ID: <CAFEqCdxErdeA35i9pqDCvwV1G+fAUq_CLGF7y3LPjp0GJVBfSA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130629/05baf945/attachment.pl>

From robert.b.lynch at gmail.com  Sun Jun 30 07:40:34 2013
From: robert.b.lynch at gmail.com (Robert Lynch)
Date: Sat, 29 Jun 2013 22:40:34 -0700
Subject: [R] interpreting GLM results and plotting fits
Message-ID: <CACYeG1hqLdGoitRs0uEX+FweXZZMze6+2E80yn89qN0sHcsSrA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130629/49742dac/attachment.pl>

From rolf.turner at xtra.co.nz  Sun Jun 30 11:24:09 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Sun, 30 Jun 2013 21:24:09 +1200
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <CAFEqCdxErdeA35i9pqDCvwV1G+fAUq_CLGF7y3LPjp0GJVBfSA@mail.gmail.com>
References: <51C8CBCE.3040903@gmail.com> <1372123341449.dc8da696@Nodemailer>
	<51C97A30.7050802@gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED4AC9F091C5@GOLD.corp.lgc-group.com>
	<CABdHhvEtL0s87GSnn8MFyHtz2CdC-_65iJ6U19mfgs3YkYSC+A@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED4AC9F09BD9@GOLD.corp.lgc-group.com>
	<51CD9242.2090707@gmail.com>
	<001701ce740f$61154b40$233fe1c0$@mcmaster.ca>
	<51CE38C4.7020601@xtra.co.nz>
	<CAFEqCdxErdeA35i9pqDCvwV1G+fAUq_CLGF7y3LPjp0GJVBfSA@mail.gmail.com>
Message-ID: <51CFF939.6050502@xtra.co.nz>

On 30/06/13 15:58, Greg Snow wrote:
> If you want to write really confusing code it is possible to do:
>
> `1` <- 2
>
> `1` + 1
>
> and things like that, but it is probably a good idea not to.

Fortune?

     cheers,

         Rolf


From hans-christian.krumholz at uni-ulm.de  Sun Jun 30 12:51:23 2013
From: hans-christian.krumholz at uni-ulm.de (hck)
Date: Sun, 30 Jun 2013 03:51:23 -0700 (PDT)
Subject: [R] 2SLS / TSLS / SEM non-linear
In-Reply-To: <CAErODj-Qdr_jAZeq2K2vXH865=qRCeRniU7k9UFfMXHNthq9gA@mail.gmail.com>
References: <1371997068977-4670123.post@n4.nabble.com>
	<alpine.DEB.2.02.1306231951350.27866@paninaro.uibk.ac.at>
	<1372519144070-4670595.post@n4.nabble.com>
	<000101ce74e4$59393550$0bab9ff0$@mcmaster.ca>
	<CAErODj-Qdr_jAZeq2K2vXH865=qRCeRniU7k9UFfMXHNthq9gA@mail.gmail.com>
Message-ID: <1372589483248-4670612.post@n4.nabble.com>

Thank you John and Paul,

I started having a look into the systemfit.

Basically, my two equations are:

1. Y = IV1 + IV2 x X
2. Y = a + b x X + u

where Y and X are the two endogenous variables, IV1 and IV2 are the
instruments, and u is the error term.



--
View this message in context: http://r.789695.n4.nabble.com/2SLS-TSLS-SEM-non-linear-tp4670123p4670612.html
Sent from the R help mailing list archive at Nabble.com.


From murdoch.duncan at gmail.com  Sun Jun 30 14:35:43 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 30 Jun 2013 08:35:43 -0400
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <CAFEqCdxErdeA35i9pqDCvwV1G+fAUq_CLGF7y3LPjp0GJVBfSA@mail.gmail.com>
References: <51C8CBCE.3040903@gmail.com> <1372123341449.dc8da696@Nodemailer>
	<51C97A30.7050802@gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED4AC9F091C5@GOLD.corp.lgc-group.com>
	<CABdHhvEtL0s87GSnn8MFyHtz2CdC-_65iJ6U19mfgs3YkYSC+A@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED4AC9F09BD9@GOLD.corp.lgc-group.com>
	<51CD9242.2090707@gmail.com>
	<001701ce740f$61154b40$233fe1c0$@mcmaster.ca>
	<51CE38C4.7020601@xtra.co.nz>
	<CAFEqCdxErdeA35i9pqDCvwV1G+fAUq_CLGF7y3LPjp0GJVBfSA@mail.gmail.com>
Message-ID: <51D0261F.1020107@gmail.com>

On 13-06-29 11:58 PM, Greg Snow wrote:
> If you want to write really confusing code it is possible to do:
>
> `1` <- 2
>
> `1` + 1
>
> and things like that, but it is probably a good idea not to.

This is actually pretty simple, as the White Knight could tell you.  `1` 
is what the name of 2 is called.  The name really is "2".  It's called 
"two", but that's only what it's called.  It really is two.

Duncan Murdoch

>
>
> On Fri, Jun 28, 2013 at 7:30 PM, Rolf Turner <rolf.turner at xtra.co.nz> wrote:
>
>> On 29/06/13 02:54, John Fox wrote:
>>
>>> Dear Duncan and Steve,
>>>
>>> Since Steve's example raises it, I've never understood why it's legal to
>>> change the built-in global "constants" in R, including T and F. That just
>>> seems to me to set a trap for users. Why not treat these as reserved
>>> symbols, like TRUE, Inf, etc.?
>>>
>>
>> I rather enjoy being able to set
>>
>>      pi <- 3
>>
>> :-)
>>
>>      cheers,
>>
>>          Rolf Turner
>>
>>
>> ______________________________**________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/**
>> posting-guide.html <http://www.R-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>


From arne.henningsen at gmail.com  Sun Jun 30 18:24:40 2013
From: arne.henningsen at gmail.com (Arne Henningsen)
Date: Sun, 30 Jun 2013 18:24:40 +0200
Subject: [R] 2SLS / TSLS / SEM non-linear
In-Reply-To: <1372589483248-4670612.post@n4.nabble.com>
References: <1371997068977-4670123.post@n4.nabble.com>
	<alpine.DEB.2.02.1306231951350.27866@paninaro.uibk.ac.at>
	<1372519144070-4670595.post@n4.nabble.com>
	<000101ce74e4$59393550$0bab9ff0$@mcmaster.ca>
	<CAErODj-Qdr_jAZeq2K2vXH865=qRCeRniU7k9UFfMXHNthq9gA@mail.gmail.com>
	<1372589483248-4670612.post@n4.nabble.com>
Message-ID: <CAMTWbJgjtL6u8ftPSqTfbJcbTKOkf6qURHra3fvpnqC-oYF4Rg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130630/fb2597c9/attachment.pl>

From arne.henningsen at gmail.com  Sun Jun 30 18:52:35 2013
From: arne.henningsen at gmail.com (Arne Henningsen)
Date: Sun, 30 Jun 2013 18:52:35 +0200
Subject: [R] Weighted SUR/NSUR
In-Reply-To: <1372530457.13427.YahooMailNeo@web164006.mail.gq1.yahoo.com>
References: <1372530457.13427.YahooMailNeo@web164006.mail.gq1.yahoo.com>
Message-ID: <CAMTWbJgRidHNqASUsO_GSqmoN0bhFGzmYz1HbAPjVyCAVUAJLQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130630/2cd254b4/attachment.pl>

From hans-christian.krumholz at uni-ulm.de  Sun Jun 30 18:53:20 2013
From: hans-christian.krumholz at uni-ulm.de (hck)
Date: Sun, 30 Jun 2013 09:53:20 -0700 (PDT)
Subject: [R] 2SLS / TSLS / SEM non-linear
In-Reply-To: <CAMTWbJgjtL6u8ftPSqTfbJcbTKOkf6qURHra3fvpnqC-oYF4Rg@mail.gmail.com>
References: <1371997068977-4670123.post@n4.nabble.com>
	<alpine.DEB.2.02.1306231951350.27866@paninaro.uibk.ac.at>
	<1372519144070-4670595.post@n4.nabble.com>
	<000101ce74e4$59393550$0bab9ff0$@mcmaster.ca>
	<CAErODj-Qdr_jAZeq2K2vXH865=qRCeRniU7k9UFfMXHNthq9gA@mail.gmail.com>
	<1372589483248-4670612.post@n4.nabble.com>
	<CAMTWbJgjtL6u8ftPSqTfbJcbTKOkf6qURHra3fvpnqC-oYF4Rg@mail.gmail.com>
Message-ID: <1372611200313-4670619.post@n4.nabble.com>

Dear Arne

Generally I would have the following equations X_i = IV3_i + IV4_i * Y_i
applying for every company (i). In a first step, I am interested in
estimating the relationship between X and Y: Y_i = a + b * X_i + u to
ultimatly estimate X_i by substituting the Y_i and solving for X_i to be
able to estimate the X_i by just IV3_i, IV4_i, and the a and b.

Now, let's construct values from a sample of listed companies. In the
capital market, I can observe IV3_i, IV4_i, and X_i. With these I calculate
Y_i: Y_i = IV1_i + IV2_i * X_i (note: IV3 and IV4 are just a transformation
of IV1 and IV2). Of course, I could rewrite this equation as Y_i = c + d *
IV1_i + e * IV2_i * X_i + v. For a couple of observations, I have now
combinations of X_i and Y_i to get the a and b coefficient by estimating Y_i
= a + b * X_i + u.

I hope the structure is more clear to you now.
Let me know. I am looking very much forward to your answer.
Best
HC





--
View this message in context: http://r.789695.n4.nabble.com/2SLS-TSLS-SEM-non-linear-tp4670123p4670619.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Sun Jun 30 19:52:54 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 30 Jun 2013 10:52:54 -0700
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <51D0261F.1020107@gmail.com>
References: <51C8CBCE.3040903@gmail.com> <1372123341449.dc8da696@Nodemailer>
	<51C97A30.7050802@gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED4AC9F091C5@GOLD.corp.lgc-group.com>
	<CABdHhvEtL0s87GSnn8MFyHtz2CdC-_65iJ6U19mfgs3YkYSC+A@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED4AC9F09BD9@GOLD.corp.lgc-group.com>
	<51CD9242.2090707@gmail.com>
	<001701ce740f$61154b40$233fe1c0$@mcmaster.ca>
	<51CE38C4.7020601@xtra.co.nz>
	<CAFEqCdxErdeA35i9pqDCvwV1G+fAUq_CLGF7y3LPjp0GJVBfSA@mail.gmail.com>
	<51D0261F.1020107@gmail.com>
Message-ID: <C0EAF2D9-E4AB-4154-9E35-1931394EE290@comcast.net>


On Jun 30, 2013, at 5:35 AM, Duncan Murdoch wrote:

> On 13-06-29 11:58 PM, Greg Snow wrote:
>> If you want to write really confusing code it is possible to do:
>> 
>> `1` <- 2
>> 
>> `1` + 1
>> 
>> and things like that, but it is probably a good idea not to.
> 
> This is actually pretty simple, as the White Knight could tell you.  `1` is what the name of 2 is called.  The name really is "2".  It's called "two", but that's only what it's called.  It really is two.
> 
> Duncan Murdoch

This fortune nominee keeps getting stronger.

-- 
David.
> 
>> 
>> 
>> On Fri, Jun 28, 2013 at 7:30 PM, Rolf Turner <rolf.turner at xtra.co.nz> wrote:
>> 
>>> On 29/06/13 02:54, John Fox wrote:
>>> 
>>>> Dear Duncan and Steve,
>>>> 
>>>> Since Steve's example raises it, I've never understood why it's legal to
>>>> change the built-in global "constants" in R, including T and F. That just
>>>> seems to me to set a trap for users. Why not treat these as reserved
>>>> symbols, like TRUE, Inf, etc.?
>>>> 
>>> 
>>> I rather enjoy being able to set
>>> 
>>>     pi <- 3
>>> 
>>> :-)
>>> 
>>>     cheers,
>>> 
>>>         Rolf Turner
>>> 
>>> 
>>> ______________________________**________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>>> PLEASE do read the posting guide http://www.R-project.org/**
>>> posting-guide.html <http://www.R-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From smartpink111 at yahoo.com  Sun Jun 30 19:09:55 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 30 Jun 2013 10:09:55 -0700 (PDT)
Subject: [R] Help: argument is not numeric or logical: returning NA
Message-ID: <1372612195.88852.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
One problem with your example dataset is that you have 11 list 
elements with the last one having different dimensions.? I think it was 
based on `summarized`.
Then, the second problem I encountered for testing is that the dataset you provided doesn't fulfill the criteria.
lst1<- list(structure(list......) #output of dput
?
lst2<- lst1[1:10] #deleted the last list element
lst3<-lapply(lst2,function(x)
 {x$V3<- as.character(x$V3);x})? #here if I apply one of the 
conditions, none of the list elements fulfill the criteria
#for example
lapply(lst3,function(x) subset(x,V1==6 & V6>300 & V6<3000,select="V6"))
#[1]]
#[1] V6
#<0 rows> (or 0-length row.names)
#
#[[2]]
#[1] V6
#<0 rows> (or 0-length row.names)
#
#[[3]]
#[1] V6
#<0 rows> (or 0-length row.names)
---------------------------------------------

#changed the V1 column
?set.seed(24)
lst4<- lapply(lst3,function(x) {x$V1<- sample(c(0,3,6),nrow(x),replace=TRUE);x})

#I am skipping the first 2, ie. 'id' and 'iat.date' as the filenames were not provided.
res<-t(sapply(lst4,function(x)
 {block4<-x[with(x,V1==3 & V6>300 & 
V6<3000),"V6"];block7<- x[with(x,V1==6 & V6>300 & 
V6<3000),"V6"];block4.m<- mean(block4);block7.m<- 
mean(block7);block4.sd<-sd(block4);block7.sd<- 
sd(block7);full<- x[with(x,(V1==3|V1==6) & (V6 >300) & (V6
 <3000)),"V6"];full.sd<- 
sd(full);diff1<-block7.m-block4.m;d<- diff1/full.sd; 
c(block4.m,block4.sd,block7.m,block7.sd,diff1,full.sd,d) }))
colnames(res)<- c("block4.m","block4.sd","block7.m","block7.sd","diff1","full.sd","d")

Hope this helps.
A.K.




Hi, 

I downloaded a psychological test off of github and it came with
 a code for R to write the data into a .csv file. When I type the 
following: 

for(i in 1:length(data.list)) 
{ 
? filename = strsplit(output.files[i],'-') 
? id = filename[[1]][2] 
? iat.date = 
paste(filename[[1]][4],"-",filename[[1]][5],"-",filename[[1]][3]," 
",filename[[1]][6],":",substr(filename[[1]][7],1,2),sep="") 
? block4.m = mean(subset(data.list[[i]], V1==3 & V6>300 & V6 < 3000, select="V6")) 
? block7.m = mean(subset(data.list[[i]], V1==6 & V6>300 & V6 < 3000, select="V6")) 
? block4.sd = sd(subset(data.list[[i]], V1==3 & V6>300 & V6 < 3000, select="V6")) 
? block7.sd = sd(subset(data.list[[i]], V1==6 & V6>300 & V6 < 3000, select="V6")) 
? full.sd = sd(subset(data.list[[i]], (V1==6 | V1==3) & V6>300 & V6 < 3000, select="V6")) 
? diff = block7.m - block4.m 
? d = diff / full.sd 
? summarized[i,] = c(id, iat.date, block4.m, block4.sd, block7.m, block7.sd, diff, full.sd, d) 
} 

I get the following errors/warnings: 

Error in is.data.frame(x) : 
? (list) object cannot be coerced to type 'double' 
In addition: Warning messages: 
1: In mean.default(subset(data.list[[i]], V1 == 3 & V6 > 300 & V6 < ?: 
? argument is not numeric or logical: returning NA 
2: In mean.default(subset(data.list[[i]], V1 == 6 & V6 > 300 & V6 < ?: 
? argument is not numeric or logical: returning NA 
3: In mean.default(subset(data.list[[i]], V1 == 3 & V6 > 300 & V6 < ?: 
? argument is not numeric or logical: returning NA 
4: In mean.default(subset(data.list[[i]], V1 == 6 & V6 > 300 & V6 < ?: 
? argument is not numeric or logical: returning NA 
5: In mean.default(subset(data.list[[i]], V1 == 3 & V6 > 300 & V6 < ?: 
? argument is not numeric or logical: returning NA 
6: In mean.default(subset(data.list[[i]], V1 == 6 & V6 > 300 & V6 < ?: 
? argument is not numeric or logical: returning NA 
7: In mean.default(subset(data.list[[i]], V1 == 3 & V6 > 300 & V6 < ?: 
? argument is not numeric or logical: returning NA 
8: In mean.default(subset(data.list[[i]], V1 == 6 & V6 > 300 & V6 < ?: 
? argument is not numeric or logical: returning NA 


Would anyone be able to help me with this problem? I am 
relatively new to R, so I cannot seem to recognize exactly what the 
problem is. 

Thanks so much! 

list(structure(list(V1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), V2 = 0:19, V3 = structure(c(2L, 
4L, 4L, 2L, 2L, 2L, 4L, 2L, 4L, 4L, 2L, 4L, 2L, 2L, 4L, 4L, 2L, 
2L, 4L, 4L), .Label = c("NEG", "NON", "POS", "SUI"), class = "factor"), 
? ? V4 = c(2L, 5L, 2L, 1L, 2L, 5L, 4L, 5L, 1L, 5L, 4L, 3L, 4L, 
? ? 0L, 2L, 3L, 1L, 3L, 5L, 0L), V5 = c(1L, 0L, 1L, 0L, 1L, 1L, 
? ? 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 0L, 1L), 
? ? V6 = c(598L, 95L, 142L, 83L, 143L, 167L, 32L, 129L, 31L, 
? ? 136L, 2L, 142L, 23L, 160L, 105L, 144L, 64L, 152L, 71L, 129L 
? ? )), .Names = c("V1", "V2", "V3", "V4", "V5", "V6"), row.names = c(NA, 
20L), class = "data.frame"), structure(list(V1 = c(0L, 0L, 0L, 
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 
0L), V2 = 0:19, V3 = structure(c(2L, 4L, 2L, 4L, 2L, 4L, 2L, 
2L, 2L, 4L, 4L, 4L, 4L, 4L, 2L, 2L, 2L, 2L, 2L, 4L), .Label = c("NEG", 
"NON", "POS", "SUI"), class = "factor"), V4 = c(2L, 1L, 4L, 1L, 
4L, 2L, 0L, 2L, 4L, 1L, 2L, 3L, 2L, 1L, 3L, 0L, 4L, 1L, 4L, 1L 
), V5 = c(1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 
1L, 0L, 1L, 1L, 1L, 1L, 0L), V6 = c(878L, 145L, 112L, 104L, 112L, 
96L, 112L, 168L, 192L, 112L, 192L, 200L, 200L, 199L, 32L, 201L, 
176L, 200L, 224L, 120L)), .Names = c("V1", "V2", "V3", "V4", 
"V5", "V6"), row.names = c(NA, 20L), class = "data.frame"), structure(list( 
? ? V1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 
? ? 0L, 0L, 0L, 0L, 0L, 0L, 0L), V2 = 0:19, V3 = structure(c(4L, 
? ? 4L, 2L, 2L, 4L, 2L, 2L, 2L, 2L, 4L, 2L, 2L, 2L, 4L, 2L, 4L, 
? ? 4L, 2L, 2L, 2L), .Label = c("NEG", "NON", "POS", "SUI"), class = "factor"), 
? ? V4 = c(5L, 2L, 1L, 3L, 1L, 0L, 1L, 5L, 1L, 3L, 2L, 3L, 4L, 
? ? 0L, 4L, 2L, 4L, 0L, 5L, 0L), V5 = c(0L, 1L, 0L, 1L, 0L, 0L, 
? ? 1L, 1L, 1L, 1L, 0L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 1L, 1L), 
? ? V6 = c(830L, 295L, 136L, 696L, 136L, 80L, 183L, 176L, 192L, 
? ? 184L, 176L, 176L, 184L, 72L, 120L, 96L, 207L, 112L, 192L, 
? ? 216L)), .Names = c("V1", "V2", "V3", "V4", "V5", "V6"), row.names = c(NA, 
20L), class = "data.frame"), structure(list(V1 = c(0L, 0L, 0L, 
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 
0L), V2 = 0:19, V3 = structure(c(4L, 2L, 2L, 4L, 2L, 4L, 2L, 
2L, 4L, 2L, 4L, 4L, 2L, 2L, 4L, 4L, 4L, 2L, 4L, 4L), .Label = c("NEG", 
"NON", "POS", "SUI"), class = "factor"), V4 = c(3L, 1L, 3L, 2L, 
0L, 2L, 1L, 3L, 2L, 1L, 4L, 0L, 1L, 2L, 4L, 2L, 3L, 4L, 1L, 2L 
), V5 = c(0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 
1L, 0L, 1L, 1L, 0L, 0L, 1L), V6 = c(1831L, 536L, 760L, 472L, 
752L, 503L, 576L, 839L, 767L, 257L, 80L, 223L, 120L, 175L, 96L, 
200L, 192L, 103L, 119L, 191L)), .Names = c("V1", "V2", "V3", 
"V4", "V5", "V6"), row.names = c(NA, 20L), class = "data.frame"), 
? ? structure(list(V1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 
? ? 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), V2 = 0:19, V3 = structure(c(2L, 
? ? 4L, 4L, 2L, 2L, 2L, 4L, 2L, 4L, 4L, 2L, 4L, 2L, 2L, 4L, 4L, 
? ? 4L, 2L, 4L, 4L), .Label = c("NEG", "NON", "POS", "SUI"), class = "factor"), 
? ? ? ? V4 = c(0L, 2L, 1L, 4L, 3L, 2L, 4L, 2L, 0L, 2L, 4L, 3L, 
? ? ? ? 5L, 0L, 5L, 4L, 2L, 0L, 4L, 1L), V5 = c(1L, 0L, 1L, 0L, 
? ? ? ? 1L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 1L, 1L, 0L, 
? ? ? ? 0L, 1L), V6 = c(775L, 1648L, 303L, 160L, 296L, 272L, 
? ? ? ? 72L, 184L, 80L, 232L, 184L, 88L, 160L, 231L, 88L, 224L, 
? ? ? ? 232L, 152L, 72L, 256L)), .Names = c("V1", "V2", "V3", 
? ? "V4", "V5", "V6"), row.names = c(NA, 20L), class = "data.frame"), 
? ? structure(list(V1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 
? ? 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), V2 = 0:19, V3 = structure(c(2L, 
? ? 2L, 2L, 2L, 4L, 4L, 4L, 4L, 2L, 4L, 2L, 4L, 4L, 2L, 2L, 4L, 
? ? 2L, 2L, 4L, 2L), .Label = c("NEG", "NON", "POS", "SUI"), class = "factor"), 
? ? ? ? V4 = c(4L, 2L, 4L, 3L, 1L, 4L, 3L, 0L, 3L, 2L, 3L, 4L, 
? ? ? ? 0L, 3L, 4L, 3L, 2L, 1L, 3L, 0L), V5 = c(1L, 1L, 1L, 1L, 
? ? ? ? 0L, 1L, 1L, 2L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 
? ? ? ? 0L, 0L), V6 = c(991L, 312L, 271L, 409L, 176L, 280L, 360L, 
? ? ? ? 735L, 248L, 208L, 152L, 167L, 295L, 159L, 393L, 199L, 
? ? ? ? 135L, 257L, 151L, 112L)), .Names = c("V1", "V2", "V3", 
? ? "V4", "V5", "V6"), row.names = c(NA, 20L), class = "data.frame"), 
? ? structure(list(V1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 
? ? 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), V2 = 0:19, V3 = structure(c(4L, 
? ? 4L, 2L, 2L, 2L, 2L, 4L, 4L, 2L, 2L, 2L, 2L, 2L, 4L, 2L, 4L, 
? ? 4L, 4L, 4L, 4L), .Label = c("NEG", "NON", "POS", "SUI"), class = "factor"), 
? ? ? ? V4 = c(0L, 2L, 4L, 0L, 2L, 0L, 3L, 2L, 3L, 0L, 2L, 3L, 
? ? ? ? 1L, 0L, 4L, 1L, 4L, 1L, 3L, 1L), V5 = c(0L, 1L, 0L, 1L, 
? ? ? ? 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 
? ? ? ? 2L, 1L), V6 = c(3367L, 631L, 159L, 193L, 176L, 192L, 
? ? ? ? 127L, 176L, 73L, 176L, 183L, 200L, 183L, 152L, 40L, 135L, 
? ? ? ? 183L, 191L, 199L, 215L)), .Names = c("V1", "V2", "V3", 
? ? "V4", "V5", "V6"), row.names = c(NA, 20L), class = "data.frame"), 
? ? structure(list(V1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 
? ? 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), V2 = 0:19, V3 = structure(c(2L, 
? ? 2L, 4L, 4L, 4L, 2L, 4L, 2L, 4L, 4L, 2L, 4L, 2L, 2L, 2L, 2L, 
? ? 2L, 2L, 4L, 2L), .Label = c("NEG", "NON", "POS", "SUI"), class = "factor"), 
? ? ? ? V4 = c(1L, 4L, 1L, 3L, 1L, 2L, 1L, 3L, 4L, 2L, 4L, 0L, 
? ? ? ? 3L, 0L, 2L, 1L, 0L, 1L, 3L, 1L), V5 = c(1L, 1L, 0L, 1L, 
? ? ? ? 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 
? ? ? ? 0L, 0L), V6 = c(566L, 263L, 80L, 247L, 280L, 143L, 104L, 
? ? ? ? 103L, 137L, 192L, 65L, 136L, 39L, 216L, 240L, 231L, 215L, 
? ? ? ? 239L, 128L, 88L)), .Names = c("V1", "V2", "V3", "V4", 
? ? "V5", "V6"), row.names = c(NA, 20L), class = "data.frame"), 
? ? structure(list(V1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 
? ? 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), V2 = 0:19, V3 = structure(c(2L, 
? ? 2L, 4L, 2L, 4L, 4L, 2L, 2L, 2L, 2L, 4L, 4L, 4L, 4L, 2L, 4L, 
? ? 2L, 4L, 4L, 4L), .Label = c("NEG", "NON", "POS", "SUI"), class = "factor"), 
? ? ? ? V4 = c(4L, 3L, 2L, 1L, 3L, 0L, 3L, 4L, 1L, 4L, 0L, 4L, 
? ? ? ? 0L, 3L, 4L, 1L, 0L, 2L, 1L, 3L), V5 = c(1L, 1L, 0L, 0L, 
? ? ? ? 0L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 
? ? ? ? 0L, 0L), V6 = c(1910L, 311L, 272L, 96L, 328L, 376L, 159L, 
? ? ? ? 352L, 1929L, 728L, 535L, 679L, 552L, 896L, 711L, 688L, 
? ? ? ? 768L, 768L, 983L, 688L)), .Names = c("V1", "V2", "V3", 
? ? "V4", "V5", "V6"), row.names = c(NA, 20L), class = "data.frame"), 
? ? structure(list(V1 = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 
? ? 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), V2 = 0:19, V3 = structure(c(2L, 
? ? 4L, 2L, 4L, 2L, 4L, 2L, 2L, 2L, 4L, 2L, 4L, 2L, 2L, 2L, 4L, 
? ? 4L, 2L, 4L, 4L), .Label = c("NEG", "NON", "POS", "SUI"), class = "factor"), 
? ? ? ? V4 = c(4L, 0L, 3L, 4L, 0L, 1L, 3L, 2L, 0L, 4L, 3L, 2L, 
? ? ? ? 1L, 3L, 2L, 1L, 0L, 4L, 2L, 3L), V5 = c(1L, 0L, 0L, 1L, 
? ? ? ? 0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 
? ? ? ? 0L, 1L), V6 = c(654L, 152L, 23L, 185L, 160L, 72L, 135L, 
? ? ? ? 184L, 183L, 112L, 94L, 106L, 96L, 200L, 200L, 135L, 201L, 
? ? ? ? 55L, 144L, 176L)), .Names = c("V1", "V2", "V3", "V4", 
? ? "V5", "V6"), row.names = c(NA, 20L), class = "data.frame"), 
? ? structure(list(V1 = c(NA, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 
? ? 9L, 10L, 11L), V2 = structure(c(1L, 2L, 2L, 2L, NA, NA, NA, 
? ? NA, NA, NA, NA, NA), .Label = c("Id", "related"), class = "factor"), 
? ? ? ? V3 = structure(c(4L, 1L, 2L, 3L, NA, NA, NA, NA, NA, 
? ? ? ? NA, NA, NA), .Label = c("2013-06-999999 25:03", "2013-06-99999as5pt 27:22", 
? ? ? ? "2013-06-99999bJ1Td 25:19", "Date"), class = "factor"), 
? ? ? ? V4 = structure(c(1L, NA, NA, NA, NA, NA, NA, NA, NA, 
? ? ? ? NA, NA, NA), .Label = "Block4.m", class = "factor"), 
? ? ? ? V5 = structure(c(1L, NA, NA, NA, NA, NA, NA, NA, NA, 
? ? ? ? NA, NA, NA), .Label = "Block4.sd", class = "factor"), 
? ? ? ? V6 = structure(c(1L, NA, NA, NA, NA, NA, NA, NA, NA, 
? ? ? ? NA, NA, NA), .Label = "Block7.m", class = "factor"), 
? ? ? ? V7 = structure(c(1L, NA, NA, NA, NA, NA, NA, NA, NA, 
? ? ? ? NA, NA, NA), .Label = "Block7.sd", class = "factor"), 
? ? ? ? V8 = structure(c(1L, NA, NA, NA, NA, NA, NA, NA, NA, 
? ? ? ? NA, NA, NA), .Label = "diff", class = "factor"), V9 = structure(c(1L, 
? ? ? ? NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), .Label = "full.sd", class = "factor"), 
? ? ? ? V10 = structure(c(1L, NA, NA, NA, NA, NA, NA, NA, NA, 
? ? ? ? NA, NA, NA), .Label = "d", class = "factor")), .Names = c("V1", 
? ? "V2", "V3", "V4", "V5", "V6", "V7", "V8", "V9", "V10"), row.names = c(NA, 
? ? 12L), class = "data.frame"))


From sorenh at math.aau.dk  Sun Jun 30 22:31:56 2013
From: sorenh at math.aau.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Sun, 30 Jun 2013 20:31:56 +0000
Subject: [R] Vignettes do not appear on CRAN if files are placed in
 /vignette subdirectory - but they do appear if placed in /inst/doc
Message-ID: <7E8037094A0C2146AA3E6F94DAE621C39310255D@AD-EXCHMBX2-1.aau.dk>

Dear all,

In my gRbase package there are 3 vignettes placed in the /vignette subdirectory. These vignettes do not appear on http://cran.r-project.org/web/packages/gRbase/index.html and neither do they appear if I open a browser with help("gRbase").

However, if instead I place the vignettes in /inst/doc then they will appear in the browser opened with help("gRbase") - and they also appear on CRAN.

Is this how it should be or am I missing something? 

Best regards
S?ren



> sessionInfo()
R version 3.0.1 Patched (2013-06-11 r62941)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=Danish_Denmark.1252  LC_CTYPE=Danish_Denmark.1252   
[3] LC_MONETARY=Danish_Denmark.1252 LC_NUMERIC=C                   
[5] LC_TIME=Danish_Denmark.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] gRain_1.1-2             gRbase_1.6-10           graph_1.38.0           
 [4] igraph_0.6.5-2          RcppArmadillo_0.3.900.0 RcppEigen_0.3.1.2.1    
 [7] Matrix_1.0-12           lattice_0.20-15         Rcpp_0.10.3            
[10] MASS_7.3-26             shTools_1.0             markdown_0.5.4         
[13] knitr_1.2              

loaded via a namespace (and not attached):
 [1] BiocGenerics_0.6.0 digest_0.6.3       evaluate_0.4.3     formatR_0.7       
 [5] grid_3.0.1         parallel_3.0.1     RBGL_1.36.2        stats4_3.0.1      
 [9] stringr_0.6.2      tools_3.0.1       


From mtmorgan at fhcrc.org  Sun Jun 30 23:09:05 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sun, 30 Jun 2013 14:09:05 -0700
Subject: [R] Vignettes do not appear on CRAN if files are placed in
 /vignette subdirectory - but they do appear if placed in /inst/doc
In-Reply-To: <7E8037094A0C2146AA3E6F94DAE621C39310255D@AD-EXCHMBX2-1.aau.dk>
References: <7E8037094A0C2146AA3E6F94DAE621C39310255D@AD-EXCHMBX2-1.aau.dk>
Message-ID: <51D09E71.3010009@fhcrc.org>

On 06/30/2013 01:31 PM, S?ren H?jsgaard wrote:
> Dear all,
>
> In my gRbase package there are 3 vignettes placed in the /vignette subdirectory. These vignettes do not appear on http://cran.r-project.org/web/packages/gRbase/index.html and neither do they appear if I open a browser with help("gRbase").
>


the directory name is plural -- vignettes.

Martin

> However, if instead I place the vignettes in /inst/doc then they will appear in the browser opened with help("gRbase") - and they also appear on CRAN.
>
> Is this how it should be or am I missing something?
>
> Best regards
> S?ren
>
>
>
>> sessionInfo()
> R version 3.0.1 Patched (2013-06-11 r62941)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=Danish_Denmark.1252  LC_CTYPE=Danish_Denmark.1252
> [3] LC_MONETARY=Danish_Denmark.1252 LC_NUMERIC=C
> [5] LC_TIME=Danish_Denmark.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
>   [1] gRain_1.1-2             gRbase_1.6-10           graph_1.38.0
>   [4] igraph_0.6.5-2          RcppArmadillo_0.3.900.0 RcppEigen_0.3.1.2.1
>   [7] Matrix_1.0-12           lattice_0.20-15         Rcpp_0.10.3
> [10] MASS_7.3-26             shTools_1.0             markdown_0.5.4
> [13] knitr_1.2
>
> loaded via a namespace (and not attached):
>   [1] BiocGenerics_0.6.0 digest_0.6.3       evaluate_0.4.3     formatR_0.7
>   [5] grid_3.0.1         parallel_3.0.1     RBGL_1.36.2        stats4_3.0.1
>   [9] stringr_0.6.2      tools_3.0.1
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From sorenh at math.aau.dk  Sun Jun 30 23:28:23 2013
From: sorenh at math.aau.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Sun, 30 Jun 2013 21:28:23 +0000
Subject: [R] Vignettes do not appear on CRAN if files are placed in
 /vignette subdirectory - but they do appear if placed in /inst/doc
In-Reply-To: <51D09E71.3010009@fhcrc.org>
References: <7E8037094A0C2146AA3E6F94DAE621C39310255D@AD-EXCHMBX2-1.aau.dk>
	<51D09E71.3010009@fhcrc.org>
Message-ID: <7E8037094A0C2146AA3E6F94DAE621C393102592@AD-EXCHMBX2-1.aau.dk>

Sorry, yes it is plural - but changing to plural has no effect.
Regards
S?ren

-----Original Message-----
From: Martin Morgan [mailto:mtmorgan at fhcrc.org] 
Sent: 30. juni 2013 23:09
To: S?ren H?jsgaard
Cc: R hELP (r-help at stat.math.ethz.ch)
Subject: Re: [R] Vignettes do not appear on CRAN if files are placed in /vignette subdirectory - but they do appear if placed in /inst/doc

On 06/30/2013 01:31 PM, S?ren H?jsgaard wrote:
> Dear all,
>
> In my gRbase package there are 3 vignettes placed in the /vignette subdirectory. These vignettes do not appear on http://cran.r-project.org/web/packages/gRbase/index.html and neither do they appear if I open a browser with help("gRbase").
>


the directory name is plural -- vignettes.

Martin

> However, if instead I place the vignettes in /inst/doc then they will appear in the browser opened with help("gRbase") - and they also appear on CRAN.
>
> Is this how it should be or am I missing something?
>
> Best regards
> S?ren
>
>
>
>> sessionInfo()
> R version 3.0.1 Patched (2013-06-11 r62941)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=Danish_Denmark.1252  LC_CTYPE=Danish_Denmark.1252 [3] 
> LC_MONETARY=Danish_Denmark.1252 LC_NUMERIC=C [5] 
> LC_TIME=Danish_Denmark.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
>   [1] gRain_1.1-2             gRbase_1.6-10           graph_1.38.0
>   [4] igraph_0.6.5-2          RcppArmadillo_0.3.900.0 RcppEigen_0.3.1.2.1
>   [7] Matrix_1.0-12           lattice_0.20-15         Rcpp_0.10.3
> [10] MASS_7.3-26             shTools_1.0             markdown_0.5.4
> [13] knitr_1.2
>
> loaded via a namespace (and not attached):
>   [1] BiocGenerics_0.6.0 digest_0.6.3       evaluate_0.4.3     formatR_0.7
>   [5] grid_3.0.1         parallel_3.0.1     RBGL_1.36.2        stats4_3.0.1
>   [9] stringr_0.6.2      tools_3.0.1
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


--
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From moritz at kebschull.me  Sun Jun 30 20:47:39 2013
From: moritz at kebschull.me (Moritz Kebschull)
Date: Sun, 30 Jun 2013 20:47:39 +0200
Subject: [R] Gene expression clustering using several dependent samples
Message-ID: <CAJox6VDtoackHjokcjunsPOUQ6JG=LYyPYDdKUCyskxCX7Mz8g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130630/126d6646/attachment.pl>

