From drj|m|emon @end|ng |rom gm@||@com  Mon Jun  1 01:36:23 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 1 Jun 2020 09:36:23 +1000
Subject: [R] Query on contour plots
In-Reply-To: <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
Message-ID: <CA+8X3fVn8eBtLj-+UbDMX-Ui5qJ-N8Tf=RKPtKPfug4T4qc0NQ@mail.gmail.com>

Hi Neo,
It's a bit of a guess, but try this:

bat_call<-read.table(text="Fc      Sc
26.58   -5.95
27.03   -8.2
27.16   -2.07
26.19   -7.68
26.62   -3.99
26.85   -6.08
26.94   0
26.1    -5.74
26.62   -5.96
26.85   -4.05
26.98   -4.09
26.02   -5.69
26.53   -7.89
26.62   -2
26.8    -4.04
28.73   7
25.72   -2.97
26.14   -5.76
26.32   -3.89
26.4    0
26.32   5.88",
header=TRUE)
library(plotrix)
color2D.matplot(makeDensityMatrix(bat_call$Fc,bat_call$Sc,nx=5,ny=5,
 zfun="sum",xlim=range(bat_call$Fc),ylim=range(bat_call$Sc)),
 main="Map of bat calls",extremes=c("blue","red"),xlab="Frequency",
 ylab="Characteristic slope",axes=FALSE)
axis(1,at=seq(0.5,4.5,1),seq(26.3,28.3,0.5))
axis(2,at=seq(0.5,4.5,1),seq(4,-11.2,-3.5))
color.legend(-0.5,-0.65,1,-0.45,legend=seq(0,4,length.out=5),
 rect.col=color.scale(0:4,extremes=c("blue","red")),align="rb")
text(0.25,-0.89,"Density",xpd=TRUE)

Jim

On Mon, Jun 1, 2020 at 3:16 AM Neotropical bat risk assessments
<neotropical.bats at gmail.com> wrote:
>
> Hi all,
>
> While exploring  packages for 3D plots that several folks suggested (Tnx
> all!)
> It seems what I really need is a contour plot.  This is not working int
> he Deducer GUI.
>
> This will be an aid to separating bats by their vocal signatures.
> What I need to do is plot *Fc *against *Sc* with the third dimension
> being the *density* of the data points in the Fc-Sc plot.
>
> Data format is like this abbreviated sample.  Fc is a frequency in kHz
> and Sc is the characteristic slope  (octaves per second) of each call pulse.
>
> Any suggestions, guidance greatly appreciated.
> Bruce
>
> Fc      Sc
> 26.58   -5.95
> 27.03   -8.2
> 27.16   -2.07
> 26.19   -7.68
> 26.62   -3.99
> 26.85   -6.08
> 26.94   0
> 26.1    -5.74
> 26.62   -5.96
> 26.85   -4.05
> 26.98   -4.09
> 26.02   -5.69
> 26.53   -7.89
> 26.62   -2
> 26.8    -4.04
> 28.73   7
> 25.72   -2.97
> 26.14   -5.76
> 26.32   -3.89
> 26.4    0
> 26.32   5.88
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Mon Jun  1 05:03:33 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 1 Jun 2020 13:03:33 +1000
Subject: [R] Query on contour plots
In-Reply-To: <7faded2a-b184-832a-f9a3-8d4216268383@gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CA+8X3fVn8eBtLj-+UbDMX-Ui5qJ-N8Tf=RKPtKPfug4T4qc0NQ@mail.gmail.com>
 <7faded2a-b184-832a-f9a3-8d4216268383@gmail.com>
Message-ID: <CA+8X3fUzxuDfjRpQted-Zzn4Wwes5c2GbAggTueRsb7cqWkMcg@mail.gmail.com>

Hi Bruce,
With a much larger data set, you would see a smoother plot like your
sample. I plotted frequency as the abcissa and slope as the ordinate. It
looks as though your sample has it the other way round and the plot limits
are extended beyond the range of the data. However, makeDensityMatrix and
color2D.matplot could produce a plot like it.

Jim

On Mon, Jun 1, 2020 at 11:13 AM Neotropical bat risk assessments <
neotropical.bats at gmail.com> wrote:

> Tnx Jim
>
> Great help.
> I need to read about package plotrix .
> Hoping to achieve something like this sample on right.
>

	[[alternative HTML version deleted]]


From v@h|d@borj|65 @end|ng |rom gm@||@com  Mon Jun  1 12:49:16 2020
From: v@h|d@borj|65 @end|ng |rom gm@||@com (Vahid Borji)
Date: Mon, 1 Jun 2020 15:19:16 +0430
Subject: [R] How to create a warning inside the factorial function for
 decimal numbers
Message-ID: <CAEPHqhYg4CBUHvG5SwgPFo2mc4csn8QQUq=0wn5vUqii1cx5CQ@mail.gmail.com>

I am writing a code for the factorial function. My code is as follows:

> f<- function(n){+ factorial <- 1+ if( n < 0 )+ print("Factorial of negative numbers is not possible")+ else if( n == 0 )+ print("Factorial of 0 is 1")+ else {+ for(i in 1:n)+ factorial <- factorial * i+ print(paste("Factorial of ",n," is ",factorial))+ }+ }

My problem with this code is for decimal numbers as input. For example for
f(6.5) my code computes 720, but we know 6.5 ! does not exist. For decimal
numbers like, or sqrt(2) I would like to see a message like

"The factorial for this number does not exist".

How can I fix this problem in my code?

	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Mon Jun  1 13:00:18 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Mon, 1 Jun 2020 13:00:18 +0200
Subject: [R] How to create a warning inside the factorial function for
 decimal numbers
In-Reply-To: <CAEPHqhYg4CBUHvG5SwgPFo2mc4csn8QQUq=0wn5vUqii1cx5CQ@mail.gmail.com>
References: <CAEPHqhYg4CBUHvG5SwgPFo2mc4csn8QQUq=0wn5vUqii1cx5CQ@mail.gmail.com>
Message-ID: <F1D4AC4F-5BCB-4544-ABA9-195958DB1C02@gmail.com>

You might check that n %% 1 == 0.

(Factorials do exist for fractional numbers -- check e.g. factorial(6.5). And please don't send HTML because, well, you can see the result below)

- pd

> On 1 Jun 2020, at 12:49 , Vahid Borji <vahid.borji65 at gmail.com> wrote:
> 
> I am writing a code for the factorial function. My code is as follows:
> 
>> f<- function(n){+ factorial <- 1+ if( n < 0 )+ print("Factorial of negative numbers is not possible")+ else if( n == 0 )+ print("Factorial of 0 is 1")+ else {+ for(i in 1:n)+ factorial <- factorial * i+ print(paste("Factorial of ",n," is ",factorial))+ }+ }
> 
> My problem with this code is for decimal numbers as input. For example for
> f(6.5) my code computes 720, but we know 6.5 ! does not exist. For decimal
> numbers like, or sqrt(2) I would like to see a message like
> 
> "The factorial for this number does not exist".
> 
> How can I fix this problem in my code?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jho|tm@n @end|ng |rom gm@||@com  Mon Jun  1 17:34:36 2020
From: jho|tm@n @end|ng |rom gm@||@com (jim holtman)
Date: Mon, 1 Jun 2020 08:34:36 -0700
Subject: [R] Creating file from raw content
In-Reply-To: <MN2PR19MB3166B78FE959F876FCEA75A9928F0@MN2PR19MB3166.namprd19.prod.outlook.com>
References: <MN2PR19MB3166B78FE959F876FCEA75A9928F0@MN2PR19MB3166.namprd19.prod.outlook.com>
Message-ID: <CAAxdm-4AhSEuC+iZHbibNgz9XNZ0cqbc4uwtf5nA9zm5_278Xg@mail.gmail.com>

You can read it in as 'raw'

============
input <- file('your.xlsx', open = 'rb')  # open as binary
excel_file <- readBin(input, raw(), 1e8)  # make sure you read in all the file
close(input)

output <- file('your_new.xlsx', 'wb')
writeBin(excel_file, output)
close(output)
===================


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Fri, May 29, 2020 at 12:12 PM Sebastien Bihorel via R-help
<r-help at r-project.org> wrote:
>
> Hi,
>
> Let's say I can extract the content of an Excel .xlsx file stored in a database and store it as raw content in an R object. What would be the proper way to "create" a .xlsx file and "transfer" the content of this obj into it? I took the example of an Excel file, but my question would extend to any kind of binary file.
>
> Thank you in advance for your input
>
> Sebastien
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @zz@||n| @end|ng |rom @t@t@un|pd@|t  Mon Jun  1 18:34:00 2020
From: @zz@||n| @end|ng |rom @t@t@un|pd@|t (Adelchi Azzalini)
Date: Mon, 1 Jun 2020 18:34:00 +0200
Subject: [R] a question of etiquette
Message-ID: <8EDB1E40-8B17-4182-AD3F-2E0D9368C5BE@stat.unipd.it>

The new version of a package which I maintain will include a new function which I have ported to R from Matlab.
The documentation of this R function indicates the authors of the original Matlab code, reference to their paper, URL of the source code.

Question: is this adequate, or should I include them as co-authors of the package, or as contributors, or what else?
Is there a general policy about this matter?

Adelchi Azzalini
http://azzalini.stat.unipd.it/


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Mon Jun  1 19:37:37 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Mon, 1 Jun 2020 18:37:37 +0100
Subject: [R] a question of etiquette
In-Reply-To: <8EDB1E40-8B17-4182-AD3F-2E0D9368C5BE@stat.unipd.it>
References: <8EDB1E40-8B17-4182-AD3F-2E0D9368C5BE@stat.unipd.it>
Message-ID: <4e75679e-d5cf-a78b-28c9-c42dbf2256b5@dewey.myzen.co.uk>

You might get better answers on the list dedicated to package 
development r-pkg-devel

This may have already been discussed there so a quick look at the 
archive might also help you.

On 01/06/2020 17:34, Adelchi Azzalini wrote:
> The new version of a package which I maintain will include a new function which I have ported to R from Matlab.
> The documentation of this R function indicates the authors of the original Matlab code, reference to their paper, URL of the source code.
> 
> Question: is this adequate, or should I include them as co-authors of the package, or as contributors, or what else?
> Is there a general policy about this matter?
> 
> Adelchi Azzalini
> http://azzalini.stat.unipd.it/
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From @eb@@t|@n@kr@ntz @end|ng |rom gr@du@te|n@t|tute@ch  Mon Jun  1 00:33:01 2020
From: @eb@@t|@n@kr@ntz @end|ng |rom gr@du@te|n@t|tute@ch (Sebastian Martin Krantz)
Date: Mon, 1 Jun 2020 00:33:01 +0200
Subject: [R] [R-pkgs] collapse package: Advanced and Fast Data
 Transformation in R
Message-ID: <CAOsNuxCjVm+eRFnK+=7s1PuG7_Nc1UtFBAzgmpj2tgsug=kaLw@mail.gmail.com>

Dear R users, with some delay I would like to make you aware of the recent
CRAN release of *collapse* (https://CRAN.R-project.org/package=collapse), a
large new C/C++ based package for advanced and high-performance general
purpose data transformation in R.

*collapse* has 2 main objectives:

1. To facilitate complex data transformation and exploration tasks in R.
*(In particular grouped and weighted statistical computations, advanced
aggregation of mixed-type data, advanced transformations of time-series and
panel-data, and the manipulation of lists)*

2. To help make R code fast, flexible, parsimonious and programmer
friendly.
*(Providing order of magnitude performance improvements via extensive use
of C/C++ and highly optimized R code, broad object orientation and
infrastructure for grouped programming)*

*collapse*'s main innovation to service these objectives is the
introduction of a comprehensive set of fast generic functions and
transformation operators, with methods for all standard R objects written
in C++.

Currently *collapse* provides 13 fast statistical functions (`fmean`,
`fmedian`, `fmode`, `fsum`, `fprod`, `fsd`, `fvar`, `fmin`, `fmax`,
`ffirst`, `flast`, `fNobs` and `fNdistinct`) supporting grouped and
weighted computations on vectors, matrices and data.frames, and 8
specialized vector-valued functions and associated transformation operators
(`fscale/STD`, `fbetween/B`, `fwithin/W`, `fHDbetween/HDB`,
`fHDwithin/HDW`, `flag/L/F`, `fdiff/D/Dlog` and `fgrowth/G`) particularly
useful for the transformation of time-series and panel-data. Furthermore
the function `collap` painlessly handles complex aggregations of mixed-type
data, and the function `qsu` computes fast (panel-) summary statistics.

Together with these functions, *collapse* also attempts to formalize and
speed up C++ based grouped programming in R: The function `GRP` creates
grouping objects which can be passed to the `g` argument of the above
functions. This eliminates all time spent on grouping when performing
several computations over the same groups! The `TRA` function also exists
for grouped replacing and sweeping out of any computed statistics.

To round things off, *collapse* provides full sets of functions for very
fast manipulation of data.frames, fast ordering, fast factor generation,
fast conversions between common data objects, and for recursive list
processing (such as the function `unlist2d` which creates a tidy data.frame
from a nested list of heterogeneous data objects).

To enhance compatibility with existing frameworks, *collapse* functions
provide methods for *dplyr* grouped tibbles and *plm* classes for
panel-data (pseries and pdata.frame). *data.table*'s are also supported by
all functions. These methods allow for easy integration of *collapse*'s
fast functions into any of the workflows with these packages. The default
methods for transformation functions like `fscale` or `flag` can also
handle most time-series classes. In general attributes are preserved as
much as possible in all *collapse* computations.

Regarding performance: *collapse* seems to be the fastest R package for a
good share of the functionality it offers. Sizable performance gains can be
realized over packages like *dplyr* or *data.table* for various grouped
computations. The emphasis is on C++, and R code employed is carefully
micro-optimized, so a *collapse* script typically evaluates significantly
faster than, say, a *dplyr* script doing the same thing. Some benchmarks
are in the vignettes.

*collapse* also realizes an innovative approach to documentation.
Installing the package and calling `help("collapse-documentation")` brings
up a full hierarchically structured documentation. The introductory
vignette also introduces all main features in a systematic way.

At this point, *collapse* 1.2.1 is already a quite mature package with a
stable user API, passing repeated checks of R and C++ code and > 5600 unit
tests on all supported operating systems. The package will continue to
receive active maintenance and development.

I hope that the availability of *collapse* would lead not only to faster
data science, but especially to faster and richer development of complex
statistical techniques. I welcome initiatives of like-minded developers
willing to speed up grouped programming in R via C++, and encourage the use
of the *collapse* API for such endeavors. For any issues, contributions,
comments or suggestions, use github or send me an e-mail.

Best regards,

Sebastian

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From @purd|e@@ @end|ng |rom gm@||@com  Mon Jun  1 20:30:00 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 2 Jun 2020 06:30:00 +1200
Subject: [R] Query on contour plots
In-Reply-To: <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
Message-ID: <CAB8pepw=_i+wwome9t79pkUL-xHAGSoxYeeX9DnkKp7W5wqDzA@mail.gmail.com>

Hi,

I'm probably biased.

But my package, bivariate, contains a wrapper for KernSmooth::bkde2D,
which can produce both 3D surface plots and (pretty) contour plots of
bivariate kernel density estimates, conveniently.

https://cran.r-project.org/web/packages/bivariate/vignettes/bivariate.pdf
(pages 18 to 19)


On Mon, Jun 1, 2020 at 5:16 AM Neotropical bat risk assessments
<neotropical.bats at gmail.com> wrote:
>
> Hi all,
>
> While exploring  packages for 3D plots that several folks suggested (Tnx
> all!)
> It seems what I really need is a contour plot.  This is not working int
> he Deducer GUI.
>
> This will be an aid to separating bats by their vocal signatures.
> What I need to do is plot *Fc *against *Sc* with the third dimension
> being the *density* of the data points in the Fc-Sc plot.
>
> Data format is like this abbreviated sample.  Fc is a frequency in kHz
> and Sc is the characteristic slope  (octaves per second) of each call pulse.
>
> Any suggestions, guidance greatly appreciated.
> Bruce
>
> Fc      Sc
> 26.58   -5.95
> 27.03   -8.2
> 27.16   -2.07
> 26.19   -7.68
> 26.62   -3.99
> 26.85   -6.08
> 26.94   0
> 26.1    -5.74
> 26.62   -5.96
> 26.85   -4.05
> 26.98   -4.09
> 26.02   -5.69
> 26.53   -7.89
> 26.62   -2
> 26.8    -4.04
> 28.73   7
> 25.72   -2.97
> 26.14   -5.76
> 26.32   -3.89
> 26.4    0
> 26.32   5.88
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @zz@||n| @end|ng |rom @t@t@un|pd@|t  Mon Jun  1 21:17:37 2020
From: @zz@||n| @end|ng |rom @t@t@un|pd@|t (Adelchi Azzalini)
Date: Mon, 1 Jun 2020 21:17:37 +0200
Subject: [R] a question of etiquette
In-Reply-To: <4e75679e-d5cf-a78b-28c9-c42dbf2256b5@dewey.myzen.co.uk>
References: <8EDB1E40-8B17-4182-AD3F-2E0D9368C5BE@stat.unipd.it>
 <4e75679e-d5cf-a78b-28c9-c42dbf2256b5@dewey.myzen.co.uk>
Message-ID: <8406489D-770A-48BF-86BF-CAFEEC3C883A@stat.unipd.it>



> On 1 Jun 2020, at 19:37, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
> 
> You might get better answers on the list dedicated to package development r-pkg-devel

This is a good suggestion. Thanks, Michael. 

Some initial search of that list did not lead to any indication,
but I will have a second look.  

Best regards,

Adelchi

> 
> This may have already been discussed there so a quick look at the archive might also help you.
> 
> On 01/06/2020 17:34, Adelchi Azzalini wrote:
>> The new version of a package which I maintain will include a new function which I have ported to R from Matlab.
>> The documentation of this R function indicates the authors of the original Matlab code, reference to their paper, URL of the source code.
>> Question: is this adequate, or should I include them as co-authors of the package, or as contributors, or what else?
>> Is there a general policy about this matter?
>> Adelchi Azzalini
>> http://azzalini.stat.unipd.it/
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Michael
> http://www.dewey.myzen.co.uk/home.html


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Mon Jun  1 21:35:06 2020
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Mon, 1 Jun 2020 19:35:06 +0000
Subject: [R] a question of etiquette
In-Reply-To: <8406489D-770A-48BF-86BF-CAFEEC3C883A@stat.unipd.it>
References: <8EDB1E40-8B17-4182-AD3F-2E0D9368C5BE@stat.unipd.it>
 <4e75679e-d5cf-a78b-28c9-c42dbf2256b5@dewey.myzen.co.uk>,
 <8406489D-770A-48BF-86BF-CAFEEC3C883A@stat.unipd.it>
Message-ID: <MN2PR03MB51677F5B5C365B28DED6609AE28A0@MN2PR03MB5167.namprd03.prod.outlook.com>

Regardless of whether the people who wrote the Matlab code you used as a reference, or who wrote the paper that published the idea that you included in your package are cited as co-authors of your package, the coders and authors should be identified as the people from whom you borrowed the idea and, or, code for the package that you developed.
John



John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)


________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Adelchi Azzalini <azzalini at stat.unipd.it>
Sent: Monday, June 1, 2020 3:17 PM
To: Michael Dewey <lists at dewey.myzen.co.uk>
Cc: r-help at r-project.org <r-help at r-project.org>
Subject: Re: [R] a question of etiquette



> On 1 Jun 2020, at 19:37, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
>
> You might get better answers on the list dedicated to package development r-pkg-devel

This is a good suggestion. Thanks, Michael.

Some initial search of that list did not lead to any indication,
but I will have a second look.

Best regards,

Adelchi

>
> This may have already been discussed there so a quick look at the archive might also help you.
>
> On 01/06/2020 17:34, Adelchi Azzalini wrote:
>> The new version of a package which I maintain will include a new function which I have ported to R from Matlab.
>> The documentation of this R function indicates the authors of the original Matlab code, reference to their paper, URL of the source code.
>> Question: is this adequate, or should I include them as co-authors of the package, or as contributors, or what else?
>> Is there a general policy about this matter?
>> Adelchi Azzalini
>> https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fazzalini.stat.unipd.it%2F&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=Q9ZyxKn3BS2K1Sg5K00bb146XiUYqa1cEfSeKzNT1E0%3D&amp;reserved=0
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://nam03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=uIllXVF7AmuyS8iXU%2FWTPBusVvsjopzNuw6j3dWBT08%3D&amp;reserved=0
>> PLEASE do read the posting guide https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=XiD8NHBiP2aEKdlyfUsEnACXVT2lzZauof9ZbtexXFI%3D&amp;reserved=0
>> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Michael
> https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.dewey.myzen.co.uk%2Fhome.html&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=T9nJx4glgaENYAL2fAfv%2FBSYXJLQB09en0oVIPRZXss%3D&amp;reserved=0

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://nam03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=uIllXVF7AmuyS8iXU%2FWTPBusVvsjopzNuw6j3dWBT08%3D&amp;reserved=0
PLEASE do read the posting guide https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807929745&amp;sdata=VwPw2Ue%2BTBysaEw3uWzWRRHQ2sY2TTfGU%2B8z6de8oZo%3D&amp;reserved=0
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From @zz@||n| @end|ng |rom @t@t@un|pd@|t  Mon Jun  1 21:43:01 2020
From: @zz@||n| @end|ng |rom @t@t@un|pd@|t (Adelchi Azzalini)
Date: Mon, 1 Jun 2020 21:43:01 +0200
Subject: [R] a question of etiquette
In-Reply-To: <MN2PR03MB51677F5B5C365B28DED6609AE28A0@MN2PR03MB5167.namprd03.prod.outlook.com>
References: <8EDB1E40-8B17-4182-AD3F-2E0D9368C5BE@stat.unipd.it>
 <4e75679e-d5cf-a78b-28c9-c42dbf2256b5@dewey.myzen.co.uk>
 <8406489D-770A-48BF-86BF-CAFEEC3C883A@stat.unipd.it>
 <MN2PR03MB51677F5B5C365B28DED6609AE28A0@MN2PR03MB5167.namprd03.prod.outlook.com>
Message-ID: <FF4EFEB3-FA52-4965-A1D1-2ECBF3A956A1@stat.unipd.it>



> On 1 Jun 2020, at 21:35, Sorkin, John <jsorkin at som.umaryland.edu> wrote:
> 
> Regardless of whether the people who wrote the Matlab code you used as a reference, or who wrote the paper that published the idea that you included in your package are cited as co-authors of your package, the coders and authors should be identified as the people from whom you borrowed the idea and, or, code for the package that you developed. 
> John

I have already stated:

"The documentation of this R function indicates the authors of the original Matlab code, reference to their paper, URL of the source code."

This was not a point in question.   The question was was about something additional, possibly:

"Question: is this adequate, or should I include them as co-authors of the package, or as contributors, or what else?"

regards
Adelchi


> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> 
> 
> From: R-help <r-help-bounces at r-project.org> on behalf of Adelchi Azzalini <azzalini at stat.unipd.it>
> Sent: Monday, June 1, 2020 3:17 PM
> To: Michael Dewey <lists at dewey.myzen.co.uk>
> Cc: r-help at r-project.org <r-help at r-project.org>
> Subject: Re: [R] a question of etiquette
>  
> 
> 
> > On 1 Jun 2020, at 19:37, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
> > 
> > You might get better answers on the list dedicated to package development r-pkg-devel
> 
> This is a good suggestion. Thanks, Michael. 
> 
> Some initial search of that list did not lead to any indication,
> but I will have a second look.  
> 
> Best regards,
> 
> Adelchi
> 
> > 
> > This may have already been discussed there so a quick look at the archive might also help you.
> > 
> > On 01/06/2020 17:34, Adelchi Azzalini wrote:
> >> The new version of a package which I maintain will include a new function which I have ported to R from Matlab.
> >> The documentation of this R function indicates the authors of the original Matlab code, reference to their paper, URL of the source code.
> >> Question: is this adequate, or should I include them as co-authors of the package, or as contributors, or what else?
> >> Is there a general policy about this matter?
> >> Adelchi Azzalini
> >> https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fazzalini.stat.unipd.it%2F&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=Q9ZyxKn3BS2K1Sg5K00bb146XiUYqa1cEfSeKzNT1E0%3D&amp;reserved=0
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://nam03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=uIllXVF7AmuyS8iXU%2FWTPBusVvsjopzNuw6j3dWBT08%3D&amp;reserved=0
> >> PLEASE do read the posting guide https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=XiD8NHBiP2aEKdlyfUsEnACXVT2lzZauof9ZbtexXFI%3D&amp;reserved=0
> >> and provide commented, minimal, self-contained, reproducible code.
> > 
> > -- 
> > Michael
> > https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.dewey.myzen.co.uk%2Fhome.html&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=T9nJx4glgaENYAL2fAfv%2FBSYXJLQB09en0oVIPRZXss%3D&amp;reserved=0
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://nam03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=uIllXVF7AmuyS8iXU%2FWTPBusVvsjopzNuw6j3dWBT08%3D&amp;reserved=0
> PLEASE do read the posting guide https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807929745&amp;sdata=VwPw2Ue%2BTBysaEw3uWzWRRHQ2sY2TTfGU%2B8z6de8oZo%3D&amp;reserved=0
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Jun  1 21:59:22 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 01 Jun 2020 12:59:22 -0700
Subject: [R] a question of etiquette
In-Reply-To: <FF4EFEB3-FA52-4965-A1D1-2ECBF3A956A1@stat.unipd.it>
References: <8EDB1E40-8B17-4182-AD3F-2E0D9368C5BE@stat.unipd.it>
 <4e75679e-d5cf-a78b-28c9-c42dbf2256b5@dewey.myzen.co.uk>
 <8406489D-770A-48BF-86BF-CAFEEC3C883A@stat.unipd.it>
 <MN2PR03MB51677F5B5C365B28DED6609AE28A0@MN2PR03MB5167.namprd03.prod.outlook.com>
 <FF4EFEB3-FA52-4965-A1D1-2ECBF3A956A1@stat.unipd.it>
Message-ID: <040425FE-41A6-418F-85BD-2554E8D14106@dcn.davis.ca.us>

Please move this discussion to R-package-devel.

On June 1, 2020 12:43:01 PM PDT, Adelchi Azzalini <azzalini at stat.unipd.it> wrote:
>
>
>> On 1 Jun 2020, at 21:35, Sorkin, John <jsorkin at som.umaryland.edu>
>wrote:
>> 
>> Regardless of whether the people who wrote the Matlab code you used
>as a reference, or who wrote the paper that published the idea that you
>included in your package are cited as co-authors of your package, the
>coders and authors should be identified as the people from whom you
>borrowed the idea and, or, code for the package that you developed. 
>> John
>
>I have already stated:
>
>"The documentation of this R function indicates the authors of the
>original Matlab code, reference to their paper, URL of the source
>code."
>
>This was not a point in question.   The question was was about
>something additional, possibly:
>
>"Question: is this adequate, or should I include them as co-authors of
>the package, or as contributors, or what else?"
>
>regards
>Adelchi
>
>
>> 
>> 
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and
>Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>> 
>> 
>> From: R-help <r-help-bounces at r-project.org> on behalf of Adelchi
>Azzalini <azzalini at stat.unipd.it>
>> Sent: Monday, June 1, 2020 3:17 PM
>> To: Michael Dewey <lists at dewey.myzen.co.uk>
>> Cc: r-help at r-project.org <r-help at r-project.org>
>> Subject: Re: [R] a question of etiquette
>>  
>> 
>> 
>> > On 1 Jun 2020, at 19:37, Michael Dewey <lists at dewey.myzen.co.uk>
>wrote:
>> > 
>> > You might get better answers on the list dedicated to package
>development r-pkg-devel
>> 
>> This is a good suggestion. Thanks, Michael. 
>> 
>> Some initial search of that list did not lead to any indication,
>> but I will have a second look.  
>> 
>> Best regards,
>> 
>> Adelchi
>> 
>> > 
>> > This may have already been discussed there so a quick look at the
>archive might also help you.
>> > 
>> > On 01/06/2020 17:34, Adelchi Azzalini wrote:
>> >> The new version of a package which I maintain will include a new
>function which I have ported to R from Matlab.
>> >> The documentation of this R function indicates the authors of the
>original Matlab code, reference to their paper, URL of the source code.
>> >> Question: is this adequate, or should I include them as co-authors
>of the package, or as contributors, or what else?
>> >> Is there a general policy about this matter?
>> >> Adelchi Azzalini
>> >>
>https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fazzalini.stat.unipd.it%2F&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=Q9ZyxKn3BS2K1Sg5K00bb146XiUYqa1cEfSeKzNT1E0%3D&amp;reserved=0
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>
>https://nam03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=uIllXVF7AmuyS8iXU%2FWTPBusVvsjopzNuw6j3dWBT08%3D&amp;reserved=0
>> >> PLEASE do read the posting guide
>https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=XiD8NHBiP2aEKdlyfUsEnACXVT2lzZauof9ZbtexXFI%3D&amp;reserved=0
>> >> and provide commented, minimal, self-contained, reproducible code.
>> > 
>> > -- 
>> > Michael
>> >
>https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.dewey.myzen.co.uk%2Fhome.html&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=T9nJx4glgaENYAL2fAfv%2FBSYXJLQB09en0oVIPRZXss%3D&amp;reserved=0
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>
>https://nam03.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807919794&amp;sdata=uIllXVF7AmuyS8iXU%2FWTPBusVvsjopzNuw6j3dWBT08%3D&amp;reserved=0
>> PLEASE do read the posting guide
>https://nam03.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=02%7C01%7C%7Cd5c4c62072b049c9585308d806607ea8%7C717009a620de461a88940312a395cac9%7C0%7C0%7C637266358807929745&amp;sdata=VwPw2Ue%2BTBysaEw3uWzWRRHQ2sY2TTfGU%2B8z6de8oZo%3D&amp;reserved=0
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Mon Jun  1 22:37:54 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Mon, 1 Jun 2020 15:37:54 -0500
Subject: [R] how to load data frame where numeric will be numeric instead of
 character
Message-ID: <CAF9-5jP=6f9fY+9kZgccoL3iugTQ5VhkwMa3T6-2vBeXF+SRKw@mail.gmail.com>

Hello,

I have a dataframe like this:

  Chr        BP           Marker      MAF A1 A2 Direction   pValue    N
1  10 100000625 10:100000625:A:G 0.416562  G  A         - 0.558228 1594
2  10 100000645 10:100000645:A:C 0.215182  C  A         - 0.880622 1594
...

which I load with:
NEU <- read.table("gokind.neuropathy.fin", header=T,stringsAsFactors=FALSE)

and every column is numeric. How to say have all numeric ones stay numeric
like: Chr, BP, MAF, pValue, N

Thanks
Ana

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Jun  1 22:46:13 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 1 Jun 2020 13:46:13 -0700
Subject: [R] 
 how to load data frame where numeric will be numeric instead of
 character
In-Reply-To: <CAF9-5jP=6f9fY+9kZgccoL3iugTQ5VhkwMa3T6-2vBeXF+SRKw@mail.gmail.com>
References: <CAF9-5jP=6f9fY+9kZgccoL3iugTQ5VhkwMa3T6-2vBeXF+SRKw@mail.gmail.com>
Message-ID: <CAGxFJbQKsBo+MOCz2yXXBoBWFmPB=0xj0Kae74eGRYu6JGVZoA@mail.gmail.com>

I count 8 fields in your data and 9 names in your heading ??


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 1, 2020 at 1:38 PM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Hello,
>
> I have a dataframe like this:
>
>   Chr        BP           Marker      MAF A1 A2 Direction   pValue    N
> 1  10 100000625 10:100000625:A:G 0.416562  G  A         - 0.558228 1594
> 2  10 100000645 10:100000645:A:C 0.215182  C  A         - 0.880622 1594
> ...
>
> which I load with:
> NEU <- read.table("gokind.neuropathy.fin", header=T,stringsAsFactors=FALSE)
>
> and every column is numeric. How to say have all numeric ones stay numeric
> like: Chr, BP, MAF, pValue, N
>
> Thanks
> Ana
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Mon Jun  1 22:50:12 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Mon, 1 Jun 2020 15:50:12 -0500
Subject: [R] 
 how to load data frame where numeric will be numeric instead of
 character
In-Reply-To: <CAGxFJbQKsBo+MOCz2yXXBoBWFmPB=0xj0Kae74eGRYu6JGVZoA@mail.gmail.com>
References: <CAF9-5jP=6f9fY+9kZgccoL3iugTQ5VhkwMa3T6-2vBeXF+SRKw@mail.gmail.com>
 <CAGxFJbQKsBo+MOCz2yXXBoBWFmPB=0xj0Kae74eGRYu6JGVZoA@mail.gmail.com>
Message-ID: <CAF9-5jMCb5zppELZQh8-65HT+r90sMQvcztX861JiQAohrq3LQ@mail.gmail.com>

7th fileld, Direction contains only "+" and "-"


On Mon, Jun 1, 2020 at 3:46 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> I count 8 fields in your data and 9 names in your heading ??
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Jun 1, 2020 at 1:38 PM Ana Marija <sokovic.anamarija at gmail.com>
> wrote:
>
>> Hello,
>>
>> I have a dataframe like this:
>>
>>   Chr        BP           Marker      MAF A1 A2 Direction   pValue    N
>> 1  10 100000625 10:100000625:A:G 0.416562  G  A         - 0.558228 1594
>> 2  10 100000645 10:100000645:A:C 0.215182  C  A         - 0.880622 1594
>> ...
>>
>> which I load with:
>> NEU <- read.table("gokind.neuropathy.fin",
>> header=T,stringsAsFactors=FALSE)
>>
>> and every column is numeric. How to say have all numeric ones stay numeric
>> like: Chr, BP, MAF, pValue, N
>>
>> Thanks
>> Ana
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Mon Jun  1 23:13:27 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 1 Jun 2020 14:13:27 -0700
Subject: [R] 
 how to load data frame where numeric will be numeric instead of
 character
In-Reply-To: <CAF9-5jP=6f9fY+9kZgccoL3iugTQ5VhkwMa3T6-2vBeXF+SRKw@mail.gmail.com>
References: <CAF9-5jP=6f9fY+9kZgccoL3iugTQ5VhkwMa3T6-2vBeXF+SRKw@mail.gmail.com>
Message-ID: <576fefe3-cf6e-1f4e-ee14-9804c168744d@comcast.net>


On 6/1/20 1:37 PM, Ana Marija wrote:
> Hello,
>
> I have a dataframe like this:
>
>    Chr        BP           Marker      MAF A1 A2 Direction   pValue    N
> 1  10 100000625 10:100000625:A:G 0.416562  G  A         - 0.558228 1594
> 2  10 100000645 10:100000645:A:C 0.215182  C  A         - 0.880622 1594
> ...
>
> which I load with:
> NEU <- read.table("gokind.neuropathy.fin", header=T,stringsAsFactors=FALSE)
>
> and every column is numeric. How to say have all numeric ones stay numeric
> like: Chr, BP, MAF, pValue, N


I cannot figure out what the problem is. You say every column is 
numeric. It's not possible to have a column that contains the value 
"10:100000625:A:G" be numeric.


If you meant to say the every column was character, then the answer 
might be:


colClassvec <- rep("numeric",9)
colClassvec[ c(3,5:7)] <- "character"

NEU <- read.table("gokind.neuropathy.fin", header=T,stringsAsFactors=FALSE, colClasses=colClassvec)

-- 
David.

>
> Thanks
> Ana
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Mon Jun  1 23:17:46 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Mon, 1 Jun 2020 16:17:46 -0500
Subject: [R] 
 how to load data frame where numeric will be numeric instead of
 character
In-Reply-To: <576fefe3-cf6e-1f4e-ee14-9804c168744d@comcast.net>
References: <CAF9-5jP=6f9fY+9kZgccoL3iugTQ5VhkwMa3T6-2vBeXF+SRKw@mail.gmail.com>
 <576fefe3-cf6e-1f4e-ee14-9804c168744d@comcast.net>
Message-ID: <CAF9-5jMcjRLYmTZsQ-age==QOVA=PFvXUrck2+YdSaz09N6E8w@mail.gmail.com>

HI David,

this is the problem:

> NEP <- read.table("gokind.nephropathy.fin",
header=T,stringsAsFactors=FALSE)
> sapply(NEP,class)
        Chr          BP      Marker         MAF          A1          A2
"character" "character" "character" "character" "character" "character"
  Direction      pValue           N

So even entries like Chr, BP, MAF....are characters while they should be
numeric
> head(NEP)
  Chr        BP           Marker      MAF A1 A2 Direction   pValue    N
1  10 100000625 10:100000625:A:G   0.4156  G  A         + 0.484813 1641
2  10 100000645 10:100000645:A:C 0.216027  C  A         +  0.73597 1641


Can you please tell me what colClasses=colClassvec suppose to do?

Thanks
Ana

On Mon, Jun 1, 2020 at 4:13 PM David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On 6/1/20 1:37 PM, Ana Marija wrote:
> > Hello,
> >
> > I have a dataframe like this:
> >
> >    Chr        BP           Marker      MAF A1 A2 Direction   pValue    N
> > 1  10 100000625 10:100000625:A:G 0.416562  G  A         - 0.558228 1594
> > 2  10 100000645 10:100000645:A:C 0.215182  C  A         - 0.880622 1594
> > ...
> >
> > which I load with:
> > NEU <- read.table("gokind.neuropathy.fin",
> header=T,stringsAsFactors=FALSE)
> >
> > and every column is numeric. How to say have all numeric ones stay
> numeric
> > like: Chr, BP, MAF, pValue, N
>
>
> I cannot figure out what the problem is. You say every column is
> numeric. It's not possible to have a column that contains the value
> "10:100000625:A:G" be numeric.
>
>
> If you meant to say the every column was character, then the answer
> might be:
>
>
> colClassvec <- rep("numeric",9)
> colClassvec[ c(3,5:7)] <- "character"
>
> NEU <- read.table("gokind.neuropathy.fin",
> header=T,stringsAsFactors=FALSE, colClasses=colClassvec)
>
> --
> David.
>
> >
> > Thanks
> > Ana
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Mon Jun  1 23:50:09 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Mon, 1 Jun 2020 16:50:09 -0500
Subject: [R] is there is a way to extract lines in between 3 files that are
 in common based on one column?
Message-ID: <CAF9-5jP7USAB5OvXm_Zx9Kyg3a2Wa0AEzL_HnD7aEzvEPgGk0w@mail.gmail.com>

Hello,

I have 3 data frames which have about 3.4 mill lines (but they don't have
exactly the same number of lines)...they look like this:

> neu1=neu[order(neu$Marker),]
> head(neu1)
       Chr        BP          Marker      MAF A1 A2 Direction   pValue    N
209565   1 100000012 1:100000012:G:T 0.229925  T  G         + 0.650403 1594
209566   1 100000827 1:100000827:C:T 0.287014  T  C         + 0.955449 1594
209567   1 100002713 1:100002713:C:T 0.097867  T  C         - 0.290455 1594
209568   1 100002882 1:100002882:T:G 0.287014  G  T         + 0.955449 1594
209569   1 100002991 1:100002991:G:A 0.097867  A  G         - 0.290455 1594
209570   1 100004726 1:100004726:G:A 0.132058  A  G         + 0.115005 1594
> nep1=nep[order(nep$Marker),]
> head(nep1)
       Chr        BP          Marker       MAF A1 A2 Direction    pValue
 N
209642   1 100000012 1:100000012:G:T 0.2300430  T  G         - 0.1420030
1641
209643   1 100000827 1:100000827:C:T 0.2867150  T  C         - 0.2045580
1641
209644   1 100002713 1:100002713:C:T 0.0975015  T  C         - 0.0555507
1641
209645   1 100002882 1:100002882:T:G 0.2867150  G  T         - 0.2045580
1641
209646   1 100002991 1:100002991:G:A 0.0975015  A  G         - 0.0555507
1641
209647   1 100004726 1:100004726:G:A 0.1325410  A  G         - 0.8725660
1641
> ret1=ret[order(ret$Marker),]
> head(ret1)
        Chr        BP          Marker       MAF A1 A2 Direction   pValue
 N
865453    1 100000012 1:100000012:G:T 0.2322760  T  G         - 0.230383
1608
451596    1 100000827 1:100000827:C:T 0.2882460  T  C         - 0.120356
1608
1026046   1 100002713 1:100002713:C:T 0.0982587  T  C         - 0.272936
1608
451597    1 100002882 1:100002882:T:G 0.2882460  G  T         - 0.120356
1608
1026047   1 100002991 1:100002991:G:A 0.0982587  A  G         - 0.272936
1608
2234642   1 100004726 1:100004726:G:A 0.1340170  A  G         - 0.594538
1608

Is there is a way to create another 3 data frames, say neu2, nep2, ret2
which would only contain lines that have the same entries in Marker column
for all 3 data frames?

Thanks
Ana

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Jun  2 00:19:37 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 1 Jun 2020 15:19:37 -0700
Subject: [R] 
 how to load data frame where numeric will be numeric instead of
 character
In-Reply-To: <CAF9-5jMcjRLYmTZsQ-age==QOVA=PFvXUrck2+YdSaz09N6E8w@mail.gmail.com>
References: <CAF9-5jP=6f9fY+9kZgccoL3iugTQ5VhkwMa3T6-2vBeXF+SRKw@mail.gmail.com>
 <576fefe3-cf6e-1f4e-ee14-9804c168744d@comcast.net>
 <CAF9-5jMcjRLYmTZsQ-age==QOVA=PFvXUrck2+YdSaz09N6E8w@mail.gmail.com>
Message-ID: <9bfb267d-4cf3-63f1-3269-5e023d2c500d@comcast.net>


On 6/1/20 2:17 PM, Ana Marija wrote:
> HI David,
>
> this is the problem:
>
> > NEP <- read.table("gokind.nephropathy.fin", 
> header=T,stringsAsFactors=FALSE)
> > sapply(NEP,class)
> ? ? ? ? Chr ? ? ? ? ?BP ? ? ?Marker ? ? ? ? MAF ? ? ? ? ?A1 ? ? ? ?A2
> "character" "character" "character" "character" "character" "character"
> ? Direction ? ? ?pValue ? ? ? ? ? N
>
> So even entries like Chr, BP, MAF....are characters while they should 
> be numeric
> > head(NEP)
> ? Chr ? ? ? ?BP ? ? ? ? ? Marker ? ? ?MAF A1 A2 Direction pValue ? ?N
> 1 ?10 100000625 10:100000625:A:G ? 0.4156 ?G ?A ? ? ? ? + 0.484813 1641
> 2 ?10 100000645 10:100000645:A:C 0.216027 ?C ?A ? ? ? ? + ?0.73597 1641
>
>
> Can you please tell me what colClasses=colClassvec suppose to do?


I could tell you, but I think instead that you should read the 
documentation for the `read.table` function.


-- 

David

>
> Thanks
> Ana
>
> On Mon, Jun 1, 2020 at 4:13 PM David Winsemius <dwinsemius at comcast.net 
> <mailto:dwinsemius at comcast.net>> wrote:
>
>
>     On 6/1/20 1:37 PM, Ana Marija wrote:
>     > Hello,
>     >
>     > I have a dataframe like this:
>     >
>     >? ? Chr? ? ? ? BP? ? ? ? ? ?Marker? ? ? MAF A1 A2 Direction?
>     ?pValue? ? N
>     > 1? 10 100000625 10:100000625:A:G 0.416562? G? A? ? ? ? ?-
>     0.558228 1594
>     > 2? 10 100000645 10:100000645:A:C 0.215182? C? A? ? ? ? ?-
>     0.880622 1594
>     > ...
>     >
>     > which I load with:
>     > NEU <- read.table("gokind.neuropathy.fin",
>     header=T,stringsAsFactors=FALSE)
>     >
>     > and every column is numeric. How to say have all numeric ones
>     stay numeric
>     > like: Chr, BP, MAF, pValue, N
>
>
>     I cannot figure out what the problem is. You say every column is
>     numeric. It's not possible to have a column that contains the value
>     "10:100000625:A:G" be numeric.
>
>
>     If you meant to say the every column was character, then the answer
>     might be:
>
>
>     colClassvec <- rep("numeric",9)
>     colClassvec[ c(3,5:7)] <- "character"
>
>     NEU <- read.table("gokind.neuropathy.fin",
>     header=T,stringsAsFactors=FALSE, colClasses=colClassvec)
>
>     -- 
>     David.
>
>     >
>     > Thanks
>     > Ana
>     >
>     >? ? ? ?[[alternative HTML version deleted]]
>     >
>     > ______________________________________________
>     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Tue Jun  2 00:50:19 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 2 Jun 2020 08:50:19 +1000
Subject: [R] Query on contour plots
In-Reply-To: <CAB8pepw=_i+wwome9t79pkUL-xHAGSoxYeeX9DnkKp7W5wqDzA@mail.gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CAB8pepw=_i+wwome9t79pkUL-xHAGSoxYeeX9DnkKp7W5wqDzA@mail.gmail.com>
Message-ID: <CA+8X3fVyUaEFss0o08MZ1DyBN29Xw_8_CPkpamdHmdWT45sNFg@mail.gmail.com>

Good morning Bruce & Abby,
The fruit bats of Sydney have retreated to their camps so I can
finally answer your last two queries. Attached is a plot of your data
set on a 100 x 100 grid. This is how I did it:

bfs<-read.csv("Procen_sample.csv")
dim(bfs)
names(bfs)
library(plotrix)
# set the matrix limits a bit beyond the data ranges
fcsc_mat<-makeDensityMatrix(bfs$Fc,bfs$Sc,nx=100,ny=100,
 zfun="sum",xlim=c(24,29),ylim=c(-20,10))
png("bat_call.png")
par(mar=c(6,4,4,2))
color2D.matplot(fcsc_mat,
 main="Freqency by chirp slope of bat calls",
 extremes=c("yellow","red"),xlab="Frequency (kHz)",
 ylab="Characteristic slope (octaves/s)",
 border=NA,axes=FALSE)
axis(1,at=seq(5,95,10),round(seq(24.5,28.5,length.out=10),1))
axis(2,at=seq(5,95,10),round(seq(-20,10,length.out=10),1))
color.legend(0,-14,25,-10,legend=seq(0,10,length.out=5),
 rect.col=color.scale(0:4,extremes=c("yellow","red")),align="rb")
text(12.5,-20,"Density (cell count)",xpd=TRUE)
dev.off()

Abby's bivariate package looks like it will do some things that
color2D.matplot won't. However, I haven't had time to install it and
try it out, so I don't know whether it will be as easy to plug
different calls onto the same grid. Also, there appears to be
constraints on the frequency and slope in the calls and I don't know
enough about them to say why. Further tweaking may lead to better
solutions.

Jim

-------------- next part --------------
A non-text attachment was scrubbed...
Name: bat_call.png
Type: image/png
Size: 18612 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200602/af0030c1/attachment.png>

From bgunter@4567 @end|ng |rom gm@||@com  Tue Jun  2 01:35:33 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 1 Jun 2020 16:35:33 -0700
Subject: [R] 
 how to load data frame where numeric will be numeric instead of
 character
In-Reply-To: <9bfb267d-4cf3-63f1-3269-5e023d2c500d@comcast.net>
References: <CAF9-5jP=6f9fY+9kZgccoL3iugTQ5VhkwMa3T6-2vBeXF+SRKw@mail.gmail.com>
 <576fefe3-cf6e-1f4e-ee14-9804c168744d@comcast.net>
 <CAF9-5jMcjRLYmTZsQ-age==QOVA=PFvXUrck2+YdSaz09N6E8w@mail.gmail.com>
 <9bfb267d-4cf3-63f1-3269-5e023d2c500d@comcast.net>
Message-ID: <CAGxFJbSCKq07sUX=hNegQM1Qf=w5BU6MvgEf_ngoaOevkAd6kQ@mail.gmail.com>

Agreed!

However, there may still be a problem, as read.table() ordinarily would
read numeric columns correctly (via type.convert()) without the colClasses
specification.
So I would suspect that her "numeric" columns contain some non-numeric
detritus (perhaps "," or some NA symbol). But of course, who knows? -- and
she should follow David's advice to read the docs anyway.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 1, 2020 at 3:19 PM David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On 6/1/20 2:17 PM, Ana Marija wrote:
> > HI David,
> >
> > this is the problem:
> >
> > > NEP <- read.table("gokind.nephropathy.fin",
> > header=T,stringsAsFactors=FALSE)
> > > sapply(NEP,class)
> >         Chr          BP      Marker         MAF          A1        A2
> > "character" "character" "character" "character" "character" "character"
> >   Direction      pValue           N
> >
> > So even entries like Chr, BP, MAF....are characters while they should
> > be numeric
> > > head(NEP)
> >   Chr        BP           Marker      MAF A1 A2 Direction pValue    N
> > 1  10 100000625 10:100000625:A:G   0.4156  G  A         + 0.484813 1641
> > 2  10 100000645 10:100000645:A:C 0.216027  C  A         +  0.73597 1641
> >
> >
> > Can you please tell me what colClasses=colClassvec suppose to do?
>
>
> I could tell you, but I think instead that you should read the
> documentation for the `read.table` function.
>
>
> --
>
> David
>
> >
> > Thanks
> > Ana
> >
> > On Mon, Jun 1, 2020 at 4:13 PM David Winsemius <dwinsemius at comcast.net
> > <mailto:dwinsemius at comcast.net>> wrote:
> >
> >
> >     On 6/1/20 1:37 PM, Ana Marija wrote:
> >     > Hello,
> >     >
> >     > I have a dataframe like this:
> >     >
> >     >    Chr        BP           Marker      MAF A1 A2 Direction
> >      pValue    N
> >     > 1  10 100000625 10:100000625:A:G 0.416562  G  A         -
> >     0.558228 1594
> >     > 2  10 100000645 10:100000645:A:C 0.215182  C  A         -
> >     0.880622 1594
> >     > ...
> >     >
> >     > which I load with:
> >     > NEU <- read.table("gokind.neuropathy.fin",
> >     header=T,stringsAsFactors=FALSE)
> >     >
> >     > and every column is numeric. How to say have all numeric ones
> >     stay numeric
> >     > like: Chr, BP, MAF, pValue, N
> >
> >
> >     I cannot figure out what the problem is. You say every column is
> >     numeric. It's not possible to have a column that contains the value
> >     "10:100000625:A:G" be numeric.
> >
> >
> >     If you meant to say the every column was character, then the answer
> >     might be:
> >
> >
> >     colClassvec <- rep("numeric",9)
> >     colClassvec[ c(3,5:7)] <- "character"
> >
> >     NEU <- read.table("gokind.neuropathy.fin",
> >     header=T,stringsAsFactors=FALSE, colClasses=colClassvec)
> >
> >     --
> >     David.
> >
> >     >
> >     > Thanks
> >     > Ana
> >     >
> >     >       [[alternative HTML version deleted]]
> >     >
> >     > ______________________________________________
> >     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> >     -- To UNSUBSCRIBE and more, see
> >     > https://stat.ethz.ch/mailman/listinfo/r-help
> >     > PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >     > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Tue Jun  2 02:31:11 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 2 Jun 2020 10:31:11 +1000
Subject: [R] 
 is there is a way to extract lines in between 3 files that are
 in common based on one column?
In-Reply-To: <CAF9-5jP7USAB5OvXm_Zx9Kyg3a2Wa0AEzL_HnD7aEzvEPgGk0w@mail.gmail.com>
References: <CAF9-5jP7USAB5OvXm_Zx9Kyg3a2Wa0AEzL_HnD7aEzvEPgGk0w@mail.gmail.com>
Message-ID: <CA+8X3fVS63pNpGJjpGyFniR8awZ9zu_TE85NzKauimp81_h5TQ@mail.gmail.com>

Hi Ana,
Not too hard, but your example has all the "marker" fields in common.
So using a sample that will show the expected result:

neu1<-read.table(text="Chr BP Marker  MAF A1 A2 Direction  pValue N
 1 100000012 1:100000012:G:T 0.229925  T  G  + 0.650403 1594
 1 100000827 1:100000827:C:T 0.287014  T  C  + 0.955449 1594
 1 100002713 1:100002713:C:T 0.097867  T  C  - 0.290455 1594
 1 100002882 1:100002882:T:G 0.287014  G  T  + 0.955449 1594
 1 100002991 1:100002991:G:A 0.097867  A  G  - 0.290455 1594
 1 100004726 1:100004726:G:A 0.132058  A  G  + 0.115005 1594",
 header=TRUE,stringsAsFactors=FALSE)

nep1<-read.table(text="Chr BP Marker MAF A1 A2 Direction    pValue N
 1 100000012 1:100000012:G:T 0.2300430 T  G - 0.1420030 1641
 1 100000827 1:100000827:C:T 0.2867150 T  C - 0.2045580 1641
 1 100002713 1:100002713:C:T 0.0975015 T  C - 0.0555507 1641
 1 100002882 1:100002882:T:G 0.2867150 G  T - 0.2045580 1641
 1 100002991 1:100002991:G:A 0.0975015 A  G - 0.0555507 1641
 1 100004726 1:100004727:G:A 0.1325410 A  G - 0.8725660 1641",
 header=TRUE,stringsAsFactors=FALSE)

ret1<-read.table(text="Chr BP Marker MAF A1 A2 Direction   pValue N
 1 100000012 1:100000012:G:T 0.2322760 T  G - 0.230383 1608
 1 100000827 1:100000827:C:T 0.2882460 T  C - 0.120356 1608
 1 100002713 1:100002713:C:T 0.0982587 T  C - 0.272936 1608
 1 100002882 1:100002882:T:G 0.2882460 G  T - 0.120356 1608
 1 100002991 1:100002992:G:A 0.0982587 A  G - 0.272936 1608
 1 100004726 1:100004727:G:A 0.1340170 A  G - 0.594538 1608",
header=TRUE,stringsAsFactors=FALSE)

# merge the three data frames on "Marker"
nn1<-merge(neu1,nep1,by="Marker")
nn2<-merge(nn1,ret1,by="Marker")
# get the common "Marker" strings
Marker3<-nn2$Marker
# subset all three data frames on Marker3
neu2<-neu1[neu1$Marker %in% Marker3,]
nep2<-nep1[nep1$Marker %in% Marker3,]
ret2<-ret1[ret1$Marker %in% Marker3,]

Jim

On Tue, Jun 2, 2020 at 7:50 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> I have 3 data frames which have about 3.4 mill lines (but they don't have
> exactly the same number of lines)...they look like this:
> ...
> Is there is a way to create another 3 data frames, say neu2, nep2, ret2
> which would only contain lines that have the same entries in Marker column
> for all 3 data frames?
>
> Thanks
> Ana
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Jun  2 02:40:32 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Mon, 1 Jun 2020 19:40:32 -0500
Subject: [R] 
 is there is a way to extract lines in between 3 files that are
 in common based on one column?
In-Reply-To: <CA+8X3fVS63pNpGJjpGyFniR8awZ9zu_TE85NzKauimp81_h5TQ@mail.gmail.com>
References: <CAF9-5jP7USAB5OvXm_Zx9Kyg3a2Wa0AEzL_HnD7aEzvEPgGk0w@mail.gmail.com>
 <CA+8X3fVS63pNpGJjpGyFniR8awZ9zu_TE85NzKauimp81_h5TQ@mail.gmail.com>
Message-ID: <CAF9-5jPYgTavbN2pFDxqQ1MTrb0f-GwgU6+GDjXsN6adQG0=Qw@mail.gmail.com>

Hi Jim,

thank you so much for getting back to me. I tried your code and this is
what I get:
> dim(neu2)
[1] 3740988       9
> dim(nep2)
[1] 3740988       9
> dim(ret2)
[1] 3740001       9

I think I would need to have the same number of lines in all 3 data frames.

Can you please advise.

Cheers
Ana

On Mon, Jun 1, 2020 at 7:31 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Ana,
> Not too hard, but your example has all the "marker" fields in common.
> So using a sample that will show the expected result:
>
> neu1<-read.table(text="Chr BP Marker  MAF A1 A2 Direction  pValue N
>  1 100000012 1:100000012:G:T 0.229925  T  G  + 0.650403 1594
>  1 100000827 1:100000827:C:T 0.287014  T  C  + 0.955449 1594
>  1 100002713 1:100002713:C:T 0.097867  T  C  - 0.290455 1594
>  1 100002882 1:100002882:T:G 0.287014  G  T  + 0.955449 1594
>  1 100002991 1:100002991:G:A 0.097867  A  G  - 0.290455 1594
>  1 100004726 1:100004726:G:A 0.132058  A  G  + 0.115005 1594",
>  header=TRUE,stringsAsFactors=FALSE)
>
> nep1<-read.table(text="Chr BP Marker MAF A1 A2 Direction    pValue N
>  1 100000012 1:100000012:G:T 0.2300430 T  G - 0.1420030 1641
>  1 100000827 1:100000827:C:T 0.2867150 T  C - 0.2045580 1641
>  1 100002713 1:100002713:C:T 0.0975015 T  C - 0.0555507 1641
>  1 100002882 1:100002882:T:G 0.2867150 G  T - 0.2045580 1641
>  1 100002991 1:100002991:G:A 0.0975015 A  G - 0.0555507 1641
>  1 100004726 1:100004727:G:A 0.1325410 A  G - 0.8725660 1641",
>  header=TRUE,stringsAsFactors=FALSE)
>
> ret1<-read.table(text="Chr BP Marker MAF A1 A2 Direction   pValue N
>  1 100000012 1:100000012:G:T 0.2322760 T  G - 0.230383 1608
>  1 100000827 1:100000827:C:T 0.2882460 T  C - 0.120356 1608
>  1 100002713 1:100002713:C:T 0.0982587 T  C - 0.272936 1608
>  1 100002882 1:100002882:T:G 0.2882460 G  T - 0.120356 1608
>  1 100002991 1:100002992:G:A 0.0982587 A  G - 0.272936 1608
>  1 100004726 1:100004727:G:A 0.1340170 A  G - 0.594538 1608",
> header=TRUE,stringsAsFactors=FALSE)
>
> # merge the three data frames on "Marker"
> nn1<-merge(neu1,nep1,by="Marker")
> nn2<-merge(nn1,ret1,by="Marker")
> # get the common "Marker" strings
> Marker3<-nn2$Marker
> # subset all three data frames on Marker3
> neu2<-neu1[neu1$Marker %in% Marker3,]
> nep2<-nep1[nep1$Marker %in% Marker3,]
> ret2<-ret1[ret1$Marker %in% Marker3,]
>
> Jim
>
> On Tue, Jun 2, 2020 at 7:50 AM Ana Marija <sokovic.anamarija at gmail.com>
> wrote:
> >
> > Hello,
> >
> > I have 3 data frames which have about 3.4 mill lines (but they don't have
> > exactly the same number of lines)...they look like this:
> > ...
> > Is there is a way to create another 3 data frames, say neu2, nep2, ret2
> > which would only contain lines that have the same entries in Marker
> column
> > for all 3 data frames?
> >
> > Thanks
> > Ana
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jr@| @end|ng |rom po@teo@no  Tue Jun  2 03:34:31 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Tue, 2 Jun 2020 03:34:31 +0200
Subject: [R] 
 is there is a way to extract lines in between 3 files that are
 in common based on one column?
In-Reply-To: <CAF9-5jPYgTavbN2pFDxqQ1MTrb0f-GwgU6+GDjXsN6adQG0=Qw@mail.gmail.com>
References: <CAF9-5jP7USAB5OvXm_Zx9Kyg3a2Wa0AEzL_HnD7aEzvEPgGk0w@mail.gmail.com>
 <CA+8X3fVS63pNpGJjpGyFniR8awZ9zu_TE85NzKauimp81_h5TQ@mail.gmail.com>
 <CAF9-5jPYgTavbN2pFDxqQ1MTrb0f-GwgU6+GDjXsN6adQG0=Qw@mail.gmail.com>
Message-ID: <20200602013431.GA1315@posteo.no>

Dear Ana and Jim,

On 2020-06-01 19:40 -0500, Ana Marija wrote:
> > dim(neu2)
> [1] 3740988       9
> > dim(nep2)
> [1] 3740988       9
> > dim(ret2)
> [1] 3740001       9

Jim's code works out of the box directly from 
the email ... I get:

[1] 6 9
[1] 4 9
[1] 4 9

On 2020-06-01 19:40 -0500, Ana Marija wrote:
> On Tue, Jun 2, 2020 at 7:50 AM Ana Marija wrote:
> > 
> > but they don't have exactly the same 
> > number of lines
> 
> I think I would need to have the same 
> number of lines in all 3 data frames.

This does not make sense :?-\

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200602/b154d574/attachment.sig>

From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Jun  2 03:41:45 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 1 Jun 2020 18:41:45 -0700
Subject: [R] 
 is there is a way to extract lines in between 3 files that are
 in common based on one column?
In-Reply-To: <CAF9-5jPYgTavbN2pFDxqQ1MTrb0f-GwgU6+GDjXsN6adQG0=Qw@mail.gmail.com>
References: <CAF9-5jP7USAB5OvXm_Zx9Kyg3a2Wa0AEzL_HnD7aEzvEPgGk0w@mail.gmail.com>
 <CA+8X3fVS63pNpGJjpGyFniR8awZ9zu_TE85NzKauimp81_h5TQ@mail.gmail.com>
 <CAF9-5jPYgTavbN2pFDxqQ1MTrb0f-GwgU6+GDjXsN6adQG0=Qw@mail.gmail.com>
Message-ID: <db327080-ffa4-f217-3087-41476ff30db5@comcast.net>


On 6/1/20 5:40 PM, Ana Marija wrote:
> Hi Jim,
>
> thank you so much for getting back to me. I tried your code and this is
> what I get:
>> dim(neu2)
> [1] 3740988       9
>> dim(nep2)
> [1] 3740988       9
>> dim(ret2)
> [1] 3740001       9
>
> I think I would need to have the same number of lines in all 3 data frames.
>
> Can you please advise.


You should check for duplicated Marker values.


-- 

David

>
> Cheers
> Ana
>
> On Mon, Jun 1, 2020 at 7:31 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi Ana,
>> Not too hard, but your example has all the "marker" fields in common.
>> So using a sample that will show the expected result:
>>
>> neu1<-read.table(text="Chr BP Marker  MAF A1 A2 Direction  pValue N
>>   1 100000012 1:100000012:G:T 0.229925  T  G  + 0.650403 1594
>>   1 100000827 1:100000827:C:T 0.287014  T  C  + 0.955449 1594
>>   1 100002713 1:100002713:C:T 0.097867  T  C  - 0.290455 1594
>>   1 100002882 1:100002882:T:G 0.287014  G  T  + 0.955449 1594
>>   1 100002991 1:100002991:G:A 0.097867  A  G  - 0.290455 1594
>>   1 100004726 1:100004726:G:A 0.132058  A  G  + 0.115005 1594",
>>   header=TRUE,stringsAsFactors=FALSE)
>>
>> nep1<-read.table(text="Chr BP Marker MAF A1 A2 Direction    pValue N
>>   1 100000012 1:100000012:G:T 0.2300430 T  G - 0.1420030 1641
>>   1 100000827 1:100000827:C:T 0.2867150 T  C - 0.2045580 1641
>>   1 100002713 1:100002713:C:T 0.0975015 T  C - 0.0555507 1641
>>   1 100002882 1:100002882:T:G 0.2867150 G  T - 0.2045580 1641
>>   1 100002991 1:100002991:G:A 0.0975015 A  G - 0.0555507 1641
>>   1 100004726 1:100004727:G:A 0.1325410 A  G - 0.8725660 1641",
>>   header=TRUE,stringsAsFactors=FALSE)
>>
>> ret1<-read.table(text="Chr BP Marker MAF A1 A2 Direction   pValue N
>>   1 100000012 1:100000012:G:T 0.2322760 T  G - 0.230383 1608
>>   1 100000827 1:100000827:C:T 0.2882460 T  C - 0.120356 1608
>>   1 100002713 1:100002713:C:T 0.0982587 T  C - 0.272936 1608
>>   1 100002882 1:100002882:T:G 0.2882460 G  T - 0.120356 1608
>>   1 100002991 1:100002992:G:A 0.0982587 A  G - 0.272936 1608
>>   1 100004726 1:100004727:G:A 0.1340170 A  G - 0.594538 1608",
>> header=TRUE,stringsAsFactors=FALSE)
>>
>> # merge the three data frames on "Marker"
>> nn1<-merge(neu1,nep1,by="Marker")
>> nn2<-merge(nn1,ret1,by="Marker")
>> # get the common "Marker" strings
>> Marker3<-nn2$Marker
>> # subset all three data frames on Marker3
>> neu2<-neu1[neu1$Marker %in% Marker3,]
>> nep2<-nep1[nep1$Marker %in% Marker3,]
>> ret2<-ret1[ret1$Marker %in% Marker3,]
>>
>> Jim
>>
>> On Tue, Jun 2, 2020 at 7:50 AM Ana Marija <sokovic.anamarija at gmail.com>
>> wrote:
>>> Hello,
>>>
>>> I have 3 data frames which have about 3.4 mill lines (but they don't have
>>> exactly the same number of lines)...they look like this:
>>> ...
>>> Is there is a way to create another 3 data frames, say neu2, nep2, ret2
>>> which would only contain lines that have the same entries in Marker
>> column
>>> for all 3 data frames?
>>>
>>> Thanks
>>> Ana
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Tue Jun  2 03:48:30 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 2 Jun 2020 11:48:30 +1000
Subject: [R] 
 is there is a way to extract lines in between 3 files that are
 in common based on one column?
In-Reply-To: <CAF9-5jPYgTavbN2pFDxqQ1MTrb0f-GwgU6+GDjXsN6adQG0=Qw@mail.gmail.com>
References: <CAF9-5jP7USAB5OvXm_Zx9Kyg3a2Wa0AEzL_HnD7aEzvEPgGk0w@mail.gmail.com>
 <CA+8X3fVS63pNpGJjpGyFniR8awZ9zu_TE85NzKauimp81_h5TQ@mail.gmail.com>
 <CAF9-5jPYgTavbN2pFDxqQ1MTrb0f-GwgU6+GDjXsN6adQG0=Qw@mail.gmail.com>
Message-ID: <CA+8X3fWnJr0MFEnR83RyFKpHP3=SvGPg-5o8R1cSvSNG+UvS6Q@mail.gmail.com>

Hi Ana,
If I add another 6 rows to neu1, 2 to nep1 and one to ret1 and modify
the "Marker" field so that there is one more match, I get the result I
expect. I think that the program logic is correct. I can't say why
ret1 has fewer lines. If there aren't too many mismatches, maybe
checking the mismatches will help:

neu3<-neu1[!(neu1$Marker %in% Marker3),]
nep3<-nep1[!(nep1$Marker %in% Marker3),]
ret3<-ret1[!(ret1$Marker %in% Marker3),]
neu3
nep3
ret3

Jim

On Tue, Jun 2, 2020 at 10:40 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hi Jim,
>
> thank you so much for getting back to me. I tried your code and this is what I get:
> > dim(neu2)
> [1] 3740988       9
> > dim(nep2)
> [1] 3740988       9
> > dim(ret2)
> [1] 3740001       9
>
> I think I would need to have the same number of lines in all 3 data frames.
>
> Can you please advise.
>
> Cheers
> Ana
>
> On Mon, Jun 1, 2020 at 7:31 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Ana,
>> Not too hard, but your example has all the "marker" fields in common.
>> So using a sample that will show the expected result:
>>
>> neu1<-read.table(text="Chr BP Marker  MAF A1 A2 Direction  pValue N
>>  1 100000012 1:100000012:G:T 0.229925  T  G  + 0.650403 1594
>>  1 100000827 1:100000827:C:T 0.287014  T  C  + 0.955449 1594
>>  1 100002713 1:100002713:C:T 0.097867  T  C  - 0.290455 1594
>>  1 100002882 1:100002882:T:G 0.287014  G  T  + 0.955449 1594
>>  1 100002991 1:100002991:G:A 0.097867  A  G  - 0.290455 1594
>>  1 100004726 1:100004726:G:A 0.132058  A  G  + 0.115005 1594",
>>  header=TRUE,stringsAsFactors=FALSE)
>>
>> nep1<-read.table(text="Chr BP Marker MAF A1 A2 Direction    pValue N
>>  1 100000012 1:100000012:G:T 0.2300430 T  G - 0.1420030 1641
>>  1 100000827 1:100000827:C:T 0.2867150 T  C - 0.2045580 1641
>>  1 100002713 1:100002713:C:T 0.0975015 T  C - 0.0555507 1641
>>  1 100002882 1:100002882:T:G 0.2867150 G  T - 0.2045580 1641
>>  1 100002991 1:100002991:G:A 0.0975015 A  G - 0.0555507 1641
>>  1 100004726 1:100004727:G:A 0.1325410 A  G - 0.8725660 1641",
>>  header=TRUE,stringsAsFactors=FALSE)
>>
>> ret1<-read.table(text="Chr BP Marker MAF A1 A2 Direction   pValue N
>>  1 100000012 1:100000012:G:T 0.2322760 T  G - 0.230383 1608
>>  1 100000827 1:100000827:C:T 0.2882460 T  C - 0.120356 1608
>>  1 100002713 1:100002713:C:T 0.0982587 T  C - 0.272936 1608
>>  1 100002882 1:100002882:T:G 0.2882460 G  T - 0.120356 1608
>>  1 100002991 1:100002992:G:A 0.0982587 A  G - 0.272936 1608
>>  1 100004726 1:100004727:G:A 0.1340170 A  G - 0.594538 1608",
>> header=TRUE,stringsAsFactors=FALSE)
>>
>> # merge the three data frames on "Marker"
>> nn1<-merge(neu1,nep1,by="Marker")
>> nn2<-merge(nn1,ret1,by="Marker")
>> # get the common "Marker" strings
>> Marker3<-nn2$Marker
>> # subset all three data frames on Marker3
>> neu2<-neu1[neu1$Marker %in% Marker3,]
>> nep2<-nep1[nep1$Marker %in% Marker3,]
>> ret2<-ret1[ret1$Marker %in% Marker3,]
>>
>> Jim
>>
>> On Tue, Jun 2, 2020 at 7:50 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>> >
>> > Hello,
>> >
>> > I have 3 data frames which have about 3.4 mill lines (but they don't have
>> > exactly the same number of lines)...they look like this:
>> > ...
>> > Is there is a way to create another 3 data frames, say neu2, nep2, ret2
>> > which would only contain lines that have the same entries in Marker column
>> > for all 3 data frames?
>> >
>> > Thanks
>> > Ana
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Jun  2 03:50:09 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Mon, 1 Jun 2020 20:50:09 -0500
Subject: [R] 
 is there is a way to extract lines in between 3 files that are
 in common based on one column?
In-Reply-To: <db327080-ffa4-f217-3087-41476ff30db5@comcast.net>
References: <CAF9-5jP7USAB5OvXm_Zx9Kyg3a2Wa0AEzL_HnD7aEzvEPgGk0w@mail.gmail.com>
 <CA+8X3fVS63pNpGJjpGyFniR8awZ9zu_TE85NzKauimp81_h5TQ@mail.gmail.com>
 <CAF9-5jPYgTavbN2pFDxqQ1MTrb0f-GwgU6+GDjXsN6adQG0=Qw@mail.gmail.com>
 <db327080-ffa4-f217-3087-41476ff30db5@comcast.net>
Message-ID: <CAF9-5jOZiLFRV8cDr_nTn6gU_W2iucAreu_s76vm3yMrhhoWpQ@mail.gmail.com>

Hi David,

that is a great point!
Yes indeed some are non unique:

> dim(neu1)
[1] 3742845       9
> length(unique(neu1$Marker))
[1] 3741858
> length(unique(nep1$Marker))
[1] 3745560
> dim(nep1)
[1] 3746550       9
> length(unique(ret1$Marker))
[1] 3743494
> dim(ret1)
[1] 3743494       9

How would I rewrite this code so that is merging by Chr and Marker
column? It seems that a Marker can be under a few Chr.





On Mon, Jun 1, 2020 at 8:41 PM David Winsemius <dwinsemius at comcast.net> wrote:
>
>
> On 6/1/20 5:40 PM, Ana Marija wrote:
> > Hi Jim,
> >
> > thank you so much for getting back to me. I tried your code and this is
> > what I get:
> >> dim(neu2)
> > [1] 3740988       9
> >> dim(nep2)
> > [1] 3740988       9
> >> dim(ret2)
> > [1] 3740001       9
> >
> > I think I would need to have the same number of lines in all 3 data frames.
> >
> > Can you please advise.
>
>
> You should check for duplicated Marker values.
>
>
> --
>
> David
>
> >
> > Cheers
> > Ana
> >
> > On Mon, Jun 1, 2020 at 7:31 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> >> Hi Ana,
> >> Not too hard, but your example has all the "marker" fields in common.
> >> So using a sample that will show the expected result:
> >>
> >> neu1<-read.table(text="Chr BP Marker  MAF A1 A2 Direction  pValue N
> >>   1 100000012 1:100000012:G:T 0.229925  T  G  + 0.650403 1594
> >>   1 100000827 1:100000827:C:T 0.287014  T  C  + 0.955449 1594
> >>   1 100002713 1:100002713:C:T 0.097867  T  C  - 0.290455 1594
> >>   1 100002882 1:100002882:T:G 0.287014  G  T  + 0.955449 1594
> >>   1 100002991 1:100002991:G:A 0.097867  A  G  - 0.290455 1594
> >>   1 100004726 1:100004726:G:A 0.132058  A  G  + 0.115005 1594",
> >>   header=TRUE,stringsAsFactors=FALSE)
> >>
> >> nep1<-read.table(text="Chr BP Marker MAF A1 A2 Direction    pValue N
> >>   1 100000012 1:100000012:G:T 0.2300430 T  G - 0.1420030 1641
> >>   1 100000827 1:100000827:C:T 0.2867150 T  C - 0.2045580 1641
> >>   1 100002713 1:100002713:C:T 0.0975015 T  C - 0.0555507 1641
> >>   1 100002882 1:100002882:T:G 0.2867150 G  T - 0.2045580 1641
> >>   1 100002991 1:100002991:G:A 0.0975015 A  G - 0.0555507 1641
> >>   1 100004726 1:100004727:G:A 0.1325410 A  G - 0.8725660 1641",
> >>   header=TRUE,stringsAsFactors=FALSE)
> >>
> >> ret1<-read.table(text="Chr BP Marker MAF A1 A2 Direction   pValue N
> >>   1 100000012 1:100000012:G:T 0.2322760 T  G - 0.230383 1608
> >>   1 100000827 1:100000827:C:T 0.2882460 T  C - 0.120356 1608
> >>   1 100002713 1:100002713:C:T 0.0982587 T  C - 0.272936 1608
> >>   1 100002882 1:100002882:T:G 0.2882460 G  T - 0.120356 1608
> >>   1 100002991 1:100002992:G:A 0.0982587 A  G - 0.272936 1608
> >>   1 100004726 1:100004727:G:A 0.1340170 A  G - 0.594538 1608",
> >> header=TRUE,stringsAsFactors=FALSE)
> >>
> >> # merge the three data frames on "Marker"
> >> nn1<-merge(neu1,nep1,by="Marker")
> >> nn2<-merge(nn1,ret1,by="Marker")
> >> # get the common "Marker" strings
> >> Marker3<-nn2$Marker
> >> # subset all three data frames on Marker3
> >> neu2<-neu1[neu1$Marker %in% Marker3,]
> >> nep2<-nep1[nep1$Marker %in% Marker3,]
> >> ret2<-ret1[ret1$Marker %in% Marker3,]
> >>
> >> Jim
> >>
> >> On Tue, Jun 2, 2020 at 7:50 AM Ana Marija <sokovic.anamarija at gmail.com>
> >> wrote:
> >>> Hello,
> >>>
> >>> I have 3 data frames which have about 3.4 mill lines (but they don't have
> >>> exactly the same number of lines)...they look like this:
> >>> ...
> >>> Is there is a way to create another 3 data frames, say neu2, nep2, ret2
> >>> which would only contain lines that have the same entries in Marker
> >> column
> >>> for all 3 data frames?
> >>>
> >>> Thanks
> >>> Ana
> >>>
> >>>          [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Jun  2 03:54:52 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Mon, 1 Jun 2020 20:54:52 -0500
Subject: [R] 
 is there is a way to extract lines in between 3 files that are
 in common based on one column?
In-Reply-To: <CAF9-5jOZiLFRV8cDr_nTn6gU_W2iucAreu_s76vm3yMrhhoWpQ@mail.gmail.com>
References: <CAF9-5jP7USAB5OvXm_Zx9Kyg3a2Wa0AEzL_HnD7aEzvEPgGk0w@mail.gmail.com>
 <CA+8X3fVS63pNpGJjpGyFniR8awZ9zu_TE85NzKauimp81_h5TQ@mail.gmail.com>
 <CAF9-5jPYgTavbN2pFDxqQ1MTrb0f-GwgU6+GDjXsN6adQG0=Qw@mail.gmail.com>
 <db327080-ffa4-f217-3087-41476ff30db5@comcast.net>
 <CAF9-5jOZiLFRV8cDr_nTn6gU_W2iucAreu_s76vm3yMrhhoWpQ@mail.gmail.com>
Message-ID: <CAF9-5jPkbmNAY6a=zrLUkZwRwJz6Jt2xwQ+XXc5dABk03GnXJA@mail.gmail.com>

Hi Jim

> neu3<-neu1[!(neu1$Marker %in% Marker3),]
> dim(neu3)
[1] 1857    9
> nep3<-nep1[!(nep1$Marker %in% Marker3),]
> dim(nep3)
[1] 5562    9
> ret3<-ret1[!(ret1$Marker %in% Marker3),]
> dim(ret3)
[1] 3493    9


If I do:

 nn1<-merge(neu1,nep1,by=c("Marker","Chr"))
nn2<-merge(nn1,ret1,by=c("Marker","Chr"))
> Marker3<-nn2$Marker
> length(Marker3)
[1] 3742962
> Marker4<-nn1$Marker
> length(Marker4)
[1] 3744443

On Mon, Jun 1, 2020 at 8:50 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hi David,
>
> that is a great point!
> Yes indeed some are non unique:
>
> > dim(neu1)
> [1] 3742845       9
> > length(unique(neu1$Marker))
> [1] 3741858
> > length(unique(nep1$Marker))
> [1] 3745560
> > dim(nep1)
> [1] 3746550       9
> > length(unique(ret1$Marker))
> [1] 3743494
> > dim(ret1)
> [1] 3743494       9
>
> How would I rewrite this code so that is merging by Chr and Marker
> column? It seems that a Marker can be under a few Chr.
>
>
>
>
>
> On Mon, Jun 1, 2020 at 8:41 PM David Winsemius <dwinsemius at comcast.net> wrote:
> >
> >
> > On 6/1/20 5:40 PM, Ana Marija wrote:
> > > Hi Jim,
> > >
> > > thank you so much for getting back to me. I tried your code and this is
> > > what I get:
> > >> dim(neu2)
> > > [1] 3740988       9
> > >> dim(nep2)
> > > [1] 3740988       9
> > >> dim(ret2)
> > > [1] 3740001       9
> > >
> > > I think I would need to have the same number of lines in all 3 data frames.
> > >
> > > Can you please advise.
> >
> >
> > You should check for duplicated Marker values.
> >
> >
> > --
> >
> > David
> >
> > >
> > > Cheers
> > > Ana
> > >
> > > On Mon, Jun 1, 2020 at 7:31 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> > >
> > >> Hi Ana,
> > >> Not too hard, but your example has all the "marker" fields in common.
> > >> So using a sample that will show the expected result:
> > >>
> > >> neu1<-read.table(text="Chr BP Marker  MAF A1 A2 Direction  pValue N
> > >>   1 100000012 1:100000012:G:T 0.229925  T  G  + 0.650403 1594
> > >>   1 100000827 1:100000827:C:T 0.287014  T  C  + 0.955449 1594
> > >>   1 100002713 1:100002713:C:T 0.097867  T  C  - 0.290455 1594
> > >>   1 100002882 1:100002882:T:G 0.287014  G  T  + 0.955449 1594
> > >>   1 100002991 1:100002991:G:A 0.097867  A  G  - 0.290455 1594
> > >>   1 100004726 1:100004726:G:A 0.132058  A  G  + 0.115005 1594",
> > >>   header=TRUE,stringsAsFactors=FALSE)
> > >>
> > >> nep1<-read.table(text="Chr BP Marker MAF A1 A2 Direction    pValue N
> > >>   1 100000012 1:100000012:G:T 0.2300430 T  G - 0.1420030 1641
> > >>   1 100000827 1:100000827:C:T 0.2867150 T  C - 0.2045580 1641
> > >>   1 100002713 1:100002713:C:T 0.0975015 T  C - 0.0555507 1641
> > >>   1 100002882 1:100002882:T:G 0.2867150 G  T - 0.2045580 1641
> > >>   1 100002991 1:100002991:G:A 0.0975015 A  G - 0.0555507 1641
> > >>   1 100004726 1:100004727:G:A 0.1325410 A  G - 0.8725660 1641",
> > >>   header=TRUE,stringsAsFactors=FALSE)
> > >>
> > >> ret1<-read.table(text="Chr BP Marker MAF A1 A2 Direction   pValue N
> > >>   1 100000012 1:100000012:G:T 0.2322760 T  G - 0.230383 1608
> > >>   1 100000827 1:100000827:C:T 0.2882460 T  C - 0.120356 1608
> > >>   1 100002713 1:100002713:C:T 0.0982587 T  C - 0.272936 1608
> > >>   1 100002882 1:100002882:T:G 0.2882460 G  T - 0.120356 1608
> > >>   1 100002991 1:100002992:G:A 0.0982587 A  G - 0.272936 1608
> > >>   1 100004726 1:100004727:G:A 0.1340170 A  G - 0.594538 1608",
> > >> header=TRUE,stringsAsFactors=FALSE)
> > >>
> > >> # merge the three data frames on "Marker"
> > >> nn1<-merge(neu1,nep1,by="Marker")
> > >> nn2<-merge(nn1,ret1,by="Marker")
> > >> # get the common "Marker" strings
> > >> Marker3<-nn2$Marker
> > >> # subset all three data frames on Marker3
> > >> neu2<-neu1[neu1$Marker %in% Marker3,]
> > >> nep2<-nep1[nep1$Marker %in% Marker3,]
> > >> ret2<-ret1[ret1$Marker %in% Marker3,]
> > >>
> > >> Jim
> > >>
> > >> On Tue, Jun 2, 2020 at 7:50 AM Ana Marija <sokovic.anamarija at gmail.com>
> > >> wrote:
> > >>> Hello,
> > >>>
> > >>> I have 3 data frames which have about 3.4 mill lines (but they don't have
> > >>> exactly the same number of lines)...they look like this:
> > >>> ...
> > >>> Is there is a way to create another 3 data frames, say neu2, nep2, ret2
> > >>> which would only contain lines that have the same entries in Marker
> > >> column
> > >>> for all 3 data frames?
> > >>>
> > >>> Thanks
> > >>> Ana
> > >>>
> > >>>          [[alternative HTML version deleted]]
> > >>>
> > >>> ______________________________________________
> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >>> and provide commented, minimal, self-contained, reproducible code.
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Tue Jun  2 05:04:11 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 2 Jun 2020 13:04:11 +1000
Subject: [R] 
 is there is a way to extract lines in between 3 files that are
 in common based on one column?
In-Reply-To: <CAF9-5jPkbmNAY6a=zrLUkZwRwJz6Jt2xwQ+XXc5dABk03GnXJA@mail.gmail.com>
References: <CAF9-5jP7USAB5OvXm_Zx9Kyg3a2Wa0AEzL_HnD7aEzvEPgGk0w@mail.gmail.com>
 <CA+8X3fVS63pNpGJjpGyFniR8awZ9zu_TE85NzKauimp81_h5TQ@mail.gmail.com>
 <CAF9-5jPYgTavbN2pFDxqQ1MTrb0f-GwgU6+GDjXsN6adQG0=Qw@mail.gmail.com>
 <db327080-ffa4-f217-3087-41476ff30db5@comcast.net>
 <CAF9-5jOZiLFRV8cDr_nTn6gU_W2iucAreu_s76vm3yMrhhoWpQ@mail.gmail.com>
 <CAF9-5jPkbmNAY6a=zrLUkZwRwJz6Jt2xwQ+XXc5dABk03GnXJA@mail.gmail.com>
Message-ID: <CA+8X3fVegAWfMGjvV-0eZe4uMu9NMcDe2DZz10=CFz+BUuNm4Q@mail.gmail.com>

So recombination sticks out its foot before us. Do you want to account
for gene linkage?

JIm

On Tue, Jun 2, 2020 at 11:55 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hi Jim
>
> > neu3<-neu1[!(neu1$Marker %in% Marker3),]
> > dim(neu3)
> [1] 1857    9
> > nep3<-nep1[!(nep1$Marker %in% Marker3),]
> > dim(nep3)
> [1] 5562    9
> > ret3<-ret1[!(ret1$Marker %in% Marker3),]
> > dim(ret3)
> [1] 3493    9
>
>
> If I do:
>
>  nn1<-merge(neu1,nep1,by=c("Marker","Chr"))
> nn2<-merge(nn1,ret1,by=c("Marker","Chr"))
> > Marker3<-nn2$Marker
> > length(Marker3)
> [1] 3742962
> > Marker4<-nn1$Marker
> > length(Marker4)
> [1] 3744443
>
> On Mon, Jun 1, 2020 at 8:50 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hi David,
> >
> > that is a great point!
> > Yes indeed some are non unique:
> >
> > > dim(neu1)
> > [1] 3742845       9
> > > length(unique(neu1$Marker))
> > [1] 3741858
> > > length(unique(nep1$Marker))
> > [1] 3745560
> > > dim(nep1)
> > [1] 3746550       9
> > > length(unique(ret1$Marker))
> > [1] 3743494
> > > dim(ret1)
> > [1] 3743494       9
> >
> > How would I rewrite this code so that is merging by Chr and Marker
> > column? It seems that a Marker can be under a few Chr.
> >
> >
> >
> >
> >
> > On Mon, Jun 1, 2020 at 8:41 PM David Winsemius <dwinsemius at comcast.net> wrote:
> > >
> > >
> > > On 6/1/20 5:40 PM, Ana Marija wrote:
> > > > Hi Jim,
> > > >
> > > > thank you so much for getting back to me. I tried your code and this is
> > > > what I get:
> > > >> dim(neu2)
> > > > [1] 3740988       9
> > > >> dim(nep2)
> > > > [1] 3740988       9
> > > >> dim(ret2)
> > > > [1] 3740001       9
> > > >
> > > > I think I would need to have the same number of lines in all 3 data frames.
> > > >
> > > > Can you please advise.
> > >
> > >
> > > You should check for duplicated Marker values.
> > >
> > >
> > > --
> > >
> > > David
> > >
> > > >
> > > > Cheers
> > > > Ana
> > > >
> > > > On Mon, Jun 1, 2020 at 7:31 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> > > >
> > > >> Hi Ana,
> > > >> Not too hard, but your example has all the "marker" fields in common.
> > > >> So using a sample that will show the expected result:
> > > >>
> > > >> neu1<-read.table(text="Chr BP Marker  MAF A1 A2 Direction  pValue N
> > > >>   1 100000012 1:100000012:G:T 0.229925  T  G  + 0.650403 1594
> > > >>   1 100000827 1:100000827:C:T 0.287014  T  C  + 0.955449 1594
> > > >>   1 100002713 1:100002713:C:T 0.097867  T  C  - 0.290455 1594
> > > >>   1 100002882 1:100002882:T:G 0.287014  G  T  + 0.955449 1594
> > > >>   1 100002991 1:100002991:G:A 0.097867  A  G  - 0.290455 1594
> > > >>   1 100004726 1:100004726:G:A 0.132058  A  G  + 0.115005 1594",
> > > >>   header=TRUE,stringsAsFactors=FALSE)
> > > >>
> > > >> nep1<-read.table(text="Chr BP Marker MAF A1 A2 Direction    pValue N
> > > >>   1 100000012 1:100000012:G:T 0.2300430 T  G - 0.1420030 1641
> > > >>   1 100000827 1:100000827:C:T 0.2867150 T  C - 0.2045580 1641
> > > >>   1 100002713 1:100002713:C:T 0.0975015 T  C - 0.0555507 1641
> > > >>   1 100002882 1:100002882:T:G 0.2867150 G  T - 0.2045580 1641
> > > >>   1 100002991 1:100002991:G:A 0.0975015 A  G - 0.0555507 1641
> > > >>   1 100004726 1:100004727:G:A 0.1325410 A  G - 0.8725660 1641",
> > > >>   header=TRUE,stringsAsFactors=FALSE)
> > > >>
> > > >> ret1<-read.table(text="Chr BP Marker MAF A1 A2 Direction   pValue N
> > > >>   1 100000012 1:100000012:G:T 0.2322760 T  G - 0.230383 1608
> > > >>   1 100000827 1:100000827:C:T 0.2882460 T  C - 0.120356 1608
> > > >>   1 100002713 1:100002713:C:T 0.0982587 T  C - 0.272936 1608
> > > >>   1 100002882 1:100002882:T:G 0.2882460 G  T - 0.120356 1608
> > > >>   1 100002991 1:100002992:G:A 0.0982587 A  G - 0.272936 1608
> > > >>   1 100004726 1:100004727:G:A 0.1340170 A  G - 0.594538 1608",
> > > >> header=TRUE,stringsAsFactors=FALSE)
> > > >>
> > > >> # merge the three data frames on "Marker"
> > > >> nn1<-merge(neu1,nep1,by="Marker")
> > > >> nn2<-merge(nn1,ret1,by="Marker")
> > > >> # get the common "Marker" strings
> > > >> Marker3<-nn2$Marker
> > > >> # subset all three data frames on Marker3
> > > >> neu2<-neu1[neu1$Marker %in% Marker3,]
> > > >> nep2<-nep1[nep1$Marker %in% Marker3,]
> > > >> ret2<-ret1[ret1$Marker %in% Marker3,]
> > > >>
> > > >> Jim
> > > >>
> > > >> On Tue, Jun 2, 2020 at 7:50 AM Ana Marija <sokovic.anamarija at gmail.com>
> > > >> wrote:
> > > >>> Hello,
> > > >>>
> > > >>> I have 3 data frames which have about 3.4 mill lines (but they don't have
> > > >>> exactly the same number of lines)...they look like this:
> > > >>> ...
> > > >>> Is there is a way to create another 3 data frames, say neu2, nep2, ret2
> > > >>> which would only contain lines that have the same entries in Marker
> > > >> column
> > > >>> for all 3 data frames?
> > > >>>
> > > >>> Thanks
> > > >>> Ana
> > > >>>
> > > >>>          [[alternative HTML version deleted]]
> > > >>>
> > > >>> ______________________________________________
> > > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > > >>> PLEASE do read the posting guide
> > > >> http://www.R-project.org/posting-guide.html
> > > >>> and provide commented, minimal, self-contained, reproducible code.
> > > >       [[alternative HTML version deleted]]
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.


From dc@r|@on @end|ng |rom t@mu@edu  Tue Jun  2 05:21:32 2020
From: dc@r|@on @end|ng |rom t@mu@edu (David Carlson)
Date: Mon, 1 Jun 2020 22:21:32 -0500
Subject: [R] 
 how to load data frame where numeric will be numeric instead of
 character
In-Reply-To: <CAGxFJbSCKq07sUX=hNegQM1Qf=w5BU6MvgEf_ngoaOevkAd6kQ@mail.gmail.com>
References: <CAF9-5jP=6f9fY+9kZgccoL3iugTQ5VhkwMa3T6-2vBeXF+SRKw@mail.gmail.com>
 <576fefe3-cf6e-1f4e-ee14-9804c168744d@comcast.net>
 <CAF9-5jMcjRLYmTZsQ-age==QOVA=PFvXUrck2+YdSaz09N6E8w@mail.gmail.com>
 <9bfb267d-4cf3-63f1-3269-5e023d2c500d@comcast.net>
 <CAGxFJbSCKq07sUX=hNegQM1Qf=w5BU6MvgEf_ngoaOevkAd6kQ@mail.gmail.com>
Message-ID: <CAE-dL2quEhS4Xe0fMbrxJ0oZu5DH+MAyrB+Oyv2D0ebhdGFb+w@mail.gmail.com>

It might be easier to diagnose if you can show us what the first ten lines
in your original file look like.

readLines("gokind.nephropathy.fin", n=10)

David L Carlson


On Mon, Jun 1, 2020 at 6:36 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Agreed!
>
> However, there may still be a problem, as read.table() ordinarily would
> read numeric columns correctly (via type.convert()) without the colClasses
> specification.
> So I would suspect that her "numeric" columns contain some non-numeric
> detritus (perhaps "," or some NA symbol). But of course, who knows? -- and
> she should follow David's advice to read the docs anyway.
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Jun 1, 2020 at 3:19 PM David Winsemius <dwinsemius at comcast.net>
> wrote:
>
> >
> > On 6/1/20 2:17 PM, Ana Marija wrote:
> > > HI David,
> > >
> > > this is the problem:
> > >
> > > > NEP <- read.table("gokind.nephropathy.fin",
> > > header=T,stringsAsFactors=FALSE)
> > > > sapply(NEP,class)
> > >         Chr          BP      Marker         MAF          A1        A2
> > > "character" "character" "character" "character" "character" "character"
> > >   Direction      pValue           N
> > >
> > > So even entries like Chr, BP, MAF....are characters while they should
> > > be numeric
> > > > head(NEP)
> > >   Chr        BP           Marker      MAF A1 A2 Direction pValue    N
> > > 1  10 100000625 10:100000625:A:G   0.4156  G  A         + 0.484813 1641
> > > 2  10 100000645 10:100000645:A:C 0.216027  C  A         +  0.73597 1641
> > >
> > >
> > > Can you please tell me what colClasses=colClassvec suppose to do?
> >
> >
> > I could tell you, but I think instead that you should read the
> > documentation for the `read.table` function.
> >
> >
> > --
> >
> > David
> >
> > >
> > > Thanks
> > > Ana
> > >
> > > On Mon, Jun 1, 2020 at 4:13 PM David Winsemius <dwinsemius at comcast.net
> > > <mailto:dwinsemius at comcast.net>> wrote:
> > >
> > >
> > >     On 6/1/20 1:37 PM, Ana Marija wrote:
> > >     > Hello,
> > >     >
> > >     > I have a dataframe like this:
> > >     >
> > >     >    Chr        BP           Marker      MAF A1 A2 Direction
> > >      pValue    N
> > >     > 1  10 100000625 10:100000625:A:G 0.416562  G  A         -
> > >     0.558228 1594
> > >     > 2  10 100000645 10:100000645:A:C 0.215182  C  A         -
> > >     0.880622 1594
> > >     > ...
> > >     >
> > >     > which I load with:
> > >     > NEU <- read.table("gokind.neuropathy.fin",
> > >     header=T,stringsAsFactors=FALSE)
> > >     >
> > >     > and every column is numeric. How to say have all numeric ones
> > >     stay numeric
> > >     > like: Chr, BP, MAF, pValue, N
> > >
> > >
> > >     I cannot figure out what the problem is. You say every column is
> > >     numeric. It's not possible to have a column that contains the value
> > >     "10:100000625:A:G" be numeric.
> > >
> > >
> > >     If you meant to say the every column was character, then the answer
> > >     might be:
> > >
> > >
> > >     colClassvec <- rep("numeric",9)
> > >     colClassvec[ c(3,5:7)] <- "character"
> > >
> > >     NEU <- read.table("gokind.neuropathy.fin",
> > >     header=T,stringsAsFactors=FALSE, colClasses=colClassvec)
> > >
> > >     --
> > >     David.
> > >
> > >     >
> > >     > Thanks
> > >     > Ana
> > >     >
> > >     >       [[alternative HTML version deleted]]
> > >     >
> > >     > ______________________________________________
> > >     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> > >     -- To UNSUBSCRIBE and more, see
> > >     >
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!XmQVDL6oNnVVTyIGSfa2u7ps0SpI04MnrWnfq7eXZ0Zz-POPe5r-P4jj2eq-EE8$
> > >     > PLEASE do read the posting guide
> > >
> https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!XmQVDL6oNnVVTyIGSfa2u7ps0SpI04MnrWnfq7eXZ0Zz-POPe5r-P4jj5SGdDSU$
> > >     > and provide commented, minimal, self-contained, reproducible
> code.
> > >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!XmQVDL6oNnVVTyIGSfa2u7ps0SpI04MnrWnfq7eXZ0Zz-POPe5r-P4jj2eq-EE8$
> > PLEASE do read the posting guide
> >
> https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!XmQVDL6oNnVVTyIGSfa2u7ps0SpI04MnrWnfq7eXZ0Zz-POPe5r-P4jj5SGdDSU$
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> https://urldefense.com/v3/__https://stat.ethz.ch/mailman/listinfo/r-help__;!!KwNVnqRv!XmQVDL6oNnVVTyIGSfa2u7ps0SpI04MnrWnfq7eXZ0Zz-POPe5r-P4jj2eq-EE8$
> PLEASE do read the posting guide
> https://urldefense.com/v3/__http://www.R-project.org/posting-guide.html__;!!KwNVnqRv!XmQVDL6oNnVVTyIGSfa2u7ps0SpI04MnrWnfq7eXZ0Zz-POPe5r-P4jj5SGdDSU$
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Jun  2 05:37:39 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Mon, 1 Jun 2020 22:37:39 -0500
Subject: [R] 
 is there is a way to extract lines in between 3 files that are
 in common based on one column?
In-Reply-To: <CA+8X3fVegAWfMGjvV-0eZe4uMu9NMcDe2DZz10=CFz+BUuNm4Q@mail.gmail.com>
References: <CAF9-5jP7USAB5OvXm_Zx9Kyg3a2Wa0AEzL_HnD7aEzvEPgGk0w@mail.gmail.com>
 <CA+8X3fVS63pNpGJjpGyFniR8awZ9zu_TE85NzKauimp81_h5TQ@mail.gmail.com>
 <CAF9-5jPYgTavbN2pFDxqQ1MTrb0f-GwgU6+GDjXsN6adQG0=Qw@mail.gmail.com>
 <db327080-ffa4-f217-3087-41476ff30db5@comcast.net>
 <CAF9-5jOZiLFRV8cDr_nTn6gU_W2iucAreu_s76vm3yMrhhoWpQ@mail.gmail.com>
 <CAF9-5jPkbmNAY6a=zrLUkZwRwJz6Jt2xwQ+XXc5dABk03GnXJA@mail.gmail.com>
 <CA+8X3fVegAWfMGjvV-0eZe4uMu9NMcDe2DZz10=CFz+BUuNm4Q@mail.gmail.com>
Message-ID: <CAF9-5jPxb7eMrbQgkDh_fzFjxBoO-c4-m5Rz=nnLbD+0pcCbAA@mail.gmail.com>

Hi Jim,

not in this case, but thanks for asking!

Ana

On Mon, Jun 1, 2020 at 10:04 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> So recombination sticks out its foot before us. Do you want to account
> for gene linkage?
>
> JIm
>
> On Tue, Jun 2, 2020 at 11:55 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hi Jim
> >
> > > neu3<-neu1[!(neu1$Marker %in% Marker3),]
> > > dim(neu3)
> > [1] 1857    9
> > > nep3<-nep1[!(nep1$Marker %in% Marker3),]
> > > dim(nep3)
> > [1] 5562    9
> > > ret3<-ret1[!(ret1$Marker %in% Marker3),]
> > > dim(ret3)
> > [1] 3493    9
> >
> >
> > If I do:
> >
> >  nn1<-merge(neu1,nep1,by=c("Marker","Chr"))
> > nn2<-merge(nn1,ret1,by=c("Marker","Chr"))
> > > Marker3<-nn2$Marker
> > > length(Marker3)
> > [1] 3742962
> > > Marker4<-nn1$Marker
> > > length(Marker4)
> > [1] 3744443
> >
> > On Mon, Jun 1, 2020 at 8:50 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> > >
> > > Hi David,
> > >
> > > that is a great point!
> > > Yes indeed some are non unique:
> > >
> > > > dim(neu1)
> > > [1] 3742845       9
> > > > length(unique(neu1$Marker))
> > > [1] 3741858
> > > > length(unique(nep1$Marker))
> > > [1] 3745560
> > > > dim(nep1)
> > > [1] 3746550       9
> > > > length(unique(ret1$Marker))
> > > [1] 3743494
> > > > dim(ret1)
> > > [1] 3743494       9
> > >
> > > How would I rewrite this code so that is merging by Chr and Marker
> > > column? It seems that a Marker can be under a few Chr.
> > >
> > >
> > >
> > >
> > >
> > > On Mon, Jun 1, 2020 at 8:41 PM David Winsemius <dwinsemius at comcast.net> wrote:
> > > >
> > > >
> > > > On 6/1/20 5:40 PM, Ana Marija wrote:
> > > > > Hi Jim,
> > > > >
> > > > > thank you so much for getting back to me. I tried your code and this is
> > > > > what I get:
> > > > >> dim(neu2)
> > > > > [1] 3740988       9
> > > > >> dim(nep2)
> > > > > [1] 3740988       9
> > > > >> dim(ret2)
> > > > > [1] 3740001       9
> > > > >
> > > > > I think I would need to have the same number of lines in all 3 data frames.
> > > > >
> > > > > Can you please advise.
> > > >
> > > >
> > > > You should check for duplicated Marker values.
> > > >
> > > >
> > > > --
> > > >
> > > > David
> > > >
> > > > >
> > > > > Cheers
> > > > > Ana
> > > > >
> > > > > On Mon, Jun 1, 2020 at 7:31 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> > > > >
> > > > >> Hi Ana,
> > > > >> Not too hard, but your example has all the "marker" fields in common.
> > > > >> So using a sample that will show the expected result:
> > > > >>
> > > > >> neu1<-read.table(text="Chr BP Marker  MAF A1 A2 Direction  pValue N
> > > > >>   1 100000012 1:100000012:G:T 0.229925  T  G  + 0.650403 1594
> > > > >>   1 100000827 1:100000827:C:T 0.287014  T  C  + 0.955449 1594
> > > > >>   1 100002713 1:100002713:C:T 0.097867  T  C  - 0.290455 1594
> > > > >>   1 100002882 1:100002882:T:G 0.287014  G  T  + 0.955449 1594
> > > > >>   1 100002991 1:100002991:G:A 0.097867  A  G  - 0.290455 1594
> > > > >>   1 100004726 1:100004726:G:A 0.132058  A  G  + 0.115005 1594",
> > > > >>   header=TRUE,stringsAsFactors=FALSE)
> > > > >>
> > > > >> nep1<-read.table(text="Chr BP Marker MAF A1 A2 Direction    pValue N
> > > > >>   1 100000012 1:100000012:G:T 0.2300430 T  G - 0.1420030 1641
> > > > >>   1 100000827 1:100000827:C:T 0.2867150 T  C - 0.2045580 1641
> > > > >>   1 100002713 1:100002713:C:T 0.0975015 T  C - 0.0555507 1641
> > > > >>   1 100002882 1:100002882:T:G 0.2867150 G  T - 0.2045580 1641
> > > > >>   1 100002991 1:100002991:G:A 0.0975015 A  G - 0.0555507 1641
> > > > >>   1 100004726 1:100004727:G:A 0.1325410 A  G - 0.8725660 1641",
> > > > >>   header=TRUE,stringsAsFactors=FALSE)
> > > > >>
> > > > >> ret1<-read.table(text="Chr BP Marker MAF A1 A2 Direction   pValue N
> > > > >>   1 100000012 1:100000012:G:T 0.2322760 T  G - 0.230383 1608
> > > > >>   1 100000827 1:100000827:C:T 0.2882460 T  C - 0.120356 1608
> > > > >>   1 100002713 1:100002713:C:T 0.0982587 T  C - 0.272936 1608
> > > > >>   1 100002882 1:100002882:T:G 0.2882460 G  T - 0.120356 1608
> > > > >>   1 100002991 1:100002992:G:A 0.0982587 A  G - 0.272936 1608
> > > > >>   1 100004726 1:100004727:G:A 0.1340170 A  G - 0.594538 1608",
> > > > >> header=TRUE,stringsAsFactors=FALSE)
> > > > >>
> > > > >> # merge the three data frames on "Marker"
> > > > >> nn1<-merge(neu1,nep1,by="Marker")
> > > > >> nn2<-merge(nn1,ret1,by="Marker")
> > > > >> # get the common "Marker" strings
> > > > >> Marker3<-nn2$Marker
> > > > >> # subset all three data frames on Marker3
> > > > >> neu2<-neu1[neu1$Marker %in% Marker3,]
> > > > >> nep2<-nep1[nep1$Marker %in% Marker3,]
> > > > >> ret2<-ret1[ret1$Marker %in% Marker3,]
> > > > >>
> > > > >> Jim
> > > > >>
> > > > >> On Tue, Jun 2, 2020 at 7:50 AM Ana Marija <sokovic.anamarija at gmail.com>
> > > > >> wrote:
> > > > >>> Hello,
> > > > >>>
> > > > >>> I have 3 data frames which have about 3.4 mill lines (but they don't have
> > > > >>> exactly the same number of lines)...they look like this:
> > > > >>> ...
> > > > >>> Is there is a way to create another 3 data frames, say neu2, nep2, ret2
> > > > >>> which would only contain lines that have the same entries in Marker
> > > > >> column
> > > > >>> for all 3 data frames?
> > > > >>>
> > > > >>> Thanks
> > > > >>> Ana
> > > > >>>
> > > > >>>          [[alternative HTML version deleted]]
> > > > >>>
> > > > >>> ______________________________________________
> > > > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > > > >>> PLEASE do read the posting guide
> > > > >> http://www.R-project.org/posting-guide.html
> > > > >>> and provide commented, minimal, self-contained, reproducible code.
> > > > >       [[alternative HTML version deleted]]
> > > > >
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.


From |omn@v@@|@ @end|ng |rom gm@||@com  Tue Jun  2 02:18:49 2020
From: |omn@v@@|@ @end|ng |rom gm@||@com (Lom Navanyo)
Date: Mon, 1 Jun 2020 19:18:49 -0500
Subject: [R] How to efficiently generate data of points within specified
 radii for each geometric point
Message-ID: <CAKBoCbGbTT2WanrBpFfW6EUeWxQtxtOZGnkPCExq5cjqWZkecA@mail.gmail.com>

Hello,
I have data set of about 3400 location points with which I am trying to
generate data of each point and their neighbors within defined radii (eg,
0.25, 1, and 3 miles).

Below is a reprex using the built-in  nz_height  data:

library(sf)
library(dplyr)
library(spData)
library(ggplot2)
library(stringr)
library(rgdal)
library(lwgeom)
library(sp)


#Transform and project to required UTM

projdata<-st_transform(nz_height, 32759)  #32759 is for UTM Zone 59S


# plot(projdata$geometry)

# sequence of radii

bufferR <- c(402.336, 1609.34, 3218.69, 4828.03, 6437.38)

#Create data of neighboring wells per buffer

dataout <- do.call("rbind", lapply(1:length(bufferR), function(y) {
    bfr <- projdata %>% st_buffer(bufferR[y]) ## create Buffer
    ## minus the next smaller buffer
    if(y>1) {
      inters <- suppressWarnings(st_difference(bfr, projdata %>%
st_buffer(bufferR[y-1])))
      bfr <- inters[which(inters$t50_fid == inters$t50_fid.1),]
    }

    # get ids that intersect with buffer
    inters <- bfr %>% st_intersects(projdata)


    do.call("rbind", lapply(which(sapply(inters, length)>0),
         function(z) data.frame(t50_fid = projdata[z,]$t50_fid, radius =
bufferR[y],
                t50_fid_2 = projdata[unlist(inters[z]),]$t50_fid,
                elevation_mtchd = projdata[unlist(inters[z]),]$elevation)))
}))

This gives data frame as:

> head(dataout)
  t50_fid  radius t50_fid_2 elevation_mtchd
1 2353944 402.336   2353944            2723
2 2354404 402.336   2354404            2820
3 2354405 402.336   2354405            2830
4 2369113 402.336   2369113            3033
5 2362630 402.336   2362630            2749
6 2362814 402.336   2362814            2822

The end goal is that for each (original) point with  t50_fids,  I want its
neighboring points within the specified radius listed under  t50_fid_2 in a
long format. The caveat is that for the very first (ie. the smallest)
radius 402.336,  t50_fid_2 should return neighboring points within that
distance. But for subsequent radii,  t50_fid_2 should return neighboring
points within them but not within the smaller radius. Thus for example, for
radius 1609.34m, I should get as neighboring points, points within 1609.34m
but not within the smaller buffer/radius 402.336m.

The problem is that if I use my full data set of over 3000 rows (points), I
get the following error:

Error in CPL_geos_op2(op, st_geometry(x), st_geometry(y)) : Evaluation
error: std::bad_alloc.

I understand this is a memory issue as the code I am using creates buffers
around each point and this approach is memory intensive.

A suggestion was made that I could achieve my objective  using
st_is_within_distance  instead of  st_buffer  , st_difference  and
st_intersect without creating buffers.

How can I achieve my objective (that is, the table in dataout) efficiently
either with the suggested use of  st_is_within_distance,  or with my code
without running out of memory (RAM) or any other approach?

Thank you for considering my question.
-----------------------
Lom Navanyo Newton

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jun  2 08:38:31 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 01 Jun 2020 23:38:31 -0700
Subject: [R] How to efficiently generate data of points within specified
 radii for each geometric point
In-Reply-To: <CAKBoCbGbTT2WanrBpFfW6EUeWxQtxtOZGnkPCExq5cjqWZkecA@mail.gmail.com>
References: <CAKBoCbGbTT2WanrBpFfW6EUeWxQtxtOZGnkPCExq5cjqWZkecA@mail.gmail.com>
Message-ID: <C3D818DD-C0E7-4985-8008-981396F1B555@dcn.davis.ca.us>

Wrong list. Do _read_ the Posting Guide and then check out r-sig-geo.

On June 1, 2020 5:18:49 PM PDT, Lom Navanyo <lomnavasia at gmail.com> wrote:
>Hello,
>I have data set of about 3400 location points with which I am trying to
>generate data of each point and their neighbors within defined radii
>(eg,
>0.25, 1, and 3 miles).
>
>Below is a reprex using the built-in  nz_height  data:
>
>library(sf)
>library(dplyr)
>library(spData)
>library(ggplot2)
>library(stringr)
>library(rgdal)
>library(lwgeom)
>library(sp)
>
>
>#Transform and project to required UTM
>
>projdata<-st_transform(nz_height, 32759)  #32759 is for UTM Zone 59S
>
>
># plot(projdata$geometry)
>
># sequence of radii
>
>bufferR <- c(402.336, 1609.34, 3218.69, 4828.03, 6437.38)
>
>#Create data of neighboring wells per buffer
>
>dataout <- do.call("rbind", lapply(1:length(bufferR), function(y) {
>    bfr <- projdata %>% st_buffer(bufferR[y]) ## create Buffer
>    ## minus the next smaller buffer
>    if(y>1) {
>      inters <- suppressWarnings(st_difference(bfr, projdata %>%
>st_buffer(bufferR[y-1])))
>      bfr <- inters[which(inters$t50_fid == inters$t50_fid.1),]
>    }
>
>    # get ids that intersect with buffer
>    inters <- bfr %>% st_intersects(projdata)
>
>
>    do.call("rbind", lapply(which(sapply(inters, length)>0),
>        function(z) data.frame(t50_fid = projdata[z,]$t50_fid, radius =
>bufferR[y],
>                t50_fid_2 = projdata[unlist(inters[z]),]$t50_fid,
>            elevation_mtchd = projdata[unlist(inters[z]),]$elevation)))
>}))
>
>This gives data frame as:
>
>> head(dataout)
>  t50_fid  radius t50_fid_2 elevation_mtchd
>1 2353944 402.336   2353944            2723
>2 2354404 402.336   2354404            2820
>3 2354405 402.336   2354405            2830
>4 2369113 402.336   2369113            3033
>5 2362630 402.336   2362630            2749
>6 2362814 402.336   2362814            2822
>
>The end goal is that for each (original) point with  t50_fids,  I want
>its
>neighboring points within the specified radius listed under  t50_fid_2
>in a
>long format. The caveat is that for the very first (ie. the smallest)
>radius 402.336,  t50_fid_2 should return neighboring points within that
>distance. But for subsequent radii,  t50_fid_2 should return
>neighboring
>points within them but not within the smaller radius. Thus for example,
>for
>radius 1609.34m, I should get as neighboring points, points within
>1609.34m
>but not within the smaller buffer/radius 402.336m.
>
>The problem is that if I use my full data set of over 3000 rows
>(points), I
>get the following error:
>
>Error in CPL_geos_op2(op, st_geometry(x), st_geometry(y)) : Evaluation
>error: std::bad_alloc.
>
>I understand this is a memory issue as the code I am using creates
>buffers
>around each point and this approach is memory intensive.
>
>A suggestion was made that I could achieve my objective  using
>st_is_within_distance  instead of  st_buffer  , st_difference  and
>st_intersect without creating buffers.
>
>How can I achieve my objective (that is, the table in dataout)
>efficiently
>either with the suggested use of  st_is_within_distance,  or with my
>code
>without running out of memory (RAM) or any other approach?
>
>Thank you for considering my question.
>-----------------------
>Lom Navanyo Newton
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @purd|e@@ @end|ng |rom gm@||@com  Tue Jun  2 10:23:24 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 2 Jun 2020 20:23:24 +1200
Subject: [R] Query on contour plots
In-Reply-To: <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
Message-ID: <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>

I'm putting this back on the list.

> So how would I set up the code to do this with the data type I have?

> I will need to replicate the same task > 200 times with other data sets.
> What I need to do is plot *Fc *against *Sc* with the third dimension being the *density* of the data points.

Using Jim's bat_call data:

    library (bivariate)

    plot_ds <- function (dataset, main="", xlim, ylim, ..., k1=1, k2=1)
    {   names <- names (dataset)
        fh <- kbvpdf (dataset [,1], dataset [,2], k1 * bw.nrd (dataset
[,1]), k2 * bw.nrd (dataset [,2]) )
        plot (fh, main=main, xlab = names [1], ylab = names [2],
            xlim=xlim, ylim=ylim,
            ncontours=2)
    }

    plot_ds (bat_call, "plot 1", k1=1.25, k2=1.25)

Note that I've used stats::bw.nrd.
The k1 and k2 values, simply scale the default bandwidth.
(In this case, I've increased the smoothness).

If you want to do it 200+ times:
(1) Create another function, to iterate over each data set.
(2) If you want to save the plots, you will need to add in a call to
pdf/png/etc and close the device, in each iteration.
(3) It may be desirable to have constant xlim/ylim values, ideally
based on the ranges of the combined data:

    plot_ds (bat_call, "plot 1", xlim = c (25, 30), ylim = c (-15, 10),
        k1=1.25, k2=1.25)


From drj|m|emon @end|ng |rom gm@||@com  Tue Jun  2 12:20:10 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 2 Jun 2020 20:20:10 +1000
Subject: [R] Query on contour plots
In-Reply-To: <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>
Message-ID: <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>

Very nice. I forgot that you didn't have the complete data set.

png("as_bat_call.png")
plot_ds (bfs[,c("Fc","Sc")], "plot 1", xlim = c (25, 30), ylim = c (-15, 10),
        k1=1.25, k2=1.25)
dev.off()

Jim

On Tue, Jun 2, 2020 at 6:24 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> I'm putting this back on the list.
>
> > So how would I set up the code to do this with the data type I have?
>
> > I will need to replicate the same task > 200 times with other data sets.
> > What I need to do is plot *Fc *against *Sc* with the third dimension being the *density* of the data points.
>
> Using Jim's bat_call data:
>
>     library (bivariate)
>
>     plot_ds <- function (dataset, main="", xlim, ylim, ..., k1=1, k2=1)
>     {   names <- names (dataset)
>         fh <- kbvpdf (dataset [,1], dataset [,2], k1 * bw.nrd (dataset
> [,1]), k2 * bw.nrd (dataset [,2]) )
>         plot (fh, main=main, xlab = names [1], ylab = names [2],
>             xlim=xlim, ylim=ylim,
>             ncontours=2)
>     }
>
>     plot_ds (bat_call, "plot 1", k1=1.25, k2=1.25)
>
> Note that I've used stats::bw.nrd.
> The k1 and k2 values, simply scale the default bandwidth.
> (In this case, I've increased the smoothness).
>
> If you want to do it 200+ times:
> (1) Create another function, to iterate over each data set.
> (2) If you want to save the plots, you will need to add in a call to
> pdf/png/etc and close the device, in each iteration.
> (3) It may be desirable to have constant xlim/ylim values, ideally
> based on the ranges of the combined data:
>
>     plot_ds (bat_call, "plot 1", xlim = c (25, 30), ylim = c (-15, 10),
>         k1=1.25, k2=1.25)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: as_bat_call.png
Type: image/png
Size: 26580 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200602/17c1cb64/attachment.png>

From neotrop|c@|@b@t@ @end|ng |rom gm@||@com  Tue Jun  2 14:33:36 2020
From: neotrop|c@|@b@t@ @end|ng |rom gm@||@com (Neotropical bat risk assessments)
Date: Tue, 2 Jun 2020 08:33:36 -0400
Subject: [R] Query on contour plots
In-Reply-To: <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>
 <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
Message-ID: <daf569fd-abe0-e45e-79ca-22b89eae1421@gmail.com>

Hi all,

Many thanks for the efforts and suggestions.

This is getting closer to what is needed.? No legend showing the density 
values yet.
I was able to replicate a similar plot with the original data set.
However when I tried this with a different data set that has other Fc & 
Sc values? the plot does not work... just a blank PNG
Code from console below:

 ?>bfs<-Eptfur
 > dim(bfs)
[1] 5638?? 17
 > names(bfs)
 ?[1] "Filename" "st"?????? "Dur"????? "TBC"????? "Fmax" "Fmin"???? "Fmean"
 ?[8] "Tk"?????? "Fk"?????? "Qk"?????? "Tc"?????? "Fc" "Dc"?????? "S1"
[15] "Sc"?????? "Qual"???? "Pmc"
 > library(plotrix)
 > # set the matrix limits a bit beyond the data ranges
 > fcsc_mat<-makeDensityMatrix(bfs$Fc,bfs$Sc,nx=25,ny=25,
+ zfun="sum",xlim=c(24,29),ylim=c(-20,10))
Range of density (>0) - Inf -Inf
Warning messages:
*1: In min(x) : no non-missing arguments to min; returning Inf**
**2: In max(x) : no non-missing arguments to max; returning -Inf*
 > png("bat_call_plot.png")
 > par(mar=c(6,4,4,2))
 > color2D.matplot(fcsc_mat,
+ main="Freqency by slope of bat calls",
+ extremes=c("yellow","red"),xlab="Frequency (kHz)",
+ ylab="Characteristic slope (octaves/s)",
+ border=NA,axes=FALSE)
Warning messages:
1: In min(x) : no non-missing arguments to min; returning Inf
2: In max(x) : no non-missing arguments to max; returning -Inf
3: In min(x) : no non-missing arguments to min; returning Inf
4: In max(x) : no non-missing arguments to max; returning -Inf
 > axis(1,at=seq(5,95,10),round(seq(24.5,28.5,length.out=10),1))
 > axis(2,at=seq(5,95,10),round(seq(-20,10,length.out=10),1))
 > color.legend(0,-14,25,-10,legend=seq(0,10,length.out=5),
+ rect.col=color.scale(0:4,extremes=c("yellow","red")),align="rb")
 > text(12.5,-20,"Density (cell count)",xpd=TRUE)
 > dev.off()
null device
 ????????? 1

I will not need to add a function it iterate as I will not be running? 
this as an iterative task at one time... I just need the code to be able 
to use different data sets that have the same fields.
The Sc values over the 200+ data sets will range from potentially large 
negative numbers to positive numbers depending on the slope of the 
calls, i.e. increasing frequencies or decreasing frequencies.
An example of these two parameters for a single species with descriptive 
stats.
N is valid number of call pulses, then 10%-90% bins of where the call 
pulses fall into.

Parameters 	N 	Min 	Max 	Mean 	St.Dev 	10% 	25% 	75% 	90%
Fc 	32802 	43.01 	50.00 	46.86 	1.31 	45.07 	45.98 	47.76 	48.63
Sc 	32802 	-309.78 	13.76 	-6.60 	10.98 	-10.31 	-7.50 	-3.91 	-2.81


I am very appreciative and thank you both for guiding the efforts.

Bruce
> Very nice. I forgot that you didn't have the complete data set.
>
> png("as_bat_call.png")
> plot_ds (bfs[,c("Fc","Sc")], "plot 1", xlim = c (25, 30), ylim = c (-15, 10),
>          k1=1.25, k2=1.25)
> dev.off()
>
> Jim
>
> On Tue, Jun 2, 2020 at 6:24 PM Abby Spurdle <spurdle.a at gmail.com> wrote:
>> I'm putting this back on the list.
>>
>>> So how would I set up the code to do this with the data type I have?
>>> I will need to replicate the same task > 200 times with other data sets.
>>> What I need to do is plot *Fc *against *Sc* with the third dimension being the *density* of the data points.
>> Using Jim's bat_call data:
>>
>>      library (bivariate)
>>
>>      plot_ds <- function (dataset, main="", xlim, ylim, ..., k1=1, k2=1)
>>      {   names <- names (dataset)
>>          fh <- kbvpdf (dataset [,1], dataset [,2], k1 * bw.nrd (dataset
>> [,1]), k2 * bw.nrd (dataset [,2]) )
>>          plot (fh, main=main, xlab = names [1], ylab = names [2],
>>              xlim=xlim, ylim=ylim,
>>              ncontours=2)
>>      }
>>
>>      plot_ds (bat_call, "plot 1", k1=1.25, k2=1.25)
>>
>> Note that I've used stats::bw.nrd.
>> The k1 and k2 values, simply scale the default bandwidth.
>> (In this case, I've increased the smoothness).
>>
>> If you want to do it 200+ times:
>> (1) Create another function, to iterate over each data set.
>> (2) If you want to save the plots, you will need to add in a call to
>> pdf/png/etc and close the device, in each iteration.
>> (3) It may be desirable to have constant xlim/ylim values, ideally
>> based on the ranges of the combined data:
>>
>>      plot_ds (bat_call, "plot 1", xlim = c (25, 30), ylim = c (-15, 10),
>>          k1=1.25, k2=1.25)
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


-- 
Bruce W. Miller, PhD.
Neotropical bat risk assessments
Conservation Fellow - Wildlife Conservation Society

If we lose the bats, we may lose much of the tropical vegetation and the lungs of the planet

Using acoustic sampling to identify and map species distributions
and pioneering acoustic tools for ecology and conservation of bats for >25 years.

Key projects include providing free interactive identification keys and call fact sheets for the vocal signatures of New World Bats


	[[alternative HTML version deleted]]


From neotrop|c@|@b@t@ @end|ng |rom gm@||@com  Tue Jun  2 19:11:54 2020
From: neotrop|c@|@b@t@ @end|ng |rom gm@||@com (Neotropical bat risk assessments)
Date: Tue, 2 Jun 2020 13:11:54 -0400
Subject: [R] Query on contour plots
In-Reply-To: <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>
 <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
Message-ID: <c3594a31-9283-d61a-c699-1f8ae153705a@gmail.com>

Hi all,

I spent some time this morning fiddling with the parameters in the plot 
code provided by Jim and Abby and? by changing some important ones.

Jim did note
*# set the matrix limits a bit beyond the data ranges*
fcsc_mat<-makeDensityMatrix(bfs$Fc,bfs$Sc,nx=100,ny=100,
 ?zfun="sum",xlim=c(*30,45*),ylim=c(*-55,110*)) and

axis(1,at=seq(5,95,10),round(seq(*30.0,50.0*,length.out=10),1))

axis(2,at=seq(5,95,10),round(seq(*-55,110*,length.out=10),1))

So editing the lines above to match what the data includes the plots for 
various species are working!

I now need to figure out how to add a legend for the density values in 
the bivariate package plots.

I am assuming there can be a line or so of code that can extract the 
min-max values from the actual data files
that will update the xlim, ylim and axis data?? I think this should be a 
simple first step after reading in each new data set.

I can not thank Jim and Abby enough.? Super helpful

Cheers,
Bruce

-- 
Bruce W. Miller, PhD.
Neotropical bat risk assessments
Conservation Fellow - Wildlife Conservation Society

If we lose the bats, we may lose much of the tropical vegetation and the lungs of the planet

Using acoustic sampling to identify and map species distributions
and pioneering acoustic tools for ecology and conservation of bats for >25 years.

Key projects include providing free interactive identification keys and call fact sheets for the vocal signatures of New World Bats


	[[alternative HTML version deleted]]


From @purd|e@@ @end|ng |rom gm@||@com  Tue Jun  2 20:44:03 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Wed, 3 Jun 2020 06:44:03 +1200
Subject: [R] Query on contour plots
In-Reply-To: <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>
 <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
Message-ID: <CAB8pepzQB7uSxp4NhYdvSdSy4YFQCGfF_UvdVZ2yej3iNDd1mA@mail.gmail.com>

> Very nice

Jim, thank you.
However, the (deterministic, or near-deterministic) diagonal lines in
the plot, make me question the suitability of this approach.
In my plot, the contour lines could be removed, and brighter colors
could be used.

But perhaps, a better approach would be to model those lines...
And it's not clear from the plot, if all the observations fall on a
diagonal line...


P.S.
I'm not sure why there's a white line on the plot.
Most of my testing was with PDF output, I will need to do some more
testing with PNG output.


From neotrop|c@|@b@t@ @end|ng |rom gm@||@com  Tue Jun  2 22:22:06 2020
From: neotrop|c@|@b@t@ @end|ng |rom gm@||@com (Neotropical bat risk assessments)
Date: Tue, 2 Jun 2020 16:22:06 -0400
Subject: [R] Query on contour plots
In-Reply-To: <CAB8pepzQB7uSxp4NhYdvSdSy4YFQCGfF_UvdVZ2yej3iNDd1mA@mail.gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>
 <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
 <CAB8pepzQB7uSxp4NhYdvSdSy4YFQCGfF_UvdVZ2yej3iNDd1mA@mail.gmail.com>
Message-ID: <94596aeb-a02f-6d50-4051-1ae150db300f@gmail.com>

Hi Abby,

The contour lines are actually useful to see groupings.
However w/o a legend for density it is not possible to see what is 
presented.
>> Very nice
> Jim, thank you.
> However, the (deterministic, or near-deterministic) diagonal lines in
> the plot, make me question the suitability of this approach.
> In my plot, the contour lines could be removed, and brighter colors
> could be used.
>
> But perhaps, a better approach would be to model those lines...
> And it's not clear from the plot, if all the observations fall on a
> diagonal line...
>
>
> P.S.
> I'm not sure why there's a white line on the plot.
> Most of my testing was with PDF output, I will need to do some more
> testing with PNG output.


-- 
Bruce W. Miller, PhD.
Neotropical bat risk assessments
Conservation Fellow - Wildlife Conservation Society

If we lose the bats, we may lose much of the tropical vegetation and the lungs of the planet

Using acoustic sampling to identify and map species distributions
and pioneering acoustic tools for ecology and conservation of bats for >25 years.

Key projects include providing free interactive identification keys and call fact sheets for the vocal signatures of New World Bats


From drj|m|emon @end|ng |rom gm@||@com  Wed Jun  3 00:50:13 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 3 Jun 2020 08:50:13 +1000
Subject: [R] Query on contour plots
In-Reply-To: <94596aeb-a02f-6d50-4051-1ae150db300f@gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>
 <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
 <CAB8pepzQB7uSxp4NhYdvSdSy4YFQCGfF_UvdVZ2yej3iNDd1mA@mail.gmail.com>
 <94596aeb-a02f-6d50-4051-1ae150db300f@gmail.com>
Message-ID: <CA+8X3fWGtUiKJVYGe1tLn_SJMm2WxwHg7_MBdE36qVn=iX2fVg@mail.gmail.com>

Hi Bruce & Abby,
Here is a start on merging the two plots.
Abby - I had to cheat on the legend colors as I could not work out
from the help pages how to specify the range of colors. Also I don't
know the range of densities. Both should be easy to fix. While I
specified xlab and ylab, they don't seem to make it to the plotting
functions. More study needed.
Bruce - The following code gives general idea of how to automate
plotting from a single data set. let me know whether you want
automated adjustment of axes, etc.
Both - I suspect that the constraints forming the diagonal lines are
due to characteristics of the bat larynx.

bfs<-read.csv("Procen_sample.csv")
# split out what you want to identify the plot
species<-unlist(strsplit("Procen_sample.csv","_"))[1]
library(bivariate)
# define the plot sequence
plot_ds <- function (dataset, main="", xlim, ylim, ..., k1=1, k2=1)
    {   names <- names (dataset)
        fh <- kbvpdf (dataset [,1], dataset [,2], k1 * bw.nrd (dataset
[,1]), k2 * bw.nrd (dataset [,2]) )
        plot (fh, main=main, xlab = names [1], ylab = names [2],
            xlim=xlim, ylim=ylim,
            ncontours=2)
}
# open the device
png(paste0(species,".png"))
# leave space for the color legend
par(mar=c(6,4,4,2))
plot_ds (bfs[,c("Fc","Sc")],
 main=paste(species,"characteristic bat call"),
 xlab="Frequency (kHz)",ylab="Characteristic slope (octaves/s)",
 ,k1=1.25, k2=1.25)
library(plotrix)
xylim<-par("usr")
color.legend(xylim[1],xylim[3]-(xylim[4]-xylim[3])/7,
 xylim[1]+(xylim[2]-xylim[1])/4,xylim[3]-(xylim[4]-xylim[3])/10,
legend=seq(0,10,length.out=5),
rect.col=color.scale(0:4,extremes=c("#7be6bd","#bdb3df")),align="rb")
text(xylim[1]+(xylim[2]-xylim[1])/8,
 xylim[3]-(xylim[4]-xylim[3])/5,
 "Density",xpd=TRUE)
dev.off()

Jim

On Wed, Jun 3, 2020 at 6:22 AM Neotropical bat risk assessments
<neotropical.bats at gmail.com> wrote:
>
> Hi Abby,
>
> The contour lines are actually useful to see groupings.
> However w/o a legend for density it is not possible to see what is
> presented.
> >> Very nice
> > Jim, thank you.
> > However, the (deterministic, or near-deterministic) diagonal lines in
> > the plot, make me question the suitability of this approach.
> > In my plot, the contour lines could be removed, and brighter colors
> > could be used.
> >
> > But perhaps, a better approach would be to model those lines...
> > And it's not clear from the plot, if all the observations fall on a
> > diagonal line...
> >
> >
> > P.S.
> > I'm not sure why there's a white line on the plot.
> > Most of my testing was with PDF output, I will need to do some more
> > testing with PNG output.
>
>
> --
> Bruce W. Miller, PhD.
> Neotropical bat risk assessments
> Conservation Fellow - Wildlife Conservation Society
>
> If we lose the bats, we may lose much of the tropical vegetation and the lungs of the planet
>
> Using acoustic sampling to identify and map species distributions
> and pioneering acoustic tools for ecology and conservation of bats for >25 years.
>
> Key projects include providing free interactive identification keys and call fact sheets for the vocal signatures of New World Bats
>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Procen.png
Type: image/png
Size: 30320 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200603/112c94e3/attachment.png>

From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Jun  3 01:31:52 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 2 Jun 2020 16:31:52 -0700
Subject: [R] Query on contour plots
In-Reply-To: <CAB8pepzQB7uSxp4NhYdvSdSy4YFQCGfF_UvdVZ2yej3iNDd1mA@mail.gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>
 <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
 <CAB8pepzQB7uSxp4NhYdvSdSy4YFQCGfF_UvdVZ2yej3iNDd1mA@mail.gmail.com>
Message-ID: <a88e32f8-1886-8e38-4e68-bb040ebc5c98@comcast.net>


On 6/2/20 11:44 AM, Abby Spurdle wrote:
>> Very nice
> Jim, thank you.
> However, the (deterministic, or near-deterministic) diagonal lines in
> the plot, make me question the suitability of this approach.
> In my plot, the contour lines could be removed, and brighter colors
> could be used.
>
> But perhaps, a better approach would be to model those lines...
> And it's not clear from the plot, if all the observations fall on a
> diagonal line...
>
>
> P.S.
> I'm not sure why there's a white line on the plot.


I think if you search the archives of Rhelp you will find many such 
whinges and that extraneous white lines in PDFs are the fault of the PDF 
viewing program rather than of R.


-- 

David.

> Most of my testing was with PDF output, I will need to do some more
> testing with PNG output.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From neotrop|c@|@b@t@ @end|ng |rom gm@||@com  Wed Jun  3 01:52:21 2020
From: neotrop|c@|@b@t@ @end|ng |rom gm@||@com (Neotropical bat risk assessments)
Date: Tue, 2 Jun 2020 19:52:21 -0400
Subject: [R] Query on contour plots
In-Reply-To: <CA+8X3fWGtUiKJVYGe1tLn_SJMm2WxwHg7_MBdE36qVn=iX2fVg@mail.gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>
 <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
 <CAB8pepzQB7uSxp4NhYdvSdSy4YFQCGfF_UvdVZ2yej3iNDd1mA@mail.gmail.com>
 <94596aeb-a02f-6d50-4051-1ae150db300f@gmail.com>
 <CA+8X3fWGtUiKJVYGe1tLn_SJMm2WxwHg7_MBdE36qVn=iX2fVg@mail.gmail.com>
Message-ID: <c21371e7-84be-a8df-d18a-733eadf527e7@gmail.com>

Tnx Jim,

Yes if there is a way to first extract the ranges of each data files Fc 
range and Sc ranges and then link to the plot that would be stellar.
I will look at this code and see how it is working so far.

Thanks a million.
Bruce
> Hi Bruce & Abby,
> Here is a start on merging the two plots.
> Abby - I had to cheat on the legend colors as I could not work out
> from the help pages how to specify the range of colors. Also I don't
> know the range of densities. Both should be easy to fix. While I
> specified xlab and ylab, they don't seem to make it to the plotting
> functions. More study needed.
> Bruce - The following code gives general idea of how to automate
> plotting from a single data set. let me know whether you want
> automated adjustment of axes, etc.
> Both - I suspect that the constraints forming the diagonal lines are
> due to characteristics of the bat larynx.
>
> bfs<-read.csv("Procen_sample.csv")
> # split out what you want to identify the plot
> species<-unlist(strsplit("Procen_sample.csv","_"))[1]
> library(bivariate)
> # define the plot sequence
> plot_ds <- function (dataset, main="", xlim, ylim, ..., k1=1, k2=1)
>      {   names <- names (dataset)
>          fh <- kbvpdf (dataset [,1], dataset [,2], k1 * bw.nrd (dataset
> [,1]), k2 * bw.nrd (dataset [,2]) )
>          plot (fh, main=main, xlab = names [1], ylab = names [2],
>              xlim=xlim, ylim=ylim,
>              ncontours=2)
> }
> # open the device
> png(paste0(species,".png"))
> # leave space for the color legend
> par(mar=c(6,4,4,2))
> plot_ds (bfs[,c("Fc","Sc")],
>   main=paste(species,"characteristic bat call"),
>   xlab="Frequency (kHz)",ylab="Characteristic slope (octaves/s)",
>   ,k1=1.25, k2=1.25)
> library(plotrix)
> xylim<-par("usr")
> color.legend(xylim[1],xylim[3]-(xylim[4]-xylim[3])/7,
>   xylim[1]+(xylim[2]-xylim[1])/4,xylim[3]-(xylim[4]-xylim[3])/10,
> legend=seq(0,10,length.out=5),
> rect.col=color.scale(0:4,extremes=c("#7be6bd","#bdb3df")),align="rb")
> text(xylim[1]+(xylim[2]-xylim[1])/8,
>   xylim[3]-(xylim[4]-xylim[3])/5,
>   "Density",xpd=TRUE)
> dev.off()
>
> Jim
>
> On Wed, Jun 3, 2020 at 6:22 AM Neotropical bat risk assessments
> <neotropical.bats at gmail.com> wrote:
>> Hi Abby,
>>
>> The contour lines are actually useful to see groupings.
>> However w/o a legend for density it is not possible to see what is
>> presented.
>>>> Very nice
>>> Jim, thank you.
>>> However, the (deterministic, or near-deterministic) diagonal lines in
>>> the plot, make me question the suitability of this approach.
>>> In my plot, the contour lines could be removed, and brighter colors
>>> could be used.
>>>
>>> But perhaps, a better approach would be to model those lines...
>>> And it's not clear from the plot, if all the observations fall on a
>>> diagonal line...
>>>
>>>
>>> P.S.
>>> I'm not sure why there's a white line on the plot.
>>> Most of my testing was with PDF output, I will need to do some more
>>> testing with PNG output.
>>
>> --
>> Bruce W. Miller, PhD.
>> Neotropical bat risk assessments
>> Conservation Fellow - Wildlife Conservation Society
>>
>> If we lose the bats, we may lose much of the tropical vegetation and the lungs of the planet
>>
>> Using acoustic sampling to identify and map species distributions
>> and pioneering acoustic tools for ecology and conservation of bats for >25 years.
>>
>> Key projects include providing free interactive identification keys and call fact sheets for the vocal signatures of New World Bats
>>


-- 
Bruce W. Miller, PhD.
Neotropical bat risk assessments
Conservation Fellow - Wildlife Conservation Society

If we lose the bats, we may lose much of the tropical vegetation and the lungs of the planet

Using acoustic sampling to identify and map species distributions
and pioneering acoustic tools for ecology and conservation of bats for >25 years.

Key projects include providing free interactive identification keys and call fact sheets for the vocal signatures of New World Bats


From @purd|e@@ @end|ng |rom gm@||@com  Wed Jun  3 02:53:28 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Wed, 3 Jun 2020 12:53:28 +1200
Subject: [R] Query on contour plots
In-Reply-To: <a88e32f8-1886-8e38-4e68-bb040ebc5c98@comcast.net>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>
 <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
 <CAB8pepzQB7uSxp4NhYdvSdSy4YFQCGfF_UvdVZ2yej3iNDd1mA@mail.gmail.com>
 <a88e32f8-1886-8e38-4e68-bb040ebc5c98@comcast.net>
Message-ID: <CAB8pepxRnkkMT1sYqfbs9eM-RLxsVPtf-Z0wZzHK1RVXSUpNSg@mail.gmail.com>

>  that extraneous white lines in PDFs are the fault of the PDF
> viewing program rather than of R.

Except it's a PNG file.

I've tried to minimize artifacts viewing PDF files.
But assumed (falsely?) that PNGs and other raster formats, would be fine.


From @purd|e@@ @end|ng |rom gm@||@com  Wed Jun  3 02:58:01 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Wed, 3 Jun 2020 12:58:01 +1200
Subject: [R] Query on contour plots
In-Reply-To: <94596aeb-a02f-6d50-4051-1ae150db300f@gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>
 <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
 <CAB8pepzQB7uSxp4NhYdvSdSy4YFQCGfF_UvdVZ2yej3iNDd1mA@mail.gmail.com>
 <94596aeb-a02f-6d50-4051-1ae150db300f@gmail.com>
Message-ID: <CAB8pepykH1AJ4_9YPesp-7EcDOpuctaHN7+sqQF5e+W3JQdvug@mail.gmail.com>

> The contour lines are actually useful to see groupings.
> However w/o a legend for density it is not possible to see what is
> presented.

I need to re-iterate, that the diagonal lines, may be important.

Also, I'm not sure I see the point in adding density values.
Unless people have a good knowledge of probability theory and
calculus, I doubt that specific density values will be useful.
i.e. If I said the density was 0.0035, what does that tell you...?

If you really want to add a legend, it's possible.

But this creates at least two problems:
(1) In the base graphics system, the resulting plots can't be nested.
(2) It's difficult to interpret specific color-encoded values.

In my opinion, a better idea, is to label the contour lines.
In my packages, this is possible by using contour.labels=TRUE,
however, the defaults are ugly.
(Something else for my todo list).

Here's a slightly more complex example, with prettier contour labels:

    library (barsurf)
    library (KernSmooth)
    set.bs.theme ("heat")

    plot_ds <- function (dataset, main="", xlim, ylim, ...,
        ncontours=3, labcex=0.8, ndec=3,
        k1=1, k2=1, n=30)
    {   names <- names (dataset)
        x <- dataset [,1]
        y <- dataset [,2]
     bw.x <- k1 * bw.nrd (x)
        bw.y <- k2 * bw.nrd (y)
        if (missing (xlim) )
            xlim <- range (x) + c(-1, 1) * bw.x
        if (missing (ylim) )
            ylim <- range (y) + c(-1, 1) * bw.y

        ks <- bkde2D (dataset, c (bw.x, bw.y),
            c (n, n), list (xlim, ylim), FALSE)

        fb <- seq (min (ks$fhat), max (ks$fhat),
            length.out = ncontours + 2)
        fb <- fb [2:(ncontours + 1)]
        fb <- round (fb, ndec)

        plot_cfield (ks$x1, ks$x2, ks$fhat,
            contours=FALSE,
            main=main, xlab = names [1], ylab = names [2],
            xyrel="m")
        points (x, y, pch=16, col="#00000040")
        contour (ks$x1, ks$x2, ks$fhat, levels=fb, labcex=labcex, add=TRUE)
    }

    plot_ds (bat_call, "plot 2", c (25, 28), c (-15, 10), k1=1.25, k2=1.25)

If you still want a legend, have a look at:
graphics::filled.contour

And then modify the second half of my code, starting after ks <- ...


From neotrop|c@|@b@t@ @end|ng |rom gm@||@com  Wed Jun  3 03:14:27 2020
From: neotrop|c@|@b@t@ @end|ng |rom gm@||@com (Neotropical bat risk assessments)
Date: Tue, 2 Jun 2020 21:14:27 -0400
Subject: [R] did bot execute
In-Reply-To: <CAB8pepykH1AJ4_9YPesp-7EcDOpuctaHN7+sqQF5e+W3JQdvug@mail.gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>
 <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
 <CAB8pepzQB7uSxp4NhYdvSdSy4YFQCGfF_UvdVZ2yej3iNDd1mA@mail.gmail.com>
 <94596aeb-a02f-6d50-4051-1ae150db300f@gmail.com>
 <CAB8pepykH1AJ4_9YPesp-7EcDOpuctaHN7+sqQF5e+W3JQdvug@mail.gmail.com>
Message-ID: <044c21a6-f301-d033-cb4a-4fac2aaaa999@gmail.com>

Hi Abby,

Tried this new version but did not execute...
Clearly I am missing a step.

Bruce
 > library (barsurf)
 > library (KernSmooth)
 > set.bs.theme ("heat")
 >
 > plot_ds <- function (dataset, main="", xlim, ylim, ...,
+ ncontours=3, labcex=0.8, ndec=3,
+ k1=1, k2=1, n=30)
+ {?? names <- names (dataset)
+ x <- dataset [,1]
+ y <- dataset [,2]
+ bw.x <- k1 * bw.nrd (x)
+ bw.y <- k2 * bw.nrd (y)
+ if (missing (xlim) )
+ xlim <- range (x) + c(-1, 1) * bw.x
+ if (missing (ylim) )
+ ylim <- range (y) + c(-1, 1) * bw.y
+
+ ks <- bkde2D (dataset, c (bw.x, bw.y),
+ c (n, n), list (xlim, ylim), FALSE)
+
+ fb <- seq (min (ks$fhat), max (ks$fhat),
+ length.out = ncontours + 2)
+ fb <- fb [2:(ncontours + 1)]
+ fb <- round (fb, ndec)
+
+ plot_cfield (ks$x1, ks$x2, ks$fhat,
+ contours=FALSE,
+ main=main, xlab = names [1], ylab = names [2],
+ xyrel="m")
+ points (x, y, pch=16, col="#00000040")
+ contour (ks$x1, ks$x2, ks$fhat, levels=fb, labcex=labcex, add=TRUE)
+ }
 >
 > plot_ds (bat_call, "plot 2", c (25, 28), c (-15, 10), k1=1.25, k2=1.25)
*Error in plot_ds(bat_call, "plot 2", c(25, 28), c(-15, 10), k1 = 1.25,? 
: **
**? object 'bat_call' not found*

	[[alternative HTML version deleted]]


From phii m@iii@g oii phiiipsmith@c@  Wed Jun  3 03:46:21 2020
From: phii m@iii@g oii phiiipsmith@c@ (phii m@iii@g oii phiiipsmith@c@)
Date: Tue, 02 Jun 2020 21:46:21 -0400
Subject: [R] Chart will not display
Message-ID: <d9a0efca86caaf430f2753c4b830939d@philipsmith.ca>

I have made what must be a simple mistake, but I have not been able to 
find it.

I create a function to plot a chart for a single variable. I want to 
display separate charts for several variables, one after another, with 
"Press [enter] to continue" in between. The function works fine for a 
single variable, but when I try to display several variables 
consecutively, using a for statement, no charts are displayed. The for 
statement executes without apparent error, but no charts appear.

Here is a reprex.

library(tidyverse)
t <- c(1,2,3,4,5)
a <- c(1,4,5,8,7)
b <- c(2,2,5,3,1)
c <- c(3,6,2,8,3)
df <- data.frame(t=t,a=a,b=b,c=c)
df1 <- pivot_longer(df,cols=c(a,b,c),names_to="var",values_to="val")
chfn <- function(chnm) {
   ggplot(filter(df1,var==chnm),aes(x=t,y=val,group=1)) +
     geom_line() +
     labs(title=chnm)
}
chfn("b") # test of the function - it works
chnms <- c("a","b","c")
for (i in chnms) {
   chfn(i)
   readline(prompt="Press [enter] to continue")
}

Thanks for your help.

Philip


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jun  3 04:02:12 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 2 Jun 2020 19:02:12 -0700
Subject: [R] Chart will not display
In-Reply-To: <d9a0efca86caaf430f2753c4b830939d@philipsmith.ca>
References: <d9a0efca86caaf430f2753c4b830939d@philipsmith.ca>
Message-ID: <CAGxFJbTjFKWU+R=e+cSD4GYgOi+XeZ7evYu=Boo=Cn5f=-nZMQ@mail.gmail.com>

In a function you must explicitly print/plot the ggplot() object, I assume.
i.e. plot(ggplot(...)) etc.

I do not use ggplot, so if I'm wrong, sorry.  But try it.  Hopefully
someone else will get it right if it doesn't do it.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jun 2, 2020 at 6:46 PM <phil at philipsmith.ca> wrote:

> I have made what must be a simple mistake, but I have not been able to
> find it.
>
> I create a function to plot a chart for a single variable. I want to
> display separate charts for several variables, one after another, with
> "Press [enter] to continue" in between. The function works fine for a
> single variable, but when I try to display several variables
> consecutively, using a for statement, no charts are displayed. The for
> statement executes without apparent error, but no charts appear.
>
> Here is a reprex.
>
> library(tidyverse)
> t <- c(1,2,3,4,5)
> a <- c(1,4,5,8,7)
> b <- c(2,2,5,3,1)
> c <- c(3,6,2,8,3)
> df <- data.frame(t=t,a=a,b=b,c=c)
> df1 <- pivot_longer(df,cols=c(a,b,c),names_to="var",values_to="val")
> chfn <- function(chnm) {
>    ggplot(filter(df1,var==chnm),aes(x=t,y=val,group=1)) +
>      geom_line() +
>      labs(title=chnm)
> }
> chfn("b") # test of the function - it works
> chnms <- c("a","b","c")
> for (i in chnms) {
>    chfn(i)
>    readline(prompt="Press [enter] to continue")
> }
>
> Thanks for your help.
>
> Philip
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From phii m@iii@g oii phiiipsmith@c@  Wed Jun  3 04:21:18 2020
From: phii m@iii@g oii phiiipsmith@c@ (phii m@iii@g oii phiiipsmith@c@)
Date: Tue, 02 Jun 2020 22:21:18 -0400
Subject: [R] Chart will not display
In-Reply-To: <CAGxFJbTjFKWU+R=e+cSD4GYgOi+XeZ7evYu=Boo=Cn5f=-nZMQ@mail.gmail.com>
References: <d9a0efca86caaf430f2753c4b830939d@philipsmith.ca>
 <CAGxFJbTjFKWU+R=e+cSD4GYgOi+XeZ7evYu=Boo=Cn5f=-nZMQ@mail.gmail.com>
Message-ID: <468ff0d758729c9cc9e091fd6c3ff444@philipsmith.ca>

Thanks Bert. That did it.

Philip

On 2020-06-02 22:02, Bert Gunter wrote:
> In a function you must explicitly print/plot the ggplot() object, I
> assume. i.e. plot(ggplot(...)) etc.
> 
> I do not use ggplot, so if I'm wrong, sorry.  But try it.  Hopefully
> someone else will get it right if it doesn't do it.
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Tue, Jun 2, 2020 at 6:46 PM <phil at philipsmith.ca> wrote:
> 
>> I have made what must be a simple mistake, but I have not been able
>> to
>> find it.
>> 
>> I create a function to plot a chart for a single variable. I want to
>> 
>> display separate charts for several variables, one after another,
>> with
>> "Press [enter] to continue" in between. The function works fine for
>> a
>> single variable, but when I try to display several variables
>> consecutively, using a for statement, no charts are displayed. The
>> for
>> statement executes without apparent error, but no charts appear.
>> 
>> Here is a reprex.
>> 
>> library(tidyverse)
>> t <- c(1,2,3,4,5)
>> a <- c(1,4,5,8,7)
>> b <- c(2,2,5,3,1)
>> c <- c(3,6,2,8,3)
>> df <- data.frame(t=t,a=a,b=b,c=c)
>> df1 <- pivot_longer(df,cols=c(a,b,c),names_to="var",values_to="val")
>> chfn <- function(chnm) {
>> ggplot(filter(df1,var==chnm),aes(x=t,y=val,group=1)) +
>> geom_line() +
>> labs(title=chnm)
>> }
>> chfn("b") # test of the function - it works
>> chnms <- c("a","b","c")
>> for (i in chnms) {
>> chfn(i)
>> readline(prompt="Press [enter] to continue")
>> }
>> 
>> Thanks for your help.
>> 
>> Philip
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Wed Jun  3 04:26:25 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Wed, 3 Jun 2020 14:26:25 +1200
Subject: [R] did bot execute
In-Reply-To: <044c21a6-f301-d033-cb4a-4fac2aaaa999@gmail.com>
References: <mailman.359211.1.1590919201.63164.r-help@r-project.org>
 <25a8922f-ca91-3c58-da96-7ad9d28c76a6@gmail.com>
 <CAB8pepzd8B0iZ751MBbNVCDRiuNS5=J9VFryPjfap4fx0uZzRA@mail.gmail.com>
 <CA+8X3fVb28iLzLCUu+Wj+PtQ5XDeK7fieADPWaWdsxdj2RKnyQ@mail.gmail.com>
 <CAB8pepzQB7uSxp4NhYdvSdSy4YFQCGfF_UvdVZ2yej3iNDd1mA@mail.gmail.com>
 <94596aeb-a02f-6d50-4051-1ae150db300f@gmail.com>
 <CAB8pepykH1AJ4_9YPesp-7EcDOpuctaHN7+sqQF5e+W3JQdvug@mail.gmail.com>
 <044c21a6-f301-d033-cb4a-4fac2aaaa999@gmail.com>
Message-ID: <CAB8pepysZFJMJG_pv2gU8oLb0ubFwwWRP5m4cVbPhGVjC2zPrg@mail.gmail.com>

(excerpts only)
> Tried this new version but did not execute...
> Error in plot_ds(bat_call, "plot 2", c(25, 28), c(-15, 10), k1 = 1.25,  :
>   object 'bat_call' not found

I've used the bat_call object, from Jim's earlier post.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Wed Jun  3 04:57:20 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Wed, 3 Jun 2020 14:57:20 +1200
Subject: [R] [FORGED] Re:  Chart will not display
In-Reply-To: <468ff0d758729c9cc9e091fd6c3ff444@philipsmith.ca>
References: <d9a0efca86caaf430f2753c4b830939d@philipsmith.ca>
 <CAGxFJbTjFKWU+R=e+cSD4GYgOi+XeZ7evYu=Boo=Cn5f=-nZMQ@mail.gmail.com>
 <468ff0d758729c9cc9e091fd6c3ff444@philipsmith.ca>
Message-ID: <153bb184-4522-dc3c-9696-a44899102e37@auckland.ac.nz>


On 3/06/20 2:21 pm, phil at philipsmith.ca wrote:

> Thanks Bert. That did it.
> 
> Philip
> 
> On 2020-06-02 22:02, Bert Gunter wrote:
>> In a function you must explicitly print/plot the ggplot() object, I
>> assume. i.e. plot(ggplot(...)) etc.
>>
>> I do not use ggplot, so if I'm wrong, sorry.? But try it.? Hopefully
>> someone else will get it right if it doesn't do it.

<SNIP>

You might find fortunes::fortune(123) to relevant.  The comment was made 
in respect of the *lattice* package, but it would seem to apply equally 
to *ggplot2*.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Jun  3 16:55:48 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 3 Jun 2020 09:55:48 -0500
Subject: [R] how to filter variables which appear in any row but do not
 include
Message-ID: <CAF9-5jMZUeXKs-yjKP4pKvpw2nmwk9qnfHVSeaQpdGbRmiY7_g@mail.gmail.com>

Hello.

I am trying to filter only rows that have ANY of these variables:
E109, E119, E149

so I did:
controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))

than I checked what I got:
> s0 <- sapply(controls, function(x) grep('^E10', x, value = TRUE))
> d0=unlist(s0)
> d10=unique(d0)
> d10
 [1] "E10"  "E103" "E104" "E109" "E101" "E108" "E105" "E100" "E106" "E102"
[11] "E107"
s1 <- sapply(controls, function(x) grep('^E11', x, value = TRUE))
d1=unlist(s1)
d11=unique(d1)
> d11
 [1] "E11"  "E119" "E113" "E115" "E111" "E114" "E110" "E118" "E116" "E112"
[11] "E117"

I need help with changing this command
controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))

so that in the output I do not have any rows that include E102 or E112?

Thanks
Ana


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jun  3 17:45:36 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 03 Jun 2020 15:45:36 -0000
Subject: [R] iterators : checkFunc with ireadLines
In-Reply-To: <CAA99HCx_VvNJzTQ=mQ7zoRFX5ZJOA3mCgbDkMiCSPAH_6Zv=QA-7372@mail.gmail.com>
References: <72174dd3-a819-b5fd-5a6f-2a6b46342774-2015@free.fr>
 <CAA99HCwtOek_jaNsD6-=CtTRoL9OHYgDqfgdSAfbNBaEZ_w8JQ@mail.gmail.com>
 <a1ad0aec-7457-b516-1a3c-43e9e83d0ae1@free.fr>
 <CAA99HCx_VvNJzTQ=mQ7zoRFX5ZJOA3mCgbDkMiCSPAH_6Zv=QA-7372@mail.gmail.com>
Message-ID: <E2222FD6-1A53-4C9C-87BA-7AEFDB3C83BB-6702@dcn.davis.ca.us>


Laurent... Bill is suggesting building your own indexed database... but this has been done before, so re-inventing the wheel seems inefficient and risky. It is actually impossible to create such a beast without reading the entire file into memory at least temporarily anyway, so you are better off looking at ways to process the entire file efficiently.

For example, you could load the data into a sqlite database in a couple of lines of code and use SQL directly or use the sqldf data frame interface, or use dplyr to query the database.

Or you could look at read_csv_chunked from readr package.

On May 18, 2020 11:37:46 AM PDT, William Michels via R-help <r-help at r-project.org> wrote:
>
>Hi Laurent,
>
>Thank you for explaining your size limitations. Below is an example
>using the read.fwf() function to grab the first column of your input
>file (in 2000 row chunks). This column is converted to an index, and
>the index is used to create an iterator useful for skipping lines when
>reading input with scan(). (You could try processing your large file
>in successive 2000 line chunks, or whatever number of lines fits into
>memory). Maybe not as elegant as the approach you were going for, but
>read.fwf() should be pretty efficient:
>
>> sensors <-  c("N053", "N163")
>> read.fwf("test2.txt", widths=c(4), as.is=TRUE, flush=TRUE, n=2000,
>skip=0)
>    V1
>1 Time
>2 N023
>3 N053
>4 N123
>5 N163
>6 N193
>> first_col <- read.fwf("test2.txt", widths=c(4), as.is=TRUE,
>flush=TRUE, n=2000, skip=0)
>> which(first_col$V1 %in% sensors)
>[1] 3 5
>> index1 <- which(first_col$V1 %in% sensors)
>> iter_index1 <- iter(1:2000, checkFunc= function(n) {n %in% index1})
>> unlist(scan(file="test2.txt",
>what=list("","","","","","","","","",""), flush=TRUE, multi.line=FALSE,
>skip=nextElem(iter_index1)-1, nlines=1, quiet=TRUE))
> [1] "N053"      "-0.014083" "-0.004741" "0.001443"  "-0.010152"
>"-0.012996" "-0.005337" "-0.008738" "-0.015094" "-0.012104"
>> unlist(scan(file="test2.txt",
>what=list("","","","","","","","","",""), flush=TRUE, multi.line=FALSE,
>skip=nextElem(iter_index1)-1, nlines=1, quiet=TRUE))
> [1] "N163"      "-0.054023" "-0.049345" "-0.037158" "-0.04112"
>"-0.044612" "-0.036953" "-0.036061" "-0.044516" "-0.046436"
>>
>
>(Note for this email and the previous one, I've deleted the first
>"hash" character from each line of your test file for clarity).
>
>HTH, Bill.
>
>W. Michels, Ph.D.
>
>
>
>
>
>On Mon, May 18, 2020 at 3:35 AM Laurent Rhelp <LaurentRHelp at free.fr>
>wrote:
>>
>> Dear William,
>>   Thank you for your answer
>> My file is very large so I cannot read it in my memory (I cannot use
>> read.table). So I want to put in memory only the line I need to
>process.
>> With readLines, as I did, it works but I would like to use an
>iterator
>> and a foreach loop to understand this way to do because I thought
>that
>> it was a better solution to write a nice code.
>>
>>
>> Le 18/05/2020 ? 04:54, William Michels a ?crit :
>> > Apologies, Laurent, for this two-part answer. I misunderstood your
>> > post where you stated you wanted to "filter(ing) some
>> > selected lines according to the line name... ." I thought that
>meant
>> > you had a separate index (like a series of primes) that you wanted
>to
>> > use to only read-in selected line numbers from a file (test file
>below
>> > with numbers 1:1000 each on a separate line):
>> >
>> >> library(gmp)
>> >> library(iterators)
>> >> iprime <- iter(1:100, checkFunc = function(n) isprime(n))
>> >> scan(file="one_thou_lines.txt", skip=nextElem(iprime)-1, nlines=1)
>> > Read 1 item
>> > [1] 2
>> >> scan(file="one_thou_lines.txt", skip=nextElem(iprime)-1, nlines=1)
>> > Read 1 item
>> > [1] 3
>> >> scan(file="one_thou_lines.txt", skip=nextElem(iprime)-1, nlines=1)
>> > Read 1 item
>> > [1] 5
>> >> scan(file="one_thou_lines.txt", skip=nextElem(iprime)-1, nlines=1)
>> > Read 1 item
>> > [1] 7
>> > However, what it really seems that you want to do is read each line
>of
>> > a (possibly enormous) file, test each line "string-wise" to keep or
>> > discard, and if you're keeping it, append the line to a list. I can
>> > certainly see the advantage of this strategy for reading in very,
>very
>> > large files, but it's not clear to me how the "ireadLines" function
>(
>> > in the "iterators" package) will help you, since it doesn't seem to
>> > generate anything but a sequential index.
>> >
>> > Anyway, below is an absolutely standard read-in of your data using
>> > read.table(). Hopefully some of the code I've posted has been
>useful
>> > to you.
>> >
>> >> sensors <-  c("N053", "N163")
>> >> read.table("test2.txt")
>> >      V1        V2        V3        V4        V5        V6        V7
>> >     V8        V9       V10
>> > 1 Time  0.000000  0.000999  0.001999  0.002998  0.003998  0.004997
>> > 0.005997  0.006996  0.007996
>> > 2 N023 -0.031323 -0.035026 -0.029759 -0.024886 -0.024464 -0.026816
>> > -0.033690 -0.041067 -0.038747
>> > 3 N053 -0.014083 -0.004741  0.001443 -0.010152 -0.012996 -0.005337
>> > -0.008738 -0.015094 -0.012104
>> > 4 N123 -0.019008 -0.013494 -0.013180 -0.029208 -0.032748 -0.020243
>> > -0.015089 -0.014439 -0.011681
>> > 5 N163 -0.054023 -0.049345 -0.037158 -0.041120 -0.044612 -0.036953
>> > -0.036061 -0.044516 -0.046436
>> > 6 N193 -0.022171 -0.022384 -0.022338 -0.023304 -0.022569 -0.021827
>> > -0.021996 -0.021755 -0.021846
>> >> Laurent_data <- read.table("test2.txt")
>> >> Laurent_data[Laurent_data$V1 %in% sensors, ]
>> >      V1        V2        V3        V4        V5        V6        V7
>> >     V8        V9       V10
>> > 3 N053 -0.014083 -0.004741  0.001443 -0.010152 -0.012996 -0.005337
>> > -0.008738 -0.015094 -0.012104
>> > 5 N163 -0.054023 -0.049345 -0.037158 -0.041120 -0.044612 -0.036953
>> > -0.036061 -0.044516 -0.046436
>> >
>> > Best, Bill.
>> >
>> > W. Michels, Ph.D.
>> >
>> >
>> > On Sun, May 17, 2020 at 5:43 PM Laurent Rhelp
><LaurentRHelp at free.fr> wrote:
>> >> Dear R-Help List,
>> >>
>> >>      I would like to use an iterator to read a file filtering some
>> >> selected lines according to the line name in order to use after a
>> >> foreach loop. I wanted to use the checkFunc argument as the
>following
>> >> example found on internet to select only prime numbers :
>> >>
>> >> |                                iprime <- ||iter||(1:100,
>checkFunc =
>> >> ||function||(n) ||isprime||(n))|
>> >>
>> >> |(https://datawookie.netlify.app/blog/2013/11/iterators-in-r/)
>> >> <https://datawookie.netlify.app/blog/2013/11/iterators-in-r/>|
>> >>
>> >> but the checkFunc argument seems not to be available with the
>function
>> >> ireadLines (package iterators). So, I did the code below to solve
>my
>> >> problem but I am sure that I miss something to use iterators with
>files.
>> >> Since I found nothing on the web about ireadLines and the
>checkFunc
>> >> argument, could somebody help me to understand how we have to use
>> >> iterator (and foreach loop) on files keeping only selected lines ?
>> >>
>> >> Thank you very much
>> >> Laurent
>> >>
>> >> Presently here is my code:
>> >>
>> >> ##        mock file to read: test.txt
>> >> ##
>> >> # Time    0    0.000999    0.001999    0.002998    0.003998
>0.004997
>> >> 0.005997    0.006996    0.007996
>> >> # N023    -0.031323    -0.035026    -0.029759    -0.024886
>-0.024464
>> >> -0.026816    -0.03369    -0.041067    -0.038747
>> >> # N053    -0.014083    -0.004741    0.001443    -0.010152
>-0.012996
>> >> -0.005337    -0.008738    -0.015094    -0.012104
>> >> # N123    -0.019008    -0.013494    -0.01318    -0.029208
>-0.032748
>> >> -0.020243    -0.015089    -0.014439    -0.011681
>> >> # N163    -0.054023    -0.049345    -0.037158    -0.04112
>-0.044612
>> >> -0.036953    -0.036061    -0.044516    -0.046436
>> >> # N193    -0.022171    -0.022384    -0.022338    -0.023304
>-0.022569
>> >> -0.021827    -0.021996    -0.021755    -0.021846
>> >>
>> >>
>> >> # sensors to keep
>> >>
>> >> sensors <-  c("N053", "N163")
>> >>
>> >>
>> >> library(iterators)
>> >>
>> >> library(rlist)
>> >>
>> >>
>> >> file_name <- "test.txt"
>> >>
>> >> con_obj <- file( file_name , "r")
>> >> ifile <- ireadLines( con_obj , n = 1 )
>> >>
>> >>
>> >> ## I do not do a loop for the example
>> >>
>> >> res <- list()
>> >>
>> >> r <- get_Lines_iter( ifile , sensors)
>> >> res <- list.append( res , r )
>> >> res
>> >> r <- get_Lines_iter( ifile , sensors)
>> >> res <- list.append( res , r )
>> >> res
>> >> r <- get_Lines_iter( ifile , sensors)
>> >> do.call("cbind",res)
>> >>
>> >> ## the function get_Lines_iter to select and process the line
>> >>
>> >> get_Lines_iter  <-  function( iter , sensors, sep = '\t', quiet =
>FALSE){
>> >>     ## read the next record in the iterator
>> >>     r = try( nextElem(iter) )
>> >>    while(  TRUE ){
>> >>       if( class(r) == "try-error") {
>> >>             return( stop("The iterator is empty") )
>> >>      } else {
>> >>      ## split the read line according to the separator
>> >>       r_txt <- textConnection(r)
>> >>       fields <- scan(file = r_txt, what = "character", sep = sep,
>quiet =
>> >> quiet)
>> >>        ## test if we have to keep the line
>> >>        if( fields[1] %in% sensors){
>> >>          ## data processing for the selected line (for the example
>> >> transformation in dataframe)
>> >>          n <- length(fields)
>> >>          x <- data.frame( as.numeric(fields[2:n]) )
>> >>          names(x) <- fields[1]
>> >>          ## We return the values
>> >>          print(paste0("sensor ",fields[1]," ok"))
>> >>          return( x )
>> >>        }else{
>> >>         print(paste0("Sensor ", fields[1] ," not selected"))
>> >>         r = try(nextElem(iter) )}
>> >>      }
>> >> }# end while loop
>> >> }
>> >>
>> >>
>> >>
>> >>
>> >>
>> >>
>> >>
>> >> --
>> >> L'absence de virus dans ce courrier ?lectronique a ?t? v?rifi?e
>par le logiciel antivirus Avast.
>> >> https://www.avast.com/antivirus
>> >>
>> >>          [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> L'absence de virus dans ce courrier ?lectronique a ?t? v?rifi?e par
>le logiciel antivirus Avast.
>> https://www.avast.com/antivirus
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From L@urentRHe|p @end|ng |rom |ree@|r  Wed Jun  3 17:46:00 2020
From: L@urentRHe|p @end|ng |rom |ree@|r (Laurent Rhelp)
Date: Wed, 03 Jun 2020 15:46:00 -0000
Subject: [R] iterators : checkFunc with ireadLines
In-Reply-To: <E2222FD6-1A53-4C9C-87BA-7AEFDB3C83BB@dcn.davis.ca.us>
References: <72174dd3-a819-b5fd-5a6f-2a6b46342774-2015@free.fr>
 <CAA99HCwtOek_jaNsD6-=CtTRoL9OHYgDqfgdSAfbNBaEZ_w8JQ@mail.gmail.com>
 <a1ad0aec-7457-b516-1a3c-43e9e83d0ae1@free.fr>
 <CAA99HCx_VvNJzTQ=mQ7zoRFX5ZJOA3mCgbDkMiCSPAH_6Zv=QA-7372@mail.gmail.com>
 <E2222FD6-1A53-4C9C-87BA-7AEFDB3C83BB@dcn.davis.ca.us>
Message-ID: <f0a8e687-c79e-c748-564a-f93cc3fdee23-3078@free.fr>


Ok, thank you for the advice I will take some time to see in details 
these packages.


Le 19/05/2020 ? 05:44, Jeff Newmiller a ?crit?:
> Laurent... Bill is suggesting building your own indexed database... but this has been done before, so re-inventing the wheel seems inefficient and risky. It is actually impossible to create such a beast without reading the entire file into memory at least temporarily anyway, so you are better off looking at ways to process the entire file efficiently.
>
> For example, you could load the data into a sqlite database in a couple of lines of code and use SQL directly or use the sqldf data frame interface, or use dplyr to query the database.
>
> Or you could look at read_csv_chunked from readr package.
>
> On May 18, 2020 11:37:46 AM PDT, William Michels via R-help <r-help at r-project.org> wrote:
>> Hi Laurent,
>>
>> Thank you for explaining your size limitations. Below is an example
>> using the read.fwf() function to grab the first column of your input
>> file (in 2000 row chunks). This column is converted to an index, and
>> the index is used to create an iterator useful for skipping lines when
>> reading input with scan(). (You could try processing your large file
>> in successive 2000 line chunks, or whatever number of lines fits into
>> memory). Maybe not as elegant as the approach you were going for, but
>> read.fwf() should be pretty efficient:
>>
>>> sensors <-  c("N053", "N163")
>>> read.fwf("test2.txt", widths=c(4), as.is=TRUE, flush=TRUE, n=2000,
>> skip=0)
>>     V1
>> 1 Time
>> 2 N023
>> 3 N053
>> 4 N123
>> 5 N163
>> 6 N193
>>> first_col <- read.fwf("test2.txt", widths=c(4), as.is=TRUE,
>> flush=TRUE, n=2000, skip=0)
>>> which(first_col$V1 %in% sensors)
>> [1] 3 5
>>> index1 <- which(first_col$V1 %in% sensors)
>>> iter_index1 <- iter(1:2000, checkFunc= function(n) {n %in% index1})
>>> unlist(scan(file="test2.txt",
>> what=list("","","","","","","","","",""), flush=TRUE, multi.line=FALSE,
>> skip=nextElem(iter_index1)-1, nlines=1, quiet=TRUE))
>> [1] "N053"      "-0.014083" "-0.004741" "0.001443"  "-0.010152"
>> "-0.012996" "-0.005337" "-0.008738" "-0.015094" "-0.012104"
>>> unlist(scan(file="test2.txt",
>> what=list("","","","","","","","","",""), flush=TRUE, multi.line=FALSE,
>> skip=nextElem(iter_index1)-1, nlines=1, quiet=TRUE))
>> [1] "N163"      "-0.054023" "-0.049345" "-0.037158" "-0.04112"
>> "-0.044612" "-0.036953" "-0.036061" "-0.044516" "-0.046436"
>> (Note for this email and the previous one, I've deleted the first
>> "hash" character from each line of your test file for clarity).
>>
>> HTH, Bill.
>>
>> W. Michels, Ph.D.
>>
>>
>>
>>
>>
>> On Mon, May 18, 2020 at 3:35 AM Laurent Rhelp <LaurentRHelp at free.fr>
>> wrote:
>>> Dear William,
>>>    Thank you for your answer
>>> My file is very large so I cannot read it in my memory (I cannot use
>>> read.table). So I want to put in memory only the line I need to
>> process.
>>> With readLines, as I did, it works but I would like to use an
>> iterator
>>> and a foreach loop to understand this way to do because I thought
>> that
>>> it was a better solution to write a nice code.
>>>
>>>
>>> Le 18/05/2020 ? 04:54, William Michels a ?crit :
>>>> Apologies, Laurent, for this two-part answer. I misunderstood your
>>>> post where you stated you wanted to "filter(ing) some
>>>> selected lines according to the line name... ." I thought that
>> meant
>>>> you had a separate index (like a series of primes) that you wanted
>> to
>>>> use to only read-in selected line numbers from a file (test file
>> below
>>>> with numbers 1:1000 each on a separate line):
>>>>
>>>>> library(gmp)
>>>>> library(iterators)
>>>>> iprime <- iter(1:100, checkFunc = function(n) isprime(n))
>>>>> scan(file="one_thou_lines.txt", skip=nextElem(iprime)-1, nlines=1)
>>>> Read 1 item
>>>> [1] 2
>>>>> scan(file="one_thou_lines.txt", skip=nextElem(iprime)-1, nlines=1)
>>>> Read 1 item
>>>> [1] 3
>>>>> scan(file="one_thou_lines.txt", skip=nextElem(iprime)-1, nlines=1)
>>>> Read 1 item
>>>> [1] 5
>>>>> scan(file="one_thou_lines.txt", skip=nextElem(iprime)-1, nlines=1)
>>>> Read 1 item
>>>> [1] 7
>>>> However, what it really seems that you want to do is read each line
>> of
>>>> a (possibly enormous) file, test each line "string-wise" to keep or
>>>> discard, and if you're keeping it, append the line to a list. I can
>>>> certainly see the advantage of this strategy for reading in very,
>> very
>>>> large files, but it's not clear to me how the "ireadLines" function
>> (
>>>> in the "iterators" package) will help you, since it doesn't seem to
>>>> generate anything but a sequential index.
>>>>
>>>> Anyway, below is an absolutely standard read-in of your data using
>>>> read.table(). Hopefully some of the code I've posted has been
>> useful
>>>> to you.
>>>>
>>>>> sensors <-  c("N053", "N163")
>>>>> read.table("test2.txt")
>>>>       V1        V2        V3        V4        V5        V6        V7
>>>>      V8        V9       V10
>>>> 1 Time  0.000000  0.000999  0.001999  0.002998  0.003998  0.004997
>>>> 0.005997  0.006996  0.007996
>>>> 2 N023 -0.031323 -0.035026 -0.029759 -0.024886 -0.024464 -0.026816
>>>> -0.033690 -0.041067 -0.038747
>>>> 3 N053 -0.014083 -0.004741  0.001443 -0.010152 -0.012996 -0.005337
>>>> -0.008738 -0.015094 -0.012104
>>>> 4 N123 -0.019008 -0.013494 -0.013180 -0.029208 -0.032748 -0.020243
>>>> -0.015089 -0.014439 -0.011681
>>>> 5 N163 -0.054023 -0.049345 -0.037158 -0.041120 -0.044612 -0.036953
>>>> -0.036061 -0.044516 -0.046436
>>>> 6 N193 -0.022171 -0.022384 -0.022338 -0.023304 -0.022569 -0.021827
>>>> -0.021996 -0.021755 -0.021846
>>>>> Laurent_data <- read.table("test2.txt")
>>>>> Laurent_data[Laurent_data$V1 %in% sensors, ]
>>>>       V1        V2        V3        V4        V5        V6        V7
>>>>      V8        V9       V10
>>>> 3 N053 -0.014083 -0.004741  0.001443 -0.010152 -0.012996 -0.005337
>>>> -0.008738 -0.015094 -0.012104
>>>> 5 N163 -0.054023 -0.049345 -0.037158 -0.041120 -0.044612 -0.036953
>>>> -0.036061 -0.044516 -0.046436
>>>>
>>>> Best, Bill.
>>>>
>>>> W. Michels, Ph.D.
>>>>
>>>>
>>>> On Sun, May 17, 2020 at 5:43 PM Laurent Rhelp
>> <LaurentRHelp at free.fr> wrote:
>>>>> Dear R-Help List,
>>>>>
>>>>>       I would like to use an iterator to read a file filtering some
>>>>> selected lines according to the line name in order to use after a
>>>>> foreach loop. I wanted to use the checkFunc argument as the
>> following
>>>>> example found on internet to select only prime numbers :
>>>>>
>>>>> |                                iprime <- ||iter||(1:100,
>> checkFunc =
>>>>> ||function||(n) ||isprime||(n))|
>>>>>
>>>>> |(https://datawookie.netlify.app/blog/2013/11/iterators-in-r/)
>>>>> <https://datawookie.netlify.app/blog/2013/11/iterators-in-r/>|
>>>>>
>>>>> but the checkFunc argument seems not to be available with the
>> function
>>>>> ireadLines (package iterators). So, I did the code below to solve
>> my
>>>>> problem but I am sure that I miss something to use iterators with
>> files.
>>>>> Since I found nothing on the web about ireadLines and the
>> checkFunc
>>>>> argument, could somebody help me to understand how we have to use
>>>>> iterator (and foreach loop) on files keeping only selected lines ?
>>>>>
>>>>> Thank you very much
>>>>> Laurent
>>>>>
>>>>> Presently here is my code:
>>>>>
>>>>> ##        mock file to read: test.txt
>>>>> ##
>>>>> # Time    0    0.000999    0.001999    0.002998    0.003998
>> 0.004997
>>>>> 0.005997    0.006996    0.007996
>>>>> # N023    -0.031323    -0.035026    -0.029759    -0.024886
>> -0.024464
>>>>> -0.026816    -0.03369    -0.041067    -0.038747
>>>>> # N053    -0.014083    -0.004741    0.001443    -0.010152
>> -0.012996
>>>>> -0.005337    -0.008738    -0.015094    -0.012104
>>>>> # N123    -0.019008    -0.013494    -0.01318    -0.029208
>> -0.032748
>>>>> -0.020243    -0.015089    -0.014439    -0.011681
>>>>> # N163    -0.054023    -0.049345    -0.037158    -0.04112
>> -0.044612
>>>>> -0.036953    -0.036061    -0.044516    -0.046436
>>>>> # N193    -0.022171    -0.022384    -0.022338    -0.023304
>> -0.022569
>>>>> -0.021827    -0.021996    -0.021755    -0.021846
>>>>>
>>>>>
>>>>> # sensors to keep
>>>>>
>>>>> sensors <-  c("N053", "N163")
>>>>>
>>>>>
>>>>> library(iterators)
>>>>>
>>>>> library(rlist)
>>>>>
>>>>>
>>>>> file_name <- "test.txt"
>>>>>
>>>>> con_obj <- file( file_name , "r")
>>>>> ifile <- ireadLines( con_obj , n = 1 )
>>>>>
>>>>>
>>>>> ## I do not do a loop for the example
>>>>>
>>>>> res <- list()
>>>>>
>>>>> r <- get_Lines_iter( ifile , sensors)
>>>>> res <- list.append( res , r )
>>>>> res
>>>>> r <- get_Lines_iter( ifile , sensors)
>>>>> res <- list.append( res , r )
>>>>> res
>>>>> r <- get_Lines_iter( ifile , sensors)
>>>>> do.call("cbind",res)
>>>>>
>>>>> ## the function get_Lines_iter to select and process the line
>>>>>
>>>>> get_Lines_iter  <-  function( iter , sensors, sep = '\t', quiet =
>> FALSE){
>>>>>      ## read the next record in the iterator
>>>>>      r = try( nextElem(iter) )
>>>>>     while(  TRUE ){
>>>>>        if( class(r) == "try-error") {
>>>>>              return( stop("The iterator is empty") )
>>>>>       } else {
>>>>>       ## split the read line according to the separator
>>>>>        r_txt <- textConnection(r)
>>>>>        fields <- scan(file = r_txt, what = "character", sep = sep,
>> quiet =
>>>>> quiet)
>>>>>         ## test if we have to keep the line
>>>>>         if( fields[1] %in% sensors){
>>>>>           ## data processing for the selected line (for the example
>>>>> transformation in dataframe)
>>>>>           n <- length(fields)
>>>>>           x <- data.frame( as.numeric(fields[2:n]) )
>>>>>           names(x) <- fields[1]
>>>>>           ## We return the values
>>>>>           print(paste0("sensor ",fields[1]," ok"))
>>>>>           return( x )
>>>>>         }else{
>>>>>          print(paste0("Sensor ", fields[1] ," not selected"))
>>>>>          r = try(nextElem(iter) )}
>>>>>       }
>>>>> }# end while loop
>>>>> }
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> L'absence de virus dans ce courrier ?lectronique a ?t? v?rifi?e
>> par le logiciel antivirus Avast.
>>>>> https://www.avast.com/antivirus
>>>>>
>>>>>           [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>> --
>>> L'absence de virus dans ce courrier ?lectronique a ?t? v?rifi?e par
>> le logiciel antivirus Avast.
>>> https://www.avast.com/antivirus
>>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
L'absence de virus dans ce courrier ?lectronique a ?t? v?rifi?e par le logiciel antivirus Avast.
https://www.avast.com/antivirus


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jun  3 18:00:39 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 3 Jun 2020 09:00:39 -0700
Subject: [R] how to filter variables which appear in any row but do not
 include
In-Reply-To: <CAF9-5jMZUeXKs-yjKP4pKvpw2nmwk9qnfHVSeaQpdGbRmiY7_g@mail.gmail.com>
References: <CAF9-5jMZUeXKs-yjKP4pKvpw2nmwk9qnfHVSeaQpdGbRmiY7_g@mail.gmail.com>
Message-ID: <CAGxFJbRMBP1xC-uEqeV6bpHVCa+dRrmBmJr4PZZt8MH-44AGMA@mail.gmail.com>

I suggest that you forget all that fancy stuff  (and this is not a use case
for regular expressions).
Use %in%  with logical subscripting instead -- basic R functionality that
can be found in any good R tutorial.

> x <- c("ab","bc","cd")
> x[x %in% c("ab","cd")]
[1] "ab" "cd"
> x[!x %in% c("ab","cd")]
[1] "bc"


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jun 3, 2020 at 7:56 AM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Hello.
>
> I am trying to filter only rows that have ANY of these variables:
> E109, E119, E149
>
> so I did:
> controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
>
> than I checked what I got:
> > s0 <- sapply(controls, function(x) grep('^E10', x, value = TRUE))
> > d0=unlist(s0)
> > d10=unique(d0)
> > d10
>  [1] "E10"  "E103" "E104" "E109" "E101" "E108" "E105" "E100" "E106" "E102"
> [11] "E107"
> s1 <- sapply(controls, function(x) grep('^E11', x, value = TRUE))
> d1=unlist(s1)
> d11=unique(d1)
> > d11
>  [1] "E11"  "E119" "E113" "E115" "E111" "E114" "E110" "E118" "E116" "E112"
> [11] "E117"
>
> I need help with changing this command
> controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
>
> so that in the output I do not have any rows that include E102 or E112?
>
> Thanks
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Jun  3 18:28:55 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 3 Jun 2020 11:28:55 -0500
Subject: [R] how to filter variables which appear in any row but do not
 include
In-Reply-To: <CAGxFJbRMBP1xC-uEqeV6bpHVCa+dRrmBmJr4PZZt8MH-44AGMA@mail.gmail.com>
References: <CAF9-5jMZUeXKs-yjKP4pKvpw2nmwk9qnfHVSeaQpdGbRmiY7_g@mail.gmail.com>
 <CAGxFJbRMBP1xC-uEqeV6bpHVCa+dRrmBmJr4PZZt8MH-44AGMA@mail.gmail.com>
Message-ID: <CAF9-5jM_F65ZHtzejqK4U1F4KC3PVD6Mj7YgxOrtHQ44aR+chA@mail.gmail.com>

Hi Bert

The issue is that I have around 2000 columns so I can not be checking if
those two are not present in each column of any row ?by hand? so to
speak....And I need my output to be a data frame where neither E102 nor
E112 are present. Basically from the data frame columns that I already
created just remove any row that contains any of those variables.

Thanks
Ana

On Wed, 3 Jun 2020 at 11:00, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> I suggest that you forget all that fancy stuff  (and this is not a use
> case for regular expressions).
> Use %in%  with logical subscripting instead -- basic R functionality that
> can be found in any good R tutorial.
>
> > x <- c("ab","bc","cd")
> > x[x %in% c("ab","cd")]
> [1] "ab" "cd"
> > x[!x %in% c("ab","cd")]
> [1] "bc"
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Jun 3, 2020 at 7:56 AM Ana Marija <sokovic.anamarija at gmail.com>
> wrote:
>
>> Hello.
>>
>> I am trying to filter only rows that have ANY of these variables:
>> E109, E119, E149
>>
>> so I did:
>> controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
>>
>> than I checked what I got:
>> > s0 <- sapply(controls, function(x) grep('^E10', x, value = TRUE))
>> > d0=unlist(s0)
>> > d10=unique(d0)
>> > d10
>>  [1] "E10"  "E103" "E104" "E109" "E101" "E108" "E105" "E100" "E106" "E102"
>> [11] "E107"
>> s1 <- sapply(controls, function(x) grep('^E11', x, value = TRUE))
>> d1=unlist(s1)
>> d11=unique(d1)
>> > d11
>>  [1] "E11"  "E119" "E113" "E115" "E111" "E114" "E110" "E118" "E116" "E112"
>> [11] "E117"
>>
>> I need help with changing this command
>> controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
>>
>> so that in the output I do not have any rows that include E102 or E112?
>>
>> Thanks
>> Ana
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From g||ted|||e2014 @end|ng |rom gm@||@com  Wed Jun  3 10:59:06 2020
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Wed, 3 Jun 2020 09:59:06 +0100
Subject: [R] Yearly hourly mean and NA
Message-ID: <CAC8ss32O-8CXjAcXO0sswnQTYdO+VThAaDYJmXUWtP1c-6ifgQ@mail.gmail.com>

Dear R-Experts,
I have a cosmic ray data that span several years. The data frame is of the
form:
03 01 01 00    3809
03 01 01 01    3771
03 01 01 02    3743
03 01 01 03    3747
03 01 01 04    3737
03 01 01 05    3751
03 01 01 06    3733
03 01 01 07    3732.
where the columns 1 to 5 stand for year, month, day, hour and counts.
Some hours when the station does not have data are assigned zero, implying
there could be several zeros in column 5. Since my aim is to plot the
hourly mean for all the  years, I started learning with one year - year
2003.

I carefully went through the data, removing any day that contains zero for
any of the hours.  Instead of the 365 days in the year 2003, I ended up
with 362 days.

I saved that as CLMX1C (now stored in Ogbos2 with dput function, see
attached please).

If I run the data with my script, it gives me what I am expecting. My
script is:
d<-read.table("CLMX1C",col.names=c("h","count"))
y<-d$count
data<-(y-mean(y))/mean(y)*100

A<-matrix(rep(1:24,362))
B<-matrix(data)

 oodf<-data.frame(A,B)
 oodf<-data.frame(A,B)
library(plotrix)
std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
oomean<-as.vector(by(oodf$B,oodf$A,mean))
oose<-as.vector(by(oodf$B,oodf$A,std.error))
plot(1:24,oomean,type="b",ylim=c(-0.4,0.5),
 xlab="Hours",ylab="CR count",main="CR daily variation for 2004")
dispersion(1:24,oomean,oose,arrow.cap=.01)

Now, instead of foraging through the big data removing the day for which
there is a missing data for any hour, I wish to try to replace the missing
data with NA and hoping that it will do the job for me.

I added just three lines in the script above:
d<-read.table("2003",col.names=c("y","m","d","h","count"))
y<-d$count
df<-data.frame(y)#line 1
library('dplyr') # line 2
y<-na_if(df, 0) #line 3
data<-(y-mean(y))/mean(y)*100.
Then I started getting error messages:
Error in is.data.frame(x) :
  (list) object cannot be coerced to type 'double'
In addition: There were 26 warnings (use warnings() to see them).

I hope you will assist me to deal with the issues of replacing zeros with
NA in column 5 in such a way that my code will run.

Iam ever indebted!!
Best regards
Ogbos

From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Jun  3 18:50:19 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 3 Jun 2020 17:50:19 +0100
Subject: [R] how to filter variables which appear in any row but do not
 include
In-Reply-To: <CAF9-5jMZUeXKs-yjKP4pKvpw2nmwk9qnfHVSeaQpdGbRmiY7_g@mail.gmail.com>
References: <CAF9-5jMZUeXKs-yjKP4pKvpw2nmwk9qnfHVSeaQpdGbRmiY7_g@mail.gmail.com>
Message-ID: <7f6c36e3-3299-843a-f5cb-edcd007a8c21@sapo.pt>

Hello,

If you want to filter out rows with any of the values in a 'unwanted' 
vector, try the following.

First, create a test data set.

x <- scan(what = character(), text = '
"E10"  "E103" "E104" "E109" "E101" "E108" "E105" "E100" "E106" "E102"
"E107" "E11"  "E119" "E113" "E115" "E111" "E114" "E110" "E118" "E116" "E112"
"E117"
')

set.seed(2020)
dat <- replicate(5, sample(x, 20, TRUE))
dat <- as.data.frame(dat)


Now, remove all rows that have at least one of "E102" or "E112"


unwanted <- c("E102", "E112")
no <- sapply(dat, function(x){
   grepl(paste(unwanted, collapse = "|"), x)
})
no <- apply(no, 1, any)
dat[!no, ]


That's it, if I understood the problem.


Hope this helps,

Rui Barradas


?s 15:55 de 03/06/20, Ana Marija escreveu:
> Hello.
> 
> I am trying to filter only rows that have ANY of these variables:
> E109, E119, E149
> 
> so I did:
> controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
> 
> than I checked what I got:
>> s0 <- sapply(controls, function(x) grep('^E10', x, value = TRUE))
>> d0=unlist(s0)
>> d10=unique(d0)
>> d10
>   [1] "E10"  "E103" "E104" "E109" "E101" "E108" "E105" "E100" "E106" "E102"
> [11] "E107"
> s1 <- sapply(controls, function(x) grep('^E11', x, value = TRUE))
> d1=unlist(s1)
> d11=unique(d1)
>> d11
>   [1] "E11"  "E119" "E113" "E115" "E111" "E114" "E110" "E118" "E116" "E112"
> [11] "E117"
> 
> I need help with changing this command
> controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
> 
> so that in the output I do not have any rows that include E102 or E112?
> 
> Thanks
> Ana
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wjm1 @end|ng |rom c@@@co|umb|@@edu  Wed Jun  3 19:19:26 2020
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Wed, 3 Jun 2020 10:19:26 -0700
Subject: [R] how to filter variables which appear in any row but do not
 include
In-Reply-To: <CAF9-5jMZUeXKs-yjKP4pKvpw2nmwk9qnfHVSeaQpdGbRmiY7_g@mail.gmail.com>
References: <CAF9-5jMZUeXKs-yjKP4pKvpw2nmwk9qnfHVSeaQpdGbRmiY7_g@mail.gmail.com>
Message-ID: <CAA99HCzKnKuGSQF_B26m1X5fHB4kB9Y5_LSp0kniSjjUqz9Q2A@mail.gmail.com>

#Below returns long list of TRUE/FALSE values,
#Note: "IDs" is a column name,
#Wrap with head() to shorten:
df$IDs %in% c("ident_1", "ident_2");

#Below returns index of IDs that are TRUE,
#Wrap with head() to shorten:
which(df$IDs %in% c("ident_1", "ident_2"));

#Below returns short TRUE/FALSE table:
table(df$IDs %in% c("ident_1", "ident_2"));

#Below check df to see unique IDs returned by "%in%" code above,
#(Good for identifying missing "desired" IDs):
unique(df[df$IDs %in% c("ident_1", "ident_2"), "IDs"]);

#Below returns dimensions of dataframe "filtered" (retained) by desired IDs,
#(Note rows below should equal number of TRUE in table above):
dim(df[df$IDs %in% c("ident_1", "ident_2"), ]);

#Create filtered dataframe object:
df_filtered  <-  df[df$IDs %in% c("ident_1", "ident_2"),  ];

#Below returns row counts per "IDs" ("ident_1", "ident_2", etc.) in df_filtered:
aggregate(df_filtered$IDs, by=list(df_filtered$IDs), FUN = "length");


HTH, Bill.

W. Michels, Ph.D.





On Wed, Jun 3, 2020 at 7:56 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello.
>
> I am trying to filter only rows that have ANY of these variables:
> E109, E119, E149
>
> so I did:
> controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
>
> than I checked what I got:
> > s0 <- sapply(controls, function(x) grep('^E10', x, value = TRUE))
> > d0=unlist(s0)
> > d10=unique(d0)
> > d10
>  [1] "E10"  "E103" "E104" "E109" "E101" "E108" "E105" "E100" "E106" "E102"
> [11] "E107"
> s1 <- sapply(controls, function(x) grep('^E11', x, value = TRUE))
> d1=unlist(s1)
> d11=unique(d1)
> > d11
>  [1] "E11"  "E119" "E113" "E115" "E111" "E114" "E110" "E118" "E116" "E112"
> [11] "E117"
>
> I need help with changing this command
> controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
>
> so that in the output I do not have any rows that include E102 or E112?
>
> Thanks
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jun  3 19:34:47 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 3 Jun 2020 10:34:47 -0700
Subject: [R] how to filter variables which appear in any row but do not
 include
In-Reply-To: <7f6c36e3-3299-843a-f5cb-edcd007a8c21@sapo.pt>
References: <CAF9-5jMZUeXKs-yjKP4pKvpw2nmwk9qnfHVSeaQpdGbRmiY7_g@mail.gmail.com>
 <7f6c36e3-3299-843a-f5cb-edcd007a8c21@sapo.pt>
Message-ID: <CAGxFJbRQWs6oh4YGr2EQaGRWQUARekgG4OUH9qSQRaXUCpxb2g@mail.gmail.com>

regex's are not needed. Using Rui's example:

> bad <- mapply(function(x) x %in% unwanted,dat)
> dat[!rowSums(bad),]

     V1   V2   V3   V4   V5
2  E117 E113 E119 E100  E10
4  E114  E11 E119 E119 E114
5  E109 E111 E103 E103 E100
7  E108 E113 E119 E117  E11
8  E114 E105  E10 E109 E110
9  E119 E116 E108 E118 E119
10 E100 E110 E104 E111 E101
13 E111 E116 E101 E110 E116
15 E103  E11 E108  E10 E113
16 E111 E117 E103 E115 E119
17 E104 E110 E104 E117 E114
19 E100 E108  E10 E111 E105
20 E109 E115 E117 E108 E106

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jun 3, 2020 at 9:57 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> If you want to filter out rows with any of the values in a 'unwanted'
> vector, try the following.
>
> First, create a test data set.
>
> x <- scan(what = character(), text = '
> "E10"  "E103" "E104" "E109" "E101" "E108" "E105" "E100" "E106" "E102"
> "E107" "E11"  "E119" "E113" "E115" "E111" "E114" "E110" "E118" "E116"
> "E112"
> "E117"
> ')
>
> set.seed(2020)
> dat <- replicate(5, sample(x, 20, TRUE))
> dat <- as.data.frame(dat)
>
>
> Now, remove all rows that have at least one of "E102" or "E112"
>
>
> unwanted <- c("E102", "E112")
> no <- sapply(dat, function(x){
>    grepl(paste(unwanted, collapse = "|"), x)
> })
> no <- apply(no, 1, any)
> dat[!no, ]
>
>
> That's it, if I understood the problem.
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> ?s 15:55 de 03/06/20, Ana Marija escreveu:
> > Hello.
> >
> > I am trying to filter only rows that have ANY of these variables:
> > E109, E119, E149
> >
> > so I did:
> > controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
> >
> > than I checked what I got:
> >> s0 <- sapply(controls, function(x) grep('^E10', x, value = TRUE))
> >> d0=unlist(s0)
> >> d10=unique(d0)
> >> d10
> >   [1] "E10"  "E103" "E104" "E109" "E101" "E108" "E105" "E100" "E106"
> "E102"
> > [11] "E107"
> > s1 <- sapply(controls, function(x) grep('^E11', x, value = TRUE))
> > d1=unlist(s1)
> > d11=unique(d1)
> >> d11
> >   [1] "E11"  "E119" "E113" "E115" "E111" "E114" "E110" "E118" "E116"
> "E112"
> > [11] "E117"
> >
> > I need help with changing this command
> > controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
> >
> > so that in the output I do not have any rows that include E102 or E112?
> >
> > Thanks
> > Ana
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Jun  3 19:49:58 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 3 Jun 2020 12:49:58 -0500
Subject: [R] how to filter variables which appear in any row but do not
 include
In-Reply-To: <7f6c36e3-3299-843a-f5cb-edcd007a8c21@sapo.pt>
References: <CAF9-5jMZUeXKs-yjKP4pKvpw2nmwk9qnfHVSeaQpdGbRmiY7_g@mail.gmail.com>
 <7f6c36e3-3299-843a-f5cb-edcd007a8c21@sapo.pt>
Message-ID: <CAF9-5jPbUespAJPR7kyekPKmbsT5_C987b+6wW5HUDVk9vV8vw@mail.gmail.com>

Hi Rui,

thank you so much, that is exactly what I needed!

Cheers,
Ana

On Wed, Jun 3, 2020 at 11:50 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
> Hello,
>
> If you want to filter out rows with any of the values in a 'unwanted'
> vector, try the following.
>
> First, create a test data set.
>
> x <- scan(what = character(), text = '
> "E10"  "E103" "E104" "E109" "E101" "E108" "E105" "E100" "E106" "E102"
> "E107" "E11"  "E119" "E113" "E115" "E111" "E114" "E110" "E118" "E116" "E112"
> "E117"
> ')
>
> set.seed(2020)
> dat <- replicate(5, sample(x, 20, TRUE))
> dat <- as.data.frame(dat)
>
>
> Now, remove all rows that have at least one of "E102" or "E112"
>
>
> unwanted <- c("E102", "E112")
> no <- sapply(dat, function(x){
>    grepl(paste(unwanted, collapse = "|"), x)
> })
> no <- apply(no, 1, any)
> dat[!no, ]
>
>
> That's it, if I understood the problem.
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> ?s 15:55 de 03/06/20, Ana Marija escreveu:
> > Hello.
> >
> > I am trying to filter only rows that have ANY of these variables:
> > E109, E119, E149
> >
> > so I did:
> > controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
> >
> > than I checked what I got:
> >> s0 <- sapply(controls, function(x) grep('^E10', x, value = TRUE))
> >> d0=unlist(s0)
> >> d10=unique(d0)
> >> d10
> >   [1] "E10"  "E103" "E104" "E109" "E101" "E108" "E105" "E100" "E106" "E102"
> > [11] "E107"
> > s1 <- sapply(controls, function(x) grep('^E11', x, value = TRUE))
> > d1=unlist(s1)
> > d11=unique(d1)
> >> d11
> >   [1] "E11"  "E119" "E113" "E115" "E111" "E114" "E110" "E118" "E116" "E112"
> > [11] "E117"
> >
> > I need help with changing this command
> > controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
> >
> > so that in the output I do not have any rows that include E102 or E112?
> >
> > Thanks
> > Ana
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Jun  3 21:25:09 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 3 Jun 2020 20:25:09 +0100
Subject: [R] how to filter variables which appear in any row but do not
 include
In-Reply-To: <CAGxFJbRQWs6oh4YGr2EQaGRWQUARekgG4OUH9qSQRaXUCpxb2g@mail.gmail.com>
References: <CAF9-5jMZUeXKs-yjKP4pKvpw2nmwk9qnfHVSeaQpdGbRmiY7_g@mail.gmail.com>
 <7f6c36e3-3299-843a-f5cb-edcd007a8c21@sapo.pt>
 <CAGxFJbRQWs6oh4YGr2EQaGRWQUARekgG4OUH9qSQRaXUCpxb2g@mail.gmail.com>
Message-ID: <2361e4d4-98d8-60be-4af6-fe9daddf6e20@sapo.pt>

Hello,

I forgot about %in%. Maybe because in the OP there were regex's.
And rowSums is much faster than apply.

In my tests this is 7 times faster than mine but with

%in% instead of grepl and apply(no, 1, any)

Hope this helps,

Rui Barradas

?s 18:34 de 03/06/20, Bert Gunter escreveu:
> regex's are not needed. Using Rui's example:
> 
>  > bad <- mapply(function(x) x %in% unwanted,dat)
>  > dat[!rowSums(bad),]
> 
>  ? ?? V1 ? V2 ? V3 ? V4 ? V5
> 2 ?E117 E113 E119 E100 ?E10
> 4 ?E114 ?E11 E119 E119 E114
> 5 ?E109 E111 E103 E103 E100
> 7 ?E108 E113 E119 E117 ?E11
> 8 ?E114 E105 ?E10 E109 E110
> 9 ?E119 E116 E108 E118 E119
> 10 E100 E110 E104 E111 E101
> 13 E111 E116 E101 E110 E116
> 15 E103 ?E11 E108 ?E10 E113
> 16 E111 E117 E103 E115 E119
> 17 E104 E110 E104 E117 E114
> 19 E100 E108 ?E10 E111 E105
> 20 E109 E115 E117 E108 E106
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along 
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Wed, Jun 3, 2020 at 9:57 AM Rui Barradas <ruipbarradas at sapo.pt 
> <mailto:ruipbarradas at sapo.pt>> wrote:
> 
>     Hello,
> 
>     If you want to filter out rows with any of the values in a 'unwanted'
>     vector, try the following.
> 
>     First, create a test data set.
> 
>     x <- scan(what = character(), text = '
>     "E10"? "E103" "E104" "E109" "E101" "E108" "E105" "E100" "E106" "E102"
>     "E107" "E11"? "E119" "E113" "E115" "E111" "E114" "E110" "E118"
>     "E116" "E112"
>     "E117"
>     ')
> 
>     set.seed(2020)
>     dat <- replicate(5, sample(x, 20, TRUE))
>     dat <- as.data.frame(dat)
> 
> 
>     Now, remove all rows that have at least one of "E102" or "E112"
> 
> 
>     unwanted <- c("E102", "E112")
>     no <- sapply(dat, function(x){
>      ? ?grepl(paste(unwanted, collapse = "|"), x)
>     })
>     no <- apply(no, 1, any)
>     dat[!no, ]
> 
> 
>     That's it, if I understood the problem.
> 
> 
>     Hope this helps,
> 
>     Rui Barradas
> 
> 
>     ?s 15:55 de 03/06/20, Ana Marija escreveu:
>      > Hello.
>      >
>      > I am trying to filter only rows that have ANY of these variables:
>      > E109, E119, E149
>      >
>      > so I did:
>      > controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
>      >
>      > than I checked what I got:
>      >> s0 <- sapply(controls, function(x) grep('^E10', x, value = TRUE))
>      >> d0=unlist(s0)
>      >> d10=unique(d0)
>      >> d10
>      >? ?[1] "E10"? "E103" "E104" "E109" "E101" "E108" "E105" "E100"
>     "E106" "E102"
>      > [11] "E107"
>      > s1 <- sapply(controls, function(x) grep('^E11', x, value = TRUE))
>      > d1=unlist(s1)
>      > d11=unique(d1)
>      >> d11
>      >? ?[1] "E11"? "E119" "E113" "E115" "E111" "E114" "E110" "E118"
>     "E116" "E112"
>      > [11] "E117"
>      >
>      > I need help with changing this command
>      > controls=t %>% filter_all(any_vars(. %in% c("E109", "E119","E149")))
>      >
>      > so that in the output I do not have any rows that include E102 or
>     E112?
>      >
>      > Thanks
>      > Ana
>      >
>      > ______________________________________________
>      > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>      >
> 
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jun  3 21:47:35 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 03 Jun 2020 12:47:35 -0700
Subject: [R] Yearly hourly mean and NA
In-Reply-To: <CAC8ss32O-8CXjAcXO0sswnQTYdO+VThAaDYJmXUWtP1c-6ifgQ@mail.gmail.com>
References: <CAC8ss32O-8CXjAcXO0sswnQTYdO+VThAaDYJmXUWtP1c-6ifgQ@mail.gmail.com>
Message-ID: <A23EE6DC-9BA9-4E76-8859-06A54E14E125@dcn.davis.ca.us>

df[[ 5 ]][ 0 == df[[ 5 ]] ] <- NA

On June 3, 2020 1:59:06 AM PDT, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>Dear R-Experts,
>I have a cosmic ray data that span several years. The data frame is of
>the
>form:
>03 01 01 00    3809
>03 01 01 01    3771
>03 01 01 02    3743
>03 01 01 03    3747
>03 01 01 04    3737
>03 01 01 05    3751
>03 01 01 06    3733
>03 01 01 07    3732.
>where the columns 1 to 5 stand for year, month, day, hour and counts.
>Some hours when the station does not have data are assigned zero,
>implying
>there could be several zeros in column 5. Since my aim is to plot the
>hourly mean for all the  years, I started learning with one year - year
>2003.
>
>I carefully went through the data, removing any day that contains zero
>for
>any of the hours.  Instead of the 365 days in the year 2003, I ended up
>with 362 days.
>
>I saved that as CLMX1C (now stored in Ogbos2 with dput function, see
>attached please).
>
>If I run the data with my script, it gives me what I am expecting. My
>script is:
>d<-read.table("CLMX1C",col.names=c("h","count"))
>y<-d$count
>data<-(y-mean(y))/mean(y)*100
>
>A<-matrix(rep(1:24,362))
>B<-matrix(data)
>
> oodf<-data.frame(A,B)
> oodf<-data.frame(A,B)
>library(plotrix)
>std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
>oomean<-as.vector(by(oodf$B,oodf$A,mean))
>oose<-as.vector(by(oodf$B,oodf$A,std.error))
>plot(1:24,oomean,type="b",ylim=c(-0.4,0.5),
> xlab="Hours",ylab="CR count",main="CR daily variation for 2004")
>dispersion(1:24,oomean,oose,arrow.cap=.01)
>
>Now, instead of foraging through the big data removing the day for
>which
>there is a missing data for any hour, I wish to try to replace the
>missing
>data with NA and hoping that it will do the job for me.
>
>I added just three lines in the script above:
>d<-read.table("2003",col.names=c("y","m","d","h","count"))
>y<-d$count
>df<-data.frame(y)#line 1
>library('dplyr') # line 2
>y<-na_if(df, 0) #line 3
>data<-(y-mean(y))/mean(y)*100.
>Then I started getting error messages:
>Error in is.data.frame(x) :
>  (list) object cannot be coerced to type 'double'
>In addition: There were 26 warnings (use warnings() to see them).
>
>I hope you will assist me to deal with the issues of replacing zeros
>with
>NA in column 5 in such a way that my code will run.
>
>Iam ever indebted!!
>Best regards
>Ogbos
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jun  4 04:14:05 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 03 Jun 2020 19:14:05 -0700
Subject: [R] Yearly hourly mean and NA
In-Reply-To: <CAC8ss334vLvefi39YHk0V6WfWOiGdAHYiSwy2uW9Y6LXBeqSKg@mail.gmail.com>
References: <CAC8ss32O-8CXjAcXO0sswnQTYdO+VThAaDYJmXUWtP1c-6ifgQ@mail.gmail.com>
 <A23EE6DC-9BA9-4E76-8859-06A54E14E125@dcn.davis.ca.us>
 <CAC8ss334vLvefi39YHk0V6WfWOiGdAHYiSwy2uW9Y6LXBeqSKg@mail.gmail.com>
Message-ID: <DB896509-4776-4B9A-8549-387D0528FC67@dcn.davis.ca.us>

Perhaps read ?mean...

On June 3, 2020 6:15:11 PM PDT, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>Dear Jeff,
>Thank you so much for your time.
>I tried your code. It successfully assigned NA to the zeros.
>
>But the main code seems not to work with the NAs. The mean, for
>example,
>resulted in NA. I am attaching the data for a period of one year  and
>the
>code which I use  in plotting the data. Maybe it might be easier for
>you to
>spot where I run into error (my plot was just empty).
>Thanks again.
>Best regards
>Ogbos
>
>
>On Wed, Jun 3, 2020 at 8:47 PM Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> df[[ 5 ]][ 0 == df[[ 5 ]] ] <- NA
>>
>> On June 3, 2020 1:59:06 AM PDT, Ogbos Okike
><giftedlife2014 at gmail.com>
>> wrote:
>> >Dear R-Experts,
>> >I have a cosmic ray data that span several years. The data frame is
>of
>> >the
>> >form:
>> >03 01 01 00    3809
>> >03 01 01 01    3771
>> >03 01 01 02    3743
>> >03 01 01 03    3747
>> >03 01 01 04    3737
>> >03 01 01 05    3751
>> >03 01 01 06    3733
>> >03 01 01 07    3732.
>> >where the columns 1 to 5 stand for year, month, day, hour and
>counts.
>> >Some hours when the station does not have data are assigned zero,
>> >implying
>> >there could be several zeros in column 5. Since my aim is to plot
>the
>> >hourly mean for all the  years, I started learning with one year -
>year
>> >2003.
>> >
>> >I carefully went through the data, removing any day that contains
>zero
>> >for
>> >any of the hours.  Instead of the 365 days in the year 2003, I ended
>up
>> >with 362 days.
>> >
>> >I saved that as CLMX1C (now stored in Ogbos2 with dput function, see
>> >attached please).
>> >
>> >If I run the data with my script, it gives me what I am expecting.
>My
>> >script is:
>> >d<-read.table("CLMX1C",col.names=c("h","count"))
>> >y<-d$count
>> >data<-(y-mean(y))/mean(y)*100
>> >
>> >A<-matrix(rep(1:24,362))
>> >B<-matrix(data)
>> >
>> > oodf<-data.frame(A,B)
>> > oodf<-data.frame(A,B)
>> >library(plotrix)
>> >std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
>> >oomean<-as.vector(by(oodf$B,oodf$A,mean))
>> >oose<-as.vector(by(oodf$B,oodf$A,std.error))
>> >plot(1:24,oomean,type="b",ylim=c(-0.4,0.5),
>> > xlab="Hours",ylab="CR count",main="CR daily variation for 2004")
>> >dispersion(1:24,oomean,oose,arrow.cap=.01)
>> >
>> >Now, instead of foraging through the big data removing the day for
>> >which
>> >there is a missing data for any hour, I wish to try to replace the
>> >missing
>> >data with NA and hoping that it will do the job for me.
>> >
>> >I added just three lines in the script above:
>> >d<-read.table("2003",col.names=c("y","m","d","h","count"))
>> >y<-d$count
>> >df<-data.frame(y)#line 1
>> >library('dplyr') # line 2
>> >y<-na_if(df, 0) #line 3
>> >data<-(y-mean(y))/mean(y)*100.
>> >Then I started getting error messages:
>> >Error in is.data.frame(x) :
>> >  (list) object cannot be coerced to type 'double'
>> >In addition: There were 26 warnings (use warnings() to see them).
>> >
>> >I hope you will assist me to deal with the issues of replacing zeros
>> >with
>> >NA in column 5 in such a way that my code will run.
>> >
>> >Iam ever indebted!!
>> >Best regards
>> >Ogbos
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>

-- 
Sent from my phone. Please excuse my brevity.


From g||ted|||e2014 @end|ng |rom gm@||@com  Thu Jun  4 08:13:28 2020
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Thu, 4 Jun 2020 07:13:28 +0100
Subject: [R] Yearly hourly mean and NA: SOLVED
In-Reply-To: <DB896509-4776-4B9A-8549-387D0528FC67@dcn.davis.ca.us>
References: <CAC8ss32O-8CXjAcXO0sswnQTYdO+VThAaDYJmXUWtP1c-6ifgQ@mail.gmail.com>
 <A23EE6DC-9BA9-4E76-8859-06A54E14E125@dcn.davis.ca.us>
 <CAC8ss334vLvefi39YHk0V6WfWOiGdAHYiSwy2uW9Y6LXBeqSKg@mail.gmail.com>
 <DB896509-4776-4B9A-8549-387D0528FC67@dcn.davis.ca.us>
Message-ID: <CAC8ss31QG_0sVPCCJCs8gqD1xO5MFd5wUKPiQabhmRCvLTLYJg@mail.gmail.com>

Dear Jeff,
It worked!!! I took a second look at "?mean" as you suggested.
I then adjusted my code, inserting rm.na here and there until it was fine.
Thank you very much.
Warm regards.
Ogbos
On Thu, Jun 4, 2020 at 3:14 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Perhaps read ?mean...
>
> On June 3, 2020 6:15:11 PM PDT, Ogbos Okike <giftedlife2014 at gmail.com>
> wrote:
> >Dear Jeff,
> >Thank you so much for your time.
> >I tried your code. It successfully assigned NA to the zeros.
> >
> >But the main code seems not to work with the NAs. The mean, for
> >example,
> >resulted in NA. I am attaching the data for a period of one year  and
> >the
> >code which I use  in plotting the data. Maybe it might be easier for
> >you to
> >spot where I run into error (my plot was just empty).
> >Thanks again.
> >Best regards
> >Ogbos
> >
> >
> >On Wed, Jun 3, 2020 at 8:47 PM Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us>
> >wrote:
> >
> >> df[[ 5 ]][ 0 == df[[ 5 ]] ] <- NA
> >>
> >> On June 3, 2020 1:59:06 AM PDT, Ogbos Okike
> ><giftedlife2014 at gmail.com>
> >> wrote:
> >> >Dear R-Experts,
> >> >I have a cosmic ray data that span several years. The data frame is
> >of
> >> >the
> >> >form:
> >> >03 01 01 00    3809
> >> >03 01 01 01    3771
> >> >03 01 01 02    3743
> >> >03 01 01 03    3747
> >> >03 01 01 04    3737
> >> >03 01 01 05    3751
> >> >03 01 01 06    3733
> >> >03 01 01 07    3732.
> >> >where the columns 1 to 5 stand for year, month, day, hour and
> >counts.
> >> >Some hours when the station does not have data are assigned zero,
> >> >implying
> >> >there could be several zeros in column 5. Since my aim is to plot
> >the
> >> >hourly mean for all the  years, I started learning with one year -
> >year
> >> >2003.
> >> >
> >> >I carefully went through the data, removing any day that contains
> >zero
> >> >for
> >> >any of the hours.  Instead of the 365 days in the year 2003, I ended
> >up
> >> >with 362 days.
> >> >
> >> >I saved that as CLMX1C (now stored in Ogbos2 with dput function, see
> >> >attached please).
> >> >
> >> >If I run the data with my script, it gives me what I am expecting.
> >My
> >> >script is:
> >> >d<-read.table("CLMX1C",col.names=c("h","count"))
> >> >y<-d$count
> >> >data<-(y-mean(y))/mean(y)*100
> >> >
> >> >A<-matrix(rep(1:24,362))
> >> >B<-matrix(data)
> >> >
> >> > oodf<-data.frame(A,B)
> >> > oodf<-data.frame(A,B)
> >> >library(plotrix)
> >> >std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
> >> >oomean<-as.vector(by(oodf$B,oodf$A,mean))
> >> >oose<-as.vector(by(oodf$B,oodf$A,std.error))
> >> >plot(1:24,oomean,type="b",ylim=c(-0.4,0.5),
> >> > xlab="Hours",ylab="CR count",main="CR daily variation for 2004")
> >> >dispersion(1:24,oomean,oose,arrow.cap=.01)
> >> >
> >> >Now, instead of foraging through the big data removing the day for
> >> >which
> >> >there is a missing data for any hour, I wish to try to replace the
> >> >missing
> >> >data with NA and hoping that it will do the job for me.
> >> >
> >> >I added just three lines in the script above:
> >> >d<-read.table("2003",col.names=c("y","m","d","h","count"))
> >> >y<-d$count
> >> >df<-data.frame(y)#line 1
> >> >library('dplyr') # line 2
> >> >y<-na_if(df, 0) #line 3
> >> >data<-(y-mean(y))/mean(y)*100.
> >> >Then I started getting error messages:
> >> >Error in is.data.frame(x) :
> >> >  (list) object cannot be coerced to type 'double'
> >> >In addition: There were 26 warnings (use warnings() to see them).
> >> >
> >> >I hope you will assist me to deal with the issues of replacing zeros
> >> >with
> >> >NA in column 5 in such a way that my code will run.
> >> >
> >> >Iam ever indebted!!
> >> >Best regards
> >> >Ogbos
> >> >______________________________________________
> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >PLEASE do read the posting guide
> >> >http://www.R-project.org/posting-guide.html
> >> >and provide commented, minimal, self-contained, reproducible code.
> >>
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jun  4 08:37:51 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 03 Jun 2020 23:37:51 -0700
Subject: [R] Yearly hourly mean and NA: SOLVED
In-Reply-To: <CAC8ss31QG_0sVPCCJCs8gqD1xO5MFd5wUKPiQabhmRCvLTLYJg@mail.gmail.com>
References: <CAC8ss32O-8CXjAcXO0sswnQTYdO+VThAaDYJmXUWtP1c-6ifgQ@mail.gmail.com>
 <A23EE6DC-9BA9-4E76-8859-06A54E14E125@dcn.davis.ca.us>
 <CAC8ss334vLvefi39YHk0V6WfWOiGdAHYiSwy2uW9Y6LXBeqSKg@mail.gmail.com>
 <DB896509-4776-4B9A-8549-387D0528FC67@dcn.davis.ca.us>
 <CAC8ss31QG_0sVPCCJCs8gqD1xO5MFd5wUKPiQabhmRCvLTLYJg@mail.gmail.com>
Message-ID: <61F5E22B-43C7-4F6E-8B65-4B5DE6A0EA8A@dcn.davis.ca.us>

Glad you had a positive experience with the documentation... there are many gems to be found there.

But I don't think rm.na will work... the na comes before the rm for some reason.

On June 3, 2020 11:13:28 PM PDT, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
>Dear Jeff,
>It worked!!! I took a second look at "?mean" as you suggested.
>I then adjusted my code, inserting rm.na here and there until it was
>fine.
>Thank you very much.
>Warm regards.
>Ogbos
>On Thu, Jun 4, 2020 at 3:14 AM Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Perhaps read ?mean...
>>
>> On June 3, 2020 6:15:11 PM PDT, Ogbos Okike
><giftedlife2014 at gmail.com>
>> wrote:
>> >Dear Jeff,
>> >Thank you so much for your time.
>> >I tried your code. It successfully assigned NA to the zeros.
>> >
>> >But the main code seems not to work with the NAs. The mean, for
>> >example,
>> >resulted in NA. I am attaching the data for a period of one year 
>and
>> >the
>> >code which I use  in plotting the data. Maybe it might be easier for
>> >you to
>> >spot where I run into error (my plot was just empty).
>> >Thanks again.
>> >Best regards
>> >Ogbos
>> >
>> >
>> >On Wed, Jun 3, 2020 at 8:47 PM Jeff Newmiller
>> ><jdnewmil at dcn.davis.ca.us>
>> >wrote:
>> >
>> >> df[[ 5 ]][ 0 == df[[ 5 ]] ] <- NA
>> >>
>> >> On June 3, 2020 1:59:06 AM PDT, Ogbos Okike
>> ><giftedlife2014 at gmail.com>
>> >> wrote:
>> >> >Dear R-Experts,
>> >> >I have a cosmic ray data that span several years. The data frame
>is
>> >of
>> >> >the
>> >> >form:
>> >> >03 01 01 00    3809
>> >> >03 01 01 01    3771
>> >> >03 01 01 02    3743
>> >> >03 01 01 03    3747
>> >> >03 01 01 04    3737
>> >> >03 01 01 05    3751
>> >> >03 01 01 06    3733
>> >> >03 01 01 07    3732.
>> >> >where the columns 1 to 5 stand for year, month, day, hour and
>> >counts.
>> >> >Some hours when the station does not have data are assigned zero,
>> >> >implying
>> >> >there could be several zeros in column 5. Since my aim is to plot
>> >the
>> >> >hourly mean for all the  years, I started learning with one year
>-
>> >year
>> >> >2003.
>> >> >
>> >> >I carefully went through the data, removing any day that contains
>> >zero
>> >> >for
>> >> >any of the hours.  Instead of the 365 days in the year 2003, I
>ended
>> >up
>> >> >with 362 days.
>> >> >
>> >> >I saved that as CLMX1C (now stored in Ogbos2 with dput function,
>see
>> >> >attached please).
>> >> >
>> >> >If I run the data with my script, it gives me what I am
>expecting.
>> >My
>> >> >script is:
>> >> >d<-read.table("CLMX1C",col.names=c("h","count"))
>> >> >y<-d$count
>> >> >data<-(y-mean(y))/mean(y)*100
>> >> >
>> >> >A<-matrix(rep(1:24,362))
>> >> >B<-matrix(data)
>> >> >
>> >> > oodf<-data.frame(A,B)
>> >> > oodf<-data.frame(A,B)
>> >> >library(plotrix)
>> >> >std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
>> >> >oomean<-as.vector(by(oodf$B,oodf$A,mean))
>> >> >oose<-as.vector(by(oodf$B,oodf$A,std.error))
>> >> >plot(1:24,oomean,type="b",ylim=c(-0.4,0.5),
>> >> > xlab="Hours",ylab="CR count",main="CR daily variation for 2004")
>> >> >dispersion(1:24,oomean,oose,arrow.cap=.01)
>> >> >
>> >> >Now, instead of foraging through the big data removing the day
>for
>> >> >which
>> >> >there is a missing data for any hour, I wish to try to replace
>the
>> >> >missing
>> >> >data with NA and hoping that it will do the job for me.
>> >> >
>> >> >I added just three lines in the script above:
>> >> >d<-read.table("2003",col.names=c("y","m","d","h","count"))
>> >> >y<-d$count
>> >> >df<-data.frame(y)#line 1
>> >> >library('dplyr') # line 2
>> >> >y<-na_if(df, 0) #line 3
>> >> >data<-(y-mean(y))/mean(y)*100.
>> >> >Then I started getting error messages:
>> >> >Error in is.data.frame(x) :
>> >> >  (list) object cannot be coerced to type 'double'
>> >> >In addition: There were 26 warnings (use warnings() to see them).
>> >> >
>> >> >I hope you will assist me to deal with the issues of replacing
>zeros
>> >> >with
>> >> >NA in column 5 in such a way that my code will run.
>> >> >
>> >> >Iam ever indebted!!
>> >> >Best regards
>> >> >Ogbos
>> >> >______________________________________________
>> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >PLEASE do read the posting guide
>> >> >http://www.R-project.org/posting-guide.html
>> >> >and provide commented, minimal, self-contained, reproducible
>code.
>> >>
>> >> --
>> >> Sent from my phone. Please excuse my brevity.
>> >>
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>

-- 
Sent from my phone. Please excuse my brevity.


From c@t@||nro|bu @end|ng |rom gm@||@com  Thu Jun  4 15:06:28 2020
From: c@t@||nro|bu @end|ng |rom gm@||@com (Catalin Roibu)
Date: Thu, 4 Jun 2020 16:06:28 +0300
Subject: [R] consecutive n values
Message-ID: <CAEW+BDKYM9Yvbk75fMoOsZ_wqcPnXDJQF=3WNEvRcW_UTAe27g@mail.gmail.com>

Dear R users,

Please help me to detect consecutive n values in R and their interval.


rle.seq1<-rle(reco$extr)
cbind(rle.seq1$values)
index<-any(rle.seq1$values=="DRY"&rle.seq1$lengths>=3)
cumsum(rle.seq1$lengths)[index]

reco is a data frame with 2 columns (year and values (DRY, WET).

I want to have something like this:
1799-1800 - WET - 2
1803-1805 - WET - 3

Thank you very much!

All the best!

Catalin


   year extr
1   1768 <NA>
2   1769 <NA>
3   1770 <NA>
4   1771 <NA>
5   1772 <NA>
6   1773  DRY
7   1774 <NA>
8   1775 <NA>
9   1776 <NA>
10  1777  DRY
11  1778 <NA>
12  1779  DRY
13  1780  DRY
14  1781 <NA>
15  1782  DRY
16  1783 <NA>
17  1784 <NA>
18  1785 <NA>
19  1786 <NA>
20  1787 <NA>
21  1788 <NA>
22  1789 <NA>
23  1790 <NA>
24  1791 <NA>
25  1792 <NA>
26  1793 <NA>
27  1794 <NA>
28  1795  WET
29  1796 <NA>
30  1797 <NA>
31  1798 <NA>
32  1799  WET
33  1800  WET
34  1801 <NA>
35  1802 <NA>
36  1803  WET
37  1804  WET
38  1805  WET
39  1806 <NA>
40  1807 <NA>
41  1808 <NA>
42  1809 <NA>
43  1810  WET
44  1811 <NA>
45  1812 <NA>
46  1813  WET
47  1814  DRY
48  1815 <NA>
49  1816 <NA>
50  1817 <NA>
51  1818 <NA>
52  1819 <NA>
53  1820 <NA>
54  1821 <NA>
55  1822  WET
56  1823  WET
57  1824  WET
58  1825  WET
59  1826 <NA>
60  1827  DRY
61  1828  DRY
62  1829  WET
63  1830  WET
64  1831  WET
65  1832  WET
66  1833 <NA>
67  1834  DRY
68  1835  DRY
69  1836 <NA>
70  1837 <NA>
71  1838 <NA>
72  1839 <NA>
73  1840 <NA>
74  1841 <NA>
75  1842 <NA>
76  1843  WET
77  1844  WET
78  1845 <NA>
79  1846 <NA>
80  1847 <NA>
81  1848  DRY
82  1849  DRY
83  1850 <NA>
84  1851 <NA>
85  1852  WET
86  1853 <NA>
87  1854 <NA>
88  1855 <NA>
89  1856 <NA>
90  1857  WET
91  1858 <NA>
92  1859 <NA>
93  1860 <NA>
94  1861 <NA>
95  1862 <NA>
96  1863 <NA>
97  1864 <NA>
98  1865 <NA>
99  1866  DRY
100 1867  DRY
101 1868 <NA>
102 1869  DRY
103 1870 <NA>
104 1871  WET
105 1872 <NA>
106 1873 <NA>
107 1874  DRY
108 1875  DRY
109 1876 <NA>
110 1877 <NA>
111 1878 <NA>
112 1879 <NA>
113 1880  WET
114 1881  WET
115 1882 <NA>
116 1883 <NA>
117 1884 <NA>
118 1885 <NA>
119 1886  DRY
120 1887  DRY
121 1888  DRY
122 1889 <NA>
123 1890 <NA>
124 1891 <NA>
125 1892 <NA>
126 1893 <NA>
127 1894 <NA>
128 1895 <NA>
129 1896 <NA>
130 1897 <NA>
131 1898 <NA>
132 1899 <NA>
133 1900 <NA>
134 1901 <NA>
135 1902 <NA>
136 1903  WET
137 1904 <NA>
138 1905 <NA>
139 1906  WET
140 1907 <NA>
141 1908 <NA>
142 1909 <NA>
143 1910 <NA>
144 1911  WET
145 1912  WET
146 1913  WET
147 1914  WET
148 1915 <NA>
149 1916 <NA>
150 1917 <NA>
151 1918  DRY
152 1919 <NA>
153 1920 <NA>
154 1921  DRY
155 1922 <NA>
156 1923 <NA>
157 1924 <NA>
158 1925 <NA>
159 1926 <NA>
160 1927 <NA>
161 1928  DRY
162 1929 <NA>
163 1930 <NA>
164 1931 <NA>
165 1932 <NA>
166 1933 <NA>
167 1934 <NA>
168 1935 <NA>
169 1936 <NA>
170 1937 <NA>
171 1938 <NA>
172 1939 <NA>
173 1940 <NA>
174 1941 <NA>
175 1942 <NA>
176 1943 <NA>
177 1944  WET
178 1945 <NA>
179 1946  DRY
180 1947  DRY
181 1948  DRY
182 1949 <NA>
183 1950  WET
184 1951 <NA>
185 1952  DRY
186 1953 <NA>
187 1954 <NA>
188 1955  WET
189 1956 <NA>
190 1957 <NA>
191 1958 <NA>
192 1959  WET
193 1960 <NA>
194 1961 <NA>
195 1962 <NA>
196 1963 <NA>
197 1964  DRY
198 1965 <NA>
199 1966 <NA>
200 1967 <NA>
201 1968  DRY
202 1969  WET
203 1970  WET
204 1971 <NA>
205 1972 <NA>
206 1973 <NA>
207 1974  WET
208 1975  WET
209 1976 <NA>
210 1977 <NA>
211 1978 <NA>
212 1979 <NA>
213 1980 <NA>
214 1981 <NA>
215 1982  WET
216 1983  DRY
217 1984 <NA>
218 1985  DRY
219 1986 <NA>
220 1987 <NA>
221 1988  WET
222 1989  WET
223 1990  WET
224 1991 <NA>
225 1992 <NA>
226 1993 <NA>
227 1994 <NA>
228 1995  DRY
229 1996  DRY
230 1997  WET
231 1998 <NA>
232 1999 <NA>
233 2000  DRY
234 2001 <NA>
235 2002 <NA>
236 2003  DRY
237 2004 <NA>
238 2005 <NA>
239 2006 <NA>
240 2007 <NA>


-- 

-
-
Catalin-Constantin ROIBU
Lecturer PhD, Forestry engineer
Forestry Faculty of Suceava
Str. Universitatii no. 13, Suceava, 720229, Romania
office phone      +4 0230 52 29 78, ext. 531
mobile phone    +4 0745 53 18 01
FAX:                +4 0230 52 16 64
silvic.usv.ro <http://www.usv.ro/>

[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
04.06.20,
16:04:35

	[[alternative HTML version deleted]]


From ccberry @end|ng |rom he@|th@uc@d@edu  Thu Jun  4 19:27:52 2020
From: ccberry @end|ng |rom he@|th@uc@d@edu (Berry, Charles)
Date: Thu, 4 Jun 2020 17:27:52 +0000
Subject: [R] consecutive n values
In-Reply-To: <CAEW+BDKYM9Yvbk75fMoOsZ_wqcPnXDJQF=3WNEvRcW_UTAe27g@mail.gmail.com>
References: <CAEW+BDKYM9Yvbk75fMoOsZ_wqcPnXDJQF=3WNEvRcW_UTAe27g@mail.gmail.com>
Message-ID: <BB4283DA-8A05-470E-871B-E335EFA51488@health.ucsd.edu>

Catalin,

> On Jun 4, 2020, at 6:06 AM, Catalin Roibu <catalinroibu at gmail.com> wrote:
> 
> Dear R users,
> 
> Please help me to detect consecutive n values in R and their interval.
> 
> 
> rle.seq1<-rle(reco$extr)
> cbind(rle.seq1$values)
> index<-any(rle.seq1$values=="DRY"&rle.seq1$lengths>=3)
> cumsum(rle.seq1$lengths)[index]
> 
> reco is a data frame with 2 columns (year and values (DRY, WET).
> 
> I want to have something like this:
> 1799-1800 - WET - 2
> 1803-1805 - WET - 3
> 
> Thank you very much!


Something like:

  wd.rle <- rle(reco$extr)
  is.wet <- wd.rle[["values"]]=="WET"
  wd.rle[["values"]] <- ifelse(is.wet, cumsum( is.wet ), 0)
  wet.list <- split( reco$year, inverse.rle( wd.rle ) )[ -1 ]
  sapply( wet.list[ lengths(wet.list) > 1 ], range)

should get you started.

The last line returns:

:         2    3    6    7    8   12   15   20   21   23
: [1,] 1799 1803 1822 1829 1843 1880 1911 1969 1974 1988
: [2,] 1800 1805 1825 1832 1844 1881 1914 1970 1975 1990

You can use `apply' to further process this to get the desired format for your result.  

I assume here that reco$years are in groups of consecutive 'WET' years. 

If there are gaps or other oddities you will need to replace `range' with a function that handles that.

HTH,

Chuck


From @|m|n@@t@work @end|ng |rom gm@||@com  Thu Jun  4 05:17:23 2020
From: @|m|n@@t@work @end|ng |rom gm@||@com (Aimin Yan)
Date: Wed, 3 Jun 2020 23:17:23 -0400
Subject: [R] ask help for ggplot
Message-ID: <CALn2QVh5R8C1qH5kLkzwmvXg9mECg=41wUdV+j9Nkv2o-NVd1g@mail.gmail.com>

I have a question about using ggplot.

Is there possible to generate a barplot like the attached file using ggplot?

Thank you,

Aimin

From g||ted|||e2014 @end|ng |rom gm@||@com  Thu Jun  4 03:15:11 2020
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Thu, 4 Jun 2020 02:15:11 +0100
Subject: [R] Yearly hourly mean and NA
In-Reply-To: <A23EE6DC-9BA9-4E76-8859-06A54E14E125@dcn.davis.ca.us>
References: <CAC8ss32O-8CXjAcXO0sswnQTYdO+VThAaDYJmXUWtP1c-6ifgQ@mail.gmail.com>
 <A23EE6DC-9BA9-4E76-8859-06A54E14E125@dcn.davis.ca.us>
Message-ID: <CAC8ss334vLvefi39YHk0V6WfWOiGdAHYiSwy2uW9Y6LXBeqSKg@mail.gmail.com>

Dear Jeff,
Thank you so much for your time.
I tried your code. It successfully assigned NA to the zeros.

But the main code seems not to work with the NAs. The mean, for example,
resulted in NA. I am attaching the data for a period of one year  and the
code which I use  in plotting the data. Maybe it might be easier for you to
spot where I run into error (my plot was just empty).
Thanks again.
Best regards
Ogbos


On Wed, Jun 3, 2020 at 8:47 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> df[[ 5 ]][ 0 == df[[ 5 ]] ] <- NA
>
> On June 3, 2020 1:59:06 AM PDT, Ogbos Okike <giftedlife2014 at gmail.com>
> wrote:
> >Dear R-Experts,
> >I have a cosmic ray data that span several years. The data frame is of
> >the
> >form:
> >03 01 01 00    3809
> >03 01 01 01    3771
> >03 01 01 02    3743
> >03 01 01 03    3747
> >03 01 01 04    3737
> >03 01 01 05    3751
> >03 01 01 06    3733
> >03 01 01 07    3732.
> >where the columns 1 to 5 stand for year, month, day, hour and counts.
> >Some hours when the station does not have data are assigned zero,
> >implying
> >there could be several zeros in column 5. Since my aim is to plot the
> >hourly mean for all the  years, I started learning with one year - year
> >2003.
> >
> >I carefully went through the data, removing any day that contains zero
> >for
> >any of the hours.  Instead of the 365 days in the year 2003, I ended up
> >with 362 days.
> >
> >I saved that as CLMX1C (now stored in Ogbos2 with dput function, see
> >attached please).
> >
> >If I run the data with my script, it gives me what I am expecting. My
> >script is:
> >d<-read.table("CLMX1C",col.names=c("h","count"))
> >y<-d$count
> >data<-(y-mean(y))/mean(y)*100
> >
> >A<-matrix(rep(1:24,362))
> >B<-matrix(data)
> >
> > oodf<-data.frame(A,B)
> > oodf<-data.frame(A,B)
> >library(plotrix)
> >std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
> >oomean<-as.vector(by(oodf$B,oodf$A,mean))
> >oose<-as.vector(by(oodf$B,oodf$A,std.error))
> >plot(1:24,oomean,type="b",ylim=c(-0.4,0.5),
> > xlab="Hours",ylab="CR count",main="CR daily variation for 2004")
> >dispersion(1:24,oomean,oose,arrow.cap=.01)
> >
> >Now, instead of foraging through the big data removing the day for
> >which
> >there is a missing data for any hour, I wish to try to replace the
> >missing
> >data with NA and hoping that it will do the job for me.
> >
> >I added just three lines in the script above:
> >d<-read.table("2003",col.names=c("y","m","d","h","count"))
> >y<-d$count
> >df<-data.frame(y)#line 1
> >library('dplyr') # line 2
> >y<-na_if(df, 0) #line 3
> >data<-(y-mean(y))/mean(y)*100.
> >Then I started getting error messages:
> >Error in is.data.frame(x) :
> >  (list) object cannot be coerced to type 'double'
> >In addition: There were 26 warnings (use warnings() to see them).
> >
> >I hope you will assist me to deal with the issues of replacing zeros
> >with
> >NA in column 5 in such a way that my code will run.
> >
> >Iam ever indebted!!
> >Best regards
> >Ogbos
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

From g||ted|||e2014 @end|ng |rom gm@||@com  Thu Jun  4 08:49:59 2020
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Thu, 4 Jun 2020 07:49:59 +0100
Subject: [R] Yearly hourly mean and NA
In-Reply-To: <DB896509-4776-4B9A-8549-387D0528FC67@dcn.davis.ca.us>
References: <CAC8ss32O-8CXjAcXO0sswnQTYdO+VThAaDYJmXUWtP1c-6ifgQ@mail.gmail.com>
 <A23EE6DC-9BA9-4E76-8859-06A54E14E125@dcn.davis.ca.us>
 <CAC8ss334vLvefi39YHk0V6WfWOiGdAHYiSwy2uW9Y6LXBeqSKg@mail.gmail.com>
 <DB896509-4776-4B9A-8549-387D0528FC67@dcn.davis.ca.us>
Message-ID: <CAC8ss33MCO9wvAOFjo8C2tuN9q-Q1orC_f6U6MMHa8LeoWt-SQ@mail.gmail.com>

Dear Jeff,
Yes. It worked. But I am still fine turning the script.
Please permit me to ask again.

Since I can handle one year. I wish to take on more years. I added extra
two years and now have 2000 to 2002.

I wish to plot the same graph for those years such that the x-axis will be
showing 2000, 2001 and 2002.  I tried to manipulate replicate function with
times and length.
I have a result but it does seem like what I am looking for. For each year,
I should get a similar graph. So the three years will just look like
similar plot repeated with some small differences. When I did per year and
added, I got it. But I could not add the error bars by doing them
separately for each year.

Here is part of my adjusted code:
d<-read.table("3years",col.names=c("y","m","d","h","count"))
y<-d$count
 data<-(y-mean(y,na.rm=TRUE))/mean(y,na.rm=TRUE)*100
A<-matrix(rep(1:24,366))
A1<-matrix(rep(25:49,365))
 A2<-matrix(rep(50:72,365))
A<-matrix(c(A,A1,A2),ncol=1)
I have also attached the complete code and data for the three years.
I am thanking you for any pointer.
Best regards
Ogbos

On Thu, Jun 4, 2020 at 3:14 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Perhaps read ?mean...
>
> On June 3, 2020 6:15:11 PM PDT, Ogbos Okike <giftedlife2014 at gmail.com>
> wrote:
> >Dear Jeff,
> >Thank you so much for your time.
> >I tried your code. It successfully assigned NA to the zeros.
> >
> >But the main code seems not to work with the NAs. The mean, for
> >example,
> >resulted in NA. I am attaching the data for a period of one year  and
> >the
> >code which I use  in plotting the data. Maybe it might be easier for
> >you to
> >spot where I run into error (my plot was just empty).
> >Thanks again.
> >Best regards
> >Ogbos
> >
> >
> >On Wed, Jun 3, 2020 at 8:47 PM Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us>
> >wrote:
> >
> >> df[[ 5 ]][ 0 == df[[ 5 ]] ] <- NA
> >>
> >> On June 3, 2020 1:59:06 AM PDT, Ogbos Okike
> ><giftedlife2014 at gmail.com>
> >> wrote:
> >> >Dear R-Experts,
> >> >I have a cosmic ray data that span several years. The data frame is
> >of
> >> >the
> >> >form:
> >> >03 01 01 00    3809
> >> >03 01 01 01    3771
> >> >03 01 01 02    3743
> >> >03 01 01 03    3747
> >> >03 01 01 04    3737
> >> >03 01 01 05    3751
> >> >03 01 01 06    3733
> >> >03 01 01 07    3732.
> >> >where the columns 1 to 5 stand for year, month, day, hour and
> >counts.
> >> >Some hours when the station does not have data are assigned zero,
> >> >implying
> >> >there could be several zeros in column 5. Since my aim is to plot
> >the
> >> >hourly mean for all the  years, I started learning with one year -
> >year
> >> >2003.
> >> >
> >> >I carefully went through the data, removing any day that contains
> >zero
> >> >for
> >> >any of the hours.  Instead of the 365 days in the year 2003, I ended
> >up
> >> >with 362 days.
> >> >
> >> >I saved that as CLMX1C (now stored in Ogbos2 with dput function, see
> >> >attached please).
> >> >
> >> >If I run the data with my script, it gives me what I am expecting.
> >My
> >> >script is:
> >> >d<-read.table("CLMX1C",col.names=c("h","count"))
> >> >y<-d$count
> >> >data<-(y-mean(y))/mean(y)*100
> >> >
> >> >A<-matrix(rep(1:24,362))
> >> >B<-matrix(data)
> >> >
> >> > oodf<-data.frame(A,B)
> >> > oodf<-data.frame(A,B)
> >> >library(plotrix)
> >> >std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
> >> >oomean<-as.vector(by(oodf$B,oodf$A,mean))
> >> >oose<-as.vector(by(oodf$B,oodf$A,std.error))
> >> >plot(1:24,oomean,type="b",ylim=c(-0.4,0.5),
> >> > xlab="Hours",ylab="CR count",main="CR daily variation for 2004")
> >> >dispersion(1:24,oomean,oose,arrow.cap=.01)
> >> >
> >> >Now, instead of foraging through the big data removing the day for
> >> >which
> >> >there is a missing data for any hour, I wish to try to replace the
> >> >missing
> >> >data with NA and hoping that it will do the job for me.
> >> >
> >> >I added just three lines in the script above:
> >> >d<-read.table("2003",col.names=c("y","m","d","h","count"))
> >> >y<-d$count
> >> >df<-data.frame(y)#line 1
> >> >library('dplyr') # line 2
> >> >y<-na_if(df, 0) #line 3
> >> >data<-(y-mean(y))/mean(y)*100.
> >> >Then I started getting error messages:
> >> >Error in is.data.frame(x) :
> >> >  (list) object cannot be coerced to type 'double'
> >> >In addition: There were 26 warnings (use warnings() to see them).
> >> >
> >> >I hope you will assist me to deal with the issues of replacing zeros
> >> >with
> >> >NA in column 5 in such a way that my code will run.
> >> >
> >> >Iam ever indebted!!
> >> >Best regards
> >> >Ogbos
> >> >______________________________________________
> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >PLEASE do read the posting guide
> >> >http://www.R-project.org/posting-guide.html
> >> >and provide commented, minimal, self-contained, reproducible code.
> >>
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
>
> --
> Sent from my phone. Please excuse my brevity.
>

From @turm|echen @end|ng |rom gm@||@com  Thu Jun  4 19:31:04 2020
From: @turm|echen @end|ng |rom gm@||@com (Lena Fehlhaber)
Date: Thu, 4 Jun 2020 19:31:04 +0200
Subject: [R] GLM model with spatialspillover on categorical variables
Message-ID: <CA+yGT=FjdTETUQ8hs=uSM0=4B6LQdWRZVfuk4iWP12OYhsTeZA@mail.gmail.com>

I did a regression analysis with categorical data with a glm model
approach, which worked fine. I have longitude and latitude coordinates for
each observation and I want to add their geographic spillover effect to the
model.

My sample data is structured:

Index DV IVI IVII IVIII IVIV Long Lat
 1  0  2  1  3  -12  -17.8  12
 2  0  1  1  6  112  11  -122
 3  1  3  6  1  91  57  53

with regression eq. DV ~ IVI + IVII + IVIII + IVIV

That mentioned, I assume that the nearer regions are, the more it may
influence my dependant variable. I found several approaches for spatial
regression models, but not for categorical data. I tried to use existing
libraries and functions, such as spdep's lagsarlm, glmmfields, spatialreg,
gstat, geoRglm and many more (I used this list as a reference:
https://cran.r-project.org/web/views/Spatial.html ). For numeric values, I
am able to do spatial regression, but for categorical values, I struggle.
The data structure is the following:

library(dplyr)
data <- data %>%
  mutate(
    DV = as.factor(DV),
    IVI = as.factor(IVI),
    IVII = as.factor(IVII),
    IVIII = as.factor(IVIII),
    IVIV = as.numeric(IVIV),
    longitude = as.numeric(longitude),
    latitude = as.numeric(latitude)
  )

My dependant variable (0|1) as well as my independant variables are
categorical and it would be no use to transform them, of course. I want to
have an other glm model in the end, but with spatial spillover effects
included. The libraries I tested so far can't handle categorical data. Any
leads/ideas would be greatly appreciated.

Thanks a lot.

	[[alternative HTML version deleted]]


From Theodore@St@nkow|ch @end|ng |rom c@u|b@edu  Thu Jun  4 19:56:22 2020
From: Theodore@St@nkow|ch @end|ng |rom c@u|b@edu (Ted Stankowich)
Date: Thu, 4 Jun 2020 17:56:22 +0000
Subject: [R] na.omit not omitting rows
Message-ID: <BY5PR12MB4180725C3336C0C4CC5E4E4FF6890@BY5PR12MB4180.namprd12.prod.outlook.com>

Hello! I'm trying to create a subset of a dataset and then remove all rows with NAs in them. Ultimately, I am running phylogenetic analyses with trees that require the tree tiplabels to match exactly with the rows in the dataframe. But when I use na.omit to delete the rows with NAs, there is still a trace of those omitted rows in the data.frame, which then causes an error in the phylogenetic analyses. Is there any way to completely scrub those omitted rows from the dataframe? The code is below. As you can see from the result of the final str(Protect1) line, there are attributes with the omitted features still in the dataframe (356 species names in the UphamComplBinomial factor, but only 319 observations). These traces are causing errors with the phylo analyses.

> Protect1=as.data.frame(cbind(UphamComplBinomial, DarkEum, NoctCrep, Shade))  #Create the dataframe with variables of interest from an attached dataset
> row.names(Protect1)=Protect1$UphamComplBinomial #assign species names as rownames
> Protect1=as.data.frame(na.omit(Protect1)) #drop rows with missing data
> str(Protect1)
'data.frame': 319 obs. of  4 variables:
 $ UphamComplBinomial: Factor w/ 356 levels "Allenopithecus_nigroviridis_CERCOPITHECIDAE_PRIMATES",..: 1 2 3 4 5 8 9 10 11 12 ...
 $ DarkEum           : Factor w/ 2 levels "0","1": 2 1 2 2 2 2 2 2 2 2 ...
 $ NoctCrep          : Factor w/ 2 levels "0","1": 1 2 1 1 1 1 1 1 1 1 ...
 $ Shade             : Factor w/ 59 levels "0.1","0.2","0.25",..: 10 58 53 17 49 52 52 39 39 41 ...
 - attr(*, "na.action")= 'omit' Named int  6 7 23 36 37 40 42 50 51 60 ...
  ..- attr(*, "names")= chr  "Alouatta_macconnelli_ATELIDAE_PRIMATES" "Alouatta_nigerrima_ATELIDAE_PRIMATES" "Ateles_fusciceps_ATELIDAE_PRIMATES" "Callicebus_baptista_PITHECIIDAE_PRIMATES" ...

Dr. Ted Stankowich
Associate Professor
Department of Biological Sciences
California State University Long Beach
Long Beach, CA 90840
theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.edu>
562-985-4826
http://www.csulb.edu/mammal-lab/
@CSULBMammalLab




	[[alternative HTML version deleted]]


From wdun|@p @end|ng |rom t|bco@com  Thu Jun  4 21:38:45 2020
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Thu, 4 Jun 2020 12:38:45 -0700
Subject: [R] na.omit not omitting rows
In-Reply-To: <BY5PR12MB4180725C3336C0C4CC5E4E4FF6890@BY5PR12MB4180.namprd12.prod.outlook.com>
References: <BY5PR12MB4180725C3336C0C4CC5E4E4FF6890@BY5PR12MB4180.namprd12.prod.outlook.com>
Message-ID: <CAF8bMcakgSRqp5Mdn6257eO4Z-5_kGr9L3=hS20UfZSoD+Cu+A@mail.gmail.com>

Does droplevels() help?

> d <- data.frame(size = factor(c("S","M","M","L","L"),
levels=c("S","M","L")), id=c(101,NA,NA,104,105))
> str(d)
'data.frame':   5 obs. of  2 variables:
 $ size: Factor w/ 3 levels "S","M","L": 1 2 2 3 3
 $ id  : num  101 NA NA 104 105
> str(na.omit(d))
'data.frame':   3 obs. of  2 variables:
 $ size: Factor w/ 3 levels "S","M","L": 1 3 3
 $ id  : num  101 104 105
 - attr(*, "na.action")= 'omit' Named int [1:2] 2 3
  ..- attr(*, "names")= chr [1:2] "2" "3"
> str(droplevels(na.omit(d)))
'data.frame':   3 obs. of  2 variables:
 $ size: Factor w/ 2 levels "S","L": 1 2 2
 $ id  : num  101 104 105
 - attr(*, "na.action")= 'omit' Named int [1:2] 2 3
  ..- attr(*, "names")= chr [1:2] "2" "3"

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Jun 4, 2020 at 12:18 PM Ted Stankowich <
Theodore.Stankowich at csulb.edu> wrote:

> Hello! I'm trying to create a subset of a dataset and then remove all rows
> with NAs in them. Ultimately, I am running phylogenetic analyses with trees
> that require the tree tiplabels to match exactly with the rows in the
> dataframe. But when I use na.omit to delete the rows with NAs, there is
> still a trace of those omitted rows in the data.frame, which then causes an
> error in the phylogenetic analyses. Is there any way to completely scrub
> those omitted rows from the dataframe? The code is below. As you can see
> from the result of the final str(Protect1) line, there are attributes with
> the omitted features still in the dataframe (356 species names in the
> UphamComplBinomial factor, but only 319 observations). These traces are
> causing errors with the phylo analyses.
>
> > Protect1=as.data.frame(cbind(UphamComplBinomial, DarkEum, NoctCrep,
> Shade))  #Create the dataframe with variables of interest from an attached
> dataset
> > row.names(Protect1)=Protect1$UphamComplBinomial #assign species names as
> rownames
> > Protect1=as.data.frame(na.omit(Protect1)) #drop rows with missing data
> > str(Protect1)
> 'data.frame': 319 obs. of  4 variables:
>  $ UphamComplBinomial: Factor w/ 356 levels
> "Allenopithecus_nigroviridis_CERCOPITHECIDAE_PRIMATES",..: 1 2 3 4 5 8 9 10
> 11 12 ...
>  $ DarkEum           : Factor w/ 2 levels "0","1": 2 1 2 2 2 2 2 2 2 2 ...
>  $ NoctCrep          : Factor w/ 2 levels "0","1": 1 2 1 1 1 1 1 1 1 1 ...
>  $ Shade             : Factor w/ 59 levels "0.1","0.2","0.25",..: 10 58 53
> 17 49 52 52 39 39 41 ...
>  - attr(*, "na.action")= 'omit' Named int  6 7 23 36 37 40 42 50 51 60 ...
>   ..- attr(*, "names")= chr  "Alouatta_macconnelli_ATELIDAE_PRIMATES"
> "Alouatta_nigerrima_ATELIDAE_PRIMATES" "Ateles_fusciceps_ATELIDAE_PRIMATES"
> "Callicebus_baptista_PITHECIIDAE_PRIMATES" ...
>
> Dr. Ted Stankowich
> Associate Professor
> Department of Biological Sciences
> California State University Long Beach
> Long Beach, CA 90840
> theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.edu>
> 562-985-4826
> http://www.csulb.edu/mammal-lab/
> @CSULBMammalLab
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Jun  4 22:07:16 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 4 Jun 2020 13:07:16 -0700
Subject: [R] GLM model with spatialspillover on categorical variables
In-Reply-To: <CA+yGT=FjdTETUQ8hs=uSM0=4B6LQdWRZVfuk4iWP12OYhsTeZA@mail.gmail.com>
References: <CA+yGT=FjdTETUQ8hs=uSM0=4B6LQdWRZVfuk4iWP12OYhsTeZA@mail.gmail.com>
Message-ID: <CAGxFJbR3b-k-heaQPfSq4eRa1znRP8ctFys=j-FT_sEYiKQKMw@mail.gmail.com>

You should post on r-sig-geo, the list devoted to spatial data analysis,
rather than here.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 4, 2020 at 12:17 PM Lena Fehlhaber <sturmiechen at gmail.com>
wrote:

> I did a regression analysis with categorical data with a glm model
> approach, which worked fine. I have longitude and latitude coordinates for
> each observation and I want to add their geographic spillover effect to the
> model.
>
> My sample data is structured:
>
> Index DV IVI IVII IVIII IVIV Long Lat
>  1  0  2  1  3  -12  -17.8  12
>  2  0  1  1  6  112  11  -122
>  3  1  3  6  1  91  57  53
>
> with regression eq. DV ~ IVI + IVII + IVIII + IVIV
>
> That mentioned, I assume that the nearer regions are, the more it may
> influence my dependant variable. I found several approaches for spatial
> regression models, but not for categorical data. I tried to use existing
> libraries and functions, such as spdep's lagsarlm, glmmfields, spatialreg,
> gstat, geoRglm and many more (I used this list as a reference:
> https://cran.r-project.org/web/views/Spatial.html ). For numeric values, I
> am able to do spatial regression, but for categorical values, I struggle.
> The data structure is the following:
>
> library(dplyr)
> data <- data %>%
>   mutate(
>     DV = as.factor(DV),
>     IVI = as.factor(IVI),
>     IVII = as.factor(IVII),
>     IVIII = as.factor(IVIII),
>     IVIV = as.numeric(IVIV),
>     longitude = as.numeric(longitude),
>     latitude = as.numeric(latitude)
>   )
>
> My dependant variable (0|1) as well as my independant variables are
> categorical and it would be no use to transform them, of course. I want to
> have an other glm model in the end, but with spatial spillover effects
> included. The libraries I tested so far can't handle categorical data. Any
> leads/ideas would be greatly appreciated.
>
> Thanks a lot.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Theodore@St@nkow|ch @end|ng |rom c@u|b@edu  Thu Jun  4 23:27:18 2020
From: Theodore@St@nkow|ch @end|ng |rom c@u|b@edu (Ted Stankowich)
Date: Thu, 4 Jun 2020 21:27:18 +0000
Subject: [R] na.omit not omitting rows
In-Reply-To: <CAF8bMcakgSRqp5Mdn6257eO4Z-5_kGr9L3=hS20UfZSoD+Cu+A@mail.gmail.com>
References: <BY5PR12MB4180725C3336C0C4CC5E4E4FF6890@BY5PR12MB4180.namprd12.prod.outlook.com>
 <CAF8bMcakgSRqp5Mdn6257eO4Z-5_kGr9L3=hS20UfZSoD+Cu+A@mail.gmail.com>
Message-ID: <BY5PR12MB4180ACC66C425D595CB1D9E1F6890@BY5PR12MB4180.namprd12.prod.outlook.com>

Thanks, but no that doesn?t work. The na.omit attributes are still in the dataframe, which you can see in the str outputs from the post. The problem line is likely:  - attr(*, "na.action")= 'omit' Named int [1:2] 2 3

From: William Dunlap [mailto:wdunlap at tibco.com]
Sent: Thursday, June 4, 2020 12:39 PM
To: Ted Stankowich <Theodore.Stankowich at csulb.edu>
Cc: r-help at r-project.org
Subject: Re: [R] na.omit not omitting rows

CAUTION: This email was sent from an external source. Use caution when replying, opening links or attachments.

Does droplevels() help?

> d <- data.frame(size = factor(c("S","M","M","L","L"), levels=c("S","M","L")), id=c(101,NA,NA,104,105))
> str(d)
'data.frame':   5 obs. of  2 variables:
 $ size: Factor w/ 3 levels "S","M","L": 1 2 2 3 3
 $ id  : num  101 NA NA 104 105
> str(na.omit(d))
'data.frame':   3 obs. of  2 variables:
 $ size: Factor w/ 3 levels "S","M","L": 1 3 3
 $ id  : num  101 104 105
 - attr(*, "na.action")= 'omit' Named int [1:2] 2 3
  ..- attr(*, "names")= chr [1:2] "2" "3"
> str(droplevels(na.omit(d)))
'data.frame':   3 obs. of  2 variables:
 $ size: Factor w/ 2 levels "S","L": 1 2 2
 $ id  : num  101 104 105
 - attr(*, "na.action")= 'omit' Named int [1:2] 2 3
  ..- attr(*, "names")= chr [1:2] "2" "3"

Bill Dunlap
TIBCO Software
wdunlap tibco.com<http://tibco.com>


On Thu, Jun 4, 2020 at 12:18 PM Ted Stankowich <Theodore.Stankowich at csulb.edu<mailto:Theodore.Stankowich at csulb.edu>> wrote:
Hello! I'm trying to create a subset of a dataset and then remove all rows with NAs in them. Ultimately, I am running phylogenetic analyses with trees that require the tree tiplabels to match exactly with the rows in the dataframe. But when I use na.omit to delete the rows with NAs, there is still a trace of those omitted rows in the data.frame, which then causes an error in the phylogenetic analyses. Is there any way to completely scrub those omitted rows from the dataframe? The code is below. As you can see from the result of the final str(Protect1) line, there are attributes with the omitted features still in the dataframe (356 species names in the UphamComplBinomial factor, but only 319 observations). These traces are causing errors with the phylo analyses.

> Protect1=as.data.frame(cbind(UphamComplBinomial, DarkEum, NoctCrep, Shade))  #Create the dataframe with variables of interest from an attached dataset
> row.names(Protect1)=Protect1$UphamComplBinomial #assign species names as rownames
> Protect1=as.data.frame(na.omit(Protect1)) #drop rows with missing data
> str(Protect1)
'data.frame': 319 obs. of  4 variables:
 $ UphamComplBinomial: Factor w/ 356 levels "Allenopithecus_nigroviridis_CERCOPITHECIDAE_PRIMATES",..: 1 2 3 4 5 8 9 10 11 12 ...
 $ DarkEum           : Factor w/ 2 levels "0","1": 2 1 2 2 2 2 2 2 2 2 ...
 $ NoctCrep          : Factor w/ 2 levels "0","1": 1 2 1 1 1 1 1 1 1 1 ...
 $ Shade             : Factor w/ 59 levels "0.1","0.2","0.25",..: 10 58 53 17 49 52 52 39 39 41 ...
 - attr(*, "na.action")= 'omit' Named int  6 7 23 36 37 40 42 50 51 60 ...
  ..- attr(*, "names")= chr  "Alouatta_macconnelli_ATELIDAE_PRIMATES" "Alouatta_nigerrima_ATELIDAE_PRIMATES" "Ateles_fusciceps_ATELIDAE_PRIMATES" "Callicebus_baptista_PITHECIIDAE_PRIMATES" ...

Dr. Ted Stankowich
Associate Professor
Department of Biological Sciences
California State University Long Beach
Long Beach, CA 90840
theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.edu><mailto:theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.edu>>
562-985-4826
http://www.csulb.edu/mammal-lab/
@CSULBMammalLab




        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Jun  4 23:49:22 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 4 Jun 2020 22:49:22 +0100
Subject: [R] na.omit not omitting rows
In-Reply-To: <BY5PR12MB4180ACC66C425D595CB1D9E1F6890@BY5PR12MB4180.namprd12.prod.outlook.com>
References: <BY5PR12MB4180725C3336C0C4CC5E4E4FF6890@BY5PR12MB4180.namprd12.prod.outlook.com>
 <CAF8bMcakgSRqp5Mdn6257eO4Z-5_kGr9L3=hS20UfZSoD+Cu+A@mail.gmail.com>
 <BY5PR12MB4180ACC66C425D595CB1D9E1F6890@BY5PR12MB4180.namprd12.prod.outlook.com>
Message-ID: <3f5abbbd-cb19-4ef2-11fb-6b0373b95d00@sapo.pt>

Hello,

If the problem is the "na.action" attribute, here are two ways of 
solving it.

First, an example data set.

set.seed(2020)    # Make the example reproducible
phamComplBinomial <- sprintf("f%003d", 1:356)
is.na(UphamComplBinomial) <- sample(356, 37)
DarkEum <- factor(sample(1:2, 356, TRUE))
Protect1 <- data.frame(UphamComplBinomial = factor(UphamComplBinomial), 
DarkEum)


1. Setting the attribute "na.action" to NULL removes it

Protect2 <- na.omit(Protect1)
attributes(Protect2)
attr(Protect2, "na.action") <- NULL
attributes(Protect2)


2. Use an index vector to subset the data

na <- is.na(Protect1$UphamComplBinomial)
Protect3 <- Protect1[!na, ]


The results are identical. But if you have more than one column with 
NA's, this second way will be more complicated.

identical(Protect2, Protect3)
#[1] TRUE


Hope this helps,

Rui Barradas

?s 22:27 de 04/06/20, Ted Stankowich escreveu:
> Thanks, but no that doesn?t work. The na.omit attributes are still in the dataframe, which you can see in the str outputs from the post. The problem line is likely:  - attr(*, "na.action")= 'omit' Named int [1:2] 2 3
> 
> From: William Dunlap [mailto:wdunlap at tibco.com]
> Sent: Thursday, June 4, 2020 12:39 PM
> To: Ted Stankowich <Theodore.Stankowich at csulb.edu>
> Cc: r-help at r-project.org
> Subject: Re: [R] na.omit not omitting rows
> 
> CAUTION: This email was sent from an external source. Use caution when replying, opening links or attachments.
> 
> Does droplevels() help?
> 
>> d <- data.frame(size = factor(c("S","M","M","L","L"), levels=c("S","M","L")), id=c(101,NA,NA,104,105))
>> str(d)
> 'data.frame':   5 obs. of  2 variables:
>   $ size: Factor w/ 3 levels "S","M","L": 1 2 2 3 3
>   $ id  : num  101 NA NA 104 105
>> str(na.omit(d))
> 'data.frame':   3 obs. of  2 variables:
>   $ size: Factor w/ 3 levels "S","M","L": 1 3 3
>   $ id  : num  101 104 105
>   - attr(*, "na.action")= 'omit' Named int [1:2] 2 3
>    ..- attr(*, "names")= chr [1:2] "2" "3"
>> str(droplevels(na.omit(d)))
> 'data.frame':   3 obs. of  2 variables:
>   $ size: Factor w/ 2 levels "S","L": 1 2 2
>   $ id  : num  101 104 105
>   - attr(*, "na.action")= 'omit' Named int [1:2] 2 3
>    ..- attr(*, "names")= chr [1:2] "2" "3"
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com<http://tibco.com>
> 
> 
> On Thu, Jun 4, 2020 at 12:18 PM Ted Stankowich <Theodore.Stankowich at csulb.edu<mailto:Theodore.Stankowich at csulb.edu>> wrote:
> Hello! I'm trying to create a subset of a dataset and then remove all rows with NAs in them. Ultimately, I am running phylogenetic analyses with trees that require the tree tiplabels to match exactly with the rows in the dataframe. But when I use na.omit to delete the rows with NAs, there is still a trace of those omitted rows in the data.frame, which then causes an error in the phylogenetic analyses. Is there any way to completely scrub those omitted rows from the dataframe? The code is below. As you can see from the result of the final str(Protect1) line, there are attributes with the omitted features still in the dataframe (356 species names in the UphamComplBinomial factor, but only 319 observations). These traces are causing errors with the phylo analyses.
> 
>> Protect1=as.data.frame(cbind(UphamComplBinomial, DarkEum, NoctCrep, Shade))  #Create the dataframe with variables of interest from an attached dataset
>> row.names(Protect1)=Protect1$UphamComplBinomial #assign species names as rownames
>> Protect1=as.data.frame(na.omit(Protect1)) #drop rows with missing data
>> str(Protect1)
> 'data.frame': 319 obs. of  4 variables:
>   $ UphamComplBinomial: Factor w/ 356 levels "Allenopithecus_nigroviridis_CERCOPITHECIDAE_PRIMATES",..: 1 2 3 4 5 8 9 10 11 12 ...
>   $ DarkEum           : Factor w/ 2 levels "0","1": 2 1 2 2 2 2 2 2 2 2 ...
>   $ NoctCrep          : Factor w/ 2 levels "0","1": 1 2 1 1 1 1 1 1 1 1 ...
>   $ Shade             : Factor w/ 59 levels "0.1","0.2","0.25",..: 10 58 53 17 49 52 52 39 39 41 ...
>   - attr(*, "na.action")= 'omit' Named int  6 7 23 36 37 40 42 50 51 60 ...
>    ..- attr(*, "names")= chr  "Alouatta_macconnelli_ATELIDAE_PRIMATES" "Alouatta_nigerrima_ATELIDAE_PRIMATES" "Ateles_fusciceps_ATELIDAE_PRIMATES" "Callicebus_baptista_PITHECIIDAE_PRIMATES" ...
> 
> Dr. Ted Stankowich
> Associate Professor
> Department of Biological Sciences
> California State University Long Beach
> Long Beach, CA 90840
> theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.edu><mailto:theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.edu>>
> 562-985-4826
> http://www.csulb.edu/mammal-lab/
> @CSULBMammalLab
> 
> 
> 
> 
>          [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jun  4 21:50:03 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 04 Jun 2020 12:50:03 -0700
Subject: [R] ask help for ggplot
In-Reply-To: <CALn2QVh5R8C1qH5kLkzwmvXg9mECg=41wUdV+j9Nkv2o-NVd1g@mail.gmail.com>
References: <CALn2QVh5R8C1qH5kLkzwmvXg9mECg=41wUdV+j9Nkv2o-NVd1g@mail.gmail.com>
Message-ID: <07E94869-7EAA-40BB-A591-C07DDEAA3EB0@dcn.davis.ca.us>

Better read the Posting Guide mentioned in the footer of this and every email on this list. Attachments can only be among a very few file types and still be passed through... yours did not.

As for your question, it is very likely that the answer is yes, though since this list is about the R language rather than specifics of contributed packages ... ggplot-specific questions are technically not in scope (though if you show a good reproducible example someone might respond anyway).

On June 3, 2020 8:17:23 PM PDT, Aimin Yan <aimin.at.work at gmail.com> wrote:
>I have a question about using ggplot.
>
>Is there possible to generate a barplot like the attached file using
>ggplot?
>
>Thank you,
>
>Aimin
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From Theodore@St@nkow|ch @end|ng |rom c@u|b@edu  Fri Jun  5 00:35:51 2020
From: Theodore@St@nkow|ch @end|ng |rom c@u|b@edu (Ted Stankowich)
Date: Thu, 4 Jun 2020 22:35:51 +0000
Subject: [R] na.omit not omitting rows
In-Reply-To: <3f5abbbd-cb19-4ef2-11fb-6b0373b95d00@sapo.pt>
References: <BY5PR12MB4180725C3336C0C4CC5E4E4FF6890@BY5PR12MB4180.namprd12.prod.outlook.com>
 <CAF8bMcakgSRqp5Mdn6257eO4Z-5_kGr9L3=hS20UfZSoD+Cu+A@mail.gmail.com>
 <BY5PR12MB4180ACC66C425D595CB1D9E1F6890@BY5PR12MB4180.namprd12.prod.outlook.com>
 <3f5abbbd-cb19-4ef2-11fb-6b0373b95d00@sapo.pt>
Message-ID: <BY5PR12MB41800FBD1253B440FC0AA540F6890@BY5PR12MB4180.namprd12.prod.outlook.com>

This worked! Thank you!

-----Original Message-----
From: Rui Barradas [mailto:ruipbarradas at sapo.pt] 
Sent: Thursday, June 4, 2020 2:49 PM
To: Ted Stankowich <Theodore.Stankowich at csulb.edu>; William Dunlap <wdunlap at tibco.com>
Cc: r-help at r-project.org
Subject: Re: [R] na.omit not omitting rows

CAUTION: This email was sent from an external source. Use caution when replying, opening links or attachments.


Hello,

If the problem is the "na.action" attribute, here are two ways of solving it.

First, an example data set.

set.seed(2020)    # Make the example reproducible
phamComplBinomial <- sprintf("f%003d", 1:356)
is.na(UphamComplBinomial) <- sample(356, 37) DarkEum <- factor(sample(1:2, 356, TRUE))
Protect1 <- data.frame(UphamComplBinomial = factor(UphamComplBinomial),
DarkEum)


1. Setting the attribute "na.action" to NULL removes it

Protect2 <- na.omit(Protect1)
attributes(Protect2)
attr(Protect2, "na.action") <- NULL
attributes(Protect2)


2. Use an index vector to subset the data

na <- is.na(Protect1$UphamComplBinomial)
Protect3 <- Protect1[!na, ]


The results are identical. But if you have more than one column with NA's, this second way will be more complicated.

identical(Protect2, Protect3)
#[1] TRUE


Hope this helps,

Rui Barradas

?s 22:27 de 04/06/20, Ted Stankowich escreveu:
> Thanks, but no that doesn?t work. The na.omit attributes are still in 
> the dataframe, which you can see in the str outputs from the post. The 
> problem line is likely:  - attr(*, "na.action")= 'omit' Named int 
> [1:2] 2 3
>
> From: William Dunlap [mailto:wdunlap at tibco.com]
> Sent: Thursday, June 4, 2020 12:39 PM
> To: Ted Stankowich <Theodore.Stankowich at csulb.edu>
> Cc: r-help at r-project.org
> Subject: Re: [R] na.omit not omitting rows
>
> CAUTION: This email was sent from an external source. Use caution when replying, opening links or attachments.
>
> Does droplevels() help?
>
>> d <- data.frame(size = factor(c("S","M","M","L","L"), 
>> levels=c("S","M","L")), id=c(101,NA,NA,104,105))
>> str(d)
> 'data.frame':   5 obs. of  2 variables:
>   $ size: Factor w/ 3 levels "S","M","L": 1 2 2 3 3
>   $ id  : num  101 NA NA 104 105
>> str(na.omit(d))
> 'data.frame':   3 obs. of  2 variables:
>   $ size: Factor w/ 3 levels "S","M","L": 1 3 3
>   $ id  : num  101 104 105
>   - attr(*, "na.action")= 'omit' Named int [1:2] 2 3
>    ..- attr(*, "names")= chr [1:2] "2" "3"
>> str(droplevels(na.omit(d)))
> 'data.frame':   3 obs. of  2 variables:
>   $ size: Factor w/ 2 levels "S","L": 1 2 2
>   $ id  : num  101 104 105
>   - attr(*, "na.action")= 'omit' Named int [1:2] 2 3
>    ..- attr(*, "names")= chr [1:2] "2" "3"
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com<http://tibco.com>
>
>
> On Thu, Jun 4, 2020 at 12:18 PM Ted Stankowich <Theodore.Stankowich at csulb.edu<mailto:Theodore.Stankowich at csulb.edu>> wrote:
> Hello! I'm trying to create a subset of a dataset and then remove all rows with NAs in them. Ultimately, I am running phylogenetic analyses with trees that require the tree tiplabels to match exactly with the rows in the dataframe. But when I use na.omit to delete the rows with NAs, there is still a trace of those omitted rows in the data.frame, which then causes an error in the phylogenetic analyses. Is there any way to completely scrub those omitted rows from the dataframe? The code is below. As you can see from the result of the final str(Protect1) line, there are attributes with the omitted features still in the dataframe (356 species names in the UphamComplBinomial factor, but only 319 observations). These traces are causing errors with the phylo analyses.
>
>> Protect1=as.data.frame(cbind(UphamComplBinomial, DarkEum, NoctCrep, 
>> Shade))  #Create the dataframe with variables of interest from an 
>> attached dataset row.names(Protect1)=Protect1$UphamComplBinomial 
>> #assign species names as rownames
>> Protect1=as.data.frame(na.omit(Protect1)) #drop rows with missing 
>> data
>> str(Protect1)
> 'data.frame': 319 obs. of  4 variables:
>   $ UphamComplBinomial: Factor w/ 356 levels "Allenopithecus_nigroviridis_CERCOPITHECIDAE_PRIMATES",..: 1 2 3 4 5 8 9 10 11 12 ...
>   $ DarkEum           : Factor w/ 2 levels "0","1": 2 1 2 2 2 2 2 2 2 2 ...
>   $ NoctCrep          : Factor w/ 2 levels "0","1": 1 2 1 1 1 1 1 1 1 1 ...
>   $ Shade             : Factor w/ 59 levels "0.1","0.2","0.25",..: 10 58 53 17 49 52 52 39 39 41 ...
>   - attr(*, "na.action")= 'omit' Named int  6 7 23 36 37 40 42 50 51 60 ...
>    ..- attr(*, "names")= chr  "Alouatta_macconnelli_ATELIDAE_PRIMATES" "Alouatta_nigerrima_ATELIDAE_PRIMATES" "Ateles_fusciceps_ATELIDAE_PRIMATES" "Callicebus_baptista_PITHECIIDAE_PRIMATES" ...
>
> Dr. Ted Stankowich
> Associate Professor
> Department of Biological Sciences
> California State University Long Beach Long Beach, CA 90840 
> theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.edu><ma
> ilto:theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.ed
> u>>
> 562-985-4826
> http://www.csulb.edu/mammal-lab/
> @CSULBMammalLab
>
>
>
>
>          [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To 
> UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Jun  5 02:01:31 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Thu, 4 Jun 2020 17:01:31 -0700
Subject: [R] na.omit not omitting rows
In-Reply-To: <BY5PR12MB41800FBD1253B440FC0AA540F6890@BY5PR12MB4180.namprd12.prod.outlook.com>
References: <BY5PR12MB41800FBD1253B440FC0AA540F6890@BY5PR12MB4180.namprd12.prod.outlook.com>
Message-ID: <215D5057-E4B3-46C4-9FBE-04B659CFC830@comcast.net>

Perhaps indexing with rowSums(is.na(dfrm))?

? 
David

Sent from my iPhone

> On Jun 4, 2020, at 4:58 PM, Ted Stankowich <Theodore.Stankowich at csulb.edu> wrote:
> 
> ?This worked! Thank you!
> 
> -----Original Message-----
> From: Rui Barradas [mailto:ruipbarradas at sapo.pt] 
> Sent: Thursday, June 4, 2020 2:49 PM
> To: Ted Stankowich <Theodore.Stankowich at csulb.edu>; William Dunlap <wdunlap at tibco.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] na.omit not omitting rows
> 
> CAUTION: This email was sent from an external source. Use caution when replying, opening links or attachments.
> 
> 
> Hello,
> 
> If the problem is the "na.action" attribute, here are two ways of solving it.
> 
> First, an example data set.
> 
> set.seed(2020)    # Make the example reproducible
> phamComplBinomial <- sprintf("f%003d", 1:356)
> is.na(UphamComplBinomial) <- sample(356, 37) DarkEum <- factor(sample(1:2, 356, TRUE))
> Protect1 <- data.frame(UphamComplBinomial = factor(UphamComplBinomial),
> DarkEum)
> 
> 
> 1. Setting the attribute "na.action" to NULL removes it
> 
> Protect2 <- na.omit(Protect1)
> attributes(Protect2)
> attr(Protect2, "na.action") <- NULL
> attributes(Protect2)
> 
> 
> 2. Use an index vector to subset the data
> 
> na <- is.na(Protect1$UphamComplBinomial)
> Protect3 <- Protect1[!na, ]
> 
> 
> The results are identical. But if you have more than one column with NA's, this second way will be more complicated.
> 
> identical(Protect2, Protect3)
> #[1] TRUE
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 22:27 de 04/06/20, Ted Stankowich escreveu:
>> Thanks, but no that doesn?t work. The na.omit attributes are still in 
>> the dataframe, which you can see in the str outputs from the post. The 
>> problem line is likely:  - attr(*, "na.action")= 'omit' Named int 
>> [1:2] 2 3
>> 
>> From: William Dunlap [mailto:wdunlap at tibco.com]
>> Sent: Thursday, June 4, 2020 12:39 PM
>> To: Ted Stankowich <Theodore.Stankowich at csulb.edu>
>> Cc: r-help at r-project.org
>> Subject: Re: [R] na.omit not omitting rows
>> 
>> CAUTION: This email was sent from an external source. Use caution when replying, opening links or attachments.
>> 
>> Does droplevels() help?
>> 
>>> d <- data.frame(size = factor(c("S","M","M","L","L"), 
>>> levels=c("S","M","L")), id=c(101,NA,NA,104,105))
>>> str(d)
>> 'data.frame':   5 obs. of  2 variables:
>>  $ size: Factor w/ 3 levels "S","M","L": 1 2 2 3 3
>>  $ id  : num  101 NA NA 104 105
>>> str(na.omit(d))
>> 'data.frame':   3 obs. of  2 variables:
>>  $ size: Factor w/ 3 levels "S","M","L": 1 3 3
>>  $ id  : num  101 104 105
>>  - attr(*, "na.action")= 'omit' Named int [1:2] 2 3
>>   ..- attr(*, "names")= chr [1:2] "2" "3"
>>> str(droplevels(na.omit(d)))
>> 'data.frame':   3 obs. of  2 variables:
>>  $ size: Factor w/ 2 levels "S","L": 1 2 2
>>  $ id  : num  101 104 105
>>  - attr(*, "na.action")= 'omit' Named int [1:2] 2 3
>>   ..- attr(*, "names")= chr [1:2] "2" "3"
>> 
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com<http://tibco.com>
>> 
>> 
>> On Thu, Jun 4, 2020 at 12:18 PM Ted Stankowich <Theodore.Stankowich at csulb.edu<mailto:Theodore.Stankowich at csulb.edu>> wrote:
>> Hello! I'm trying to create a subset of a dataset and then remove all rows with NAs in them. Ultimately, I am running phylogenetic analyses with trees that require the tree tiplabels to match exactly with the rows in the dataframe. But when I use na.omit to delete the rows with NAs, there is still a trace of those omitted rows in the data.frame, which then causes an error in the phylogenetic analyses. Is there any way to completely scrub those omitted rows from the dataframe? The code is below. As you can see from the result of the final str(Protect1) line, there are attributes with the omitted features still in the dataframe (356 species names in the UphamComplBinomial factor, but only 319 observations). These traces are causing errors with the phylo analyses.
>> 
>>> Protect1=as.data.frame(cbind(UphamComplBinomial, DarkEum, NoctCrep, 
>>> Shade))  #Create the dataframe with variables of interest from an 
>>> attached dataset row.names(Protect1)=Protect1$UphamComplBinomial 
>>> #assign species names as rownames
>>> Protect1=as.data.frame(na.omit(Protect1)) #drop rows with missing 
>>> data
>>> str(Protect1)
>> 'data.frame': 319 obs. of  4 variables:
>>  $ UphamComplBinomial: Factor w/ 356 levels "Allenopithecus_nigroviridis_CERCOPITHECIDAE_PRIMATES",..: 1 2 3 4 5 8 9 10 11 12 ...
>>  $ DarkEum           : Factor w/ 2 levels "0","1": 2 1 2 2 2 2 2 2 2 2 ...
>>  $ NoctCrep          : Factor w/ 2 levels "0","1": 1 2 1 1 1 1 1 1 1 1 ...
>>  $ Shade             : Factor w/ 59 levels "0.1","0.2","0.25",..: 10 58 53 17 49 52 52 39 39 41 ...
>>  - attr(*, "na.action")= 'omit' Named int  6 7 23 36 37 40 42 50 51 60 ...
>>   ..- attr(*, "names")= chr  "Alouatta_macconnelli_ATELIDAE_PRIMATES" "Alouatta_nigerrima_ATELIDAE_PRIMATES" "Ateles_fusciceps_ATELIDAE_PRIMATES" "Callicebus_baptista_PITHECIIDAE_PRIMATES" ...
>> 
>> Dr. Ted Stankowich
>> Associate Professor
>> Department of Biological Sciences
>> California State University Long Beach Long Beach, CA 90840 
>> theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.edu><ma
>> ilto:theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.ed
>> u>>
>> 562-985-4826
>> http://www.csulb.edu/mammal-lab/
>> @CSULBMammalLab
>> 
>> 
>> 
>> 
>>         [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To 
>> UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>>      [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Theodore@St@nkow|ch @end|ng |rom c@u|b@edu  Fri Jun  5 03:03:13 2020
From: Theodore@St@nkow|ch @end|ng |rom c@u|b@edu (Ted Stankowich)
Date: Fri, 5 Jun 2020 01:03:13 +0000
Subject: [R] na.omit not omitting rows
In-Reply-To: <215D5057-E4B3-46C4-9FBE-04B659CFC830@comcast.net>
References: <BY5PR12MB41800FBD1253B440FC0AA540F6890@BY5PR12MB4180.namprd12.prod.outlook.com>
 <215D5057-E4B3-46C4-9FBE-04B659CFC830@comcast.net>
Message-ID: <BY5PR12MB4180515FEB50F998A68F37C4F6860@BY5PR12MB4180.namprd12.prod.outlook.com>

Thanks - a previous response resolved the issue and I'm off and running with the analyses. 

-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: Thursday, June 4, 2020 5:02 PM
To: Ted Stankowich <Theodore.Stankowich at csulb.edu>
Cc: Rui Barradas <ruipbarradas at sapo.pt>; William Dunlap <wdunlap at tibco.com>; r-help at r-project.org
Subject: Re: [R] na.omit not omitting rows

CAUTION: This email was sent from an external source. Use caution when replying, opening links or attachments.


Perhaps indexing with rowSums(is.na(dfrm))?

?
David

Sent from my iPhone

> On Jun 4, 2020, at 4:58 PM, Ted Stankowich <Theodore.Stankowich at csulb.edu> wrote:
>
> ?This worked! Thank you!
>
> -----Original Message-----
> From: Rui Barradas [mailto:ruipbarradas at sapo.pt]
> Sent: Thursday, June 4, 2020 2:49 PM
> To: Ted Stankowich <Theodore.Stankowich at csulb.edu>; William Dunlap 
> <wdunlap at tibco.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] na.omit not omitting rows
>
> CAUTION: This email was sent from an external source. Use caution when replying, opening links or attachments.
>
>
> Hello,
>
> If the problem is the "na.action" attribute, here are two ways of solving it.
>
> First, an example data set.
>
> set.seed(2020)    # Make the example reproducible
> phamComplBinomial <- sprintf("f%003d", 1:356)
> is.na(UphamComplBinomial) <- sample(356, 37) DarkEum <- 
> factor(sample(1:2, 356, TRUE))
> Protect1 <- data.frame(UphamComplBinomial = 
> factor(UphamComplBinomial),
> DarkEum)
>
>
> 1. Setting the attribute "na.action" to NULL removes it
>
> Protect2 <- na.omit(Protect1)
> attributes(Protect2)
> attr(Protect2, "na.action") <- NULL
> attributes(Protect2)
>
>
> 2. Use an index vector to subset the data
>
> na <- is.na(Protect1$UphamComplBinomial)
> Protect3 <- Protect1[!na, ]
>
>
> The results are identical. But if you have more than one column with NA's, this second way will be more complicated.
>
> identical(Protect2, Protect3)
> #[1] TRUE
>
>
> Hope this helps,
>
> Rui Barradas
>
> ?s 22:27 de 04/06/20, Ted Stankowich escreveu:
>> Thanks, but no that doesn?t work. The na.omit attributes are still in 
>> the dataframe, which you can see in the str outputs from the post. 
>> The problem line is likely:  - attr(*, "na.action")= 'omit' Named int 
>> [1:2] 2 3
>>
>> From: William Dunlap [mailto:wdunlap at tibco.com]
>> Sent: Thursday, June 4, 2020 12:39 PM
>> To: Ted Stankowich <Theodore.Stankowich at csulb.edu>
>> Cc: r-help at r-project.org
>> Subject: Re: [R] na.omit not omitting rows
>>
>> CAUTION: This email was sent from an external source. Use caution when replying, opening links or attachments.
>>
>> Does droplevels() help?
>>
>>> d <- data.frame(size = factor(c("S","M","M","L","L"), 
>>> levels=c("S","M","L")), id=c(101,NA,NA,104,105))
>>> str(d)
>> 'data.frame':   5 obs. of  2 variables:
>>  $ size: Factor w/ 3 levels "S","M","L": 1 2 2 3 3  $ id  : num  101 
>> NA NA 104 105
>>> str(na.omit(d))
>> 'data.frame':   3 obs. of  2 variables:
>>  $ size: Factor w/ 3 levels "S","M","L": 1 3 3  $ id  : num  101 104 
>> 105
>>  - attr(*, "na.action")= 'omit' Named int [1:2] 2 3
>>   ..- attr(*, "names")= chr [1:2] "2" "3"
>>> str(droplevels(na.omit(d)))
>> 'data.frame':   3 obs. of  2 variables:
>>  $ size: Factor w/ 2 levels "S","L": 1 2 2  $ id  : num  101 104 105
>>  - attr(*, "na.action")= 'omit' Named int [1:2] 2 3
>>   ..- attr(*, "names")= chr [1:2] "2" "3"
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com<http://tibco.com>
>>
>>
>> On Thu, Jun 4, 2020 at 12:18 PM Ted Stankowich <Theodore.Stankowich at csulb.edu<mailto:Theodore.Stankowich at csulb.edu>> wrote:
>> Hello! I'm trying to create a subset of a dataset and then remove all rows with NAs in them. Ultimately, I am running phylogenetic analyses with trees that require the tree tiplabels to match exactly with the rows in the dataframe. But when I use na.omit to delete the rows with NAs, there is still a trace of those omitted rows in the data.frame, which then causes an error in the phylogenetic analyses. Is there any way to completely scrub those omitted rows from the dataframe? The code is below. As you can see from the result of the final str(Protect1) line, there are attributes with the omitted features still in the dataframe (356 species names in the UphamComplBinomial factor, but only 319 observations). These traces are causing errors with the phylo analyses.
>>
>>> Protect1=as.data.frame(cbind(UphamComplBinomial, DarkEum, NoctCrep,
>>> Shade))  #Create the dataframe with variables of interest from an 
>>> attached dataset row.names(Protect1)=Protect1$UphamComplBinomial
>>> #assign species names as rownames
>>> Protect1=as.data.frame(na.omit(Protect1)) #drop rows with missing 
>>> data
>>> str(Protect1)
>> 'data.frame': 319 obs. of  4 variables:
>>  $ UphamComplBinomial: Factor w/ 356 levels "Allenopithecus_nigroviridis_CERCOPITHECIDAE_PRIMATES",..: 1 2 3 4 5 8 9 10 11 12 ...
>>  $ DarkEum           : Factor w/ 2 levels "0","1": 2 1 2 2 2 2 2 2 2 2 ...
>>  $ NoctCrep          : Factor w/ 2 levels "0","1": 1 2 1 1 1 1 1 1 1 1 ...
>>  $ Shade             : Factor w/ 59 levels "0.1","0.2","0.25",..: 10 58 53 17 49 52 52 39 39 41 ...
>>  - attr(*, "na.action")= 'omit' Named int  6 7 23 36 37 40 42 50 51 60 ...
>>   ..- attr(*, "names")= chr  "Alouatta_macconnelli_ATELIDAE_PRIMATES" "Alouatta_nigerrima_ATELIDAE_PRIMATES" "Ateles_fusciceps_ATELIDAE_PRIMATES" "Callicebus_baptista_PITHECIIDAE_PRIMATES" ...
>>
>> Dr. Ted Stankowich
>> Associate Professor
>> Department of Biological Sciences
>> California State University Long Beach Long Beach, CA 90840 
>> theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.edu><m
>> a 
>> ilto:theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.e
>> d
>> u>>
>> 562-985-4826
>> http://www.csulb.edu/mammal-lab/
>> @CSULBMammalLab
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To 
>> UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>      [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From er|nm@hodge@@ @end|ng |rom gm@||@com  Fri Jun  5 03:34:14 2020
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Thu, 4 Jun 2020 19:34:14 -0600
Subject: [R] confusion about write.csv
Message-ID: <CACxE24kQ6nd1R_Z9t9_u2QZ2idYKLDnRbe0P3cH0bbM4YtEy_A@mail.gmail.com>

 Hello!

Hope everyone is doing as well as possible.

I have a question about write.csv.  I thought that the append argument
would permit adding another data frame with the same column names.

Here is my example:

 date1 <- as.Date("2020-03-09")
 wday <- weekdays(date1)
 x1 <- data.frame(date=date1,day=wday,lev=1:5,y=rnorm(5))
 x1
        date    day lev           y
1 2020-03-09 Monday   1 -0.09543049
2 2020-03-09 Monday   2  0.53943428
3 2020-03-09 Monday   3 -0.79224851
4 2020-03-09 Monday   4  0.68168147
5 2020-03-09 Monday   5 -1.02902897
 write.csv(file="test1.csv",x1,row.names=FALSE)
 date1 <- date1 + 1
 wday <- weekdays(date1)
 x2 <- data.frame(date=date1,day=wday,lev=1:5,y=rnorm(5))
 x2
        date     day lev          y
1 2020-03-10 Tuesday   1 -0.6648301
2 2020-03-10 Tuesday   2 -0.1137580
3 2020-03-10 Tuesday   3  1.6532675
4 2020-03-10 Tuesday   4 -0.5845293
5 2020-03-10 Tuesday   5  0.2849392
 write.csv(file="test1.csv",x2,row.names=FALSE,append=TRUE)
Warning message:
In write.csv(file = "test1.csv", x2, row.names = FALSE, append = TRUE) :
  attempt to set 'append' ignored

The values from x2 appear in the test1.csv file.

What am I missing, please?

Thanks,
Erin


Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From er|nm@hodge@@ @end|ng |rom gm@||@com  Fri Jun  5 03:48:00 2020
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Thu, 4 Jun 2020 19:48:00 -0600
Subject: [R] Solved: confusion with write.csv
Message-ID: <CACxE24kvdzPK9=x7xn-iz63y0DvsZaWoFLrb3_zysR2zr01+og@mail.gmail.com>

Change over to write.table.

Sorry for the wasted bandwidth.

Thanks,
Erin

Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From m@rk|eed@2 @end|ng |rom gm@||@com  Fri Jun  5 03:48:34 2020
From: m@rk|eed@2 @end|ng |rom gm@||@com (Mark Leeds)
Date: Thu, 4 Jun 2020 21:48:34 -0400
Subject: [R] confusion about write.csv
In-Reply-To: <CACxE24kQ6nd1R_Z9t9_u2QZ2idYKLDnRbe0P3cH0bbM4YtEy_A@mail.gmail.com>
References: <CACxE24kQ6nd1R_Z9t9_u2QZ2idYKLDnRbe0P3cH0bbM4YtEy_A@mail.gmail.com>
Message-ID: <CAHz+bWaSab5numOVVbJ2JVcNeMeJ+2dKX22UMpv+nmO=mjC99w@mail.gmail.com>

Hi Erin: The default for write.csv is col.names = TRUE . So, in the second
one,
if you put, col.names = FALSE, that should work.  It's confused right now
because you want to append but also write the column names again.


Mark




On Thu, Jun 4, 2020 at 9:34 PM Erin Hodgess <erinm.hodgess at gmail.com> wrote:

>  Hello!
>
> Hope everyone is doing as well as possible.
>
> I have a question about write.csv.  I thought that the append argument
> would permit adding another data frame with the same column names.
>
> Here is my example:
>
>  date1 <- as.Date("2020-03-09")
>  wday <- weekdays(date1)
>  x1 <- data.frame(date=date1,day=wday,lev=1:5,y=rnorm(5))
>  x1
>         date    day lev           y
> 1 2020-03-09 Monday   1 -0.09543049
> 2 2020-03-09 Monday   2  0.53943428
> 3 2020-03-09 Monday   3 -0.79224851
> 4 2020-03-09 Monday   4  0.68168147
> 5 2020-03-09 Monday   5 -1.02902897
>  write.csv(file="test1.csv",x1,row.names=FALSE)
>  date1 <- date1 + 1
>  wday <- weekdays(date1)
>  x2 <- data.frame(date=date1,day=wday,lev=1:5,y=rnorm(5))
>  x2
>         date     day lev          y
> 1 2020-03-10 Tuesday   1 -0.6648301
> 2 2020-03-10 Tuesday   2 -0.1137580
> 3 2020-03-10 Tuesday   3  1.6532675
> 4 2020-03-10 Tuesday   4 -0.5845293
> 5 2020-03-10 Tuesday   5  0.2849392
>  write.csv(file="test1.csv",x2,row.names=FALSE,append=TRUE)
> Warning message:
> In write.csv(file = "test1.csv", x2, row.names = FALSE, append = TRUE) :
>   attempt to set 'append' ignored
>
> The values from x2 appear in the test1.csv file.
>
> What am I missing, please?
>
> Thanks,
> Erin
>
>
> Erin Hodgess, PhD
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Jun  5 03:56:45 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 04 Jun 2020 18:56:45 -0700
Subject: [R] confusion about write.csv
In-Reply-To: <CACxE24kQ6nd1R_Z9t9_u2QZ2idYKLDnRbe0P3cH0bbM4YtEy_A@mail.gmail.com>
References: <CACxE24kQ6nd1R_Z9t9_u2QZ2idYKLDnRbe0P3cH0bbM4YtEy_A@mail.gmail.com>
Message-ID: <4A8C1F82-474C-4458-B6C0-79990A830AC6@dcn.davis.ca.us>

Use write.table.

Write.csv follows a very specific definition for csv... one element of which is that it is not allowed to have a second header line after data lines. The only way for write.csv to enforce this is to disallow appending.

On June 4, 2020 6:34:14 PM PDT, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> Hello!
>
>Hope everyone is doing as well as possible.
>
>I have a question about write.csv.  I thought that the append argument
>would permit adding another data frame with the same column names.
>
>Here is my example:
>
> date1 <- as.Date("2020-03-09")
> wday <- weekdays(date1)
> x1 <- data.frame(date=date1,day=wday,lev=1:5,y=rnorm(5))
> x1
>        date    day lev           y
>1 2020-03-09 Monday   1 -0.09543049
>2 2020-03-09 Monday   2  0.53943428
>3 2020-03-09 Monday   3 -0.79224851
>4 2020-03-09 Monday   4  0.68168147
>5 2020-03-09 Monday   5 -1.02902897
> write.csv(file="test1.csv",x1,row.names=FALSE)
> date1 <- date1 + 1
> wday <- weekdays(date1)
> x2 <- data.frame(date=date1,day=wday,lev=1:5,y=rnorm(5))
> x2
>        date     day lev          y
>1 2020-03-10 Tuesday   1 -0.6648301
>2 2020-03-10 Tuesday   2 -0.1137580
>3 2020-03-10 Tuesday   3  1.6532675
>4 2020-03-10 Tuesday   4 -0.5845293
>5 2020-03-10 Tuesday   5  0.2849392
> write.csv(file="test1.csv",x2,row.names=FALSE,append=TRUE)
>Warning message:
>In write.csv(file = "test1.csv", x2, row.names = FALSE, append = TRUE)
>:
>  attempt to set 'append' ignored
>
>The values from x2 appear in the test1.csv file.
>
>What am I missing, please?
>
>Thanks,
>Erin
>
>
>Erin Hodgess, PhD
>mailto: erinm.hodgess at gmail.com
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Fri Jun  5 03:55:04 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 4 Jun 2020 18:55:04 -0700
Subject: [R] confusion about write.csv
In-Reply-To: <CACxE24kQ6nd1R_Z9t9_u2QZ2idYKLDnRbe0P3cH0bbM4YtEy_A@mail.gmail.com>
References: <CACxE24kQ6nd1R_Z9t9_u2QZ2idYKLDnRbe0P3cH0bbM4YtEy_A@mail.gmail.com>
Message-ID: <CAGxFJbSTt52oZ=eVQUAUHrdo8jwOa8HEhHQ5V64PNJs4y3GQ-Q@mail.gmail.com>

... :

"arguments to write.table: append, col.names, sep, dec and qmethod cannot
be altered."

The default is FALSE, so cannot be altered.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 4, 2020 at 6:34 PM Erin Hodgess <erinm.hodgess at gmail.com> wrote:

>  Hello!
>
> Hope everyone is doing as well as possible.
>
> I have a question about write.csv.  I thought that the append argument
> would permit adding another data frame with the same column names.
>
> Here is my example:
>
>  date1 <- as.Date("2020-03-09")
>  wday <- weekdays(date1)
>  x1 <- data.frame(date=date1,day=wday,lev=1:5,y=rnorm(5))
>  x1
>         date    day lev           y
> 1 2020-03-09 Monday   1 -0.09543049
> 2 2020-03-09 Monday   2  0.53943428
> 3 2020-03-09 Monday   3 -0.79224851
> 4 2020-03-09 Monday   4  0.68168147
> 5 2020-03-09 Monday   5 -1.02902897
>  write.csv(file="test1.csv",x1,row.names=FALSE)
>  date1 <- date1 + 1
>  wday <- weekdays(date1)
>  x2 <- data.frame(date=date1,day=wday,lev=1:5,y=rnorm(5))
>  x2
>         date     day lev          y
> 1 2020-03-10 Tuesday   1 -0.6648301
> 2 2020-03-10 Tuesday   2 -0.1137580
> 3 2020-03-10 Tuesday   3  1.6532675
> 4 2020-03-10 Tuesday   4 -0.5845293
> 5 2020-03-10 Tuesday   5  0.2849392
>  write.csv(file="test1.csv",x2,row.names=FALSE,append=TRUE)
> Warning message:
> In write.csv(file = "test1.csv", x2, row.names = FALSE, append = TRUE) :
>   attempt to set 'append' ignored
>
> The values from x2 appear in the test1.csv file.
>
> What am I missing, please?
>
> Thanks,
> Erin
>
>
> Erin Hodgess, PhD
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|nm@hodge@@ @end|ng |rom gm@||@com  Fri Jun  5 04:12:11 2020
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Thu, 4 Jun 2020 20:12:11 -0600
Subject: [R] confusion about write.csv
In-Reply-To: <4A8C1F82-474C-4458-B6C0-79990A830AC6@dcn.davis.ca.us>
References: <CACxE24kQ6nd1R_Z9t9_u2QZ2idYKLDnRbe0P3cH0bbM4YtEy_A@mail.gmail.com>
 <4A8C1F82-474C-4458-B6C0-79990A830AC6@dcn.davis.ca.us>
Message-ID: <CACxE24mo6S63xLJLfmLtA3iZDa4RvaNrs5woMieCoO29bYfUpw@mail.gmail.com>

Thanks to all for the help.

I found that write.table works nicely, with col.names = FALSE with append =
TRUE.

Sincerely,
Erin

Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com


On Thu, Jun 4, 2020 at 7:56 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Use write.table.
>
> Write.csv follows a very specific definition for csv... one element of
> which is that it is not allowed to have a second header line after data
> lines. The only way for write.csv to enforce this is to disallow appending.
>
> On June 4, 2020 6:34:14 PM PDT, Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
> > Hello!
> >
> >Hope everyone is doing as well as possible.
> >
> >I have a question about write.csv.  I thought that the append argument
> >would permit adding another data frame with the same column names.
> >
> >Here is my example:
> >
> > date1 <- as.Date("2020-03-09")
> > wday <- weekdays(date1)
> > x1 <- data.frame(date=date1,day=wday,lev=1:5,y=rnorm(5))
> > x1
> >        date    day lev           y
> >1 2020-03-09 Monday   1 -0.09543049
> >2 2020-03-09 Monday   2  0.53943428
> >3 2020-03-09 Monday   3 -0.79224851
> >4 2020-03-09 Monday   4  0.68168147
> >5 2020-03-09 Monday   5 -1.02902897
> > write.csv(file="test1.csv",x1,row.names=FALSE)
> > date1 <- date1 + 1
> > wday <- weekdays(date1)
> > x2 <- data.frame(date=date1,day=wday,lev=1:5,y=rnorm(5))
> > x2
> >        date     day lev          y
> >1 2020-03-10 Tuesday   1 -0.6648301
> >2 2020-03-10 Tuesday   2 -0.1137580
> >3 2020-03-10 Tuesday   3  1.6532675
> >4 2020-03-10 Tuesday   4 -0.5845293
> >5 2020-03-10 Tuesday   5  0.2849392
> > write.csv(file="test1.csv",x2,row.names=FALSE,append=TRUE)
> >Warning message:
> >In write.csv(file = "test1.csv", x2, row.names = FALSE, append = TRUE)
> >:
> >  attempt to set 'append' ignored
> >
> >The values from x2 appear in the test1.csv file.
> >
> >What am I missing, please?
> >
> >Thanks,
> >Erin
> >
> >
> >Erin Hodgess, PhD
> >mailto: erinm.hodgess at gmail.com
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From @|m|n@@t@work @end|ng |rom gm@||@com  Fri Jun  5 06:14:16 2020
From: @|m|n@@t@work @end|ng |rom gm@||@com (Aimin Yan)
Date: Fri, 5 Jun 2020 00:14:16 -0400
Subject: [R] ask help for ggplot
In-Reply-To: <07E94869-7EAA-40BB-A591-C07DDEAA3EB0@dcn.davis.ca.us>
References: <CALn2QVh5R8C1qH5kLkzwmvXg9mECg=41wUdV+j9Nkv2o-NVd1g@mail.gmail.com>
 <07E94869-7EAA-40BB-A591-C07DDEAA3EB0@dcn.davis.ca.us>
Message-ID: <CALn2QVj7P74vbqu7M2KyFtd=ueYJCT4UtSdboAE1jJLcdoohjQ@mail.gmail.com>

Is there possible to generate a barplot in the following link using ggplot?

https://photos.app.goo.gl/E3MC461dKaTZfHza9

here is what I did

library(ggplot2)

df <- read.csv(text=
"trt,gene,freq,cols
M6,ALDH16A1,100.0000000,red
M6,Others,0.0000000,lightgrey
M12,ALDH16A1,64.6638015,red
M12,GBE1,2.0074865,#4C00FF
M12,ZNF598,1.5832525,#004CFF
M12,CHMP6,1.3503397,#00E5FF
M12,C20orf27,1.2033828,#00FF4D
M12,NEGR1,0.9676972,#4DFF00
M12,TNFAIP6,0.9122418,#E6FF00
M12,ZSCAN25,0.7375572,#FFFF00
M12,BCL2,0.6848745,#FFDE59
M12,CBL,0.6765562,#FFE0B3
M12,Others,25.2128102,lightgrey
M18,ALDH16A1,42.4503581,red
M18,ATF2,2.2360682,#4C00FF
M18,DIAPH1,1.5256507,#004CFF
M18,SESTD1,1.2053805,#00E5FF
M18,TFCP2,1.1587958,#00FF4D
M18,SCAPER,1.1180341,#4DFF00
M18,CUX1,1.0306877,#E6FF00
M18,TEX10,0.9841030,#FFFF00
M18,C6orf89,0.9666337,#FFDE59
M18,PTTG1IP,0.9258720,#FFE0B3
M18,Others,46.3984161,lightgrey")

df$trt <- factor(df$trt,levels=unique(as.character(df$trt)))
df$gene <- factor(df$gene,levels = unique(as.character(df$gene)))

ggplot(df, aes(x=trt,y=freq, fill = gene))+geom_bar(stat = "identity",
width = 0.5,color="black") + theme(axis.text.x = element_text(angle = 45,
hjust = 1,size = 4))

df$cols is the color I want to use to label different gene in M6, M12,M18
as shown in Figure, and in each bar, the 'Others' of df$gene is always in
the bottom of bar in M6,M12,M18

Thank you

Aimin

	[[alternative HTML version deleted]]


From tcmu|g@| @end|ng |rom gm@||@com  Fri Jun  5 06:18:00 2020
From: tcmu|g@| @end|ng |rom gm@||@com (Charles Thuo)
Date: Fri, 5 Jun 2020 07:18:00 +0300
Subject: [R] how to add a calculated column into a data frame
Message-ID: <CAAJc=rPbEOfho+RefsFBv9NBc-yB_YfYUzEiZm+GuwHgNobYAQ@mail.gmail.com>

Dear  Sirs,

I have a data frame that has a column that shows the transaction date.

How do i add another column that  extracts the year of transaction from the
transaction date.

Charles

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Jun  5 07:38:31 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 04 Jun 2020 22:38:31 -0700
Subject: [R] how to add a calculated column into a data frame
In-Reply-To: <CAAJc=rPbEOfho+RefsFBv9NBc-yB_YfYUzEiZm+GuwHgNobYAQ@mail.gmail.com>
References: <CAAJc=rPbEOfho+RefsFBv9NBc-yB_YfYUzEiZm+GuwHgNobYAQ@mail.gmail.com>
Message-ID: <24C10DD2-48E5-457A-AA55-38B7B501A0E2@dcn.davis.ca.us>

This should get you started:

x <- "2009-03-21"
substr( x, 1, 4 )
y <- as.integer( substr( x, 1, 4 ) )
y

or

yy <- as.POSIXlt( x )$year + 1900
yy

RShowDoc( "R-intro" )

On June 4, 2020 9:18:00 PM PDT, Charles Thuo <tcmuigai at gmail.com> wrote:
>Dear  Sirs,
>
>I have a data frame that has a column that shows the transaction date.
>
>How do i add another column that  extracts the year of transaction from
>the
>transaction date.
>
>Charles
>
>	[[alternative HTML version deleted]]

Please post in plain text. It will get converted for you if you forget, and the quality of the automatic conversion can be awful.

>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From teotjunk @end|ng |rom hotm@||@com  Fri Jun  5 09:02:44 2020
From: teotjunk @end|ng |rom hotm@||@com (TJUN KIAT TEO)
Date: Fri, 5 Jun 2020 07:02:44 +0000
Subject: [R] Applying a function to dataframe column where the function
 value depends on the value of another column
Message-ID: <SG2PR03MB5103D5B625F973B3F2D975E9DF860@SG2PR03MB5103.apcprd03.prod.outlook.com>

Suppose I have a dataframe in this from

a b c
g 2 3
h 4 5
i 6 7

I want to apply a function to individual elements of column C where the function value depends on the value of column A

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Jun  5 09:13:57 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 05 Jun 2020 00:13:57 -0700
Subject: [R] Applying a function to dataframe column where the function
 value depends on the value of another column
In-Reply-To: <SG2PR03MB5103D5B625F973B3F2D975E9DF860@SG2PR03MB5103.apcprd03.prod.outlook.com>
References: <SG2PR03MB5103D5B625F973B3F2D975E9DF860@SG2PR03MB5103.apcprd03.prod.outlook.com>
Message-ID: <A7C5D61E-1871-41AA-A411-E8183E548763@dcn.davis.ca.us>

Press send too soon? This is not actually a question.

Do read the Posting Guide... for one thing you need to post in plain text because the automatic text conversion tends to mess up what you send if it is HTML.

On June 5, 2020 12:02:44 AM PDT, TJUN KIAT TEO <teotjunk at hotmail.com> wrote:
>Suppose I have a dataframe in this from
>
>a b c
>g 2 3
>h 4 5
>i 6 7
>
>I want to apply a function to individual elements of column C where the
>function value depends on the value of column A
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ph@t@ch@u @end|ng |rom m@||@utoronto@c@  Thu Jun  4 22:17:41 2020
From: ph@t@ch@u @end|ng |rom m@||@utoronto@c@ (Phat Chau)
Date: Thu, 4 Jun 2020 20:17:41 +0000
Subject: [R] Error in gee.fit$working.correlation[1,
 2] : subscript out of bounds
Message-ID: <D53BCA3D-7D29-428A-9830-482061E164FE@mail.utoronto.ca>

Hello,

I have a dataframe in R that looks like the following

  cluster id period   u_3 timeID startTrt Ijt    error      y
1:       1  1      0 -1.26      1        1   0   1.2015 17.809
2:       1  2      0 -1.26      1        1   0  -1.6577 14.950
3:       1  3      0 -1.26      1        1   0  -3.8639 12.744
4:       1  4      0 -1.26      1        1   0   1.4978 18.105
5:       1  5      0 -1.26      1        1   0  -5.3182 11.289

When I try to run a gee model on it using the geesmv package which adjusts the variance covariance matrix for small sample sizes as follows

test <- GEE.var.fg(y ~ factor(period) + factor(Ijt),id="id",family=gaussian, dx,corstr="exchangeable")

I get this error message:

Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27
running glm to get initial regression estimate
    (Intercept) factor(period)1 factor(period)2 factor(period)3 factor(period)4 factor(period)5    factor(Ijt)1
          17.25           -8.27           -6.47           -9.13           -8.17          -11.89            8.96
Error in gee.fit$working.correlation[1, 2] : subscript out of bounds

I think the usual culprit for this kind of error message is that the variable being referred to (id in this case I assume) is non-existent. That is clearly not the case here and I checked to make sure it is it not a typo.

Does anyone know why this is? How would I troubleshoot this?

Thank you,
Edward


	[[alternative HTML version deleted]]


From @turm|echen @end|ng |rom gm@||@com  Thu Jun  4 14:38:35 2020
From: @turm|echen @end|ng |rom gm@||@com (Lena Fehlhaber)
Date: Thu, 4 Jun 2020 14:38:35 +0200
Subject: [R] Spatial model for categorical data
Message-ID: <CA+yGT=GbxwR-MZjQPvgzKWRC_sBa0JvwbR8eLJEUchkAywEuLQ@mail.gmail.com>

I did a regression analysis with categorical data with a glm model
approach, which worked fine. I have longitude and latitude coordinates for
each observation and I want to add their geographic spillover effect to the
model.

My sample data is structured:

Index DV IVI IVII IVIII IVIV Long Lat
 1  0  2  1  3  -12  -17.8  12
 2  0  1  1  6  112  11  -122
 3  1  3  6  1  91  57  53

with regression eq. DV ~ IVI + IVII + IVIII + IVIV

That mentioned, I assume that the nearer regions are, the more it may
influence my dependant variable. I found several approaches for spatial
regression models, but not for categorical data. When I try to use existing
libraries and functions, such as spdep's lagsarlm, glmmfields, spatialreg,
gstat, geoRglm and many more (I used this list as a reference:
https://cran.r-project.org/web/views/Spatial.html ). For numeric values, I
am able to do spatial regression, but for categorical values, I struggle.
The data structure is the following:

library(dplyr)
data <- data %>%
  mutate(
    DV = as.factor(DV),
    IVI = as.factor(IVI),
    IVII = as.factor(IVII),
    IVIII = as.factor(IVIII),
    IVIV = as.numeric(IVIV),
    longitude = as.numeric(longitude),
    latitude = as.numeric(latitude)
  )

My dependant variable (0|1) as well as my independant variables are
categorical and it would be no use to transform them, of course. I want to
have an other glm model in the end, but with spatial spillover effects
included. The libraries I tested so far can't handle categorical data. Any
leads/ideas would be greatly appreciated.

Thanks a lot.

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Jun  5 11:36:33 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 5 Jun 2020 10:36:33 +0100
Subject: [R] ask help for ggplot
In-Reply-To: <CALn2QVj7P74vbqu7M2KyFtd=ueYJCT4UtSdboAE1jJLcdoohjQ@mail.gmail.com>
References: <CALn2QVh5R8C1qH5kLkzwmvXg9mECg=41wUdV+j9Nkv2o-NVd1g@mail.gmail.com>
 <07E94869-7EAA-40BB-A591-C07DDEAA3EB0@dcn.davis.ca.us>
 <CALn2QVj7P74vbqu7M2KyFtd=ueYJCT4UtSdboAE1jJLcdoohjQ@mail.gmail.com>
Message-ID: <794a30da-af67-b10b-bae5-87dcc99faf43@sapo.pt>

Hello,

Something like this?


g <- unique(as.character(df$gene))
i <- which(g == "Others")
g <- c(g[i], g[-i])
df$trt <- factor(df$trt,levels=unique(as.character(df$trt)))
df$gene <- factor(df$gene,levels = g)

ggplot(df, aes(x=trt,y=freq, fill = gene, group = gene)) +
   geom_bar(stat = "identity", width = 0.5,
            position = position_fill()) +
   scale_fill_manual(breaks = df$gene, values = df$cols) +
   theme(axis.text.x = element_text(angle = 45, hjust = 1,size = 4))


But this places "Others" at the top of each bar.
To move it to the bottom, instead of the code that creates 'g' run

g <- unique(as.character(df$gene))
i <- which(g == "Others")
g <- c(g[-i], g[i])


Hope this helps,

Rui Barradas


?s 05:14 de 05/06/20, Aimin Yan escreveu:
> Is there possible to generate a barplot in the following link using ggplot?
> 
> https://photos.app.goo.gl/E3MC461dKaTZfHza9
> 
> here is what I did
> 
> library(ggplot2)
> 
> df <- read.csv(text=
> "trt,gene,freq,cols
> M6,ALDH16A1,100.0000000,red
> M6,Others,0.0000000,lightgrey
> M12,ALDH16A1,64.6638015,red
> M12,GBE1,2.0074865,#4C00FF
> M12,ZNF598,1.5832525,#004CFF
> M12,CHMP6,1.3503397,#00E5FF
> M12,C20orf27,1.2033828,#00FF4D
> M12,NEGR1,0.9676972,#4DFF00
> M12,TNFAIP6,0.9122418,#E6FF00
> M12,ZSCAN25,0.7375572,#FFFF00
> M12,BCL2,0.6848745,#FFDE59
> M12,CBL,0.6765562,#FFE0B3
> M12,Others,25.2128102,lightgrey
> M18,ALDH16A1,42.4503581,red
> M18,ATF2,2.2360682,#4C00FF
> M18,DIAPH1,1.5256507,#004CFF
> M18,SESTD1,1.2053805,#00E5FF
> M18,TFCP2,1.1587958,#00FF4D
> M18,SCAPER,1.1180341,#4DFF00
> M18,CUX1,1.0306877,#E6FF00
> M18,TEX10,0.9841030,#FFFF00
> M18,C6orf89,0.9666337,#FFDE59
> M18,PTTG1IP,0.9258720,#FFE0B3
> M18,Others,46.3984161,lightgrey")
> 
> df$trt <- factor(df$trt,levels=unique(as.character(df$trt)))
> df$gene <- factor(df$gene,levels = unique(as.character(df$gene)))
> 
> ggplot(df, aes(x=trt,y=freq, fill = gene))+geom_bar(stat = "identity",
> width = 0.5,color="black") + theme(axis.text.x = element_text(angle = 45,
> hjust = 1,size = 4))
> 
> df$cols is the color I want to use to label different gene in M6, M12,M18
> as shown in Figure, and in each bar, the 'Others' of df$gene is always in
> the bottom of bar in M6,M12,M18
> 
> Thank you
> 
> Aimin
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r@v|76 @end|ng |rom gm@||@com  Fri Jun  5 18:32:36 2020
From: r@v|76 @end|ng |rom gm@||@com (Ravi Jeyaraman)
Date: Fri, 5 Jun 2020 12:32:36 -0400
Subject: [R] Cumulative split of value in data frame column
Message-ID: <02a701d63b56$ec6b2780$c5417680$@gmail.com>

Assuming, I have a data frame like this ..

df <- data.frame(ID=1:3, FOO=c('A_B','A_B_C','A_B_C_D_E'))

I want to do a 'cumulative split' of the values in column FOO based on the
delimiter '_'.  The end result should be like this ..

ID  FOO		FOO_SPLIT1		FOO_SPLIT2 	FOO_SPLIT3
FOO_SPLIT4		FOO_SPLIT5
1   A_B		A		     A_B	
2   A_B_C	    	A			A_B
A_B_C
3   A_B_C_D_E	A		     A_B		    	A_B_C
A_B_C_D		A_B_C_D_E

Any efficient, optimized way to do this?


-- 
This email has been checked for viruses by AVG.
https://www.avg.com

	[[alternative HTML version deleted]]


From r@v|76 @end|ng |rom gm@||@com  Fri Jun  5 18:41:10 2020
From: r@v|76 @end|ng |rom gm@||@com (Ravi Jeyaraman)
Date: Fri, 5 Jun 2020 12:41:10 -0400
Subject: [R] how to add a calculated column into a data frame
In-Reply-To: <CAAJc=rPbEOfho+RefsFBv9NBc-yB_YfYUzEiZm+GuwHgNobYAQ@mail.gmail.com>
References: <CAAJc=rPbEOfho+RefsFBv9NBc-yB_YfYUzEiZm+GuwHgNobYAQ@mail.gmail.com>
Message-ID: <035701d63b58$1e7f5330$5b7df990$@gmail.com>

How about something like this?

df <- data.frame(ID=1:3, DTVAL=c("2009-03-21","2010-05-11","2020-05-05"))

df <- df %>% mutate(YEAR = as.numeric(format(as.Date(DTVAL,'%Y-%m-%d'),
'%Y')))



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Charles Thuo
Sent: Friday, June 05, 2020 12:18 AM
To: r-help at r-project.org
Subject: [R] how to add a calculated column into a data frame

Dear  Sirs,

I have a data frame that has a column that shows the transaction date.

How do i add another column that  extracts the year of transaction from the
transaction date.

Charles

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To
UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


-- 
This email has been checked for viruses by AVG.
https://www.avg.com

	[[alternative HTML version deleted]]


From wdun|@p @end|ng |rom t|bco@com  Fri Jun  5 18:52:32 2020
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 5 Jun 2020 09:52:32 -0700
Subject: [R] Error in gee.fit$working.correlation[1,
 2] : subscript out of bounds
In-Reply-To: <D53BCA3D-7D29-428A-9830-482061E164FE@mail.utoronto.ca>
References: <D53BCA3D-7D29-428A-9830-482061E164FE@mail.utoronto.ca>
Message-ID: <CAF8bMcZFLg+7kpH6DDg8z-dR6JnvaOXQTL4j-GPBKvZ=4m24xg@mail.gmail.com>

The usual reason for the 'subscript out of bounds' error is that an array's
subscripts exceed the dimensions of the array.  In this case
gee.fit$working.correlation is a 1 by 1 matrix, so subscripting with [1,2]
will cause the error.

Here is a self-contained example that you can send the package's maintainer.

> maintainer("geesmv")
[1] "Zheng Li <zheng.li at outlook.com>"

> dx <- cbind(id=1:18, y=sin(1:18), expand.grid(period=c(1.1,1.2,1.3),
Ijt=c("i","ii","iii"))[c(1:9,1:9),])
> options(error=recover)
> test <- GEE.var.fg(y ~ factor(period) +
factor(Ijt),id="id",family=gaussian, dx,corstr="exchangeable")
Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27
running glm to get initial regression estimate
      (Intercept) factor(period)1.2 factor(period)1.3     factor(Ijt)ii
       0.02712257       -0.06015777       -0.11555784        0.04243596
   factor(Ijt)iii
       0.04114518
Error in gee.fit$working.correlation[1, 2] : subscript out of bounds

Enter a frame number, or 0 to exit

1: GEE.var.fg(y ~ factor(period) + factor(Ijt), id = "id", family =
gaussian,

Selection: 1
Called from: top level
Browse[1]> str(gee.fit$working.correlation)
 num [1, 1] 1

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Jun 5, 2020 at 12:28 AM Phat Chau <phat.chau at mail.utoronto.ca>
wrote:

> Hello,
>
> I have a dataframe in R that looks like the following
>
>   cluster id period   u_3 timeID startTrt Ijt    error      y
> 1:       1  1      0 -1.26      1        1   0   1.2015 17.809
> 2:       1  2      0 -1.26      1        1   0  -1.6577 14.950
> 3:       1  3      0 -1.26      1        1   0  -3.8639 12.744
> 4:       1  4      0 -1.26      1        1   0   1.4978 18.105
> 5:       1  5      0 -1.26      1        1   0  -5.3182 11.289
>
> When I try to run a gee model on it using the geesmv package which adjusts
> the variance covariance matrix for small sample sizes as follows
>
> test <- GEE.var.fg(y ~ factor(period) +
> factor(Ijt),id="id",family=gaussian, dx,corstr="exchangeable")
>
> I get this error message:
>
> Beginning Cgee S-function, @(#) geeformula.q 4.13 98/01/27
> running glm to get initial regression estimate
>     (Intercept) factor(period)1 factor(period)2 factor(period)3
> factor(period)4 factor(period)5    factor(Ijt)1
>           17.25           -8.27           -6.47           -9.13
>  -8.17          -11.89            8.96
> Error in gee.fit$working.correlation[1, 2] : subscript out of bounds
>
> I think the usual culprit for this kind of error message is that the
> variable being referred to (id in this case I assume) is non-existent. That
> is clearly not the case here and I checked to make sure it is it not a typo.
>
> Does anyone know why this is? How would I troubleshoot this?
>
> Thank you,
> Edward
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Jun  5 20:28:50 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 5 Jun 2020 11:28:50 -0700
Subject: [R] Cumulative split of value in data frame column
In-Reply-To: <02a701d63b56$ec6b2780$c5417680$@gmail.com>
References: <02a701d63b56$ec6b2780$c5417680$@gmail.com>
Message-ID: <CAGxFJbTLHYmc1Q5Jmc-+cCEmY1zFNwjcHE94K+DZPXA2RJObcw@mail.gmail.com>

This is a **plain text list **. In future please post in plain text so that
your post does not get mangled.

Anyway,...

I don't know about "efficient, optimized", but here's one simple way to do
it using ?strsplit to unsplit and then ?paste to recombine:

df <- data.frame(ID=1:3, FOO=c('A_B','A_B_C','A_B_C_D_E'))

cumsplit<- function(x,split = "_"){
    w <- x[1]
    for(i in seq_along(x)[-1])  w <- c(w, paste(w[i-1],x[i], sep = split))
    w
}

> lapply(strsplit(df$FOO, split = "_"), cumsplit)
[[1]]
[1] "A"   "A_B"

[[2]]
[1] "A"     "A_B"   "A_B_C"

[[3]]
[1] "A"         "A_B"       "A_B_C"     "A_B_C_D"   "A_B_C_D_E"

I wouldn't be surprised if clever use of regex's would be faster, but as I
said, this is simple.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 5, 2020 at 9:33 AM Ravi Jeyaraman <ravi76 at gmail.com> wrote:

> Assuming, I have a data frame like this ..
>
> df <- data.frame(ID=1:3, FOO=c('A_B','A_B_C','A_B_C_D_E'))
>
> I want to do a 'cumulative split' of the values in column FOO based on the
> delimiter '_'.  The end result should be like this ..
>
> ID  FOO         FOO_SPLIT1              FOO_SPLIT2      FOO_SPLIT3
> FOO_SPLIT4              FOO_SPLIT5
> 1   A_B         A                    A_B
> 2   A_B_C               A                       A_B
> A_B_C
> 3   A_B_C_D_E   A                    A_B                        A_B_C
> A_B_C_D         A_B_C_D_E
>
> Any efficient, optimized way to do this?
>
>
> --
> This email has been checked for viruses by AVG.
> https://www.avg.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @|m|n@@t@work @end|ng |rom gm@||@com  Fri Jun  5 21:49:57 2020
From: @|m|n@@t@work @end|ng |rom gm@||@com (Aimin Yan)
Date: Fri, 5 Jun 2020 15:49:57 -0400
Subject: [R] ask help for ggplot
In-Reply-To: <794a30da-af67-b10b-bae5-87dcc99faf43@sapo.pt>
References: <CALn2QVh5R8C1qH5kLkzwmvXg9mECg=41wUdV+j9Nkv2o-NVd1g@mail.gmail.com>
 <07E94869-7EAA-40BB-A591-C07DDEAA3EB0@dcn.davis.ca.us>
 <CALn2QVj7P74vbqu7M2KyFtd=ueYJCT4UtSdboAE1jJLcdoohjQ@mail.gmail.com>
 <794a30da-af67-b10b-bae5-87dcc99faf43@sapo.pt>
Message-ID: <CALn2QVhu2t2GSYHeqyWUi1u6h24uy5bwyBqFvzgetsoomvMzEA@mail.gmail.com>

Thank you, it is very helpful.

I tried the following way to generate stacked bar plot for trt 'M6' and
'M12'

However, the label position of legend in 'M12' is not what I want,
actually in the legend I also want to keep "Others" in the bottom(like the
gene order in stacked bar)

In addition, how to  make  a stacked bar plot for 'M6','M12' and 'M18'
together with different legends('M6', 'M12', 'M18')

Thank you,

Aimin

df.1 <- df[df$trt=='M6',]

g <- unique(as.character(df.1$gene))
i <- which(g == "Others")
g <- c(g[-i], g[i])

df.1$trt <- factor(df.1$trt,levels=unique(as.character(df$trt)))
df.1$gene <- factor(df.1$gene,levels = g)

df.1 %>% ggplot(aes(x=trt,y=freq, fill = gene, group = gene)) +
  geom_bar(stat = "identity", width = 0.5) +
  scale_fill_manual(breaks = df$gene, values = df$cols) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1,size = 4)) +
theme(legend.position="bottom")+guides(fill=guide_legend(title=df.1$trt,title.position
= "top", ncol=1, keyheight=0.35, default.unit="inch"))

df.2 <- df[df$trt=='M12',]

g <- unique(as.character(df.2$gene))
i <- which(g == "Others")
g <- c(g[-i], g[i])

df.2$trt <- factor(df.2$trt,levels=unique(as.character(df$trt)))
df.2$gene <- factor(df.2$gene,levels = g)

df.2 %>% ggplot(aes(x=trt,y=freq, fill = gene, group = gene)) +
  geom_bar(stat = "identity", width = 0.5) +
  scale_fill_manual(breaks = df$gene, values = df$cols) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1,size = 4)) +
theme(legend.position="bottom")+guides(fill=guide_legend(title=df.2$trt,title.position
= "top", ncol=1, keyheight=0.35, default.unit="inch"))




On Fri, Jun 5, 2020 at 5:36 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Something like this?
>
>
> g <- unique(as.character(df$gene))
> i <- which(g == "Others")
> g <- c(g[i], g[-i])
> df$trt <- factor(df$trt,levels=unique(as.character(df$trt)))
> df$gene <- factor(df$gene,levels = g)
>
> ggplot(df, aes(x=trt,y=freq, fill = gene, group = gene)) +
>    geom_bar(stat = "identity", width = 0.5,
>             position = position_fill()) +
>    scale_fill_manual(breaks = df$gene, values = df$cols) +
>    theme(axis.text.x = element_text(angle = 45, hjust = 1,size = 4))
>
>
> But this places "Others" at the top of each bar.
> To move it to the bottom, instead of the code that creates 'g' run
>
> g <- unique(as.character(df$gene))
> i <- which(g == "Others")
> g <- c(g[-i], g[i])
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> ?s 05:14 de 05/06/20, Aimin Yan escreveu:
> > Is there possible to generate a barplot in the following link using
> ggplot?
> >
> > https://photos.app.goo.gl/E3MC461dKaTZfHza9
> >
> > here is what I did
> >
> > library(ggplot2)
> >
> > df <- read.csv(text=
> > "trt,gene,freq,cols
> > M6,ALDH16A1,100.0000000,red
> > M6,Others,0.0000000,lightgrey
> > M12,ALDH16A1,64.6638015,red
> > M12,GBE1,2.0074865,#4C00FF
> > M12,ZNF598,1.5832525,#004CFF
> > M12,CHMP6,1.3503397,#00E5FF
> > M12,C20orf27,1.2033828,#00FF4D
> > M12,NEGR1,0.9676972,#4DFF00
> > M12,TNFAIP6,0.9122418,#E6FF00
> > M12,ZSCAN25,0.7375572,#FFFF00
> > M12,BCL2,0.6848745,#FFDE59
> > M12,CBL,0.6765562,#FFE0B3
> > M12,Others,25.2128102,lightgrey
> > M18,ALDH16A1,42.4503581,red
> > M18,ATF2,2.2360682,#4C00FF
> > M18,DIAPH1,1.5256507,#004CFF
> > M18,SESTD1,1.2053805,#00E5FF
> > M18,TFCP2,1.1587958,#00FF4D
> > M18,SCAPER,1.1180341,#4DFF00
> > M18,CUX1,1.0306877,#E6FF00
> > M18,TEX10,0.9841030,#FFFF00
> > M18,C6orf89,0.9666337,#FFDE59
> > M18,PTTG1IP,0.9258720,#FFE0B3
> > M18,Others,46.3984161,lightgrey")
> >
> > df$trt <- factor(df$trt,levels=unique(as.character(df$trt)))
> > df$gene <- factor(df$gene,levels = unique(as.character(df$gene)))
> >
> > ggplot(df, aes(x=trt,y=freq, fill = gene))+geom_bar(stat = "identity",
> > width = 0.5,color="black") + theme(axis.text.x = element_text(angle = 45,
> > hjust = 1,size = 4))
> >
> > df$cols is the color I want to use to label different gene in M6, M12,M18
> > as shown in Figure, and in each bar, the 'Others' of df$gene is always in
> > the bottom of bar in M6,M12,M18
> >
> > Thank you
> >
> > Aimin
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From @|m|n@@t@work @end|ng |rom gm@||@com  Sat Jun  6 05:59:47 2020
From: @|m|n@@t@work @end|ng |rom gm@||@com (Aimin Yan)
Date: Fri, 5 Jun 2020 23:59:47 -0400
Subject: [R] (no subject)
Message-ID: <CALn2QVjjWchdZMQX_JQHq8ADfqUFB4QpOi1j6uWwCm3tvMWuLg@mail.gmail.com>

I want the stacked bar and its legend following the order as tr from
left to right like the following:

"100.0.250ng_CellLine_0" "75.25.250ng_CellLine_0"
"50.50.250ng_CellLine_0" "10.90.250ng_CellLine_0"
"1.99.250ng_CellLine_0" "0.100.250ng_CellLine_0"
"100.0.500ng_CellLine_0" "75.25.500ng_CellLine_0"
"50.50.500ng_CellLine_0" "10.90.500ng_CellLine_0"
"1.99.500ng_CellLine_0" "0.100.500ng_CellLine_0"

However, It seems the above code does not generate the stacked bar as this order

In addition, for '0.100.500ng_CellLine_0' in df, the order for gene
and color in stacked bar is not same as the order in df:



0.100.500ng_CellLine_0       ALYREF   1.5326986       red
                  0.100.500ng_CellLine_0        HCG18   1.5108475   #4C00FF
                  0.100.500ng_CellLine_0    RNU7-146P   0.9224286   #004CFF
                  0.100.500ng_CellLine_0      ST3GAL3   0.8849696   #00E5FF
                  0.100.500ng_CellLine_0         HSF1   0.8116123   #00FF4D
                  0.100.500ng_CellLine_0       HP1BP3   0.7928828   #4DFF00
                  0.100.500ng_CellLine_0         DAOA   0.7366942   #E6FF00
                  0.100.500ng_CellLine_0        CDK13   0.6898705   #FFFF00
                  0.100.500ng_CellLine_0       PDXDC1   0.6805057   #FFDE59
                  0.100.500ng_CellLine_0        CKAP5   0.6477290   #FFE0B3
                  0.100.500ng_CellLine_0       Others  90.7897612 lightgrey'

library(dplyr)
library(tidyverse)
library(ggnewscale)

df <- read.csv(text='"trt","gene","freq","cols"
                 "100.0.250ng_CellLine_0","ALDH16A1",100,"red"
                 "100.0.250ng_CellLine_0","Others",0,"lightgrey"
                 "75.25.250ng_CellLine_0","ALDH16A1",64.6638014695688,"red"
                 "75.25.250ng_CellLine_0","GBE1",2.0074864827395,"#4C00FF"
                 "75.25.250ng_CellLine_0","ZNF598",1.5832524608346,"#004CFF"
                 "75.25.250ng_CellLine_0","CHMP6",1.35033966449466,"#00E5FF"
                 "75.25.250ng_CellLine_0","C20orf27",1.2033827810897,"#00FF4D"
                 "75.25.250ng_CellLine_0","NEGR1",0.967697213364758,"#4DFF00"
                 "75.25.250ng_CellLine_0","TNFAIP6",0.912241785664772,"#E6FF00"
                 "75.25.250ng_CellLine_0","ZSCAN25",0.737557188409816,"#FFFF00"
                 "75.25.250ng_CellLine_0","BCL2",0.684874532094829,"#FFDE59"
                 "75.25.250ng_CellLine_0","CBL",0.676556217939831,"#FFE0B3"
                 "75.25.250ng_CellLine_0","Others",25.2128102037987,"lightgrey"
                 "50.50.250ng_CellLine_0","ALDH16A1",42.4503581203051,"red"
                 "50.50.250ng_CellLine_0","ATF2",2.23606824666628,"#4C00FF"
                 "50.50.250ng_CellLine_0","DIAPH1",1.52565073079835,"#004CFF"
                 "50.50.250ng_CellLine_0","SESTD1",1.20538053921854,"#00E5FF"
                 "50.50.250ng_CellLine_0","TFCP2",1.15879578407966,"#00FF4D"
                 "50.50.250ng_CellLine_0","SCAPER",1.11803412333314,"#4DFF00"
                 "50.50.250ng_CellLine_0","CUX1",1.03068770744774,"#E6FF00"
                 "50.50.250ng_CellLine_0","TEX10",0.984102952308857,"#FFFF00"
                 "50.50.250ng_CellLine_0","C6orf89",0.966633669131777,"#FFDE59"
                 "50.50.250ng_CellLine_0","PTTG1IP",0.925872008385256,"#FFE0B3"
                 "50.50.250ng_CellLine_0","Others",46.3984161183253,"lightgrey"
                 "10.90.250ng_CellLine_0","ALDH16A1",4.68952007835455,"red"
                 "10.90.250ng_CellLine_0","STK11",1.93143976493634,"#4C00FF"
                 "10.90.250ng_CellLine_0","ERGIC2",1.46523016650343,"#004CFF"
                 "10.90.250ng_CellLine_0","EFR3A",1.1126346718903,"#00E5FF"
                 "10.90.250ng_CellLine_0","TMEM235",1.03819784524976,"#00FF4D"
                 "10.90.250ng_CellLine_0","NGLY1",1.01469147894221,"#4DFF00"
                 "10.90.250ng_CellLine_0","CNOT10",0.991185112634672,"#E6FF00"
                 "10.90.250ng_CellLine_0","NPLOC4",0.983349657198825,"#FFFF00"
                 "10.90.250ng_CellLine_0","GZMB",0.928501469147894,"#FFDE59"
                 "10.90.250ng_CellLine_0","KIF2C",0.924583741429971,"#FFE0B3"
                 "10.90.250ng_CellLine_0","Others",84.9206660137121,"lightgrey"
                 "1.99.250ng_CellLine_0","DNAH1",2.36284289276808,"red"
                 "1.99.250ng_CellLine_0","ALOX5AP",2.29426433915212,"#4C00FF"
                 "1.99.250ng_CellLine_0","SEPT7",1.78304239401496,"#004CFF"
                 "1.99.250ng_CellLine_0","TCF20",1.35910224438903,"#00E5FF"
                 "1.99.250ng_CellLine_0","USP32",1.27805486284289,"#00FF4D"
                 "1.99.250ng_CellLine_0","MUS81",1.24688279301746,"#4DFF00"
                 "1.99.250ng_CellLine_0","CEP44",1.22817955112219,"#E6FF00"
                 "1.99.250ng_CellLine_0","TMEM164",1.20324189526185,"#FFFF00"
                 "1.99.250ng_CellLine_0","RAP1B",1.18453865336658,"#FFDE59"
                 "1.99.250ng_CellLine_0","GSN",1.14713216957606,"#FFE0B3"
                 "1.99.250ng_CellLine_0","Others",84.9127182044888,"lightgrey"
                 "0.100.250ng_CellLine_0","RTN3",2.3050199437531,"red"
                 "0.100.250ng_CellLine_0","CHTF18",1.67637814091135,"#4C00FF"
                 "0.100.250ng_CellLine_0","RNPS1",1.41168685550429,"#004CFF"
                 "0.100.250ng_CellLine_0","RBKS",1.05325073984891,"#00E5FF"
                 "0.100.250ng_CellLine_0","ZNF805",0.987077918497142,"#00FF4D"
                 "0.100.250ng_CellLine_0","TMBIM6",0.865761079352242,"#4DFF00"

"0.100.250ng_CellLine_0","RP3-449O17.1",0.841865338308549,"#E6FF00"
                 "0.100.250ng_CellLine_0","RNASEH2A",0.814293329411981,"#FFFF00"
                 "0.100.250ng_CellLine_0","FAM46A",0.810617061559105,"#FFDE59"
                 "0.100.250ng_CellLine_0","CYB561A3",0.79775012407404,"#FFE0B3"
                 "0.100.250ng_CellLine_0","Others",88.4362994687793,"lightgrey"
                 "100.0.500ng_CellLine_0","ALDH16A1",100,"red"
                 "100.0.500ng_CellLine_0","Others",0,"lightgrey"
                 "75.25.500ng_CellLine_0","ALDH16A1",64.6680558047111,"red"
                 "75.25.500ng_CellLine_0","STX18",0.76034608856445,"#4C00FF"
                 "75.25.500ng_CellLine_0","BCL7A",0.685829412008224,"#004CFF"
                 "75.25.500ng_CellLine_0","PTPRC",0.634771689182662,"#00E5FF"
                 "75.25.500ng_CellLine_0","GABRB1",0.626492058454193,"#00FF4D"
                 "75.25.500ng_CellLine_0","EDNRB",0.59751335090455,"#4DFF00"
                 "75.25.500ng_CellLine_0","TBC1D10C",0.538175997350518,"#E6FF00"
                 "75.25.500ng_CellLine_0","SRGAP2B",0.534036181986283,"#FFFF00"
                 "75.25.500ng_CellLine_0","RABGAP1",0.527136489712559,"#FFDE59"
                 "75.25.500ng_CellLine_0","CD44",0.485738336070211,"#FFE0B3"
                 "75.25.500ng_CellLine_0","Others",29.9419045910552,"lightgrey"
                 "50.50.500ng_CellLine_0","ALDH16A1",40.5808575357307,"red"
                 "50.50.500ng_CellLine_0","TNPO1",0.979207466977791,"#4C00FF"
                 "50.50.500ng_CellLine_0","RNA5SP443",0.93337222384266,"#004CFF"
                 "50.50.500ng_CellLine_0","MND1",0.912538022417601,"#00E5FF"
                 "50.50.500ng_CellLine_0","RB1",0.900037501562565,"#00FF4D"
                 "50.50.500ng_CellLine_0","PTPRA",0.791699654152256,"#4DFF00"
                 "50.50.500ng_CellLine_0","SUCNR1",0.783365973582233,"#E6FF00"
                 "50.50.500ng_CellLine_0","MIR1284",0.625026042751781,"#FFFF00"
                 "50.50.500ng_CellLine_0","RWDD1",0.587524480186674,"#FFDE59"
                 "50.50.500ng_CellLine_0","NTN1",0.575023959331639,"#FFE0B3"
                 "50.50.500ng_CellLine_0","Others",52.3313471394641,"lightgrey"
                 "10.90.500ng_CellLine_0","ALDH16A1",7.05601485476812,"red"
                 "10.90.500ng_CellLine_0","ENTPD5",1.4722136257129,"#4C00FF"
                 "10.90.500ng_CellLine_0","MFSD10",1.28210796233255,"#004CFF"

"10.90.500ng_CellLine_0","LENG8-AS1",0.915159821389098,"#00E5FF"
                 "10.90.500ng_CellLine_0","FRMD4B",0.884212387815553,"#00FF4D"
                 "10.90.500ng_CellLine_0","TWISTNB",0.853264954242009,"#4DFF00"
                 "10.90.500ng_CellLine_0","ZNF544",0.778106901277687,"#E6FF00"
                 "10.90.500ng_CellLine_0","NUDCD1",0.738317343825987,"#FFFF00"
                 "10.90.500ng_CellLine_0","PHF20",0.720633096069676,"#FFDE59"
                 "10.90.500ng_CellLine_0","HNRNPK",0.702948848313365,"#FFE0B3"
                 "10.90.500ng_CellLine_0","Others",84.5970202042531,"lightgrey"
                 "1.99.500ng_CellLine_0","SND1",2.97318305479984,"red"
                 "1.99.500ng_CellLine_0","ATF1",2.18940277237984,"#4C00FF"
                 "1.99.500ng_CellLine_0","CARM1",1.96916699054282,"#004CFF"
                 "1.99.500ng_CellLine_0","OR4K15",1.28902707604612,"#00E5FF"
                 "1.99.500ng_CellLine_0","MTMR3",1.26311698406529,"#00FF4D"
                 "1.99.500ng_CellLine_0","CDK13",1.13356652416116,"#4DFF00"
                 "1.99.500ng_CellLine_0","RNU6-385P",1.0752688172043,"#E6FF00"
                 "1.99.500ng_CellLine_0","SLC4A2",0.809690374400829,"#FFFF00"
                 "1.99.500ng_CellLine_0","TMF1",0.770825236429589,"#FFDE59"
                 "1.99.500ng_CellLine_0","MAN1A1",0.738437621453556,"#FFE0B3"
                 "1.99.500ng_CellLine_0","Others",85.7883145485167,"lightgrey"
                 "0.100.500ng_CellLine_0","ALYREF",1.53269861089433,"red"
                 "0.100.500ng_CellLine_0","HCG18",1.51084751053535,"#4C00FF"

"0.100.500ng_CellLine_0","RNU7-146P",0.922428593725613,"#004CFF"
                 "0.100.500ng_CellLine_0","ST3GAL3",0.884969564538786,"#00E5FF"
                 "0.100.500ng_CellLine_0","HSF1",0.811612299047916,"#00FF4D"
                 "0.100.500ng_CellLine_0","HP1BP3",0.792882784454503,"#4DFF00"
                 "0.100.500ng_CellLine_0","DAOA",0.736694240674262,"#E6FF00"
                 "0.100.500ng_CellLine_0","CDK13",0.689870454190729,"#FFFF00"
                 "0.100.500ng_CellLine_0","PDXDC1",0.680505696894022,"#FFDE59"
                 "0.100.500ng_CellLine_0","CKAP5",0.647729046355549,"#FFE0B3"
                 "0.100.500ng_CellLine_0","Others",90.7897611986889,"lightgrey"'
                 ,sep=",",header=T)

g <- unique(as.character(df$gene))
i <- which(g == "Others")
g <- c(g[-i], g[i])

df$trt <- factor(df$trt,levels=unique(as.character(df$trt)))
df$gene <- factor(df$gene,levels = g)

cols <- dplyr::select(df, gene, cols) %>%
  distinct() %>%
  deframe()

tr <- levels(df$trt)

p <- ggplot() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[1]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[1],
ncol = 1, title.position = "top")) +
  new_scale_fill() + # Define scales before initiating a new one
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[2]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[2],
ncol = 1, title.position = "top")) +
  new_scale_fill() + # Define scales before initiating a new one
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[3]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[3],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[4]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[4],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[5]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[5],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[6]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[6],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[7]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[7],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[8]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[8],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[9]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[9],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[10]), stat = "identity", color = "black")
+
  scale_fill_manual(values = cols, guide = guide_legend(title =
tr[10], ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[11]), stat = "identity", color = "black")
+
  scale_fill_manual(values = cols, guide = guide_legend(title =
tr[11], ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[12]), stat = "identity", color = "black")
+
  scale_fill_manual(values = cols, guide = guide_legend(title =
tr[12], ncol = 1, title.position = "top")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1,size = 4),
legend.position = "bottom", legend.justification = 0)

p

	[[alternative HTML version deleted]]


From @|m|n@@t@work @end|ng |rom gm@||@com  Sat Jun  6 06:08:02 2020
From: @|m|n@@t@work @end|ng |rom gm@||@com (Aimin Yan)
Date: Sat, 6 Jun 2020 00:08:02 -0400
Subject: [R] Change the oder of stacked bar
In-Reply-To: <CALn2QVjjWchdZMQX_JQHq8ADfqUFB4QpOi1j6uWwCm3tvMWuLg@mail.gmail.com>
References: <CALn2QVjjWchdZMQX_JQHq8ADfqUFB4QpOi1j6uWwCm3tvMWuLg@mail.gmail.com>
Message-ID: <CALn2QVivU2zbsmSfZ8wW8=ce847YgV4G2kaVHB=6PXQT2hx-jw@mail.gmail.com>

I want to use the code below this message to make stacked bar plot, my
question is :


I want the stacked bar and its legend following the order as tr from
left to right like the following:

"100.0.250ng_CellLine_0" "75.25.250ng_CellLine_0"
"50.50.250ng_CellLine_0" "10.90.250ng_CellLine_0"
"1.99.250ng_CellLine_0" "0.100.250ng_CellLine_0"
"100.0.500ng_CellLine_0" "75.25.500ng_CellLine_0"
"50.50.500ng_CellLine_0" "10.90.500ng_CellLine_0"
"1.99.500ng_CellLine_0" "0.100.500ng_CellLine_0"

However, It seems the following code does not generate the stacked bar
as this order

In addition, for '0.100.500ng_CellLine_0' in df, the order for gene
and color in stacked bar is not same as the order in df, how to change
this?

Another question is:

tr has 12 treatments, I have to add new_scale_fill() for each
treatment, so I get long code, Is there a way to simplify this?

Thank you

Aimin


library(ggplot2)

library(dplyr)

library(tidyverse)

library(ggnewscale)

df <- read.csv(text='"trt","gene","freq","cols"
                 "100.0.250ng_CellLine_0","ALDH16A1",100,"red"
                 "100.0.250ng_CellLine_0","Others",0,"lightgrey"
                 "75.25.250ng_CellLine_0","ALDH16A1",64.6638014695688,"red"
                 "75.25.250ng_CellLine_0","GBE1",2.0074864827395,"#4C00FF"
                 "75.25.250ng_CellLine_0","ZNF598",1.5832524608346,"#004CFF"
                 "75.25.250ng_CellLine_0","CHMP6",1.35033966449466,"#00E5FF"
                 "75.25.250ng_CellLine_0","C20orf27",1.2033827810897,"#00FF4D"
                 "75.25.250ng_CellLine_0","NEGR1",0.967697213364758,"#4DFF00"
                 "75.25.250ng_CellLine_0","TNFAIP6",0.912241785664772,"#E6FF00"
                 "75.25.250ng_CellLine_0","ZSCAN25",0.737557188409816,"#FFFF00"
                 "75.25.250ng_CellLine_0","BCL2",0.684874532094829,"#FFDE59"
                 "75.25.250ng_CellLine_0","CBL",0.676556217939831,"#FFE0B3"
                 "75.25.250ng_CellLine_0","Others",25.2128102037987,"lightgrey"
                 "50.50.250ng_CellLine_0","ALDH16A1",42.4503581203051,"red"
                 "50.50.250ng_CellLine_0","ATF2",2.23606824666628,"#4C00FF"
                 "50.50.250ng_CellLine_0","DIAPH1",1.52565073079835,"#004CFF"
                 "50.50.250ng_CellLine_0","SESTD1",1.20538053921854,"#00E5FF"
                 "50.50.250ng_CellLine_0","TFCP2",1.15879578407966,"#00FF4D"
                 "50.50.250ng_CellLine_0","SCAPER",1.11803412333314,"#4DFF00"
                 "50.50.250ng_CellLine_0","CUX1",1.03068770744774,"#E6FF00"
                 "50.50.250ng_CellLine_0","TEX10",0.984102952308857,"#FFFF00"
                 "50.50.250ng_CellLine_0","C6orf89",0.966633669131777,"#FFDE59"
                 "50.50.250ng_CellLine_0","PTTG1IP",0.925872008385256,"#FFE0B3"
                 "50.50.250ng_CellLine_0","Others",46.3984161183253,"lightgrey"
                 "10.90.250ng_CellLine_0","ALDH16A1",4.68952007835455,"red"
                 "10.90.250ng_CellLine_0","STK11",1.93143976493634,"#4C00FF"
                 "10.90.250ng_CellLine_0","ERGIC2",1.46523016650343,"#004CFF"
                 "10.90.250ng_CellLine_0","EFR3A",1.1126346718903,"#00E5FF"
                 "10.90.250ng_CellLine_0","TMEM235",1.03819784524976,"#00FF4D"
                 "10.90.250ng_CellLine_0","NGLY1",1.01469147894221,"#4DFF00"
                 "10.90.250ng_CellLine_0","CNOT10",0.991185112634672,"#E6FF00"
                 "10.90.250ng_CellLine_0","NPLOC4",0.983349657198825,"#FFFF00"
                 "10.90.250ng_CellLine_0","GZMB",0.928501469147894,"#FFDE59"
                 "10.90.250ng_CellLine_0","KIF2C",0.924583741429971,"#FFE0B3"
                 "10.90.250ng_CellLine_0","Others",84.9206660137121,"lightgrey"
                 "1.99.250ng_CellLine_0","DNAH1",2.36284289276808,"red"
                 "1.99.250ng_CellLine_0","ALOX5AP",2.29426433915212,"#4C00FF"
                 "1.99.250ng_CellLine_0","SEPT7",1.78304239401496,"#004CFF"
                 "1.99.250ng_CellLine_0","TCF20",1.35910224438903,"#00E5FF"
                 "1.99.250ng_CellLine_0","USP32",1.27805486284289,"#00FF4D"
                 "1.99.250ng_CellLine_0","MUS81",1.24688279301746,"#4DFF00"
                 "1.99.250ng_CellLine_0","CEP44",1.22817955112219,"#E6FF00"
                 "1.99.250ng_CellLine_0","TMEM164",1.20324189526185,"#FFFF00"
                 "1.99.250ng_CellLine_0","RAP1B",1.18453865336658,"#FFDE59"
                 "1.99.250ng_CellLine_0","GSN",1.14713216957606,"#FFE0B3"
                 "1.99.250ng_CellLine_0","Others",84.9127182044888,"lightgrey"
                 "0.100.250ng_CellLine_0","RTN3",2.3050199437531,"red"
                 "0.100.250ng_CellLine_0","CHTF18",1.67637814091135,"#4C00FF"
                 "0.100.250ng_CellLine_0","RNPS1",1.41168685550429,"#004CFF"
                 "0.100.250ng_CellLine_0","RBKS",1.05325073984891,"#00E5FF"
                 "0.100.250ng_CellLine_0","ZNF805",0.987077918497142,"#00FF4D"
                 "0.100.250ng_CellLine_0","TMBIM6",0.865761079352242,"#4DFF00"

"0.100.250ng_CellLine_0","RP3-449O17.1",0.841865338308549,"#E6FF00"
                 "0.100.250ng_CellLine_0","RNASEH2A",0.814293329411981,"#FFFF00"
                 "0.100.250ng_CellLine_0","FAM46A",0.810617061559105,"#FFDE59"
                 "0.100.250ng_CellLine_0","CYB561A3",0.79775012407404,"#FFE0B3"
                 "0.100.250ng_CellLine_0","Others",88.4362994687793,"lightgrey"
                 "100.0.500ng_CellLine_0","ALDH16A1",100,"red"
                 "100.0.500ng_CellLine_0","Others",0,"lightgrey"
                 "75.25.500ng_CellLine_0","ALDH16A1",64.6680558047111,"red"
                 "75.25.500ng_CellLine_0","STX18",0.76034608856445,"#4C00FF"
                 "75.25.500ng_CellLine_0","BCL7A",0.685829412008224,"#004CFF"
                 "75.25.500ng_CellLine_0","PTPRC",0.634771689182662,"#00E5FF"
                 "75.25.500ng_CellLine_0","GABRB1",0.626492058454193,"#00FF4D"
                 "75.25.500ng_CellLine_0","EDNRB",0.59751335090455,"#4DFF00"
                 "75.25.500ng_CellLine_0","TBC1D10C",0.538175997350518,"#E6FF00"
                 "75.25.500ng_CellLine_0","SRGAP2B",0.534036181986283,"#FFFF00"
                 "75.25.500ng_CellLine_0","RABGAP1",0.527136489712559,"#FFDE59"
                 "75.25.500ng_CellLine_0","CD44",0.485738336070211,"#FFE0B3"
                 "75.25.500ng_CellLine_0","Others",29.9419045910552,"lightgrey"
                 "50.50.500ng_CellLine_0","ALDH16A1",40.5808575357307,"red"
                 "50.50.500ng_CellLine_0","TNPO1",0.979207466977791,"#4C00FF"
                 "50.50.500ng_CellLine_0","RNA5SP443",0.93337222384266,"#004CFF"
                 "50.50.500ng_CellLine_0","MND1",0.912538022417601,"#00E5FF"
                 "50.50.500ng_CellLine_0","RB1",0.900037501562565,"#00FF4D"
                 "50.50.500ng_CellLine_0","PTPRA",0.791699654152256,"#4DFF00"
                 "50.50.500ng_CellLine_0","SUCNR1",0.783365973582233,"#E6FF00"
                 "50.50.500ng_CellLine_0","MIR1284",0.625026042751781,"#FFFF00"
                 "50.50.500ng_CellLine_0","RWDD1",0.587524480186674,"#FFDE59"
                 "50.50.500ng_CellLine_0","NTN1",0.575023959331639,"#FFE0B3"
                 "50.50.500ng_CellLine_0","Others",52.3313471394641,"lightgrey"
                 "10.90.500ng_CellLine_0","ALDH16A1",7.05601485476812,"red"
                 "10.90.500ng_CellLine_0","ENTPD5",1.4722136257129,"#4C00FF"
                 "10.90.500ng_CellLine_0","MFSD10",1.28210796233255,"#004CFF"

"10.90.500ng_CellLine_0","LENG8-AS1",0.915159821389098,"#00E5FF"
                 "10.90.500ng_CellLine_0","FRMD4B",0.884212387815553,"#00FF4D"
                 "10.90.500ng_CellLine_0","TWISTNB",0.853264954242009,"#4DFF00"
                 "10.90.500ng_CellLine_0","ZNF544",0.778106901277687,"#E6FF00"
                 "10.90.500ng_CellLine_0","NUDCD1",0.738317343825987,"#FFFF00"
                 "10.90.500ng_CellLine_0","PHF20",0.720633096069676,"#FFDE59"
                 "10.90.500ng_CellLine_0","HNRNPK",0.702948848313365,"#FFE0B3"
                 "10.90.500ng_CellLine_0","Others",84.5970202042531,"lightgrey"
                 "1.99.500ng_CellLine_0","SND1",2.97318305479984,"red"
                 "1.99.500ng_CellLine_0","ATF1",2.18940277237984,"#4C00FF"
                 "1.99.500ng_CellLine_0","CARM1",1.96916699054282,"#004CFF"
                 "1.99.500ng_CellLine_0","OR4K15",1.28902707604612,"#00E5FF"
                 "1.99.500ng_CellLine_0","MTMR3",1.26311698406529,"#00FF4D"
                 "1.99.500ng_CellLine_0","CDK13",1.13356652416116,"#4DFF00"
                 "1.99.500ng_CellLine_0","RNU6-385P",1.0752688172043,"#E6FF00"
                 "1.99.500ng_CellLine_0","SLC4A2",0.809690374400829,"#FFFF00"
                 "1.99.500ng_CellLine_0","TMF1",0.770825236429589,"#FFDE59"
                 "1.99.500ng_CellLine_0","MAN1A1",0.738437621453556,"#FFE0B3"
                 "1.99.500ng_CellLine_0","Others",85.7883145485167,"lightgrey"
                 "0.100.500ng_CellLine_0","ALYREF",1.53269861089433,"red"
                 "0.100.500ng_CellLine_0","HCG18",1.51084751053535,"#4C00FF"

"0.100.500ng_CellLine_0","RNU7-146P",0.922428593725613,"#004CFF"
                 "0.100.500ng_CellLine_0","ST3GAL3",0.884969564538786,"#00E5FF"
                 "0.100.500ng_CellLine_0","HSF1",0.811612299047916,"#00FF4D"
                 "0.100.500ng_CellLine_0","HP1BP3",0.792882784454503,"#4DFF00"
                 "0.100.500ng_CellLine_0","DAOA",0.736694240674262,"#E6FF00"
                 "0.100.500ng_CellLine_0","CDK13",0.689870454190729,"#FFFF00"
                 "0.100.500ng_CellLine_0","PDXDC1",0.680505696894022,"#FFDE59"
                 "0.100.500ng_CellLine_0","CKAP5",0.647729046355549,"#FFE0B3"
                 "0.100.500ng_CellLine_0","Others",90.7897611986889,"lightgrey"'
                 ,sep=",",header=T)

g <- unique(as.character(df$gene))
i <- which(g == "Others")
g <- c(g[-i], g[i])

df$trt <- factor(df$trt,levels=unique(as.character(df$trt)))
df$gene <- factor(df$gene,levels = g)

cols <- dplyr::select(df, gene, cols) %>%
  distinct() %>%
  deframe()

tr <- levels(df$trt)

p <- ggplot() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[1]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[1],
ncol = 1, title.position = "top")) +
  new_scale_fill() + # Define scales before initiating a new one
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[2]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[2],
ncol = 1, title.position = "top")) +
  new_scale_fill() + # Define scales before initiating a new one
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[3]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[3],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[4]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[4],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[5]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[5],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[6]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[6],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[7]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[7],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[8]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[8],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[9]), stat = "identity", color = "black") +
  scale_fill_manual(values = cols, guide = guide_legend(title = tr[9],
ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[10]), stat = "identity", color = "black")
+
  scale_fill_manual(values = cols, guide = guide_legend(title =
tr[10], ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[11]), stat = "identity", color = "black")
+
  scale_fill_manual(values = cols, guide = guide_legend(title =
tr[11], ncol = 1, title.position = "top")) +
  new_scale_fill() +
  geom_bar(mapping = aes(x = trt, y = freq, fill = gene), data =
dplyr::filter(df, trt == tr[12]), stat = "identity", color = "black")
+
  scale_fill_manual(values = cols, guide = guide_legend(title =
tr[12], ncol = 1, title.position = "top")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1,size = 4),
legend.position = "bottom", legend.justification = 0)

p

	[[alternative HTML version deleted]]


From pd@me@ @end|ng |rom cb@@dk  Sat Jun  6 10:25:36 2020
From: pd@me@ @end|ng |rom cb@@dk (Peter Dalgaard)
Date: Sat, 6 Jun 2020 08:25:36 +0000
Subject: [R] R 4.0.1 is released
Message-ID: <E3CC9F48-B248-43DF-82A5-E51EFDD0BFDD@cbs.dk>

The build system rolled up R-4.0.1.tar.gz (codename "See Things Now") this morning.

The list below details the changes in this release.

You can get the source code from

http://cran.r-project.org/src/base/R-4/R-4.0.1.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard

These are the checksums (md5 and SHA-256) for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = b9c44f9f78cab3184ad9898bebc854b4
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 4afa171cd982aaa60f0ba92e2e7bc5d6
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = 425fd186ac71e462e66af7fb33f86ab4
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 496062c138e2def06cebccddfb814ac6
MD5 (NEWS.3) = 012e7f4a80cc8ec947bf3f0ff6117ec8
MD5 (R-latest.tar.gz) = 8d199d11865c202cf2bd006e7f32dab7
MD5 (README) = f468f281c919665e276a1b691decbbe6
MD5 (RESOURCES) = 529223fd3ffef95731d0a87353108435
MD5 (THANKS) = 251d20510bfc3cc93b82c5a99f7efcc6
MD5 (VERSION-INFO.dcf) = 7d8af8c338a1e146f9471744d092078a
MD5 (R-4/R-4.0.1.tar.gz) = 8d199d11865c202cf2bd006e7f32dab7

2cde824a7b18958e5f06b391c801c8288be0f84fa8934b7ddefef23c67e60c09  AUTHORS
e6d6a009505e345fe949e1310334fcb0747f28dae2856759de102ab66b722cb4  COPYING
6095e9ffa777dd22839f7801aa845b31c9ed07f3d6bf8a26dc5d2dec8ccc0ef3  COPYING.LIB
eddf87b12197c7b3b19cbc9b11c1beab95b14e3dcd715bf37d2f6a8b2a72c2a1  FAQ
f87461be6cbaecc4dce44ac58e5bd52364b0491ccdadaf846cb9b452e9550f31  INSTALL
1dfd76a990f2a1b11ee4ff17284d18c2177179ee7bbaef51b32e1e7a58719596  NEWS
4e21b62f515b749f80997063fceab626d7258c7d650e81a662ba8e0640f12f62  NEWS.0
12b30c724117b1b2b11484673906a6dcd48a361f69fc420b36194f9218692d01  NEWS.1
e80de410c77f05ff2012fa70051b89119845f734a7fa5c55857e61e4ed7d5f6e  NEWS.2
7201d139947afa52b5e09d26dc01445edf444506264355b2185122bc1ed3dce0  NEWS.3
95fe24a4d8d8f8f888460c8f5fe4311cec656e7a1722d233218bc03861bc6f32  R-latest.tar.gz
2fdd3e90f23f32692d4b3a0c0452f2c219a10882033d1774f8cadf25886c3ddc  README
408737572ecc6e1135fdb2cf7a9dbb1a6cb27967c757f1771b8c39d1fd2f1ab9  RESOURCES
c9c7cb32308b4e560a22c858819ade9de524a602abd4e92d1c328c89f8037d73  THANKS
d3cdccb1b1645fce356d08892baa0587aa2aef2e851ad552d47cce856137d9b3  VERSION-INFO.dcf
95fe24a4d8d8f8f888460c8f5fe4311cec656e7a1722d233218bc03861bc6f32  R-4/R-4.0.1.tar.gz

This is the relevant part of the NEWS file

CHANGES IN R 4.0.1:

  NEW FEATURES:

    * paste() and paste0() gain a new optional argument recycle0.  When
      set to true, zero-length arguments are recycled leading to
      character(0) after the sep-concatenation, i.e., to the empty
      string "" if collapse is a string and to the zero-length value
      character(0) when collapse = NULL.

      A package whose code uses this should depend on R (>= 4.0.1).

    * The summary(<warnings>) method now maps the counts correctly to
      the warning messages.

  BUG FIXES:

    * aov(frml, ...) now also works where the formula deparses to more
      than 500 characters, thanks to a report and patch proposal by Jan
      Hauffa.

    * Fix a dozen places (code, examples) as Sys.setlocale() returns
      the new rather than the previous setting.

    * Fix for adding two complex grid units via sum().  Thanks to Gu
      Zuguang for the report and Thomas Lin Pedersen for the patch.

    * Fix parallel::mclapply(..., mc.preschedule=FALSE) to handle raw
      vector results correctly. PR#17779

    * Computing the base value, i.e., 2, "everywhere", now uses
      FLT_RADIX, as the original machar code looped indefinitely on the
      ppc64 architecture for the longdouble case.

    * In R 4.0.0, sort.list(x) when is.object(x) was true, e.g., for x
      <- I(letters), was accidentally using method = "radix".
      Consequently, e.g., merge(<data.frame>) was much slower than
      previously; reported in PR#17794.

    * plot(y ~ x, ylab = quote(y[i])) now works, as e.g., for xlab;
      related to PR#10525.

    * parallel::detect.cores(all.tests = TRUE) tries a matching OS name
      before the other tests (which were intended only for unknown
      OSes).

    * Parse data for raw strings is now recorded correctly. Reported by
      Gabor Csardi.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From m@n|@hmukherjee @end|ng |rom hotm@||@com  Sat Jun  6 11:42:49 2020
From: m@n|@hmukherjee @end|ng |rom hotm@||@com (Manish Mukherjee)
Date: Sat, 6 Jun 2020 09:42:49 +0000
Subject: [R] Dependent data validation in R
Message-ID: <MA1PR01MB3513091A15B791E38F84092CB9870@MA1PR01MB3513.INDPRD01.PROD.OUTLOOK.COM>

Hi All ,
I need help in creating dependent data validation in R while creating an excel workbook
So i have two columns one has country and other states . I have to create the excel workbook in such a way that when i select the one specific country , the corresponding states appear in the next column . Something similar to dependent input in shiny ,
Here is the code what i have written

wb <- createWorkbook()
addWorksheet(wb, "Input")
addWorksheet(wb, "list")

df = data.frame("Country"=c("India","US"))
df1=data.frame("IndiaStates"=c("tamilnadu","Andhra pradesh"))
df2=data.frame("USStates"=c("Texas","California"))

# Add drop-down values "
writeData(wb, sheet = "list", x = df, startCol = 1)
writeData(wb, sheet = "list", x = df1, startCol = 2)
writeData(wb, sheet = "list", x = df2, startCol = 3)
#Add drop-downs to the column
dataValidation(wb, "input", col = 1, rows = 2:5, type = "list", value =
                 "'db'!$A$2:$A$3")

dataValidation(wb, "input", col = 2, rows = 2:5, type = "list", value =
                 "'db'!$b$2:$b$3")

dataValidation(wb, "input", col = 3, rows = 2:5, type = "list", value =
                 "'db'!$c$2:$c$3")

saveWorkbook(wb, "dataValidationExample.xlsx", overwrite = TRUE)


The states should be in single column in exported excel workbook with dependent data validation


Thanks, and Regards

Manish Mukherjee



	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Jun  6 15:55:26 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 06 Jun 2020 06:55:26 -0700
Subject: [R] Dependent data validation in R
In-Reply-To: <MA1PR01MB3513091A15B791E38F84092CB9870@MA1PR01MB3513.INDPRD01.PROD.OUTLOOK.COM>
References: <MA1PR01MB3513091A15B791E38F84092CB9870@MA1PR01MB3513.INDPRD01.PROD.OUTLOOK.COM>
Message-ID: <ACC8241B-924A-4F4E-A009-59D1C501587F@dcn.davis.ca.us>

Why are you telling us all of this? Do you have a question about the R language? Dragging in stuff about Excel makes it seem like you just want us to do your work for you.

Try to be more specific about what your difficulty is with R. Here are some links that may help:

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette) 


On June 6, 2020 2:42:49 AM PDT, Manish Mukherjee <manishmukherjee at hotmail.com> wrote:
>Hi All ,
>I need help in creating dependent data validation in R while creating
>an excel workbook
>So i have two columns one has country and other states . I have to
>create the excel workbook in such a way that when i select the one
>specific country , the corresponding states appear in the next column .
>Something similar to dependent input in shiny ,
>Here is the code what i have written
>
>wb <- createWorkbook()
>addWorksheet(wb, "Input")
>addWorksheet(wb, "list")
>
>df = data.frame("Country"=c("India","US"))
>df1=data.frame("IndiaStates"=c("tamilnadu","Andhra pradesh"))
>df2=data.frame("USStates"=c("Texas","California"))
>
># Add drop-down values "
>writeData(wb, sheet = "list", x = df, startCol = 1)
>writeData(wb, sheet = "list", x = df1, startCol = 2)
>writeData(wb, sheet = "list", x = df2, startCol = 3)
>#Add drop-downs to the column
>dataValidation(wb, "input", col = 1, rows = 2:5, type = "list", value =
>                 "'db'!$A$2:$A$3")
>
>dataValidation(wb, "input", col = 2, rows = 2:5, type = "list", value =
>                 "'db'!$b$2:$b$3")
>
>dataValidation(wb, "input", col = 3, rows = 2:5, type = "list", value =
>                 "'db'!$c$2:$c$3")
>
>saveWorkbook(wb, "dataValidationExample.xlsx", overwrite = TRUE)
>
>
>The states should be in single column in exported excel workbook with
>dependent data validation
>
>
>Thanks, and Regards
>
>Manish Mukherjee
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From rob@|or@yth @end|ng |rom newc@@t|e@@c@uk  Sun Jun  7 12:59:14 2020
From: rob@|or@yth @end|ng |rom newc@@t|e@@c@uk (Rob Forsyth)
Date: Sun, 7 Jun 2020 10:59:14 +0000
Subject: [R] Using item difficulties from a fitted Partial Credit Model to
 predict person abilities in an extended dataset?
Message-ID: <5516A151-C1C8-42BD-B5D5-AAC8082BD3DF@newcastle.ac.uk>

I am using the eRm package to examine the properties of a clinical rating scale using a Partial Credit Model (PCM). I understand how to extract the person ability estimates (thetas) from a simple fitted PCM but I have a dataset with repeated observations over time (~1200 observations of the instrument in ~250 individuals). So as not to violate assumptions of conditional independence I've fitted the PCM to single observations drawn at random from each subject. This works but I would now like to use the item diffculty estimates from the fitted PCM to generate person-ability estimates for the remaining ~950 observations (at other timepoints) not used to fit the model; and I can't see from the eRm package documentation how to do this?

Advice very much appreciated
Rob

From bgunter@4567 @end|ng |rom gm@||@com  Sun Jun  7 17:15:21 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 7 Jun 2020 08:15:21 -0700
Subject: [R] 
 Using item difficulties from a fitted Partial Credit Model to
 predict person abilities in an extended dataset?
In-Reply-To: <5516A151-C1C8-42BD-B5D5-AAC8082BD3DF@newcastle.ac.uk>
References: <5516A151-C1C8-42BD-B5D5-AAC8082BD3DF@newcastle.ac.uk>
Message-ID: <CAGxFJbQfB+aGUgUa-CtfCewnkb9sbUDg_pnpaxr+9c2ysyGQLA@mail.gmail.com>

Such package/methodology specific questions may well go unanswered here.
They are essentially offtopic anyway: this list is about general R
programming questions and cannot be expected to support the ~ 20000
packages now in the ecosystem. I suggest that you contact the package
maintainer (?maintainer) for help or to find out what support resources may
be available.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Jun 7, 2020 at 3:59 AM Rob Forsyth <rob.forsyth at newcastle.ac.uk>
wrote:

> I am using the eRm package to examine the properties of a clinical rating
> scale using a Partial Credit Model (PCM). I understand how to extract the
> person ability estimates (thetas) from a simple fitted PCM but I have a
> dataset with repeated observations over time (~1200 observations of the
> instrument in ~250 individuals). So as not to violate assumptions of
> conditional independence I've fitted the PCM to single observations drawn
> at random from each subject. This works but I would now like to use the
> item diffculty estimates from the fitted PCM to generate person-ability
> estimates for the remaining ~950 observations (at other timepoints) not
> used to fit the model; and I can't see from the eRm package documentation
> how to do this?
>
> Advice very much appreciated
> Rob
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rob@|or@yth @end|ng |rom newc@@t|e@@c@uk  Sun Jun  7 17:31:54 2020
From: rob@|or@yth @end|ng |rom newc@@t|e@@c@uk (Rob Forsyth)
Date: Sun, 7 Jun 2020 15:31:54 +0000
Subject: [R] 
 Using item difficulties from a fitted Partial Credit Model to
 predict person abilities in an extended dataset?
In-Reply-To: <CAGxFJbQfB+aGUgUa-CtfCewnkb9sbUDg_pnpaxr+9c2ysyGQLA@mail.gmail.com>
References: <5516A151-C1C8-42BD-B5D5-AAC8082BD3DF@newcastle.ac.uk>
 <CAGxFJbQfB+aGUgUa-CtfCewnkb9sbUDg_pnpaxr+9c2ysyGQLA@mail.gmail.com>
Message-ID: <968BD577-CB95-4D71-B76A-2907FD1F2129@newcastle.ac.uk>

OK thanks for the guidance
Rob

> On 7 Jun 2020, at 16:15, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> ? External sender. Take care when opening links or attachments. Do not provide your login details.
> Such package/methodology specific questions may well go unanswered here. They are essentially offtopic anyway: this list is about general R programming questions and cannot be expected to support the ~ 20000 packages now in the ecosystem. I suggest that you contact the package maintainer (?maintainer) for help or to find out what support resources may be available.
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Sun, Jun 7, 2020 at 3:59 AM Rob Forsyth <rob.forsyth at newcastle.ac.uk> wrote:
> I am using the eRm package to examine the properties of a clinical rating scale using a Partial Credit Model (PCM). I understand how to extract the person ability estimates (thetas) from a simple fitted PCM but I have a dataset with repeated observations over time (~1200 observations of the instrument in ~250 individuals). So as not to violate assumptions of conditional independence I've fitted the PCM to single observations drawn at random from each subject. This works but I would now like to use the item diffculty estimates from the fitted PCM to generate person-ability estimates for the remaining ~950 observations (at other timepoints) not used to fit the model; and I can't see from the eRm package documentation how to do this?
> 
> Advice very much appreciated
> Rob
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Sun Jun  7 20:48:49 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sun, 7 Jun 2020 11:48:49 -0700
Subject: [R] 
 Using item difficulties from a fitted Partial Credit Model to
 predict person abilities in an extended dataset?
In-Reply-To: <968BD577-CB95-4D71-B76A-2907FD1F2129@newcastle.ac.uk>
References: <5516A151-C1C8-42BD-B5D5-AAC8082BD3DF@newcastle.ac.uk>
 <CAGxFJbQfB+aGUgUa-CtfCewnkb9sbUDg_pnpaxr+9c2ysyGQLA@mail.gmail.com>
 <968BD577-CB95-4D71-B76A-2907FD1F2129@newcastle.ac.uk>
Message-ID: <5612414e-43e4-5a23-f3fa-5bc1e2fd00ab@comcast.net>

There is a StackExchange forum dedicated to Quantitative Finance.


-- 

David.

On 6/7/20 8:31 AM, Rob Forsyth wrote:
> OK thanks for the guidance
> Rob
>
>> On 7 Jun 2020, at 16:15, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>> ? External sender. Take care when opening links or attachments. Do not provide your login details.
>> Such package/methodology specific questions may well go unanswered here. They are essentially offtopic anyway: this list is about general R programming questions and cannot be expected to support the ~ 20000 packages now in the ecosystem. I suggest that you contact the package maintainer (?maintainer) for help or to find out what support resources may be available.
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sun, Jun 7, 2020 at 3:59 AM Rob Forsyth <rob.forsyth at newcastle.ac.uk> wrote:
>> I am using the eRm package to examine the properties of a clinical rating scale using a Partial Credit Model (PCM). I understand how to extract the person ability estimates (thetas) from a simple fitted PCM but I have a dataset with repeated observations over time (~1200 observations of the instrument in ~250 individuals). So as not to violate assumptions of conditional independence I've fitted the PCM to single observations drawn at random from each subject. This works but I would now like to use the item diffculty estimates from the fitted PCM to generate person-ability estimates for the remaining ~950 observations (at other timepoints) not used to fit the model; and I can't see from the eRm package documentation how to do this?
>>
>> Advice very much appreciated
>> Rob
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From p@u|o@pheno| @end|ng |rom gm@||@com  Sun Jun  7 19:15:56 2020
From: p@u|o@pheno| @end|ng |rom gm@||@com (Paulo Figueiredo)
Date: Sun, 7 Jun 2020 18:15:56 +0100
Subject: [R] R 4.0.1 crashes with R commander
Message-ID: <4362ca7f-e88c-089f-8f2a-b6e7e1d9ac40@gmail.com>

Hi,

I just updated R from 4.0 to 4.0.1 and when trying to load R commander 
(both in R and RStudio) the programme crashes. Any suggestion?

Thanks


-- 
This email has been checked for viruses by Avast antivirus software.
https://www.avast.com/antivirus


From p@u|o@pheno| @end|ng |rom gm@||@com  Sun Jun  7 19:53:14 2020
From: p@u|o@pheno| @end|ng |rom gm@||@com (Paulo Figueiredo)
Date: Sun, 7 Jun 2020 18:53:14 +0100
Subject: [R] R 4.0.1 crashes with R Commander
Message-ID: <815fcd89-54d8-a079-94bf-8b6e0b56a72b@gmail.com>

Hi again,

as an update, I tried to open R Commander under R 32 bits and it worked, 
but not with R Studio choosing the 32 bit R.

Thus, trying to load R Commander under R Studio (32 and 64 bits) or R 64 
bits crashes the programmes. It only loads under 32 bit R 4.0.1.

Appreciate any help.

Cheers


-- 
This email has been checked for viruses by Avast antivirus software.
https://www.avast.com/antivirus


From n|ko@m@t@@ve|@@ @end|ng |rom gm@||@com  Sun Jun  7 23:39:15 2020
From: n|ko@m@t@@ve|@@ @end|ng |rom gm@||@com (Nikos Matsavelas)
Date: Mon, 8 Jun 2020 00:39:15 +0300
Subject: [R] Dynamic Programming in R
Message-ID: <1BCA1844-7297-4D13-B6BE-14A0C76E0A19@gmail.com>

Is there any package that implements Dynamic Programming like maximises/minizises the sum or product in a three way matrix in R?Like the problem that i have solved by hand (attached pdf file)

From |eg|d| @end|ng |rom un|t@@|t  Sun Jun  7 14:49:18 2020
From: |eg|d| @end|ng |rom un|t@@|t (EGIDI LEONARDO)
Date: Sun, 7 Jun 2020 12:49:18 +0000
Subject: [R] [R-pkgs] R: pivmet 0.3.0
In-Reply-To: <DB7PR04MB4714DDBBE318A4F7640A12B3B6860@DB7PR04MB4714.eurprd04.prod.outlook.com>
References: <DB7PR04MB4714DDBBE318A4F7640A12B3B6860@DB7PR04MB4714.eurprd04.prod.outlook.com>
Message-ID: <DB7PR04MB4714A8BB6BF07B57FE04B59CB6840@DB7PR04MB4714.eurprd04.prod.outlook.com>

Dear R users,

pivmet 0.3.0 for pivotal relabelling in Bayesian Mixture Models and Kmeans clustering with pivotal seeding is on CRAN .
The new updated version includes the following new features:


  *   multivariate mixtures
  *   bayesplot plots now available and linked to the package
  *   Stan divergences and diagnostics
  *   updated vignette

CRAN: https://CRAN.R-project.org/package=pivmet<https://cran.r-project.org/package=pivmet>
Github: https://github.com/LeoEgidi/pivmet

Cheers,

Leonardo Egidi
University of Trieste




________________________________
Da: EGIDI LEONARDO
Inviato: venerd? 5 giugno 2020 17:40
A: r-packages at r-project.org <r-packages at r-project.org>
Oggetto: pivmet 0.3.0

Dear R users,

pivmet 0.3.0 for pivotal relabelling in Bayesian Mixture Models and Kmeans clustering with pivotal seeding is on CRAN .
The new updated version includes the following new features:


  *   multivariate mixtures
  *   bayesplot plots now available and linked to the package
  *   Stan divergences and diagnostics
  *   updated vignette

CRAN: https://cran.r-project.org/web/packages/pivmet/index.html
Github: https://github.com/LeoEgidi/pivmet

Cheers,

Leonardo Egidi
University of Trieste


	[[alternative HTML version deleted]]


-------------- next part --------------
_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From j|ox @end|ng |rom mcm@@ter@c@  Mon Jun  8 15:43:46 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Mon, 8 Jun 2020 13:43:46 +0000
Subject: [R] R 4.0.1 crashes with R Commander
In-Reply-To: <27736_1591620860_058CsJa8002784_815fcd89-54d8-a079-94bf-8b6e0b56a72b@gmail.com>
References: <27736_1591620860_058CsJa8002784_815fcd89-54d8-a079-94bf-8b6e0b56a72b@gmail.com>
Message-ID: <5C475426-099C-4920-92B8-FF6B183654FC@mcmaster.ca>

Dear Paulo,

This is due to a known bug in R 4.0.1 for Windows that is general to Tcl/Tk. The bug should be fixed in the current patched version of R 4.0.1 for Windows, so you could use that or just go back to R 4.0.0. 

Best,
 John

  -----------------------------
  John Fox, Professor Emeritus
  McMaster University
  Hamilton, Ontario, Canada
  Web: http::/socserv.mcmaster.ca/jfox

> On Jun 7, 2020, at 1:53 PM, Paulo Figueiredo <paulo.phenol at gmail.com> wrote:
> 
> Hi again,
> 
> as an update, I tried to open R Commander under R 32 bits and it worked, but not with R Studio choosing the 32 bit R.
> 
> Thus, trying to load R Commander under R Studio (32 and 64 bits) or R 64 bits crashes the programmes. It only loads under 32 bit R 4.0.1.
> 
> Appreciate any help.
> 
> Cheers
> 
> 
> -- 
> This email has been checked for viruses by Avast antivirus software.
> https://www.avast.com/antivirus
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pd@|gd @end|ng |rom gm@||@com  Mon Jun  8 15:46:28 2020
From: pd@|gd @end|ng |rom gm@||@com (Peter Dalgaard)
Date: Mon, 8 Jun 2020 15:46:28 +0200
Subject: [R] R 4.0.1 crashes with R commander
In-Reply-To: <4362ca7f-e88c-089f-8f2a-b6e7e1d9ac40@gmail.com>
References: <4362ca7f-e88c-089f-8f2a-b6e7e1d9ac40@gmail.com>
Message-ID: <9FCF712D-1807-441C-9F67-E86996FEC835@gmail.com>

This was fixed by r78653, so should be in R-patched already

https://cran.r-project.org/bin/windows/base/rpatched.html

-pd

> On 7 Jun 2020, at 19:15 , Paulo Figueiredo <paulo.phenol at gmail.com> wrote:
> 
> Hi,
> 
> I just updated R from 4.0 to 4.0.1 and when trying to load R commander (both in R and RStudio) the programme crashes. Any suggestion?
> 
> Thanks
> 
> 
> -- 
> This email has been checked for viruses by Avast antivirus software.
> https://www.avast.com/antivirus
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Jun  8 15:47:25 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 8 Jun 2020 09:47:25 -0400
Subject: [R] R 4.0.1 crashes with R Commander
In-Reply-To: <815fcd89-54d8-a079-94bf-8b6e0b56a72b@gmail.com>
References: <815fcd89-54d8-a079-94bf-8b6e0b56a72b@gmail.com>
Message-ID: <62c47f43-ae45-601f-1d0f-9429dae5abc8@gmail.com>

On 07/06/2020 1:53 p.m., Paulo Figueiredo wrote:
> Hi again,
> 
> as an update, I tried to open R Commander under R 32 bits and it worked,
> but not with R Studio choosing the 32 bit R.
> 
> Thus, trying to load R Commander under R Studio (32 and 64 bits) or R 64
> bits crashes the programmes. It only loads under 32 bit R 4.0.1.

There's a report of a bug in 4.0.1 that causes this.  So far it's only 
known to affect Windows, but it may also affect other systems. The only 
thing you can do at the moment is install a nightly build of R-patched 
with revision number of at least r78653.  You can get it from here:

https://cloud.r-project.org/bin/windows/base/rpatched.html

Duncan Murdoch


From bgunter@4567 @end|ng |rom gm@||@com  Mon Jun  8 16:45:34 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 8 Jun 2020 07:45:34 -0700
Subject: [R] Dynamic Programming in R
In-Reply-To: <1BCA1844-7297-4D13-B6BE-14A0C76E0A19@gmail.com>
References: <1BCA1844-7297-4D13-B6BE-14A0C76E0A19@gmail.com>
Message-ID: <CAGxFJbQ6CgmWEObxRTRbobUnWzJD+XgbyODyQDSFgLTyS9mcug@mail.gmail.com>

Search before posting here!

"dynamic programming R" brought up several relevant hits.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 8, 2020 at 5:54 AM Nikos Matsavelas <nikosmatsavelas at gmail.com>
wrote:

> Is there any package that implements Dynamic Programming like
> maximises/minizises the sum or product in a three way matrix in R?Like the
> problem that i have solved by hand (attached pdf file)
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Mon Jun  8 17:37:46 2020
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Mon, 8 Jun 2020 17:37:46 +0200
Subject: [R] ggplot to visualize data
Message-ID: <CA+nrPnschdtZbRRd6GHe2d1=oN+0xuUu5iYzxdrPQH-Q-zbCFQ@mail.gmail.com>

I have a model NN, which has 10 piece of data in 10 folds of test (ts) data
such as 0.1, 0.5, 0.3 etc.
And another model SVM, which also have this type of information. I usually
visualize it like:

boxplot (NN, SVM)

I have two questions?

(1) I want to ask how can I visualize them via ggplot?

(2) If I have to process it again on another dataset, then how can I
combine these two boxplots in order to make a better prediction.

Regards

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Jun  8 17:41:35 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 8 Jun 2020 08:41:35 -0700
Subject: [R] ggplot to visualize data
In-Reply-To: <CA+nrPnschdtZbRRd6GHe2d1=oN+0xuUu5iYzxdrPQH-Q-zbCFQ@mail.gmail.com>
References: <CA+nrPnschdtZbRRd6GHe2d1=oN+0xuUu5iYzxdrPQH-Q-zbCFQ@mail.gmail.com>
Message-ID: <CAGxFJbQ_z4QUYFF1Rs4_Brp16JRRXxeJU-0W_Yo7OrsoPkDR1A@mail.gmail.com>

Largely off topic here. RStudio has Help forums on ggplot and other of its
R software products. Post there.
Or on stats.stackexchange.com perhaps for questions about how to visualize
statistical data.
See the posting guide linked below for what is ON topic here.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 8, 2020 at 8:38 AM Neha gupta <neha.bologna90 at gmail.com> wrote:

> I have a model NN, which has 10 piece of data in 10 folds of test (ts) data
> such as 0.1, 0.5, 0.3 etc.
> And another model SVM, which also have this type of information. I usually
> visualize it like:
>
> boxplot (NN, SVM)
>
> I have two questions?
>
> (1) I want to ask how can I visualize them via ggplot?
>
> (2) If I have to process it again on another dataset, then how can I
> combine these two boxplots in order to make a better prediction.
>
> Regards
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From neh@@bo|ogn@90 @end|ng |rom gm@||@com  Mon Jun  8 18:18:00 2020
From: neh@@bo|ogn@90 @end|ng |rom gm@||@com (Neha gupta)
Date: Mon, 8 Jun 2020 18:18:00 +0200
Subject: [R] ggplot to visualize data
In-Reply-To: <CAGxFJbQ_z4QUYFF1Rs4_Brp16JRRXxeJU-0W_Yo7OrsoPkDR1A@mail.gmail.com>
References: <CA+nrPnschdtZbRRd6GHe2d1=oN+0xuUu5iYzxdrPQH-Q-zbCFQ@mail.gmail.com>
 <CAGxFJbQ_z4QUYFF1Rs4_Brp16JRRXxeJU-0W_Yo7OrsoPkDR1A@mail.gmail.com>
Message-ID: <CA+nrPnv7LGnKJ8g1vPUB2hUoR4=t7MRM2Z=GVogdur8ELZtBeg@mail.gmail.com>

I am still waiting for someone to respond.

If someone want to help other, they do not need a special platform for it.

Thank you, yet again for not helping.

Regards

On Mon, Jun 8, 2020 at 5:41 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Largely off topic here. RStudio has Help forums on ggplot and other of its
> R software products. Post there.
> Or on stats.stackexchange.com perhaps for questions about how to
> visualize statistical data.
> See the posting guide linked below for what is ON topic here.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Jun 8, 2020 at 8:38 AM Neha gupta <neha.bologna90 at gmail.com>
> wrote:
>
>> I have a model NN, which has 10 piece of data in 10 folds of test (ts)
>> data
>> such as 0.1, 0.5, 0.3 etc.
>> And another model SVM, which also have this type of information. I usually
>> visualize it like:
>>
>> boxplot (NN, SVM)
>>
>> I have two questions?
>>
>> (1) I want to ask how can I visualize them via ggplot?
>>
>> (2) If I have to process it again on another dataset, then how can I
>> combine these two boxplots in order to make a better prediction.
>>
>> Regards
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From tr@xp|@yer @end|ng |rom gm@||@com  Mon Jun  8 19:22:28 2020
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Mon, 8 Jun 2020 19:22:28 +0200
Subject: [R] ggplot to visualize data
In-Reply-To: <CA+nrPnv7LGnKJ8g1vPUB2hUoR4=t7MRM2Z=GVogdur8ELZtBeg@mail.gmail.com>
References: <CA+nrPnschdtZbRRd6GHe2d1=oN+0xuUu5iYzxdrPQH-Q-zbCFQ@mail.gmail.com>
 <CAGxFJbQ_z4QUYFF1Rs4_Brp16JRRXxeJU-0W_Yo7OrsoPkDR1A@mail.gmail.com>
 <CA+nrPnv7LGnKJ8g1vPUB2hUoR4=t7MRM2Z=GVogdur8ELZtBeg@mail.gmail.com>
Message-ID: <CAGAA5bcf_gQLcGM+ytTNtifB8QjEar0+oaZ-34Htb=+oab4Lng@mail.gmail.com>

On Mon, 8 Jun 2020 at 18:25, Neha gupta <neha.bologna90 at gmail.com> wrote:

> I am still waiting for someone to respond.
>
>
Please read this guide about asking questions and try again on the correct
mailing-list.
https://www.r-project.org/posting-guide.html

Regards
Martin

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Jun  8 18:58:20 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 8 Jun 2020 17:58:20 +0100
Subject: [R] ggplot to visualize data
In-Reply-To: <CA+nrPnv7LGnKJ8g1vPUB2hUoR4=t7MRM2Z=GVogdur8ELZtBeg@mail.gmail.com>
References: <CA+nrPnschdtZbRRd6GHe2d1=oN+0xuUu5iYzxdrPQH-Q-zbCFQ@mail.gmail.com>
 <CAGxFJbQ_z4QUYFF1Rs4_Brp16JRRXxeJU-0W_Yo7OrsoPkDR1A@mail.gmail.com>
 <CA+nrPnv7LGnKJ8g1vPUB2hUoR4=t7MRM2Z=GVogdur8ELZtBeg@mail.gmail.com>
Message-ID: <3c0d8a32-ff1b-8ffb-9388-a753751155bc@sapo.pt>

Hello,

Inline.


?s 17:18 de 08/06/20, Neha gupta escreveu:
> I am still waiting for someone to respond.
> 
> If someone want to help other, they do not need a special platform for it.
> 
> Thank you, yet again for not helping.


1. You have waited 41 minutes.
2. You have not posted data and code.
3. Read the posting guide, please. It's not the first time you post 
questions, and this one does *not* give enough information for anyone to 
answer.
4. I wonder how you can have two models, NN and SVM, and run

boxplot(NN, SVM)

without error. Given the problem description, the code line above simply 
doesn't make sense.

So it's not our fault if you are not getting answers.

Do read the posting guide, please.


Rui Barradas

> 
> Regards
> 
> On Mon, Jun 8, 2020 at 5:41 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
>> Largely off topic here. RStudio has Help forums on ggplot and other of its
>> R software products. Post there.
>> Or on stats.stackexchange.com perhaps for questions about how to
>> visualize statistical data.
>> See the posting guide linked below for what is ON topic here.
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Mon, Jun 8, 2020 at 8:38 AM Neha gupta <neha.bologna90 at gmail.com>
>> wrote:
>>
>>> I have a model NN, which has 10 piece of data in 10 folds of test (ts)
>>> data
>>> such as 0.1, 0.5, 0.3 etc.
>>> And another model SVM, which also have this type of information. I usually
>>> visualize it like:
>>>

>>>
>>> I have two questions?
>>>
>>> (1) I want to ask how can I visualize them via ggplot?
>>>
>>> (2) If I have to process it again on another dataset, then how can I
>>> combine these two boxplots in order to make a better prediction.
>>>
>>> Regards
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Theodore@St@nkow|ch @end|ng |rom c@u|b@edu  Mon Jun  8 21:27:56 2020
From: Theodore@St@nkow|ch @end|ng |rom c@u|b@edu (Ted Stankowich)
Date: Mon, 8 Jun 2020 19:27:56 +0000
Subject: [R] phyl.RMA error
Message-ID: <BY5PR12MB418052F64481EA592994FD49F6850@BY5PR12MB4180.namprd12.prod.outlook.com>

Hello,

We're trying to run phylogenetically corrected reduced major axes regression analyses and have encountered an error we can't debug. We're using the function phyl.RMA in the package 'phytools'. Here is the code we are using and the error it returns.



>Model <- phyl.RMA(log(Skull), log(Tusk), tree, h0=1.0)

Error in if (sign(beta1) != sign(h0)) { :

  missing value where TRUE/FALSE needed

We can't seem to figure out which argument is missing, and we've tried including all of the T/F based arguments we think are possible. Our species dataset and nexus file are printed below.  Any advice would be greatly appreciated.

We have the following dataset:
Binomial                 Skull  Tusk
   <chr>                    <dbl> <dbl>
1 Tragulus_javanicus        93.7  14.6
2 Tragulus_kanchil          99.7  13.9
3 Tragulus_napu             98.1  11.1
4 Tragulus_nigricans        99.8  13.2
5 Moschiola_meminna        101.   14.6
6 Moschus_berezovskii      134.   55.0
7 Moschus_moschiferus      152.   52.9
8 Muntiacus_muntjak        193.   26.4
9 Muntiacus_reevesi        159.   23.4
10 Muntiacus_truongsonensis 184.   27.7
11 Muntiacus_vaginalis      203.   28.6
12 Hydropotes_inermis       162.   48.5
13 Hyemoschus_aquaticus     122.   20.1
14 Elaphodus_cephalophus    186.   17.3

And the following nexus tree:

#NEXUS
[R-package APE, Mon Jun 08 12:20:01 2020]

BEGIN TAXA;
              DIMENSIONS NTAX = 12;
              TAXLABELS
                             Tragulus_napu
                             Tragulus_kanchil
                             Tragulus_javanicus
                             Hyemoschus_aquaticus
                             Moschiola_meminna
                             Muntiacus_reevesi
                             Muntiacus_muntjak
                             Muntiacus_truongsonensis
                             Elaphodus_cephalophus
                             Hydropotes_inermis
                             Moschus_moschiferus
                             Moschus_berezovskii
              ;
END;
BEGIN TREES;
              TRANSLATE
                             1            Tragulus_napu,
                             2            Tragulus_kanchil,
                             3            Tragulus_javanicus,
                             4            Hyemoschus_aquaticus,
                             5            Moschiola_meminna,
                             6            Muntiacus_reevesi,
                             7            Muntiacus_muntjak,
                             8            Muntiacus_truongsonensis,
                             9            Elaphodus_cephalophus,
                             10          Hydropotes_inermis,
                             11          Moschus_moschiferus,
                             12          Moschus_berezovskii
              ;
              TREE * UNTITLED = [&R] ((((1:5.540957781,(2:2.978817423,3:2.978817423):2.562139698):10.78911152,4:16.33006601):6.360692368,5:22.69076035):5.725388419,(((((6:1.611149584,7:1.611149848):1.556474893,8:3.167624477):4.130280196,9:7.297904013):1.497063399,10:8.794967413):7.19682079,(11:2.539095678,12:2.539096008):13.45269085):12.42436025);



Dr. Ted Stankowich
Associate Professor
Department of Biological Sciences
California State University Long Beach
Long Beach, CA 90840
theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.edu>
562-985-4826
http://www.csulb.edu/mammal-lab/
@CSULBMammalLab




	[[alternative HTML version deleted]]


From motyoc@k@ @end|ng |rom y@hoo@com  Mon Jun  8 21:28:35 2020
From: motyoc@k@ @end|ng |rom y@hoo@com (Andras Farkas)
Date: Mon, 8 Jun 2020 19:28:35 +0000 (UTC)
Subject: [R] (almost) rolling function or fill?
References: <2102647901.806088.1591644515768.ref@mail.yahoo.com>
Message-ID: <2102647901.806088.1591644515768@mail.yahoo.com>

Hello,
please see if you have a thought on how to achieve the following:
we have:
 df<-data.frame(a=Sys.Date()+1:10,? ? ? ? ? ? ? ?b=Sys.Date()+c(NA,NA,NA,rep(3,4),NA,NA,3),? ? ? ? ? ? ? ?c=Sys.Date()+c(NA,NA,NA,rep(9,4),NA,NA,9))


the idea I have difficulty wrapping my head around is to do the following: I need the system to look at df$a by row (lets call it the index row) and look at df$b and df$c 1 row before the given row in df$a? (lets call it index row -1)?and evaluate if the index row value in df$a falls into the range (>= and <=) of the index row -1 values in df$b and df$c. If it does, then copy over?the index row -1 values in df$b and df$c into the index row in?df$b and df$c, if not place an NA in both cells of the?index row in?df$b and df$c.?
?examples:
1. the date value in df$a[8] is between df$b[7] and df$c[7] so we can copy the values in?df$b[7] and df$c[7] into?df$b[8] and df$c[8]2.??the date value in df$a[9] is between df$b[8] and df$c[8] (as we copied it in in step 1)? so we can copy the values in?df$b[8] and df$c[8] into?df$b[9] and df$c[9]3.??the date value in df$a[10] is NOT between df$b[9] and df$c[9] (as we copied it in in step 2)? so we can place NA in?df$b[10] and df$c[10]?

also would like to do this going up, too, similar to fill(...,"downup"). On the end we would want to have this:
 dfwanted<-data.frame(a=Sys.Date()+1:10,? ? ? ? ? ? ? ?b=Sys.Date()+c(NA,NA,rep(3,7),NA),? ? ? ? ? ? ? ?c=Sys.Date()+c(NA,NA,rep(9,7),NA))


much appreciate any help you could provide.
thanks,

Andras?
	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Jun  8 23:00:42 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 8 Jun 2020 14:00:42 -0700
Subject: [R] (almost) rolling function or fill?
In-Reply-To: <2102647901.806088.1591644515768@mail.yahoo.com>
References: <2102647901.806088.1591644515768.ref@mail.yahoo.com>
 <2102647901.806088.1591644515768@mail.yahoo.com>
Message-ID: <CAGxFJbRhkEekk403cmavG_FDi_dwzM_3rMHkm5Vi0NM=ij=zQw@mail.gmail.com>

This is a plain text list. Your html post was completely mangled. Re-post
in plain text, please.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 8, 2020 at 1:08 PM Andras Farkas via R-help <
r-help at r-project.org> wrote:

> Hello,
> please see if you have a thought on how to achieve the following:
> we have:
>  df<-data.frame(a=Sys.Date()+1:10,
>  b=Sys.Date()+c(NA,NA,NA,rep(3,4),NA,NA,3),
>  c=Sys.Date()+c(NA,NA,NA,rep(9,4),NA,NA,9))
>
>
> the idea I have difficulty wrapping my head around is to do the following:
> I need the system to look at df$a by row (lets call it the index row) and
> look at df$b and df$c 1 row before the given row in df$a  (lets call it
> index row -1) and evaluate if the index row value in df$a falls into the
> range (>= and <=) of the index row -1 values in df$b and df$c. If it does,
> then copy over the index row -1 values in df$b and df$c into the index row
> in df$b and df$c, if not place an NA in both cells of the index row in df$b
> and df$c.
>  examples:
> 1. the date value in df$a[8] is between df$b[7] and df$c[7] so we can copy
> the values in df$b[7] and df$c[7] into df$b[8] and df$c[8]2.  the date
> value in df$a[9] is between df$b[8] and df$c[8] (as we copied it in in step
> 1)  so we can copy the values in df$b[8] and df$c[8] into df$b[9] and
> df$c[9]3.  the date value in df$a[10] is NOT between df$b[9] and df$c[9]
> (as we copied it in in step 2)  so we can place NA in df$b[10] and df$c[10]
>
> also would like to do this going up, too, similar to fill(...,"downup").
> On the end we would want to have this:
>  dfwanted<-data.frame(a=Sys.Date()+1:10,
>  b=Sys.Date()+c(NA,NA,rep(3,7),NA),
>  c=Sys.Date()+c(NA,NA,rep(9,7),NA))
>
>
> much appreciate any help you could provide.
> thanks,
>
> Andras
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Jun  8 23:08:54 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 8 Jun 2020 14:08:54 -0700
Subject: [R] phyl.RMA error
In-Reply-To: <BY5PR12MB418052F64481EA592994FD49F6850@BY5PR12MB4180.namprd12.prod.outlook.com>
References: <BY5PR12MB418052F64481EA592994FD49F6850@BY5PR12MB4180.namprd12.prod.outlook.com>
Message-ID: <CAGxFJbQG5+4=RgqxLdW+tHr-uzOmRY+v8hSTcivx8yxTPjotTg@mail.gmail.com>

Do you have NA's or Infs in your beta1 due to the use of log(Skull) and
log(Tusk) in your modeling or did you misspell something?.

If it's not something "obvious" like that, you should probably post on the
r-sig-ecology list instead, where you are more likely to find both the
interest and expertise in this specialized topic. This list is for general
R language questions primarily.

Cheers,
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Jun 8, 2020 at 12:28 PM Ted Stankowich <
Theodore.Stankowich at csulb.edu> wrote:

> Hello,
>
> We're trying to run phylogenetically corrected reduced major axes
> regression analyses and have encountered an error we can't debug. We're
> using the function phyl.RMA in the package 'phytools'. Here is the code we
> are using and the error it returns.
>
>
>
> >Model <- phyl.RMA(log(Skull), log(Tusk), tree, h0=1.0)
>
> Error in if (sign(beta1) != sign(h0)) { :
>
>   missing value where TRUE/FALSE needed
>
> We can't seem to figure out which argument is missing, and we've tried
> including all of the T/F based arguments we think are possible. Our species
> dataset and nexus file are printed below.  Any advice would be greatly
> appreciated.
>
> We have the following dataset:
> Binomial                 Skull  Tusk
>    <chr>                    <dbl> <dbl>
> 1 Tragulus_javanicus        93.7  14.6
> 2 Tragulus_kanchil          99.7  13.9
> 3 Tragulus_napu             98.1  11.1
> 4 Tragulus_nigricans        99.8  13.2
> 5 Moschiola_meminna        101.   14.6
> 6 Moschus_berezovskii      134.   55.0
> 7 Moschus_moschiferus      152.   52.9
> 8 Muntiacus_muntjak        193.   26.4
> 9 Muntiacus_reevesi        159.   23.4
> 10 Muntiacus_truongsonensis 184.   27.7
> 11 Muntiacus_vaginalis      203.   28.6
> 12 Hydropotes_inermis       162.   48.5
> 13 Hyemoschus_aquaticus     122.   20.1
> 14 Elaphodus_cephalophus    186.   17.3
>
> And the following nexus tree:
>
> #NEXUS
> [R-package APE, Mon Jun 08 12:20:01 2020]
>
> BEGIN TAXA;
>               DIMENSIONS NTAX = 12;
>               TAXLABELS
>                              Tragulus_napu
>                              Tragulus_kanchil
>                              Tragulus_javanicus
>                              Hyemoschus_aquaticus
>                              Moschiola_meminna
>                              Muntiacus_reevesi
>                              Muntiacus_muntjak
>                              Muntiacus_truongsonensis
>                              Elaphodus_cephalophus
>                              Hydropotes_inermis
>                              Moschus_moschiferus
>                              Moschus_berezovskii
>               ;
> END;
> BEGIN TREES;
>               TRANSLATE
>                              1            Tragulus_napu,
>                              2            Tragulus_kanchil,
>                              3            Tragulus_javanicus,
>                              4            Hyemoschus_aquaticus,
>                              5            Moschiola_meminna,
>                              6            Muntiacus_reevesi,
>                              7            Muntiacus_muntjak,
>                              8            Muntiacus_truongsonensis,
>                              9            Elaphodus_cephalophus,
>                              10          Hydropotes_inermis,
>                              11          Moschus_moschiferus,
>                              12          Moschus_berezovskii
>               ;
>               TREE * UNTITLED = [&R]
> ((((1:5.540957781,(2:2.978817423,3:2.978817423):2.562139698):10.78911152,4:16.33006601):6.360692368,5:22.69076035):5.725388419,(((((6:1.611149584,7:1.611149848):1.556474893,8:3.167624477):4.130280196,9:7.297904013):1.497063399,10:8.794967413):7.19682079,(11:2.539095678,12:2.539096008):13.45269085):12.42436025);
>
>
>
> Dr. Ted Stankowich
> Associate Professor
> Department of Biological Sciences
> California State University Long Beach
> Long Beach, CA 90840
> theodore.stankowich at csulb.edu<mailto:theodore.stankowich at csulb.edu>
> 562-985-4826
> http://www.csulb.edu/mammal-lab/
> @CSULBMammalLab
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From V|ncent@Gou|et @end|ng |rom @ct@u|@v@|@c@  Mon Jun  8 16:46:08 2020
From: V|ncent@Gou|et @end|ng |rom @ct@u|@v@|@c@ (Vincent Goulet)
Date: Mon, 8 Jun 2020 14:46:08 +0000
Subject: [R] [R-pkgs] 3.0-0 milestone for actuar
Message-ID: <4E58D00B-0A44-47EA-810F-9EB09EDC02D2@act.ulaval.ca>

Dear useRs and developeRs,

We are proud to announce that version 3.0-0 of actuar is now available on CRAN.

This newest release further extends support of the package for heavy tail and extreme value size distributions. It also introduces a package API, so that developers may easily integrate our C code into their own package.

From the NEWS file:

? Support functions ?[dpqrm,lev]fpareto? for the Feller-Pareto
  distribution and related Pareto distributions with a
  location parameter. The Feller-Pareto defines a large family
  of distributions encompassing the transformed beta family
  and many variants of the Pareto distribution. Using the
  nomenclature of Arnold (2015), the following distributions
  are now supported by ?actuar?: Feller-Pareto, Pareto IV,
  Pareto III, and Pareto II. The Pareto I was already
  supported under the name Single Parameter Pareto.

? The package now exposes through an API its 200+ C routines
  for probability functions and the beta integral. This is
  documented in a new section of the ?distributions? package
  vignette. See file ?include/actuarAPI.h? in the package
  installation directory for the complete list of exported
  routines.

The complete NEWS is available on CRAN as usual:

	https://cran.r-project.org/web/packages/actuar/news.html

Cheers,

Vincent Goulet
Professor
?cole d'actuariat, Universit? Laval

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From |v@|ery @end|ng |rom out|ook@|r  Mon Jun  8 18:52:08 2020
From: |v@|ery @end|ng |rom out|ook@|r (=?utf-8?B?TG/Dr2MgVmFsw6lyeQ==?=)
Date: Mon, 8 Jun 2020 16:52:08 +0000
Subject: [R] Need help using GRASS within R - problem with CRS using the
 'v.generalize' command
Message-ID: <AM5PR0601MB2692F2F68C0EA1E1169E663BD0850@AM5PR0601MB2692.eurprd06.prod.outlook.com>

Dear all,

First of all, this is my first message on the list. Therefore, please be indulgent if my message is not perfectly formatted as it should be. 

I am currently encountering a difficulty with GRASS 7.8 within R when using the 'v.generalize' command to smooth the contour of polygons after a segmentation step.

I tried two different ways to "call" GRASS: 

          1 - using the RQGIS3 package
          2 - using the rgrass7 package

The first method returns an error message (i.e. "proj_create_from_database: Cannot find proj.db") and therefore does not produce any result.
The second method results in a layer of smoothed polygons but the projection reference (i.e. CRS) is lost whereas the input layer has one.

Since in both cases the problem seems to be the same (i.e. GRASS fails to access the projection information), I thought it was interesting to deal with these two cases simultaneously. So, below you will find two small examples - each dealing with one of the two procedures - in order to clarify the problem.

1 - Example using the RQGIS3 package :

> setwd("D:/test")
> library(sp)
> library(rgdal)
rgdal: version: 1.4-8, (SVN revision 845)
Geospatial Data Abstraction Library extensions to R successfully loaded
Loaded GDAL runtime: GDAL 2.2.3, released 2017/11/20
Path to GDAL shared files: C:/Users/toto/Documents/R/win-library/3.6/rgdal/gdal
GDAL binary built with GEOS: TRUE 
Loaded PROJ.4 runtime: Rel. 4.9.3, 15 August 2016, [PJ_VERSION: 493]
Path to PROJ.4 shared files: C:/Users/toto/Documents/R/win-library/3.6/rgdal/proj
Linking to sp version: 1.4-1 
> library(rgeos)
rgeos version: 0.5-3, (SVN revision 634)
GEOS runtime version: 3.8.0-CAPI-1.13.1 
Linking to sp version: 1.4-1 
Polygon checking: TRUE 
> library(raster)
> library(sf)
Linking to GEOS 3.8.0, GDAL 3.0.4, PROJ 6.3.1
> library(reticulate, lib.loc="C:/Users/toto/documents/RQGIS3")
> library(RQGIS3, lib.loc="C:/Users/toto/Documents/RQGIS3")

> # set the environment to run QGIS from within R
> set_env(root="C:/Program Files/QGIS 3.12")

$root
[1] "C:/Program Files/QGIS 3.12"

$qgis_prefix_path
[1] "C:/Program Files/QGIS 3.12/apps/qgis"

$python_plugins
[1] "C:/Program Files/QGIS 3.12/apps/qgis/python/plugins"

$platform
[1] "Windows"

 

> # Opening of the application
> open_app()
proj_create_from_database: Cannot find proj.db
proj_create_from_database: Cannot find proj.db

However, this does not completely prevent the package from working because I can find the function I want, call it and enter the input parameters. Here is an excerpt :

> # Search for the desired function within QGIS 3.12
> find_algorithms(search_term="generalize", name_only=TRUE)
[1] "grass7:v.generalize"

> # Information on how to use the selected function (here, the function 'generalize' from GRASS 7 within QGIS 3.12)
> get_usage(alg="grass7:v.generalize")
v.generalize (grass7:v.generalize)
Vector based generalization.
 ----------------
Input parameters
----------------

input: Input layer
         Parameter type:  QgsProcessingParameterFeatureSource
         Accepted data types:
                 - str: layer ID
                 - str: layer name
                 - str: layer source
                 - QgsProcessingFeatureSourceDefinition
                 - QgsProperty
                 - QgsVectorLayer
 
type: Input feature type
         Parameter type:  QgsProcessingParameterEnum
         Available values:
                 - 0: line
                 - 1: boundary
                 - 2: area
         Accepted data types:
                 - int
                 - str: as string representation of int
e.g. 1
                 - QgsProperty

 
> # Indicates the mandatory parameters
> params <- get_args_man(alg = "grass7:v.generalize")
Choosing default values for following parameters:
type: 0
method: 0
GRASS_OUTPUT_TYPE_PARAMETER: 0
See get_options('grass7:v.generalize') for all available options.

> # Input of mandatory parameters
> params$input<-"D:/test/seg_poly.shp"
> params$type<-"0"
> params$method<-"7"
> params$threshold<-1
> params$output<-"D:/test/smooth_seg_poly.shp"
> params$error<- "D:/test/smooth_seg_poly_error.shp"
> params$GRASS_OUTPUT_TYPE_PARAMETER<-"0"

But when I execute the function, R returns an error message that is related to the previous error message (i.e. when I executed the 'open_app()' command). Please find below the second error message :

> # Execution of the selected function
> out <- run_qgis(alg = "grass7:v.generalize",
+                 params = params,
+                 load_output = TRUE)

ERROR 1: PROJ: proj_identify: Cannot find proj.db
proj_create_from_wkt: Cannot find proj.db
proj_identify: Cannot find proj.db
Error in py_call_impl(callable, dots$args, dots$keywords) : 

  QgsProcessingException: There were errors executing the algorithm.

Detailed traceback: 
  File "C:/Program Files/QGIS 3.12/apps/qgis/python/plugins\processing\tools\general.py", line 106, in run
    return Processing.runAlgorithm(algOrName, parameters, onFinish, feedback, context)
  File "C:/Program Files/QGIS 3.12/apps/qgis/python/plugins\processing\core\Processing.py", line 181, in runAlgorithm
    raise QgsProcessingException(msg)

 

To help you find the solution to the problem, here are the results of some commands specifying the working environment :

> Sys.info()
       sysname        release        version       nodename        machine          login           user effective_user 
     "Windows"      "8.1 x64"   "build 9600"     "BERNACHE"       "x86-64"         "toto"         "toto"         "toto" 

> sessionInfo()
R version 3.6.3 (2020-02-29)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 8.1 x64 (build 9600)
Matrix products: default

locale:
[1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252    LC_MONETARY=French_France.1252 LC_NUMERIC=C                  
[5] LC_TIME=French_France.1252    
 
attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] RQGIS3_1.0.1.9000 reticulate_1.16   sf_0.9-3          raster_3.1-5      rgeos_0.5-3       rgdal_1.4-8       sp_1.4-2         

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.4.6       compiler_3.6.3     pillar_1.4.4       class_7.3-15       tools_3.6.3        jsonlite_1.6.1     tibble_3.0.1      
 [8] lifecycle_0.2.0    lattice_0.20-38    pkgconfig_2.0.3    rlang_0.4.6        Matrix_1.2-18      DBI_1.1.0          cli_2.0.2         
[15] rstudioapi_0.11    parallel_3.6.3     e1071_1.7-3        stringr_1.4.0      vctrs_0.3.0        hms_0.5.3          classInt_0.4-3    
[22] grid_3.6.3         glue_1.4.1         R6_2.4.1           fansi_0.4.1        readr_1.3.1        magrittr_1.5       codetools_0.2-16  
[29] ellipsis_0.3.1     units_0.6-6        assertthat_0.2.1   KernSmooth_2.23-16 stringi_1.4.6      crayon_1.3.4      

> qgis_session_info()

$gdal
[1] "3.0.4"

$grass7
[1] FALSE

$qgis_version
[1] "3.12.0-Bucure?ti"

$saga
[1] "2.3.2"

 Finally, since the problem probably comes from accessing the proj.db file, I ran the command Sys.getenv(?PROJ_LIB?) and R finds two locations?

> Sys.getenv("PROJ_LIB")
[1] "C:/Program Files/QGIS 3.12/share/proj;C:/Users/toto/Documents/R/win-library/3.6/rgdal/proj"

 
Please, note that, when searching on my computer, the file proj.db is also found in the following locations (which R does not seem to find) :
1.       C:/Users/toto/Documents/R/win-library/3.6/sf/proj
2.       C:/Programmes/GRASS GIS 7.8/share/proj
3.       C:/Programmes/QGIS 3.12/apps/Python3.7/lib/site-packages/pyproj/proj-dir/share/proj



2 - EXAMPLE USING THE RGRASS7 PACKAGE

seg_poly = a SpatialPolygonsDataFrame with CRS (cf. below) :

> setwd("D:/test")
> library(rgrass7)
> 
> # characteristics of the SpatialPolygonsDataFrame 'seg_poly' : CRS does exist
> seg_poly
class       : SpatialPolygonsDataFrame 
features    : 31 
extent      : 477371.3, 477397.6, 5631995, 5632020  (xmin, xmax, ymin, ymax)
crs         : +proj=utm +zone=32 +datum=WGS84 +units=m +no_defs 
variables   : 1
names       : Seg_ID 
min values  :      1 
max values  :     31 
Warning message:
In proj4string(x) : CRS object has comment, which is lost in output
> 
> # initialization of GRASS 7.8 from R
> initGRASS(gisBase ="C:/Program Files/GRASS GIS 7.8", home="temp/GRASS",gisDbase="temp/GRASS", use_g.dirseps.exe=F,remove_GISRC=T, override=T)
gisdbase    temp/GRASS 
location    file19685026c56 
mapset      file196829fa7141 
rows        1 
columns     1 
north       1 
south       0 
west        0 
east        1 
nsres       1 
ewres       1 
projection  NA 

I suspect that the problem comes from 'projection NA' when initializing GRASS (cf. just above)


Running GRASS : everything seems to be going fine...

> # specifies to GRASS that objects of type "sp" are used
> rgrass7::use_sp()
> 
> # export of the vector in GRASS format from the sp object 'seg_poly'
> writeVECT(seg_poly,"vec1",v.in.ogr_flags=c("o", "overwrite"), driver="ESRI Shapefile")
>

> # run the 'v.generalize' command to smooth the contours of polygons
> execGRASS("v.generalize",flag=c("overwrite"),parameters=list(input="vec1",
+                                                              output="GRASS_smooth_seg_poly",
+                                                              error="GRASS_smooth_seg_poly_error",
+                                                              method="distance_weighting",
+                                                              threshold=1))


...but when retrieving the result, the CRS has been lost :

> # retrieving the result of the 'v.generalize' command in a SpatialPolygonDataFrame : 'smooth_seg_poly'
> smooth_seg_poly<-readVECT("GRASS_smooth_seg_poly", with_prj=T, driver="ESRI Shapefile")
Exporting 31 areas (may take some time)...
 100%
VOUTOG~1 termin?. 31 features (Polygon type) written to <GRASS_sm>
(ESRI_Shapefile format).
OGR data source with driver: ESRI Shapefile 
Source: "D:\test\temp\GRASS\file19685026c56\file196829fa7141\.tmp\unknown", layer: "GRASS_sm"
with 31 features
It has 2 fields
Warning message:
In vColumns(vname) : vColumns: v.info -c output not in two columns:
Displaying column types/names for database connection of layer <1>:
> 
> # characteristics of the SpatialPolygonsDataFrame 'smoooth_seg_poly' : CRS no longer exists !!!
> smooth_seg_poly
class       : SpatialPolygonsDataFrame 
features    : 31 
extent      : 477371.3, 477397.6, 5631995, 5632020  (xmin, xmax, ymin, ymax)
crs         : NA 
variables   : 2
names       : cat, Seg_ID 
min values  :   1,      1 
max values  :  31,     31 


If it helps some info on my R session and on some environment variables (i.e. PROJ_LIB and GRASS_PROJSHARE)

> sessionInfo()
R version 3.6.3 (2020-02-29)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 8.1 x64 (build 9600)

Matrix products: default

locale:
[1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252    LC_MONETARY=French_France.1252 LC_NUMERIC=C                  
[5] LC_TIME=French_France.1252    

attached base packages:
[1] tools     stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] RSAGA_1.3.0         plyr_1.8.6          shapefiles_0.7      foreign_0.8-75      gstat_2.0-6         exactextractr_0.4.0 sf_0.9-3           
 [8] rgrass7_0.2-1       RSQLite_2.2.0       XML_3.99-0.3        RQGIS3_1.0.1.9000   reticulate_1.16     smoothr_0.1.2       maptools_1.0-1     
[15] link2GI_0.4.3       glue_1.4.1          listviewer_3.0.0    raster_3.1-5        rgeos_0.5-3         rgdal_1.5-8         sp_1.4-2           

loaded via a namespace (and not attached):
 [1] pkgload_1.0.2      bit64_0.9-7        jsonlite_1.6.1     R.utils_2.9.2      assertthat_0.2.1   blob_1.2.1         remotes_2.1.1     
 [8] sessioninfo_1.1.1  pillar_1.4.4       backports_1.1.7    lattice_0.20-38    digest_0.6.25      R.oo_1.23.0        htmltools_0.4.0   
[15] Matrix_1.2-18      pkgconfig_2.0.3    devtools_2.3.0     purrr_0.3.4        intervals_0.15.2   processx_3.4.2     tibble_3.0.1      
[22] usethis_1.6.1      ellipsis_0.3.1     withr_2.2.0        cli_2.0.2          magrittr_1.5       crayon_1.3.4       memoise_1.1.0     
[29] ps_1.3.3           R.methodsS3_1.8.0  fs_1.4.1           fansi_0.4.1        xts_0.12-0         xml2_1.3.2         class_7.3-15      
[36] FNN_1.1.3          pkgbuild_1.0.8     prettyunits_1.1.1  hms_0.5.3          lifecycle_0.2.0    stringr_1.4.0      callr_3.4.3       
[43] compiler_3.6.3     e1071_1.7-3        spacetime_1.2-3    rlang_0.4.6        classInt_0.4-3     units_0.6-6        grid_3.6.3        
[50] rstudioapi_0.11    htmlwidgets_1.5.1  testthat_2.3.2     codetools_0.2-16   DBI_1.1.0          roxygen2_7.1.0     R6_2.4.1          
[57] zoo_1.8-8          knitr_1.28         bit_1.1-15.2       rprojroot_1.3-2    KernSmooth_2.23-16 readr_1.3.1        desc_1.2.0        
[64] stringi_1.4.6      parallel_3.6.3     Rcpp_1.0.4.6       vctrs_0.3.0        xfun_0.14         
> 
> Sys.getenv("PROJ_LIB")
[1] "C:/Users/toto/Documents/R/win-library/3.6/rgdal/proj"
> Sys.getenv("GRASS_PROJSHARE")
[1] "NA\\share\\proj"

I guess that the "NA\\share\\proj" just above is not normal but I don't know precisely what path should be the right one...  and this anomaly may not be the only problem...

As a novice in the field, I would be very grateful for your help.
I remain at your entire disposal for any further information you may need to help me in finding a solution to this problem.

Yours sincerely,
Lo?c

From h||u @end|ng |rom w@ve|||e@c|@com  Mon Jun  8 21:58:21 2020
From: h||u @end|ng |rom w@ve|||e@c|@com (Hui Liu)
Date: Mon, 8 Jun 2020 19:58:21 +0000
Subject: [R] to read data for GCalignR package
Message-ID: <BN8PR04MB6259F64C7F6C96E12549E467D7850@BN8PR04MB6259.namprd04.prod.outlook.com>

Dear R-help colleagues,

I am looking for a way to read my txt file into R such that it can pass the check_input() function and be processed by in GCalignR.

The vignette mentioned to save data in txt format, with first row listing items, 2nd row listing RT and Area, third rows and afterwards concatenate multiple RT and area from items listed in first row.

I did this but did not find an effective way to import this data. Tried read.delim, scan, read individual and combine into a list. Saved to system.file and read as the example data. None worked.

Any suggestions?

Thank you very much.

Hui

Wave Life Sciences Email Confidentiality Notice: This message, including any attachments, is for use by the intended recipient(s) and may be proprietary, confidential and/or privileged. If you are not the intended recipient(s), please destroy all copies of this message and any attachments. Any use, forwarding, copying, or printing of this message or portion thereof by anyone other than the intended recipient(s) is prohibited. This email neither constitutes an agreement to conduct transactions by electronic means nor creates any legally binding contract or enforceable obligation in the absence of a fully signed written contract.

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: CDs02.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200608/44326c74/attachment.txt>

From jrkr|de@u @end|ng |rom gm@||@com  Tue Jun  9 00:08:11 2020
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Mon, 8 Jun 2020 18:08:11 -0400
Subject: [R] to read data for GCalignR package
In-Reply-To: <BN8PR04MB6259F64C7F6C96E12549E467D7850@BN8PR04MB6259.namprd04.prod.outlook.com>
References: <BN8PR04MB6259F64C7F6C96E12549E467D7850@BN8PR04MB6259.namprd04.prod.outlook.com>
Message-ID: <CAKZQJMDasKsL=+4K3Ntb8PfPPXic2saccL8kuaQDtNp2xk+-xQ@mail.gmail.com>

I am not sure what they are doing but have a look at
https://rdrr.io/cran/GCalignR/man/read_peak_list.html




On Mon, 8 Jun 2020 at 17:38, Hui Liu <hliu at wavelifesci.com> wrote:

> Dear R-help colleagues,
>
> I am looking for a way to read my txt file into R such that it can pass
> the check_input() function and be processed by in GCalignR.
>
> The vignette mentioned to save data in txt format, with first row listing
> items, 2nd row listing RT and Area, third rows and afterwards concatenate
> multiple RT and area from items listed in first row.
>
> I did this but did not find an effective way to import this data. Tried
> read.delim, scan, read individual and combine into a list. Saved to
> system.file and read as the example data. None worked.
>
> Any suggestions?
>
> Thank you very much.
>
> Hui
>
> Wave Life Sciences Email Confidentiality Notice: This message, including
> any attachments, is for use by the intended recipient(s) and may be
> proprietary, confidential and/or privileged. If you are not the intended
> recipient(s), please destroy all copies of this message and any
> attachments. Any use, forwarding, copying, or printing of this message or
> portion thereof by anyone other than the intended recipient(s) is
> prohibited. This email neither constitutes an agreement to conduct
> transactions by electronic means nor creates any legally binding contract
> or enforceable obligation in the absence of a fully signed written contract.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From motyoc@k@ @end|ng |rom y@hoo@com  Tue Jun  9 00:13:07 2020
From: motyoc@k@ @end|ng |rom y@hoo@com (Andras Farkas)
Date: Mon, 8 Jun 2020 22:13:07 +0000 (UTC)
Subject: [R] (almost) rolling or fill function?
References: <1502226575.863816.1591654387337.ref@mail.yahoo.com>
Message-ID: <1502226575.863816.1591654387337@mail.yahoo.com>

Thanks Bert, here it is in plain.



Hello,

please see if you have a thought on how to achieve the following:

we have:

df<-data.frame(a=Sys.Date()+1:10,
? ? ? ? ? ? ? ?b=Sys.Date()+c(NA,NA,NA,rep(3,4),NA,NA,3),
? ? ? ? ? ? ? ?c=Sys.Date()+c(NA,NA,NA,rep(9,4),NA,NA,9))



the idea I have difficulty wrapping my head around is to do the following: I need the system to look at df$a by row (lets call it the index row) and look at df$b and df$c 1 row before the given row in df$a??(lets call it index row -1)?and evaluate if the index row value in df$a falls into the range (>= and <=) of the index row -1 values in df$b and df$c. If it does, then copy over?the index row -1 values in df$b and df$c into the index row in?df$b and df$c, if not place an NA in both cells of the?index row in?df$b and df$c.?

?examples:

1. the date value in df$a[8] is between df$b[7] and df$c[7] so we can copy the values in?df$b[7] and df$c[7] into?df$b[8] and df$c[8]
2.??the date value in df$a[9] is between df$b[8] and df$c[8] (as we copied it in in step 1)? so we can copy the values in?df$b[8] and df$c[8] into?df$b[9] and df$c[9]
3.??the date value in df$a[10] is NOT between df$b[9] and df$c[9] (as we copied it in in step 2)? so we can place NA in?df$b[10] and df$c[10]?


also would like to do this going up, too, similar to fill(...,"downup"). On the end we would want to have this:

dfwanted<-data.frame(a=Sys.Date()+1:10,
? ? ? ? ? ? ? ?b=Sys.Date()+c(NA,NA,rep(3,7),NA),
? ? ? ? ? ? ? ?c=Sys.Date()+c(NA,NA,rep(9,7),NA))



much appreciate any help you could provide.

thanks,


Andras?


Andras?


From t@v|b@r @end|ng |rom gm@||@com  Tue Jun  9 08:44:19 2020
From: t@v|b@r @end|ng |rom gm@||@com (Micha Silver)
Date: Tue, 9 Jun 2020 09:44:19 +0300
Subject: [R] Need help using GRASS within R - problem with CRS using the
 'v.generalize' command
In-Reply-To: <AM5PR0601MB2692F2F68C0EA1E1169E663BD0850@AM5PR0601MB2692.eurprd06.prod.outlook.com>
References: <AM5PR0601MB2692F2F68C0EA1E1169E663BD0850@AM5PR0601MB2692.eurprd06.prod.outlook.com>
Message-ID: <dabf4146-6c35-030b-e7ff-2b88b6ef117b@gmail.com>

Hello


On 08/06/2020 19:52, Lo?c Val?ry wrote:
> Dear all,
>
> First of all, this is my first message on the list. Therefore, please be indulgent if my message is not perfectly formatted as it should be.
>
> I am currently encountering a difficulty with GRASS 7.8 within R when using the 'v.generalize' command to smooth the contour of polygons after a segmentation step.
>
> I tried two different ways to "call" GRASS:
>
>            1 - using the RQGIS3 package

My first suggestion: no need for getting QGIS involved here. That's an 
extra layer of complication that seems unnecessary, given your goal of 
using the GRASS module, v.generalize.


>            2 - using the rgrass7 package
>
> The first method returns an error message (i.e. "proj_create_from_database: Cannot find proj.db") and therefore does not produce any result.
> The second method results in a layer of smoothed polygons but the projection reference (i.e. CRS) is lost whereas the input layer has one.
>
> Since in both cases the problem seems to be the same (i.e. GRASS fails to access the projection information), I thought it was interesting to deal with these two cases simultaneously. So, below you will find two small examples - each dealing with one of the two procedures - in order to clarify the problem.
>
> 1 - Example using the RQGIS3 package :
>
>> setwd("D:/test")
>> library(sp)
>> library(rgdal)
> rgdal: version: 1.4-8, (SVN revision 845)
> Geospatial Data Abstraction Library extensions to R successfully loaded
> Loaded GDAL runtime: GDAL 2.2.3, released 2017/11/20
> Path to GDAL shared files: C:/Users/toto/Documents/R/win-library/3.6/rgdal/gdal
> GDAL binary built with GEOS: TRUE
> Loaded PROJ.4 runtime: Rel. 4.9.3, 15 August 2016, [PJ_VERSION: 493]
> Path to PROJ.4 shared files: C:/Users/toto/Documents/R/win-library/3.6/rgdal/proj
> Linking to sp version: 1.4-1


Please note that you have older versions of GDAL (2.2.3 here) and PROJ.4 
(4.9 here). These are currently being replaced by GDAL 3.0 and PROJ 6.3. 
You might (should) want to follow the discussion the the r-sig-geo maillist:


https://stat.ethz.ch/pipermail/r-sig-geo/2020-June/028165.html


....... (skipped all the discussion regarding RQGIS3 as I think it's not 
relevant)
>
>
> 2 - EXAMPLE USING THE RGRASS7 PACKAGE
>
> seg_poly = a SpatialPolygonsDataFrame with CRS (cf. below) :
>
>> setwd("D:/test")
>> library(rgrass7)
>>
>> # characteristics of the SpatialPolygonsDataFrame 'seg_poly' : CRS does exist
>> seg_poly
> class       : SpatialPolygonsDataFrame
> features    : 31
> extent      : 477371.3, 477397.6, 5631995, 5632020  (xmin, xmax, ymin, ymax)
> crs         : +proj=utm +zone=32 +datum=WGS84 +units=m +no_defs
> variables   : 1
> names       : Seg_ID
> min values  :      1
> max values  :     31
> Warning message:
> In proj4string(x) : CRS object has comment, which is lost in output
>> # initialization of GRASS 7.8 from R
>> initGRASS(gisBase ="C:/Program Files/GRASS GIS 7.8", home="temp/GRASS",gisDbase="temp/GRASS", use_g.dirseps.exe=F,remove_GISRC=T, override=T)
> gisdbase    temp/GRASS
> location    file19685026c56
> mapset      file196829fa7141
> rows        1
> columns     1
> north       1
> south       0
> west        0
> east        1
> nsres       1
> ewres       1
> projection  NA
>
> I suspect that the problem comes from 'projection NA' when initializing GRASS (cf. just above)


What you need to do here is setup the CRS of your new location. 
Typically, you would run initGRASS and point to a *previously created*? 
LOCATION, with CRS already defined. In this case, since you are creating 
a new location, you must define it's coordinate system. (GRASS is very 
"picky" about that).

Here's a GIS Stackexchange post that explains:

https://gis.stackexchange.com/questions/183032/create-a-new-grass-database-in-r-with-crs-projection


You can derive the full proj4 string from your sp object with:


p4str = sp::proj4string(seg_poly)


Then use that to set the project parameters for the new LOCATION, with

execGRASS("g.proj", flags = "c", proj4 = p4str) Now you should be able 
to continue with...


>> execGRASS("v.generalize",flag=c("overwrite"),parameters=list(input="vec1",
> +                                                              output="GRASS_smooth_seg_poly",
> +                                                              error="GRASS_smooth_seg_poly_error",
> +                                                              method="distance_weighting",
> +                                                              threshold=1))
>
>
>
> As a novice in the field, I would be very grateful for your help.
> I remain at your entire disposal for any further information you may need to help me in finding a solution to this problem.
>
> Yours sincerely,
> Lo?c
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Micha Silver
Ben Gurion Univ.
Sde Boker, Remote Sensing Lab
cell: +972-523-665918
https://orcid.org/0000-0002-1128-1325


From petr@p|k@| @end|ng |rom prechez@@cz  Tue Jun  9 13:20:43 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 9 Jun 2020 11:20:43 +0000
Subject: [R] almost logistic data evaluation
Message-ID: <9ade43c225ea496e9ca8f0acc50ba767@SRVEXCHCM1302.precheza.cz>

Dear all

I have several files with data like those.

> dput(temp)
temp <- structure(list(V1 = c(0L, 15L, 30L, 45L, 60L, 75L, 90L, 105L, 
120L, 135L, 150L, 165L, 180L, 195L, 210L, 225L, 240L, 255L, 270L, 
285L, 300L, 315L, 330L, 345L, 360L), V2 = c(98.68666667, 100.8, 
103.28, 107.44, 110.06, 114.26, 117.6, 121.04, 123.8533333, 126.66, 
129.98, 134.1866667, 139.04, 144.6, 152.08, 161.3, 169.8733333, 
176.6133333, 181.92, 186.0266667, 188.7533333, 190.7066667, 192.0533333, 
192.9933333, 193.3533333)), class = "data.frame", row.names = c(NA, 
-25L))

plot(temp)

They resemble logistics curve but they do not start as flat curve but
growing curve. Can you please give me some hints how to deal with such data?
I know that it is not strictly speaking R question but maybe somebody could
give me directions how to model such data and find model parameters.

I considered stepwise regression but it is not completely satisfactory.

Thanks beforehand
Petr Pikal

From petr@p|k@| @end|ng |rom prechez@@cz  Tue Jun  9 14:29:27 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 9 Jun 2020 12:29:27 +0000
Subject: [R] almost logistic data evaluation
In-Reply-To: <CAJc=yOF42mNL6pF6tVvPbqSixHLY5B=TWkF94VGk6QfnbEDLiA@mail.gmail.com>
References: <9ade43c225ea496e9ca8f0acc50ba767@SRVEXCHCM1302.precheza.cz>
 <CAJc=yOF42mNL6pF6tVvPbqSixHLY5B=TWkF94VGk6QfnbEDLiA@mail.gmail.com>
Message-ID: <bee44a52463e42e2bcb60249e0cde5e6@SRVEXCHCM1302.precheza.cz>

Hallo Patrick

 

Thanks. Actually ?y? is growing temperature, which, at some point, rise more rapidly due to exothermic reaction. This reaction starts and ends and proceed with some speed (hopefully different in each material). I hope to get starting point and speed of temperature rise by evaluating shape of curves.

 

I do not think left censoring could help. As seen from data plot at first ?y? is linearly growing but logistics curve needs to start from flat (left asymptote) and end as flat (right asymptote, AFAIK). With linear growth on left site simple logistics fail to model data correctly.

 

One option could be to estimate linear part and deduct it from the data and fit simple logistics model on deducted data. If this is the only way, I will do it but I, as always, first try to ask helpful and ingenious people on this list.

 

Cheers

Petr

 

From: Patrick (Malone Quantitative) <malone at malonequantitative.com> 
Sent: Tuesday, June 9, 2020 2:05 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Subject: Re: [R] almost logistic data evaluation

 

Off-list because off-topic.

 

I didn't plot your data, but took your word that "They resemble logistics curve but they do not start as flat curve but
growing curve."

 

You also didn't say what your research question is. But if you're trying to model the growth, could it be *part* of a logistic curve, with a censoring point on the left? Maybe that helps with some avenues.

 

On Tue, Jun 9, 2020 at 7:21 AM PIKAL Petr <petr.pikal at precheza.cz <mailto:petr.pikal at precheza.cz> > wrote:

Dear all

I have several files with data like those.

> dput(temp)
temp <- structure(list(V1 = c(0L, 15L, 30L, 45L, 60L, 75L, 90L, 105L, 
120L, 135L, 150L, 165L, 180L, 195L, 210L, 225L, 240L, 255L, 270L, 
285L, 300L, 315L, 330L, 345L, 360L), V2 = c(98.68666667, 100.8, 
103.28, 107.44, 110.06, 114.26, 117.6, 121.04, 123.8533333, 126.66, 
129.98, 134.1866667, 139.04, 144.6, 152.08, 161.3, 169.8733333, 
176.6133333, 181.92, 186.0266667, 188.7533333, 190.7066667, 192.0533333, 
192.9933333, 193.3533333)), class = "data.frame", row.names = c(NA, 
-25L))

plot(temp)

They resemble logistics curve but they do not start as flat curve but
growing curve. Can you please give me some hints how to deal with such data?
I know that it is not strictly speaking R question but maybe somebody could
give me directions how to model such data and find model parameters.

I considered stepwise regression but it is not completely satisfactory.

Thanks beforehand
Petr Pikal
______________________________________________
R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



-- 

Patrick S. Malone, Ph.D., Malone Quantitative
NEW Service Models: http://malonequantitative.com

He/Him/His


From SUSANA@ALBERICHMESA @end|ng |rom o@@k|detz@@eu@  Tue Jun  9 13:33:24 2020
From: SUSANA@ALBERICHMESA @end|ng |rom o@@k|detz@@eu@ (SUSANA ALBERICH MESA)
Date: Tue, 9 Jun 2020 11:33:24 +0000
Subject: [R] Error in ordinal mixed effects
Message-ID: <70265D6234EC4C44A70A59B2825EF54E0115B74049@S800000MBX01.osakidetza.svs.local>

Hi,
I'm trying to run an ordinal mixed effects model with Mixor command. I have 65 cases and repeated visits in 0, 6, 9, 12 and 18 months. My code is the following:

cannabis<-c(datos$cannabis0, datos$cannabis6, datos$cannabis9, datos$cannabis12, datos$cannabis18)
time<-c(rep(0, 65), rep(6, 65), rep(9, 65), rep(12, 65), rep(18, 65))
id<-c(rep(datos$id, 5))
group<-c(rep(datos$group, 5))

res<-data.frame(cbind(id, group, time, cannabis))
names(res)<-c("id", "group", "time", "cannabis")
res<-res[order(res$id),]

cannabismod<-mixor(cannabis~ time + as.factor(group), data=res, id=id, na.exclude, which.random.slope=na, link="logit")
summary(cannabismod)


However, I have obtained this error:

Error in xj[i] : invalid subscript type 'closure'

Please, could anyone help me to solve it?

Many thanks,
Susana

[https://edukiak.osakidetza.net/coronavirus/pie_email7.jpg]



	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jun  9 15:57:26 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 09 Jun 2020 06:57:26 -0700
Subject: [R] Error in ordinal mixed effects
In-Reply-To: <70265D6234EC4C44A70A59B2825EF54E0115B74049@S800000MBX01.osakidetza.svs.local>
References: <70265D6234EC4C44A70A59B2825EF54E0115B74049@S800000MBX01.osakidetza.svs.local>
Message-ID: <A89F6684-354B-4D81-83B1-5591C91A8813@dcn.davis.ca.us>

Can't tell... example is not reproducible because it is missing "datos'.

On June 9, 2020 4:33:24 AM PDT, SUSANA ALBERICH MESA <SUSANA.ALBERICHMESA at osakidetza.eus> wrote:
>Hi,
>I'm trying to run an ordinal mixed effects model with Mixor command. I
>have 65 cases and repeated visits in 0, 6, 9, 12 and 18 months. My code
>is the following:
>
>cannabis<-c(datos$cannabis0, datos$cannabis6, datos$cannabis9,
>datos$cannabis12, datos$cannabis18)
>time<-c(rep(0, 65), rep(6, 65), rep(9, 65), rep(12, 65), rep(18, 65))
>id<-c(rep(datos$id, 5))
>group<-c(rep(datos$group, 5))
>
>res<-data.frame(cbind(id, group, time, cannabis))
>names(res)<-c("id", "group", "time", "cannabis")
>res<-res[order(res$id),]
>
>cannabismod<-mixor(cannabis~ time + as.factor(group), data=res, id=id,
>na.exclude, which.random.slope=na, link="logit")
>summary(cannabismod)
>
>
>However, I have obtained this error:
>
>Error in xj[i] : invalid subscript type 'closure'
>
>Please, could anyone help me to solve it?
>
>Many thanks,
>Susana
>
>[https://edukiak.osakidetza.net/coronavirus/pie_email7.jpg]
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Tue Jun  9 16:51:05 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 9 Jun 2020 07:51:05 -0700
Subject: [R] Error in ordinal mixed effects
In-Reply-To: <70265D6234EC4C44A70A59B2825EF54E0115B74049@S800000MBX01.osakidetza.svs.local>
References: <70265D6234EC4C44A70A59B2825EF54E0115B74049@S800000MBX01.osakidetza.svs.local>
Message-ID: <CAGxFJbS5sM593BkT_sDNtXLY=5dkxz7VOhxRwesqWdnkjja_OA@mail.gmail.com>

Not sure, and we don't have your data, datos, but this is almost always a
bad thing to do:

res<-data.frame(cbind(id, group, time, cannabis))

Change it to:

res<-data.frame(id, group, time, cannabis)
## and you then won't need to name them either

and see if that fixes things.
Also, res$id is probably a factor: is order(res$id) really meaningful as a
subscript?

Cheers,
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jun 9, 2020 at 6:01 AM SUSANA ALBERICH MESA
<SUSANA.ALBERICHMESA at osakidetza.eus> wrote:

> Hi,
> I'm trying to run an ordinal mixed effects model with Mixor command. I
> have 65 cases and repeated visits in 0, 6, 9, 12 and 18 months. My code is
> the following:
>
> cannabis<-c(datos$cannabis0, datos$cannabis6, datos$cannabis9,
> datos$cannabis12, datos$cannabis18)
> time<-c(rep(0, 65), rep(6, 65), rep(9, 65), rep(12, 65), rep(18, 65))
> id<-c(rep(datos$id, 5))
> group<-c(rep(datos$group, 5))
>
> res<-data.frame(cbind(id, group, time, cannabis))
> names(res)<-c("id", "group", "time", "cannabis")
> res<-res[order(res$id),]
>
> cannabismod<-mixor(cannabis~ time + as.factor(group), data=res, id=id,
> na.exclude, which.random.slope=na, link="logit")
> summary(cannabismod)
>
>
> However, I have obtained this error:
>
> Error in xj[i] : invalid subscript type 'closure'
>
> Please, could anyone help me to solve it?
>
> Many thanks,
> Susana
>
> [https://edukiak.osakidetza.net/coronavirus/pie_email7.jpg]
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Tue Jun  9 17:00:36 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Tue, 9 Jun 2020 16:00:36 +0100
Subject: [R] Error in ordinal mixed effects
In-Reply-To: <70265D6234EC4C44A70A59B2825EF54E0115B74049@S800000MBX01.osakidetza.svs.local>
References: <70265D6234EC4C44A70A59B2825EF54E0115B74049@S800000MBX01.osakidetza.svs.local>
Message-ID: <30e89b76-d72c-bef6-25c1-620e482e5e49@dewey.myzen.co.uk>

Dear Susana

Without your dat  it is hard to say (and it would have helped to know 
where mixor() comes from) but this almost always means that ne of your 
parameters to the call is not what you thought it was so trying str(res) 
might be enlightening. Also I do not see anywhere in your example where 
you define na unless it is really NA and you did not copy it correctly.

Michael

On 09/06/2020 12:33, SUSANA ALBERICH MESA wrote:
> Hi,
> I'm trying to run an ordinal mixed effects model with Mixor command. I have 65 cases and repeated visits in 0, 6, 9, 12 and 18 months. My code is the following:
> 
> cannabis<-c(datos$cannabis0, datos$cannabis6, datos$cannabis9, datos$cannabis12, datos$cannabis18)
> time<-c(rep(0, 65), rep(6, 65), rep(9, 65), rep(12, 65), rep(18, 65))
> id<-c(rep(datos$id, 5))
> group<-c(rep(datos$group, 5))
> 
> res<-data.frame(cbind(id, group, time, cannabis))
> names(res)<-c("id", "group", "time", "cannabis")
> res<-res[order(res$id),]
> 
> cannabismod<-mixor(cannabis~ time + as.factor(group), data=res, id=id, na.exclude, which.random.slope=na, link="logit")
> summary(cannabismod)
> 
> 
> However, I have obtained this error:
> 
> Error in xj[i] : invalid subscript type 'closure'
> 
> Please, could anyone help me to solve it?
> 
> Many thanks,
> Susana
> 
> [https://edukiak.osakidetza.net/coronavirus/pie_email7.jpg]
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From S@E|||@on @end|ng |rom LGCGroup@com  Tue Jun  9 19:10:59 2020
From: S@E|||@on @end|ng |rom LGCGroup@com (Stephen Ellison)
Date: Tue, 9 Jun 2020 17:10:59 +0000
Subject: [R] almost logistic data evaluation
In-Reply-To: <bee44a52463e42e2bcb60249e0cde5e6@SRVEXCHCM1302.precheza.cz>
References: <9ade43c225ea496e9ca8f0acc50ba767@SRVEXCHCM1302.precheza.cz>
 <CAJc=yOF42mNL6pF6tVvPbqSixHLY5B=TWkF94VGk6QfnbEDLiA@mail.gmail.com>,
 <bee44a52463e42e2bcb60249e0cde5e6@SRVEXCHCM1302.precheza.cz>
Message-ID: <c51c48b110764b4fa966602de2d6028d@GBDCVPEXC08.corp.lgc-group.com>

> Actually ?y? is growing temperature, which, at some point, rise more rapidly due to exothermic reaction. 
> This reaction starts and ends and proceed with some speed (hopefully different in each material). 

Are you applying external heating or is it solely due to reaction kinetics?


Steve E

*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From j@vedbtk111 @end|ng |rom gm@||@com  Tue Jun  9 23:08:53 2020
From: j@vedbtk111 @end|ng |rom gm@||@com (javed khan)
Date: Tue, 9 Jun 2020 23:08:53 +0200
Subject: [R] Error in code (no applicable method for 'train' applied to an
 object of class "formula" )
Message-ID: <CAJhui+sn5vgMC+vqNY+oB44D4h9Wf9bFwLcWbKjrtRDRoq4feA@mail.gmail.com>

Greetings, till yesterday the following code was executed normally but
today, it give me the following error:

 Error in UseMethod("train") :
  no applicable method for 'train' applied to an object of class "formula"


I have tried other methods also such as rf, pls, but all gives the same
error message. Could you plz guide why it happens?

data=readARFF("albrecht.arff")

index <- createDataPartition(data$Effort, p = .70,list = FALSE)
tr <- data[index, ]
ts <- data[-index, ]

CV <- trainControl(method = "repeatedcv", number=10, repeats=10)

m1 <- train(Effort ~ ., data = tr,
                 method = "mlp",
                 metric = "RMSE",
                 preProc = c("center", "scale"),
                 trControl = CV)

m1

My data structure is the following

structure(list(Input = c(25, 193, 70, 40), Output = c(150, 98,
27, 60), Inquiry = c(75, 70, 0, 20), File = c(60, 36, 12, 12),
    FPAdj = c(1, 1, 0.8, 1.15), RawFPcounts = c(1750, 1902, 535,
    660), AdjFP = c(1750, 1902, 428, 759), Effort = c(102.4,
    105.2, 11.1, 21.1)), row.names = c(NA, 4L), class = "data.frame")

	[[alternative HTML version deleted]]


From pd@me@ @end|ng |rom cb@@dk  Tue Jun  9 23:28:03 2020
From: pd@me@ @end|ng |rom cb@@dk (Peter Dalgaard)
Date: Tue, 9 Jun 2020 21:28:03 +0000
Subject: [R] [Rd] R 4.0.2 scheduled for June 22
Message-ID: <270EFEE1-89B1-48F7-BBD6-E66B46D1C32C@cbs.dk>

Unfortunatly, a memory allocation bug prevented the R Commander package from working on Windows. This is fixed in R-patched, but we cannot have this not working in the official release when IT departments start installing for the Fall semester, so we need to issue a new release.

Full schedule is available on developer.r-project.org.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From j|ox @end|ng |rom mcm@@ter@c@  Tue Jun  9 23:37:50 2020
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Tue, 9 Jun 2020 21:37:50 +0000
Subject: [R] [Rd] R 4.0.2 scheduled for June 22
In-Reply-To: <4168_1591738244_059LUFtX007139_270EFEE1-89B1-48F7-BBD6-E66B46D1C32C@cbs.dk>
References: <4168_1591738244_059LUFtX007139_270EFEE1-89B1-48F7-BBD6-E66B46D1C32C@cbs.dk>
Message-ID: <F16DCD72-2D0C-47D4-ABDB-196BB02B63E1@mcmaster.ca>

Dear Peter,

Thank you very much for this.

To clarify slightly, the bug affects not just the Rcmdr package but use of the tcltk package on Windows more generally.

Best,
 John

  -----------------------------
  John Fox, Professor Emeritus
  McMaster University
  Hamilton, Ontario, Canada
  Web: http::/socserv.mcmaster.ca/jfox

> On Jun 9, 2020, at 5:28 PM, Peter Dalgaard via R-help <r-help at r-project.org> wrote:
> 
> Unfortunatly, a memory allocation bug prevented the R Commander package from working on Windows. This is fixed in R-patched, but we cannot have this not working in the official release when IT departments start installing for the Fall semester, so we need to issue a new release.
> 
> Full schedule is available on developer.r-project.org.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> _______________________________________________
> R-announce at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-announce
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From drj|m|emon @end|ng |rom gm@||@com  Wed Jun 10 03:09:03 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 10 Jun 2020 11:09:03 +1000
Subject: [R] Error in ordinal mixed effects
In-Reply-To: <70265D6234EC4C44A70A59B2825EF54E0115B74049@S800000MBX01.osakidetza.svs.local>
References: <70265D6234EC4C44A70A59B2825EF54E0115B74049@S800000MBX01.osakidetza.svs.local>
Message-ID: <CA+8X3fXXrDCVrBbwyssUF7upe+Gj1FgrYgfSAXHEsNSGEuuPVA@mail.gmail.com>

Hi Susana,
I ran your code on a fake data frame:

datos<-data.frame(id=paste0("s",1:65),
 group=c(rep("control",30),rep("treat",35)),
 cannabis0=sample(1:5,65,TRUE),
 cannabis6=sample(1:5,65,TRUE),
 cannabis9=sample(1:5,65,TRUE),
 cannabis12=sample(1:5,65,TRUE),
 cannabis18=sample(1:5,65,TRUE))
time<-c(rep(0, 65), rep(6, 65), rep(9, 65), rep(12, 65), rep(18, 65))
id<-c(rep(datos$id, 5))
group<-c(rep(datos$group, 5))
res<-data.frame(cbind(id, group, time, cannabis))
names(res)<-c("id", "group", "time", "cannabis")
res<-res[order(res$id),]
library(mixor)
cannabismod<-mixor(cannabis~ time + as.factor(group), data=res,
 id=id,which.random.slope=NA,link="logit")

The error seems to be that you have inserted a function name
"na.exclude" in the arguments. When I removed it as above, it ran okay
with a warning.

Jim

On Tue, Jun 9, 2020 at 11:01 PM SUSANA ALBERICH MESA
<SUSANA.ALBERICHMESA at osakidetza.eus> wrote:
>
> Hi,
> I'm trying to run an ordinal mixed effects model with Mixor command. I have 65 cases and repeated visits in 0, 6, 9, 12 and 18 months. My code is the following:
>
> cannabis<-c(datos$cannabis0, datos$cannabis6, datos$cannabis9, datos$cannabis12, datos$cannabis18)
> time<-c(rep(0, 65), rep(6, 65), rep(9, 65), rep(12, 65), rep(18, 65))
> id<-c(rep(datos$id, 5))
> group<-c(rep(datos$group, 5))
>
> res<-data.frame(cbind(id, group, time, cannabis))
> names(res)<-c("id", "group", "time", "cannabis")
> res<-res[order(res$id),]
>
> cannabismod<-mixor(cannabis~ time + as.factor(group), data=res, id=id, na.exclude, which.random.slope=na, link="logit")
> summary(cannabismod)
>
>
> However, I have obtained this error:
>
> Error in xj[i] : invalid subscript type 'closure'
>
> Please, could anyone help me to solve it?
>
> Many thanks,
> Susana
>
> [https://edukiak.osakidetza.net/coronavirus/pie_email7.jpg]
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr@p|k@| @end|ng |rom prechez@@cz  Wed Jun 10 08:59:42 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 10 Jun 2020 06:59:42 +0000
Subject: [R] almost logistic data evaluation
In-Reply-To: <c51c48b110764b4fa966602de2d6028d@GBDCVPEXC08.corp.lgc-group.com>
References: <9ade43c225ea496e9ca8f0acc50ba767@SRVEXCHCM1302.precheza.cz>
 <CAJc=yOF42mNL6pF6tVvPbqSixHLY5B=TWkF94VGk6QfnbEDLiA@mail.gmail.com>,
 <bee44a52463e42e2bcb60249e0cde5e6@SRVEXCHCM1302.precheza.cz>
 <c51c48b110764b4fa966602de2d6028d@GBDCVPEXC08.corp.lgc-group.com>
Message-ID: <d88d94d3831b44aa993130658169a007@SRVEXCHCM1302.precheza.cz>

Hi

External heating. Normally I would use TA instrumentation but for technical
reasons it is impossible. And other complicating factor is that temperature
rise is from beginning almost parabolic (it's derivation is straight line).

Therefore I started with double exponential fit, which is sometimes
satisfactory but sometimes gives nonsense result. After help from R
community I got in almost all cases reasonable fit. 

However I want to concentrate on just the reaction part and to find some
more simple way how to get slope for temperature rise and maybe other
parameters related to changes in experiments.

I was advised to look at "growth curve analysis" which I will try to, but I
wonder if due to twisted data is appropriate.

Thanks.
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Stephen Ellison
> Sent: Tuesday, June 9, 2020 7:11 PM
> To: r-help at r-project.org
> Subject: Re: [R] almost logistic data evaluation
> 
> > Actually "y" is growing temperature, which, at some point, rise more
rapidly
> due to exothermic reaction.
> > This reaction starts and ends and proceed with some speed (hopefully
> different in each material).
> 
> Are you applying external heating or is it solely due to reaction
kinetics?
> 
> 
> Steve E
> 
> *****************************************************************
> **
> This email and any attachments are confidential. Any use...{{dropped:8}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From m@rong|u@|u|g| @end|ng |rom gm@||@com  Wed Jun 10 10:20:01 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Wed, 10 Jun 2020 10:20:01 +0200
Subject: [R] How to convert European short dates to ISO format?
Message-ID: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>

Hello,
I have been trying to convert European short dates formatted as
dd/mm/yy into the ISO 8601 but the function as.Dates interprets them
as American ones (mm/dd/yy), thus I get:

```
oriDates = c("23/01/20", "24/01/20", "25/01/20", "26/01/20",
"27/01/20", "28/01/20", "29/01/20", "30/01/20",
             "31/01/20", "01/02/20", "02/02/20", "03/02/20",
"04/02/20", "05/02/20", "06/02/20", "07/02/20")
isoDates = as.Date(oriDates, format = "%m/%d/%y")
> isoDates
 [1] NA           NA           NA           NA           NA
NA           NA
 [8] NA           NA           "2020-01-02" "2020-02-02" "2020-03-02"
"2020-04-02" "2020-05-02"
[15] "2020-06-02" "2020-07-02"
```

How can I convert properly?
-- 
Best regards,
Luigi


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Jun 10 10:28:33 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 10 Jun 2020 11:28:33 +0300
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
Message-ID: <20200610112833.3cf4a5c2@Tarkus>

On Wed, 10 Jun 2020 10:20:01 +0200
Luigi Marongiu <marongiu.luigi at gmail.com> wrote:

> the function as.Dates interprets them as American ones (mm/dd/yy)

> isoDates = as.Date(oriDates, format = "%m/%d/%y")

> How can I convert properly?

Pass the correct format? (Swap m and d in the format string.)

-- 
Best regards,
Ivan


From djnord|und @end|ng |rom gm@||@com  Wed Jun 10 10:29:11 2020
From: djnord|und @end|ng |rom gm@||@com (Daniel Nordlund)
Date: Wed, 10 Jun 2020 01:29:11 -0700
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
Message-ID: <a1a9bb99-aff9-db5f-e8d4-aad02d724efd@gmail.com>

On 6/10/2020 1:20 AM, Luigi Marongiu wrote:
> isoDates = as.Date(oriDates, format = "%m/%d/%y")

You need to use the format for European short dates.

isoDates = as.Date(oriDates, format = "%d/%m/%y")


Hope this is helpful,

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From m@||||@t@ @end|ng |rom pp@|net@||  Wed Jun 10 10:30:54 2020
From: m@||||@t@ @end|ng |rom pp@|net@|| (Kimmo Elo)
Date: Wed, 10 Jun 2020 11:30:54 +0300
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
Message-ID: <b328e7565108b4bf705e051ee258239a9b01e3f9.camel@pp.inet.fi>

Hi!

Should it be:

as.Date(oriDates, format="%d/%m/%y") # See the order of %d and %m!!

This command seems to work for me, here the output:

 [1] "2020-01-23" "2020-01-24" "2020-01-25" "2020-01-26" "2020-01-27"
"2020-01-28" "2020-01-29" "2020-01-30"
 [9] "2020-01-31" "2020-02-01" "2020-02-02" "2020-02-03" "2020-02-04"
"2020-02-05" "2020-02-06" "2020-02-07"

HTH,
Kimmo

ke, 2020-06-10 kello 10:20 +0200, Luigi Marongiu kirjoitti:
> Hello,
> I have been trying to convert European short dates formatted as
> dd/mm/yy into the ISO 8601 but the function as.Dates interprets them
> as American ones (mm/dd/yy), thus I get:
> 
> ```
> oriDates = c("23/01/20", "24/01/20", "25/01/20", "26/01/20",
> "27/01/20", "28/01/20", "29/01/20", "30/01/20",
>              "31/01/20", "01/02/20", "02/02/20", "03/02/20",
> "04/02/20", "05/02/20", "06/02/20", "07/02/20")
> isoDates = as.Date(oriDates, format = "%m/%d/%y")
> > isoDates
> 
>  [1] NA           NA           NA           NA           NA
> NA           NA
>  [8] NA           NA           "2020-01-02" "2020-02-02" "2020-03-02"
> "2020-04-02" "2020-05-02"
> [15] "2020-06-02" "2020-07-02"
> ```
> 
> How can I convert properly?


From bhh @end|ng |rom x@4@||@n|  Wed Jun 10 10:30:54 2020
From: bhh @end|ng |rom x@4@||@n| (Berend Hasselman)
Date: Wed, 10 Jun 2020 10:30:54 +0200
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
Message-ID: <66A418C2-CB3C-41CC-A752-5733D2F885C3@xs4all.nl>

Luigi,

Try format = "%d/%m/%y"

Berend Hasselman

> On 10 Jun 2020, at 10:20, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> 
>  ISO 8601


From tuech|er @end|ng |rom gmx@@t  Wed Jun 10 10:34:37 2020
From: tuech|er @end|ng |rom gmx@@t (Heinz Tuechler)
Date: Wed, 10 Jun 2020 10:34:37 +0200
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
Message-ID: <1b9b9e00-7d45-3804-ae3f-4c44258eab7e@gmx.at>

maybe
isoDates <- as.Date(oriDates, format = "%d/%m/%y")

Heinz

Luigi Marongiu wrote/hat geschrieben on/am 10.06.2020 10:20:
> Hello,
> I have been trying to convert European short dates formatted as
> dd/mm/yy into the ISO 8601 but the function as.Dates interprets them
> as American ones (mm/dd/yy), thus I get:
>
> ```
> oriDates = c("23/01/20", "24/01/20", "25/01/20", "26/01/20",
> "27/01/20", "28/01/20", "29/01/20", "30/01/20",
>              "31/01/20", "01/02/20", "02/02/20", "03/02/20",
> "04/02/20", "05/02/20", "06/02/20", "07/02/20")
> isoDates = as.Date(oriDates, format = "%m/%d/%y")
>> isoDates
>  [1] NA           NA           NA           NA           NA
> NA           NA
>  [8] NA           NA           "2020-01-02" "2020-02-02" "2020-03-02"
> "2020-04-02" "2020-05-02"
> [15] "2020-06-02" "2020-07-02"
> ```
>
> How can I convert properly?
>


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Wed Jun 10 10:36:47 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Wed, 10 Jun 2020 10:36:47 +0200
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <a1a9bb99-aff9-db5f-e8d4-aad02d724efd@gmail.com>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
 <a1a9bb99-aff9-db5f-e8d4-aad02d724efd@gmail.com>
Message-ID: <CAMk+s2T8f42vL_XBxAg34XCohcB90=auiuQxioFEA=Dmtd+aaA@mail.gmail.com>

Thank you!

On Wed, Jun 10, 2020 at 10:29 AM Daniel Nordlund <djnordlund at gmail.com> wrote:
>
> On 6/10/2020 1:20 AM, Luigi Marongiu wrote:
> > isoDates = as.Date(oriDates, format = "%m/%d/%y")
>
> You need to use the format for European short dates.
>
> isoDates = as.Date(oriDates, format = "%d/%m/%y")
>
>
> Hope this is helpful,
>
> Dan
>
> --
> Daniel Nordlund
> Port Townsend, WA  USA
>


-- 
Best regards,
Luigi


From petr@p|k@| @end|ng |rom prechez@@cz  Wed Jun 10 12:09:19 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 10 Jun 2020 10:09:19 +0000
Subject: [R] segmented do not correctly fit data (variable names problem)
Message-ID: <996341cc2b9d4a1e8be200d87238c2e1@SRVEXCHCM1302.precheza.cz>

Dear all

To make my problem more on topic I would like to ask about weird results
from segmented fit, despite of Bert's warning.

Here is my data

temp <- structure(list(V1 = c(0L, 15L, 30L, 45L, 60L, 75L, 90L, 105L, 120L,
135L, 150L, 165L, 180L, 195L, 210L, 225L, 240L, 255L, 270L, 285L, 300L,
315L, 330L, 345L, 360L), V2 = c(98.68666667, 100.8, 103.28, 107.44, 110.06,
114.26, 117.6, 121.04, 123.8533333, 126.66, 129.98, 134.1866667, 139.04,
144.6, 152.08, 161.3, 169.8733333, 176.6133333, 181.92, 186.0266667,
188.7533333, 190.7066667, 192.0533333, 192.9933333, 193.3533333)), class =
"data.frame", row.names = c(NA,
+ -25L))

Here is the fit.

library(segmented)
plot(temp$V1, temp$V2)
fit <- lm(V2~V1, temp)
fit.s <- segmented(fit, seg.Z = ~ V1, npsi=2)
plot(fit.s, add=TRUE, col=2)

which is wrong.

If I take example from web, the result is OK.

set.seed(12)
xx <- 1:100
zz <- runif(100)
yy <- 2 + 1.5*pmax(xx - 35, 0) - 1.5*pmax(xx - 70, 0) + 15*pmax(zz - .5, 0)
+  rnorm(100,0,2)
dati <- data.frame(x = xx, y = yy, z = zz)
out.lm <- lm(y ~ x, data = dati)
o <- segmented(out.lm, seg.Z = ~x, psi = list(x = c(30,60)),  control =
seg.control(display = FALSE)
)
plot(dati$x, dati$y)
plot(o, add=TRUE, col=2)

What am I doing wrong? Is there a bug in segmented? BTW, if I change column
names in temp to x and y, segmented found correct fit.

names(temp) <- c("x", "y")
plot(temp$x, temp$y)
fit <- lm(y~x, temp)
fit.s <- segmented(fit, seg.Z = ~x, npsi=2)
plot(fit.s, add=TRUE, col=2)

> sessionInfo()
R Under development (unstable) (2020-03-08 r77917)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 18363)

Matrix products: default

locale:
[1] LC_COLLATE=Czech_Czechia.1250  LC_CTYPE=Czech_Czechia.1250   
[3] LC_MONETARY=Czech_Czechia.1250 LC_NUMERIC=C                  
[5] LC_TIME=Czech_Czechia.1250    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] segmented_1.1-0

loaded via a namespace (and not attached):
[1] compiler_4.0.0 tools_4.0.0    splines_4.0.0 


Cheers
Petr



From m@rong|u@|u|g| @end|ng |rom gm@||@com  Wed Jun 10 15:29:05 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Wed, 10 Jun 2020 15:29:05 +0200
Subject: [R] Doubling time definition package incidence
Message-ID: <CAMk+s2SaG5HDhkd5oyoHSXE7_zVj=vUKZAom-yCsd2tLPnJwYw@mail.gmail.com>

The package incidence provides the function fit_optim_split that
returns a predicted doubling time in days. Would this be serial
interval described in the epidemiology manuals?
Thank you


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jun 10 16:29:13 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 10 Jun 2020 07:29:13 -0700
Subject: [R] 
 segmented do not correctly fit data (variable names problem)
In-Reply-To: <996341cc2b9d4a1e8be200d87238c2e1@SRVEXCHCM1302.precheza.cz>
References: <996341cc2b9d4a1e8be200d87238c2e1@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAGxFJbTuwY7bafOE1orEx-X-dFo4UMJk0H72j_pELFJdurMe=Q@mail.gmail.com>

Note: My warning was for "stepwise" regression, which is what *you wrote*,
not "segmented".

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jun 10, 2020 at 3:09 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Dear all
>
> To make my problem more on topic I would like to ask about weird results
> from segmented fit, despite of Bert's warning.
>
> Here is my data
>
> temp <- structure(list(V1 = c(0L, 15L, 30L, 45L, 60L, 75L, 90L, 105L, 120L,
> 135L, 150L, 165L, 180L, 195L, 210L, 225L, 240L, 255L, 270L, 285L, 300L,
> 315L, 330L, 345L, 360L), V2 = c(98.68666667, 100.8, 103.28, 107.44, 110.06,
> 114.26, 117.6, 121.04, 123.8533333, 126.66, 129.98, 134.1866667, 139.04,
> 144.6, 152.08, 161.3, 169.8733333, 176.6133333, 181.92, 186.0266667,
> 188.7533333, 190.7066667, 192.0533333, 192.9933333, 193.3533333)), class =
> "data.frame", row.names = c(NA,
> + -25L))
>
> Here is the fit.
>
> library(segmented)
> plot(temp$V1, temp$V2)
> fit <- lm(V2~V1, temp)
> fit.s <- segmented(fit, seg.Z = ~ V1, npsi=2)
> plot(fit.s, add=TRUE, col=2)
>
> which is wrong.
>
> If I take example from web, the result is OK.
>
> set.seed(12)
> xx <- 1:100
> zz <- runif(100)
> yy <- 2 + 1.5*pmax(xx - 35, 0) - 1.5*pmax(xx - 70, 0) + 15*pmax(zz - .5, 0)
> +  rnorm(100,0,2)
> dati <- data.frame(x = xx, y = yy, z = zz)
> out.lm <- lm(y ~ x, data = dati)
> o <- segmented(out.lm, seg.Z = ~x, psi = list(x = c(30,60)),  control =
> seg.control(display = FALSE)
> )
> plot(dati$x, dati$y)
> plot(o, add=TRUE, col=2)
>
> What am I doing wrong? Is there a bug in segmented? BTW, if I change column
> names in temp to x and y, segmented found correct fit.
>
> names(temp) <- c("x", "y")
> plot(temp$x, temp$y)
> fit <- lm(y~x, temp)
> fit.s <- segmented(fit, seg.Z = ~x, npsi=2)
> plot(fit.s, add=TRUE, col=2)
>
> > sessionInfo()
> R Under development (unstable) (2020-03-08 r77917)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 18363)
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=Czech_Czechia.1250  LC_CTYPE=Czech_Czechia.1250
> [3] LC_MONETARY=Czech_Czechia.1250 LC_NUMERIC=C
> [5] LC_TIME=Czech_Czechia.1250
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] segmented_1.1-0
>
> loaded via a namespace (and not attached):
> [1] compiler_4.0.0 tools_4.0.0    splines_4.0.0
>
>
> Cheers
> Petr
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jun 10 16:37:23 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 10 Jun 2020 07:37:23 -0700
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
Message-ID: <D8937C33-7558-4E88-B768-9D831970BFF6@dcn.davis.ca.us>

Fix your format specification?

?strptime

On June 10, 2020 1:20:01 AM PDT, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>Hello,
>I have been trying to convert European short dates formatted as
>dd/mm/yy into the ISO 8601 but the function as.Dates interprets them
>as American ones (mm/dd/yy), thus I get:
>
>```
>oriDates = c("23/01/20", "24/01/20", "25/01/20", "26/01/20",
>"27/01/20", "28/01/20", "29/01/20", "30/01/20",
>             "31/01/20", "01/02/20", "02/02/20", "03/02/20",
>"04/02/20", "05/02/20", "06/02/20", "07/02/20")
>isoDates = as.Date(oriDates, format = "%m/%d/%y")
>> isoDates
> [1] NA           NA           NA           NA           NA
>NA           NA
> [8] NA           NA           "2020-01-02" "2020-02-02" "2020-03-02"
>"2020-04-02" "2020-05-02"
>[15] "2020-06-02" "2020-07-02"
>```
>
>How can I convert properly?

-- 
Sent from my phone. Please excuse my brevity.


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Wed Jun 10 16:44:49 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Wed, 10 Jun 2020 07:44:49 -0700 (PDT)
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <D8937C33-7558-4E88-B768-9D831970BFF6@dcn.davis.ca.us>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
 <D8937C33-7558-4E88-B768-9D831970BFF6@dcn.davis.ca.us>
Message-ID: <alpine.LNX.2.20.2006100742230.20965@salmo.appl-ecosys.com>

On Wed, 10 Jun 2020, Jeff Newmiller wrote:

> Fix your format specification?
> ?strptime

>> I have been trying to convert European short dates formatted as dd/mm/yy
>> into the ISO 8601 but the function as.Dates interprets them as American
>> ones (mm/dd/yy), thus I get:

Look at Hadley Wickham's 'tidyverse' collection as described in R for Data
Science. There are date, datetime, and time functions that will do just what
you want.

Rich


From S@E|||@on @end|ng |rom LGCGroup@com  Wed Jun 10 17:46:29 2020
From: S@E|||@on @end|ng |rom LGCGroup@com (Stephen Ellison)
Date: Wed, 10 Jun 2020 15:46:29 +0000
Subject: [R] almost logistic data evaluation
In-Reply-To: <d88d94d3831b44aa993130658169a007@SRVEXCHCM1302.precheza.cz>
References: <9ade43c225ea496e9ca8f0acc50ba767@SRVEXCHCM1302.precheza.cz>
 <CAJc=yOF42mNL6pF6tVvPbqSixHLY5B=TWkF94VGk6QfnbEDLiA@mail.gmail.com>,
 <bee44a52463e42e2bcb60249e0cde5e6@SRVEXCHCM1302.precheza.cz>
 <c51c48b110764b4fa966602de2d6028d@GBDCVPEXC08.corp.lgc-group.com>,
 <d88d94d3831b44aa993130658169a007@SRVEXCHCM1302.precheza.cz>
Message-ID: <9f904a1a4d9d4708b0660a1ad58f7ecd@GBDCVPEXC08.corp.lgc-group.com>


I'm not sure this is really a statistical problem, in the sense of looking for a convenient but arbitrary statistical function; to do it well is more of a physicochemical modelling problem.
I can't give you an answer but maybe a direction I'd consider if I wanted to take it seriously ...

You have a steady heat input (which is initially a straight line but becomes asymptotic as cooling rate approaches heating rate),  plus an exothermic reaction whose rate will almost certainly depend on temperature (I guess close to the usual 'double every 10K' rule of thumb for chemistry, but of course there are plenty of exceptions and diffusion control doesn't follow Arrhenius rate dependence. ). On a bad day it may self-catalyse as well, but it's already self-accelerating in the sense that the rate will go up with the temperature and the temperature will go up faster at higher rates.

To model that you would ideally set up a kinetic model for the chemistry, with coefficients for (probably) an activation energy rather than a simple rate constant, enthalpy of reaction, heat input and at least one arbitrary heat capacity so that you have something that relates heat input and enthalpy to temperature. There'll be another term (probably based on newton's law of cooling) to model external heating and cooling, again with that system heat capacity to convert energy to temperature.
 
That'll be a moderately awkward differential equation.  For the common exponential relation of temperature and rate (assuming an Arrhenius relationship for the rate constant), with temperature not constant, it will almost certainly need numerical solution with something like the deSolve package. That can give you an integrated change at different times. After that 'all' you need to do is wrap that in a function to return a residual sum of squares and then plug that into something like optim() or perhaps nls() to fit the curve. 

You may want to set I say 'all you need ...'; obviously, that's a fair bit of work...

________________________________________
From: PIKAL Petr [petr.pikal at precheza.cz]
Sent: 10 June 2020 07:59
To: Stephen Ellison; r-help at r-project.org
Subject: RE: [R] almost logistic data evaluation

Hi

External heating. Normally I would use TA instrumentation but for technical
reasons it is impossible. And other complicating factor is that temperature
rise is from beginning almost parabolic (it's derivation is straight line).

Therefore I started with double exponential fit, which is sometimes
satisfactory but sometimes gives nonsense result. After help from R
community I got in almost all cases reasonable fit.

However I want to concentrate on just the reaction part and to find some
more simple way how to get slope for temperature rise and maybe other
parameters related to changes in experiments.

I was advised to look at "growth curve analysis" which I will try to, but I
wonder if due to twisted data is appropriate.

Thanks.
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Stephen Ellison
> Sent: Tuesday, June 9, 2020 7:11 PM
> To: r-help at r-project.org
> Subject: Re: [R] almost logistic data evaluation
>
> > Actually "y" is growing temperature, which, at some point, rise more
rapidly
> due to exothermic reaction.
> > This reaction starts and ends and proceed with some speed (hopefully
> different in each material).
>
> Are you applying external heating or is it solely due to reaction
kinetics?
>
>
> Steve E
>
> *****************************************************************
> **
> This email and any attachments are confidential. Any u...{{dropped:19}}


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Jun 10 20:13:03 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 10 Jun 2020 13:13:03 -0500
Subject: [R] Error in plot.window(...) : need finite 'ylim' values
Message-ID: <CAF9-5jNMgUnPZ=XVTW8UHTL044O-h=KFmK+tOoiyMKPAdYdbvQ@mail.gmail.com>

Hello,

I do have a file like this:
head M3.assoc.logistic.C
CHR SNP BP P
1 1:785989:T:C 785989 0.4544
1 1:785989:T:C 785989 0.689
1 1:1130727:A:C 1130727 0.05068
1 1:1130727:A:C 1130727 0.07381
1 1:1156131:T:C 1156131 0.6008
1 1:1156131:T:C 1156131 0.8685
...

And I don't have any "NA" or "inf" values in it

and I am plotting it in R via:

library(qqman)
results_log <- read.table("M3.assoc.logistic.C", head=TRUE)
jpeg("Logistic_manhattan_retinopathy_M3.jpeg")
manhattan(results_log,chr="CHR",bp="BP",p="P",snp="SNP", main =
"Manhattan plot: logistic")
dev.off()

but I am getting:

Error in plot.window(...) : need finite 'ylim' values
Calls: manhattan ... do.call -> plot -> plot.default -> localWindow ->
plot.window
Execution halted

Please advise,

Thanks
Ana


From k@pr@@@d@h @end|ng |rom gm@||@com  Wed Jun 10 06:36:06 2020
From: k@pr@@@d@h @end|ng |rom gm@||@com (Keshava PRASADa Halemane)
Date: Wed, 10 Jun 2020 10:06:06 +0530
Subject: [R] Seeking implementation of my algorithm 'spdspds' - a novel
 algorithm for solving Linear Programming Problems with O(L^1.5)
 computational complexity
In-Reply-To: <CA+Pe9YVX+52fpxOBRY5+XC9yUQzAs-EB3F1EQOxNc+iX8k_6fQ@mail.gmail.com>
References: <CA+Pe9YUe5JmXz3DxPOGre_KnQeror+E44R5j6x_sDok6HWuSAQ@mail.gmail.com>
 <CA+Pe9YWE=6WkmxRe_JKhrfA4w3_JyS4Q-MHR+vvcUuNrNUH64Q@mail.gmail.com>
 <CA+Pe9YVX+52fpxOBRY5+XC9yUQzAs-EB3F1EQOxNc+iX8k_6fQ@mail.gmail.com>
Message-ID: <CA+Pe9YXUr-uzpR5JnQ=f8o5SGNfQayWyBKw4sHV0d+cv1DjGoA@mail.gmail.com>

Friends:
i am a retired Professor -
not having any access to the resources (human/financial/business/whatever)
that may be required -
therefore i am seeking implementation of my algorithm 'spdspds' -
a novel algorithm for solving Linear Programming Problems with O(L^1.5)
computational complexity -
in order to show/convince the esteemed world optimization community
that it is indeed a great grand breakthrough in terms of achievement of the
linear programming performance challenge of the millennium -
with far reaching deep impact on optimization algorithm development in
general -
holy grail fantasy realized!

I need some individual or team who is interested & willing to work on this.
Earlier experience in implementation of optimization/LP algorithms will
greatly help.

You may access / download / read my paper -
"Unbelievable *O*(*L*^1.5) worst case computational complexity achieved by
spdspds algorithm for linear programming problem"
which is available at - arxiv . org / abs / 1405 . 6902

Thanks a lot.
 - Dr(Prof) Keshava Prasad Halemane

	[[alternative HTML version deleted]]


From @y@g||@d @end|ng |rom gm@||@com  Wed Jun 10 09:57:46 2020
From: @y@g||@d @end|ng |rom gm@||@com (Aya Gilad)
Date: Wed, 10 Jun 2020 10:57:46 +0300
Subject: [R] Help about extracting data
Message-ID: <CABirntQV6SHK6sFNCVSqCTfUYCM_6S5Ce0=B+No-0oWqu=WwLA@mail.gmail.com>

Hello,
I'm analyzing a 6-question questionnaire. I need to exclude participants
who answered more than 4 questions with a grade of 3 or higher.
How do I write such a code?
Thank you!

	[[alternative HTML version deleted]]


From mozhg@n@o|eym@n| @end|ng |rom gm@||@com  Wed Jun 10 11:08:46 2020
From: mozhg@n@o|eym@n| @end|ng |rom gm@||@com (Mozhgan Soleimani)
Date: Wed, 10 Jun 2020 13:38:46 +0430
Subject: [R] request
Message-ID: <CAKOwFD=hMNi_ruOmHobaBLjjAJNY8p1=YGppX6zuP6j+q2T1Eg@mail.gmail.com>

Hello
thank you for reading email
please help me,
I have used mgcv package for GAM model.

To get contributions of each variable, Which code should I write in the R
software?
please see attached file

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 1.PNG
Type: image/png
Size: 9624 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200610/2d64a69f/attachment.png>

From uret@@@|ej@ndro @end|ng |rom gm@||@com  Wed Jun 10 17:13:24 2020
From: uret@@@|ej@ndro @end|ng |rom gm@||@com (Alejandro Ureta)
Date: Wed, 10 Jun 2020 12:13:24 -0300
Subject: [R] Creating one df from 85 df present in a list
Message-ID: <CAASu+7OARc+AFuVGtHBp_q2TLVqnw57VdjN9WCpuMrwcjfOxpQ@mail.gmail.com>

hi, I am trying to fuse (cbind, merge... NOT rbind) several dataframes with
different numbers of rows, all df included in a list, and using the code
extract shown below. The function merge() works well with two df but not
more than two...I have 85 dataframes to join in this way (85 df in the
list)....could you please let me know how to get all 85 df merged ?,,,,,
thanks

fusion_de_tablas = merge(red_tablas_por_punto[["1 - Bv.Artigas y la Rambla
(Terminal CUTCSA)"]],
red_tablas_por_punto[["10 - Avenida Mill?n 2515 (Hospital Vilardeb?)"]],
red_tablas_por_punto[["100 - Fauquet 6358 (Hospital Saint Bois)"]],
by= 'toma_de_muestras', all = T )

-- 
*Alejandro *

	[[alternative HTML version deleted]]


From @@ud|@@d|q @end|ng |rom gm@||@com  Wed Jun 10 17:47:52 2020
From: @@ud|@@d|q @end|ng |rom gm@||@com (Saudi Sadiq)
Date: Wed, 10 Jun 2020 17:47:52 +0200
Subject: [R] Help with a (g)lmer code
Message-ID: <CAB_D3mrPo9JYv_i3RAonNxtZ6qneNtTMn_i2xFOQAGWHY1zPUg@mail.gmail.com>

Dear Sir/Madam,

Hope everyone is safe and sound. I appreciate your help a lot.

I am evaluating two Arabic subtitles of a humorous English scene and asked
263 participants (part) to evaluate the two subtitles (named Standard
Arabic, SA, and Egyptian Arabic, EA) via a questionnaire that asked them to
rank the two subtitles in terms of how much each subtitle is

2) more humorous (hum),

5) closer to Egyptian culture (cul)



The questionnaire contained two 1-10 linear scale questions regarding the 2
points clarified, with 1 meaning the most humorous and closest to Egyptian
culture, and 1 meaning the least humorous and furthest from Egyptian
culture. Also, the questionnaire had a general multiple-choice question
regarding which subtitle is better in general (better). General information
about the participants were also collected concerning gender (categorical
factor), age (numeric factor) and education (categorical factor).

Two versions of the questionnaire were relied on: one showing the ?SA
subtitle first? and another showing the ?EA subtitle first?. Nearly half
the participants answered the first and nearly half answered the latter.

I am focusing on which social factor/s lead/s the participants to evaluate
one of the two subtitles as generally better and which subtitle is more
humorous and closer to Egyptian culture. Each of these points alone can be
the dependent factor, but the results altogether can be linked.

I thought that mixed effects analyses would clarify the picture and answer
the research questions (which  factor/s lead/s participants to favour a
subtitle over another?) and, so,  tried the lme4 package in R and ran many
models but all the codes I have used are not working.

I ran the following codes, which yielded Error messages, like:

model1<- lmer (better ~ gender + age + education + WF + (1 | part),
data=sub_data)

Error: number of levels of each grouping factor must be < number of
observations (problems: part)



Model2 <- glmer (better ~ gender + age + education + WF + (1 | part), data
= sub_data, family='binomial')

Error in mkRespMod(fr, family = family) :

  response must be numeric or factor



Model3 <- glmer (better ~ age + gender + education + WF + (1 | part), data
= sub_data, family='binomial', control=glmerControl(optimizer=c("bobyqa")))

Error in mkRespMod(fr, family = family) :

  response must be numeric or factor



Why does the model crash? Does the problem lie in the random factor part (which
is a code for participants)? Or is it something related to the mixed
effects analysis?

Best
Saudi Sadiq

	[[alternative HTML version deleted]]


From @ong@k@y|@ @end|ng |rom gm@||@com  Wed Jun 10 20:33:53 2020
From: @ong@k@y|@ @end|ng |rom gm@||@com (Kayla Song)
Date: Wed, 10 Jun 2020 14:33:53 -0400
Subject: [R] Error messages (Long vectors not supported)
Message-ID: <7610FEE1-D09B-4ECF-9164-1E9D7AE74E35@gmail.com>

Hello there,

I hope this email finds you well.

I?m just having a difficulty running RServe, which I?m trying to get communicate with Tableau. I have this error message every time I try to do this:

Error: long vectors not supported yet: qap_encode.c:36
Fatal error: unable to initialize the JIT

I searched some online forums but could not find the answer that resolved this problem. For example, I tried:

install.packages("Rserve", "Rserve_1.8-6.tgz", "http://www.rforge.net/?)

But the error message still appears. 
Could you please advise?

thanks so much,
Kayla
	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Jun 10 21:39:05 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 10 Jun 2020 12:39:05 -0700
Subject: [R] Error messages (Long vectors not supported)
In-Reply-To: <7610FEE1-D09B-4ECF-9164-1E9D7AE74E35@gmail.com>
References: <7610FEE1-D09B-4ECF-9164-1E9D7AE74E35@gmail.com>
Message-ID: <ab38359c-804e-c170-0155-4a204115fa46@comcast.net>

If that is an exact copy of the issued command than it should be 
throwing an error related to the use of "smart quotes".


Furthermore it was not clear if that command was the proximate cause of 
the error or perhaps it was encountered when you tried to load (rather 
than install) the Rserve package?

-- 

David

On 6/10/20 11:33 AM, Kayla Song wrote:
> Hello there,
>
> I hope this email finds you well.
>
> I?m just having a difficulty running RServe, which I?m trying to get communicate with Tableau. I have this error message every time I try to do this:
>
> Error: long vectors not supported yet: qap_encode.c:36
> Fatal error: unable to initialize the JIT
>
> I searched some online forums but could not find the answer that resolved this problem. For example, I tried:
>
> install.packages("Rserve", "Rserve_1.8-6.tgz", "http://www.rforge.net/?)
>
> But the error message still appears.
> Could you please advise?
>
> thanks so much,
> Kayla
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jun 10 22:14:04 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 10 Jun 2020 13:14:04 -0700
Subject: [R] Creating one df from 85 df present in a list
In-Reply-To: <CAASu+7OARc+AFuVGtHBp_q2TLVqnw57VdjN9WCpuMrwcjfOxpQ@mail.gmail.com>
References: <CAASu+7OARc+AFuVGtHBp_q2TLVqnw57VdjN9WCpuMrwcjfOxpQ@mail.gmail.com>
Message-ID: <CAGxFJbSD8WMa6005P1DP-J6BGZbdkreJnePYFw6OfDdXp6jLjg@mail.gmail.com>

?do.call  -- takes a list of arguments to a function
... as in
do.call(merge, yourlist)  ## or similar perhaps


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jun 10, 2020 at 11:48 AM Alejandro Ureta <ureta.alejandro at gmail.com>
wrote:

> hi, I am trying to fuse (cbind, merge... NOT rbind) several dataframes with
> different numbers of rows, all df included in a list, and using the code
> extract shown below. The function merge() works well with two df but not
> more than two...I have 85 dataframes to join in this way (85 df in the
> list)....could you please let me know how to get all 85 df merged ?,,,,,
> thanks
>
> fusion_de_tablas = merge(red_tablas_por_punto[["1 - Bv.Artigas y la Rambla
> (Terminal CUTCSA)"]],
> red_tablas_por_punto[["10 - Avenida Mill?n 2515 (Hospital Vilardeb?)"]],
> red_tablas_por_punto[["100 - Fauquet 6358 (Hospital Saint Bois)"]],
> by= 'toma_de_muestras', all = T )
>
> --
> *Alejandro *
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Jun 10 22:36:11 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 10 Jun 2020 15:36:11 -0500
Subject: [R] How to stack two Stack manhattan plots?
Message-ID: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>

Hello,

I have a data frame like this:

> head(tmp1)
  CHR      BP   Pold    Pnew
1   1  785989 0.9521 0.09278
2   1 1130727 0.4750 0.19010
3   1 1156131 0.5289 0.48520
4   1 1158631 0.2554 0.18140
5   1 1211292 0.2954 0.48590
6   1 1478153 0.5542 0.68790
...

I did:
tmp.tidy <- tmp1 %>% gather(key, value, -BP, -CHR)
jpeg("over.jpeg")
ggplot(tmp.tidy, aes(BP, value, color=key)) + geom_point() +
facet_wrap(~CHR, nrow=1)
dev.off()

but I got this plot in attach which doesn't make sense. Can you please
advise how to make this plot?

thanks
Ana

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screen Shot 2020-06-10 at 3.34.47 PM.png
Type: image/png
Size: 311087 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200610/59234ecb/attachment.png>

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jun 10 23:49:58 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 10 Jun 2020 14:49:58 -0700
Subject: [R] How to stack two Stack manhattan plots?
In-Reply-To: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>
References: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>
Message-ID: <39898A38-9C09-4BD4-86EC-0C13A92DE0A3@dcn.davis.ca.us>

?dput

We cannot tell how the columns are being stored in memory from your head() output.

On June 10, 2020 1:36:11 PM PDT, Ana Marija <sokovic.anamarija at gmail.com> wrote:
>Hello,
>
>I have a data frame like this:
>
>> head(tmp1)
>  CHR      BP   Pold    Pnew
>1   1  785989 0.9521 0.09278
>2   1 1130727 0.4750 0.19010
>3   1 1156131 0.5289 0.48520
>4   1 1158631 0.2554 0.18140
>5   1 1211292 0.2954 0.48590
>6   1 1478153 0.5542 0.68790
>...
>
>I did:
>tmp.tidy <- tmp1 %>% gather(key, value, -BP, -CHR)
>jpeg("over.jpeg")
>ggplot(tmp.tidy, aes(BP, value, color=key)) + geom_point() +
>facet_wrap(~CHR, nrow=1)
>dev.off()
>
>but I got this plot in attach which doesn't make sense. Can you please
>advise how to make this plot?
>
>thanks
>Ana

-- 
Sent from my phone. Please excuse my brevity.


From drj|m|emon @end|ng |rom gm@||@com  Thu Jun 11 00:11:32 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 11 Jun 2020 08:11:32 +1000
Subject: [R] Error in plot.window(...) : need finite 'ylim' values
In-Reply-To: <CAF9-5jNMgUnPZ=XVTW8UHTL044O-h=KFmK+tOoiyMKPAdYdbvQ@mail.gmail.com>
References: <CAF9-5jNMgUnPZ=XVTW8UHTL044O-h=KFmK+tOoiyMKPAdYdbvQ@mail.gmail.com>
Message-ID: <CA+8X3fVSJqO7yfSC3KFC+WtfjrkLnYDj4_tRNBxGAeQg2mboog@mail.gmail.com>

Hi Ana,
I don't have the qqman package, but is your "P" column in
"M3.assoc.logistic.C" numeric or has it been read in as a factor?

Jim

On Thu, Jun 11, 2020 at 4:13 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> I do have a file like this:
> head M3.assoc.logistic.C
> CHR SNP BP P
> 1 1:785989:T:C 785989 0.4544
> 1 1:785989:T:C 785989 0.689
> 1 1:1130727:A:C 1130727 0.05068
> 1 1:1130727:A:C 1130727 0.07381
> 1 1:1156131:T:C 1156131 0.6008
> 1 1:1156131:T:C 1156131 0.8685
> ...
>
> And I don't have any "NA" or "inf" values in it
>
> and I am plotting it in R via:
>
> library(qqman)
> results_log <- read.table("M3.assoc.logistic.C", head=TRUE)
> jpeg("Logistic_manhattan_retinopathy_M3.jpeg")
> manhattan(results_log,chr="CHR",bp="BP",p="P",snp="SNP", main =
> "Manhattan plot: logistic")
> dev.off()
>
> but I am getting:
>
> Error in plot.window(...) : need finite 'ylim' values
> Calls: manhattan ... do.call -> plot -> plot.default -> localWindow ->
> plot.window
> Execution halted
>
> Please advise,
>
> Thanks
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Thu Jun 11 00:17:14 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 11 Jun 2020 08:17:14 +1000
Subject: [R] How to stack two Stack manhattan plots?
In-Reply-To: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>
References: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>
Message-ID: <CA+8X3fVF5hjgGmfFuF1s_R9bP+myPbcDN2xj_VoyMWPNfPCTyg@mail.gmail.com>

Hi Ana,
The problem may be that the JPEG device doesn't handle transparency.
Perhaps PNG?

Jim

On Thu, Jun 11, 2020 at 6:48 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> I have a data frame like this:
>
> > head(tmp1)
>   CHR      BP   Pold    Pnew
> 1   1  785989 0.9521 0.09278
> 2   1 1130727 0.4750 0.19010
> 3   1 1156131 0.5289 0.48520
> 4   1 1158631 0.2554 0.18140
> 5   1 1211292 0.2954 0.48590
> 6   1 1478153 0.5542 0.68790
> ...
>
> I did:
> tmp.tidy <- tmp1 %>% gather(key, value, -BP, -CHR)
> jpeg("over.jpeg")
> ggplot(tmp.tidy, aes(BP, value, color=key)) + geom_point() +
> facet_wrap(~CHR, nrow=1)
> dev.off()
>
> but I got this plot in attach which doesn't make sense. Can you please
> advise how to make this plot?
>
> thanks
> Ana
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Thu Jun 11 00:22:04 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 10 Jun 2020 17:22:04 -0500
Subject: [R] How to stack two Stack manhattan plots?
In-Reply-To: <CA+8X3fVF5hjgGmfFuF1s_R9bP+myPbcDN2xj_VoyMWPNfPCTyg@mail.gmail.com>
References: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>
 <CA+8X3fVF5hjgGmfFuF1s_R9bP+myPbcDN2xj_VoyMWPNfPCTyg@mail.gmail.com>
Message-ID: <CAF9-5jNVnYXouU-T2v-BMTjt+YJ=ZXwx4gmUkCrjB+ce4XuTZA@mail.gmail.com>

HI Jim

I run it like this:
Rscript --no-save Manhattan_plot.R

and just in case I added: stringsAsFactors=FALSE

so the script looks like this:
library(qqman)
results_log <- read.table("logistic_results_M3.assoc.logistic.C",
head=TRUE,stringsAsFactors=FALSE)
jpeg("M3.assoc.logistic.jpeg")
manhattan(results_log,chr="CHR",bp="BP",p="P",snp="SNP", main =
"Manhattan plot:logistic")
dev.off()

this code does work with another data set, the jpeg() does work. I
will try now with PNG

On Wed, Jun 10, 2020 at 5:17 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Ana,
> The problem may be that the JPEG device doesn't handle transparency.
> Perhaps PNG?
>
> Jim
>
> On Thu, Jun 11, 2020 at 6:48 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hello,
> >
> > I have a data frame like this:
> >
> > > head(tmp1)
> >   CHR      BP   Pold    Pnew
> > 1   1  785989 0.9521 0.09278
> > 2   1 1130727 0.4750 0.19010
> > 3   1 1156131 0.5289 0.48520
> > 4   1 1158631 0.2554 0.18140
> > 5   1 1211292 0.2954 0.48590
> > 6   1 1478153 0.5542 0.68790
> > ...
> >
> > I did:
> > tmp.tidy <- tmp1 %>% gather(key, value, -BP, -CHR)
> > jpeg("over.jpeg")
> > ggplot(tmp.tidy, aes(BP, value, color=key)) + geom_point() +
> > facet_wrap(~CHR, nrow=1)
> > dev.off()
> >
> > but I got this plot in attach which doesn't make sense. Can you please
> > advise how to make this plot?
> >
> > thanks
> > Ana
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Thu Jun 11 00:22:38 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 11 Jun 2020 08:22:38 +1000
Subject: [R] request
In-Reply-To: <CAKOwFD=hMNi_ruOmHobaBLjjAJNY8p1=YGppX6zuP6j+q2T1Eg@mail.gmail.com>
References: <CAKOwFD=hMNi_ruOmHobaBLjjAJNY8p1=YGppX6zuP6j+q2T1Eg@mail.gmail.com>
Message-ID: <CA+8X3fXhKYisq+TD5U7hcedc_50NzS=Viwd3kewraDaxkQxivA@mail.gmail.com>

Hi Mozhgan,
This is pretty obscure. If you have entered all of the variables in
your attached list, You can start by looking at the summary of the
output. This may help:

https://stat.ethz.ch/R-manual/R-devel/library/mgcv/html/summary.gam.html

Jim

On Thu, Jun 11, 2020 at 4:47 AM Mozhgan Soleimani
<mozhgansoleymani at gmail.com> wrote:
>
> Hello
> thank you for reading email
> please help me,
> I have used mgcv package for GAM model.
>
> To get contributions of each variable, Which code should I write in the R
> software?
> please see attached file
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From twoo|m@n @end|ng |rom ont@rgettek@com  Thu Jun 11 00:49:18 2020
From: twoo|m@n @end|ng |rom ont@rgettek@com (Tom Woolman)
Date: Wed, 10 Jun 2020 18:49:18 -0400
Subject: [R] kernlab ksvm rbfdot kernel - prediction returning fewer rows
 than provided for input
In-Reply-To: <546404572.1122955.1586898034318@mail.yahoo.com>
References: <546404572.1122955.1586898034318.ref@mail.yahoo.com>
 <546404572.1122955.1586898034318@mail.yahoo.com>
Message-ID: <20200610184918.Horde.Zaj5ME0PfiJF648X5AR2u7D@www.ontargettek.com>


Hi everyone. I'm using the kernlab ksvm function with the rbfdot  
kernel for a binary classification problem and getting a strange  
result back. The predictions seem to be very accurate judging by the  
training results provided by the algorithm, but I'm unable to generate  
a confusion matrix because there is a difference in the number of  
output records from my model test compared to what was input into the  
test dataframe.

I've used ksvm before but never had this problem.

Here's my sample code:



install.packages("kernlab")
library(kernlab)


set.seed(3233)


trainIndex <-  
caret::createDataPartition(dataset_labeled_fraud$isFraud,  
p=0.70,kist=FALSE)

train <- dataset_labeled_fraud[trainIndex,]
test <- dataset_labeled_fraud[-trainIndex,]


#clear out the training model
filter <- NULL

filter <-  
kernlab::ksvm(isFraud~.,data=train,kernel="rbfdot",kpar=list(sigma=0.5),C=3,prob.model=TRUE)


#clear out the test results
test_pred_rbfdot <- NULL

test_pred_rbfdot <- kernlab::predict(filter,test,type="probabilities")

dataframe_test_pred_rbfdot <- as.data.frame(test_pred_rbfdot)


nrow(dataframe_test_pred_rbfdot)

> 23300

nrow(test)

> 24408


# ok, how did I go from 24408 input rows to only 23300 output  
prediction rows? :(


Thanks in advance anyone!




Thomas A. Woolman
PhD Candidate, Technology Management
Indiana State University


From twoo|m@n @end|ng |rom ont@rgettek@com  Thu Jun 11 00:51:01 2020
From: twoo|m@n @end|ng |rom ont@rgettek@com (Tom Woolman)
Date: Wed, 10 Jun 2020 18:51:01 -0400
Subject: [R] 
 kernlab ksvm rbfdot kernel - prediction returning fewer rows
 than provided for input
In-Reply-To: <20200610184918.Horde.Zaj5ME0PfiJF648X5AR2u7D@www.ontargettek.com>
References: <546404572.1122955.1586898034318.ref@mail.yahoo.com>
 <546404572.1122955.1586898034318@mail.yahoo.com>
 <20200610184918.Horde.Zaj5ME0PfiJF648X5AR2u7D@www.ontargettek.com>
Message-ID: <20200610185101.Horde.m_98poAiaPc7cthZzJTMjaE@www.ontargettek.com>

forgot to mention, the training and testing dataframes are composed of  
4 IVs (one double numeric IV and three factor IVs) and one DV  
(dichotomous factor, i.e. true or false).

The training dataframe consists of 48819 rows and test dataframe  
consists of 24408 rows.



Thanks again.



Quoting Tom Woolman <twoolman at ontargettek.com>:

> Hi everyone. I'm using the kernlab ksvm function with the rbfdot  
> kernel for a binary classification problem and getting a strange  
> result back. The predictions seem to be very accurate judging by the  
> training results provided by the algorithm, but I'm unable to  
> generate a confusion matrix because there is a difference in the  
> number of output records from my model test compared to what was  
> input into the test dataframe.
>
> I've used ksvm before but never had this problem.
>
> Here's my sample code:
>
>
>
> install.packages("kernlab")
> library(kernlab)
>
>
> set.seed(3233)
>
>
> trainIndex <-  
> caret::createDataPartition(dataset_labeled_fraud$isFraud,  
> p=0.70,kist=FALSE)
>
> train <- dataset_labeled_fraud[trainIndex,]
> test <- dataset_labeled_fraud[-trainIndex,]
>
>
> #clear out the training model
> filter <- NULL
>
> filter <-  
> kernlab::ksvm(isFraud~.,data=train,kernel="rbfdot",kpar=list(sigma=0.5),C=3,prob.model=TRUE)
>
>
> #clear out the test results
> test_pred_rbfdot <- NULL
>
> test_pred_rbfdot <- kernlab::predict(filter,test,type="probabilities")
>
> dataframe_test_pred_rbfdot <- as.data.frame(test_pred_rbfdot)
>
>
> nrow(dataframe_test_pred_rbfdot)
>
>> 23300
>
> nrow(test)
>
>> 24408
>
>
> # ok, how did I go from 24408 input rows to only 23300 output  
> prediction rows? :(
>
>
> Thanks in advance anyone!
>
>
>
>
> Thomas A. Woolman
> PhD Candidate, Technology Management
> Indiana State University


From pro|jcn@@h @end|ng |rom gm@||@com  Thu Jun 11 01:00:29 2020
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Wed, 10 Jun 2020 19:00:29 -0400
Subject: [R] Seeking implementation of my algorithm 'spdspds' - a novel
 algorithm for solving Linear Programming Problems with O(L^1.5)
 computational complexity
In-Reply-To: <CA+Pe9YXUr-uzpR5JnQ=f8o5SGNfQayWyBKw4sHV0d+cv1DjGoA@mail.gmail.com>
References: <CA+Pe9YUe5JmXz3DxPOGre_KnQeror+E44R5j6x_sDok6HWuSAQ@mail.gmail.com>
 <CA+Pe9YWE=6WkmxRe_JKhrfA4w3_JyS4Q-MHR+vvcUuNrNUH64Q@mail.gmail.com>
 <CA+Pe9YVX+52fpxOBRY5+XC9yUQzAs-EB3F1EQOxNc+iX8k_6fQ@mail.gmail.com>
 <CA+Pe9YXUr-uzpR5JnQ=f8o5SGNfQayWyBKw4sHV0d+cv1DjGoA@mail.gmail.com>
Message-ID: <76e9f973-aa59-db58-db28-ab0998622edb@gmail.com>

Your best chance to get some interest is to adapt an existing package
such as linprog or lpSolve to use your algorithm. Then there will be
sufficient structure to allow R users and developers to see your
ideas working, even if they are not efficiently programmed. It's
always easier to start with something that is working and improve it.
And you would be able to show comparisons of the existing examples by
the current and new methods.

I've worked on a lot of optimization (mainly function minimization) methods
over many decades, and there are several "brilliant" ideas that have not
turned out to be very good practical methods, while some rather pedestrian
ideas have proved reliable and effective, even if they don't fulfill nice
theoretical properties. There are, however, a few nice cases where theory
and practice are both great.

JN

On 2020-06-10 12:36 a.m., Keshava PRASADa Halemane wrote:
> Friends:
> i am a retired Professor -
> not having any access to the resources (human/financial/business/whatever)
> that may be required -
> therefore i am seeking implementation of my algorithm 'spdspds' -
> a novel algorithm for solving Linear Programming Problems with O(L^1.5)
> computational complexity -
> in order to show/convince the esteemed world optimization community
> that it is indeed a great grand breakthrough in terms of achievement of the
> linear programming performance challenge of the millennium -
> with far reaching deep impact on optimization algorithm development in
> general -
> holy grail fantasy realized!
> 
> I need some individual or team who is interested & willing to work on this.
> Earlier experience in implementation of optimization/LP algorithms will
> greatly help.
> 
> You may access / download / read my paper -
> "Unbelievable *O*(*L*^1.5) worst case computational complexity achieved by
> spdspds algorithm for linear programming problem"
> which is available at - arxiv . org / abs / 1405 . 6902
> 
> Thanks a lot.
>  - Dr(Prof) Keshava Prasad Halemane
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From 538280 @end|ng |rom gm@||@com  Thu Jun 11 01:16:40 2020
From: 538280 @end|ng |rom gm@||@com (Greg Snow)
Date: Wed, 10 Jun 2020 17:16:40 -0600
Subject: [R] Help about extracting data
In-Reply-To: <CABirntQV6SHK6sFNCVSqCTfUYCM_6S5Ce0=B+No-0oWqu=WwLA@mail.gmail.com>
References: <CABirntQV6SHK6sFNCVSqCTfUYCM_6S5Ce0=B+No-0oWqu=WwLA@mail.gmail.com>
Message-ID: <CAFEqCdxLvM3aNHrR+ym7MeOw2BsAB0VBvNFXEuqh2xybt1OBrQ@mail.gmail.com>

There are more than one way to do it, and it would help if you
provided some sample data.

But here is an example for one way to do it:

examp.dat <- as.data.frame(matrix(sample(1:5, 100*6, replace=TRUE), ncol=6)
tmp.count <- apply(examp.dat, 1, function(x) sum(x>=3))
examp2.dat <- examp.dat[tmp.count <= 4, ]

examp.dat is a data frame with example data.
tmp.count is then the result of applying an anonymous function to each
row, the function counts how many entries in each row are greater than
or equal to 3
examp2.dat is then created as the subset where tmp.count is less than
or equal to 4.


On Wed, Jun 10, 2020 at 12:47 PM Aya Gilad <ayagilad at gmail.com> wrote:
>
> Hello,
> I'm analyzing a 6-question questionnaire. I need to exclude participants
> who answered more than 4 questions with a grade of 3 or higher.
> How do I write such a code?
> Thank you!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From cpoiw@rt m@iii@g oii chemo@org@uk  Thu Jun 11 01:17:24 2020
From: cpoiw@rt m@iii@g oii chemo@org@uk (cpoiw@rt m@iii@g oii chemo@org@uk)
Date: Thu, 11 Jun 2020 00:17:24 +0100
Subject: [R] How to stack two Stack manhattan plots?
In-Reply-To: <CAF9-5jNVnYXouU-T2v-BMTjt+YJ=ZXwx4gmUkCrjB+ce4XuTZA@mail.gmail.com>
References: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>
 <CA+8X3fVF5hjgGmfFuF1s_R9bP+myPbcDN2xj_VoyMWPNfPCTyg@mail.gmail.com>
 <CAF9-5jNVnYXouU-T2v-BMTjt+YJ=ZXwx4gmUkCrjB+ce4XuTZA@mail.gmail.com>
Message-ID: <d28ffccd630a828a4eb446df507a1edb@chemo.org.uk>

What did you expect?

I'm assuming two plots (based on the subject) and side by side based on 
the code (nrow =1)

But you are getting several graphs (facets) on the row and only expected 
2?

What is in CHR?  i.e. summary(tmp1$CHR)

I'm assuming its not a factor with 2 elements...?


>> > Hello,
>> >
>> > I have a data frame like this:
>> >
>> > > head(tmp1)
>> >   CHR      BP   Pold    Pnew
>> > 1   1  785989 0.9521 0.09278
>> > 2   1 1130727 0.4750 0.19010
>> > 3   1 1156131 0.5289 0.48520
>> > 4   1 1158631 0.2554 0.18140
>> > 5   1 1211292 0.2954 0.48590
>> > 6   1 1478153 0.5542 0.68790
>> > ...
>> > ggplot(tmp.tidy, aes(BP, value, color=key)) + geom_point() +
>> > facet_wrap(~CHR, nrow=1)


From j@zh@o @end|ng |rom ye@h@net  Thu Jun 11 02:29:10 2020
From: j@zh@o @end|ng |rom ye@h@net (Jinsong Zhao)
Date: Thu, 11 Jun 2020 08:29:10 +0800
Subject: [R] how to extract specific subscript of a matrix
Message-ID: <31210cbb-91e6-fe2a-b958-a01862295d6b@yeah.net>

Hi there,

I have a matrix similar as:

M <- matrix(c(2,2,rep(1,12), 2), nrow = 5,byrow = FALSE)

I hope to get the border subscript of the block with value 1. In the 
above example, I hope to get:

(3,1), (5,1), (5,2), (4,2), (4,3), (1,3), (1,2), (3,2)

Is there any function can do that? or any implement idea? Thanks!

Best,
Jinsong


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jun 11 03:01:57 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 10 Jun 2020 18:01:57 -0700
Subject: [R] how to extract specific subscript of a matrix
In-Reply-To: <31210cbb-91e6-fe2a-b958-a01862295d6b@yeah.net>
References: <31210cbb-91e6-fe2a-b958-a01862295d6b@yeah.net>
Message-ID: <E9A6B727-0CE5-48EE-887A-4840302F4D83@dcn.davis.ca.us>

M <- matrix(c(2,2,rep(1,12), 2), nrow = 5,byrow = FALSE)
ix <- expand.grid( r = seq.int( nrow( M ) )
                 , c = seq.int( ncol( M ) )
                 )
ix[ 1 == c(M), ]


On June 10, 2020 5:29:10 PM PDT, Jinsong Zhao <jszhao at yeah.net> wrote:
>Hi there,
>
>I have a matrix similar as:
>
>M <- matrix(c(2,2,rep(1,12), 2), nrow = 5,byrow = FALSE)
>
>I hope to get the border subscript of the block with value 1. In the 
>above example, I hope to get:
>
>(3,1), (5,1), (5,2), (4,2), (4,3), (1,3), (1,2), (3,2)
>
>Is there any function can do that? or any implement idea? Thanks!
>
>Best,
>Jinsong
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jr@| @end|ng |rom po@teo@no  Thu Jun 11 03:21:40 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Thu, 11 Jun 2020 03:21:40 +0200
Subject: [R] how to extract specific subscript of a matrix
In-Reply-To: <E9A6B727-0CE5-48EE-887A-4840302F4D83@dcn.davis.ca.us>
References: <31210cbb-91e6-fe2a-b958-a01862295d6b@yeah.net>
 <E9A6B727-0CE5-48EE-887A-4840302F4D83@dcn.davis.ca.us>
Message-ID: <20200611012140.GA162277@posteo.no>

On 2020-06-10 18:01 -0700, Jeff Newmiller wrote:
> On June 10, 2020 5:29:10 PM PDT, Jinsong Zhao wrote:
> > 
> > (3,1), (5,1), (5,2), (4,2), (4,3), (1,3), (1,2), (3,2)
> 
> M <- matrix(c(2,2,rep(1,12), 2), nrow = 5,byrow = FALSE)
> ix <- expand.grid( r = seq.int( nrow( M ) )
>                  , c = seq.int( ncol( M ) )
>                  )
> ix[ 1 == c(M), ]

Dear Jinsong and Jeff,

I thought out this, really similar to Jeff's answer:

	M <- matrix(c(2, 2, rep(1, 12), 2),
	            nrow=5, byrow=FALSE)
	
	points <- expand.grid(1:nrow(M), 1:ncol(M))
	points <- apply(points, 1, paste, collapse=",")
	points <- matrix(paste0("(", points, ")"),
	                 nrow=nrow(M))
	
	paste(points[M==1], collapse=", ")

you get

	[1] "(3,1), (4,1), (5,1), (1,2), (2,2), (3,2), (4,2), (5,2), (1,3), (2,3), (3,3), (4,3)"

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200611/5675bb5e/attachment.sig>

From drj|m|emon @end|ng |rom gm@||@com  Thu Jun 11 05:24:27 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 11 Jun 2020 13:24:27 +1000
Subject: [R] Help with a (g)lmer code
In-Reply-To: <CAB_D3mrPo9JYv_i3RAonNxtZ6qneNtTMn_i2xFOQAGWHY1zPUg@mail.gmail.com>
References: <CAB_D3mrPo9JYv_i3RAonNxtZ6qneNtTMn_i2xFOQAGWHY1zPUg@mail.gmail.com>
Message-ID: <CA+8X3fX60Afeq+y90gwQwabO31_=bk1VFR=-Osb8cpWN0Qmr9Q@mail.gmail.com>

Hi Saudi,
I can only make a guess, but that is that a variable having a unique
value for each participant has been read in as a factor. I assume that
"better" is some combination of "hum" and "cul" and exactly what is
WF?

Jim

On Thu, Jun 11, 2020 at 5:27 AM Saudi Sadiq <saudisadiq at gmail.com> wrote:
>
> Dear Sir/Madam,
>
> Hope everyone is safe and sound. I appreciate your help a lot.
>
> I am evaluating two Arabic subtitles of a humorous English scene and asked
> 263 participants (part) to evaluate the two subtitles (named Standard
> Arabic, SA, and Egyptian Arabic, EA) via a questionnaire that asked them to
> rank the two subtitles in terms of how much each subtitle is
>
> 2) more humorous (hum),
>
> 5) closer to Egyptian culture (cul)
>
>
>
> The questionnaire contained two 1-10 linear scale questions regarding the 2
> points clarified, with 1 meaning the most humorous and closest to Egyptian
> culture, and 1 meaning the least humorous and furthest from Egyptian
> culture. Also, the questionnaire had a general multiple-choice question
> regarding which subtitle is better in general (better). General information
> about the participants were also collected concerning gender (categorical
> factor), age (numeric factor) and education (categorical factor).
>
> Two versions of the questionnaire were relied on: one showing the ?SA
> subtitle first? and another showing the ?EA subtitle first?. Nearly half
> the participants answered the first and nearly half answered the latter.
>
> I am focusing on which social factor/s lead/s the participants to evaluate
> one of the two subtitles as generally better and which subtitle is more
> humorous and closer to Egyptian culture. Each of these points alone can be
> the dependent factor, but the results altogether can be linked.
>
> I thought that mixed effects analyses would clarify the picture and answer
> the research questions (which  factor/s lead/s participants to favour a
> subtitle over another?) and, so,  tried the lme4 package in R and ran many
> models but all the codes I have used are not working.
>
> I ran the following codes, which yielded Error messages, like:
>
> model1<- lmer (better ~ gender + age + education + WF + (1 | part),
> data=sub_data)
>
> Error: number of levels of each grouping factor must be < number of
> observations (problems: part)
>
>
>
> Model2 <- glmer (better ~ gender + age + education + WF + (1 | part), data
> = sub_data, family='binomial')
>
> Error in mkRespMod(fr, family = family) :
>
>   response must be numeric or factor
>
>
>
> Model3 <- glmer (better ~ age + gender + education + WF + (1 | part), data
> = sub_data, family='binomial', control=glmerControl(optimizer=c("bobyqa")))
>
> Error in mkRespMod(fr, family = family) :
>
>   response must be numeric or factor
>
>
>
> Why does the model crash? Does the problem lie in the random factor part (which
> is a code for participants)? Or is it something related to the mixed
> effects analysis?
>
> Best
> Saudi Sadiq
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jwd @end|ng |rom @urewe@t@net  Thu Jun 11 06:24:55 2020
From: jwd @end|ng |rom @urewe@t@net (John)
Date: Wed, 10 Jun 2020 21:24:55 -0700
Subject: [R] How to stack two Stack manhattan plots?
In-Reply-To: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>
References: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>
Message-ID: <20200610212455.52872fd6@Draco>

On Wed, 10 Jun 2020 15:36:11 -0500
Ana Marija <sokovic.anamarija at gmail.com> wrote:

> Hello,
> 
> I have a data frame like this:
> 
> > head(tmp1)  
>   CHR      BP   Pold    Pnew
> 1   1  785989 0.9521 0.09278
> 2   1 1130727 0.4750 0.19010
> 3   1 1156131 0.5289 0.48520
> 4   1 1158631 0.2554 0.18140
> 5   1 1211292 0.2954 0.48590
> 6   1 1478153 0.5542 0.68790
> ...
> 
> I did:
> tmp.tidy <- tmp1 %>% gather(key, value, -BP, -CHR)
> jpeg("over.jpeg")
> ggplot(tmp.tidy, aes(BP, value, color=key)) + geom_point() +
> facet_wrap(~CHR, nrow=1)
> dev.off()
> 
> but I got this plot in attach which doesn't make sense. Can you please
> advise how to make this plot?
> 
> thanks
> Ana

If you would, the str() output might help people understand what is
happening, and also how many records you're looking at.  The head()
output is a bit thin on information.  There are various manhattan plot
packages for R including a specialized package for ggplot2. 

JWDougherty


From chr|@ho|d @end|ng |rom p@yctc@org  Thu Jun 11 08:48:52 2020
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Thu, 11 Jun 2020 07:48:52 +0100 (BST)
Subject: [R] Seeking implementation of my algorithm 'spdspds' - a novel
 algorithm for solving Linear Programming Problems with O(L^1.5)
 computational complexity
In-Reply-To: <76e9f973-aa59-db58-db28-ab0998622edb@gmail.com>
References: <CA+Pe9YUe5JmXz3DxPOGre_KnQeror+E44R5j6x_sDok6HWuSAQ@mail.gmail.com>
 <CA+Pe9YWE=6WkmxRe_JKhrfA4w3_JyS4Q-MHR+vvcUuNrNUH64Q@mail.gmail.com>
 <CA+Pe9YVX+52fpxOBRY5+XC9yUQzAs-EB3F1EQOxNc+iX8k_6fQ@mail.gmail.com>
 <CA+Pe9YXUr-uzpR5JnQ=f8o5SGNfQayWyBKw4sHV0d+cv1DjGoA@mail.gmail.com>
 <76e9f973-aa59-db58-db28-ab0998622edb@gmail.com>
Message-ID: <1377273822.3824145.1591858132256.JavaMail.zimbra@psyctc.org>



----- Original Message -----
> From: "J C Nash" <profjcnash at gmail.com>
> To: "Keshava PRASADa Halemane" <k.prasad.h at gmail.com>, r-help at r-project.org
> Sent: Thursday, 11 June, 2020 01:00:29
> Subject: Re: [R] Seeking implementation of my algorithm 'spdspds' - a novel algorithm for solving Linear Programming
> Problems with O(L^1.5) computational complexity

[snipped]
 
> I've worked on a lot of optimization (mainly function minimization) methods
> over many decades, and there are several "brilliant" ideas that have not
> turned out to be very good practical methods, while some rather pedestrian
> ideas have proved reliable and effective, even if they don't fulfill nice
> theoretical properties. There are, however, a few nice cases where theory
> and practice are both great.

Fortune nomination!   Glorious.  Thanks for making me smile.

Chris

[rest snipped]

-- 
Small contribution in our coronavirus rigours: 
https://www.coresystemtrust.org.uk/home/free-options-to-replace-paper-core-forms-during-the-coronavirus-pandemic/

Chris Evans <chris at psyctc.org> Visiting Professor, University of Sheffield <chris.evans at sheffield.ac.uk>
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places
but <chris at psyctc.org> remains my main Email address.  I have a work web site at:
   https://www.psyctc.org/psyctc/
and a site I manage for CORE and CORE system trust at:
   http://www.coresystemtrust.org.uk/
I have "semigrated" to France, see: 
   https://www.psyctc.org/pelerinage2016/semigrating-to-france/ 
   https://www.psyctc.org/pelerinage2016/register-to-get-updates-from-pelerinage2016/

If you want an Emeeting, I am trying to keep them to Thursdays and my diary is at:
   https://www.psyctc.org/pelerinage2016/ceworkdiary/
Beware: French time, generally an hour ahead of UK.


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Jun 11 09:17:28 2020
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 11 Jun 2020 09:17:28 +0200
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <alpine.LNX.2.20.2006100742230.20965@salmo.appl-ecosys.com>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
 <D8937C33-7558-4E88-B768-9D831970BFF6@dcn.davis.ca.us>
 <alpine.LNX.2.20.2006100742230.20965@salmo.appl-ecosys.com>
Message-ID: <24289.55944.187150.598914@stat.math.ethz.ch>

>>>>> Rich Shepard 
>>>>>     on Wed, 10 Jun 2020 07:44:49 -0700 writes:

    > On Wed, 10 Jun 2020, Jeff Newmiller wrote:
    >> Fix your format specification?  ?strptime

    >>> I have been trying to convert European short dates
    >>> formatted as dd/mm/yy into the ISO 8601 but the function
    >>> as.Dates interprets them as American ones (mm/dd/yy),
    >>> thus I get:

    > Look at Hadley Wickham's 'tidyverse' collection as
    > described in R for Data Science. There are date, datetime,
    > and time functions that will do just what you want.

    > Rich

I strongly disagree that automatic guessing of date format is a
good idea:

If you have dates such as  01/02/03, 10/11/12 , ...
you cannot have a software (and also not a human) to *guess* for
you what it means.  You have to *know* or get that knowledge "exogenously",
i.e., from context (say "meta data" if you want) that you as
data analyst must have before you can reliably work with that
data.

There is a global standard (ISO) for dates,  2020-06-11, for today's;
These have the huge advantage that alphabetical ordering is
equivalent to time ordering ... and honestly I don't see why
smart people (such as most? R users) do not all use these much
more often, notably when it comes to data.

But as long as most people in the world don't use that format
and practically all default formats for dates (e.g. in
spreadsheats and computer locales) do not use the ISO
standard, but rather regional conventions, one must add meta
data to have 100% garantee to use the correct format.

Of course, you can often guess correctly with very high
(subjective) probability, e.g.,   11/23/99  is highly probably
the 23rd of Nov, 1999.... and indeed if you have more than a few
dates, it often helps to guess correctly.  But there's no
guarantee.

No, I state that it is much better to ask from the data analyst
to use their brains a little bit and enter the date format
explicitly, than using software that does guess it for them
correctly most of the time.  How should they find out at all in
the rare cases the automatic guess will be wrong ?

Martin Maechler
ETH Zurich  and  R Core team


From jk|boger@ @end|ng |rom gm@||@com  Thu Jun 11 09:28:37 2020
From: jk|boger@ @end|ng |rom gm@||@com (jacob bogers)
Date: Thu, 11 Jun 2020 09:28:37 +0200
Subject: [R] Seeking implementation of my algorithm 'spdspds' - a novel
 algorithm for solving Linear Programming Problems with O(L^1.5)
 computational complexity
In-Reply-To: <CA+Pe9YXUr-uzpR5JnQ=f8o5SGNfQayWyBKw4sHV0d+cv1DjGoA@mail.gmail.com>
References: <CA+Pe9YUe5JmXz3DxPOGre_KnQeror+E44R5j6x_sDok6HWuSAQ@mail.gmail.com>
 <CA+Pe9YWE=6WkmxRe_JKhrfA4w3_JyS4Q-MHR+vvcUuNrNUH64Q@mail.gmail.com>
 <CA+Pe9YVX+52fpxOBRY5+XC9yUQzAs-EB3F1EQOxNc+iX8k_6fQ@mail.gmail.com>
 <CA+Pe9YXUr-uzpR5JnQ=f8o5SGNfQayWyBKw4sHV0d+cv1DjGoA@mail.gmail.com>
Message-ID: <CALuwgN6cozcT+zG+3m3n6aMy3aU9Z0L3MRwRY_18meNdxtyNsQ@mail.gmail.com>

" not having any access to the resources "
You have internet (as is proven by sending this email)
you even have R cli these days on mobile (I do anyway).
Learn R , code,  let me know how it turns out



On Wed, Jun 10, 2020 at 8:46 PM Keshava PRASADa Halemane <
k.prasad.h at gmail.com> wrote:

> Friends:
> i am a retired Professor -
> not having any access to the resources (human/financial/business/whatever)
> that may be required -
> therefore i am seeking implementation of my algorithm 'spdspds' -
> a novel algorithm for solving Linear Programming Problems with O(L^1.5)
> computational complexity -
> in order to show/convince the esteemed world optimization community
> that it is indeed a great grand breakthrough in terms of achievement of the
> linear programming performance challenge of the millennium -
> with far reaching deep impact on optimization algorithm development in
> general -
> holy grail fantasy realized!
>
> I need some individual or team who is interested & willing to work on this.
> Earlier experience in implementation of optimization/LP algorithms will
> greatly help.
>
> You may access / download / read my paper -
> "Unbelievable *O*(*L*^1.5) worst case computational complexity achieved by
> spdspds algorithm for linear programming problem"
> which is available at - arxiv . org / abs / 1405 . 6902
>
> Thanks a lot.
>  - Dr(Prof) Keshava Prasad Halemane
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Thu Jun 11 11:31:58 2020
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Thu, 11 Jun 2020 21:31:58 +1200
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <24289.55944.187150.598914@stat.math.ethz.ch>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
 <D8937C33-7558-4E88-B768-9D831970BFF6@dcn.davis.ca.us>
 <alpine.LNX.2.20.2006100742230.20965@salmo.appl-ecosys.com>
 <24289.55944.187150.598914@stat.math.ethz.ch>
Message-ID: <CABcYAdL8pfCFcf6Ka+4jGNMFcn44-dQTYmjgfHh+QkA5MwMqpw@mail.gmail.com>

I would add to this that in an important data set I was working with,
most of the dates were dd/mm/yy but some of them were mm/dd/yy and
that led to the realisation that I couldn't *tell* for about 40% of
the dates which they were.  If they were all one or the other, no
worries, but when you have people from mixed backgrounds writing in
mixed formats, you have a problem.

On Thu, 11 Jun 2020 at 19:17, Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>>>> Rich Shepard
> >>>>>     on Wed, 10 Jun 2020 07:44:49 -0700 writes:
>
>     > On Wed, 10 Jun 2020, Jeff Newmiller wrote:
>     >> Fix your format specification?  ?strptime
>
>     >>> I have been trying to convert European short dates
>     >>> formatted as dd/mm/yy into the ISO 8601 but the function
>     >>> as.Dates interprets them as American ones (mm/dd/yy),
>     >>> thus I get:
>
>     > Look at Hadley Wickham's 'tidyverse' collection as
>     > described in R for Data Science. There are date, datetime,
>     > and time functions that will do just what you want.
>
>     > Rich
>
> I strongly disagree that automatic guessing of date format is a
> good idea:
>
> If you have dates such as  01/02/03, 10/11/12 , ...
> you cannot have a software (and also not a human) to *guess* for
> you what it means.  You have to *know* or get that knowledge "exogenously",
> i.e., from context (say "meta data" if you want) that you as
> data analyst must have before you can reliably work with that
> data.
>
> There is a global standard (ISO) for dates,  2020-06-11, for today's;
> These have the huge advantage that alphabetical ordering is
> equivalent to time ordering ... and honestly I don't see why
> smart people (such as most? R users) do not all use these much
> more often, notably when it comes to data.
>
> But as long as most people in the world don't use that format
> and practically all default formats for dates (e.g. in
> spreadsheats and computer locales) do not use the ISO
> standard, but rather regional conventions, one must add meta
> data to have 100% garantee to use the correct format.
>
> Of course, you can often guess correctly with very high
> (subjective) probability, e.g.,   11/23/99  is highly probably
> the 23rd of Nov, 1999.... and indeed if you have more than a few
> dates, it often helps to guess correctly.  But there's no
> guarantee.
>
> No, I state that it is much better to ask from the data analyst
> to use their brains a little bit and enter the date format
> explicitly, than using software that does guess it for them
> correctly most of the time.  How should they find out at all in
> the rare cases the automatic guess will be wrong ?
>
> Martin Maechler
> ETH Zurich  and  R Core team
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@v|76 @end|ng |rom gm@||@com  Thu Jun 11 15:00:28 2020
From: r@v|76 @end|ng |rom gm@||@com (Ravi Jeyaraman)
Date: Thu, 11 Jun 2020 09:00:28 -0400
Subject: [R] sqldf and number of records affected
Message-ID: <01ec01d63ff0$48a0ffa0$d9e2fee0$@gmail.com>

Hello all, When I execute a SQL using SQLDF, how do I get the number of
records affected?  I mean, if I run an UPDATE on a data frame, it doesn't
tell me if and how many records got updated.  I've read through the
documentation and there don't seem to be a way to get this info unless it's
done on a database.  Any ideas?

Thanks
Ravi


-- 
This email has been checked for viruses by AVG.
https://www.avg.com


From ggrothend|eck @end|ng |rom gm@||@com  Thu Jun 11 15:12:22 2020
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Thu, 11 Jun 2020 09:12:22 -0400
Subject: [R] sqldf and number of records affected
In-Reply-To: <01ec01d63ff0$48a0ffa0$d9e2fee0$@gmail.com>
References: <01ec01d63ff0$48a0ffa0$d9e2fee0$@gmail.com>
Message-ID: <CAP01uRnOv3JaaVF8jrCR3ypEE1DBRhouNdxNusBps0JHnbE8Bw@mail.gmail.com>

Here is an example.  Ignore the warning or use the workaround discussed here
https://github.com/ggrothendieck/sqldf/issues/40
to avoid the warning.

  library(sqldf)
  sqldf()  # use same connection until next sqldf()
  sqldf(c("pragma count_changes = 1", "update BOD set demand = 99
where Time > 4"))
  sqldf("select * from main.BOD")
  sqldf()


On Thu, Jun 11, 2020 at 9:01 AM Ravi Jeyaraman <ravi76 at gmail.com> wrote:
>
> Hello all, When I execute a SQL using SQLDF, how do I get the number of
> records affected?  I mean, if I run an UPDATE on a data frame, it doesn't
> tell me if and how many records got updated.  I've read through the
> documentation and there don't seem to be a way to get this info unless it's
> done on a database.  Any ideas?
>
> Thanks
> Ravi
>
>
> --
> This email has been checked for viruses by AVG.
> https://www.avg.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Jun 11 15:29:13 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 11 Jun 2020 06:29:13 -0700 (PDT)
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <24289.55944.187150.598914@stat.math.ethz.ch>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
 <D8937C33-7558-4E88-B768-9D831970BFF6@dcn.davis.ca.us>
 <alpine.LNX.2.20.2006100742230.20965@salmo.appl-ecosys.com>
 <24289.55944.187150.598914@stat.math.ethz.ch>
Message-ID: <alpine.LNX.2.20.2006110625040.13945@salmo.appl-ecosys.com>

On Thu, 11 Jun 2020, Martin Maechler wrote:

>    > Look at Hadley Wickham's 'tidyverse' collection as
>    > described in R for Data Science. There are date, datetime,
>    > and time functions that will do just what you want.

> I strongly disagree that automatic guessing of date format is a
> good idea:

Martin,

I think either you misunderstood what I wrote or I was not sufficiently
explicit in my brief response. I did not mean to imply there was any
automatic guessing involved. Specifying input and output formats is
required.

Reading Hadley's book I was impressed that one could specify the format of
dates in the dataset and convert them all to the ISO-8601 format. Before
learning this I'd use emacs regex to do the reformating I needed (or,
sometimes, awk).

Regards,

Rich


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Thu Jun 11 15:32:20 2020
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Thu, 11 Jun 2020 06:32:20 -0700 (PDT)
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <CABcYAdL8pfCFcf6Ka+4jGNMFcn44-dQTYmjgfHh+QkA5MwMqpw@mail.gmail.com>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
 <D8937C33-7558-4E88-B768-9D831970BFF6@dcn.davis.ca.us>
 <alpine.LNX.2.20.2006100742230.20965@salmo.appl-ecosys.com>
 <24289.55944.187150.598914@stat.math.ethz.ch>
 <CABcYAdL8pfCFcf6Ka+4jGNMFcn44-dQTYmjgfHh+QkA5MwMqpw@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.2006110629250.13945@salmo.appl-ecosys.com>

On Thu, 11 Jun 2020, Richard O'Keefe wrote:

> I would add to this that in an important data set I was working with, most
> of the dates were dd/mm/yy but some of them were mm/dd/yy and that led to
> the realisation that I couldn't *tell* for about 40% of the dates which
> they were. If they were all one or the other, no worries, but when you
> have people from mixed backgrounds writing in mixed formats, you have a
> problem.

Richard,

Ouch! While I've not had data sets with this problem I've had many that were
extracted from spreadsheets that had a mix of date formats mm/dd/yyyy,
mm-dd-yyyy, and other strange strings. That's why I encourage my clients to
use a database rather than spreadsheets for their environmental data.

Regards,

Rich


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Thu Jun 11 15:54:40 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Thu, 11 Jun 2020 08:54:40 -0500
Subject: [R] How to stack two Stack manhattan plots?
In-Reply-To: <20200610212455.52872fd6@Draco>
References: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>
 <20200610212455.52872fd6@Draco>
Message-ID: <CAF9-5jMmCAZr_0o0HiW1MFSrnV_RHyD_+bTj3wCOJzSwj_iobg@mail.gmail.com>

Hello,

I expected it to look like this:
https://imgur.com/a/pj40c

where x-axis would be CHR, there is 22 of them
> unique(tmp.tidy$CHR)
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22

I also have two phenotypes (keys) which I would like to compare
> unique(tmp.tidy$key)
[1] "Pold" "Pnew"

> dim(tmp.tidy)
[1] 2600184       4

I would like the x-axis to be separated by CHR

> sapply(tmp.tidy,class)
        CHR          BP         key       value
  "integer"   "integer" "character"   "numeric"

> str(tmp.tidy)
'data.frame':    2600184 obs. of  4 variables:
 $ CHR  : int  1 1 1 1 1 1 1 1 1 1 ...
 $ BP   : int  785989 1130727 1156131 1158631 1211292 1478153 1500941
1506035 1510801 1721479 ...
 $ key  : chr  "Pold" "Pold" "Pold" "Pold" ...
 $ value: num  0.952 0.475 0.529 0.255 0.295 ...

Unfortunately qqman doesn't do this kind of overlay of two plots

On Wed, Jun 10, 2020 at 11:24 PM John <jwd at surewest.net> wrote:
>
> On Wed, 10 Jun 2020 15:36:11 -0500
> Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> > Hello,
> >
> > I have a data frame like this:
> >
> > > head(tmp1)
> >   CHR      BP   Pold    Pnew
> > 1   1  785989 0.9521 0.09278
> > 2   1 1130727 0.4750 0.19010
> > 3   1 1156131 0.5289 0.48520
> > 4   1 1158631 0.2554 0.18140
> > 5   1 1211292 0.2954 0.48590
> > 6   1 1478153 0.5542 0.68790
> > ...
> >
> > I did:
> > tmp.tidy <- tmp1 %>% gather(key, value, -BP, -CHR)
> > jpeg("over.jpeg")
> > ggplot(tmp.tidy, aes(BP, value, color=key)) + geom_point() +
> > facet_wrap(~CHR, nrow=1)
> > dev.off()
> >
> > but I got this plot in attach which doesn't make sense. Can you please
> > advise how to make this plot?
> >
> > thanks
> > Ana
>
> If you would, the str() output might help people understand what is
> happening, and also how many records you're looking at.  The head()
> output is a bit thin on information.  There are various manhattan plot
> packages for R including a specialized package for ggplot2.
>
> JWDougherty


From r@v|76 @end|ng |rom gm@||@com  Thu Jun 11 16:06:35 2020
From: r@v|76 @end|ng |rom gm@||@com (Ravi Jeyaraman)
Date: Thu, 11 Jun 2020 10:06:35 -0400
Subject: [R] sqldf and number of records affected
In-Reply-To: <CAP01uRnOv3JaaVF8jrCR3ypEE1DBRhouNdxNusBps0JHnbE8Bw@mail.gmail.com>
References: <01ec01d63ff0$48a0ffa0$d9e2fee0$@gmail.com>
 <CAP01uRnOv3JaaVF8jrCR3ypEE1DBRhouNdxNusBps0JHnbE8Bw@mail.gmail.com>
Message-ID: <104401d63ff9$84d4e640$8e7eb2c0$@gmail.com>

Thanks for the response Gabor.  Looks like the below example will work when using SQLite, but in my case I'm just creating a dataframe in R and trying to update it using sqldf as below and it doesn't seem to work ...

con <- data.frame(V1 = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
sqldf()
sqldf(c("pragma count_changes = 1", "update con set V1 = 0 where V1 > 5 "))
ans <- sqldf("select * from main.con")
sqldf()

-----Original Message-----
From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com] 
Sent: Thursday, June 11, 2020 9:12 AM
To: Ravi Jeyaraman <ravi76 at gmail.com>
Cc: r-help at r-project.org
Subject: Re: [R] sqldf and number of records affected

Here is an example.  Ignore the warning or use the workaround discussed here
https://github.com/ggrothendieck/sqldf/issues/40
to avoid the warning.

  library(sqldf)
  sqldf()  # use same connection until next sqldf()
  sqldf(c("pragma count_changes = 1", "update BOD set demand = 99 where Time > 4"))
  sqldf("select * from main.BOD")
  sqldf()


On Thu, Jun 11, 2020 at 9:01 AM Ravi Jeyaraman <ravi76 at gmail.com> wrote:
>
> Hello all, When I execute a SQL using SQLDF, how do I get the number 
> of records affected?  I mean, if I run an UPDATE on a data frame, it 
> doesn't tell me if and how many records got updated.  I've read 
> through the documentation and there don't seem to be a way to get this 
> info unless it's done on a database.  Any ideas?
>
> Thanks
> Ravi
>
>
> --
> This email has been checked for viruses by AVG.
> https://www.avg.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



--
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


-- 
This email has been checked for viruses by AVG.
https://www.avg.com


From cpoiw@rt m@iii@g oii chemo@org@uk  Thu Jun 11 16:26:40 2020
From: cpoiw@rt m@iii@g oii chemo@org@uk (cpoiw@rt m@iii@g oii chemo@org@uk)
Date: Thu, 11 Jun 2020 15:26:40 +0100
Subject: [R] How to stack two Stack manhattan plots?
In-Reply-To: <CAF9-5jMmCAZr_0o0HiW1MFSrnV_RHyD_+bTj3wCOJzSwj_iobg@mail.gmail.com>
References: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>
 <20200610212455.52872fd6@Draco>
 <CAF9-5jMmCAZr_0o0HiW1MFSrnV_RHyD_+bTj3wCOJzSwj_iobg@mail.gmail.com>
Message-ID: <5a83736b8248685d1ff8352f7894cd10@chemo.org.uk>

On 2020-06-11 14:54, Ana Marija wrote:
> Hello,
> 
> I expected it to look like this:
> https://imgur.com/a/pj40c
> 

Ah - so all on the one plot? - so you don't want a facet. It puts two 
plots side by side (or 22)

> where x-axis would be CHR, there is 22 of them
>> unique(tmp.tidy$CHR)
>  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22
> 

You have 22 plots all appearing side by size as part of the facet

I think you want color=CHR - but I don't know what your current color 
setting is doing.

> I also have two phenotypes (keys) which I would like to compare
>> unique(tmp.tidy$key)
> [1] "Pold" "Pnew"
> 

So did you want to Facet those?


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Jun 11 16:27:30 2020
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 11 Jun 2020 16:27:30 +0200
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <alpine.LNX.2.20.2006110625040.13945@salmo.appl-ecosys.com>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
 <D8937C33-7558-4E88-B768-9D831970BFF6@dcn.davis.ca.us>
 <alpine.LNX.2.20.2006100742230.20965@salmo.appl-ecosys.com>
 <24289.55944.187150.598914@stat.math.ethz.ch>
 <alpine.LNX.2.20.2006110625040.13945@salmo.appl-ecosys.com>
Message-ID: <24290.16210.645249.430350@stat.math.ethz.ch>

>>>>> Rich Shepard 
>>>>>     on Thu, 11 Jun 2020 06:29:13 -0700 writes:

    > On Thu, 11 Jun 2020, Martin Maechler wrote:
    >> > Look at Hadley Wickham's 'tidyverse' collection as >
    >> described in R for Data Science. There are date,
    >> datetime, > and time functions that will do just what you
    >> want.

    >> I strongly disagree that automatic guessing of date
    >> format is a good idea:

    > Martin,

    > I think either you misunderstood what I wrote or I was not
    > sufficiently explicit in my brief response. I did not mean
    > to imply there was any automatic guessing
    > involved. Specifying input and output formats is required.

Well, ok.  Yes, then I misunderstood.  I know there *are* R
packages out there which boast automatically finding the correct format.

If you are willing to specify the input format, I don't see why
one should use the huge tidyverse  instead of just using the
potent enough base R functions,  one of which Jeff Newmiller was
talking about (and to whom you replied saying you'd rather use
the extra functions).

    > Reading Hadley's book I was impressed that one could
    > specify the format of dates in the dataset and convert
    > them all to the ISO-8601 format. Before learning this I'd
    > use emacs regex to do the reformating I needed (or,
    > sometimes, awk).

Well, as you know I use emacs even more than R (because I use R
via emacs's ESS),  but I think I wouldn't use it to transform
dates or date times [well, unless such a date/datetime column
is so severely messed up that one format is not appropriate for
at least a few large chunks of these] because I'd rather try to
use completely reproducible R code from the beginning of
cleaning/reading/analysing the raw data to the end.

And for that, base R is entirely sufficient in spite of all the
advertisements of the many date/time formatting packages.
But yes, I wrote more about this about 10 weeks ago on the
R-devel list here  (which also seemed to have been
rather mis-understood, for which I must mostly blame myself of course) :

  https://stat.ethz.ch/pipermail/r-devel/2020-April/079260.html

In that thread, the following  'R News' article was mentioned as
good introduction in the subject from a 'base R' (+ "almost
recommended" package 'chron') point of view 

  https://www.researchgate.net/publication/229087103_R_Help_Desk_Date_and_time_classes_in_R

which is really from here

  https://www.r-project.org/doc/Rnews/Rnews_2004-1.pdf

'R News' was the predecessor of the
R Journal, https://journal.r-project.org/

I think we should leave it here, because we've been diverting
too much.

Best,
Martin


From ggrothend|eck @end|ng |rom gm@||@com  Thu Jun 11 16:30:02 2020
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Thu, 11 Jun 2020 10:30:02 -0400
Subject: [R] sqldf and number of records affected
In-Reply-To: <104401d63ff9$84d4e640$8e7eb2c0$@gmail.com>
References: <01ec01d63ff0$48a0ffa0$d9e2fee0$@gmail.com>
 <CAP01uRnOv3JaaVF8jrCR3ypEE1DBRhouNdxNusBps0JHnbE8Bw@mail.gmail.com>
 <104401d63ff9$84d4e640$8e7eb2c0$@gmail.com>
Message-ID: <CAP01uRkF_CgC9BehTE79VherJyKF0TBUuMLY5Wuq+KepQY9P-g@mail.gmail.com>

There is no real difference between your example and the example I provided.
Both use a data.frame in R and both work for me under R 3.5 with RSQLite 2.2.0
See log below.

Note that there is a bug in R 4.0 related to tcltk that could possibly affect
sqldf as it uses tcltk.  A fix has been announced for R 4.0.2.

> library(sqldf)
Loading required package: gsubfn
Loading required package: proto
Loading required package: RSQLite
> con <- data.frame(V1 = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
> sqldf()
<SQLiteConnection>
  Path: :memory:
  Extensions: TRUE
> sqldf(c("pragma count_changes = 1", "update con set V1 = 0 where V1 > 5 "))
  rows updated
1            5
Warning message:
In result_fetch(res at ptr, n = n) :
  SQL statements must be issued with dbExecute() or dbSendStatement()
instead of dbGetQuery() or dbSendQuery().
> ans <- sqldf("select * from main.con")
> sqldf()
NULL
> ans
   V1
1   1
2   2
3   3
4   4
5   5
6   0
7   0
8   0
9   0
10  0
> R.version.string
[1] "R version 3.5.3 (2019-03-11)"
> packageVersion("sqldf")
[1] ?0.4.11?
> packageVersion("RSQLite")
[1] ?2.2.0?
> packageVersion("DBI")
[1] ?1.1.0?



On Thu, Jun 11, 2020 at 10:06 AM Ravi Jeyaraman <ravi76 at gmail.com> wrote:
>
> Thanks for the response Gabor.  Looks like the below example will work when using SQLite, but in my case I'm just creating a dataframe in R and trying to update it using sqldf as below and it doesn't seem to work ...
>
> con <- data.frame(V1 = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
> sqldf()
> sqldf(c("pragma count_changes = 1", "update con set V1 = 0 where V1 > 5 "))
> ans <- sqldf("select * from main.con")
> sqldf()
>
> -----Original Message-----
> From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com]
> Sent: Thursday, June 11, 2020 9:12 AM
> To: Ravi Jeyaraman <ravi76 at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] sqldf and number of records affected
>
> Here is an example.  Ignore the warning or use the workaround discussed here
> https://github.com/ggrothendieck/sqldf/issues/40
> to avoid the warning.
>
>   library(sqldf)
>   sqldf()  # use same connection until next sqldf()
>   sqldf(c("pragma count_changes = 1", "update BOD set demand = 99 where Time > 4"))
>   sqldf("select * from main.BOD")
>   sqldf()
>
>
> On Thu, Jun 11, 2020 at 9:01 AM Ravi Jeyaraman <ravi76 at gmail.com> wrote:
> >
> > Hello all, When I execute a SQL using SQLDF, how do I get the number
> > of records affected?  I mean, if I run an UPDATE on a data frame, it
> > doesn't tell me if and how many records got updated.  I've read
> > through the documentation and there don't seem to be a way to get this
> > info unless it's done on a database.  Any ideas?
> >
> > Thanks
> > Ravi
> >
> >
> > --
> > This email has been checked for viruses by AVG.
> > https://www.avg.com
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
>
>
> --
> This email has been checked for viruses by AVG.
> https://www.avg.com
>


--
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From jr@| @end|ng |rom po@teo@no  Thu Jun 11 16:48:51 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Thu, 11 Jun 2020 16:48:51 +0200
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
Message-ID: <20200611144851.GB162277@posteo.no>

On 2020-06-10 10:20 +0200, Luigi Marongiu wrote:
> I have been trying to convert European 
> short dates formatted as dd/mm/yy into the 
> ISO 8601 but the function as.Dates 
> interprets them as American ones 
> (mm/dd/yy)

Dear Luigi,

?strptime says:

	?%D? Date format such as ?%m/%d/%y?: the C99 standard says it
	     should be that exact format (but not all OSes comply).

as.Date(oriDates, format="%d/%m/%y") works 
fine for me here on the Linux laptop ... 

You could also try to work on the strings 
themselves to convert them to ISO format, 
like:

	oriDates = c("23/01/20", "24/01/20", "25/01/20", "26/01/20",
	             "27/01/20", "28/01/20", "29/01/20", "30/01/20",
	             "31/01/20", "01/02/20", "02/02/20", "03/02/20",
	             "04/02/20", "05/02/20", "06/02/20", "07/02/20")
	d <- t(as.data.frame(strsplit(oriDates, "/")))
	dimnames(d) <- list(NULL, c("d", "m", "y"))
	u <- unique(d[,"y"])
	millenia <- "20"
	if (length(u)==1 & u==millenia) {
	  Dates <- paste0(millenia, d[,"y"], "-",
	                  d[,"m"], "-", d[,"d"])
	  Dates <- as.Date(Dates)
	} else {
	  Dates <- "'Allo 'allo ... error, error ... more complicated formatting is required to digest those dates ..."
	}
	print(Dates)

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200611/1108b6bb/attachment.sig>

From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Thu Jun 11 16:59:37 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Thu, 11 Jun 2020 09:59:37 -0500
Subject: [R] How to stack two Stack manhattan plots?
In-Reply-To: <5a83736b8248685d1ff8352f7894cd10@chemo.org.uk>
References: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>
 <20200610212455.52872fd6@Draco>
 <CAF9-5jMmCAZr_0o0HiW1MFSrnV_RHyD_+bTj3wCOJzSwj_iobg@mail.gmail.com>
 <5a83736b8248685d1ff8352f7894cd10@chemo.org.uk>
Message-ID: <CAF9-5jPkWqVhuxsxurhiiyRzytco-Rsf1AH6n4yR-y_O9RgOYA@mail.gmail.com>

yes all in one plot.
So I want key (and therefore color)to be "Pold" and "Pnew" as those I
am comparing per CHR
so I used facet_wrap(~CHR) to create a graph per chromosome (on x-axis)
On the end x-axis would have two strikes of Pold and Pnew (different
colors) per one chromosome, and CHR would go from 1 to 22

On Thu, Jun 11, 2020 at 9:26 AM <cpolwart at chemo.org.uk> wrote:
>
> On 2020-06-11 14:54, Ana Marija wrote:
> > Hello,
> >
> > I expected it to look like this:
> > https://imgur.com/a/pj40c
> >
>
> Ah - so all on the one plot? - so you don't want a facet. It puts two
> plots side by side (or 22)
>
> > where x-axis would be CHR, there is 22 of them
> >> unique(tmp.tidy$CHR)
> >  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22
> >
>
> You have 22 plots all appearing side by size as part of the facet
>
> I think you want color=CHR - but I don't know what your current color
> setting is doing.
>
> > I also have two phenotypes (keys) which I would like to compare
> >> unique(tmp.tidy$key)
> > [1] "Pold" "Pnew"
> >
>
> So did you want to Facet those?


From r@v|76 @end|ng |rom gm@||@com  Thu Jun 11 17:30:40 2020
From: r@v|76 @end|ng |rom gm@||@com (Ravi Jeyaraman)
Date: Thu, 11 Jun 2020 11:30:40 -0400
Subject: [R] sqldf and number of records affected
In-Reply-To: <CAP01uRkF_CgC9BehTE79VherJyKF0TBUuMLY5Wuq+KepQY9P-g@mail.gmail.com>
References: <01ec01d63ff0$48a0ffa0$d9e2fee0$@gmail.com>
 <CAP01uRnOv3JaaVF8jrCR3ypEE1DBRhouNdxNusBps0JHnbE8Bw@mail.gmail.com>
 <104401d63ff9$84d4e640$8e7eb2c0$@gmail.com>
 <CAP01uRkF_CgC9BehTE79VherJyKF0TBUuMLY5Wuq+KepQY9P-g@mail.gmail.com>
Message-ID: <107201d64005$43ced190$cb6c74b0$@gmail.com>

You're correct.  It does work.  I was looking at some other result printed.  My bad.

Looks like we can also get the same result using 'SELECT changes()'.     

Approach 1:

con <- data.frame(V1 = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
sqldf()
suppressWarnings(sqldf(c(" update con set V1 = 0 where V1 > 5 ", "select changes()")))
sqldf("select * from main.con")
sqldf()

Approach 2:

con <- data.frame(V1 = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
sqldf()
suppressWarnings(sqldf(c("pragma count_changes = 1", "update con set V1 = 0 where V1 > 5 ")))
sqldf("select * from main.con")
sqldf()



-----Original Message-----
From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com] 
Sent: Thursday, June 11, 2020 10:30 AM
To: Ravi Jeyaraman <ravi76 at gmail.com>
Cc: r-help at r-project.org
Subject: Re: [R] sqldf and number of records affected

There is no real difference between your example and the example I provided.
Both use a data.frame in R and both work for me under R 3.5 with RSQLite 2.2.0 See log below.

Note that there is a bug in R 4.0 related to tcltk that could possibly affect sqldf as it uses tcltk.  A fix has been announced for R 4.0.2.

> library(sqldf)
Loading required package: gsubfn
Loading required package: proto
Loading required package: RSQLite
> con <- data.frame(V1 = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
> sqldf()
<SQLiteConnection>
  Path: :memory:
  Extensions: TRUE
> sqldf(c("pragma count_changes = 1", "update con set V1 = 0 where V1 > 
> 5 "))
  rows updated
1            5
Warning message:
In result_fetch(res at ptr, n = n) :
  SQL statements must be issued with dbExecute() or dbSendStatement() instead of dbGetQuery() or dbSendQuery().
> ans <- sqldf("select * from main.con")
> sqldf()
NULL
> ans
   V1
1   1
2   2
3   3
4   4
5   5
6   0
7   0
8   0
9   0
10  0
> R.version.string
[1] "R version 3.5.3 (2019-03-11)"
> packageVersion("sqldf")
[1] ?0.4.11?
> packageVersion("RSQLite")
[1] ?2.2.0?
> packageVersion("DBI")
[1] ?1.1.0?



On Thu, Jun 11, 2020 at 10:06 AM Ravi Jeyaraman <ravi76 at gmail.com> wrote:
>
> Thanks for the response Gabor.  Looks like the below example will work when using SQLite, but in my case I'm just creating a dataframe in R and trying to update it using sqldf as below and it doesn't seem to work ...
>
> con <- data.frame(V1 = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10))
> sqldf()
> sqldf(c("pragma count_changes = 1", "update con set V1 = 0 where V1 > 
> 5 ")) ans <- sqldf("select * from main.con")
> sqldf()
>
> -----Original Message-----
> From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com]
> Sent: Thursday, June 11, 2020 9:12 AM
> To: Ravi Jeyaraman <ravi76 at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] sqldf and number of records affected
>
> Here is an example.  Ignore the warning or use the workaround 
> discussed here
> https://github.com/ggrothendieck/sqldf/issues/40
> to avoid the warning.
>
>   library(sqldf)
>   sqldf()  # use same connection until next sqldf()
>   sqldf(c("pragma count_changes = 1", "update BOD set demand = 99 where Time > 4"))
>   sqldf("select * from main.BOD")
>   sqldf()
>
>
> On Thu, Jun 11, 2020 at 9:01 AM Ravi Jeyaraman <ravi76 at gmail.com> wrote:
> >
> > Hello all, When I execute a SQL using SQLDF, how do I get the number 
> > of records affected?  I mean, if I run an UPDATE on a data frame, it 
> > doesn't tell me if and how many records got updated.  I've read 
> > through the documentation and there don't seem to be a way to get 
> > this info unless it's done on a database.  Any ideas?
> >
> > Thanks
> > Ravi
> >
> >
> > --
> > This email has been checked for viruses by AVG.
> > https://www.avg.com
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
>
>
> --
> This email has been checked for viruses by AVG.
> https://www.avg.com
>


--
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From cpoiw@rt m@iii@g oii chemo@org@uk  Thu Jun 11 18:52:38 2020
From: cpoiw@rt m@iii@g oii chemo@org@uk (cpoiw@rt m@iii@g oii chemo@org@uk)
Date: Thu, 11 Jun 2020 17:52:38 +0100
Subject: [R] How to stack two Stack manhattan plots?
In-Reply-To: <CAF9-5jPkWqVhuxsxurhiiyRzytco-Rsf1AH6n4yR-y_O9RgOYA@mail.gmail.com>
References: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>
 <20200610212455.52872fd6@Draco>
 <CAF9-5jMmCAZr_0o0HiW1MFSrnV_RHyD_+bTj3wCOJzSwj_iobg@mail.gmail.com>
 <5a83736b8248685d1ff8352f7894cd10@chemo.org.uk>
 <CAF9-5jPkWqVhuxsxurhiiyRzytco-Rsf1AH6n4yR-y_O9RgOYA@mail.gmail.com>
Message-ID: <f5bbf6217dc3af9d5b83bcea68a2a20a@chemo.org.uk>

On 2020-06-11 15:59, Ana Marija wrote:
> yes all in one plot.
> So I want key (and therefore color)to be "Pold" and "Pnew" as those I
> am comparing per CHR
> so I used facet_wrap(~CHR) to create a graph per chromosome (on x-axis)
> On the end x-axis would have two strikes of Pold and Pnew (different
> colors) per one chromosome, and CHR would go from 1 to 22
> 


ggplot( data = tmp.tidy) +
geom_point( aes(
             y = BP,
             x = CHR,
             color=key) )

?


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Thu Jun 11 22:41:41 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Thu, 11 Jun 2020 15:41:41 -0500
Subject: [R] How to stack two Stack manhattan plots?
In-Reply-To: <f5bbf6217dc3af9d5b83bcea68a2a20a@chemo.org.uk>
References: <CAF9-5jMhXU6p+4WO09zw4TjO-oTTUf2SRvO68cH49aYRyDELCQ@mail.gmail.com>
 <20200610212455.52872fd6@Draco>
 <CAF9-5jMmCAZr_0o0HiW1MFSrnV_RHyD_+bTj3wCOJzSwj_iobg@mail.gmail.com>
 <5a83736b8248685d1ff8352f7894cd10@chemo.org.uk>
 <CAF9-5jPkWqVhuxsxurhiiyRzytco-Rsf1AH6n4yR-y_O9RgOYA@mail.gmail.com>
 <f5bbf6217dc3af9d5b83bcea68a2a20a@chemo.org.uk>
Message-ID: <CAF9-5jNkXvuBabj8Ep9cu25R4w-mdvct=hWPniNChLuA87mb_Q@mail.gmail.com>

Hello,

I tried your code and this is what I got

I really need two groups side by side shown per chromosome as it is here:
https://imgur.com/a/pj40c
on the image there are 4 groups I do have only two

On Thu, Jun 11, 2020 at 11:52 AM <cpolwart at chemo.org.uk> wrote:
>
> On 2020-06-11 15:59, Ana Marija wrote:
> > yes all in one plot.
> > So I want key (and therefore color)to be "Pold" and "Pnew" as those I
> > am comparing per CHR
> > so I used facet_wrap(~CHR) to create a graph per chromosome (on x-axis)
> > On the end x-axis would have two strikes of Pold and Pnew (different
> > colors) per one chromosome, and CHR would go from 1 to 22
> >
>
>
> ggplot( data = tmp.tidy) +
> geom_point( aes(
>              y = BP,
>              x = CHR,
>              color=key) )
>
> ?

From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Thu Jun 11 23:26:49 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Thu, 11 Jun 2020 16:26:49 -0500
Subject: [R] How to stack two Stack manhattan plots?
In-Reply-To: <eb1a2f83-fc61-4df9-99c3-afc620b15b59@email.android.com>
References: <CAF9-5jNkXvuBabj8Ep9cu25R4w-mdvct=hWPniNChLuA87mb_Q@mail.gmail.com>
 <eb1a2f83-fc61-4df9-99c3-afc620b15b59@email.android.com>
Message-ID: <CAF9-5jPG855OJZx7PmE204vi4awWBCjR6c5rV57-dKmKVho_eA@mail.gmail.com>

I tried it,
ggplot( data = tmp.tidy) +geom_point( aes(y = BP,x = CHR,color=key)
,position = "jitter" )
I got the attached

On Thu, Jun 11, 2020 at 4:18 PM <cpolwart at chemo.org.uk> wrote:
>
> Try adding
> position = "jitter" to the geom_point(...
>
>
>
> On 11 Jun 2020 21:41, Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> I tried your code and this is what I got
>
> I really need two groups side by side shown per chromosome as it is here:
> https://imgur.com/a/pj40c
> on the image there are 4 groups I do have only two
>
> On Thu, Jun 11, 2020 at 11:52 AM <cpolwart at chemo.org.uk> wrote:
> >
> > On 2020-06-11 15:59, Ana Marija wrote:
> > > yes all in one plot.
> > > So I want key (and therefore color)to be "Pold" and "Pnew" as those I
> > > am comparing per CHR
> > > so I used facet_wrap(~CHR) to create a graph per chromosome (on x-axis)
> > > On the end x-axis would have two strikes of Pold and Pnew (different
> > > colors) per one chromosome, and CHR would go from 1 to 22
> > >
> >
> >
> > ggplot( data = tmp.tidy) +
> > geom_point( aes(
> >              y = BP,
> >              x = CHR,
> >              color=key) )
> >
> > ?
>
>

From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Thu Jun 11 23:50:31 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Thu, 11 Jun 2020 16:50:31 -0500
Subject: [R] How to stack two Stack manhattan plots?
In-Reply-To: <7759e2a5-2d68-4c48-933a-0b853a4e9e38@email.android.com>
References: <CAF9-5jPG855OJZx7PmE204vi4awWBCjR6c5rV57-dKmKVho_eA@mail.gmail.com>
 <7759e2a5-2d68-4c48-933a-0b853a4e9e38@email.android.com>
Message-ID: <CAF9-5jMb=9ugeZC_isVL1p0TF-BPJwPWYQMXb4YVTH6-3=axSA@mail.gmail.com>

Thank you so much it is getting better (see attach) when I do:
ggplot( data = tmp.tidy) +geom_point( aes(y = -log10(value),x =
CHR,color=key) ,position = "jitter", size=0.5 )

is there is a way to have separation between every chromosome shown
better and also every number of chromosome shown on the x-axis?

On Thu, Jun 11, 2020 at 4:39 PM <cpolwart at chemo.org.uk> wrote:
>
> Your dots are too big!
>
> Add
>
> geom_points(... , size = 1
>
> May need to play... 0.5 or 0.1?
>
> On 11 Jun 2020 22:26, Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> I tried it,
> ggplot( data = tmp.tidy) +geom_point( aes(y = BP,x = CHR,color=key)
> ,position = "jitter" )
> I got the attached
>
> On Thu, Jun 11, 2020 at 4:18 PM <cpolwart at chemo.org.uk> wrote:
> >
> > Try adding
> > position = "jitter" to the geom_point(...
> >
> >
> >
> > On 11 Jun 2020 21:41, Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hello,
> >
> > I tried your code and this is what I got
> >
> > I really need two groups side by side shown per chromosome as it is here:
> > https://imgur.com/a/pj40c
> > on the image there are 4 groups I do have only two
> >
> > On Thu, Jun 11, 2020 at 11:52 AM <cpolwart at chemo.org.uk> wrote:
> > >
> > > On 2020-06-11 15:59, Ana Marija wrote:
> > > > yes all in one plot.
> > > > So I want key (and therefore color)to be "Pold" and "Pnew" as those I
> > > > am comparing per CHR
> > > > so I used facet_wrap(~CHR) to create a graph per chromosome (on x-axis)
> > > > On the end x-axis would have two strikes of Pold and Pnew (different
> > > > colors) per one chromosome, and CHR would go from 1 to 22
> > > >
> > >
> > >
> > > ggplot( data = tmp.tidy) +
> > > geom_point( aes(
> > >              y = BP,
> > >              x = CHR,
> > >              color=key) )
> > >
> > > ?
> >
> >
>
>

From @purd|e@@ @end|ng |rom gm@||@com  Fri Jun 12 02:14:29 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Fri, 12 Jun 2020 12:14:29 +1200
Subject: [R] Seeking implementation of my algorithm 'spdspds' - a novel
 algorithm for solving Linear Programming Problems with O(L^1.5)
 computational complexity
In-Reply-To: <CA+Pe9YXUr-uzpR5JnQ=f8o5SGNfQayWyBKw4sHV0d+cv1DjGoA@mail.gmail.com>
References: <CA+Pe9YUe5JmXz3DxPOGre_KnQeror+E44R5j6x_sDok6HWuSAQ@mail.gmail.com>
 <CA+Pe9YWE=6WkmxRe_JKhrfA4w3_JyS4Q-MHR+vvcUuNrNUH64Q@mail.gmail.com>
 <CA+Pe9YVX+52fpxOBRY5+XC9yUQzAs-EB3F1EQOxNc+iX8k_6fQ@mail.gmail.com>
 <CA+Pe9YXUr-uzpR5JnQ=f8o5SGNfQayWyBKw4sHV0d+cv1DjGoA@mail.gmail.com>
Message-ID: <CAB8pepwWxvw_RDQydtoBtdBu8k5NpudfKHC_Af5P5X2Jkkui3w@mail.gmail.com>

> solving Linear Programming Problems with O(L^1.5)
> computational complexity

I'm not an expert on this topic.
However, a quick glance at the topic suggests that these sorts of
algorithms are usually exponential in "n", here the number of
variables/dimensions.
Apparently, "L" is the number of input bits.

Your notation suggests your algorithm is dependent on the number input
bits only, and is otherwise constant in the number of
variables/dimensions.
So, we can solve an LP with hundreds of millions of variables,
near-instantaneously...?


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Jun 12 08:45:15 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 12 Jun 2020 08:45:15 +0200
Subject: [R] How to convert European short dates to ISO format?
In-Reply-To: <20200611144851.GB162277@posteo.no>
References: <CAMk+s2Sj4vQyQY0r1FKG9zL3y7vFSmUZVmHWXDP0G8hf6poeXg@mail.gmail.com>
 <20200611144851.GB162277@posteo.no>
Message-ID: <CAMk+s2R087CY8BZnuBCy1Y9PtxQVG90fvVue5txruft6p+byEA@mail.gmail.com>

Thank you. It worked. Case closed

On Thu, 11 Jun 2020, 16:48 Rasmus Liland, <jral at posteo.no> wrote:

> On 2020-06-10 10:20 +0200, Luigi Marongiu wrote:
> > I have been trying to convert European
> > short dates formatted as dd/mm/yy into the
> > ISO 8601 but the function as.Dates
> > interprets them as American ones
> > (mm/dd/yy)
>
> Dear Luigi,
>
> ?strptime says:
>
>         ?%D? Date format such as ?%m/%d/%y?: the C99 standard says it
>              should be that exact format (but not all OSes comply).
>
> as.Date(oriDates, format="%d/%m/%y") works
> fine for me here on the Linux laptop ...
>
> You could also try to work on the strings
> themselves to convert them to ISO format,
> like:
>
>         oriDates = c("23/01/20", "24/01/20", "25/01/20", "26/01/20",
>                      "27/01/20", "28/01/20", "29/01/20", "30/01/20",
>                      "31/01/20", "01/02/20", "02/02/20", "03/02/20",
>                      "04/02/20", "05/02/20", "06/02/20", "07/02/20")
>         d <- t(as.data.frame(strsplit(oriDates, "/")))
>         dimnames(d) <- list(NULL, c("d", "m", "y"))
>         u <- unique(d[,"y"])
>         millenia <- "20"
>         if (length(u)==1 & u==millenia) {
>           Dates <- paste0(millenia, d[,"y"], "-",
>                           d[,"m"], "-", d[,"d"])
>           Dates <- as.Date(Dates)
>         } else {
>           Dates <- "'Allo 'allo ... error, error ... more complicated
> formatting is required to digest those dates ..."
>         }
>         print(Dates)
>
> Best,
> Rasmus
>

	[[alternative HTML version deleted]]


From n@re@h_gurbux@n| @end|ng |rom hotm@||@com  Fri Jun 12 11:52:28 2020
From: n@re@h_gurbux@n| @end|ng |rom hotm@||@com (Naresh Gurbuxani)
Date: Fri, 12 Jun 2020 05:52:28 -0400
Subject: [R] function to return plots
Message-ID: <BL0PR01MB403602C8D0F73B69DCACC44FFA810@BL0PR01MB4036.prod.exchangelabs.com>


I want to write a function that will return lattice plots.  This simple
function output a list of two plots.  These plots can be
individually shown on the console.  But I am unable to put them on two
panels of a single plot.

What changes do I need to make to this function?

Thanks,
Naresh

library(lattice)

getPlots <- function(){
    x <- rnorm(1000)
    plt1 <- histogram(x)
    plt2 <- bwplot(x)
    list(plt1, plt2)
}

plot.list <- getPlots()

plot.list[1] #Plots graph
plot.list[2] #Plots graph

plot(plot.list[1], position = c(0, 0, 1, 0.5), more = TRUE) #Error message
plot(plot.list[2], position = c(0, 0.5, 1, 1), more = FALSE) #Error message

## Plotting outside function works
x <- rnorm(1000)
plt1 <- histogram(x)
plt2 <- bwplot(x)
plot(plt1, position = c(0, 0, 1, 0.5), more = TRUE)
plot(plt2, position = c(0, 0.5, 1, 1), more = FALSE)


From drj|m|emon @end|ng |rom gm@||@com  Fri Jun 12 12:50:41 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 12 Jun 2020 20:50:41 +1000
Subject: [R] function to return plots
In-Reply-To: <BL0PR01MB403602C8D0F73B69DCACC44FFA810@BL0PR01MB4036.prod.exchangelabs.com>
References: <BL0PR01MB403602C8D0F73B69DCACC44FFA810@BL0PR01MB4036.prod.exchangelabs.com>
Message-ID: <CA+8X3fUBcjxW9Pj=E9Wgi_kSKJ3Vqo1Xw-cd59TU94Haamiaaw@mail.gmail.com>

Hi Naresh,
The somewhat obscure syntax of lattice.

print(plot.list[[1]])
print(plot.list[[2]])

Jim

On Fri, Jun 12, 2020 at 7:53 PM Naresh Gurbuxani
<naresh_gurbuxani at hotmail.com> wrote:
>
>
> I want to write a function that will return lattice plots.  This simple
> function output a list of two plots.  These plots can be
> individually shown on the console.  But I am unable to put them on two
> panels of a single plot.
>
> What changes do I need to make to this function?
>
> Thanks,
> Naresh
>
> library(lattice)
>
> getPlots <- function(){
>     x <- rnorm(1000)
>     plt1 <- histogram(x)
>     plt2 <- bwplot(x)
>     list(plt1, plt2)
> }
>
> plot.list <- getPlots()
>
> plot.list[1] #Plots graph
> plot.list[2] #Plots graph
>
> plot(plot.list[1], position = c(0, 0, 1, 0.5), more = TRUE) #Error message
> plot(plot.list[2], position = c(0, 0.5, 1, 1), more = FALSE) #Error message
>
> ## Plotting outside function works
> x <- rnorm(1000)
> plt1 <- histogram(x)
> plt2 <- bwplot(x)
> plot(plt1, position = c(0, 0, 1, 0.5), more = TRUE)
> plot(plt2, position = c(0, 0.5, 1, 1), more = FALSE)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Jun 12 13:08:18 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 12 Jun 2020 12:08:18 +0100
Subject: [R] function to return plots
In-Reply-To: <BL0PR01MB403602C8D0F73B69DCACC44FFA810@BL0PR01MB4036.prod.exchangelabs.com>
References: <BL0PR01MB403602C8D0F73B69DCACC44FFA810@BL0PR01MB4036.prod.exchangelabs.com>
Message-ID: <2283fcb4-e247-f4cf-4f4e-f6ff2c700629@sapo.pt>

Hello,

plot.list is a list, try '[[' to access its members.
('[' returns sub-lists.)


plot(plot.list[[1]], position = c(0, 0, 1, 0.5), more = TRUE) #Works
plot(plot.list[[2]], position = c(0, 0.5, 1, 1), more = FALSE) #Works


Hope this helps,

Rui Barradas

?s 10:52 de 12/06/20, Naresh Gurbuxani escreveu:
> 
> I want to write a function that will return lattice plots.  This simple
> function output a list of two plots.  These plots can be
> individually shown on the console.  But I am unable to put them on two
> panels of a single plot.
> 
> What changes do I need to make to this function?
> 
> Thanks,
> Naresh
> 
> library(lattice)
> 
> getPlots <- function(){
>      x <- rnorm(1000)
>      plt1 <- histogram(x)
>      plt2 <- bwplot(x)
>      list(plt1, plt2)
> }
> 
> plot.list <- getPlots()
> 
> plot.list[1] #Plots graph
> plot.list[2] #Plots graph
> 
> plot(plot.list[1], position = c(0, 0, 1, 0.5), more = TRUE) #Error message
> plot(plot.list[2], position = c(0, 0.5, 1, 1), more = FALSE) #Error message
> 
> ## Plotting outside function works
> x <- rnorm(1000)
> plt1 <- histogram(x)
> plt2 <- bwplot(x)
> plot(plt1, position = c(0, 0, 1, 0.5), more = TRUE)
> plot(plt2, position = c(0, 0.5, 1, 1), more = FALSE)
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From n@re@h_gurbux@n| @end|ng |rom hotm@||@com  Fri Jun 12 14:37:08 2020
From: n@re@h_gurbux@n| @end|ng |rom hotm@||@com (Naresh Gurbuxani)
Date: Fri, 12 Jun 2020 12:37:08 +0000
Subject: [R] function to return plots
In-Reply-To: <2283fcb4-e247-f4cf-4f4e-f6ff2c700629@sapo.pt>
References: <BL0PR01MB403602C8D0F73B69DCACC44FFA810@BL0PR01MB4036.prod.exchangelabs.com>,
 <2283fcb4-e247-f4cf-4f4e-f6ff2c700629@sapo.pt>
Message-ID: <BL0PR01MB4036C3868E1E84C2BD210DF8FA810@BL0PR01MB4036.prod.exchangelabs.com>

Thanks for your quick response. ?It works as I wanted.?



From: Rui Barradas <ruipbarradas at sapo.pt>
Sent: Friday, June 12, 2020 7:08 AM
To: Naresh Gurbuxani <naresh_gurbuxani at hotmail.com>; r-help at r-project.org <r-help at R-project.org>
Subject: Re: [R] function to return plots 
?
Hello,

plot.list is a list, try '[[' to access its members.
('[' returns sub-lists.)


plot(plot.list[[1]], position = c(0, 0, 1, 0.5), more = TRUE) #Works
plot(plot.list[[2]], position = c(0, 0.5, 1, 1), more = FALSE) #Works


Hope this helps,

Rui Barradas

?s 10:52 de 12/06/20, Naresh Gurbuxani escreveu:
> 
> I want to write a function that will return lattice plots.? This simple
> function output a list of two plots.? These plots can be
> individually shown on the console.? But I am unable to put them on two
> panels of a single plot.
> 
> What changes do I need to make to this function?
> 
> Thanks,
> Naresh
> 
> library(lattice)
> 
> getPlots <- function(){
>????? x <- rnorm(1000)
>????? plt1 <- histogram(x)
>????? plt2 <- bwplot(x)
>????? list(plt1, plt2)
> }
> 
> plot.list <- getPlots()
> 
> plot.list[1] #Plots graph
> plot.list[2] #Plots graph
> 
> plot(plot.list[1], position = c(0, 0, 1, 0.5), more = TRUE) #Error message
> plot(plot.list[2], position = c(0, 0.5, 1, 1), more = FALSE) #Error message
> 
> ## Plotting outside function works
> x <- rnorm(1000)
> plt1 <- histogram(x)
> plt2 <- bwplot(x)
> plot(plt1, position = c(0, 0, 1, 0.5), more = TRUE)
> plot(plt2, position = c(0, 0.5, 1, 1), more = FALSE)
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

From @@ud|@@d|q @end|ng |rom gm@||@com  Fri Jun 12 16:18:05 2020
From: @@ud|@@d|q @end|ng |rom gm@||@com (Saudi Sadiq)
Date: Fri, 12 Jun 2020 16:18:05 +0200
Subject: [R] Help with a (g)lmer code
In-Reply-To: <CA+8X3fX60Afeq+y90gwQwabO31_=bk1VFR=-Osb8cpWN0Qmr9Q@mail.gmail.com>
References: <CAB_D3mrPo9JYv_i3RAonNxtZ6qneNtTMn_i2xFOQAGWHY1zPUg@mail.gmail.com>
 <CA+8X3fX60Afeq+y90gwQwabO31_=bk1VFR=-Osb8cpWN0Qmr9Q@mail.gmail.com>
Message-ID: <CAB_D3mqjGinHXO178OpZHr2_dEb+oOxTntYMc0p=57tVYu3L2g@mail.gmail.com>

Hi Jim,

So many thanks for your reply. I actually made a mistake in presenting the
problem; I should have clarified that the 1-10 linear scale questions went
as: 10 most humorous/closest to Egyptian culture and 1 the least. Also, I
should have attached some examples so the participant issue could be clear.
Here is attached the dataset (if there is no problem or I am not going
against the rules of the R-help group).

Actually, I wanted better to be the only dependent factor and asking
participants 'which subtitle is better?' could be enough, but I wanted to
have detailed information of why a subtitle is better by asking
participants specific questions (regarding which subtitle is more humorous
and closer to Egyptian culture). Most of the time, the total of the hum +
cul = better, but sometimes it is not (e.g. the sum for subtitle EA could
be bigger than for SA, but the participant prefers SA in the better
column).

The WF (*watched first*) is the mode via which participants watched the two
subtitles; some participants watched the SA subtitle first and other
watched the EA first.

Does this make sense?

All the best

On Thu, 11 Jun 2020 at 05:24, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Saudi,
> I can only make a guess, but that is that a variable having a unique
> value for each participant has been read in as a factor. I assume that
> "better" is some combination of "hum" and "cul" and exactly what is
> WF?
>
> Jim
>
> On Thu, Jun 11, 2020 at 5:27 AM Saudi Sadiq <saudisadiq at gmail.com> wrote:
> >
> > Dear Sir/Madam,
> >
> > Hope everyone is safe and sound. I appreciate your help a lot.
> >
> > I am evaluating two Arabic subtitles of a humorous English scene and
> asked
> > 263 participants (part) to evaluate the two subtitles (named Standard
> > Arabic, SA, and Egyptian Arabic, EA) via a questionnaire that asked them
> to
> > rank the two subtitles in terms of how much each subtitle is
> >
> > 2) more humorous (hum),
> >
> > 5) closer to Egyptian culture (cul)
> >
> >
> >
> > The questionnaire contained two 1-10 linear scale questions regarding
> the 2
> > points clarified, with 1 meaning the most humorous and closest to
> Egyptian
> > culture, and 1 meaning the least humorous and furthest from Egyptian
> > culture. Also, the questionnaire had a general multiple-choice question
> > regarding which subtitle is better in general (better). General
> information
> > about the participants were also collected concerning gender (categorical
> > factor), age (numeric factor) and education (categorical factor).
> >
> > Two versions of the questionnaire were relied on: one showing the ?SA
> > subtitle first? and another showing the ?EA subtitle first?. Nearly half
> > the participants answered the first and nearly half answered the latter.
> >
> > I am focusing on which social factor/s lead/s the participants to
> evaluate
> > one of the two subtitles as generally better and which subtitle is more
> > humorous and closer to Egyptian culture. Each of these points alone can
> be
> > the dependent factor, but the results altogether can be linked.
> >
> > I thought that mixed effects analyses would clarify the picture and
> answer
> > the research questions (which  factor/s lead/s participants to favour a
> > subtitle over another?) and, so,  tried the lme4 package in R and ran
> many
> > models but all the codes I have used are not working.
> >
> > I ran the following codes, which yielded Error messages, like:
> >
> > model1<- lmer (better ~ gender + age + education + WF + (1 | part),
> > data=sub_data)
> >
> > Error: number of levels of each grouping factor must be < number of
> > observations (problems: part)
> >
> >
> >
> > Model2 <- glmer (better ~ gender + age + education + WF + (1 | part),
> data
> > = sub_data, family='binomial')
> >
> > Error in mkRespMod(fr, family = family) :
> >
> >   response must be numeric or factor
> >
> >
> >
> > Model3 <- glmer (better ~ age + gender + education + WF + (1 | part),
> data
> > = sub_data, family='binomial',
> control=glmerControl(optimizer=c("bobyqa")))
> >
> > Error in mkRespMod(fr, family = family) :
> >
> >   response must be numeric or factor
> >
> >
> >
> > Why does the model crash? Does the problem lie in the random factor part
> (which
> > is a code for participants)? Or is it something related to the mixed
> > effects analysis?
> >
> > Best
> > Saudi Sadiq
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


-- 
Saudi Sadiq,

Lecturer, Minia University, Egypt

Academia <http://york.academia.edu/SaudiSadiq>, Reserachgate
<https://www.researchgate.net/profile/Saudi_Sadiq>, Google Scholar
<https://scholar.google.co.uk/citations?user=h0latzcAAAAJ&hl=en>, Publons
<https://publons.com/researcher/2950905/saudi-sadiq/>

Certified Translator by (Egyta) <https://www.egyta.com/>

Associate Fellow of the Higher Education Academy, UK
<https://www.heacademy.ac.uk/>

From bgunter@4567 @end|ng |rom gm@||@com  Fri Jun 12 16:28:17 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 12 Jun 2020 07:28:17 -0700
Subject: [R] Update of addScales package with vignette on CRAN
Message-ID: <CAGxFJbTNzDC6UZRNsbdp8deOohwKLAxtiBBs-=J3LHMToyFoTA@mail.gmail.com>

I have added a couple of what I would like to think are worthwhile features
to my addScales package. More important, also a short vignette. While this
is part of the lattice graphics ecosystem, have a look at the vignette as
it may have ideas that can be adapted/improved on in other graphics
paradigms (e.g. ggplot).

Apologies for the noise -- just trying to promote better data graphics.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Jun 12 16:30:44 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 12 Jun 2020 07:30:44 -0700
Subject: [R] Help with a (g)lmer code
In-Reply-To: <CAB_D3mqjGinHXO178OpZHr2_dEb+oOxTntYMc0p=57tVYu3L2g@mail.gmail.com>
References: <CAB_D3mrPo9JYv_i3RAonNxtZ6qneNtTMn_i2xFOQAGWHY1zPUg@mail.gmail.com>
 <CA+8X3fX60Afeq+y90gwQwabO31_=bk1VFR=-Osb8cpWN0Qmr9Q@mail.gmail.com>
 <CAB_D3mqjGinHXO178OpZHr2_dEb+oOxTntYMc0p=57tVYu3L2g@mail.gmail.com>
Message-ID: <CAGxFJbSsa35p6KY4eF7eWZ+6XE6y+JRFSmkTHMt9QfsmOhz7CQ@mail.gmail.com>

Questions on mixed models methodology, which this is, should be posted on
the r-sig-mixed-models list, not here.
That's where both the interest and expertise are.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 12, 2020 at 7:19 AM Saudi Sadiq <saudisadiq at gmail.com> wrote:

> Hi Jim,
>
> So many thanks for your reply. I actually made a mistake in presenting the
> problem; I should have clarified that the 1-10 linear scale questions went
> as: 10 most humorous/closest to Egyptian culture and 1 the least. Also, I
> should have attached some examples so the participant issue could be clear.
> Here is attached the dataset (if there is no problem or I am not going
> against the rules of the R-help group).
>
> Actually, I wanted better to be the only dependent factor and asking
> participants 'which subtitle is better?' could be enough, but I wanted to
> have detailed information of why a subtitle is better by asking
> participants specific questions (regarding which subtitle is more humorous
> and closer to Egyptian culture). Most of the time, the total of the hum +
> cul = better, but sometimes it is not (e.g. the sum for subtitle EA could
> be bigger than for SA, but the participant prefers SA in the better
> column).
>
> The WF (*watched first*) is the mode via which participants watched the two
> subtitles; some participants watched the SA subtitle first and other
> watched the EA first.
>
> Does this make sense?
>
> All the best
>
> On Thu, 11 Jun 2020 at 05:24, Jim Lemon <drjimlemon at gmail.com> wrote:
>
> > Hi Saudi,
> > I can only make a guess, but that is that a variable having a unique
> > value for each participant has been read in as a factor. I assume that
> > "better" is some combination of "hum" and "cul" and exactly what is
> > WF?
> >
> > Jim
> >
> > On Thu, Jun 11, 2020 at 5:27 AM Saudi Sadiq <saudisadiq at gmail.com>
> wrote:
> > >
> > > Dear Sir/Madam,
> > >
> > > Hope everyone is safe and sound. I appreciate your help a lot.
> > >
> > > I am evaluating two Arabic subtitles of a humorous English scene and
> > asked
> > > 263 participants (part) to evaluate the two subtitles (named Standard
> > > Arabic, SA, and Egyptian Arabic, EA) via a questionnaire that asked
> them
> > to
> > > rank the two subtitles in terms of how much each subtitle is
> > >
> > > 2) more humorous (hum),
> > >
> > > 5) closer to Egyptian culture (cul)
> > >
> > >
> > >
> > > The questionnaire contained two 1-10 linear scale questions regarding
> > the 2
> > > points clarified, with 1 meaning the most humorous and closest to
> > Egyptian
> > > culture, and 1 meaning the least humorous and furthest from Egyptian
> > > culture. Also, the questionnaire had a general multiple-choice question
> > > regarding which subtitle is better in general (better). General
> > information
> > > about the participants were also collected concerning gender
> (categorical
> > > factor), age (numeric factor) and education (categorical factor).
> > >
> > > Two versions of the questionnaire were relied on: one showing the ?SA
> > > subtitle first? and another showing the ?EA subtitle first?. Nearly
> half
> > > the participants answered the first and nearly half answered the
> latter.
> > >
> > > I am focusing on which social factor/s lead/s the participants to
> > evaluate
> > > one of the two subtitles as generally better and which subtitle is more
> > > humorous and closer to Egyptian culture. Each of these points alone can
> > be
> > > the dependent factor, but the results altogether can be linked.
> > >
> > > I thought that mixed effects analyses would clarify the picture and
> > answer
> > > the research questions (which  factor/s lead/s participants to favour a
> > > subtitle over another?) and, so,  tried the lme4 package in R and ran
> > many
> > > models but all the codes I have used are not working.
> > >
> > > I ran the following codes, which yielded Error messages, like:
> > >
> > > model1<- lmer (better ~ gender + age + education + WF + (1 | part),
> > > data=sub_data)
> > >
> > > Error: number of levels of each grouping factor must be < number of
> > > observations (problems: part)
> > >
> > >
> > >
> > > Model2 <- glmer (better ~ gender + age + education + WF + (1 | part),
> > data
> > > = sub_data, family='binomial')
> > >
> > > Error in mkRespMod(fr, family = family) :
> > >
> > >   response must be numeric or factor
> > >
> > >
> > >
> > > Model3 <- glmer (better ~ age + gender + education + WF + (1 | part),
> > data
> > > = sub_data, family='binomial',
> > control=glmerControl(optimizer=c("bobyqa")))
> > >
> > > Error in mkRespMod(fr, family = family) :
> > >
> > >   response must be numeric or factor
> > >
> > >
> > >
> > > Why does the model crash? Does the problem lie in the random factor
> part
> > (which
> > > is a code for participants)? Or is it something related to the mixed
> > > effects analysis?
> > >
> > > Best
> > > Saudi Sadiq
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
> --
> Saudi Sadiq,
>
> Lecturer, Minia University, Egypt
>
> Academia <http://york.academia.edu/SaudiSadiq>, Reserachgate
> <https://www.researchgate.net/profile/Saudi_Sadiq>, Google Scholar
> <https://scholar.google.co.uk/citations?user=h0latzcAAAAJ&hl=en>, Publons
> <https://publons.com/researcher/2950905/saudi-sadiq/>
>
> Certified Translator by (Egyta) <https://www.egyta.com/>
>
> Associate Fellow of the Higher Education Academy, UK
> <https://www.heacademy.ac.uk/>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Fri Jun 12 23:34:44 2020
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Fri, 12 Jun 2020 21:34:44 +0000
Subject: [R] Obtaining p values from t-test run with a by function
Message-ID: <MN2PR03MB5167961B19C3312A91104696E2810@MN2PR03MB5167.namprd03.prod.outlook.com>

Colleagues,
I am trying to retrieve the p values produced by a Student's t-test run using a by function, but can not do so. I can easily get the p value when I run s Student's t-test without a by function. What is the secret to obtaining results returned from a function run within a by function.

An annotated repeatable example (including data) can be found below.
Thank you,
John


# Test data
mydata <- structure(list(Group = structure(c(2L, 1L, 2L, 2L, 1L, 2L, 1L,
           2L, 2L, 1L, 2L, 1L, 2L), .Label = c("EPA", "P"), class = "factor"),
           WtBaseline = c(76.6, 73.8, 77.6, 91.7, 110.3, 121.7, 82.1,
           82.8, 119, 88.4, 75.7, 71.4, 72.1)), class = "data.frame", row.names = c(NA,-13L))

cat("This is what mydata looks like\n")
mydata

result <- by(mydata$WtBaseline,mydata$Group,t.test)
cat("Student's t-test run using by command\n")
cat("Result has results for both groups, EPA and P\n")
result

cat("I can isolate the collective results for group EPA\n")
result[1]
cat("I can isolate the collective results for group P\n")
result[2]

cat("I cant get the p-values for the gruops")
result[1]$p.value
result[2]$p.value

cat("When run without by function, one can get the p value\n")
xxx <- t.test(WtBaseline~Group,data=mydata)
cat("t-test run without by fundtion\n")
xxx
cat("p value isolated from t-test run without by function\n")
xxx$p.value


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)


	[[alternative HTML version deleted]]


From S@E|||@on @end|ng |rom LGCGroup@com  Sat Jun 13 00:10:28 2020
From: S@E|||@on @end|ng |rom LGCGroup@com (Stephen Ellison)
Date: Fri, 12 Jun 2020 22:10:28 +0000
Subject: [R] Obtaining p values from t-test run with a by function
In-Reply-To: <MN2PR03MB5167961B19C3312A91104696E2810@MN2PR03MB5167.namprd03.prod.outlook.com>
References: <MN2PR03MB5167961B19C3312A91104696E2810@MN2PR03MB5167.namprd03.prod.outlook.com>
Message-ID: <f76d5ac5a608499e8148336e9551d589@GBDCVPEXC08.corp.lgc-group.com>

Define a wrapper function for the t test that only returns the p-value?

by(mydata$WtBaseline,mydata$Group, function(...) t.test(...)$p.value)

S Ellison
________________________________________
From: R-help [r-help-bounces at r-project.org] on behalf of Sorkin, John [jsorkin at som.umaryland.edu]
Sent: 12 June 2020 22:34
To: r-help at r-project.org (r-help at r-project.org)
Subject: [R] Obtaining p values from t-test run with a by function

===============
 EXTERNAL EMAIL
===============

Colleagues,
I am trying to retrieve the p values produced by a Student's t-test run using a by function, but can not do so. I can easily get the p value when I run s Student's t-test without a by function. What is the secret to obtaining results returned from a function run within a by function.

An annotated repeatable example (including data) can be found below.
Thank you,
John


# Test data
mydata <- structure(list(Group = structure(c(2L, 1L, 2L, 2L, 1L, 2L, 1L,
           2L, 2L, 1L, 2L, 1L, 2L), .Label = c("EPA", "P"), class = "factor"),
           WtBaseline = c(76.6, 73.8, 77.6, 91.7, 110.3, 121.7, 82.1,
           82.8, 119, 88.4, 75.7, 71.4, 72.1)), class = "data.frame", row.names = c(NA,-13L))

cat("This is what mydata looks like\n")
mydata

result <- by(mydata$WtBaseline,mydata$Group,t.test)
cat("Student's t-test run using by command\n")
cat("Result has results for both groups, EPA and P\n")
result

cat("I can isolate the collective results for group EPA\n")
result[1]
cat("I can isolate the collective results for group P\n")
result[2]

cat("I cant get the p-values for the gruops")
result[1]$p.value
result[2]$p.value

cat("When run without by function, one can get the p value\n")
xxx <- t.test(WtBaseline~Group,data=mydata)
cat("t-test run without by fundtion\n")
xxx
cat("p value isolated from t-test run without by function\n")
xxx$p.value


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


==============================================================================================
WARNING - EXTERNAL: This email originated from outside of LGC. Do not click any links or open any attachments
unless you trust the sender and know that the content is safe
==============================================================================================


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From @@r@h@go@|ee @end|ng |rom gm@||@com  Sat Jun 13 00:20:04 2020
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Fri, 12 Jun 2020 18:20:04 -0400
Subject: [R] Obtaining p values from t-test run with a by function
In-Reply-To: <MN2PR03MB5167961B19C3312A91104696E2810@MN2PR03MB5167.namprd03.prod.outlook.com>
References: <MN2PR03MB5167961B19C3312A91104696E2810@MN2PR03MB5167.namprd03.prod.outlook.com>
Message-ID: <CAM_vju=mkUdwONAYgk=fK4Oy2XXs402rGzOnRojv7hi1xsNjFQ@mail.gmail.com>

Where you have

result[1]$p.value
result[2]$p.value

You need

result[[1]]$p.value
result[[2]]$p.value

to get the first component of the list.

Sarah

On Fri, Jun 12, 2020 at 5:35 PM Sorkin, John <jsorkin at som.umaryland.edu> wrote:
>
> Colleagues,
> I am trying to retrieve the p values produced by a Student's t-test run using a by function, but can not do so. I can easily get the p value when I run s Student's t-test without a by function. What is the secret to obtaining results returned from a function run within a by function.
>
> An annotated repeatable example (including data) can be found below.
> Thank you,
> John
>
>
> # Test data
> mydata <- structure(list(Group = structure(c(2L, 1L, 2L, 2L, 1L, 2L, 1L,
>            2L, 2L, 1L, 2L, 1L, 2L), .Label = c("EPA", "P"), class = "factor"),
>            WtBaseline = c(76.6, 73.8, 77.6, 91.7, 110.3, 121.7, 82.1,
>            82.8, 119, 88.4, 75.7, 71.4, 72.1)), class = "data.frame", row.names = c(NA,-13L))
>
> cat("This is what mydata looks like\n")
> mydata
>
> result <- by(mydata$WtBaseline,mydata$Group,t.test)
> cat("Student's t-test run using by command\n")
> cat("Result has results for both groups, EPA and P\n")
> result
>
> cat("I can isolate the collective results for group EPA\n")
> result[1]
> cat("I can isolate the collective results for group P\n")
> result[2]
>
> cat("I cant get the p-values for the gruops")
> result[1]$p.value
> result[2]$p.value
>
> cat("When run without by function, one can get the p value\n")
> xxx <- t.test(WtBaseline~Group,data=mydata)
> cat("t-test run without by fundtion\n")
> xxx
> cat("p value isolated from t-test run without by function\n")
> xxx$p.value
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From jr@| @end|ng |rom po@teo@no  Sat Jun 13 01:54:17 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Sat, 13 Jun 2020 01:54:17 +0200
Subject: [R] Creating one df from 85 df present in a list
In-Reply-To: <CAGxFJbSD8WMa6005P1DP-J6BGZbdkreJnePYFw6OfDdXp6jLjg@mail.gmail.com>
References: <CAASu+7OARc+AFuVGtHBp_q2TLVqnw57VdjN9WCpuMrwcjfOxpQ@mail.gmail.com>
 <CAGxFJbSD8WMa6005P1DP-J6BGZbdkreJnePYFw6OfDdXp6jLjg@mail.gmail.com>
Message-ID: <20200612235417.GB723678@posteo.no>

On 2020-06-10 13:14 -0700, Bert Gunter wrote:
> On Wed, Jun 10, 2020 at 11:48 AM Alejandro Ureta wrote:
> > 
> > hi, I am trying to fuse (cbind, merge... 
> > NOT rbind) several dataframes with 
> > different numbers of rows, all df 
> > included in a list, and using the code 
> > extract shown below. The function merge() 
> > works well with two df but not more than 
> > two...I have 85 dataframes to join in 
> > this way (85 df in the list)....could you 
> > please let me know how to get all 85 df 
> > merged ?,,,,, thanks
> >
> > fusion_de_tablas = merge(red_tablas_por_punto[["1 - Bv.Artigas y la Rambla
> > (Terminal CUTCSA)"]],
> > red_tablas_por_punto[["10 - Avenida Mill?n 2515 (Hospital Vilardeb?)"]],
> > red_tablas_por_punto[["100 - Fauquet 6358 (Hospital Saint Bois)"]],
> > by= 'toma_de_muestras', all = T )
> 
> ?do.call  -- takes a list of arguments to a function
> ... as in
> do.call(merge, yourlist)  ## or similar perhaps

Dear Alejandro,

it would be easier to help you if you 
provided some example of how fusion_de_tablas 
looks like.  

Here is a small example on uniting some odd 
sized dataframes with some common and some 
differently named columns. 

	red_tablas_por_punto <-
	  list(
	    "1 - Bv.Artigas y la Rambla (Terminal CUTCSA)" =
	      data.frame("a"=1:3,
	                 "b"=4:6,
	                 "c"=4:6,
	                 'toma_de_muestras'=1),
	    "10 - Avenida Mill?n 2515 (Hospital Vilardeb?)" =
	      data.frame("d"=4:8,
	                 "b"=8:12,
	                 'toma_de_muestras'=7),
	    "100 - Fauquet 6358 (Hospital Saint Bois)" =
	      data.frame("e"=100:101,
	                 "a"=85:86,
	                 'toma_de_muestras'=4)
	  )
	unified.df <- lapply(names(red_tablas_por_punto),
	  function(tabla, cn) {
	    x <- red_tablas_por_punto[[tabla]]
	    x[,cn[!(cn %in% colnames(x))]] <- NA
	    x <- x[,cn]
	    x$tabla <- tabla
	    return(x)
	  }, cn=unique(unlist(lapply(red_tablas_por_punto, colnames))))
	unified.df <- do.call(rbind, unified.df)
	unified.df

which yields

	    a  b  c toma_de_muestras  d   e                                         tabla
	1   1  4  4                1 NA  NA  1 - Bv.Artigas y la Rambla (Terminal CUTCSA)
	2   2  5  5                1 NA  NA  1 - Bv.Artigas y la Rambla (Terminal CUTCSA)
	3   3  6  6                1 NA  NA  1 - Bv.Artigas y la Rambla (Terminal CUTCSA)
	4  NA  8 NA                7  4  NA 10 - Avenida Mill?n 2515 (Hospital Vilardeb?)
	5  NA  9 NA                7  5  NA 10 - Avenida Mill?n 2515 (Hospital Vilardeb?)
	6  NA 10 NA                7  6  NA 10 - Avenida Mill?n 2515 (Hospital Vilardeb?)
	7  NA 11 NA                7  7  NA 10 - Avenida Mill?n 2515 (Hospital Vilardeb?)
	8  NA 12 NA                7  8  NA 10 - Avenida Mill?n 2515 (Hospital Vilardeb?)
	9  85 NA NA                4 NA 100      100 - Fauquet 6358 (Hospital Saint Bois)
	10 86 NA NA                4 NA 101      100 - Fauquet 6358 (Hospital Saint Bois)

I also found that [1] you could use merge 
like you tried with Reduce, like 

	Reduce(function(x, y)
	  merge(x, y, by='toma_de_muestras', all=T),
	  red_tablas_por_punto)

which yields

	   toma_de_muestras a.x b.x  c  d b.y   e a.y
	1             10001   1   4  4 NA  NA  NA  NA
	2             10002   2   5  5 NA  NA  NA  NA
	3             10003   3   6  6 NA  NA  NA  NA
	4             10004  NA  NA NA  4   8  NA  NA
	5             10005  NA  NA NA  5   9  NA  NA
	6             10006  NA  NA NA  6  10  NA  NA
	7             10007  NA  NA NA  7  11  NA  NA
	8             10008  NA  NA NA  8  12  NA  NA
	9             10009  NA  NA NA NA  NA 100  85
	10            10010  NA  NA NA NA  NA 101  86

where the semi-common ?a? column does not 
become unified ...  thus, I like my initial 
step-by-step apply-based solution better ... 

Best,
Rasmus

[1] https://stackoverflow.com/questions/22644780/merging-multiple-csv-files-in-r-using-do-call

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200613/f877bdec/attachment.sig>

From jr@| @end|ng |rom po@teo@no  Sat Jun 13 02:25:08 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Sat, 13 Jun 2020 02:25:08 +0200
Subject: [R] Creating one df from 85 df present in a list
In-Reply-To: <20200612235417.GB723678@posteo.no>
References: <CAASu+7OARc+AFuVGtHBp_q2TLVqnw57VdjN9WCpuMrwcjfOxpQ@mail.gmail.com>
 <CAGxFJbSD8WMa6005P1DP-J6BGZbdkreJnePYFw6OfDdXp6jLjg@mail.gmail.com>
 <20200612235417.GB723678@posteo.no>
Message-ID: <20200613002508.GC723678@posteo.no>

On 2020-06-13 01:54 +0200, Rasmus Liland wrote:
> Dear Alejandro,

Sorry, I programmed and wrote that email at 
the same time, changed the ?toma_de_muestras? 
perhaps other things, then continued 
programming, thus this might make more 
sense ...

Firstly, it would be easier to help you if 
you provided some example of how 
fusion_de_tablas looks like.

In this first example, I create a small list 
of oddly shaped data.frames which might look 
like your 85-element-long list.  Then, 
determining the unique colnames.  Lastly, 
applying my way through the list again to 
fill in N/A in the columns not there, so the 
do.call function recieves what it expects ... 

	red_tablas_por_punto <-
	  list(
	    "1 - Bv.Artigas y la Rambla (Terminal CUTCSA)" =
	      data.frame("a"=1:3,
	                 "b"=4:6,
	                 "c"=4:6,
	                 'toma_de_muestras'=10001:10003),
	    "10 - Avenida Mill?n 2515 (Hospital Vilardeb?)" =
	      data.frame("d"=4:8,
	                 "b"=8:12,
	                 'toma_de_muestras'=10004:10008),
	    "100 - Fauquet 6358 (Hospital Saint Bois)" =
	      data.frame("e"=100:101,
	                 "a"=85:86,
	                 'toma_de_muestras'=10009:10010)
	  )
	unified.df <- lapply(names(red_tablas_por_punto),
	  function(tabla, cn) {
	    x <- red_tablas_por_punto[[tabla]]
	    x[,cn[!(cn %in% colnames(x))]] <- NA
	    x <- x[,cn]
	    x$tabla <- tabla
	    return(x)
	  }, cn=unique(unlist(lapply(red_tablas_por_punto, colnames))))
	unified.df <- do.call(rbind, unified.df)
	unified.df

yields this:

	    a  b  c toma_de_muestras  d   e                                         tabla
	1   1  4  4            10001 NA  NA  1 - Bv.Artigas y la Rambla (Terminal CUTCSA)
	2   2  5  5            10002 NA  NA  1 - Bv.Artigas y la Rambla (Terminal CUTCSA)
	3   3  6  6            10003 NA  NA  1 - Bv.Artigas y la Rambla (Terminal CUTCSA)
	4  NA  8 NA            10004  4  NA 10 - Avenida Mill?n 2515 (Hospital Vilardeb?)
	5  NA  9 NA            10005  5  NA 10 - Avenida Mill?n 2515 (Hospital Vilardeb?)
	6  NA 10 NA            10006  6  NA 10 - Avenida Mill?n 2515 (Hospital Vilardeb?)
	7  NA 11 NA            10007  7  NA 10 - Avenida Mill?n 2515 (Hospital Vilardeb?)
	8  NA 12 NA            10008  8  NA 10 - Avenida Mill?n 2515 (Hospital Vilardeb?)
	9  85 NA NA            10009 NA 100      100 - Fauquet 6358 (Hospital Saint Bois)
	10 86 NA NA            10010 NA 101      100 - Fauquet 6358 (Hospital Saint Bois)

... right, so you could also use merge with 
Reduce like in that stackoverflow answer [1], 
which might have been what you were looking 
for anyway:

	Reduce(function(x, y)
	  merge(x, y, by='toma_de_muestras', all=T),
	  red_tablas_por_punto)

yields this:

	   toma_de_muestras a.x b.x  c  d b.y   e a.y
	1             10001   1   4  4 NA  NA  NA  NA
	2             10002   2   5  5 NA  NA  NA  NA
	3             10003   3   6  6 NA  NA  NA  NA
	4             10004  NA  NA NA  4   8  NA  NA
	5             10005  NA  NA NA  5   9  NA  NA
	6             10006  NA  NA NA  6  10  NA  NA
	7             10007  NA  NA NA  7  11  NA  NA
	8             10008  NA  NA NA  8  12  NA  NA
	9             10009  NA  NA NA NA  NA 100  85
	10            10010  NA  NA NA NA  NA 101  86

Best,
Rasmus

[1] https://stackoverflow.com/questions/22644780/merging-multiple-csv-files-in-r-using-do-call

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200613/4defe719/attachment.sig>

From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Jun 13 02:46:02 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 12 Jun 2020 19:46:02 -0500
Subject: [R] if else statement adjustemtn
Message-ID: <CAF9-5jMVc9jhfj-x2NW96=MoQ_0zyRDoupJTD28M_aEkOvM-ag@mail.gmail.com>

Hello

I have a data frame like this:

> head(b)
       FID   IID FLASER PLASER
1: fam1000 G1000      1      1
2: fam1001 G1001      1      1
3: fam1003 G1003      1      2
4: fam1005 G1005      1      1
5: fam1009 G1009      1      1
6: fam1052 G1052      1      1
...

> table(b$PLASER,b$FLASER, exclude = NULL)

         1   2   3 <NA>
  1    836  14   0    0
  2    691  70  43    2
  3      2   7  21    0
  <NA>   4   1   0    7

I am trying to make a new column "pheno" so that I reduce the number of NAs

right now I am doing:

> b$pheno=ifelse(b$PLASER==2 | b$FLASER==2,2,1)
> table(b$pheno, exclude = NULL)

   1    2 <NA>
 859  828   11

I would like to reduce this number of NAs to be 7
so I would like to have in "pheno column"
7 NAs
825 2s (825=691+14+70+7+43)
and the rest would be 1s (866=1698-7-825)

How can I change the above command to get these numbers?

Thanks
Ana


From drj|m|emon @end|ng |rom gm@||@com  Sat Jun 13 03:06:45 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 13 Jun 2020 11:06:45 +1000
Subject: [R] if else statement adjustemtn
In-Reply-To: <CAF9-5jMVc9jhfj-x2NW96=MoQ_0zyRDoupJTD28M_aEkOvM-ag@mail.gmail.com>
References: <CAF9-5jMVc9jhfj-x2NW96=MoQ_0zyRDoupJTD28M_aEkOvM-ag@mail.gmail.com>
Message-ID: <CA+8X3fVQDKyL4jA+E1MPQP=x3aTe9zzm-me9WNWEFZCKUQtgQA@mail.gmail.com>

Hi Ana,
>From your desired result, it looks like those two NA values in PLASER
are the ones you want to drop.
If so, try this:

b$pheno<-ifelse(b$PLASER==2 | b$FLASER==2 |
 is.na(b$PLASER) & b$FLASER == 2,2,1)

and if I have it the wrong way round, swap FLASER and PLASER in the
bit I have added.

Jim

On Sat, Jun 13, 2020 at 10:46 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello
>
> I have a data frame like this:
>
> > head(b)
>        FID   IID FLASER PLASER
> 1: fam1000 G1000      1      1
> 2: fam1001 G1001      1      1
> 3: fam1003 G1003      1      2
> 4: fam1005 G1005      1      1
> 5: fam1009 G1009      1      1
> 6: fam1052 G1052      1      1
> ...
>
> > table(b$PLASER,b$FLASER, exclude = NULL)
>
>          1   2   3 <NA>
>   1    836  14   0    0
>   2    691  70  43    2
>   3      2   7  21    0
>   <NA>   4   1   0    7
>
> I am trying to make a new column "pheno" so that I reduce the number of NAs
>
> right now I am doing:
>
> > b$pheno=ifelse(b$PLASER==2 | b$FLASER==2,2,1)
> > table(b$pheno, exclude = NULL)
>
>    1    2 <NA>
>  859  828   11
>
> I would like to reduce this number of NAs to be 7
> so I would like to have in "pheno column"
> 7 NAs
> 825 2s (825=691+14+70+7+43)
> and the rest would be 1s (866=1698-7-825)
>
> How can I change the above command to get these numbers?
>
> Thanks
> Ana
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Jun 13 03:16:03 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 12 Jun 2020 20:16:03 -0500
Subject: [R] if else statement adjustemtn
In-Reply-To: <CA+8X3fVQDKyL4jA+E1MPQP=x3aTe9zzm-me9WNWEFZCKUQtgQA@mail.gmail.com>
References: <CAF9-5jMVc9jhfj-x2NW96=MoQ_0zyRDoupJTD28M_aEkOvM-ag@mail.gmail.com>
 <CA+8X3fVQDKyL4jA+E1MPQP=x3aTe9zzm-me9WNWEFZCKUQtgQA@mail.gmail.com>
Message-ID: <CAF9-5jNeKhEaDBdsVrAzdekfiaU0jwcCwCy-D4pHe7-JN4sw+g@mail.gmail.com>

Hi Jim,

I tried it:
> b$pheno<-ifelse(b$PLASER==2 | b$FLASER==2 |is.na(b$PLASER) & b$FLASER == 2,2,1)
> table(b$pheno,exclude = NULL)

   1    2 <NA>
 859  828   11
> b$pheno<-ifelse(b$PLASER==2 | b$FLASER==2 |is.na(b$FLASER) & b$PLASER == 2,2,1)
> table(b$pheno,exclude = NULL)

   1    2 <NA>
 859  828   11

Am I am doing something wrong?

Thanks
Ana

On Fri, Jun 12, 2020 at 8:06 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Ana,
> From your desired result, it looks like those two NA values in PLASER
> are the ones you want to drop.
> If so, try this:
>
> b$pheno<-ifelse(b$PLASER==2 | b$FLASER==2 |
>  is.na(b$PLASER) & b$FLASER == 2,2,1)
>
> and if I have it the wrong way round, swap FLASER and PLASER in the
> bit I have added.
>
> Jim
>
> On Sat, Jun 13, 2020 at 10:46 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hello
> >
> > I have a data frame like this:
> >
> > > head(b)
> >        FID   IID FLASER PLASER
> > 1: fam1000 G1000      1      1
> > 2: fam1001 G1001      1      1
> > 3: fam1003 G1003      1      2
> > 4: fam1005 G1005      1      1
> > 5: fam1009 G1009      1      1
> > 6: fam1052 G1052      1      1
> > ...
> >
> > > table(b$PLASER,b$FLASER, exclude = NULL)
> >
> >          1   2   3 <NA>
> >   1    836  14   0    0
> >   2    691  70  43    2
> >   3      2   7  21    0
> >   <NA>   4   1   0    7
> >
> > I am trying to make a new column "pheno" so that I reduce the number of NAs
> >
> > right now I am doing:
> >
> > > b$pheno=ifelse(b$PLASER==2 | b$FLASER==2,2,1)
> > > table(b$pheno, exclude = NULL)
> >
> >    1    2 <NA>
> >  859  828   11
> >
> > I would like to reduce this number of NAs to be 7
> > so I would like to have in "pheno column"
> > 7 NAs
> > 825 2s (825=691+14+70+7+43)
> > and the rest would be 1s (866=1698-7-825)
> >
> > How can I change the above command to get these numbers?
> >
> > Thanks
> > Ana
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Sat Jun 13 03:30:45 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 13 Jun 2020 11:30:45 +1000
Subject: [R] if else statement adjustemtn
In-Reply-To: <CAF9-5jNeKhEaDBdsVrAzdekfiaU0jwcCwCy-D4pHe7-JN4sw+g@mail.gmail.com>
References: <CAF9-5jMVc9jhfj-x2NW96=MoQ_0zyRDoupJTD28M_aEkOvM-ag@mail.gmail.com>
 <CA+8X3fVQDKyL4jA+E1MPQP=x3aTe9zzm-me9WNWEFZCKUQtgQA@mail.gmail.com>
 <CAF9-5jNeKhEaDBdsVrAzdekfiaU0jwcCwCy-D4pHe7-JN4sw+g@mail.gmail.com>
Message-ID: <CA+8X3fXDJUv=mPu6SMSg_O=ra-4QgT+JBjdPsS0CqDUai2fgSg@mail.gmail.com>

Obviously my guess was wrong. I thought you wanted to impute the value
of "pheno" from FLASER if PLASER was missing. From just your summary
table, it's hard to guess the distribution of NA values. My guess that
the two undesirable NAs were cases where PLASER was missing and FLASER
was 2. My tactic at this point would be to look at the cases where
either FLASER or PLASER was missing and work out the logic to impute
the two that are giving you trouble.

Jim

On Sat, Jun 13, 2020 at 11:16 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hi Jim,
>
> I tried it:
> > b$pheno<-ifelse(b$PLASER==2 | b$FLASER==2 |is.na(b$PLASER) & b$FLASER == 2,2,1)
> > table(b$pheno,exclude = NULL)
>
>    1    2 <NA>
>  859  828   11
> > b$pheno<-ifelse(b$PLASER==2 | b$FLASER==2 |is.na(b$FLASER) & b$PLASER == 2,2,1)
> > table(b$pheno,exclude = NULL)
>
>    1    2 <NA>
>  859  828   11
>
> Am I am doing something wrong?
>
> Thanks
> Ana
>
> On Fri, Jun 12, 2020 at 8:06 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Hi Ana,
> > From your desired result, it looks like those two NA values in PLASER
> > are the ones you want to drop.
> > If so, try this:
> >
> > b$pheno<-ifelse(b$PLASER==2 | b$FLASER==2 |
> >  is.na(b$PLASER) & b$FLASER == 2,2,1)
> >
> > and if I have it the wrong way round, swap FLASER and PLASER in the
> > bit I have added.
> >
> > Jim
> >
> > On Sat, Jun 13, 2020 at 10:46 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> > >
> > > Hello
> > >
> > > I have a data frame like this:
> > >
> > > > head(b)
> > >        FID   IID FLASER PLASER
> > > 1: fam1000 G1000      1      1
> > > 2: fam1001 G1001      1      1
> > > 3: fam1003 G1003      1      2
> > > 4: fam1005 G1005      1      1
> > > 5: fam1009 G1009      1      1
> > > 6: fam1052 G1052      1      1
> > > ...
> > >
> > > > table(b$PLASER,b$FLASER, exclude = NULL)
> > >
> > >          1   2   3 <NA>
> > >   1    836  14   0    0
> > >   2    691  70  43    2
> > >   3      2   7  21    0
> > >   <NA>   4   1   0    7
> > >
> > > I am trying to make a new column "pheno" so that I reduce the number of NAs
> > >
> > > right now I am doing:
> > >
> > > > b$pheno=ifelse(b$PLASER==2 | b$FLASER==2,2,1)
> > > > table(b$pheno, exclude = NULL)
> > >
> > >    1    2 <NA>
> > >  859  828   11
> > >
> > > I would like to reduce this number of NAs to be 7
> > > so I would like to have in "pheno column"
> > > 7 NAs
> > > 825 2s (825=691+14+70+7+43)
> > > and the rest would be 1s (866=1698-7-825)
> > >
> > > How can I change the above command to get these numbers?
> > >
> > > Thanks
> > > Ana
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.


From jr@| @end|ng |rom po@teo@no  Sat Jun 13 04:28:37 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Sat, 13 Jun 2020 04:28:37 +0200
Subject: [R] if else statement adjustemtn
In-Reply-To: <CA+8X3fXDJUv=mPu6SMSg_O=ra-4QgT+JBjdPsS0CqDUai2fgSg@mail.gmail.com>
References: <CAF9-5jMVc9jhfj-x2NW96=MoQ_0zyRDoupJTD28M_aEkOvM-ag@mail.gmail.com>
 <CA+8X3fVQDKyL4jA+E1MPQP=x3aTe9zzm-me9WNWEFZCKUQtgQA@mail.gmail.com>
 <CAF9-5jNeKhEaDBdsVrAzdekfiaU0jwcCwCy-D4pHe7-JN4sw+g@mail.gmail.com>
 <CA+8X3fXDJUv=mPu6SMSg_O=ra-4QgT+JBjdPsS0CqDUai2fgSg@mail.gmail.com>
Message-ID: <20200613022837.GD723678@posteo.no>

On 2020-06-13 11:30 +1000, Jim Lemon wrote:
> On Fri, Jun 12, 2020 at 8:06 PM Jim Lemon wrote:
> > On Sat, Jun 13, 2020 at 10:46 AM Ana Marija wrote:
> > >
> > > I am trying to make a new column 
> > > "pheno" so that I reduce the number 
> > > of NAs
> >
> > it looks like those two NA values in 
> > PLASER are the ones you want to drop.
> 
> From just your summary table, it's hard to 
> guess the distribution of NA values.

Dear Ana,

This small sample

	b <- read.table(text="FLASER;PLASER
	1;2
	;2
	;
	1;
	2;
	2;2
	3;2
	3;3
	1;1", sep=";", header=TRUE)
	
	table(b$PLASER,b$FLASER, exclude = NULL)

yields the same combinations you showed 
earlier:

	       1 2 3 <NA>
	  1    1 0 0    0
	  2    1 1 1    1
	  3    0 0 1    0
	  <NA> 1 1 0    1

If you want to eliminate the four <NA>-based 
combinations completely, this line

	b$pheno <-
	  ifelse(b$PLASER==2 |
	         b$FLASER==2 |
	         is.na(b$PLASER) |
	         is.na(b$PLASER) & b$FLASER %in% 1:2 |
	         is.na(b$FLASER) & b$PLASER == 2,
	         2, 1)
	table(b$pheno, exclude = NULL)

will do it:

	1 2
	2 7

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200613/40a643bb/attachment.sig>

From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Jun 13 04:50:04 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 12 Jun 2020 21:50:04 -0500
Subject: [R] if else statement adjustemtn
In-Reply-To: <20200613022837.GD723678@posteo.no>
References: <CAF9-5jMVc9jhfj-x2NW96=MoQ_0zyRDoupJTD28M_aEkOvM-ag@mail.gmail.com>
 <CA+8X3fVQDKyL4jA+E1MPQP=x3aTe9zzm-me9WNWEFZCKUQtgQA@mail.gmail.com>
 <CAF9-5jNeKhEaDBdsVrAzdekfiaU0jwcCwCy-D4pHe7-JN4sw+g@mail.gmail.com>
 <CA+8X3fXDJUv=mPu6SMSg_O=ra-4QgT+JBjdPsS0CqDUai2fgSg@mail.gmail.com>
 <20200613022837.GD723678@posteo.no>
Message-ID: <CAF9-5jO+Q6Q6-WuvjmUWH6-gTL_cZXwugteZiEr-CZWwnfd-hw@mail.gmail.com>

Hi Rasmus,

thank you for getting back to be, the command your provided seems to
add all 11 NAs to 2s
> b$pheno <-
+           ifelse(b$PLASER==2 |
+                  b$FLASER==2 |
+                  is.na(b$PLASER) |
+                  is.na(b$PLASER) & b$FLASER %in% 1:2 |
+                  is.na(b$FLASER) & b$PLASER == 2,
+                  2, 1)
>         table(b$pheno, exclude = NULL)

  1   2
859 839

Once again my desired results is to keep these 7 NAs as NAs
> table(b$PLASER,b$FLASER, exclude = NULL)

         1   2   3 <NA>
  1    836  14   0    0
  2    691  70  43    2
  3      2   7  21    0
  <NA>   4   1   0    7

and have
825 2s (825=691+14+70+7+43)
and the rest would be 1s (866=1698-7-825)

On Fri, Jun 12, 2020 at 9:29 PM Rasmus Liland <jral at posteo.no> wrote:
>
> On 2020-06-13 11:30 +1000, Jim Lemon wrote:
> > On Fri, Jun 12, 2020 at 8:06 PM Jim Lemon wrote:
> > > On Sat, Jun 13, 2020 at 10:46 AM Ana Marija wrote:
> > > >
> > > > I am trying to make a new column
> > > > "pheno" so that I reduce the number
> > > > of NAs
> > >
> > > it looks like those two NA values in
> > > PLASER are the ones you want to drop.
> >
> > From just your summary table, it's hard to
> > guess the distribution of NA values.
>
> Dear Ana,
>
> This small sample
>
>         b <- read.table(text="FLASER;PLASER
>         1;2
>         ;2
>         ;
>         1;
>         2;
>         2;2
>         3;2
>         3;3
>         1;1", sep=";", header=TRUE)
>
>         table(b$PLASER,b$FLASER, exclude = NULL)
>
> yields the same combinations you showed
> earlier:
>
>                1 2 3 <NA>
>           1    1 0 0    0
>           2    1 1 1    1
>           3    0 0 1    0
>           <NA> 1 1 0    1
>
> If you want to eliminate the four <NA>-based
> combinations completely, this line
>
>         b$pheno <-
>           ifelse(b$PLASER==2 |
>                  b$FLASER==2 |
>                  is.na(b$PLASER) |
>                  is.na(b$PLASER) & b$FLASER %in% 1:2 |
>                  is.na(b$FLASER) & b$PLASER == 2,
>                  2, 1)
>         table(b$pheno, exclude = NULL)
>
> will do it:
>
>         1 2
>         2 7
>
> Best,
> Rasmus
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Sat Jun 13 05:29:17 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 13 Jun 2020 13:29:17 +1000
Subject: [R] if else statement adjustemtn
In-Reply-To: <CAF9-5jO+Q6Q6-WuvjmUWH6-gTL_cZXwugteZiEr-CZWwnfd-hw@mail.gmail.com>
References: <CAF9-5jMVc9jhfj-x2NW96=MoQ_0zyRDoupJTD28M_aEkOvM-ag@mail.gmail.com>
 <CA+8X3fVQDKyL4jA+E1MPQP=x3aTe9zzm-me9WNWEFZCKUQtgQA@mail.gmail.com>
 <CAF9-5jNeKhEaDBdsVrAzdekfiaU0jwcCwCy-D4pHe7-JN4sw+g@mail.gmail.com>
 <CA+8X3fXDJUv=mPu6SMSg_O=ra-4QgT+JBjdPsS0CqDUai2fgSg@mail.gmail.com>
 <20200613022837.GD723678@posteo.no>
 <CAF9-5jO+Q6Q6-WuvjmUWH6-gTL_cZXwugteZiEr-CZWwnfd-hw@mail.gmail.com>
Message-ID: <CA+8X3fX+iErrBMM+cr2Rypo7n3dN6PSJW6Lwc7XmpREDHa3VMQ@mail.gmail.com>

Since you have only a few troublesome NA values, if you look at them,
or even better, post them:

b[is.na(b$FLASER) | is.na(b$PLASER),]

perhaps we can work out the appropriate logic to get rid of only the
ones you don't want.

Jim

On Sat, Jun 13, 2020 at 12:50 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hi Rasmus,
>
> thank you for getting back to be, the command your provided seems to
> add all 11 NAs to 2s
> > b$pheno <-
> +           ifelse(b$PLASER==2 |
> +                  b$FLASER==2 |
> +                  is.na(b$PLASER) |
> +                  is.na(b$PLASER) & b$FLASER %in% 1:2 |
> +                  is.na(b$FLASER) & b$PLASER == 2,
> +                  2, 1)
> >         table(b$pheno, exclude = NULL)
>
>   1   2
> 859 839
>
> Once again my desired results is to keep these 7 NAs as NAs
> > table(b$PLASER,b$FLASER, exclude = NULL)
>
>          1   2   3 <NA>
>   1    836  14   0    0
>   2    691  70  43    2
>   3      2   7  21    0
>   <NA>   4   1   0    7
>
> and have
> 825 2s (825=691+14+70+7+43)
> and the rest would be 1s (866=1698-7-825)
>
> On Fri, Jun 12, 2020 at 9:29 PM Rasmus Liland <jral at posteo.no> wrote:
> >
> > On 2020-06-13 11:30 +1000, Jim Lemon wrote:
> > > On Fri, Jun 12, 2020 at 8:06 PM Jim Lemon wrote:
> > > > On Sat, Jun 13, 2020 at 10:46 AM Ana Marija wrote:
> > > > >
> > > > > I am trying to make a new column
> > > > > "pheno" so that I reduce the number
> > > > > of NAs
> > > >
> > > > it looks like those two NA values in
> > > > PLASER are the ones you want to drop.
> > >
> > > From just your summary table, it's hard to
> > > guess the distribution of NA values.
> >
> > Dear Ana,
> >
> > This small sample
> >
> >         b <- read.table(text="FLASER;PLASER
> >         1;2
> >         ;2
> >         ;
> >         1;
> >         2;
> >         2;2
> >         3;2
> >         3;3
> >         1;1", sep=";", header=TRUE)
> >
> >         table(b$PLASER,b$FLASER, exclude = NULL)
> >
> > yields the same combinations you showed
> > earlier:
> >
> >                1 2 3 <NA>
> >           1    1 0 0    0
> >           2    1 1 1    1
> >           3    0 0 1    0
> >           <NA> 1 1 0    1
> >
> > If you want to eliminate the four <NA>-based
> > combinations completely, this line
> >
> >         b$pheno <-
> >           ifelse(b$PLASER==2 |
> >                  b$FLASER==2 |
> >                  is.na(b$PLASER) |
> >                  is.na(b$PLASER) & b$FLASER %in% 1:2 |
> >                  is.na(b$FLASER) & b$PLASER == 2,
> >                  2, 1)
> >         table(b$pheno, exclude = NULL)
> >
> > will do it:
> >
> >         1 2
> >         2 7
> >
> > Best,
> > Rasmus
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Jun 13 05:59:13 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 12 Jun 2020 22:59:13 -0500
Subject: [R] if else statement adjustemtn
In-Reply-To: <CA+8X3fX+iErrBMM+cr2Rypo7n3dN6PSJW6Lwc7XmpREDHa3VMQ@mail.gmail.com>
References: <CAF9-5jMVc9jhfj-x2NW96=MoQ_0zyRDoupJTD28M_aEkOvM-ag@mail.gmail.com>
 <CA+8X3fVQDKyL4jA+E1MPQP=x3aTe9zzm-me9WNWEFZCKUQtgQA@mail.gmail.com>
 <CAF9-5jNeKhEaDBdsVrAzdekfiaU0jwcCwCy-D4pHe7-JN4sw+g@mail.gmail.com>
 <CA+8X3fXDJUv=mPu6SMSg_O=ra-4QgT+JBjdPsS0CqDUai2fgSg@mail.gmail.com>
 <20200613022837.GD723678@posteo.no>
 <CAF9-5jO+Q6Q6-WuvjmUWH6-gTL_cZXwugteZiEr-CZWwnfd-hw@mail.gmail.com>
 <CA+8X3fX+iErrBMM+cr2Rypo7n3dN6PSJW6Lwc7XmpREDHa3VMQ@mail.gmail.com>
Message-ID: <CAF9-5jPxnKNYuivUhgq6Pq408BEOYHjrVfrQ_YDTQJF5mcB_CA@mail.gmail.com>

Great idea!
Here it is:
> b[is.na(b$FLASER) | is.na(b$PLASER),]
        FID   IID FLASER PLASER pheno
 1: fam1837 G1837      1     NA     2
 2: fam2410 G2410     NA     NA     2
 3: fam2838 G2838     NA      2     2
 4: fam3367 G3367      1     NA     2
 5: fam3410 G3410      1     NA     2
 6: fam3492 G3492      1     NA     2
 7: fam3834 G3834      2     NA     2
 8: fam4708 G4708     NA      2     2
 9: fam5162 G5162     NA     NA     2
10: fam5274 G5274     NA     NA     2
11: fam0637  G637     NA     NA     2
12: fam0640  G640     NA     NA     2
13: fam0743  G743     NA     NA     2
14: fam0911  G911     NA     NA     2

On Fri, Jun 12, 2020 at 10:29 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Since you have only a few troublesome NA values, if you look at them,
> or even better, post them:
>
> b[is.na(b$FLASER) | is.na(b$PLASER),]
>
> perhaps we can work out the appropriate logic to get rid of only the
> ones you don't want.
>
> Jim
>
> On Sat, Jun 13, 2020 at 12:50 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hi Rasmus,
> >
> > thank you for getting back to be, the command your provided seems to
> > add all 11 NAs to 2s
> > > b$pheno <-
> > +           ifelse(b$PLASER==2 |
> > +                  b$FLASER==2 |
> > +                  is.na(b$PLASER) |
> > +                  is.na(b$PLASER) & b$FLASER %in% 1:2 |
> > +                  is.na(b$FLASER) & b$PLASER == 2,
> > +                  2, 1)
> > >         table(b$pheno, exclude = NULL)
> >
> >   1   2
> > 859 839
> >
> > Once again my desired results is to keep these 7 NAs as NAs
> > > table(b$PLASER,b$FLASER, exclude = NULL)
> >
> >          1   2   3 <NA>
> >   1    836  14   0    0
> >   2    691  70  43    2
> >   3      2   7  21    0
> >   <NA>   4   1   0    7
> >
> > and have
> > 825 2s (825=691+14+70+7+43)
> > and the rest would be 1s (866=1698-7-825)
> >
> > On Fri, Jun 12, 2020 at 9:29 PM Rasmus Liland <jral at posteo.no> wrote:
> > >
> > > On 2020-06-13 11:30 +1000, Jim Lemon wrote:
> > > > On Fri, Jun 12, 2020 at 8:06 PM Jim Lemon wrote:
> > > > > On Sat, Jun 13, 2020 at 10:46 AM Ana Marija wrote:
> > > > > >
> > > > > > I am trying to make a new column
> > > > > > "pheno" so that I reduce the number
> > > > > > of NAs
> > > > >
> > > > > it looks like those two NA values in
> > > > > PLASER are the ones you want to drop.
> > > >
> > > > From just your summary table, it's hard to
> > > > guess the distribution of NA values.
> > >
> > > Dear Ana,
> > >
> > > This small sample
> > >
> > >         b <- read.table(text="FLASER;PLASER
> > >         1;2
> > >         ;2
> > >         ;
> > >         1;
> > >         2;
> > >         2;2
> > >         3;2
> > >         3;3
> > >         1;1", sep=";", header=TRUE)
> > >
> > >         table(b$PLASER,b$FLASER, exclude = NULL)
> > >
> > > yields the same combinations you showed
> > > earlier:
> > >
> > >                1 2 3 <NA>
> > >           1    1 0 0    0
> > >           2    1 1 1    1
> > >           3    0 0 1    0
> > >           <NA> 1 1 0    1
> > >
> > > If you want to eliminate the four <NA>-based
> > > combinations completely, this line
> > >
> > >         b$pheno <-
> > >           ifelse(b$PLASER==2 |
> > >                  b$FLASER==2 |
> > >                  is.na(b$PLASER) |
> > >                  is.na(b$PLASER) & b$FLASER %in% 1:2 |
> > >                  is.na(b$FLASER) & b$PLASER == 2,
> > >                  2, 1)
> > >         table(b$pheno, exclude = NULL)
> > >
> > > will do it:
> > >
> > >         1 2
> > >         2 7
> > >
> > > Best,
> > > Rasmus
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Jun 13 07:20:44 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 13 Jun 2020 06:20:44 +0100
Subject: [R] Obtaining p values from t-test run with a by function
In-Reply-To: <CAM_vju=mkUdwONAYgk=fK4Oy2XXs402rGzOnRojv7hi1xsNjFQ@mail.gmail.com>
References: <MN2PR03MB5167961B19C3312A91104696E2810@MN2PR03MB5167.namprd03.prod.outlook.com>
 <CAM_vju=mkUdwONAYgk=fK4Oy2XXs402rGzOnRojv7hi1xsNjFQ@mail.gmail.com>
Message-ID: <7a18ddac-e653-9f6e-a9bf-5ca51f2c4abd@sapo.pt>

Hello,

Or in one go with *apply, function '[[':

sapply(result, '[[', 'p.value')
#         EPA            P
#2.564503e-04 4.173480e-06


Hope this helps,

Rui Barradas

?s 23:20 de 12/06/20, Sarah Goslee escreveu:
> Where you have
> 
> result[1]$p.value
> result[2]$p.value
> 
> You need
> 
> result[[1]]$p.value
> result[[2]]$p.value
> 
> to get the first component of the list.
> 
> Sarah
> 
> On Fri, Jun 12, 2020 at 5:35 PM Sorkin, John <jsorkin at som.umaryland.edu> wrote:
>>
>> Colleagues,
>> I am trying to retrieve the p values produced by a Student's t-test run using a by function, but can not do so. I can easily get the p value when I run s Student's t-test without a by function. What is the secret to obtaining results returned from a function run within a by function.
>>
>> An annotated repeatable example (including data) can be found below.
>> Thank you,
>> John
>>
>>
>> # Test data
>> mydata <- structure(list(Group = structure(c(2L, 1L, 2L, 2L, 1L, 2L, 1L,
>>             2L, 2L, 1L, 2L, 1L, 2L), .Label = c("EPA", "P"), class = "factor"),
>>             WtBaseline = c(76.6, 73.8, 77.6, 91.7, 110.3, 121.7, 82.1,
>>             82.8, 119, 88.4, 75.7, 71.4, 72.1)), class = "data.frame", row.names = c(NA,-13L))
>>
>> cat("This is what mydata looks like\n")
>> mydata
>>
>> result <- by(mydata$WtBaseline,mydata$Group,t.test)
>> cat("Student's t-test run using by command\n")
>> cat("Result has results for both groups, EPA and P\n")
>> result
>>
>> cat("I can isolate the collective results for group EPA\n")
>> result[1]
>> cat("I can isolate the collective results for group P\n")
>> result[2]
>>
>> cat("I cant get the p-values for the gruops")
>> result[1]$p.value
>> result[2]$p.value
>>
>> cat("When run without by function, one can get the p value\n")
>> xxx <- t.test(WtBaseline~Group,data=mydata)
>> cat("t-test run without by fundtion\n")
>> xxx
>> cat("p value isolated from t-test run without by function\n")
>> xxx$p.value
>>
>>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
>


From drj|m|emon @end|ng |rom gm@||@com  Sat Jun 13 11:09:11 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 13 Jun 2020 19:09:11 +1000
Subject: [R] if else statement adjustemtn
In-Reply-To: <CAF9-5jPxnKNYuivUhgq6Pq408BEOYHjrVfrQ_YDTQJF5mcB_CA@mail.gmail.com>
References: <CAF9-5jMVc9jhfj-x2NW96=MoQ_0zyRDoupJTD28M_aEkOvM-ag@mail.gmail.com>
 <CA+8X3fVQDKyL4jA+E1MPQP=x3aTe9zzm-me9WNWEFZCKUQtgQA@mail.gmail.com>
 <CAF9-5jNeKhEaDBdsVrAzdekfiaU0jwcCwCy-D4pHe7-JN4sw+g@mail.gmail.com>
 <CA+8X3fXDJUv=mPu6SMSg_O=ra-4QgT+JBjdPsS0CqDUai2fgSg@mail.gmail.com>
 <20200613022837.GD723678@posteo.no>
 <CAF9-5jO+Q6Q6-WuvjmUWH6-gTL_cZXwugteZiEr-CZWwnfd-hw@mail.gmail.com>
 <CA+8X3fX+iErrBMM+cr2Rypo7n3dN6PSJW6Lwc7XmpREDHa3VMQ@mail.gmail.com>
 <CAF9-5jPxnKNYuivUhgq6Pq408BEOYHjrVfrQ_YDTQJF5mcB_CA@mail.gmail.com>
Message-ID: <CA+8X3fU6-wp1cT3Ox6+idUvu7wL2M9THbLBDsewUB-8_Vja-Nw@mail.gmail.com>

Right, back from shopping. Since you have fourteen rows containing NAs
and you only want seven, we can infer that half of them must go. As
they are neatly divided into seven rows in which only one NA appears
and seven in which two stare meaninglessly out at us. I will assume
that the latter are the ones to be discarded. As your condition for
calculating "pheno" stated that a 2 in either FLASER or PLASER should
result in a 2 in pheno, the following statement closely conforms to
that:

b<-read.table(text="FID   IID FLASER PLASER
  fam1837 G1837      1     NA
  fam2410 G2410     NA     NA
  fam2838 G2838     NA      2
  fam3367 G3367      1     NA
  fam3410 G3410      1     NA
  fam3492 G3492      1     NA
  fam0911  G911     NA     NA
  fam3834 G3834      2     NA
  fam4708 G4708     NA      2
  fam5162 G5162     NA     NA
  fam5274 G5274     NA     NA
  fam0637  G637     NA     NA
  fam0640  G640     NA     NA
  fam0743  G743     NA     NA
  fam0911  G911     NA     NA",
  header=TRUE,stringsAsFactors=FALSE)

b$pheno<-ifelse(b$FLASER == 2 | b$PLASER == 2,2,1)
# use the valid FLASER values when PLASER is NA
b[is.na(b$pheno),]$pheno<-ifelse(!is.na(b[is.na(b$pheno),]$FLASER),
 b[is.na(b$pheno),]$FLASER,NA)
# use the valid PLASER values when FLASER if NA
b[is.na(b$pheno),]$pheno<-ifelse(!is.na(b[is.na(b$pheno),]$PLASER),
 b[is.na(b$pheno),]$PLASER,NA)
b

I could write that mess in one straitjacket of conditional statements
but my brain hurts enough.

Jim


On Sat, Jun 13, 2020 at 1:59 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Great idea!
> Here it is:
> > b[is.na(b$FLASER) | is.na(b$PLASER),]
>         FID   IID FLASER PLASER pheno
>  1: fam1837 G1837      1     NA     2
>  2: fam2410 G2410     NA     NA     2
>  3: fam2838 G2838     NA      2     2
>  4: fam3367 G3367      1     NA     2
>  5: fam3410 G3410      1     NA     2
>  6: fam3492 G3492      1     NA     2
>  7: fam3834 G3834      2     NA     2
>  8: fam4708 G4708     NA      2     2
>  9: fam5162 G5162     NA     NA     2
> 10: fam5274 G5274     NA     NA     2
> 11: fam0637  G637     NA     NA     2
> 12: fam0640  G640     NA     NA     2
> 13: fam0743  G743     NA     NA     2
> 14: fam0911  G911     NA     NA     2
>
> On Fri, Jun 12, 2020 at 10:29 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> > Since you have only a few troublesome NA values, if you look at them,
> > or even better, post them:
> >
> > b[is.na(b$FLASER) | is.na(b$PLASER),]
> >
> > perhaps we can work out the appropriate logic to get rid of only the
> > ones you don't want.
> >
> > Jim
> >
> > On Sat, Jun 13, 2020 at 12:50 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> > >
> > > Hi Rasmus,
> > >
> > > thank you for getting back to be, the command your provided seems to
> > > add all 11 NAs to 2s
> > > > b$pheno <-
> > > +           ifelse(b$PLASER==2 |
> > > +                  b$FLASER==2 |
> > > +                  is.na(b$PLASER) |
> > > +                  is.na(b$PLASER) & b$FLASER %in% 1:2 |
> > > +                  is.na(b$FLASER) & b$PLASER == 2,
> > > +                  2, 1)
> > > >         table(b$pheno, exclude = NULL)
> > >
> > >   1   2
> > > 859 839
> > >
> > > Once again my desired results is to keep these 7 NAs as NAs
> > > > table(b$PLASER,b$FLASER, exclude = NULL)
> > >
> > >          1   2   3 <NA>
> > >   1    836  14   0    0
> > >   2    691  70  43    2
> > >   3      2   7  21    0
> > >   <NA>   4   1   0    7
> > >
> > > and have
> > > 825 2s (825=691+14+70+7+43)
> > > and the rest would be 1s (866=1698-7-825)
> > >
> > > On Fri, Jun 12, 2020 at 9:29 PM Rasmus Liland <jral at posteo.no> wrote:
> > > >
> > > > On 2020-06-13 11:30 +1000, Jim Lemon wrote:
> > > > > On Fri, Jun 12, 2020 at 8:06 PM Jim Lemon wrote:
> > > > > > On Sat, Jun 13, 2020 at 10:46 AM Ana Marija wrote:
> > > > > > >
> > > > > > > I am trying to make a new column
> > > > > > > "pheno" so that I reduce the number
> > > > > > > of NAs
> > > > > >
> > > > > > it looks like those two NA values in
> > > > > > PLASER are the ones you want to drop.
> > > > >
> > > > > From just your summary table, it's hard to
> > > > > guess the distribution of NA values.
> > > >
> > > > Dear Ana,
> > > >
> > > > This small sample
> > > >
> > > >         b <- read.table(text="FLASER;PLASER
> > > >         1;2
> > > >         ;2
> > > >         ;
> > > >         1;
> > > >         2;
> > > >         2;2
> > > >         3;2
> > > >         3;3
> > > >         1;1", sep=";", header=TRUE)
> > > >
> > > >         table(b$PLASER,b$FLASER, exclude = NULL)
> > > >
> > > > yields the same combinations you showed
> > > > earlier:
> > > >
> > > >                1 2 3 <NA>
> > > >           1    1 0 0    0
> > > >           2    1 1 1    1
> > > >           3    0 0 1    0
> > > >           <NA> 1 1 0    1
> > > >
> > > > If you want to eliminate the four <NA>-based
> > > > combinations completely, this line
> > > >
> > > >         b$pheno <-
> > > >           ifelse(b$PLASER==2 |
> > > >                  b$FLASER==2 |
> > > >                  is.na(b$PLASER) |
> > > >                  is.na(b$PLASER) & b$FLASER %in% 1:2 |
> > > >                  is.na(b$FLASER) & b$PLASER == 2,
> > > >                  2, 1)
> > > >         table(b$pheno, exclude = NULL)
> > > >
> > > > will do it:
> > > >
> > > >         1 2
> > > >         2 7
> > > >
> > > > Best,
> > > > Rasmus
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.


From m@rk@@z@|@|@hu @end|ng |rom gm@||@com  Sat Jun 13 14:39:59 2020
From: m@rk@@z@|@|@hu @end|ng |rom gm@||@com (=?UTF-8?B?TcOhcmsgU3phbGFp?=)
Date: Sat, 13 Jun 2020 14:39:59 +0200
Subject: [R] if else statement adjustemtn
In-Reply-To: <mailman.359442.1.1592042401.7337.r-help@r-project.org>
References: <mailman.359442.1.1592042401.7337.r-help@r-project.org>
Message-ID: <CAA14ACwTD_kbcUMg+G3HoTCpeZJpHKn+pTH7GbOoiF_zu4BrxA@mail.gmail.com>

Dear Ana,

pmax could also fit here.
pmax(b$FLASER, b$PLASER, na.rm = TRUE)

Bests,
Mark



> ------------------------------
>
> Message: 21
> Date: Sat, 13 Jun 2020 19:09:11 +1000
> From: Jim Lemon <drjimlemon at gmail.com>
> To: sokovic.anamarija at gmail.com
> Cc: Rasmus Liland <jral at posteo.no>, r-help <r-help at r-project.org>
> Subject: Re: [R] if else statement adjustemtn
> Message-ID:
>         <CA+8X3fU6-wp1cT3Ox6+idUvu7wL2M9THbLBDsewUB-8_Vja-Nw at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> Right, back from shopping. Since you have fourteen rows containing NAs
> and you only want seven, we can infer that half of them must go. As
> they are neatly divided into seven rows in which only one NA appears
> and seven in which two stare meaninglessly out at us. I will assume
> that the latter are the ones to be discarded. As your condition for
> calculating "pheno" stated that a 2 in either FLASER or PLASER should
> result in a 2 in pheno, the following statement closely conforms to
> that:
>
> b<-read.table(text="FID   IID FLASER PLASER
>   fam1837 G1837      1     NA
>   fam2410 G2410     NA     NA
>   fam2838 G2838     NA      2
>   fam3367 G3367      1     NA
>   fam3410 G3410      1     NA
>   fam3492 G3492      1     NA
>   fam0911  G911     NA     NA
>   fam3834 G3834      2     NA
>   fam4708 G4708     NA      2
>   fam5162 G5162     NA     NA
>   fam5274 G5274     NA     NA
>   fam0637  G637     NA     NA
>   fam0640  G640     NA     NA
>   fam0743  G743     NA     NA
>   fam0911  G911     NA     NA",
>   header=TRUE,stringsAsFactors=FALSE)
>
> b$pheno<-ifelse(b$FLASER == 2 | b$PLASER == 2,2,1)
> # use the valid FLASER values when PLASER is NA
> b[is.na(b$pheno),]$pheno<-ifelse(!is.na(b[is.na(b$pheno),]$FLASER),
>  b[is.na(b$pheno),]$FLASER,NA)
> # use the valid PLASER values when FLASER if NA
> b[is.na(b$pheno),]$pheno<-ifelse(!is.na(b[is.na(b$pheno),]$PLASER),
>  b[is.na(b$pheno),]$PLASER,NA)
> b
>
> I could write that mess in one straitjacket of conditional statements
> but my brain hurts enough.
>
> Jim
>
>
> On Sat, Jun 13, 2020 at 1:59 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Great idea!
> > Here it is:
> > > b[is.na(b$FLASER) | is.na(b$PLASER),]
> >         FID   IID FLASER PLASER pheno
> >  1: fam1837 G1837      1     NA     2
> >  2: fam2410 G2410     NA     NA     2
> >  3: fam2838 G2838     NA      2     2
> >  4: fam3367 G3367      1     NA     2
> >  5: fam3410 G3410      1     NA     2
> >  6: fam3492 G3492      1     NA     2
> >  7: fam3834 G3834      2     NA     2
> >  8: fam4708 G4708     NA      2     2
> >  9: fam5162 G5162     NA     NA     2
> > 10: fam5274 G5274     NA     NA     2
> > 11: fam0637  G637     NA     NA     2
> > 12: fam0640  G640     NA     NA     2
> > 13: fam0743  G743     NA     NA     2
> > 14: fam0911  G911     NA     NA     2
> >
> > On Fri, Jun 12, 2020 at 10:29 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> > >
> > > Since you have only a few troublesome NA values, if you look at them,
> > > or even better, post them:
> > >
> > > b[is.na(b$FLASER) | is.na(b$PLASER),]
> > >
> > > perhaps we can work out the appropriate logic to get rid of only the
> > > ones you don't want.
> > >
> > > Jim
> > >
> > > On Sat, Jun 13, 2020 at 12:50 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> > > >
> > > > Hi Rasmus,
> > > >
> > > > thank you for getting back to be, the command your provided seems to
> > > > add all 11 NAs to 2s
> > > > > b$pheno <-
> > > > +           ifelse(b$PLASER==2 |
> > > > +                  b$FLASER==2 |
> > > > +                  is.na(b$PLASER) |
> > > > +                  is.na(b$PLASER) & b$FLASER %in% 1:2 |
> > > > +                  is.na(b$FLASER) & b$PLASER == 2,
> > > > +                  2, 1)
> > > > >         table(b$pheno, exclude = NULL)
> > > >
> > > >   1   2
> > > > 859 839
> > > >
> > > > Once again my desired results is to keep these 7 NAs as NAs
> > > > > table(b$PLASER,b$FLASER, exclude = NULL)
> > > >
> > > >          1   2   3 <NA>
> > > >   1    836  14   0    0
> > > >   2    691  70  43    2
> > > >   3      2   7  21    0
> > > >   <NA>   4   1   0    7
> > > >
> > > > and have
> > > > 825 2s (825=691+14+70+7+43)
> > > > and the rest would be 1s (866=1698-7-825)
> > > >
> > > > On Fri, Jun 12, 2020 at 9:29 PM Rasmus Liland <jral at posteo.no> wrote:
> > > > >
> > > > > On 2020-06-13 11:30 +1000, Jim Lemon wrote:
> > > > > > On Fri, Jun 12, 2020 at 8:06 PM Jim Lemon wrote:
> > > > > > > On Sat, Jun 13, 2020 at 10:46 AM Ana Marija wrote:
> > > > > > > >
> > > > > > > > I am trying to make a new column
> > > > > > > > "pheno" so that I reduce the number
> > > > > > > > of NAs
> > > > > > >
> > > > > > > it looks like those two NA values in
> > > > > > > PLASER are the ones you want to drop.
> > > > > >
> > > > > > From just your summary table, it's hard to
> > > > > > guess the distribution of NA values.
> > > > >
> > > > > Dear Ana,
> > > > >
> > > > > This small sample
> > > > >
> > > > >         b <- read.table(text="FLASER;PLASER
> > > > >         1;2
> > > > >         ;2
> > > > >         ;
> > > > >         1;
> > > > >         2;
> > > > >         2;2
> > > > >         3;2
> > > > >         3;3
> > > > >         1;1", sep=";", header=TRUE)
> > > > >
> > > > >         table(b$PLASER,b$FLASER, exclude = NULL)
> > > > >
> > > > > yields the same combinations you showed
> > > > > earlier:
> > > > >
> > > > >                1 2 3 <NA>
> > > > >           1    1 0 0    0
> > > > >           2    1 1 1    1
> > > > >           3    0 0 1    0
> > > > >           <NA> 1 1 0    1
> > > > >
> > > > > If you want to eliminate the four <NA>-based
> > > > > combinations completely, this line
> > > > >
> > > > >         b$pheno <-
> > > > >           ifelse(b$PLASER==2 |
> > > > >                  b$FLASER==2 |
> > > > >                  is.na(b$PLASER) |
> > > > >                  is.na(b$PLASER) & b$FLASER %in% 1:2 |
> > > > >                  is.na(b$FLASER) & b$PLASER == 2,
> > > > >                  2, 1)
> > > > >         table(b$pheno, exclude = NULL)
> > > > >
> > > > > will do it:
> > > > >
> > > > >         1 2
> > > > >         2 7
> > > > >
> > > > > Best,
> > > > > Rasmus
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.


From bennet @end|ng |rom um|ch@edu  Sat Jun 13 19:13:15 2020
From: bennet @end|ng |rom um|ch@edu (Bennet Fauber)
Date: Sat, 13 Jun 2020 13:13:15 -0400
Subject: [R] rgdal errors from proj
Message-ID: <CAB2ovotcvr9SQXwXGCN2neCAOZcVLWty6HqvUhf7GoCVa=fapg@mail.gmail.com>

I am trying to install rgdal from source on CentOS 7.

I have installed geos, proj, and gdal successfully, they test fine.

This is with R version 3.6.3 (2020-02-29) -- "Holding the Windsock"
compiled with gcc/8.2.0.

This is an HPC system, and I have the following modules loaded,

Currently Loaded Modules:
  1) gcc/8.2.0   3) image-libraries/190711.1   5) proj/6.2.1
  2) R/3.6.3     4) geos/3.8.1                 6) gdal/3.1.0

I get the output included below.  In that output, it appears that the
configure correctly identifies the proj options needed from
pkg-config, repeated here

configure: pkg-config proj exists, will use it
configure: PROJ version: 6.2.1
configure: proj CPP flags: -DPROJ_H_API
-I/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/include
configure: PROJ LIBS: -L/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/lib -lproj

and

$ nm /sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/lib/libproj.so | grep
proj_context_create
00000000001ef4e0 T proj_context_create

seems to indicate that is truly there.

I unpacked the rgdal source tar ball and ran ./configure from its
directory and get the same error.  Looking in the generated
config.log, I find

configure:3869: checking for proj_context_create in -lproj
configure:3894: gcc -o conftest -O3 -mtune=native -I/usr/local/include
-DPROJ_H_API -I/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/include
-L/usr/local/lib64 conftest.c -lproj
-L/sw/arcts/centos7/gcc_8_2_0/gdal/3.1.0/lib -lgdal >&5
/usr/bin/ld: cannot find -lproj

and from that, it appears that configure is not including the correct
CFLAGS to include proj.  It is, instead, putting in
-L/usr/local/lib64, and that is not where the proj libraries are.

Extracting the confdefs.h and conftest.c file from config.log and
running the test compilation command modified by hand to include the
correct library directory for proj,

$ gcc -o conftest -O3 -mtune=native -I/usr/local/include -DPROJ_H_API
-I/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/include
-L/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/lib conftest.c -lproj
-L/sw/arcts/centos7/gcc_8_2_0/gdal/3.1.0/lib -lgdal
$ echo $?
0

So, I believe there is an error in configure.ac, or in the included
configure script that is not properly registering the library path for
proj.  Note, also, that I get the same result if using

$ ./configure --with-proj-include=/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/include
\
    --with-proj-lib=/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/lib \
    --with-proj-share=/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/share/proj
. . . .
configure: error: proj_context_create not found in libproj.

Might anyone know what needs to be done to fix this?

Thanks,    -- bennet

Full output of install.packages('rgdal')
#----------------------------------------------
> install.packages('rgdal', "/sw/arcts/centos7/Rgeospatial/062020", repo="https:Warning: unable to access index for repository https:repo.miserver.it.umich.edu/cran/src/contrib:
> install.packages('rgdal', "/sw/arcts/centos7/Rgeospatial/062020", repos="https://repo.miserver.it.umich.edu/cran/")
trying URL 'https://repo.miserver.it.umich.edu/cran/src/contrib/rgdal_1.5-10.tar.gz'
Content type 'application/octet-stream' length 2300923 bytes (2.2 MB)
==================================================
downloaded 2.2 MB

* installing *source* package ?rgdal? ...
** package ?rgdal? successfully unpacked and MD5 sums checked
** using staged installation
configure: R_HOME: /sw/arcts/centos7/R/3.6.3/lib64/R
configure: CC: gcc
configure: CXX: g++ -std=gnu++11
configure: CXX11 is: g++, CXX11STD is: -std=gnu++11
configure: CXX is: g++ -std=gnu++11
configure: C++11 support available
configure: rgdal: 1.5-10
checking for /usr/bin/svnversion... yes
configure: svn revision: 1006
checking for gdal-config...
/sw/arcts/centos7/gcc_8_2_0/gdal/3.1.0/bin/gdal-config
checking gdal-config usability... yes
configure: GDAL: 3.1.0
checking GDAL version >= 1.11.4... yes
checking GDAL version <= 2.5 or >= 3.0... yes
checking gdal: linking with --libs only... yes
checking GDAL: gdal-config data directory readable... yes
checking GDAL: /sw/arcts/centos7/gcc_8_2_0/gdal/3.1.0/share/gdal/stateplane.csv
readable... yes
configure: pkg-config proj exists, will use it
configure: PROJ version: 6.2.1
configure: proj CPP flags: -DPROJ_H_API
-I/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/include
configure: PROJ LIBS: -L/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/lib -lproj
checking PROJ header API:... yes
checking for gcc... gcc
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables...
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ISO C89... none needed
checking how to run the C preprocessor... gcc -E
checking for grep that handles long lines and -e... /usr/bin/grep
checking for egrep... /usr/bin/grep -E
checking for ANSI C header files... yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking proj.h usability... yes
checking proj.h presence... yes
checking for proj.h... yes
checking for proj_context_create in -lproj... no
configure: error: proj_context_create not found in libproj.
ERROR: configuration failed for package ?rgdal?


From bennet @end|ng |rom um|ch@edu  Sun Jun 14 00:51:03 2020
From: bennet @end|ng |rom um|ch@edu (Bennet Fauber)
Date: Sat, 13 Jun 2020 18:51:03 -0400
Subject: [R] rgdal errors from proj
In-Reply-To: <CAB2ovotcvr9SQXwXGCN2neCAOZcVLWty6HqvUhf7GoCVa=fapg@mail.gmail.com>
References: <CAB2ovotcvr9SQXwXGCN2neCAOZcVLWty6HqvUhf7GoCVa=fapg@mail.gmail.com>
Message-ID: <CAB2ovot7PuPUJ3H8XvnxBVVfDBrk3O_5_K4hVtYMYOzKEydd=A@mail.gmail.com>

After doing some experimentation,  I find that making the following
change to configure.ac and running autoreconf produces a configure
script that does not error.

*** configure.ac.original    2020-06-13 15:23:43.865733311 -0400
--- configure.ac    2020-06-13 15:25:05.455499480 -0400
***************
*** 397,402 ****
--- 397,404 ----
    fi # proj_config_ok
  fi # proj_lib_path

+ LIBS="${PKG_LIBS} ${LIBS}"
+
  AC_MSG_NOTICE([PROJ LIBS: ${PKG_LIBS}])

and leads to

checking for proj.h... yes
checking for proj_context_create in -lproj... yes
checking Using GDAL < 3 with PROJ >= 6... no
checking PROJ version >= 4.8.0... yes
checking PROJ: proj.db found and readable... yes
configure: Package CPP flags:
-I/sw/arcts/centos7/gcc_8_2_0/gdal/3.1.0/include
-I/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/include   -DPROJ_H_API
configure: Package LIBS:  -L/sw/arcts/centos7/gcc_8_2_0/gdal/3.1.0/lib
-lgdal -L/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/lib -lproj
configure: creating ./config.status
config.status: creating src/Makevars

In config.log, this shows

configure:3871: checking for proj_context_create in -lproj
configure:3896: gcc -o conftest -O3 -mtune=native -I/usr/local/include
-DPROJ_H_API -I/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/include
-L/usr/local/lib64 conftest.c -lproj
-L/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/lib -lproj
-L/sw/arcts/centos7/gcc_8_2_0/gdal/3.1.0/lib -lgdal >&5
configure:3896: $? = 0
configure:3905: result: yes

I am unable to find a repository to which I can submit this for
consideration as a patch.



On Sat, Jun 13, 2020 at 1:13 PM Bennet Fauber <bennet at umich.edu> wrote:
>
> I am trying to install rgdal from source on CentOS 7.
>
> I have installed geos, proj, and gdal successfully, they test fine.
>
> This is with R version 3.6.3 (2020-02-29) -- "Holding the Windsock"
> compiled with gcc/8.2.0.
>
> This is an HPC system, and I have the following modules loaded,
>
> Currently Loaded Modules:
>   1) gcc/8.2.0   3) image-libraries/190711.1   5) proj/6.2.1
>   2) R/3.6.3     4) geos/3.8.1                 6) gdal/3.1.0
>
> I get the output included below.  In that output, it appears that the
> configure correctly identifies the proj options needed from
> pkg-config, repeated here
>
> configure: pkg-config proj exists, will use it
> configure: PROJ version: 6.2.1
> configure: proj CPP flags: -DPROJ_H_API
> -I/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/include
> configure: PROJ LIBS: -L/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/lib -lproj
>
> and
>
> $ nm /sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/lib/libproj.so | grep
> proj_context_create
> 00000000001ef4e0 T proj_context_create
>
> seems to indicate that is truly there.
>
> I unpacked the rgdal source tar ball and ran ./configure from its
> directory and get the same error.  Looking in the generated
> config.log, I find
>
> configure:3869: checking for proj_context_create in -lproj
> configure:3894: gcc -o conftest -O3 -mtune=native -I/usr/local/include
> -DPROJ_H_API -I/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/include
> -L/usr/local/lib64 conftest.c -lproj
> -L/sw/arcts/centos7/gcc_8_2_0/gdal/3.1.0/lib -lgdal >&5
> /usr/bin/ld: cannot find -lproj
>
> and from that, it appears that configure is not including the correct
> CFLAGS to include proj.  It is, instead, putting in
> -L/usr/local/lib64, and that is not where the proj libraries are.
>
> Extracting the confdefs.h and conftest.c file from config.log and
> running the test compilation command modified by hand to include the
> correct library directory for proj,
>
> $ gcc -o conftest -O3 -mtune=native -I/usr/local/include -DPROJ_H_API
> -I/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/include
> -L/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/lib conftest.c -lproj
> -L/sw/arcts/centos7/gcc_8_2_0/gdal/3.1.0/lib -lgdal
> $ echo $?
> 0
>
> So, I believe there is an error in configure.ac, or in the included
> configure script that is not properly registering the library path for
> proj.  Note, also, that I get the same result if using
>
> $ ./configure --with-proj-include=/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/include
> \
>     --with-proj-lib=/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/lib \
>     --with-proj-share=/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/share/proj
> . . . .
> configure: error: proj_context_create not found in libproj.
>
> Might anyone know what needs to be done to fix this?
>
> Thanks,    -- bennet
>
> Full output of install.packages('rgdal')
> #----------------------------------------------
> > install.packages('rgdal', "/sw/arcts/centos7/Rgeospatial/062020", repo="https:Warning: unable to access index for repository https:repo.miserver.it.umich.edu/cran/src/contrib:
> > install.packages('rgdal', "/sw/arcts/centos7/Rgeospatial/062020", repos="https://repo.miserver.it.umich.edu/cran/")
> trying URL 'https://repo.miserver.it.umich.edu/cran/src/contrib/rgdal_1.5-10.tar.gz'
> Content type 'application/octet-stream' length 2300923 bytes (2.2 MB)
> ==================================================
> downloaded 2.2 MB
>
> * installing *source* package ?rgdal? ...
> ** package ?rgdal? successfully unpacked and MD5 sums checked
> ** using staged installation
> configure: R_HOME: /sw/arcts/centos7/R/3.6.3/lib64/R
> configure: CC: gcc
> configure: CXX: g++ -std=gnu++11
> configure: CXX11 is: g++, CXX11STD is: -std=gnu++11
> configure: CXX is: g++ -std=gnu++11
> configure: C++11 support available
> configure: rgdal: 1.5-10
> checking for /usr/bin/svnversion... yes
> configure: svn revision: 1006
> checking for gdal-config...
> /sw/arcts/centos7/gcc_8_2_0/gdal/3.1.0/bin/gdal-config
> checking gdal-config usability... yes
> configure: GDAL: 3.1.0
> checking GDAL version >= 1.11.4... yes
> checking GDAL version <= 2.5 or >= 3.0... yes
> checking gdal: linking with --libs only... yes
> checking GDAL: gdal-config data directory readable... yes
> checking GDAL: /sw/arcts/centos7/gcc_8_2_0/gdal/3.1.0/share/gdal/stateplane.csv
> readable... yes
> configure: pkg-config proj exists, will use it
> configure: PROJ version: 6.2.1
> configure: proj CPP flags: -DPROJ_H_API
> -I/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/include
> configure: PROJ LIBS: -L/sw/arcts/centos7/gcc_8_2_0/proj/6.2.1/lib -lproj
> checking PROJ header API:... yes
> checking for gcc... gcc
> checking whether the C compiler works... yes
> checking for C compiler default output file name... a.out
> checking for suffix of executables...
> checking whether we are cross compiling... no
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc accepts -g... yes
> checking for gcc option to accept ISO C89... none needed
> checking how to run the C preprocessor... gcc -E
> checking for grep that handles long lines and -e... /usr/bin/grep
> checking for egrep... /usr/bin/grep -E
> checking for ANSI C header files... yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking proj.h usability... yes
> checking proj.h presence... yes
> checking for proj.h... yes
> checking for proj_context_create in -lproj... no
> configure: error: proj_context_create not found in libproj.
> ERROR: configuration failed for package ?rgdal?


From ph@t@ch@u @end|ng |rom m@||@utoronto@c@  Sun Jun 14 03:50:54 2020
From: ph@t@ch@u @end|ng |rom m@||@utoronto@c@ (Phat Chau)
Date: Sun, 14 Jun 2020 01:50:54 +0000
Subject: [R] Convergence in Monte Carlo Simulation
Message-ID: <9F0BC01E-F5CB-464A-852C-A7AB684F3F9F@mail.utoronto.ca>

Hello,

I put together the following code and am curious about its correctness. My first question relates to the Monte Carlo simulations ? the goal is to continue to iterate until I get n = 1000 simulations where the model successfully converges. I am wondering if I coded it correctly below with the while loop. Is the idea that the counter increments by one only if ?model? does not return a string?

I would also like to know how I can create n = 1000 independent data sets. I think to do this, I would have to set a random number seed via set.seed() before the creation of each dataset. Where would I enter set.seed in the syntax below? Would it be in the function (as indicated in red)?

powercrosssw <- function(nclus, clsize) {

  set.seed()

  cohortsw <- genData(nclus, id = "cluster")
  cohortsw <- addColumns(clusterDef, cohortsw)
  cohortswTm <- addPeriods(cohortsw, nPeriods = 8, idvars = "cluster", perName = "period")
  cohortstep <- trtStepWedge(cohortswTm, "cluster", nWaves = 4, lenWaves = 1, startPer = 1, grpName = "Ijt")

  pat <- genCluster(cohortswTm, cLevelVar = "timeID", numIndsVar = clsize, level1ID = "id")

  dx <- merge(pat[, .(cluster, period, id)], cohortstep, by = c("cluster", "period"))
  dx <- addColumns(patError, dx)

  setkey(dx, id, cluster, period)

  dx <- addColumns(outDef, dx)

  return(dx)

}

i=1

while (i < 1000) {

  dx <- powercrosssw()

  #Fit multi-level model to simulated dataset
  model5 <- tryCatch(lme(y ~ factor(period) + factor(Ijt), data = dx, random = ~1|cluster, method = "REML"),
                     warning = function(w) { "warning" }
  )

  if (! is.character(model5)) {

    coeff <- coef(summary(model5))["factor(Ijt)1", "Value"]
    pvalue <- coef(summary(model5))["factor(Ijt)1", "p-value"]
    error <- coef(summary(model5))["factor(Ijt)1", "Std.Error"]
    bresult <- c(bresult, coeff)
    presult <- c(presult, pvalue)
    eresult <- c(eresult, error)

    i <- i + 1
  }
}

Thank you so much.



	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Sun Jun 14 12:30:39 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sun, 14 Jun 2020 20:30:39 +1000
Subject: [R] Help with a (g)lmer code
In-Reply-To: <CAB_D3mp2s-dyawjJpYEesY6h49UBM0q3ZFkKA64HZWPdo3HtmQ@mail.gmail.com>
References: <CAB_D3mrPo9JYv_i3RAonNxtZ6qneNtTMn_i2xFOQAGWHY1zPUg@mail.gmail.com>
 <CA+8X3fX60Afeq+y90gwQwabO31_=bk1VFR=-Osb8cpWN0Qmr9Q@mail.gmail.com>
 <CAB_D3mqjGinHXO178OpZHr2_dEb+oOxTntYMc0p=57tVYu3L2g@mail.gmail.com>
 <CAB_D3mp2s-dyawjJpYEesY6h49UBM0q3ZFkKA64HZWPdo3HtmQ@mail.gmail.com>
Message-ID: <CA+8X3fVLVOHSsXPwCEwVasZxNH1jWw5g=GCyAxgk21YXZ-10vg@mail.gmail.com>

Hi Saudi,
Apologies for the delay. (also returning to the list)
In your initial code:

model1<- lmer (better ~ gender + age + education + WF + (1 | part),
> data=sub_data)

you have age as a fixed effect and there are also 36 levels. This
probably causing the error you describe above and I have changed it to
a random factor. Your response variable is "better", which has the
same levels as WF and is not numeric. This looks like a mistake. I
have written four models with the "hum" and "cul" variables as
response variables. This looks more sensible to me. The levels of the
"education" variable are not ordered correctly. The following code
runs okay, but there is a singular fit for EA_cul. The effects seem to
be of education, except for the EA_cul model. The following may get
you started:

sub_data<-read.csv("sub_data.csv",stringsAsFactors=FALSE)
# get the education factor into the correct order
sub_data$education<-factor(sub_data$education,
 levels=c("seconadry or below","university","postgrad"))
library(lme4)
modelSA_hum<-lmer(SA_hum~gender+education+WF+(1|age),data=sub_data)
modelSA_cul<-lmer(SA_cul~gender+education+WF+(1|age),data=sub_data)
modelEA_hum<-lmer(EA_hum~gender+education+WF+(1|age),data=sub_data)
modelEA_cul<-lmer(EA_cul~gender+education+WF+(1|age),data=sub_data)
summary(modelSA_hum)
summary(modelSA_cul)
summary(modelEA_hum)
summary(modelEA_cul)
# look at the distribution of responses
table(sub_data$SA_hum)
table(sub_data$SA_cul)
table(sub_data$EA_hum)
table(sub_data$EA_cul)

Jim

On Sun, Jun 14, 2020 at 9:42 AM Saudi Sadiq <saudisadiq at gmail.com> wrote:
>
> Hi Jim,
> Hope you are safe and sound.
> So sorry to bother you again. I am still waiting for your reply after I have attached the dataset.
> I know you are very busy, but I will appreciate it a lot if you can guide me in how to make the g(lmer) mkdel work, or guide me to something different.
> All the best
>
> ---------- Forwarded message ---------
> From: Saudi Sadiq <saudisadiq at gmail.com>
> Date: Fri, 12 Jun 2020, 4:18 pm
> Subject: Re: [R] Help with a (g)lmer code
> To: Jim Lemon <drjimlemon at gmail.com>
> Cc: r-help mailing list <r-help at r-project.org>
>
>
> Hi Jim,
>
> So many thanks for your reply. I actually made a mistake in presenting the problem; I should have clarified that the 1-10 linear scale questions went as: 10 most humorous/closest to Egyptian culture and 1 the least. Also, I should have attached some examples so the participant issue could be clear. Here is attached the dataset (if there is no problem or I am not going against the rules of the R-help group).
>
> Actually, I wanted better to be the only dependent factor and asking participants 'which subtitle is better?' could be enough, but I wanted to have detailed information of why a subtitle is better by asking participants specific questions (regarding which subtitle is more humorous and closer to Egyptian culture). Most of the time, the total of the hum + cul = better, but sometimes it is not (e.g. the sum for subtitle EA could be bigger than for SA, but the participant prefers SA in the better column).
>
> The WF (watched first) is the mode via which participants watched the two subtitles; some participants watched the SA subtitle first and other watched the EA first.
>
> Does this make sense?
>
> All the best
>
>
> On Thu, 11 Jun 2020 at 05:24, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Saudi,
>> I can only make a guess, but that is that a variable having a unique
>> value for each participant has been read in as a factor. I assume that
>> "better" is some combination of "hum" and "cul" and exactly what is
>> WF?
>>
>> Jim
>>
>> On Thu, Jun 11, 2020 at 5:27 AM Saudi Sadiq <saudisadiq at gmail.com> wrote:
>> >
>> > Dear Sir/Madam,
>> >
>> > Hope everyone is safe and sound. I appreciate your help a lot.
>> >
>> > I am evaluating two Arabic subtitles of a humorous English scene and asked
>> > 263 participants (part) to evaluate the two subtitles (named Standard
>> > Arabic, SA, and Egyptian Arabic, EA) via a questionnaire that asked them to
>> > rank the two subtitles in terms of how much each subtitle is
>> >
>> > 2) more humorous (hum),
>> >
>> > 5) closer to Egyptian culture (cul)
>> >
>> >
>> >
>> > The questionnaire contained two 1-10 linear scale questions regarding the 2
>> > points clarified, with 1 meaning the most humorous and closest to Egyptian
>> > culture, and 1 meaning the least humorous and furthest from Egyptian
>> > culture. Also, the questionnaire had a general multiple-choice question
>> > regarding which subtitle is better in general (better). General information
>> > about the participants were also collected concerning gender (categorical
>> > factor), age (numeric factor) and education (categorical factor).
>> >
>> > Two versions of the questionnaire were relied on: one showing the ?SA
>> > subtitle first? and another showing the ?EA subtitle first?. Nearly half
>> > the participants answered the first and nearly half answered the latter.
>> >
>> > I am focusing on which social factor/s lead/s the participants to evaluate
>> > one of the two subtitles as generally better and which subtitle is more
>> > humorous and closer to Egyptian culture. Each of these points alone can be
>> > the dependent factor, but the results altogether can be linked.
>> >
>> > I thought that mixed effects analyses would clarify the picture and answer
>> > the research questions (which  factor/s lead/s participants to favour a
>> > subtitle over another?) and, so,  tried the lme4 package in R and ran many
>> > models but all the codes I have used are not working.
>> >
>> > I ran the following codes, which yielded Error messages, like:
>> >
>> > model1<- lmer (better ~ gender + age + education + WF + (1 | part),
>> > data=sub_data)
>> >
>> > Error: number of levels of each grouping factor must be < number of
>> > observations (problems: part)
>> >
>> >
>> >
>> > Model2 <- glmer (better ~ gender + age + education + WF + (1 | part), data
>> > = sub_data, family='binomial')
>> >
>> > Error in mkRespMod(fr, family = family) :
>> >
>> >   response must be numeric or factor
>> >
>> >
>> >
>> > Model3 <- glmer (better ~ age + gender + education + WF + (1 | part), data
>> > = sub_data, family='binomial', control=glmerControl(optimizer=c("bobyqa")))
>> >
>> > Error in mkRespMod(fr, family = family) :
>> >
>> >   response must be numeric or factor
>> >
>> >
>> >
>> > Why does the model crash? Does the problem lie in the random factor part (which
>> > is a code for participants)? Or is it something related to the mixed
>> > effects analysis?
>> >
>> > Best
>> > Saudi Sadiq
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Saudi Sadiq,
>
> Lecturer, Minia University, Egypt
>
> Academia, Reserachgate, Google Scholar, Publons
>
> Certified Translator by (Egyta)
>
> Associate Fellow of the Higher Education Academy, UK


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Sun Jun 14 12:46:54 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Sun, 14 Jun 2020 11:46:54 +0100
Subject: [R] Convergence in Monte Carlo Simulation
In-Reply-To: <9F0BC01E-F5CB-464A-852C-A7AB684F3F9F@mail.utoronto.ca>
References: <9F0BC01E-F5CB-464A-852C-A7AB684F3F9F@mail.utoronto.ca>
Message-ID: <7553d0bd-1e5d-51a0-1a47-e16a0b236b1e@dewey.myzen.co.uk>

I am not 100% clear what your code is doing as it gets a bit wangled as 
you posted in HTML but here are a couple of thoughts.

You need to set the seed outside any loops so it happens once and for all.

I would test after trycatch and keep a separate count of failures and 
successes as the failure to converge must be meaningful about the 
scientific question whatever that is. At the moment your count appears 
to be in the correct place to count successes.

Michael

On 14/06/2020 02:50, Phat Chau wrote:
> Hello,
> 
> I put together the following code and am curious about its correctness. My first question relates to the Monte Carlo simulations ? the goal is to continue to iterate until I get n = 1000 simulations where the model successfully converges. I am wondering if I coded it correctly below with the while loop. Is the idea that the counter increments by one only if ?model? does not return a string?
> 
> I would also like to know how I can create n = 1000 independent data sets. I think to do this, I would have to set a random number seed via set.seed() before the creation of each dataset. Where would I enter set.seed in the syntax below? Would it be in the function (as indicated in red)?
> 
> powercrosssw <- function(nclus, clsize) {
> 
>    set.seed()
> 
>    cohortsw <- genData(nclus, id = "cluster")
>    cohortsw <- addColumns(clusterDef, cohortsw)
>    cohortswTm <- addPeriods(cohortsw, nPeriods = 8, idvars = "cluster", perName = "period")
>    cohortstep <- trtStepWedge(cohortswTm, "cluster", nWaves = 4, lenWaves = 1, startPer = 1, grpName = "Ijt")
> 
>    pat <- genCluster(cohortswTm, cLevelVar = "timeID", numIndsVar = clsize, level1ID = "id")
> 
>    dx <- merge(pat[, .(cluster, period, id)], cohortstep, by = c("cluster", "period"))
>    dx <- addColumns(patError, dx)
> 
>    setkey(dx, id, cluster, period)
> 
>    dx <- addColumns(outDef, dx)
> 
>    return(dx)
> 
> }
> 
> i=1
> 
> while (i < 1000) {
> 
>    dx <- powercrosssw()
> 
>    #Fit multi-level model to simulated dataset
>    model5 <- tryCatch(lme(y ~ factor(period) + factor(Ijt), data = dx, random = ~1|cluster, method = "REML"),
>                       warning = function(w) { "warning" }
>    )
> 
>    if (! is.character(model5)) {
> 
>      coeff <- coef(summary(model5))["factor(Ijt)1", "Value"]
>      pvalue <- coef(summary(model5))["factor(Ijt)1", "p-value"]
>      error <- coef(summary(model5))["factor(Ijt)1", "Std.Error"]
>      bresult <- c(bresult, coeff)
>      presult <- c(presult, pvalue)
>      eresult <- c(eresult, error)
> 
>      i <- i + 1
>    }
> }
> 
> Thank you so much.
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From novo@|rj @end|ng |rom rutger@@edu  Sun Jun 14 04:16:38 2020
From: novo@|rj @end|ng |rom rutger@@edu (Ryan Novosielski)
Date: Sun, 14 Jun 2020 02:16:38 +0000
Subject: [R] R 4.0.1 built with Intel Composer 19.1.1,
 error in R CMD make check on CentOS 7.7
Message-ID: <39C5E435-33B5-4753-9E9E-BCAB869CDCDF@rutgers.edu>

Hi there,

Built R 4.0.1 with the Intel Composer 19.1.1. Build seems to go fine. I built it like this:

module purge
module load intel/19.1.1
module list

export CC=icc
export CXX=icpc
export F77=ifort
export FC=ifort
export AR=xiar
export LD=xild

export CFLAGS="-O3 -ipo -qopenmp -axAVX,CORE-AVX2,CORE-AVX512"
export F77FLAGS="-O3 -ipo -qopenmp -axAVX,CORE-AVX2,CORE-AVX512"
export FFLAGS="-O3 -ipo -qopenmp -axAVX,CORE-AVX2,CORE-AVX512"
export CXXFLAGS="-O3 -ipo -qopenmp -axAVX,CORE-AVX2,CORE-AVX512"
export MKL="-lmkl_intel_lp64 -lmkl_intel_thread -lmkl_core -liomp5 -lpthread"

VERSION=4.0.1

/scratch/novosirj/install-files/R-${VERSION}/configure --with-blas="$MKL" --with-lapack --prefix=/opt/sw/packages/intel-19_1/R-Project/${VERSION} && \
        make -j32 && make check && make -j32 install

However, the ?make check" phase fails at this part:

Testing examples for package ?parallel?
make[2]: Leaving directory `/mnt/scratch/novosirj/R-4.0.1-intel-19.1-build/tests/Examples'
make[1]: Leaving directory `/mnt/scratch/novosirj/R-4.0.1-intel-19.1-build/tests'
make[1]: Entering directory `/mnt/scratch/novosirj/R-4.0.1-intel-19.1-build/tests'
running strict specific tests
make[2]: Entering directory `/mnt/scratch/novosirj/R-4.0.1-intel-19.1-build/tests'
running code in '/scratch/novosirj/install-files/R-4.0.1/tests/eval-etc.R' ... OK
  comparing 'eval-etc.Rout' to '/scratch/novosirj/install-files/R-4.0.1/tests/eval-etc.Rout.save' ... OK
running code in '/scratch/novosirj/install-files/R-4.0.1/tests/simple-true.R' ... OK
  comparing 'simple-true.Rout' to '/scratch/novosirj/install-files/R-4.0.1/tests/simple-true.Rout.save' ... OK
running code in '/scratch/novosirj/install-files/R-4.0.1/tests/arith-true.R' ... OK
  comparing 'arith-true.Rout' to '/scratch/novosirj/install-files/R-4.0.1/tests/arith-true.Rout.save' ... OK
running code in '/scratch/novosirj/install-files/R-4.0.1/tests/arith.R' ... OK
  comparing 'arith.Rout' to '/scratch/novosirj/install-files/R-4.0.1/tests/arith.Rout.save' ... OK
running code in '/scratch/novosirj/install-files/R-4.0.1/tests/lm-tests.R' ... OK
  comparing 'lm-tests.Rout' to '/scratch/novosirj/install-files/R-4.0.1/tests/lm-tests.Rout.save' ... OK
/bin/sh: line 1: 62064 Segmentation fault      (core dumped) LANGUAGE=en LC_ALL=C SRCDIR=/scratch/novosirj/install-files/R-4.0.1/tests R_DEFAULT_PACKAGES= ../bin/R --vanilla < /scratch/novosirj/install-files/R-4.0.1/tests/ok-errors.R > ok-errors.Rout.fail 2>&1
running code in '/scratch/novosirj/install-files/R-4.0.1/tests/ok-errors.R' ...make[2]: *** [ok-errors.Rout] Error 1
make[2]: Leaving directory `/mnt/scratch/novosirj/R-4.0.1-intel-19.1-build/tests'
make[1]: *** [test-Specific] Error 2
make[1]: Leaving directory `/mnt/scratch/novosirj/R-4.0.1-intel-19.1-build/tests'
make: *** [test-all-basics] Error 1

Is this something I should be concerned about, or something I can fix? Not seeing any real information about what?s going wrong here. Here?s what?s contained in ok-errors.Rout.fail:

---
R version 4.0.1 (2020-06-06) -- "See Things Now"
Copyright (C) 2020 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #### STRICT test suite in the spirit of no-segfaults,
> #### but with explicit statements.
>
> options(error=expression(NULL))
> stop("test of `options(error=expression(NULL))'")
Error: test of `options(error=expression(NULL))'
>
> if(FALSE) {
+ ## these ought to work on machines with enough memory
+ ## These segfaulted in 1.3.x ,  give "could not allocate" errors now
+   integer(2^30+1)
+    double(2^30+1)
+   complex(2^30+1)
+ character(2^30+1)
+ vector("list", 2^30+2)
+ }
>
> ## bad infinite recursion / on.exit / ... interactions
> ##   catch the error to permit different error messages emitted
> ##   (handling of infinite recursion is different in the AST interpreter
> ##   and the byte-code interpreter)
>
> bar <- function() 1+1
> foo <- function() { on.exit(bar()); foo() }
> tryCatch(foo(), error=function(x) TRUE) # now simple "infinite recursion"

 *** caught segfault ***
address 0x7fff4dc1b9f8, cause 'memory not mapped'

Traceback:
 1: foo()
 2: foo()
 3: foo()
 4: foo()

...

2712: foo()
2713: foo()
2714: foo()
2715: foo()
2716: foo()
2717: foo()
2718: foo()
2719: doTryCatch(return(expr), name, parentenv, handler)
2720: tryCatchOne(expr, names, parentenv, handlers[[1L]])
2721: tryCatchList(expr, classes, parentenv, handlers)
2722: tryCatch(foo(), error = function(x) TRUE)
An irrecoverable exception occurred. R is aborting now ...
---

Thanks in advance.

--
____
|| \\UTGERS,  	 |---------------------------*O*---------------------------
||_// the State	 |         Ryan Novosielski - novosirj at rutgers.edu
|| \\ University | Sr. Technologist - 973/972.0922 (2x0922) ~*~ RBHS Campus
||  \\    of NJ	 | Office of Advanced Research Computing - MSB C630, Newark
     `'


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 195 bytes
Desc: Message signed with OpenPGP
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200614/e62d9041/attachment.sig>

From ph@t@ch@u @end|ng |rom m@||@utoronto@c@  Sun Jun 14 14:57:18 2020
From: ph@t@ch@u @end|ng |rom m@||@utoronto@c@ (Phat Chau)
Date: Sun, 14 Jun 2020 12:57:18 +0000
Subject: [R] Convergence in Monte Carlo Simulation
In-Reply-To: <7553d0bd-1e5d-51a0-1a47-e16a0b236b1e@dewey.myzen.co.uk>
References: <9F0BC01E-F5CB-464A-852C-A7AB684F3F9F@mail.utoronto.ca>
 <7553d0bd-1e5d-51a0-1a47-e16a0b236b1e@dewey.myzen.co.uk>
Message-ID: <2EF798EB-576D-413A-A77A-43DD69265054@mail.utoronto.ca>

Thank you Michael. 

I will clarify some more. The function in the first part of the code that I posted generates the simulated dataset for a cluster randomized trial from the simstudy package. 

I am not quite clear what you mean by placing it outside the loop. So the goal here is to create n = 1000 independent datasets with different (randomly drawn values from the specified normal distributions not shown) for all of the parameters. What I have tried to do is place the seed at the very top of all my code in the past, but what that does is it leads to the creation of a single dataset that gets repeated over and over n = 1000 times. Hence, there ends up being no variability in the data (and power estimates from the p-values given the stated and required power). 

Regarding the counter, is it correct in this instance that the loop will continue until n = 1000 iterations have successfully converged? I am not so concerned with counting failures.

Thank you.
Edward

?On 2020-06-14, 6:46 AM, "Michael Dewey" <lists at dewey.myzen.co.uk> wrote:

    I am not 100% clear what your code is doing as it gets a bit wangled as 
    you posted in HTML but here are a couple of thoughts.
    
    You need to set the seed outside any loops so it happens once and for all.
    
    I would test after trycatch and keep a separate count of failures and 
    successes as the failure to converge must be meaningful about the 
    scientific question whatever that is. At the moment your count appears 
    to be in the correct place to count successes.
    
    Michael
    
    On 14/06/2020 02:50, Phat Chau wrote:
    > Hello,
    > 
    > I put together the following code and am curious about its correctness. My first question relates to the Monte Carlo simulations ? the goal is to continue to iterate until I get n = 1000 simulations where the model successfully converges. I am wondering if I coded it correctly below with the while loop. Is the idea that the counter increments by one only if ?model? does not return a string?
    > 
    > I would also like to know how I can create n = 1000 independent data sets. I think to do this, I would have to set a random number seed via set.seed() before the creation of each dataset. Where would I enter set.seed in the syntax below? Would it be in the function (as indicated in red)?
    > 
    > powercrosssw <- function(nclus, clsize) {
    > 
    >    set.seed()
    > 
    >    cohortsw <- genData(nclus, id = "cluster")
    >    cohortsw <- addColumns(clusterDef, cohortsw)
    >    cohortswTm <- addPeriods(cohortsw, nPeriods = 8, idvars = "cluster", perName = "period")
    >    cohortstep <- trtStepWedge(cohortswTm, "cluster", nWaves = 4, lenWaves = 1, startPer = 1, grpName = "Ijt")
    > 
    >    pat <- genCluster(cohortswTm, cLevelVar = "timeID", numIndsVar = clsize, level1ID = "id")
    > 
    >    dx <- merge(pat[, .(cluster, period, id)], cohortstep, by = c("cluster", "period"))
    >    dx <- addColumns(patError, dx)
    > 
    >    setkey(dx, id, cluster, period)
    > 
    >    dx <- addColumns(outDef, dx)
    > 
    >    return(dx)
    > 
    > }
    > 
    > i=1
    > 
    > while (i < 1000) {
    > 
    >    dx <- powercrosssw()
    > 
    >    #Fit multi-level model to simulated dataset
    >    model5 <- tryCatch(lme(y ~ factor(period) + factor(Ijt), data = dx, random = ~1|cluster, method = "REML"),
    >                       warning = function(w) { "warning" }
    >    )
    > 
    >    if (! is.character(model5)) {
    > 
    >      coeff <- coef(summary(model5))["factor(Ijt)1", "Value"]
    >      pvalue <- coef(summary(model5))["factor(Ijt)1", "p-value"]
    >      error <- coef(summary(model5))["factor(Ijt)1", "Std.Error"]
    >      bresult <- c(bresult, coeff)
    >      presult <- c(presult, pvalue)
    >      eresult <- c(eresult, error)
    > 
    >      i <- i + 1
    >    }
    > }
    > 
    > Thank you so much.
    > 
    > 
    > 
    > 	[[alternative HTML version deleted]]
    > 
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    > 
    > 
    
    -- 
    Michael
    http://www.dewey.myzen.co.uk/home.html
    


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Sun Jun 14 16:16:13 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Sun, 14 Jun 2020 15:16:13 +0100
Subject: [R] Convergence in Monte Carlo Simulation
In-Reply-To: <2EF798EB-576D-413A-A77A-43DD69265054@mail.utoronto.ca>
References: <9F0BC01E-F5CB-464A-852C-A7AB684F3F9F@mail.utoronto.ca>
 <7553d0bd-1e5d-51a0-1a47-e16a0b236b1e@dewey.myzen.co.uk>
 <2EF798EB-576D-413A-A77A-43DD69265054@mail.utoronto.ca>
Message-ID: <a799b060-3728-96f6-7415-b9d9776e42e9@dewey.myzen.co.uk>

Dear Edward

Every time you call your function powercrosssw() it resets the seed so 
you must be calling it multiple times in some way.

Michael

On 14/06/2020 13:57, Phat Chau wrote:
> Thank you Michael.
> 
> I will clarify some more. The function in the first part of the code that I posted generates the simulated dataset for a cluster randomized trial from the simstudy package.
> 
> I am not quite clear what you mean by placing it outside the loop. So the goal here is to create n = 1000 independent datasets with different (randomly drawn values from the specified normal distributions not shown) for all of the parameters. What I have tried to do is place the seed at the very top of all my code in the past, but what that does is it leads to the creation of a single dataset that gets repeated over and over n = 1000 times. Hence, there ends up being no variability in the data (and power estimates from the p-values given the stated and required power).
> 
> Regarding the counter, is it correct in this instance that the loop will continue until n = 1000 iterations have successfully converged? I am not so concerned with counting failures.
> 
> Thank you.
> Edward
> 
> ?On 2020-06-14, 6:46 AM, "Michael Dewey" <lists at dewey.myzen.co.uk> wrote:
> 
>      I am not 100% clear what your code is doing as it gets a bit wangled as
>      you posted in HTML but here are a couple of thoughts.
>      
>      You need to set the seed outside any loops so it happens once and for all.
>      
>      I would test after trycatch and keep a separate count of failures and
>      successes as the failure to converge must be meaningful about the
>      scientific question whatever that is. At the moment your count appears
>      to be in the correct place to count successes.
>      
>      Michael
>      
>      On 14/06/2020 02:50, Phat Chau wrote:
>      > Hello,
>      >
>      > I put together the following code and am curious about its correctness. My first question relates to the Monte Carlo simulations ? the goal is to continue to iterate until I get n = 1000 simulations where the model successfully converges. I am wondering if I coded it correctly below with the while loop. Is the idea that the counter increments by one only if ?model? does not return a string?
>      >
>      > I would also like to know how I can create n = 1000 independent data sets. I think to do this, I would have to set a random number seed via set.seed() before the creation of each dataset. Where would I enter set.seed in the syntax below? Would it be in the function (as indicated in red)?
>      >
>      > powercrosssw <- function(nclus, clsize) {
>      >
>      >    set.seed()
>      >
>      >    cohortsw <- genData(nclus, id = "cluster")
>      >    cohortsw <- addColumns(clusterDef, cohortsw)
>      >    cohortswTm <- addPeriods(cohortsw, nPeriods = 8, idvars = "cluster", perName = "period")
>      >    cohortstep <- trtStepWedge(cohortswTm, "cluster", nWaves = 4, lenWaves = 1, startPer = 1, grpName = "Ijt")
>      >
>      >    pat <- genCluster(cohortswTm, cLevelVar = "timeID", numIndsVar = clsize, level1ID = "id")
>      >
>      >    dx <- merge(pat[, .(cluster, period, id)], cohortstep, by = c("cluster", "period"))
>      >    dx <- addColumns(patError, dx)
>      >
>      >    setkey(dx, id, cluster, period)
>      >
>      >    dx <- addColumns(outDef, dx)
>      >
>      >    return(dx)
>      >
>      > }
>      >
>      > i=1
>      >
>      > while (i < 1000) {
>      >
>      >    dx <- powercrosssw()
>      >
>      >    #Fit multi-level model to simulated dataset
>      >    model5 <- tryCatch(lme(y ~ factor(period) + factor(Ijt), data = dx, random = ~1|cluster, method = "REML"),
>      >                       warning = function(w) { "warning" }
>      >    )
>      >
>      >    if (! is.character(model5)) {
>      >
>      >      coeff <- coef(summary(model5))["factor(Ijt)1", "Value"]
>      >      pvalue <- coef(summary(model5))["factor(Ijt)1", "p-value"]
>      >      error <- coef(summary(model5))["factor(Ijt)1", "Std.Error"]
>      >      bresult <- c(bresult, coeff)
>      >      presult <- c(presult, pvalue)
>      >      eresult <- c(eresult, error)
>      >
>      >      i <- i + 1
>      >    }
>      > }
>      >
>      > Thank you so much.
>      >
>      >
>      >
>      > 	[[alternative HTML version deleted]]
>      >
>      > ______________________________________________
>      > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>      > https://stat.ethz.ch/mailman/listinfo/r-help
>      > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>      > and provide commented, minimal, self-contained, reproducible code.
>      >
>      >
>      
>      --
>      Michael
>      http://www.dewey.myzen.co.uk/home.html
>      
> 
> 
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From jr@| @end|ng |rom po@teo@no  Mon Jun 15 13:27:50 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Mon, 15 Jun 2020 13:27:50 +0200
Subject: [R] if else statement adjustemtn
In-Reply-To: <CA+8X3fU6-wp1cT3Ox6+idUvu7wL2M9THbLBDsewUB-8_Vja-Nw@mail.gmail.com>
References: <CAF9-5jMVc9jhfj-x2NW96=MoQ_0zyRDoupJTD28M_aEkOvM-ag@mail.gmail.com>
 <CA+8X3fVQDKyL4jA+E1MPQP=x3aTe9zzm-me9WNWEFZCKUQtgQA@mail.gmail.com>
 <CAF9-5jNeKhEaDBdsVrAzdekfiaU0jwcCwCy-D4pHe7-JN4sw+g@mail.gmail.com>
 <CA+8X3fXDJUv=mPu6SMSg_O=ra-4QgT+JBjdPsS0CqDUai2fgSg@mail.gmail.com>
 <20200613022837.GD723678@posteo.no>
 <CAF9-5jO+Q6Q6-WuvjmUWH6-gTL_cZXwugteZiEr-CZWwnfd-hw@mail.gmail.com>
 <CA+8X3fX+iErrBMM+cr2Rypo7n3dN6PSJW6Lwc7XmpREDHa3VMQ@mail.gmail.com>
 <CAF9-5jPxnKNYuivUhgq6Pq408BEOYHjrVfrQ_YDTQJF5mcB_CA@mail.gmail.com>
 <CA+8X3fU6-wp1cT3Ox6+idUvu7wL2M9THbLBDsewUB-8_Vja-Nw@mail.gmail.com>
Message-ID: <20200615112750.GB8864@posteo.no>

On 2020-06-13 19:09 +1000, Jim Lemon wrote:
> Right, back from shopping. Since you have fourteen rows containing NAs
> and you only want seven, we can infer that half of them must go. As
> they are neatly divided into seven rows in which only one NA appears
> and seven in which two stare meaninglessly out at us. I will assume
> that the latter are the ones to be discarded. As your condition for
> calculating "pheno" stated that a 2 in either FLASER or PLASER should
> result in a 2 in pheno, the following statement closely conforms to
> that:
> 
> b<-read.table(text="FID   IID FLASER PLASER
>   fam1837 G1837      1     NA
>   fam2410 G2410     NA     NA
>   fam2838 G2838     NA      2
>   fam3367 G3367      1     NA
>   fam3410 G3410      1     NA
>   fam3492 G3492      1     NA
>   fam0911  G911     NA     NA
>   fam3834 G3834      2     NA
>   fam4708 G4708     NA      2
>   fam5162 G5162     NA     NA
>   fam5274 G5274     NA     NA
>   fam0637  G637     NA     NA
>   fam0640  G640     NA     NA
>   fam0743  G743     NA     NA
>   fam0911  G911     NA     NA",
>   header=TRUE,stringsAsFactors=FALSE)
> 
> b$pheno<-ifelse(b$FLASER == 2 | b$PLASER == 2,2,1)
> # use the valid FLASER values when PLASER is NA
> b[is.na(b$pheno),]$pheno<-ifelse(!is.na(b[is.na(b$pheno),]$FLASER),
>  b[is.na(b$pheno),]$FLASER,NA)
> # use the valid PLASER values when FLASER if NA
> b[is.na(b$pheno),]$pheno<-ifelse(!is.na(b[is.na(b$pheno),]$PLASER),
>  b[is.na(b$pheno),]$PLASER,NA)
> b
> 
> I could write that mess in one straitjacket of conditional statements
> but my brain hurts enough.

I think this answer is billiant!

Here's a picture of my laptop screen out in my local park 
yesterday as I was trying to figure this out

https://mega.nz/#!OERQFSgL!McUkMYwkrcQXN148Wr11K1xRHSTOWVFfz4gRwaZYLzM

I have nothing more to add at the moment :)

/Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200615/8cba0334/attachment.sig>

From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Jun 15 14:46:38 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 15 Jun 2020 14:46:38 +0200
Subject: [R] Rstudio does not run on ubuntu 20
Message-ID: <CAMk+s2Qs-eiy9wJcOuVna8gPajj8AnuSi11Ty27eDUbmrK12Pw@mail.gmail.com>

Hello,
all of a sudden rstudio stopped working on ubuntu 20.04. I
re-installed from `rstudio-1.3.959-amd64.deb` but it does not launch
even if there is an icon. On terminal I got:
```
$ rstudio
rstudio: error while loading shared libraries: libssl.so.1.0.0: cannot
open shared object file: No such file or directory
$ sudo apt-get install libssl1.0.0 libssl-dev
Reading package lists... Done
Building dependency tree
Reading state information... Done
Package libssl1.0.0 is not available, but is referred to by another package.
This may mean that the package is missing, has been obsoleted, or
is only available from another source

E: Package 'libssl1.0.0' has no installation candidate

```
On internet, it is said that this library was discontinued
(https://askubuntu.com/questions/897444/libssl-so-1-0-0-is-missing)
R is up and running instead:
```
$ R
R version 4.0.1 (2020-06-06) -- "See Things Now"
Copyright (C) 2020 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

```
How can I launch studio then?
-- 
Best regards,
Luigi


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Mon Jun 15 15:26:08 2020
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Mon, 15 Jun 2020 15:26:08 +0200
Subject: [R] Rstudio does not run on ubuntu 20
In-Reply-To: <CAMk+s2Qs-eiy9wJcOuVna8gPajj8AnuSi11Ty27eDUbmrK12Pw@mail.gmail.com>
References: <CAMk+s2Qs-eiy9wJcOuVna8gPajj8AnuSi11Ty27eDUbmrK12Pw@mail.gmail.com>
Message-ID: <24295.30448.278813.362314@stat.math.ethz.ch>

>>>>> Luigi Marongiu 
>>>>>     on Mon, 15 Jun 2020 14:46:38 +0200 writes:

    > Hello,
    > all of a sudden rstudio stopped working on ubuntu 20.04. I
    > re-installed from `rstudio-1.3.959-amd64.deb` but it does not launch
    > even if there is an icon. On terminal I got:
    > ```
    > $ rstudio
    > rstudio: error while loading shared libraries: libssl.so.1.0.0: cannot
    > open shared object file: No such file or directory
    > $ sudo apt-get install libssl1.0.0 libssl-dev
    > Reading package lists... Done
    > Building dependency tree
    > Reading state information... Done
    > Package libssl1.0.0 is not available, but is referred to by another package.
    > This may mean that the package is missing, has been obsoleted, or
    > is only available from another source

    > E: Package 'libssl1.0.0' has no installation candidate

    > ```
    > On internet, it is said that this library was discontinued
    > (https://askubuntu.com/questions/897444/libssl-so-1-0-0-is-missing)
    > R is up and running instead:
    > ```
    > $ R
    > R version 4.0.1 (2020-06-06) -- "See Things Now"
    > Copyright (C) 2020 The R Foundation for Statistical Computing
    > Platform: x86_64-pc-linux-gnu (64-bit)

    > ```
    > How can I launch studio then?

you don't.  Use R ! ..

Well, I'm mostly joking.  Personally, I do use Rstudio very
rarely (but R daily, 85% of my work time), but then I'm a
co-author of ESS (Emacs Speaks Statistics) and have been an
emacs lover since ~1988 ..

It's good, Luigi, we (all R-help readers) now know about the problem.
But this mailing list is about R (and the R project). Rstudio is
a company and a product has their own support list.
Though I'm sure they will get the message from here or otherwise
anyway.

Do keep using Linux, it's well worth the occasional small
pain.  It allows you to smell the true original fresh air if you
want instead of having to breathe continuously being wrapped
inside  sugar candy.
At home and at work, I have no computer but those running Linux
(even though I'm occasionally glad to have access to a Windows
 terminal server at work, not the least to test R and packages,
 almost always using ESS also there)!

Best wishes,
Martin

--
Martin <Maechler at stat.math.ethz.ch>   http://stat.ethz.ch/~maechler
Seminar f?r Statistik, ETH Z?rich     HG G 16       R?mistrasse 101
CH-8092 Zurich, SWITZERLAND           ? +41 44 632 3408        <><


From th|erry@onke||nx @end|ng |rom |nbo@be  Mon Jun 15 15:27:25 2020
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Mon, 15 Jun 2020 15:27:25 +0200
Subject: [R] Rstudio does not run on ubuntu 20
In-Reply-To: <CAMk+s2Qs-eiy9wJcOuVna8gPajj8AnuSi11Ty27eDUbmrK12Pw@mail.gmail.com>
References: <CAMk+s2Qs-eiy9wJcOuVna8gPajj8AnuSi11Ty27eDUbmrK12Pw@mail.gmail.com>
Message-ID: <CAJuCY5ywWsv82fJ1TJzrzfL2J023ABGvGs1kWDxkpuU86tjgCw@mail.gmail.com>

Dear Luigi,

This is rather an RStudio problem than an R problem. I suggest contacting
RStudio or their community help forum at https://community.rstudio.com/

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op ma 15 jun. 2020 om 14:47 schreef Luigi Marongiu <marongiu.luigi at gmail.com
>:

> Hello,
> all of a sudden rstudio stopped working on ubuntu 20.04. I
> re-installed from `rstudio-1.3.959-amd64.deb` but it does not launch
> even if there is an icon. On terminal I got:
> ```
> $ rstudio
> rstudio: error while loading shared libraries: libssl.so.1.0.0: cannot
> open shared object file: No such file or directory
> $ sudo apt-get install libssl1.0.0 libssl-dev
> Reading package lists... Done
> Building dependency tree
> Reading state information... Done
> Package libssl1.0.0 is not available, but is referred to by another
> package.
> This may mean that the package is missing, has been obsoleted, or
> is only available from another source
>
> E: Package 'libssl1.0.0' has no installation candidate
>
> ```
> On internet, it is said that this library was discontinued
> (https://askubuntu.com/questions/897444/libssl-so-1-0-0-is-missing)
> R is up and running instead:
> ```
> $ R
> R version 4.0.1 (2020-06-06) -- "See Things Now"
> Copyright (C) 2020 The R Foundation for Statistical Computing
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> ```
> How can I launch studio then?
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Jun 15 15:27:29 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 15 Jun 2020 15:27:29 +0200
Subject: [R] Rstudio does not run on ubuntu 20
In-Reply-To: <24295.30448.278813.362314@stat.math.ethz.ch>
References: <CAMk+s2Qs-eiy9wJcOuVna8gPajj8AnuSi11Ty27eDUbmrK12Pw@mail.gmail.com>
 <24295.30448.278813.362314@stat.math.ethz.ch>
Message-ID: <CAMk+s2Q_0O_fzo37PWu_wQ57eZ10aZL9Mar-TefQ0ewE_-5S9A@mail.gmail.com>

ok so I'll redirect to Rstudio...
Thanks

On Mon, Jun 15, 2020 at 3:26 PM Martin Maechler <maechler at stat.math.ethz.ch>
wrote:

> >>>>> Luigi Marongiu
> >>>>>     on Mon, 15 Jun 2020 14:46:38 +0200 writes:
>
>     > Hello,
>     > all of a sudden rstudio stopped working on ubuntu 20.04. I
>     > re-installed from `rstudio-1.3.959-amd64.deb` but it does not launch
>     > even if there is an icon. On terminal I got:
>     > ```
>     > $ rstudio
>     > rstudio: error while loading shared libraries: libssl.so.1.0.0:
> cannot
>     > open shared object file: No such file or directory
>     > $ sudo apt-get install libssl1.0.0 libssl-dev
>     > Reading package lists... Done
>     > Building dependency tree
>     > Reading state information... Done
>     > Package libssl1.0.0 is not available, but is referred to by another
> package.
>     > This may mean that the package is missing, has been obsoleted, or
>     > is only available from another source
>
>     > E: Package 'libssl1.0.0' has no installation candidate
>
>     > ```
>     > On internet, it is said that this library was discontinued
>     > (https://askubuntu.com/questions/897444/libssl-so-1-0-0-is-missing)
>     > R is up and running instead:
>     > ```
>     > $ R
>     > R version 4.0.1 (2020-06-06) -- "See Things Now"
>     > Copyright (C) 2020 The R Foundation for Statistical Computing
>     > Platform: x86_64-pc-linux-gnu (64-bit)
>
>     > ```
>     > How can I launch studio then?
>
> you don't.  Use R ! ..
>
> Well, I'm mostly joking.  Personally, I do use Rstudio very
> rarely (but R daily, 85% of my work time), but then I'm a
> co-author of ESS (Emacs Speaks Statistics) and have been an
> emacs lover since ~1988 ..
>
> It's good, Luigi, we (all R-help readers) now know about the problem.
> But this mailing list is about R (and the R project). Rstudio is
> a company and a product has their own support list.
> Though I'm sure they will get the message from here or otherwise
> anyway.
>
> Do keep using Linux, it's well worth the occasional small
> pain.  It allows you to smell the true original fresh air if you
> want instead of having to breathe continuously being wrapped
> inside  sugar candy.
> At home and at work, I have no computer but those running Linux
> (even though I'm occasionally glad to have access to a Windows
>  terminal server at work, not the least to test R and packages,
>  almost always using ESS also there)!
>
> Best wishes,
> Martin
>
> --
> Martin <Maechler at stat.math.ethz.ch>   http://stat.ethz.ch/~maechler
> Seminar f?r Statistik, ETH Z?rich     HG G 16       R?mistrasse 101
> CH-8092 Zurich, SWITZERLAND           ? +41 44 632 3408        <><
>


-- 
Best regards,
Luigi

	[[alternative HTML version deleted]]


From pro|jcn@@h @end|ng |rom gm@||@com  Mon Jun 15 15:31:45 2020
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Mon, 15 Jun 2020 09:31:45 -0400
Subject: [R] Fortune nomination!
In-Reply-To: <24295.30448.278813.362314@stat.math.ethz.ch>
References: <CAMk+s2Qs-eiy9wJcOuVna8gPajj8AnuSi11Ty27eDUbmrK12Pw@mail.gmail.com>
 <24295.30448.278813.362314@stat.math.ethz.ch>
Message-ID: <4d7f4a4a-22ab-a1f8-3a03-56f050852122@gmail.com>



On 2020-06-15 9:26 a.m., Martin Maechler wrote:
> It allows you to smell the true original fresh air if you
> want instead of having to breathe continuously being wrapped
> inside  sugar candy.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Mon Jun 15 15:44:03 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Mon, 15 Jun 2020 08:44:03 -0500
Subject: [R] if else statement adjustemtn
In-Reply-To: <CA+8X3fU6-wp1cT3Ox6+idUvu7wL2M9THbLBDsewUB-8_Vja-Nw@mail.gmail.com>
References: <CAF9-5jMVc9jhfj-x2NW96=MoQ_0zyRDoupJTD28M_aEkOvM-ag@mail.gmail.com>
 <CA+8X3fVQDKyL4jA+E1MPQP=x3aTe9zzm-me9WNWEFZCKUQtgQA@mail.gmail.com>
 <CAF9-5jNeKhEaDBdsVrAzdekfiaU0jwcCwCy-D4pHe7-JN4sw+g@mail.gmail.com>
 <CA+8X3fXDJUv=mPu6SMSg_O=ra-4QgT+JBjdPsS0CqDUai2fgSg@mail.gmail.com>
 <20200613022837.GD723678@posteo.no>
 <CAF9-5jO+Q6Q6-WuvjmUWH6-gTL_cZXwugteZiEr-CZWwnfd-hw@mail.gmail.com>
 <CA+8X3fX+iErrBMM+cr2Rypo7n3dN6PSJW6Lwc7XmpREDHa3VMQ@mail.gmail.com>
 <CAF9-5jPxnKNYuivUhgq6Pq408BEOYHjrVfrQ_YDTQJF5mcB_CA@mail.gmail.com>
 <CA+8X3fU6-wp1cT3Ox6+idUvu7wL2M9THbLBDsewUB-8_Vja-Nw@mail.gmail.com>
Message-ID: <CAF9-5jNeaZ+62z4OQj+qytcg-aW_6O+pVP1ezBu+m6w9AAdxHg@mail.gmail.com>

HI Jim

thank you so much! This is amazing answer!!!

Ana

On Sat, Jun 13, 2020 at 4:09 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Right, back from shopping. Since you have fourteen rows containing NAs
> and you only want seven, we can infer that half of them must go. As
> they are neatly divided into seven rows in which only one NA appears
> and seven in which two stare meaninglessly out at us. I will assume
> that the latter are the ones to be discarded. As your condition for
> calculating "pheno" stated that a 2 in either FLASER or PLASER should
> result in a 2 in pheno, the following statement closely conforms to
> that:
>
> b<-read.table(text="FID   IID FLASER PLASER
>   fam1837 G1837      1     NA
>   fam2410 G2410     NA     NA
>   fam2838 G2838     NA      2
>   fam3367 G3367      1     NA
>   fam3410 G3410      1     NA
>   fam3492 G3492      1     NA
>   fam0911  G911     NA     NA
>   fam3834 G3834      2     NA
>   fam4708 G4708     NA      2
>   fam5162 G5162     NA     NA
>   fam5274 G5274     NA     NA
>   fam0637  G637     NA     NA
>   fam0640  G640     NA     NA
>   fam0743  G743     NA     NA
>   fam0911  G911     NA     NA",
>   header=TRUE,stringsAsFactors=FALSE)
>
> b$pheno<-ifelse(b$FLASER == 2 | b$PLASER == 2,2,1)
> # use the valid FLASER values when PLASER is NA
> b[is.na(b$pheno),]$pheno<-ifelse(!is.na(b[is.na(b$pheno),]$FLASER),
>  b[is.na(b$pheno),]$FLASER,NA)
> # use the valid PLASER values when FLASER if NA
> b[is.na(b$pheno),]$pheno<-ifelse(!is.na(b[is.na(b$pheno),]$PLASER),
>  b[is.na(b$pheno),]$PLASER,NA)
> b
>
> I could write that mess in one straitjacket of conditional statements
> but my brain hurts enough.
>
> Jim
>
>
> On Sat, Jun 13, 2020 at 1:59 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Great idea!
> > Here it is:
> > > b[is.na(b$FLASER) | is.na(b$PLASER),]
> >         FID   IID FLASER PLASER pheno
> >  1: fam1837 G1837      1     NA     2
> >  2: fam2410 G2410     NA     NA     2
> >  3: fam2838 G2838     NA      2     2
> >  4: fam3367 G3367      1     NA     2
> >  5: fam3410 G3410      1     NA     2
> >  6: fam3492 G3492      1     NA     2
> >  7: fam3834 G3834      2     NA     2
> >  8: fam4708 G4708     NA      2     2
> >  9: fam5162 G5162     NA     NA     2
> > 10: fam5274 G5274     NA     NA     2
> > 11: fam0637  G637     NA     NA     2
> > 12: fam0640  G640     NA     NA     2
> > 13: fam0743  G743     NA     NA     2
> > 14: fam0911  G911     NA     NA     2
> >
> > On Fri, Jun 12, 2020 at 10:29 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> > >
> > > Since you have only a few troublesome NA values, if you look at them,
> > > or even better, post them:
> > >
> > > b[is.na(b$FLASER) | is.na(b$PLASER),]
> > >
> > > perhaps we can work out the appropriate logic to get rid of only the
> > > ones you don't want.
> > >
> > > Jim
> > >
> > > On Sat, Jun 13, 2020 at 12:50 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> > > >
> > > > Hi Rasmus,
> > > >
> > > > thank you for getting back to be, the command your provided seems to
> > > > add all 11 NAs to 2s
> > > > > b$pheno <-
> > > > +           ifelse(b$PLASER==2 |
> > > > +                  b$FLASER==2 |
> > > > +                  is.na(b$PLASER) |
> > > > +                  is.na(b$PLASER) & b$FLASER %in% 1:2 |
> > > > +                  is.na(b$FLASER) & b$PLASER == 2,
> > > > +                  2, 1)
> > > > >         table(b$pheno, exclude = NULL)
> > > >
> > > >   1   2
> > > > 859 839
> > > >
> > > > Once again my desired results is to keep these 7 NAs as NAs
> > > > > table(b$PLASER,b$FLASER, exclude = NULL)
> > > >
> > > >          1   2   3 <NA>
> > > >   1    836  14   0    0
> > > >   2    691  70  43    2
> > > >   3      2   7  21    0
> > > >   <NA>   4   1   0    7
> > > >
> > > > and have
> > > > 825 2s (825=691+14+70+7+43)
> > > > and the rest would be 1s (866=1698-7-825)
> > > >
> > > > On Fri, Jun 12, 2020 at 9:29 PM Rasmus Liland <jral at posteo.no> wrote:
> > > > >
> > > > > On 2020-06-13 11:30 +1000, Jim Lemon wrote:
> > > > > > On Fri, Jun 12, 2020 at 8:06 PM Jim Lemon wrote:
> > > > > > > On Sat, Jun 13, 2020 at 10:46 AM Ana Marija wrote:
> > > > > > > >
> > > > > > > > I am trying to make a new column
> > > > > > > > "pheno" so that I reduce the number
> > > > > > > > of NAs
> > > > > > >
> > > > > > > it looks like those two NA values in
> > > > > > > PLASER are the ones you want to drop.
> > > > > >
> > > > > > From just your summary table, it's hard to
> > > > > > guess the distribution of NA values.
> > > > >
> > > > > Dear Ana,
> > > > >
> > > > > This small sample
> > > > >
> > > > >         b <- read.table(text="FLASER;PLASER
> > > > >         1;2
> > > > >         ;2
> > > > >         ;
> > > > >         1;
> > > > >         2;
> > > > >         2;2
> > > > >         3;2
> > > > >         3;3
> > > > >         1;1", sep=";", header=TRUE)
> > > > >
> > > > >         table(b$PLASER,b$FLASER, exclude = NULL)
> > > > >
> > > > > yields the same combinations you showed
> > > > > earlier:
> > > > >
> > > > >                1 2 3 <NA>
> > > > >           1    1 0 0    0
> > > > >           2    1 1 1    1
> > > > >           3    0 0 1    0
> > > > >           <NA> 1 1 0    1
> > > > >
> > > > > If you want to eliminate the four <NA>-based
> > > > > combinations completely, this line
> > > > >
> > > > >         b$pheno <-
> > > > >           ifelse(b$PLASER==2 |
> > > > >                  b$FLASER==2 |
> > > > >                  is.na(b$PLASER) |
> > > > >                  is.na(b$PLASER) & b$FLASER %in% 1:2 |
> > > > >                  is.na(b$FLASER) & b$PLASER == 2,
> > > > >                  2, 1)
> > > > >         table(b$pheno, exclude = NULL)
> > > > >
> > > > > will do it:
> > > > >
> > > > >         1 2
> > > > >         2 7
> > > > >
> > > > > Best,
> > > > > Rasmus
> > > > > ______________________________________________
> > > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > > and provide commented, minimal, self-contained, reproducible code.
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.


From ph@t@ch@u @end|ng |rom m@||@utoronto@c@  Mon Jun 15 14:19:38 2020
From: ph@t@ch@u @end|ng |rom m@||@utoronto@c@ (Phat Chau)
Date: Mon, 15 Jun 2020 12:19:38 +0000
Subject: [R] Convergence in Monte Carlo Simulation
In-Reply-To: <a799b060-3728-96f6-7415-b9d9776e42e9@dewey.myzen.co.uk>
References: <9F0BC01E-F5CB-464A-852C-A7AB684F3F9F@mail.utoronto.ca>
 <7553d0bd-1e5d-51a0-1a47-e16a0b236b1e@dewey.myzen.co.uk>
 <2EF798EB-576D-413A-A77A-43DD69265054@mail.utoronto.ca>
 <a799b060-3728-96f6-7415-b9d9776e42e9@dewey.myzen.co.uk>
Message-ID: <A6DEEF4D-1C30-4185-9BB3-C4B7DBB458AA@mail.utoronto.ca>

Dear Michael, 

So I shouldn't be setting the seed at all then since it is automatic? Or is the suggestion here that a new seed is chosen each time?

I think rather than having you guess at the problem (my apologies) I will post the entire of the code (with omissions where it is not directly impacting the problem at hand). Sometimes I hesitate to post huge blocks because it can be a bit daunting, but I realize in coding that even the smallest glitch can throw everything off.

Set.seed(123) <<<Placing the seed here leads to no variation at all in my simulations as noted previously 

clusterDef <- defDataAdd(varname = "u_3", dist = "normal", formula = 0, variance = 25.77) 
patDef <- defDataAdd(varname = "u_2", dist = "normal", formula = 0, variance = 120.62) 
patError <- defDataAdd(varname = "error", dist = "normal", formula = 0, variance = 38.35) 

...(Data definition code omitted)

setkey(patTm, id, cluster, period)

#Define outcome y 
outDef <- defDataAdd(varname = "y", formula = "17.87 + 5.0*Ijt - 5.42*I(period == 1) - 5.72*I(period == 2) - 7.03*I(period == 3) - 6.13*I(period == 4) - 9.13*I(period == 5) + u_3 + u_2 + error", dist = "normal")

patTm <- addColumns(outDef, patTm)

powercrosssw <- function(nclus, clsize) {
	
	set.seed() < not sure if placing it the function rather than at the top is appropriate to generate a new and independent dataset for each of the 1000 iterations

Regarding the convergence issue, it seems that what you are saying is I have it all set up correctly (i.e. it will iterate until 1000 iterations converge). I do get this rather peculiar error though in some cases:

Error in lme.formula(y ~ factor(period) + factor(Ijt), data = patTm, random = ~1 |  : 
  nlminb problem, convergence error code = 1
  message = false convergence (8)

I am not quite sure what the problem is there.

Edward


?On 2020-06-14, 10:16 AM, "Michael Dewey" <lists at dewey.myzen.co.uk> wrote:

    Dear Edward
    
    Every time you call your function powercrosssw() it resets the seed so 
    you must be calling it multiple times in some way.
    
    Michael
    
    On 14/06/2020 13:57, Phat Chau wrote:
    > Thank you Michael.
    > 
    > I will clarify some more. The function in the first part of the code that I posted generates the simulated dataset for a cluster randomized trial from the simstudy package.
    > 
    > I am not quite clear what you mean by placing it outside the loop. So the goal here is to create n = 1000 independent datasets with different (randomly drawn values from the specified normal distributions not shown) for all of the parameters. What I have tried to do is place the seed at the very top of all my code in the past, but what that does is it leads to the creation of a single dataset that gets repeated over and over n = 1000 times. Hence, there ends up being no variability in the data (and power estimates from the p-values given the stated and required power).
    > 
    > Regarding the counter, is it correct in this instance that the loop will continue until n = 1000 iterations have successfully converged? I am not so concerned with counting failures.
    > 
    > Thank you.
    > Edward
    > 
    > On 2020-06-14, 6:46 AM, "Michael Dewey" <lists at dewey.myzen.co.uk> wrote:
    > 
    >      I am not 100% clear what your code is doing as it gets a bit wangled as
    >      you posted in HTML but here are a couple of thoughts.
    >      
    >      You need to set the seed outside any loops so it happens once and for all.
    >      
    >      I would test after trycatch and keep a separate count of failures and
    >      successes as the failure to converge must be meaningful about the
    >      scientific question whatever that is. At the moment your count appears
    >      to be in the correct place to count successes.
    >      
    >      Michael
    >      
    >      On 14/06/2020 02:50, Phat Chau wrote:
    >      > Hello,
    >      >
    >      > I put together the following code and am curious about its correctness. My first question relates to the Monte Carlo simulations ? the goal is to continue to iterate until I get n = 1000 simulations where the model successfully converges. I am wondering if I coded it correctly below with the while loop. Is the idea that the counter increments by one only if ?model? does not return a string?
    >      >
    >      > I would also like to know how I can create n = 1000 independent data sets. I think to do this, I would have to set a random number seed via set.seed() before the creation of each dataset. Where would I enter set.seed in the syntax below? Would it be in the function (as indicated in red)?
    >      >
    >      > powercrosssw <- function(nclus, clsize) {
    >      >
    >      >    set.seed()
    >      >
    >      >    cohortsw <- genData(nclus, id = "cluster")
    >      >    cohortsw <- addColumns(clusterDef, cohortsw)
    >      >    cohortswTm <- addPeriods(cohortsw, nPeriods = 8, idvars = "cluster", perName = "period")
    >      >    cohortstep <- trtStepWedge(cohortswTm, "cluster", nWaves = 4, lenWaves = 1, startPer = 1, grpName = "Ijt")
    >      >
    >      >    pat <- genCluster(cohortswTm, cLevelVar = "timeID", numIndsVar = clsize, level1ID = "id")
    >      >
    >      >    dx <- merge(pat[, .(cluster, period, id)], cohortstep, by = c("cluster", "period"))
    >      >    dx <- addColumns(patError, dx)
    >      >
    >      >    setkey(dx, id, cluster, period)
    >      >
    >      >    dx <- addColumns(outDef, dx)
    >      >
    >      >    return(dx)
    >      >
    >      > }
    >      >
    >      > i=1
    >      >
    >      > while (i < 1000) {
    >      >
    >      >    dx <- powercrosssw()
    >      >
    >      >    #Fit multi-level model to simulated dataset
    >      >    model5 <- tryCatch(lme(y ~ factor(period) + factor(Ijt), data = dx, random = ~1|cluster, method = "REML"),
    >      >                       warning = function(w) { "warning" }
    >      >    )
    >      >
    >      >    if (! is.character(model5)) {
    >      >
    >      >      coeff <- coef(summary(model5))["factor(Ijt)1", "Value"]
    >      >      pvalue <- coef(summary(model5))["factor(Ijt)1", "p-value"]
    >      >      error <- coef(summary(model5))["factor(Ijt)1", "Std.Error"]
    >      >      bresult <- c(bresult, coeff)
    >      >      presult <- c(presult, pvalue)
    >      >      eresult <- c(eresult, error)
    >      >
    >      >      i <- i + 1
    >      >    }
    >      > }
    >      >
    >      > Thank you so much.
    >      >
    >      >
    >      >
    >      > 	[[alternative HTML version deleted]]
    >      >
    >      > ______________________________________________
    >      > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >      > https://stat.ethz.ch/mailman/listinfo/r-help
    >      > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >      > and provide commented, minimal, self-contained, reproducible code.
    >      >
    >      >
    >      
    >      --
    >      Michael
    >      http://www.dewey.myzen.co.uk/home.html
    >      
    > 
    > 
    > 
    
    -- 
    Michael
    http://www.dewey.myzen.co.uk/home.html
    


From edd @end|ng |rom deb|@n@org  Mon Jun 15 16:03:03 2020
From: edd @end|ng |rom deb|@n@org (Dirk Eddelbuettel)
Date: Mon, 15 Jun 2020 09:03:03 -0500
Subject: [R] Rstudio does not run on ubuntu 20
In-Reply-To: <CAMk+s2Qs-eiy9wJcOuVna8gPajj8AnuSi11Ty27eDUbmrK12Pw@mail.gmail.com>
References: <CAMk+s2Qs-eiy9wJcOuVna8gPajj8AnuSi11Ty27eDUbmrK12Pw@mail.gmail.com>
Message-ID: <24295.32663.708854.711638@rob.eddelbuettel.com>


On 15 June 2020 at 14:46, Luigi Marongiu wrote:
| Hello,
| all of a sudden rstudio stopped working on ubuntu 20.04. I
| re-installed from `rstudio-1.3.959-amd64.deb` but it does not launch
| even if there is an icon. On terminal I got:
| ```
| $ rstudio
| rstudio: error while loading shared libraries: libssl.so.1.0.0: cannot
| open shared object file: No such file or directory
| $ sudo apt-get install libssl1.0.0 libssl-dev
| Reading package lists... Done
| Building dependency tree
| Reading state information... Done
| Package libssl1.0.0 is not available, but is referred to by another package.
| This may mean that the package is missing, has been obsoleted, or
| is only available from another source
| 
| E: Package 'libssl1.0.0' has no installation candidate
| 
| ```
| On internet, it is said that this library was discontinued
| (https://askubuntu.com/questions/897444/libssl-so-1-0-0-is-missing)
| R is up and running instead:
| ```
| $ R
| R version 4.0.1 (2020-06-06) -- "See Things Now"
| Copyright (C) 2020 The R Foundation for Statistical Computing
| Platform: x86_64-pc-linux-gnu (64-bit)
| 
| ```
| How can I launch studio then?

You appear to have asked the wrong part of the internet. If you go to

  packages.ubuntu.com

and search for 'libssl1.0.0', selecting "all" distributions, and "search
package name", you get the page

  https://packages.ubuntu.com/search?keywords=libssl1.0.0&searchon=names&suite=all&section=all

suggesting downloads of the package from two LTS releases (and two updates
within). Download the file eg

  cd /tmp
  wget http://mirrors.kernel.org/ubuntu/pool/main/o/openssl1.0/libssl1.0.0_1.0.2n-1ubuntu5.3_amd64.deb
  sudo dpkg -i libssl1.0.0_1.0.2n-1ubuntu5.3_amd64.deb

Lastly, you asked _on the wrong mailing list_. Questions for R use on Debian
or Ubuntu (or derived) systems should got to r-sig-debian instead. It is a
friendly place.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Mon Jun 15 16:15:18 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Mon, 15 Jun 2020 16:15:18 +0200
Subject: [R] Rstudio does not run on ubuntu 20
In-Reply-To: <24295.32663.708854.711638@rob.eddelbuettel.com>
References: <CAMk+s2Qs-eiy9wJcOuVna8gPajj8AnuSi11Ty27eDUbmrK12Pw@mail.gmail.com>
 <24295.32663.708854.711638@rob.eddelbuettel.com>
Message-ID: <CAMk+s2Q9D4vCN-jxPXoY4p_Mfqu2j_4kUe0i0-Q9-htuACX-Cw@mail.gmail.com>

Ok I will use another blog. Thank you

On Mon, Jun 15, 2020 at 4:03 PM Dirk Eddelbuettel <edd at debian.org> wrote:
>
>
> On 15 June 2020 at 14:46, Luigi Marongiu wrote:
> | Hello,
> | all of a sudden rstudio stopped working on ubuntu 20.04. I
> | re-installed from `rstudio-1.3.959-amd64.deb` but it does not launch
> | even if there is an icon. On terminal I got:
> | ```
> | $ rstudio
> | rstudio: error while loading shared libraries: libssl.so.1.0.0: cannot
> | open shared object file: No such file or directory
> | $ sudo apt-get install libssl1.0.0 libssl-dev
> | Reading package lists... Done
> | Building dependency tree
> | Reading state information... Done
> | Package libssl1.0.0 is not available, but is referred to by another package.
> | This may mean that the package is missing, has been obsoleted, or
> | is only available from another source
> |
> | E: Package 'libssl1.0.0' has no installation candidate
> |
> | ```
> | On internet, it is said that this library was discontinued
> | (https://askubuntu.com/questions/897444/libssl-so-1-0-0-is-missing)
> | R is up and running instead:
> | ```
> | $ R
> | R version 4.0.1 (2020-06-06) -- "See Things Now"
> | Copyright (C) 2020 The R Foundation for Statistical Computing
> | Platform: x86_64-pc-linux-gnu (64-bit)
> |
> | ```
> | How can I launch studio then?
>
> You appear to have asked the wrong part of the internet. If you go to
>
>   packages.ubuntu.com
>
> and search for 'libssl1.0.0', selecting "all" distributions, and "search
> package name", you get the page
>
>   https://packages.ubuntu.com/search?keywords=libssl1.0.0&searchon=names&suite=all&section=all
>
> suggesting downloads of the package from two LTS releases (and two updates
> within). Download the file eg
>
>   cd /tmp
>   wget http://mirrors.kernel.org/ubuntu/pool/main/o/openssl1.0/libssl1.0.0_1.0.2n-1ubuntu5.3_amd64.deb
>   sudo dpkg -i libssl1.0.0_1.0.2n-1ubuntu5.3_amd64.deb
>
> Lastly, you asked _on the wrong mailing list_. Questions for R use on Debian
> or Ubuntu (or derived) systems should got to r-sig-debian instead. It is a
> friendly place.
>
> Dirk
>
> --
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org



-- 
Best regards,
Luigi


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Jun 16 00:06:08 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Mon, 15 Jun 2020 17:06:08 -0500
Subject: [R] how to change manhattan plot code to get a different color per
 chromosome
Message-ID: <CAF9-5jMGbOD9aeyRPrXbxZLrUGOsto8PXdmc_OUEHJws9fkkLw@mail.gmail.com>

Hello,

Is there is a way to set colors in this plot to look like this one in
attach (different color for each CHR-there is 22 of them)?


library(qqman)
results_log <- read.table("meta_p_pos_chr.F", head=TRUE,stringsAsFactors=FALSE)
png("META.png")
manhattan(results_log,chr="CHR",bp="POS",p="META_pval",snp="MARKER",ylim
= c(0, 10))
dev.off()

Thanks
Ana

From drj|m|emon @end|ng |rom gm@||@com  Tue Jun 16 11:00:06 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 16 Jun 2020 19:00:06 +1000
Subject: [R] 
 how to change manhattan plot code to get a different color per
 chromosome
In-Reply-To: <CAF9-5jMGbOD9aeyRPrXbxZLrUGOsto8PXdmc_OUEHJws9fkkLw@mail.gmail.com>
References: <CAF9-5jMGbOD9aeyRPrXbxZLrUGOsto8PXdmc_OUEHJws9fkkLw@mail.gmail.com>
Message-ID: <CA+8X3fW-vB5nrHEHYX8wOJU5fSJLXt9kekeVSj3pQWiqGs0A5A@mail.gmail.com>

Hi Ana,
Your attached image seems to have bailed out before landing in the
list. Here's how to do it using a simple manhattan plot with the data
from:

https://reneshbedre.github.io//assets/posts/mhat/gwas_res_sim.csv

gwas<-read.csv("gwas_res_sim.csv",stringsAsFactors=FALSE)
# get the data into chromosome order
gwas<-gwas[order(gwas$chr,gwas$SNP),]
gwas$BP<-rep(NA,dim(gwas)[1]
# fake some base positions
for(chromosome in 1:20) {
 snporder<-order(as.numeric(gsub("rs","",gwas[gwas$chr == chromosome,"SNP"])))
 gwas$BP[gwas$chr == chromosome]<-
  as.numeric(paste(chromosome,snporder,sep="."))
}
library(plotrix)
# set the chromosome colors here - be more creative than me
chrcol<-color.scale(1:10,extremes=c("red","blue"))

# simple manhattan plot function
manhattan<-function(x,CHR="CHR",BP="BP",SNP="SNP",p="p",
 main="Manhattan Plot",xlab="Chromosome",ylab="-log10(p)",
 pch=".",cex=1,siglevel=0.00001,sigcol="green",sigcex=2,
 chrlab=NULL,chrcol=NULL,annotate=FALSE) {

 par(xaxs="i",yaxs="i")
 nchr<-length(unique(x[,CHR]))
 if(is.null(chrlab)) chrlab<-1:nchr
 ypos<--log10(x[,p])
 plot(x[,BP],ypos,ylim=c(0,max(ypos,na.rm=TRUE)*1.05),
  main=main,xlab=xlab,ylab=ylab,
  pch=pch,col=chrcol[x[,CHR]],cex=4,xaxt="n")
 abline(h=-log10(siglevel),lty=2)
 staxlab(1,at=(1:nchr) + 0.5,labels=chrlab)
 sigindx<-which(ypos >= -log10(siglevel))
 sigSNP<-unique(x[sigindx,SNP])
 cat(length(sigindx),"sig\n")
 points(x[sigindx,BP],ypos[sigindx],
  pch=pch,col=sigcol,cex=sigcex)
 if(annotate) text(x[sigindx,BP],ypos[sigindx]*1.03,x[sigindx,SNP])
 return(sigSNP=sigSNP)
}

manhattan(gwas,CHR="chr",p="pvalue",cex=4,sigcex=6,
 chrcol=chrcol,annotate=TRUE)

Jim

On Tue, Jun 16, 2020 at 8:06 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> Is there is a way to set colors in this plot to look like this one in
> attach (different color for each CHR-there is 22 of them)?
>
>
> library(qqman)
> results_log <- read.table("meta_p_pos_chr.F", head=TRUE,stringsAsFactors=FALSE)
> png("META.png")
> manhattan(results_log,chr="CHR",bp="POS",p="META_pval",snp="MARKER",ylim
> = c(0, 10))
> dev.off()
>
> Thanks
> Ana
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @mo@tw|k20 @end|ng |rom gm@||@com  Tue Jun 16 04:49:30 2020
From: @mo@tw|k20 @end|ng |rom gm@||@com (K Amoatwi)
Date: Mon, 15 Jun 2020 22:49:30 -0400
Subject: [R] Error message in meta-analysis package Metafor-weights =""
Message-ID: <CAN5pK_21tgCA_Zyuj0=0jL7Pxg4T-NS09trteXnphiOpv9EbEg@mail.gmail.com>

Dear All,
I am using the example from one of the tutorial about "Metafor" package and
"escalc" function, to learn how this package can be applied to do
meta-analysi; the code and the data is directly from the tutorials but
"weights=freq" option in the escalc function is given me error message
This is the code below:

library(metafor) # Load package
#####DATASET 1: BCG Vaccine Trials
data(dat.bcg) # BCG meta-analytic dataset

##Formula based Specification
##That is, what if I have multiple rows per study, corresponding to
difference treatment groups?

library(reshape2) # Load package for data reshaping

bcg.long <- melt(dat.bcg[, c("trial", "tpos", "tneg", "cpos", "cneg")], id
= "trial")
bcg.long$pos <- ifelse(bcg.long$var == "tpos" | bcg.long$var == "cpos", 1,
0)
bcg.long$group <- ifelse(bcg.long$var == "tpos" | bcg.long$var == "tneg",
1, 0)

##sample of the data, the first 6 rows
head(bcg.long)
  trial variable value pos group
1     1     tpos     4     1     1
2     2     tpos     6     1     1
3     3     tpos     3     1     1
4     4     tpos    62    1     1
5     5     tpos    33    1     1
6     6     tpos   180   1     1

##Now applying the " escalc " function

escalc(factor(pos)~factor(group)| factor(trial),weights = value,data =
bcg.long, measure = "OR")

##Then I got this error message
Error in escalc(factor(pos) ~ factor(group) | factor(trial), weights =
value,  :
  object 'value' not found

I used the same data with different example from another author and got a
similar error message
Second code with the same data but different coding
Sample data

with the first 6 rows of the rearranged data shown below. (T=treatment,
C=Control group, Out=outcome whether positive or negative, and then
frequency)
    study grp out freq
1        1    T    +      4
2        1    T    -    119
3        1    C   +      11
4        1    C   -     128
5        2    T   +        6
6        2    T   -      300

>escalc(out ~ grp | study, weights = freq, data = dat.fm, measure = "OR")

Error in escalc(out ~ grp | study, weights = freq, data = dat.fm, measure =
"OR") :
  object 'freq' not found

I am not sure what I am doing wrong since both authors were able to get
their results while I am getting error messages.

Any help will be very much appreciated

Amoatwi

	[[alternative HTML version deleted]]


From t@yr||ne @end|ng |rom @tudent@un|me|b@edu@@u  Tue Jun 16 05:53:11 2020
From: t@yr||ne @end|ng |rom @tudent@un|me|b@edu@@u (Eddie Tsyrlin)
Date: Tue, 16 Jun 2020 13:53:11 +1000
Subject: [R] species accumulation curve with percentages
Message-ID: <CAJX7CjdBuf=eJh0+UT39601EeRY__nucunNVyU0u3ABaOBNXRw@mail.gmail.com>

I need to express species accumulation curve in percentage terms, i.e. the
vertical axis is from 1% to 100%
I have community data similar to BCI (from vegan package).
I can construct the 'usual' species curve (see below) but I need to convert
the species number to percentage.

data("BCI")
bcispec<-specaccum(BCI, method = "random",
                   permutations = 100)
plot(bcispec)

-- 
Eddie Tsyrlin, PhD Candidate | PEARG | Building 404, Grd Floor, Rm G21

School of Biosciences | University of Melbourne
*Post:* Bio21,  Flemington Rd, Parkville VIC 3052
*m: *0413 995525

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot05.png
Type: image/png
Size: 4396 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200616/43bcf636/attachment.png>

From jeroenoom@ @end|ng |rom gm@||@com  Tue Jun 16 17:40:51 2020
From: jeroenoom@ @end|ng |rom gm@||@com (Jeroen Ooms)
Date: Tue, 16 Jun 2020 17:40:51 +0200
Subject: [R] Rstudio does not run on ubuntu 20
In-Reply-To: <CAMk+s2Qs-eiy9wJcOuVna8gPajj8AnuSi11Ty27eDUbmrK12Pw@mail.gmail.com>
References: <CAMk+s2Qs-eiy9wJcOuVna8gPajj8AnuSi11Ty27eDUbmrK12Pw@mail.gmail.com>
Message-ID: <CABFfbXtMO-obaA7G=WqZMZbeHdWXEZUA5fQ+q=rUr5-TSwECfA@mail.gmail.com>

On Mon, Jun 15, 2020 at 2:47 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Hello,
> all of a sudden rstudio stopped working on ubuntu 20.04. I
> re-installed from `rstudio-1.3.959-amd64.deb` but it does not launch
> even if there is an icon. On terminal I got:
> ```
> $ rstudio
> rstudio: error while loading shared libraries: libssl.so.1.0.0: cannot
> open shared object file: No such file or directory
> $ sudo apt-get install libssl1.0.0 libssl-dev
> Reading package lists... Done
> Building dependency tree
> Reading state information... Done
> Package libssl1.0.0 is not available, but is referred to by another package.
> This may mean that the package is missing, has been obsoleted, or
> is only available from another source
>
> E: Package 'libssl1.0.0' has no installation candidate


This happens when you install the wrong rstudio binary for your
version of debian/ubuntu. Go to
https://rstudio.com/products/rstudio/download-server/debian-ubuntu/
and scroll down to "Install for Debian 10 / Ubuntu 18" and try that
one.

I think you had downloaded the binary for Ubuntu 16, which depends on
an old version of openssl.


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Tue Jun 16 18:49:38 2020
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Tue, 16 Jun 2020 16:49:38 +0000
Subject: [R] Error message in meta-analysis package Metafor-weights =""
In-Reply-To: <CAN5pK_21tgCA_Zyuj0=0jL7Pxg4T-NS09trteXnphiOpv9EbEg@mail.gmail.com>
References: <CAN5pK_21tgCA_Zyuj0=0jL7Pxg4T-NS09trteXnphiOpv9EbEg@mail.gmail.com>
Message-ID: <6f755e6d576e4d168d1a7da438cde545@UM-MAIL3214.unimaas.nl>

Dear Amoatwi,

This way of using the escalc() function has been deprecated. It might be added back once there is actually any benefit from having this functionality, but for years it just meant that I had to maintain two different ways of doing the exact same thing without any additional benefits.

Best,
Wolfgang

-- 
Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and    
Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD    
Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com    

>-----Original Message-----
>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of K Amoatwi
>Sent: Tuesday, 16 June, 2020 4:50
>To: r-help at r-project.org
>Subject: [R] Error message in meta-analysis package Metafor-weights =""
>
>Dear All,
>I am using the example from one of the tutorial about "Metafor" package and
>"escalc" function, to learn how this package can be applied to do
>meta-analysi; the code and the data is directly from the tutorials but
>"weights=freq" option in the escalc function is given me error message
>This is the code below:
>
>library(metafor) # Load package
>#####DATASET 1: BCG Vaccine Trials
>data(dat.bcg) # BCG meta-analytic dataset
>
>##Formula based Specification
>##That is, what if I have multiple rows per study, corresponding to
>difference treatment groups?
>
>library(reshape2) # Load package for data reshaping
>
>bcg.long <- melt(dat.bcg[, c("trial", "tpos", "tneg", "cpos", "cneg")], id
>= "trial")
>bcg.long$pos <- ifelse(bcg.long$var == "tpos" | bcg.long$var == "cpos", 1,
>0)
>bcg.long$group <- ifelse(bcg.long$var == "tpos" | bcg.long$var == "tneg",
>1, 0)
>
>##sample of the data, the first 6 rows
>head(bcg.long)
>  trial variable value pos group
>1     1     tpos     4     1     1
>2     2     tpos     6     1     1
>3     3     tpos     3     1     1
>4     4     tpos    62    1     1
>5     5     tpos    33    1     1
>6     6     tpos   180   1     1
>
>##Now applying the " escalc " function
>
>escalc(factor(pos)~factor(group)| factor(trial),weights = value,data =
>bcg.long, measure = "OR")
>
>##Then I got this error message
>Error in escalc(factor(pos) ~ factor(group) | factor(trial), weights =
>value,  :
>  object 'value' not found
>
>I used the same data with different example from another author and got a
>similar error message
>Second code with the same data but different coding
>Sample data
>
>with the first 6 rows of the rearranged data shown below. (T=treatment,
>C=Control group, Out=outcome whether positive or negative, and then
>frequency)
>    study grp out freq
>1        1    T    +      4
>2        1    T    -    119
>3        1    C   +      11
>4        1    C   -     128
>5        2    T   +        6
>6        2    T   -      300
>
>>escalc(out ~ grp | study, weights = freq, data = dat.fm, measure = "OR")
>
>Error in escalc(out ~ grp | study, weights = freq, data = dat.fm, measure =
>"OR") :
>  object 'freq' not found
>
>I am not sure what I am doing wrong since both authors were able to get
>their results while I am getting error messages.
>
>Any help will be very much appreciated
>
>Amoatwi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Jun 16 19:11:00 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 16 Jun 2020 19:11:00 +0200
Subject: [R] Rstudio does not run on ubuntu 20
In-Reply-To: <CABFfbXtMO-obaA7G=WqZMZbeHdWXEZUA5fQ+q=rUr5-TSwECfA@mail.gmail.com>
References: <CAMk+s2Qs-eiy9wJcOuVna8gPajj8AnuSi11Ty27eDUbmrK12Pw@mail.gmail.com>
 <CABFfbXtMO-obaA7G=WqZMZbeHdWXEZUA5fQ+q=rUr5-TSwECfA@mail.gmail.com>
Message-ID: <CAMk+s2TvS6QK5UxiZioS2APs-cDOGmt1uWcsMwQxKU0Yc8Ombw@mail.gmail.com>

Thank you, but isn't this the link to Rstudio server? Is there one for
Rstudio desktop?

On Tue, Jun 16, 2020 at 5:41 PM Jeroen Ooms <jeroenooms at gmail.com> wrote:
>
> On Mon, Jun 15, 2020 at 2:47 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Hello,
> > all of a sudden rstudio stopped working on ubuntu 20.04. I
> > re-installed from `rstudio-1.3.959-amd64.deb` but it does not launch
> > even if there is an icon. On terminal I got:
> > ```
> > $ rstudio
> > rstudio: error while loading shared libraries: libssl.so.1.0.0: cannot
> > open shared object file: No such file or directory
> > $ sudo apt-get install libssl1.0.0 libssl-dev
> > Reading package lists... Done
> > Building dependency tree
> > Reading state information... Done
> > Package libssl1.0.0 is not available, but is referred to by another package.
> > This may mean that the package is missing, has been obsoleted, or
> > is only available from another source
> >
> > E: Package 'libssl1.0.0' has no installation candidate
>
>
> This happens when you install the wrong rstudio binary for your
> version of debian/ubuntu. Go to
> https://rstudio.com/products/rstudio/download-server/debian-ubuntu/
> and scroll down to "Install for Debian 10 / Ubuntu 18" and try that
> one.
>
> I think you had downloaded the binary for Ubuntu 16, which depends on
> an old version of openssl.



-- 
Best regards,
Luigi


From @mo@tw|k20 @end|ng |rom gm@||@com  Tue Jun 16 19:16:15 2020
From: @mo@tw|k20 @end|ng |rom gm@||@com (K Amoatwi)
Date: Tue, 16 Jun 2020 13:16:15 -0400
Subject: [R] Error message in meta-analysis package Metafor-weights =""
In-Reply-To: <6f755e6d576e4d168d1a7da438cde545@UM-MAIL3214.unimaas.nl>
References: <CAN5pK_21tgCA_Zyuj0=0jL7Pxg4T-NS09trteXnphiOpv9EbEg@mail.gmail.com>
 <6f755e6d576e4d168d1a7da438cde545@UM-MAIL3214.unimaas.nl>
Message-ID: <CAN5pK_0OdMFGXVEbKz1O-hJrfkaN0g2jcyGKAFikgfyGzeJjog@mail.gmail.com>

Thank you, very much appreciated.

On Tue, Jun 16, 2020 at 12:50 PM Viechtbauer, Wolfgang (SP) <
wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:

> Dear Amoatwi,
>
> This way of using the escalc() function has been deprecated. It might be
> added back once there is actually any benefit from having this
> functionality, but for years it just meant that I had to maintain two
> different ways of doing the exact same thing without any additional
> benefits.
>
> Best,
> Wolfgang
>
> --
> Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and
>
> Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD
>
> Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com
>
>
> >-----Original Message-----
> >From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of K Amoatwi
> >Sent: Tuesday, 16 June, 2020 4:50
> >To: r-help at r-project.org
> >Subject: [R] Error message in meta-analysis package Metafor-weights =""
> >
> >Dear All,
> >I am using the example from one of the tutorial about "Metafor" package
> and
> >"escalc" function, to learn how this package can be applied to do
> >meta-analysi; the code and the data is directly from the tutorials but
> >"weights=freq" option in the escalc function is given me error message
> >This is the code below:
> >
> >library(metafor) # Load package
> >#####DATASET 1: BCG Vaccine Trials
> >data(dat.bcg) # BCG meta-analytic dataset
> >
> >##Formula based Specification
> >##That is, what if I have multiple rows per study, corresponding to
> >difference treatment groups?
> >
> >library(reshape2) # Load package for data reshaping
> >
> >bcg.long <- melt(dat.bcg[, c("trial", "tpos", "tneg", "cpos", "cneg")], id
> >= "trial")
> >bcg.long$pos <- ifelse(bcg.long$var == "tpos" | bcg.long$var == "cpos", 1,
> >0)
> >bcg.long$group <- ifelse(bcg.long$var == "tpos" | bcg.long$var == "tneg",
> >1, 0)
> >
> >##sample of the data, the first 6 rows
> >head(bcg.long)
> >  trial variable value pos group
> >1     1     tpos     4     1     1
> >2     2     tpos     6     1     1
> >3     3     tpos     3     1     1
> >4     4     tpos    62    1     1
> >5     5     tpos    33    1     1
> >6     6     tpos   180   1     1
> >
> >##Now applying the " escalc " function
> >
> >escalc(factor(pos)~factor(group)| factor(trial),weights = value,data =
> >bcg.long, measure = "OR")
> >
> >##Then I got this error message
> >Error in escalc(factor(pos) ~ factor(group) | factor(trial), weights =
> >value,  :
> >  object 'value' not found
> >
> >I used the same data with different example from another author and got a
> >similar error message
> >Second code with the same data but different coding
> >Sample data
> >
> >with the first 6 rows of the rearranged data shown below. (T=treatment,
> >C=Control group, Out=outcome whether positive or negative, and then
> >frequency)
> >    study grp out freq
> >1        1    T    +      4
> >2        1    T    -    119
> >3        1    C   +      11
> >4        1    C   -     128
> >5        2    T   +        6
> >6        2    T   -      300
> >
> >>escalc(out ~ grp | study, weights = freq, data = dat.fm, measure = "OR")
> >
> >Error in escalc(out ~ grp | study, weights = freq, data = dat.fm,
> measure =
> >"OR") :
> >  object 'freq' not found
> >
> >I am not sure what I am doing wrong since both authors were able to get
> >their results while I am getting error messages.
> >
> >Any help will be very much appreciated
> >
> >Amoatwi
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Jun 16 19:24:01 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 16 Jun 2020 10:24:01 -0700
Subject: [R] species accumulation curve with percentages
In-Reply-To: <CAJX7CjdBuf=eJh0+UT39601EeRY__nucunNVyU0u3ABaOBNXRw@mail.gmail.com>
References: <CAJX7CjdBuf=eJh0+UT39601EeRY__nucunNVyU0u3ABaOBNXRw@mail.gmail.com>
Message-ID: <CAGxFJbSkwmwbF9-8MSkdckav02EJYXstTJU49VA53jXpW4UcNQ@mail.gmail.com>

Probably: ?sum  ?cumsum

e.g.
> x <- runif(100, 10,20)
> cumsum(x)/sum(x) *100

Cheers,
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jun 16, 2020 at 8:15 AM Eddie Tsyrlin <
tsyrline at student.unimelb.edu.au> wrote:

> I need to express species accumulation curve in percentage terms, i.e. the
> vertical axis is from 1% to 100%
> I have community data similar to BCI (from vegan package).
> I can construct the 'usual' species curve (see below) but I need to convert
> the species number to percentage.
>
> data("BCI")
> bcispec<-specaccum(BCI, method = "random",
>                    permutations = 100)
> plot(bcispec)
>
> --
> Eddie Tsyrlin, PhD Candidate | PEARG | Building 404, Grd Floor, Rm G21
>
> School of Biosciences | University of Melbourne
> *Post:* Bio21,  Flemington Rd, Parkville VIC 3052
> *m: *0413 995525
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Jun 16 19:45:14 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 16 Jun 2020 10:45:14 -0700
Subject: [R] Rstudio does not run on ubuntu 20
In-Reply-To: <CAMk+s2TvS6QK5UxiZioS2APs-cDOGmt1uWcsMwQxKU0Yc8Ombw@mail.gmail.com>
References: <CAMk+s2Qs-eiy9wJcOuVna8gPajj8AnuSi11Ty27eDUbmrK12Pw@mail.gmail.com>
 <CABFfbXtMO-obaA7G=WqZMZbeHdWXEZUA5fQ+q=rUr5-TSwECfA@mail.gmail.com>
 <CAMk+s2TvS6QK5UxiZioS2APs-cDOGmt1uWcsMwQxKU0Yc8Ombw@mail.gmail.com>
Message-ID: <6a02029d-5b37-75f2-9f0b-e668ae4e7500@comcast.net>


On 6/16/20 10:11 AM, Luigi Marongiu wrote:
> Thank you, but isn't this the link to Rstudio server? Is there one for
> Rstudio desktop?


It didn't seem that difficult to find:


https://download1.rstudio.org/desktop/bionic/amd64/rstudio-1.3.959-amd64.deb


-- 

David.

> On Tue, Jun 16, 2020 at 5:41 PM Jeroen Ooms <jeroenooms at gmail.com> wrote:
>> On Mon, Jun 15, 2020 at 2:47 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>> Hello,
>>> all of a sudden rstudio stopped working on ubuntu 20.04. I
>>> re-installed from `rstudio-1.3.959-amd64.deb` but it does not launch
>>> even if there is an icon. On terminal I got:
>>> ```
>>> $ rstudio
>>> rstudio: error while loading shared libraries: libssl.so.1.0.0: cannot
>>> open shared object file: No such file or directory
>>> $ sudo apt-get install libssl1.0.0 libssl-dev
>>> Reading package lists... Done
>>> Building dependency tree
>>> Reading state information... Done
>>> Package libssl1.0.0 is not available, but is referred to by another package.
>>> This may mean that the package is missing, has been obsoleted, or
>>> is only available from another source
>>>
>>> E: Package 'libssl1.0.0' has no installation candidate
>>
>> This happens when you install the wrong rstudio binary for your
>> version of debian/ubuntu. Go to
>> https://rstudio.com/products/rstudio/download-server/debian-ubuntu/
>> and scroll down to "Install for Debian 10 / Ubuntu 18" and try that
>> one.
>>
>> I think you had downloaded the binary for Ubuntu 16, which depends on
>> an old version of openssl.
>
>


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Jun 16 20:47:28 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 16 Jun 2020 20:47:28 +0200
Subject: [R] Rstudio does not run on ubuntu 20
In-Reply-To: <6a02029d-5b37-75f2-9f0b-e668ae4e7500@comcast.net>
References: <CAMk+s2Qs-eiy9wJcOuVna8gPajj8AnuSi11Ty27eDUbmrK12Pw@mail.gmail.com>
 <CABFfbXtMO-obaA7G=WqZMZbeHdWXEZUA5fQ+q=rUr5-TSwECfA@mail.gmail.com>
 <CAMk+s2TvS6QK5UxiZioS2APs-cDOGmt1uWcsMwQxKU0Yc8Ombw@mail.gmail.com>
 <6a02029d-5b37-75f2-9f0b-e668ae4e7500@comcast.net>
Message-ID: <CAMk+s2R265gG9Wr-Vre9uXv96v7ABHgZBDOeAEq=DkSbvSsePw@mail.gmail.com>

No it wasn't, in fact is the same I have already downloaded...

On Tue, Jun 16, 2020 at 7:45 PM David Winsemius <dwinsemius at comcast.net> wrote:
>
>
> On 6/16/20 10:11 AM, Luigi Marongiu wrote:
> > Thank you, but isn't this the link to Rstudio server? Is there one for
> > Rstudio desktop?
>
>
> It didn't seem that difficult to find:
>
>
> https://download1.rstudio.org/desktop/bionic/amd64/rstudio-1.3.959-amd64.deb
>
>
> --
>
> David.
>
> > On Tue, Jun 16, 2020 at 5:41 PM Jeroen Ooms <jeroenooms at gmail.com> wrote:
> >> On Mon, Jun 15, 2020 at 2:47 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >>> Hello,
> >>> all of a sudden rstudio stopped working on ubuntu 20.04. I
> >>> re-installed from `rstudio-1.3.959-amd64.deb` but it does not launch
> >>> even if there is an icon. On terminal I got:
> >>> ```
> >>> $ rstudio
> >>> rstudio: error while loading shared libraries: libssl.so.1.0.0: cannot
> >>> open shared object file: No such file or directory
> >>> $ sudo apt-get install libssl1.0.0 libssl-dev
> >>> Reading package lists... Done
> >>> Building dependency tree
> >>> Reading state information... Done
> >>> Package libssl1.0.0 is not available, but is referred to by another package.
> >>> This may mean that the package is missing, has been obsoleted, or
> >>> is only available from another source
> >>>
> >>> E: Package 'libssl1.0.0' has no installation candidate
> >>
> >> This happens when you install the wrong rstudio binary for your
> >> version of debian/ubuntu. Go to
> >> https://rstudio.com/products/rstudio/download-server/debian-ubuntu/
> >> and scroll down to "Install for Debian 10 / Ubuntu 18" and try that
> >> one.
> >>
> >> I think you had downloaded the binary for Ubuntu 16, which depends on
> >> an old version of openssl.
> >
> >



-- 
Best regards,
Luigi


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Tue Jun 16 21:16:28 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Tue, 16 Jun 2020 14:16:28 -0500
Subject: [R] 
 how to change manhattan plot code to get a different color per
 chromosome
In-Reply-To: <CA+8X3fW-vB5nrHEHYX8wOJU5fSJLXt9kekeVSj3pQWiqGs0A5A@mail.gmail.com>
References: <CAF9-5jMGbOD9aeyRPrXbxZLrUGOsto8PXdmc_OUEHJws9fkkLw@mail.gmail.com>
 <CA+8X3fW-vB5nrHEHYX8wOJU5fSJLXt9kekeVSj3pQWiqGs0A5A@mail.gmail.com>
Message-ID: <CAF9-5jNVQJJx-Lwxu_Oq-dfgTtRqsVKcnxTJvUeiSX6EBWtTEg@mail.gmail.com>

Hi Jim,

thank you so much for this elaborate code I will definitely use some
hacks from it in the future.
For now, for the purpose of compactness of the code I just set
manually colors which I want to be there:
manhattan(results_log,chr="CHR",bp="POS",p="META_pval",snp="MARKER",suggestiveline
= F, genomewideline = F,main = "Gokind old",col = c("red2", "orange",
"gold1","springgreen4", "dodgerblue",
"darkorchid1","orchid1"),ylim=c(0,9),cex = 0.6)
in this qqman function.

Cheers,
Ana

On Tue, Jun 16, 2020 at 4:00 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Ana,
> Your attached image seems to have bailed out before landing in the
> list. Here's how to do it using a simple manhattan plot with the data
> from:
>
> https://reneshbedre.github.io//assets/posts/mhat/gwas_res_sim.csv
>
> gwas<-read.csv("gwas_res_sim.csv",stringsAsFactors=FALSE)
> # get the data into chromosome order
> gwas<-gwas[order(gwas$chr,gwas$SNP),]
> gwas$BP<-rep(NA,dim(gwas)[1]
> # fake some base positions
> for(chromosome in 1:20) {
>  snporder<-order(as.numeric(gsub("rs","",gwas[gwas$chr == chromosome,"SNP"])))
>  gwas$BP[gwas$chr == chromosome]<-
>   as.numeric(paste(chromosome,snporder,sep="."))
> }
> library(plotrix)
> # set the chromosome colors here - be more creative than me
> chrcol<-color.scale(1:10,extremes=c("red","blue"))
>
> # simple manhattan plot function
> manhattan<-function(x,CHR="CHR",BP="BP",SNP="SNP",p="p",
>  main="Manhattan Plot",xlab="Chromosome",ylab="-log10(p)",
>  pch=".",cex=1,siglevel=0.00001,sigcol="green",sigcex=2,
>  chrlab=NULL,chrcol=NULL,annotate=FALSE) {
>
>  par(xaxs="i",yaxs="i")
>  nchr<-length(unique(x[,CHR]))
>  if(is.null(chrlab)) chrlab<-1:nchr
>  ypos<--log10(x[,p])
>  plot(x[,BP],ypos,ylim=c(0,max(ypos,na.rm=TRUE)*1.05),
>   main=main,xlab=xlab,ylab=ylab,
>   pch=pch,col=chrcol[x[,CHR]],cex=4,xaxt="n")
>  abline(h=-log10(siglevel),lty=2)
>  staxlab(1,at=(1:nchr) + 0.5,labels=chrlab)
>  sigindx<-which(ypos >= -log10(siglevel))
>  sigSNP<-unique(x[sigindx,SNP])
>  cat(length(sigindx),"sig\n")
>  points(x[sigindx,BP],ypos[sigindx],
>   pch=pch,col=sigcol,cex=sigcex)
>  if(annotate) text(x[sigindx,BP],ypos[sigindx]*1.03,x[sigindx,SNP])
>  return(sigSNP=sigSNP)
> }
>
> manhattan(gwas,CHR="chr",p="pvalue",cex=4,sigcex=6,
>  chrcol=chrcol,annotate=TRUE)
>
> Jim
>
> On Tue, Jun 16, 2020 at 8:06 AM Ana Marija <sokovic.anamarija at gmail.com> wrote:
> >
> > Hello,
> >
> > Is there is a way to set colors in this plot to look like this one in
> > attach (different color for each CHR-there is 22 of them)?
> >
> >
> > library(qqman)
> > results_log <- read.table("meta_p_pos_chr.F", head=TRUE,stringsAsFactors=FALSE)
> > png("META.png")
> > manhattan(results_log,chr="CHR",bp="POS",p="META_pval",snp="MARKER",ylim
> > = c(0, 10))
> > dev.off()
> >
> > Thanks
> > Ana
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Wed Jun 17 00:23:04 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 17 Jun 2020 08:23:04 +1000
Subject: [R] species accumulation curve with percentages
In-Reply-To: <CAJX7CjdBuf=eJh0+UT39601EeRY__nucunNVyU0u3ABaOBNXRw@mail.gmail.com>
References: <CAJX7CjdBuf=eJh0+UT39601EeRY__nucunNVyU0u3ABaOBNXRw@mail.gmail.com>
Message-ID: <CA+8X3fVTAgg35xEJahu3E9Pf6PYZSQGe67Yr3KBrBZ1Tt2-Y_A@mail.gmail.com>

Hi Eddie,
I don't have the vegan package, but this may help:

accum<-function(x,y) return(x+(y-x)/7)
nspec<-90
for(i in 2:50) nspec[i]<-accum(nspec[i-1],220)
plot(nspec/nspec[1]*100,type="l",xlab="Sites",
 ylab="Species accumulation (%)")

Jim

On Wed, Jun 17, 2020 at 1:15 AM Eddie Tsyrlin
<tsyrline at student.unimelb.edu.au> wrote:
>
> I need to express species accumulation curve in percentage terms, i.e. the
> vertical axis is from 1% to 100%
> I have community data similar to BCI (from vegan package).
> I can construct the 'usual' species curve (see below) but I need to convert
> the species number to percentage.
>
> data("BCI")
> bcispec<-specaccum(BCI, method = "random",
>                    permutations = 100)
> plot(bcispec)
>
> --
> Eddie Tsyrlin, PhD Candidate | PEARG | Building 404, Grd Floor, Rm G21
>
> School of Biosciences | University of Melbourne
> *Post:* Bio21,  Flemington Rd, Parkville VIC 3052
> *m: *0413 995525
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Wed Jun 17 04:47:07 2020
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 17 Jun 2020 12:47:07 +1000
Subject: [R] species accumulation curve with percentages
In-Reply-To: <CA+8X3fVTAgg35xEJahu3E9Pf6PYZSQGe67Yr3KBrBZ1Tt2-Y_A@mail.gmail.com>
References: <CAJX7CjdBuf=eJh0+UT39601EeRY__nucunNVyU0u3ABaOBNXRw@mail.gmail.com>
 <CA+8X3fVTAgg35xEJahu3E9Pf6PYZSQGe67Yr3KBrBZ1Tt2-Y_A@mail.gmail.com>
Message-ID: <CA+8X3fUAWZEH42pdmq5bejxNaJWfc9-R=bhg_5ajEPMTOpv2sA@mail.gmail.com>

Hi Eddie,
Upon reading your initial request more carefully, the last command should be:

plot(nspec/nspec[50]*100,type="l",xlab="Sites",
 ylab="Species accumulation (%)",ylim=c(1,100))

Jim

On Wed, Jun 17, 2020 at 8:23 AM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Eddie,
> I don't have the vegan package, but this may help:
>
> accum<-function(x,y) return(x+(y-x)/7)
> nspec<-90
> for(i in 2:50) nspec[i]<-accum(nspec[i-1],220)
> plot(nspec/nspec[1]*100,type="l",xlab="Sites",
>  ylab="Species accumulation (%)")
>
> Jim
>
> On Wed, Jun 17, 2020 at 1:15 AM Eddie Tsyrlin
> <tsyrline at student.unimelb.edu.au> wrote:
> >
> > I need to express species accumulation curve in percentage terms, i.e. the
> > vertical axis is from 1% to 100%
> > I have community data similar to BCI (from vegan package).
> > I can construct the 'usual' species curve (see below) but I need to convert
> > the species number to percentage.
> >
> > data("BCI")
> > bcispec<-specaccum(BCI, method = "random",
> >                    permutations = 100)
> > plot(bcispec)
> >
> > --
> > Eddie Tsyrlin, PhD Candidate | PEARG | Building 404, Grd Floor, Rm G21
> >
> > School of Biosciences | University of Melbourne
> > *Post:* Bio21,  Flemington Rd, Parkville VIC 3052
> > *m: *0413 995525
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From wewo|@k| @end|ng |rom gm@||@com  Wed Jun 17 11:58:46 2020
From: wewo|@k| @end|ng |rom gm@||@com (Witold E Wolski)
Date: Wed, 17 Jun 2020 11:58:46 +0200
Subject: [R] smoothScatter() and the KernSmooth package
Message-ID: <CAAjnpdg-2BC8scPEgpHySNPWBqB3dKvDXy2yO-ap_H4uQ-qpNw@mail.gmail.com>

Hello,

I am getting the following error when running a package check
```
  Error in loadNamespace(name) : there is no package called 'KernSmooth'
  Calls: <Anonymous> ... loadNamespace -> withRestarts ->
withOneRestart -> doWithOneRestart
  Execution halted
```

The error happens in a function which calls graphics::smoothScatter

I found this e-mail on the r-devel list where this problem is also reported.
https://stat.ethz.ch/pipermail/r-devel/2015-February/070671.html

So I could add KernSmooth to Suggest in the DESCRIPTION but I have a
few questions:
(and I am citing from the e-mail above to which I could not find a reply):

"I have a few questions: isn't it unusual the way smoothScatter calls

grDevices:::.smoothScatterCalcDensity() and KernSmooth::bkde2D(),
i.e., without requiring the packages?
Shouldn't "graphics" suggest "KernSmooth"?
"

best regards
Witek




-- 
Witold Eryk Wolski


From verdoneone @end|ng |rom gm@||@com  Wed Jun 17 09:37:54 2020
From: verdoneone @end|ng |rom gm@||@com (giulio verdi)
Date: Wed, 17 Jun 2020 09:37:54 +0200
Subject: [R] Rmarkdown flexdashboard
Message-ID: <CAHuhrpp9BocfiFNVR0smJVzjFehWC1T=LQxgj73hYR5gYgfAJg@mail.gmail.com>

Hello to everyone,
How can I change the color of the tickets on the dashboards from blue to
grey when you hover your mouse over it.

An example: [image: image]
I need to change the color form blue to grey.
Thanks in advance.
Marco

	[[alternative HTML version deleted]]


From v@h|d@borj|65 @end|ng |rom gm@||@com  Wed Jun 17 17:35:24 2020
From: v@h|d@borj|65 @end|ng |rom gm@||@com (Vahid Borji)
Date: Wed, 17 Jun 2020 20:05:24 +0430
Subject: [R] mnormt package for bivariate normal distribution
Message-ID: <CAEPHqhbQtG8r6RchXG0Zv-1Fo1cXQ0h4g=cKVYytaF97xBTYEw@mail.gmail.com>

Hi, my R friends,
I am going to plot the surface of a bivariate normal distribution and its
contours. I have written the below codes:

library(MASS)

set.seed(69)
n <- 5000
x <- rnorm(n, 0, 15)
y <- 0.5 * x  + rnorm(n, 0, 10)
z <- kde2d(x, y, n = 50)

persp(z, theta = 55, phi = 35,
      shade = 0.75, col = "gold", expand = 0.5, r = 2,
      ltheta = 25, ticktype = "detailed")

contour(z)

It seems that I could use mnormt package for bivariate normal distribution.
How can I use suitable functions of mnormt package in my above codes?
Indeed I want to change my above codes somewhat and use the mnormt package.

Thank you in advance

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Jun 17 18:19:53 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 17 Jun 2020 09:19:53 -0700
Subject: [R] Rmarkdown flexdashboard
In-Reply-To: <CAHuhrpp9BocfiFNVR0smJVzjFehWC1T=LQxgj73hYR5gYgfAJg@mail.gmail.com>
References: <CAHuhrpp9BocfiFNVR0smJVzjFehWC1T=LQxgj73hYR5gYgfAJg@mail.gmail.com>
Message-ID: <9e377153-9876-5153-cba6-04acd5e84cc8@comcast.net>


On 6/17/20 12:37 AM, giulio verdi wrote:
> Hello to everyone,
> How can I change the color of the tickets on the dashboards from blue to
> grey when you hover your mouse over it.
>
> An example: [image: image]
> I need to change the color form blue to grey.
> Thanks in advance.
> Marco
>
> 	[[alternative HTML version deleted]]


Rhelp is a plain text mailing list. Furthermore, if you did attach an 
image to this mailing, it was not in one of the acceptable formats for 
the rhelp mailserver. You should read the Posting Guide for details.

>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rvpr@@@d @end|ng |rom c|@@k@u@edu  Wed Jun 17 19:22:51 2020
From: rvpr@@@d @end|ng |rom c|@@k@u@edu (Venkatesh Prasad Ranganath)
Date: Wed, 17 Jun 2020 12:22:51 -0500
Subject: [R] Installation of mclust package v5.4.6 on R v4.0.1 on Ubuntu
 v20.04 hangs
Message-ID: <CACYG_RVCjOU5SJ66BedLob8NvNL6xkZHS-=DxA6W8gtRe=zysw@mail.gmail.com>

Hey All,

When I execute 'Rscript -e "install.packages('mclust')"` with R 4.0.1 on
Ubuntu 20.04, the process hangs during package preparation.  Any idea how
to fix or debug this issue?

Venkatesh-Prasad Ranganath

-----------------------------------------
ENV: R v4.0.1, GCC v9, Ubuntu v20.04
CMD: Rscript -e "install.packages('mclust')"
OUTPUT:
Installing package into ?/usr/local/lib/R/site-library?
(as ?lib? is unspecified)
trying URL 'https://cloud.r-project.org/src/contrib/mclust_5.4.6.tar.gz'
Content type 'application/x-gzip' length 2877519 bytes (2.7 MB)
==================================================
downloaded 2.7 MB

* installing *source* package ?mclust? ...
** package ?mclust? successfully unpacked and MD5 sums checked
** using staged installation
** libs
gfortran -fno-optimize-sibling-calls  -fpic  -g -O2
-fdebug-prefix-map=/build/r-base-dEscXG/r-base-4.0.1=.
-fstack-protector-strong  -c dmvnorm.f -o dmvnorm.o
gcc -std=gnu99 -I"/usr/share/R/include" -DNDEBUG      -fpic  -g -O2
-fdebug-prefix-map=/build/r-base-dEscXG/r-base-4.0.1=.
-fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
-D_FORTIFY_SOURCE=2 -g  -c init.c -o init.o
gfortran -fno-optimize-sibling-calls  -fpic  -g -O2
-fdebug-prefix-map=/build/r-base-dEscXG/r-base-4.0.1=.
-fstack-protector-strong  -c mclust.f -o mclust.o
gfortran -fno-optimize-sibling-calls  -fpic  -g -O2
-fdebug-prefix-map=/build/r-base-dEscXG/r-base-4.0.1=.
-fstack-protector-strong  -c mclustaddson.f -o mclustaddson.o
gcc -std=gnu99 -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions
-Wl,-z,relro -o mclust.so dmvnorm.o init.o mclust.o mclustaddson.o -llapack
-lblas -lgfortran -lm -lquadmath -lgfortran -lm -lquadmath -L/usr/lib/R/lib
-lR
installing to /usr/local/lib/R/site-library/00LOCK-mclust/00new/mclust/libs
** R
** data
*** moving datasets to lazyload DB
** inst
** byte-compile and prepare package for lazy loading

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jun 17 20:39:43 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 17 Jun 2020 11:39:43 -0700
Subject: [R] Installation of mclust package v5.4.6 on R v4.0.1 on Ubuntu
 v20.04 hangs
In-Reply-To: <CACYG_RVCjOU5SJ66BedLob8NvNL6xkZHS-=DxA6W8gtRe=zysw@mail.gmail.com>
References: <CACYG_RVCjOU5SJ66BedLob8NvNL6xkZHS-=DxA6W8gtRe=zysw@mail.gmail.com>
Message-ID: <CAGxFJbQ+r4J6vkzd-KSei_OvwKvn002sKW3weg_9SAr0js+YhQ@mail.gmail.com>

Probably better posted on R-sig-debian.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jun 17, 2020 at 11:33 AM Venkatesh Prasad Ranganath <
rvprasad at cis.ksu.edu> wrote:

> Hey All,
>
> When I execute 'Rscript -e "install.packages('mclust')"` with R 4.0.1 on
> Ubuntu 20.04, the process hangs during package preparation.  Any idea how
> to fix or debug this issue?
>
> Venkatesh-Prasad Ranganath
>
> -----------------------------------------
> ENV: R v4.0.1, GCC v9, Ubuntu v20.04
> CMD: Rscript -e "install.packages('mclust')"
> OUTPUT:
> Installing package into ?/usr/local/lib/R/site-library?
> (as ?lib? is unspecified)
> trying URL 'https://cloud.r-project.org/src/contrib/mclust_5.4.6.tar.gz'
> Content type 'application/x-gzip' length 2877519 bytes (2.7 MB)
> ==================================================
> downloaded 2.7 MB
>
> * installing *source* package ?mclust? ...
> ** package ?mclust? successfully unpacked and MD5 sums checked
> ** using staged installation
> ** libs
> gfortran -fno-optimize-sibling-calls  -fpic  -g -O2
> -fdebug-prefix-map=/build/r-base-dEscXG/r-base-4.0.1=.
> -fstack-protector-strong  -c dmvnorm.f -o dmvnorm.o
> gcc -std=gnu99 -I"/usr/share/R/include" -DNDEBUG      -fpic  -g -O2
> -fdebug-prefix-map=/build/r-base-dEscXG/r-base-4.0.1=.
> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> -D_FORTIFY_SOURCE=2 -g  -c init.c -o init.o
> gfortran -fno-optimize-sibling-calls  -fpic  -g -O2
> -fdebug-prefix-map=/build/r-base-dEscXG/r-base-4.0.1=.
> -fstack-protector-strong  -c mclust.f -o mclust.o
> gfortran -fno-optimize-sibling-calls  -fpic  -g -O2
> -fdebug-prefix-map=/build/r-base-dEscXG/r-base-4.0.1=.
> -fstack-protector-strong  -c mclustaddson.f -o mclustaddson.o
> gcc -std=gnu99 -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions
> -Wl,-z,relro -o mclust.so dmvnorm.o init.o mclust.o mclustaddson.o -llapack
> -lblas -lgfortran -lm -lquadmath -lgfortran -lm -lquadmath -L/usr/lib/R/lib
> -lR
> installing to /usr/local/lib/R/site-library/00LOCK-mclust/00new/mclust/libs
> ** R
> ** data
> *** moving datasets to lazyload DB
> ** inst
> ** byte-compile and prepare package for lazy loading
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rvpr@@@d @end|ng |rom c|@@k@u@edu  Wed Jun 17 21:49:57 2020
From: rvpr@@@d @end|ng |rom c|@@k@u@edu (Venkatesh Prasad Ranganath)
Date: Wed, 17 Jun 2020 14:49:57 -0500
Subject: [R] Installation of mclust package v5.4.6 on R v4.0.1 on Ubuntu
 v20.04 hangs
In-Reply-To: <CAGxFJbQ+r4J6vkzd-KSei_OvwKvn002sKW3weg_9SAr0js+YhQ@mail.gmail.com>
References: <CACYG_RVCjOU5SJ66BedLob8NvNL6xkZHS-=DxA6W8gtRe=zysw@mail.gmail.com>
 <CAGxFJbQ+r4J6vkzd-KSei_OvwKvn002sKW3weg_9SAr0js+YhQ@mail.gmail.com>
Message-ID: <CACYG_RXF0vk2bv1o6qg3BhTaiqOngi=LvvdvgKO=zyNT0qjYpg@mail.gmail.com>

Hey Bert,

Since the process stalls during byte-compilation and package preparation, I
am thinking the issue is likely due to R and not the Ubuntu platform.  If
you think otherwise, then can you please say you think so?  Also, is there
a way to trace/debug the package build process?

The same action via "R CMD INSTALL --no-byte-compile" and "R CMD INSTALL
--no-staged-install" also results in a hang (except the absence of
"byte-compile and" in the output when --no-byte-compile option is
specified).

Cheers,

Venkatesh-Prasad Ranganath



On Wed, Jun 17, 2020 at 1:40 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Probably better posted on R-sig-debian.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Wed, Jun 17, 2020 at 11:33 AM Venkatesh Prasad Ranganath <
> rvprasad at cis.ksu.edu> wrote:
>
>> Hey All,
>>
>> When I execute 'Rscript -e "install.packages('mclust')"` with R 4.0.1 on
>> Ubuntu 20.04, the process hangs during package preparation.  Any idea how
>> to fix or debug this issue?
>>
>> Venkatesh-Prasad Ranganath
>>
>> -----------------------------------------
>> ENV: R v4.0.1, GCC v9, Ubuntu v20.04
>> CMD: Rscript -e "install.packages('mclust')"
>> OUTPUT:
>> Installing package into ?/usr/local/lib/R/site-library?
>> (as ?lib? is unspecified)
>> trying URL 'https://cloud.r-project.org/src/contrib/mclust_5.4.6.tar.gz'
>> Content type 'application/x-gzip' length 2877519 bytes (2.7 MB)
>> ==================================================
>> downloaded 2.7 MB
>>
>> * installing *source* package ?mclust? ...
>> ** package ?mclust? successfully unpacked and MD5 sums checked
>> ** using staged installation
>> ** libs
>> gfortran -fno-optimize-sibling-calls  -fpic  -g -O2
>> -fdebug-prefix-map=/build/r-base-dEscXG/r-base-4.0.1=.
>> -fstack-protector-strong  -c dmvnorm.f -o dmvnorm.o
>> gcc -std=gnu99 -I"/usr/share/R/include" -DNDEBUG      -fpic  -g -O2
>> -fdebug-prefix-map=/build/r-base-dEscXG/r-base-4.0.1=.
>> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
>> -D_FORTIFY_SOURCE=2 -g  -c init.c -o init.o
>> gfortran -fno-optimize-sibling-calls  -fpic  -g -O2
>> -fdebug-prefix-map=/build/r-base-dEscXG/r-base-4.0.1=.
>> -fstack-protector-strong  -c mclust.f -o mclust.o
>> gfortran -fno-optimize-sibling-calls  -fpic  -g -O2
>> -fdebug-prefix-map=/build/r-base-dEscXG/r-base-4.0.1=.
>> -fstack-protector-strong  -c mclustaddson.f -o mclustaddson.o
>> gcc -std=gnu99 -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions
>> -Wl,-z,relro -o mclust.so dmvnorm.o init.o mclust.o mclustaddson.o
>> -llapack
>> -lblas -lgfortran -lm -lquadmath -lgfortran -lm -lquadmath
>> -L/usr/lib/R/lib
>> -lR
>> installing to
>> /usr/local/lib/R/site-library/00LOCK-mclust/00new/mclust/libs
>> ** R
>> ** data
>> *** moving datasets to lazyload DB
>> ** inst
>> ** byte-compile and prepare package for lazy loading
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Jun 17 22:06:16 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 17 Jun 2020 15:06:16 -0500
Subject: [R] comparing variances/distributions
Message-ID: <CAF9-5jMGRms_W+2WoN8RjLJEaZU=oTzS_uW_jktKt5dA7pZQBg@mail.gmail.com>

Hello,

I have p values from two distributions, Pold and Pnew
> head(m)
   CHR     POS     MARKER   Pnew   Pold
1:   1  785989  rs2980300 0.1419 0.9521
2:   1 1130727 rs10907175 0.1022 0.4750
3:   1 1156131  rs2887286 0.3698 0.5289
4:   1 1158631  rs6603781 0.1929 0.2554
5:   1 1211292  rs6685064 0.6054 0.2954
6:   1 1478153  rs3766180 0.6511 0.5542
...

In order to compare those two distributions (QQ plots shown in attach)
does it make sense to use:

var.test(m$Pold, m$Pnew, alternative = "two.sided")

    F test to compare two variances

data:  m$Pold and m$Pnew
F = 0.99937, num df = 1454159, denom df = 1454159, p-value = 0.7057
alternative hypothesis: true ratio of variances is not equal to 1
95 percent confidence interval:
 0.9970808 1.0016750
sample estimates:
ratio of variances
         0.9993739


Or some other test makes more sense?

Thanks
Ana

-------------- next part --------------
A non-text attachment was scrubbed...
Name: qq-plots-compressed.pdf
Type: application/pdf
Size: 31402 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200617/eea61110/attachment.pdf>

From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Jun 17 22:20:22 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 17 Jun 2020 15:20:22 -0500
Subject: [R] comparing variances/distributions
In-Reply-To: <CAF9-5jMGRms_W+2WoN8RjLJEaZU=oTzS_uW_jktKt5dA7pZQBg@mail.gmail.com>
References: <CAF9-5jMGRms_W+2WoN8RjLJEaZU=oTzS_uW_jktKt5dA7pZQBg@mail.gmail.com>
Message-ID: <CAF9-5jPgu72A_NhBhvNW-qN0+5fK-4Lq1fbhhRwJRBh3930sWA@mail.gmail.com>

would using Kolmogorov-Smirnov test make more sense here?

> x=m$Pold
> y=m$Pnew
> ks.test(x,y)

    Two-sample Kolmogorov-Smirnov test

data:  x and y
D = 0.0049066, p-value = 1.221e-15
alternative hypothesis: two-sided

Warning message:
In ks.test(x, y) : p-value will be approximate in the presence of ties

as I understand high p-values here say I cannot claim statistical
support for a difference, but low p-values are not evidence of
sameness?
D should be the maximum difference between the two probability distributions?

On Wed, Jun 17, 2020 at 3:06 PM Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> Hello,
>
> I have p values from two distributions, Pold and Pnew
> > head(m)
>    CHR     POS     MARKER   Pnew   Pold
> 1:   1  785989  rs2980300 0.1419 0.9521
> 2:   1 1130727 rs10907175 0.1022 0.4750
> 3:   1 1156131  rs2887286 0.3698 0.5289
> 4:   1 1158631  rs6603781 0.1929 0.2554
> 5:   1 1211292  rs6685064 0.6054 0.2954
> 6:   1 1478153  rs3766180 0.6511 0.5542
> ...
>
> In order to compare those two distributions (QQ plots shown in attach)
> does it make sense to use:
>
> var.test(m$Pold, m$Pnew, alternative = "two.sided")
>
>     F test to compare two variances
>
> data:  m$Pold and m$Pnew
> F = 0.99937, num df = 1454159, denom df = 1454159, p-value = 0.7057
> alternative hypothesis: true ratio of variances is not equal to 1
> 95 percent confidence interval:
>  0.9970808 1.0016750
> sample estimates:
> ratio of variances
>          0.9993739
>
>
> Or some other test makes more sense?
>
> Thanks
> Ana


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jun 17 22:47:30 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 17 Jun 2020 13:47:30 -0700 (PDT)
Subject: [R] Installation of mclust package v5.4.6 on R v4.0.1 on Ubuntu
 v20.04 hangs
In-Reply-To: <CACYG_RXF0vk2bv1o6qg3BhTaiqOngi=LvvdvgKO=zyNT0qjYpg@mail.gmail.com>
References: <CACYG_RVCjOU5SJ66BedLob8NvNL6xkZHS-=DxA6W8gtRe=zysw@mail.gmail.com>
 <CAGxFJbQ+r4J6vkzd-KSei_OvwKvn002sKW3weg_9SAr0js+YhQ@mail.gmail.com>
 <CACYG_RXF0vk2bv1o6qg3BhTaiqOngi=LvvdvgKO=zyNT0qjYpg@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.2006171339470.76328@pedal.dcn.davis.ca.us>

Please (re)read the Posting guide, which says that this mailing list is 
for questions about the R language and not about compiling issues, and 
then go to r-sig-debian to look for more expertise.

FYI I don't have Ubuntu 20.04, but I had no trouble installing mclust 
5.4.6 with R4.0.1 on Ubuntu 18.04, so your problem is a specific 
interaction with your OS (or how you have your OS configured).

> sessionInfo()
R version 4.0.1 (2020-06-06)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 18.04.4 LTS

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.7.1
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.7.1

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] mclust_5.4.6

loaded via a namespace (and not attached):
[1] compiler_4.0.1 tools_4.0.1
>

On Wed, 17 Jun 2020, Venkatesh Prasad Ranganath wrote:

> Hey Bert,
>
> Since the process stalls during byte-compilation and package preparation, I
> am thinking the issue is likely due to R and not the Ubuntu platform.  If
> you think otherwise, then can you please say you think so?  Also, is there
> a way to trace/debug the package build process?
>
> The same action via "R CMD INSTALL --no-byte-compile" and "R CMD INSTALL
> --no-staged-install" also results in a hang (except the absence of
> "byte-compile and" in the output when --no-byte-compile option is
> specified).
>
> Cheers,
>
> Venkatesh-Prasad Ranganath
>
>
>
> On Wed, Jun 17, 2020 at 1:40 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
>> Probably better posted on R-sig-debian.
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Wed, Jun 17, 2020 at 11:33 AM Venkatesh Prasad Ranganath <
>> rvprasad at cis.ksu.edu> wrote:
>>
>>> Hey All,
>>>
>>> When I execute 'Rscript -e "install.packages('mclust')"` with R 4.0.1 on
>>> Ubuntu 20.04, the process hangs during package preparation.  Any idea how
>>> to fix or debug this issue?
>>>
>>> Venkatesh-Prasad Ranganath
>>>
>>> -----------------------------------------
>>> ENV: R v4.0.1, GCC v9, Ubuntu v20.04
>>> CMD: Rscript -e "install.packages('mclust')"
>>> OUTPUT:
>>> Installing package into ?/usr/local/lib/R/site-library?
>>> (as ?lib? is unspecified)
>>> trying URL 'https://cloud.r-project.org/src/contrib/mclust_5.4.6.tar.gz'
>>> Content type 'application/x-gzip' length 2877519 bytes (2.7 MB)
>>> ==================================================
>>> downloaded 2.7 MB
>>>
>>> * installing *source* package ?mclust? ...
>>> ** package ?mclust? successfully unpacked and MD5 sums checked
>>> ** using staged installation
>>> ** libs
>>> gfortran -fno-optimize-sibling-calls  -fpic  -g -O2
>>> -fdebug-prefix-map=/build/r-base-dEscXG/r-base-4.0.1=.
>>> -fstack-protector-strong  -c dmvnorm.f -o dmvnorm.o
>>> gcc -std=gnu99 -I"/usr/share/R/include" -DNDEBUG      -fpic  -g -O2
>>> -fdebug-prefix-map=/build/r-base-dEscXG/r-base-4.0.1=.
>>> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
>>> -D_FORTIFY_SOURCE=2 -g  -c init.c -o init.o
>>> gfortran -fno-optimize-sibling-calls  -fpic  -g -O2
>>> -fdebug-prefix-map=/build/r-base-dEscXG/r-base-4.0.1=.
>>> -fstack-protector-strong  -c mclust.f -o mclust.o
>>> gfortran -fno-optimize-sibling-calls  -fpic  -g -O2
>>> -fdebug-prefix-map=/build/r-base-dEscXG/r-base-4.0.1=.
>>> -fstack-protector-strong  -c mclustaddson.f -o mclustaddson.o
>>> gcc -std=gnu99 -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions
>>> -Wl,-z,relro -o mclust.so dmvnorm.o init.o mclust.o mclustaddson.o
>>> -llapack
>>> -lblas -lgfortran -lm -lquadmath -lgfortran -lm -lquadmath
>>> -L/usr/lib/R/lib
>>> -lR
>>> installing to
>>> /usr/local/lib/R/site-library/00LOCK-mclust/00new/mclust/libs
>>> ** R
>>> ** data
>>> *** moving datasets to lazyload DB
>>> ** inst
>>> ** byte-compile and prepare package for lazy loading
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From rvpr@@@d @end|ng |rom c|@@k@u@edu  Wed Jun 17 22:47:16 2020
From: rvpr@@@d @end|ng |rom c|@@k@u@edu (Venkatesh Prasad Ranganath)
Date: Wed, 17 Jun 2020 15:47:16 -0500
Subject: [R] Installation of mclust package v5.4.6 on R v4.0.1 on Ubuntu
 v20.04 hangs
In-Reply-To: <alpine.BSF.2.00.2006171339470.76328@pedal.dcn.davis.ca.us>
References: <CACYG_RVCjOU5SJ66BedLob8NvNL6xkZHS-=DxA6W8gtRe=zysw@mail.gmail.com>
 <CAGxFJbQ+r4J6vkzd-KSei_OvwKvn002sKW3weg_9SAr0js+YhQ@mail.gmail.com>
 <CACYG_RXF0vk2bv1o6qg3BhTaiqOngi=LvvdvgKO=zyNT0qjYpg@mail.gmail.com>
 <alpine.BSF.2.00.2006171339470.76328@pedal.dcn.davis.ca.us>
Message-ID: <CACYG_RUcRnRoRFV5sSuxp2jO9SsLi49WsXetYJqY4ywmzpX2Yg@mail.gmail.com>

Hey Jeff,

Thanks for confirming the package could be built and installed on Ubuntu
18.04.  I will pose the question to the SIG.

Cheers,

Venkatesh-Prasad Ranganath
http://rvprasad.com


On Wed, Jun 17, 2020 at 3:39 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Please (re)read the Posting guide, which says that this mailing list is
> for questions about the R language and not about compiling issues, and
> then go to r-sig-debian to look for more expertise.
>
> FYI I don't have Ubuntu 20.04, but I had no trouble installing mclust
> 5.4.6 with R4.0.1 on Ubuntu 18.04, so your problem is a specific
> interaction with your OS (or how you have your OS configured).
>
> > sessionInfo()
> R version 4.0.1 (2020-06-06)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 18.04.4 LTS
>
> Matrix products: default
> BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.7.1
> LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.7.1
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] mclust_5.4.6
>
> loaded via a namespace (and not attached):
> [1] compiler_4.0.1 tools_4.0.1
> >
>
> On Wed, 17 Jun 2020, Venkatesh Prasad Ranganath wrote:
>
> > Hey Bert,
> >
> > Since the process stalls during byte-compilation and package
> preparation, I
> > am thinking the issue is likely due to R and not the Ubuntu platform.  If
> > you think otherwise, then can you please say you think so?  Also, is
> there
> > a way to trace/debug the package build process?
> >
> > The same action via "R CMD INSTALL --no-byte-compile" and "R CMD INSTALL
> > --no-staged-install" also results in a hang (except the absence of
> > "byte-compile and" in the output when --no-byte-compile option is
> > specified).
> >
> > Cheers,
> >
> > Venkatesh-Prasad Ranganath
> >
> >
> >
> > On Wed, Jun 17, 2020 at 1:40 PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >
> >> Probably better posted on R-sig-debian.
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> and
> >> sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Wed, Jun 17, 2020 at 11:33 AM Venkatesh Prasad Ranganath <
> >> rvprasad at cis.ksu.edu> wrote:
> >>
> >>> Hey All,
> >>>
> >>> When I execute 'Rscript -e "install.packages('mclust')"` with R 4.0.1
> on
> >>> Ubuntu 20.04, the process hangs during package preparation.  Any idea
> how
> >>> to fix or debug this issue?
> >>>
> >>> Venkatesh-Prasad Ranganath
> >>>
> >>> -----------------------------------------
> >>> ENV: R v4.0.1, GCC v9, Ubuntu v20.04
> >>> CMD: Rscript -e "install.packages('mclust')"
> >>> OUTPUT:
> >>> Installing package into ?/usr/local/lib/R/site-library?
> >>> (as ?lib? is unspecified)
> >>> trying URL '
> https://cloud.r-project.org/src/contrib/mclust_5.4.6.tar.gz'
> >>> Content type 'application/x-gzip' length 2877519 bytes (2.7 MB)
> >>> ==================================================
> >>> downloaded 2.7 MB
> >>>
> >>> * installing *source* package ?mclust? ...
> >>> ** package ?mclust? successfully unpacked and MD5 sums checked
> >>> ** using staged installation
> >>> ** libs
> >>> gfortran -fno-optimize-sibling-calls  -fpic  -g -O2
> >>> -fdebug-prefix-map=/build/r-base-dEscXG/r-base-4.0.1=.
> >>> -fstack-protector-strong  -c dmvnorm.f -o dmvnorm.o
> >>> gcc -std=gnu99 -I"/usr/share/R/include" -DNDEBUG      -fpic  -g -O2
> >>> -fdebug-prefix-map=/build/r-base-dEscXG/r-base-4.0.1=.
> >>> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
> >>> -D_FORTIFY_SOURCE=2 -g  -c init.c -o init.o
> >>> gfortran -fno-optimize-sibling-calls  -fpic  -g -O2
> >>> -fdebug-prefix-map=/build/r-base-dEscXG/r-base-4.0.1=.
> >>> -fstack-protector-strong  -c mclust.f -o mclust.o
> >>> gfortran -fno-optimize-sibling-calls  -fpic  -g -O2
> >>> -fdebug-prefix-map=/build/r-base-dEscXG/r-base-4.0.1=.
> >>> -fstack-protector-strong  -c mclustaddson.f -o mclustaddson.o
> >>> gcc -std=gnu99 -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions
> >>> -Wl,-z,relro -o mclust.so dmvnorm.o init.o mclust.o mclustaddson.o
> >>> -llapack
> >>> -lblas -lgfortran -lm -lquadmath -lgfortran -lm -lquadmath
> >>> -L/usr/lib/R/lib
> >>> -lR
> >>> installing to
> >>> /usr/local/lib/R/site-library/00LOCK-mclust/00new/mclust/libs
> >>> ** R
> >>> ** data
> >>> *** moving datasets to lazyload DB
> >>> ** inst
> >>> ** byte-compile and prepare package for lazy loading
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Jun 17 23:41:12 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 17 Jun 2020 14:41:12 -0700
Subject: [R] Installation of mclust package v5.4.6 on R v4.0.1 on Ubuntu
 v20.04 hangs
In-Reply-To: <CACYG_RXF0vk2bv1o6qg3BhTaiqOngi=LvvdvgKO=zyNT0qjYpg@mail.gmail.com>
References: <CACYG_RVCjOU5SJ66BedLob8NvNL6xkZHS-=DxA6W8gtRe=zysw@mail.gmail.com>
 <CAGxFJbQ+r4J6vkzd-KSei_OvwKvn002sKW3weg_9SAr0js+YhQ@mail.gmail.com>
 <CACYG_RXF0vk2bv1o6qg3BhTaiqOngi=LvvdvgKO=zyNT0qjYpg@mail.gmail.com>
Message-ID: <CAGxFJbQEUJ+0dCzm2cpLhyxqmKdte0L-Yn_-_kGObxqq4DsWQg@mail.gmail.com>

I would think that it is how interacts with the OS on Ubuntu, which is what
the SIG is about and where also relevant expertise is likely to be found.
But I claim no such expertise and you are certainly free to reject my
suggestion as useless.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Jun 17, 2020 at 12:50 PM Venkatesh Prasad Ranganath <
rvprasad at cis.ksu.edu> wrote:

> Hey Bert,
>
> Since the process stalls during byte-compilation and package preparation,
> I am thinking the issue is likely due to R and not the Ubuntu platform.  If
> you think otherwise, then can you please say you think so?  Also, is there
> a way to trace/debug the package build process?
>
> The same action via "R CMD INSTALL --no-byte-compile" and "R CMD INSTALL
> --no-staged-install" also results in a hang (except the absence of
> "byte-compile and" in the output when --no-byte-compile option is
> specified).
>
> Cheers,
>
> Venkatesh-Prasad Ranganath
>
>
>
> On Wed, Jun 17, 2020 at 1:40 PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
>> Probably better posted on R-sig-debian.
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Wed, Jun 17, 2020 at 11:33 AM Venkatesh Prasad Ranganath <
>> rvprasad at cis.ksu.edu> wrote:
>>
>>> Hey All,
>>>
>>> When I execute 'Rscript -e "install.packages('mclust')"` with R 4.0.1 on
>>> Ubuntu 20.04, the process hangs during package preparation.  Any idea how
>>> to fix or debug this issue?
>>>
>>> Venkatesh-Prasad Ranganath
>>>
>>> -----------------------------------------
>>> ENV: R v4.0.1, GCC v9, Ubuntu v20.04
>>> CMD: Rscript -e "install.packages('mclust')"
>>> OUTPUT:
>>> Installing package into ?/usr/local/lib/R/site-library?
>>> (as ?lib? is unspecified)
>>> trying URL 'https://cloud.r-project.org/src/contrib/mclust_5.4.6.tar.gz'
>>> Content type 'application/x-gzip' length 2877519 bytes (2.7 MB)
>>> ==================================================
>>> downloaded 2.7 MB
>>>
>>> * installing *source* package ?mclust? ...
>>> ** package ?mclust? successfully unpacked and MD5 sums checked
>>> ** using staged installation
>>> ** libs
>>> gfortran -fno-optimize-sibling-calls  -fpic  -g -O2
>>> -fdebug-prefix-map=/build/r-base-dEscXG/r-base-4.0.1=.
>>> -fstack-protector-strong  -c dmvnorm.f -o dmvnorm.o
>>> gcc -std=gnu99 -I"/usr/share/R/include" -DNDEBUG      -fpic  -g -O2
>>> -fdebug-prefix-map=/build/r-base-dEscXG/r-base-4.0.1=.
>>> -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time
>>> -D_FORTIFY_SOURCE=2 -g  -c init.c -o init.o
>>> gfortran -fno-optimize-sibling-calls  -fpic  -g -O2
>>> -fdebug-prefix-map=/build/r-base-dEscXG/r-base-4.0.1=.
>>> -fstack-protector-strong  -c mclust.f -o mclust.o
>>> gfortran -fno-optimize-sibling-calls  -fpic  -g -O2
>>> -fdebug-prefix-map=/build/r-base-dEscXG/r-base-4.0.1=.
>>> -fstack-protector-strong  -c mclustaddson.f -o mclustaddson.o
>>> gcc -std=gnu99 -shared -L/usr/lib/R/lib -Wl,-Bsymbolic-functions
>>> -Wl,-z,relro -o mclust.so dmvnorm.o init.o mclust.o mclustaddson.o
>>> -llapack
>>> -lblas -lgfortran -lm -lquadmath -lgfortran -lm -lquadmath
>>> -L/usr/lib/R/lib
>>> -lR
>>> installing to
>>> /usr/local/lib/R/site-library/00LOCK-mclust/00new/mclust/libs
>>> ** R
>>> ** data
>>> *** moving datasets to lazyload DB
>>> ** inst
>>> ** byte-compile and prepare package for lazy loading
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Wed Jun 17 21:57:56 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Wed, 17 Jun 2020 14:57:56 -0500
Subject: [R] comparing variances/distributions
Message-ID: <CAF9-5jMdS0_1SMNCzPdGYsTJYoeyYnoGnsNAqGFoyPYEMrjTwA@mail.gmail.com>

Hello,

I have p values from two distributions, Pold and Pnew
> head(m)
   CHR     POS     MARKER   Pnew   Pold
1:   1  785989  rs2980300 0.1419 0.9521
2:   1 1130727 rs10907175 0.1022 0.4750
3:   1 1156131  rs2887286 0.3698 0.5289
4:   1 1158631  rs6603781 0.1929 0.2554
5:   1 1211292  rs6685064 0.6054 0.2954
6:   1 1478153  rs3766180 0.6511 0.5542
...

In order to compare those two distributions (QQ plots shown in attach)
does it make sense to use:

var.test(m$Pold, m$Pnew, alternative = "two.sided")

    F test to compare two variances

data:  m$Pold and m$Pnew
F = 0.99937, num df = 1454159, denom df = 1454159, p-value = 0.7057
alternative hypothesis: true ratio of variances is not equal to 1
95 percent confidence interval:
 0.9970808 1.0016750
sample estimates:
ratio of variances
         0.9993739


Or some other test makes more sense?

Thanks
Ana

-------------- next part --------------
A non-text attachment was scrubbed...
Name: qq-plots.pdf
Type: application/pdf
Size: 265660 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200617/1e622242/attachment.pdf>

From mrit@@go@c@ives m@iii@g oii gm@ii@com  Wed Jun 17 22:06:35 2020
From: mrit@@go@c@ives m@iii@g oii gm@ii@com (mrit@@go@c@ives m@iii@g oii gm@ii@com)
Date: Wed, 17 Jun 2020 17:06:35 -0300
Subject: [R] Help guidelines to install packages and tools of R Studio
Message-ID: <000a01d644e2$cefa0dc0$6cee2940$@gmail.com>

Dear Sirs,

I have installed Rstudio 4.0 version to start using and learn R language.

 

I am not able to install the learnr package or create the library directory.

 

Also appears that message.of error in Portuguese(Brazil)

Warning in install.packages :

  n?o foi poss?vel criar o diret?rio 'C:\Users\Rita\OneDrive - BRA ADVISORY
(1)\Documentos\R\win-library\4.0\file29a81d847d22', motivo 'No such file or
directory'

Error in install.packages : unable to create temporary directory
?C:\Users\Rita\OneDrive - BRA ADVISORY
(1)\Documentos\R\win-library\4.0\file29a81d847d22?

 

 

Could help me out or give instructions how I should procedure to fix those
problems.

 

Regards,

Maria Rita Gon?alves

mrita.goncalves at gmail.com <mailto:mrita.goncalves at gmail.com> 

+55 21 981113308

Skype mrita.goncalves1


	[[alternative HTML version deleted]]


From novo@|rj @end|ng |rom rutger@@edu  Thu Jun 18 00:04:30 2020
From: novo@|rj @end|ng |rom rutger@@edu (Ryan Novosielski)
Date: Wed, 17 Jun 2020 22:04:30 +0000
Subject: [R] R 4.0.1/R-devel 2020-06-16-r78702 built with Intel Composer
 19.1.1, error in R CMD make check on CentOS 7.7
In-Reply-To: <39C5E435-33B5-4753-9E9E-BCAB869CDCDF@rutgers.edu>
References: <39C5E435-33B5-4753-9E9E-BCAB869CDCDF@rutgers.edu>
Message-ID: <D2041414-AF32-4B9E-9A75-430E6ECE334A@rutgers.edu>

Same story with R-devel 2020-06-16-r78702, everything else the same. Should I be reporting this someplace else?

--
____
|| \\UTGERS,  	 |---------------------------*O*---------------------------
||_// the State	 |         Ryan Novosielski - novosirj at rutgers.edu
|| \\ University | Sr. Technologist - 973/972.0922 (2x0922) ~*~ RBHS Campus
||  \\    of NJ	 | Office of Advanced Research Computing - MSB C630, Newark
     `'

> On Jun 13, 2020, at 10:16 PM, Ryan Novosielski <novosirj at rutgers.edu> wrote:
> 
> Signed PGP part
> Hi there,
> 
> Built R 4.0.1 with the Intel Composer 19.1.1. Build seems to go fine. I built it like this:
> 
> module purge
> module load intel/19.1.1
> module list
> 
> export CC=icc
> export CXX=icpc
> export F77=ifort
> export FC=ifort
> export AR=xiar
> export LD=xild
> 
> export CFLAGS="-O3 -ipo -qopenmp -axAVX,CORE-AVX2,CORE-AVX512"
> export F77FLAGS="-O3 -ipo -qopenmp -axAVX,CORE-AVX2,CORE-AVX512"
> export FFLAGS="-O3 -ipo -qopenmp -axAVX,CORE-AVX2,CORE-AVX512"
> export CXXFLAGS="-O3 -ipo -qopenmp -axAVX,CORE-AVX2,CORE-AVX512"
> export MKL="-lmkl_intel_lp64 -lmkl_intel_thread -lmkl_core -liomp5 -lpthread"
> 
> VERSION=4.0.1
> 
> /scratch/novosirj/install-files/R-${VERSION}/configure --with-blas="$MKL" --with-lapack --prefix=/opt/sw/packages/intel-19_1/R-Project/${VERSION} && \
>        make -j32 && make check && make -j32 install
> 
> However, the ?make check" phase fails at this part:
> 
> Testing examples for package ?parallel?
> make[2]: Leaving directory `/mnt/scratch/novosirj/R-4.0.1-intel-19.1-build/tests/Examples'
> make[1]: Leaving directory `/mnt/scratch/novosirj/R-4.0.1-intel-19.1-build/tests'
> make[1]: Entering directory `/mnt/scratch/novosirj/R-4.0.1-intel-19.1-build/tests'
> running strict specific tests
> make[2]: Entering directory `/mnt/scratch/novosirj/R-4.0.1-intel-19.1-build/tests'
> running code in '/scratch/novosirj/install-files/R-4.0.1/tests/eval-etc.R' ... OK
>  comparing 'eval-etc.Rout' to '/scratch/novosirj/install-files/R-4.0.1/tests/eval-etc.Rout.save' ... OK
> running code in '/scratch/novosirj/install-files/R-4.0.1/tests/simple-true.R' ... OK
>  comparing 'simple-true.Rout' to '/scratch/novosirj/install-files/R-4.0.1/tests/simple-true.Rout.save' ... OK
> running code in '/scratch/novosirj/install-files/R-4.0.1/tests/arith-true.R' ... OK
>  comparing 'arith-true.Rout' to '/scratch/novosirj/install-files/R-4.0.1/tests/arith-true.Rout.save' ... OK
> running code in '/scratch/novosirj/install-files/R-4.0.1/tests/arith.R' ... OK
>  comparing 'arith.Rout' to '/scratch/novosirj/install-files/R-4.0.1/tests/arith.Rout.save' ... OK
> running code in '/scratch/novosirj/install-files/R-4.0.1/tests/lm-tests.R' ... OK
>  comparing 'lm-tests.Rout' to '/scratch/novosirj/install-files/R-4.0.1/tests/lm-tests.Rout.save' ... OK
> /bin/sh: line 1: 62064 Segmentation fault      (core dumped) LANGUAGE=en LC_ALL=C SRCDIR=/scratch/novosirj/install-files/R-4.0.1/tests R_DEFAULT_PACKAGES= ../bin/R --vanilla < /scratch/novosirj/install-files/R-4.0.1/tests/ok-errors.R > ok-errors.Rout.fail 2>&1
> running code in '/scratch/novosirj/install-files/R-4.0.1/tests/ok-errors.R' ...make[2]: *** [ok-errors.Rout] Error 1
> make[2]: Leaving directory `/mnt/scratch/novosirj/R-4.0.1-intel-19.1-build/tests'
> make[1]: *** [test-Specific] Error 2
> make[1]: Leaving directory `/mnt/scratch/novosirj/R-4.0.1-intel-19.1-build/tests'
> make: *** [test-all-basics] Error 1
> 
> Is this something I should be concerned about, or something I can fix? Not seeing any real information about what?s going wrong here. Here?s what?s contained in ok-errors.Rout.fail:
> 
> ---
> R version 4.0.1 (2020-06-06) -- "See Things Now"
> Copyright (C) 2020 The R Foundation for Statistical Computing
> Platform: x86_64-pc-linux-gnu (64-bit)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
> 
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
> 
>> #### STRICT test suite in the spirit of no-segfaults,
>> #### but with explicit statements.
>> 
>> options(error=expression(NULL))
>> stop("test of `options(error=expression(NULL))'")
> Error: test of `options(error=expression(NULL))'
>> 
>> if(FALSE) {
> + ## these ought to work on machines with enough memory
> + ## These segfaulted in 1.3.x ,  give "could not allocate" errors now
> +   integer(2^30+1)
> +    double(2^30+1)
> +   complex(2^30+1)
> + character(2^30+1)
> + vector("list", 2^30+2)
> + }
>> 
>> ## bad infinite recursion / on.exit / ... interactions
>> ##   catch the error to permit different error messages emitted
>> ##   (handling of infinite recursion is different in the AST interpreter
>> ##   and the byte-code interpreter)
>> 
>> bar <- function() 1+1
>> foo <- function() { on.exit(bar()); foo() }
>> tryCatch(foo(), error=function(x) TRUE) # now simple "infinite recursion"
> 
> *** caught segfault ***
> address 0x7fff4dc1b9f8, cause 'memory not mapped'
> 
> Traceback:
> 1: foo()
> 2: foo()
> 3: foo()
> 4: foo()
> 
> ...
> 
> 2712: foo()
> 2713: foo()
> 2714: foo()
> 2715: foo()
> 2716: foo()
> 2717: foo()
> 2718: foo()
> 2719: doTryCatch(return(expr), name, parentenv, handler)
> 2720: tryCatchOne(expr, names, parentenv, handlers[[1L]])
> 2721: tryCatchList(expr, classes, parentenv, handlers)
> 2722: tryCatch(foo(), error = function(x) TRUE)
> An irrecoverable exception occurred. R is aborting now ...
> ---
> 
> Thanks in advance.
> 
> --
> ____
> || \\UTGERS,  	 |---------------------------*O*---------------------------
> ||_// the State	 |         Ryan Novosielski - novosirj at rutgers.edu
> || \\ University | Sr. Technologist - 973/972.0922 (2x0922) ~*~ RBHS Campus
> ||  \\    of NJ	 | Office of Advanced Research Computing - MSB C630, Newark
>     `'
> 
> 
> 


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 195 bytes
Desc: Message signed with OpenPGP
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200617/5ebc8037/attachment.sig>

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jun 18 02:13:59 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 17 Jun 2020 17:13:59 -0700
Subject: [R] R 4.0.1/R-devel 2020-06-16-r78702 built with Intel Composer
 19.1.1, error in R CMD make check on CentOS 7.7
In-Reply-To: <D2041414-AF32-4B9E-9A75-430E6ECE334A@rutgers.edu>
References: <39C5E435-33B5-4753-9E9E-BCAB869CDCDF@rutgers.edu>
 <D2041414-AF32-4B9E-9A75-430E6ECE334A@rutgers.edu>
Message-ID: <332BF57B-F525-4F61-8B02-7C6946547B6F@dcn.davis.ca.us>

Read the Posting Guide ... this is definitely off-topic here. I think this is an r-devel question, though I really don't know whether you will find interest in discussing compilation of R with a non-standard tool chain. There are a lot of "moving parts" in R and it can be challenging just to keep up with upgrades in the standard tool chain without getting caught up in yet another one.

On June 17, 2020 3:04:30 PM PDT, Ryan Novosielski <novosirj at rutgers.edu> wrote:
>Same story with R-devel 2020-06-16-r78702, everything else the same.
>Should I be reporting this someplace else?
>
>--
>____
>|| \\UTGERS,  	
>|---------------------------*O*---------------------------
>||_// the State	 |         Ryan Novosielski - novosirj at rutgers.edu
>|| \\ University | Sr. Technologist - 973/972.0922 (2x0922) ~*~ RBHS
>Campus
>||  \\    of NJ	 | Office of Advanced Research Computing - MSB C630,
>Newark
>     `'
>
>> On Jun 13, 2020, at 10:16 PM, Ryan Novosielski <novosirj at rutgers.edu>
>wrote:
>> 
>> Signed PGP part
>> Hi there,
>> 
>> Built R 4.0.1 with the Intel Composer 19.1.1. Build seems to go fine.
>I built it like this:
>> 
>> module purge
>> module load intel/19.1.1
>> module list
>> 
>> export CC=icc
>> export CXX=icpc
>> export F77=ifort
>> export FC=ifort
>> export AR=xiar
>> export LD=xild
>> 
>> export CFLAGS="-O3 -ipo -qopenmp -axAVX,CORE-AVX2,CORE-AVX512"
>> export F77FLAGS="-O3 -ipo -qopenmp -axAVX,CORE-AVX2,CORE-AVX512"
>> export FFLAGS="-O3 -ipo -qopenmp -axAVX,CORE-AVX2,CORE-AVX512"
>> export CXXFLAGS="-O3 -ipo -qopenmp -axAVX,CORE-AVX2,CORE-AVX512"
>> export MKL="-lmkl_intel_lp64 -lmkl_intel_thread -lmkl_core -liomp5
>-lpthread"
>> 
>> VERSION=4.0.1
>> 
>> /scratch/novosirj/install-files/R-${VERSION}/configure
>--with-blas="$MKL" --with-lapack
>--prefix=/opt/sw/packages/intel-19_1/R-Project/${VERSION} && \
>>        make -j32 && make check && make -j32 install
>> 
>> However, the ?make check" phase fails at this part:
>> 
>> Testing examples for package ?parallel?
>> make[2]: Leaving directory
>`/mnt/scratch/novosirj/R-4.0.1-intel-19.1-build/tests/Examples'
>> make[1]: Leaving directory
>`/mnt/scratch/novosirj/R-4.0.1-intel-19.1-build/tests'
>> make[1]: Entering directory
>`/mnt/scratch/novosirj/R-4.0.1-intel-19.1-build/tests'
>> running strict specific tests
>> make[2]: Entering directory
>`/mnt/scratch/novosirj/R-4.0.1-intel-19.1-build/tests'
>> running code in
>'/scratch/novosirj/install-files/R-4.0.1/tests/eval-etc.R' ... OK
>>  comparing 'eval-etc.Rout' to
>'/scratch/novosirj/install-files/R-4.0.1/tests/eval-etc.Rout.save' ...
>OK
>> running code in
>'/scratch/novosirj/install-files/R-4.0.1/tests/simple-true.R' ... OK
>>  comparing 'simple-true.Rout' to
>'/scratch/novosirj/install-files/R-4.0.1/tests/simple-true.Rout.save'
>... OK
>> running code in
>'/scratch/novosirj/install-files/R-4.0.1/tests/arith-true.R' ... OK
>>  comparing 'arith-true.Rout' to
>'/scratch/novosirj/install-files/R-4.0.1/tests/arith-true.Rout.save'
>... OK
>> running code in
>'/scratch/novosirj/install-files/R-4.0.1/tests/arith.R' ... OK
>>  comparing 'arith.Rout' to
>'/scratch/novosirj/install-files/R-4.0.1/tests/arith.Rout.save' ... OK
>> running code in
>'/scratch/novosirj/install-files/R-4.0.1/tests/lm-tests.R' ... OK
>>  comparing 'lm-tests.Rout' to
>'/scratch/novosirj/install-files/R-4.0.1/tests/lm-tests.Rout.save' ...
>OK
>> /bin/sh: line 1: 62064 Segmentation fault      (core dumped)
>LANGUAGE=en LC_ALL=C
>SRCDIR=/scratch/novosirj/install-files/R-4.0.1/tests
>R_DEFAULT_PACKAGES= ../bin/R --vanilla <
>/scratch/novosirj/install-files/R-4.0.1/tests/ok-errors.R >
>ok-errors.Rout.fail 2>&1
>> running code in
>'/scratch/novosirj/install-files/R-4.0.1/tests/ok-errors.R' ...make[2]:
>*** [ok-errors.Rout] Error 1
>> make[2]: Leaving directory
>`/mnt/scratch/novosirj/R-4.0.1-intel-19.1-build/tests'
>> make[1]: *** [test-Specific] Error 2
>> make[1]: Leaving directory
>`/mnt/scratch/novosirj/R-4.0.1-intel-19.1-build/tests'
>> make: *** [test-all-basics] Error 1
>> 
>> Is this something I should be concerned about, or something I can
>fix? Not seeing any real information about what?s going wrong here.
>Here?s what?s contained in ok-errors.Rout.fail:
>> 
>> ---
>> R version 4.0.1 (2020-06-06) -- "See Things Now"
>> Copyright (C) 2020 The R Foundation for Statistical Computing
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> 
>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>> You are welcome to redistribute it under certain conditions.
>> Type 'license()' or 'licence()' for distribution details.
>> 
>> R is a collaborative project with many contributors.
>> Type 'contributors()' for more information and
>> 'citation()' on how to cite R or R packages in publications.
>> 
>> Type 'demo()' for some demos, 'help()' for on-line help, or
>> 'help.start()' for an HTML browser interface to help.
>> Type 'q()' to quit R.
>> 
>>> #### STRICT test suite in the spirit of no-segfaults,
>>> #### but with explicit statements.
>>> 
>>> options(error=expression(NULL))
>>> stop("test of `options(error=expression(NULL))'")
>> Error: test of `options(error=expression(NULL))'
>>> 
>>> if(FALSE) {
>> + ## these ought to work on machines with enough memory
>> + ## These segfaulted in 1.3.x ,  give "could not allocate" errors
>now
>> +   integer(2^30+1)
>> +    double(2^30+1)
>> +   complex(2^30+1)
>> + character(2^30+1)
>> + vector("list", 2^30+2)
>> + }
>>> 
>>> ## bad infinite recursion / on.exit / ... interactions
>>> ##   catch the error to permit different error messages emitted
>>> ##   (handling of infinite recursion is different in the AST
>interpreter
>>> ##   and the byte-code interpreter)
>>> 
>>> bar <- function() 1+1
>>> foo <- function() { on.exit(bar()); foo() }
>>> tryCatch(foo(), error=function(x) TRUE) # now simple "infinite
>recursion"
>> 
>> *** caught segfault ***
>> address 0x7fff4dc1b9f8, cause 'memory not mapped'
>> 
>> Traceback:
>> 1: foo()
>> 2: foo()
>> 3: foo()
>> 4: foo()
>> 
>> ...
>> 
>> 2712: foo()
>> 2713: foo()
>> 2714: foo()
>> 2715: foo()
>> 2716: foo()
>> 2717: foo()
>> 2718: foo()
>> 2719: doTryCatch(return(expr), name, parentenv, handler)
>> 2720: tryCatchOne(expr, names, parentenv, handlers[[1L]])
>> 2721: tryCatchList(expr, classes, parentenv, handlers)
>> 2722: tryCatch(foo(), error = function(x) TRUE)
>> An irrecoverable exception occurred. R is aborting now ...
>> ---
>> 
>> Thanks in advance.
>> 
>> --
>> ____
>> || \\UTGERS,  	
>|---------------------------*O*---------------------------
>> ||_// the State	 |         Ryan Novosielski - novosirj at rutgers.edu
>> || \\ University | Sr. Technologist - 973/972.0922 (2x0922) ~*~ RBHS
>Campus
>> ||  \\    of NJ	 | Office of Advanced Research Computing - MSB C630,
>Newark
>>     `'
>> 
>> 
>> 

-- 
Sent from my phone. Please excuse my brevity.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Jun 18 03:22:54 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 17 Jun 2020 18:22:54 -0700
Subject: [R] Help guidelines to install packages and tools of R Studio
In-Reply-To: <000a01d644e2$cefa0dc0$6cee2940$@gmail.com>
References: <000a01d644e2$cefa0dc0$6cee2940$@gmail.com>
Message-ID: <be7863e4-6f42-614a-57e4-1ae6f4e69191@comcast.net>


On 6/17/20 1:06 PM, mrita.goncalves at gmail.com wrote:
> Dear Sirs,
>
> I have installed Rstudio 4.0 version to start using and learn R language.
>
>   
>
> I am not able to install the learnr package or create the library directory.
>
>   
>
> Also appears that message.of error in Portuguese(Brazil)
>
> Warning in install.packages :
>
>    n?o foi poss?vel criar o diret?rio 'C:\Users\Rita\OneDrive - BRA ADVISORY
> (1)\Documentos\R\win-library\4.0\file29a81d847d22', motivo 'No such file or
> directory'
>
> Error in install.packages : unable to create temporary directory
> ?C:\Users\Rita\OneDrive - BRA ADVISORY
> (1)\Documentos\R\win-library\4.0\file29a81d847d22?
>
>   
>
>   
>
> Could help me out or give instructions how I should procedure to fix those
> problems.

My suggestion would be to explore the world of Windows help forums since 
this appears to be a permissions issue rather than anything for which R 
is responsible.


-- 

David

>   
>
> Regards,
>
> Maria Rita Gon?alves
>
> mrita.goncalves at gmail.com <mailto:mrita.goncalves at gmail.com>
>
> +55 21 981113308
>
> Skype mrita.goncalves1
>
>
> 	[[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jun 18 04:04:56 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 17 Jun 2020 19:04:56 -0700
Subject: [R] Help guidelines to install packages and tools of R Studio
In-Reply-To: <000a01d644e2$cefa0dc0$6cee2940$@gmail.com>
References: <000a01d644e2$cefa0dc0$6cee2940$@gmail.com>
Message-ID: <0BE26130-EDC7-4A48-A6F2-37AC1203208E@dcn.davis.ca.us>

It is not a good idea to locate the default user library in a OneDrive or other network-backed software like it (Dropbox, etc.). Nor should you work on R files directly in such a directory. The network backup interferes with R and various common support tools used with R.

If you delete the directory, R will prompt you to re-create it. When it does so, specify a directory that is not located under the OneDrive directory.

On June 17, 2020 1:06:35 PM PDT, mrita.goncalves at gmail.com wrote:
>Dear Sirs,
>
>I have installed Rstudio 4.0 version to start using and learn R
>language.
>
> 
>
>I am not able to install the learnr package or create the library
>directory.
>
> 
>
>Also appears that message.of error in Portuguese(Brazil)
>
>Warning in install.packages :
>
>n?o foi poss?vel criar o diret?rio 'C:\Users\Rita\OneDrive - BRA
>ADVISORY
>(1)\Documentos\R\win-library\4.0\file29a81d847d22', motivo 'No such
>file or
>directory'
>
>Error in install.packages : unable to create temporary directory
>?C:\Users\Rita\OneDrive - BRA ADVISORY
>(1)\Documentos\R\win-library\4.0\file29a81d847d22?
>
> 
>
> 
>
>Could help me out or give instructions how I should procedure to fix
>those
>problems.
>
> 
>
>Regards,
>
>Maria Rita Gon?alves
>
>mrita.goncalves at gmail.com <mailto:mrita.goncalves at gmail.com> 
>
>+55 21 981113308
>
>Skype mrita.goncalves1
>
>
>	[[alternative HTML version deleted]]

-- 
Sent from my phone. Please excuse my brevity.


From @purd|e@@ @end|ng |rom gm@||@com  Thu Jun 18 05:02:22 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Thu, 18 Jun 2020 15:02:22 +1200
Subject: [R] mnormt package for bivariate normal distribution
In-Reply-To: <CAEPHqhbQtG8r6RchXG0Zv-1Fo1cXQ0h4g=cKVYytaF97xBTYEw@mail.gmail.com>
References: <CAEPHqhbQtG8r6RchXG0Zv-1Fo1cXQ0h4g=cKVYytaF97xBTYEw@mail.gmail.com>
Message-ID: <CAB8pepz+GNguRMS0J1wRHywEXmhy2RPoQ3PnrHhgL-d6zfuQkA@mail.gmail.com>

I'm not familiar with the mnormt package.
I'm guessing its documentation may answer some (if not all) of your questions.

Note that my package, bivariate, wraps the dmvnorm function, from the
mvtnorm package.

library (bivariate)

f <- nbvpdf (
    0, 0, #means X, Y
    1, 1, #sds X, Y
    0.5)  #cor

#combined contour-heat
plot (f)
#surface
plot (f, TRUE, arrows=FALSE)
#other
plot (f, all=TRUE, arrows=FALSE)

https://cran.r-project.org/web/packages/mnormt/mnormt.pdf
https://cran.r-project.org/web/packages/mvtnorm/mvtnorm.pdf

https://cran.r-project.org/web/packages/bivariate/vignettes/bivariate.pdf


On Thu, Jun 18, 2020 at 3:36 AM Vahid Borji <vahid.borji65 at gmail.com> wrote:
>
> Hi, my R friends,
> I am going to plot the surface of a bivariate normal distribution and its
> contours. I have written the below codes:
>
> library(MASS)
>
> set.seed(69)
> n <- 5000
> x <- rnorm(n, 0, 15)
> y <- 0.5 * x  + rnorm(n, 0, 10)
> z <- kde2d(x, y, n = 50)
>
> persp(z, theta = 55, phi = 35,
>       shade = 0.75, col = "gold", expand = 0.5, r = 2,
>       ltheta = 25, ticktype = "detailed")
>
> contour(z)
>
> It seems that I could use mnormt package for bivariate normal distribution.
> How can I use suitable functions of mnormt package in my above codes?
> Indeed I want to change my above codes somewhat and use the mnormt package.
>
> Thank you in advance
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@r|e|@@contrer@@ @end|ng |rom gm@||@com  Thu Jun 18 03:18:58 2020
From: m@r|e|@@contrer@@ @end|ng |rom gm@||@com (Mariela Contreras)
Date: Wed, 17 Jun 2020 19:18:58 -0600
Subject: [R] Support to reshape data from wide to long in R using the
 argument pivot_longer
Message-ID: <CACdDnwS0hk-7gWdYygxMCaEJt9_AWqzXW5O6SGcto5QxT+njhg@mail.gmail.com>

Hi all,

I am using Demographic and Health Survey data and want to convert the data
from wide to long in R. I got an error when I used the argument
pivot_longer, recommended in Stack Overflow. Below you can see my steps
with codes and also the data output. I imported the data from PSPP.

"HNIR62FL_data_1 <read_sav("~/DHS/HNIR62SV/HNIR62FL_data_1.SAV")"
"obsHNIR62FL_data_1 <- subset(HNIR62FL_data_1, !is.na(V021) & !is.na(V022)
& !is.na(D005))"

"myvars <- c("CASEID", "V013", "V021", "V022", "V025", "V106", "V137",
"V190", "V714", "D005", "D104", "D106", "D107", "D108","v1014", "v1016",
"v1023", "v1038", "v1039", "v1045", "v1113", "V701", "v1007_1", "v1007_2",
"v1007_3", "v1007_4", "v1008_1", "v1008_2", "v1008_3", "v1008_4",
"v1009_1", "v1009_2", "v1009_3", "v1009_4", "v1010_1", "v1010_2",
"v1010_3", "v1010_4", "v1020_1", "v1020_2", "v1020_3", "v1020_4",
"v1071_1", "v1071_2", "v1071_3", "v1071_4", "v1088_1", "v1088_2",
"v1088_3", "v1088_4", "v1096_1", "v1096_2", "v1096_3", "v1096_4",
"v1104_1", "v1104_2", "v1104_3", "v1104_4", "v1111_1", "v1111_2",
"v1111_3", "v1111_4", "v1112_1", "v1112_2", "v1112_3", "v1112_4")"

"newobsHNIR62FL_data_1 <- obsHNIR62FL_data_1[myvars]"

"tidyr::pivot_longer(newobsHNIR62FL_data_1, cols=starts_with(c("V", "v")),
names_to = c("name", "id"), values_to = "value", names_sep = "_")"

Error: Can't convert from > to > due to loss of precision. * Locations: 1,
3, 4, 5, 6, 9, 13, 15, 16, 17, 18, 19, 20, 21, 22, 24, 26, ... Values are
labelled in but not in.

In addition: Warning message: Expected 2 pieces. Missing pieces filled with
NA in 16 rows [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16].

"dput(head(newobsHNIR62FL_data_1))"

structure(list(CASEID = structure(c(" 372151 1", " 503201 2", " 76 81 1", "
603191 2", " 559 21 1", " 643131 1" ), label = "Case Identification",
format.spss = "A15", display_width = 17L), V013 = structure(c(3, 2, 3, 4,
3, 5), label = "Age in 5-year groups", format.spss = "F1.0", display_width
= 6L, labels = c(15-19 = 1, 20-24 = 2, 25-29 = 3, 30-34 = 4, 35-39 = 5,
40-44 = 6, 45-49 = 7), class = c("haven_labelled", "vctrs_vctr", "double"
)), V021 = structure(c(372, 503, 76, 603, 559, 643), label = "Primary
sampling unit", format.spss = "F4.0", display_width = 6L), V022 =
structure(c(11, 16, 3, 18, 16, 20), label = "Sample strata for sampling
errors", format.spss = "F4.0", display_width = 6L, labels = c(Atl?ntida
Urbano = 1, Atl?ntida Rural = 2, Col?n Urbano = 3, Col?n Rural = 4, Comayagua
Urbano = 5, Comayagua Rural = 6, Cop?n Urbano = 7, Cop?n Rural = 8, San
Pedro Sula Urbano = 9, Cort?s Resto Urbano = 10, Cort?s Resto Rural =
11, Choluteca
Urbano = 12, Choluteca Rural = 13, El Para?so Urbano = 14, El Para?so Rural =
15, Tegucigalpa Urbano = 16, Moraz?n Resto Urbano = 17, Moraz?n Resto Rural =
18, Gracias a Dios Urbano = 19, Gracias a Dios Rural = 20, Intibuc? Urbano =
21, Intibuc? Rural = 22, Islas de Bah?a Urbano = 23, Islas de Bah?a Rural =
24, La Paz Urbano = 25, La Paz Rural = 26, Lempira Urbano = 27, Lempira
Rural = 28, Ocotepeque Urbano = 29, Ocotepeque Rural = 30, Olancho Urbano =
31, Olancho Rural = 32, Santa B?rbara Urbano = 33, Santa B?rbara Rural =
34, Valle Urbano = 35, Valle Rural = 36, Yoro Urbano = 37, Yoro Rural =
38), class = c("haven_labelled", "vctrs_vctr", "double")), V025 =
structure(c(2, 1, 1, 2, 1, 2), label = "Type of place of residence",
format.spss = "F1.0", display_width = 6L, labels = c(Urban = 1, Rural = 2),
class = c("haven_labelled", "vctrs_vctr", "double" )), V106 =
structure(c(3, 2, 2, 1, 2, 1), label = "Highest educational level",
format.spss = "F1.0", display_width = 6L, labels = c(No education = 0,
Primary = 1, Secondary = 2, Higher = 3), class = c("haven_labelled",
"vctrs_vctr", "double")), V137 = structure(c(2, 1, 0, 0, 1, 0), label =
"Number of children 5 and under in household (de jure)", format.spss =
"F2.0", display_width = 6L), V190 = structure(c(5, 5, 4, 2, 4, 1), label =
"Wealth index", format.spss = "F1.0", display_width = 6L, labels =
c(Poorest = 1, Poorer = 2, Middle = 3, Richer = 4, Richest = 5), class =
c("haven_labelled", "vctrs_vctr", "double")), V714 = structure(c(1, 1, 1,
1, 1, 1), label = "Respondent currently working", format.spss = "F1.0",
display_width = 6L, labels = c(No = 0, Yes = 1), class =
c("haven_labelled", "vctrs_vctr", "double" )), D005 = structure(c(1190085,
1726649, 607124, 1671912, 1102085, 118158), label = "Weight for Domestic
Violence (6 decimals)", format.spss = "F8.0", display_width = 10L), D104 =
structure(c(0, 0, 0, 1, 0, 0), label = "Experienced any emotional
violence", format.spss = "F1.0", display_width = 6L, labels = c(No = 0, Yes
= 1), class = c("haven_labelled", "vctrs_vctr", "double" )), D106 =
structure(c(0, 0, 0, 0, 0, 0), label = "Experienced any less severe
violence (D105A-C,J) by husband/partner", format.spss = "F1.0",
display_width = 6L, labels = c(No = 0, Yes (D105A-D) = 1), class =
c("haven_labelled", "vctrs_vctr", "double")), D107 = structure(c(0, 0, 0,
0, 0, 0), label = "Experienced any severe violence (D105D-F) by
husband/partner", format.spss = "F1.0", display_width = 6L, labels = c(No =
0, Yes (D105E-G) = 1), class = c("haven_labelled", "vctrs_vctr",
"double")), D108 = structure(c(0, 0, 0, 0, 0, 0), label = "Experienced any
sexual violence (D105H-I,K) by husband/partner", format.spss = "F1.0",
display_width = 6L, labels = c(No = 0, Yes (D105H-I) = 1), class =
c("haven_labelled", "vctrs_vctr", "double")), v1014 = structure(c(2, 2, 3,
3, 3, 4), label = "women BMI category", format.spss = "F8.0", labels =
c(underweight = 1, normal weight = 2, overweight = 3, obese = 4), class =
c("haven_labelled", "vctrs_vctr", "double")), v1016 = structure(c(1, 1, 1,
0, 1, 0), label = "women height category", format.spss = "F8.0",
labels = c(woman
height <150 cm = 0, woman height 150 cm or more = 1), class =
c("haven_labelled", "vctrs_vctr", "double")), v1023 = structure(c(2, 1, 1,
2, 1, 1), label = "parity", format.spss = "F8.0", labels = c(0 = 0, 1 = 1, 2 =
2, 3 = 3, 4 = 4, 5 or more = 5), class = c("haven_labelled", "vctrs_vctr",
"double")), v1038 = structure(c(2, 3, 2, 3, 3, 2), label = "marital
status", format.spss = "F8.0", labels = c(Never in union = 0, Married
= 1, Living
with partner = 2, Divorced, widowed or separated/no longer living together =
3 ), class = c("haven_labelled", "vctrs_vctr", "double")), v1039 =
structure(c(2, 2, 2, 3, 1, 4), label = "marital duration", format.spss =
"F8.0", labels = c(Never in a union = 0, 0-4 years = 1, 5-9 years = 2, 10-14
years = 3, 15 years or more = 4 ), class = c("haven_labelled",
"vctrs_vctr", "double")), v1045 = structure(c(4, NA, 4, NA, NA, 4), label =
"Women decision making scale", format.spss = "F8.0", labels = c(No decision
making skills = 0, Respondent alone/respondent and husband/partner decide
on one issue = 1, Respondent alone/respondent and husband/partner decide on
two issues = 2, Respondent alone/respondent and husband/partner decide on
three issues = 3, Respondent alone/respondent and husband/partner decide on
four issues = 4 ), class = c("haven_labelled", "vctrs_vctr", "double")),
v1113 = structure(c(0, 0, 0, 1, 0, 0), label = "Any intimate partner
violence", format.spss = "F8.0", labels = c(Has not experienced any form of
intimate partner violence = 0, Has experienced any form of intimate partner
violence = 1 ), class = c("haven_labelled", "vctrs_vctr", "double")), V701
= structure(c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_),
label = "Husband/partner's education level", format.spss = "F1.0",
display_width = 6L, labels = c(No education = 0, Primary = 1, Secondary =
2, Higher = 3, Don't know = 8), class = c("haven_labelled", "vctrs_vctr",
"double")), v1007_1 = structure(c(1, 1, NA, NA, 1, NA), label = "youngest
child stunting category", format.spss = "F8.0", labels = c(stunted child =
0, not stunted child = 1), class = c("haven_labelled", "vctrs_vctr",
"double")), v1007_2 = structure(c(NA_real_, NA_real_, NA_real_, NA_real_,
NA_real_, NA_real_), label = "stunting category (second to youngest
child)", format.spss = "F8.0", labels = c(stunted = 0, not stunted = 1),
class = c("haven_labelled", "vctrs_vctr", "double")), v1007_3 =
structure(c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_),
label = "stunting category (third to youngest child)", format.spss =
"F8.0", labels = c(stunted = 0, not stunted = 1), class =
c("haven_labelled", "vctrs_vctr", "double")), v1007_4 =
structure(c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_),
label = "stunting category (fourth to youngest child)", format.spss =
"F8.0", labels = c(stunted = 0, not stunted = 1), class =
c("haven_labelled", "vctrs_vctr", "double")), v1008_1 = structure(c(1, 1,
NA, NA, 1, NA), label = "youngest child underweight category", format.spss
= "F8.0", labels = c(underweight child = 0, not underweight child = 1),
class = c("haven_labelled", "vctrs_vctr", "double")), v1008_2 =
structure(c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_),
label = "underweight category (second to youngest child)", format.spss =
"F8.0", labels = c(underweight = 0, not underweight = 1), class =
c("haven_labelled", "vctrs_vctr", "double")), v1008_3 =
structure(c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_),
label = "underweight category (third to youngest child)", format.spss =
"F8.0", labels = c(underweight = 0, not underweight = 1), class =
c("haven_labelled", "vctrs_vctr", "double")), v1008_4 =
structure(c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_),
label = "underweight category (fourth to youngest child)", format.spss =
"F8.0", labels = c(underweight = 0, not underweight = 1), class =
c("haven_labelled", "vctrs_vctr", "double")), v1009_1 = structure(c(1, 1,
NA, NA, 1, NA), label = "youngest child wasting category", format.spss =
"F8.0", labels = c(wasted child = 0, not wasted child = 1), class =
c("haven_labelled", "vctrs_vctr", "double")), v1009_2 =
structure(c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_),
label = "wasting category (second to youngest child)", format.spss =
"F8.0", labels = c(wasted = 0, not wasted = 1), class = c("haven_labelled",
"vctrs_vctr", "double")), v1009_3 = structure(c(NA_real_, NA_real_,
NA_real_, NA_real_, NA_real_, NA_real_), label = "wasting category (third
to youngest child)", format.spss = "F8.0", labels = c(wasted = 0, not wasted =
1), class = c("haven_labelled", "vctrs_vctr", "double")), v1009_4 =
structure(c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_),
label = "wasting category (fourth to youngest child)", format.spss =
"F8.0", labels = c(wasted = 0, not wasted = 1), class = c("haven_labelled",
"vctrs_vctr", "double")), v1010_1 = structure(c(1, 1, NA, NA, 1, NA), label
= "youngest child overweight category", format.spss = "F8.0", labels =
c(overweight
child = 0, not overweight child = 1), class = c("haven_labelled",
"vctrs_vctr", "double")), v1010_2 = structure(c(NA_real_, NA_real_,
NA_real_, NA_real_, NA_real_, NA_real_), label = "overweight category
(second to youngest child)", format.spss = "F8.0", labels = c(overweight =
0, not overweight = 1), class = c("haven_labelled", "vctrs_vctr",
"double")), v1010_3 = structure(c(NA_real_, NA_real_, NA_real_, NA_real_,
NA_real_, NA_real_), label = "overweight category (third to youngest
child)", format.spss = "F8.0", labels = c(overweight = 0, not overweight =
1), class = c("haven_labelled", "vctrs_vctr", "double")), v1010_4 =
structure(c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_),
label = "overweight category (fourth to youngest child)", format.spss =
"F8.0", labels = c(overweight = 0, not overweight = 1), class =
c("haven_labelled", "vctrs_vctr", "double")), v1020_1 = structure(c(1, 1,
NA, NA, 0, NA), label = "youngest child morbidity category", format.spss =
"F8.0", labels = c(youngest child with no morbidity = 0, youngest child
with morbidity = 1), class = c("haven_labelled", "vctrs_vctr", "double")),
v1020_2 = structure(c(0, NA, NA, NA, NA, NA), label = "Morbidity category
(second to youngest child)", format.spss = "F8.0", labels = c(youngest
child with no morbidity = 0, youngest child with morbidity = 1), class =
c("haven_labelled", "vctrs_vctr", "double")), v1020_3 =
structure(c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_),
label = "Morbidity category (third to youngest child)", format.spss =
"F8.0", labels = c(youngest child with no morbidity = 0, youngest child
with morbidity = 1), class = c("haven_labelled", "vctrs_vctr", "double")),
v1020_4 = structure(c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_,
NA_real_), label = "Morbidity category (fourth to youngest child)",
format.spss = "F8.0", labels = c(youngest child with no morbidity = 0, youngest
child with morbidity = 1), class = c("haven_labelled", "vctrs_vctr",
"double")), v1071_1 = structure(c(NA, 1, NA, NA, 1, NA), label = "anemia
category (youngest child)", format.spss = "F8.0", labels = c(anemic = 0, not
anemic = 1), class = c("haven_labelled", "vctrs_vctr", "double")), v1071_2
= structure(c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_),
label = "anemia category (second to youngest child)", format.spss = "F8.0",
labels = c(anemic = 0, not anemic = 1), class = c("haven_labelled",
"vctrs_vctr", "double")), v1071_3 = structure(c(NA_real_, NA_real_,
NA_real_, NA_real_, NA_real_, NA_real_), label = "anemia category (third to
youngest child)", format.spss = "F8.0", labels = c(anemic = 0, not anemic =
1), class = c("haven_labelled", "vctrs_vctr", "double")), v1071_4 =
structure(c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_),
label = "anemia category (fourth to youngest child)", format.spss = "F8.0",
labels = c(anemic = 0, not anemic = 1), class = c("haven_labelled",
"vctrs_vctr", "double")), v1088_1 = structure(c(1, 1, NA, NA, 1, NA), label
= "youngest child stunting + overweight category", format.spss = "F8.0",
labels = c(stunted and overweight child = 0, not stunted and overweight
child = 1), class = c("haven_labelled", "vctrs_vctr", "double")), v1088_2 =
structure(c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_),
label = "second to youngest child stunting + overweight category",
format.spss = "F8.0", labels = c(stunted and overweight child = 0, not
stunted and overweight child = 1), class = c("haven_labelled",
"vctrs_vctr", "double")), v1088_3 = structure(c(NA_real_, NA_real_,
NA_real_, NA_real_, NA_real_, NA_real_), label = "third to youngest child
stunting + overweight category", format.spss = "F8.0", labels = c(stunted
and overweight child = 0, not stunted and overweight child = 1), class =
c("haven_labelled", "vctrs_vctr", "double")), v1088_4 =
structure(c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_),
label = "fourth to youngest child stunting + overweight category",
format.spss = "F8.0", labels = c(stunted and overweight child = 0, not
stunted and overweight child = 1), class = c("haven_labelled",
"vctrs_vctr", "double")), v1096_1 = structure(c(NA, 1, NA, NA, 1, NA),
label = "youngest child anemic + overweight category", format.spss =
"F8.0", labels = c(anemic and overweight child = 0, not anemic and
overweight child = 1), class = c("haven_labelled", "vctrs_vctr",
"double")), v1096_2 = structure(c(NA_real_, NA_real_, NA_real_, NA_real_,
NA_real_, NA_real_), label = "second to youngest child anemic + overweight
category", format.spss = "F8.0", labels = c(anemic and overweight child =
0, not anemic and overweight child = 1), class = c("haven_labelled",
"vctrs_vctr", "double")), v1096_3 = structure(c(NA_real_, NA_real_,
NA_real_, NA_real_, NA_real_, NA_real_), label = "third to youngest child
anemic + overweight category", format.spss = "F8.0", labels = c(anemic and
overweight child = 0, not anemic and overweight child = 1), class =
c("haven_labelled", "vctrs_vctr", "double")), v1096_4 =
structure(c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_),
label = "fourth to youngest child anemic + overweight category",
format.spss = "F8.0", labels = c(anemic and overweight child = 0, not
anemic and overweight child = 1), class = c("haven_labelled", "vctrs_vctr",
"double")), v1104_1 = structure(c(NA, 1, NA, NA, 1, NA), label = "youngest
child anemic + stunted category", format.spss = "F8.0", labels = c(anemic
and stunted child = 0, not anemic and not stunted child = 1), class =
c("haven_labelled", "vctrs_vctr", "double")), v1104_2 =
structure(c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_),
label = "second to youngest child anemic + stunted category", format.spss =
"F8.0", labels = c(anemic and stunted child = 0, not anemic and stunted
child = 1), class = c("haven_labelled", "vctrs_vctr", "double")), v1104_3 =
structure(c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_),
label = "third to youngest child anemic + stunted category", format.spss =
"F8.0", labels = c(anemic and stunted child = 0, not anemic and stunted
child = 1), class = c("haven_labelled", "vctrs_vctr", "double")), v1104_4 =
structure(c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_),
label = "fourth to youngest child anemic + stunted category", format.spss =
"F8.0", labels = c(stunted and anemic child = 0, not stunted and anemic
child = 1), class = c("haven_labelled", "vctrs_vctr", "double")), v1111_1 =
structure(c(2, 5, NA, NA, 6, NA), label = "Child age (youngest child)",
format.spss = "F8.0", labels = c(0-5 months = 1, 6-11 months = 2, 12-23
months = 3, 24-35 months = 4, 36-47 months = 5, 48-59 months = 6), class =
c("haven_labelled", "vctrs_vctr", "double")), v1111_2 = structure(c(5, NA,
NA, NA, NA, NA), label = "Child age (second to youngest)", format.spss =
"F8.0", labels = c(0-5 months = 1, 6-11 months = 2, 12-23 months = 3, 24-35
months = 4, 36-47 months = 5, 48-59 months = 6), class =
c("haven_labelled", "vctrs_vctr", "double")), v1111_3 =
structure(c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_),
label = "Child age (third to youngest)", format.spss = "F8.0", labels = c(0-5
months = 1, 6-11 months = 2, 12-23 months = 3, 24-35 months = 4, 36-47
months = 5, 48-59 months = 6), class = c("haven_labelled", "vctrs_vctr",
"double")), v1111_4 = structure(c(NA_real_, NA_real_, NA_real_, NA_real_,
NA_real_, NA_real_), label = "Child age (fourth to youngest)", format.spss
= "F8.0", labels = c(0-5 months = 1, 6-11 months = 2, 12-23 months = 3, 24-35
months = 4, 36-47 months = 5, 48-59 months = 6), class =
c("haven_labelled", "vctrs_vctr", "double")), v1112_1 = structure(c(2, 1,
2, 2, 2, 1), label = "Sex of child", format.spss = "F1.0", display_width =
7L, labels = c(Male = 1, Female = 2), class = c("haven_labelled",
"vctrs_vctr", "double" )), v1112_2 = structure(c(2, NA, NA, 2, NA, NA),
label = "Sex of child", format.spss = "F1.0", display_width = 7L, labels =
c(Male = 1, Female = 2), class = c("haven_labelled", "vctrs_vctr", "double"
)), v1112_3 = structure(c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_,
NA_real_), label = "Sex of child", format.spss = "F1.0", display_width =
7L, labels = c(Male = 1, Female = 2), class = c("haven_labelled",
"vctrs_vctr", "double" )), v1112_4 = structure(c(NA_real_, NA_real_,
NA_real_, NA_real_, NA_real_, NA_real_), label = "Sex of child",
format.spss = "F1.0", display_width = 7L, labels = c(Male = 1, Female = 2),
class = c("haven_labelled", "vctrs_vctr", "double" ))), row.names = c(NA,
-6L), class = c("tbl_df", "tbl", "data.frame"))

How can I proceed?

Thank you for your support.

All the best,

Mariela

	[[alternative HTML version deleted]]


From @ho@|b@||gw|02 @end|ng |rom gm@||@com  Thu Jun 18 07:52:16 2020
From: @ho@|b@||gw|02 @end|ng |rom gm@||@com (shaaib)
Date: Thu, 18 Jun 2020 11:22:16 +0530
Subject: [R] number of count in function
Message-ID: <CAMDUrYObtbWhfrWmt9n7OjrXGsB4fp72_HW-A2Y2ts+qiisdpg@mail.gmail.com>

Hi I have created function for a summary and i want "N" (number of
frequency) should come at the second row but its coming in between
variables, not coming at top and bottom. please help where i am missing or
where i need to change.

multi<-function(dataset,var_list,var_name){
data<-dataset[unlist(var_list)]

total_column<-NA^!rowSums(!is.na(data[,1:ncol(data)]))
lst1 <- lapply(names(data[,1:ncol(data)]), function(x) freq(data,x))
lst2 <- lst1[!sapply(lst1, is.null)]
tab<-Reduce(rbind,lst2)
tab<-tab%>%
mutate(Var1=as.character(Var1),
Freq=as.numeric(Freq),
N=sum(total_column,na.rm = TRUE))%>%
mutate(UQ(rlang::sym(var_name)) := Freq*100/N)%>%
select(Var1,!!var_name,N)%>%
dplyr::rename(" "=Var1)
tab[,2]<- mask_m(tab[,2],tab[,3])
tab[,2]<-ifelse(tab[,2]=="--","--", paste0(roundUp(tab[,2]),"%"))
tab<-rbind(c("N",sum(total_column,na.rm = TRUE)),tab[,1:2])
tab
}

	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Jun 18 09:14:54 2020
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 18 Jun 2020 09:14:54 +0200
Subject: [R] R 4.0.1/R-devel 2020-06-16-r78702 built with Intel Composer
 19.1.1, error in R CMD make check on CentOS 7.7
In-Reply-To: <D2041414-AF32-4B9E-9A75-430E6ECE334A@rutgers.edu>
References: <39C5E435-33B5-4753-9E9E-BCAB869CDCDF@rutgers.edu>
 <D2041414-AF32-4B9E-9A75-430E6ECE334A@rutgers.edu>
Message-ID: <24299.5230.897469.73576@stat.math.ethz.ch>

>>>>> Ryan Novosielski 
>>>>>     on Wed, 17 Jun 2020 22:04:30 +0000 writes:

    > Same story with R-devel 2020-06-16-r78702, everything else the same. Should I be reporting this someplace else?

Well, maybe Intel?  {I've never heard of 'Intel Composer', and
to me it does not look like Free / Open Source Software so why
should I care}

In any case, such issues belong more to the  R-devel mailing
list than R-help.

Best regards,
Martin Maechler
ETH Zurich  and  R Core team


    > ____
    > || \\UTGERS,  	 |---------------------------*O*---------------------------
    > ||_// the State	 |         Ryan Novosielski - novosirj at rutgers.edu
    > || \\ University | Sr. Technologist - 973/972.0922 (2x0922) ~*~ RBHS Campus
    > ||  \\    of NJ	 | Office of Advanced Research Computing - MSB C630, Newark
    > `'

    >> On Jun 13, 2020, at 10:16 PM, Ryan Novosielski <novosirj at rutgers.edu> wrote:
    >> 
    >> Signed PGP part
    >> Hi there,
    >> 
    >> Built R 4.0.1 with the Intel Composer 19.1.1. Build seems to go fine. I built it like this:
    >> 
    >> module purge
    >> module load intel/19.1.1
    >> module list
    >> 
    >> export CC=icc
    >> export CXX=icpc
    >> export F77=ifort
    >> export FC=ifort
    >> export AR=xiar
    >> export LD=xild
    >> 
    >> export CFLAGS="-O3 -ipo -qopenmp -axAVX,CORE-AVX2,CORE-AVX512"
    >> export F77FLAGS="-O3 -ipo -qopenmp -axAVX,CORE-AVX2,CORE-AVX512"
    >> export FFLAGS="-O3 -ipo -qopenmp -axAVX,CORE-AVX2,CORE-AVX512"
    >> export CXXFLAGS="-O3 -ipo -qopenmp -axAVX,CORE-AVX2,CORE-AVX512"
    >> export MKL="-lmkl_intel_lp64 -lmkl_intel_thread -lmkl_core -liomp5 -lpthread"
    >> 
    >> VERSION=4.0.1
    >> 
    >> /scratch/novosirj/install-files/R-${VERSION}/configure --with-blas="$MKL" --with-lapack --prefix=/opt/sw/packages/intel-19_1/R-Project/${VERSION} && \
    >> make -j32 && make check && make -j32 install
    >> 
    >> However, the ?make check" phase fails at this part:
    >> 
    >> Testing examples for package ?parallel?
    >> make[2]: Leaving directory `/mnt/scratch/novosirj/R-4.0.1-intel-19.1-build/tests/Examples'
    >> make[1]: Leaving directory `/mnt/scratch/novosirj/R-4.0.1-intel-19.1-build/tests'
    >> make[1]: Entering directory `/mnt/scratch/novosirj/R-4.0.1-intel-19.1-build/tests'
    >> running strict specific tests
    >> make[2]: Entering directory `/mnt/scratch/novosirj/R-4.0.1-intel-19.1-build/tests'
    >> running code in '/scratch/novosirj/install-files/R-4.0.1/tests/eval-etc.R' ... OK
    >> comparing 'eval-etc.Rout' to '/scratch/novosirj/install-files/R-4.0.1/tests/eval-etc.Rout.save' ... OK
    >> running code in '/scratch/novosirj/install-files/R-4.0.1/tests/simple-true.R' ... OK
    >> comparing 'simple-true.Rout' to '/scratch/novosirj/install-files/R-4.0.1/tests/simple-true.Rout.save' ... OK
    >> running code in '/scratch/novosirj/install-files/R-4.0.1/tests/arith-true.R' ... OK
    >> comparing 'arith-true.Rout' to '/scratch/novosirj/install-files/R-4.0.1/tests/arith-true.Rout.save' ... OK
    >> running code in '/scratch/novosirj/install-files/R-4.0.1/tests/arith.R' ... OK
    >> comparing 'arith.Rout' to '/scratch/novosirj/install-files/R-4.0.1/tests/arith.Rout.save' ... OK
    >> running code in '/scratch/novosirj/install-files/R-4.0.1/tests/lm-tests.R' ... OK
    >> comparing 'lm-tests.Rout' to '/scratch/novosirj/install-files/R-4.0.1/tests/lm-tests.Rout.save' ... OK
    >> /bin/sh: line 1: 62064 Segmentation fault      (core dumped) LANGUAGE=en LC_ALL=C SRCDIR=/scratch/novosirj/install-files/R-4.0.1/tests R_DEFAULT_PACKAGES= ../bin/R --vanilla < /scratch/novosirj/install-files/R-4.0.1/tests/ok-errors.R > ok-errors.Rout.fail 2>&1
    >> running code in '/scratch/novosirj/install-files/R-4.0.1/tests/ok-errors.R' ...make[2]: *** [ok-errors.Rout] Error 1
    >> make[2]: Leaving directory `/mnt/scratch/novosirj/R-4.0.1-intel-19.1-build/tests'
    >> make[1]: *** [test-Specific] Error 2
    >> make[1]: Leaving directory `/mnt/scratch/novosirj/R-4.0.1-intel-19.1-build/tests'
    >> make: *** [test-all-basics] Error 1
    >> 
    >> Is this something I should be concerned about, or something I can fix? Not seeing any real information about what?s going wrong here. Here?s what?s contained in ok-errors.Rout.fail:
    >> 
    >> ---
    >> R version 4.0.1 (2020-06-06) -- "See Things Now"
    >> Copyright (C) 2020 The R Foundation for Statistical Computing
    >> Platform: x86_64-pc-linux-gnu (64-bit)
    >> 
    >> R is free software and comes with ABSOLUTELY NO WARRANTY.
    >> You are welcome to redistribute it under certain conditions.
    >> Type 'license()' or 'licence()' for distribution details.
    >> 
    >> R is a collaborative project with many contributors.
    >> Type 'contributors()' for more information and
    >> 'citation()' on how to cite R or R packages in publications.
    >> 
    >> Type 'demo()' for some demos, 'help()' for on-line help, or
    >> 'help.start()' for an HTML browser interface to help.
    >> Type 'q()' to quit R.
    >> 
    >>> #### STRICT test suite in the spirit of no-segfaults,
    >>> #### but with explicit statements.
    >>> 
    >>> options(error=expression(NULL))
    >>> stop("test of `options(error=expression(NULL))'")
    >> Error: test of `options(error=expression(NULL))'
    >>> 
    >>> if(FALSE) {
    >> + ## these ought to work on machines with enough memory
    >> + ## These segfaulted in 1.3.x ,  give "could not allocate" errors now
    >> +   integer(2^30+1)
    >> +    double(2^30+1)
    >> +   complex(2^30+1)
    >> + character(2^30+1)
    >> + vector("list", 2^30+2)
    >> + }
    >>> 
    >>> ## bad infinite recursion / on.exit / ... interactions
    >>> ##   catch the error to permit different error messages emitted
    >>> ##   (handling of infinite recursion is different in the AST interpreter
    >>> ##   and the byte-code interpreter)
    >>> 
    >>> bar <- function() 1+1
    >>> foo <- function() { on.exit(bar()); foo() }
    >>> tryCatch(foo(), error=function(x) TRUE) # now simple "infinite recursion"
    >> 
    >> *** caught segfault ***
    >> address 0x7fff4dc1b9f8, cause 'memory not mapped'
    >> 
    >> Traceback:
    >> 1: foo()
    >> 2: foo()
    >> 3: foo()
    >> 4: foo()
    >> 
    >> ...
    >> 
    >> 2712: foo()
    >> 2713: foo()
    >> 2714: foo()
    >> 2715: foo()
    >> 2716: foo()
    >> 2717: foo()
    >> 2718: foo()
    >> 2719: doTryCatch(return(expr), name, parentenv, handler)
    >> 2720: tryCatchOne(expr, names, parentenv, handlers[[1L]])
    >> 2721: tryCatchList(expr, classes, parentenv, handlers)
    >> 2722: tryCatch(foo(), error = function(x) TRUE)
    >> An irrecoverable exception occurred. R is aborting now ...
    >> ---
    >> 
    >> Thanks in advance.
    >> 
    >> --
    >> ____
    >> || \\UTGERS,  	 |---------------------------*O*---------------------------
    >> ||_// the State	 |         Ryan Novosielski - novosirj at rutgers.edu
    >> || \\ University | Sr. Technologist - 973/972.0922 (2x0922) ~*~ RBHS Campus
    >> ||  \\    of NJ	 | Office of Advanced Research Computing - MSB C630, Newark
    >> `'
    >> 
    >> 
    >> 

    > x[DELETED ATTACHMENT signature.asc, application/pgp-signature]
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Thu Jun 18 12:52:23 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Thu, 18 Jun 2020 11:52:23 +0100
Subject: [R] comparing variances/distributions
In-Reply-To: <CAF9-5jMdS0_1SMNCzPdGYsTJYoeyYnoGnsNAqGFoyPYEMrjTwA@mail.gmail.com>
References: <CAF9-5jMdS0_1SMNCzPdGYsTJYoeyYnoGnsNAqGFoyPYEMrjTwA@mail.gmail.com>
Message-ID: <2af24c96-9fa9-a590-1b37-ba8e16f666ec@dewey.myzen.co.uk>

Dear Ana

This really depends on your scientific question. The two techniques you 
have shown do different things and there must be many more which could 
be applied.

Michael

On 17/06/2020 20:57, Ana Marija wrote:
> Hello,
> 
> I have p values from two distributions, Pold and Pnew
>> head(m)
>     CHR     POS     MARKER   Pnew   Pold
> 1:   1  785989  rs2980300 0.1419 0.9521
> 2:   1 1130727 rs10907175 0.1022 0.4750
> 3:   1 1156131  rs2887286 0.3698 0.5289
> 4:   1 1158631  rs6603781 0.1929 0.2554
> 5:   1 1211292  rs6685064 0.6054 0.2954
> 6:   1 1478153  rs3766180 0.6511 0.5542
> ...
> 
> In order to compare those two distributions (QQ plots shown in attach)
> does it make sense to use:
> 
> var.test(m$Pold, m$Pnew, alternative = "two.sided")
> 
>      F test to compare two variances
> 
> data:  m$Pold and m$Pnew
> F = 0.99937, num df = 1454159, denom df = 1454159, p-value = 0.7057
> alternative hypothesis: true ratio of variances is not equal to 1
> 95 percent confidence interval:
>   0.9970808 1.0016750
> sample estimates:
> ratio of variances
>           0.9993739
> 
> 
> Or some other test makes more sense?
> 
> Thanks
> Ana
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From W@|tK @end|ng |rom @mc@edu  Thu Jun 18 18:58:50 2020
From: W@|tK @end|ng |rom @mc@edu (Wait, Kristin)
Date: Thu, 18 Jun 2020 16:58:50 +0000
Subject: [R] R Software  Risk Analysis
Message-ID: <BLAPR17MB4226B28612AD2AD0D95288A6AF9B0@BLAPR17MB4226.namprd17.prod.outlook.com>

HI all,

I am with a NYS major trauma center and all programs that our employees/providers use must be vetted through the IT Department by way of a Risk Analysis.
Is there someone I would talk to about this?

I scoured your website and could not find a specific person.

Thank you so much
Kristin Wait
Albany, NY
----------------------------------------- CONFIDENTIALITY NOTICE: This email and any attachments may contain confidential information that is protected by law and is for the sole use of the individuals or entities to which it is addressed. If you are not the intended recipient, please notify the sender by replying to this email and destroying all copies of the communication and attachments. Further use, disclosure, copying, distribution of, or reliance upon the contents of this email and attachments is strictly prohibited. To contact Albany Medical Center, or for a copy of our privacy practices, please visit us on the Internet at www.amc.edu.

	[[alternative HTML version deleted]]


From john@m@h@rro|d @end|ng |rom gm@||@com  Fri Jun 19 00:41:29 2020
From: john@m@h@rro|d @end|ng |rom gm@||@com (John Harrold)
Date: Thu, 18 Jun 2020 15:41:29 -0700
Subject: [R] R Software Risk Analysis
In-Reply-To: <BLAPR17MB4226B28612AD2AD0D95288A6AF9B0@BLAPR17MB4226.namprd17.prod.outlook.com>
References: <BLAPR17MB4226B28612AD2AD0D95288A6AF9B0@BLAPR17MB4226.namprd17.prod.outlook.com>
Message-ID: <CANAiAiX_WhtA1LJeOgLSq3ZdQxu5P6AOOPfDmAoyNDZRgSrSAg@mail.gmail.com>

Hello Kristin,

Are you talking about risk analysis from the perspective of software
vulnerabilities?

John

On Thu, Jun 18, 2020 at 3:21 PM Wait, Kristin <WaitK at amc.edu> wrote:

> HI all,
>
> I am with a NYS major trauma center and all programs that our
> employees/providers use must be vetted through the IT Department by way of
> a Risk Analysis.
> Is there someone I would talk to about this?
>
> I scoured your website and could not find a specific person.
>
> Thank you so much
> Kristin Wait
> Albany, NY
> ----------------------------------------- CONFIDENTIALITY NOTICE: This
> email and any attachments may contain confidential information that is
> protected by law and is for the sole use of the individuals or entities to
> which it is addressed. If you are not the intended recipient, please notify
> the sender by replying to this email and destroying all copies of the
> communication and attachments. Further use, disclosure, copying,
> distribution of, or reliance upon the contents of this email and
> attachments is strictly prohibited. To contact Albany Medical Center, or
> for a copy of our privacy practices, please visit us on the Internet at
> www.amc.edu.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John
:wq

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Jun 19 00:55:13 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 18 Jun 2020 15:55:13 -0700
Subject: [R] R Software  Risk Analysis
In-Reply-To: <BLAPR17MB4226B28612AD2AD0D95288A6AF9B0@BLAPR17MB4226.namprd17.prod.outlook.com>
References: <BLAPR17MB4226B28612AD2AD0D95288A6AF9B0@BLAPR17MB4226.namprd17.prod.outlook.com>
Message-ID: <81CE887F-2659-4557-A60A-C55503B7EADA@dcn.davis.ca.us>

R is open source software that is offered as-is, and many users of R utilize additional "contributed" packages which are developed and vetted independently of the R Core members. In addition, it is common for users of R to add minor functionality in the course of obtaining useful results, which are clearly out of scope for R Core or any CRAN package maintainers. You may be able to find consultants who will address your concerns for a fee, but AFAIK that is not a service offered by the authors and maintainers of R and CRAN.

https://cran.r-project.org/web/packages/policies.html

On June 18, 2020 9:58:50 AM PDT, "Wait, Kristin" <WaitK at amc.edu> wrote:
>HI all,
>
>I am with a NYS major trauma center and all programs that our
>employees/providers use must be vetted through the IT Department by way
>of a Risk Analysis.
>Is there someone I would talk to about this?
>
>I scoured your website and could not find a specific person.
>
>Thank you so much
>Kristin Wait
>Albany, NY
>----------------------------------------- CONFIDENTIALITY NOTICE: This
>email and any attachments may contain confidential information that is
>protected by law and is for the sole use of the individuals or entities
>to which it is addressed. If you are not the intended recipient, please
>notify the sender by replying to this email and destroying all copies
>of the communication and attachments. Further use, disclosure, copying,
>distribution of, or reliance upon the contents of this email and
>attachments is strictly prohibited. To contact Albany Medical Center,
>or for a copy of our privacy practices, please visit us on the Internet
>at www.amc.edu.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Jun 19 01:45:52 2020
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Thu, 18 Jun 2020 16:45:52 -0700
Subject: [R] R Software Risk Analysis
In-Reply-To: <CANAiAiX_WhtA1LJeOgLSq3ZdQxu5P6AOOPfDmAoyNDZRgSrSAg@mail.gmail.com>
References: <BLAPR17MB4226B28612AD2AD0D95288A6AF9B0@BLAPR17MB4226.namprd17.prod.outlook.com>
 <CANAiAiX_WhtA1LJeOgLSq3ZdQxu5P6AOOPfDmAoyNDZRgSrSAg@mail.gmail.com>
Message-ID: <487fb208-ed7a-6e81-75ef-edbe28fa275a@comcast.net>


On 6/18/20 3:41 PM, John Harrold wrote:
> Hello Kristin,
>
> Are you talking about risk analysis from the perspective of software
> vulnerabilities?


It appears that is exactly what is being asked. What is not clear is 
whether the installation would be offered to persons or groups on the 
network with no other security wrappers. R has never claimed to be 
"web-safe". It offers access to system level commands and file system 
manipulation that would probably compromise security arrangements.? In 
fact, over the course of the last 12 years when I've been reading this 
mailing list, there has never been a credible suggestion to offer R 
applications to untrusted users. Quite the opposite. Naked R is surely 
not going to pass any sort threat or risk scrutiny.


My suggestion would be to investigate various wrappers for R such as 
Rstudio or the Microsoft re-worked version of what used to be Revolution 
R. They have lawyers and offer "enterprise solutions" and would 
presumably be able to speak to some sort of security analysis.? Whether 
either of those approaches would provide the level of security needed by 
a healthcare organization would be an interesting question. Perhaps yopu 
can report back after completing your investigation?


-- 

David.

>
> John
>
> On Thu, Jun 18, 2020 at 3:21 PM Wait, Kristin <WaitK at amc.edu> wrote:
>
>> HI all,
>>
>> I am with a NYS major trauma center and all programs that our
>> employees/providers use must be vetted through the IT Department by way of
>> a Risk Analysis.
>> Is there someone I would talk to about this?
>>
>> I scoured your website and could not find a specific person.
>>
>> Thank you so much
>> Kristin Wait
>> Albany, NY
>> ----------------------------------------- CONFIDENTIALITY NOTICE: This
>> email and any attachments may contain confidential information that is
>> protected by law and is for the sole use of the individuals or entities to
>> which it is addressed. If you are not the intended recipient, please notify
>> the sender by replying to this email and destroying all copies of the
>> communication and attachments. Further use, disclosure, copying,
>> distribution of, or reliance upon the contents of this email and
>> attachments is strictly prohibited. To contact Albany Medical Center, or
>> for a copy of our privacy practices, please visit us on the Internet at
>> www.amc.edu.
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From john@m@h@rro|d @end|ng |rom gm@||@com  Fri Jun 19 01:56:15 2020
From: john@m@h@rro|d @end|ng |rom gm@||@com (John Harrold)
Date: Thu, 18 Jun 2020 16:56:15 -0700
Subject: [R] R Software Risk Analysis
In-Reply-To: <487fb208-ed7a-6e81-75ef-edbe28fa275a@comcast.net>
References: <BLAPR17MB4226B28612AD2AD0D95288A6AF9B0@BLAPR17MB4226.namprd17.prod.outlook.com>
 <CANAiAiX_WhtA1LJeOgLSq3ZdQxu5P6AOOPfDmAoyNDZRgSrSAg@mail.gmail.com>
 <487fb208-ed7a-6e81-75ef-edbe28fa275a@comcast.net>
Message-ID: <CANAiAiVPRRVJB-otPxgk8dSvbPgopvPCgPtJxUf7MN1cMBkzew@mail.gmail.com>

I work in Pharma and we use R in all the companies I've worked for. They
are really paranoid and it's used in regulated environments as well with
patient data. So there should be something they can do.

Kristin: I can put you in touch with vendors who do our regulated work in R
if you're interested.

On Thu, Jun 18, 2020 at 4:45 PM David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On 6/18/20 3:41 PM, John Harrold wrote:
> > Hello Kristin,
> >
> > Are you talking about risk analysis from the perspective of software
> > vulnerabilities?
>
>
> It appears that is exactly what is being asked. What is not clear is
> whether the installation would be offered to persons or groups on the
> network with no other security wrappers. R has never claimed to be
> "web-safe". It offers access to system level commands and file system
> manipulation that would probably compromise security arrangements.  In
> fact, over the course of the last 12 years when I've been reading this
> mailing list, there has never been a credible suggestion to offer R
> applications to untrusted users. Quite the opposite. Naked R is surely
> not going to pass any sort threat or risk scrutiny.
>
>
> My suggestion would be to investigate various wrappers for R such as
> Rstudio or the Microsoft re-worked version of what used to be Revolution
> R. They have lawyers and offer "enterprise solutions" and would
> presumably be able to speak to some sort of security analysis.  Whether
> either of those approaches would provide the level of security needed by
> a healthcare organization would be an interesting question. Perhaps yopu
> can report back after completing your investigation?
>
>
> --
>
> David.
>
> >
> > John
> >
> > On Thu, Jun 18, 2020 at 3:21 PM Wait, Kristin <WaitK at amc.edu> wrote:
> >
> >> HI all,
> >>
> >> I am with a NYS major trauma center and all programs that our
> >> employees/providers use must be vetted through the IT Department by way
> of
> >> a Risk Analysis.
> >> Is there someone I would talk to about this?
> >>
> >> I scoured your website and could not find a specific person.
> >>
> >> Thank you so much
> >> Kristin Wait
> >> Albany, NY
> >> ----------------------------------------- CONFIDENTIALITY NOTICE: This
> >> email and any attachments may contain confidential information that is
> >> protected by law and is for the sole use of the individuals or entities
> to
> >> which it is addressed. If you are not the intended recipient, please
> notify
> >> the sender by replying to this email and destroying all copies of the
> >> communication and attachments. Further use, disclosure, copying,
> >> distribution of, or reliance upon the contents of this email and
> >> attachments is strictly prohibited. To contact Albany Medical Center, or
> >> for a copy of our privacy practices, please visit us on the Internet at
> >> www.amc.edu.
> >>
> >>          [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
>


-- 
John
:wq

	[[alternative HTML version deleted]]


From rmh @end|ng |rom temp|e@edu  Fri Jun 19 02:26:41 2020
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Thu, 18 Jun 2020 20:26:41 -0400
Subject: [R] [External] Re:  R Software Risk Analysis
In-Reply-To: <487fb208-ed7a-6e81-75ef-edbe28fa275a@comcast.net>
References: <BLAPR17MB4226B28612AD2AD0D95288A6AF9B0@BLAPR17MB4226.namprd17.prod.outlook.com>
 <CANAiAiX_WhtA1LJeOgLSq3ZdQxu5P6AOOPfDmAoyNDZRgSrSAg@mail.gmail.com>
 <487fb208-ed7a-6e81-75ef-edbe28fa275a@comcast.net>
Message-ID: <CAGx1TMA5E0YxEXvo7PE__tT_F1tpyT1Ys_Hrc0huQpihXDQqEg@mail.gmail.com>

You should start by reading
R: Regulatory Compliance and Validation Issues: A guidance document
for the use of R in regulated clinical trial environments.
https://www.r-project.org/doc/R-FDA.pdf

The official link to that file is at the R home page https://www.r-project.org/
In the left column, click on Certification.

That takes you to the page that offers the Compliance paper and a
paper on the R Development cycle.

Rich

On Thu, Jun 18, 2020 at 7:46 PM David Winsemius <dwinsemius at comcast.net> wrote:
>
>
> On 6/18/20 3:41 PM, John Harrold wrote:
> > Hello Kristin,
> >
> > Are you talking about risk analysis from the perspective of software
> > vulnerabilities?
>
>
> It appears that is exactly what is being asked. What is not clear is
> whether the installation would be offered to persons or groups on the
> network with no other security wrappers. R has never claimed to be
> "web-safe". It offers access to system level commands and file system
> manipulation that would probably compromise security arrangements.  In
> fact, over the course of the last 12 years when I've been reading this
> mailing list, there has never been a credible suggestion to offer R
> applications to untrusted users. Quite the opposite. Naked R is surely
> not going to pass any sort threat or risk scrutiny.
>
>
> My suggestion would be to investigate various wrappers for R such as
> Rstudio or the Microsoft re-worked version of what used to be Revolution
> R. They have lawyers and offer "enterprise solutions" and would
> presumably be able to speak to some sort of security analysis.  Whether
> either of those approaches would provide the level of security needed by
> a healthcare organization would be an interesting question. Perhaps yopu
> can report back after completing your investigation?
>
>
> --
>
> David.
>
> >
> > John
> >
> > On Thu, Jun 18, 2020 at 3:21 PM Wait, Kristin <WaitK at amc.edu> wrote:
> >
> >> HI all,
> >>
> >> I am with a NYS major trauma center and all programs that our
> >> employees/providers use must be vetted through the IT Department by way of
> >> a Risk Analysis.
> >> Is there someone I would talk to about this?
> >>
> >> I scoured your website and could not find a specific person.
> >>
> >> Thank you so much
> >> Kristin Wait
> >> Albany, NY
> >> ----------------------------------------- CONFIDENTIALITY NOTICE: This
> >> email and any attachments may contain confidential information that is
> >> protected by law and is for the sole use of the individuals or entities to
> >> which it is addressed. If you are not the intended recipient, please notify
> >> the sender by replying to this email and destroying all copies of the
> >> communication and attachments. Further use, disclosure, copying,
> >> distribution of, or reliance upon the contents of this email and
> >> attachments is strictly prohibited. To contact Albany Medical Center, or
> >> for a copy of our privacy practices, please visit us on the Internet at
> >> www.amc.edu.
> >>
> >>          [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Fri Jun 19 02:46:39 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 18 Jun 2020 17:46:39 -0700
Subject: [R] [External] Re: R Software Risk Analysis
In-Reply-To: <CAGx1TMA5E0YxEXvo7PE__tT_F1tpyT1Ys_Hrc0huQpihXDQqEg@mail.gmail.com>
References: <BLAPR17MB4226B28612AD2AD0D95288A6AF9B0@BLAPR17MB4226.namprd17.prod.outlook.com>
 <CANAiAiX_WhtA1LJeOgLSq3ZdQxu5P6AOOPfDmAoyNDZRgSrSAg@mail.gmail.com>
 <487fb208-ed7a-6e81-75ef-edbe28fa275a@comcast.net>
 <CAGx1TMA5E0YxEXvo7PE__tT_F1tpyT1Ys_Hrc0huQpihXDQqEg@mail.gmail.com>
Message-ID: <CAGxFJbTVzRru52Wv61XJks_wk6jr5_ewCxH8RY+4oQ9edkbUUQ@mail.gmail.com>

As others have noted, R's vulnerabilities depend on the environments in
which it is used. Perhaps the other issue is whether any downloaded R
software could be problematic, perhaps due to malware. R's core
functionality is, I'm sure fine. For the 20,000 or so packages on CRAN and
elsewhere -- ?? One would have to probaby check the security on CRAN's (or
others') servers for that. My ignorant expectation is that the most such
university associated servers are quite secure.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 18, 2020 at 5:27 PM Richard M. Heiberger <rmh at temple.edu> wrote:

> You should start by reading
> R: Regulatory Compliance and Validation Issues: A guidance document
> for the use of R in regulated clinical trial environments.
> https://www.r-project.org/doc/R-FDA.pdf
>
> The official link to that file is at the R home page
> https://www.r-project.org/
> In the left column, click on Certification.
>
> That takes you to the page that offers the Compliance paper and a
> paper on the R Development cycle.
>
> Rich
>
> On Thu, Jun 18, 2020 at 7:46 PM David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> >
> > On 6/18/20 3:41 PM, John Harrold wrote:
> > > Hello Kristin,
> > >
> > > Are you talking about risk analysis from the perspective of software
> > > vulnerabilities?
> >
> >
> > It appears that is exactly what is being asked. What is not clear is
> > whether the installation would be offered to persons or groups on the
> > network with no other security wrappers. R has never claimed to be
> > "web-safe". It offers access to system level commands and file system
> > manipulation that would probably compromise security arrangements.  In
> > fact, over the course of the last 12 years when I've been reading this
> > mailing list, there has never been a credible suggestion to offer R
> > applications to untrusted users. Quite the opposite. Naked R is surely
> > not going to pass any sort threat or risk scrutiny.
> >
> >
> > My suggestion would be to investigate various wrappers for R such as
> > Rstudio or the Microsoft re-worked version of what used to be Revolution
> > R. They have lawyers and offer "enterprise solutions" and would
> > presumably be able to speak to some sort of security analysis.  Whether
> > either of those approaches would provide the level of security needed by
> > a healthcare organization would be an interesting question. Perhaps yopu
> > can report back after completing your investigation?
> >
> >
> > --
> >
> > David.
> >
> > >
> > > John
> > >
> > > On Thu, Jun 18, 2020 at 3:21 PM Wait, Kristin <WaitK at amc.edu> wrote:
> > >
> > >> HI all,
> > >>
> > >> I am with a NYS major trauma center and all programs that our
> > >> employees/providers use must be vetted through the IT Department by
> way of
> > >> a Risk Analysis.
> > >> Is there someone I would talk to about this?
> > >>
> > >> I scoured your website and could not find a specific person.
> > >>
> > >> Thank you so much
> > >> Kristin Wait
> > >> Albany, NY
> > >> ----------------------------------------- CONFIDENTIALITY NOTICE: This
> > >> email and any attachments may contain confidential information that is
> > >> protected by law and is for the sole use of the individuals or
> entities to
> > >> which it is addressed. If you are not the intended recipient, please
> notify
> > >> the sender by replying to this email and destroying all copies of the
> > >> communication and attachments. Further use, disclosure, copying,
> > >> distribution of, or reliance upon the contents of this email and
> > >> attachments is strictly prohibited. To contact Albany Medical Center,
> or
> > >> for a copy of our privacy practices, please visit us on the Internet
> at
> > >> www.amc.edu.
> > >>
> > >>          [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Fri Jun 19 03:31:20 2020
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Fri, 19 Jun 2020 13:31:20 +1200
Subject: [R] R Software Risk Analysis
In-Reply-To: <BLAPR17MB4226B28612AD2AD0D95288A6AF9B0@BLAPR17MB4226.namprd17.prod.outlook.com>
References: <BLAPR17MB4226B28612AD2AD0D95288A6AF9B0@BLAPR17MB4226.namprd17.prod.outlook.com>
Message-ID: <CABcYAdKy=vnutYgwMPjQqgDVPHB-gHGaBBuKLm06uAhsXcPpbA@mail.gmail.com>

Just as a matter of curiosity, what are some of the programs
that have already been vetted, what methods were used, and
how long did the vetting take?

As the R guidance points out, R was not designed for
creating or updating medical records, so it should be
treated the same way as say LibreOffice Calc or Matlab.

On Fri, 19 Jun 2020 at 10:21, Wait, Kristin <WaitK at amc.edu> wrote:

> HI all,
>
> I am with a NYS major trauma center and all programs that our
> employees/providers use must be vetted through the IT Department by way of
> a Risk Analysis.
> Is there someone I would talk to about this?
>
> I scoured your website and could not find a specific person.
>
> Thank you so much
> Kristin Wait
> Albany, NY
> ----------------------------------------- CONFIDENTIALITY NOTICE: This
> email and any attachments may contain confidential information that is
> protected by law and is for the sole use of the individuals or entities to
> which it is addressed. If you are not the intended recipient, please notify
> the sender by replying to this email and destroying all copies of the
> communication and attachments. Further use, disclosure, copying,
> distribution of, or reliance upon the contents of this email and
> attachments is strictly prohibited. To contact Albany Medical Center, or
> for a copy of our privacy practices, please visit us on the Internet at
> www.amc.edu.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Jun 19 04:17:30 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 18 Jun 2020 19:17:30 -0700
Subject: [R] R Software Risk Analysis
In-Reply-To: <CABcYAdKy=vnutYgwMPjQqgDVPHB-gHGaBBuKLm06uAhsXcPpbA@mail.gmail.com>
References: <BLAPR17MB4226B28612AD2AD0D95288A6AF9B0@BLAPR17MB4226.namprd17.prod.outlook.com>
 <CABcYAdKy=vnutYgwMPjQqgDVPHB-gHGaBBuKLm06uAhsXcPpbA@mail.gmail.com>
Message-ID: <CAGxFJbQOpAdmEVbOuzT7D80LFKsazLNgoytM1F_KPGC6BARdMA@mail.gmail.com>

Ummm...Except that Matlab is proprietary and for profit, not open source.
Did you perhaps mean Octave?

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 18, 2020 at 6:31 PM Richard O'Keefe <raoknz at gmail.com> wrote:

> Just as a matter of curiosity, what are some of the programs
> that have already been vetted, what methods were used, and
> how long did the vetting take?
>
> As the R guidance points out, R was not designed for
> creating or updating medical records, so it should be
> treated the same way as say LibreOffice Calc or Matlab.
>
> On Fri, 19 Jun 2020 at 10:21, Wait, Kristin <WaitK at amc.edu> wrote:
>
> > HI all,
> >
> > I am with a NYS major trauma center and all programs that our
> > employees/providers use must be vetted through the IT Department by way
> of
> > a Risk Analysis.
> > Is there someone I would talk to about this?
> >
> > I scoured your website and could not find a specific person.
> >
> > Thank you so much
> > Kristin Wait
> > Albany, NY
> > ----------------------------------------- CONFIDENTIALITY NOTICE: This
> > email and any attachments may contain confidential information that is
> > protected by law and is for the sole use of the individuals or entities
> to
> > which it is addressed. If you are not the intended recipient, please
> notify
> > the sender by replying to this email and destroying all copies of the
> > communication and attachments. Further use, disclosure, copying,
> > distribution of, or reliance upon the contents of this email and
> > attachments is strictly prohibited. To contact Albany Medical Center, or
> > for a copy of our privacy practices, please visit us on the Internet at
> > www.amc.edu.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@oknz @end|ng |rom gm@||@com  Fri Jun 19 04:34:05 2020
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Fri, 19 Jun 2020 14:34:05 +1200
Subject: [R] R Software Risk Analysis
In-Reply-To: <CAGxFJbQOpAdmEVbOuzT7D80LFKsazLNgoytM1F_KPGC6BARdMA@mail.gmail.com>
References: <BLAPR17MB4226B28612AD2AD0D95288A6AF9B0@BLAPR17MB4226.namprd17.prod.outlook.com>
 <CABcYAdKy=vnutYgwMPjQqgDVPHB-gHGaBBuKLm06uAhsXcPpbA@mail.gmail.com>
 <CAGxFJbQOpAdmEVbOuzT7D80LFKsazLNgoytM1F_KPGC6BARdMA@mail.gmail.com>
Message-ID: <CABcYAdJ+akL2nHR49_7rW-mnFG3ZtoGjz8upCjSqGB4MW_7-=A@mail.gmail.com>

No, it was precisely my *point* that Matlab is proprietary.
The medical researchers I knew a few years ago refused to use
R on the grounds that the international agencies they dealt
with all used SAS, which is proprietary.  So I am wondering
if "ALL programs that our employees/PROVIDERS use" includes
things like Windows, Excel, SAS, Matlab, Oracle, DB2, ..."
and if so how the IT department could credibly vet them.

On Fri, 19 Jun 2020 at 14:17, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Ummm...Except that Matlab is proprietary and for profit, not open source.
> Did you perhaps mean Octave?
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Jun 18, 2020 at 6:31 PM Richard O'Keefe <raoknz at gmail.com> wrote:
>
>> Just as a matter of curiosity, what are some of the programs
>> that have already been vetted, what methods were used, and
>> how long did the vetting take?
>>
>> As the R guidance points out, R was not designed for
>> creating or updating medical records, so it should be
>> treated the same way as say LibreOffice Calc or Matlab.
>>
>> On Fri, 19 Jun 2020 at 10:21, Wait, Kristin <WaitK at amc.edu> wrote:
>>
>> > HI all,
>> >
>> > I am with a NYS major trauma center and all programs that our
>> > employees/providers use must be vetted through the IT Department by way
>> of
>> > a Risk Analysis.
>> > Is there someone I would talk to about this?
>> >
>> > I scoured your website and could not find a specific person.
>> >
>> > Thank you so much
>> > Kristin Wait
>> > Albany, NY
>> > ----------------------------------------- CONFIDENTIALITY NOTICE: This
>> > email and any attachments may contain confidential information that is
>> > protected by law and is for the sole use of the individuals or entities
>> to
>> > which it is addressed. If you are not the intended recipient, please
>> notify
>> > the sender by replying to this email and destroying all copies of the
>> > communication and attachments. Further use, disclosure, copying,
>> > distribution of, or reliance upon the contents of this email and
>> > attachments is strictly prohibited. To contact Albany Medical Center, or
>> > for a copy of our privacy practices, please visit us on the Internet at
>> > www.amc.edu.
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From cry@n @end|ng |rom b|ngh@mton@edu  Fri Jun 19 05:47:52 2020
From: cry@n @end|ng |rom b|ngh@mton@edu (Christopher W. Ryan)
Date: Thu, 18 Jun 2020 23:47:52 -0400
Subject: [R] [External Email]  R Software Risk Analysis
In-Reply-To: <BLAPR17MB4226B28612AD2AD0D95288A6AF9B0@BLAPR17MB4226.namprd17.prod.outlook.com>
References: <BLAPR17MB4226B28612AD2AD0D95288A6AF9B0@BLAPR17MB4226.namprd17.prod.outlook.com>
Message-ID: <92da77e4-36c1-4e6a-c82d-488b08731e0f@binghamton.edu>

I use R every day with pretty sensitive data in my county health
department. Of course, this is for manipulation and analysis of data
pulled from their sources, not for interacting directly with, or
updating, patient records in any clinically operational sense. As others
have said, the structure and security of the overall computing
environment is what matters most.

--Chris Ryan

Wait, Kristin wrote:
> HI all,
> 
> I am with a NYS major trauma center and all programs that our employees/providers use must be vetted through the IT Department by way of a Risk Analysis.
> Is there someone I would talk to about this?
> 
> I scoured your website and could not find a specific person.
> 
> Thank you so much
> Kristin Wait
> Albany, NY
> ----------------------------------------- CONFIDENTIALITY NOTICE: This email and any attachments may contain confidential information that is protected by law and is for the sole use of the individuals or entities to which it is addressed. If you are not the intended recipient, please notify the sender by replying to this email and destroying all copies of the communication and attachments. Further use, disclosure, copying, distribution of, or reliance upon the contents of this email and attachments is strictly prohibited. To contact Albany Medical Center, or for a copy of our privacy practices, please visit us on the Internet at www.amc.edu.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @nku@h@@@k @end|ng |rom gm@||@com  Fri Jun 19 12:07:28 2020
From: @nku@h@@@k @end|ng |rom gm@||@com (Ankush Sharma)
Date: Fri, 19 Jun 2020 12:07:28 +0200
Subject: [R] =?utf-8?q?Error=3A_cannot_remove_prior_installation_of_packa?=
	=?utf-8?b?Z2Ug4oCYQmlvY01hbmFnZXLigJk=?=
Message-ID: <CAALWEk0n5CvgiFqT_5tYKXBivdV-mLjPTB9TeXJP-3Q10Xw4LA@mail.gmail.com>

Dear all,

I am working R version 4.0.1 macos catalina , I?m not able to load
libraries e.g ggplot2

Error: Error: package or namespace load failed for ?ggplot2? in
loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):
 there is no package called ?gtable?
Then i tried installing gtable,  But  installation is showing error :
Error in install.packages : cannot remove prior installation of package
?gtable?

This is also for other packages like BiocManager, when I manually changed
the name or removed the BiocManager from the library, the package was
smoothly installed.
Any pointers on how to solve this problem without manual removal of
packages.  remove.packages command is also not working.

Thanks in advance.

Best Regards
*Ankush Sharma*

	[[alternative HTML version deleted]]


From ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de  Fri Jun 19 13:56:52 2020
From: ||gge@ @end|ng |rom @t@t|@t|k@tu-dortmund@de (Uwe Ligges)
Date: Fri, 19 Jun 2020 13:56:52 +0200
Subject: [R] 
 =?utf-8?q?Error=3A_cannot_remove_prior_installation_of_packa?=
 =?utf-8?b?Z2Ug4oCYQmlvY01hbmFnZXLigJk=?=
In-Reply-To: <CAALWEk0n5CvgiFqT_5tYKXBivdV-mLjPTB9TeXJP-3Q10Xw4LA@mail.gmail.com>
References: <CAALWEk0n5CvgiFqT_5tYKXBivdV-mLjPTB9TeXJP-3Q10Xw4LA@mail.gmail.com>
Message-ID: <bd4beec5-f185-283c-4382-ef2e9cd92a32@statistik.tu-dortmund.de>

The packages must not be loaded when you try to update.

Best,
Uwe Ligges



On 19.06.2020 12:07, Ankush Sharma wrote:
> Dear all,
> 
> I am working R version 4.0.1 macos catalina , I?m not able to load
> libraries e.g ggplot2
> 
> Error: Error: package or namespace load failed for ?ggplot2? in
> loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):
>   there is no package called ?gtable?
> Then i tried installing gtable,  But  installation is showing error :
> Error in install.packages : cannot remove prior installation of package
> ?gtable?
> 
> This is also for other packages like BiocManager, when I manually changed
> the name or removed the BiocManager from the library, the package was
> smoothly installed.
> Any pointers on how to solve this problem without manual removal of
> packages.  remove.packages command is also not working.
> 
> Thanks in advance.
> 
> Best Regards
> *Ankush Sharma*
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @nku@h@@@k @end|ng |rom gm@||@com  Fri Jun 19 14:06:56 2020
From: @nku@h@@@k @end|ng |rom gm@||@com (Ankush Sharma)
Date: Fri, 19 Jun 2020 14:06:56 +0200
Subject: [R] 
	=?utf-8?q?Error=3A_cannot_remove_prior_installation_of_packa?=
	=?utf-8?b?Z2Ug4oCYQmlvY01hbmFnZXLigJk=?=
In-Reply-To: <bd4beec5-f185-283c-4382-ef2e9cd92a32@statistik.tu-dortmund.de>
References: <CAALWEk0n5CvgiFqT_5tYKXBivdV-mLjPTB9TeXJP-3Q10Xw4LA@mail.gmail.com>
 <bd4beec5-f185-283c-4382-ef2e9cd92a32@statistik.tu-dortmund.de>
Message-ID: <CAALWEk0q5T1ZDswiHWkrBJXaFk8RDO9=ENs6-oosdg3URpXpXg@mail.gmail.com>

The packages were installed after the update!

Best Regards
*Ankush Sharma*


On Fri, Jun 19, 2020 at 1:56 PM Uwe Ligges <ligges at statistik.tu-dortmund.de>
wrote:

> The packages must not be loaded when you try to update.
>
> Best,
> Uwe Ligges
>
>
>
> On 19.06.2020 12:07, Ankush Sharma wrote:
> > Dear all,
> >
> > I am working R version 4.0.1 macos catalina , I?m not able to load
> > libraries e.g ggplot2
> >
> > Error: Error: package or namespace load failed for ?ggplot2? in
> > loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):
> >   there is no package called ?gtable?
> > Then i tried installing gtable,  But  installation is showing error :
> > Error in install.packages : cannot remove prior installation of package
> > ?gtable?
> >
> > This is also for other packages like BiocManager, when I manually changed
> > the name or removed the BiocManager from the library, the package was
> > smoothly installed.
> > Any pointers on how to solve this problem without manual removal of
> > packages.  remove.packages command is also not working.
> >
> > Thanks in advance.
> >
> > Best Regards
> > *Ankush Sharma*
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Jun 19 14:24:58 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 19 Jun 2020 08:24:58 -0400
Subject: [R] 
 =?utf-8?q?Error=3A_cannot_remove_prior_installation_of_packa?=
 =?utf-8?b?Z2Ug4oCYQmlvY01hbmFnZXLigJk=?=
In-Reply-To: <CAALWEk0q5T1ZDswiHWkrBJXaFk8RDO9=ENs6-oosdg3URpXpXg@mail.gmail.com>
References: <CAALWEk0n5CvgiFqT_5tYKXBivdV-mLjPTB9TeXJP-3Q10Xw4LA@mail.gmail.com>
 <bd4beec5-f185-283c-4382-ef2e9cd92a32@statistik.tu-dortmund.de>
 <CAALWEk0q5T1ZDswiHWkrBJXaFk8RDO9=ENs6-oosdg3URpXpXg@mail.gmail.com>
Message-ID: <1448b1cb-47dc-13e0-86d7-2e4b8ac58080@gmail.com>

On 19/06/2020 8:06 a.m., Ankush Sharma wrote:
> The packages were installed after the update!

That's not relevant.  The issue is that the packages were loaded at the 
time you tried to update them.

You may have to start R with the --vanilla option to avoid automatically 
loading packages if you've got a .Rprofile (or similar) file running 
automatically on startup.

A simpler solution to this is to use RStudio; it will automatically 
restart R if necessary when installing a package.

Duncan Murdoch

> 
> Best Regards
> *Ankush Sharma*
> 
> 
> On Fri, Jun 19, 2020 at 1:56 PM Uwe Ligges <ligges at statistik.tu-dortmund.de>
> wrote:
> 
>> The packages must not be loaded when you try to update.
>>
>> Best,
>> Uwe Ligges
>>
>>
>>
>> On 19.06.2020 12:07, Ankush Sharma wrote:
>>> Dear all,
>>>
>>> I am working R version 4.0.1 macos catalina , I?m not able to load
>>> libraries e.g ggplot2
>>>
>>> Error: Error: package or namespace load failed for ?ggplot2? in
>>> loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):
>>>    there is no package called ?gtable?
>>> Then i tried installing gtable,  But  installation is showing error :
>>> Error in install.packages : cannot remove prior installation of package
>>> ?gtable?
>>>
>>> This is also for other packages like BiocManager, when I manually changed
>>> the name or removed the BiocManager from the library, the package was
>>> smoothly installed.
>>> Any pointers on how to solve this problem without manual removal of
>>> packages.  remove.packages command is also not working.
>>>
>>> Thanks in advance.
>>>
>>> Best Regards
>>> *Ankush Sharma*
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @nku@h@@@k @end|ng |rom gm@||@com  Fri Jun 19 15:17:06 2020
From: @nku@h@@@k @end|ng |rom gm@||@com (Ankush Sharma)
Date: Fri, 19 Jun 2020 15:17:06 +0200
Subject: [R] 
	=?utf-8?q?Error=3A_cannot_remove_prior_installation_of_packa?=
	=?utf-8?b?Z2Ug4oCYQmlvY01hbmFnZXLigJk=?=
In-Reply-To: <1448b1cb-47dc-13e0-86d7-2e4b8ac58080@gmail.com>
References: <CAALWEk0n5CvgiFqT_5tYKXBivdV-mLjPTB9TeXJP-3Q10Xw4LA@mail.gmail.com>
 <bd4beec5-f185-283c-4382-ef2e9cd92a32@statistik.tu-dortmund.de>
 <CAALWEk0q5T1ZDswiHWkrBJXaFk8RDO9=ENs6-oosdg3URpXpXg@mail.gmail.com>
 <1448b1cb-47dc-13e0-86d7-2e4b8ac58080@gmail.com>
Message-ID: <CAALWEk0B+_6OUeqCz+KFxvbPh6Pb0hy06WmPBE_0Y3yfJvgnfQ@mail.gmail.com>

Thanks, Duncan and Uwe,
I was using Rstudio.  This solved the problem

Best Regards
*Ankush Sharma*


On Fri, Jun 19, 2020 at 2:25 PM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 19/06/2020 8:06 a.m., Ankush Sharma wrote:
> > The packages were installed after the update!
>
> That's not relevant.  The issue is that the packages were loaded at the
> time you tried to update them.
>
> You may have to start R with the --vanilla option to avoid automatically
> loading packages if you've got a .Rprofile (or similar) file running
> automatically on startup.
>
> A simpler solution to this is to use RStudio; it will automatically
> restart R if necessary when installing a package.
>
> Duncan Murdoch
>
> >
> > Best Regards
> > *Ankush Sharma*
> >
> >
> > On Fri, Jun 19, 2020 at 1:56 PM Uwe Ligges <
> ligges at statistik.tu-dortmund.de>
> > wrote:
> >
> >> The packages must not be loaded when you try to update.
> >>
> >> Best,
> >> Uwe Ligges
> >>
> >>
> >>
> >> On 19.06.2020 12:07, Ankush Sharma wrote:
> >>> Dear all,
> >>>
> >>> I am working R version 4.0.1 macos catalina , I?m not able to load
> >>> libraries e.g ggplot2
> >>>
> >>> Error: Error: package or namespace load failed for ?ggplot2? in
> >>> loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]):
> >>>    there is no package called ?gtable?
> >>> Then i tried installing gtable,  But  installation is showing error :
> >>> Error in install.packages : cannot remove prior installation of package
> >>> ?gtable?
> >>>
> >>> This is also for other packages like BiocManager, when I manually
> changed
> >>> the name or removed the BiocManager from the library, the package was
> >>> smoothly installed.
> >>> Any pointers on how to solve this problem without manual removal of
> >>> packages.  remove.packages command is also not working.
> >>>
> >>> Thanks in advance.
> >>>
> >>> Best Regards
> >>> *Ankush Sharma*
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>

	[[alternative HTML version deleted]]


From j3||d|ck @end|ng |rom gm@||@com  Fri Jun 19 15:59:15 2020
From: j3||d|ck @end|ng |rom gm@||@com (Jeffrey Dick)
Date: Fri, 19 Jun 2020 20:59:15 +0700
Subject: [R] smoothScatter() and the KernSmooth package
In-Reply-To: <CAAjnpdg-2BC8scPEgpHySNPWBqB3dKvDXy2yO-ap_H4uQ-qpNw@mail.gmail.com>
References: <CAAjnpdg-2BC8scPEgpHySNPWBqB3dKvDXy2yO-ap_H4uQ-qpNw@mail.gmail.com>
Message-ID: <CANBtttYQEpXEnt5JotytXgwXtyriRwp2AezbG8co8y7MNZFfMA@mail.gmail.com>

Hi Witold,

See also this thread on R-pkg-devel. Quoting Duncan Murdoch, "That
looks like a bug in grDevices."

https://stat.ethz.ch/pipermail/r-package-devel/2019q3/004287.html

Cheers,
Jeff



On Wed, Jun 17, 2020 at 4:59 PM Witold E Wolski <wewolski at gmail.com> wrote:
>
> Hello,
>
> I am getting the following error when running a package check
> ```
>   Error in loadNamespace(name) : there is no package called 'KernSmooth'
>   Calls: <Anonymous> ... loadNamespace -> withRestarts ->
> withOneRestart -> doWithOneRestart
>   Execution halted
> ```
>
> The error happens in a function which calls graphics::smoothScatter
>
> I found this e-mail on the r-devel list where this problem is also reported.
> https://stat.ethz.ch/pipermail/r-devel/2015-February/070671.html
>
> So I could add KernSmooth to Suggest in the DESCRIPTION but I have a
> few questions:
> (and I am citing from the e-mail above to which I could not find a reply):
>
> "I have a few questions: isn't it unusual the way smoothScatter calls
>
> grDevices:::.smoothScatterCalcDensity() and KernSmooth::bkde2D(),
> i.e., without requiring the packages?
> Shouldn't "graphics" suggest "KernSmooth"?
> "
>
> best regards
> Witek
>
>
>
>
> --
> Witold Eryk Wolski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Jun 19 16:14:19 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 19 Jun 2020 10:14:19 -0400
Subject: [R] smoothScatter() and the KernSmooth package
In-Reply-To: <CANBtttYQEpXEnt5JotytXgwXtyriRwp2AezbG8co8y7MNZFfMA@mail.gmail.com>
References: <CAAjnpdg-2BC8scPEgpHySNPWBqB3dKvDXy2yO-ap_H4uQ-qpNw@mail.gmail.com>
 <CANBtttYQEpXEnt5JotytXgwXtyriRwp2AezbG8co8y7MNZFfMA@mail.gmail.com>
Message-ID: <f211996f-09ac-4bbd-4d0a-fca4f4c8f4e3@gmail.com>

On 19/06/2020 9:59 a.m., Jeffrey Dick wrote:
> Hi Witold,
> 
> See also this thread on R-pkg-devel. Quoting Duncan Murdoch, "That
> looks like a bug in grDevices."

Yes, and the bug is still there:  grDevices:::.smoothScatterCalcDensity 
calls KernSmooth::bkde2D without checking whether KernSmooth is available.

Duncan Murdoch

> 
> https://stat.ethz.ch/pipermail/r-package-devel/2019q3/004287.html
> 
> Cheers,
> Jeff
> 
> 
> 
> On Wed, Jun 17, 2020 at 4:59 PM Witold E Wolski <wewolski at gmail.com> wrote:
>>
>> Hello,
>>
>> I am getting the following error when running a package check
>> ```
>>    Error in loadNamespace(name) : there is no package called 'KernSmooth'
>>    Calls: <Anonymous> ... loadNamespace -> withRestarts ->
>> withOneRestart -> doWithOneRestart
>>    Execution halted
>> ```
>>
>> The error happens in a function which calls graphics::smoothScatter
>>
>> I found this e-mail on the r-devel list where this problem is also reported.
>> https://stat.ethz.ch/pipermail/r-devel/2015-February/070671.html
>>
>> So I could add KernSmooth to Suggest in the DESCRIPTION but I have a
>> few questions:
>> (and I am citing from the e-mail above to which I could not find a reply):
>>
>> "I have a few questions: isn't it unusual the way smoothScatter calls
>>
>> grDevices:::.smoothScatterCalcDensity() and KernSmooth::bkde2D(),
>> i.e., without requiring the packages?
>> Shouldn't "graphics" suggest "KernSmooth"?
>> "
>>
>> best regards
>> Witek
>>
>>
>>
>>
>> --
>> Witold Eryk Wolski
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @eb@@t|en@|@h@|e @end|ng |rom gm@||@com  Fri Jun 19 14:49:25 2020
From: @eb@@t|en@|@h@|e @end|ng |rom gm@||@com (=?UTF-8?Q?S=C3=A9bastien_Lahaie?=)
Date: Fri, 19 Jun 2020 08:49:25 -0400
Subject: [R] Strange behavior when sampling rows of a data frame
Message-ID: <CAKQpU6Lr_ARRHdWpCJf1Bg5k3JDV3_Kw8CUBsYnSJLkeq03Nzw@mail.gmail.com>

I ran into some strange behavior in R when trying to assign a treatment to
rows in a data frame. I'm wondering whether any R experts can explain
what's going on.

First, let's assign a treatment to 3 out of 10 rows as follows.

> df <- data.frame(unit = 1:10)

> df$treated <- FALSE

>

> s <- sample(nrow(df), 3)

> df[s,]$treated <- TRUE

>

> df

   unit treated

1     1   FALSE

2     2    TRUE

3     3   FALSE

4     4   FALSE

5     5    TRUE

6     6   FALSE

7     7    TRUE

8     8   FALSE

9     9   FALSE

10   10   FALSE

This is as expected. Now we'll just skip the intermediate step of saving
the sampled indices, and apply the treatment directly as follows.

> df <- data.frame(unit = 1:10)

> df$treated <- FALSE

>

> df[sample(nrow(df), 3),]$treated <- TRUE

>

> df

   unit treated

1     6    TRUE

2     2   FALSE

3     3   FALSE

4     9    TRUE

5     5   FALSE

6     6   FALSE

7     7   FALSE

8     5    TRUE

9     9   FALSE

10   10   FALSE

Now the data frame still has 10 rows with 3 assigned to the treatment. But
the units are garbled. Units 1 and 4 have disappeared, for instance, and
there are duplicates for 6 and 9, one assigned to treatment and the other
to control. Why would this happen?

Thanks,
Sebastien

	[[alternative HTML version deleted]]


From R@|ner @end|ng |rom krug@@de  Fri Jun 19 16:56:13 2020
From: R@|ner @end|ng |rom krug@@de (Rainer M Krug)
Date: Fri, 19 Jun 2020 16:56:13 +0200
Subject: [R] Load svg, eps or png into graphics device?
Message-ID: <A7F8903F-97D3-4CB8-BC2A-CA2117EFB5DE@krugs.de>


Hi

I have a package, which plots from the plantuml syntax (https://plantuml.com) graphs via a knitr engine, into a file, or into a graphics device (https://github.com/rkrug/plantuml).

I am using at the moment grImport for the eps import, but would like to cut down on dependencies.

Is there a way of bringing graphics files (png, sag, eps, ?) into a graphics device in R?

Thanks,

Rainer






--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Orcid ID: 0000-0002-7490-0066

Department of Evolutionary Biology and Environmental Studies
University of Z?rich
Office Y34-J-74
Winterthurerstrasse 190
8075 Z?rich
Switzerland

Office:	+41 (0)44 635 47 64
Cell:       	+41 (0)78 630 66 57
email:      Rainer.Krug at uzh.ch
		Rainer at krugs.de
Skype:     RMkrug

PGP: 0x0F52F982


From he|mut@@chuetz @end|ng |rom beb@c@@t  Fri Jun 19 17:31:29 2020
From: he|mut@@chuetz @end|ng |rom beb@c@@t (=?UTF-8?Q?Helmut_Sch=c3=bctz?=)
Date: Fri, 19 Jun 2020 17:31:29 +0200
Subject: [R] R Software Risk Analysis
In-Reply-To: <mailman.359509.1.1592560801.37602.r-help@r-project.org>
References: <mailman.359509.1.1592560801.37602.r-help@r-project.org>
Message-ID: <dbbdc83f-64b2-fd4b-fd86-2bbe94669cc6@bebac.at>

Dear all,

any (!) software used in regulated environments has to be validated. 
Regrettably is is a misconception by many working in the pharmaceutical 
industry that only studies evaluated by SAS are accepted by the FDA.
See this one-pager https://www.fda.gov/media/109552/download and a 
presentation by the FDA's Paul Schuette at the useR! 2016 
(https://channel9.msdn.com/Events/useR-international-R-User-conference/useR2016/Using-R-in-a-regulatory-environment-FDA-experiences).
Note that the FDA itself uses R in modeling & simulation.

Contrary to proprietary (off-the-shelf, commercial, you name it) 
software ? where only a black box validation (aka, rubbish in, rubbish 
out) is possible ? open source SW allows ? in principle ? a white box 
validation is possible.

Relying on proprietary SW is not necessarily a good idea ("We payed a 
lot, hence, it will work.") Stephen Senn once told me (given, a good 
while ago) that after an update of SAS, the Welch-test for unequal group 
sizes / variances collapsed into the simple t-test. He called up SAS and 
got the coder on the line. He inspected the source and after a couple of 
minutes replied "Hey, you are right. We screwed up." It took SAS half a 
year to roll out a corrective patch. What about clinicial studies 
evaluated in the meantime?

We published a couple of papers in a specific field comparing software 
(doi:10.1208/s12248-014-9661-0, doi:10.1208/s12248-014-9704-6, 
doi:10.1208/s12248-020-0427-6). It turned out that one of the commercial 
[sic] SWs tested was seriously flawed. Consequences: Dozens of approved 
drugs taken off the market. The glitch in the software was _partly_ 
corrected in 2014 and the vendor stopped marketing it in 2019.

Just by two cents
Helmut

-- 
Ing. Helmut Sch?tz
BEBAC?? Consultancy Services for
Bioequivalence and Bioavailability Studies
Neubaugasse 36/11
1070 Vienna, Austria
T +43 1 2311746
M +43 699 10792458
E helmut.schuetz at bebac.at
W https://bebac.at/
C https://bebac.at/Contact.htm
F https://forum.bebac.at/


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Jun 19 17:37:45 2020
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 19 Jun 2020 17:37:45 +0200
Subject: [R] smoothScatter() and the KernSmooth package
In-Reply-To: <f211996f-09ac-4bbd-4d0a-fca4f4c8f4e3@gmail.com>
References: <CAAjnpdg-2BC8scPEgpHySNPWBqB3dKvDXy2yO-ap_H4uQ-qpNw@mail.gmail.com>
 <CANBtttYQEpXEnt5JotytXgwXtyriRwp2AezbG8co8y7MNZFfMA@mail.gmail.com>
 <f211996f-09ac-4bbd-4d0a-fca4f4c8f4e3@gmail.com>
Message-ID: <24300.56265.240039.981858@stat.math.ethz.ch>

>>>>> Duncan Murdoch 
>>>>>     on Fri, 19 Jun 2020 10:14:19 -0400 writes:

    > On 19/06/2020 9:59 a.m., Jeffrey Dick wrote:
    >> Hi Witold,
    >> 
    >> See also this thread on R-pkg-devel. Quoting Duncan Murdoch, "That
    >> looks like a bug in grDevices."

    > Yes, and the bug is still there:  grDevices:::.smoothScatterCalcDensity 
    > calls KernSmooth::bkde2D without checking whether KernSmooth is available.

    > Duncan Murdoch

    >> https://stat.ethz.ch/pipermail/r-package-devel/2019q3/004287.html

Thank you, Duncan.

I'm taking care of this now -- but just for R-devel, not the
upcoming 4.0.2

Martin

    >> Cheers,
    >> Jeff

    >> On Wed, Jun 17, 2020 at 4:59 PM Witold E Wolski <wewolski at gmail.com> wrote:
    >>> 
    >>> Hello,
    >>> 
    >>> I am getting the following error when running a package check
    >>> ```
    >>> Error in loadNamespace(name) : there is no package called 'KernSmooth'
    >>> Calls: <Anonymous> ... loadNamespace -> withRestarts ->
    >>> withOneRestart -> doWithOneRestart
    >>> Execution halted
    >>> ```
    >>> 
    >>> The error happens in a function which calls graphics::smoothScatter
    >>> 
    >>> I found this e-mail on the r-devel list where this problem is also reported.
    >>> https://stat.ethz.ch/pipermail/r-devel/2015-February/070671.html
    >>> 
    >>> So I could add KernSmooth to Suggest in the DESCRIPTION but I have a
    >>> few questions:
    >>> (and I am citing from the e-mail above to which I could not find a reply):
    >>> 
    >>> "I have a few questions: isn't it unusual the way smoothScatter calls
    >>> 
    >>> grDevices:::.smoothScatterCalcDensity() and KernSmooth::bkde2D(),
    >>> i.e., without requiring the packages?
    >>> Shouldn't "graphics" suggest "KernSmooth"?
    >>> "
    >>> 
    >>> best regards
    >>> Witek
    >>> 
    >>> 
    >>> 
    >>> 
    >>> --
    >>> Witold Eryk Wolski
    >>> 
    >>> ______________________________________________
    >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >>> https://stat.ethz.ch/mailman/listinfo/r-help
    >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >>> and provide commented, minimal, self-contained, reproducible code.
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.
    >> 

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Jun 19 17:45:42 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 19 Jun 2020 16:45:42 +0100
Subject: [R] Strange behavior when sampling rows of a data frame
In-Reply-To: <CAKQpU6Lr_ARRHdWpCJf1Bg5k3JDV3_Kw8CUBsYnSJLkeq03Nzw@mail.gmail.com>
References: <CAKQpU6Lr_ARRHdWpCJf1Bg5k3JDV3_Kw8CUBsYnSJLkeq03Nzw@mail.gmail.com>
Message-ID: <e09460bb-61e6-b31c-af7c-e45a8a9a4c69@sapo.pt>

Hello,

I don't have an answer on the reason why this happens but it seems like 
a bug. Where?

In which of? `[<-.data.frame` or `[<-.default`?

A solution is to subset and assign the vector:


set.seed(2020)
df2 <- data.frame(unit = 1:10)
df2$treated <- FALSE

df2$treated[sample(nrow(df2), 3)] <- TRUE
df2
#? unit treated
#1???? 1?? FALSE
#2???? 2?? FALSE
#3???? 3?? FALSE
#4???? 4?? FALSE
#5???? 5?? FALSE
#6???? 6??? TRUE
#7???? 7??? TRUE
#8???? 8??? TRUE
#9???? 9?? FALSE
#10?? 10?? FALSE


Or


set.seed(2020)
df3 <- data.frame(unit = 1:10)
df3$treated <- FALSE

df3[sample(nrow(df3), 3), "treated"] <- TRUE
df3
# result as expected


Hope this helps,

Rui? Barradas



?s 13:49 de 19/06/2020, S?bastien Lahaie escreveu:
> I ran into some strange behavior in R when trying to assign a treatment to
> rows in a data frame. I'm wondering whether any R experts can explain
> what's going on.
>
> First, let's assign a treatment to 3 out of 10 rows as follows.
>
>> df <- data.frame(unit = 1:10)
>> df$treated <- FALSE
>> s <- sample(nrow(df), 3)
>> df[s,]$treated <- TRUE
>> df
>     unit treated
>
> 1     1   FALSE
>
> 2     2    TRUE
>
> 3     3   FALSE
>
> 4     4   FALSE
>
> 5     5    TRUE
>
> 6     6   FALSE
>
> 7     7    TRUE
>
> 8     8   FALSE
>
> 9     9   FALSE
>
> 10   10   FALSE
>
> This is as expected. Now we'll just skip the intermediate step of saving
> the sampled indices, and apply the treatment directly as follows.
>
>> df <- data.frame(unit = 1:10)
>> df$treated <- FALSE
>> df[sample(nrow(df), 3),]$treated <- TRUE
>> df
>     unit treated
>
> 1     6    TRUE
>
> 2     2   FALSE
>
> 3     3   FALSE
>
> 4     9    TRUE
>
> 5     5   FALSE
>
> 6     6   FALSE
>
> 7     7   FALSE
>
> 8     5    TRUE
>
> 9     9   FALSE
>
> 10   10   FALSE
>
> Now the data frame still has 10 rows with 3 assigned to the treatment. But
> the units are garbled. Units 1 and 4 have disappeared, for instance, and
> there are duplicates for 6 and 9, one assigned to treatment and the other
> to control. Why would this happen?
>
> Thanks,
> Sebastien
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Este e-mail foi verificado em termos de v?rus pelo software antiv?rus Avast.
https://www.avast.com/antivirus


From wdun|@p @end|ng |rom t|bco@com  Fri Jun 19 18:20:43 2020
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 19 Jun 2020 09:20:43 -0700
Subject: [R] Strange behavior when sampling rows of a data frame
In-Reply-To: <e09460bb-61e6-b31c-af7c-e45a8a9a4c69@sapo.pt>
References: <CAKQpU6Lr_ARRHdWpCJf1Bg5k3JDV3_Kw8CUBsYnSJLkeq03Nzw@mail.gmail.com>
 <e09460bb-61e6-b31c-af7c-e45a8a9a4c69@sapo.pt>
Message-ID: <CAF8bMcYNJ52_vKmM2Ypa6NobB30gJqcVpx3KJ++N3Nwe90sWkg@mail.gmail.com>

The first subscript argument is getting evaluated twice.
> trace(sample)
> set.seed(2020); df[i<-sample(10,3), ]$Treated <- TRUE
trace: sample(10, 3)
trace: sample(10, 3)
> i
[1]  1 10  4
> set.seed(2020); sample(10,3)
trace: sample(10, 3)
[1] 7 6 8
> sample(10,3)
trace: sample(10, 3)
[1]  1 10  4

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Jun 19, 2020 at 8:46 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> I don't have an answer on the reason why this happens but it seems like
> a bug. Where?
>
> In which of  `[<-.data.frame` or `[<-.default`?
>
> A solution is to subset and assign the vector:
>
>
> set.seed(2020)
> df2 <- data.frame(unit = 1:10)
> df2$treated <- FALSE
>
> df2$treated[sample(nrow(df2), 3)] <- TRUE
> df2
> #  unit treated
> #1     1   FALSE
> #2     2   FALSE
> #3     3   FALSE
> #4     4   FALSE
> #5     5   FALSE
> #6     6    TRUE
> #7     7    TRUE
> #8     8    TRUE
> #9     9   FALSE
> #10   10   FALSE
>
>
> Or
>
>
> set.seed(2020)
> df3 <- data.frame(unit = 1:10)
> df3$treated <- FALSE
>
> df3[sample(nrow(df3), 3), "treated"] <- TRUE
> df3
> # result as expected
>
>
> Hope this helps,
>
> Rui  Barradas
>
>
>
> ?s 13:49 de 19/06/2020, S?bastien Lahaie escreveu:
> > I ran into some strange behavior in R when trying to assign a treatment
> to
> > rows in a data frame. I'm wondering whether any R experts can explain
> > what's going on.
> >
> > First, let's assign a treatment to 3 out of 10 rows as follows.
> >
> >> df <- data.frame(unit = 1:10)
> >> df$treated <- FALSE
> >> s <- sample(nrow(df), 3)
> >> df[s,]$treated <- TRUE
> >> df
> >     unit treated
> >
> > 1     1   FALSE
> >
> > 2     2    TRUE
> >
> > 3     3   FALSE
> >
> > 4     4   FALSE
> >
> > 5     5    TRUE
> >
> > 6     6   FALSE
> >
> > 7     7    TRUE
> >
> > 8     8   FALSE
> >
> > 9     9   FALSE
> >
> > 10   10   FALSE
> >
> > This is as expected. Now we'll just skip the intermediate step of saving
> > the sampled indices, and apply the treatment directly as follows.
> >
> >> df <- data.frame(unit = 1:10)
> >> df$treated <- FALSE
> >> df[sample(nrow(df), 3),]$treated <- TRUE
> >> df
> >     unit treated
> >
> > 1     6    TRUE
> >
> > 2     2   FALSE
> >
> > 3     3   FALSE
> >
> > 4     9    TRUE
> >
> > 5     5   FALSE
> >
> > 6     6   FALSE
> >
> > 7     7   FALSE
> >
> > 8     5    TRUE
> >
> > 9     9   FALSE
> >
> > 10   10   FALSE
> >
> > Now the data frame still has 10 rows with 3 assigned to the treatment.
> But
> > the units are garbled. Units 1 and 4 have disappeared, for instance, and
> > there are duplicates for 6 and 9, one assigned to treatment and the other
> > to control. Why would this happen?
> >
> > Thanks,
> > Sebastien
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Este e-mail foi verificado em termos de v?rus pelo software antiv?rus
> Avast.
> https://www.avast.com/antivirus
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From john@m@h@rro|d @end|ng |rom gm@||@com  Fri Jun 19 18:37:26 2020
From: john@m@h@rro|d @end|ng |rom gm@||@com (John Harrold)
Date: Fri, 19 Jun 2020 09:37:26 -0700
Subject: [R] R Software Risk Analysis
In-Reply-To: <dbbdc83f-64b2-fd4b-fd86-2bbe94669cc6@bebac.at>
References: <mailman.359509.1.1592560801.37602.r-help@r-project.org>
 <dbbdc83f-64b2-fd4b-fd86-2bbe94669cc6@bebac.at>
Message-ID: <CANAiAiU3vsOZGf2uUkZXGHXv_VUCkM8g=efZ8BFxFrM1ekJwUg@mail.gmail.com>

I think the question of validation is very different from the risk analysis
referenced in the subject line.

On the subject of  the FDA accepting open source software. Personally I've
done two sBLA submissions where simulation results were essential aspects
of the filings. Both were approved and during the filings we included both
the results from R as well as the R code (as requested by the FDA).


On Fri, Jun 19, 2020 at 8:41 AM Helmut Sch?tz <helmut.schuetz at bebac.at>
wrote:

> Dear all,
>
> any (!) software used in regulated environments has to be validated.
> Regrettably is is a misconception by many working in the pharmaceutical
> industry that only studies evaluated by SAS are accepted by the FDA.
> See this one-pager https://www.fda.gov/media/109552/download and a
> presentation by the FDA's Paul Schuette at the useR! 2016
> (
> https://channel9.msdn.com/Events/useR-international-R-User-conference/useR2016/Using-R-in-a-regulatory-environment-FDA-experiences
> ).
> Note that the FDA itself uses R in modeling & simulation.
>
> Contrary to proprietary (off-the-shelf, commercial, you name it)
> software ? where only a black box validation (aka, rubbish in, rubbish
> out) is possible ? open source SW allows ? in principle ? a white box
> validation is possible.
>
> Relying on proprietary SW is not necessarily a good idea ("We payed a
> lot, hence, it will work.") Stephen Senn once told me (given, a good
> while ago) that after an update of SAS, the Welch-test for unequal group
> sizes / variances collapsed into the simple t-test. He called up SAS and
> got the coder on the line. He inspected the source and after a couple of
> minutes replied "Hey, you are right. We screwed up." It took SAS half a
> year to roll out a corrective patch. What about clinicial studies
> evaluated in the meantime?
>
> We published a couple of papers in a specific field comparing software
> (doi:10.1208/s12248-014-9661-0, doi:10.1208/s12248-014-9704-6,
> doi:10.1208/s12248-020-0427-6). It turned out that one of the commercial
> [sic] SWs tested was seriously flawed. Consequences: Dozens of approved
> drugs taken off the market. The glitch in the software was _partly_
> corrected in 2014 and the vendor stopped marketing it in 2019.
>
> Just by two cents
> Helmut
>
> --
> Ing. Helmut Sch?tz
> BEBAC ? Consultancy Services for
> Bioequivalence and Bioavailability Studies
> Neubaugasse 36/11
> 1070 Vienna, Austria
> T +43 1 2311746
> M +43 699 10792458
> E helmut.schuetz at bebac.at
> W https://bebac.at/
> C https://bebac.at/Contact.htm
> F https://forum.bebac.at/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John
:wq

	[[alternative HTML version deleted]]


From re|chm@nj @end|ng |rom @bcg|ob@|@net  Fri Jun 19 19:00:42 2020
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Fri, 19 Jun 2020 12:00:42 -0500
Subject: [R] Error plotting the results form a Holt Winters model with no
 seasonality
References: <001a01d6465b$2b644c50$822ce4f0$.ref@sbcglobal.net>
Message-ID: <001a01d6465b$2b644c50$822ce4f0$@sbcglobal.net>

r-help

 

I'm trying to use the TSstudio library to plot a forecast created from a
Holt Winters model and I get the following error: 

 

Error in `[<-`(`*tmp*`, n + 1, , value = data.frame(x = tmp[["x"]][n],  : 

  subscript out of bounds

 

So looking through the package documentation I tried the package's example

 

data(USgas)
library(forecast)
fit <- ets(USgas)
fc<- forecast(fit, h = 60)
plot_forecast(fc)

 

and get the same error

 

Error in `[<-`(`*tmp*`, n + 1, , value = data.frame(x = tmp[["x"]][n],  : 

  subscript out of bounds

 

So I am at a loss to figure out my error when the example gives me the same
error.

 

Sincerely

 

Jeff Reichman

 


	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Jun 19 19:32:16 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 19 Jun 2020 10:32:16 -0700
Subject: [R] 
 Error plotting the results form a Holt Winters model with no
 seasonality
In-Reply-To: <001a01d6465b$2b644c50$822ce4f0$@sbcglobal.net>
References: <001a01d6465b$2b644c50$822ce4f0$.ref@sbcglobal.net>
 <001a01d6465b$2b644c50$822ce4f0$@sbcglobal.net>
Message-ID: <CAGxFJbThwvD+QTAW6RSx9GmzFtajxX7ucT7MUQexrD=t0fhqcA@mail.gmail.com>

OS? R version? package versions?

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 19, 2020 at 10:02 AM Jeff Reichman <reichmanj at sbcglobal.net>
wrote:

> r-help
>
>
>
> I'm trying to use the TSstudio library to plot a forecast created from a
> Holt Winters model and I get the following error:
>
>
>
> Error in `[<-`(`*tmp*`, n + 1, , value = data.frame(x = tmp[["x"]][n],  :
>
>   subscript out of bounds
>
>
>
> So looking through the package documentation I tried the package's example
>
>
>
> data(USgas)
> library(forecast)
> fit <- ets(USgas)
> fc<- forecast(fit, h = 60)
> plot_forecast(fc)
>
>
>
> and get the same error
>
>
>
> Error in `[<-`(`*tmp*`, n + 1, , value = data.frame(x = tmp[["x"]][n],  :
>
>   subscript out of bounds
>
>
>
> So I am at a loss to figure out my error when the example gives me the same
> error.
>
>
>
> Sincerely
>
>
>
> Jeff Reichman
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Fri Jun 19 19:34:22 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Fri, 19 Jun 2020 20:34:22 +0300
Subject: [R] 
 Error plotting the results form a Holt Winters model with no
 seasonality
In-Reply-To: <001a01d6465b$2b644c50$822ce4f0$@sbcglobal.net>
References: <001a01d6465b$2b644c50$822ce4f0$.ref@sbcglobal.net>
 <001a01d6465b$2b644c50$822ce4f0$@sbcglobal.net>
Message-ID: <CAGgJW77qC745ayL9eg1mpGd4P38NptfM5gw1ddUSysasVT2-iA@mail.gmail.com>

Hi Jeff,
I tried to reproduce your problem with the package's example and I did
not get an error.
Here's the output from my sessionInfo().

R version 3.6.3 (2020-02-29)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 18.04.3 LTS

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3
LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.2.20.so

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
LC_TIME=en_US.UTF-8
 [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8
LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
LC_ADDRESS=C
[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8
LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] TSstudio_0.1.6 forecast_8.12

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.4.6      urca_1.3-0        pillar_1.4.4      compiler_3.6.3
 [5] xts_0.12-0        tseries_0.10-47   tools_3.6.3       digest_0.6.25
 [9] packrat_0.5.0     viridisLite_0.3.0 jsonlite_1.6.1    nlme_3.1-148
[13] evaluate_0.14     lifecycle_0.2.0   tibble_3.0.1      gtable_0.3.0
[17] lattice_0.20-41   pkgconfig_2.0.3   rlang_0.4.6       rstudioapi_0.11
[21] crosstalk_1.1.0.1 curl_4.2          yaml_2.2.1        parallel_3.6.3
[25] xfun_0.14         httr_1.4.1        dplyr_1.0.0       knitr_1.28
[29] htmlwidgets_1.5.1 generics_0.0.2    vctrs_0.3.1       lmtest_0.9-37
[33] grid_3.6.3        nnet_7.3-14       tidyselect_1.1.0  data.table_1.12.8
[37] glue_1.4.1        R6_2.4.1          plotly_4.9.2.1    rmarkdown_2.2
[41] bookdown_0.19     tidyr_1.1.0       TTR_0.23-6        ggplot2_3.3.1
[45] purrr_0.3.4       magrittr_1.5      scales_1.1.1      ellipsis_0.3.1
[49] htmltools_0.5.0   quantmod_0.4.17   rsconnect_0.8.16  timeDate_3043.102
[53] colorspace_1.4-1  fracdiff_1.5-1    quadprog_1.5-8    lazyeval_0.2.2
[57] munsell_0.5.0     crayon_1.3.4      zoo_1.8-8




On Fri, Jun 19, 2020 at 8:03 PM Jeff Reichman <reichmanj at sbcglobal.net> wrote:
>
> r-help
>
>
>
> I'm trying to use the TSstudio library to plot a forecast created from a
> Holt Winters model and I get the following error:
>
>
>
> Error in `[<-`(`*tmp*`, n + 1, , value = data.frame(x = tmp[["x"]][n],  :
>
>   subscript out of bounds
>
>
>
> So looking through the package documentation I tried the package's example
>
>
>
> data(USgas)
> library(forecast)
> fit <- ets(USgas)
> fc<- forecast(fit, h = 60)
> plot_forecast(fc)
>
>
>
> and get the same error
>
>
>
> Error in `[<-`(`*tmp*`, n + 1, , value = data.frame(x = tmp[["x"]][n],  :
>
>   subscript out of bounds
>
>
>
> So I am at a loss to figure out my error when the example gives me the same
> error.
>
>
>
> Sincerely
>
>
>
> Jeff Reichman
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Jun 19 19:37:51 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 19 Jun 2020 18:37:51 +0100
Subject: [R] Strange behavior when sampling rows of a data frame
In-Reply-To: <CAF8bMcYNJ52_vKmM2Ypa6NobB30gJqcVpx3KJ++N3Nwe90sWkg@mail.gmail.com>
References: <CAKQpU6Lr_ARRHdWpCJf1Bg5k3JDV3_Kw8CUBsYnSJLkeq03Nzw@mail.gmail.com>
 <e09460bb-61e6-b31c-af7c-e45a8a9a4c69@sapo.pt>
 <CAF8bMcYNJ52_vKmM2Ypa6NobB30gJqcVpx3KJ++N3Nwe90sWkg@mail.gmail.com>
Message-ID: <153b7026-3d63-44b7-3701-482441cdab94@sapo.pt>

Hello,


Thanks, I hadn't thought of that.

But, why? Is it evaluated once before assignment and a second time when 
the assignment occurs?

To trace both sample and `[<-` gives 2 calls to sample.


trace(sample)
trace(`[<-`)
df[sample(nrow(df), 3),]$treated <- TRUE
trace: sample(nrow(df), 3)
trace: `[<-`(`*tmp*`, sample(nrow(df), 3), , value = list(unit = c(7L,
6L, 8L), treated = c(TRUE, TRUE, TRUE)))
trace: sample(nrow(df), 3)


Regards,

Rui Barradas


?s 17:20 de 19/06/2020, William Dunlap escreveu:
> The first subscript argument is getting evaluated twice.
> > trace(sample)
> > set.seed(2020); df[i<-sample(10,3), ]$Treated <- TRUE
> trace: sample(10, 3)
> trace: sample(10, 3)
> > i
> [1] ?1 10 ?4
> > set.seed(2020); sample(10,3)
> trace: sample(10, 3)
> [1] 7 6 8
> > sample(10,3)
> trace: sample(10, 3)
> [1] ?1 10 ?4
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com>
>
>
> On Fri, Jun 19, 2020 at 8:46 AM Rui Barradas <ruipbarradas at sapo.pt 
> <mailto:ruipbarradas at sapo.pt>> wrote:
>
>     Hello,
>
>     I don't have an answer on the reason why this happens but it seems
>     like
>     a bug. Where?
>
>     In which of? `[<-.data.frame` or `[<-.default`?
>
>     A solution is to subset and assign the vector:
>
>
>     set.seed(2020)
>     df2 <- data.frame(unit = 1:10)
>     df2$treated <- FALSE
>
>     df2$treated[sample(nrow(df2), 3)] <- TRUE
>     df2
>     #? unit treated
>     #1???? 1?? FALSE
>     #2???? 2?? FALSE
>     #3???? 3?? FALSE
>     #4???? 4?? FALSE
>     #5???? 5?? FALSE
>     #6???? 6??? TRUE
>     #7???? 7??? TRUE
>     #8???? 8??? TRUE
>     #9???? 9?? FALSE
>     #10?? 10?? FALSE
>
>
>     Or
>
>
>     set.seed(2020)
>     df3 <- data.frame(unit = 1:10)
>     df3$treated <- FALSE
>
>     df3[sample(nrow(df3), 3), "treated"] <- TRUE
>     df3
>     # result as expected
>
>
>     Hope this helps,
>
>     Rui? Barradas
>
>
>
>     ?s 13:49 de 19/06/2020, S?bastien Lahaie escreveu:
>     > I ran into some strange behavior in R when trying to assign a
>     treatment to
>     > rows in a data frame. I'm wondering whether any R experts can
>     explain
>     > what's going on.
>     >
>     > First, let's assign a treatment to 3 out of 10 rows as follows.
>     >
>     >> df <- data.frame(unit = 1:10)
>     >> df$treated <- FALSE
>     >> s <- sample(nrow(df), 3)
>     >> df[s,]$treated <- TRUE
>     >> df
>     >? ? ?unit treated
>     >
>     > 1? ? ?1? ?FALSE
>     >
>     > 2? ? ?2? ? TRUE
>     >
>     > 3? ? ?3? ?FALSE
>     >
>     > 4? ? ?4? ?FALSE
>     >
>     > 5? ? ?5? ? TRUE
>     >
>     > 6? ? ?6? ?FALSE
>     >
>     > 7? ? ?7? ? TRUE
>     >
>     > 8? ? ?8? ?FALSE
>     >
>     > 9? ? ?9? ?FALSE
>     >
>     > 10? ?10? ?FALSE
>     >
>     > This is as expected. Now we'll just skip the intermediate step
>     of saving
>     > the sampled indices, and apply the treatment directly as follows.
>     >
>     >> df <- data.frame(unit = 1:10)
>     >> df$treated <- FALSE
>     >> df[sample(nrow(df), 3),]$treated <- TRUE
>     >> df
>     >? ? ?unit treated
>     >
>     > 1? ? ?6? ? TRUE
>     >
>     > 2? ? ?2? ?FALSE
>     >
>     > 3? ? ?3? ?FALSE
>     >
>     > 4? ? ?9? ? TRUE
>     >
>     > 5? ? ?5? ?FALSE
>     >
>     > 6? ? ?6? ?FALSE
>     >
>     > 7? ? ?7? ?FALSE
>     >
>     > 8? ? ?5? ? TRUE
>     >
>     > 9? ? ?9? ?FALSE
>     >
>     > 10? ?10? ?FALSE
>     >
>     > Now the data frame still has 10 rows with 3 assigned to the
>     treatment. But
>     > the units are garbled. Units 1 and 4 have disappeared, for
>     instance, and
>     > there are duplicates for 6 and 9, one assigned to treatment and
>     the other
>     > to control. Why would this happen?
>     >
>     > Thanks,
>     > Sebastien
>     >
>     >? ? ? ?[[alternative HTML version deleted]]
>     >
>     > ______________________________________________
>     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>
>     -- 
>     Este e-mail foi verificado em termos de v?rus pelo software
>     antiv?rus Avast.
>     https://www.avast.com/antivirus
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>

-- 
Este e-mail foi verificado em termos de v?rus pelo software antiv?rus Avast.
https://www.avast.com/antivirus


From wdun|@p @end|ng |rom t|bco@com  Fri Jun 19 19:42:08 2020
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 19 Jun 2020 10:42:08 -0700
Subject: [R] Strange behavior when sampling rows of a data frame
In-Reply-To: <153b7026-3d63-44b7-3701-482441cdab94@sapo.pt>
References: <CAKQpU6Lr_ARRHdWpCJf1Bg5k3JDV3_Kw8CUBsYnSJLkeq03Nzw@mail.gmail.com>
 <e09460bb-61e6-b31c-af7c-e45a8a9a4c69@sapo.pt>
 <CAF8bMcYNJ52_vKmM2Ypa6NobB30gJqcVpx3KJ++N3Nwe90sWkg@mail.gmail.com>
 <153b7026-3d63-44b7-3701-482441cdab94@sapo.pt>
Message-ID: <CAF8bMcb8+uN_9HTT-H+h+an8yufkS7K9K7eY6+-n4uUD4Yix6w@mail.gmail.com>

It is a bug that has been present in R since at least R-2.14.0 (the oldest
that I have installed on my laptop).

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Jun 19, 2020 at 10:37 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
>
> Thanks, I hadn't thought of that.
>
> But, why? Is it evaluated once before assignment and a second time when
> the assignment occurs?
>
> To trace both sample and `[<-` gives 2 calls to sample.
>
>
> trace(sample)
> trace(`[<-`)
> df[sample(nrow(df), 3),]$treated <- TRUE
> trace: sample(nrow(df), 3)
> trace: `[<-`(`*tmp*`, sample(nrow(df), 3), , value = list(unit = c(7L,
> 6L, 8L), treated = c(TRUE, TRUE, TRUE)))
> trace: sample(nrow(df), 3)
>
>
> Regards,
>
> Rui Barradas
>
>
> ?s 17:20 de 19/06/2020, William Dunlap escreveu:
> > The first subscript argument is getting evaluated twice.
> > > trace(sample)
> > > set.seed(2020); df[i<-sample(10,3), ]$Treated <- TRUE
> > trace: sample(10, 3)
> > trace: sample(10, 3)
> > > i
> > [1]  1 10  4
> > > set.seed(2020); sample(10,3)
> > trace: sample(10, 3)
> > [1] 7 6 8
> > > sample(10,3)
> > trace: sample(10, 3)
> > [1]  1 10  4
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com <http://tibco.com>
> >
> >
> > On Fri, Jun 19, 2020 at 8:46 AM Rui Barradas <ruipbarradas at sapo.pt
> > <mailto:ruipbarradas at sapo.pt>> wrote:
> >
> >     Hello,
> >
> >     I don't have an answer on the reason why this happens but it seems
> >     like
> >     a bug. Where?
> >
> >     In which of  `[<-.data.frame` or `[<-.default`?
> >
> >     A solution is to subset and assign the vector:
> >
> >
> >     set.seed(2020)
> >     df2 <- data.frame(unit = 1:10)
> >     df2$treated <- FALSE
> >
> >     df2$treated[sample(nrow(df2), 3)] <- TRUE
> >     df2
> >     #  unit treated
> >     #1     1   FALSE
> >     #2     2   FALSE
> >     #3     3   FALSE
> >     #4     4   FALSE
> >     #5     5   FALSE
> >     #6     6    TRUE
> >     #7     7    TRUE
> >     #8     8    TRUE
> >     #9     9   FALSE
> >     #10   10   FALSE
> >
> >
> >     Or
> >
> >
> >     set.seed(2020)
> >     df3 <- data.frame(unit = 1:10)
> >     df3$treated <- FALSE
> >
> >     df3[sample(nrow(df3), 3), "treated"] <- TRUE
> >     df3
> >     # result as expected
> >
> >
> >     Hope this helps,
> >
> >     Rui  Barradas
> >
> >
> >
> >     ?s 13:49 de 19/06/2020, S?bastien Lahaie escreveu:
> >     > I ran into some strange behavior in R when trying to assign a
> >     treatment to
> >     > rows in a data frame. I'm wondering whether any R experts can
> >     explain
> >     > what's going on.
> >     >
> >     > First, let's assign a treatment to 3 out of 10 rows as follows.
> >     >
> >     >> df <- data.frame(unit = 1:10)
> >     >> df$treated <- FALSE
> >     >> s <- sample(nrow(df), 3)
> >     >> df[s,]$treated <- TRUE
> >     >> df
> >     >     unit treated
> >     >
> >     > 1     1   FALSE
> >     >
> >     > 2     2    TRUE
> >     >
> >     > 3     3   FALSE
> >     >
> >     > 4     4   FALSE
> >     >
> >     > 5     5    TRUE
> >     >
> >     > 6     6   FALSE
> >     >
> >     > 7     7    TRUE
> >     >
> >     > 8     8   FALSE
> >     >
> >     > 9     9   FALSE
> >     >
> >     > 10   10   FALSE
> >     >
> >     > This is as expected. Now we'll just skip the intermediate step
> >     of saving
> >     > the sampled indices, and apply the treatment directly as follows.
> >     >
> >     >> df <- data.frame(unit = 1:10)
> >     >> df$treated <- FALSE
> >     >> df[sample(nrow(df), 3),]$treated <- TRUE
> >     >> df
> >     >     unit treated
> >     >
> >     > 1     6    TRUE
> >     >
> >     > 2     2   FALSE
> >     >
> >     > 3     3   FALSE
> >     >
> >     > 4     9    TRUE
> >     >
> >     > 5     5   FALSE
> >     >
> >     > 6     6   FALSE
> >     >
> >     > 7     7   FALSE
> >     >
> >     > 8     5    TRUE
> >     >
> >     > 9     9   FALSE
> >     >
> >     > 10   10   FALSE
> >     >
> >     > Now the data frame still has 10 rows with 3 assigned to the
> >     treatment. But
> >     > the units are garbled. Units 1 and 4 have disappeared, for
> >     instance, and
> >     > there are duplicates for 6 and 9, one assigned to treatment and
> >     the other
> >     > to control. Why would this happen?
> >     >
> >     > Thanks,
> >     > Sebastien
> >     >
> >     >       [[alternative HTML version deleted]]
> >     >
> >     > ______________________________________________
> >     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> >     -- To UNSUBSCRIBE and more, see
> >     > https://stat.ethz.ch/mailman/listinfo/r-help
> >     > PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >     > and provide commented, minimal, self-contained, reproducible code.
> >
> >     --
> >     Este e-mail foi verificado em termos de v?rus pelo software
> >     antiv?rus Avast.
> >     https://www.avast.com/antivirus
> >
> >     ______________________________________________
> >     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
> >     To UNSUBSCRIBE and more, see
> >     https://stat.ethz.ch/mailman/listinfo/r-help
> >     PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >     and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Este e-mail foi verificado em termos de v?rus pelo software antiv?rus
> Avast.
> https://www.avast.com/antivirus
>
>

	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @end|ng |rom me@com  Fri Jun 19 19:48:46 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Fri, 19 Jun 2020 13:48:46 -0400
Subject: [R] R Software Risk Analysis
In-Reply-To: <7D31DABB-D947-4740-9E97-6CF7CC6FCCD4@me.com>
References: <mailman.359509.1.1592560801.37602.r-help@r-project.org>
 <dbbdc83f-64b2-fd4b-fd86-2bbe94669cc6@bebac.at>
 <7D31DABB-D947-4740-9E97-6CF7CC6FCCD4@me.com>
Message-ID: <48B0E98D-B96E-4BBF-9D70-200B30334027@me.com>

Hi All,

We need to get clarification from Kristin as to what kinds of issues are raised in the context of a risk analysis from her IT people.

Since Kristin's wording indicated:

  "...all programs that our employees/providers use must be vetted through the IT Department by way of a Risk Analysis."

that tells me that the risk analysis is *not* in reference to a software validation in the FDA sense of regulated clinical trials, not to mention that such validation is entirely on the end user, and not on the software publisher, in either case.

To reference various FDA related materials, such as the current R FDA guidance document and the 2015 FDA statistical software clarifying statement are not likely to be helpful here, and I say that as one of the co-authors of the R FDA document, along with Frank Harrell, Tony Rossini and Ian Francis. 

The general use by all employees context that Kristin references also suggests that one of the commercial vendors of R may or may not be helpful here either, unless they specifically provide consulting services and/or documentation to support their implementation of R and how it would conform to Kristin's IT department requirements, and not for use in an FDA-like trials setting.

For a general IT risk analysis, there is likely to be some kind of check-list or form that is required, and it will likely have questions such as:

1. Can R access operating system level commands - Yes

2. Can R access a local or remote file system, to create/read/delete files and folders - Yes

3. Can R access the internet to read remote locations and download files from servers - Yes

4. Can R alter operating system environment variables - Yes

5. Does the R installer require Administrative level privileges - Yes, with some qualifications, depending upon the platform

6. Does R provide end user documentation - Yes

and so forth.

There may be requirements set by Kristin's IT department where such characteristics will eliminate R from consideration, albeit, many commercial and open source applications would also have similar functionality. 

It may simply be a matter of her IT people understanding whether R provides or does not provide certain functionality, so that they know how it will perform in their environment, and what, if any, additional security measures may be required or need to be adjusted to enable required functionality.

Thus, in the absence of more detail from Kristin as to what is specifically required, it is hard to know how to respond, within the context here, of a community based support list, and within the R community at large, where we all volunteer our time.

Regards,

Marc Schwartz


From iuke-tier@ey m@iii@g oii uiow@@edu  Fri Jun 19 20:40:32 2020
From: iuke-tier@ey m@iii@g oii uiow@@edu (iuke-tier@ey m@iii@g oii uiow@@edu)
Date: Fri, 19 Jun 2020 13:40:32 -0500 (CDT)
Subject: [R] 
 [External] Re: Strange behavior when sampling rows of a data frame
In-Reply-To: <CAF8bMcb8+uN_9HTT-H+h+an8yufkS7K9K7eY6+-n4uUD4Yix6w@mail.gmail.com>
References: <CAKQpU6Lr_ARRHdWpCJf1Bg5k3JDV3_Kw8CUBsYnSJLkeq03Nzw@mail.gmail.com>
 <e09460bb-61e6-b31c-af7c-e45a8a9a4c69@sapo.pt>
 <CAF8bMcYNJ52_vKmM2Ypa6NobB30gJqcVpx3KJ++N3Nwe90sWkg@mail.gmail.com>
 <153b7026-3d63-44b7-3701-482441cdab94@sapo.pt>
 <CAF8bMcb8+uN_9HTT-H+h+an8yufkS7K9K7eY6+-n4uUD4Yix6w@mail.gmail.com>
Message-ID: <alpine.DEB.2.21.2006191321540.32631@luke-Latitude-7480>

The behavior has been there much longer than that in R and it's been a
known issue with complex assignment for a long time (not the only
one). You're in a better position than I to know how Splus handles this.

The complex assignment expression

     df[<index>, ]$treated <- TRUE

is basically evaluated as

     tmp <-df[<index>, ]
     tmp$treated <- TRUE
     df[<index>,] <- tmp

So the <index> argument is evaluated twice. This is always a little
inefficient, but probably not what you want if there are side effects
in the index argument. So the main take-away is:

     Don't use index arguments with side effects in complex assignments.

It is in principle possible, when standard evaluation is in use, to
capture the value of <index> from the first evaluation and re-use for
the second. But, for better or worse, assignment methods can and do
use non-standard evaluation for the index arguments, and it would be
very hard for authors of such methods to avoid this. So changing to
avoid multiple index evaluation would always have to come with an
asterisk.

There are other issues with complex assignment as implemented
currently that have higher priority but are also quite tricky to
address. Possibly this one can be addressed at the same time.

Best,

luke

On Fri, 19 Jun 2020, William Dunlap via R-help wrote:

> It is a bug that has been present in R since at least R-2.14.0 (the oldest
> that I have installed on my laptop).
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Fri, Jun 19, 2020 at 10:37 AM Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
>> Hello,
>>
>>
>> Thanks, I hadn't thought of that.
>>
>> But, why? Is it evaluated once before assignment and a second time when
>> the assignment occurs?
>>
>> To trace both sample and `[<-` gives 2 calls to sample.
>>
>>
>> trace(sample)
>> trace(`[<-`)
>> df[sample(nrow(df), 3),]$treated <- TRUE
>> trace: sample(nrow(df), 3)
>> trace: `[<-`(`*tmp*`, sample(nrow(df), 3), , value = list(unit = c(7L,
>> 6L, 8L), treated = c(TRUE, TRUE, TRUE)))
>> trace: sample(nrow(df), 3)
>>
>>
>> Regards,
>>
>> Rui Barradas
>>
>>
>> ?s 17:20 de 19/06/2020, William Dunlap escreveu:
>>> The first subscript argument is getting evaluated twice.
>>>> trace(sample)
>>>> set.seed(2020); df[i<-sample(10,3), ]$Treated <- TRUE
>>> trace: sample(10, 3)
>>> trace: sample(10, 3)
>>>> i
>>> [1]  1 10  4
>>>> set.seed(2020); sample(10,3)
>>> trace: sample(10, 3)
>>> [1] 7 6 8
>>>> sample(10,3)
>>> trace: sample(10, 3)
>>> [1]  1 10  4
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com <http://tibco.com>
>>>
>>>
>>> On Fri, Jun 19, 2020 at 8:46 AM Rui Barradas <ruipbarradas at sapo.pt
>>> <mailto:ruipbarradas at sapo.pt>> wrote:
>>>
>>>     Hello,
>>>
>>>     I don't have an answer on the reason why this happens but it seems
>>>     like
>>>     a bug. Where?
>>>
>>>     In which of  `[<-.data.frame` or `[<-.default`?
>>>
>>>     A solution is to subset and assign the vector:
>>>
>>>
>>>     set.seed(2020)
>>>     df2 <- data.frame(unit = 1:10)
>>>     df2$treated <- FALSE
>>>
>>>     df2$treated[sample(nrow(df2), 3)] <- TRUE
>>>     df2
>>>     #  unit treated
>>>     #1     1   FALSE
>>>     #2     2   FALSE
>>>     #3     3   FALSE
>>>     #4     4   FALSE
>>>     #5     5   FALSE
>>>     #6     6    TRUE
>>>     #7     7    TRUE
>>>     #8     8    TRUE
>>>     #9     9   FALSE
>>>     #10   10   FALSE
>>>
>>>
>>>     Or
>>>
>>>
>>>     set.seed(2020)
>>>     df3 <- data.frame(unit = 1:10)
>>>     df3$treated <- FALSE
>>>
>>>     df3[sample(nrow(df3), 3), "treated"] <- TRUE
>>>     df3
>>>     # result as expected
>>>
>>>
>>>     Hope this helps,
>>>
>>>     Rui  Barradas
>>>
>>>
>>>
>>>     ?s 13:49 de 19/06/2020, S?bastien Lahaie escreveu:
>>>    > I ran into some strange behavior in R when trying to assign a
>>>     treatment to
>>>    > rows in a data frame. I'm wondering whether any R experts can
>>>     explain
>>>    > what's going on.
>>>    >
>>>    > First, let's assign a treatment to 3 out of 10 rows as follows.
>>>    >
>>>    >> df <- data.frame(unit = 1:10)
>>>    >> df$treated <- FALSE
>>>    >> s <- sample(nrow(df), 3)
>>>    >> df[s,]$treated <- TRUE
>>>    >> df
>>>    >     unit treated
>>>    >
>>>    > 1     1   FALSE
>>>    >
>>>    > 2     2    TRUE
>>>    >
>>>    > 3     3   FALSE
>>>    >
>>>    > 4     4   FALSE
>>>    >
>>>    > 5     5    TRUE
>>>    >
>>>    > 6     6   FALSE
>>>    >
>>>    > 7     7    TRUE
>>>    >
>>>    > 8     8   FALSE
>>>    >
>>>    > 9     9   FALSE
>>>    >
>>>    > 10   10   FALSE
>>>    >
>>>    > This is as expected. Now we'll just skip the intermediate step
>>>     of saving
>>>    > the sampled indices, and apply the treatment directly as follows.
>>>    >
>>>    >> df <- data.frame(unit = 1:10)
>>>    >> df$treated <- FALSE
>>>    >> df[sample(nrow(df), 3),]$treated <- TRUE
>>>    >> df
>>>    >     unit treated
>>>    >
>>>    > 1     6    TRUE
>>>    >
>>>    > 2     2   FALSE
>>>    >
>>>    > 3     3   FALSE
>>>    >
>>>    > 4     9    TRUE
>>>    >
>>>    > 5     5   FALSE
>>>    >
>>>    > 6     6   FALSE
>>>    >
>>>    > 7     7   FALSE
>>>    >
>>>    > 8     5    TRUE
>>>    >
>>>    > 9     9   FALSE
>>>    >
>>>    > 10   10   FALSE
>>>    >
>>>    > Now the data frame still has 10 rows with 3 assigned to the
>>>     treatment. But
>>>    > the units are garbled. Units 1 and 4 have disappeared, for
>>>     instance, and
>>>    > there are duplicates for 6 and 9, one assigned to treatment and
>>>     the other
>>>    > to control. Why would this happen?
>>>    >
>>>    > Thanks,
>>>    > Sebastien
>>>    >
>>>    >       [[alternative HTML version deleted]]
>>>    >
>>>    > ______________________________________________
>>>    > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>>     -- To UNSUBSCRIBE and more, see
>>>    > https://stat.ethz.ch/mailman/listinfo/r-help
>>>    > PLEASE do read the posting guide
>>>     http://www.R-project.org/posting-guide.html
>>>    > and provide commented, minimal, self-contained, reproducible code.
>>>
>>>     --
>>>     Este e-mail foi verificado em termos de v?rus pelo software
>>>     antiv?rus Avast.
>>>     https://www.avast.com/antivirus
>>>
>>>     ______________________________________________
>>>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>>>     To UNSUBSCRIBE and more, see
>>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>>     PLEASE do read the posting guide
>>>     http://www.R-project.org/posting-guide.html
>>>     and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> --
>> Este e-mail foi verificado em termos de v?rus pelo software antiv?rus
>> Avast.
>> https://www.avast.com/antivirus
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Fri Jun 19 21:34:17 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 19 Jun 2020 14:34:17 -0500
Subject: [R] How to loop over two files ...
Message-ID: <CAF9-5jPXwoHr4cxDmRtP5Xt=6p5bZbgkRCZSMUsfdm3WsWvmDQ@mail.gmail.com>

Hello,

I have two files (each has 300 lines)like this:

head 1g.txt
rs6792369
rs1414517
rs16857712
rs16857703
rs12239392
...

head 1n.txt
rs1042779
rs2360630
rs10753597
rs7549096
rs2343491
...

For each pair of rs# from those two files I can run this command in R

library(httr)
library(jsonlite)
library(xml2)

server <- "http://rest.ensembl.org"
ext <- "/ld/human/pairwise/rs6792369/rs1042779?population_name=1000GENOMES:phase_3:KHV"

r <- GET(paste(server, ext, sep = ""), content_type("application/json"))

stop_for_status(r)
head(fromJSON(toJSON(content(r))))
   d_prime       r2 variation1 variation2         population_name
1 0.975513 0.951626  rs6792369  rs1042779 1000GENOMES:phase_3:KHV

What I would like to do is to do is to run this command for every SNP
in one list (1g.txt) to each SNP in another list (1n.txt). Where SNP#
is rs# and output every line of result in list.txt

The process is illustrated in the attachment.

Please help,
Ana

-------------- next part --------------
A non-text attachment was scrubbed...
Name: lists.pdf
Type: application/pdf
Size: 27519 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200619/45aca40e/attachment.pdf>

From cpoiw@rt m@iii@g oii chemo@org@uk  Fri Jun 19 22:28:53 2020
From: cpoiw@rt m@iii@g oii chemo@org@uk (cpoiw@rt m@iii@g oii chemo@org@uk)
Date: Fri, 19 Jun 2020 21:28:53 +0100
Subject: [R] How to loop over two files ...
In-Reply-To: <CAF9-5jPXwoHr4cxDmRtP5Xt=6p5bZbgkRCZSMUsfdm3WsWvmDQ@mail.gmail.com>
References: <CAF9-5jPXwoHr4cxDmRtP5Xt=6p5bZbgkRCZSMUsfdm3WsWvmDQ@mail.gmail.com>
Message-ID: <0f251037d302d02e0da085399ab4b627@chemo.org.uk>

so (untested) if you did something like

f1 <- read.text("1g.txt")
f2 <- read.text("1n.txt")

for ( a in as.list(f1) ) {

   for ( b in as.list(f2) ) {

ext <- paste0( "/ld/human/pairwise/",
                a,
                "/",
                b,
                "?population_name=1000GENOMES:phase_3:KHV")

                r <- GET(paste(server, ext, sep = ""), 
content_type("application/json"))

                # You presumably need to do something with 'r' at the 
moment its over written by the next loop..  were
                # you appending it to list.txt?  Possibly its just a bit 
of the R output you want.?

                write(r,file="list.txt",append=TRUE)


   }

}


Are we doing your PhD for you ;-)  Do we get to share ;-)


On 2020-06-19 20:34, Ana Marija wrote:
> Hello,
> 
> I have two files (each has 300 lines)like this:
> 
> head 1g.txt
> rs6792369
> rs1414517
> rs16857712
> rs16857703
> rs12239392
> ...
> 
> head 1n.txt
> rs1042779
> rs2360630
> rs10753597
> rs7549096
> rs2343491
> ...
> 
> For each pair of rs# from those two files I can run this command in R
> 
> library(httr)
> library(jsonlite)
> library(xml2)
> 
> server <- "http://rest.ensembl.org"
> ext <-
> "/ld/human/pairwise/rs6792369/rs1042779?population_name=1000GENOMES:phase_3:KHV"
> 
> r <- GET(paste(server, ext, sep = ""), 
> content_type("application/json"))
> 
> stop_for_status(r)
> head(fromJSON(toJSON(content(r))))
>    d_prime       r2 variation1 variation2         population_name
> 1 0.975513 0.951626  rs6792369  rs1042779 1000GENOMES:phase_3:KHV
> 
> What I would like to do is to do is to run this command for every SNP
> in one list (1g.txt) to each SNP in another list (1n.txt). Where SNP#
> is rs# and output every line of result in list.txt
> 
> The process is illustrated in the attachment.
> 
> Please help,
> Ana
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jr@| @end|ng |rom po@teo@no  Fri Jun 19 22:49:51 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Fri, 19 Jun 2020 22:49:51 +0200
Subject: [R] How to loop over two files ...
In-Reply-To: <CAF9-5jPXwoHr4cxDmRtP5Xt=6p5bZbgkRCZSMUsfdm3WsWvmDQ@mail.gmail.com>
References: <CAF9-5jPXwoHr4cxDmRtP5Xt=6p5bZbgkRCZSMUsfdm3WsWvmDQ@mail.gmail.com>
Message-ID: <20200619204951.GD35011@posteo.no>

On 2020-06-19 14:34 -0500, Ana Marija wrote:
> 
> server <- "http://rest.ensembl.org"
> ext <- "/ld/human/pairwise/rs6792369/rs1042779?population_name=1000GENOMES:phase_3:KHV"
> 
> r <- GET(paste(server, ext, sep = ""), content_type("application/json"))
> 
> stop_for_status(r)
> head(fromJSON(toJSON(content(r))))
>    d_prime       r2 variation1 variation2         population_name
> 1 0.975513 0.951626  rs6792369  rs1042779 1000GENOMES:phase_3:KHV
> 
> What I would like to do is to do is to run this command for every SNP
> in one list (1g.txt) to each SNP in another list (1n.txt). Where SNP#
> is rs# and output every line of result in list.txt

Dear Ana,

I tried, but for some reason I get only a 
response for the first URL you supplied.  

I wrote this:

	files <- c("1g.txt", "1n.txt")
	files <- lapply(files, readLines)
	server <- "http://rest.ensembl.org"
	population.name <- "1000GENOMES:phase_3:KHV"
	ext <- apply(expand.grid(files), 1, function(x) {
	  return(paste0(server, "/ld/human/pairwise/",
	    x[1], "/", x[2],
	    "?population_name=", population.name))
	})
	
	# r <- lapply(ext, function(x) {
	#   httr::GET(x, httr::content_type("application/json"))
	# })
	# names(r) <- ext
	# file <- paste0(population.name, ".rds")
	# saveRDS(object=r, compress="xz", file=file)
	
	r <- readRDS(paste0(population.name, ".rds"))
	lapply(r[1:4], function(x) {
	  jsonlite::fromJSON(jsonlite::toJSON(httr::content(x)))
	})


Which if you are able to run it (saving the 
output in that rds file), yields this: 

	$`http://rest.ensembl.org/ld/human/pairwise/rs6792369/rs1042779?population_name=1000GENOMES:phase_3:KHV`
	  variation2         population_name  d_prime       r2 variation1
	1  rs1042779 1000GENOMES:phase_3:KHV 0.975513 0.951626  rs6792369
	
	$`http://rest.ensembl.org/ld/human/pairwise/rs1414517/rs1042779?population_name=1000GENOMES:phase_3:KHV`
	list()
	
	$`http://rest.ensembl.org/ld/human/pairwise/rs16857712/rs1042779?population_name=1000GENOMES:phase_3:KHV`
	list()
	
	$`http://rest.ensembl.org/ld/human/pairwise/rs16857703/rs1042779?population_name=1000GENOMES:phase_3:KHV`
	list()

For some reason, only the first url works ...

I am a bit unfamiliar working with REST 
API's.  Or web scraping in general.  Daniel 
Cegie?ka knows something in this thread some 
days ago, where it might be similar to the 
API of borsaitaliana.it, where you can supply 
headers with curl like he quickly did [2].

You might be able to supply the list of SNPs 
in a header to Ensemble in httr::GET somehow 
if you read some docs on their API? 

Best,
Rasmus

[1] https://marc.info/?t=159249246100002&r=1&w=2
[2] https://marc.info/?l=r-sig-finance&m=159249894208684&w=2

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200619/65f5d896/attachment.sig>

From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Fri Jun 19 23:02:47 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 19 Jun 2020 16:02:47 -0500
Subject: [R] How to loop over two files ...
In-Reply-To: <0f251037d302d02e0da085399ab4b627@chemo.org.uk>
References: <CAF9-5jPXwoHr4cxDmRtP5Xt=6p5bZbgkRCZSMUsfdm3WsWvmDQ@mail.gmail.com>
 <0f251037d302d02e0da085399ab4b627@chemo.org.uk>
Message-ID: <CAF9-5jNHw5M1BZUMq26zroUD3QnA84e0=D7Wb1g1DMECQ5wChA@mail.gmail.com>

Hi,

thanks for getting back to me, it is just for my job :)

so I tried it:

library(httr)
library(jsonlite)
library(xml2)
library(SparkR, lib.loc = c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib")))
sparkR.session(master = "local[*]", sparkConfig =
list(spark.driver.memory = "2g"))

server <- "http://rest.ensembl.org"

f1 <- read.text("1g.txt")
f2 <- read.text("1n.txt")

for ( a in as.list(f1) ) {

   for ( b in as.list(f2) ) {

ext <- paste0( "/ld/human/pairwise/",
                a,
                "/",
                b,
                "?population_name=1000GENOMES:phase_3:KHV")

                r <- GET(paste(server, ext, sep = ""),
content_type("application/json"))

                write(r,file="list.txt",append=TRUE)


   }

}

and I got this error:
Error in as.list.default(f1) :
  no method for coercing this S4 class to a vector

Please advise

On Fri, Jun 19, 2020 at 3:28 PM <cpolwart at chemo.org.uk> wrote:
>
> so (untested) if you did something like
>
> f1 <- read.text("1g.txt")
> f2 <- read.text("1n.txt")
>
> for ( a in as.list(f1) ) {
>
>    for ( b in as.list(f2) ) {
>
> ext <- paste0( "/ld/human/pairwise/",
>                 a,
>                 "/",
>                 b,
>                 "?population_name=1000GENOMES:phase_3:KHV")
>
>                 r <- GET(paste(server, ext, sep = ""),
> content_type("application/json"))
>
>                 # You presumably need to do something with 'r' at the
> moment its over written by the next loop..  were
>                 # you appending it to list.txt?  Possibly its just a bit
> of the R output you want.?
>
>                 write(r,file="list.txt",append=TRUE)
>
>
>    }
>
> }
>
>
> Are we doing your PhD for you ;-)  Do we get to share ;-)
>
>
> On 2020-06-19 20:34, Ana Marija wrote:
> > Hello,
> >
> > I have two files (each has 300 lines)like this:
> >
> > head 1g.txt
> > rs6792369
> > rs1414517
> > rs16857712
> > rs16857703
> > rs12239392
> > ...
> >
> > head 1n.txt
> > rs1042779
> > rs2360630
> > rs10753597
> > rs7549096
> > rs2343491
> > ...
> >
> > For each pair of rs# from those two files I can run this command in R
> >
> > library(httr)
> > library(jsonlite)
> > library(xml2)
> >
> > server <- "http://rest.ensembl.org"
> > ext <-
> > "/ld/human/pairwise/rs6792369/rs1042779?population_name=1000GENOMES:phase_3:KHV"
> >
> > r <- GET(paste(server, ext, sep = ""),
> > content_type("application/json"))
> >
> > stop_for_status(r)
> > head(fromJSON(toJSON(content(r))))
> >    d_prime       r2 variation1 variation2         population_name
> > 1 0.975513 0.951626  rs6792369  rs1042779 1000GENOMES:phase_3:KHV
> >
> > What I would like to do is to do is to run this command for every SNP
> > in one list (1g.txt) to each SNP in another list (1n.txt). Where SNP#
> > is rs# and output every line of result in list.txt
> >
> > The process is illustrated in the attachment.
> >
> > Please help,
> > Ana
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Fri Jun 19 23:07:04 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 19 Jun 2020 16:07:04 -0500
Subject: [R] How to loop over two files ...
In-Reply-To: <20200619204951.GD35011@posteo.no>
References: <CAF9-5jPXwoHr4cxDmRtP5Xt=6p5bZbgkRCZSMUsfdm3WsWvmDQ@mail.gmail.com>
 <20200619204951.GD35011@posteo.no>
Message-ID: <CAF9-5jPhtTnsTd+aLgscEu37YjbUJS0+53d-XUB48GkpUxpOrg@mail.gmail.com>

HI Rasmus,

I tried it:

library(base)

files <- c("1g.txt", "1n.txt")
        files <- lapply(files, readLines)
        server <- "http://rest.ensembl.org"
        population.name <- "1000GENOMES:phase_3:KHV"
        ext <- apply(expand.grid(files), 1, function(x) {
          return(paste0(server, "/ld/human/pairwise/",
            x[1], "/", x[2],
            "?population_name=", population.name))
        })

r <- readRDS(paste0(population.name, ".rds"))
        lapply(r[1:4], function(x) {
          jsonlite::fromJSON(jsonlite::toJSON(httr::content(x)))
        })

and I got this error:
> r <- readRDS(paste0(population.name, ".rds"))
Error in gzfile(file, "rb") : cannot open the connection
In addition: Warning message:
In gzfile(file, "rb") :
  cannot open compressed file '1000GENOMES:phase_3:KHV.rds', probable
reason 'No such file or directory'
>         lapply(r[1:4], function(x) {
+           jsonlite::fromJSON(jsonlite::toJSON(httr::content(x)))
+         })
Error in lapply(r[1:4], function(x) { : object 'r' not found

Am I am doing here something wrong?
Do I need any other libraries loaded?

Thanks
Ana

On Fri, Jun 19, 2020 at 3:49 PM Rasmus Liland <jral at posteo.no> wrote:
>
> On 2020-06-19 14:34 -0500, Ana Marija wrote:
> >
> > server <- "http://rest.ensembl.org"
> > ext <- "/ld/human/pairwise/rs6792369/rs1042779?population_name=1000GENOMES:phase_3:KHV"
> >
> > r <- GET(paste(server, ext, sep = ""), content_type("application/json"))
> >
> > stop_for_status(r)
> > head(fromJSON(toJSON(content(r))))
> >    d_prime       r2 variation1 variation2         population_name
> > 1 0.975513 0.951626  rs6792369  rs1042779 1000GENOMES:phase_3:KHV
> >
> > What I would like to do is to do is to run this command for every SNP
> > in one list (1g.txt) to each SNP in another list (1n.txt). Where SNP#
> > is rs# and output every line of result in list.txt
>
> Dear Ana,
>
> I tried, but for some reason I get only a
> response for the first URL you supplied.
>
> I wrote this:
>
>         files <- c("1g.txt", "1n.txt")
>         files <- lapply(files, readLines)
>         server <- "http://rest.ensembl.org"
>         population.name <- "1000GENOMES:phase_3:KHV"
>         ext <- apply(expand.grid(files), 1, function(x) {
>           return(paste0(server, "/ld/human/pairwise/",
>             x[1], "/", x[2],
>             "?population_name=", population.name))
>         })
>
>         # r <- lapply(ext, function(x) {
>         #   httr::GET(x, httr::content_type("application/json"))
>         # })
>         # names(r) <- ext
>         # file <- paste0(population.name, ".rds")
>         # saveRDS(object=r, compress="xz", file=file)
>
>         r <- readRDS(paste0(population.name, ".rds"))
>         lapply(r[1:4], function(x) {
>           jsonlite::fromJSON(jsonlite::toJSON(httr::content(x)))
>         })
>
>
> Which if you are able to run it (saving the
> output in that rds file), yields this:
>
>         $`http://rest.ensembl.org/ld/human/pairwise/rs6792369/rs1042779?population_name=1000GENOMES:phase_3:KHV`
>           variation2         population_name  d_prime       r2 variation1
>         1  rs1042779 1000GENOMES:phase_3:KHV 0.975513 0.951626  rs6792369
>
>         $`http://rest.ensembl.org/ld/human/pairwise/rs1414517/rs1042779?population_name=1000GENOMES:phase_3:KHV`
>         list()
>
>         $`http://rest.ensembl.org/ld/human/pairwise/rs16857712/rs1042779?population_name=1000GENOMES:phase_3:KHV`
>         list()
>
>         $`http://rest.ensembl.org/ld/human/pairwise/rs16857703/rs1042779?population_name=1000GENOMES:phase_3:KHV`
>         list()
>
> For some reason, only the first url works ...
>
> I am a bit unfamiliar working with REST
> API's.  Or web scraping in general.  Daniel
> Cegie?ka knows something in this thread some
> days ago, where it might be similar to the
> API of borsaitaliana.it, where you can supply
> headers with curl like he quickly did [2].
>
> You might be able to supply the list of SNPs
> in a header to Ensemble in httr::GET somehow
> if you read some docs on their API?
>
> Best,
> Rasmus
>
> [1] https://marc.info/?t=159249246100002&r=1&w=2
> [2] https://marc.info/?l=r-sig-finance&m=159249894208684&w=2


From jr@| @end|ng |rom po@teo@no  Fri Jun 19 23:31:33 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Fri, 19 Jun 2020 23:31:33 +0200
Subject: [R] How to loop over two files ...
In-Reply-To: <CAF9-5jPhtTnsTd+aLgscEu37YjbUJS0+53d-XUB48GkpUxpOrg@mail.gmail.com>
References: <CAF9-5jPXwoHr4cxDmRtP5Xt=6p5bZbgkRCZSMUsfdm3WsWvmDQ@mail.gmail.com>
 <20200619204951.GD35011@posteo.no>
 <CAF9-5jPhtTnsTd+aLgscEu37YjbUJS0+53d-XUB48GkpUxpOrg@mail.gmail.com>
Message-ID: <20200619213133.GE35011@posteo.no>

On 2020-06-19 16:07 -0500, Ana Marija wrote:
> HI Rasmus,
> 
> I tried it:
> 
> library(base)
> 
> > r <- readRDS(paste0(population.name, ".rds"))
> Error in gzfile(file, "rb") : cannot open the connection
> In addition: Warning message:
> In gzfile(file, "rb") :
>   cannot open compressed file '1000GENOMES:phase_3:KHV.rds', probable
> reason 'No such file or directory'

Because I run my script again and again after 
every little small change using the program 
entr[1] as opposed to using Emacs Speaks 
Statistics or RStudio, I find it useful to 
save partial outputs in rds files, but it 
also make sense to not call ensembl.org again 
and again ...

Right, so you would run the commented bit 
before that first, then save the output list 
to the rds to not send too many requests to 
the list.  I have attached my rds here.  

	files <- c("1g.txt", "1n.txt")
	files <- lapply(files, readLines)
	server <- "http://rest.ensembl.org"
	population.name <- "1000GENOMES:phase_3:KHV"
	ext <- apply(expand.grid(files), 1, function(x) {
	  return(paste0(server, "/ld/human/pairwise/",
	    x[1], "/", x[2],
	    "?population_name=", population.name))
	})
	
	r <- lapply(ext, function(x) {
	  httr::GET(x, httr::content_type("application/json"))
	})
	names(r) <- ext
	file <- paste0(population.name, ".rds")
	
	saveRDS(object=r, compress="xz", file=file)  # <--- Then save the list here for another time!
	# r <- readRDS(paste0(population.name, ".rds"))  # Read it back like this
	
	r <-
	sapply(r, function(x) {
	  x <- jsonlite::fromJSON(jsonlite::toJSON(httr::content(x)))
	  length(x)
	})
	names(r) <- NULL
	r

[1] http://eradman.com/entrproject/

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200619/e6b6ddea/attachment.sig>

From cpoiw@rt m@iii@g oii chemo@org@uk  Fri Jun 19 23:41:54 2020
From: cpoiw@rt m@iii@g oii chemo@org@uk (cpoiw@rt m@iii@g oii chemo@org@uk)
Date: Fri, 19 Jun 2020 22:41:54 +0100
Subject: [R] How to loop over two files ...
In-Reply-To: <CAF9-5jNHw5M1BZUMq26zroUD3QnA84e0=D7Wb1g1DMECQ5wChA@mail.gmail.com>
References: <CAF9-5jPXwoHr4cxDmRtP5Xt=6p5bZbgkRCZSMUsfdm3WsWvmDQ@mail.gmail.com>
 <0f251037d302d02e0da085399ab4b627@chemo.org.uk>
 <CAF9-5jNHw5M1BZUMq26zroUD3QnA84e0=D7Wb1g1DMECQ5wChA@mail.gmail.com>
Message-ID: <687ca3db19cde8b8f340a54632e75ea6@chemo.org.uk>

Oh - read.text isn't in base!  Not sure where is came from (my head 
mostly!)  You may have something that adds it but better to use 
something that works.  So try using:

library(readr)
f1 <- read_tsv("1g.txt", col.names=F)

This will give you a tibble with f1$X1 with the file in it

then loop it with (a in as.list(f1[,1])

Others will have much slicker code than me!

On 2020-06-19 22:02, Ana Marija wrote:
> Hi,
> 
> thanks for getting back to me, it is just for my job :)
> 
> so I tried it:
> 
> library(httr)
> library(jsonlite)
> library(xml2)
> library(SparkR, lib.loc = c(file.path(Sys.getenv("SPARK_HOME"), "R", 
> "lib")))
> sparkR.session(master = "local[*]", sparkConfig =
> list(spark.driver.memory = "2g"))
> 
> server <- "http://rest.ensembl.org"
> 
> f1 <- read.text("1g.txt")
> f2 <- read.text("1n.txt")
> 
> for ( a in as.list(f1) ) {
> 
>    for ( b in as.list(f2) ) {
> 
> ext <- paste0( "/ld/human/pairwise/",
>                 a,
>                 "/",
>                 b,
>                 "?population_name=1000GENOMES:phase_3:KHV")
> 
>                 r <- GET(paste(server, ext, sep = ""),
> content_type("application/json"))
> 
>                 write(r,file="list.txt",append=TRUE)
> 
> 
>    }
> 
> }
> 
> and I got this error:
> Error in as.list.default(f1) :
>   no method for coercing this S4 class to a vector
> 
> Please advise
> 
> On Fri, Jun 19, 2020 at 3:28 PM <cpolwart at chemo.org.uk> wrote:
>> 
>> so (untested) if you did something like
>> 
>> f1 <- read.text("1g.txt")
>> f2 <- read.text("1n.txt")
>> 
>> for ( a in as.list(f1) ) {
>> 
>>    for ( b in as.list(f2) ) {
>> 
>> ext <- paste0( "/ld/human/pairwise/",
>>                 a,
>>                 "/",
>>                 b,
>>                 "?population_name=1000GENOMES:phase_3:KHV")
>> 
>>                 r <- GET(paste(server, ext, sep = ""),
>> content_type("application/json"))
>> 
>>                 # You presumably need to do something with 'r' at the
>> moment its over written by the next loop..  were
>>                 # you appending it to list.txt?  Possibly its just a 
>> bit
>> of the R output you want.?
>> 
>>                 write(r,file="list.txt",append=TRUE)
>> 
>> 
>>    }
>> 
>> }
>> 
>> 
>> Are we doing your PhD for you ;-)  Do we get to share ;-)
>> 
>> 
>> On 2020-06-19 20:34, Ana Marija wrote:
>> > Hello,
>> >
>> > I have two files (each has 300 lines)like this:
>> >
>> > head 1g.txt
>> > rs6792369
>> > rs1414517
>> > rs16857712
>> > rs16857703
>> > rs12239392
>> > ...
>> >
>> > head 1n.txt
>> > rs1042779
>> > rs2360630
>> > rs10753597
>> > rs7549096
>> > rs2343491
>> > ...
>> >
>> > For each pair of rs# from those two files I can run this command in R
>> >
>> > library(httr)
>> > library(jsonlite)
>> > library(xml2)
>> >
>> > server <- "http://rest.ensembl.org"
>> > ext <-
>> > "/ld/human/pairwise/rs6792369/rs1042779?population_name=1000GENOMES:phase_3:KHV"
>> >
>> > r <- GET(paste(server, ext, sep = ""),
>> > content_type("application/json"))
>> >
>> > stop_for_status(r)
>> > head(fromJSON(toJSON(content(r))))
>> >    d_prime       r2 variation1 variation2         population_name
>> > 1 0.975513 0.951626  rs6792369  rs1042779 1000GENOMES:phase_3:KHV
>> >
>> > What I would like to do is to do is to run this command for every SNP
>> > in one list (1g.txt) to each SNP in another list (1n.txt). Where SNP#
>> > is rs# and output every line of result in list.txt
>> >
>> > The process is illustrated in the attachment.
>> >
>> > Please help,
>> > Ana
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Fri Jun 19 23:54:42 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 19 Jun 2020 16:54:42 -0500
Subject: [R] How to loop over two files ...
In-Reply-To: <687ca3db19cde8b8f340a54632e75ea6@chemo.org.uk>
References: <CAF9-5jPXwoHr4cxDmRtP5Xt=6p5bZbgkRCZSMUsfdm3WsWvmDQ@mail.gmail.com>
 <0f251037d302d02e0da085399ab4b627@chemo.org.uk>
 <CAF9-5jNHw5M1BZUMq26zroUD3QnA84e0=D7Wb1g1DMECQ5wChA@mail.gmail.com>
 <687ca3db19cde8b8f340a54632e75ea6@chemo.org.uk>
Message-ID: <CAF9-5jN=MSaKWziUXW-F1acq_d5nnr0UvLNr=A=xJJWhVw39EA@mail.gmail.com>

I tried it:

 > library(httr)
> library(jsonlite)
> library(xml2)
> library(readr)
> server <- "http://rest.ensembl.org"
> f1 <- read_tsv("1g", col_names=F)
Parsed with column specification:
cols(
  X1 = col_character()
)
> f2 <- read_tsv("1n", col_names=F)
Parsed with column specification:
cols(
  X1 = col_character()
)
>
> for ( a in as.list(f1[,1]) ) {
+
+    for ( b in as.list(f2[,1]) ) {
+
+ ext <- paste0( "/ld/human/pairwise/",
+                 a,
+                 "/",
+                 b,
+                 "?population_name=1000GENOMES:phase_3:KHV")
+
+                 r <- GET(paste(server, ext, sep = ""),
+ content_type("application/json"))
+
+                 write(r,file="list.txt",append=TRUE)
+
+
+    }
+
+ }
Error in parse_url(url) : length(url) == 1 is not TRUE

> traceback()
10: stop(simpleError(msg, call = if (p <- sys.parent(1L)) sys.call(p)))
9: stopifnot(length(url) == 1)
8: parse_url(url)
7: is.url(url)
6: stopifnot(is.url(url))
5: build_url(parse_url(url)[c("scheme", "hostname", "port")])
4: handle_name(url)
3: handle_find(url)
2: handle_url(handle, url, ...)
1: GET(paste(server, ext, sep = ""), content_type("application/json"))

On Fri, Jun 19, 2020 at 4:41 PM <cpolwart at chemo.org.uk> wrote:
>
> Oh - read.text isn't in base!  Not sure where is came from (my head
> mostly!)  You may have something that adds it but better to use
> something that works.  So try using:
>
> library(readr)
> f1 <- read_tsv("1g.txt", col.names=F)
>
> This will give you a tibble with f1$X1 with the file in it
>
> then loop it with (a in as.list(f1[,1])
>
> Others will have much slicker code than me!
>
> On 2020-06-19 22:02, Ana Marija wrote:
> > Hi,
> >
> > thanks for getting back to me, it is just for my job :)
> >
> > so I tried it:
> >
> > library(httr)
> > library(jsonlite)
> > library(xml2)
> > library(SparkR, lib.loc = c(file.path(Sys.getenv("SPARK_HOME"), "R",
> > "lib")))
> > sparkR.session(master = "local[*]", sparkConfig =
> > list(spark.driver.memory = "2g"))
> >
> > server <- "http://rest.ensembl.org"
> >
> > f1 <- read.text("1g.txt")
> > f2 <- read.text("1n.txt")
> >
> > for ( a in as.list(f1) ) {
> >
> >    for ( b in as.list(f2) ) {
> >
> > ext <- paste0( "/ld/human/pairwise/",
> >                 a,
> >                 "/",
> >                 b,
> >                 "?population_name=1000GENOMES:phase_3:KHV")
> >
> >                 r <- GET(paste(server, ext, sep = ""),
> > content_type("application/json"))
> >
> >                 write(r,file="list.txt",append=TRUE)
> >
> >
> >    }
> >
> > }
> >
> > and I got this error:
> > Error in as.list.default(f1) :
> >   no method for coercing this S4 class to a vector
> >
> > Please advise
> >
> > On Fri, Jun 19, 2020 at 3:28 PM <cpolwart at chemo.org.uk> wrote:
> >>
> >> so (untested) if you did something like
> >>
> >> f1 <- read.text("1g.txt")
> >> f2 <- read.text("1n.txt")
> >>
> >> for ( a in as.list(f1) ) {
> >>
> >>    for ( b in as.list(f2) ) {
> >>
> >> ext <- paste0( "/ld/human/pairwise/",
> >>                 a,
> >>                 "/",
> >>                 b,
> >>                 "?population_name=1000GENOMES:phase_3:KHV")
> >>
> >>                 r <- GET(paste(server, ext, sep = ""),
> >> content_type("application/json"))
> >>
> >>                 # You presumably need to do something with 'r' at the
> >> moment its over written by the next loop..  were
> >>                 # you appending it to list.txt?  Possibly its just a
> >> bit
> >> of the R output you want.?
> >>
> >>                 write(r,file="list.txt",append=TRUE)
> >>
> >>
> >>    }
> >>
> >> }
> >>
> >>
> >> Are we doing your PhD for you ;-)  Do we get to share ;-)
> >>
> >>
> >> On 2020-06-19 20:34, Ana Marija wrote:
> >> > Hello,
> >> >
> >> > I have two files (each has 300 lines)like this:
> >> >
> >> > head 1g.txt
> >> > rs6792369
> >> > rs1414517
> >> > rs16857712
> >> > rs16857703
> >> > rs12239392
> >> > ...
> >> >
> >> > head 1n.txt
> >> > rs1042779
> >> > rs2360630
> >> > rs10753597
> >> > rs7549096
> >> > rs2343491
> >> > ...
> >> >
> >> > For each pair of rs# from those two files I can run this command in R
> >> >
> >> > library(httr)
> >> > library(jsonlite)
> >> > library(xml2)
> >> >
> >> > server <- "http://rest.ensembl.org"
> >> > ext <-
> >> > "/ld/human/pairwise/rs6792369/rs1042779?population_name=1000GENOMES:phase_3:KHV"
> >> >
> >> > r <- GET(paste(server, ext, sep = ""),
> >> > content_type("application/json"))
> >> >
> >> > stop_for_status(r)
> >> > head(fromJSON(toJSON(content(r))))
> >> >    d_prime       r2 variation1 variation2         population_name
> >> > 1 0.975513 0.951626  rs6792369  rs1042779 1000GENOMES:phase_3:KHV
> >> >
> >> > What I would like to do is to do is to run this command for every SNP
> >> > in one list (1g.txt) to each SNP in another list (1n.txt). Where SNP#
> >> > is rs# and output every line of result in list.txt
> >> >
> >> > The process is illustrated in the attachment.
> >> >
> >> > Please help,
> >> > Ana
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.


From jr@| @end|ng |rom po@teo@no  Sat Jun 20 00:17:11 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Sat, 20 Jun 2020 00:17:11 +0200
Subject: [R] How to loop over two files ...
In-Reply-To: <20200619213133.GE35011@posteo.no>
References: <CAF9-5jPXwoHr4cxDmRtP5Xt=6p5bZbgkRCZSMUsfdm3WsWvmDQ@mail.gmail.com>
 <20200619204951.GD35011@posteo.no>
 <CAF9-5jPhtTnsTd+aLgscEu37YjbUJS0+53d-XUB48GkpUxpOrg@mail.gmail.com>
 <20200619213133.GE35011@posteo.no>
Message-ID: <20200619221711.GA149628@posteo.no>

Dear other list readers, 

On 2020-06-19 23:31 +0200, Rasmus Liland wrote:
> I have attached my rds here.  

only Ana recieved this because of a Mailman 
attachment policy, which also is why my 
signature was bad ...

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200620/7c5a3036/attachment.sig>

From cpoiw@rt m@iii@g oii chemo@org@uk  Sat Jun 20 00:19:05 2020
From: cpoiw@rt m@iii@g oii chemo@org@uk (cpoiw@rt m@iii@g oii chemo@org@uk)
Date: Fri, 19 Jun 2020 23:19:05 +0100
Subject: [R] How to loop over two files ...
In-Reply-To: <CAF9-5jN=MSaKWziUXW-F1acq_d5nnr0UvLNr=A=xJJWhVw39EA@mail.gmail.com>
References: <CAF9-5jPXwoHr4cxDmRtP5Xt=6p5bZbgkRCZSMUsfdm3WsWvmDQ@mail.gmail.com>
 <0f251037d302d02e0da085399ab4b627@chemo.org.uk>
 <CAF9-5jNHw5M1BZUMq26zroUD3QnA84e0=D7Wb1g1DMECQ5wChA@mail.gmail.com>
 <687ca3db19cde8b8f340a54632e75ea6@chemo.org.uk>
 <CAF9-5jN=MSaKWziUXW-F1acq_d5nnr0UvLNr=A=xJJWhVw39EA@mail.gmail.com>
Message-ID: <74a49794ea4387f177f83f5d8be7b28f@chemo.org.uk>

Sorry - its been a long week!

there is a foreach package but I try to avoid extras

make your for statements:

for ( a in rownames(f1) ) {

# a will now be a row number rather than the value, so replace ' a ' in 
the paste0 with: f1[ a, 1]

so

ext <- paste0( "/ld/human/pairwise/",
                  f1[a,1],
                  "/",
                  f2[b,1],
                  "?population_name=1000GENOMES:phase_3:KHV")

On 2020-06-19 22:54, Ana Marija wrote:
> I tried it:
> 
>  > library(httr)
>> library(jsonlite)
>> library(xml2)
>> library(readr)
>> server <- "http://rest.ensembl.org"
>> f1 <- read_tsv("1g", col_names=F)
> Parsed with column specification:
> cols(
>   X1 = col_character()
> )
>> f2 <- read_tsv("1n", col_names=F)
> Parsed with column specification:
> cols(
>   X1 = col_character()
> )
>> 
>> for ( a in as.list(f1[,1]) ) {
> +
> +    for ( b in as.list(f2[,1]) ) {
> +
> + ext <- paste0( "/ld/human/pairwise/",
> +                 a,
> +                 "/",
> +                 b,
> +                 "?population_name=1000GENOMES:phase_3:KHV")
> +
> +                 r <- GET(paste(server, ext, sep = ""),
> + content_type("application/json"))
> +
> +                 write(r,file="list.txt",append=TRUE)
> +
> +
> +    }
> +
> + }
> Error in parse_url(url) : length(url) == 1 is not TRUE
> 
>> traceback()
> 10: stop(simpleError(msg, call = if (p <- sys.parent(1L)) sys.call(p)))
> 9: stopifnot(length(url) == 1)
> 8: parse_url(url)
> 7: is.url(url)
> 6: stopifnot(is.url(url))
> 5: build_url(parse_url(url)[c("scheme", "hostname", "port")])
> 4: handle_name(url)
> 3: handle_find(url)
> 2: handle_url(handle, url, ...)
> 1: GET(paste(server, ext, sep = ""), content_type("application/json"))
> 
> On Fri, Jun 19, 2020 at 4:41 PM <cpolwart at chemo.org.uk> wrote:
>> 
>> Oh - read.text isn't in base!  Not sure where is came from (my head
>> mostly!)  You may have something that adds it but better to use
>> something that works.  So try using:
>> 
>> library(readr)
>> f1 <- read_tsv("1g.txt", col.names=F)
>> 
>> This will give you a tibble with f1$X1 with the file in it
>> 
>> then loop it with (a in as.list(f1[,1])
>> 
>> Others will have much slicker code than me!
>> 
>> On 2020-06-19 22:02, Ana Marija wrote:
>> > Hi,
>> >
>> > thanks for getting back to me, it is just for my job :)
>> >
>> > so I tried it:
>> >
>> > library(httr)
>> > library(jsonlite)
>> > library(xml2)
>> > library(SparkR, lib.loc = c(file.path(Sys.getenv("SPARK_HOME"), "R",
>> > "lib")))
>> > sparkR.session(master = "local[*]", sparkConfig =
>> > list(spark.driver.memory = "2g"))
>> >
>> > server <- "http://rest.ensembl.org"
>> >
>> > f1 <- read.text("1g.txt")
>> > f2 <- read.text("1n.txt")
>> >
>> > for ( a in as.list(f1) ) {
>> >
>> >    for ( b in as.list(f2) ) {
>> >
>> > ext <- paste0( "/ld/human/pairwise/",
>> >                 a,
>> >                 "/",
>> >                 b,
>> >                 "?population_name=1000GENOMES:phase_3:KHV")
>> >
>> >                 r <- GET(paste(server, ext, sep = ""),
>> > content_type("application/json"))
>> >
>> >                 write(r,file="list.txt",append=TRUE)
>> >
>> >
>> >    }
>> >
>> > }
>> >
>> > and I got this error:
>> > Error in as.list.default(f1) :
>> >   no method for coercing this S4 class to a vector
>> >
>> > Please advise
>> >
>> > On Fri, Jun 19, 2020 at 3:28 PM <cpolwart at chemo.org.uk> wrote:
>> >>
>> >> so (untested) if you did something like
>> >>
>> >> f1 <- read.text("1g.txt")
>> >> f2 <- read.text("1n.txt")
>> >>
>> >> for ( a in as.list(f1) ) {
>> >>
>> >>    for ( b in as.list(f2) ) {
>> >>
>> >> ext <- paste0( "/ld/human/pairwise/",
>> >>                 a,
>> >>                 "/",
>> >>                 b,
>> >>                 "?population_name=1000GENOMES:phase_3:KHV")
>> >>
>> >>                 r <- GET(paste(server, ext, sep = ""),
>> >> content_type("application/json"))
>> >>
>> >>                 # You presumably need to do something with 'r' at the
>> >> moment its over written by the next loop..  were
>> >>                 # you appending it to list.txt?  Possibly its just a
>> >> bit
>> >> of the R output you want.?
>> >>
>> >>                 write(r,file="list.txt",append=TRUE)
>> >>
>> >>
>> >>    }
>> >>
>> >> }
>> >>
>> >>
>> >> Are we doing your PhD for you ;-)  Do we get to share ;-)
>> >>
>> >>
>> >> On 2020-06-19 20:34, Ana Marija wrote:
>> >> > Hello,
>> >> >
>> >> > I have two files (each has 300 lines)like this:
>> >> >
>> >> > head 1g.txt
>> >> > rs6792369
>> >> > rs1414517
>> >> > rs16857712
>> >> > rs16857703
>> >> > rs12239392
>> >> > ...
>> >> >
>> >> > head 1n.txt
>> >> > rs1042779
>> >> > rs2360630
>> >> > rs10753597
>> >> > rs7549096
>> >> > rs2343491
>> >> > ...
>> >> >
>> >> > For each pair of rs# from those two files I can run this command in R
>> >> >
>> >> > library(httr)
>> >> > library(jsonlite)
>> >> > library(xml2)
>> >> >
>> >> > server <- "http://rest.ensembl.org"
>> >> > ext <-
>> >> > "/ld/human/pairwise/rs6792369/rs1042779?population_name=1000GENOMES:phase_3:KHV"
>> >> >
>> >> > r <- GET(paste(server, ext, sep = ""),
>> >> > content_type("application/json"))
>> >> >
>> >> > stop_for_status(r)
>> >> > head(fromJSON(toJSON(content(r))))
>> >> >    d_prime       r2 variation1 variation2         population_name
>> >> > 1 0.975513 0.951626  rs6792369  rs1042779 1000GENOMES:phase_3:KHV
>> >> >
>> >> > What I would like to do is to do is to run this command for every SNP
>> >> > in one list (1g.txt) to each SNP in another list (1n.txt). Where SNP#
>> >> > is rs# and output every line of result in list.txt
>> >> >
>> >> > The process is illustrated in the attachment.
>> >> >
>> >> > Please help,
>> >> > Ana
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide
>> >> > http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible code.


From djnord|und @end|ng |rom gm@||@com  Sat Jun 20 01:04:33 2020
From: djnord|und @end|ng |rom gm@||@com (Daniel Nordlund)
Date: Fri, 19 Jun 2020 16:04:33 -0700
Subject: [R] Strange behavior when sampling rows of a data frame
In-Reply-To: <CAKQpU6Lr_ARRHdWpCJf1Bg5k3JDV3_Kw8CUBsYnSJLkeq03Nzw@mail.gmail.com>
References: <CAKQpU6Lr_ARRHdWpCJf1Bg5k3JDV3_Kw8CUBsYnSJLkeq03Nzw@mail.gmail.com>
Message-ID: <f29504f9-5dfb-8657-3820-de8aa80369c6@gmail.com>

On 6/19/2020 5:49 AM, S?bastien Lahaie wrote:
> I ran into some strange behavior in R when trying to assign a treatment to
> rows in a data frame. I'm wondering whether any R experts can explain
> what's going on.
>
> First, let's assign a treatment to 3 out of 10 rows as follows.
>
> df <- data.frame(unit = 1:10)
> df$treated <- FALSE
> s <- sample(nrow(df), 3)
> df[s,]$treated <- TRUE
> df
>     unit treated
> 1     1   FALSE
> 2     2    TRUE
> 3     3   FALSE
> 4     4   FALSE
> 5     5    TRUE
> 6     6   FALSE
> 7     7    TRUE
> 8     8   FALSE
> 9     9   FALSE
> 10   10   FALSE
>
> This is as expected. Now we'll just skip the intermediate step of saving
> the sampled indices, and apply the treatment directly as follows.
>
> df <- data.frame(unit = 1:10)
> df$treated <- FALSE
> df[sample(nrow(df), 3),]$treated <- TRUE
> df
>     unit treated
> 1     6    TRUE
> 2     2   FALSE
> 3     3   FALSE
> 4     9    TRUE
> 5     5   FALSE
> 6     6   FALSE
> 7     7   FALSE
> 8     5    TRUE
> 9     9   FALSE
> 10   10   FALSE
>
> Now the data frame still has 10 rows with 3 assigned to the treatment. But
> the units are garbled. Units 1 and 4 have disappeared, for instance, and
> there are duplicates for 6 and 9, one assigned to treatment and the other
> to control. Why would this happen?
>
> Thanks,
> Sebastien
>
S?bastien,

You have received good explanations of what is going on with your code.? 
I think you can get what you want by making a simple modification of 
your treatment assignment statement. At least it works for me.

df[sample(nrow(df),3), 'treated'] <- TRUE

Hope this is helpful,

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From @purd|e@@ @end|ng |rom gm@||@com  Sat Jun 20 01:30:03 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Sat, 20 Jun 2020 11:30:03 +1200
Subject: [R] Load svg, eps or png into graphics device?
In-Reply-To: <A7F8903F-97D3-4CB8-BC2A-CA2117EFB5DE@krugs.de>
References: <A7F8903F-97D3-4CB8-BC2A-CA2117EFB5DE@krugs.de>
Message-ID: <CAB8pepx54Wn7AgpTNAeJw2KoDoBqCfqNKeSjx-Zjc20amLoy4w@mail.gmail.com>

If I understand your question correctly, you're already able to read
an EPS file.
So, essentially, you have an answer to your question.

Paul Murrell published an article on using raster graphics, in 2011.
https://journal.r-project.org/archive/2011-1/RJournal_2011-1_Murrell.pdf

I would assume there's been progress since then.
But I don't see the point here.
Writing what would otherwise be vector graphics to a raster-based
image file, and then reading it back into a vector graphics system,
would create unnecessary problems.


On Sat, Jun 20, 2020 at 2:56 AM Rainer M Krug <Rainer at krugs.de> wrote:
>
>
> Hi
>
> I have a package, which plots from the plantuml syntax (https://plantuml.com) graphs via a knitr engine, into a file, or into a graphics device (https://github.com/rkrug/plantuml).
>
> I am using at the moment grImport for the eps import, but would like to cut down on dependencies.
>
> Is there a way of bringing graphics files (png, sag, eps, ?) into a graphics device in R?
>
> Thanks,
>
> Rainer
>
>
>
>
>
>
> --
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
>
> Orcid ID: 0000-0002-7490-0066
>
> Department of Evolutionary Biology and Environmental Studies
> University of Z?rich
> Office Y34-J-74
> Winterthurerstrasse 190
> 8075 Z?rich
> Switzerland
>
> Office: +41 (0)44 635 47 64
> Cell:           +41 (0)78 630 66 57
> email:      Rainer.Krug at uzh.ch
>                 Rainer at krugs.de
> Skype:     RMkrug
>
> PGP: 0x0F52F982
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jr@| @end|ng |rom po@teo@no  Sat Jun 20 01:42:44 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Sat, 20 Jun 2020 01:42:44 +0200
Subject: [R] How to loop over two files ...
In-Reply-To: <CAF9-5jPXwoHr4cxDmRtP5Xt=6p5bZbgkRCZSMUsfdm3WsWvmDQ@mail.gmail.com>
References: <CAF9-5jPXwoHr4cxDmRtP5Xt=6p5bZbgkRCZSMUsfdm3WsWvmDQ@mail.gmail.com>
Message-ID: <20200619234244.GA165867@posteo.no>

On 2020-06-19 14:34 -0500, Ana Marija wrote:
> 
> I have two files (each has 300 lines)like this:

The example looks quite similar to the R example in 
https://rest.ensembl.org/documentation/info/ld_pairwise_get#ra 
...

The question becomes: how did you query the 
600 variant names in 1g.txt and 1n.txt?

  curl 'https://rest.ensembl.org/ld/human/pairwise/rs6792369/rs1042779?' -H 'Content-type:application/json'

shows the 26 population_names for the 
rs6792369/rs1042779 combination ... 

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200620/07eaf84e/attachment.sig>

From @eb@@t|en@|@h@|e @end|ng |rom gm@||@com  Sat Jun 20 01:45:40 2020
From: @eb@@t|en@|@h@|e @end|ng |rom gm@||@com (=?UTF-8?Q?S=C3=A9bastien_Lahaie?=)
Date: Fri, 19 Jun 2020 19:45:40 -0400
Subject: [R] Strange behavior when sampling rows of a data frame
In-Reply-To: <f29504f9-5dfb-8657-3820-de8aa80369c6@gmail.com>
References: <CAKQpU6Lr_ARRHdWpCJf1Bg5k3JDV3_Kw8CUBsYnSJLkeq03Nzw@mail.gmail.com>
 <f29504f9-5dfb-8657-3820-de8aa80369c6@gmail.com>
Message-ID: <CAKQpU6KKj6UV2Gv3n5GOg=FAxW=AS2H3dd-NUCx4xiZKPxRmmw@mail.gmail.com>

Thank you all for the responses, these are the insights I was hoping for.
There are many ways to get this right, and I happened to run into one that
has a glitch. I see from Luke's explanation how the strange output came
about. Glad to hear that this bug/behavior is already known.

On Fri, Jun 19, 2020 at 7:04 PM Daniel Nordlund <djnordlund at gmail.com>
wrote:

> On 6/19/2020 5:49 AM, S?bastien Lahaie wrote:
> > I ran into some strange behavior in R when trying to assign a treatment
> to
> > rows in a data frame. I'm wondering whether any R experts can explain
> > what's going on.
> >
> > First, let's assign a treatment to 3 out of 10 rows as follows.
> >
> > df <- data.frame(unit = 1:10)
> > df$treated <- FALSE
> > s <- sample(nrow(df), 3)
> > df[s,]$treated <- TRUE
> > df
> >     unit treated
> > 1     1   FALSE
> > 2     2    TRUE
> > 3     3   FALSE
> > 4     4   FALSE
> > 5     5    TRUE
> > 6     6   FALSE
> > 7     7    TRUE
> > 8     8   FALSE
> > 9     9   FALSE
> > 10   10   FALSE
> >
> > This is as expected. Now we'll just skip the intermediate step of saving
> > the sampled indices, and apply the treatment directly as follows.
> >
> > df <- data.frame(unit = 1:10)
> > df$treated <- FALSE
> > df[sample(nrow(df), 3),]$treated <- TRUE
> > df
> >     unit treated
> > 1     6    TRUE
> > 2     2   FALSE
> > 3     3   FALSE
> > 4     9    TRUE
> > 5     5   FALSE
> > 6     6   FALSE
> > 7     7   FALSE
> > 8     5    TRUE
> > 9     9   FALSE
> > 10   10   FALSE
> >
> > Now the data frame still has 10 rows with 3 assigned to the treatment.
> But
> > the units are garbled. Units 1 and 4 have disappeared, for instance, and
> > there are duplicates for 6 and 9, one assigned to treatment and the other
> > to control. Why would this happen?
> >
> > Thanks,
> > Sebastien
> >
> S?bastien,
>
> You have received good explanations of what is going on with your code.
> I think you can get what you want by making a simple modification of
> your treatment assignment statement. At least it works for me.
>
> df[sample(nrow(df),3), 'treated'] <- TRUE
>
> Hope this is helpful,
>
> Dan
>
> --
> Daniel Nordlund
> Port Townsend, WA  USA
>
>

	[[alternative HTML version deleted]]


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Jun 20 02:34:32 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 19 Jun 2020 19:34:32 -0500
Subject: [R] How to loop over two files ...
In-Reply-To: <20200619234244.GA165867@posteo.no>
References: <CAF9-5jPXwoHr4cxDmRtP5Xt=6p5bZbgkRCZSMUsfdm3WsWvmDQ@mail.gmail.com>
 <20200619234244.GA165867@posteo.no>
Message-ID: <CAF9-5jPRorUvniKQTALGANG-ccrhZpGf5mKvmXYCr9qyL+drkw@mail.gmail.com>

Hi Rasmus,

I got those SNPs from two GWAS-es which I run with different
phenotypes and I would like to compare weather the top SNPs in both of
them are in LD.
So 1n.txt and 1g.txt are just top SNPs from those two GWAS-es.
Unfortunately https://ldlink.nci.nih.gov/?tab=ldpair works for only
two SNPs at the time and I need to do that for 300 pairs

On Fri, Jun 19, 2020 at 6:42 PM Rasmus Liland <jral at posteo.no> wrote:
>
> On 2020-06-19 14:34 -0500, Ana Marija wrote:
> >
> > I have two files (each has 300 lines)like this:
>
> The example looks quite similar to the R example in
> https://rest.ensembl.org/documentation/info/ld_pairwise_get#ra
> ...
>
> The question becomes: how did you query the
> 600 variant names in 1g.txt and 1n.txt?
>
>   curl 'https://rest.ensembl.org/ld/human/pairwise/rs6792369/rs1042779?' -H 'Content-type:application/json'
>
> shows the 26 population_names for the
> rs6792369/rs1042779 combination ...


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Sat Jun 20 02:36:41 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Fri, 19 Jun 2020 19:36:41 -0500
Subject: [R] How to loop over two files ...
In-Reply-To: <74a49794ea4387f177f83f5d8be7b28f@chemo.org.uk>
References: <CAF9-5jPXwoHr4cxDmRtP5Xt=6p5bZbgkRCZSMUsfdm3WsWvmDQ@mail.gmail.com>
 <0f251037d302d02e0da085399ab4b627@chemo.org.uk>
 <CAF9-5jNHw5M1BZUMq26zroUD3QnA84e0=D7Wb1g1DMECQ5wChA@mail.gmail.com>
 <687ca3db19cde8b8f340a54632e75ea6@chemo.org.uk>
 <CAF9-5jN=MSaKWziUXW-F1acq_d5nnr0UvLNr=A=xJJWhVw39EA@mail.gmail.com>
 <74a49794ea4387f177f83f5d8be7b28f@chemo.org.uk>
Message-ID: <CAF9-5jPpFTucD5X=S5yaZbjHRVtz4VkNvmTusHTghh5+d+igNQ@mail.gmail.com>

unfortunately it complains again:

> f1 <- read_tsv("1g", col_names=F)
Parsed with column specification:
cols(
  X1 = col_character()
)
> f2 <- read_tsv("1n", col_names=F)
Parsed with column specification:
cols(
  X1 = col_character()
)
> for ( a in rownames(f1) ) {
+
+    for ( b in rownames(f2) ) {
+
+ ext <- paste0( "/ld/human/pairwise/",
+                   f1[a,1],
+                   "/",
+                   f2[b,1],
+                   "?population_name=1000GENOMES:phase_3:KHV")
+
+                 r <- GET(paste(server, ext, sep = ""),
+ content_type("application/json"))
+
+                 write(r,file="list.txt",append=TRUE)
+
+
+    }
+
+ }
Error in cat(x, file = file, sep = c(rep.int(sep, ncolumns - 1), "\n"),  :
  argument 1 (type 'list') cannot be handled by 'cat'

> traceback()
2: cat(x, file = file, sep = c(rep.int(sep, ncolumns - 1), "\n"),
       append = append)
1: write(r, file = "list.txt", append = TRUE)

On Fri, Jun 19, 2020 at 5:19 PM <cpolwart at chemo.org.uk> wrote:
>
> Sorry - its been a long week!
>
> there is a foreach package but I try to avoid extras
>
> make your for statements:
>
> for ( a in rownames(f1) ) {
>
> # a will now be a row number rather than the value, so replace ' a ' in
> the paste0 with: f1[ a, 1]
>
> so
>
> ext <- paste0( "/ld/human/pairwise/",
>                   f1[a,1],
>                   "/",
>                   f2[b,1],
>                   "?population_name=1000GENOMES:phase_3:KHV")
>
> On 2020-06-19 22:54, Ana Marija wrote:
> > I tried it:
> >
> >  > library(httr)
> >> library(jsonlite)
> >> library(xml2)
> >> library(readr)
> >> server <- "http://rest.ensembl.org"
> >> f1 <- read_tsv("1g", col_names=F)
> > Parsed with column specification:
> > cols(
> >   X1 = col_character()
> > )
> >> f2 <- read_tsv("1n", col_names=F)
> > Parsed with column specification:
> > cols(
> >   X1 = col_character()
> > )
> >>
> >> for ( a in as.list(f1[,1]) ) {
> > +
> > +    for ( b in as.list(f2[,1]) ) {
> > +
> > + ext <- paste0( "/ld/human/pairwise/",
> > +                 a,
> > +                 "/",
> > +                 b,
> > +                 "?population_name=1000GENOMES:phase_3:KHV")
> > +
> > +                 r <- GET(paste(server, ext, sep = ""),
> > + content_type("application/json"))
> > +
> > +                 write(r,file="list.txt",append=TRUE)
> > +
> > +
> > +    }
> > +
> > + }
> > Error in parse_url(url) : length(url) == 1 is not TRUE
> >
> >> traceback()
> > 10: stop(simpleError(msg, call = if (p <- sys.parent(1L)) sys.call(p)))
> > 9: stopifnot(length(url) == 1)
> > 8: parse_url(url)
> > 7: is.url(url)
> > 6: stopifnot(is.url(url))
> > 5: build_url(parse_url(url)[c("scheme", "hostname", "port")])
> > 4: handle_name(url)
> > 3: handle_find(url)
> > 2: handle_url(handle, url, ...)
> > 1: GET(paste(server, ext, sep = ""), content_type("application/json"))
> >
> > On Fri, Jun 19, 2020 at 4:41 PM <cpolwart at chemo.org.uk> wrote:
> >>
> >> Oh - read.text isn't in base!  Not sure where is came from (my head
> >> mostly!)  You may have something that adds it but better to use
> >> something that works.  So try using:
> >>
> >> library(readr)
> >> f1 <- read_tsv("1g.txt", col.names=F)
> >>
> >> This will give you a tibble with f1$X1 with the file in it
> >>
> >> then loop it with (a in as.list(f1[,1])
> >>
> >> Others will have much slicker code than me!
> >>
> >> On 2020-06-19 22:02, Ana Marija wrote:
> >> > Hi,
> >> >
> >> > thanks for getting back to me, it is just for my job :)
> >> >
> >> > so I tried it:
> >> >
> >> > library(httr)
> >> > library(jsonlite)
> >> > library(xml2)
> >> > library(SparkR, lib.loc = c(file.path(Sys.getenv("SPARK_HOME"), "R",
> >> > "lib")))
> >> > sparkR.session(master = "local[*]", sparkConfig =
> >> > list(spark.driver.memory = "2g"))
> >> >
> >> > server <- "http://rest.ensembl.org"
> >> >
> >> > f1 <- read.text("1g.txt")
> >> > f2 <- read.text("1n.txt")
> >> >
> >> > for ( a in as.list(f1) ) {
> >> >
> >> >    for ( b in as.list(f2) ) {
> >> >
> >> > ext <- paste0( "/ld/human/pairwise/",
> >> >                 a,
> >> >                 "/",
> >> >                 b,
> >> >                 "?population_name=1000GENOMES:phase_3:KHV")
> >> >
> >> >                 r <- GET(paste(server, ext, sep = ""),
> >> > content_type("application/json"))
> >> >
> >> >                 write(r,file="list.txt",append=TRUE)
> >> >
> >> >
> >> >    }
> >> >
> >> > }
> >> >
> >> > and I got this error:
> >> > Error in as.list.default(f1) :
> >> >   no method for coercing this S4 class to a vector
> >> >
> >> > Please advise
> >> >
> >> > On Fri, Jun 19, 2020 at 3:28 PM <cpolwart at chemo.org.uk> wrote:
> >> >>
> >> >> so (untested) if you did something like
> >> >>
> >> >> f1 <- read.text("1g.txt")
> >> >> f2 <- read.text("1n.txt")
> >> >>
> >> >> for ( a in as.list(f1) ) {
> >> >>
> >> >>    for ( b in as.list(f2) ) {
> >> >>
> >> >> ext <- paste0( "/ld/human/pairwise/",
> >> >>                 a,
> >> >>                 "/",
> >> >>                 b,
> >> >>                 "?population_name=1000GENOMES:phase_3:KHV")
> >> >>
> >> >>                 r <- GET(paste(server, ext, sep = ""),
> >> >> content_type("application/json"))
> >> >>
> >> >>                 # You presumably need to do something with 'r' at the
> >> >> moment its over written by the next loop..  were
> >> >>                 # you appending it to list.txt?  Possibly its just a
> >> >> bit
> >> >> of the R output you want.?
> >> >>
> >> >>                 write(r,file="list.txt",append=TRUE)
> >> >>
> >> >>
> >> >>    }
> >> >>
> >> >> }
> >> >>
> >> >>
> >> >> Are we doing your PhD for you ;-)  Do we get to share ;-)
> >> >>
> >> >>
> >> >> On 2020-06-19 20:34, Ana Marija wrote:
> >> >> > Hello,
> >> >> >
> >> >> > I have two files (each has 300 lines)like this:
> >> >> >
> >> >> > head 1g.txt
> >> >> > rs6792369
> >> >> > rs1414517
> >> >> > rs16857712
> >> >> > rs16857703
> >> >> > rs12239392
> >> >> > ...
> >> >> >
> >> >> > head 1n.txt
> >> >> > rs1042779
> >> >> > rs2360630
> >> >> > rs10753597
> >> >> > rs7549096
> >> >> > rs2343491
> >> >> > ...
> >> >> >
> >> >> > For each pair of rs# from those two files I can run this command in R
> >> >> >
> >> >> > library(httr)
> >> >> > library(jsonlite)
> >> >> > library(xml2)
> >> >> >
> >> >> > server <- "http://rest.ensembl.org"
> >> >> > ext <-
> >> >> > "/ld/human/pairwise/rs6792369/rs1042779?population_name=1000GENOMES:phase_3:KHV"
> >> >> >
> >> >> > r <- GET(paste(server, ext, sep = ""),
> >> >> > content_type("application/json"))
> >> >> >
> >> >> > stop_for_status(r)
> >> >> > head(fromJSON(toJSON(content(r))))
> >> >> >    d_prime       r2 variation1 variation2         population_name
> >> >> > 1 0.975513 0.951626  rs6792369  rs1042779 1000GENOMES:phase_3:KHV
> >> >> >
> >> >> > What I would like to do is to do is to run this command for every SNP
> >> >> > in one list (1g.txt) to each SNP in another list (1n.txt). Where SNP#
> >> >> > is rs# and output every line of result in list.txt
> >> >> >
> >> >> > The process is illustrated in the attachment.
> >> >> >
> >> >> > Please help,
> >> >> > Ana
> >> >> >
> >> >> > ______________________________________________
> >> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> > PLEASE do read the posting guide
> >> >> > http://www.R-project.org/posting-guide.html
> >> >> > and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Sat Jun 20 03:33:36 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 19 Jun 2020 18:33:36 -0700
Subject: [R] How to loop over two files ...
In-Reply-To: <CAF9-5jPRorUvniKQTALGANG-ccrhZpGf5mKvmXYCr9qyL+drkw@mail.gmail.com>
References: <CAF9-5jPXwoHr4cxDmRtP5Xt=6p5bZbgkRCZSMUsfdm3WsWvmDQ@mail.gmail.com>
 <20200619234244.GA165867@posteo.no>
 <CAF9-5jPRorUvniKQTALGANG-ccrhZpGf5mKvmXYCr9qyL+drkw@mail.gmail.com>
Message-ID: <CAGxFJbR4ZRMy=nMK=dEn5eVC72_yJrmsay1HnmpUfWrXcgiEoA@mail.gmail.com>

All of your torrent of requests for help to have others do your work for
you are about genomics issues. Why aren't you posting on the Bioconductor
Help forum instead, where both the expertise and tools for such matters
exist?  I would characterize your posts here as being largely inappropriate
for that reason.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 19, 2020 at 5:35 PM Ana Marija <sokovic.anamarija at gmail.com>
wrote:

> Hi Rasmus,
>
> I got those SNPs from two GWAS-es which I run with different
> phenotypes and I would like to compare weather the top SNPs in both of
> them are in LD.
> So 1n.txt and 1g.txt are just top SNPs from those two GWAS-es.
> Unfortunately https://ldlink.nci.nih.gov/?tab=ldpair works for only
> two SNPs at the time and I need to do that for 300 pairs
>
> On Fri, Jun 19, 2020 at 6:42 PM Rasmus Liland <jral at posteo.no> wrote:
> >
> > On 2020-06-19 14:34 -0500, Ana Marija wrote:
> > >
> > > I have two files (each has 300 lines)like this:
> >
> > The example looks quite similar to the R example in
> > https://rest.ensembl.org/documentation/info/ld_pairwise_get#ra
> > ...
> >
> > The question becomes: how did you query the
> > 600 variant names in 1g.txt and 1n.txt?
> >
> >   curl 'https://rest.ensembl.org/ld/human/pairwise/rs6792369/rs1042779?'
> -H 'Content-type:application/json'
> >
> > shows the 26 population_names for the
> > rs6792369/rs1042779 combination ...
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Jun 20 04:07:32 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 20 Jun 2020 14:07:32 +1200
Subject: [R] Adjusting axis limits in ggplot2.
Message-ID: <b70b4dba-eb03-9218-43bd-ccf500408161@auckland.ac.nz>


I'm having trouble adjusting axis limits in ggplot2 when the variable
corresponding to that axis is a factor.  I have attached a minimal
reproducible example in the file demo.txt.

The result (see it by sourcing demo.txt and printing ldCiPlot) is fine
except that I would like the y-axis limits to be 0 and 7 rather than
0.5 and 6.5.

I tried adding xlim(0,7) ("x" because I do a coord_flip()) but this 
causes the error

> Error: Discrete value supplied to continuous scale

to be thrown.  I have Googled around quite a bit and have not managed to 
find anything useful that I can understand.  I'm sure there is a simple
solution, but I can't find it.  Can anyone point me in the right 
direction?  Ta.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: demo.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200620/63ff71c5/attachment.txt>

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Jun 20 05:57:55 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 19 Jun 2020 20:57:55 -0700
Subject: [R] Adjusting axis limits in ggplot2.
In-Reply-To: <b70b4dba-eb03-9218-43bd-ccf500408161@auckland.ac.nz>
References: <b70b4dba-eb03-9218-43bd-ccf500408161@auckland.ac.nz>
Message-ID: <72AF8955-BFD5-4046-95C0-4482F27FD299@dcn.davis.ca.us>

?scale_x_discrete, in particular the expand argument.

On June 19, 2020 7:07:32 PM PDT, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>I'm having trouble adjusting axis limits in ggplot2 when the variable
>corresponding to that axis is a factor.  I have attached a minimal
>reproducible example in the file demo.txt.
>
>The result (see it by sourcing demo.txt and printing ldCiPlot) is fine
>except that I would like the y-axis limits to be 0 and 7 rather than
>0.5 and 6.5.
>
>I tried adding xlim(0,7) ("x" because I do a coord_flip()) but this 
>causes the error
>
>> Error: Discrete value supplied to continuous scale
>
>to be thrown.  I have Googled around quite a bit and have not managed
>to 
>find anything useful that I can understand.  I'm sure there is a simple
>solution, but I can't find it.  Can anyone point me in the right 
>direction?  Ta.
>
>cheers,
>
>Rolf Turner

-- 
Sent from my phone. Please excuse my brevity.


From jr@| @end|ng |rom po@teo@no  Sat Jun 20 08:17:38 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Sat, 20 Jun 2020 08:17:38 +0200
Subject: [R] How to loop over two files ...
In-Reply-To: <CAGxFJbR4ZRMy=nMK=dEn5eVC72_yJrmsay1HnmpUfWrXcgiEoA@mail.gmail.com>
References: <CAF9-5jPXwoHr4cxDmRtP5Xt=6p5bZbgkRCZSMUsfdm3WsWvmDQ@mail.gmail.com>
 <20200619234244.GA165867@posteo.no>
 <CAF9-5jPRorUvniKQTALGANG-ccrhZpGf5mKvmXYCr9qyL+drkw@mail.gmail.com>
 <CAGxFJbR4ZRMy=nMK=dEn5eVC72_yJrmsay1HnmpUfWrXcgiEoA@mail.gmail.com>
Message-ID: <20200620061738.GA1026791@posteo.no>

Dear Bert,

On 2020-06-19 18:33 -0700, Bert Gunter wrote:
> All of your torrent of requests for help to 
> have others do your work for you are about 
> genomics issues.

I am a bioinformatician, I am supposed should 
know all of these things, GWAS, Le ggplot, 
etc. ... 

> Why aren't you posting on the Bioconductor 
> Help forum instead, where both the 
> expertise and tools for such matters exist?  
> I would characterize your posts here as 
> being largely inappropriate for that 
> reason.

Perhaps r-sig-genetics@ or r-sig-phylo@?  It 
needs some more volume ... 

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200620/524fc186/attachment.sig>

From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Jun 20 09:11:01 2020
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 20 Jun 2020 19:11:01 +1200
Subject: [R] Adjusting axis limits in ggplot2.
In-Reply-To: <72AF8955-BFD5-4046-95C0-4482F27FD299@dcn.davis.ca.us>
References: <b70b4dba-eb03-9218-43bd-ccf500408161@auckland.ac.nz>
 <72AF8955-BFD5-4046-95C0-4482F27FD299@dcn.davis.ca.us>
Message-ID: <0a5b5f52-b92e-1e9f-3c3a-23e1cd1501fc@auckland.ac.nz>


On 20/06/20 3:57 pm, Jeff Newmiller wrote:

> ?scale_x_discrete, in particular the expand argument.

Thanks Jeff.  Took me a while to get my head around it (I'm slow!!!) but 
I eventually got it.

For the record, what I needed to do was set:

ldCiPlot <- ldCiPlot + scale_x_discrete(expand=expansion(add=1))

Thanks again.

cheers,

Rolf

> 
> On June 19, 2020 7:07:32 PM PDT, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>
>> I'm having trouble adjusting axis limits in ggplot2 when the variable
>> corresponding to that axis is a factor.  I have attached a minimal
>> reproducible example in the file demo.txt.
>>
>> The result (see it by sourcing demo.txt and printing ldCiPlot) is fine
>> except that I would like the y-axis limits to be 0 and 7 rather than
>> 0.5 and 6.5.
>>
>> I tried adding xlim(0,7) ("x" because I do a coord_flip()) but this
>> causes the error
>>
>>> Error: Discrete value supplied to continuous scale
>>
>> to be thrown.  I have Googled around quite a bit and have not managed
>> to
>> find anything useful that I can understand.  I'm sure there is a simple
>> solution, but I can't find it.  Can anyone point me in the right
>> direction?  Ta.
>>
>> cheers,
>>
>> Rolf Turner


From kry|ov@r00t @end|ng |rom gm@||@com  Sat Jun 20 10:47:53 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Sat, 20 Jun 2020 11:47:53 +0300
Subject: [R] How to loop over two files ...
In-Reply-To: <CAF9-5jPpFTucD5X=S5yaZbjHRVtz4VkNvmTusHTghh5+d+igNQ@mail.gmail.com>
References: <CAF9-5jPXwoHr4cxDmRtP5Xt=6p5bZbgkRCZSMUsfdm3WsWvmDQ@mail.gmail.com>
 <0f251037d302d02e0da085399ab4b627@chemo.org.uk>
 <CAF9-5jNHw5M1BZUMq26zroUD3QnA84e0=D7Wb1g1DMECQ5wChA@mail.gmail.com>
 <687ca3db19cde8b8f340a54632e75ea6@chemo.org.uk>
 <CAF9-5jN=MSaKWziUXW-F1acq_d5nnr0UvLNr=A=xJJWhVw39EA@mail.gmail.com>
 <74a49794ea4387f177f83f5d8be7b28f@chemo.org.uk>
 <CAF9-5jPpFTucD5X=S5yaZbjHRVtz4VkNvmTusHTghh5+d+igNQ@mail.gmail.com>
Message-ID: <20200620114753.2bb6c9dc@Tarkus>

On Fri, 19 Jun 2020 19:36:41 -0500
Ana Marija <sokovic.anamarija at gmail.com> wrote:

> Error in cat(x, file = file, sep = c(rep.int(sep, ncolumns - 1),
> "\n"),  : argument 1 (type 'list') cannot be handled by 'cat'

It might be a good idea to try to solve problems like this yourself
instead of waiting for hours for someone to reply. All the required
information is there in the error message: write() fails because r is a
list. Why is r a list? It's returned from GET(), so let's read its
documentation.

httr::GET() returns a response object, not a string [1]. Try passing
as.character(r) or content(r,'text') instead of just r to write(...) or
use a different way of extracting the actual response from the response
object.

-- 
Best regards,
Ivan

[1] https://httr.r-lib.org/reference/GET.html


From btyner @end|ng |rom gm@||@com  Sat Jun 20 13:15:28 2020
From: btyner @end|ng |rom gm@||@com (Benjamin Tyner)
Date: Sat, 20 Jun 2020 07:15:28 -0400
Subject: [R] chaining closure arguments on-the-fly
Message-ID: <bc3185bc-bcfe-f57c-ef72-0c6bbdc8f594@gmail.com>

Greetings,

Occasionally, I desire to call a function with one argument set to equal 
to another. Here is a toy example:

 ?? f <- function(x, y) {

 ? ? ?? x + y
 ?? }

 ?? f(x = 3, y = x) # Error in f(x = 3, y = x) : object 'x' not found

So far, the most concise way I found to accomplish this is:

 ?? f(x = 3, y = local(sys.frame(1)$x)) # evaluates to 6

but I dislike this solution because local() creates a new environment. 
Surely there must be a better way?

Note: I'm not interested in solutions that require modifying or currying f.

Regards,
Ben


From m@rc_@chw@rtz @end|ng |rom me@com  Sat Jun 20 13:50:38 2020
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Sat, 20 Jun 2020 07:50:38 -0400
Subject: [R] chaining closure arguments on-the-fly
In-Reply-To: <bc3185bc-bcfe-f57c-ef72-0c6bbdc8f594@gmail.com>
References: <bc3185bc-bcfe-f57c-ef72-0c6bbdc8f594@gmail.com>
Message-ID: <B0EFEC6D-7DB9-404A-A7DC-6A17AD39EB87@me.com>

Hi Ben,

How about something like this:

f <- function(x, y = NULL) {

  if (is.null(y)) 
    y <- x

  x + y
}

> f(3, 4)
[1] 7

> f(3)
[1] 6

Regards,

Marc Schwartz


> On Jun 20, 2020, at 7:15 AM, Benjamin Tyner <btyner at gmail.com> wrote:
> 
> Greetings,
> 
> Occasionally, I desire to call a function with one argument set to equal to another. Here is a toy example:
> 
>    f <- function(x, y) {
> 
>        x + y
>    }
> 
>    f(x = 3, y = x) # Error in f(x = 3, y = x) : object 'x' not found
> 
> So far, the most concise way I found to accomplish this is:
> 
>    f(x = 3, y = local(sys.frame(1)$x)) # evaluates to 6
> 
> but I dislike this solution because local() creates a new environment. Surely there must be a better way?
> 
> Note: I'm not interested in solutions that require modifying or currying f.
> 
> Regards,
> Ben
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Jun 20 15:00:06 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 20 Jun 2020 09:00:06 -0400
Subject: [R] chaining closure arguments on-the-fly
In-Reply-To: <bc3185bc-bcfe-f57c-ef72-0c6bbdc8f594@gmail.com>
References: <bc3185bc-bcfe-f57c-ef72-0c6bbdc8f594@gmail.com>
Message-ID: <be50bd91-26b9-5ba8-9a47-9af88df58f92@gmail.com>

On 20/06/2020 7:15 a.m., Benjamin Tyner wrote:
> Greetings,
> 
> Occasionally, I desire to call a function with one argument set to equal
> to another. Here is a toy example:
> 
>   ?? f <- function(x, y) {
> 
>   ? ? ?? x + y
>   ?? }
> 
>   ?? f(x = 3, y = x) # Error in f(x = 3, y = x) : object 'x' not found
> 
> So far, the most concise way I found to accomplish this is:
> 
>   ?? f(x = 3, y = local(sys.frame(1)$x)) # evaluates to 6
> 
> but I dislike this solution because local() creates a new environment.
> Surely there must be a better way?
> 
> Note: I'm not interested in solutions that require modifying or currying f.

How about

g <- function(x, y = x) {
   f(x, y)
}
g(x = 3)

or even

yEqualsX <- function(f) function(x, y = x) f(x, y)

yEqualsX(f)(x = 3)

These are a lot like currying, but aren't currying, so they may be 
acceptable to you.  Personally I'd choose the first one.

Duncan Murdoch


From bgunter@4567 @end|ng |rom gm@||@com  Sat Jun 20 16:29:51 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 20 Jun 2020 07:29:51 -0700
Subject: [R] How to loop over two files ...
In-Reply-To: <20200620061738.GA1026791@posteo.no>
References: <CAF9-5jPXwoHr4cxDmRtP5Xt=6p5bZbgkRCZSMUsfdm3WsWvmDQ@mail.gmail.com>
 <20200619234244.GA165867@posteo.no>
 <CAF9-5jPRorUvniKQTALGANG-ccrhZpGf5mKvmXYCr9qyL+drkw@mail.gmail.com>
 <CAGxFJbR4ZRMy=nMK=dEn5eVC72_yJrmsay1HnmpUfWrXcgiEoA@mail.gmail.com>
 <20200620061738.GA1026791@posteo.no>
Message-ID: <CAGxFJbRqzivY+rFd3Tbq-5JYZ+w2UYopUnz1i77gJdsmPVBwWA@mail.gmail.com>

genetics is not genomics. Nor are phylogenies. I still believe Bioc is the
right resource.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Jun 19, 2020 at 11:17 PM Rasmus Liland <jral at posteo.no> wrote:

> Dear Bert,
>
> On 2020-06-19 18:33 -0700, Bert Gunter wrote:
> > All of your torrent of requests for help to
> > have others do your work for you are about
> > genomics issues.
>
> I am a bioinformatician, I am supposed should
> know all of these things, GWAS, Le ggplot,
> etc. ...
>
> > Why aren't you posting on the Bioconductor
> > Help forum instead, where both the
> > expertise and tools for such matters exist?
> > I would characterize your posts here as
> > being largely inappropriate for that
> > reason.
>
> Perhaps r-sig-genetics@ or r-sig-phylo@?  It
> needs some more volume ...
>
> Best,
> Rasmus
>

	[[alternative HTML version deleted]]


From btyner @end|ng |rom gm@||@com  Sat Jun 20 22:44:38 2020
From: btyner @end|ng |rom gm@||@com (Benjamin Tyner)
Date: Sat, 20 Jun 2020 16:44:38 -0400
Subject: [R] chaining closure arguments on-the-fly
In-Reply-To: <be50bd91-26b9-5ba8-9a47-9af88df58f92@gmail.com>
References: <bc3185bc-bcfe-f57c-ef72-0c6bbdc8f594@gmail.com>
 <be50bd91-26b9-5ba8-9a47-9af88df58f92@gmail.com>
Message-ID: <5d0945d8-a389-a661-4b87-ca538e865f72@gmail.com>

On 6/20/20 9:00 AM, Duncan Murdoch wrote:
> How about
>
> g <- function(x, y = x) {
> ? f(x, y)
> }
> g(x = 3)
>
> or even
>
> yEqualsX <- function(f) function(x, y = x) f(x, y)
>
> yEqualsX(f)(x = 3)
>
> These are a lot like currying, but aren't currying, so they may be 
> acceptable to you.? Personally I'd choose the first one.
>
> Duncan Murdoch
>
Thank you Duncan; I should have been more explicit that I was also 
trying to avoid defining any new functions, but yes, it's hard to argue 
with the wrapper approach as a longstanding best practice.

Basically I'm wondering if it would be theoretically possible to 
construct a function "g" (possibly it would have to be 
primitive/internal) such that

    f(x = 3, y = g(expr))

would evaluate expr in the evaluation environment of f? After rereading 
section 4.3.3 of the R Language Definition, it's clear that supplied 
arguments are evaluated in the calling environment; though trickery in 
f()'s body may be used to evaluate elsewhere, such options seem limited 
from within the argument list itself.

Ben


From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Jun 20 23:04:05 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sat, 20 Jun 2020 17:04:05 -0400
Subject: [R] chaining closure arguments on-the-fly
In-Reply-To: <5d0945d8-a389-a661-4b87-ca538e865f72@gmail.com>
References: <bc3185bc-bcfe-f57c-ef72-0c6bbdc8f594@gmail.com>
 <be50bd91-26b9-5ba8-9a47-9af88df58f92@gmail.com>
 <5d0945d8-a389-a661-4b87-ca538e865f72@gmail.com>
Message-ID: <3d8bf377-e99e-b145-ec13-6b294d69b718@gmail.com>

On 20/06/2020 4:44 p.m., Benjamin Tyner wrote:
> On 6/20/20 9:00 AM, Duncan Murdoch wrote:
>> How about
>>
>> g <- function(x, y = x) {
>>  ? f(x, y)
>> }
>> g(x = 3)
>>
>> or even
>>
>> yEqualsX <- function(f) function(x, y = x) f(x, y)
>>
>> yEqualsX(f)(x = 3)
>>
>> These are a lot like currying, but aren't currying, so they may be
>> acceptable to you.? Personally I'd choose the first one.
>>
>> Duncan Murdoch
>>
> Thank you Duncan; I should have been more explicit that I was also
> trying to avoid defining any new functions, but yes, it's hard to argue
> with the wrapper approach as a longstanding best practice.
> 
> Basically I'm wondering if it would be theoretically possible to
> construct a function "g" (possibly it would have to be
> primitive/internal) such that
> 
>      f(x = 3, y = g(expr))
> 
> would evaluate expr in the evaluation environment of f? After rereading
> section 4.3.3 of the R Language Definition, it's clear that supplied
> arguments are evaluated in the calling environment; though trickery in
> f()'s body may be used to evaluate elsewhere, such options seem limited
> from within the argument list itself.

I think you effectively did that in your original post (all but 
encapsulating the expression in a function), so yes, it's possible. 
However, it's a really bad idea.  Why use non-standard evaluation when 
standard evaluation is fine?  Standard evaluation follows some well 
defined rules, and is easy to reason about.  NSE follows whatever rules 
it wants, so it's really hard for users to follow.  For example, 
assuming you had the g() you want, what would this give?

z <- 3
f(x = z, y = g(z))

You can't possibly know that without knowing whether there's a local 
variable in f named z that is created before y is evaluated.

Duncan Murdoch


From @kh||e@h@|ngh@|gkv @end|ng |rom gm@||@com  Fri Jun 19 17:13:00 2020
From: @kh||e@h@|ngh@|gkv @end|ng |rom gm@||@com (Akhilesh Singh)
Date: Fri, 19 Jun 2020 20:43:00 +0530
Subject: [R] Error in "plot(aov.object)" after upgradation to R-4.0.0 and
 R-4.0.1 for given R-Script-Example
Message-ID: <CACLgfx1FLG5Ei9b96PcFRHKk0f7z60Uxw+2iG-xkOFkTuTsbOw@mail.gmail.com>

Dear learned experts of R,

I was writing a book through RStudio-Rmarkdown and had finally compiled it
successfully based on R package R-3.6.2. Afterwards, I updated my R-3.6.2
to R-4.0.0 and even later to R-4.0.1.

Then, the publishers demanded to recompile the book with font embedding, so
I tried to recompile the book, when I found the following error:

"Error in (dm - 1) %*% ff : non-conformable arguments"

For convenience and reproducibility of the error, I am giving below the
same code chunk as an R-Script-Example, wherein the error is occurring in
the plot() function with the input of an aov() object.

R-Script-Example producing error:
==========================

setwd("E:/AKS-DATA-New/Software/R and allied
packages/R-Markdown/knitr/MyBooks/STAT-512_STAT-564")
getwd()

#After Upgrading to R-4.0.0 and even in R-4.0.1 following error in "plot()"
function occurs:

Block=c(1,1,1,1,2,2,2,2,3,3,3,3)
Permanganate=c("without","without","with","with","without","without","with","with","without","without","with","with")
Sample.Size=c(0.25,1,0.25,1,0.25,1,0.25,1,0.25,1,0.25,1)
Riboflavin=c(39.5,38.6,27.2,24.6,43.1,39.5,23.2,24.2,45.2,33,24.8,22.2)

#Creating data frame
sned.2x2.woint=data.frame(Block, Sample.Size, Permanganate, Riboflavin)

#Declaring Block, Sample.Size, Permanganate as factors
sned.2x2.woint$Block = factor(sned.2x2.woint$Block)
sned.2x2.woint$Sample.Size = factor(sned.2x2.woint$Sample.Size)
sned.2x2.woint$Permangate=factor(sned.2x2.woint$Permanganate)

#ANOVA of RBD when Block, Sample.Size, Permanganate are a fixed effects
sned.2x2.woint.aov1=aov(Riboflavin ~ Block + Sample.Size + Permanganate +
Sample.Size:Permanganate,data=sned.2x2.woint)

cat("ANOVA of RBD when Block, Sample.Size and Permanganate are fixed
effects:\n")
summary(sned.2x2.woint.aov1)

#ANOVA of RBD when Block, Sample.Size, Permanganate are fixed effects
sned.2x2.woint.aov2=aov(Riboflavin ~ Block + Sample.Size + Permanganate,
data=sned.2x2.woint)

cat("ANOVA of RBD when Block, Sample.Size and Permanganate are fixed
effects:\n")

summary(sned.2x2.woint.aov2)

plot(sned.2x2.woint.aov2, which=1) #OK
plot(sned.2x2.woint.aov2, which=2) #Ok
plot(sned.2x2.woint.aov2, which=3) #OK
plot(sned.2x2.woint.aov2, which=4) #OK

plot(sned.2x2.woint.aov2, which=5) #Error in (dm - 1) %*% ff :
non-conformable arguments

plot(sned.2x2.woint.aov2, which=6) #OK
=================================

I request the esteemed and learned experts of R to kindly me out to
overcome this error.

With regards



-- 
Dr. A.K. Singh
Professor and Head (Agricultural Statistics)
Department of Agricultural Statistics and Social Science (L)
Indira Gandhi Krishi Vishwavidyalaya, Raipur-492 012,
Chhattisgarh, India
Mobile: +918770625795
Email: akhileshsingh.igkv at gmail.com

	[[alternative HTML version deleted]]


From tr@|ner914 @end|ng |rom y@hoo@com  Sat Jun 20 14:40:41 2020
From: tr@|ner914 @end|ng |rom y@hoo@com (shahram salehi zadeh)
Date: Sat, 20 Jun 2020 12:40:41 +0000 (UTC)
Subject: [R] Running SEM
References: <1520426813.899447.1592656841994.ref@mail.yahoo.com>
Message-ID: <1520426813.899447.1592656841994@mail.yahoo.com>

I have a problem running SEM using lavaan. I have 44 items on likert scale. I would like to develop a model containing two latent factors. This is the model I have constructed:
library(lavaan)
library(sem)
library(haven)
getwd()
View(Dissertation)
kashk <- c(Dissertation$Q1, Dissertation$Q2, Dissertation$Q3, Dissertation$Q4, Dissertation$Q5,
?????????????? Dissertation$Q6, Dissertation$Q7, Dissertation$Q8, Dissertation$Q9, Dissertation$Q10, Dissertation$Q11,
?????????????? Dissertation$Q12, Dissertation$Q13, Dissertation$Q14, Dissertation$Q15, Dissertation$Q16, Dissertation$Q17, 
?????????????? Dissertation$Q18,
?????????????? Dissertation$Q19, Dissertation$Q20, Dissertation$Q21, 
?????????????? Dissertation$Q22, Dissertation$Q23, Dissertation$Q24, Dissertation$Q25, Dissertation$Q26,
?????????????? Dissertation$Q27, Dissertation$Q28, Dissertation$Q29, Dissertation$Q30, Dissertation$Q31,
?????????????? Dissertation$Q32, Dissertation$Q33, Dissertation$Q34, Dissertation$Q35, Dissertation$Q36,
?????????????? Dissertation$Q37, Dissertation$Q38, Dissertation$Q39, Dissertation$Q40, 
?????????????? Dissertation$Q41, Dissertation$Q42, Dissertation$Q43,Dissertation$Q44)cfa.model<- "F1=~? NA*Dissertation$Q39 + Dissertation$Q23 + Dissertation$Q38 + Dissertation$Q35 + 
Dissertation$Q31 +Dissertation$ Q21 +Dissertation$Q32 +
Dissertation$Q24 +Dissertation$Q4+ Dissertation$Q40 +Dissertation$Q14 +Dissertation$Q12 +Dissertation$Q17 +
Dissertation$Q7 +Dissertation$Q5 +Dissertation$Q30 +Dissertation$Q27 +Dissertation$Q8+ Dissertation$Q33
F2 =~ NA* Dissertation$Q36 +Dissertation$Q41 +Dissertation$Q16 +Dissertation$Q28+ Dissertation$Q19 +
Dissertation$Q25 +Dissertation$Q6+ Dissertation$Q44 +Dissertation$Q10+ Dissertation$Q29 +Dissertation$Q3
F1 ~~ F2
F1 ~~ 1*F1 #fix factor variance to 1
F2 ~~ 1*F2 #fix factor variance to 1"
cfa.fit <- sem(cfa.model, data =Dissertation)
summary(cfa.fit, fit.measures = TRUE)
However, it does not work. This is the following error:?
| Error in if ((!is.matrix(model)) | ncol(model) != 3) stop("model argument must be a 3-column matrix") : 
  argument is of length zero
 |
|  |
| 
| This is the final error:
| Error in summary(cfa.fit, fit.measures = TRUE) : 
  object 'cfa.fit' not found
 |
|  |
| 
| Please help me out of the problem. I hereby appreciate your kind help. |

 |


 |

 |




	[[alternative HTML version deleted]]


From jr@| @end|ng |rom po@teo@no  Sat Jun 20 23:39:04 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Sat, 20 Jun 2020 23:39:04 +0200
Subject: [R] How to loop over two files ...
In-Reply-To: <CAGxFJbRqzivY+rFd3Tbq-5JYZ+w2UYopUnz1i77gJdsmPVBwWA@mail.gmail.com>
References: <CAF9-5jPXwoHr4cxDmRtP5Xt=6p5bZbgkRCZSMUsfdm3WsWvmDQ@mail.gmail.com>
 <20200619234244.GA165867@posteo.no>
 <CAF9-5jPRorUvniKQTALGANG-ccrhZpGf5mKvmXYCr9qyL+drkw@mail.gmail.com>
 <CAGxFJbR4ZRMy=nMK=dEn5eVC72_yJrmsay1HnmpUfWrXcgiEoA@mail.gmail.com>
 <20200620061738.GA1026791@posteo.no>
 <CAGxFJbRqzivY+rFd3Tbq-5JYZ+w2UYopUnz1i77gJdsmPVBwWA@mail.gmail.com>
Message-ID: <20200620213904.GA169464@posteo.no>

On 2020-06-20 07:29 -0700, Bert Gunter wrote:
> On Fri, Jun 19, 2020 at 11:17 PM Rasmus Liland wrote:
> > On 2020-06-19 18:33 -0700, Bert Gunter wrote:
> > > Why aren't you posting on the 
> > > Bioconductor Help forum instead
> >
> > Perhaps r-sig-genetics@ or r-sig-phylo@?  
> 
> genetics is not genomics. Nor are 
> phylogenies. I still believe Bioc is the 
> right resource.

Right, I had a hunch all these fields 
were kind of related somehow ?\_(?)_/?

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200620/2ba18ecc/attachment.sig>

From bgunter@4567 @end|ng |rom gm@||@com  Sat Jun 20 23:49:06 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 20 Jun 2020 14:49:06 -0700
Subject: [R] chaining closure arguments on-the-fly
In-Reply-To: <3d8bf377-e99e-b145-ec13-6b294d69b718@gmail.com>
References: <bc3185bc-bcfe-f57c-ef72-0c6bbdc8f594@gmail.com>
 <be50bd91-26b9-5ba8-9a47-9af88df58f92@gmail.com>
 <5d0945d8-a389-a661-4b87-ca538e865f72@gmail.com>
 <3d8bf377-e99e-b145-ec13-6b294d69b718@gmail.com>
Message-ID: <CAGxFJbQHCGYrTKGkhQRLZcsdTO0ga6iYVJ9A5V9tV3ZXw=099Q@mail.gmail.com>

Gents:
(with trepidation)

f(x = 3, y = g(expr))
**already** evaluates g in the environment of f, **not** in the environment
of the caller.
(This does not contradict Duncan's example -- 3 is a constant, not a
variable).

e.g.
> f <- function(x = 3, y = x^2 +k){
+     k <- 3
+     x + y
+ }

Ergo
> k <- 100; x <- 10
> f()
[1] 15
> f(0)
[1] 3
> x
[1] 10

This is all due to lazy evaluation where default arguments are evaluated in
the function's environment (using standard evaluation). Arguments supplied
in the call are evaluated in the caller's environment, so:

> f(x = x)
[1] 113

Am I missing something here?

Cheers,

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Jun 20, 2020 at 2:05 PM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 20/06/2020 4:44 p.m., Benjamin Tyner wrote:
> > On 6/20/20 9:00 AM, Duncan Murdoch wrote:
> >> How about
> >>
> >> g <- function(x, y = x) {
> >>    f(x, y)
> >> }
> >> g(x = 3)
> >>
> >> or even
> >>
> >> yEqualsX <- function(f) function(x, y = x) f(x, y)
> >>
> >> yEqualsX(f)(x = 3)
> >>
> >> These are a lot like currying, but aren't currying, so they may be
> >> acceptable to you.  Personally I'd choose the first one.
> >>
> >> Duncan Murdoch
> >>
> > Thank you Duncan; I should have been more explicit that I was also
> > trying to avoid defining any new functions, but yes, it's hard to argue
> > with the wrapper approach as a longstanding best practice.
> >
> > Basically I'm wondering if it would be theoretically possible to
> > construct a function "g" (possibly it would have to be
> > primitive/internal) such that
> >
> >      f(x = 3, y = g(expr))
> >
> > would evaluate expr in the evaluation environment of f? After rereading
> > section 4.3.3 of the R Language Definition, it's clear that supplied
> > arguments are evaluated in the calling environment; though trickery in
> > f()'s body may be used to evaluate elsewhere, such options seem limited
> > from within the argument list itself.
>
> I think you effectively did that in your original post (all but
> encapsulating the expression in a function), so yes, it's possible.
> However, it's a really bad idea.  Why use non-standard evaluation when
> standard evaluation is fine?  Standard evaluation follows some well
> defined rules, and is easy to reason about.  NSE follows whatever rules
> it wants, so it's really hard for users to follow.  For example,
> assuming you had the g() you want, what would this give?
>
> z <- 3
> f(x = z, y = g(z))
>
> You can't possibly know that without knowing whether there's a local
> variable in f named z that is created before y is evaluated.
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From btyner @end|ng |rom gm@||@com  Sun Jun 21 00:19:24 2020
From: btyner @end|ng |rom gm@||@com (Benjamin Tyner)
Date: Sat, 20 Jun 2020 18:19:24 -0400
Subject: [R] chaining closure arguments on-the-fly
In-Reply-To: <CAGxFJbQHCGYrTKGkhQRLZcsdTO0ga6iYVJ9A5V9tV3ZXw=099Q@mail.gmail.com>
References: <bc3185bc-bcfe-f57c-ef72-0c6bbdc8f594@gmail.com>
 <be50bd91-26b9-5ba8-9a47-9af88df58f92@gmail.com>
 <5d0945d8-a389-a661-4b87-ca538e865f72@gmail.com>
 <3d8bf377-e99e-b145-ec13-6b294d69b718@gmail.com>
 <CAGxFJbQHCGYrTKGkhQRLZcsdTO0ga6iYVJ9A5V9tV3ZXw=099Q@mail.gmail.com>
Message-ID: <d9886832-c9d2-a6c3-dd0c-d0768c8cae6d@gmail.com>


On 6/20/20 5:49 PM, Bert Gunter wrote:
> Gents:
> (with trepidation)
>
> f(x = 3, y = g(expr))
> **already** evaluates g in the environment of f, **not** in the 
> environment of the caller.
> (This does not contradict Duncan's example -- 3 is a constant, not a 
> variable).
>
> e.g.
> > f <- function(x = 3, y = x^2 +k){
> + ? ? k <- 3
> + ? ? x + y
> + }
>
> Ergo
> > k <- 100; x <- 10
> > f()
> [1] 15
> > f(0)
> [1] 3
> > x
> [1] 10
>
> This is all due to lazy evaluation where default arguments are 
> evaluated in the function's environment (using standard evaluation). 
> Arguments supplied in the call are evaluated in the caller's 
> environment, so:
>
> > f(x = x)
> [1] 113
>
> Am I missing something here?
>
> Cheers,
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along 
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
Default arguments are indeed evaluated in f's environment, but not 
supplied arguments. I haven't really thought about the semantics of 'g' 
with respect to default arguments. But certainly, lazy evaluation is key 
here.

Ben (with trepidation as well)


From bgunter@4567 @end|ng |rom gm@||@com  Sun Jun 21 00:31:13 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 20 Jun 2020 15:31:13 -0700
Subject: [R] chaining closure arguments on-the-fly
In-Reply-To: <d9886832-c9d2-a6c3-dd0c-d0768c8cae6d@gmail.com>
References: <bc3185bc-bcfe-f57c-ef72-0c6bbdc8f594@gmail.com>
 <be50bd91-26b9-5ba8-9a47-9af88df58f92@gmail.com>
 <5d0945d8-a389-a661-4b87-ca538e865f72@gmail.com>
 <3d8bf377-e99e-b145-ec13-6b294d69b718@gmail.com>
 <CAGxFJbQHCGYrTKGkhQRLZcsdTO0ga6iYVJ9A5V9tV3ZXw=099Q@mail.gmail.com>
 <d9886832-c9d2-a6c3-dd0c-d0768c8cae6d@gmail.com>
Message-ID: <CAGxFJbQ3xiGQq1edXhsbKjPJo49eq6uv=pFzkjFDJfeXS0GUgw@mail.gmail.com>

OK -- you were referring explicitly to the function call. That's what I
missed. Apologies for the noise.

-- Bert

On Sat, Jun 20, 2020 at 3:19 PM Benjamin Tyner <btyner at gmail.com> wrote:

>
> On 6/20/20 5:49 PM, Bert Gunter wrote:
> > Gents:
> > (with trepidation)
> >
> > f(x = 3, y = g(expr))
> > **already** evaluates g in the environment of f, **not** in the
> > environment of the caller.
> > (This does not contradict Duncan's example -- 3 is a constant, not a
> > variable).
> >
> > e.g.
> > > f <- function(x = 3, y = x^2 +k){
> > +     k <- 3
> > +     x + y
> > + }
> >
> > Ergo
> > > k <- 100; x <- 10
> > > f()
> > [1] 15
> > > f(0)
> > [1] 3
> > > x
> > [1] 10
> >
> > This is all due to lazy evaluation where default arguments are
> > evaluated in the function's environment (using standard evaluation).
> > Arguments supplied in the call are evaluated in the caller's
> > environment, so:
> >
> > > f(x = x)
> > [1] 113
> >
> > Am I missing something here?
> >
> > Cheers,
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> Default arguments are indeed evaluated in f's environment, but not
> supplied arguments. I haven't really thought about the semantics of 'g'
> with respect to default arguments. But certainly, lazy evaluation is key
> here.
>
> Ben (with trepidation as well)
>
>

	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Sun Jun 21 13:41:40 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Sun, 21 Jun 2020 13:41:40 +0200
Subject: [R] 
 Error in "plot(aov.object)" after upgradation to R-4.0.0 and
 R-4.0.1 for given R-Script-Example
In-Reply-To: <CACLgfx1FLG5Ei9b96PcFRHKk0f7z60Uxw+2iG-xkOFkTuTsbOw@mail.gmail.com>
References: <CACLgfx1FLG5Ei9b96PcFRHKk0f7z60Uxw+2iG-xkOFkTuTsbOw@mail.gmail.com>
Message-ID: <7B06D30E-F969-48FF-8793-08B1284B7541@gmail.com>

This is fallout from the stringsAsFactors changes. You have 'Permanganate' as a character vector and it runs afoul of this code

    aterms <- attributes(terms(x))
    dcl <- aterms$dataClasses[-aterms$response]
    facvars <- names(dcl)[dcl %in% c("factor", "ordered")]

which does not include 'Permanganate', even though the model fit has de facto promoted it to a factor. In the end, you try to multiply a px2-matrix by a 3-vector and things go poof.

This probably counts a bug in R, but I see that your code actually tries to pre-convert the variables to factors. However, you misspelled "Permangate"....

-pd

> On 19 Jun 2020, at 17:13 , Akhilesh Singh <akhileshsingh.igkv at gmail.com> wrote:
> 
> Dear learned experts of R,
> 
> I was writing a book through RStudio-Rmarkdown and had finally compiled it
> successfully based on R package R-3.6.2. Afterwards, I updated my R-3.6.2
> to R-4.0.0 and even later to R-4.0.1.
> 
> Then, the publishers demanded to recompile the book with font embedding, so
> I tried to recompile the book, when I found the following error:
> 
> "Error in (dm - 1) %*% ff : non-conformable arguments"
> 
> For convenience and reproducibility of the error, I am giving below the
> same code chunk as an R-Script-Example, wherein the error is occurring in
> the plot() function with the input of an aov() object.
> 
> R-Script-Example producing error:
> ==========================
> 
> setwd("E:/AKS-DATA-New/Software/R and allied
> packages/R-Markdown/knitr/MyBooks/STAT-512_STAT-564")
> getwd()
> 
> #After Upgrading to R-4.0.0 and even in R-4.0.1 following error in "plot()"
> function occurs:
> 
> Block=c(1,1,1,1,2,2,2,2,3,3,3,3)
> Permanganate=c("without","without","with","with","without","without","with","with","without","without","with","with")
> Sample.Size=c(0.25,1,0.25,1,0.25,1,0.25,1,0.25,1,0.25,1)
> Riboflavin=c(39.5,38.6,27.2,24.6,43.1,39.5,23.2,24.2,45.2,33,24.8,22.2)
> 
> #Creating data frame
> sned.2x2.woint=data.frame(Block, Sample.Size, Permanganate, Riboflavin)
> 
> #Declaring Block, Sample.Size, Permanganate as factors
> sned.2x2.woint$Block = factor(sned.2x2.woint$Block)
> sned.2x2.woint$Sample.Size = factor(sned.2x2.woint$Sample.Size)
> sned.2x2.woint$Permangate=factor(sned.2x2.woint$Permanganate)
> 
> #ANOVA of RBD when Block, Sample.Size, Permanganate are a fixed effects
> sned.2x2.woint.aov1=aov(Riboflavin ~ Block + Sample.Size + Permanganate +
> Sample.Size:Permanganate,data=sned.2x2.woint)
> 
> cat("ANOVA of RBD when Block, Sample.Size and Permanganate are fixed
> effects:\n")
> summary(sned.2x2.woint.aov1)
> 
> #ANOVA of RBD when Block, Sample.Size, Permanganate are fixed effects
> sned.2x2.woint.aov2=aov(Riboflavin ~ Block + Sample.Size + Permanganate,
> data=sned.2x2.woint)
> 
> cat("ANOVA of RBD when Block, Sample.Size and Permanganate are fixed
> effects:\n")
> 
> summary(sned.2x2.woint.aov2)
> 
> plot(sned.2x2.woint.aov2, which=1) #OK
> plot(sned.2x2.woint.aov2, which=2) #Ok
> plot(sned.2x2.woint.aov2, which=3) #OK
> plot(sned.2x2.woint.aov2, which=4) #OK
> 
> plot(sned.2x2.woint.aov2, which=5) #Error in (dm - 1) %*% ff :
> non-conformable arguments
> 
> plot(sned.2x2.woint.aov2, which=6) #OK
> =================================
> 
> I request the esteemed and learned experts of R to kindly me out to
> overcome this error.
> 
> With regards
> 
> 
> 
> -- 
> Dr. A.K. Singh
> Professor and Head (Agricultural Statistics)
> Department of Agricultural Statistics and Social Science (L)
> Indira Gandhi Krishi Vishwavidyalaya, Raipur-492 012,
> Chhattisgarh, India
> Mobile: +918770625795
> Email: akhileshsingh.igkv at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From |re|ey@ @end|ng |rom gm@||@com  Sun Jun 21 12:42:03 2020
From: |re|ey@ @end|ng |rom gm@||@com (Frederik Feys)
Date: Sun, 21 Jun 2020 12:42:03 +0200
Subject: [R] how to combine uncertainty and weighting in spearman
 correlation?
Message-ID: <1ED37B7A-1174-4245-9FEC-AC99CFB64F60@gmail.com>

Hello everyone

At the moment I put a lot of attention in the uncertainty of my analyzes. I want to do a spearman correlation that takes into account the uncertainty in my observations and has weighting.

uncertainty of observations: I came across this excellent blog that proposes a bootstrap function: https://www.r-bloggers.com/finding-correlations-in-data-with-uncertainty/

weighted: I do weighted correlations with the wCorr package.

Now I want to combine both approaches in one approach for a final analysis. How would you do that?

Thanks for the help!

Frederik Feys
PhD Medical Sciences
Onafhankelijk Methodoloog
https://www.researchgate.net/profile/Frederik_Feys
+32488020010







	[[alternative HTML version deleted]]


From btyner @end|ng |rom gm@||@com  Sun Jun 21 17:37:27 2020
From: btyner @end|ng |rom gm@||@com (Benjamin Tyner)
Date: Sun, 21 Jun 2020 11:37:27 -0400
Subject: [R] chaining closure arguments on-the-fly
In-Reply-To: <3d8bf377-e99e-b145-ec13-6b294d69b718@gmail.com>
References: <bc3185bc-bcfe-f57c-ef72-0c6bbdc8f594@gmail.com>
 <be50bd91-26b9-5ba8-9a47-9af88df58f92@gmail.com>
 <5d0945d8-a389-a661-4b87-ca538e865f72@gmail.com>
 <3d8bf377-e99e-b145-ec13-6b294d69b718@gmail.com>
Message-ID: <2a88d0e8-7282-5f76-9b08-f6d275d23017@gmail.com>

On 6/20/20 5:04 PM, Duncan Murdoch wrote:
> I think you effectively did that in your original post (all but 
> encapsulating the expression in a function), so yes, it's possible. 
> However, it's a really bad idea.? Why use non-standard evaluation when 
> standard evaluation is fine?? Standard evaluation follows some well 
> defined rules, and is easy to reason about.? NSE follows whatever 
> rules it wants, so it's really hard for users to follow.? For example, 
> assuming you had the g() you want, what would this give?
>
> z <- 3
> f(x = z, y = g(z))
>
> You can't possibly know that without knowing whether there's a local 
> variable in f named z that is created before y is evaluated.
>
> Duncan Murdoch
>
>
Very good point, and I agree it's best to use standard evaluation 
whenever possible. The role of g would essentially be to modify one or 
more elements of f's formals in-place. For example calling:

    f(x = 3, y = g(expr))

would be equivalent to calling a function fm:

    fm(x = 3)

where the body of fm is identical to that of f, but:

     > formals(fm)
    $x


    $y
    expr

though I expect g would be non-trivial to code up robustly.


From @kh||e@h@|ngh@|gkv @end|ng |rom gm@||@com  Sun Jun 21 21:23:33 2020
From: @kh||e@h@|ngh@|gkv @end|ng |rom gm@||@com (Akhilesh Singh)
Date: Mon, 22 Jun 2020 00:53:33 +0530
Subject: [R] 
 Error in "plot(aov.object)" after upgradation to R-4.0.0 and
 R-4.0.1 for given R-Script-Example
In-Reply-To: <7B06D30E-F969-48FF-8793-08B1284B7541@gmail.com>
References: <CACLgfx1FLG5Ei9b96PcFRHKk0f7z60Uxw+2iG-xkOFkTuTsbOw@mail.gmail.com>
 <7B06D30E-F969-48FF-8793-08B1284B7541@gmail.com>
Message-ID: <CACLgfx1p785uZm4nbXq1N1YGvykCxwQetvb=BLyDigZo6Jx8Pw@mail.gmail.com>

Dear Peter,

Thanks for your reply, and pointing out my mistake of misspelling in
'Permanganate' variable.

However, it couldn't be detected because the same code, with misspelled
variable at factor declaration level, ran successful ly till I upgraded to
R-4.0.0 and later to R-0.1.

I am sure the bug pointed out by you would taken care of soon. Thanks again.

With best regards,

Dr. A.K. Singh



On Sun, Jun 21, 2020, 5:11 PM peter dalgaard <pdalgd at gmail.com> wrote:

> This is fallout from the stringsAsFactors changes. You have 'Permanganate'
> as a character vector and it runs afoul of this code
>
>     aterms <- attributes(terms(x))
>     dcl <- aterms$dataClasses[-aterms$response]
>     facvars <- names(dcl)[dcl %in% c("factor", "ordered")]
>
> which does not include 'Permanganate', even though the model fit has de
> facto promoted it to a factor. In the end, you try to multiply a px2-matrix
> by a 3-vector and things go poof.
>
> This probably counts a bug in R, but I see that your code actually tries
> to pre-convert the variables to factors. However, you misspelled
> "Permangate"....
>
> -pd
>
> > On 19 Jun 2020, at 17:13 , Akhilesh Singh <akhileshsingh.igkv at gmail.com>
> wrote:
> >
> > Dear learned experts of R,
> >
> > I was writing a book through RStudio-Rmarkdown and had finally compiled
> it
> > successfully based on R package R-3.6.2. Afterwards, I updated my R-3.6.2
> > to R-4.0.0 and even later to R-4.0.1.
> >
> > Then, the publishers demanded to recompile the book with font embedding,
> so
> > I tried to recompile the book, when I found the following error:
> >
> > "Error in (dm - 1) %*% ff : non-conformable arguments"
> >
> > For convenience and reproducibility of the error, I am giving below the
> > same code chunk as an R-Script-Example, wherein the error is occurring in
> > the plot() function with the input of an aov() object.
> >
> > R-Script-Example producing error:
> > ==========================
> >
> > setwd("E:/AKS-DATA-New/Software/R and allied
> > packages/R-Markdown/knitr/MyBooks/STAT-512_STAT-564")
> > getwd()
> >
> > #After Upgrading to R-4.0.0 and even in R-4.0.1 following error in
> "plot()"
> > function occurs:
> >
> > Block=c(1,1,1,1,2,2,2,2,3,3,3,3)
> >
> Permanganate=c("without","without","with","with","without","without","with","with","without","without","with","with")
> > Sample.Size=c(0.25,1,0.25,1,0.25,1,0.25,1,0.25,1,0.25,1)
> > Riboflavin=c(39.5,38.6,27.2,24.6,43.1,39.5,23.2,24.2,45.2,33,24.8,22.2)
> >
> > #Creating data frame
> > sned.2x2.woint=data.frame(Block, Sample.Size, Permanganate, Riboflavin)
> >
> > #Declaring Block, Sample.Size, Permanganate as factors
> > sned.2x2.woint$Block = factor(sned.2x2.woint$Block)
> > sned.2x2.woint$Sample.Size = factor(sned.2x2.woint$Sample.Size)
> > sned.2x2.woint$Permangate=factor(sned.2x2.woint$Permanganate)
> >
> > #ANOVA of RBD when Block, Sample.Size, Permanganate are a fixed effects
> > sned.2x2.woint.aov1=aov(Riboflavin ~ Block + Sample.Size + Permanganate +
> > Sample.Size:Permanganate,data=sned.2x2.woint)
> >
> > cat("ANOVA of RBD when Block, Sample.Size and Permanganate are fixed
> > effects:\n")
> > summary(sned.2x2.woint.aov1)
> >
> > #ANOVA of RBD when Block, Sample.Size, Permanganate are fixed effects
> > sned.2x2.woint.aov2=aov(Riboflavin ~ Block + Sample.Size + Permanganate,
> > data=sned.2x2.woint)
> >
> > cat("ANOVA of RBD when Block, Sample.Size and Permanganate are fixed
> > effects:\n")
> >
> > summary(sned.2x2.woint.aov2)
> >
> > plot(sned.2x2.woint.aov2, which=1) #OK
> > plot(sned.2x2.woint.aov2, which=2) #Ok
> > plot(sned.2x2.woint.aov2, which=3) #OK
> > plot(sned.2x2.woint.aov2, which=4) #OK
> >
> > plot(sned.2x2.woint.aov2, which=5) #Error in (dm - 1) %*% ff :
> > non-conformable arguments
> >
> > plot(sned.2x2.woint.aov2, which=6) #OK
> > =================================
> >
> > I request the esteemed and learned experts of R to kindly me out to
> > overcome this error.
> >
> > With regards
> >
> >
> >
> > --
> > Dr. A.K. Singh
> > Professor and Head (Agricultural Statistics)
> > Department of Agricultural Statistics and Social Science (L)
> > Indira Gandhi Krishi Vishwavidyalaya, Raipur-492 012,
> > Chhattisgarh, India
> > Mobile: +918770625795
> > Email: akhileshsingh.igkv at gmail.com
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz  Sun Jun 21 22:42:01 2020
From: p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz (Paul Murrell)
Date: Mon, 22 Jun 2020 08:42:01 +1200
Subject: [R] Load svg, eps or png into graphics device?
In-Reply-To: <A7F8903F-97D3-4CB8-BC2A-CA2117EFB5DE@krugs.de>
References: <A7F8903F-97D3-4CB8-BC2A-CA2117EFB5DE@krugs.de>
Message-ID: <6f702567-2a9b-a78e-a461-1dc0400b8a19@stat.auckland.ac.nz>

Hi

Do you mean you want to reduce *system requirements* ?  I'm not sure you 
have many options.  Looking at the plantuml output format options, there 
is ...

png via 'png', which requires libpng
svg via 'grImport2', which requires 'rsvg', which requires librsvg2
eps via 'grImport', which requires ghostscript

... and a number of other formats that cannot be read directly into R AFAIK.

The only option that does not require dependencies looks like the "txt" 
format, which you could read in with readLines(), but I'm not sure you 
want an ASCII art version :)

Paul

On 20/06/20 2:56 am, Rainer M Krug wrote:
> 
> Hi
> 
> I have a package, which plots from the plantuml syntax (https://plantuml.com) graphs via a knitr engine, into a file, or into a graphics device (https://github.com/rkrug/plantuml).
> 
> I am using at the moment grImport for the eps import, but would like to cut down on dependencies.
> 
> Is there a way of bringing graphics files (png, sag, eps, ?) into a graphics device in R?
> 
> Thanks,
> 
> Rainer
> 
> 
> 
> 
> 
> 
> --
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
> 
> Orcid ID: 0000-0002-7490-0066
> 
> Department of Evolutionary Biology and Environmental Studies
> University of Z?rich
> Office Y34-J-74
> Winterthurerstrasse 190
> 8075 Z?rich
> Switzerland
> 
> Office:	+41 (0)44 635 47 64
> Cell:       	+41 (0)78 630 66 57
> email:      Rainer.Krug at uzh.ch
> 		Rainer at krugs.de
> Skype:     RMkrug
> 
> PGP: 0x0F52F982
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Jun 21 22:48:22 2020
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 21 Jun 2020 16:48:22 -0400
Subject: [R] chaining closure arguments on-the-fly
In-Reply-To: <2a88d0e8-7282-5f76-9b08-f6d275d23017@gmail.com>
References: <bc3185bc-bcfe-f57c-ef72-0c6bbdc8f594@gmail.com>
 <be50bd91-26b9-5ba8-9a47-9af88df58f92@gmail.com>
 <5d0945d8-a389-a661-4b87-ca538e865f72@gmail.com>
 <3d8bf377-e99e-b145-ec13-6b294d69b718@gmail.com>
 <2a88d0e8-7282-5f76-9b08-f6d275d23017@gmail.com>
Message-ID: <d4ebb1dd-5d89-12db-fc89-785f443fd7b2@gmail.com>

On 21/06/2020 11:37 a.m., Benjamin Tyner wrote:
> On 6/20/20 5:04 PM, Duncan Murdoch wrote:
>> I think you effectively did that in your original post (all but
>> encapsulating the expression in a function), so yes, it's possible.
>> However, it's a really bad idea.? Why use non-standard evaluation when
>> standard evaluation is fine?? Standard evaluation follows some well
>> defined rules, and is easy to reason about.? NSE follows whatever
>> rules it wants, so it's really hard for users to follow.? For example,
>> assuming you had the g() you want, what would this give?
>>
>> z <- 3
>> f(x = z, y = g(z))
>>
>> You can't possibly know that without knowing whether there's a local
>> variable in f named z that is created before y is evaluated.
>>
>> Duncan Murdoch
>>
>>
> Very good point, and I agree it's best to use standard evaluation
> whenever possible. The role of g would essentially be to modify one or
> more elements of f's formals in-place. For example calling:
> 
>      f(x = 3, y = g(expr))
> 
> would be equivalent to calling a function fm:
> 
>      fm(x = 3)
> 
> where the body of fm is identical to that of f, but:
> 
>       > formals(fm)
>      $x
> 
> 
>      $y
>      expr
> 
> though I expect g would be non-trivial to code up robustly.

I would still say that's a bad idea.  The defaults for a function's 
arguments are decided by the function's author, so it makes sense for 
them to be evaluated in the evaluation frame of the function.  The 
actual arguments given to the function are decided by whoever calls it, 
so they should be evaluated in the caller's environment.  That's 
standard evaluation.

What you're trying to do mixes up these things:  you want the caller to 
be able to evaluate things that depend on function internals.  That is 
bad, because it means the function can no longer be a black box that 
does what it is documented to do:  it also needs to do it in exactly the 
way it did when the caller wrote g(expr), or that could give a garbage 
value.  Effectively you've broken the encapsulation that functions give 
you.  You've made f() part of whatever function calls it (but imposed 
the rule that says the source of f() can't be modified, which makes no 
sense).

Duncan Murdoch


From @purd|e@@ @end|ng |rom gm@||@com  Mon Jun 22 00:00:31 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Mon, 22 Jun 2020 10:00:31 +1200
Subject: [R] how to combine uncertainty and weighting in spearman
 correlation?
In-Reply-To: <1ED37B7A-1174-4245-9FEC-AC99CFB64F60@gmail.com>
References: <1ED37B7A-1174-4245-9FEC-AC99CFB64F60@gmail.com>
Message-ID: <CAB8pepwZACSR3dcP9XuAjM8TVxYFo6ismxNCL2S=uHnRV1FGLw@mail.gmail.com>

Hi Frederick,

I glanced at the webpage you've linked.
(But only the top three snippets).

This is what I would call the sum of random variables.
(X, Y) = (X1, X1) + (X2, Y2) + ... + (Xn, Yn)

The example makes the mistake of assuming that the Xs are normally
distributed, and each of the Ys are from exactly the same uniform
distribution.
By "combine"-ing both approaches, are you wanting to weight each pair?

w1(X1, X1) + w2(X2, Y2) + ... + wn(Xn, Yn)

I note that you haven't told us much about your data.
There may be an easier way of doing things...


On Mon, Jun 22, 2020 at 1:53 AM Frederik Feys <frefeys at gmail.com> wrote:
>
> Hello everyone
>
> At the moment I put a lot of attention in the uncertainty of my analyzes. I want to do a spearman correlation that takes into account the uncertainty in my observations and has weighting.
>
> uncertainty of observations: I came across this excellent blog that proposes a bootstrap function: https://www.r-bloggers.com/finding-correlations-in-data-with-uncertainty/
>
> weighted: I do weighted correlations with the wCorr package.
>
> Now I want to combine both approaches in one approach for a final analysis. How would you do that?
>
> Thanks for the help!
>
> Frederik Feys
> PhD Medical Sciences
> Onafhankelijk Methodoloog
> https://www.researchgate.net/profile/Frederik_Feys
> +32488020010
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Mon Jun 22 00:07:36 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Mon, 22 Jun 2020 10:07:36 +1200
Subject: [R] how to combine uncertainty and weighting in spearman
 correlation?
In-Reply-To: <CAB8pepwZACSR3dcP9XuAjM8TVxYFo6ismxNCL2S=uHnRV1FGLw@mail.gmail.com>
References: <1ED37B7A-1174-4245-9FEC-AC99CFB64F60@gmail.com>
 <CAB8pepwZACSR3dcP9XuAjM8TVxYFo6ismxNCL2S=uHnRV1FGLw@mail.gmail.com>
Message-ID: <CAB8pepz+wOEeSsWr4ntGX5CHPG+4=1MLqYQ-O-o9Zty=O4=iqg@mail.gmail.com>

Just realised the above notation may be a bit misleading.
Because I was thinking in terms of simulated data.


On Mon, Jun 22, 2020 at 10:00 AM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> Hi Frederick,
>
> I glanced at the webpage you've linked.
> (But only the top three snippets).
>
> This is what I would call the sum of random variables.
> (X, Y) = (X1, X1) + (X2, Y2) + ... + (Xn, Yn)
>
> The example makes the mistake of assuming that the Xs are normally
> distributed, and each of the Ys are from exactly the same uniform
> distribution.
> By "combine"-ing both approaches, are you wanting to weight each pair?
>
> w1(X1, X1) + w2(X2, Y2) + ... + wn(Xn, Yn)
>
> I note that you haven't told us much about your data.
> There may be an easier way of doing things...
>
>
> On Mon, Jun 22, 2020 at 1:53 AM Frederik Feys <frefeys at gmail.com> wrote:
> >
> > Hello everyone
> >
> > At the moment I put a lot of attention in the uncertainty of my analyzes. I want to do a spearman correlation that takes into account the uncertainty in my observations and has weighting.
> >
> > uncertainty of observations: I came across this excellent blog that proposes a bootstrap function: https://www.r-bloggers.com/finding-correlations-in-data-with-uncertainty/
> >
> > weighted: I do weighted correlations with the wCorr package.
> >
> > Now I want to combine both approaches in one approach for a final analysis. How would you do that?
> >
> > Thanks for the help!
> >
> > Frederik Feys
> > PhD Medical Sciences
> > Onafhankelijk Methodoloog
> > https://www.researchgate.net/profile/Frederik_Feys
> > +32488020010
> >
> >
> >
> >
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Mon Jun 22 02:02:19 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Mon, 22 Jun 2020 12:02:19 +1200
Subject: [R] how to combine uncertainty and weighting in spearman
 correlation?
In-Reply-To: <CAB8pepwZACSR3dcP9XuAjM8TVxYFo6ismxNCL2S=uHnRV1FGLw@mail.gmail.com>
References: <1ED37B7A-1174-4245-9FEC-AC99CFB64F60@gmail.com>
 <CAB8pepwZACSR3dcP9XuAjM8TVxYFo6ismxNCL2S=uHnRV1FGLw@mail.gmail.com>
Message-ID: <CAB8pepxvwxk=kfOoEga7L_GbEfqrJXCzH_q1h0pu4Erw6JuW-Q@mail.gmail.com>

I need to fix my mistakes, from earlier this morning.
The sums should be over densities, so:

fh (X, Y) = [fh1 (X1, X1) + fh2 (X2, Y2) + ... + fhn (Xn, Yn)] / n

fh (X, Y) = w1*fh1 (X1, X1) + w2*fh2 (X2, Y2) + ... + wn*fhn (Xn, Yn)

    assuming the weights sum to 1

If simulated data is used, then the expressions above can be replaced
with the union of multiple (sub)samples.
Then an estimate/inference (say correlation) can be computed from one
or more combined samples.

Sorry, for triple posting.


On Mon, Jun 22, 2020 at 10:00 AM Abby Spurdle <spurdle.a at gmail.com> wrote:
>
> Hi Frederick,
>
> I glanced at the webpage you've linked.
> (But only the top three snippets).
>
> This is what I would call the sum of random variables.
> (X, Y) = (X1, X1) + (X2, Y2) + ... + (Xn, Yn)
>
> The example makes the mistake of assuming that the Xs are normally
> distributed, and each of the Ys are from exactly the same uniform
> distribution.
> By "combine"-ing both approaches, are you wanting to weight each pair?
>
> w1(X1, X1) + w2(X2, Y2) + ... + wn(Xn, Yn)
>
> I note that you haven't told us much about your data.
> There may be an easier way of doing things...
>
>
> On Mon, Jun 22, 2020 at 1:53 AM Frederik Feys <frefeys at gmail.com> wrote:
> >
> > Hello everyone
> >
> > At the moment I put a lot of attention in the uncertainty of my analyzes. I want to do a spearman correlation that takes into account the uncertainty in my observations and has weighting.
> >
> > uncertainty of observations: I came across this excellent blog that proposes a bootstrap function: https://www.r-bloggers.com/finding-correlations-in-data-with-uncertainty/
> >
> > weighted: I do weighted correlations with the wCorr package.
> >
> > Now I want to combine both approaches in one approach for a final analysis. How would you do that?
> >
> > Thanks for the help!
> >
> > Frederik Feys
> > PhD Medical Sciences
> > Onafhankelijk Methodoloog
> > https://www.researchgate.net/profile/Frederik_Feys
> > +32488020010
> >
> >
> >
> >
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From R@|ner @end|ng |rom krug@@de  Mon Jun 22 09:04:55 2020
From: R@|ner @end|ng |rom krug@@de (Rainer M Krug)
Date: Mon, 22 Jun 2020 09:04:55 +0200
Subject: [R] Load svg, eps or png into graphics device?
In-Reply-To: <6f702567-2a9b-a78e-a461-1dc0400b8a19@stat.auckland.ac.nz>
References: <A7F8903F-97D3-4CB8-BC2A-CA2117EFB5DE@krugs.de>
 <6f702567-2a9b-a78e-a461-1dc0400b8a19@stat.auckland.ac.nz>
Message-ID: <649AAD60-1E34-4F6D-8458-9B79DFD321A3@krugs.de>



> On 21 Jun 2020, at 22:42, Paul Murrell <paul at stat.auckland.ac.nz> wrote:
> 
> Hi
> 
> Do you mean you want to reduce *system requirements* ?

system requirements and package dependencies. Yes.

>  I'm not sure you have many options.

That was my impression as well, and that is why I asked here - possibly somebody has any smart idea.


>  Looking at the plantuml output format options, there is ...
> 
> png via 'png', which requires libpng

Yup.

> svg via 'grImport2', which requires 'rsvg', which requires librsvg2

Tried it, but did not work as well as

> eps via 'grImport', which requires ghostscript

Which I am using for the vector graph.

> 
> ... and a number of other formats that cannot be read directly into R AFAIK.
> 
> The only option that does not require dependencies looks like the "txt" format, which you could read in with readLines(), but I'm not sure you want an ASCII art version :)

Actually, it could actually be an option if none of the above is installed. Kind of cascading, depending if installed: eps - sag - png - ASCII art.

Thanks,

Rainer


> 
> Paul
> 
> On 20/06/20 2:56 am, Rainer M Krug wrote:
>> Hi
>> I have a package, which plots from the plantuml syntax (https://plantuml.com) graphs via a knitr engine, into a file, or into a graphics device (https://github.com/rkrug/plantuml).
>> I am using at the moment grImport for the eps import, but would like to cut down on dependencies.
>> Is there a way of bringing graphics files (png, sag, eps, ?) into a graphics device in R?
>> Thanks,
>> Rainer
>> --
>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
>> Orcid ID: 0000-0002-7490-0066
>> Department of Evolutionary Biology and Environmental Studies
>> University of Z?rich
>> Office Y34-J-74
>> Winterthurerstrasse 190
>> 8075 Z?rich
>> Switzerland
>> Office:	+41 (0)44 635 47 64
>> Cell:       	+41 (0)78 630 66 57
>> email:      Rainer.Krug at uzh.ch
>> 		Rainer at krugs.de
>> Skype:     RMkrug
>> PGP: 0x0F52F982
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Orcid ID: 0000-0002-7490-0066

Department of Evolutionary Biology and Environmental Studies
University of Z?rich
Office Y34-J-74
Winterthurerstrasse 190
8075 Z?rich
Switzerland

Office:	+41 (0)44 635 47 64
Cell:       	+41 (0)78 630 66 57
email:      Rainer.Krug at uzh.ch
		Rainer at krugs.de
Skype:     RMkrug

PGP: 0x0F52F982




	[[alternative HTML version deleted]]


From R@|ner @end|ng |rom krug@@de  Mon Jun 22 09:07:51 2020
From: R@|ner @end|ng |rom krug@@de (Rainer M Krug)
Date: Mon, 22 Jun 2020 09:07:51 +0200
Subject: [R] Load svg, eps or png into graphics device?
In-Reply-To: <CAB8pepx54Wn7AgpTNAeJw2KoDoBqCfqNKeSjx-Zjc20amLoy4w@mail.gmail.com>
References: <A7F8903F-97D3-4CB8-BC2A-CA2117EFB5DE@krugs.de>
 <CAB8pepx54Wn7AgpTNAeJw2KoDoBqCfqNKeSjx-Zjc20amLoy4w@mail.gmail.com>
Message-ID: <D64D1410-A223-4322-A52D-004AFB3F0674@krugs.de>



> On 20 Jun 2020, at 01:30, Abby Spurdle <spurdle.a at gmail.com> wrote:
> 
> If I understand your question correctly, you're already able to read
> an EPS file.
> So, essentially, you have an answer to your question.

Well - there are some dependencies (system as well as package dependencies) which I would like to cut down - that is why I am asking. 
> 
> Paul Murrell published an article on using raster graphics, in 2011.
> https://journal.r-project.org/archive/2011-1/RJournal_2011-1_Murrell.pdf
> 
> I would assume there's been progress since then.
> But I don't see the point here.

Depending on the use, it might be better to have a raster or a vector representation. But I agree - in general, is vector better.


> Writing what would otherwise be vector graphics to a raster-based

No - plantuml can also produce png graphs - these are the ones I am using for the raster representation.

> image file, and then reading it back into a vector graphics system,
> would create unnecessary problems.

That one is true.


Thanks,

Rainer

> 
> 
> On Sat, Jun 20, 2020 at 2:56 AM Rainer M Krug <Rainer at krugs.de> wrote:
>> 
>> 
>> Hi
>> 
>> I have a package, which plots from the plantuml syntax (https://plantuml.com) graphs via a knitr engine, into a file, or into a graphics device (https://github.com/rkrug/plantuml).
>> 
>> I am using at the moment grImport for the eps import, but would like to cut down on dependencies.
>> 
>> Is there a way of bringing graphics files (png, sag, eps, ?) into a graphics device in R?
>> 
>> Thanks,
>> 
>> Rainer
>> 
>> 
>> 
>> 
>> 
>> 
>> --
>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
>> 
>> Orcid ID: 0000-0002-7490-0066
>> 
>> Department of Evolutionary Biology and Environmental Studies
>> University of Z?rich
>> Office Y34-J-74
>> Winterthurerstrasse 190
>> 8075 Z?rich
>> Switzerland
>> 
>> Office: +41 (0)44 635 47 64
>> Cell:           +41 (0)78 630 66 57
>> email:      Rainer.Krug at uzh.ch
>>                Rainer at krugs.de
>> Skype:     RMkrug
>> 
>> PGP: 0x0F52F982
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Orcid ID: 0000-0002-7490-0066

Department of Evolutionary Biology and Environmental Studies
University of Z?rich
Office Y34-J-74
Winterthurerstrasse 190
8075 Z?rich
Switzerland

Office:	+41 (0)44 635 47 64
Cell:       	+41 (0)78 630 66 57
email:      Rainer.Krug at uzh.ch
		Rainer at krugs.de
Skype:     RMkrug

PGP: 0x0F52F982




	[[alternative HTML version deleted]]


From pd@me@ @end|ng |rom cb@@dk  Mon Jun 22 10:21:31 2020
From: pd@me@ @end|ng |rom cb@@dk (Peter Dalgaard)
Date: Mon, 22 Jun 2020 08:21:31 +0000
Subject: [R] R 4.0.2 is released
Message-ID: <109235C0-23F3-4DA6-B895-51596AD62D31@cbs.dk>

The build system rolled up R-4.0.2.tar.gz (codename "Taking Off Again") this morning.

The list below details the changes in this release.

You can get the source code from

http://cran.r-project.org/src/base/R-4/R-4.0.2.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard

These are the checksums (md5 and SHA-256) for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = b9c44f9f78cab3184ad9898bebc854b4
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 4afa171cd982aaa60f0ba92e2e7bc5d6
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = 566a6bb3642e28e6bf01cf98db31137c
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 496062c138e2def06cebccddfb814ac6
MD5 (NEWS.3) = 012e7f4a80cc8ec947bf3f0ff6117ec8
MD5 (R-latest.tar.gz) = 1eac7293d5fe313a56ddabfda02b437e
MD5 (README) = f468f281c919665e276a1b691decbbe6
MD5 (RESOURCES) = 529223fd3ffef95731d0a87353108435
MD5 (THANKS) = 251d20510bfc3cc93b82c5a99f7efcc6
MD5 (VERSION-INFO.dcf) = 62496d3a0fd8cc2ed644ea518c052371
MD5 (R-4/R-4.0.2.tar.gz) = 1eac7293d5fe313a56ddabfda02b437e

2cde824a7b18958e5f06b391c801c8288be0f84fa8934b7ddefef23c67e60c09  AUTHORS
e6d6a009505e345fe949e1310334fcb0747f28dae2856759de102ab66b722cb4  COPYING
6095e9ffa777dd22839f7801aa845b31c9ed07f3d6bf8a26dc5d2dec8ccc0ef3  COPYING.LIB
eddf87b12197c7b3b19cbc9b11c1beab95b14e3dcd715bf37d2f6a8b2a72c2a1  FAQ
f87461be6cbaecc4dce44ac58e5bd52364b0491ccdadaf846cb9b452e9550f31  INSTALL
ec05bba338358410fae6b34fed061605989ab3601aba1b3fcb45a610d5dd2eb9  NEWS
4e21b62f515b749f80997063fceab626d7258c7d650e81a662ba8e0640f12f62  NEWS.0
12b30c724117b1b2b11484673906a6dcd48a361f69fc420b36194f9218692d01  NEWS.1
e80de410c77f05ff2012fa70051b89119845f734a7fa5c55857e61e4ed7d5f6e  NEWS.2
7201d139947afa52b5e09d26dc01445edf444506264355b2185122bc1ed3dce0  NEWS.3
d3bceab364da0876625e4097808b42512395fdf41292f4915ab1fd257c1bbe75  R-latest.tar.gz
2fdd3e90f23f32692d4b3a0c0452f2c219a10882033d1774f8cadf25886c3ddc  README
408737572ecc6e1135fdb2cf7a9dbb1a6cb27967c757f1771b8c39d1fd2f1ab9  RESOURCES
c9c7cb32308b4e560a22c858819ade9de524a602abd4e92d1c328c89f8037d73  THANKS
10cc5f566a4a5ce49147e7dcfbe9180dba09ccb9efb17298b067309eb799e92e  VERSION-INFO.dcf
d3bceab364da0876625e4097808b42512395fdf41292f4915ab1fd257c1bbe75  R-4/R-4.0.2.tar.gz

This is the relevant part of the NEWS file

CHANGES IN R 4.0.2:

  UTILITIES:

    * R CMD check skips vignette re-building (with a warning) if the
      VignetteBuilder package(s) are not available.

  BUG FIXES:

    * Paths with non-ASCII characters caused problems for package
      loading on Windows PR#17833.

    * Using tcltk widgets no longer crashes R on Windows.

    * source(*, echo=TRUE) no longer fails in some cases with empty
      lines; reported by Bill Dunlap in PR#17769.

    * on.exit() now correctly matches named arguments, thanks to
      PR#17815 (including patch) by Brodie Gaslam.

    * regexpr(*, perl=TRUE) no longer returns incorrect positions into
      text containing characters outside of the Unicode Basic
      Multilingual Plane on Windows.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Mon Jun 22 14:59:24 2020
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Mon, 22 Jun 2020 07:59:24 -0500
Subject: [R] R 4.0.2 is released
In-Reply-To: <109235C0-23F3-4DA6-B895-51596AD62D31@cbs.dk>
References: <109235C0-23F3-4DA6-B895-51596AD62D31@cbs.dk>
Message-ID: <928c918a-7c1c-3c99-517c-9bc860eea347@effectivedefense.org>

Thank you and all the core R team.? Spencer Graves


On 2020-06-22 03:21, Peter Dalgaard via R-help wrote:
> The build system rolled up R-4.0.2.tar.gz (codename "Taking Off Again") this morning.
>
> The list below details the changes in this release.
>
> You can get the source code from
>
> http://cran.r-project.org/src/base/R-4/R-4.0.2.tar.gz
>
> or wait for it to be mirrored at a CRAN site nearer to you.
>
> Binaries for various platforms will appear in due course.
>
>
> For the R Core Team,
>
> Peter Dalgaard
>
> These are the checksums (md5 and SHA-256) for the freshly created files, in case you wish
> to check that they are uncorrupted:
>
> MD5 (AUTHORS) = b9c44f9f78cab3184ad9898bebc854b4
> MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
> MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
> MD5 (FAQ) = 4afa171cd982aaa60f0ba92e2e7bc5d6
> MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
> MD5 (NEWS) = 566a6bb3642e28e6bf01cf98db31137c
> MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
> MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
> MD5 (NEWS.2) = 496062c138e2def06cebccddfb814ac6
> MD5 (NEWS.3) = 012e7f4a80cc8ec947bf3f0ff6117ec8
> MD5 (R-latest.tar.gz) = 1eac7293d5fe313a56ddabfda02b437e
> MD5 (README) = f468f281c919665e276a1b691decbbe6
> MD5 (RESOURCES) = 529223fd3ffef95731d0a87353108435
> MD5 (THANKS) = 251d20510bfc3cc93b82c5a99f7efcc6
> MD5 (VERSION-INFO.dcf) = 62496d3a0fd8cc2ed644ea518c052371
> MD5 (R-4/R-4.0.2.tar.gz) = 1eac7293d5fe313a56ddabfda02b437e
>
> 2cde824a7b18958e5f06b391c801c8288be0f84fa8934b7ddefef23c67e60c09  AUTHORS
> e6d6a009505e345fe949e1310334fcb0747f28dae2856759de102ab66b722cb4  COPYING
> 6095e9ffa777dd22839f7801aa845b31c9ed07f3d6bf8a26dc5d2dec8ccc0ef3  COPYING.LIB
> eddf87b12197c7b3b19cbc9b11c1beab95b14e3dcd715bf37d2f6a8b2a72c2a1  FAQ
> f87461be6cbaecc4dce44ac58e5bd52364b0491ccdadaf846cb9b452e9550f31  INSTALL
> ec05bba338358410fae6b34fed061605989ab3601aba1b3fcb45a610d5dd2eb9  NEWS
> 4e21b62f515b749f80997063fceab626d7258c7d650e81a662ba8e0640f12f62  NEWS.0
> 12b30c724117b1b2b11484673906a6dcd48a361f69fc420b36194f9218692d01  NEWS.1
> e80de410c77f05ff2012fa70051b89119845f734a7fa5c55857e61e4ed7d5f6e  NEWS.2
> 7201d139947afa52b5e09d26dc01445edf444506264355b2185122bc1ed3dce0  NEWS.3
> d3bceab364da0876625e4097808b42512395fdf41292f4915ab1fd257c1bbe75  R-latest.tar.gz
> 2fdd3e90f23f32692d4b3a0c0452f2c219a10882033d1774f8cadf25886c3ddc  README
> 408737572ecc6e1135fdb2cf7a9dbb1a6cb27967c757f1771b8c39d1fd2f1ab9  RESOURCES
> c9c7cb32308b4e560a22c858819ade9de524a602abd4e92d1c328c89f8037d73  THANKS
> 10cc5f566a4a5ce49147e7dcfbe9180dba09ccb9efb17298b067309eb799e92e  VERSION-INFO.dcf
> d3bceab364da0876625e4097808b42512395fdf41292f4915ab1fd257c1bbe75  R-4/R-4.0.2.tar.gz
>
> This is the relevant part of the NEWS file
>
> CHANGES IN R 4.0.2:
>
>    UTILITIES:
>
>      * R CMD check skips vignette re-building (with a warning) if the
>        VignetteBuilder package(s) are not available.
>
>    BUG FIXES:
>
>      * Paths with non-ASCII characters caused problems for package
>        loading on Windows PR#17833.
>
>      * Using tcltk widgets no longer crashes R on Windows.
>
>      * source(*, echo=TRUE) no longer fails in some cases with empty
>        lines; reported by Bill Dunlap in PR#17769.
>
>      * on.exit() now correctly matches named arguments, thanks to
>        PR#17815 (including patch) by Brodie Gaslam.
>
>      * regexpr(*, perl=TRUE) no longer returns incorrect positions into
>        text containing characters outside of the Unicode Basic
>        Multilingual Plane on Windows.
>


From @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com  Mon Jun 22 20:01:57 2020
From: @okov|c@@n@m@r|j@ @end|ng |rom gm@||@com (Ana Marija)
Date: Mon, 22 Jun 2020 13:01:57 -0500
Subject: [R] How to loop over two files ...
In-Reply-To: <20200620114753.2bb6c9dc@Tarkus>
References: <CAF9-5jPXwoHr4cxDmRtP5Xt=6p5bZbgkRCZSMUsfdm3WsWvmDQ@mail.gmail.com>
 <0f251037d302d02e0da085399ab4b627@chemo.org.uk>
 <CAF9-5jNHw5M1BZUMq26zroUD3QnA84e0=D7Wb1g1DMECQ5wChA@mail.gmail.com>
 <687ca3db19cde8b8f340a54632e75ea6@chemo.org.uk>
 <CAF9-5jN=MSaKWziUXW-F1acq_d5nnr0UvLNr=A=xJJWhVw39EA@mail.gmail.com>
 <74a49794ea4387f177f83f5d8be7b28f@chemo.org.uk>
 <CAF9-5jPpFTucD5X=S5yaZbjHRVtz4VkNvmTusHTghh5+d+igNQ@mail.gmail.com>
 <20200620114753.2bb6c9dc@Tarkus>
Message-ID: <CAF9-5jNQ5KLK1LWrcZ9rTLtP0KzjUxJJCBgOLvYM_=eBsmE8sQ@mail.gmail.com>

Thank you so much as.character(r) indeed resolved the issue!

On Sat, Jun 20, 2020 at 3:47 AM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>
> On Fri, 19 Jun 2020 19:36:41 -0500
> Ana Marija <sokovic.anamarija at gmail.com> wrote:
>
> > Error in cat(x, file = file, sep = c(rep.int(sep, ncolumns - 1),
> > "\n"),  : argument 1 (type 'list') cannot be handled by 'cat'
>
> It might be a good idea to try to solve problems like this yourself
> instead of waiting for hours for someone to reply. All the required
> information is there in the error message: write() fails because r is a
> list. Why is r a list? It's returned from GET(), so let's read its
> documentation.
>
> httr::GET() returns a response object, not a string [1]. Try passing
> as.character(r) or content(r,'text') instead of just r to write(...) or
> use a different way of extracting the actual response from the response
> object.
>
> --
> Best regards,
> Ivan
>
> [1] https://httr.r-lib.org/reference/GET.html


From @mo@tw|k20 @end|ng |rom gm@||@com  Mon Jun 22 22:29:48 2020
From: @mo@tw|k20 @end|ng |rom gm@||@com (K Amoatwi)
Date: Mon, 22 Jun 2020 16:29:48 -0400
Subject: [R] Error message in meta-analysis package Metafor-weights =""
In-Reply-To: <6f755e6d576e4d168d1a7da438cde545@UM-MAIL3214.unimaas.nl>
References: <CAN5pK_21tgCA_Zyuj0=0jL7Pxg4T-NS09trteXnphiOpv9EbEg@mail.gmail.com>
 <6f755e6d576e4d168d1a7da438cde545@UM-MAIL3214.unimaas.nl>
Message-ID: <CAN5pK_1XGbo3ob3BhUg2sZoA5ufMv1iEgAfexHO6teg8Y3hWxw@mail.gmail.com>

Hi Wolfgang and All,
I am still practising my meta-analysis with the "Metafor" package, I tried
to run the code for "Forest plot" and got error message as shown below:
forest(result.md)
> forest(result.md)
Error in UseMethod("forest") :
  no applicable method for 'forest' applied to an object of class
"c('rma.uni', 'rma')"

Thank you in advance for your support

regards
Kobby


On Tue, Jun 16, 2020 at 12:50 PM Viechtbauer, Wolfgang (SP) <
wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:

> Dear Amoatwi,
>
> This way of using the escalc() function has been deprecated. It might be
> added back once there is actually any benefit from having this
> functionality, but for years it just meant that I had to maintain two
> different ways of doing the exact same thing without any additional
> benefits.
>
> Best,
> Wolfgang
>
> --
> Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and
>
> Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD
>
> Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com
>
>
> >-----Original Message-----
> >From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of K Amoatwi
> >Sent: Tuesday, 16 June, 2020 4:50
> >To: r-help at r-project.org
> >Subject: [R] Error message in meta-analysis package Metafor-weights =""
> >
> >Dear All,
> >I am using the example from one of the tutorial about "Metafor" package
> and
> >"escalc" function, to learn how this package can be applied to do
> >meta-analysi; the code and the data is directly from the tutorials but
> >"weights=freq" option in the escalc function is given me error message
> >This is the code below:
> >
> >library(metafor) # Load package
> >#####DATASET 1: BCG Vaccine Trials
> >data(dat.bcg) # BCG meta-analytic dataset
> >
> >##Formula based Specification
> >##That is, what if I have multiple rows per study, corresponding to
> >difference treatment groups?
> >
> >library(reshape2) # Load package for data reshaping
> >
> >bcg.long <- melt(dat.bcg[, c("trial", "tpos", "tneg", "cpos", "cneg")], id
> >= "trial")
> >bcg.long$pos <- ifelse(bcg.long$var == "tpos" | bcg.long$var == "cpos", 1,
> >0)
> >bcg.long$group <- ifelse(bcg.long$var == "tpos" | bcg.long$var == "tneg",
> >1, 0)
> >
> >##sample of the data, the first 6 rows
> >head(bcg.long)
> >  trial variable value pos group
> >1     1     tpos     4     1     1
> >2     2     tpos     6     1     1
> >3     3     tpos     3     1     1
> >4     4     tpos    62    1     1
> >5     5     tpos    33    1     1
> >6     6     tpos   180   1     1
> >
> >##Now applying the " escalc " function
> >
> >escalc(factor(pos)~factor(group)| factor(trial),weights = value,data =
> >bcg.long, measure = "OR")
> >
> >##Then I got this error message
> >Error in escalc(factor(pos) ~ factor(group) | factor(trial), weights =
> >value,  :
> >  object 'value' not found
> >
> >I used the same data with different example from another author and got a
> >similar error message
> >Second code with the same data but different coding
> >Sample data
> >
> >with the first 6 rows of the rearranged data shown below. (T=treatment,
> >C=Control group, Out=outcome whether positive or negative, and then
> >frequency)
> >    study grp out freq
> >1        1    T    +      4
> >2        1    T    -    119
> >3        1    C   +      11
> >4        1    C   -     128
> >5        2    T   +        6
> >6        2    T   -      300
> >
> >>escalc(out ~ grp | study, weights = freq, data = dat.fm, measure = "OR")
> >
> >Error in escalc(out ~ grp | study, weights = freq, data = dat.fm,
> measure =
> >"OR") :
> >  object 'freq' not found
> >
> >I am not sure what I am doing wrong since both authors were able to get
> >their results while I am getting error messages.
> >
> >Any help will be very much appreciated
> >
> >Amoatwi
>

	[[alternative HTML version deleted]]


From |re|ey@ @end|ng |rom gm@||@com  Mon Jun 22 09:55:28 2020
From: |re|ey@ @end|ng |rom gm@||@com (Frederik Feys)
Date: Mon, 22 Jun 2020 09:55:28 +0200
Subject: [R] how to combine uncertainty and weighting in spearman
 correlation?
In-Reply-To: <CAB8pepxvwxk=kfOoEga7L_GbEfqrJXCzH_q1h0pu4Erw6JuW-Q@mail.gmail.com>
References: <1ED37B7A-1174-4245-9FEC-AC99CFB64F60@gmail.com>
 <CAB8pepwZACSR3dcP9XuAjM8TVxYFo6ismxNCL2S=uHnRV1FGLw@mail.gmail.com>
 <CAB8pepxvwxk=kfOoEga7L_GbEfqrJXCzH_q1h0pu4Erw6JuW-Q@mail.gmail.com>
Message-ID: <7A076665-6FF7-44F8-AE4E-2204CD3ABEA9@gmail.com>

Thanks Abby, some info on the data:

score	score_SD	death_count	population_size
x1		x1_SD		y1			corr_weight	
4.3		2.3			5800		900.000	
5.7		6.1			250 			11.000.600
..		..			..			..

> Op 22 jun. 2020, om 02:02 heeft Abby Spurdle <spurdle.a at gmail.com> het volgende geschreven:
> 
> I need to fix my mistakes, from earlier this morning.
> The sums should be over densities, so:
> 
> fh (X, Y) = [fh1 (X1, X1) + fh2 (X2, Y2) + ... + fhn (Xn, Yn)] / n
> 
> fh (X, Y) = w1*fh1 (X1, X1) + w2*fh2 (X2, Y2) + ... + wn*fhn (Xn, Yn)
> 
>    assuming the weights sum to 1
> 
> If simulated data is used, then the expressions above can be replaced
> with the union of multiple (sub)samples.
> Then an estimate/inference (say correlation) can be computed from one
> or more combined samples.
> 
> Sorry, for triple posting.
> 
> 
> On Mon, Jun 22, 2020 at 10:00 AM Abby Spurdle <spurdle.a at gmail.com> wrote:
>> 
>> Hi Frederick,
>> 
>> I glanced at the webpage you've linked.
>> (But only the top three snippets).
>> 
>> This is what I would call the sum of random variables.
>> (X, Y) = (X1, X1) + (X2, Y2) + ... + (Xn, Yn)
>> 
>> The example makes the mistake of assuming that the Xs are normally
>> distributed, and each of the Ys are from exactly the same uniform
>> distribution.
>> By "combine"-ing both approaches, are you wanting to weight each pair?
>> 
>> w1(X1, X1) + w2(X2, Y2) + ... + wn(Xn, Yn)
>> 
>> I note that you haven't told us much about your data.
>> There may be an easier way of doing things...
>> 
>> 
>> On Mon, Jun 22, 2020 at 1:53 AM Frederik Feys <frefeys at gmail.com> wrote:
>>> 
>>> Hello everyone
>>> 
>>> At the moment I put a lot of attention in the uncertainty of my analyzes. I want to do a spearman correlation that takes into account the uncertainty in my observations and has weighting.
>>> 
>>> uncertainty of observations: I came across this excellent blog that proposes a bootstrap function: https://www.r-bloggers.com/finding-correlations-in-data-with-uncertainty/
>>> 
>>> weighted: I do weighted correlations with the wCorr package.
>>> 
>>> Now I want to combine both approaches in one approach for a final analysis. How would you do that?
>>> 
>>> Thanks for the help!
>>> 
>>> Frederik Feys
>>> PhD Medical Sciences
>>> Onafhankelijk Methodoloog
>>> https://www.researchgate.net/profile/Frederik_Feys
>>> +32488020010
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Tue Jun 23 06:57:31 2020
From: @purd|e@@ @end|ng |rom gm@||@com (Abby Spurdle)
Date: Tue, 23 Jun 2020 16:57:31 +1200
Subject: [R] how to combine uncertainty and weighting in spearman
 correlation?
In-Reply-To: <7A076665-6FF7-44F8-AE4E-2204CD3ABEA9@gmail.com>
References: <1ED37B7A-1174-4245-9FEC-AC99CFB64F60@gmail.com>
 <CAB8pepwZACSR3dcP9XuAjM8TVxYFo6ismxNCL2S=uHnRV1FGLw@mail.gmail.com>
 <CAB8pepxvwxk=kfOoEga7L_GbEfqrJXCzH_q1h0pu4Erw6JuW-Q@mail.gmail.com>
 <7A076665-6FF7-44F8-AE4E-2204CD3ABEA9@gmail.com>
Message-ID: <CAB8pepz_sr2buSDv92mTS6vqS7K=JFqXX-6i_Wn=1CcPc03GeA@mail.gmail.com>

Hi,

I suspect that there's a formula for this.
However, I couldn't find it.
So, here's (most of) the code to produce a simulated data set.

---------------------------
sim.data <- function (xmean, ymean, xsd=NULL, ysd=NULL, w, ...,
print=FALSE, plot=FALSE, nsub=1000)
{   N <- length (xmean)

    x <- y <- u <- matrix (0, nsub, N)
    for (k in 1:N)
    {   if (is.null (xsd) ) x [,k] <- xmean [k]
        else x [,k] <- rnorm (nsub, xmean [k], xsd [k])
        if (is.null (ysd) ) y [,k] <- ymean [k]
        else y [,k] <- rnorm (nsub, ymean [k], ysd [k])
        u [,k] <- w [k] / nsub
    }
    x <- as.vector (x)
    y <- as.vector (y)
    u <- as.vector (u)

    if (print)
        print (cbind (x, y, u) )
    if (plot)
    {   plot (x, y)
        points (xmean, ymean, pch=16, col="blue")
    }

    cor (x, y)
}
---------------------------

I didn't install the wCorr package, so you'll need to change the
second to last line.
The weights are in the vector, u (not w).

A subsample is generated for each group.
I've computed weights, such that the total weights for each group are
equal to the original weight for that group.
That sounds right, but I'm not completely sure.

Then call it using something like:
sim.data (x1, y1, x1_SD, NULL, corr_weight)

You can remove the print/plot parts if you want.
But if you call it with print=TRUE, then set nsub to a smaller value.
sim.data (x1, y1, x1_SD, NULL, corr_weight, print=TRUE, plot=TRUE, nsub=10)

If there's any problems, let me know.

On Mon, Jun 22, 2020 at 7:55 PM Frederik Feys <frefeys at gmail.com> wrote:
>
> Thanks Abby, some info on the data:
>
> score   score_SD        death_count     population_size
> x1              x1_SD           y1                      corr_weight
> 4.3             2.3                     5800            900.000
> 5.7             6.1                     250                     11.000.600
> ..              ..                      ..                      ..
>
> > Op 22 jun. 2020, om 02:02 heeft Abby Spurdle <spurdle.a at gmail.com> het volgende geschreven:
> >
> > I need to fix my mistakes, from earlier this morning.
> > The sums should be over densities, so:
> >
> > fh (X, Y) = [fh1 (X1, X1) + fh2 (X2, Y2) + ... + fhn (Xn, Yn)] / n
> >
> > fh (X, Y) = w1*fh1 (X1, X1) + w2*fh2 (X2, Y2) + ... + wn*fhn (Xn, Yn)
> >
> >    assuming the weights sum to 1
> >
> > If simulated data is used, then the expressions above can be replaced
> > with the union of multiple (sub)samples.
> > Then an estimate/inference (say correlation) can be computed from one
> > or more combined samples.
> >
> > Sorry, for triple posting.
> >
> >
> > On Mon, Jun 22, 2020 at 10:00 AM Abby Spurdle <spurdle.a at gmail.com> wrote:
> >>
> >> Hi Frederick,
> >>
> >> I glanced at the webpage you've linked.
> >> (But only the top three snippets).
> >>
> >> This is what I would call the sum of random variables.
> >> (X, Y) = (X1, X1) + (X2, Y2) + ... + (Xn, Yn)
> >>
> >> The example makes the mistake of assuming that the Xs are normally
> >> distributed, and each of the Ys are from exactly the same uniform
> >> distribution.
> >> By "combine"-ing both approaches, are you wanting to weight each pair?
> >>
> >> w1(X1, X1) + w2(X2, Y2) + ... + wn(Xn, Yn)
> >>
> >> I note that you haven't told us much about your data.
> >> There may be an easier way of doing things...
> >>
> >>
> >> On Mon, Jun 22, 2020 at 1:53 AM Frederik Feys <frefeys at gmail.com> wrote:
> >>>
> >>> Hello everyone
> >>>
> >>> At the moment I put a lot of attention in the uncertainty of my analyzes. I want to do a spearman correlation that takes into account the uncertainty in my observations and has weighting.
> >>>
> >>> uncertainty of observations: I came across this excellent blog that proposes a bootstrap function: https://www.r-bloggers.com/finding-correlations-in-data-with-uncertainty/
> >>>
> >>> weighted: I do weighted correlations with the wCorr package.
> >>>
> >>> Now I want to combine both approaches in one approach for a final analysis. How would you do that?
> >>>
> >>> Thanks for the help!
> >>>
> >>> Frederik Feys
> >>> PhD Medical Sciences
> >>> Onafhankelijk Methodoloog
> >>> https://www.researchgate.net/profile/Frederik_Feys
> >>> +32488020010
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
>


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Tue Jun 23 09:24:22 2020
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Tue, 23 Jun 2020 07:24:22 +0000
Subject: [R] Error message in meta-analysis package Metafor-weights =""
In-Reply-To: <CAN5pK_1XGbo3ob3BhUg2sZoA5ufMv1iEgAfexHO6teg8Y3hWxw@mail.gmail.com>
References: <CAN5pK_21tgCA_Zyuj0=0jL7Pxg4T-NS09trteXnphiOpv9EbEg@mail.gmail.com>
 <6f755e6d576e4d168d1a7da438cde545@UM-MAIL3214.unimaas.nl>
 <CAN5pK_1XGbo3ob3BhUg2sZoA5ufMv1iEgAfexHO6teg8Y3hWxw@mail.gmail.com>
Message-ID: <9216960491984fc78dc1210565825f3b@UM-MAIL3214.unimaas.nl>

Dear Kobby,

Please post the output of sessionInfo() and class(result.md).

Best,
Wolfgang

>-----Original Message-----
>From: K Amoatwi [mailto:amoatwik20 at gmail.com]
>Sent: Monday, 22 June, 2020 22:30
>To: Viechtbauer, Wolfgang (SP)
>Cc: r-help at r-project.org
>Subject: Re: [R] Error message in meta-analysis package Metafor-weights =""
>
>Hi?Wolfgang and All,
>I am still practising my meta-analysis with the "Metafor" package, I tried
>to run the code for "Forest plot" and got error message as shown below:
>forest(result.md)
>> forest(result.md)
>Error in UseMethod("forest") :
>? no applicable method for 'forest' applied to an object of class
>"c('rma.uni', 'rma')"
>
>Thank you in advance for your support
>
>regards
>Kobby
>
>On Tue, Jun 16, 2020 at 12:50 PM Viechtbauer, Wolfgang (SP)
><wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>Dear Amoatwi,
>
>This way of using the escalc() function has been deprecated. It might be
>added back once there is actually any benefit from having this
>functionality, but for years it just meant that I had to maintain two
>different ways of doing the exact same thing without any additional
>benefits.
>
>Best,
>Wolfgang
>
>--
>Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and
>Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD
>Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com
>
>>-----Original Message-----
>>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of K Amoatwi
>>Sent: Tuesday, 16 June, 2020 4:50
>>To: r-help at r-project.org
>>Subject: [R] Error message in meta-analysis package Metafor-weights =""
>>
>>Dear All,
>>I am using the example from one of the tutorial about "Metafor" package and
>>"escalc" function, to learn how this package can be applied to do
>>meta-analysi; the code and the data is directly from the tutorials but
>>"weights=freq" option in the escalc function is given me error message
>>This is the code below:
>>
>>library(metafor) # Load package
>>#####DATASET 1: BCG Vaccine Trials
>>data(dat.bcg) # BCG meta-analytic dataset
>>
>>##Formula based Specification
>>##That is, what if I have multiple rows per study, corresponding to
>>difference treatment groups?
>>
>>library(reshape2) # Load package for data reshaping
>>
>>bcg.long <- melt(dat.bcg[, c("trial", "tpos", "tneg", "cpos", "cneg")], id
>>= "trial")
>>bcg.long$pos <- ifelse(bcg.long$var == "tpos" | bcg.long$var == "cpos", 1,
>>0)
>>bcg.long$group <- ifelse(bcg.long$var == "tpos" | bcg.long$var == "tneg",
>>1, 0)
>>
>>##sample of the data, the first 6 rows
>>head(bcg.long)
>>? trial variable value pos group
>>1? ? ?1? ? ?tpos? ? ?4? ? ?1? ? ?1
>>2? ? ?2? ? ?tpos? ? ?6? ? ?1? ? ?1
>>3? ? ?3? ? ?tpos? ? ?3? ? ?1? ? ?1
>>4? ? ?4? ? ?tpos? ? 62? ? 1? ? ?1
>>5? ? ?5? ? ?tpos? ? 33? ? 1? ? ?1
>>6? ? ?6? ? ?tpos? ?180? ?1? ? ?1
>>
>>##Now applying the " escalc " function
>>
>>escalc(factor(pos)~factor(group)| factor(trial),weights = value,data =
>>bcg.long, measure = "OR")
>>
>>##Then I got this error message
>>Error in escalc(factor(pos) ~ factor(group) | factor(trial), weights =
>>value,? :
>>? object 'value' not found
>>
>>I used the same data with different example from another author and got a
>>similar error message
>>Second code with the same data but different coding
>>Sample data
>>
>>with the first 6 rows of the rearranged data shown below. (T=treatment,
>>C=Control group, Out=outcome whether positive or negative, and then
>>frequency)
>>? ? study grp out freq
>>1? ? ? ? 1? ? T? ? +? ? ? 4
>>2? ? ? ? 1? ? T? ? -? ? 119
>>3? ? ? ? 1? ? C? ?+? ? ? 11
>>4? ? ? ? 1? ? C? ?-? ? ?128
>>5? ? ? ? 2? ? T? ?+? ? ? ? 6
>>6? ? ? ? 2? ? T? ?-? ? ? 300
>>
>>>escalc(out ~ grp | study, weights = freq, data = dat.fm, measure = "OR")
>>
>>Error in escalc(out ~ grp | study, weights = freq, data = dat.fm, measure =
>>"OR") :
>>? object 'freq' not found
>>
>>I am not sure what I am doing wrong since both authors were able to get
>>their results while I am getting error messages.
>>
>>Any help will be very much appreciated
>>
>>Amoatwi

From @mo@tw|k20 @end|ng |rom gm@||@com  Tue Jun 23 16:37:24 2020
From: @mo@tw|k20 @end|ng |rom gm@||@com (K Amoatwi)
Date: Tue, 23 Jun 2020 10:37:24 -0400
Subject: [R] Error message in meta-analysis package Metafor-weights =""
In-Reply-To: <9216960491984fc78dc1210565825f3b@UM-MAIL3214.unimaas.nl>
References: <CAN5pK_21tgCA_Zyuj0=0jL7Pxg4T-NS09trteXnphiOpv9EbEg@mail.gmail.com>
 <6f755e6d576e4d168d1a7da438cde545@UM-MAIL3214.unimaas.nl>
 <CAN5pK_1XGbo3ob3BhUg2sZoA5ufMv1iEgAfexHO6teg8Y3hWxw@mail.gmail.com>
 <9216960491984fc78dc1210565825f3b@UM-MAIL3214.unimaas.nl>
Message-ID: <CAN5pK_3Bwpbid68k92BukW-ifSUHdWg3aaWcAgZdNwDi7FR_CQ@mail.gmail.com>

Dear Wolfgang,
I have posted the requested information you asked for.

>  sessionInfo()
R version 4.0.1 (2020-06-06)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 18362)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C

[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] meta_4.12-0    reshape2_1.4.4 metafor_2.4-0  Matrix_1.2-18

loaded via a namespace (and not attached):
 [1] Rcpp_1.0.4.6       lattice_0.20-41    MASS_7.3-51.6      grid_4.0.1

 [5] plyr_1.8.6         nlme_3.1-148       magrittr_1.5       stringi_1.4.6

 [9] minqa_1.2.4        nloptr_1.2.2.1     boot_1.3-25        splines_4.0.1

[13] statmod_1.4.34     lme4_1.1-23        tools_4.0.1        stringr_1.4.0

[17] CompQuadForm_1.4.3 compiler_4.0.1
>

> class(result.md)
[1] "rma.uni" "rma"
>

Thank you
Kobby

On Tue, Jun 23, 2020 at 3:24 AM Viechtbauer, Wolfgang (SP) <
wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:

> Dear Kobby,
>
> Please post the output of sessionInfo() and class(result.md).
>
> Best,
> Wolfgang
>
> >-----Original Message-----
> >From: K Amoatwi [mailto:amoatwik20 at gmail.com]
> >Sent: Monday, 22 June, 2020 22:30
> >To: Viechtbauer, Wolfgang (SP)
> >Cc: r-help at r-project.org
> >Subject: Re: [R] Error message in meta-analysis package Metafor-weights
> =""
> >
> >Hi Wolfgang and All,
> >I am still practising my meta-analysis with the "Metafor" package, I tried
> >to run the code for "Forest plot" and got error message as shown below:
> >forest(result.md)
> >> forest(result.md)
> >Error in UseMethod("forest") :
> >  no applicable method for 'forest' applied to an object of class
> >"c('rma.uni', 'rma')"
> >
> >Thank you in advance for your support
> >
> >regards
> >Kobby
> >
> >On Tue, Jun 16, 2020 at 12:50 PM Viechtbauer, Wolfgang (SP)
> ><wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> >Dear Amoatwi,
> >
> >This way of using the escalc() function has been deprecated. It might be
> >added back once there is actually any benefit from having this
> >functionality, but for years it just meant that I had to maintain two
> >different ways of doing the exact same thing without any additional
> >benefits.
> >
> >Best,
> >Wolfgang
> >
> >--
> >Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and
> >Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD
> >Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com
> >
> >>-----Original Message-----
> >>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of K
> Amoatwi
> >>Sent: Tuesday, 16 June, 2020 4:50
> >>To: r-help at r-project.org
> >>Subject: [R] Error message in meta-analysis package Metafor-weights =""
> >>
> >>Dear All,
> >>I am using the example from one of the tutorial about "Metafor" package
> and
> >>"escalc" function, to learn how this package can be applied to do
> >>meta-analysi; the code and the data is directly from the tutorials but
> >>"weights=freq" option in the escalc function is given me error message
> >>This is the code below:
> >>
> >>library(metafor) # Load package
> >>#####DATASET 1: BCG Vaccine Trials
> >>data(dat.bcg) # BCG meta-analytic dataset
> >>
> >>##Formula based Specification
> >>##That is, what if I have multiple rows per study, corresponding to
> >>difference treatment groups?
> >>
> >>library(reshape2) # Load package for data reshaping
> >>
> >>bcg.long <- melt(dat.bcg[, c("trial", "tpos", "tneg", "cpos", "cneg")],
> id
> >>= "trial")
> >>bcg.long$pos <- ifelse(bcg.long$var == "tpos" | bcg.long$var == "cpos",
> 1,
> >>0)
> >>bcg.long$group <- ifelse(bcg.long$var == "tpos" | bcg.long$var == "tneg",
> >>1, 0)
> >>
> >>##sample of the data, the first 6 rows
> >>head(bcg.long)
> >>  trial variable value pos group
> >>1     1     tpos     4     1     1
> >>2     2     tpos     6     1     1
> >>3     3     tpos     3     1     1
> >>4     4     tpos    62    1     1
> >>5     5     tpos    33    1     1
> >>6     6     tpos   180   1     1
> >>
> >>##Now applying the " escalc " function
> >>
> >>escalc(factor(pos)~factor(group)| factor(trial),weights = value,data =
> >>bcg.long, measure = "OR")
> >>
> >>##Then I got this error message
> >>Error in escalc(factor(pos) ~ factor(group) | factor(trial), weights =
> >>value,  :
> >>  object 'value' not found
> >>
> >>I used the same data with different example from another author and got a
> >>similar error message
> >>Second code with the same data but different coding
> >>Sample data
> >>
> >>with the first 6 rows of the rearranged data shown below. (T=treatment,
> >>C=Control group, Out=outcome whether positive or negative, and then
> >>frequency)
> >>    study grp out freq
> >>1        1    T    +      4
> >>2        1    T    -    119
> >>3        1    C   +      11
> >>4        1    C   -     128
> >>5        2    T   +        6
> >>6        2    T   -      300
> >>
> >>>escalc(out ~ grp | study, weights = freq, data = dat.fm, measure =
> "OR")
> >>
> >>Error in escalc(out ~ grp | study, weights = freq, data = dat.fm,
> measure =
> >>"OR") :
> >>  object 'freq' not found
> >>
> >>I am not sure what I am doing wrong since both authors were able to get
> >>their results while I am getting error messages.
> >>
> >>Any help will be very much appreciated
> >>
> >>Amoatwi
>

	[[alternative HTML version deleted]]


From m@015k3113 @end|ng |rom b|ueyonder@co@uk  Tue Jun 23 16:56:47 2020
From: m@015k3113 @end|ng |rom b|ueyonder@co@uk (Ahson)
Date: Tue, 23 Jun 2020 15:56:47 +0100
Subject: [R] Help with locating error on import of data
Message-ID: <mailman.359587.0.1592926940.1124.r-help@r-project.org>

I have imported data from an Excel file and I am getting errors:

> library(readxl)
> Balance_sheet <- read_excel("Y:/All Documents/Training/Data/Routines for consolidating all the data/Individual tables/AIM companies/Balance_sheet.xlsx", na = "")
New names:
* `` -> ...6
* `` -> ...7
* `` -> ...9
* `` -> ...10
* `` -> ...11
* ... and 22 more problems


How can I find where the error is originating? What does New names mean?

Thanks in advance for your help.


Sent from Mail for Windows 10


	[[alternative HTML version deleted]]


From m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com  Tue Jun 23 17:08:57 2020
From: m@|one @end|ng |rom m@|onequ@nt|t@t|ve@com (Patrick (Malone Quantitative))
Date: Tue, 23 Jun 2020 11:08:57 -0400
Subject: [R] Help with locating error on import of data
In-Reply-To: <20200623145701.A77DD857@hypatia.math.ethz.ch>
References: <20200623145701.A77DD857@hypatia.math.ethz.ch>
Message-ID: <CAJc=yOEt1M+u638iVbNesvwzSErszGq7Cd4DxugjUGqj+BDX9Q@mail.gmail.com>

It looks like it's looking for column names in the first row of your Excel
sheet and not finding them. What does the first row contain?

On Tue, Jun 23, 2020 at 10:57 AM Ahson via R-help <r-help at r-project.org>
wrote:

> I have imported data from an Excel file and I am getting errors:
>
> > library(readxl)
> > Balance_sheet <- read_excel("Y:/All Documents/Training/Data/Routines for
> consolidating all the data/Individual tables/AIM
> companies/Balance_sheet.xlsx", na = "")
> New names:
> * `` -> ...6
> * `` -> ...7
> * `` -> ...9
> * `` -> ...10
> * `` -> ...11
> * ... and 22 more problems
>
>
> How can I find where the error is originating? What does New names mean?
>
> Thanks in advance for your help.
>
>
> Sent from Mail for Windows 10
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Patrick S. Malone, Ph.D., Malone Quantitative
NEW Service Models: http://malonequantitative.com

He/Him/His

	[[alternative HTML version deleted]]


From wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n|  Tue Jun 23 17:17:45 2020
From: wo||g@ng@v|echtb@uer @end|ng |rom m@@@tr|chtun|ver@|ty@n| (Viechtbauer, Wolfgang (SP))
Date: Tue, 23 Jun 2020 15:17:45 +0000
Subject: [R] Error message in meta-analysis package Metafor-weights =""
In-Reply-To: <CAN5pK_3Bwpbid68k92BukW-ifSUHdWg3aaWcAgZdNwDi7FR_CQ@mail.gmail.com>
References: <CAN5pK_21tgCA_Zyuj0=0jL7Pxg4T-NS09trteXnphiOpv9EbEg@mail.gmail.com>
 <6f755e6d576e4d168d1a7da438cde545@UM-MAIL3214.unimaas.nl>
 <CAN5pK_1XGbo3ob3BhUg2sZoA5ufMv1iEgAfexHO6teg8Y3hWxw@mail.gmail.com>
 <9216960491984fc78dc1210565825f3b@UM-MAIL3214.unimaas.nl>
 <CAN5pK_3Bwpbid68k92BukW-ifSUHdWg3aaWcAgZdNwDi7FR_CQ@mail.gmail.com>
Message-ID: <c006a623417e414584c1167731ab5740@UM-MAIL3214.unimaas.nl>

You have loaded the 'meta' package after 'metafor' and then forest() will try to use the corresponding function from the meta package and not metafor. With:

metafor::forest(result.md)

it should work.

Best,
Wolfgang

>-----Original Message-----
>From: K Amoatwi [mailto:amoatwik20 at gmail.com]
>Sent: Tuesday, 23 June, 2020 16:37
>To: Viechtbauer, Wolfgang (SP)
>Cc: r-help at r-project.org
>Subject: Re: [R] Error message in meta-analysis package Metafor-weights =""
>
>Dear Wolfgang,
>I have posted the requested information you asked?for.
>
>> ?sessionInfo()
>R version 4.0.1 (2020-06-06)
>Platform: x86_64-w64-mingw32/x64 (64-bit)
>Running under: Windows 10 x64 (build 18362)
>
>Matrix products: default
>
>locale:
>[1] LC_COLLATE=English_United States.1252 ?LC_CTYPE=English_United
>States.1252
>[3] LC_MONETARY=English_United States.1252
>LC_NUMERIC=C
>[5] LC_TIME=English_United States.1252
>
>attached base packages:
>[1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base
>
>other attached packages:
>[1] meta_4.12-0 ? ?reshape2_1.4.4 metafor_2.4-0 ?Matrix_1.2-18
>
>loaded via a namespace (and not attached):
>?[1] Rcpp_1.0.4.6 ? ? ? lattice_0.20-41 ? ?MASS_7.3-
>51.6 ? ? ?grid_4.0.1
>?[5] plyr_1.8.6 ? ? ? ? nlme_3.1-
>148 ? ? ? magrittr_1.5 ? ? ? stringi_1.4.6
>?[9] minqa_1.2.4 ? ? ? ?nloptr_1.2.2.1 ? ? boot_1.3-
>25 ? ? ? ?splines_4.0.1
>[13] statmod_1.4.34 ? ? lme4_1.1-
>23 ? ? ? ?tools_4.0.1 ? ? ? ?stringr_1.4.0
>[17] CompQuadForm_1.4.3 compiler_4.0.1
>>
>
>> class(result.md)
>[1] "rma.uni" "rma"
>>
>
>Thank you
>Kobby
>
>On Tue, Jun 23, 2020 at 3:24 AM Viechtbauer, Wolfgang (SP)
><wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>Dear Kobby,
>
>Please post the output of sessionInfo() and class(result.md).
>
>Best,
>Wolfgang
>
>>-----Original Message-----
>>From: K Amoatwi [mailto:amoatwik20 at gmail.com]
>>Sent: Monday, 22 June, 2020 22:30
>>To: Viechtbauer, Wolfgang (SP)
>>Cc: r-help at r-project.org
>>Subject: Re: [R] Error message in meta-analysis package Metafor-weights =""
>>
>>Hi?Wolfgang and All,
>>I am still practising my meta-analysis with the "Metafor" package, I tried
>>to run the code for "Forest plot" and got error message as shown below:
>>forest(result.md)
>>> forest(result.md)
>>Error in UseMethod("forest") :
>>? no applicable method for 'forest' applied to an object of class
>>"c('rma.uni', 'rma')"
>>
>>Thank you in advance for your support
>>
>>regards
>>Kobby
>>
>>On Tue, Jun 16, 2020 at 12:50 PM Viechtbauer, Wolfgang (SP)
>><wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>>Dear Amoatwi,
>>
>>This way of using the escalc() function has been deprecated. It might be
>>added back once there is actually any benefit from having this
>>functionality, but for years it just meant that I had to maintain two
>>different ways of doing the exact same thing without any additional
>>benefits.
>>
>>Best,
>>Wolfgang
>>
>>--
>>Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and
>>Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD
>>Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com
>>
>>>-----Original Message-----
>>>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of K Amoatwi
>>>Sent: Tuesday, 16 June, 2020 4:50
>>>To: r-help at r-project.org
>>>Subject: [R] Error message in meta-analysis package Metafor-weights =""
>>>
>>>Dear All,
>>>I am using the example from one of the tutorial about "Metafor" package
>and
>>>"escalc" function, to learn how this package can be applied to do
>>>meta-analysi; the code and the data is directly from the tutorials but
>>>"weights=freq" option in the escalc function is given me error message
>>>This is the code below:
>>>
>>>library(metafor) # Load package
>>>#####DATASET 1: BCG Vaccine Trials
>>>data(dat.bcg) # BCG meta-analytic dataset
>>>
>>>##Formula based Specification
>>>##That is, what if I have multiple rows per study, corresponding to
>>>difference treatment groups?
>>>
>>>library(reshape2) # Load package for data reshaping
>>>
>>>bcg.long <- melt(dat.bcg[, c("trial", "tpos", "tneg", "cpos", "cneg")], id
>>>= "trial")
>>>bcg.long$pos <- ifelse(bcg.long$var == "tpos" | bcg.long$var == "cpos", 1,
>>>0)
>>>bcg.long$group <- ifelse(bcg.long$var == "tpos" | bcg.long$var == "tneg",
>>>1, 0)
>>>
>>>##sample of the data, the first 6 rows
>>>head(bcg.long)
>>>? trial variable value pos group
>>>1? ? ?1? ? ?tpos? ? ?4? ? ?1? ? ?1
>>>2? ? ?2? ? ?tpos? ? ?6? ? ?1? ? ?1
>>>3? ? ?3? ? ?tpos? ? ?3? ? ?1? ? ?1
>>>4? ? ?4? ? ?tpos? ? 62? ? 1? ? ?1
>>>5? ? ?5? ? ?tpos? ? 33? ? 1? ? ?1
>>>6? ? ?6? ? ?tpos? ?180? ?1? ? ?1
>>>
>>>##Now applying the " escalc " function
>>>
>>>escalc(factor(pos)~factor(group)| factor(trial),weights = value,data =
>>>bcg.long, measure = "OR")
>>>
>>>##Then I got this error message
>>>Error in escalc(factor(pos) ~ factor(group) | factor(trial), weights =
>>>value,? :
>>>? object 'value' not found
>>>
>>>I used the same data with different example from another author and got a
>>>similar error message
>>>Second code with the same data but different coding
>>>Sample data
>>>
>>>with the first 6 rows of the rearranged data shown below. (T=treatment,
>>>C=Control group, Out=outcome whether positive or negative, and then
>>>frequency)
>>>? ? study grp out freq
>>>1? ? ? ? 1? ? T? ? +? ? ? 4
>>>2? ? ? ? 1? ? T? ? -? ? 119
>>>3? ? ? ? 1? ? C? ?+? ? ? 11
>>>4? ? ? ? 1? ? C? ?-? ? ?128
>>>5? ? ? ? 2? ? T? ?+? ? ? ? 6
>>>6? ? ? ? 2? ? T? ?-? ? ? 300
>>>
>>>>escalc(out ~ grp | study, weights = freq, data = dat.fm, measure = "OR")
>>>
>>>Error in escalc(out ~ grp | study, weights = freq, data = dat.fm, measure
>=
>>>"OR") :
>>>? object 'freq' not found
>>>
>>>I am not sure what I am doing wrong since both authors were able to get
>>>their results while I am getting error messages.
>>>
>>>Any help will be very much appreciated
>>>
>>>Amoatwi

From @mo@tw|k20 @end|ng |rom gm@||@com  Tue Jun 23 17:29:46 2020
From: @mo@tw|k20 @end|ng |rom gm@||@com (K Amoatwi)
Date: Tue, 23 Jun 2020 11:29:46 -0400
Subject: [R] Error message in meta-analysis package Metafor-weights =""
In-Reply-To: <c006a623417e414584c1167731ab5740@UM-MAIL3214.unimaas.nl>
References: <CAN5pK_21tgCA_Zyuj0=0jL7Pxg4T-NS09trteXnphiOpv9EbEg@mail.gmail.com>
 <6f755e6d576e4d168d1a7da438cde545@UM-MAIL3214.unimaas.nl>
 <CAN5pK_1XGbo3ob3BhUg2sZoA5ufMv1iEgAfexHO6teg8Y3hWxw@mail.gmail.com>
 <9216960491984fc78dc1210565825f3b@UM-MAIL3214.unimaas.nl>
 <CAN5pK_3Bwpbid68k92BukW-ifSUHdWg3aaWcAgZdNwDi7FR_CQ@mail.gmail.com>
 <c006a623417e414584c1167731ab5740@UM-MAIL3214.unimaas.nl>
Message-ID: <CAN5pK_1rUAGgjFbd_JP1cZTDQaXFtvafOaiKgr4HBA-9e+F9FA@mail.gmail.com>

Dear Wolfgang,
Yes! The "metafor::forest(result.md)" works

Thank you very much.

Any reason why "forest(result.md)" was not working?

Kobby

On Tue, Jun 23, 2020 at 11:18 AM Viechtbauer, Wolfgang (SP) <
wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:

> You have loaded the 'meta' package after 'metafor' and then forest() will
> try to use the corresponding function from the meta package and not
> metafor. With:
>
> metafor::forest(result.md)
>
> it should work.
>
> Best,
> Wolfgang
>
> >-----Original Message-----
> >From: K Amoatwi [mailto:amoatwik20 at gmail.com]
> >Sent: Tuesday, 23 June, 2020 16:37
> >To: Viechtbauer, Wolfgang (SP)
> >Cc: r-help at r-project.org
> >Subject: Re: [R] Error message in meta-analysis package Metafor-weights
> =""
> >
> >Dear Wolfgang,
> >I have posted the requested information you asked for.
> >
> >>  sessionInfo()
> >R version 4.0.1 (2020-06-06)
> >Platform: x86_64-w64-mingw32/x64 (64-bit)
> >Running under: Windows 10 x64 (build 18362)
> >
> >Matrix products: default
> >
> >locale:
> >[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> >States.1252
> >[3] LC_MONETARY=English_United States.1252
> >LC_NUMERIC=C
> >[5] LC_TIME=English_United States.1252
> >
> >attached base packages:
> >[1] stats     graphics  grDevices utils     datasets  methods   base
> >
> >other attached packages:
> >[1] meta_4.12-0    reshape2_1.4.4 metafor_2.4-0  Matrix_1.2-18
> >
> >loaded via a namespace (and not attached):
> > [1] Rcpp_1.0.4.6       lattice_0.20-41    MASS_7.3-
> >51.6      grid_4.0.1
> > [5] plyr_1.8.6         nlme_3.1-
> >148       magrittr_1.5       stringi_1.4.6
> > [9] minqa_1.2.4        nloptr_1.2.2.1     boot_1.3-
> >25        splines_4.0.1
> >[13] statmod_1.4.34     lme4_1.1-
> >23        tools_4.0.1        stringr_1.4.0
> >[17] CompQuadForm_1.4.3 compiler_4.0.1
> >>
> >
> >> class(result.md)
> >[1] "rma.uni" "rma"
> >>
> >
> >Thank you
> >Kobby
> >
> >On Tue, Jun 23, 2020 at 3:24 AM Viechtbauer, Wolfgang (SP)
> ><wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> >Dear Kobby,
> >
> >Please post the output of sessionInfo() and class(result.md).
> >
> >Best,
> >Wolfgang
> >
> >>-----Original Message-----
> >>From: K Amoatwi [mailto:amoatwik20 at gmail.com]
> >>Sent: Monday, 22 June, 2020 22:30
> >>To: Viechtbauer, Wolfgang (SP)
> >>Cc: r-help at r-project.org
> >>Subject: Re: [R] Error message in meta-analysis package Metafor-weights
> =""
> >>
> >>Hi Wolfgang and All,
> >>I am still practising my meta-analysis with the "Metafor" package, I
> tried
> >>to run the code for "Forest plot" and got error message as shown below:
> >>forest(result.md)
> >>> forest(result.md)
> >>Error in UseMethod("forest") :
> >>  no applicable method for 'forest' applied to an object of class
> >>"c('rma.uni', 'rma')"
> >>
> >>Thank you in advance for your support
> >>
> >>regards
> >>Kobby
> >>
> >>On Tue, Jun 16, 2020 at 12:50 PM Viechtbauer, Wolfgang (SP)
> >><wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> >>Dear Amoatwi,
> >>
> >>This way of using the escalc() function has been deprecated. It might be
> >>added back once there is actually any benefit from having this
> >>functionality, but for years it just meant that I had to maintain two
> >>different ways of doing the exact same thing without any additional
> >>benefits.
> >>
> >>Best,
> >>Wolfgang
> >>
> >>--
> >>Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and
> >>Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD
> >>Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com
> >>
> >>>-----Original Message-----
> >>>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of K
> Amoatwi
> >>>Sent: Tuesday, 16 June, 2020 4:50
> >>>To: r-help at r-project.org
> >>>Subject: [R] Error message in meta-analysis package Metafor-weights =""
> >>>
> >>>Dear All,
> >>>I am using the example from one of the tutorial about "Metafor" package
> >and
> >>>"escalc" function, to learn how this package can be applied to do
> >>>meta-analysi; the code and the data is directly from the tutorials but
> >>>"weights=freq" option in the escalc function is given me error message
> >>>This is the code below:
> >>>
> >>>library(metafor) # Load package
> >>>#####DATASET 1: BCG Vaccine Trials
> >>>data(dat.bcg) # BCG meta-analytic dataset
> >>>
> >>>##Formula based Specification
> >>>##That is, what if I have multiple rows per study, corresponding to
> >>>difference treatment groups?
> >>>
> >>>library(reshape2) # Load package for data reshaping
> >>>
> >>>bcg.long <- melt(dat.bcg[, c("trial", "tpos", "tneg", "cpos", "cneg")],
> id
> >>>= "trial")
> >>>bcg.long$pos <- ifelse(bcg.long$var == "tpos" | bcg.long$var == "cpos",
> 1,
> >>>0)
> >>>bcg.long$group <- ifelse(bcg.long$var == "tpos" | bcg.long$var ==
> "tneg",
> >>>1, 0)
> >>>
> >>>##sample of the data, the first 6 rows
> >>>head(bcg.long)
> >>>  trial variable value pos group
> >>>1     1     tpos     4     1     1
> >>>2     2     tpos     6     1     1
> >>>3     3     tpos     3     1     1
> >>>4     4     tpos    62    1     1
> >>>5     5     tpos    33    1     1
> >>>6     6     tpos   180   1     1
> >>>
> >>>##Now applying the " escalc " function
> >>>
> >>>escalc(factor(pos)~factor(group)| factor(trial),weights = value,data =
> >>>bcg.long, measure = "OR")
> >>>
> >>>##Then I got this error message
> >>>Error in escalc(factor(pos) ~ factor(group) | factor(trial), weights =
> >>>value,  :
> >>>  object 'value' not found
> >>>
> >>>I used the same data with different example from another author and got
> a
> >>>similar error message
> >>>Second code with the same data but different coding
> >>>Sample data
> >>>
> >>>with the first 6 rows of the rearranged data shown below. (T=treatment,
> >>>C=Control group, Out=outcome whether positive or negative, and then
> >>>frequency)
> >>>    study grp out freq
> >>>1        1    T    +      4
> >>>2        1    T    -    119
> >>>3        1    C   +      11
> >>>4        1    C   -     128
> >>>5        2    T   +        6
> >>>6        2    T   -      300
> >>>
> >>>>escalc(out ~ grp | study, weights = freq, data = dat.fm, measure =
> "OR")
> >>>
> >>>Error in escalc(out ~ grp | study, weights = freq, data = dat.fm,
> measure
> >=
> >>>"OR") :
> >>>  object 'freq' not found
> >>>
> >>>I am not sure what I am doing wrong since both authors were able to get
> >>>their results while I am getting error messages.
> >>>
> >>>Any help will be very much appreciated
> >>>
> >>>Amoatwi
>

	[[alternative HTML version deleted]]


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Tue Jun 23 17:39:45 2020
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Tue, 23 Jun 2020 16:39:45 +0100
Subject: [R] Error message in meta-analysis package Metafor-weights =""
In-Reply-To: <CAN5pK_1rUAGgjFbd_JP1cZTDQaXFtvafOaiKgr4HBA-9e+F9FA@mail.gmail.com>
References: <CAN5pK_21tgCA_Zyuj0=0jL7Pxg4T-NS09trteXnphiOpv9EbEg@mail.gmail.com>
 <6f755e6d576e4d168d1a7da438cde545@UM-MAIL3214.unimaas.nl>
 <CAN5pK_1XGbo3ob3BhUg2sZoA5ufMv1iEgAfexHO6teg8Y3hWxw@mail.gmail.com>
 <9216960491984fc78dc1210565825f3b@UM-MAIL3214.unimaas.nl>
 <CAN5pK_3Bwpbid68k92BukW-ifSUHdWg3aaWcAgZdNwDi7FR_CQ@mail.gmail.com>
 <c006a623417e414584c1167731ab5740@UM-MAIL3214.unimaas.nl>
 <CAN5pK_1rUAGgjFbd_JP1cZTDQaXFtvafOaiKgr4HBA-9e+F9FA@mail.gmail.com>
Message-ID: <a32257d5-5a7f-bad4-2613-8820844814ce@dewey.myzen.co.uk>

The two packages both define a function forest. When you load the second 
package R will have told you that it was masking the definition of 
forest from the first package. If you had loaded them in the other order 
it would have masked the other one.

In fact it masked seven functions in total in this case as the message 
told you.

Michael

On 23/06/2020 16:29, K Amoatwi wrote:
> Dear Wolfgang,
> Yes! The "metafor::forest(result.md)" works
> 
> Thank you very much.
> 
> Any reason why "forest(result.md)" was not working?
> 
> Kobby
> 
> On Tue, Jun 23, 2020 at 11:18 AM Viechtbauer, Wolfgang (SP) <
> wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> 
>> You have loaded the 'meta' package after 'metafor' and then forest() will
>> try to use the corresponding function from the meta package and not
>> metafor. With:
>>
>> metafor::forest(result.md)
>>
>> it should work.
>>
>> Best,
>> Wolfgang
>>
>>> -----Original Message-----
>>> From: K Amoatwi [mailto:amoatwik20 at gmail.com]
>>> Sent: Tuesday, 23 June, 2020 16:37
>>> To: Viechtbauer, Wolfgang (SP)
>>> Cc: r-help at r-project.org
>>> Subject: Re: [R] Error message in meta-analysis package Metafor-weights
>> =""
>>>
>>> Dear Wolfgang,
>>> I have posted the requested information you asked for.
>>>
>>>>   sessionInfo()
>>> R version 4.0.1 (2020-06-06)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>> Running under: Windows 10 x64 (build 18362)
>>>
>>> Matrix products: default
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>>> States.1252
>>> [3] LC_MONETARY=English_United States.1252
>>> LC_NUMERIC=C
>>> [5] LC_TIME=English_United States.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] meta_4.12-0    reshape2_1.4.4 metafor_2.4-0  Matrix_1.2-18
>>>
>>> loaded via a namespace (and not attached):
>>> [1] Rcpp_1.0.4.6       lattice_0.20-41    MASS_7.3-
>>> 51.6      grid_4.0.1
>>> [5] plyr_1.8.6         nlme_3.1-
>>> 148       magrittr_1.5       stringi_1.4.6
>>> [9] minqa_1.2.4        nloptr_1.2.2.1     boot_1.3-
>>> 25        splines_4.0.1
>>> [13] statmod_1.4.34     lme4_1.1-
>>> 23        tools_4.0.1        stringr_1.4.0
>>> [17] CompQuadForm_1.4.3 compiler_4.0.1
>>>>
>>>
>>>> class(result.md)
>>> [1] "rma.uni" "rma"
>>>>
>>>
>>> Thank you
>>> Kobby
>>>
>>> On Tue, Jun 23, 2020 at 3:24 AM Viechtbauer, Wolfgang (SP)
>>> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>>> Dear Kobby,
>>>
>>> Please post the output of sessionInfo() and class(result.md).
>>>
>>> Best,
>>> Wolfgang
>>>
>>>> -----Original Message-----
>>>> From: K Amoatwi [mailto:amoatwik20 at gmail.com]
>>>> Sent: Monday, 22 June, 2020 22:30
>>>> To: Viechtbauer, Wolfgang (SP)
>>>> Cc: r-help at r-project.org
>>>> Subject: Re: [R] Error message in meta-analysis package Metafor-weights
>> =""
>>>>
>>>> Hi Wolfgang and All,
>>>> I am still practising my meta-analysis with the "Metafor" package, I
>> tried
>>>> to run the code for "Forest plot" and got error message as shown below:
>>>> forest(result.md)
>>>>> forest(result.md)
>>>> Error in UseMethod("forest") :
>>>>   no applicable method for 'forest' applied to an object of class
>>>> "c('rma.uni', 'rma')"
>>>>
>>>> Thank you in advance for your support
>>>>
>>>> regards
>>>> Kobby
>>>>
>>>> On Tue, Jun 16, 2020 at 12:50 PM Viechtbauer, Wolfgang (SP)
>>>> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
>>>> Dear Amoatwi,
>>>>
>>>> This way of using the escalc() function has been deprecated. It might be
>>>> added back once there is actually any benefit from having this
>>>> functionality, but for years it just meant that I had to maintain two
>>>> different ways of doing the exact same thing without any additional
>>>> benefits.
>>>>
>>>> Best,
>>>> Wolfgang
>>>>
>>>> --
>>>> Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and
>>>> Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD
>>>> Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com
>>>>
>>>>> -----Original Message-----
>>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of K
>> Amoatwi
>>>>> Sent: Tuesday, 16 June, 2020 4:50
>>>>> To: r-help at r-project.org
>>>>> Subject: [R] Error message in meta-analysis package Metafor-weights =""
>>>>>
>>>>> Dear All,
>>>>> I am using the example from one of the tutorial about "Metafor" package
>>> and
>>>>> "escalc" function, to learn how this package can be applied to do
>>>>> meta-analysi; the code and the data is directly from the tutorials but
>>>>> "weights=freq" option in the escalc function is given me error message
>>>>> This is the code below:
>>>>>
>>>>> library(metafor) # Load package
>>>>> #####DATASET 1: BCG Vaccine Trials
>>>>> data(dat.bcg) # BCG meta-analytic dataset
>>>>>
>>>>> ##Formula based Specification
>>>>> ##That is, what if I have multiple rows per study, corresponding to
>>>>> difference treatment groups?
>>>>>
>>>>> library(reshape2) # Load package for data reshaping
>>>>>
>>>>> bcg.long <- melt(dat.bcg[, c("trial", "tpos", "tneg", "cpos", "cneg")],
>> id
>>>>> = "trial")
>>>>> bcg.long$pos <- ifelse(bcg.long$var == "tpos" | bcg.long$var == "cpos",
>> 1,
>>>>> 0)
>>>>> bcg.long$group <- ifelse(bcg.long$var == "tpos" | bcg.long$var ==
>> "tneg",
>>>>> 1, 0)
>>>>>
>>>>> ##sample of the data, the first 6 rows
>>>>> head(bcg.long)
>>>>>   trial variable value pos group
>>>>> 1     1     tpos     4     1     1
>>>>> 2     2     tpos     6     1     1
>>>>> 3     3     tpos     3     1     1
>>>>> 4     4     tpos    62    1     1
>>>>> 5     5     tpos    33    1     1
>>>>> 6     6     tpos   180   1     1
>>>>>
>>>>> ##Now applying the " escalc " function
>>>>>
>>>>> escalc(factor(pos)~factor(group)| factor(trial),weights = value,data =
>>>>> bcg.long, measure = "OR")
>>>>>
>>>>> ##Then I got this error message
>>>>> Error in escalc(factor(pos) ~ factor(group) | factor(trial), weights =
>>>>> value,  :
>>>>>   object 'value' not found
>>>>>
>>>>> I used the same data with different example from another author and got
>> a
>>>>> similar error message
>>>>> Second code with the same data but different coding
>>>>> Sample data
>>>>>
>>>>> with the first 6 rows of the rearranged data shown below. (T=treatment,
>>>>> C=Control group, Out=outcome whether positive or negative, and then
>>>>> frequency)
>>>>>     study grp out freq
>>>>> 1        1    T    +      4
>>>>> 2        1    T    -    119
>>>>> 3        1    C   +      11
>>>>> 4        1    C   -     128
>>>>> 5        2    T   +        6
>>>>> 6        2    T   -      300
>>>>>
>>>>>> escalc(out ~ grp | study, weights = freq, data = dat.fm, measure =
>> "OR")
>>>>>
>>>>> Error in escalc(out ~ grp | study, weights = freq, data = dat.fm,
>> measure
>>> =
>>>>> "OR") :
>>>>>   object 'freq' not found
>>>>>
>>>>> I am not sure what I am doing wrong since both authors were able to get
>>>>> their results while I am getting error messages.
>>>>>
>>>>> Any help will be very much appreciated
>>>>>
>>>>> Amoatwi
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From @mo@tw|k20 @end|ng |rom gm@||@com  Tue Jun 23 17:58:28 2020
From: @mo@tw|k20 @end|ng |rom gm@||@com (K Amoatwi)
Date: Tue, 23 Jun 2020 11:58:28 -0400
Subject: [R] Error message in meta-analysis package Metafor-weights =""
In-Reply-To: <a32257d5-5a7f-bad4-2613-8820844814ce@dewey.myzen.co.uk>
References: <CAN5pK_21tgCA_Zyuj0=0jL7Pxg4T-NS09trteXnphiOpv9EbEg@mail.gmail.com>
 <6f755e6d576e4d168d1a7da438cde545@UM-MAIL3214.unimaas.nl>
 <CAN5pK_1XGbo3ob3BhUg2sZoA5ufMv1iEgAfexHO6teg8Y3hWxw@mail.gmail.com>
 <9216960491984fc78dc1210565825f3b@UM-MAIL3214.unimaas.nl>
 <CAN5pK_3Bwpbid68k92BukW-ifSUHdWg3aaWcAgZdNwDi7FR_CQ@mail.gmail.com>
 <c006a623417e414584c1167731ab5740@UM-MAIL3214.unimaas.nl>
 <CAN5pK_1rUAGgjFbd_JP1cZTDQaXFtvafOaiKgr4HBA-9e+F9FA@mail.gmail.com>
 <a32257d5-5a7f-bad4-2613-8820844814ce@dewey.myzen.co.uk>
Message-ID: <CAN5pK_2XAxT8_jWB9cWZ7y--51eAW46h3Ns0u3bReS5rAT1JNw@mail.gmail.com>

Thank Michael and Wolfgang, very much appreciated.

Kobby

On Tue, Jun 23, 2020 at 11:39 AM Michael Dewey <lists at dewey.myzen.co.uk>
wrote:

> The two packages both define a function forest. When you load the second
> package R will have told you that it was masking the definition of
> forest from the first package. If you had loaded them in the other order
> it would have masked the other one.
>
> In fact it masked seven functions in total in this case as the message
> told you.
>
> Michael
>
> On 23/06/2020 16:29, K Amoatwi wrote:
> > Dear Wolfgang,
> > Yes! The "metafor::forest(result.md)" works
> >
> > Thank you very much.
> >
> > Any reason why "forest(result.md)" was not working?
> >
> > Kobby
> >
> > On Tue, Jun 23, 2020 at 11:18 AM Viechtbauer, Wolfgang (SP) <
> > wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> >
> >> You have loaded the 'meta' package after 'metafor' and then forest()
> will
> >> try to use the corresponding function from the meta package and not
> >> metafor. With:
> >>
> >> metafor::forest(result.md)
> >>
> >> it should work.
> >>
> >> Best,
> >> Wolfgang
> >>
> >>> -----Original Message-----
> >>> From: K Amoatwi [mailto:amoatwik20 at gmail.com]
> >>> Sent: Tuesday, 23 June, 2020 16:37
> >>> To: Viechtbauer, Wolfgang (SP)
> >>> Cc: r-help at r-project.org
> >>> Subject: Re: [R] Error message in meta-analysis package Metafor-weights
> >> =""
> >>>
> >>> Dear Wolfgang,
> >>> I have posted the requested information you asked for.
> >>>
> >>>>   sessionInfo()
> >>> R version 4.0.1 (2020-06-06)
> >>> Platform: x86_64-w64-mingw32/x64 (64-bit)
> >>> Running under: Windows 10 x64 (build 18362)
> >>>
> >>> Matrix products: default
> >>>
> >>> locale:
> >>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> >>> States.1252
> >>> [3] LC_MONETARY=English_United States.1252
> >>> LC_NUMERIC=C
> >>> [5] LC_TIME=English_United States.1252
> >>>
> >>> attached base packages:
> >>> [1] stats     graphics  grDevices utils     datasets  methods   base
> >>>
> >>> other attached packages:
> >>> [1] meta_4.12-0    reshape2_1.4.4 metafor_2.4-0  Matrix_1.2-18
> >>>
> >>> loaded via a namespace (and not attached):
> >>> [1] Rcpp_1.0.4.6       lattice_0.20-41    MASS_7.3-
> >>> 51.6      grid_4.0.1
> >>> [5] plyr_1.8.6         nlme_3.1-
> >>> 148       magrittr_1.5       stringi_1.4.6
> >>> [9] minqa_1.2.4        nloptr_1.2.2.1     boot_1.3-
> >>> 25        splines_4.0.1
> >>> [13] statmod_1.4.34     lme4_1.1-
> >>> 23        tools_4.0.1        stringr_1.4.0
> >>> [17] CompQuadForm_1.4.3 compiler_4.0.1
> >>>>
> >>>
> >>>> class(result.md)
> >>> [1] "rma.uni" "rma"
> >>>>
> >>>
> >>> Thank you
> >>> Kobby
> >>>
> >>> On Tue, Jun 23, 2020 at 3:24 AM Viechtbauer, Wolfgang (SP)
> >>> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> >>> Dear Kobby,
> >>>
> >>> Please post the output of sessionInfo() and class(result.md).
> >>>
> >>> Best,
> >>> Wolfgang
> >>>
> >>>> -----Original Message-----
> >>>> From: K Amoatwi [mailto:amoatwik20 at gmail.com]
> >>>> Sent: Monday, 22 June, 2020 22:30
> >>>> To: Viechtbauer, Wolfgang (SP)
> >>>> Cc: r-help at r-project.org
> >>>> Subject: Re: [R] Error message in meta-analysis package
> Metafor-weights
> >> =""
> >>>>
> >>>> Hi Wolfgang and All,
> >>>> I am still practising my meta-analysis with the "Metafor" package, I
> >> tried
> >>>> to run the code for "Forest plot" and got error message as shown
> below:
> >>>> forest(result.md)
> >>>>> forest(result.md)
> >>>> Error in UseMethod("forest") :
> >>>>   no applicable method for 'forest' applied to an object of class
> >>>> "c('rma.uni', 'rma')"
> >>>>
> >>>> Thank you in advance for your support
> >>>>
> >>>> regards
> >>>> Kobby
> >>>>
> >>>> On Tue, Jun 16, 2020 at 12:50 PM Viechtbauer, Wolfgang (SP)
> >>>> <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:
> >>>> Dear Amoatwi,
> >>>>
> >>>> This way of using the escalc() function has been deprecated. It might
> be
> >>>> added back once there is actually any benefit from having this
> >>>> functionality, but for years it just meant that I had to maintain two
> >>>> different ways of doing the exact same thing without any additional
> >>>> benefits.
> >>>>
> >>>> Best,
> >>>> Wolfgang
> >>>>
> >>>> --
> >>>> Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry
> and
> >>>> Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200
> MD
> >>>> Maastricht, The Netherlands | +31 (43) 388-4170 |
> http://www.wvbauer.com
> >>>>
> >>>>> -----Original Message-----
> >>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of K
> >> Amoatwi
> >>>>> Sent: Tuesday, 16 June, 2020 4:50
> >>>>> To: r-help at r-project.org
> >>>>> Subject: [R] Error message in meta-analysis package Metafor-weights
> =""
> >>>>>
> >>>>> Dear All,
> >>>>> I am using the example from one of the tutorial about "Metafor"
> package
> >>> and
> >>>>> "escalc" function, to learn how this package can be applied to do
> >>>>> meta-analysi; the code and the data is directly from the tutorials
> but
> >>>>> "weights=freq" option in the escalc function is given me error
> message
> >>>>> This is the code below:
> >>>>>
> >>>>> library(metafor) # Load package
> >>>>> #####DATASET 1: BCG Vaccine Trials
> >>>>> data(dat.bcg) # BCG meta-analytic dataset
> >>>>>
> >>>>> ##Formula based Specification
> >>>>> ##That is, what if I have multiple rows per study, corresponding to
> >>>>> difference treatment groups?
> >>>>>
> >>>>> library(reshape2) # Load package for data reshaping
> >>>>>
> >>>>> bcg.long <- melt(dat.bcg[, c("trial", "tpos", "tneg", "cpos",
> "cneg")],
> >> id
> >>>>> = "trial")
> >>>>> bcg.long$pos <- ifelse(bcg.long$var == "tpos" | bcg.long$var ==
> "cpos",
> >> 1,
> >>>>> 0)
> >>>>> bcg.long$group <- ifelse(bcg.long$var == "tpos" | bcg.long$var ==
> >> "tneg",
> >>>>> 1, 0)
> >>>>>
> >>>>> ##sample of the data, the first 6 rows
> >>>>> head(bcg.long)
> >>>>>   trial variable value pos group
> >>>>> 1     1     tpos     4     1     1
> >>>>> 2     2     tpos     6     1     1
> >>>>> 3     3     tpos     3     1     1
> >>>>> 4     4     tpos    62    1     1
> >>>>> 5     5     tpos    33    1     1
> >>>>> 6     6     tpos   180   1     1
> >>>>>
> >>>>> ##Now applying the " escalc " function
> >>>>>
> >>>>> escalc(factor(pos)~factor(group)| factor(trial),weights = value,data
> =
> >>>>> bcg.long, measure = "OR")
> >>>>>
> >>>>> ##Then I got this error message
> >>>>> Error in escalc(factor(pos) ~ factor(group) | factor(trial), weights
> =
> >>>>> value,  :
> >>>>>   object 'value' not found
> >>>>>
> >>>>> I used the same data with different example from another author and
> got
> >> a
> >>>>> similar error message
> >>>>> Second code with the same data but different coding
> >>>>> Sample data
> >>>>>
> >>>>> with the first 6 rows of the rearranged data shown below.
> (T=treatment,
> >>>>> C=Control group, Out=outcome whether positive or negative, and then
> >>>>> frequency)
> >>>>>     study grp out freq
> >>>>> 1        1    T    +      4
> >>>>> 2        1    T    -    119
> >>>>> 3        1    C   +      11
> >>>>> 4        1    C   -     128
> >>>>> 5        2    T   +        6
> >>>>> 6        2    T   -      300
> >>>>>
> >>>>>> escalc(out ~ grp | study, weights = freq, data = dat.fm, measure =
> >> "OR")
> >>>>>
> >>>>> Error in escalc(out ~ grp | study, weights = freq, data = dat.fm,
> >> measure
> >>> =
> >>>>> "OR") :
> >>>>>   object 'freq' not found
> >>>>>
> >>>>> I am not sure what I am doing wrong since both authors were able to
> get
> >>>>> their results while I am getting error messages.
> >>>>>
> >>>>> Any help will be very much appreciated
> >>>>>
> >>>>> Amoatwi
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Jun 23 18:24:44 2020
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 23 Jun 2020 17:24:44 +0100
Subject: [R] Help with locating error on import of data
In-Reply-To: <20200623145702.F2B08DFF@hypatia.math.ethz.ch>
References: <20200623145702.F2B08DFF@hypatia.math.ethz.ch>
Message-ID: <d1065f1e-98b7-e20e-9118-96ad626a737e@sapo.pt>

Hello,

Try setting argument col.names = FALSE, it seems that the function is 
not find column headers and is choosing its own.


Balance_sheet <- read_excel("Y:/All Documents/Training/Data/Routines for 
consolidating all the data/Individual tables/AIM 
companies/Balance_sheet.xlsx", na = "", col_names = FALSE)


Hope this helps,

Rui Barradas

?s 15:56 de 23/06/2020, Ahson via R-help escreveu:
> I have imported data from an Excel file and I am getting errors:
>
>> library(readxl)
>> Balance_sheet <- read_excel("Y:/All Documents/Training/Data/Routines for consolidating all the data/Individual tables/AIM companies/Balance_sheet.xlsx", na = "")
> New names:
> * `` -> ...6
> * `` -> ...7
> * `` -> ...9
> * `` -> ...10
> * `` -> ...11
> * ... and 22 more problems
>
>
> How can I find where the error is originating? What does New names mean?
>
> Thanks in advance for your help.
>
>
> Sent from Mail for Windows 10
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Este e-mail foi verificado em termos de v?rus pelo software antiv?rus Avast.
https://www.avast.com/antivirus


From g@@@powe|| @end|ng |rom protonm@||@com  Tue Jun 23 07:13:32 2020
From: g@@@powe|| @end|ng |rom protonm@||@com (Gregg)
Date: Tue, 23 Jun 2020 05:13:32 +0000
Subject: [R] How to convert column from millisecond epoch time to yyyy-mm-dd
 GMT
Message-ID: <jsk0wxJfI0qRk9-N10ALg9OxpVLFiCM7fCSiyGXC7Hu5E0TfgKQGxPTLA_vd4oo46_PsL0KvcHuUwrPHbc91GqrPaYrcqe2Qbupkstjcr_k=@protonmail.com>

Hello to all the smart people out there....

I have a data.frame labeled itsm_service_type_field. I need to convert the Timestamp field which is epoch time in milliseconds to a yyyy-mm-dd GMT Date.?

Data.frame format is below.

I've attempted to use the lapply and as.POSIXct functions to convert the time field in the original data.frame to a new data.frame I've labeled "itsm_service_type_field_adjusted_time",
but I've got the order and syntax wrong.

Help would be so much appreciated.

Thanks in advance.
Gregg
Arizona

Details - See Below:

itsm_service_type_field <- fread("itsm_service_type_2018-2019_CONUS.csv")

>>>>>>>>>>>>>???????????itsm_service_type_field_adjusted_time <- lapply(itsm_service_type_field[ , Timestamp], as.POSIXct(Timestamp, origin="1970-01-01", tz="GMT"))

head(itsm_service_type_field)
? ? Id? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Timestamp? ? ? ? ?Data Type Visibility? ? ? ? ? ? ? ? ? ? ? TYPE_SERVICE
1: INCBR0005072277 1577059200000 itsm-ticket U&FOUO&USA??????????? 0
2: INCBR0005073034 1577059200000 itsm-ticket U&FOUO&USA??????????? 1
3: INCBR0005073131 1577059200000 itsm-ticket U&FOUO&USA??????????? 0
4: INCBR0005074186 1577059200000 itsm-ticket U&FOUO&USA??????????? 0
5: INCBR0005074188 1577059200000 itsm-ticket U&FOUO&USA??????????? 0
6: INCBR0005074546 1577059200000 itsm-ticket U&FOUO&USA??????????? 0
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 477 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200623/b4584a9c/attachment.sig>

From @dr|@n@@c@ro||n@@@cero @end|ng |rom gm@||@com  Tue Jun 23 14:59:48 2020
From: @dr|@n@@c@ro||n@@@cero @end|ng |rom gm@||@com (Adriana Acero)
Date: Tue, 23 Jun 2020 08:59:48 -0400
Subject: [R] RLQ and data.frame scores PCA
Message-ID: <CAKrVO18cbL8deXgJdUQ=N3XMTui7KxtQzycLS5RkKcevGE+6fg@mail.gmail.com>

Hi everybody,

My name is Adriana and I'm working with Community Ecology and Geometric
morphometric of bats.

At this moment, I'm trying to perform an RLQ analysis with ADE4, with a
data frame that already contains the mean shape scores (PCA) of some
species of bats (Matriz Q).

I couldn't do the PCA into ADE4 because I'm working with landmarks and the
structure of the data is a multidimensional array, so the PCA comes from
Geomorph. I save only the scores in a data frame. I'm searching on the
internet for solutions but I don't find How to do an RLQ with my data.frame
or how to transform it in a dudi object without doing an extra analysis.

I appreciate your help.

Thanks

Adriana Acero

	[[alternative HTML version deleted]]


From rog@njord@n23 @end|ng |rom gm@||@com  Tue Jun 23 19:09:43 2020
From: rog@njord@n23 @end|ng |rom gm@||@com (Jordan Rogan)
Date: Tue, 23 Jun 2020 11:09:43 -0600
Subject: [R] How to create path for OpenBUGS into R using R2OpenBUGS with
 new Wineskin-Winery 1.8.4.1/Wineskin2.9.06-1 on MacOS Catalina 10.15.5
Message-ID: <CA+PynfkAQ128HK718a6KOZFYHaPxMXoCOpGbDXTJP0XM46LUUA@mail.gmail.com>

Hi!

I recently downloaded the new Wineskin-Winery 1.8.4.1/Wineskin2.9.06-1 onto
my mac adapted for the limitations for MacOS Catalina 10.15.5 that caused
old versions of Wine to no longer work. I downloaded it so that I could
download the Windows program OpenBUGS and use R2openBUGS in R to use the
program. I am not very experienced with R, and I am trying to figure out
how to call OpenBUGS into R with R2OpenBUGS with the new
wineskin/wineskin-winery version. I found older code using the Wine
argument in R2OpenBuGS, but I think the path has significantly changed with
the new version of Wineskin which is not downloaded using homebrew as old
versions of Wine were. I think I just need to figure out how to create the
correct path for the new version of wine--I do not know if this is possible
using the old wine argument designed for older versions of wine.

I downloaded the new Wineskin from here:
https://github.com/Gcenx/WineskinServer/releases

The old path for OpenBUGS and R2OpenBUGS for older versions of wine I found
were: WINE="/usr/local/Cellar/wine/2.0.4/bin/wine"
WINEPATH="/usr/local/Cellar/wine/2.0.4/bin/winepath"
OpenBUGS.pgm="/Applications/OpenBUGS323/OpenBUGS.exe"

But trying to do the same, I received the error message: "Error in
bugs(spp.data, inits, params, "model1.txt", debug = T, n.chains = nc, : *unused
argument (OpenBUGS.pgm = bugs)"*

Part of my confusion is what the difference is between the arguments "wine"
and "winepath". There is also an argument "newWINE" that says: "Use new
versions of Wine that have ?winepath? utility", but I don't know if my
version of wine has this, and how this argument is then written.

If I go to the "get info" on where my wineskin app is on my computer, the
path is (while redacting my name)
"/Users/firstname_lastname/Applications/Wineskin/Wineskin-2.9.0.7.app".
Maybe this would work? But I don't know if this would be in the argument
for wine, or winepath.

I think perhaps if I can adapt the path, it will work. But I'm not sure
exactly what is needed, particularly for the new version of wine for MacOS
Catalina, and if the old wine arguments even work with the new version of
wine. If anyone could help I would sincerely appreciate it. Thanks!!

-- 
Jordan Rogan

Ph.D. Candidate, Applied Biodiversity Sciences
Department of Ecology and Conservation Biology (ECCB)
Texas A&M University
Website: jordanrogan.wordpress.com | Twitter: @jordrogan | Skype: jord0123

	[[alternative HTML version deleted]]


From jho|tm@n @end|ng |rom gm@||@com  Tue Jun 23 21:07:07 2020
From: jho|tm@n @end|ng |rom gm@||@com (jim holtman)
Date: Tue, 23 Jun 2020 12:07:07 -0700
Subject: [R] Help with locating error on import of data
In-Reply-To: <CAJc=yOEt1M+u638iVbNesvwzSErszGq7Cd4DxugjUGqj+BDX9Q@mail.gmail.com>
References: <20200623145701.A77DD857@hypatia.math.ethz.ch>
 <CAJc=yOEt1M+u638iVbNesvwzSErszGq7Cd4DxugjUGqj+BDX9Q@mail.gmail.com>
Message-ID: <CAAxdm-4CHTwHS=nH5X8aV_-POOYZm2oGaTeCfSC6+Zo-hKd0dA@mail.gmail.com>

one of the problems with Excel is that people can put anything in any
column.  You might want to restrict which columns you are reading
since if it finds data in some cells and there is not a header, it
will create one.

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Tue, Jun 23, 2020 at 8:09 AM Patrick (Malone Quantitative)
<malone at malonequantitative.com> wrote:
>
> It looks like it's looking for column names in the first row of your Excel
> sheet and not finding them. What does the first row contain?
>
> On Tue, Jun 23, 2020 at 10:57 AM Ahson via R-help <r-help at r-project.org>
> wrote:
>
> > I have imported data from an Excel file and I am getting errors:
> >
> > > library(readxl)
> > > Balance_sheet <- read_excel("Y:/All Documents/Training/Data/Routines for
> > consolidating all the data/Individual tables/AIM
> > companies/Balance_sheet.xlsx", na = "")
> > New names:
> > * `` -> ...6
> > * `` -> ...7
> > * `` -> ...9
> > * `` -> ...10
> > * `` -> ...11
> > * ... and 22 more problems
> >
> >
> > How can I find where the error is originating? What does New names mean?
> >
> > Thanks in advance for your help.
> >
> >
> > Sent from Mail for Windows 10
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
> --
> Patrick S. Malone, Ph.D., Malone Quantitative
> NEW Service Models: http://malonequantitative.com
>
> He/Him/His
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From e@ @end|ng |rom enr|co@chum@nn@net  Tue Jun 23 21:09:44 2020
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Tue, 23 Jun 2020 21:09:44 +0200
Subject: [R] 
 How to convert column from millisecond epoch time to yyyy-mm-dd GMT
In-Reply-To: <jsk0wxJfI0qRk9-N10ALg9OxpVLFiCM7fCSiyGXC7Hu5E0TfgKQGxPTLA_vd4oo46_PsL0KvcHuUwrPHbc91GqrPaYrcqe2Qbupkstjcr_k=@protonmail.com>
 (Gregg via's message of "Tue, 23 Jun 2020 05:13:32 +0000")
References: <jsk0wxJfI0qRk9-N10ALg9OxpVLFiCM7fCSiyGXC7Hu5E0TfgKQGxPTLA_vd4oo46_PsL0KvcHuUwrPHbc91GqrPaYrcqe2Qbupkstjcr_k=@protonmail.com>
Message-ID: <877dvxa9af.fsf@enricoschumann.net>

On Tue, 23 Jun 2020, Gregg via R-help writes:

> Hello to all the smart people out there....
>
> I have a data.frame labeled itsm_service_type_field. I need to convert
> the Timestamp field which is epoch time in milliseconds to a
> yyyy-mm-dd GMT Date.?
>
> Data.frame format is below.
>
> I've attempted to use the lapply and as.POSIXct
> functions to convert the time field in the original
> data.frame to a new data.frame I've labeled
> "itsm_service_type_field_adjusted_time",
> but I've got the order and syntax wrong.
>
> Help would be so much appreciated.
>
> Thanks in advance.
> Gregg
> Arizona
>
> Details - See Below:
>
> itsm_service_type_field <- fread("itsm_service_type_2018-2019_CONUS.csv")
>
>>>>>>>>>>>>>>???????????itsm_service_type_field_adjusted_time <- lapply(itsm_service_type_field[ , Timestamp], as.POSIXct(Timestamp, origin="1970-01-01", tz="GMT"))
>
> head(itsm_service_type_field)
> ? ? Id? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Timestamp? ? ? ? ?Data Type Visibility? ? ? ? ? ? ? ? ? ? ? TYPE_SERVICE
> 1: INCBR0005072277 1577059200000 itsm-ticket U&FOUO&USA??????????? 0
> 2: INCBR0005073034 1577059200000 itsm-ticket U&FOUO&USA??????????? 1
> 3: INCBR0005073131 1577059200000 itsm-ticket U&FOUO&USA??????????? 0
> 4: INCBR0005074186 1577059200000 itsm-ticket U&FOUO&USA??????????? 0
> 5: INCBR0005074188 1577059200000 itsm-ticket U&FOUO&USA??????????? 0
> 6: INCBR0005074546 1577059200000 itsm-ticket U&FOUO&USA??????????? 0
>

You should divide by 1000:

    .POSIXct(1577059200000/1000, tz = "GMT")
    ## [1] "2019-12-23 GMT"

    as.POSIXct(1577059200000/1000,
               origin = as.POSIXct("1970-01-01 00:00:00", tz = "GMT"),
               tz = "GMT")
    ## [1] "2019-12-23 GMT"


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From wdun|@p @end|ng |rom t|bco@com  Tue Jun 23 21:20:35 2020
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Tue, 23 Jun 2020 12:20:35 -0700
Subject: [R] 
 How to convert column from millisecond epoch time to yyyy-mm-dd GMT
In-Reply-To: <jsk0wxJfI0qRk9-N10ALg9OxpVLFiCM7fCSiyGXC7Hu5E0TfgKQGxPTLA_vd4oo46_PsL0KvcHuUwrPHbc91GqrPaYrcqe2Qbupkstjcr_k=@protonmail.com>
References: <jsk0wxJfI0qRk9-N10ALg9OxpVLFiCM7fCSiyGXC7Hu5E0TfgKQGxPTLA_vd4oo46_PsL0KvcHuUwrPHbc91GqrPaYrcqe2Qbupkstjcr_k=@protonmail.com>
Message-ID: <CAF8bMcaAWYNNjaJWgEaVLhNo8=Dfh-GQz=sKA5KgLSyC_DkVXQ@mail.gmail.com>

When you give an example it really helps to (a) show the data as the output
of dput() or dump() so one can copy and paste into R and (b) show the
result (the wrong value or error message) that you got.

You example is missing some quotes and has an unneeded call to lapply().

> dump("Data", file=stdout())
Data <-
structure(list(Id = c("INCBR0005072277", "INCBR0005073034",
"INCBR0005073131",
"INCBR0005074186", "INCBR0005074188"), Timestamp = c(1577059200000,
1577059200000, 1577059200000, 1577059200000, 1577059200000),
    `Data Type` = c("itsm-ticket", "itsm-ticket", "itsm-ticket",
    "itsm-ticket", "itsm-ticket"), Visibility = c("U&FOUO&USA",
    "U&FOUO&USA", "U&FOUO&USA", "U&FOUO&USA", "U&FOUO&USA"),
    TYPE_SERVER = c(0L, 1L, 0L, 0L, 0L)), row.names = c(NA, -5L
), class = "data.frame")
> str(as.POSIXct(Data$Timestamp/1000,
origin=as.POSIXct("1970-01-01",tz="UTC"), tz="UTC"))
 POSIXct[1:5], format: "2019-12-23" "2019-12-23" "2019-12-23" "2019-12-23"
"2019-12-23"

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Jun 23, 2020 at 11:24 AM Gregg via R-help <r-help at r-project.org>
wrote:

> Hello to all the smart people out there....
>
> I have a data.frame labeled itsm_service_type_field. I need to convert the
> Timestamp field which is epoch time in milliseconds to a yyyy-mm-dd GMT
> Date.
>
> Data.frame format is below.
>
> I've attempted to use the lapply and as.POSIXct functions to convert the
> time field in the original data.frame to a new data.frame I've labeled
> "itsm_service_type_field_adjusted_time",
> but I've got the order and syntax wrong.
>
> Help would be so much appreciated.
>
> Thanks in advance.
> Gregg
> Arizona
>
> Details - See Below:
>
> itsm_service_type_field <- fread("itsm_service_type_2018-2019_CONUS.csv")
>
> >>>>>>>>>>>>>???????????itsm_service_type_field_adjusted_time <-
> lapply(itsm_service_type_field[ , Timestamp], as.POSIXct(Timestamp,
> origin="1970-01-01", tz="GMT"))
>
> head(itsm_service_type_field)
>     Id                              Timestamp         Data Type
> Visibility                      TYPE_SERVICE
> 1: INCBR0005072277 1577059200000 itsm-ticket U&FOUO&USA            0
> 2: INCBR0005073034 1577059200000 itsm-ticket U&FOUO&USA            1
> 3: INCBR0005073131 1577059200000 itsm-ticket U&FOUO&USA            0
> 4: INCBR0005074186 1577059200000 itsm-ticket U&FOUO&USA            0
> 5: INCBR0005074188 1577059200000 itsm-ticket U&FOUO&USA            0
> 6: INCBR0005074546 1577059200000 itsm-ticket U&FOUO&USA
> 0______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jun 23 21:30:05 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 23 Jun 2020 12:30:05 -0700
Subject: [R] 
 How to create path for OpenBUGS into R using R2OpenBUGS with
 new Wineskin-Winery 1.8.4.1/Wineskin2.9.06-1 on MacOS Catalina 10.15.5
In-Reply-To: <CA+PynfkAQ128HK718a6KOZFYHaPxMXoCOpGbDXTJP0XM46LUUA@mail.gmail.com>
References: <CA+PynfkAQ128HK718a6KOZFYHaPxMXoCOpGbDXTJP0XM46LUUA@mail.gmail.com>
Message-ID: <FC3775B9-25A5-49B5-8C4A-CF3D27396499@dcn.davis.ca.us>

While you might get lucky here, there are two indicators in your post that suggest a different venue would be appropriate: one is that your question is very specific regarding a contributed package... this venue is about the language and base packages. Second, your customized (Wine+MacOSX) platform is very non-standard, though the nearest hit in the mailing lists may be r-sig-mac or r-sig-debian, since users on either of those platforms might have been tempted to use Wine at some point. But really you may need to ask in a Wine-specific mailing list because this smells like Wine-vs-Catalina incompatibility rather than an R issue.

On June 23, 2020 10:09:43 AM PDT, Jordan Rogan <roganjordan23 at gmail.com> wrote:
>Hi!
>
>I recently downloaded the new Wineskin-Winery 1.8.4.1/Wineskin2.9.06-1
>onto
>my mac adapted for the limitations for MacOS Catalina 10.15.5 that
>caused
>old versions of Wine to no longer work. I downloaded it so that I could
>download the Windows program OpenBUGS and use R2openBUGS in R to use
>the
>program. I am not very experienced with R, and I am trying to figure
>out
>how to call OpenBUGS into R with R2OpenBUGS with the new
>wineskin/wineskin-winery version. I found older code using the Wine
>argument in R2OpenBuGS, but I think the path has significantly changed
>with
>the new version of Wineskin which is not downloaded using homebrew as
>old
>versions of Wine were. I think I just need to figure out how to create
>the
>correct path for the new version of wine--I do not know if this is
>possible
>using the old wine argument designed for older versions of wine.
>
>I downloaded the new Wineskin from here:
>https://github.com/Gcenx/WineskinServer/releases
>
>The old path for OpenBUGS and R2OpenBUGS for older versions of wine I
>found
>were: WINE="/usr/local/Cellar/wine/2.0.4/bin/wine"
>WINEPATH="/usr/local/Cellar/wine/2.0.4/bin/winepath"
>OpenBUGS.pgm="/Applications/OpenBUGS323/OpenBUGS.exe"
>
>But trying to do the same, I received the error message: "Error in
>bugs(spp.data, inits, params, "model1.txt", debug = T, n.chains = nc, :
>*unused
>argument (OpenBUGS.pgm = bugs)"*
>
>Part of my confusion is what the difference is between the arguments
>"wine"
>and "winepath". There is also an argument "newWINE" that says: "Use new
>versions of Wine that have ?winepath? utility", but I don't know if my
>version of wine has this, and how this argument is then written.
>
>If I go to the "get info" on where my wineskin app is on my computer,
>the
>path is (while redacting my name)
>"/Users/firstname_lastname/Applications/Wineskin/Wineskin-2.9.0.7.app".
>Maybe this would work? But I don't know if this would be in the
>argument
>for wine, or winepath.
>
>I think perhaps if I can adapt the path, it will work. But I'm not sure
>exactly what is needed, particularly for the new version of wine for
>MacOS
>Catalina, and if the old wine arguments even work with the new version
>of
>wine. If anyone could help I would sincerely appreciate it. Thanks!!

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Tue Jun 23 22:45:08 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 23 Jun 2020 13:45:08 -0700
Subject: [R] RLQ and data.frame scores PCA
In-Reply-To: <CAKrVO18cbL8deXgJdUQ=N3XMTui7KxtQzycLS5RkKcevGE+6fg@mail.gmail.com>
References: <CAKrVO18cbL8deXgJdUQ=N3XMTui7KxtQzycLS5RkKcevGE+6fg@mail.gmail.com>
Message-ID: <CAGxFJbSz5wjPHaH1bdX1U443L4KX4fveYaV0Dn6fCd6RLbbGrA@mail.gmail.com>

Wrong list. This list is for general R programming. Few of us here will
have a clue about RLQ analysis and other subject specific methodology. I
suggest you post on the r-sig-ecology of perhaps r-sig-phylo list (not sure
which is more appropriate) where you should find both the interest and
expertise you seek.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Jun 23, 2020 at 11:23 AM Adriana Acero <
adriana.carolina.acero at gmail.com> wrote:

> Hi everybody,
>
> My name is Adriana and I'm working with Community Ecology and Geometric
> morphometric of bats.
>
> At this moment, I'm trying to perform an RLQ analysis with ADE4, with a
> data frame that already contains the mean shape scores (PCA) of some
> species of bats (Matriz Q).
>
> I couldn't do the PCA into ADE4 because I'm working with landmarks and the
> structure of the data is a multidimensional array, so the PCA comes from
> Geomorph. I save only the scores in a data frame. I'm searching on the
> internet for solutions but I don't find How to do an RLQ with my data.frame
> or how to transform it in a dudi object without doing an extra analysis.
>
> I appreciate your help.
>
> Thanks
>
> Adriana Acero
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From herd_dog @end|ng |rom cox@net  Tue Jun 23 23:19:16 2020
From: herd_dog @end|ng |rom cox@net (Philip)
Date: Tue, 23 Jun 2020 14:19:16 -0700
Subject: [R] rNOMADS Package
Message-ID: <0A06973E823A403C933B52D7828079F4@OWNERPC>

Does anyone out there have any advise about how to download the wgrib2 software from the National Weather Service onto a Windows 10 computer?

I tried using the instructions from Bovine Aerospace website but am not sure if it loaded correctly.

Thanks,
Philip
	[[alternative HTML version deleted]]


From jr@| @end|ng |rom po@teo@no  Tue Jun 23 23:19:27 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Tue, 23 Jun 2020 23:19:27 +0200
Subject: [R] Help with locating error on import of data
In-Reply-To: <d1065f1e-98b7-e20e-9118-96ad626a737e@sapo.pt>
References: <20200623145702.F2B08DFF@hypatia.math.ethz.ch>
 <d1065f1e-98b7-e20e-9118-96ad626a737e@sapo.pt>
Message-ID: <20200623211927.GA1160@posteo.no>

On 2020-06-23 17:24 +0100, Rui Barradas wrote:
> ?s 15:56 de 23/06/2020, Ahson via R-help escreveu:
> > I have imported data from an Excel file 
> > and I am getting errors:
> 
> Try setting argument col.names = FALSE, it 
> seems that the function is not find column 
> headers and is choosing its own.

Dear Ahson,

The openxlsx package is also worth checking 
out for situations like this one.

First read the file into a workbook object, 
then read the sheet names from the workbook, 
lastly use the sheet names to read each sheet 
from the workbook using lapply:

	xlsxFile <- "hmm.xlsx"
	wb <- openxlsx::loadWorkbook(xlsxFile)
	sheets <- names(wb)
	list.of.sheet.dfs <- lapply(sheets, function(sheet, wb) {
	  openxlsx::read.xlsx(
	    xlsxFile=wb,
	    sheet=sheet,
	    colNames=FALSE)
	}, wb=wb)
	names(list.of.sheet.dfs) <- sheets
	list.of.sheet.dfs

yields:

	$Sheet1
	     X1   X2   X3        X4     X5
	1  this <NA> <NA> blablabla   <NA>
	2  <NA> does <NA>      <NA>   <NA>
	3  <NA> <NA> <NA>       not   <NA>
	4  <NA> <NA> make      <NA>   <NA>
	5 sense <NA> <NA>      <NA>     42
	6  <NA> <NA> <NA>      <NA> lalala
	
	$ReallyComplexSamples0003
	    X1      X2   X3    X4     X5     X6   X7
	1 <NA>    <NA> <NA>  <NA>   <NA>   <NA> some
	2 <NA>    <NA> with  <NA>   <NA> other  <NA>
	3 <NA> random  <NA>  <NA>   <NA>   <NA> <NA>
	4 info    <NA> <NA> sheet   <NA>   <NA> <NA>
	5 <NA>  stuck    in  <NA>   <NA>   <NA> <NA>
	6 <NA>    <NA>   it  <NA> lalala    $$$ <NA>
	7 <NA>    <NA> <NA>  <NA>   <NA>      2 <NA>

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200623/654d1daa/attachment.sig>

From @rr@ypro|||e @end|ng |rom y@hoo@com  Wed Jun 24 05:56:14 2020
From: @rr@ypro|||e @end|ng |rom y@hoo@com (array chip)
Date: Wed, 24 Jun 2020 03:56:14 +0000 (UTC)
Subject: [R] R 4.0.2 is released
In-Reply-To: <109235C0-23F3-4DA6-B895-51596AD62D31@cbs.dk>
References: <109235C0-23F3-4DA6-B895-51596AD62D31@cbs.dk>
Message-ID: <21866665.2834303.1592970974385@mail.yahoo.com>

Hi,

I downloaded R4.0.2 and installed it succesffully without any error. However, when I opened up a R session (using x64) and tried to install packages, I got the following error message:

> utils:::menuInstallPkgs()
Warning: failed to download mirrors file (internet routines cannot be loaded); using local file 'C:/PROGRA~1/R/R-40~1.2/doc/CRAN_mirrors.csv'
Warning: unable to access index for repository https://rweb.crmda.ku.edu/cran/src/contrib:
? internet routines cannot be loaded
Error in install.packages(lib = .libPaths()[1L], dependencies = NA, type = type) :?
? argument "pkgs" is missing, with no default
In addition: Warning message:
In download.file(url, destfile = f, quiet = TRUE) :
? unable to load shared object 'C:/PROGRA~1/R/R-40~1.2/modules/x64/internet.dll':
? LoadLibrary failure:? Access is denied.

> sessionInfo()
R version 4.0.2 (2020-06-22)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 18363)


Matrix products: default


locale:
[1] LC_COLLATE=English_United States.1252? LC_CTYPE=English_United States.1252? ?
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C? ? ? ? ? ? ? ? ? ? ? ? ??
[5] LC_TIME=English_United States.1252? ??


attached base packages:
[1] stats? ? ?graphics? grDevices utils? ? ?datasets? methods? ?base? ? ?


loaded via a namespace (and not attached):
[1] compiler_4.0.2 tools_4.0.2? ?


However, if I load up a session using i386 verson, then everything is ok - I can install packages.

Can you and anyone suggest what is going on?

Thanks,

John




On Monday, June 22, 2020, 01:24:20 AM PDT, Peter Dalgaard via R-help <r-help at r-project.org> wrote: 





The build system rolled up R-4.0.2.tar.gz (codename "Taking Off Again") this morning.

The list below details the changes in this release.

You can get the source code from

http://cran.r-project.org/src/base/R-4/R-4.0.2.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard

These are the checksums (md5 and SHA-256) for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = b9c44f9f78cab3184ad9898bebc854b4
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 4afa171cd982aaa60f0ba92e2e7bc5d6
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = 566a6bb3642e28e6bf01cf98db31137c
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 496062c138e2def06cebccddfb814ac6
MD5 (NEWS.3) = 012e7f4a80cc8ec947bf3f0ff6117ec8
MD5 (R-latest.tar.gz) = 1eac7293d5fe313a56ddabfda02b437e
MD5 (README) = f468f281c919665e276a1b691decbbe6
MD5 (RESOURCES) = 529223fd3ffef95731d0a87353108435
MD5 (THANKS) = 251d20510bfc3cc93b82c5a99f7efcc6
MD5 (VERSION-INFO.dcf) = 62496d3a0fd8cc2ed644ea518c052371
MD5 (R-4/R-4.0.2.tar.gz) = 1eac7293d5fe313a56ddabfda02b437e

2cde824a7b18958e5f06b391c801c8288be0f84fa8934b7ddefef23c67e60c09? AUTHORS
e6d6a009505e345fe949e1310334fcb0747f28dae2856759de102ab66b722cb4? COPYING
6095e9ffa777dd22839f7801aa845b31c9ed07f3d6bf8a26dc5d2dec8ccc0ef3? COPYING.LIB
eddf87b12197c7b3b19cbc9b11c1beab95b14e3dcd715bf37d2f6a8b2a72c2a1? FAQ
f87461be6cbaecc4dce44ac58e5bd52364b0491ccdadaf846cb9b452e9550f31? INSTALL
ec05bba338358410fae6b34fed061605989ab3601aba1b3fcb45a610d5dd2eb9? NEWS
4e21b62f515b749f80997063fceab626d7258c7d650e81a662ba8e0640f12f62? NEWS.0
12b30c724117b1b2b11484673906a6dcd48a361f69fc420b36194f9218692d01? NEWS.1
e80de410c77f05ff2012fa70051b89119845f734a7fa5c55857e61e4ed7d5f6e? NEWS.2
7201d139947afa52b5e09d26dc01445edf444506264355b2185122bc1ed3dce0? NEWS.3
d3bceab364da0876625e4097808b42512395fdf41292f4915ab1fd257c1bbe75? R-latest.tar.gz
2fdd3e90f23f32692d4b3a0c0452f2c219a10882033d1774f8cadf25886c3ddc? README
408737572ecc6e1135fdb2cf7a9dbb1a6cb27967c757f1771b8c39d1fd2f1ab9? RESOURCES
c9c7cb32308b4e560a22c858819ade9de524a602abd4e92d1c328c89f8037d73? THANKS
10cc5f566a4a5ce49147e7dcfbe9180dba09ccb9efb17298b067309eb799e92e? VERSION-INFO.dcf
d3bceab364da0876625e4097808b42512395fdf41292f4915ab1fd257c1bbe75? R-4/R-4.0.2.tar.gz

This is the relevant part of the NEWS file

CHANGES IN R 4.0.2:

? UTILITIES:

? ? * R CMD check skips vignette re-building (with a warning) if the
? ? ? VignetteBuilder package(s) are not available.

? BUG FIXES:

? ? * Paths with non-ASCII characters caused problems for package
? ? ? loading on Windows PR#17833.

? ? * Using tcltk widgets no longer crashes R on Windows.

? ? * source(*, echo=TRUE) no longer fails in some cases with empty
? ? ? lines; reported by Bill Dunlap in PR#17769.

? ? * on.exit() now correctly matches named arguments, thanks to
? ? ? PR#17815 (including patch) by Brodie Gaslam.

? ? * regexpr(*, perl=TRUE) no longer returns incorrect positions into
? ? ? text containing characters outside of the Unicode Basic
? ? ? Multilingual Plane on Windows.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk? Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From @rr@ypro|||e @end|ng |rom y@hoo@com  Wed Jun 24 07:27:04 2020
From: @rr@ypro|||e @end|ng |rom y@hoo@com (array chip)
Date: Wed, 24 Jun 2020 05:27:04 +0000 (UTC)
Subject: [R] R 4.0.2 is released
In-Reply-To: <21866665.2834303.1592970974385@mail.yahoo.com>
References: <109235C0-23F3-4DA6-B895-51596AD62D31@cbs.dk>
 <21866665.2834303.1592970974385@mail.yahoo.com>
Message-ID: <1005203576.2841691.1592976424467@mail.yahoo.com>

My current version of R is 3.6.3, there is no problem of installing packages there. I also have no problem installing bioconductor packages with 3.6.3.?

But installing packages from biocondcutor failed as well on 4.0.2 (also tried 4.0.0 and failed, too)


On Tuesday, June 23, 2020, 08:56:45 PM PDT, array chip via R-help <r-help at r-project.org> wrote: 

Hi,

I downloaded R4.0.2 and installed it succesffully without any error. However, when I opened up a R session (using x64) and tried to install packages, I got the following error message:

> utils:::menuInstallPkgs()
Warning: failed to download mirrors file (internet routines cannot be loaded); using local file 'C:/PROGRA~1/R/R-40~1.2/doc/CRAN_mirrors.csv'
Warning: unable to access index for repository https://rweb.crmda.ku.edu/cran/src/contrib:
? internet routines cannot be loaded
Error in install.packages(lib = .libPaths()[1L], dependencies = NA, type = type) :?
? argument "pkgs" is missing, with no default
In addition: Warning message:
In download.file(url, destfile = f, quiet = TRUE) :
? unable to load shared object 'C:/PROGRA~1/R/R-40~1.2/modules/x64/internet.dll':
? LoadLibrary failure:? Access is denied.

> sessionInfo()
R version 4.0.2 (2020-06-22)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 18363)


Matrix products: default


locale:
[1] LC_COLLATE=English_United States.1252? LC_CTYPE=English_United States.1252? ?
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C? ? ? ? ? ? ? ? ? ? ? ? ??
[5] LC_TIME=English_United States.1252? ??


attached base packages:
[1] stats? ? ?graphics? grDevices utils? ? ?datasets? methods? ?base? ? ?


loaded via a namespace (and not attached):
[1] compiler_4.0.2 tools_4.0.2? ?


However, if I load up a session using i386 verson, then everything is ok - I can install packages.

Can you and anyone suggest what is going on?

Thanks,

John




On Monday, June 22, 2020, 01:24:20 AM PDT, Peter Dalgaard via R-help <r-help at r-project.org> wrote: 





The build system rolled up R-4.0.2.tar.gz (codename "Taking Off Again") this morning.

The list below details the changes in this release.

You can get the source code from

http://cran.r-project.org/src/base/R-4/R-4.0.2.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard

These are the checksums (md5 and SHA-256) for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = b9c44f9f78cab3184ad9898bebc854b4
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 4afa171cd982aaa60f0ba92e2e7bc5d6
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = 566a6bb3642e28e6bf01cf98db31137c
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 496062c138e2def06cebccddfb814ac6
MD5 (NEWS.3) = 012e7f4a80cc8ec947bf3f0ff6117ec8
MD5 (R-latest.tar.gz) = 1eac7293d5fe313a56ddabfda02b437e
MD5 (README) = f468f281c919665e276a1b691decbbe6
MD5 (RESOURCES) = 529223fd3ffef95731d0a87353108435
MD5 (THANKS) = 251d20510bfc3cc93b82c5a99f7efcc6
MD5 (VERSION-INFO.dcf) = 62496d3a0fd8cc2ed644ea518c052371
MD5 (R-4/R-4.0.2.tar.gz) = 1eac7293d5fe313a56ddabfda02b437e

2cde824a7b18958e5f06b391c801c8288be0f84fa8934b7ddefef23c67e60c09? AUTHORS
e6d6a009505e345fe949e1310334fcb0747f28dae2856759de102ab66b722cb4? COPYING
6095e9ffa777dd22839f7801aa845b31c9ed07f3d6bf8a26dc5d2dec8ccc0ef3? COPYING.LIB
eddf87b12197c7b3b19cbc9b11c1beab95b14e3dcd715bf37d2f6a8b2a72c2a1? FAQ
f87461be6cbaecc4dce44ac58e5bd52364b0491ccdadaf846cb9b452e9550f31? INSTALL
ec05bba338358410fae6b34fed061605989ab3601aba1b3fcb45a610d5dd2eb9? NEWS
4e21b62f515b749f80997063fceab626d7258c7d650e81a662ba8e0640f12f62? NEWS.0
12b30c724117b1b2b11484673906a6dcd48a361f69fc420b36194f9218692d01? NEWS.1
e80de410c77f05ff2012fa70051b89119845f734a7fa5c55857e61e4ed7d5f6e? NEWS.2
7201d139947afa52b5e09d26dc01445edf444506264355b2185122bc1ed3dce0? NEWS.3
d3bceab364da0876625e4097808b42512395fdf41292f4915ab1fd257c1bbe75? R-latest.tar.gz
2fdd3e90f23f32692d4b3a0c0452f2c219a10882033d1774f8cadf25886c3ddc? README
408737572ecc6e1135fdb2cf7a9dbb1a6cb27967c757f1771b8c39d1fd2f1ab9? RESOURCES
c9c7cb32308b4e560a22c858819ade9de524a602abd4e92d1c328c89f8037d73? THANKS
10cc5f566a4a5ce49147e7dcfbe9180dba09ccb9efb17298b067309eb799e92e? VERSION-INFO.dcf
d3bceab364da0876625e4097808b42512395fdf41292f4915ab1fd257c1bbe75? R-4/R-4.0.2.tar.gz

This is the relevant part of the NEWS file

CHANGES IN R 4.0.2:

? UTILITIES:

? ? * R CMD check skips vignette re-building (with a warning) if the
? ? ? VignetteBuilder package(s) are not available.

? BUG FIXES:

? ? * Paths with non-ASCII characters caused problems for package
? ? ? loading on Windows PR#17833.

? ? * Using tcltk widgets no longer crashes R on Windows.

? ? * source(*, echo=TRUE) no longer fails in some cases with empty
? ? ? lines; reported by Bill Dunlap in PR#17769.

? ? * on.exit() now correctly matches named arguments, thanks to
? ? ? PR#17815 (including patch) by Brodie Gaslam.

? ? * regexpr(*, perl=TRUE) no longer returns incorrect positions into
? ? ? text containing characters outside of the Unicode Basic
? ? ? Multilingual Plane on Windows.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk? Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From petr@p|k@| @end|ng |rom prechez@@cz  Wed Jun 24 12:03:54 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 24 Jun 2020 10:03:54 +0000
Subject: [R] version plot problem
Message-ID: <5cba6fbe1f574bfc830a4c47343f1945@SRVEXCHCM1302.precheza.cz>

Dear all

I have strange problem with plotting data.frame.

test <- structure(list(`N?zev Anal?zy` = c("Kalcin?t A", "Kalcin?t A", 
"Kalcin?t A", "Kalcin?t A", "Kalcin?t A", "Kalcin?t A"), Prac = c("TB", 
"TB", "TB", "TB", "TB", "TB"), Vzorek = c("6101B", "6101B", "6101B", 
"6101B", "6101B", "6101B"), Datum = structure(c(1590624000, 1590624000, 
1590537600, 1590537600, 1590537600, 1590537600), class = c("POSIXct", 
"POSIXt"), tzone = "UTC"), ?asm = structure(c(1590649200, 1590634800, 
1590620400, 1590606000, 1590591600, 1590577200), class = c("POSIXct", 
"POSIXt"), tzone = "UTC"), Time = structure(c(1590649200, 1590634800, 
1590620400, 1590606000, 1590591600, 1590577200), class = c("POSIXct", 
"POSIXt"), tzone = "UTC"), Kontrolor = c("BAROTOV?", "KR?TK?", 
"KR?TK?", "HOLASOV?", "HOLASOV?", "BAROTOV?"), SFM2 = c(239.4, 
221, 190.3, 215.7, 241.4, 214.8), SFM1 = c(48.7, 55.6, 52.9, 
50.1, 46.6, 54.4), `WI CIE` = c(94.2, 93, 92.4, 94.2, 96.3, 94.4
), `b*` = c(0.8, 1, 1, 0.8, 0.7, 0.8)), row.names = c(NA, 6L), class =
"data.frame")

plot(test)

is OK in R 4.0.0 but throws error in R 3.6.3, which is installed by our IT
> plot(test)
Error in plot.window(...) : need finite 'xlim' values
In addition: Warning messages:
1: In data.matrix(x) : NAs introduced by coercion
2: In data.matrix(x) : NAs introduced by coercion
3: In data.matrix(x) : NAs introduced by coercion
4: In

I know that latest version should be always used but I wonder if this
behavior is specific to 3.6.3 version and the only way is to reinstall R of
if there is some workaround like changing character columns to factor. I
found that it has something to do with character columns.

Best regards.
Petr
*************
platform       x86_64-w64-mingw32                                
arch           x86_64                                            
os             mingw32                                           
system         x86_64, mingw32                                   
status         Under development (unstable)                      
major          4                                                 
minor          0.0                                               
year           2020                                              
month          03                                                
day            08                                                
svn rev        77917                                             
language       R                                                 
version.string R Under development (unstable) (2020-03-08 r77917)
nickname       Unsuffered Consequences


platform       x86_64-w64-mingw32          
arch           x86_64                      
os             mingw32                     
system         x86_64, mingw32             
status                                     
major          3                           
minor          6.3                         
year           2020                        
month          02                          
day            29                          
svn rev        77875                       
language       R                           
version.string R version 3.6.3 (2020-02-29)
nickname       Holding the Windsock        


From jr@| @end|ng |rom po@teo@no  Wed Jun 24 15:12:36 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Wed, 24 Jun 2020 15:12:36 +0200
Subject: [R] version plot problem
In-Reply-To: <5cba6fbe1f574bfc830a4c47343f1945@SRVEXCHCM1302.precheza.cz>
References: <5cba6fbe1f574bfc830a4c47343f1945@SRVEXCHCM1302.precheza.cz>
Message-ID: <20200624131236.GA24907@posteo.no>

On 2020-06-24 10:03 +0000, PIKAL Petr wrote:
> Dear all
> 
> I have strange problem with plotting data.frame.

Dear Petr,

After fending off the iso-8859-2 encoding, 
continuing using my regular Unicode encoding, 
I was able to reproduce the error 3.6.3 
(sessionInfo and version at the end of the 
email).

Dropping the columns "N?zev Anal?zy", 
"Kontrolor", "Prac", and "Vzorek" indeed 
makes the error go away ...

Best,
Rasmus

3.6.3:

	> sessionInfo()
	R version 3.6.3 (2020-02-29)
	Platform: x86_64-pc-linux-gnu (64-bit)
	Running under: Arch Linux
	
	Matrix products: default
	BLAS:   /usr/lib/libblas.so.3.9.0
	LAPACK: /usr/lib/liblapack.so.3.9.0
	
	locale:
	 [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C
	 [3] LC_TIME=en_DK.utf8        LC_COLLATE=en_GB.utf8
	 [5] LC_MONETARY=nb_NO.utf8    LC_MESSAGES=en_GB.utf8
	 [7] LC_PAPER=nb_NO.utf8       LC_NAME=C
	 [9] LC_ADDRESS=C              LC_TELEPHONE=C
	[11] LC_MEASUREMENT=nb_NO.utf8 LC_IDENTIFICATION=C
	
	attached base packages:
	[1] stats     graphics  grDevices utils     datasets  methods   base
	
	loaded via a namespace (and not attached):
	[1] compiler_3.6.3
	> version
	               _
	platform       x86_64-pc-linux-gnu
	arch           x86_64
	os             linux-gnu
	system         x86_64, linux-gnu
	status
	major          3
	minor          6.3
	year           2020
	month          02
	day            29
	svn rev        77875
	language       R
	version.string R version 3.6.3 (2020-02-29)
	nickname       Holding the Windsock

4.0.2:

	> sessionInfo()
	R version 4.0.2 (2020-06-22)
	Platform: x86_64-pc-linux-gnu (64-bit)
	Running under: Arch Linux
	
	Matrix products: default
	BLAS:   /usr/lib/libblas.so.3.9.0
	LAPACK: /usr/lib/liblapack.so.3.9.0
	
	locale:
	 [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C
	 [3] LC_TIME=en_DK.utf8        LC_COLLATE=en_GB.utf8
	 [5] LC_MONETARY=nb_NO.utf8    LC_MESSAGES=en_GB.utf8
	 [7] LC_PAPER=nb_NO.utf8       LC_NAME=C
	 [9] LC_ADDRESS=C              LC_TELEPHONE=C
	[11] LC_MEASUREMENT=nb_NO.utf8 LC_IDENTIFICATION=C
	
	attached base packages:
	[1] stats     graphics  grDevices utils     datasets  methods   base
	
	loaded via a namespace (and not attached):
	[1] compiler_4.0.2
	> version
	               _
	platform       x86_64-pc-linux-gnu
	arch           x86_64
	os             linux-gnu
	system         x86_64, linux-gnu
	status
	major          4
	minor          0.2
	year           2020
	month          06
	day            22
	svn rev        78730
	language       R
	version.string R version 4.0.2 (2020-06-22)
	nickname       Taking Off Again


From S@E|||@on @end|ng |rom LGCGroup@com  Wed Jun 24 18:44:11 2020
From: S@E|||@on @end|ng |rom LGCGroup@com (Stephen Ellison)
Date: Wed, 24 Jun 2020 16:44:11 +0000
Subject: [R] version plot problem
In-Reply-To: <20200624131236.GA24907@posteo.no>
References: <5cba6fbe1f574bfc830a4c47343f1945@SRVEXCHCM1302.precheza.cz>,
 <20200624131236.GA24907@posteo.no>
Message-ID: <251c1576907b443ab3bf3bdc55926b81@GBDCVPEXC08.corp.lgc-group.com>

You have four character vectors in your data frame; those return non-finite ranges.

plot(test[sapply(test, class)!="character"])

plots the non-character columns.

S Ellison

________________________________________
From: R-help [r-help-bounces at r-project.org] on behalf of Rasmus Liland [jral at posteo.no]
Sent: 24 June 2020 14:12
To: R-help
Subject: Re: [R] version plot problem

===============
 EXTERNAL EMAIL
===============

On 2020-06-24 10:03 +0000, PIKAL Petr wrote:
> Dear all
>
> I have strange problem with plotting data.frame.

Dear Petr,

After fending off the iso-8859-2 encoding,
continuing using my regular Unicode encoding,
I was able to reproduce the error 3.6.3
(sessionInfo and version at the end of the
email).

Dropping the columns "N?zev Anal?zy",
"Kontrolor", "Prac", and "Vzorek" indeed
makes the error go away ...

Best,
Rasmus

3.6.3:

        > sessionInfo()
        R version 3.6.3 (2020-02-29)
        Platform: x86_64-pc-linux-gnu (64-bit)
        Running under: Arch Linux

        Matrix products: default
        BLAS:   /usr/lib/libblas.so.3.9.0
        LAPACK: /usr/lib/liblapack.so.3.9.0

        locale:
         [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C
         [3] LC_TIME=en_DK.utf8        LC_COLLATE=en_GB.utf8
         [5] LC_MONETARY=nb_NO.utf8    LC_MESSAGES=en_GB.utf8
         [7] LC_PAPER=nb_NO.utf8       LC_NAME=C
         [9] LC_ADDRESS=C              LC_TELEPHONE=C
        [11] LC_MEASUREMENT=nb_NO.utf8 LC_IDENTIFICATION=C

        attached base packages:
        [1] stats     graphics  grDevices utils     datasets  methods   base

        loaded via a namespace (and not attached):
        [1] compiler_3.6.3
        > version
                       _
        platform       x86_64-pc-linux-gnu
        arch           x86_64
        os             linux-gnu
        system         x86_64, linux-gnu
        status
        major          3
        minor          6.3
        year           2020
        month          02
        day            29
        svn rev        77875
        language       R
        version.string R version 3.6.3 (2020-02-29)
        nickname       Holding the Windsock

4.0.2:

        > sessionInfo()
        R version 4.0.2 (2020-06-22)
        Platform: x86_64-pc-linux-gnu (64-bit)
        Running under: Arch Linux

        Matrix products: default
        BLAS:   /usr/lib/libblas.so.3.9.0
        LAPACK: /usr/lib/liblapack.so.3.9.0

        locale:
         [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C
         [3] LC_TIME=en_DK.utf8        LC_COLLATE=en_GB.utf8
         [5] LC_MONETARY=nb_NO.utf8    LC_MESSAGES=en_GB.utf8
         [7] LC_PAPER=nb_NO.utf8       LC_NAME=C
         [9] LC_ADDRESS=C              LC_TELEPHONE=C
        [11] LC_MEASUREMENT=nb_NO.utf8 LC_IDENTIFICATION=C

        attached base packages:
        [1] stats     graphics  grDevices utils     datasets  methods   base

        loaded via a namespace (and not attached):
        [1] compiler_4.0.2
        > version
                       _
        platform       x86_64-pc-linux-gnu
        arch           x86_64
        os             linux-gnu
        system         x86_64, linux-gnu
        status
        major          4
        minor          0.2
        year           2020
        month          06
        day            22
        svn rev        78730
        language       R
        version.string R version 4.0.2 (2020-06-22)
        nickname       Taking Off Again

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


==============================================================================================
WARNING - EXTERNAL: This email originated from outside of LGC. Do not click any links or open any attachments
unless you trust the sender and know that the content is safe
==============================================================================================


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Jun 25 12:18:49 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 25 Jun 2020 12:18:49 +0200
Subject: [R] invalid type (list) for variable 'y' in library minpack.lm
Message-ID: <CAMk+s2TeoVRx5XV3wrbg6g7aQf2cuy=N-T4gHMwZesU1Gh8hVw@mail.gmail.com>

Hello,
I am trying to find the best fit to a function for epidemic analysis.
I am trying with the package minpack.lm but I don't really know how to
use it. I am getting the error:
```
Error in model.frame.default(formula = ~y + x, data = list(Y)) :
  invalid type (list) for variable 'y'
In addition: Warning messages:
1: In min(x) : no non-missing arguments to min; returning Inf
2: In max(x) : no non-missing arguments to max; returning -Inf
```
So I have some questions:
- how to solve the list problem? (what is the input for nlsLM? I have
a vector with the actual values, shall I convert in a dataframe?)
- how to avoid infinitives?
- is there another function other than nlsLM that I should use?
- is there another function that could fit a sigmoid profile other
than Holling type III?

This is the working example:
```
holling = function(a, b, x) {
  y = (a * x^2) / (b^2 + x^2)
  return(y)
}
Y = c(8,   24,   39,   63,   89,  115,  153,  196,  242,  287,  344,  408,  473,
      546,  619,  705,  794,  891,  999, 1096, 1242, 1363, 1506, 1648, 1753,
      1851, 1987, 2101, 2219, 2328, 2425, 2575, 2646, 2698, 2727, 2771, 2818,
      2853, 2895, 2926, 2964, 2995, 3025, 3053, 3080, 3102, 3119, 3141, 3152,
      3159, 3172, 3182, 3196, 3209, 3220, 3231, 3239, 3246, 3252, 3261)
X = 1:60
A = 3261
B = 10
plot(X, Y,
     col = "red", pch =16, lwd = 2,
     main = paste("Starting values: a=", A, "; b=", B, sep =""),
     xlab = expression(bold("Days of infection")),
     ylab = expression(bold("Cumulative incidence")))
HL = holling(A, B, X)
points(X, HL, type = "l", lty = 2)

# estimation
library("minpack.lm")
init_parms = c(a=A, b=B)
est = nlsLM(formula = y~(a*x^2)/(b^2 + x^2), start=init_parms, data=list(Y))
```

-- 
Best regards,
Luigi


From jr@| @end|ng |rom po@teo@no  Thu Jun 25 13:24:23 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Thu, 25 Jun 2020 13:24:23 +0200
Subject: [R] invalid type (list) for variable 'y' in library minpack.lm
In-Reply-To: <CAMk+s2TeoVRx5XV3wrbg6g7aQf2cuy=N-T4gHMwZesU1Gh8hVw@mail.gmail.com>
References: <CAMk+s2TeoVRx5XV3wrbg6g7aQf2cuy=N-T4gHMwZesU1Gh8hVw@mail.gmail.com>
Message-ID: <20200625112423.GA1090@posteo.no>

Dear Luigi,

On 2020-06-25 12:18 +0200, Luigi Marongiu wrote:
> Hello,
> I am trying to find the best fit to a 
> function for epidemic analysis.
> I am trying with the package minpack.lm but 
> I don't really know how to use it.

Me neither ...

> So I have some questions:
> - how to solve the list problem? (what is 
>   the input for nlsLM? I have a vector with 
>   the actual values, shall I convert in a 
>   dataframe?)

I got past the error by give 
minpack.lm::nlsLM X and Y in a data.frame

	minpack.lm::nlsLM(
	  formula = y~(a*x^2)/(b^2 + x^2),
	  start=c(a=A, b=B),
	  data=data.frame(x=X, y=Y))

as per ?minpack.lm::nlsLM:

	data: an optional data frame in which to evaluate the variables
	      in?formula? and ?weights?.  Can also be a list or an
	      environment, but not a matrix.

> - how to avoid infinitives?
> - is there another function other than 
>   nlsLM that I should use?
> - is there another function that could fit 
>   a sigmoid profile other than Holling type 
>   III?

These other questions seem good and 
interesting, I hope someone else can answer 
them.

Best,
Rasmus

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200625/0684db7f/attachment.sig>

From petr@p|k@| @end|ng |rom prechez@@cz  Thu Jun 25 16:45:09 2020
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 25 Jun 2020 14:45:09 +0000
Subject: [R] version plot problem
In-Reply-To: <251c1576907b443ab3bf3bdc55926b81@GBDCVPEXC08.corp.lgc-group.com>
References: <5cba6fbe1f574bfc830a4c47343f1945@SRVEXCHCM1302.precheza.cz>,
 <20200624131236.GA24907@posteo.no>
 <251c1576907b443ab3bf3bdc55926b81@GBDCVPEXC08.corp.lgc-group.com>
Message-ID: <b1bf757c9afd478688f7d95477cfe49f@SRVEXCHCM1302.precheza.cz>

Thanks. 

I try to spread R to some other people and I use 4.0.0 - version.string R
Under development (unstable) (2020-03-08 r77917) nickname       Unsuffered
Consequences  whereas they use R 3.6.3
version.string R version 3.6.3 (2020-02-29) nickname       Holding the
Windsock

With artificial data frame both behave with the same error
dat <- data.frame(a=letters[1:5], b=1:5)
dat$a <- as.character(dat$a)
plot(dat)
Error in plot.window(...) : need finite 'xlim' values
In addition: Warning messages:
1: In xy.coords(x, y, xlabel, ylabel, log) : NAs introduced by coercion
2: In min(x) : no non-missing arguments to min; returning Inf
3: In max(x) : no non-missing arguments to max; returning -Inf

So far so good.

But with original data with **character** columns
dput(head(mok))
mok <- structure(list(a = c("Kalcin?t A", "Kalcin?t A", "Kalcin?t A", 
"Kalcin?t A", "Kalcin?t A", "Kalcin?t A"), b = c("TB", "TB", 
"TB", "TB", "TB", "TB"), c = c("6101B", "6101B", "6101B", "6101B", 
"6101B", "6101B"), d = structure(c(1590624000, 1590624000, 1590537600, 
1590537600, 1590537600, 1590537600), class = c("POSIXct", "POSIXt"
), tzone = "UTC"), e = structure(c(1590649200, 1590634800, 1590620400, 
1590606000, 1590591600, 1590577200), class = c("POSIXct", "POSIXt"
), tzone = "UTC"), f = structure(c(1590649200, 1590634800, 1590620400, 
1590606000, 1590591600, 1590577200), class = c("POSIXct", "POSIXt"
), tzone = "UTC"), g = c("BAROTOV?", "KR?TK?", "KR?TK?", "HOLASOV?", 
"HOLASOV?", "BAROTOV?"), h = c(239.4, 221, 190.3, 215.7, 241.4, 
214.8), i = c(48.7, 55.6, 52.9, 50.1, 46.6, 54.4), j = c(94.2, 
93, 92.4, 94.2, 96.3, 94.4), k = c(0.8, 1, 1, 0.8, 0.7, 0.8)), row.names =
c(NA, 
6L), class = "data.frame")

PLOT WORKS in R 400 but not in R 363??????

plot(mok)

Why it works in R400??? How should I explain it?

Best regards.
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Stephen Ellison
> Sent: Wednesday, June 24, 2020 6:44 PM
> To: Rasmus Liland <jral at posteo.no>; R-help <r-help at r-project.org>
> Subject: Re: [R] version plot problem
> 
> You have four character vectors in your data frame; those return
non-finite
> ranges.
> 
> plot(test[sapply(test, class)!="character"])
> 
> plots the non-character columns.
> 
> S Ellison
> 
> ________________________________________
> From: R-help [r-help-bounces at r-project.org] on behalf of Rasmus Liland
> [jral at posteo.no]
> Sent: 24 June 2020 14:12
> To: R-help
> Subject: Re: [R] version plot problem
> 
> ===============
>  EXTERNAL EMAIL
> ===============
> 
> On 2020-06-24 10:03 +0000, PIKAL Petr wrote:
> > Dear all
> >
> > I have strange problem with plotting data.frame.
> 
> Dear Petr,
> 
> After fending off the iso-8859-2 encoding, continuing using my regular
> Unicode encoding, I was able to reproduce the error 3.6.3 (sessionInfo and
> version at the end of the email).
> 
> Dropping the columns "N?zev Anal?zy",
> "Kontrolor", "Prac", and "Vzorek" indeed makes the error go away ...
> 
> Best,
> Rasmus
> 
> 3.6.3:
> 
>         > sessionInfo()
>         R version 3.6.3 (2020-02-29)
>         Platform: x86_64-pc-linux-gnu (64-bit)
>         Running under: Arch Linux
> 
>         Matrix products: default
>         BLAS:   /usr/lib/libblas.so.3.9.0
>         LAPACK: /usr/lib/liblapack.so.3.9.0
> 
>         locale:
>          [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C
>          [3] LC_TIME=en_DK.utf8        LC_COLLATE=en_GB.utf8
>          [5] LC_MONETARY=nb_NO.utf8    LC_MESSAGES=en_GB.utf8
>          [7] LC_PAPER=nb_NO.utf8       LC_NAME=C
>          [9] LC_ADDRESS=C              LC_TELEPHONE=C
>         [11] LC_MEASUREMENT=nb_NO.utf8 LC_IDENTIFICATION=C
> 
>         attached base packages:
>         [1] stats     graphics  grDevices utils     datasets  methods
base
> 
>         loaded via a namespace (and not attached):
>         [1] compiler_3.6.3
>         > version
>                        _
>         platform       x86_64-pc-linux-gnu
>         arch           x86_64
>         os             linux-gnu
>         system         x86_64, linux-gnu
>         status
>         major          3
>         minor          6.3
>         year           2020
>         month          02
>         day            29
>         svn rev        77875
>         language       R
>         version.string R version 3.6.3 (2020-02-29)
>         nickname       Holding the Windsock
> 
> 4.0.2:
> 
>         > sessionInfo()
>         R version 4.0.2 (2020-06-22)
>         Platform: x86_64-pc-linux-gnu (64-bit)
>         Running under: Arch Linux
> 
>         Matrix products: default
>         BLAS:   /usr/lib/libblas.so.3.9.0
>         LAPACK: /usr/lib/liblapack.so.3.9.0
> 
>         locale:
>          [1] LC_CTYPE=en_GB.utf8       LC_NUMERIC=C
>          [3] LC_TIME=en_DK.utf8        LC_COLLATE=en_GB.utf8
>          [5] LC_MONETARY=nb_NO.utf8    LC_MESSAGES=en_GB.utf8
>          [7] LC_PAPER=nb_NO.utf8       LC_NAME=C
>          [9] LC_ADDRESS=C              LC_TELEPHONE=C
>         [11] LC_MEASUREMENT=nb_NO.utf8 LC_IDENTIFICATION=C
> 
>         attached base packages:
>         [1] stats     graphics  grDevices utils     datasets  methods
base
> 
>         loaded via a namespace (and not attached):
>         [1] compiler_4.0.2
>         > version
>                        _
>         platform       x86_64-pc-linux-gnu
>         arch           x86_64
>         os             linux-gnu
>         system         x86_64, linux-gnu
>         status
>         major          4
>         minor          0.2
>         year           2020
>         month          06
>         day            22
>         svn rev        78730
>         language       R
>         version.string R version 4.0.2 (2020-06-22)
>         nickname       Taking Off Again
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> =================================================================
> =============================
> WARNING - EXTERNAL: This email originated from outside of LGC. Do not
click
> any links or open any attachments unless you trust the sender and know
that
> the content is safe
> =================================================================
> =============================
> 
> 
> *****************************************************************
> **
> This email and any attachments are confidential. Any use...{{dropped:8}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From bgunter@4567 @end|ng |rom gm@||@com  Thu Jun 25 16:52:11 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 25 Jun 2020 07:52:11 -0700
Subject: [R] invalid type (list) for variable 'y' in library minpack.lm
In-Reply-To: <20200625112423.GA1090@posteo.no>
References: <CAMk+s2TeoVRx5XV3wrbg6g7aQf2cuy=N-T4gHMwZesU1Gh8hVw@mail.gmail.com>
 <20200625112423.GA1090@posteo.no>
Message-ID: <CAGxFJbRGAr7at90R2i=yFXTNH-KZg9AsvgPJv2FiavJDYGBnfQ@mail.gmail.com>

"These other questions seem good and
interesting, I hope someone else can answer
them."

Perhaps, but not appropriate for this list, imo. Statistics issue mostly
belong elsewhere, e.g. on stats.stackexchange.com.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 25, 2020 at 4:25 AM Rasmus Liland <jral at posteo.no> wrote:

> Dear Luigi,
>
> On 2020-06-25 12:18 +0200, Luigi Marongiu wrote:
> > Hello,
> > I am trying to find the best fit to a
> > function for epidemic analysis.
> > I am trying with the package minpack.lm but
> > I don't really know how to use it.
>
> Me neither ...
>
> > So I have some questions:
> > - how to solve the list problem? (what is
> >   the input for nlsLM? I have a vector with
> >   the actual values, shall I convert in a
> >   dataframe?)
>
> I got past the error by give
> minpack.lm::nlsLM X and Y in a data.frame
>
>         minpack.lm::nlsLM(
>           formula = y~(a*x^2)/(b^2 + x^2),
>           start=c(a=A, b=B),
>           data=data.frame(x=X, y=Y))
>
> as per ?minpack.lm::nlsLM:
>
>         data: an optional data frame in which to evaluate the variables
>               in?formula? and ?weights?.  Can also be a list or an
>               environment, but not a matrix.
>
> > - how to avoid infinitives?
> > - is there another function other than
> >   nlsLM that I should use?
> > - is there another function that could fit
> >   a sigmoid profile other than Holling type
> >   III?
>
> These other questions seem good and
> interesting, I hope someone else can answer
> them.
>
> Best,
> Rasmus
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jr@| @end|ng |rom po@teo@no  Thu Jun 25 17:18:41 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Thu, 25 Jun 2020 17:18:41 +0200
Subject: [R] invalid type (list) for variable 'y' in library minpack.lm
In-Reply-To: <CAGxFJbRGAr7at90R2i=yFXTNH-KZg9AsvgPJv2FiavJDYGBnfQ@mail.gmail.com>
References: <CAMk+s2TeoVRx5XV3wrbg6g7aQf2cuy=N-T4gHMwZesU1Gh8hVw@mail.gmail.com>
 <20200625112423.GA1090@posteo.no>
 <CAGxFJbRGAr7at90R2i=yFXTNH-KZg9AsvgPJv2FiavJDYGBnfQ@mail.gmail.com>
Message-ID: <20200625151841.GF1090@posteo.no>

On 2020-06-25 07:52 -0700, Bert Gunter wrote:
> On Thu, Jun 25, 2020 at 4:25 AM Rasmus Liland wrote:
> > On 2020-06-25 12:18 +0200, Luigi Marongiu wrote:
> > > - how to avoid infinitives?
> > > - is there another function other than 
> > >   nlsLM that I should use?
> > > - is there another function that could 
> > >   fit a sigmoid profile other than 
> > >   Holling type III?
> >
> > These other questions seem good and 
> > interesting, I hope someone else can 
> > answer them.
> 
> Perhaps, but not appropriate for this list, 
> imo.  Statistics issue mostly belong 
> elsewhere, e.g. on 
> stats.stackexchange.com.

+1

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200625/f75aef95/attachment.sig>

From jr@| @end|ng |rom po@teo@no  Thu Jun 25 18:00:04 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Thu, 25 Jun 2020 18:00:04 +0200
Subject: [R] rNOMADS Package
In-Reply-To: <0A06973E823A403C933B52D7828079F4@OWNERPC>
References: <0A06973E823A403C933B52D7828079F4@OWNERPC>
Message-ID: <20200625160004.GG1090@posteo.no>

Dear Philip,

On 2020-06-23 14:19 -0700, Philip wrote:
> Does anyone out there have any advise about 
> how to download the wgrib2 software from 
> the National Weather Service onto a Windows 
> 10 computer?

I don't run Windows, but the wgrib2 page [1] 
says you install [2] it in in Cygwin [3].

> I tried using the instructions from Bovine 
> Aerospace website but am not sure if it 
> loaded correctly.

This might not be the appropriate forum, you 
might try a Cygwin list [4] instead.

If you quit gaming on Windows, and swich to 
ArchLinux at some point, it's just a matter 
of installing the package from Arch User 
Repository [5]  :-)

Best,
Rasmus

[1] https://www.cpc.ncep.noaa.gov/products/wesley/wgrib2/
[2] https://www.cpc.ncep.noaa.gov/products/wesley/wgrib2/compile_questions.html
[3] https://x.cygwin.com/docs/ug/setup.html
[4] https://www.cygwin.com/lists.html
[5] https://aur.archlinux.org/packages/wgrib2/

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200625/9f23d56b/attachment.sig>

From jr@| @end|ng |rom po@teo@no  Thu Jun 25 18:59:11 2020
From: jr@| @end|ng |rom po@teo@no (Rasmus Liland)
Date: Thu, 25 Jun 2020 18:59:11 +0200
Subject: [R] rNOMADS Package
In-Reply-To: <20200625160004.GG1090@posteo.no>
References: <0A06973E823A403C933B52D7828079F4@OWNERPC>
 <20200625160004.GG1090@posteo.no>
Message-ID: <20200625165911.GH1090@posteo.no>

On 2020-06-25 18:00 +0200, Rasmus Liland wrote:
> it's just a matter of installing the 
> package from Arch User Repository

wgrib2 is such a complex program.  How can it 
be compiled anyway?  Seems impossible.

Linking libjasper.so and mysqlclient.so and 
using the anaconda build like sundar_ima 
suggests [2] seems to work ... but might 
cause failures later ... 

[1]?https://anaconda.org/conda-forge/wgrib2/files
[2]?https://aur.archlinux.org/packages/wgrib2/#comment-730699

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20200625/5e6ad794/attachment.sig>

From gregco@t@ @end|ng |rom me@com  Wed Jun 24 21:35:26 2020
From: gregco@t@ @end|ng |rom me@com (Gregory Coats)
Date: Wed, 24 Jun 2020 15:35:26 -0400
Subject: [R] R Compied for Mac OS X
Message-ID: <780FA777-36E8-451F-8078-EA378DD983DE@me.com>

Today, I downloaded, and installed the June 6, 2020 version of R, from the CRAN official site at Carnegie Mellon University. Unfortunately, while the CMU compiled Mac OS X R application provides access to base R stat functions, like mean, it does not provide me with access to any of R?s more advanced functions like movavg, and ggplot.
>From where can I download a more complete R executable, compiled for Mac OS X?
Greg Coats

http://lib.stat.cmu.edu/R/CRAN/ <http://lib.stat.cmu.edu/R/CRAN/>
Download R for (Mac) OS X
R-4.0.2.pkg (notarized and signed)
> version                          
platform       x86_64-apple-darwin17.0     
arch           x86_64                      
os             darwin17.0                  
system         x86_64, darwin17.0          
status                                     
major          4                           
minor          0.1                         
year           2020                        
month          06                          
day            06                          
svn rev        78648                       
language       R                           
version.string R version 4.0.1 (2020-06-06)
nickname       See Things Now      
> mean
function (x, ...) 
UseMethod("mean")
<bytecode: 0x7ffe5d0f0c60>
<environment: namespace:base>
> movavg
Error: object 'movavg' not found
> ggplot
Error: object 'ggplot' not found
>  
	[[alternative HTML version deleted]]


From eder@@||v@ @end|ng |rom cortev@@com  Thu Jun 25 02:29:42 2020
From: eder@@||v@ @end|ng |rom cortev@@com (Silva, Eder David Borges da)
Date: Thu, 25 Jun 2020 00:29:42 +0000
Subject: [R] doParallel cores HPC
Message-ID: <DM6PR17MB25728C6AC94E747A70257B4794920@DM6PR17MB2572.namprd17.prod.outlook.com>

Hi R team,
I have the HPC, with 10 nodes, and each node with 20 cores in UNIX OS.
my goal is a set cluster to use all machine power, and thy this code:

library(doParallel)
cl <- makePSOCKcluster(names=c('Host01', ... , 'Host10)
registerDoParallel(cl=cl,cores=20)
lP <- foreach(j = 1:1000000) %dopar% {Mysimu(j)}
stopCluster(cl)

This code is the best way for use all machine power? the code will be run in
200 tasks? 10 x 20?
what is the limited of nodes in makePSOCKcluster?
Thanks


?der David Borges da Silva
Research Scientist


This communication is for use by the intended recipient ...{{dropped:16}}


From jrkr|de@u @end|ng |rom gm@||@com  Fri Jun 26 01:24:15 2020
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Thu, 25 Jun 2020 19:24:15 -0400
Subject: [R] R Compied for Mac OS X
In-Reply-To: <780FA777-36E8-451F-8078-EA378DD983DE@me.com>
References: <780FA777-36E8-451F-8078-EA378DD983DE@me.com>
Message-ID: <CAKZQJMBd5n3TtWJ5GQhS5OquAMjcdCfGqboHX-V_be6jOUpFOA@mail.gmail.com>

What you probably have downloaded and installed is R base.  I am not
familiar with "movavg" but "ggplot" is a command from the "ggplot2"
package.  R, in total, consists of R baase and at least 1,000+ packages
that do different things. One installs and uses various packages depending
on the work one is doing. Have a look at https://cran.r-project.org/ for
most of the packages available.

You need to install "ggplot2" independently or install "tidyverse" which
will install "ggplot2" and a number of other often useful programs.

Try 'install.packages("tidyverse") and see what happens.
Or 'install.packages("gplot2")

On Thu, 25 Jun 2020 at 19:09, Gregory Coats via R-help <r-help at r-project.org>
wrote:

> Today, I downloaded, and installed the June 6, 2020 version of R, from the
> CRAN official site at Carnegie Mellon University. Unfortunately, while the
> CMU compiled Mac OS X R application provides access to base R stat
> functions, like mean, it does not provide me with access to any of R?s more
> advanced functions like movavg, and ggplot.
> From where can I download a more complete R executable, compiled for Mac
> OS X?
> Greg Coats
>
> http://lib.stat.cmu.edu/R/CRAN/ <http://lib.stat.cmu.edu/R/CRAN/>
> Download R for (Mac) OS X
> R-4.0.2.pkg (notarized and signed)
> > version
> platform       x86_64-apple-darwin17.0
> arch           x86_64
> os             darwin17.0
> system         x86_64, darwin17.0
> status
> major          4
> minor          0.1
> year           2020
> month          06
> day            06
> svn rev        78648
> language       R
> version.string R version 4.0.1 (2020-06-06)
> nickname       See Things Now
> > mean
> function (x, ...)
> UseMethod("mean")
> <bytecode: 0x7ffe5d0f0c60>
> <environment: namespace:base>
> > movavg
> Error: object 'movavg' not found
> > ggplot
> Error: object 'ggplot' not found
> >
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
John Kane
Kingston ON Canada

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Jun 26 01:33:24 2020
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 25 Jun 2020 16:33:24 -0700
Subject: [R] R Compied for Mac OS X
In-Reply-To: <780FA777-36E8-451F-8078-EA378DD983DE@me.com>
References: <780FA777-36E8-451F-8078-EA378DD983DE@me.com>
Message-ID: <CAGxFJbQWG6hWHxfZt+x6a==F5XSMcPiBa10kPx_jUvo=JCzFgw@mail.gmail.com>

These are functions in extra packages that you have to first download from
a repository, -- presumably lib.stat/.cmu.edu/r/cran -- install, and then
load for use. I suggest you check for tutorials there to to learn how to
use R, as it sounds like you are flying blind.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Jun 25, 2020 at 4:09 PM Gregory Coats via R-help <
r-help at r-project.org> wrote:

> Today, I downloaded, and installed the June 6, 2020 version of R, from the
> CRAN official site at Carnegie Mellon University. Unfortunately, while the
> CMU compiled Mac OS X R application provides access to base R stat
> functions, like mean, it does not provide me with access to any of R?s more
> advanced functions like movavg, and ggplot.
> From where can I download a more complete R executable, compiled for Mac
> OS X?
> Greg Coats
>
> http://lib.stat.cmu.edu/R/CRAN/ <http://lib.stat.cmu.edu/R/CRAN/>
> Download R for (Mac) OS X
> R-4.0.2.pkg (notarized and signed)
> > version
> platform       x86_64-apple-darwin17.0
> arch           x86_64
> os             darwin17.0
> system         x86_64, darwin17.0
> status
> major          4
> minor          0.1
> year           2020
> month          06
> day            06
> svn rev        78648
> language       R
> version.string R version 4.0.1 (2020-06-06)
> nickname       See Things Now
> > mean
> function (x, ...)
> UseMethod("mean")
> <bytecode: 0x7ffe5d0f0c60>
> <environment: namespace:base>
> > movavg
> Error: object 'movavg' not found
> > ggplot
> Error: object 'ggplot' not found
> >
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wjm1 @end|ng |rom c@@@co|umb|@@edu  Fri Jun 26 02:05:11 2020
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Thu, 25 Jun 2020 17:05:11 -0700
Subject: [R] R Compied for Mac OS X
In-Reply-To: <780FA777-36E8-451F-8078-EA378DD983DE@me.com>
References: <780FA777-36E8-451F-8078-EA378DD983DE@me.com>
Message-ID: <CAA99HCyXZtsky_M2Ycepvx0H5puZQzj9DR3+c+K242yxNYfxxQ@mail.gmail.com>

Hi, you can try starting at the link below:

https://stat.ethz.ch/R-manual/R-patched/doc/html/packages.html

Or type any of following commands into your R-Console (for starters):

> library()
> library(help="base")
> library(help="stats")
> library(help="graphics")
> library(help="grDevices")
> library(help="utils")
> library(help="datasets")
> library(help="methods")
>

HTH, Bill.

W. Michels, Ph.D.

On Thu, Jun 25, 2020 at 4:09 PM Gregory Coats via R-help
<r-help at r-project.org> wrote:
>
> Today, I downloaded, and installed the June 6, 2020 version of R, from the CRAN official site at Carnegie Mellon University. Unfortunately, while the CMU compiled Mac OS X R application provides access to base R stat functions, like mean, it does not provide me with access to any of R?s more advanced functions like movavg, and ggplot.
> From where can I download a more complete R executable, compiled for Mac OS X?
> Greg Coats
>
> http://lib.stat.cmu.edu/R/CRAN/ <http://lib.stat.cmu.edu/R/CRAN/>
> Download R for (Mac) OS X
> R-4.0.2.pkg (notarized and signed)
> > version
> platform       x86_64-apple-darwin17.0
> arch           x86_64
> os             darwin17.0
> system         x86_64, darwin17.0
> status
> major          4
> minor          0.1
> year           2020
> month          06
> day            06
> svn rev        78648
> language       R
> version.string R version 4.0.1 (2020-06-06)
> nickname       See Things Now
> > mean
> function (x, ...)
> UseMethod("mean")
> <bytecode: 0x7ffe5d0f0c60>
> <environment: namespace:base>
> > movavg
> Error: object 'movavg' not found
> > ggplot
> Error: object 'ggplot' not found
> >
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kry|ov@r00t @end|ng |rom gm@||@com  Fri Jun 26 09:10:46 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Fri, 26 Jun 2020 10:10:46 +0300
Subject: [R] doParallel cores HPC
In-Reply-To: <DM6PR17MB25728C6AC94E747A70257B4794920@DM6PR17MB2572.namprd17.prod.outlook.com>
References: <DM6PR17MB25728C6AC94E747A70257B4794920@DM6PR17MB2572.namprd17.prod.outlook.com>
Message-ID: <20200626101046.3095c6e2@Tarkus>

On Thu, 25 Jun 2020 00:29:42 +0000
"Silva, Eder David Borges da" <eder.silva at corteva.com> wrote:

> I have the HPC, with 10 nodes, and each node with 20 cores in UNIX OS.

> cl <- makePSOCKcluster(names=c('Host01', ... , 'Host10)
 
> This code is the best way for use all machine power?

The code as written will create one worker _process_ on each of the
hosts. What happens next depends on the code to be running and the way
R is installed.

The code may or may not be written to take advantage of multi-core CPUs
(e.g. using OpenMP). In particular, if R is linked with a
multi-threaded BLAS (such as OpenBLAS or MKL) and uses matrix algebra
during the computation, it may spawn multiple _threads_ to utilise the
CPU better. Whether it succeeds depends on multiple factors, including
the size of the task. On occasion I noticed OpenBLAS threads spending
most of their time in sched_yield() system call, making the kernel do a
lot of unnecessary work, and set the environment variable
OPENBLAS_NUM_THREADS=1 to use only one thread instead.

On the other hand, if the computation is purely single-threaded (or you
disabled the multi-threaded behaviour of OpenMP or BLAS for some
reason), you can spawn 20 workers on each of the 10 hosts:

makePSOCKcluster(names = rep(c('Host01', ..., 'Host10'), each = 20))

You can also try to combine the two approaches by limiting the number
of working threads to a sensible value which results in the threads
spending most of the time computing things (instead of waiting for more
work busy-looping on sched_yield()), then spawning as many processes as
required to utilise all of the cores.

-- 
Best regards,
Ivan


From henr|k@bengt@@on @end|ng |rom gm@||@com  Sat Jun 27 05:20:05 2020
From: henr|k@bengt@@on @end|ng |rom gm@||@com (Henrik Bengtsson)
Date: Fri, 26 Jun 2020 20:20:05 -0700
Subject: [R] doParallel cores HPC
In-Reply-To: <20200626101046.3095c6e2@Tarkus>
References: <DM6PR17MB25728C6AC94E747A70257B4794920@DM6PR17MB2572.namprd17.prod.outlook.com>
 <20200626101046.3095c6e2@Tarkus>
Message-ID: <CAFDcVCTQ9ohVX-=94oK2pmD0pLNyQz5=dQkviG0vDpUmwWp-hw@mail.gmail.com>

> On the other hand, [...], you can spawn 20 workers on each of the 10 hosts:
>
> makePSOCKcluster(names = rep(c('Host01', ..., 'Host10'), each = 20))

Unfortunately, this will most likely not work because it will require
200 open connections - one for each worker - but R limits you to 125
(see ?base::connections):

> A maximum of 128 connections can be allocated (not necessarily open) at any one time. Three of these are pre-allocated (see stdout). The OS will impose limits on the numbers of connections of various types, but these are usually larger than 125.

Depending on the system, you might be able to increase this by
rebuilding R from source after editing a hard-coded constant.  I've
verified that this worked on a local Ubuntu 16.04 system.  See
https://github.com/HenrikBengtsson/Wishlist-for-R/issues/28 for
details about this problem.

/Henrik

On Fri, Jun 26, 2020 at 12:11 AM Ivan Krylov <krylov.r00t at gmail.com> wrote:
>
> On Thu, 25 Jun 2020 00:29:42 +0000
> "Silva, Eder David Borges da" <eder.silva at corteva.com> wrote:
>
> > I have the HPC, with 10 nodes, and each node with 20 cores in UNIX OS.
>
> > cl <- makePSOCKcluster(names=c('Host01', ... , 'Host10)
>
> > This code is the best way for use all machine power?
>
> The code as written will create one worker _process_ on each of the
> hosts. What happens next depends on the code to be running and the way
> R is installed.
>
> The code may or may not be written to take advantage of multi-core CPUs
> (e.g. using OpenMP). In particular, if R is linked with a
> multi-threaded BLAS (such as OpenBLAS or MKL) and uses matrix algebra
> during the computation, it may spawn multiple _threads_ to utilise the
> CPU better. Whether it succeeds depends on multiple factors, including
> the size of the task. On occasion I noticed OpenBLAS threads spending
> most of their time in sched_yield() system call, making the kernel do a
> lot of unnecessary work, and set the environment variable
> OPENBLAS_NUM_THREADS=1 to use only one thread instead.
>
> On the other hand, if the computation is purely single-threaded (or you
> disabled the multi-threaded behaviour of OpenMP or BLAS for some
> reason), you can spawn 20 workers on each of the 10 hosts:
>
> makePSOCKcluster(names = rep(c('Host01', ..., 'Host10'), each = 20))
>
> You can also try to combine the two approaches by limiting the number
> of working threads to a sensible value which results in the threads
> spending most of the time computing things (instead of waiting for more
> work busy-looping on sched_yield()), then spawning as many processes as
> required to utilise all of the cores.
>
> --
> Best regards,
> Ivan
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pd@|gd @end|ng |rom gm@||@com  Sat Jun 27 16:14:12 2020
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Sat, 27 Jun 2020 16:14:12 +0200
Subject: [R] how to extract specific subscript of a matrix
In-Reply-To: <E9A6B727-0CE5-48EE-887A-4840302F4D83@dcn.davis.ca.us>
References: <31210cbb-91e6-fe2a-b958-a01862295d6b@yeah.net>
 <E9A6B727-0CE5-48EE-887A-4840302F4D83@dcn.davis.ca.us>
Message-ID: <E171C28E-42D8-4491-958F-0E209681C83C@gmail.com>

For that, it is more straightforward to use

which(M==1, arr.ind=TRUE)

However, the desired output has 8 indices, not 12. I don't see what the desired pattern is...

- pd

> On 11 Jun 2020, at 03:01 , Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> M <- matrix(c(2,2,rep(1,12), 2), nrow = 5,byrow = FALSE)
> ix <- expand.grid( r = seq.int( nrow( M ) )
>                 , c = seq.int( ncol( M ) )
>                 )
> ix[ 1 == c(M), ]
> 
> 
> On June 10, 2020 5:29:10 PM PDT, Jinsong Zhao <jszhao at yeah.net> wrote:
>> Hi there,
>> 
>> I have a matrix similar as:
>> 
>> M <- matrix(c(2,2,rep(1,12), 2), nrow = 5,byrow = FALSE)
>> 
>> I hope to get the border subscript of the block with value 1. In the 
>> above example, I hope to get:
>> 
>> (3,1), (5,1), (5,2), (4,2), (4,3), (1,3), (1,2), (3,2)
>> 
>> Is there any function can do that? or any implement idea? Thanks!
>> 
>> Best,
>> Jinsong
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From v@r|n@@ch@ @end|ng |rom y@hoo@|r  Sun Jun 28 20:45:31 2020
From: v@r|n@@ch@ @end|ng |rom y@hoo@|r (varin sacha)
Date: Sun, 28 Jun 2020 18:45:31 +0000 (UTC)
Subject: [R] Permutation Ramsey RESET test ?
References: <950706125.8628021.1593369931807.ref@mail.yahoo.com>
Message-ID: <950706125.8628021.1593369931807@mail.yahoo.com>

Dear R-experts,

I am trying to do a permutation test for the Ramsey RESET test. More precisely, I am interested in the "exact" p-value of the test.

I have checked the coin package and all the functions (oneway_test; ...). There are plenty of functions but no one is helping me for RESET test. I have checked as well lmPerm package for linear model but I don't find anything that can help me. I have googled but did not find anything to help me. I guess I have to write my own function. I really don't know how to do that. Any help would be highly appreciated.

Here below the reproducible example :

####################
Y=c(22349,34567,23123,43212,56765,45321,34534,33345,34356,56434,65434,32143,34532,23453,34321,65434,40983,56432,23435,65432)
X1=c(23,12,43,23,54,34,12,11,32,23,21,12,11,43,54,23,23,22,17,18)
X2=c(121,212,101,109,432,154,342,176,324,254,421,342,333,444,123,213,243,254,398,397)
X3=c(12,32,22,12,13,15,23,24,31,17,18,21,23,24,31,21,12,18,19,20)

fit=lm(Y~ X1+X2+X3)

install.packages("lmtest")
library(lmtest)
resettest(Y~ X1+X2+X3)
####################

?


From ycd|ng @end|ng |rom coh@org  Sun Jun 28 22:35:30 2020
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Sun, 28 Jun 2020 20:35:30 +0000
Subject: [R] help with sqldf
Message-ID: <A86C6438FB909A409DDEF926277952B6113EF6EA@PPWEXCH2KX13.coh.org>

Hi R Users,

I tried to use sql in R;  test1 works well, 
library(sqldf)
test1 <- sqldf("select * from r where V1 like '%GCCATGTCAGCACACTACC%TGAAACCTTTAACTATTT%'")
test2 <- sqldf("select * from r where V1 like markerinfo$flank1[1] ")

but I want to store the search content in a markerinfo file as shown below
> markerinfo$flank1[1]
[1] "%GCCATGTCAGCACACTACC%TGAAACCTTTAACTATTT%"

However, test2 does not work well.
How to make test2 work?
Thank you,

Ding


----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-  

This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)


From @@r@h@go@|ee @end|ng |rom gm@||@com  Sun Jun 28 23:01:18 2020
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Sun, 28 Jun 2020 17:01:18 -0400
Subject: [R] help with sqldf
In-Reply-To: <A86C6438FB909A409DDEF926277952B6113EF6EA@PPWEXCH2KX13.coh.org>
References: <A86C6438FB909A409DDEF926277952B6113EF6EA@PPWEXCH2KX13.coh.org>
Message-ID: <CAM_vju=0GPcoVzscktzqZR=ZZ2_1CpiXX6v+ZXLcdtjHNdZfNQ@mail.gmail.com>

WIthout knowing anything about your research domain, take a look at
what your sql looks like:

"select * from r where V1 like markerinfo$flank1[1] "

You are asking to match literally "markerinfo$flank1[1]" and not the R
object referred to.

Try something more like,

paste("select * from r where V1 like", markerinfo$flank1[1])

Sarah



On Sun, Jun 28, 2020 at 4:35 PM Yuan Chun Ding <ycding at coh.org> wrote:
>
> Hi R Users,
>
> I tried to use sql in R;  test1 works well,
> library(sqldf)
> test1 <- sqldf("select * from r where V1 like '%GCCATGTCAGCACACTACC%TGAAACCTTTAACTATTT%'")
> test2 <- sqldf("select * from r where V1 like markerinfo$flank1[1] ")
>
> but I want to store the search content in a markerinfo file as shown below
> > markerinfo$flank1[1]
> [1] "%GCCATGTCAGCACACTACC%TGAAACCTTTAACTATTT%"
>
> However, test2 does not work well.
> How to make test2 work?
> Thank you,
>
> Ding
>
>
> ----------------------------------------------------------------------

-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From ycd|ng @end|ng |rom coh@org  Sun Jun 28 23:44:28 2020
From: ycd|ng @end|ng |rom coh@org (Yuan Chun Ding)
Date: Sun, 28 Jun 2020 21:44:28 +0000
Subject: [R] help with sqldf
In-Reply-To: <CAM_vju=0GPcoVzscktzqZR=ZZ2_1CpiXX6v+ZXLcdtjHNdZfNQ@mail.gmail.com>
References: <A86C6438FB909A409DDEF926277952B6113EF6EA@PPWEXCH2KX13.coh.org>
 <CAM_vju=0GPcoVzscktzqZR=ZZ2_1CpiXX6v+ZXLcdtjHNdZfNQ@mail.gmail.com>
Message-ID: <A86C6438FB909A409DDEF926277952B6113EF720@PPWEXCH2KX13.coh.org>

Thank you,  Sarah, I modified your suggestion a little and it works.

Ding

-----Original Message-----
From: Sarah Goslee [mailto:sarah.goslee at gmail.com] 
Sent: Sunday, June 28, 2020 2:01 PM
To: Yuan Chun Ding
Cc: r-help at r-project.org
Subject: Re: [R] help with sqldf

[Attention: This email came from an external source. Do not open attachments or click on links from unknown senders or unexpected emails.]

----------------------------------------------------------------------
WIthout knowing anything about your research domain, take a look at what your sql looks like:

"select * from r where V1 like markerinfo$flank1[1] "

You are asking to match literally "markerinfo$flank1[1]" and not the R object referred to.

Try something more like,

paste("select * from r where V1 like", markerinfo$flank1[1])

Sarah



On Sun, Jun 28, 2020 at 4:35 PM Yuan Chun Ding <ycding at coh.org> wrote:
>
> Hi R Users,
>
> I tried to use sql in R;  test1 works well,
> library(sqldf)
> test1 <- sqldf("select * from r where V1 like 
> '%GCCATGTCAGCACACTACC%TGAAACCTTTAACTATTT%'")
> test2 <- sqldf("select * from r where V1 like markerinfo$flank1[1] ")
>
> but I want to store the search content in a markerinfo file as shown 
> below
> > markerinfo$flank1[1]
> [1] "%GCCATGTCAGCACACTACC%TGAAACCTTTAACTATTT%"
>
> However, test2 does not work well.
> How to make test2 work?
> Thank you,
>
> Ding
>
>
> ----------------------------------------------------------------------

--
Sarah Goslee (she/her)
https://urldefense.com/v3/__http://www.numberwright.com__;!!Fou38LsQmgU!9SCiZIQ_zHuDAXWGYxM7lRBCYFNjyeIBBixmHgks3DT_1F48jN5kSuPQ5c2T$ 

----------------------------------------------------------------------
------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-  

This message and any attachments are intended solely for the individual or entity to which they are addressed. This communication may contain information that is privileged, confidential, or exempt from disclosure under applicable law (e.g., personal health information, research data, financial information). Because this e-mail has been sent without encryption, individuals other than the intended recipient may be able to view the information, forward it to others or tamper with the information without the knowledge or consent of the sender. If you are not the intended recipient, or the employee or person responsible for delivering the message to the intended recipient, any dissemination, distribution or copying of the communication is strictly prohibited. If you received the communication in error, please notify the sender immediately by replying to this message and deleting the message and any accompanying files from your system. If, due to the security risks, you do not wish to receive further communications via e-mail, please reply to this message and inform the sender that you do not wish to receive further e-mail from the sender. (LCP301)
------------------------------------------------------------

From er|nm@hodge@@ @end|ng |rom gm@||@com  Mon Jun 29 04:54:49 2020
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Sun, 28 Jun 2020 20:54:49 -0600
Subject: [R] Using OpenBLAS on Ubuntu
Message-ID: <CACxE24nt7ohUzCZLdYv8d5-42oy6sA=tzHrNCxNm6CLspuHJwg@mail.gmail.com>

Hello!

Hope everyone is doing well.

I'm not sure if this is the correct place to post, but I thought I would
start here.

I have R 4.0.2 on Ubuntu 20.04.  I would like to use OpenBLAS with it, but
I'm not sure if I can because I did not compile from source.  Is that
possible, please?

Thanks for any help!

Sincerely,
Erin

Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Jun 29 05:51:22 2020
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 28 Jun 2020 20:51:22 -0700
Subject: [R] Using OpenBLAS on Ubuntu
In-Reply-To: <CACxE24nt7ohUzCZLdYv8d5-42oy6sA=tzHrNCxNm6CLspuHJwg@mail.gmail.com>
References: <CACxE24nt7ohUzCZLdYv8d5-42oy6sA=tzHrNCxNm6CLspuHJwg@mail.gmail.com>
Message-ID: <2DA0B7CE-D5A9-416C-8A44-3ADFBB3A04BC@dcn.davis.ca.us>

Wouldn't this question make more sense in r-sig-debian?

On June 28, 2020 7:54:49 PM PDT, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>Hello!
>
>Hope everyone is doing well.
>
>I'm not sure if this is the correct place to post, but I thought I
>would
>start here.
>
>I have R 4.0.2 on Ubuntu 20.04.  I would like to use OpenBLAS with it,
>but
>I'm not sure if I can because I did not compile from source.  Is that
>possible, please?
>
>Thanks for any help!
>
>Sincerely,
>Erin
>
>Erin Hodgess, PhD
>mailto: erinm.hodgess at gmail.com
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From er|nm@hodge@@ @end|ng |rom gm@||@com  Mon Jun 29 06:07:03 2020
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Sun, 28 Jun 2020 22:07:03 -0600
Subject: [R] Using OpenBLAS on Ubuntu
In-Reply-To: <2DA0B7CE-D5A9-416C-8A44-3ADFBB3A04BC@dcn.davis.ca.us>
References: <CACxE24nt7ohUzCZLdYv8d5-42oy6sA=tzHrNCxNm6CLspuHJwg@mail.gmail.com>
 <2DA0B7CE-D5A9-416C-8A44-3ADFBB3A04BC@dcn.davis.ca.us>
Message-ID: <CACxE24meB4+tPhC_aSf65jxAtKE2oo0=5Z69-c3=sdtDxacUCw@mail.gmail.com>

That?s why I thought to check here first.

Thanks!

On Sun, Jun 28, 2020 at 9:51 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Wouldn't this question make more sense in r-sig-debian?
>
> On June 28, 2020 7:54:49 PM PDT, Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
> >Hello!
> >
> >Hope everyone is doing well.
> >
> >I'm not sure if this is the correct place to post, but I thought I
> >would
> >start here.
> >
> >I have R 4.0.2 on Ubuntu 20.04.  I would like to use OpenBLAS with it,
> >but
> >I'm not sure if I can because I did not compile from source.  Is that
> >possible, please?
> >
> >Thanks for any help!
> >
> >Sincerely,
> >Erin
> >
> >Erin Hodgess, PhD
> >mailto: erinm.hodgess at gmail.com
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
-- 
Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From jmh@nnon@ucd@v|@ @end|ng |rom gm@||@com  Mon Jun 29 06:27:14 2020
From: jmh@nnon@ucd@v|@ @end|ng |rom gm@||@com (Michael Hannon)
Date: Sun, 28 Jun 2020 21:27:14 -0700
Subject: [R] Using OpenBLAS on Ubuntu
In-Reply-To: <2DA0B7CE-D5A9-416C-8A44-3ADFBB3A04BC@dcn.davis.ca.us>
References: <CACxE24nt7ohUzCZLdYv8d5-42oy6sA=tzHrNCxNm6CLspuHJwg@mail.gmail.com>
 <2DA0B7CE-D5A9-416C-8A44-3ADFBB3A04BC@dcn.davis.ca.us>
Message-ID: <CACdH2ZboZacm8L1Coj1CQsa0JU+chqCa3ktM0yKgB78bTTvwoQ@mail.gmail.com>

Or maybe R-devel.

On Sun, Jun 28, 2020 at 8:51 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> Wouldn't this question make more sense in r-sig-debian?
>
> On June 28, 2020 7:54:49 PM PDT, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> >Hello!
> >
> >Hope everyone is doing well.
> >
> >I'm not sure if this is the correct place to post, but I thought I
> >would
> >start here.
> >
> >I have R 4.0.2 on Ubuntu 20.04.  I would like to use OpenBLAS with it,
> >but
> >I'm not sure if I can because I did not compile from source.  Is that
> >possible, please?
> >
> >Thanks for any help!
> >
> >Sincerely,
> >Erin
> >
> >Erin Hodgess, PhD
> >mailto: erinm.hodgess at gmail.com
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From er|nm@hodge@@ @end|ng |rom gm@||@com  Mon Jun 29 06:28:20 2020
From: er|nm@hodge@@ @end|ng |rom gm@||@com (Erin Hodgess)
Date: Sun, 28 Jun 2020 22:28:20 -0600
Subject: [R] Using OpenBLAS on Ubuntu
In-Reply-To: <CACdH2ZboZacm8L1Coj1CQsa0JU+chqCa3ktM0yKgB78bTTvwoQ@mail.gmail.com>
References: <CACxE24nt7ohUzCZLdYv8d5-42oy6sA=tzHrNCxNm6CLspuHJwg@mail.gmail.com>
 <2DA0B7CE-D5A9-416C-8A44-3ADFBB3A04BC@dcn.davis.ca.us>
 <CACdH2ZboZacm8L1Coj1CQsa0JU+chqCa3ktM0yKgB78bTTvwoQ@mail.gmail.com>
Message-ID: <CACxE24==LEAbAB6YhHBu5KXOR0owW9hNY+y_jZZ=iCP=_DezXA@mail.gmail.com>

Thanks

On Sun, Jun 28, 2020 at 10:27 PM Michael Hannon <jmhannon.ucdavis at gmail.com>
wrote:

> Or maybe R-devel.
>
> On Sun, Jun 28, 2020 at 8:51 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> >
> > Wouldn't this question make more sense in r-sig-debian?
> >
> > On June 28, 2020 7:54:49 PM PDT, Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
> > >Hello!
> > >
> > >Hope everyone is doing well.
> > >
> > >I'm not sure if this is the correct place to post, but I thought I
> > >would
> > >start here.
> > >
> > >I have R 4.0.2 on Ubuntu 20.04.  I would like to use OpenBLAS with it,
> > >but
> > >I'm not sure if I can because I did not compile from source.  Is that
> > >possible, please?
> > >
> > >Thanks for any help!
> > >
> > >Sincerely,
> > >Erin
> > >
> > >Erin Hodgess, PhD
> > >mailto: erinm.hodgess at gmail.com
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Sent from my phone. Please excuse my brevity.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
-- 
Erin Hodgess, PhD
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From @enge| @end|ng |rom p@terr@@com  Mon Jun 29 04:20:06 2020
From: @enge| @end|ng |rom p@terr@@com (Alan)
Date: Mon, 29 Jun 2020 11:20:06 +0900
Subject: [R] readOGR workaround for Japanese UTF-8 geojson
Message-ID: <00d601d64dbb$ce317860$6a946920$@com>

I am working on a project https://github.com/AlanInTsukuba/jpucd that
involves
extracting shapefiles and property data from Japanese geojson files. When
reading with readOGR(ibarakipath1 , encoding="UTF-8", use_iconv=TRUE),
I find that the subsets of cannot be written with writeOGR without losing
text fields that are in Japanese text. I found the following workaround but
wonder if there is a better way to do this.

# load ibaraki shapefiles, extract TX subset, write to geojson
library(jpucd)
shppath <- system.file("extdata",package="jpucd")

ibarakipath1 <-
paste(shppath,"JPGen2005CTgenlCY2000P08Ibaraki.geojson",sep="/")

#^ JPGen2005CTgenlCY2000P08Ibaraki.geojson is a UTF-8 encoded geojson file
#^     having Japanese names in property fields. To be able to
#^    read these fields, they need to be converted (to switch-jis?).
#^     The following command does this.
#^ This can also be done by use_iconv=FALSE and setting
#^     the encoding of the Japanese columns using Encoding(x) <- "UTF-8".

ibaraki <- readOGR(ibarakipath1 , encoding="UTF-8", use_iconv=FALSE) ##
use_iconv=TRUE
## loads so that the Japanese fields are readable but writeOGR doesn$B!G(Bt
write them.
head(ibaraki at data)

#^ Apply Encoding(x) <- $B!H(BUTF-8$B!I(B
for (name in colnames(ibaraki at data[,sapply(ibaraki @data, is.character)])){
  Encoding(ibaraki @data[[name]]) <- "UTF-8"}

#^ Get TX subset
tx2000 <- ibaraki[ibaraki at data$CITY_NAME=="$B$D$/$P;T(B
"|ibaraki at data$CITY_NAME=="$B<iC+D.(B"
              |ibaraki at data$CITY_NAME=="$B0KF`D.(B"|ibaraki at data$CITY_NAME=="$BC+(B
$BOB86B<(B",]
head(tx2000 at data)

#^ Write it.
dsn <- "TsukubaExpressCensusDistricts2000.geojson"
writeOGR(tx2000 , dsn,layer="TsukubaExpressCensusDistricts2000" ,
driver="GeoJSON", dataset_options = NULL,
layer_options=NULL, verbose = FALSE, check_exists=NULL,
overwrite_layer=FALSE, delete_dsn=FALSE, morphToESRI=NULL,
encoding="UTF-8")

Thank you.
Alan
 <https://alanintsukuba.github.io/> https://alanintsukuba.github.io/


	[[alternative HTML version deleted]]


From j|en@gu90 @end|ng |rom gm@||@com  Sat Jun 27 22:10:26 2020
From: j|en@gu90 @end|ng |rom gm@||@com (Jiena McLellan)
Date: Sat, 27 Jun 2020 16:10:26 -0400
Subject: [R] [R-pkgs] forestry v0.1.0 on CRAN
Message-ID: <CAB+AFnL4HigGrUeZeSCEhayfkGW2tSBL0d9FS+zjNo+qop+3sQ@mail.gmail.com>

R Users,

I?m writing to introduce a new package, forestry. This package offers a
series of utility functions to help with reshaping the hierarchy of data
tree, and reform the structure of data tree.

It is particularly useful in these following ways:

1. Reshape tree data then convert to JSON to fit the (nested) JSON format
of your htmlwidget.
2. Manipulate data across a desired level. For example, get `cumsum` data
across a desired level in data tree.

Hopefully you find this useful. Please feel free to reach out with feedback
or questions.

CRAN: https://cran.r-project.org/web/packages/forestry/index.html
Github: https://github.com/jienagu/forestry

Best Regards,
Jiena

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Jun 30 11:35:01 2020
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 30 Jun 2020 11:35:01 +0200
Subject: [R] version plot problem
In-Reply-To: <b1bf757c9afd478688f7d95477cfe49f@SRVEXCHCM1302.precheza.cz>
References: <5cba6fbe1f574bfc830a4c47343f1945@SRVEXCHCM1302.precheza.cz>
 <20200624131236.GA24907@posteo.no>
 <251c1576907b443ab3bf3bdc55926b81@GBDCVPEXC08.corp.lgc-group.com>
 <b1bf757c9afd478688f7d95477cfe49f@SRVEXCHCM1302.precheza.cz>
Message-ID: <24315.1861.131402.615115@stat.math.ethz.ch>

>>>>> PIKAL Petr 
>>>>>     on Thu, 25 Jun 2020 14:45:09 +0000 writes:

    > Thanks. 
    > I try to spread R to some other people and I use 4.0.0 - version.string R
    > Under development (unstable) (2020-03-08 r77917) nickname       Unsuffered
    > Consequences  whereas they use R 3.6.3
    > version.string R version 3.6.3 (2020-02-29) nickname       Holding the
    > Windsock

    > With artificial data frame both behave with the same error
    > dat <- data.frame(a=letters[1:5], b=1:5)
    > dat$a <- as.character(dat$a)
    > plot(dat)
    > Error in plot.window(...) : need finite 'xlim' values
    > In addition: Warning messages:
    > 1: In xy.coords(x, y, xlabel, ylabel, log) : NAs introduced by coercion
    > 2: In min(x) : no non-missing arguments to min; returning Inf
    > 3: In max(x) : no non-missing arguments to max; returning -Inf

    > So far so good.

    > But with original data with **character** columns
    > dput(head(mok))
    > mok <- structure(list(a = c("Kalcin?t A", "Kalcin?t A", "Kalcin?t A", 
    > "Kalcin?t A", "Kalcin?t A", "Kalcin?t A"), b = c("TB", "TB", 
    > "TB", "TB", "TB", "TB"), c = c("6101B", "6101B", "6101B", "6101B", 
    > "6101B", "6101B"), d = structure(c(1590624000, 1590624000, 1590537600, 
    > 1590537600, 1590537600, 1590537600), class = c("POSIXct", "POSIXt"
    > ), tzone = "UTC"), e = structure(c(1590649200, 1590634800, 1590620400, 
    > 1590606000, 1590591600, 1590577200), class = c("POSIXct", "POSIXt"
    > ), tzone = "UTC"), f = structure(c(1590649200, 1590634800, 1590620400, 
    > 1590606000, 1590591600, 1590577200), class = c("POSIXct", "POSIXt"
    > ), tzone = "UTC"), g = c("BAROTOV?", "KR?TK?", "KR?TK?", "HOLASOV?", 
    > "HOLASOV?", "BAROTOV?"), h = c(239.4, 221, 190.3, 215.7, 241.4, 
    > 214.8), i = c(48.7, 55.6, 52.9, 50.1, 46.6, 54.4), j = c(94.2, 
    > 93, 92.4, 94.2, 96.3, 94.4), k = c(0.8, 1, 1, 0.8, 0.7, 0.8)), row.names =
    > c(NA, 
    > 6L), class = "data.frame")

    > PLOT WORKS in R 400 but not in R 363??????

    > plot(mok)

    > Why it works in R400??? How should I explain it?

(it's  "R 4.0.0" , here spaces are relevant I think)

Well, new versions of R  are always better than previous ones
(even though, yes, rarely sometimes bugs are introduced).

and you have heard that  R 4.0.0  came with *many* new features, right ?

In this case the long NEW FEATURES section in the
NEWS | NEWS.pdf | NEWS.html files contained the entry

    ? data.matrix() now converts character columns to factors and from
      this to integers.

and this contains the answer to your question, as

  plot(mok)  |->  plot.data.frame(mok)  |->  pairs(data.matrix(mok))

and  data.matrix(mok) in R 3.6.3 gives 4 warnings and ends in a
character matrix.

--

And yes, the above new feature was related and made particularly
sense with the important user-visible  stringsAsFactors  change
in R 4.0.0; see also the corresponding R blog (by Kurt Hornik) :

  https://developer.r-project.org/Blog/public/2020/02/16/stringsasfactors/


Martin Maechler
R Core team  and  ETH Zurich


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Jun 30 11:39:11 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 30 Jun 2020 11:39:11 +0200
Subject: [R] How to use mle2 function?
Message-ID: <CAMk+s2Rmmga-kBnUZqA1wxgp_iqvsfDrmmXER0v4-OtG6-u5Yg@mail.gmail.com>

Hello,
I would like to optimize the function:
```
holling = function(a, b, x) {
  y = (a * x^2) / (b^2 + x^2)
  return(y)
}
```
I am trying to use the function mle2 from bbmle, but how do I need to
feed the data?
If I give `holling` as function to be optimized, passing the starting
values for `a`, `b`, and `x`, I get:
```
X = 1:60
A = 3261
B = 10
O = mle2(minuslogl = holling, start = list(a = A, h = B, x = X))
> Error in mle2(minuslogl = holling, start = list(a = A, b = B, x = X)) :
  some named arguments in 'start' are not arguments to the specified
log-likelihood function
```
If I pass the negative log-function (assuming a binomial distribution
of the data, which I am not sure about)
```
nll = function(p, n, k) {
  # extract parms
  a = p[1]
  h = p[2]
  # calculate probability of attack
  pred = a/(1+a*h*n)
  # calc NLL
  -sum(dbinom(k, prob = pred, size = n, log = TRUE))
}
```
then I get the same error:
```
> O = mle2(minuslogl = nll, start = list(a = A, h = B),
+          data = list(n = 57200000, k = A))
Error in mle2(minuslogl = nll, start = list(a = A, h = B), data =
list(n = 57200000,  :
  some named arguments in 'start' are not arguments to the specified
log-likelihood function
```
but with the disadvantage of working on an assumed function (nll).
How can I optimize the function `holling` properly?
Thank you




-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Jun 30 12:00:47 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 30 Jun 2020 12:00:47 +0200
Subject: [R] argument "x" is missing in minpack.lm
Message-ID: <CAMk+s2SZUAoF1tmQh_O6fx504VqM53DEHJAY0fsFCiHXBqAWJA@mail.gmail.com>

Hello,
I am trying to optimize a function with the function nls.lm from the
package minpack.lm. But I can't get it right:
```
A = 3261
B = 10
K = c(8,   24,   39,   63,   89,  115,  153,  196,  242,  287,  344,  408,  473,
      546,  619,  705,  794,  891,  999, 1096, 1242, 1363, 1506, 1648, 1753,
      1851, 1987, 2101, 2219, 2328, 2425, 2575, 2646, 2698, 2727, 2771, 2818,
      2853, 2895, 2926, 2964, 2995, 3025, 3053, 3080, 3102, 3119, 3141, 3152,
      3159, 3172, 3182, 3196, 3209, 3220, 3231, 3239, 3246, 3252, 3261)
O = nls.lm(list(a=A, b=B, x=X), holling,
           lower=NULL, upper=NULL, jac = NULL)
> Error in fn(par, ...) : argument "x" is missing, with no default
```
What am I missing?
Is nls.lm the right function for functions that are not linear?
Thank you
-- 
Best regards,
Luigi


From er|cjberger @end|ng |rom gm@||@com  Tue Jun 30 12:03:18 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 30 Jun 2020 13:03:18 +0300
Subject: [R] How to use mle2 function?
In-Reply-To: <CAMk+s2Rmmga-kBnUZqA1wxgp_iqvsfDrmmXER0v4-OtG6-u5Yg@mail.gmail.com>
References: <CAMk+s2Rmmga-kBnUZqA1wxgp_iqvsfDrmmXER0v4-OtG6-u5Yg@mail.gmail.com>
Message-ID: <CAGgJW741SayyPJeG72K8AVOs9hgTBrSC+-k3t7WAwE9N1wGbjw@mail.gmail.com>

Hi Luigi,
I took a quick look.

First error:
You wrote
O = mle2(minuslogl = holling, start = list(a = A, h = B, x = X))

it should be b=B  (h is not an argument of holling())
The error message gave very precise information!

Second error:
You wrote
O = mle2(minuslogl = nll, start = list(a = A, h = B),   data = list(n
= 57200000, k = A))
but the arguments to nll() are p,n,k. Setting start to values for a
and h causes the function to complain.

HTH,
Eric

On Tue, Jun 30, 2020 at 12:45 PM Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
>
> Hello,
> I would like to optimize the function:
> ```
> holling = function(a, b, x) {
>   y = (a * x^2) / (b^2 + x^2)
>   return(y)
> }
> ```
> I am trying to use the function mle2 from bbmle, but how do I need to
> feed the data?
> If I give `holling` as function to be optimized, passing the starting
> values for `a`, `b`, and `x`, I get:
> ```
> X = 1:60
> A = 3261
> B = 10
> O = mle2(minuslogl = holling, start = list(a = A, h = B, x = X))
> > Error in mle2(minuslogl = holling, start = list(a = A, b = B, x = X)) :
>   some named arguments in 'start' are not arguments to the specified
> log-likelihood function
> ```
> If I pass the negative log-function (assuming a binomial distribution
> of the data, which I am not sure about)
> ```
> nll = function(p, n, k) {
>   # extract parms
>   a = p[1]
>   h = p[2]
>   # calculate probability of attack
>   pred = a/(1+a*h*n)
>   # calc NLL
>   -sum(dbinom(k, prob = pred, size = n, log = TRUE))
> }
> ```
> then I get the same error:
> ```
> > O = mle2(minuslogl = nll, start = list(a = A, h = B),
> +          data = list(n = 57200000, k = A))
> Error in mle2(minuslogl = nll, start = list(a = A, h = B), data =
> list(n = 57200000,  :
>   some named arguments in 'start' are not arguments to the specified
> log-likelihood function
> ```
> but with the disadvantage of working on an assumed function (nll).
> How can I optimize the function `holling` properly?
> Thank you
>
>
>
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @@r@h@go@|ee @end|ng |rom gm@||@com  Tue Jun 30 13:32:07 2020
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Tue, 30 Jun 2020 07:32:07 -0400
Subject: [R] argument "x" is missing in minpack.lm
In-Reply-To: <CAMk+s2SZUAoF1tmQh_O6fx504VqM53DEHJAY0fsFCiHXBqAWJA@mail.gmail.com>
References: <CAMk+s2SZUAoF1tmQh_O6fx504VqM53DEHJAY0fsFCiHXBqAWJA@mail.gmail.com>
Message-ID: <CAM_vjumpYbPoCDqC8pnJCksGPrq-SbMKLur6ZPGYY7nt=iLRMQ@mail.gmail.com>

You create objects A, B, and K, but then use A, B, and X in the call to
nls.lm().

I have no idea if nls.lm is the right tool for your job, but I do know that
you need to use the same names.

Sarah

On Tue, Jun 30, 2020 at 6:01 AM Luigi Marongiu <marongiu.luigi at gmail.com>
wrote:

> Hello,
> I am trying to optimize a function with the function nls.lm from the
> package minpack.lm. But I can't get it right:
> ```
> A = 3261
> B = 10
> K = c(8,   24,   39,   63,   89,  115,  153,  196,  242,  287,  344,
> 408,  473,
>       546,  619,  705,  794,  891,  999, 1096, 1242, 1363, 1506, 1648,
> 1753,
>       1851, 1987, 2101, 2219, 2328, 2425, 2575, 2646, 2698, 2727, 2771,
> 2818,
>       2853, 2895, 2926, 2964, 2995, 3025, 3053, 3080, 3102, 3119, 3141,
> 3152,
>       3159, 3172, 3182, 3196, 3209, 3220, 3231, 3239, 3246, 3252, 3261)
> O = nls.lm(list(a=A, b=B, x=X), holling,
>            lower=NULL, upper=NULL, jac = NULL)
> > Error in fn(par, ...) : argument "x" is missing, with no default
> ```
> What am I missing?
> Is nls.lm the right function for functions that are not linear?
> Thank you
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Sarah Goslee (she/her)
http://www.sarahgoslee.com

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Jun 30 13:53:10 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 30 Jun 2020 13:53:10 +0200
Subject: [R] argument "x" is missing in minpack.lm
In-Reply-To: <CAM_vjumpYbPoCDqC8pnJCksGPrq-SbMKLur6ZPGYY7nt=iLRMQ@mail.gmail.com>
References: <CAMk+s2SZUAoF1tmQh_O6fx504VqM53DEHJAY0fsFCiHXBqAWJA@mail.gmail.com>
 <CAM_vjumpYbPoCDqC8pnJCksGPrq-SbMKLur6ZPGYY7nt=iLRMQ@mail.gmail.com>
Message-ID: <CAMk+s2TnZzoWDBDE0aT3W=NrJf=0waHhSG_ATtjeZ9BKiXqw=Q@mail.gmail.com>

But I get the same error even if I run:
```
parms = list(a=3261, b=10, x=CH$Cum_Dead[1:60])
O = nls.lm(parms, holling,
           lower=NULL, upper=NULL, jac = NULL)
> Error in fn(par, ...) : argument "x" is missing, with no default
```
the function to be optimized is:
```
function(a, b, x) {
  y = (a * x^2) / (b^2 + x^2)
  return(y)
}
```
so the parameters a, b, x are the same I called within nls.lm

On Tue, Jun 30, 2020 at 1:32 PM Sarah Goslee <sarah.goslee at gmail.com> wrote:
>
> You create objects A, B, and K, but then use A, B, and X in the call to nls.lm().
>
> I have no idea if nls.lm is the right tool for your job, but I do know that you need to use the same names.
>
> Sarah
>
> On Tue, Jun 30, 2020 at 6:01 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>
>> Hello,
>> I am trying to optimize a function with the function nls.lm from the
>> package minpack.lm. But I can't get it right:
>> ```
>> A = 3261
>> B = 10
>> K = c(8,   24,   39,   63,   89,  115,  153,  196,  242,  287,  344,  408,  473,
>>       546,  619,  705,  794,  891,  999, 1096, 1242, 1363, 1506, 1648, 1753,
>>       1851, 1987, 2101, 2219, 2328, 2425, 2575, 2646, 2698, 2727, 2771, 2818,
>>       2853, 2895, 2926, 2964, 2995, 3025, 3053, 3080, 3102, 3119, 3141, 3152,
>>       3159, 3172, 3182, 3196, 3209, 3220, 3231, 3239, 3246, 3252, 3261)
>> O = nls.lm(list(a=A, b=B, x=X), holling,
>>            lower=NULL, upper=NULL, jac = NULL)
>> > Error in fn(par, ...) : argument "x" is missing, with no default
>> ```
>> What am I missing?
>> Is nls.lm the right function for functions that are not linear?
>> Thank you
>> --
>> Best regards,
>> Luigi
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sarah Goslee (she/her)
> http://www.sarahgoslee.com



-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Jun 30 14:00:21 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 30 Jun 2020 14:00:21 +0200
Subject: [R] How to use mle2 function?
In-Reply-To: <CAGgJW741SayyPJeG72K8AVOs9hgTBrSC+-k3t7WAwE9N1wGbjw@mail.gmail.com>
References: <CAMk+s2Rmmga-kBnUZqA1wxgp_iqvsfDrmmXER0v4-OtG6-u5Yg@mail.gmail.com>
 <CAGgJW741SayyPJeG72K8AVOs9hgTBrSC+-k3t7WAwE9N1wGbjw@mail.gmail.com>
Message-ID: <CAMk+s2RaS1TzzTiKHKLc01mouLzieyB2bYWZgJfKk_O5F+0rmg@mail.gmail.com>

Sorry for the typo, but I have the same error if using b instead of h:
```
> O = mle2(minuslogl = holling, start = list(a = A, b = B))
> Error in minuslogl(a = 3261, b = 10) :
  argument "x" is missing, with no default
# let's add x
X = c(8,   24,   39,   63,   89,  115,  153,  196,  242,  287,  344,  408,  473,
      546,  619,  705,  794,  891,  999, 1096, 1242, 1363, 1506, 1648, 1753,
      1851, 1987, 2101, 2219, 2328, 2425, 2575, 2646, 2698, 2727, 2771, 2818,
      2853, 2895, 2926, 2964, 2995, 3025, 3053, 3080, 3102, 3119, 3141, 3152,
      3159, 3172, 3182, 3196, 3209, 3220, 3231, 3239, 3246, 3252, 3261)
O = mle2(minuslogl = holling, start = list(a = A, b = B, x = X))
Error in mle2(minuslogl = holling, start = list(a = A, b = B, x = X)) :
  some named arguments in 'start' are not arguments to the specified
log-likelihood function
```
And even if I use the log-likelihood function:
```
O = mle2(minuslogl = nll, start = list(p = c(A, B), n = 57200000, x = X))
> Error in mle2(minuslogl = nll, start = list(p = c(A, B), n = 57200000,  :
  some named arguments in 'start' are not arguments to the specified
log-likelihood function
```

On Tue, Jun 30, 2020 at 12:03 PM Eric Berger <ericjberger at gmail.com> wrote:
>
> Hi Luigi,
> I took a quick look.
>
> First error:
> You wrote
> O = mle2(minuslogl = holling, start = list(a = A, h = B, x = X))
>
> it should be b=B  (h is not an argument of holling())
> The error message gave very precise information!
>
> Second error:
> You wrote
> O = mle2(minuslogl = nll, start = list(a = A, h = B),   data = list(n
> = 57200000, k = A))
> but the arguments to nll() are p,n,k. Setting start to values for a
> and h causes the function to complain.
>
> HTH,
> Eric
>
> On Tue, Jun 30, 2020 at 12:45 PM Luigi Marongiu
> <marongiu.luigi at gmail.com> wrote:
> >
> > Hello,
> > I would like to optimize the function:
> > ```
> > holling = function(a, b, x) {
> >   y = (a * x^2) / (b^2 + x^2)
> >   return(y)
> > }
> > ```
> > I am trying to use the function mle2 from bbmle, but how do I need to
> > feed the data?
> > If I give `holling` as function to be optimized, passing the starting
> > values for `a`, `b`, and `x`, I get:
> > ```
> > X = 1:60
> > A = 3261
> > B = 10
> > O = mle2(minuslogl = holling, start = list(a = A, h = B, x = X))
> > > Error in mle2(minuslogl = holling, start = list(a = A, b = B, x = X)) :
> >   some named arguments in 'start' are not arguments to the specified
> > log-likelihood function
> > ```
> > If I pass the negative log-function (assuming a binomial distribution
> > of the data, which I am not sure about)
> > ```
> > nll = function(p, n, k) {
> >   # extract parms
> >   a = p[1]
> >   h = p[2]
> >   # calculate probability of attack
> >   pred = a/(1+a*h*n)
> >   # calc NLL
> >   -sum(dbinom(k, prob = pred, size = n, log = TRUE))
> > }
> > ```
> > then I get the same error:
> > ```
> > > O = mle2(minuslogl = nll, start = list(a = A, h = B),
> > +          data = list(n = 57200000, k = A))
> > Error in mle2(minuslogl = nll, start = list(a = A, h = B), data =
> > list(n = 57200000,  :
> >   some named arguments in 'start' are not arguments to the specified
> > log-likelihood function
> > ```
> > but with the disadvantage of working on an assumed function (nll).
> > How can I optimize the function `holling` properly?
> > Thank you
> >
> >
> >
> >
> > --
> > Best regards,
> > Luigi
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From kry|ov@r00t @end|ng |rom gm@||@com  Tue Jun 30 14:04:41 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Tue, 30 Jun 2020 15:04:41 +0300
Subject: [R] argument "x" is missing in minpack.lm
In-Reply-To: <CAMk+s2TnZzoWDBDE0aT3W=NrJf=0waHhSG_ATtjeZ9BKiXqw=Q@mail.gmail.com>
References: <CAMk+s2SZUAoF1tmQh_O6fx504VqM53DEHJAY0fsFCiHXBqAWJA@mail.gmail.com>
 <CAM_vjumpYbPoCDqC8pnJCksGPrq-SbMKLur6ZPGYY7nt=iLRMQ@mail.gmail.com>
 <CAMk+s2TnZzoWDBDE0aT3W=NrJf=0waHhSG_ATtjeZ9BKiXqw=Q@mail.gmail.com>
Message-ID: <20200630150441.05528386@Tarkus>

On Tue, 30 Jun 2020 13:53:10 +0200
Luigi Marongiu <marongiu.luigi at gmail.com> wrote:

> function(a, b, x) {
>   y = (a * x^2) / (b^2 + x^2)
>   return(y)
> }

Take a look at the examples in ?nls.lm. The first argument of the
function must be the parameter list/vector; the rest of the arguments
are passed from ... in nls.lm call. This is _unlike_ do.call, which can
be used to "unpack" a list of arguments into function arguments.

To make it more concrete, change your function to:

function(par) (par$a * par$x^2) / (par$b^2 + par$x^2)

Then it should work.

-- 
Best regards,
Ivan


From er|cjberger @end|ng |rom gm@||@com  Tue Jun 30 14:06:08 2020
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 30 Jun 2020 15:06:08 +0300
Subject: [R] How to use mle2 function?
In-Reply-To: <CAMk+s2RaS1TzzTiKHKLc01mouLzieyB2bYWZgJfKk_O5F+0rmg@mail.gmail.com>
References: <CAMk+s2Rmmga-kBnUZqA1wxgp_iqvsfDrmmXER0v4-OtG6-u5Yg@mail.gmail.com>
 <CAGgJW741SayyPJeG72K8AVOs9hgTBrSC+-k3t7WAwE9N1wGbjw@mail.gmail.com>
 <CAMk+s2RaS1TzzTiKHKLc01mouLzieyB2bYWZgJfKk_O5F+0rmg@mail.gmail.com>
Message-ID: <CAGgJW75k_6XnSW9bV9CPM4V57OsZtvvPwSsgvVBsH-mOEUwG_w@mail.gmail.com>

I have no problem with the following code:

library(bbmle)
holling <- function( a, b, x ) {
a*x^2 / (b^2 + x^2)
}
A=3261
B=10
X=30
foo <- mle2( minuslogl=holling, start=list(a=A,b=B,x=X) )

foo

# Call:
# mle2(minuslogl = holling, start = list(a = A, b = B, x = X))

# Coefficients:
#            a             b             x
# 3.260044e+03  7.315124e+01 -2.332448e-14

# Log-likelihood: 0


Does this code create a problem for you?

On Tue, Jun 30, 2020 at 3:00 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Sorry for the typo, but I have the same error if using b instead of h:
> ```
> > O = mle2(minuslogl = holling, start = list(a = A, b = B))
> > Error in minuslogl(a = 3261, b = 10) :
>   argument "x" is missing, with no default
> # let's add x
> X = c(8,   24,   39,   63,   89,  115,  153,  196,  242,  287,  344,  408,  473,
>       546,  619,  705,  794,  891,  999, 1096, 1242, 1363, 1506, 1648, 1753,
>       1851, 1987, 2101, 2219, 2328, 2425, 2575, 2646, 2698, 2727, 2771, 2818,
>       2853, 2895, 2926, 2964, 2995, 3025, 3053, 3080, 3102, 3119, 3141, 3152,
>       3159, 3172, 3182, 3196, 3209, 3220, 3231, 3239, 3246, 3252, 3261)
> O = mle2(minuslogl = holling, start = list(a = A, b = B, x = X))
> Error in mle2(minuslogl = holling, start = list(a = A, b = B, x = X)) :
>   some named arguments in 'start' are not arguments to the specified
> log-likelihood function
> ```
> And even if I use the log-likelihood function:
> ```
> O = mle2(minuslogl = nll, start = list(p = c(A, B), n = 57200000, x = X))
> > Error in mle2(minuslogl = nll, start = list(p = c(A, B), n = 57200000,  :
>   some named arguments in 'start' are not arguments to the specified
> log-likelihood function
> ```
>
> On Tue, Jun 30, 2020 at 12:03 PM Eric Berger <ericjberger at gmail.com> wrote:
> >
> > Hi Luigi,
> > I took a quick look.
> >
> > First error:
> > You wrote
> > O = mle2(minuslogl = holling, start = list(a = A, h = B, x = X))
> >
> > it should be b=B  (h is not an argument of holling())
> > The error message gave very precise information!
> >
> > Second error:
> > You wrote
> > O = mle2(minuslogl = nll, start = list(a = A, h = B),   data = list(n
> > = 57200000, k = A))
> > but the arguments to nll() are p,n,k. Setting start to values for a
> > and h causes the function to complain.
> >
> > HTH,
> > Eric
> >
> > On Tue, Jun 30, 2020 at 12:45 PM Luigi Marongiu
> > <marongiu.luigi at gmail.com> wrote:
> > >
> > > Hello,
> > > I would like to optimize the function:
> > > ```
> > > holling = function(a, b, x) {
> > >   y = (a * x^2) / (b^2 + x^2)
> > >   return(y)
> > > }
> > > ```
> > > I am trying to use the function mle2 from bbmle, but how do I need to
> > > feed the data?
> > > If I give `holling` as function to be optimized, passing the starting
> > > values for `a`, `b`, and `x`, I get:
> > > ```
> > > X = 1:60
> > > A = 3261
> > > B = 10
> > > O = mle2(minuslogl = holling, start = list(a = A, h = B, x = X))
> > > > Error in mle2(minuslogl = holling, start = list(a = A, b = B, x = X)) :
> > >   some named arguments in 'start' are not arguments to the specified
> > > log-likelihood function
> > > ```
> > > If I pass the negative log-function (assuming a binomial distribution
> > > of the data, which I am not sure about)
> > > ```
> > > nll = function(p, n, k) {
> > >   # extract parms
> > >   a = p[1]
> > >   h = p[2]
> > >   # calculate probability of attack
> > >   pred = a/(1+a*h*n)
> > >   # calc NLL
> > >   -sum(dbinom(k, prob = pred, size = n, log = TRUE))
> > > }
> > > ```
> > > then I get the same error:
> > > ```
> > > > O = mle2(minuslogl = nll, start = list(a = A, h = B),
> > > +          data = list(n = 57200000, k = A))
> > > Error in mle2(minuslogl = nll, start = list(a = A, h = B), data =
> > > list(n = 57200000,  :
> > >   some named arguments in 'start' are not arguments to the specified
> > > log-likelihood function
> > > ```
> > > but with the disadvantage of working on an assumed function (nll).
> > > How can I optimize the function `holling` properly?
> > > Thank you
> > >
> > >
> > >
> > >
> > > --
> > > Best regards,
> > > Luigi
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Best regards,
> Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Jun 30 14:22:19 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 30 Jun 2020 14:22:19 +0200
Subject: [R] How to use mle2 function?
In-Reply-To: <CAGgJW75k_6XnSW9bV9CPM4V57OsZtvvPwSsgvVBsH-mOEUwG_w@mail.gmail.com>
References: <CAMk+s2Rmmga-kBnUZqA1wxgp_iqvsfDrmmXER0v4-OtG6-u5Yg@mail.gmail.com>
 <CAGgJW741SayyPJeG72K8AVOs9hgTBrSC+-k3t7WAwE9N1wGbjw@mail.gmail.com>
 <CAMk+s2RaS1TzzTiKHKLc01mouLzieyB2bYWZgJfKk_O5F+0rmg@mail.gmail.com>
 <CAGgJW75k_6XnSW9bV9CPM4V57OsZtvvPwSsgvVBsH-mOEUwG_w@mail.gmail.com>
Message-ID: <CAMk+s2QwH=69HMQU6h_=ZOvS+RrxtgEvZjf1kEjBp9BQubtc=w@mail.gmail.com>

No, I got the same. I reckon the problem is with X: this was I scalar,
I was providing a vector with the actual values.
Ho can mle2 optimize without knowing what are the actual data? and
what values should I give for X?
Thank you

On Tue, Jun 30, 2020 at 2:06 PM Eric Berger <ericjberger at gmail.com> wrote:
>
> I have no problem with the following code:
>
> library(bbmle)
> holling <- function( a, b, x ) {
> a*x^2 / (b^2 + x^2)
> }
> A=3261
> B=10
> X=30
> foo <- mle2( minuslogl=holling, start=list(a=A,b=B,x=X) )
>
> foo
>
> # Call:
> # mle2(minuslogl = holling, start = list(a = A, b = B, x = X))
>
> # Coefficients:
> #            a             b             x
> # 3.260044e+03  7.315124e+01 -2.332448e-14
>
> # Log-likelihood: 0
>
>
> Does this code create a problem for you?
>
> On Tue, Jun 30, 2020 at 3:00 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Sorry for the typo, but I have the same error if using b instead of h:
> > ```
> > > O = mle2(minuslogl = holling, start = list(a = A, b = B))
> > > Error in minuslogl(a = 3261, b = 10) :
> >   argument "x" is missing, with no default
> > # let's add x
> > X = c(8,   24,   39,   63,   89,  115,  153,  196,  242,  287,  344,  408,  473,
> >       546,  619,  705,  794,  891,  999, 1096, 1242, 1363, 1506, 1648, 1753,
> >       1851, 1987, 2101, 2219, 2328, 2425, 2575, 2646, 2698, 2727, 2771, 2818,
> >       2853, 2895, 2926, 2964, 2995, 3025, 3053, 3080, 3102, 3119, 3141, 3152,
> >       3159, 3172, 3182, 3196, 3209, 3220, 3231, 3239, 3246, 3252, 3261)
> > O = mle2(minuslogl = holling, start = list(a = A, b = B, x = X))
> > Error in mle2(minuslogl = holling, start = list(a = A, b = B, x = X)) :
> >   some named arguments in 'start' are not arguments to the specified
> > log-likelihood function
> > ```
> > And even if I use the log-likelihood function:
> > ```
> > O = mle2(minuslogl = nll, start = list(p = c(A, B), n = 57200000, x = X))
> > > Error in mle2(minuslogl = nll, start = list(p = c(A, B), n = 57200000,  :
> >   some named arguments in 'start' are not arguments to the specified
> > log-likelihood function
> > ```
> >
> > On Tue, Jun 30, 2020 at 12:03 PM Eric Berger <ericjberger at gmail.com> wrote:
> > >
> > > Hi Luigi,
> > > I took a quick look.
> > >
> > > First error:
> > > You wrote
> > > O = mle2(minuslogl = holling, start = list(a = A, h = B, x = X))
> > >
> > > it should be b=B  (h is not an argument of holling())
> > > The error message gave very precise information!
> > >
> > > Second error:
> > > You wrote
> > > O = mle2(minuslogl = nll, start = list(a = A, h = B),   data = list(n
> > > = 57200000, k = A))
> > > but the arguments to nll() are p,n,k. Setting start to values for a
> > > and h causes the function to complain.
> > >
> > > HTH,
> > > Eric
> > >
> > > On Tue, Jun 30, 2020 at 12:45 PM Luigi Marongiu
> > > <marongiu.luigi at gmail.com> wrote:
> > > >
> > > > Hello,
> > > > I would like to optimize the function:
> > > > ```
> > > > holling = function(a, b, x) {
> > > >   y = (a * x^2) / (b^2 + x^2)
> > > >   return(y)
> > > > }
> > > > ```
> > > > I am trying to use the function mle2 from bbmle, but how do I need to
> > > > feed the data?
> > > > If I give `holling` as function to be optimized, passing the starting
> > > > values for `a`, `b`, and `x`, I get:
> > > > ```
> > > > X = 1:60
> > > > A = 3261
> > > > B = 10
> > > > O = mle2(minuslogl = holling, start = list(a = A, h = B, x = X))
> > > > > Error in mle2(minuslogl = holling, start = list(a = A, b = B, x = X)) :
> > > >   some named arguments in 'start' are not arguments to the specified
> > > > log-likelihood function
> > > > ```
> > > > If I pass the negative log-function (assuming a binomial distribution
> > > > of the data, which I am not sure about)
> > > > ```
> > > > nll = function(p, n, k) {
> > > >   # extract parms
> > > >   a = p[1]
> > > >   h = p[2]
> > > >   # calculate probability of attack
> > > >   pred = a/(1+a*h*n)
> > > >   # calc NLL
> > > >   -sum(dbinom(k, prob = pred, size = n, log = TRUE))
> > > > }
> > > > ```
> > > > then I get the same error:
> > > > ```
> > > > > O = mle2(minuslogl = nll, start = list(a = A, h = B),
> > > > +          data = list(n = 57200000, k = A))
> > > > Error in mle2(minuslogl = nll, start = list(a = A, h = B), data =
> > > > list(n = 57200000,  :
> > > >   some named arguments in 'start' are not arguments to the specified
> > > > log-likelihood function
> > > > ```
> > > > but with the disadvantage of working on an assumed function (nll).
> > > > How can I optimize the function `holling` properly?
> > > > Thank you
> > > >
> > > >
> > > >
> > > >
> > > > --
> > > > Best regards,
> > > > Luigi
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Best regards,
> > Luigi



-- 
Best regards,
Luigi


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Jun 30 14:36:01 2020
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 30 Jun 2020 14:36:01 +0200
Subject: [R] How to use mle2 function?
In-Reply-To: <CAGgJW75k_6XnSW9bV9CPM4V57OsZtvvPwSsgvVBsH-mOEUwG_w@mail.gmail.com>
References: <CAMk+s2Rmmga-kBnUZqA1wxgp_iqvsfDrmmXER0v4-OtG6-u5Yg@mail.gmail.com>
 <CAGgJW741SayyPJeG72K8AVOs9hgTBrSC+-k3t7WAwE9N1wGbjw@mail.gmail.com>
 <CAMk+s2RaS1TzzTiKHKLc01mouLzieyB2bYWZgJfKk_O5F+0rmg@mail.gmail.com>
 <CAGgJW75k_6XnSW9bV9CPM4V57OsZtvvPwSsgvVBsH-mOEUwG_w@mail.gmail.com>
Message-ID: <CAMk+s2RFcXquE2MPyUp1zT+bsxreujqJi6uvEgkqwti8Yt-XbQ@mail.gmail.com>

Addendum:
the optimization actually got a worse outcome than the original
eyeball estimation:
```
actual <- c(8,   24,   39,   63,   89,  115,  153,  196,  242,  287,
344,  408,  473,
                  546,  619,  705,  794,  891,  999, 1096, 1242, 1363,
1506, 1648, 1753,
                  1851, 1987, 2101, 2219, 2328, 2425, 2575, 2646,
2698, 2727, 2771, 2818,
                  2853, 2895, 2926, 2964, 2995, 3025, 3053, 3080,
3102, 3119, 3141, 3152,
                  3159, 3172, 3182, 3196, 3209, 3220, 3231, 3239,
3246, 3252, 3261)
# a = 3261, b = 10
raw_estim <- c(32.28713,  125.42308,  269.25688,  449.79310,  652.20000,
               863.20588, 1072.40940, 1272.58537,
1459.34254, 1630.50000, 1785.43439, 1924.52459, 2048.73234,
2159.31081, 2257.61538, 2344.98876,
2422.69666, 2491.89623, 2553.62473, 2608.80000, 2658.22736,
2702.60959, 2742.55803, 2778.60355,
2811.20690, 2840.76804, 2867.63450, 2892.10860, 2914.45377,
2934.90000, 2953.64844, 2970.87544,
2986.73591, 3001.36624, 3014.88679, 3027.40401, 3039.01225,
3049.79534, 3059.82788, 3069.17647,
3077.90062, 3086.05365, 3093.68343, 3100.83301, 3107.54118,
3113.84296, 3119.77003, 3125.35108,
3130.61216, 3135.57692, 3140.26694, 3144.70185, 3148.89962,
3152.87666, 3156.64800, 3160.22744,
3163.62765, 3166.86028, 3169.93605, 3172.86486)
# a = 3260.044, b = 73.15124
opt_estim <- c(38.52979,  316.81330,  721.54423, 1388.30154,
1945.64544, 2320.94319,
               2653.48033, 2861.46076,
2987.10641, 3061.17472, 3119.00396, 3158.51140, 3183.89232,
3202.55891, 3215.14235, 3225.31935,
3232.60583, 3238.21701, 3242.65745, 3245.58576, 3248.77411,
3250.68076, 3252.37050, 3253.63342,
3254.37708, 3254.96034, 3255.63152, 3256.09680, 3256.50500,
3256.82832, 3257.08020, 3257.41517,
3257.55425, 3257.64923, 3257.69986, 3257.77366, 3257.84871,
3257.90221, 3257.96386, 3258.00768,
3258.05952, 3258.10037, 3258.13871, 3258.17347, 3258.20611,
3258.23207, 3258.25176, 3258.27676,
3258.28907, 3258.29683, 3258.31112, 3258.32198, 3258.33703,
3258.35083, 3258.36237, 3258.37379,
3258.38203, 3258.38919, 3258.39528, 3258.40437)
plot(1:60, actual, lty = 1 , type = "l", lwd = 2,
     xlab = "Index", ylab = "Values")
points(1:60, raw_estim, lty = 2, type = "l")
points(1:60, opt_estim, lty = 3, type = "l")
legend("bottomright",
       legend = c("Actual values", "Raw estimate", "Optimized values"),
       lty = c(1, 2, 3), lwd = c(2, 1,1))
```

On Tue, Jun 30, 2020 at 2:06 PM Eric Berger <ericjberger at gmail.com> wrote:
>
> I have no problem with the following code:
>
> library(bbmle)
> holling <- function( a, b, x ) {
> a*x^2 / (b^2 + x^2)
> }
> A=3261
> B=10
> X=30
> foo <- mle2( minuslogl=holling, start=list(a=A,b=B,x=X) )
>
> foo
>
> # Call:
> # mle2(minuslogl = holling, start = list(a = A, b = B, x = X))
>
> # Coefficients:
> #            a             b             x
> # 3.260044e+03  7.315124e+01 -2.332448e-14
>
> # Log-likelihood: 0
>
>
> Does this code create a problem for you?
>
> On Tue, Jun 30, 2020 at 3:00 PM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Sorry for the typo, but I have the same error if using b instead of h:
> > ```
> > > O = mle2(minuslogl = holling, start = list(a = A, b = B))
> > > Error in minuslogl(a = 3261, b = 10) :
> >   argument "x" is missing, with no default
> > # let's add x
> > X = c(8,   24,   39,   63,   89,  115,  153,  196,  242,  287,  344,  408,  473,
> >       546,  619,  705,  794,  891,  999, 1096, 1242, 1363, 1506, 1648, 1753,
> >       1851, 1987, 2101, 2219, 2328, 2425, 2575, 2646, 2698, 2727, 2771, 2818,
> >       2853, 2895, 2926, 2964, 2995, 3025, 3053, 3080, 3102, 3119, 3141, 3152,
> >       3159, 3172, 3182, 3196, 3209, 3220, 3231, 3239, 3246, 3252, 3261)
> > O = mle2(minuslogl = holling, start = list(a = A, b = B, x = X))
> > Error in mle2(minuslogl = holling, start = list(a = A, b = B, x = X)) :
> >   some named arguments in 'start' are not arguments to the specified
> > log-likelihood function
> > ```
> > And even if I use the log-likelihood function:
> > ```
> > O = mle2(minuslogl = nll, start = list(p = c(A, B), n = 57200000, x = X))
> > > Error in mle2(minuslogl = nll, start = list(p = c(A, B), n = 57200000,  :
> >   some named arguments in 'start' are not arguments to the specified
> > log-likelihood function
> > ```
> >
> > On Tue, Jun 30, 2020 at 12:03 PM Eric Berger <ericjberger at gmail.com> wrote:
> > >
> > > Hi Luigi,
> > > I took a quick look.
> > >
> > > First error:
> > > You wrote
> > > O = mle2(minuslogl = holling, start = list(a = A, h = B, x = X))
> > >
> > > it should be b=B  (h is not an argument of holling())
> > > The error message gave very precise information!
> > >
> > > Second error:
> > > You wrote
> > > O = mle2(minuslogl = nll, start = list(a = A, h = B),   data = list(n
> > > = 57200000, k = A))
> > > but the arguments to nll() are p,n,k. Setting start to values for a
> > > and h causes the function to complain.
> > >
> > > HTH,
> > > Eric
> > >
> > > On Tue, Jun 30, 2020 at 12:45 PM Luigi Marongiu
> > > <marongiu.luigi at gmail.com> wrote:
> > > >
> > > > Hello,
> > > > I would like to optimize the function:
> > > > ```
> > > > holling = function(a, b, x) {
> > > >   y = (a * x^2) / (b^2 + x^2)
> > > >   return(y)
> > > > }
> > > > ```
> > > > I am trying to use the function mle2 from bbmle, but how do I need to
> > > > feed the data?
> > > > If I give `holling` as function to be optimized, passing the starting
> > > > values for `a`, `b`, and `x`, I get:
> > > > ```
> > > > X = 1:60
> > > > A = 3261
> > > > B = 10
> > > > O = mle2(minuslogl = holling, start = list(a = A, h = B, x = X))
> > > > > Error in mle2(minuslogl = holling, start = list(a = A, b = B, x = X)) :
> > > >   some named arguments in 'start' are not arguments to the specified
> > > > log-likelihood function
> > > > ```
> > > > If I pass the negative log-function (assuming a binomial distribution
> > > > of the data, which I am not sure about)
> > > > ```
> > > > nll = function(p, n, k) {
> > > >   # extract parms
> > > >   a = p[1]
> > > >   h = p[2]
> > > >   # calculate probability of attack
> > > >   pred = a/(1+a*h*n)
> > > >   # calc NLL
> > > >   -sum(dbinom(k, prob = pred, size = n, log = TRUE))
> > > > }
> > > > ```
> > > > then I get the same error:
> > > > ```
> > > > > O = mle2(minuslogl = nll, start = list(a = A, h = B),
> > > > +          data = list(n = 57200000, k = A))
> > > > Error in mle2(minuslogl = nll, start = list(a = A, h = B), data =
> > > > list(n = 57200000,  :
> > > >   some named arguments in 'start' are not arguments to the specified
> > > > log-likelihood function
> > > > ```
> > > > but with the disadvantage of working on an assumed function (nll).
> > > > How can I optimize the function `holling` properly?
> > > > Thank you
> > > >
> > > >
> > > >
> > > >
> > > > --
> > > > Best regards,
> > > > Luigi
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Best regards,
> > Luigi



-- 
Best regards,
Luigi


From kry|ov@r00t @end|ng |rom gm@||@com  Tue Jun 30 15:41:00 2020
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Tue, 30 Jun 2020 16:41:00 +0300
Subject: [R] argument "x" is missing in minpack.lm
In-Reply-To: <CAMk+s2S_X2WkX9-Qm_39x5Gh44Vz1+uAWDJCPX9UV_Mq26-y5A@mail.gmail.com>
References: <CAMk+s2SZUAoF1tmQh_O6fx504VqM53DEHJAY0fsFCiHXBqAWJA@mail.gmail.com>
 <CAM_vjumpYbPoCDqC8pnJCksGPrq-SbMKLur6ZPGYY7nt=iLRMQ@mail.gmail.com>
 <CAMk+s2TnZzoWDBDE0aT3W=NrJf=0waHhSG_ATtjeZ9BKiXqw=Q@mail.gmail.com>
 <20200630150441.05528386@Tarkus>
 <CAMk+s2S_X2WkX9-Qm_39x5Gh44Vz1+uAWDJCPX9UV_Mq26-y5A@mail.gmail.com>
Message-ID: <20200630164100.3366d68b@Tarkus>

(Adding R-help back to Cc:)

On Tue, 30 Jun 2020 14:44:29 +0200
Luigi Marongiu <marongiu.luigi at gmail.com> wrote:

> Ok, I tried with:
> ```
> holly <- function(p) {
>   y = (p$a * p$x^2) / (p$b^2 + p$x^2)
>   return(y)
> }
> X = 1:60
> A = 3261
> B = 10

> X = c(8,   24,   39,   63,   89,  115,  153,  196,  242,  287,  344,
> 408,  473, 546,  619,  705,  794,  891,  999, 1096, 1242, 1363, 1506,
> 1648, 1753, 1851, 1987, 2101, 2219, 2328, 2425, 2575, 2646, 2698,
> 2727, 2771, 2818, 2853, 2895, 2926, 2964, 2995, 3025, 3053, 3080,
> 3102, 3119, 3141, 3152, 3159, 3172, 3182, 3196, 3209, 3220, 3231,
> 3239, 3246, 3252, 3261)

You are correct in returning a vector of residuals to minimise a sum of
squares of, but X seems to be an independent variable, not a parameter
to optimize, so it shouldn't be passed as such. Instead you can either
close over X:

X <- c(...)
holly <- function(p) (p$a * X^2) / (p:b^2 + X^2)
# function holly now "contains" the vector X

or pass X as an argument that nls.lm will pass to your function:

holly <- function(p, X) (p$a * X^2) / (p$b^2 + X^2)
# nls.lm will pass the X argument to function holly
O <- nls.lm(par = list(a = 3261, b = 10), fn = holly, X = X)
summary(O)
# Parameters:
#    Estimate Std. Error   t value Pr(>|t|)    
# a 3.090e-16  4.102e-17 7.533e+00 3.72e-10 ***
# b 1.000e+01  1.525e-08 6.558e+08  < 2e-16 ***
# ---
# Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
# 
# Residual standard error: 3.107e-16 on 58 degrees of freedom
# Number of iterations to termination: 2 
# Reason for termination: Relative error between `par' and the solution
# is at most `ptol'. 

-- 
Best regards,
Ivan


From S@E|||@on @end|ng |rom LGCGroup@com  Tue Jun 30 21:59:03 2020
From: S@E|||@on @end|ng |rom LGCGroup@com (Stephen Ellison)
Date: Tue, 30 Jun 2020 19:59:03 +0000
Subject: [R] argument "x" is missing in minpack.lm
In-Reply-To: <20200630164100.3366d68b@Tarkus>
References: <CAMk+s2SZUAoF1tmQh_O6fx504VqM53DEHJAY0fsFCiHXBqAWJA@mail.gmail.com>
 <CAM_vjumpYbPoCDqC8pnJCksGPrq-SbMKLur6ZPGYY7nt=iLRMQ@mail.gmail.com>
 <CAMk+s2TnZzoWDBDE0aT3W=NrJf=0waHhSG_ATtjeZ9BKiXqw=Q@mail.gmail.com>
 <20200630150441.05528386@Tarkus>
 <CAMk+s2S_X2WkX9-Qm_39x5Gh44Vz1+uAWDJCPX9UV_Mq26-y5A@mail.gmail.com>,
 <20200630164100.3366d68b@Tarkus>
Message-ID: <a643ad2f5d5b4ec5bb4c0ded775f36ea@GBDCVPEXC08.corp.lgc-group.com>

Ivan Krylov [krylov.r00t at gmail.com] said:
>  Instead you can either close over X:
> 
> X <- c(...)
> holly <- function(p) (p$a * X^2) / (p:b^2 + X^2)
> # function holly now "contains" the vector X

That would not be an accurate statement as written.
The function only contains an unevaluated call referencing X; not the vector X. 
If X is not defined inside the function or its arguments, scoping rules take over and R goes looking in the function's environment, using the first thing called "X" that it finds.

So
X<-1:5
h <- function(p=2) p*X
h()
# works, but
X <- pi
h()
# Not the same answer. If the function 'contained' the vector, the result would be 2*(1:5) as above.
# This is why it's not wise to rely on scoping rules in functions, unless you _completely_ control the environment.

# and
rm(X)
h()
# returns an error because X is no longer defined, in the function or out of it, even though X was defined at the time h() was defined.

BUT 

X <- pi/2
fh <- function(p=2) {
        X <- 7
        h(p)
}
fh()
# returns pi and not 14 because h() was bound to the global environment on creation and still is when R finds it on evaluating h() in the fh() function body. 

Moral: if you want to be safe, pass it as an argument.


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From neer@jdh@nr@j @end|ng |rom gm@||@com  Mon Jun 29 18:18:32 2020
From: neer@jdh@nr@j @end|ng |rom gm@||@com (Neeraj Dhanraj)
Date: Mon, 29 Jun 2020 21:48:32 +0530
Subject: [R] [R-pkgs] ForecastTB package on CRAN
Message-ID: <CAC58_Y=zJDBJkYG_R9RLbXQhYM33LrMkrkjNwYi3Vd1VpCArXw@mail.gmail.com>

Hi All,

I am glad to share a new R package, named 'ForecastTB'. It is an automated
testbench to compare the performance of forecasting methods for univariate
time series.

The details are as follows:

CRAN: https://CRAN.R-project.org/package=ForecastTB
<https://cran.r-project.org/package=ForecastTB>
Details:
https://towardsdatascience.com/a-tool-to-ease-and-reproduce-the-univariate-time-series-forecast-prediction-analysis-bd9ffc14a3a

I hope that you will find this useful and feel free to share your thoughts
and feedback.

Regards,
-- 

*Neeraj Dhanraj Bokde *
Postdoctoral Researcher
Ph.D., M.E.

Mobil: +45 5222 6500
Mail: neerajdhanraj at eng.au.dk

*Department of Engineering*
Aarhus University
Inge Lehmanns Gade 10
DK-8000 Aarhus C

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


