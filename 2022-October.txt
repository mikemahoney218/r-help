From @v|@e@gro@@ @end|ng |rom gm@||@com  Sat Oct  1 01:01:28 2022
From: @v|@e@gro@@ @end|ng |rom gm@||@com (Avi Gross)
Date: Fri, 30 Sep 2022 19:01:28 -0400
Subject: [R] Reading very large text files into R
In-Reply-To: <BN6PR2201MB15533DA430761C7B4A46AD15CF569@BN6PR2201MB1553.namprd22.prod.outlook.com>
References: <CABxY9BMk+Y82OV8Rcaoe-r+GeheN9ji6hvGpjVjejKD0h0=E+A@mail.gmail.com>
 <CABcYAdKtUWnUdpMBOZ6R_EajctOtVAHa=DUd6X4ytEr9H_acVQ@mail.gmail.com>
 <BN6PR2201MB155318FFE325C623BE53AAC2CF569@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <004e01d8d501$12d6f2f0$3884d8d0$@gmail.com>
 <BN6PR2201MB15533DA430761C7B4A46AD15CF569@BN6PR2201MB1553.namprd22.prod.outlook.com>
Message-ID: <CABaFrRZkz8td3gzznUbSkmy=F5gacnCigGkGpnpiY7xiwKDMBQ@mail.gmail.com>

Those are valid reasons as examining data and cleaning or fixing it is a
major thing to do before making an analysis or plots. Indeed, an extra
column caused by something in an earlier column mat have messed up all
columns to the right.

My point was about replicating a problem like this may require many more
lines from the file.

On Fri, Sep 30, 2022, 5:58 PM Ebert,Timothy Aaron <tebert at ufl.edu> wrote:

> The point was more to figure out why most lines have 15 values and some
> give an error indicating that there are 16. Are there notes, or an extra
> comma? Some weather stations fail and give interesting data at, before, or
> after failure. Are the problem lines indicating machine failure? Typically
> code does not randomly enter extra data. Most answers appear to assume that
> the 16th column has been entered at the end of the data, but no evidence
> indicates this is true. If there is an initial value at the beginning of
> the row, then all of the data for that row will be in error if the "16"
> value is deleted. I am just paranoid enough to suggest looking at one case
> to make sure all is as assumed.
>    Another way to address the problem is to test the data. Are there
> temperatures less than -100 C or greater than 60 C? Why would one ever get
> such a thing? Machine error, or a column misaligned so that humidity values
> are in the temperature column.
>
> Tim
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of
> avi.e.gross at gmail.com
> Sent: Friday, September 30, 2022 3:16 PM
> Cc: r-help at r-project.org
> Subject: Re: [R] Reading very large text files into R
>
> [External Email]
>
> Tim and others,
>
> A point to consider is that there are various algorithms in the functions
> used to read in formatted data into data.frame form and they vary. Some do
> a look-ahead of some size to determine things and if they find a column
> that LOOKS LIKE all integers for say the first thousand lines, they go and
> read in that column as integer. If the first floating point value is
> thousands of lines further along, things may go wrong.
>
> So asking for line/row 16 to have an extra 16th entry/column may work fine
> for an algorithm that looks ahead and concludes there are 16 columns
> throughout. Yet a file where the first time a sixteenth entry is seen is at
> line/row 31,459 may well just set the algorithm to expect exactly 15
> columns and then be surprised as noted above.
>
> I have stayed out of this discussion and others have supplied pretty much
> what I would have said. I also see the data as flawed and ask which rows
> are the valid ones. If a sixteenth column is allowed, it would be better if
> all other rows had an empty sixteenth column. If not allowed, none should
> have it.
>
> The approach I might take, again as others have noted, is to preprocess
> the data file using some form of stream editor such as AWK that
> automagically reads in a line at a time and parses lines into a collection
> of tokens based on what separates them such as a comma. You can then either
> write out just the first 15 to the output stream if your choice is to
> ignore a spurious sixteenth, or write out all sixteen for every line, with
> the last being some form of null most of the time. And, of course, to be
> more general, you could make two passes through the file with the first one
> determining the maximum number of entries as well as what the most common
> number of entries is, and a second pass using that info to normalize the
> file the way you want. And note some of what was mentioned could often be
> done in this preprocessing such as removing any columns you do not want to
> read into R later. Do note such filters may need to handle edge cases like
> skipping comment lines or treating the row of headers differently.
>
> As some have shown, you can create your own filters within a language like
> R too and either read in lines and pre-process them as discussed or
> continue on to making your own data.frame and skip the read.table() type of
> functionality. For very large files, though, having multiple variations in
> memory at once may be an issue, especially if they are not removed and
> further processing and analysis continues.
>
> Perhaps it might be sensible to contact those maintaining the data and
> point out the anomaly and ask if their files might be saved alternately in
> a format that can be used without anomalies.
>
> Avi
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Ebert,Timothy
> Aaron
> Sent: Friday, September 30, 2022 7:27 AM
> To: Richard O'Keefe <raoknz at gmail.com>; Nick Wray <nickmwray at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] Reading very large text files into R
>
> Hi Nick,
>    Can you post one line of data with 15 entries followed by the next line
> of data with 16 entries?
>
> Tim
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=05%7C01%7Ctebert%40ufl.edu%7C3d75da30d3744c13847308daa3184c98%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638001622016765705%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=5w0Yrih%2Fxf09zpgabscAzMTVzcw4nhjNKX5%2FgWEPVWk%3D&amp;reserved=0
> PLEASE do read the posting guide
> https://nam10.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=05%7C01%7Ctebert%40ufl.edu%7C3d75da30d3744c13847308daa3184c98%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638001622016765705%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=K4ddCaLbSB5XU8TELCMhDEFsG4drevbeRp2YKPxY2ag%3D&amp;reserved=0
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tebert @end|ng |rom u||@edu  Sat Oct  1 01:43:01 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Fri, 30 Sep 2022 23:43:01 +0000
Subject: [R] Reading very large text files into R
In-Reply-To: <CABaFrRZkz8td3gzznUbSkmy=F5gacnCigGkGpnpiY7xiwKDMBQ@mail.gmail.com>
References: <CABxY9BMk+Y82OV8Rcaoe-r+GeheN9ji6hvGpjVjejKD0h0=E+A@mail.gmail.com>
 <CABcYAdKtUWnUdpMBOZ6R_EajctOtVAHa=DUd6X4ytEr9H_acVQ@mail.gmail.com>
 <BN6PR2201MB155318FFE325C623BE53AAC2CF569@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <004e01d8d501$12d6f2f0$3884d8d0$@gmail.com>
 <BN6PR2201MB15533DA430761C7B4A46AD15CF569@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <CABaFrRZkz8td3gzznUbSkmy=F5gacnCigGkGpnpiY7xiwKDMBQ@mail.gmail.com>
Message-ID: <BN6PR2201MB1553B86BFEE83B5EDD382CD9CF569@BN6PR2201MB1553.namprd22.prod.outlook.com>

Truth

Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Avi Gross
Sent: Friday, September 30, 2022 7:01 PM
Cc: R help Mailing list <r-help at r-project.org>
Subject: Re: [R] Reading very large text files into R

[External Email]

Those are valid reasons as examining data and cleaning or fixing it is a major thing to do before making an analysis or plots. Indeed, an extra column caused by something in an earlier column mat have messed up all columns to the right.

My point was about replicating a problem like this may require many more lines from the file.

On Fri, Sep 30, 2022, 5:58 PM Ebert,Timothy Aaron <tebert at ufl.edu> wrote:

> The point was more to figure out why most lines have 15 values and 
> some give an error indicating that there are 16. Are there notes, or 
> an extra comma? Some weather stations fail and give interesting data 
> at, before, or after failure. Are the problem lines indicating machine 
> failure? Typically code does not randomly enter extra data. Most 
> answers appear to assume that the 16th column has been entered at the 
> end of the data, but no evidence indicates this is true. If there is 
> an initial value at the beginning of the row, then all of the data for that row will be in error if the "16"
> value is deleted. I am just paranoid enough to suggest looking at one 
> case to make sure all is as assumed.
>    Another way to address the problem is to test the data. Are there 
> temperatures less than -100 C or greater than 60 C? Why would one ever 
> get such a thing? Machine error, or a column misaligned so that 
> humidity values are in the temperature column.
>
> Tim
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of 
> avi.e.gross at gmail.com
> Sent: Friday, September 30, 2022 3:16 PM
> Cc: r-help at r-project.org
> Subject: Re: [R] Reading very large text files into R
>
> [External Email]
>
> Tim and others,
>
> A point to consider is that there are various algorithms in the 
> functions used to read in formatted data into data.frame form and they 
> vary. Some do a look-ahead of some size to determine things and if 
> they find a column that LOOKS LIKE all integers for say the first 
> thousand lines, they go and read in that column as integer. If the 
> first floating point value is thousands of lines further along, things may go wrong.
>
> So asking for line/row 16 to have an extra 16th entry/column may work 
> fine for an algorithm that looks ahead and concludes there are 16 
> columns throughout. Yet a file where the first time a sixteenth entry 
> is seen is at line/row 31,459 may well just set the algorithm to 
> expect exactly 15 columns and then be surprised as noted above.
>
> I have stayed out of this discussion and others have supplied pretty 
> much what I would have said. I also see the data as flawed and ask 
> which rows are the valid ones. If a sixteenth column is allowed, it 
> would be better if all other rows had an empty sixteenth column. If 
> not allowed, none should have it.
>
> The approach I might take, again as others have noted, is to 
> preprocess the data file using some form of stream editor such as AWK 
> that automagically reads in a line at a time and parses lines into a 
> collection of tokens based on what separates them such as a comma. You 
> can then either write out just the first 15 to the output stream if 
> your choice is to ignore a spurious sixteenth, or write out all 
> sixteen for every line, with the last being some form of null most of 
> the time. And, of course, to be more general, you could make two 
> passes through the file with the first one determining the maximum 
> number of entries as well as what the most common number of entries 
> is, and a second pass using that info to normalize the file the way 
> you want. And note some of what was mentioned could often be done in 
> this preprocessing such as removing any columns you do not want to 
> read into R later. Do note such filters may need to handle edge cases like skipping comment lines or treating the row of headers differently.
>
> As some have shown, you can create your own filters within a language 
> like R too and either read in lines and pre-process them as discussed 
> or continue on to making your own data.frame and skip the read.table() 
> type of functionality. For very large files, though, having multiple 
> variations in memory at once may be an issue, especially if they are 
> not removed and further processing and analysis continues.
>
> Perhaps it might be sensible to contact those maintaining the data and 
> point out the anomaly and ask if their files might be saved 
> alternately in a format that can be used without anomalies.
>
> Avi
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Ebert,Timothy 
> Aaron
> Sent: Friday, September 30, 2022 7:27 AM
> To: Richard O'Keefe <raoknz at gmail.com>; Nick Wray 
> <nickmwray at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] Reading very large text files into R
>
> Hi Nick,
>    Can you post one line of data with 15 entries followed by the next 
> line of data with 16 entries?
>
> Tim
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat
> .ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=05%7C01%7Ctebert%40ufl
> .edu%7C5044822c1b7f45f2b5f408daa337cc46%7C0d4da0f84a314d76ace60a62331e
> 1b84%7C0%7C0%7C638001757304040018%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4w
> LjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C
> &amp;sdata=s1Vx7PfKdb12NTQFAsGPQ5k8oXBylcFyD30xtAnHqYQ%3D&amp;reserved
> =0
> PLEASE do read the posting guide
> https://nam10.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r
> -project.org%2Fposting-guide.html&amp;data=05%7C01%7Ctebert%40ufl.edu%
> 7C5044822c1b7f45f2b5f408daa337cc46%7C0d4da0f84a314d76ace60a62331e1b84%
> 7C0%7C0%7C638001757304040018%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwM
> DAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;
> sdata=Q3cceHqosMsjflLn5cPgBE58EGdE%2B7riPYhubX%2BwEL8%3D&amp;reserved=
> 0 and provide commented, minimal, self-contained, reproducible code.
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=05%7C01%7Ctebert%40ufl.edu%7C5044822c1b7f45f2b5f408daa337cc46%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638001757304040018%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=s1Vx7PfKdb12NTQFAsGPQ5k8oXBylcFyD30xtAnHqYQ%3D&amp;reserved=0
PLEASE do read the posting guide https://nam10.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=05%7C01%7Ctebert%40ufl.edu%7C5044822c1b7f45f2b5f408daa337cc46%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638001757304040018%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=Q3cceHqosMsjflLn5cPgBE58EGdE%2B7riPYhubX%2BwEL8%3D&amp;reserved=0
and provide commented, minimal, self-contained, reproducible code.


From dr@@|@m@o|@ng| @end|ng |rom gm@||@com  Sat Oct  1 14:53:00 2022
From: dr@@|@m@o|@ng| @end|ng |rom gm@||@com (Shah Alam)
Date: Sat, 1 Oct 2022 14:53:00 +0200
Subject: [R] could not find function "flexsurvreg"
Message-ID: <CA+bivFj5M5HeVawxZXeZ4S9JgZUAY2eF8DCUb_JXyNiNoLk59A@mail.gmail.com>

Dear All,
I am analyzing trial data for survival. During the loading of the R package
"flexsurv", the following error message appeared.

"Loading required package: survival
Error: package or namespace load failed for ?flexsurv? in loadNamespace(j
<- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):
 there is no package called ?lifecycle?

Despite installing lifecycle package, loading lifecycle package results in
the following error message:

Error in library(lifecycle) : there is no package called ?lifecycle?

Moreover, the flexsurvreg function in the flexsurv library also produces an
error:

Error in flexsurvreg(Surv(Time, Event) ~ 1, anc = NULL, data = data1,  :
  could not find function "flexsurvreg"

Several times I have installed and uninstalled packages, re-started R, but
the error persists.

Could anyone help me with the flexsurv package, why is it not working?

Best regards,
Shah

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Oct  1 15:29:15 2022
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 1 Oct 2022 14:29:15 +0100
Subject: [R] could not find function "flexsurvreg"
In-Reply-To: <CA+bivFj5M5HeVawxZXeZ4S9JgZUAY2eF8DCUb_JXyNiNoLk59A@mail.gmail.com>
References: <CA+bivFj5M5HeVawxZXeZ4S9JgZUAY2eF8DCUb_JXyNiNoLk59A@mail.gmail.com>
Message-ID: <2975651c-bf02-4f2c-a44d-9f49b7f84deb@sapo.pt>

Hello,

Not knowing which system you have, here is a way that usually works.

1. If you are using an IDE sych as RStudio or RGui, save your work and 
exit. This is because when the packages' namepaces are loaded, the 
shared libs, if they exist, are blocked,

2. Open a terminal window
3. Run

R -q -e "install.packages(c('lifecycle', 'flexsurv'))"


The packages should now be installed.


Hope this helps,

Rui Barradas

?s 13:53 de 01/10/2022, Shah Alam escreveu:
> Dear All,
> I am analyzing trial data for survival. During the loading of the R package
> "flexsurv", the following error message appeared.
> 
> "Loading required package: survival
> Error: package or namespace load failed for ?flexsurv? in loadNamespace(j
> <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):
>   there is no package called ?lifecycle?
> 
> Despite installing lifecycle package, loading lifecycle package results in
> the following error message:
> 
> Error in library(lifecycle) : there is no package called ?lifecycle?
> 
> Moreover, the flexsurvreg function in the flexsurv library also produces an
> error:
> 
> Error in flexsurvreg(Surv(Time, Event) ~ 1, anc = NULL, data = data1,  :
>    could not find function "flexsurvreg"
> 
> Several times I have installed and uninstalled packages, re-started R, but
> the error persists.
> 
> Could anyone help me with the flexsurv package, why is it not working?
> 
> Best regards,
> Shah
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From t@r|qkh@@|r| @end|ng |rom gm@||@com  Sun Oct  2 14:06:02 2022
From: t@r|qkh@@|r| @end|ng |rom gm@||@com (Tariq Khasiri)
Date: Sun, 2 Oct 2022 07:06:02 -0500
Subject: [R] Help with steam graph
Message-ID: <CAFy_oHAn0RGPVXG=ypbxHM_idX08=c94QOh+gpqwXVEEKYnuSw@mail.gmail.com>

Hi, i'm trying to create a steamgraph with the following data by creating a
unit indicator by combing the year and month. But, I'm getting error as :

Error in `group_by()`:
! Must group by variables found in `.data`.
? Column `com_num` is not found.
Run `rlang::last_error()` to see where the error occurred.

### Packages needed for the code
devtools::install_github("hrbrmstr/streamgraph")

library(tidyverse)
library(ggplot2)
library(dplyr)
library(steamgraph)

### Code ( The following code can be found on creator's account
https://hrbrmstr.github.io/streamgraph/  )

dat %>%
select(year, month, company, share, com_num) %>%
  tidyr::gather(company, share, -year) %>%
  group_by(year, com_num) %>%
  tally(wt=share) %>%
  ungroup %>%
  streamgraph("com_num", "n", "year") %>%
  sg_axis_x(0.8) %>%
  sg_fill_brewer("PuOr") %>%
  sg_legend(show=TRUE, label="Share: ")


### data is like the following

dput(dat)
structure(list(year = c(2018, 2019, 2019, 2019, 2019, 2019, 2019,
2019, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017,
2017, 2017, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018,
2018, 2018, 2018, 2019, 2019, 2019, 2019, 2019), month = c(12,
1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1,
2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5), company = c("ABC",
"ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "FGH", "FGH",
"FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
"FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
"FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH"
), share = c(20, 16.5, 15, 15.5, 15.5, 16, 17, 16.5, 61, 55,
53, 53, 54, 53, 58, 54, 50, 47, 55, 50, 52, 51, 51.5, 52, 53,
54, 55, 53, 54, 50, 42, 48, 41, 40, 39, 36.5, 35), com_name = c(1,
1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)), row.names = c(NA,
-37L), spec = structure(list(cols = list(year = structure(list(), class =
c("collector_double",
"collector")), month = structure(list(), class = c("collector_double",
"collector")), company = structure(list(), class = c("collector_character",
"collector")), share = structure(list(), class = c("collector_double",
"collector")), com_name = structure(list(), class = c("collector_double",
"collector"))), default = structure(list(), class = c("collector_guess",
"collector")), delim = ","), class = "col_spec"), problems = <pointer:
0x7fd732028680>, class = c("spec_tbl_df",
"tbl_df", "tbl", "data.frame"))

	[[alternative HTML version deleted]]


From m@@c|@@|mone99 @end|ng |rom gm@||@com  Sun Oct  2 12:56:44 2022
From: m@@c|@@|mone99 @end|ng |rom gm@||@com (Simone Mascia)
Date: Sun, 2 Oct 2022 12:56:44 +0200
Subject: [R] Robust standard error
Message-ID: <CAPkN0fY32F=b=RFsTuCnDytg4i=++CkB_Bw7VLN+i=0rvaBQtQ@mail.gmail.com>

Is there a way to estimate Robust standard errors when using a nls()
function? I'm trying to fit some data to a complicated model and everything
works fine with nls() but I also wanted to obtain a robust estimate of my
errors.

I tried "coeftest(m, vcov=sandwich)" and it seems to work, but so does
"coeftest(m, vcov = NeweyWest(m, lag = 4))" or "coeftest(m, vcov =
kernHAC(m, kernel = "Bartlett", bw = 5, prewhite = FALSE, adjust =
FALSE))". They return different error estimates so I wanted you to help me
understand what I should do, if I'm doing something wrong and other stuff.

Thank you

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Sun Oct  2 16:11:55 2022
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sun, 2 Oct 2022 07:11:55 -0700
Subject: [R] Help with steam graph
In-Reply-To: <CAFy_oHAn0RGPVXG=ypbxHM_idX08=c94QOh+gpqwXVEEKYnuSw@mail.gmail.com>
References: <CAFy_oHAn0RGPVXG=ypbxHM_idX08=c94QOh+gpqwXVEEKYnuSw@mail.gmail.com>
Message-ID: <0073C340-0152-48CF-BB4B-1890BFD1DDF3@comcast.net>

I don?t see a column with the name ?com_num?, so the error message makes complete sense. 

? 
David

Sent from my iPhone

> On Oct 2, 2022, at 5:06 AM, Tariq Khasiri <tariqkhasiri at gmail.com> wrote:
> 
> ?Hi, i'm trying to create a steamgraph with the following data by creating a
> unit indicator by combing the year and month. But, I'm getting error as :
> 
> Error in `group_by()`:
> ! Must group by variables found in `.data`.
> ? Column `com_num` is not found.
> Run `rlang::last_error()` to see where the error occurred.
> 
> ### Packages needed for the code
> devtools::install_github("hrbrmstr/streamgraph")
> 
> library(tidyverse)
> library(ggplot2)
> library(dplyr)
> library(steamgraph)
> 
> ### Code ( The following code can be found on creator's account
> https://hrbrmstr.github.io/streamgraph/  )
> 
> dat %>%
> select(year, month, company, share, com_num) %>%
>  tidyr::gather(company, share, -year) %>%
>  group_by(year, com_num) %>%
>  tally(wt=share) %>%
>  ungroup %>%
>  streamgraph("com_num", "n", "year") %>%
>  sg_axis_x(0.8) %>%
>  sg_fill_brewer("PuOr") %>%
>  sg_legend(show=TRUE, label="Share: ")
> 
> 
> ### data is like the following
> 
> dput(dat)
> structure(list(year = c(2018, 2019, 2019, 2019, 2019, 2019, 2019,
> 2019, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017,
> 2017, 2017, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018,
> 2018, 2018, 2018, 2019, 2019, 2019, 2019, 2019), month = c(12,
> 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1,
> 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5), company = c("ABC",
> "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "FGH", "FGH",
> "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
> "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
> "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH"
> ), share = c(20, 16.5, 15, 15.5, 15.5, 16, 17, 16.5, 61, 55,
> 53, 53, 54, 53, 58, 54, 50, 47, 55, 50, 52, 51, 51.5, 52, 53,
> 54, 55, 53, 54, 50, 42, 48, 41, 40, 39, 36.5, 35), com_name = c(1,
> 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)), row.names = c(NA,
> -37L), spec = structure(list(cols = list(year = structure(list(), class =
> c("collector_double",
> "collector")), month = structure(list(), class = c("collector_double",
> "collector")), company = structure(list(), class = c("collector_character",
> "collector")), share = structure(list(), class = c("collector_double",
> "collector")), com_name = structure(list(), class = c("collector_double",
> "collector"))), default = structure(list(), class = c("collector_guess",
> "collector")), delim = ","), class = "col_spec"), problems = <pointer:
> 0x7fd732028680>, class = c("spec_tbl_df",
> "tbl_df", "tbl", "data.frame"))
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Sun Oct  2 16:43:00 2022
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 2 Oct 2022 07:43:00 -0700
Subject: [R] Robust standard error
In-Reply-To: <CAPkN0fY32F=b=RFsTuCnDytg4i=++CkB_Bw7VLN+i=0rvaBQtQ@mail.gmail.com>
References: <CAPkN0fY32F=b=RFsTuCnDytg4i=++CkB_Bw7VLN+i=0rvaBQtQ@mail.gmail.com>
Message-ID: <CAGxFJbSTKN5C4SbGh4XRNTe95WArNd2m5XaE1gi8YgfC4ajnrg@mail.gmail.com>

You may get a helpful response here, but generally speaking, this list is
about R **programming**, and statistical issues/tutorials are off topic.
You might try
https://stackoverflow.com/questions/tagged/statistics
if you don't get adequate help here.

-- Bert

On Sun, Oct 2, 2022 at 6:42 AM Simone Mascia <masciasimone99 at gmail.com>
wrote:

> Is there a way to estimate Robust standard errors when using a nls()
> function? I'm trying to fit some data to a complicated model and everything
> works fine with nls() but I also wanted to obtain a robust estimate of my
> errors.
>
> I tried "coeftest(m, vcov=sandwich)" and it seems to work, but so does
> "coeftest(m, vcov = NeweyWest(m, lag = 4))" or "coeftest(m, vcov =
> kernHAC(m, kernel = "Bartlett", bw = 5, prewhite = FALSE, adjust =
> FALSE))". They return different error estimates so I wanted you to help me
> understand what I should do, if I'm doing something wrong and other stuff.
>
> Thank you
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From e@ @end|ng |rom enr|co@chum@nn@net  Sun Oct  2 17:59:32 2022
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Sun, 02 Oct 2022 17:59:32 +0200
Subject: [R] Robust standard error
In-Reply-To: <CAGxFJbSTKN5C4SbGh4XRNTe95WArNd2m5XaE1gi8YgfC4ajnrg@mail.gmail.com>
 (Bert Gunter's message of "Sun, 2 Oct 2022 07:43:00 -0700")
References: <CAPkN0fY32F=b=RFsTuCnDytg4i=++CkB_Bw7VLN+i=0rvaBQtQ@mail.gmail.com>
 <CAGxFJbSTKN5C4SbGh4XRNTe95WArNd2m5XaE1gi8YgfC4ajnrg@mail.gmail.com>
Message-ID: <87lepykyhn.fsf@enricoschumann.net>

On Sun, 02 Oct 2022, Bert Gunter writes:

> On Sun, Oct 2, 2022 at 6:42 AM Simone Mascia <masciasimone99 at gmail.com>
> wrote:
>
>> Is there a way to estimate Robust standard errors when using a nls()
>> function? I'm trying to fit some data to a complicated model and everything
>> works fine with nls() but I also wanted to obtain a robust estimate of my
>> errors.
>>
>> I tried "coeftest(m, vcov=sandwich)" and it seems to work, but so does
>> "coeftest(m, vcov = NeweyWest(m, lag = 4))" or "coeftest(m, vcov =
>> kernHAC(m, kernel = "Bartlett", bw = 5, prewhite = FALSE, adjust =
>> FALSE))". They return different error estimates so I wanted you to help me
>> understand what I should do, if I'm doing something wrong and other stuff.
>>
>> Thank you
>>
>
> You may get a helpful response here, but generally speaking, this list is
> about R **programming**, and statistical issues/tutorials are off topic.
> You might try
> https://stackoverflow.com/questions/tagged/statistics
> if you don't get adequate help here.
>
> -- Bert
>

Additionally, there is also
https://stat.ethz.ch/mailman/listinfo/R-sig-Robust .

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From t@r|qkh@@|r| @end|ng |rom gm@||@com  Sun Oct  2 19:03:51 2022
From: t@r|qkh@@|r| @end|ng |rom gm@||@com (Tariq Khasiri)
Date: Sun, 2 Oct 2022 12:03:51 -0500
Subject: [R] Help with steam graph
In-Reply-To: <0073C340-0152-48CF-BB4B-1890BFD1DDF3@comcast.net>
References: <CAFy_oHAn0RGPVXG=ypbxHM_idX08=c94QOh+gpqwXVEEKYnuSw@mail.gmail.com>
 <0073C340-0152-48CF-BB4B-1890BFD1DDF3@comcast.net>
Message-ID: <CAFy_oHCNXkHGOXGixzyee74TRKsxjeaozwuR2Y2OY4T4236Kag@mail.gmail.com>

Actually in my main data the column name is com_num ( where mistakenly I
pasted the sample data here under the com_name ). So, when I run the
command successfully this is the error shows up -

    ?
  1. ??... %>% sg_legend(show = TRUE, label = "Share: ")
  2. ??streamgraph::sg_legend(., show = TRUE, label = "Share: ")
  3. ??streamgraph::sg_fill_brewer(., "PuOr")
  4. ??streamgraph::sg_axis_x(., 0.8)
  5. ??streamgraph::streamgraph(., "com_num", "n", "year")
  6. ? ??base::data.frame(data)
  7. ??dplyr::ungroup(.)
  8. ??dplyr::tally(., wt = share)
  9. ??dplyr::group_by(., year, com_num)
 10. ??dplyr:::group_by.data.frame(., year, com_num)
 11.   ??dplyr::group_by_prepare(.data, ..., .add = .add, caller_env =
caller_env())
 12.     ??rlang::abort(bullets, call = error_call)

Any suggestions on how I can fix it ??

On Sun, 2 Oct 2022 at 09:12, David Winsemius <dwinsemius at comcast.net> wrote:

> I don?t see a column with the name ?com_num?, so the error message makes
> complete sense.
>
> ?
> David
>
> Sent from my iPhone
>
> > On Oct 2, 2022, at 5:06 AM, Tariq Khasiri <tariqkhasiri at gmail.com>
> wrote:
> >
> > ?Hi, i'm trying to create a steamgraph with the following data by
> creating a
> > unit indicator by combing the year and month. But, I'm getting error as :
> >
> > Error in `group_by()`:
> > ! Must group by variables found in `.data`.
> > ? Column `com_num` is not found.
> > Run `rlang::last_error()` to see where the error occurred.
> >
> > ### Packages needed for the code
> > devtools::install_github("hrbrmstr/streamgraph")
> >
> > library(tidyverse)
> > library(ggplot2)
> > library(dplyr)
> > library(steamgraph)
> >
> > ### Code ( The following code can be found on creator's account
> > https://hrbrmstr.github.io/streamgraph/  )
> >
> > dat %>%
> > select(year, month, company, share, com_num) %>%
> >  tidyr::gather(company, share, -year) %>%
> >  group_by(year, com_num) %>%
> >  tally(wt=share) %>%
> >  ungroup %>%
> >  streamgraph("com_num", "n", "year") %>%
> >  sg_axis_x(0.8) %>%
> >  sg_fill_brewer("PuOr") %>%
> >  sg_legend(show=TRUE, label="Share: ")
> >
> >
> > ### data is like the following
> >
> > dput(dat)
> > structure(list(year = c(2018, 2019, 2019, 2019, 2019, 2019, 2019,
> > 2019, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017,
> > 2017, 2017, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018,
> > 2018, 2018, 2018, 2019, 2019, 2019, 2019, 2019), month = c(12,
> > 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1,
> > 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5), company = c("ABC",
> > "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "FGH", "FGH",
> > "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
> > "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
> > "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH"
> > ), share = c(20, 16.5, 15, 15.5, 15.5, 16, 17, 16.5, 61, 55,
> > 53, 53, 54, 53, 58, 54, 50, 47, 55, 50, 52, 51, 51.5, 52, 53,
> > 54, 55, 53, 54, 50, 42, 48, 41, 40, 39, 36.5, 35), com_name = c(1,
> > 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> > 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)), row.names = c(NA,
> > -37L), spec = structure(list(cols = list(year = structure(list(), class =
> > c("collector_double",
> > "collector")), month = structure(list(), class = c("collector_double",
> > "collector")), company = structure(list(), class =
> c("collector_character",
> > "collector")), share = structure(list(), class = c("collector_double",
> > "collector")), com_name = structure(list(), class = c("collector_double",
> > "collector"))), default = structure(list(), class = c("collector_guess",
> > "collector")), delim = ","), class = "col_spec"), problems = <pointer:
> > 0x7fd732028680>, class = c("spec_tbl_df",
> > "tbl_df", "tbl", "data.frame"))
> >
> >    [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From tebert @end|ng |rom u||@edu  Sun Oct  2 23:27:10 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Sun, 2 Oct 2022 21:27:10 +0000
Subject: [R] Robust standard error
In-Reply-To: <87lepykyhn.fsf@enricoschumann.net>
References: <CAPkN0fY32F=b=RFsTuCnDytg4i=++CkB_Bw7VLN+i=0rvaBQtQ@mail.gmail.com>
 <CAGxFJbSTKN5C4SbGh4XRNTe95WArNd2m5XaE1gi8YgfC4ajnrg@mail.gmail.com>
 <87lepykyhn.fsf@enricoschumann.net>
Message-ID: <BN6PR2201MB1553F98BC7B6CD7D3134E849CF589@BN6PR2201MB1553.namprd22.prod.outlook.com>

Most computer code will take a pile of numbers and return a pile of numbers. Reading the documentation should help you figure out where each measure is appropriate. It all depends on the purpose of a specific method and its assumptions and how those relate to your data, application, and model assumptions. It is important to know that information because it could change if you change your model or find other questions to ask of your data. There is no universal right answer.

Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Enrico Schumann
Sent: Sunday, October 2, 2022 12:00 PM
To: Simone Mascia <masciasimone99 at gmail.com>
Cc: r-help at r-project.org
Subject: Re: [R] Robust standard error

[External Email]

On Sun, 02 Oct 2022, Bert Gunter writes:

> On Sun, Oct 2, 2022 at 6:42 AM Simone Mascia 
> <masciasimone99 at gmail.com>
> wrote:
>
>> Is there a way to estimate Robust standard errors when using a nls() 
>> function? I'm trying to fit some data to a complicated model and 
>> everything works fine with nls() but I also wanted to obtain a robust 
>> estimate of my errors.
>>
>> I tried "coeftest(m, vcov=sandwich)" and it seems to work, but so 
>> does "coeftest(m, vcov = NeweyWest(m, lag = 4))" or "coeftest(m, vcov 
>> = kernHAC(m, kernel = "Bartlett", bw = 5, prewhite = FALSE, adjust = 
>> FALSE))". They return different error estimates so I wanted you to 
>> help me understand what I should do, if I'm doing something wrong and other stuff.
>>
>> Thank you
>>
>
> You may get a helpful response here, but generally speaking, this list 
> is about R **programming**, and statistical issues/tutorials are off topic.
> You might try
> https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstac
> koverflow.com%2Fquestions%2Ftagged%2Fstatistics&amp;data=05%7C01%7Cteb
> ert%40ufl.edu%7C86352d688e094b941f6108daa48f2bb0%7C0d4da0f84a314d76ace
> 60a62331e1b84%7C0%7C0%7C638003232071609206%7CUnknown%7CTWFpbGZsb3d8eyJ
> WIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000
> %7C%7C%7C&amp;sdata=yFTdmRZyRqZd9F3XNsg12IvYlnWE2P6TTkRvNL6U4ZI%3D&amp
> ;reserved=0
> if you don't get adequate help here.
>
> -- Bert
>

Additionally, there is also
https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2FR-sig-Robust&amp;data=05%7C01%7Ctebert%40ufl.edu%7C86352d688e094b941f6108daa48f2bb0%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638003232071609206%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=WJY8zHOxsMLUv1uiHJ91q04mGVvkPi0Kg%2BYydMZMKhs%3D&amp;reserved=0 .

--
Enrico Schumann
Lucerne, Switzerland
https://nam10.safelinks.protection.outlook.com/?url=http%3A%2F%2Fenricoschumann.net%2F&amp;data=05%7C01%7Ctebert%40ufl.edu%7C86352d688e094b941f6108daa48f2bb0%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638003232071609206%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=nntdbtWzMra1ZsSrTR2ZEuDNndB6J5GJ%2B1WSC%2Bhweqo%3D&amp;reserved=0

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=05%7C01%7Ctebert%40ufl.edu%7C86352d688e094b941f6108daa48f2bb0%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638003232071609206%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=6J1gU7dtTJexvDxujaA10nKYYxypFk1CMjN8qc8NQZM%3D&amp;reserved=0
PLEASE do read the posting guide https://nam10.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=05%7C01%7Ctebert%40ufl.edu%7C86352d688e094b941f6108daa48f2bb0%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638003232071609206%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=qd99tAhjS4vz7SemhzyXKvpSDG%2FZD%2FtQ4BYbCtt%2Fsu8%3D&amp;reserved=0
and provide commented, minimal, self-contained, reproducible code.


From t@r|qkh@@|r| @end|ng |rom gm@||@com  Mon Oct  3 01:04:24 2022
From: t@r|qkh@@|r| @end|ng |rom gm@||@com (Tariq Khasiri)
Date: Sun, 2 Oct 2022 18:04:24 -0500
Subject: [R] Creating a year-month indicator and groupby with category
Message-ID: <CAFy_oHDGR7cnNwcTW3mNknKvHhRz+LC4v4XSeKrKEOUjMTcsmA@mail.gmail.com>

Hello,

I have the following data. I want to show in a line plot how each different
company is earning over the timeline of my data sample.

I'm not sure how I can create the *year-month indicator* to plot it nicely
in my horizontal axis out of my dataset.

After creating the *year-month* indicator ( which will be in my x axis) I
want to create a dataframe where I can groupby companies over the
year-month indicator by putting *share *in the y axis as variables.

### data is like the following

dput(dat)
structure(list(year = c(2018, 2019, 2019, 2019, 2019, 2019, 2019,
2019, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017,
2017, 2017, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018,
2018, 2018, 2018, 2019, 2019, 2019, 2019, 2019), month = c(12,
1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1,
2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5), company = c("ABC",
"ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "FGH", "FGH",
"FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
"FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
"FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH"
), share = c(20, 16.5, 15, 15.5, 15.5, 16, 17, 16.5, 61, 55,
53, 53, 54, 53, 58, 54, 50, 47, 55, 50, 52, 51, 51.5, 52, 53,
54, 55, 53, 54, 50, 42, 48, 41, 40, 39, 36.5, 35), com_name = c(1,
1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)), row.names = c(NA,
-37L), spec = structure(list(cols = list(year = structure(list(), class =
c("collector_double",
"collector")), month = structure(list(), class = c("collector_double",
"collector")), company = structure(list(), class = c("collector_character",
"collector")), share = structure(list(), class = c("collector_double",
"collector")), com_name = structure(list(), class = c("collector_double",
"collector"))), default = structure(list(), class = c("collector_guess",
"collector")), delim = ","), class = "col_spec"), problems = <pointer:
0x7fd732028680>, class = c("spec_tbl_df",
"tbl_df", "tbl", "data.frame"))

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Mon Oct  3 04:33:37 2022
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sun, 2 Oct 2022 19:33:37 -0700
Subject: [R] Help with steam graph
In-Reply-To: <CAFy_oHCNXkHGOXGixzyee74TRKsxjeaozwuR2Y2OY4T4236Kag@mail.gmail.com>
References: <CAFy_oHAn0RGPVXG=ypbxHM_idX08=c94QOh+gpqwXVEEKYnuSw@mail.gmail.com>
 <0073C340-0152-48CF-BB4B-1890BFD1DDF3@comcast.net>
 <CAFy_oHCNXkHGOXGixzyee74TRKsxjeaozwuR2Y2OY4T4236Kag@mail.gmail.com>
Message-ID: <1129c7dc-e5ba-3938-663b-85aeedf0e9ce@comcast.net>

I think you are being dishonest. That code does not appear on hrbrmstr's 
vignette at least in a form that I recognize.

When I run your code from the first posting with all the instances of 
`com_num` replaced by `com_name` and removing the `pointer` entry in dat 
which throws an error when trying to define dat, I get

Error in `group_by()`: ! Must group by variables found in `.data`. ? 
Column `com_name` is not found. So I "rewind the process to the point 
where the error is reported and find

> dat %>%+ select(year, month, company, share, com_name) %>% + 
tidyr::gather(company, share, -year) # A tibble: 148 ? 3 year company 
share <dbl> <chr> <chr> 1 2018 month 12 2 2019 month 1 3 2019 month 2 4 
2019 month 3 5 2019 month 4 6 2019 month 5 7 2019 month 6 8 2019 month 7 
9 2017 month 1 10 2017 month 2 # ? with 138 more rows # ? Use `print(n = 
...)` to see more rows So the "gathering" process seems to have removed 
the `com_name` column. Can exit R without saving your workspace and then 
construct a series of R commands that will create a reproducible 
example? -- David.

On 10/2/22 10:03, Tariq Khasiri wrote:
> Actually in my main data the column name is com_num ( where 
> mistakenly?I pasted the sample data here under the com_name ). So, 
> when I run the command successfully?this is the error shows up -
>
> ? ? ?
> ? 1. ??... %>% sg_legend(show = TRUE, label = "Share: ")
> ? 2. ??streamgraph::sg_legend(., show = TRUE, label = "Share: ")
> ? 3. ??streamgraph::sg_fill_brewer(., "PuOr")
> ? 4. ??streamgraph::sg_axis_x(., 0.8)
> ? 5. ??streamgraph::streamgraph(., "com_num", "n", "year")
> ? 6. ? ??base::data.frame(data)
> ? 7. ??dplyr::ungroup(.)
> ? 8. ??dplyr::tally(., wt = share)
> ? 9. ??dplyr::group_by(., year, com_num)
> ?10. ??dplyr:::group_by.data.frame(., year, com_num)
> ?11. ? ??dplyr::group_by_prepare(.data, ..., .add = .add, caller_env = 
> caller_env())
> ?12. ? ? ??rlang::abort(bullets, call = error_call)
>
> Any suggestions on how I can fix it ??
>
> On Sun, 2 Oct 2022 at 09:12, David Winsemius <dwinsemius at comcast.net> 
> wrote:
>
>     I don?t see a column with the name ?com_num?, so the error message
>     makes complete sense.
>
>     ?
>     David
>
>     Sent from my iPhone
>
>     > On Oct 2, 2022, at 5:06 AM, Tariq Khasiri
>     <tariqkhasiri at gmail.com> wrote:
>     >
>     > ?Hi, i'm trying to create a steamgraph with the following data
>     by creating a
>     > unit indicator by combing the year and month. But, I'm getting
>     error as :
>     >
>     > Error in `group_by()`:
>     > ! Must group by variables found in `.data`.
>     > ? Column `com_num` is not found.
>     > Run `rlang::last_error()` to see where the error occurred.
>     >
>     > ### Packages needed for the code
>     > devtools::install_github("hrbrmstr/streamgraph")
>     >
>     > library(tidyverse)
>     > library(ggplot2)
>     > library(dplyr)
>     > library(steamgraph)
>     >
>     > ### Code ( The following code can be found on creator's account
>     > https://hrbrmstr.github.io/streamgraph/ )
>     >
>     > dat %>%
>     > select(year, month, company, share, com_num) %>%
>     >? tidyr::gather(company, share, -year) %>%
>     >? group_by(year, com_num) %>%
>     >? tally(wt=share) %>%
>     >? ungroup %>%
>     >? streamgraph("com_num", "n", "year") %>%
>     >? sg_axis_x(0.8) %>%
>     >? sg_fill_brewer("PuOr") %>%
>     >? sg_legend(show=TRUE, label="Share: ")
>     >
>     >
>     > ### data is like the following
>     >
>     > dput(dat)
>     > structure(list(year = c(2018, 2019, 2019, 2019, 2019, 2019, 2019,
>     > 2019, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017,
>     > 2017, 2017, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018,
>     > 2018, 2018, 2018, 2019, 2019, 2019, 2019, 2019), month = c(12,
>     > 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1,
>     > 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5), company =
>     c("ABC",
>     > "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "FGH", "FGH",
>     > "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
>     > "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
>     > "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH"
>     > ), share = c(20, 16.5, 15, 15.5, 15.5, 16, 17, 16.5, 61, 55,
>     > 53, 53, 54, 53, 58, 54, 50, 47, 55, 50, 52, 51, 51.5, 52, 53,
>     > 54, 55, 53, 54, 50, 42, 48, 41, 40, 39, 36.5, 35), com_name = c(1,
>     > 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>     > 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)), row.names = c(NA,
>     > -37L), spec = structure(list(cols = list(year =
>     structure(list(), class =
>     > c("collector_double",
>     > "collector")), month = structure(list(), class =
>     c("collector_double",
>     > "collector")), company = structure(list(), class =
>     c("collector_character",
>     > "collector")), share = structure(list(), class =
>     c("collector_double",
>     > "collector")), com_name = structure(list(), class =
>     c("collector_double",
>     > "collector"))), default = structure(list(), class =
>     c("collector_guess",
>     > "collector")), delim = ","), class = "col_spec"), problems =
>     <pointer:
>     > 0x7fd732028680>, class = c("spec_tbl_df",
>     > "tbl_df", "tbl", "data.frame"))
>     >
>     >? ? [[alternative HTML version deleted]]
>     >
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     > and provide commented, minimal, self-contained, reproducible code.
>


From |eo@m@d@ @end|ng |rom @yon|c@eu  Mon Oct  3 05:05:56 2022
From: |eo@m@d@ @end|ng |rom @yon|c@eu (Leonard Mada)
Date: Mon, 3 Oct 2022 06:05:56 +0300
Subject: [R] [External Help] Multivariate Polynomials in R
Message-ID: <b3d455f8-4446-6417-cc1e-b746842bc78e@syonic.eu>

Dear R Users,

I have written some R code for multivariate polynomials in R. I am 
looking forward for some help in redesigning and improving the code.

Although this code was not planned initially to be released as a 
package, the functionality has become quite versatile over time. I will 
provide some examples below. If anyone is interested in multivariate 
polynomials and has some spare time, or has some students interested to 
learn some interesting math, feel free to contact me.

The immediate focus should be on:
1) Writing/improving the automatic tests;
2) Redesigning the code (and build an R package);

As the code has grown in size, I am very cautious to change anything, 
until proper tests are written. I have started to write some test code 
(the link to the GitHub page is below), but I am not yet very confident 
how to properly write the tests and also lack the time as well. I will 
appreciate any expertise and help on this topic.

Ultimately, I hope to be able to focus more on the math topics. I will 
post a separate call for some of these topics.

CODE DETAILS

The source files are on GitHub:
https://github.com/discoleo/R/blob/master/Math/Polynomials.Helper.R
- (all) files named Polynomials.Helper.XXX.R are needed; (~ 25 files, 
including the test files);
- if requested, I can also upload a zip file with all these source files;
- the code started as some helper scripts (which is why all those files 
are mixed with other files);

The multivariate polynomials are stored as data.frames and R's 
aggregate() function is the workhorse: but it proved sufficiently fast 
and the code works well even with polynomials with > 10,000 monomials. I 
have some older Java code which used a TreeMap (sorted map), but I do 
not maintain that code anymore. I was very reserved initially regarding 
the efficiency of the data frame; but it worked well! And it proved very 
useful for sub-setting specific monomials!

I have attached some concrete examples below.

Sincerely,

Leonard


### Examples

source("Polynomials.Helper.R")
# - requires also the other Helper scripts;
# - not strictly needed (but are loaded automatically):
#?? library(polynom)
#?? library(pracma)

### Example 1:
n = 2; # Power "n" will be evaluated automatically
p1 = toPoly.pm("x^n*y + b*z - R")
p2 = toPoly.pm("y^n*z + b*x - R")
p3 = toPoly.pm("z^n*x + b*y - R")

pR = solve.lpm(p1, p2, p3, xn=c("z", "y"))
str(pR) # 124 monomials
# tweaking manually can improve the results;
pR = solve.lpm(p1, p2, p3, xn=c("y", "z"))
str(pR)
# pR[[2]]$Rez: 19 monomials: much better;

pR2 = div.pm(pR[[2]]$Rez, "x^3 + b*x - R", "x")
# Divisible!
str(pR2)
# Order 12 polynomial in x (24 monomials);

### Note:
# - the P[12] contains the distinct roots:
#?? it is the minimal order polynomial;
# - the trivial solution (x^3 + b*x = R) was removed;
# - this is the naive way to solve this system (but good as Demo);

# print the coefficients of x;
# (will be used inside the function coeff.S3Ht below)
pR2 = pR2$Rez;
pR2$coeff = - pR2$coeff; # positive leading coeff;
toCoeff(pR2, "x")

### Quick Check
solve.S3Ht = function(R, b) {
 ?? ?coeff = coeff.S3Ht(R, b);
 ?? ?x = roots(coeff); # library(pracma)
 ?? ?# Note: pracma uses leading to free coeff;
 ?? ?z = b*x^11 - R*x^10 - 2*R^2*b*x^5 + 2*R^2*b^2*x^3 + R*b^4*x^2 - R*b^5;
 ?? ?z = z / (- R^2*x^6 - R*b^2*x^5 + 3*R*b^3*x^3 - b^6);
 ?? ?y = (R - z^2*x) / b;
 ?? ?sol = cbind(x, y, z);
 ?? ?return(sol);
}
coeff.S3Ht = function(R, b) {
 ?? ?coeff = c(b^2, - 2*R*b, R^2 - b^3, 3*R*b^2,
 ?? ???? - 3*R^2*b + b^4, R^3 - 4*R*b^3,
 ?? ???? 2*R^2*b^2 - b^5, 5*R*b^4,
 ?? ???? R^4 - R^2*b^3 + b^6, - 3*R^3*b^2 - 3*R*b^5,
 ?? ???? - R^4*b + 3*R^2*b^4 - b^7,
 ?? ???? 2*R^3*b^3 - R*b^6,
 ?? ???? - R^2*b^5 + b^8);
 ?? ?return(coeff);
}

R = 5; b = -2;
sol = solve.S3Ht(R, b)
# all 12 sets of solutions:
x = sol[,1]; y = sol[,2]; z = sol[,3];

### Test:
x^2*y + b*z
y^2*z + b*x
z^2*x + b*y

id = 1;
eval.pm(p1, list(x=x[id], y=y[id], z=z[id], b=b, R=R))


##############

### Example 2:

n = 5
p1 = toPoly.pm("(x + a)^n + (y + a)^n - R1")
p2 = toPoly.pm("(x + b)*(y + b) - R2")

# Very Naive way to solve:
pR = solve.pm(p1, p2, "y")
str(pR)
table(pR$Rez$x)
# Order 10 with 109 monomials;
# [very naive!]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Oct  3 07:47:41 2022
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 3 Oct 2022 06:47:41 +0100
Subject: [R] Creating a year-month indicator and groupby with category
In-Reply-To: <CAFy_oHDGR7cnNwcTW3mNknKvHhRz+LC4v4XSeKrKEOUjMTcsmA@mail.gmail.com>
References: <CAFy_oHDGR7cnNwcTW3mNknKvHhRz+LC4v4XSeKrKEOUjMTcsmA@mail.gmail.com>
Message-ID: <3a22c0a7-3459-3982-0ff1-cd5df22b842a@sapo.pt>

Hello,

First of all, I'll repost the data at end because the OP posted with a 
pointer ref:

problems = <pointer: 0x7fd732028680>

and this must be removed for the dput output to run.
Suggestion: coerce to class "data.frame" and post the output of


dput(as.data.frame(dat))


Now the plot.
Here are two plots of share by date, grouped by company. One with base R 
graphics and the other one with package ggplot2.

Create a date/time column to be used by both plots.


dat$date <- with(dat, ISOdate(year, month, 1))


1) Base R plot.


ylim <- range(dat$share) + c(0, 2)  # make room for the legend on top
comp <- unique(dat$company)         # draw each line in a loop on companies

# open a blank plot witth all the data,
# setting the ylim as explained above
plot(share ~ date, dat, type = "n", ylim = ylim)
for(i in seq_along(comp)) {
   lines(share ~ date, subset(dat, company == comp[i]), col = i)
}
legend("top", legend = comp, col = seq_along(comp), lty = "solid", horiz 
= TRUE)


2) ggplot2 plot.


library(ggplot2)

ggplot(dat, aes(date, share, color = company)) +
   geom_line() +
   scale_x_datetime(date_labels = "%Y-%m") +
   scale_color_manual(values = c(ABC = "black", FGH = "red")) +
   theme_bw()


3) The data, reposted with the new pipe operator introduced in R 4.1.0 
to make it look modern and slightly edited.


dat |> as.data.frame() |> dput()
dat <-
structure(list(year = c(2018, 2019, 2019, 2019, 2019, 2019, 2019,
2019, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017,
2017, 2017, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018,
2018, 2018, 2018, 2019, 2019, 2019, 2019, 2019), month = c(12,
1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1,
2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5), company = c("ABC",
"ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "FGH", "FGH",
"FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
"FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
"FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH"
), share = c(20, 16.5, 15, 15.5, 15.5, 16, 17, 16.5, 61, 55,
53, 53, 54, 53, 58, 54, 50, 47, 55, 50, 52, 51, 51.5, 52, 53,
54, 55, 53, 54, 50, 42, 48, 41, 40, 39, 36.5, 35), com_name = c(1,
1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2), date = 
structure(c(1543665600,
1546344000, 1549022400, 1551441600, 1554120000, 1556712000, 1559390400,
1561982400, 1483272000, 1485950400, 1488369600, 1491048000, 1493640000,
1496318400, 1498910400, 1501588800, 1504267200, 1506859200, 1509537600,
1512129600, 1514808000, 1517486400, 1519905600, 1522584000, 1525176000,
1527854400, 1530446400, 1533124800, 1535803200, 1538395200, 1541073600,
1543665600, 1546344000, 1549022400, 1551441600, 1554120000, 1556712000
), class = c("POSIXct", "POSIXt"), tzone = "GMT")),
row.names = c(NA, -37L), class = "data.frame")


Hope this helps,

Rui Barradas

?s 00:04 de 03/10/2022, Tariq Khasiri escreveu:
> Hello,
> 
> I have the following data. I want to show in a line plot how each different
> company is earning over the timeline of my data sample.
> 
> I'm not sure how I can create the *year-month indicator* to plot it nicely
> in my horizontal axis out of my dataset.
> 
> After creating the *year-month* indicator ( which will be in my x axis) I
> want to create a dataframe where I can groupby companies over the
> year-month indicator by putting *share *in the y axis as variables.
> 
> ### data is like the following
> 
> dput(dat)
> structure(list(year = c(2018, 2019, 2019, 2019, 2019, 2019, 2019,
> 2019, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017,
> 2017, 2017, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018,
> 2018, 2018, 2018, 2019, 2019, 2019, 2019, 2019), month = c(12,
> 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1,
> 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5), company = c("ABC",
> "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "FGH", "FGH",
> "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
> "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
> "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH"
> ), share = c(20, 16.5, 15, 15.5, 15.5, 16, 17, 16.5, 61, 55,
> 53, 53, 54, 53, 58, 54, 50, 47, 55, 50, 52, 51, 51.5, 52, 53,
> 54, 55, 53, 54, 50, 42, 48, 41, 40, 39, 36.5, 35), com_name = c(1,
> 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)), row.names = c(NA,
> -37L), spec = structure(list(cols = list(year = structure(list(), class =
> c("collector_double",
> "collector")), month = structure(list(), class = c("collector_double",
> "collector")), company = structure(list(), class = c("collector_character",
> "collector")), share = structure(list(), class = c("collector_double",
> "collector")), com_name = structure(list(), class = c("collector_double",
> "collector"))), default = structure(list(), class = c("collector_guess",
> "collector")), delim = ","), class = "col_spec"), problems = <pointer:
> 0x7fd732028680>, class = c("spec_tbl_df",
> "tbl_df", "tbl", "data.frame"))
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drj|m|emon @end|ng |rom gm@||@com  Mon Oct  3 09:45:40 2022
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 3 Oct 2022 18:45:40 +1100
Subject: [R] Creating a year-month indicator and groupby with category
In-Reply-To: <CAFy_oHDGR7cnNwcTW3mNknKvHhRz+LC4v4XSeKrKEOUjMTcsmA@mail.gmail.com>
References: <CAFy_oHDGR7cnNwcTW3mNknKvHhRz+LC4v4XSeKrKEOUjMTcsmA@mail.gmail.com>
Message-ID: <CA+8X3fUzVS1zKi0BaJoq2ZJC0cgXgPj_rXFNq9vVBpo7HCXojA@mail.gmail.com>

Hi Tariq,
There were a couple of glitches in your data structure. Here's an
example of a simple plot:

dat<-structure(list(year = c(2018, 2019, 2019, 2019, 2019, 2019, 2019,
2019, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017,
2017, 2017, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018,
2018, 2018, 2018, 2019, 2019, 2019, 2019, 2019), month = c(12,
1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1,
2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5), company = c("ABC",
"ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "FGH", "FGH",
"FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
"FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
"FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH"
), share = c(20, 16.5, 15, 15.5, 15.5, 16, 17, 16.5, 61, 55,
53, 53, 54, 53, 58, 54, 50, 47, 55, 50, 52, 51, 51.5, 52, 53,
54, 55, 53, 54, 50, 42, 48, 41, 40, 39, 36.5, 35), com_name = c(1,
1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)), row.names = c(NA,
-37L), spec = structure(list(cols = list(year = structure(list(), class =
c("collector_double",
"collector")), month = structure(list(), class = c("collector_double",
"collector")), company = structure(list(), class = c("collector_character",
"collector")), share = structure(list(), class = c("collector_double",
"collector")), com_name = structure(list(), class = c("collector_double",
"collector"))), default = structure(list(), class = c("collector_guess",
"collector")), delim = ","), class = "col_spec"), class = c("spec_tbl_df",
"tbl_df", "tbl", "data.frame"))
# convert year and month fields to dates about the middle of each month
dat$date<-as.Date(paste(dat$year,dat$month,15,sep="-"),"%Y-%m-%d")
# plot the values for one company
plot(dat$date[dat$company=="ABC"],dat$share[dat$company=="ABC"],
 main="Plot of dat",xlab="Year",ylab="Share",
 xlim=range(dat$date),ylim=range(dat$share),
 type="l",col="red")
# add a line for the other one
lines(dat$date[dat$company=="FGH"],dat$share[dat$company=="FGH"],col="green")
# get the x plot limits as they are date values
xspan<-par("usr")[1:2]
# place a legend about in the middle of the plot
legend(xspan[1]+diff(xspan)*0.3,35,c("ABC","FGH"),lty=1,col=c("red","green"))

There are many more elegant ways to plot something like this.

Jim

On Mon, Oct 3, 2022 at 10:05 AM Tariq Khasiri <tariqkhasiri at gmail.com> wrote:
>
> Hello,
>
> I have the following data. I want to show in a line plot how each different
> company is earning over the timeline of my data sample.
>
> I'm not sure how I can create the *year-month indicator* to plot it nicely
> in my horizontal axis out of my dataset.
>
> After creating the *year-month* indicator ( which will be in my x axis) I
> want to create a dataframe where I can groupby companies over the
> year-month indicator by putting *share *in the y axis as variables.
>
> ### data is like the following
>
> dput(dat)
> structure(list(year = c(2018, 2019, 2019, 2019, 2019, 2019, 2019,
> 2019, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017,
> 2017, 2017, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018,
> 2018, 2018, 2018, 2019, 2019, 2019, 2019, 2019), month = c(12,
> 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1,
> 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5), company = c("ABC",
> "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "FGH", "FGH",
> "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
> "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
> "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH"
> ), share = c(20, 16.5, 15, 15.5, 15.5, 16, 17, 16.5, 61, 55,
> 53, 53, 54, 53, 58, 54, 50, 47, 55, 50, 52, 51, 51.5, 52, 53,
> 54, 55, 53, 54, 50, 42, 48, 41, 40, 39, 36.5, 35), com_name = c(1,
> 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)), row.names = c(NA,
> -37L), spec = structure(list(cols = list(year = structure(list(), class =
> c("collector_double",
> "collector")), month = structure(list(), class = c("collector_double",
> "collector")), company = structure(list(), class = c("collector_character",
> "collector")), share = structure(list(), class = c("collector_double",
> "collector")), com_name = structure(list(), class = c("collector_double",
> "collector"))), default = structure(list(), class = c("collector_guess",
> "collector")), delim = ","), class = "col_spec"), problems = <pointer:
> 0x7fd732028680>, class = c("spec_tbl_df",
> "tbl_df", "tbl", "data.frame"))
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From y@ngk@|9999 @end|ng |rom y@hoo@com  Mon Oct  3 17:51:04 2022
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Mon, 3 Oct 2022 15:51:04 +0000 (UTC)
Subject: [R] automatic convert list to dataframe
References: <667635225.2169008.1664812264411.ref@mail.yahoo.com>
Message-ID: <667635225.2169008.1664812264411@mail.yahoo.com>

Hi R team,
I can use rio package to read excel file into R as a list. The excel file content multiple sheets (30 - 40 data sheets). I can convert each data elements into dataframe manually. I have multiple excel files with multiple data sheets. I need to load them into R and do the comparison for same sheet name from difference excel file. My current code is:
 library(rio)? ?setwd ("C:/temp")
filenames <- gsub("\\.xlsx$","", list.files(pattern="\\.xlsx$"))
for(i in filenames){
? assign(i, import_list(paste0(i, ".xlsx", sep="")))
}
file1_dx1? ? ?<-? file1[["dx1"]]

file1_dx2? ? ?<-? file1[["dx2"]]

file1_dx3? ? ?<-? file1[["dx3"]]

file2_dx1? ? ?<-? file1[["dx1"]]

file2_dx2? ? ?<-? file1[["dx2"]]
......

I hope the code can?automatic converting the list (may have 30 - 40 lists) by adding file name (such as: filename_sheetname) and put it in for loop


Thank you,
Kai




	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Oct  3 19:14:19 2022
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 3 Oct 2022 18:14:19 +0100
Subject: [R] automatic convert list to dataframe
In-Reply-To: <667635225.2169008.1664812264411@mail.yahoo.com>
References: <667635225.2169008.1664812264411.ref@mail.yahoo.com>
 <667635225.2169008.1664812264411@mail.yahoo.com>
Message-ID: <ddf82083-4b7e-24d6-e31e-2c868004f391@sapo.pt>

Hello,


list2env(file1, envir = .GlobalEnv)


will create data.frames dx1, dx2, etc, in the global environment.
If you really need the names file1_dx1, file1_dx2, etc, you can first 
change the names


names(file1) <- paste("file1", names(file1), sep = "_")


and then run list2env like above.

Hope this helps,

Rui Barradas

?s 16:51 de 03/10/2022, Kai Yang via R-help escreveu:
> Hi R team,
> I can use rio package to read excel file into R as a list. The excel file content multiple sheets (30 - 40 data sheets). I can convert each data elements into dataframe manually. I have multiple excel files with multiple data sheets. I need to load them into R and do the comparison for same sheet name from difference excel file. My current code is:
>   library(rio)? ?setwd ("C:/temp")
> filenames <- gsub("\\.xlsx$","", list.files(pattern="\\.xlsx$"))
> for(i in filenames){
>  ? assign(i, import_list(paste0(i, ".xlsx", sep="")))
> }
> file1_dx1? ? ?<-? file1[["dx1"]]
> 
> file1_dx2? ? ?<-? file1[["dx2"]]
> 
> file1_dx3? ? ?<-? file1[["dx3"]]
> 
> file2_dx1? ? ?<-? file1[["dx1"]]
> 
> file2_dx2? ? ?<-? file1[["dx2"]]
> ......
> 
> I hope the code can?automatic converting the list (may have 30 - 40 lists) by adding file name (such as: filename_sheetname) and put it in for loop
> 
> 
> Thank you,
> Kai
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From y@ngk@|9999 @end|ng |rom y@hoo@com  Mon Oct  3 19:38:43 2022
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Mon, 3 Oct 2022 17:38:43 +0000 (UTC)
Subject: [R] automatic convert list to dataframe
In-Reply-To: <ddf82083-4b7e-24d6-e31e-2c868004f391@sapo.pt>
References: <667635225.2169008.1664812264411.ref@mail.yahoo.com>
 <667635225.2169008.1664812264411@mail.yahoo.com>
 <ddf82083-4b7e-24d6-e31e-2c868004f391@sapo.pt>
Message-ID: <1293770278.2201006.1664818723656@mail.yahoo.com>

 Hi Rui,
list2env(file1, envir = .GlobalEnv) is worked very well. Thank you.

But when?I tried to put the sample code? into for loop. I got error message:
for(i in filenames){
? assign(i, import_list(paste0(i, ".xlsx", sep="")))
? names(i) <- paste(i, names(i), sep = "_")
? list2env(names(i), envir = .GlobalEnv)
}
Error in list2env(names(i), envir = .GlobalEnv) :?? first argument must be a named list

It seems I cannot put names(i) into for loop,?Could you please help me to debug it?
Thank you,Kai    On Monday, October 3, 2022 at 10:14:25 AM PDT, Rui Barradas <ruipbarradas at sapo.pt> wrote:  
 
 Hello,


list2env(file1, envir = .GlobalEnv)


will create data.frames dx1, dx2, etc, in the global environment.
If you really need the names file1_dx1, file1_dx2, etc, you can first 
change the names


names(file1) <- paste("file1", names(file1), sep = "_")


and then run list2env like above.

Hope this helps,

Rui Barradas

?s 16:51 de 03/10/2022, Kai Yang via R-help escreveu:
> Hi R team,
> I can use rio package to read excel file into R as a list. The excel file content multiple sheets (30 - 40 data sheets). I can convert each data elements into dataframe manually. I have multiple excel files with multiple data sheets. I need to load them into R and do the comparison for same sheet name from difference excel file. My current code is:
>? library(rio)? ?setwd ("C:/temp")
> filenames <- gsub("\\.xlsx$","", list.files(pattern="\\.xlsx$"))
> for(i in filenames){
>? ? assign(i, import_list(paste0(i, ".xlsx", sep="")))
> }
> file1_dx1? ? ?<-? file1[["dx1"]]
> 
> file1_dx2? ? ?<-? file1[["dx2"]]
> 
> file1_dx3? ? ?<-? file1[["dx3"]]
> 
> file2_dx1? ? ?<-? file1[["dx1"]]
> 
> file2_dx2? ? ?<-? file1[["dx2"]]
> ......
> 
> I hope the code can?automatic converting the list (may have 30 - 40 lists) by adding file name (such as: filename_sheetname) and put it in for loop
> 
> 
> Thank you,
> Kai
> 
> 
> 
> 
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
  
	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Oct  3 21:08:57 2022
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 3 Oct 2022 20:08:57 +0100
Subject: [R] automatic convert list to dataframe
In-Reply-To: <1293770278.2201006.1664818723656@mail.yahoo.com>
References: <667635225.2169008.1664812264411.ref@mail.yahoo.com>
 <667635225.2169008.1664812264411@mail.yahoo.com>
 <ddf82083-4b7e-24d6-e31e-2c868004f391@sapo.pt>
 <1293770278.2201006.1664818723656@mail.yahoo.com>
Message-ID: <4a102d90-352b-9c07-a83d-7dc9c3054be3@sapo.pt>

Hello,

If in each iteration i is a list, try removing the call to names().
Try, in the loop,


list2env(i, envir = .GlobalEnv)


The error message is telling that list2env's first argument must be a 
named list and names(i) is an unnamed vector, it's i that's the named 
list (you even changed its names in the previous instruction).

Hope this helps,

Rui Barradas

?s 18:38 de 03/10/2022, Kai Yang escreveu:
>   Hi Rui,
> list2env(file1, envir = .GlobalEnv) is worked very well. Thank you.
> 
> But when?I tried to put the sample code? into for loop. I got error message:
> for(i in filenames){
>  ? assign(i, import_list(paste0(i, ".xlsx", sep="")))
>  ? names(i) <- paste(i, names(i), sep = "_")
>  ? list2env(names(i), envir = .GlobalEnv)
> }
> Error in list2env(names(i), envir = .GlobalEnv) :?? first argument must be a named list
> 
> It seems I cannot put names(i) into for loop,?Could you please help me to debug it?
> Thank you,Kai    On Monday, October 3, 2022 at 10:14:25 AM PDT, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>   
>   Hello,
> 
> 
> list2env(file1, envir = .GlobalEnv)
> 
> 
> will create data.frames dx1, dx2, etc, in the global environment.
> If you really need the names file1_dx1, file1_dx2, etc, you can first
> change the names
> 
> 
> names(file1) <- paste("file1", names(file1), sep = "_")
> 
> 
> and then run list2env like above.
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 16:51 de 03/10/2022, Kai Yang via R-help escreveu:
>> Hi R team,
>> I can use rio package to read excel file into R as a list. The excel file content multiple sheets (30 - 40 data sheets). I can convert each data elements into dataframe manually. I have multiple excel files with multiple data sheets. I need to load them into R and do the comparison for same sheet name from difference excel file. My current code is:
>>  ? library(rio)? ?setwd ("C:/temp")
>> filenames <- gsub("\\.xlsx$","", list.files(pattern="\\.xlsx$"))
>> for(i in filenames){
>>  ? ? assign(i, import_list(paste0(i, ".xlsx", sep="")))
>> }
>> file1_dx1? ? ?<-? file1[["dx1"]]
>>
>> file1_dx2? ? ?<-? file1[["dx2"]]
>>
>> file1_dx3? ? ?<-? file1[["dx3"]]
>>
>> file2_dx1? ? ?<-? file1[["dx1"]]
>>
>> file2_dx2? ? ?<-? file1[["dx2"]]
>> ......
>>
>> I hope the code can?automatic converting the list (may have 30 - 40 lists) by adding file name (such as: filename_sheetname) and put it in for loop
>>
>>
>> Thank you,
>> Kai
>>
>>
>>
>>
>>  ??? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From y@ngk@|9999 @end|ng |rom y@hoo@com  Mon Oct  3 21:51:11 2022
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Mon, 3 Oct 2022 19:51:11 +0000 (UTC)
Subject: [R] automatic convert list to dataframe
In-Reply-To: <4a102d90-352b-9c07-a83d-7dc9c3054be3@sapo.pt>
References: <667635225.2169008.1664812264411.ref@mail.yahoo.com>
 <667635225.2169008.1664812264411@mail.yahoo.com>
 <ddf82083-4b7e-24d6-e31e-2c868004f391@sapo.pt>
 <1293770278.2201006.1664818723656@mail.yahoo.com>
 <4a102d90-352b-9c07-a83d-7dc9c3054be3@sapo.pt>
Message-ID: <97481848.2244592.1664826671871@mail.yahoo.com>

 Hi Rui,
I copied "list2env(i, envir = .GlobalEnv)" to the code, but I got the same error message of "first argument must be a named list". Maybe list2env cannot put in loop? the code works very well outside of for loop.
One more thing, the difference file may have same sheet name. that's why I want to add file name in front of sheet name to avoid overwriting. It still works well outside of loop, but doesn't work in loop. I don't know how to fix the problems.
Thank you,
Kai

    On Monday, October 3, 2022 at 12:09:04 PM PDT, Rui Barradas <ruipbarradas at sapo.pt> wrote:  
 
 Hello,

If in each iteration i is a list, try removing the call to names().
Try, in the loop,


list2env(i, envir = .GlobalEnv)


The error message is telling that list2env's first argument must be a 
named list and names(i) is an unnamed vector, it's i that's the named 
list (you even changed its names in the previous instruction).

Hope this helps,

Rui Barradas

?s 18:38 de 03/10/2022, Kai Yang escreveu:
>? Hi Rui,
> list2env(file1, envir = .GlobalEnv) is worked very well. Thank you.
> 
> But when?I tried to put the sample code? into for loop. I got error message:
> for(i in filenames){
>? ? assign(i, import_list(paste0(i, ".xlsx", sep="")))
>? ? names(i) <- paste(i, names(i), sep = "_")
>? ? list2env(names(i), envir = .GlobalEnv)
> }
> Error in list2env(names(i), envir = .GlobalEnv) :?? first argument must be a named list
> 
> It seems I cannot put names(i) into for loop,?Could you please help me to debug it?
> Thank you,Kai? ? On Monday, October 3, 2022 at 10:14:25 AM PDT, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>? 
>? Hello,
> 
> 
> list2env(file1, envir = .GlobalEnv)
> 
> 
> will create data.frames dx1, dx2, etc, in the global environment.
> If you really need the names file1_dx1, file1_dx2, etc, you can first
> change the names
> 
> 
> names(file1) <- paste("file1", names(file1), sep = "_")
> 
> 
> and then run list2env like above.
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 16:51 de 03/10/2022, Kai Yang via R-help escreveu:
>> Hi R team,
>> I can use rio package to read excel file into R as a list. The excel file content multiple sheets (30 - 40 data sheets). I can convert each data elements into dataframe manually. I have multiple excel files with multiple data sheets. I need to load them into R and do the comparison for same sheet name from difference excel file. My current code is:
>>? ? library(rio)? ?setwd ("C:/temp")
>> filenames <- gsub("\\.xlsx$","", list.files(pattern="\\.xlsx$"))
>> for(i in filenames){
>>? ? ? assign(i, import_list(paste0(i, ".xlsx", sep="")))
>> }
>> file1_dx1? ? ?<-? file1[["dx1"]]
>>
>> file1_dx2? ? ?<-? file1[["dx2"]]
>>
>> file1_dx3? ? ?<-? file1[["dx3"]]
>>
>> file2_dx1? ? ?<-? file1[["dx1"]]
>>
>> file2_dx2? ? ?<-? file1[["dx2"]]
>> ......
>>
>> I hope the code can?automatic converting the list (may have 30 - 40 lists) by adding file name (such as: filename_sheetname) and put it in for loop
>>
>>
>> Thank you,
>> Kai
>>
>>
>>
>>
>>? ??? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>? ? 
  
	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Oct  4 00:04:12 2022
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 3 Oct 2022 23:04:12 +0100
Subject: [R] automatic convert list to dataframe
In-Reply-To: <97481848.2244592.1664826671871@mail.yahoo.com>
References: <667635225.2169008.1664812264411.ref@mail.yahoo.com>
 <667635225.2169008.1664812264411@mail.yahoo.com>
 <ddf82083-4b7e-24d6-e31e-2c868004f391@sapo.pt>
 <1293770278.2201006.1664818723656@mail.yahoo.com>
 <4a102d90-352b-9c07-a83d-7dc9c3054be3@sapo.pt>
 <97481848.2244592.1664826671871@mail.yahoo.com>
Message-ID: <9ce3b94f-6533-5ecb-bc35-584d6877526a@sapo.pt>

Hello,

Here are two more attempts at solving the problem.

1. Instead of having 30-40 data.frames per file in the globalenv, not a 
good idea, the following code will create as many lists as you have 
files and each list is a list of df's.


temp_list <- vector("list", length = length(filenames))
for(i in seq_along(filenames)){
   xlfile <- filenames[i]
   temp_list[[i]] <- import_list(paste0(xlfile, ".xlsx"))
}
list2env(temp_list, envir = .GlobalEnv)
rm(temp_list)

Now you can access the data with code like


file1$dx1       # a data.frame, first sheet in excel file1
file1[["dx1"]]  # equivalent


2. I cannot see a reason why the following shouldn't work. It creates 
lots of data.frames in the globalenv, 30-40 per file. This makes the 
globalenv messy and is not recommended.


temp_list <- vector("list", length = length(filenames))
for(i in seq_along(filenames)){
   # import the data
   xlfile <- filenames[i]
   temp_list[[i]] <- import_list(paste0(xlfile, ".xlsx"))
   # now take care of the names
   new_names <- paste(xlfile, names(temp_list[[i]]), sep = "_")
   names(temp_list[[i]]) <- new_names
   # create the current data.frames in the globalenv
   list2env(temp_list[[i]], envir = .GlobalEnv)
}
rm(temp_list)


Hope this helps,

Rui Barradas


?s 20:51 de 03/10/2022, Kai Yang escreveu:
>   Hi Rui,
> I copied "list2env(i, envir = .GlobalEnv)" to the code, but I got the same error message of "first argument must be a named list". Maybe list2env cannot put in loop? the code works very well outside of for loop.
> One more thing, the difference file may have same sheet name. that's why I want to add file name in front of sheet name to avoid overwriting. It still works well outside of loop, but doesn't work in loop. I don't know how to fix the problems.
> Thank you,
> Kai
> 
>      On Monday, October 3, 2022 at 12:09:04 PM PDT, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>   
>   Hello,
> 
> If in each iteration i is a list, try removing the call to names().
> Try, in the loop,
> 
> 
> list2env(i, envir = .GlobalEnv)
> 
> 
> The error message is telling that list2env's first argument must be a
> named list and names(i) is an unnamed vector, it's i that's the named
> list (you even changed its names in the previous instruction).
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 18:38 de 03/10/2022, Kai Yang escreveu:
>>  ? Hi Rui,
>> list2env(file1, envir = .GlobalEnv) is worked very well. Thank you.
>>
>> But when?I tried to put the sample code? into for loop. I got error message:
>> for(i in filenames){
>>  ? ? assign(i, import_list(paste0(i, ".xlsx", sep="")))
>>  ? ? names(i) <- paste(i, names(i), sep = "_")
>>  ? ? list2env(names(i), envir = .GlobalEnv)
>> }
>> Error in list2env(names(i), envir = .GlobalEnv) :?? first argument must be a named list
>>
>> It seems I cannot put names(i) into for loop,?Could you please help me to debug it?
>> Thank you,Kai? ? On Monday, October 3, 2022 at 10:14:25 AM PDT, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>    
>>  ? Hello,
>>
>>
>> list2env(file1, envir = .GlobalEnv)
>>
>>
>> will create data.frames dx1, dx2, etc, in the global environment.
>> If you really need the names file1_dx1, file1_dx2, etc, you can first
>> change the names
>>
>>
>> names(file1) <- paste("file1", names(file1), sep = "_")
>>
>>
>> and then run list2env like above.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 16:51 de 03/10/2022, Kai Yang via R-help escreveu:
>>> Hi R team,
>>> I can use rio package to read excel file into R as a list. The excel file content multiple sheets (30 - 40 data sheets). I can convert each data elements into dataframe manually. I have multiple excel files with multiple data sheets. I need to load them into R and do the comparison for same sheet name from difference excel file. My current code is:
>>>  ? ? library(rio)? ?setwd ("C:/temp")
>>> filenames <- gsub("\\.xlsx$","", list.files(pattern="\\.xlsx$"))
>>> for(i in filenames){
>>>  ? ? ? assign(i, import_list(paste0(i, ".xlsx", sep="")))
>>> }
>>> file1_dx1? ? ?<-? file1[["dx1"]]
>>>
>>> file1_dx2? ? ?<-? file1[["dx2"]]
>>>
>>> file1_dx3? ? ?<-? file1[["dx3"]]
>>>
>>> file2_dx1? ? ?<-? file1[["dx1"]]
>>>
>>> file2_dx2? ? ?<-? file1[["dx2"]]
>>> ......
>>>
>>> I hope the code can?automatic converting the list (may have 30 - 40 lists) by adding file name (such as: filename_sheetname) and put it in for loop
>>>
>>>
>>> Thank you,
>>> Kai
>>>
>>>
>>>
>>>
>>>  ? ??? [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>      
>


From t@r|qkh@@|r| @end|ng |rom gm@||@com  Tue Oct  4 00:30:46 2022
From: t@r|qkh@@|r| @end|ng |rom gm@||@com (Tariq Khasiri)
Date: Mon, 3 Oct 2022 17:30:46 -0500
Subject: [R] Creating a year-month indicator and groupby with category
In-Reply-To: <CA+8X3fUzVS1zKi0BaJoq2ZJC0cgXgPj_rXFNq9vVBpo7HCXojA@mail.gmail.com>
References: <CAFy_oHDGR7cnNwcTW3mNknKvHhRz+LC4v4XSeKrKEOUjMTcsmA@mail.gmail.com>
 <CA+8X3fUzVS1zKi0BaJoq2ZJC0cgXgPj_rXFNq9vVBpo7HCXojA@mail.gmail.com>
Message-ID: <CAFy_oHDaT-a=G_PrE768Xhk56MA3JwSqWOYGvogtDoQfF6F7+Q@mail.gmail.com>

Thanks everyone for being so kind and patient with me throughout the
process! Mr. Barradas and Mr. Lemon, very generous of you for taking the
time and patience to go over my code and data , and taking the time to give
me meaningful feedback!

With your help and suggestion, I was successful in making a graph from my
data. In my main data I have four companies, and just making the graph
process a little more advanced. However after writing the command , I get
the error that I have 4 values but gave only 2 values. Would anyone kindly
guide me what's the mistake and how I can rectify this?

Data is the same. But my main data has 4 companies whereas in R project I
just gave 2 only for convenience.

#### Code needed to execute it #########

library(tidyverse)
library(showtext)
library(usefunc)
library(patchwork)
library(cowplot)
library(rcartocolor)
library(zoo)

# load fonts
font_add_google(name = "Bungee Shade", family = "bungee")
font_add_google(name = "Dosis", family = "dosis")
showtext_auto()

# set colours
f_cols = c("#008080", "#329999", "#66b2b2",
           "#7fbfbf", "#99cccc", "#cce5e5")
m_cols = c("#4b0082", "#6e329b", "#9366b4",
           "#a57fc0", "#b799cd", "#dbcce6")

dat$YearMonth <- as.yearmon(paste(dat$year, " ", dat$month), "%Y %m")

# plot of share of companies per year
p1 <- ggplot(data = dat,
             mapping = aes(x = YearMonth, y = share, colour = company)) +
  geom_line() +
  geom_point(size = 1) +
  scale_colour_manual("", values = c(f_cols[1], m_cols[1]), labels = c("F",
"M" , "C" , "G")) +
  scale_y_continuous(limits = c(0, 80)) +
  coord_cartesian(expand = F) +
  labs(x = "Year",
       y = "Share of Companies") +
  theme(legend.position = c(0.1, 0.9),
        legend.title = element_blank(),
        legend.text = element_text(family = "dosis", size = 14),
        panel.background = element_rect(fill = "#FAFAFA", colour =
"#FAFAFA"),
        plot.background = element_rect(fill = "#FAFAFA", colour =
"#FAFAFA"),
        legend.background = element_rect(fill = "transparent", colour =
"transparent"),
        legend.key = element_rect(fill = "transparent", colour =
"transparent"),
        axis.title.y = element_text(margin = margin(0, 20, 0, 0), family =
"dosis"),
        axis.text = element_text(family = "dosis"),
        plot.margin = unit(c(0.5, 0.8, 0.5, 0.5), "cm"),
        panel.grid.major = element_line(colour = "#DEDEDE"),
        panel.grid.minor = element_blank())
p1

The error is saying :

??ggplot2 (local) FUN(X[[i]], ...)
  7.         ??base::unlist(...)
  8.         ??base::lapply(scales$scales, function(scale) scale$map_df(df
= df))
  9.           ??ggplot2 (local) FUN(X[[i]], ...)
 10.             ??scale$map_df(df = df)
 11.               ??ggplot2 (local) f(..., self = self)
 12.                 ??base::lapply(aesthetics, function(j)
self$map(df[[j]]))
 13.                   ??ggplot2 (local) FUN(X[[i]], ...)
 14.                     ??self$map(df[[j]])
 15.                       ??ggplot2 (local) f(..., self = self)
 16.                         ??self$palette(n)
 17.                           ??ggplot2 (local) f(...)
 18.                             ??rlang::abort(glue("Insufficient values
in manual scale. {n} needed but only {length(values)} provided."))

On Mon, 3 Oct 2022 at 02:45, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Tariq,
> There were a couple of glitches in your data structure. Here's an
> example of a simple plot:
>
> dat<-structure(list(year = c(2018, 2019, 2019, 2019, 2019, 2019, 2019,
> 2019, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017,
> 2017, 2017, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018,
> 2018, 2018, 2018, 2019, 2019, 2019, 2019, 2019), month = c(12,
> 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1,
> 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5), company = c("ABC",
> "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "FGH", "FGH",
> "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
> "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
> "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH"
> ), share = c(20, 16.5, 15, 15.5, 15.5, 16, 17, 16.5, 61, 55,
> 53, 53, 54, 53, 58, 54, 50, 47, 55, 50, 52, 51, 51.5, 52, 53,
> 54, 55, 53, 54, 50, 42, 48, 41, 40, 39, 36.5, 35), com_name = c(1,
> 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)), row.names = c(NA,
> -37L), spec = structure(list(cols = list(year = structure(list(), class =
> c("collector_double",
> "collector")), month = structure(list(), class = c("collector_double",
> "collector")), company = structure(list(), class = c("collector_character",
> "collector")), share = structure(list(), class = c("collector_double",
> "collector")), com_name = structure(list(), class = c("collector_double",
> "collector"))), default = structure(list(), class = c("collector_guess",
> "collector")), delim = ","), class = "col_spec"), class = c("spec_tbl_df",
> "tbl_df", "tbl", "data.frame"))
> # convert year and month fields to dates about the middle of each month
> dat$date<-as.Date(paste(dat$year,dat$month,15,sep="-"),"%Y-%m-%d")
> # plot the values for one company
> plot(dat$date[dat$company=="ABC"],dat$share[dat$company=="ABC"],
>  main="Plot of dat",xlab="Year",ylab="Share",
>  xlim=range(dat$date),ylim=range(dat$share),
>  type="l",col="red")
> # add a line for the other one
>
> lines(dat$date[dat$company=="FGH"],dat$share[dat$company=="FGH"],col="green")
> # get the x plot limits as they are date values
> xspan<-par("usr")[1:2]
> # place a legend about in the middle of the plot
>
> legend(xspan[1]+diff(xspan)*0.3,35,c("ABC","FGH"),lty=1,col=c("red","green"))
>
> There are many more elegant ways to plot something like this.
>
> Jim
>
> On Mon, Oct 3, 2022 at 10:05 AM Tariq Khasiri <tariqkhasiri at gmail.com>
> wrote:
> >
> > Hello,
> >
> > I have the following data. I want to show in a line plot how each
> different
> > company is earning over the timeline of my data sample.
> >
> > I'm not sure how I can create the *year-month indicator* to plot it
> nicely
> > in my horizontal axis out of my dataset.
> >
> > After creating the *year-month* indicator ( which will be in my x axis) I
> > want to create a dataframe where I can groupby companies over the
> > year-month indicator by putting *share *in the y axis as variables.
> >
> > ### data is like the following
> >
> > dput(dat)
> > structure(list(year = c(2018, 2019, 2019, 2019, 2019, 2019, 2019,
> > 2019, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017,
> > 2017, 2017, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018,
> > 2018, 2018, 2018, 2019, 2019, 2019, 2019, 2019), month = c(12,
> > 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1,
> > 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5), company = c("ABC",
> > "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "FGH", "FGH",
> > "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
> > "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
> > "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH"
> > ), share = c(20, 16.5, 15, 15.5, 15.5, 16, 17, 16.5, 61, 55,
> > 53, 53, 54, 53, 58, 54, 50, 47, 55, 50, 52, 51, 51.5, 52, 53,
> > 54, 55, 53, 54, 50, 42, 48, 41, 40, 39, 36.5, 35), com_name = c(1,
> > 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> > 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)), row.names = c(NA,
> > -37L), spec = structure(list(cols = list(year = structure(list(), class =
> > c("collector_double",
> > "collector")), month = structure(list(), class = c("collector_double",
> > "collector")), company = structure(list(), class =
> c("collector_character",
> > "collector")), share = structure(list(), class = c("collector_double",
> > "collector")), com_name = structure(list(), class = c("collector_double",
> > "collector"))), default = structure(list(), class = c("collector_guess",
> > "collector")), delim = ","), class = "col_spec"), problems = <pointer:
> > 0x7fd732028680>, class = c("spec_tbl_df",
> > "tbl_df", "tbl", "data.frame"))
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Oct  4 00:41:34 2022
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 3 Oct 2022 15:41:34 -0700
Subject: [R] automatic convert list to dataframe
In-Reply-To: <9ce3b94f-6533-5ecb-bc35-584d6877526a@sapo.pt>
References: <667635225.2169008.1664812264411.ref@mail.yahoo.com>
 <667635225.2169008.1664812264411@mail.yahoo.com>
 <ddf82083-4b7e-24d6-e31e-2c868004f391@sapo.pt>
 <1293770278.2201006.1664818723656@mail.yahoo.com>
 <4a102d90-352b-9c07-a83d-7dc9c3054be3@sapo.pt>
 <97481848.2244592.1664826671871@mail.yahoo.com>
 <9ce3b94f-6533-5ecb-bc35-584d6877526a@sapo.pt>
Message-ID: <CAGxFJbT-xm49epvu1cU2cffpD4u1FMaLe=Y031PGg97kTU+aTg@mail.gmail.com>

... But why not dispense with multiple files, name juggling, and
environments by simply putting everything in one list of lists (lists are
recursive structures!):

all_files <- lapply(filenames, function(nm)import_list(nm,...))
names(all_files) <- filenames
## Note: the ... are any optional parameters to import_list() that may be
needed.
## Perhaps none.

all_files will then be a single list, each of whose components is a list of
data frames for all the sheets in the file. I would think that such a list
could easily be accessed and manipulated via list indexing and
*apply-family functions. Just seems like a more straightforward approach to
me (assuming I haven't misunderstood, of course).

Bert




On Mon, Oct 3, 2022 at 3:04 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Here are two more attempts at solving the problem.
>
> 1. Instead of having 30-40 data.frames per file in the globalenv, not a
> good idea, the following code will create as many lists as you have
> files and each list is a list of df's.
>
>
> temp_list <- vector("list", length = length(filenames))
> for(i in seq_along(filenames)){
>    xlfile <- filenames[i]
>    temp_list[[i]] <- import_list(paste0(xlfile, ".xlsx"))
> }
> list2env(temp_list, envir = .GlobalEnv)
> rm(temp_list)
>
> Now you can access the data with code like
>
>
> file1$dx1       # a data.frame, first sheet in excel file1
> file1[["dx1"]]  # equivalent
>
>
> 2. I cannot see a reason why the following shouldn't work. It creates
> lots of data.frames in the globalenv, 30-40 per file. This makes the
> globalenv messy and is not recommended.
>
>
> temp_list <- vector("list", length = length(filenames))
> for(i in seq_along(filenames)){
>    # import the data
>    xlfile <- filenames[i]
>    temp_list[[i]] <- import_list(paste0(xlfile, ".xlsx"))
>    # now take care of the names
>    new_names <- paste(xlfile, names(temp_list[[i]]), sep = "_")
>    names(temp_list[[i]]) <- new_names
>    # create the current data.frames in the globalenv
>    list2env(temp_list[[i]], envir = .GlobalEnv)
> }
> rm(temp_list)
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> ?s 20:51 de 03/10/2022, Kai Yang escreveu:
> >   Hi Rui,
> > I copied "list2env(i, envir = .GlobalEnv)" to the code, but I got the
> same error message of "first argument must be a named list". Maybe list2env
> cannot put in loop? the code works very well outside of for loop.
> > One more thing, the difference file may have same sheet name. that's why
> I want to add file name in front of sheet name to avoid overwriting. It
> still works well outside of loop, but doesn't work in loop. I don't know
> how to fix the problems.
> > Thank you,
> > Kai
> >
> >      On Monday, October 3, 2022 at 12:09:04 PM PDT, Rui Barradas <
> ruipbarradas at sapo.pt> wrote:
> >
> >   Hello,
> >
> > If in each iteration i is a list, try removing the call to names().
> > Try, in the loop,
> >
> >
> > list2env(i, envir = .GlobalEnv)
> >
> >
> > The error message is telling that list2env's first argument must be a
> > named list and names(i) is an unnamed vector, it's i that's the named
> > list (you even changed its names in the previous instruction).
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> > ?s 18:38 de 03/10/2022, Kai Yang escreveu:
> >>    Hi Rui,
> >> list2env(file1, envir = .GlobalEnv) is worked very well. Thank you.
> >>
> >> But when I tried to put the sample code  into for loop. I got error
> message:
> >> for(i in filenames){
> >>      assign(i, import_list(paste0(i, ".xlsx", sep="")))
> >>      names(i) <- paste(i, names(i), sep = "_")
> >>      list2env(names(i), envir = .GlobalEnv)
> >> }
> >> Error in list2env(names(i), envir = .GlobalEnv) :   first argument must
> be a named list
> >>
> >> It seems I cannot put names(i) into for loop, Could you please help me
> to debug it?
> >> Thank you,Kai    On Monday, October 3, 2022 at 10:14:25 AM PDT, Rui
> Barradas <ruipbarradas at sapo.pt> wrote:
> >>
> >>    Hello,
> >>
> >>
> >> list2env(file1, envir = .GlobalEnv)
> >>
> >>
> >> will create data.frames dx1, dx2, etc, in the global environment.
> >> If you really need the names file1_dx1, file1_dx2, etc, you can first
> >> change the names
> >>
> >>
> >> names(file1) <- paste("file1", names(file1), sep = "_")
> >>
> >>
> >> and then run list2env like above.
> >>
> >> Hope this helps,
> >>
> >> Rui Barradas
> >>
> >> ?s 16:51 de 03/10/2022, Kai Yang via R-help escreveu:
> >>> Hi R team,
> >>> I can use rio package to read excel file into R as a list. The excel
> file content multiple sheets (30 - 40 data sheets). I can convert each data
> elements into dataframe manually. I have multiple excel files with multiple
> data sheets. I need to load them into R and do the comparison for same
> sheet name from difference excel file. My current code is:
> >>>      library(rio)   setwd ("C:/temp")
> >>> filenames <- gsub("\\.xlsx$","", list.files(pattern="\\.xlsx$"))
> >>> for(i in filenames){
> >>>        assign(i, import_list(paste0(i, ".xlsx", sep="")))
> >>> }
> >>> file1_dx1     <-  file1[["dx1"]]
> >>>
> >>> file1_dx2     <-  file1[["dx2"]]
> >>>
> >>> file1_dx3     <-  file1[["dx3"]]
> >>>
> >>> file2_dx1     <-  file1[["dx1"]]
> >>>
> >>> file2_dx2     <-  file1[["dx2"]]
> >>> ......
> >>>
> >>> I hope the code can automatic converting the list (may have 30 - 40
> lists) by adding file name (such as: filename_sheetname) and put it in for
> loop
> >>>
> >>>
> >>> Thank you,
> >>> Kai
> >>>
> >>>
> >>>
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From y@ngk@|9999 @end|ng |rom y@hoo@com  Tue Oct  4 01:08:14 2022
From: y@ngk@|9999 @end|ng |rom y@hoo@com (Kai Yang)
Date: Mon, 3 Oct 2022 23:08:14 +0000 (UTC)
Subject: [R] automatic convert list to dataframe
In-Reply-To: <CAGxFJbT-xm49epvu1cU2cffpD4u1FMaLe=Y031PGg97kTU+aTg@mail.gmail.com>
References: <667635225.2169008.1664812264411.ref@mail.yahoo.com>
 <667635225.2169008.1664812264411@mail.yahoo.com>
 <ddf82083-4b7e-24d6-e31e-2c868004f391@sapo.pt>
 <1293770278.2201006.1664818723656@mail.yahoo.com>
 <4a102d90-352b-9c07-a83d-7dc9c3054be3@sapo.pt>
 <97481848.2244592.1664826671871@mail.yahoo.com>
 <9ce3b94f-6533-5ecb-bc35-584d6877526a@sapo.pt>
 <CAGxFJbT-xm49epvu1cU2cffpD4u1FMaLe=Y031PGg97kTU+aTg@mail.gmail.com>
Message-ID: <1316789341.2303013.1664838494147@mail.yahoo.com>

 Hello Rui and Bert,
This is a great help! Thank you both!
Here is my job assignment: boss accumulate many years excel reports from same lab. Each report contents multiple data sheets. Those sheets may/may not updated, and some sheets are new. Good news is, the same testing result data will be saved in a data sheet and assign the same sheet name with same fields name, but does not in same file. Boss wants me to get non.duplicate data for difference testing from those excel files. So, I want to load all data into R and assign each data frame name as filename_sheetname. I use the 2nd suggestion from Rui to get this step done! Thanks Rui again. This method save a lot of time for me. Now, I can combine data frames (same _sheetname) together and remove duplicate.
Best,
Kai
    On Monday, October 3, 2022 at 03:41:45 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:  
 
 ... But why not dispense with multiple files, name juggling, and environments by simply putting everything in one list of lists (lists are recursive structures!):

all_files <- lapply(filenames, function(nm)import_list(nm,...))names(all_files) <- filenames
## Note: the ... are any optional parameters to import_list() that may be needed. 
## Perhaps none.

all_files will then be a single list, each of whose components is a list of data frames for all the sheets in the file. I would think that such a list could easily be accessed and manipulated via list indexing and *apply-family functions. Just seems like a more straightforward approach to me (assuming I haven't misunderstood, of course).
Bert




On Mon, Oct 3, 2022 at 3:04 PM Rui Barradas <ruipbarradas at sapo.pt> wrote:

Hello,

Here are two more attempts at solving the problem.

1. Instead of having 30-40 data.frames per file in the globalenv, not a 
good idea, the following code will create as many lists as you have 
files and each list is a list of df's.


temp_list <- vector("list", length = length(filenames))
for(i in seq_along(filenames)){
? ?xlfile <- filenames[i]
? ?temp_list[[i]] <- import_list(paste0(xlfile, ".xlsx"))
}
list2env(temp_list, envir = .GlobalEnv)
rm(temp_list)

Now you can access the data with code like


file1$dx1? ? ? ?# a data.frame, first sheet in excel file1
file1[["dx1"]]? # equivalent


2. I cannot see a reason why the following shouldn't work. It creates 
lots of data.frames in the globalenv, 30-40 per file. This makes the 
globalenv messy and is not recommended.


temp_list <- vector("list", length = length(filenames))
for(i in seq_along(filenames)){
? ?# import the data
? ?xlfile <- filenames[i]
? ?temp_list[[i]] <- import_list(paste0(xlfile, ".xlsx"))
? ?# now take care of the names
? ?new_names <- paste(xlfile, names(temp_list[[i]]), sep = "_")
? ?names(temp_list[[i]]) <- new_names
? ?# create the current data.frames in the globalenv
? ?list2env(temp_list[[i]], envir = .GlobalEnv)
}
rm(temp_list)


Hope this helps,

Rui Barradas


?s 20:51 de 03/10/2022, Kai Yang escreveu:
>? ?Hi Rui,
> I copied "list2env(i, envir = .GlobalEnv)" to the code, but I got the same error message of "first argument must be a named list". Maybe list2env cannot put in loop? the code works very well outside of for loop.
> One more thing, the difference file may have same sheet name. that's why I want to add file name in front of sheet name to avoid overwriting. It still works well outside of loop, but doesn't work in loop. I don't know how to fix the problems.
> Thank you,
> Kai
> 
>? ? ? On Monday, October 3, 2022 at 12:09:04 PM PDT, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>? ?
>? ?Hello,
> 
> If in each iteration i is a list, try removing the call to names().
> Try, in the loop,
> 
> 
> list2env(i, envir = .GlobalEnv)
> 
> 
> The error message is telling that list2env's first argument must be a
> named list and names(i) is an unnamed vector, it's i that's the named
> list (you even changed its names in the previous instruction).
> 
> Hope this helps,
> 
> Rui Barradas
> 
> ?s 18:38 de 03/10/2022, Kai Yang escreveu:
>>? ? Hi Rui,
>> list2env(file1, envir = .GlobalEnv) is worked very well. Thank you.
>>
>> But when?I tried to put the sample code? into for loop. I got error message:
>> for(i in filenames){
>>? ? ? assign(i, import_list(paste0(i, ".xlsx", sep="")))
>>? ? ? names(i) <- paste(i, names(i), sep = "_")
>>? ? ? list2env(names(i), envir = .GlobalEnv)
>> }
>> Error in list2env(names(i), envir = .GlobalEnv) :?? first argument must be a named list
>>
>> It seems I cannot put names(i) into for loop,?Could you please help me to debug it?
>> Thank you,Kai? ? On Monday, October 3, 2022 at 10:14:25 AM PDT, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>? ? 
>>? ? Hello,
>>
>>
>> list2env(file1, envir = .GlobalEnv)
>>
>>
>> will create data.frames dx1, dx2, etc, in the global environment.
>> If you really need the names file1_dx1, file1_dx2, etc, you can first
>> change the names
>>
>>
>> names(file1) <- paste("file1", names(file1), sep = "_")
>>
>>
>> and then run list2env like above.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> ?s 16:51 de 03/10/2022, Kai Yang via R-help escreveu:
>>> Hi R team,
>>> I can use rio package to read excel file into R as a list. The excel file content multiple sheets (30 - 40 data sheets). I can convert each data elements into dataframe manually. I have multiple excel files with multiple data sheets. I need to load them into R and do the comparison for same sheet name from difference excel file. My current code is:
>>>? ? ? library(rio)? ?setwd ("C:/temp")
>>> filenames <- gsub("\\.xlsx$","", list.files(pattern="\\.xlsx$"))
>>> for(i in filenames){
>>>? ? ? ? assign(i, import_list(paste0(i, ".xlsx", sep="")))
>>> }
>>> file1_dx1? ? ?<-? file1[["dx1"]]
>>>
>>> file1_dx2? ? ?<-? file1[["dx2"]]
>>>
>>> file1_dx3? ? ?<-? file1[["dx3"]]
>>>
>>> file2_dx1? ? ?<-? file1[["dx1"]]
>>>
>>> file2_dx2? ? ?<-? file1[["dx2"]]
>>> ......
>>>
>>> I hope the code can?automatic converting the list (may have 30 - 40 lists) by adding file name (such as: filename_sheetname) and put it in for loop
>>>
>>>
>>> Thank you,
>>> Kai
>>>
>>>
>>>
>>>
>>>? ? ??? [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>? ? ? 
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

  
	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Oct  4 08:23:29 2022
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 4 Oct 2022 07:23:29 +0100
Subject: [R] Creating a year-month indicator and groupby with category
In-Reply-To: <CAFy_oHDaT-a=G_PrE768Xhk56MA3JwSqWOYGvogtDoQfF6F7+Q@mail.gmail.com>
References: <CAFy_oHDGR7cnNwcTW3mNknKvHhRz+LC4v4XSeKrKEOUjMTcsmA@mail.gmail.com>
 <CA+8X3fUzVS1zKi0BaJoq2ZJC0cgXgPj_rXFNq9vVBpo7HCXojA@mail.gmail.com>
 <CAFy_oHDaT-a=G_PrE768Xhk56MA3JwSqWOYGvogtDoQfF6F7+Q@mail.gmail.com>
Message-ID: <7e07b891-b085-910d-0c32-c6ad693b9cb4@sapo.pt>

Hello,

The error comes from having 2 colors and 4 labels in


scale_colour_manual("", values = c(f_cols[1], m_cols[1]), labels = 
c("F", "M" , "C" , "G"))


You need the same number of colors and labels. For instance, though 
they're probably not the colors you want the following vector has 4 
colors and the plot code doesn't give an error.


values = c(f_cols[1], m_cols[1], f_cols[2], m_cols[2])



Besides, why are you defining 2 colors vectors with 6 colors each if you 
only have 4 companies?

Hope this helps,

Rui Barradas

?s 23:30 de 03/10/2022, Tariq Khasiri escreveu:
> Thanks everyone for being so kind and patient with me throughout the
> process! Mr. Barradas and Mr. Lemon, very generous of you for taking the
> time and patience to go over my code and data , and taking the time to give
> me meaningful feedback!
> 
> With your help and suggestion, I was successful in making a graph from my
> data. In my main data I have four companies, and just making the graph
> process a little more advanced. However after writing the command , I get
> the error that I have 4 values but gave only 2 values. Would anyone kindly
> guide me what's the mistake and how I can rectify this?
> 
> Data is the same. But my main data has 4 companies whereas in R project I
> just gave 2 only for convenience.
> 
> #### Code needed to execute it #########
> 
> library(tidyverse)
> library(showtext)
> library(usefunc)
> library(patchwork)
> library(cowplot)
> library(rcartocolor)
> library(zoo)
> 
> # load fonts
> font_add_google(name = "Bungee Shade", family = "bungee")
> font_add_google(name = "Dosis", family = "dosis")
> showtext_auto()
> 
> # set colours
> f_cols = c("#008080", "#329999", "#66b2b2",
>             "#7fbfbf", "#99cccc", "#cce5e5")
> m_cols = c("#4b0082", "#6e329b", "#9366b4",
>             "#a57fc0", "#b799cd", "#dbcce6")
> 
> dat$YearMonth <- as.yearmon(paste(dat$year, " ", dat$month), "%Y %m")
> 
> # plot of share of companies per year
> p1 <- ggplot(data = dat,
>               mapping = aes(x = YearMonth, y = share, colour = company)) +
>    geom_line() +
>    geom_point(size = 1) +
>    scale_colour_manual("", values = c(f_cols[1], m_cols[1]), labels = c("F",
> "M" , "C" , "G")) +
>    scale_y_continuous(limits = c(0, 80)) +
>    coord_cartesian(expand = F) +
>    labs(x = "Year",
>         y = "Share of Companies") +
>    theme(legend.position = c(0.1, 0.9),
>          legend.title = element_blank(),
>          legend.text = element_text(family = "dosis", size = 14),
>          panel.background = element_rect(fill = "#FAFAFA", colour =
> "#FAFAFA"),
>          plot.background = element_rect(fill = "#FAFAFA", colour =
> "#FAFAFA"),
>          legend.background = element_rect(fill = "transparent", colour =
> "transparent"),
>          legend.key = element_rect(fill = "transparent", colour =
> "transparent"),
>          axis.title.y = element_text(margin = margin(0, 20, 0, 0), family =
> "dosis"),
>          axis.text = element_text(family = "dosis"),
>          plot.margin = unit(c(0.5, 0.8, 0.5, 0.5), "cm"),
>          panel.grid.major = element_line(colour = "#DEDEDE"),
>          panel.grid.minor = element_blank())
> p1
> 
> The error is saying :
> 
> ??ggplot2 (local) FUN(X[[i]], ...)
>    7.         ??base::unlist(...)
>    8.         ??base::lapply(scales$scales, function(scale) scale$map_df(df
> = df))
>    9.           ??ggplot2 (local) FUN(X[[i]], ...)
>   10.             ??scale$map_df(df = df)
>   11.               ??ggplot2 (local) f(..., self = self)
>   12.                 ??base::lapply(aesthetics, function(j)
> self$map(df[[j]]))
>   13.                   ??ggplot2 (local) FUN(X[[i]], ...)
>   14.                     ??self$map(df[[j]])
>   15.                       ??ggplot2 (local) f(..., self = self)
>   16.                         ??self$palette(n)
>   17.                           ??ggplot2 (local) f(...)
>   18.                             ??rlang::abort(glue("Insufficient values
> in manual scale. {n} needed but only {length(values)} provided."))
> 
> On Mon, 3 Oct 2022 at 02:45, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
>> Hi Tariq,
>> There were a couple of glitches in your data structure. Here's an
>> example of a simple plot:
>>
>> dat<-structure(list(year = c(2018, 2019, 2019, 2019, 2019, 2019, 2019,
>> 2019, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017,
>> 2017, 2017, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018,
>> 2018, 2018, 2018, 2019, 2019, 2019, 2019, 2019), month = c(12,
>> 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1,
>> 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5), company = c("ABC",
>> "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "FGH", "FGH",
>> "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
>> "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
>> "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH"
>> ), share = c(20, 16.5, 15, 15.5, 15.5, 16, 17, 16.5, 61, 55,
>> 53, 53, 54, 53, 58, 54, 50, 47, 55, 50, 52, 51, 51.5, 52, 53,
>> 54, 55, 53, 54, 50, 42, 48, 41, 40, 39, 36.5, 35), com_name = c(1,
>> 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)), row.names = c(NA,
>> -37L), spec = structure(list(cols = list(year = structure(list(), class =
>> c("collector_double",
>> "collector")), month = structure(list(), class = c("collector_double",
>> "collector")), company = structure(list(), class = c("collector_character",
>> "collector")), share = structure(list(), class = c("collector_double",
>> "collector")), com_name = structure(list(), class = c("collector_double",
>> "collector"))), default = structure(list(), class = c("collector_guess",
>> "collector")), delim = ","), class = "col_spec"), class = c("spec_tbl_df",
>> "tbl_df", "tbl", "data.frame"))
>> # convert year and month fields to dates about the middle of each month
>> dat$date<-as.Date(paste(dat$year,dat$month,15,sep="-"),"%Y-%m-%d")
>> # plot the values for one company
>> plot(dat$date[dat$company=="ABC"],dat$share[dat$company=="ABC"],
>>   main="Plot of dat",xlab="Year",ylab="Share",
>>   xlim=range(dat$date),ylim=range(dat$share),
>>   type="l",col="red")
>> # add a line for the other one
>>
>> lines(dat$date[dat$company=="FGH"],dat$share[dat$company=="FGH"],col="green")
>> # get the x plot limits as they are date values
>> xspan<-par("usr")[1:2]
>> # place a legend about in the middle of the plot
>>
>> legend(xspan[1]+diff(xspan)*0.3,35,c("ABC","FGH"),lty=1,col=c("red","green"))
>>
>> There are many more elegant ways to plot something like this.
>>
>> Jim
>>
>> On Mon, Oct 3, 2022 at 10:05 AM Tariq Khasiri <tariqkhasiri at gmail.com>
>> wrote:
>>>
>>> Hello,
>>>
>>> I have the following data. I want to show in a line plot how each
>> different
>>> company is earning over the timeline of my data sample.
>>>
>>> I'm not sure how I can create the *year-month indicator* to plot it
>> nicely
>>> in my horizontal axis out of my dataset.
>>>
>>> After creating the *year-month* indicator ( which will be in my x axis) I
>>> want to create a dataframe where I can groupby companies over the
>>> year-month indicator by putting *share *in the y axis as variables.
>>>
>>> ### data is like the following
>>>
>>> dput(dat)
>>> structure(list(year = c(2018, 2019, 2019, 2019, 2019, 2019, 2019,
>>> 2019, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017,
>>> 2017, 2017, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018,
>>> 2018, 2018, 2018, 2019, 2019, 2019, 2019, 2019), month = c(12,
>>> 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1,
>>> 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5), company = c("ABC",
>>> "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "FGH", "FGH",
>>> "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
>>> "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
>>> "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH"
>>> ), share = c(20, 16.5, 15, 15.5, 15.5, 16, 17, 16.5, 61, 55,
>>> 53, 53, 54, 53, 58, 54, 50, 47, 55, 50, 52, 51, 51.5, 52, 53,
>>> 54, 55, 53, 54, 50, 42, 48, 41, 40, 39, 36.5, 35), com_name = c(1,
>>> 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>>> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)), row.names = c(NA,
>>> -37L), spec = structure(list(cols = list(year = structure(list(), class =
>>> c("collector_double",
>>> "collector")), month = structure(list(), class = c("collector_double",
>>> "collector")), company = structure(list(), class =
>> c("collector_character",
>>> "collector")), share = structure(list(), class = c("collector_double",
>>> "collector")), com_name = structure(list(), class = c("collector_double",
>>> "collector"))), default = structure(list(), class = c("collector_guess",
>>> "collector")), delim = ","), class = "col_spec"), problems = <pointer:
>>> 0x7fd732028680>, class = c("spec_tbl_df",
>>> "tbl_df", "tbl", "data.frame"))
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Er|c@RhonC@|deron @end|ng |rom pennmed|c|ne@upenn@edu  Tue Oct  4 15:36:59 2022
From: Er|c@RhonC@|deron @end|ng |rom pennmed|c|ne@upenn@edu (Rhon Calderon, Eric)
Date: Tue, 4 Oct 2022 13:36:59 +0000
Subject: [R] Help executing R on High Performance Cluster
Message-ID: <MN2PR04MB6400AA8141307B71683D51F8CB5A9@MN2PR04MB6400.namprd04.prod.outlook.com>

Hi,

I need some help executing recently downloaded R on my HPC.

Here is the script I used to install R on my HPC module:


wget https://cran.r-project.org/src/base-prerelease/R-devel.tar.gz

tar -xvf R-devel.tar.gz

cd /home/ericrhon/labsoftware/R-devel/

./configure --prefix=/home/ericrhon/labsoftware/R-devel -with-recommended-packages=no --without-x --with-cairo --with-libpng --with-libtiff --with-jpeglib --enable-R-shlib --with-pcre1

make

make install

After I installed, I tried to run /home/ericrhon/labsoftware/R-devel/R. But I get the next error:


/home/ericrhon/labsoftware/R-devel/bin/exec/R: line 272: /home/ericrhon/labsoftware/R-devel/bin/exec/R: Argument list too long

/home/ericrhon/labsoftware/R-devel/bin/exec/R: line 272: /home/ericrhon/labsoftware/R-devel/bin/exec/R: Success

Here is the exec script of R, line 272 is highlighted:


#!/bin/sh

# Shell wrapper for R executable.


R_HOME_DIR="/home/ericrhon/labsoftware/R-devel"

if test "${R_HOME_DIR}" = "/home/ericrhon/labsoftware/shared_Renv/versions/R-devel/lib64/R"; then

   case "linux-gnu" in

   linux*)

     run_arch=`uname -m`

     case "$run_arch" in

        x86_64|mips64|ppc64|powerpc64|sparc64|s390x)

          libnn=lib64

          libnn_fallback=lib

        ;;

        *)

          libnn=lib

          libnn_fallback=lib64

        ;;

     esac

     if [ -x "/home/ericrhon/labsoftware/shared_Renv/versions/R-devel/${libnn}/R/bin/exec/R" ]; then

        R_HOME_DIR="/home/ericrhon/labsoftware/shared_Renv/versions/R-devel/${libnn}/R"

     elif [ -x "/home/ericrhon/labsoftware/shared_Renv/versions/R-devel/${libnn_fallback}/R/bin/exec/R" ]; then

        R_HOME_DIR="/home/ericrhon/labsoftware/shared_Renv/versions/R-devel/${libnn_fallback}/R"

     ## else -- leave alone (might be a sub-arch)

     fi

     ;;

  esac

fi


if test -n "${R_HOME}" && \

   test "${R_HOME}" != "${R_HOME_DIR}"; then

  echo "WARNING: ignoring environment value of R_HOME"

fi

R_HOME="${R_HOME_DIR}"

export R_HOME

R_SHARE_DIR="${R_HOME_DIR}/share"

export R_SHARE_DIR

R_INCLUDE_DIR="${R_HOME_DIR}/include"

export R_INCLUDE_DIR

R_DOC_DIR="${R_HOME_DIR}/doc"

export R_DOC_DIR


# Since this script can be called recursively, we allow R_ARCH to

# be overridden from the environment.

# This script is shared by parallel installs, so nothing in it should

# depend on the sub-architecture except the default here.

: ${R_ARCH=}


usage="

Usage: R [options] [< infile] [> outfile]

   or: R CMD command [arguments]


Start R, a system for statistical computation and graphics, with the

specified options, or invoke an R tool via the 'R CMD' interface.


Options:

  -h, --help            Print short help message and exit

  --version             Print version info and exit

  --encoding=ENC        Specify encoding to be used for stdin

  --encoding ENC

  RHOME                                  Print path to R home directory and exit

  --save                Do save workspace at the end of the session

  --no-save             Don't save it

  --no-environ          Don't read the site and user environment files

  --no-site-file        Don't read the site-wide Rprofile

  --no-init-file        Don't read the user R profile

  --restore             Do restore previously saved objects at startup

  --no-restore-data     Don't restore previously saved objects

  --no-restore-history  Don't restore the R history file

  --no-restore          Don't restore anything

  --vanilla                     Combine --no-save, --no-restore, --no-site-file,

                                    --no-init-file and --no-environ

  --no-readline         Don't use readline for command-line editing

  --max-ppsize=N        Set max size of protect stack to N

  --min-nsize=N         Set min number of fixed size obj's (\"cons cells\") to N

  --min-vsize=N         Set vector heap minimum to N bytes; '4M' = 4 MegaB

  -q, --quiet           Don't print startup message

  --silent              Same as --quiet

  -s, --no-echo         Make R run as quietly as possible

  --interactive         Force an interactive session

  --verbose             Print more information about progress

  -d, --debugger=NAME   Run R through debugger NAME

  --debugger-args=ARGS  Pass ARGS as arguments to the debugger

  -g TYPE, --gui=TYPE   Use TYPE as GUI; possible values are 'X11' (default)

                                    and 'Tk'.

  --arch=NAME            Specify a sub-architecture

  --args                Skip the rest of the command line

  -f FILE, --file=FILE  Take input from 'FILE'

  -e EXPR               Execute 'EXPR' and exit


FILE may contain spaces but not shell metacharacters.


Commands:

  BATCH                                   Run R in batch mode

  COMPILE                   Compile files for use with R

  SHLIB                         Build shared library for dynamic loading

  INSTALL                     Install add-on packages

  REMOVE                    Remove add-on packages

  build                          Build add-on packages

  check                         Check add-on packages

  LINK                           Front-end for creating executable programs

  Rprof                         Post-process R profiling files

  Rdconv                      Convert Rd format to various other formats

  Rd2pdf                      Convert Rd format to PDF

  Rd2txt                       Convert Rd format to pretty text

  Stangle                      Extract S/R code from Sweave documentation

  Sweave                      Process Sweave documentation

  Rdiff                           Diff R output ignoring headers etc

  config            Obtain configuration information about R

  javareconf                 Update the Java configuration variables

  rtags                 Create Emacs-style tag files from C, R, and Rd files


Please use 'R CMD command --help' to obtain further information about

the usage of 'command'.


Options --arch, --no-environ, --no-init-file, --no-site-file and --vanilla

can be placed between R and CMD, to apply to R processes run by 'command'


Report bugs at <https://bugs.R-project.org>."


## some systems have a more portable sed, e.g. /usr/xpg4/bin/sed on Solaris,

## so make sure that is used.

SED=/usr/bin/sed

export SED


error () {

  echo "ERROR: $*" >&2

  exit 1

}


### Argument loop

args=

debugger=

debugger_args=

gui=

while test -n "${1}"; do

  case ${1} in

    RHOME|--print-home)

      echo "${R_HOME}"; exit 0 ;;

    CMD)

      shift;

      export R_ARCH

      . "${R_HOME}/etc${R_ARCH}/ldpaths"

      exec sh "${R_HOME}/bin/Rcmd" "${@}" ;;

    -g|--gui)

      if test -n "`echo ${2} | ${SED} 's/^-.*//'`"; then

            gui="${2}"

        args="${args} ${1} ${2}"

            shift

      else

            error "option '${1}' requires an argument"

      fi

      ;;

    --gui=*)

      gui=`echo "${1}" | ${SED} -e 's/[^=]*=//'`

      args="${args} ${1}"

      ;;

    -d|--debugger)

      if test -n "`echo ${2} | ${SED} 's/^-.*//'`"; then

            debugger="${2}"; shift

      else

            error "option '${1}' requires an argument"

      fi

      ;;

    --debugger=*)

      debugger=`echo "${1}" | ${SED} -e 's/[^=]*=//'` ;;

    --debugger-args=*)

      debugger_args=`echo "${1}" | ${SED} -e 's/[^=]*=//'` ;;

    -h|--help)

      echo "${usage}"; exit 0 ;;

    --args)

      break ;;

    --arch)

      if test -n "`echo ${2} | ${SED} 's/^-.*//'`"; then

            R_ARCH="/${2}"

        shift

      else

        error "option '${1}' requires an argument"

      fi

      ## check sub-architecture here for a better error message

      if ! test -d ${R_HOME}/etc${R_ARCH}; then

        error "sub-architecture '${1}' is not installed"

      fi

      ;;

    --arch=*)

      r_arch=`echo "${1}" | ${SED} -e 's/[^=]*=//'`

      R_ARCH="/${r_arch}"

      ## check sub-architecture here for a better error message

      if ! test -d ${R_HOME}/etc${R_ARCH}; then

        error "sub-architecture '${r_arch}' is not installed"

      fi

      ;;

    -e)

      TAB=`printf "\t"`

      if test -n "`echo ${2} | ${SED} 's/^-.*//'`"; then

            a=`(echo "${2}" && echo) | ${SED} -e 's/ /~+~/g' | \

          ${SED} -e :a -e N -e '$!ba' -e 's/\n/~n~/g' -e 's/~n~$//g' -e "s/$TAB/~t~/g"`

        shift

      else

            error "option '${1}' requires a non-empty argument"

      fi

      args="${args} -e $a"

      ;;

    -f)

      if test -n "`echo ${2} | ${SED} 's/^-.*//'`"; then

            a=`echo "${2}" | ${SED} -e 's/ /~+~/g'`; shift

      else

            error "option '${1}' requires a filename argument"

      fi

      args="${args} -f $a"

      ;;

    --file=*)

      a=`echo "${1}" | ${SED} -e 's/[^=]*=//' | ${SED} -e 's/ /~+~/g'`

      args="${args} --file=$a"

      ;;

    --no-environ)

      R_ENVIRON=''

      export R_ENVIRON

      R_ENVIRON_USER=''

      export R_ENVIRON_USER

      args="${args} ${1}"

      ;;

    --no-site-file)

      R_PROFILE=''

      export R_PROFILE

      args="${args} ${1}"

      ;;

    --no-init-file)

      R_PROFILE_USER=''

      export R_PROFILE_USER

      args="${args} ${1}"

      ;;

    --vanilla)

      R_ENVIRON=''

      export R_ENVIRON

      R_ENVIRON_USER=''

      export R_ENVIRON_USER

      R_PROFILE=''

      export R_PROFILE

      R_PROFILE_USER=''

      export R_PROFILE_USER

      args="${args} ${1}"

      ;;

    *)

      args="${args} ${1}" ;;

  esac

  shift

done


. "${R_HOME}/etc${R_ARCH}/ldpaths"


R_binary="${R_HOME}/bin/exec${R_ARCH}/R"

export R_ARCH


case "${gui}" in

Tk|tk|X11|x11)

  ;;

"")

  ;;

*)

  error "unknown GUI ${gui}"

esac


## R_HOME may have moved, so check

if test -x "${R_HOME}"; then

  :

else

  error "R_HOME ('${R_HOME}') not found"

fi


## Startup
if test -z "${debugger}"; then
  exec "${R_binary}"  ${args} "${@}"

else

  ## Ideally, we would like the debugger to start R with additional

  ## ('inferior') arguments, but not all debuggers can do this.  We know

  ## about valgrind and some versions of GDB , and deal with these.

  ## Otherwise, to be on the safe side, we disregard non-debugger

  ## command line args.

  args_ok=no

  case "`${debugger} --version 2>/dev/null`" in

    "GNU gdb"*)

      if ${debugger} --help 2>/dev/null | \

          grep ' *--args' >/dev/null; then

            args_ok=yes

            debugger_args="${debugger_args} --args"

      fi

      ;;

    valgrind*)

      args_ok=yes

      ;;

  esac

  if test -n "${args}${*}" && test "${args_ok}" = no; then

    args=`expr "${args} ${*}" : " *\(.*\)"`

    echo "*** Further command line arguments ('${args}') disregarded"

    echo "*** (maybe use 'run ${args}' from *inside* ${debugger})"

    echo ""

    exec ${debugger} ${debugger_args} "${R_binary}"

  else

    exec ${debugger} ${debugger_args} "${R_binary}" ${args} "${@}"

  fi

fi


### Local Variables: ***

### mode: sh ***

### sh-indentation: 2 ***

### End: ***


Could you please help me? I have been trying to load it unsuccessfully.

Thanks.

Eric



	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Tue Oct  4 16:27:36 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Tue, 4 Oct 2022 17:27:36 +0300
Subject: [R] Help executing R on High Performance Cluster
In-Reply-To: <MN2PR04MB6400AA8141307B71683D51F8CB5A9@MN2PR04MB6400.namprd04.prod.outlook.com>
References: <MN2PR04MB6400AA8141307B71683D51F8CB5A9@MN2PR04MB6400.namprd04.prod.outlook.com>
Message-ID: <20221004172736.637bca14@arachnoid>

Hi Eric!

? Tue, 4 Oct 2022 13:36:59 +0000
"Rhon Calderon, Eric" <Eric.RhonCalderon at pennmedicine.upenn.edu> ?????:

> cd /home/ericrhon/labsoftware/R-devel/

> ./configure --prefix=/home/ericrhon/labsoftware/R-devel

I'm not sure, but the reason for the confusing behaviour could be
that the installation prefix is set to be the same as the directory
where you had unpacked the source code. This may have caused file path
conflicts and maybe some kind of recursion when building the final
executable path.

R can run straight from the build directory, without installation.
If you start from scratch, does bin/R work without `make install`? If
not, do you get any useful output if you run bin/R under sh -x?

(Additionally, R supports building away from the source code directory.
For example, if you navigate to the source code directory, then run
mkdir build && cd build && ../configure $CONFIGURE_ARGUMENTS, the build
will be mostly self-contained to that directory, which may be useful
when experimenting.)

Why are you building R with --with-recommended-packages=no?

R is supposed to be easy to build and start working with, but there may
be important details to consider, especially on an HPC, in the "R
installation and administration" guide:
https://cran.r-project.org/doc/manuals/r-release/R-admin.html

> Here is the exec script of R, line 272 is highlighted:
<...>
>	[[alternative HTML version deleted]]

This mailing list strips the HTML version of the e-mails; here's what
we see: https://stat.ethz.ch/pipermail/r-help/2022-October/475956.html

One way to link to R source code is to use the GitHub mirror:
https://github.com/r-devel/r-svn

-- 
Best regards,
Ivan


From petr@p|k@| @end|ng |rom prechez@@cz  Tue Oct  4 13:01:14 2022
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 4 Oct 2022 11:01:14 +0000
Subject: [R] R version 4.2.1 install.packages does not work with IE proxy
 setting
Message-ID: <344ae947626245a392ebba421f73e483@SRVEXCHCM1302.precheza.cz>

Dear all

After we installed new R version R 4.2.1 installing packages through IE
proxy setting is compromised with warning that R could not connect to server
(tested in vanilla R).

> chooseCRANmirror()
Warning: failed to download mirrors file (cannot open URL
'https://cran.r-project.org/CRAN_mirrors.csv'); using local file
'D:/programy/R/doc/CRAN_mirrors.csv'
Warning message:
In download.file(url, destfile = f, quiet = TRUE) :
  URL 'https://cran.r-project.org/CRAN_mirrors.csv': status was 'Couldn't
connect to server'

So install.packages("whatever") also ends with similar warnings.

When using directly (without proxy need) install.packages works as expected.

In R4.1.0 version it works as expected, without any warnings and packages
could be installed smoothly.

Is it known issue with this version? 
Could it be due to somehow corrupted installation?
Should we set something differently for this new R version

Best regards
Petr

From kry|ov@r00t @end|ng |rom gm@||@com  Tue Oct  4 17:42:56 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Tue, 4 Oct 2022 18:42:56 +0300
Subject: [R] 
 R version 4.2.1 install.packages does not work with IE proxy setting
In-Reply-To: <344ae947626245a392ebba421f73e483@SRVEXCHCM1302.precheza.cz>
References: <344ae947626245a392ebba421f73e483@SRVEXCHCM1302.precheza.cz>
Message-ID: <20221004184256.7ce13c60@arachnoid>

On Tue, 4 Oct 2022 11:01:14 +0000
PIKAL Petr <petr.pikal at precheza.cz> wrote:

> After we installed new R version R 4.2.1 installing packages through
> IE proxy setting is compromised with warning that R could not connect
> to server (tested in vanilla R).

R 4.1 deprecated the use of download.file(method = 'wininet'). R 4.2
switched the default download method to 'libcurl' and started giving
warnings for 'wininet' and http[s]:// URLs.

A workaround to get it working right now would be to set
options(download.file.method = 'wininet') and live with the resulting
warnings while R downloads the files, but a next version of R may
remove 'wininet' support altogether.

In order to get it working with the 'libcurl' method, you'll need to
provide some environment variables to curl:
https://stat.ethz.ch/pipermail/r-help/2022-September/475917.html

Not sure if libcurl would accept a patch to discover the Windows proxy
settings automatically, but I don't think it does that now.

-- 
Best regards,
Ivan


From M@|@@_D@S||v@ @end|ng |rom h@dm@h@rv@rd@edu  Tue Oct  4 17:58:20 2022
From: M@|@@_D@S||v@ @end|ng |rom h@dm@h@rv@rd@edu (Da Silva, Maisa Monseff Rodrigues)
Date: Tue, 4 Oct 2022 15:58:20 +0000
Subject: [R] R version 4.2.1 (2022-06-23),
 RStudio 2022.07.2 "Spotted Wakerobin" Release (e7373ef8,
 2022-09-06) for macOS, macOS Monterey version 12.6. Error: SVN not found
Message-ID: <BYAPR07MB5447FD6F319350E1EDDAA2D5AA5A9@BYAPR07MB5447.namprd07.prod.outlook.com>

Hello.
Thank you for helping me.
I am starting my Bioinformatics pathway, and came across a problem im stuck with, even after trying different things:

When in RStudio, I was able to install Git, but SVN remains "not found".
I tried installing SVN through HomeBrew and downloaded Xcode's Command Lines from Apple Developer (as instructed on https://support.rstudio.com/hc/en-us/articles/200532077?version=2022.07.2%2B576&mode=desktop).
After those steps, I restarted R and continue to see "not found" for SVN (git is working fine).
When on mac terminal,

"svn --version" prints

svn, version 1.14.2 (r1899510)

   compiled Oct  3 2022, 21:23:39 on x86_64-apple-darwin21.6.0


"svn info" prints

svn: E155007: '/Users/maisamonseff' is not a working copy

Could you point out what it is I am doing wrong?


Thank you in advance,

Maisa Monseff Rodrigues da Silva
MD - Endocrinologist - University S?o Paulo (Brazil)
PhD Student University S?o Paulo (BR) / Harvard (USA)

________________________________
CONFIDENTIALITY NOTICE: This message and any attached do...{{dropped:11}}


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Oct  4 19:18:22 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 04 Oct 2022 10:18:22 -0700
Subject: [R] R version 4.2.1 (2022-06-23),
 RStudio 2022.07.2 "Spotted Wakerobin" Release (e7373ef8,
 2022-09-06) for macOS, macOS Monterey version 12.6. Error: SVN not found
In-Reply-To: <BYAPR07MB5447FD6F319350E1EDDAA2D5AA5A9@BYAPR07MB5447.namprd07.prod.outlook.com>
References: <BYAPR07MB5447FD6F319350E1EDDAA2D5AA5A9@BYAPR07MB5447.namprd07.prod.outlook.com>
Message-ID: <8A776EC5-00FF-4F1A-A7CA-909331FB0463@dcn.davis.ca.us>

>Could you point out what it is I am doing wrong?

... wrong... posting questions about SVN and RStudio in a forum about R? Do read the Posting Guide before posting. There are specialty mailing lists mentioned there that _might_ be relevant, but it seems to me that you need to learn how to use SVN before you learn how to use it with RStudio, and neither of those tools are on their own relevant in any of the R mailing lists.

I don't use a Mac, but I believe you may encounter difficulties using it related to the fact that everything homebrew tools do has permissions restrictions related to homebrew so mixing in non-homebrew tools may not work.

Try perhaps StackOverflow or Reddit?

On October 4, 2022 8:58:20 AM PDT, "Da Silva, Maisa Monseff Rodrigues" <Maisa_DaSilva at hsdm.harvard.edu> wrote:
>Hello.
>Thank you for helping me.
>I am starting my Bioinformatics pathway, and came across a problem im stuck with, even after trying different things:
>
>When in RStudio, I was able to install Git, but SVN remains "not found".
>I tried installing SVN through HomeBrew and downloaded Xcode's Command Lines from Apple Developer (as instructed on https://support.rstudio.com/hc/en-us/articles/200532077?version=2022.07.2%2B576&mode=desktop).
>After those steps, I restarted R and continue to see "not found" for SVN (git is working fine).
>When on mac terminal,
>
>"svn --version" prints
>
>svn, version 1.14.2 (r1899510)
>
>   compiled Oct  3 2022, 21:23:39 on x86_64-apple-darwin21.6.0
>
>
>"svn info" prints
>
>svn: E155007: '/Users/maisamonseff' is not a working copy
>
>Could you point out what it is I am doing wrong?
>
>
>Thank you in advance,
>
>Maisa Monseff Rodrigues da Silva
>MD - Endocrinologist - University S?o Paulo (Brazil)
>PhD Student University S?o Paulo (BR) / Harvard (USA)
>
>________________________________
>CONFIDENTIALITY NOTICE: This message and any attached do...{{dropped:11}}
>

-- 
Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Oct  4 19:32:55 2022
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Tue, 4 Oct 2022 18:32:55 +0100
Subject: [R] R version 4.2.1 (2022-06-23),
 RStudio 2022.07.2 "Spotted Wakerobin" Release (e7373ef8,
 2022-09-06) for macOS, macOS Monterey version 12.6. Error: SVN not found
In-Reply-To: <8A776EC5-00FF-4F1A-A7CA-909331FB0463@dcn.davis.ca.us>
References: <BYAPR07MB5447FD6F319350E1EDDAA2D5AA5A9@BYAPR07MB5447.namprd07.prod.outlook.com>
 <8A776EC5-00FF-4F1A-A7CA-909331FB0463@dcn.davis.ca.us>
Message-ID: <72780772-4b53-ee0c-d220-2c33d2bbdc18@sapo.pt>

Hello,

Post to R-SIG-Mac [1], the R help mailing list for Mac related questions?

[1] https://stat.ethz.ch/mailman/listinfo/r-sig-mac

Hope this helps,

Rui Barradas

?s 18:18 de 04/10/2022, Jeff Newmiller escreveu:
>> Could you point out what it is I am doing wrong?
> 
> ... wrong... posting questions about SVN and RStudio in a forum about R? Do read the Posting Guide before posting. There are specialty mailing lists mentioned there that _might_ be relevant, but it seems to me that you need to learn how to use SVN before you learn how to use it with RStudio, and neither of those tools are on their own relevant in any of the R mailing lists.
> 
> I don't use a Mac, but I believe you may encounter difficulties using it related to the fact that everything homebrew tools do has permissions restrictions related to homebrew so mixing in non-homebrew tools may not work.
> 
> Try perhaps StackOverflow or Reddit?
> 
> On October 4, 2022 8:58:20 AM PDT, "Da Silva, Maisa Monseff Rodrigues" <Maisa_DaSilva at hsdm.harvard.edu> wrote:
>> Hello.
>> Thank you for helping me.
>> I am starting my Bioinformatics pathway, and came across a problem im stuck with, even after trying different things:
>>
>> When in RStudio, I was able to install Git, but SVN remains "not found".
>> I tried installing SVN through HomeBrew and downloaded Xcode's Command Lines from Apple Developer (as instructed on https://support.rstudio.com/hc/en-us/articles/200532077?version=2022.07.2%2B576&mode=desktop).
>> After those steps, I restarted R and continue to see "not found" for SVN (git is working fine).
>> When on mac terminal,
>>
>> "svn --version" prints
>>
>> svn, version 1.14.2 (r1899510)
>>
>>    compiled Oct  3 2022, 21:23:39 on x86_64-apple-darwin21.6.0
>>
>>
>> "svn info" prints
>>
>> svn: E155007: '/Users/maisamonseff' is not a working copy
>>
>> Could you point out what it is I am doing wrong?
>>
>>
>> Thank you in advance,
>>
>> Maisa Monseff Rodrigues da Silva
>> MD - Endocrinologist - University S?o Paulo (Brazil)
>> PhD Student University S?o Paulo (BR) / Harvard (USA)
>>
>> ________________________________
>> CONFIDENTIALITY NOTICE: This message and any attached do...{{dropped:11}}
>>
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Oct  4 20:30:34 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 04 Oct 2022 11:30:34 -0700
Subject: [R] R version 4.2.1 (2022-06-23),
 RStudio 2022.07.2 "Spotted Wakerobin" Release (e7373ef8,
 2022-09-06) for macOS, macOS Monterey version 12.6. Error: SVN not found
In-Reply-To: <72780772-4b53-ee0c-d220-2c33d2bbdc18@sapo.pt>
References: <BYAPR07MB5447FD6F319350E1EDDAA2D5AA5A9@BYAPR07MB5447.namprd07.prod.outlook.com>
 <8A776EC5-00FF-4F1A-A7CA-909331FB0463@dcn.davis.ca.us>
 <72780772-4b53-ee0c-d220-2c33d2bbdc18@sapo.pt>
Message-ID: <49AC5E23-F7DE-408A-A164-C9579840255B@dcn.davis.ca.us>

Possibly, but the question is actually not about R, so probably not...

On October 4, 2022 10:32:55 AM PDT, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>Hello,
>
>Post to R-SIG-Mac [1], the R help mailing list for Mac related questions?
>
>[1] https://stat.ethz.ch/mailman/listinfo/r-sig-mac
>
>Hope this helps,
>
>Rui Barradas
>
>?s 18:18 de 04/10/2022, Jeff Newmiller escreveu:
>>> Could you point out what it is I am doing wrong?
>> 
>> ... wrong... posting questions about SVN and RStudio in a forum about R? Do read the Posting Guide before posting. There are specialty mailing lists mentioned there that _might_ be relevant, but it seems to me that you need to learn how to use SVN before you learn how to use it with RStudio, and neither of those tools are on their own relevant in any of the R mailing lists.
>> 
>> I don't use a Mac, but I believe you may encounter difficulties using it related to the fact that everything homebrew tools do has permissions restrictions related to homebrew so mixing in non-homebrew tools may not work.
>> 
>> Try perhaps StackOverflow or Reddit?
>> 
>> On October 4, 2022 8:58:20 AM PDT, "Da Silva, Maisa Monseff Rodrigues" <Maisa_DaSilva at hsdm.harvard.edu> wrote:
>>> Hello.
>>> Thank you for helping me.
>>> I am starting my Bioinformatics pathway, and came across a problem im stuck with, even after trying different things:
>>> 
>>> When in RStudio, I was able to install Git, but SVN remains "not found".
>>> I tried installing SVN through HomeBrew and downloaded Xcode's Command Lines from Apple Developer (as instructed on https://support.rstudio.com/hc/en-us/articles/200532077?version=2022.07.2%2B576&mode=desktop).
>>> After those steps, I restarted R and continue to see "not found" for SVN (git is working fine).
>>> When on mac terminal,
>>> 
>>> "svn --version" prints
>>> 
>>> svn, version 1.14.2 (r1899510)
>>> 
>>>    compiled Oct  3 2022, 21:23:39 on x86_64-apple-darwin21.6.0
>>> 
>>> 
>>> "svn info" prints
>>> 
>>> svn: E155007: '/Users/maisamonseff' is not a working copy
>>> 
>>> Could you point out what it is I am doing wrong?
>>> 
>>> 
>>> Thank you in advance,
>>> 
>>> Maisa Monseff Rodrigues da Silva
>>> MD - Endocrinologist - University S?o Paulo (Brazil)
>>> PhD Student University S?o Paulo (BR) / Harvard (USA)
>>> 
>>> ________________________________
>>> CONFIDENTIALITY NOTICE: This message and any attached do...{{dropped:11}}
>>> 
>> 

-- 
Sent from my phone. Please excuse my brevity.


From tder@mu@ @end|ng |rom p@rtner@@org  Wed Oct  5 01:35:09 2022
From: tder@mu@ @end|ng |rom p@rtner@@org (Deramus, Thomas Patrick)
Date: Tue, 4 Oct 2022 23:35:09 +0000
Subject: [R] Getting "Error in ect,
 plot.new has not been called yet" despite grouping plot call
Message-ID: <PH0PR04MB7493E39389D0196BEC260CB6BE5A9@PH0PR04MB7493.namprd04.prod.outlook.com>

Sorry to cross-post on Stackoverflow and here but I'm having some difficulty.
https://stackoverflow.com/questions/73942794/still-getting-error-in-ect-plot-new-has-not-been-called-yet-despite-grouping

Trying to make a nested loop that produces PDFs off different graphs, one for ACF/PACF diagnostics and another for the actual data, based on some time-series analyses I'm doing.

Unfortunately, I keep getting the dreaded: Error plot.new has not been called yet

The code is meant to write a PDF containing the ACF and PACF graphs, then do some analyses on the timeseries, and then make a separate PDF containing a plot describing the timeseries based on the p-values of each test for each individual.

library(plyr)
library(dplyr)
library(ggplot2)
library(Kendall)
library(lubridate)
library(xts)
library(TTR)
library(trend)
library(forecast)
library(openxlsx)

Game_Metrics_Word_Task <- read.xlsx("GamePack_Analytics_ALL_TIME_Short.xlsx", "Boggle")
Game_Metrics_Word_Task <- Game_Metrics_Word_Task %>% filter(grepl('1440', StudyId))
Game_Metrics_Word_Task$DeviceTime <- ymd_hms(Game_Metrics_Word_Task$DeviceTime,  tz = "America/New_York")
Game_Metrics_Word_Task <- Game_Metrics_Word_Task[!duplicated(Game_Metrics_Word_Task[1:2,])]

Participant_Word_Task <- split(arrange(Game_Metrics_Word_Task,StudyId,DeviceTime), arrange(Game_Metrics_Word_Task,StudyId,DeviceTime,StudyId,DeviceTime)$StudyId)

WordFrame <- data.frame(Participant = c(0), Task = c(0), MannKendall_Tau = c(0), MannKendall_P = c(0), Sen_Slope_Value = c(0), Sen_Slope_Pval = c(0), Pettitts_CIV = c(0), Pettitts_Pval = c(0), ARIMA_Model = c(0), Time_to_Petit = c(0), Number_of_Trials_to_Pettitt = c(0), Playtime_to_Petit_seconds = c(0), Time_Start_to_end_days = c(0), Number_of_Total_Trials = c(0), Total_Playtime_seconds = c(0), Learning_rate_days = c(0), Learning_rate_seconds = c(0), Learned_Task = c(0))

for (i in 1:length(Participant_Word_Task)){
    success_series <- xts(filter(Participant_Word_Task[[i]], GameEndReason == "TIMER_UP")$NumberOfSuccesfulWords , order.by=as.POSIXct(filter(Participant_Word_Task[[i]], GameEndReason == "TIMER_UP")$DeviceTime))
    original_series <- xts(Participant_Word_Task[[i]]$NumberOfSuccesfulWords, order.by=as.POSIXct(Participant_Word_Task[[i]]$DeviceTime))
    success_decomp <- ts(success_series, frequency = nweeks(success_series))
    original_decomp <- ts(original_series, frequency = nweeks(success_series))

    pdf(paste("Word_Task_Autocorrelation_plots_for_subject_",unique(Participant_Word_Task[[i]]$StudyId),".pdf" ,collapse = NULL, sep = ""))
    par(mfrow=c(1,2))
    Autocorrelationplot <- acf(success_decomp, main=paste(""))
    PartialAutocorrelationplot <- pacf(success_decomp, main=paste(""))
    mtext(paste("Word Task Auto and Partialauto correlations for subject ",unique(Participant_Word_Task[[i]]$StudyId)), side = 3, line = -3, outer = TRUE)
    dev.off()

    AutomatedArimaoutputs <- auto.arima(success_decomp)
    p <- length(AutomatedArimaoutputs$model$phi)
    #AR component
    q <- length(AutomatedArimaoutputs$model$theta)
    #MA component
    d <- AutomatedArimaoutputs$model$Delta
    #order of difference
    WordFrame[i,1] <- unique(Participant_Word_Task[[i]]$StudyId)
    WordFrame[i,2] <- "Word"
    WordFrame[i,3] <- MannKendall(success_decomp)$tau[1]
    WordFrame[i,4] <- MannKendall(success_decomp)$sl[1]
    WordFrame[i,5] <- sens.slope(success_decomp)$estimates
    WordFrame[i,6] <- sens.slope(success_decomp)$p.value
    WordFrame[i,7] <- pettitt.test(success_decomp)$estimate
    WordFrame[i,8] <- pettitt.test(success_decomp)$p.value
    WordFrame[i,9] <- paste("ARIMA(",p,",",q,",",d,")", collapse = NULL, sep = "")
    WordFrame[i,10] <- difftime(time(success_series[WordFrame[i,7]]),time(original_series[1]))
    WordFrame[i,11] <- tail(which(grepl(success_series[WordFrame[i,7]], original_series)), n=1)
    WordFrame[i,12] <- sum(Participant_Word_Task[[i]]$TotalDuration[1:WordFrame[i,11]])-sum(Participant_Word_Task[[i]]$TotalTimePaused[1:WordFrame[i,11]])
    WordFrame[i,13] <- difftime(time(original_series[length(original_series)]),time(original_series[1]))
    WordFrame[i,14] <- length(original_series)
    WordFrame[i,15] <- sum(Participant_Word_Task[[i]]$TotalDuration[1:length(original_series)])-sum(Participant_Word_Task[[i]]$TotalTimePaused[1:length(original_series)])


    simplemovingaverage <- SMA(original_series, n = nweeks(original_series))

    if (WordFrame[i,4] <= 0.05 & WordFrame[i,6] <= 0.05 & WordFrame[i,8] <= 0.05){
              {
              pdf(paste(WordFrame[i,1],"_Word_Task_Acquisition.pdf",collapse = NULL, sep = ""))
              plout <- plot(original_series,type='l',col='blue',xlab="Date of Play",ylab="Number of Successful Words")
              lines(simplemovingaverage,type='l',col='red')
              title(paste("Word Task Acquisition for Subject", WordFrame[i,1]))
              abline(v = index(original_series[WordFrame[i,7]]),lty=2, col='green', lwd=3)
              dev.off()
              }
              WordFrame[i,18] <- T
              WordFrame[i,16] <- (1-(WordFrame[i,10]/WordFrame[i,13]))
              WordFrame[i,17] <- (1-(WordFrame[i,12]/WordFrame[i,15]))
    } else {
              {
              pdf(paste(WordFrame[i,1],"_Word_Task_Acquisition.pdf",collapse = NULL, sep = ""))
              plout <- plot(original_series,type='l',col='blue',xlab="Date of Play",ylab="Number of Successful Words")
              lines(simplemovingaverage,type='l',col='red')
              title(paste("Word Task Acquisition for Subject", WordFrame[i,1]))
              dev.off()
              }
              WordFrame[i,18] <- F
              WordFrame[i,16] <- 0
              WordFrame[i,17] <- 0
    }
}

It will work just fine if I run the lines individually (e.g. set i = 1, 2, ect), and if I comment out abline and title (lines seems to work fine). But it will throw the error everytime I try to run the loop without these commented.

Have tried just about everything I could find on the Stack forums to run everything as a single argument and I'm just not sure what is wrong with it.

dev.list() spits out:

pdf
  2
following the error.

With abline and title commented out and lines run individually it's NULL.

Happens in both RStudio

2022.07.2+576 "Spotted Wakerobin" Release (e7373ef832b49b2a9b88162cfe7eac5f22c40b34, 2022-09-06) for Ubuntu Bionic
Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) QtWebEngine/5.12.8 Chrome/69.0.3497.128 Safari/537.36

And R:

platform       x86_64-pc-linux-gnu
arch           x86_64
os             linux-gnu
system         x86_64, linux-gnu
status
major          4
minor          2.1
year           2022
month          06
day            23
svn rev        82513
language       R
version.string R version 4.2.1 (2022-06-23)
nickname       Funny-Looking Kid


My OS:
PRETTY_NAME="Debian GNU/Linux 11 (bullseye)"
NAME="Debian GNU/Linux"
VERSION_ID="11"
VERSION="11 (bullseye)"
VERSION_CODENAME=bullseye
ID=debian
HOME_URL="https://www.debian.org/"
SUPPORT_URL="https://www.debian.org/support"
BUG_REPORT_URL="https://bugs.debian.org/"
No LSB modules are available.
Distributor ID:???Debian
Description:??????Debian GNU/Linux 11 (bullseye)
Release:????11
Codename:???bullseye
         Icon name: computer-desktop
           Chassis: desktop
        Machine ID: 053ebf23707f49c8ad4e0684f4cf19d3
           Boot ID: d0e6294d3b944286bef10e76c21e6401
  Operating System: Debian GNU/Linux 11 (bullseye)
            Kernel: Linux 5.10.0-18-amd64
      Architecture: x86-64


Any suggestions would be greatly appreciated.

--

Thomas DeRamus (He/Him/His)

Data Analyst

Massachusetts General Hospital Brigham

Alzheimer?s Clinical & Translational Research Unit

149 13th Street

Charlestown, MA 02129

Phone: 205-834-5066

Email: tderamus at partners.org<mailto:tderamus at partners.org>, tpderamus at gmail.com<mailto:tpderamus at gmail.com>


[https://ci3.googleusercontent.com/mail-sig/AIorK4we2sU30P2HyfDQF5hpEjYTt-9FTBK7cAVsP7EenrZ0nsKCf48fuYMtElj6Szn_2fpSPWr66eQ][https://ci3.googleusercontent.com/mail-sig/AIorK4yyY0DlImU0UONJrHTbPc5T3lJj8Kmu8SbDKJJ3XjcX6CgvVsvSueYKwficYFz4zXt6fZV8YIY]

?If knowledge can create problems, it is not through ignorance that we can solve them.?

?Issac Asimov
The information in this e-mail is intended only for the person to whom it is addressed.  If you believe this e-mail was sent to you in error and the e-mail contains patient information, please contact the Mass General Brigham Compliance HelpLine at https://www.massgeneralbrigham.org/complianceline <https://www.massgeneralbrigham.org/complianceline> .
Please note that this e-mail is not secure (encrypted).  If you do not wish to continue communication over unencrypted e-mail, please notify the sender of this message immediately.  Continuing to send or respond to e-mail after receiving this message means you understand and accept this risk and wish to continue to communicate over unencrypted e-mail. 

From r@turner @end|ng |rom @uck|@nd@@c@nz  Wed Oct  5 12:06:08 2022
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Wed, 5 Oct 2022 23:06:08 +1300
Subject: [R] Getting "Error in ect,
 plot.new has not been called yet" despite grouping plot call
In-Reply-To: <PH0PR04MB7493E39389D0196BEC260CB6BE5A9@PH0PR04MB7493.namprd04.prod.outlook.com>
References: <PH0PR04MB7493E39389D0196BEC260CB6BE5A9@PH0PR04MB7493.namprd04.prod.outlook.com>
Message-ID: <20221005230608.793c8b9f@rolf-Latitude-E7470>


What you doing or trying to do is far too complex for my poor feeble
and senile brain to come anywhere near comprehending.  The code that
you present exceeds my complexity tolerance by many orders of magnitude.

I have a suggestion, but.  Strip your code down to the *essentials*.
Construct a simple sequence of plotting commands, with *simple* names
for the pdf files involved.  You should require only two or three such
files and two or three index levels associated with each of your
nested loops.

Run the stripped down code and the source of the problem will almost
surely become clear.

cheers,

Rolf Turner

On Tue, 4 Oct 2022 23:35:09 +0000
"Deramus, Thomas Patrick" <tderamus at partners.org> wrote:

> Sorry to cross-post on Stackoverflow and here but I'm having some
> difficulty.
> https://stackoverflow.com/questions/73942794/still-getting-error-in-ect-plot-new-has-not-been-called-yet-despite-grouping
> 
> Trying to make a nested loop that produces PDFs off different graphs,
> one for ACF/PACF diagnostics and another for the actual data, based
> on some time-series analyses I'm doing.
> 
> Unfortunately, I keep getting the dreaded: Error plot.new has not
> been called yet
> 
> The code is meant to write a PDF containing the ACF and PACF graphs,
> then do some analyses on the timeseries, and then make a separate PDF
> containing a plot describing the timeseries based on the p-values of
> each test for each individual.
> 
> library(plyr)
> library(dplyr)
> library(ggplot2)
> library(Kendall)
> library(lubridate)
> library(xts)
> library(TTR)
> library(trend)
> library(forecast)
> library(openxlsx)
> 
> Game_Metrics_Word_Task <-
> read.xlsx("GamePack_Analytics_ALL_TIME_Short.xlsx", "Boggle")
> Game_Metrics_Word_Task <- Game_Metrics_Word_Task %>%
> filter(grepl('1440', StudyId)) Game_Metrics_Word_Task$DeviceTime <-
> ymd_hms(Game_Metrics_Word_Task$DeviceTime,  tz = "America/New_York")
> Game_Metrics_Word_Task <-
> Game_Metrics_Word_Task[!duplicated(Game_Metrics_Word_Task[1:2,])]
> 
> Participant_Word_Task <-
> split(arrange(Game_Metrics_Word_Task,StudyId,DeviceTime),
> arrange(Game_Metrics_Word_Task,StudyId,DeviceTime,StudyId,DeviceTime)$StudyId)
> 
> WordFrame <- data.frame(Participant = c(0), Task = c(0),
> MannKendall_Tau = c(0), MannKendall_P = c(0), Sen_Slope_Value = c(0),
> Sen_Slope_Pval = c(0), Pettitts_CIV = c(0), Pettitts_Pval = c(0),
> ARIMA_Model = c(0), Time_to_Petit = c(0), Number_of_Trials_to_Pettitt
> = c(0), Playtime_to_Petit_seconds = c(0), Time_Start_to_end_days =
> c(0), Number_of_Total_Trials = c(0), Total_Playtime_seconds = c(0),
> Learning_rate_days = c(0), Learning_rate_seconds = c(0), Learned_Task
> = c(0))
> 
> for (i in 1:length(Participant_Word_Task)){
>     success_series <- xts(filter(Participant_Word_Task[[i]],
> GameEndReason == "TIMER_UP")$NumberOfSuccesfulWords ,
> order.by=as.POSIXct(filter(Participant_Word_Task[[i]], GameEndReason
> == "TIMER_UP")$DeviceTime)) original_series <-
> xts(Participant_Word_Task[[i]]$NumberOfSuccesfulWords,
> order.by=as.POSIXct(Participant_Word_Task[[i]]$DeviceTime))
> success_decomp <- ts(success_series, frequency =
> nweeks(success_series)) original_decomp <- ts(original_series,
> frequency = nweeks(success_series))
> 
>     pdf(paste("Word_Task_Autocorrelation_plots_for_subject_",unique(Participant_Word_Task[[i]]$StudyId),".pdf"
> ,collapse = NULL, sep = "")) par(mfrow=c(1,2))
>     Autocorrelationplot <- acf(success_decomp, main=paste(""))
>     PartialAutocorrelationplot <- pacf(success_decomp, main=paste(""))
>     mtext(paste("Word Task Auto and Partialauto correlations for
> subject ",unique(Participant_Word_Task[[i]]$StudyId)), side = 3, line
> = -3, outer = TRUE) dev.off()
> 
>     AutomatedArimaoutputs <- auto.arima(success_decomp)
>     p <- length(AutomatedArimaoutputs$model$phi)
>     #AR component
>     q <- length(AutomatedArimaoutputs$model$theta)
>     #MA component
>     d <- AutomatedArimaoutputs$model$Delta
>     #order of difference
>     WordFrame[i,1] <- unique(Participant_Word_Task[[i]]$StudyId)
>     WordFrame[i,2] <- "Word"
>     WordFrame[i,3] <- MannKendall(success_decomp)$tau[1]
>     WordFrame[i,4] <- MannKendall(success_decomp)$sl[1]
>     WordFrame[i,5] <- sens.slope(success_decomp)$estimates
>     WordFrame[i,6] <- sens.slope(success_decomp)$p.value
>     WordFrame[i,7] <- pettitt.test(success_decomp)$estimate
>     WordFrame[i,8] <- pettitt.test(success_decomp)$p.value
>     WordFrame[i,9] <- paste("ARIMA(",p,",",q,",",d,")", collapse =
> NULL, sep = "") WordFrame[i,10] <-
> difftime(time(success_series[WordFrame[i,7]]),time(original_series[1]))
> WordFrame[i,11] <- tail(which(grepl(success_series[WordFrame[i,7]],
> original_series)), n=1) WordFrame[i,12] <-
> sum(Participant_Word_Task[[i]]$TotalDuration[1:WordFrame[i,11]])-sum(Participant_Word_Task[[i]]$TotalTimePaused[1:WordFrame[i,11]])
> WordFrame[i,13] <-
> difftime(time(original_series[length(original_series)]),time(original_series[1]))
> WordFrame[i,14] <- length(original_series) WordFrame[i,15] <-
> sum(Participant_Word_Task[[i]]$TotalDuration[1:length(original_series)])-sum(Participant_Word_Task[[i]]$TotalTimePaused[1:length(original_series)])
> 
> 
>     simplemovingaverage <- SMA(original_series, n =
> nweeks(original_series))
> 
>     if (WordFrame[i,4] <= 0.05 & WordFrame[i,6] <= 0.05 &
> WordFrame[i,8] <= 0.05){ {
>               pdf(paste(WordFrame[i,1],"_Word_Task_Acquisition.pdf",collapse
> = NULL, sep = "")) plout <-
> plot(original_series,type='l',col='blue',xlab="Date of
> Play",ylab="Number of Successful Words")
> lines(simplemovingaverage,type='l',col='red') title(paste("Word Task
> Acquisition for Subject", WordFrame[i,1])) abline(v =
> index(original_series[WordFrame[i,7]]),lty=2, col='green', lwd=3)
> dev.off() } WordFrame[i,18] <- T
>               WordFrame[i,16] <- (1-(WordFrame[i,10]/WordFrame[i,13]))
>               WordFrame[i,17] <- (1-(WordFrame[i,12]/WordFrame[i,15]))
>     } else {
>               {
>               pdf(paste(WordFrame[i,1],"_Word_Task_Acquisition.pdf",collapse
> = NULL, sep = "")) plout <-
> plot(original_series,type='l',col='blue',xlab="Date of
> Play",ylab="Number of Successful Words")
> lines(simplemovingaverage,type='l',col='red') title(paste("Word Task
> Acquisition for Subject", WordFrame[i,1])) dev.off() }
>               WordFrame[i,18] <- F
>               WordFrame[i,16] <- 0
>               WordFrame[i,17] <- 0
>     }
> }
> 
> It will work just fine if I run the lines individually (e.g. set i =
> 1, 2, ect), and if I comment out abline and title (lines seems to
> work fine). But it will throw the error everytime I try to run the
> loop without these commented.
> 
> Have tried just about everything I could find on the Stack forums to
> run everything as a single argument and I'm just not sure what is
> wrong with it.
> 
> dev.list() spits out:
> 
> pdf
>   2
> following the error.
> 
> With abline and title commented out and lines run individually it's
> NULL.
> 
> Happens in both RStudio
> 
> 2022.07.2+576 "Spotted Wakerobin" Release
> (e7373ef832b49b2a9b88162cfe7eac5f22c40b34, 2022-09-06) for Ubuntu
> Bionic Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML,
> like Gecko) QtWebEngine/5.12.8 Chrome/69.0.3497.128 Safari/537.36
> 
> And R:
> 
> platform       x86_64-pc-linux-gnu
> arch           x86_64
> os             linux-gnu
> system         x86_64, linux-gnu
> status
> major          4
> minor          2.1
> year           2022
> month          06
> day            23
> svn rev        82513
> language       R
> version.string R version 4.2.1 (2022-06-23)
> nickname       Funny-Looking Kid
> 
> 
> My OS:
> PRETTY_NAME="Debian GNU/Linux 11 (bullseye)"
> NAME="Debian GNU/Linux"
> VERSION_ID="11"
> VERSION="11 (bullseye)"
> VERSION_CODENAME=bullseye
> ID=debian
> HOME_URL="https://www.debian.org"
> SUPPORT_URL="https://www.debian.org/support"
> BUG_REPORT_URL="https://bugs.debian.org"
> No LSB modules are available.
> Distributor ID:???Debian
> Description:??????Debian GNU/Linux 11 (bullseye)
> Release:????11
> Codename:???bullseye
>          Icon name: computer-desktop
>            Chassis: desktop
>         Machine ID: 053ebf23707f49c8ad4e0684f4cf19d3
>            Boot ID: d0e6294d3b944286bef10e76c21e6401
>   Operating System: Debian GNU/Linux 11 (bullseye)
>             Kernel: Linux 5.10.0-18-amd64
>       Architecture: x86-64
> 
> 
> Any suggestions would be greatly appreciated.
> 
> --
> 
> Thomas DeRamus (He/Him/His)
> 
> Data Analyst
> 
> Massachusetts General Hospital Brigham
> 
> Alzheimer?s Clinical & Translational Research Unit
> 
> 149 13th Street
> 
> Charlestown, MA 02129
> 
> Phone: 205-834-5066
> 
> Email: tderamus at partners.org<mailto:tderamus at partners.org>,
> tpderamus at gmail.com<mailto:tpderamus at gmail.com>
> 
> 
> [https://ci3.googleusercontent.com/mail-sig/AIorK4we2sU30P2HyfDQF5hpEjYTt-9FTBK7cAVsP7EenrZ0nsKCf48fuYMtElj6Szn_2fpSPWr66eQ][https://ci3.googleusercontent.com/mail-sig/AIorK4yyY0DlImU0UONJrHTbPc5T3lJj8Kmu8SbDKJJ3XjcX6CgvVsvSueYKwficYFz4zXt6fZV8YIY]
> 
> ?If knowledge can create problems, it is not through ignorance that
> we can solve them.?
> 
> ?Issac Asimov


From petr@p|k@| @end|ng |rom prechez@@cz  Wed Oct  5 12:34:02 2022
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Wed, 5 Oct 2022 10:34:02 +0000
Subject: [R] 
 R version 4.2.1 install.packages does not work with IE proxy setting
In-Reply-To: <20221004184256.7ce13c60@arachnoid>
References: <344ae947626245a392ebba421f73e483@SRVEXCHCM1302.precheza.cz>
 <20221004184256.7ce13c60@arachnoid>
Message-ID: <9b38aacf51d746bb87a9cc3765a16b99@SRVEXCHCM1302.precheza.cz>

Thanks, 

the workaround works but we need try the "permanent" solution with
Renviron.site file in future.

Cheers
Petr

> -----Original Message-----
> From: Ivan Krylov <krylov.r00t at gmail.com>
> Sent: Tuesday, October 4, 2022 5:43 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] R version 4.2.1 install.packages does not work with IE
proxy
> setting
> 
> On Tue, 4 Oct 2022 11:01:14 +0000
> PIKAL Petr <petr.pikal at precheza.cz> wrote:
> 
> > After we installed new R version R 4.2.1 installing packages through
> > IE proxy setting is compromised with warning that R could not connect
> > to server (tested in vanilla R).
> 
> R 4.1 deprecated the use of download.file(method = 'wininet'). R 4.2
switched
> the default download method to 'libcurl' and started giving warnings for
> 'wininet' and http[s]:// URLs.
> 
> A workaround to get it working right now would be to set
> options(download.file.method = 'wininet') and live with the resulting
warnings
> while R downloads the files, but a next version of R may remove 'wininet'
> support altogether.
> 
> In order to get it working with the 'libcurl' method, you'll need to
provide some
> environment variables to curl:
> https://stat.ethz.ch/pipermail/r-help/2022-September/475917.html
> 
> Not sure if libcurl would accept a patch to discover the Windows proxy
settings
> automatically, but I don't think it does that now.
> 
> --
> Best regards,
> Ivan

From r@turner @end|ng |rom @uck|@nd@@c@nz  Thu Oct  6 00:28:02 2022
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 6 Oct 2022 11:28:02 +1300
Subject: [R] Getting "Error in ect,
 plot.new has not been called yet" despite grouping plot call
In-Reply-To: <PH0PR04MB7493CE9332F02B56C0AFE31FBE5D9@PH0PR04MB7493.namprd04.prod.outlook.com>
References: <PH0PR04MB7493E39389D0196BEC260CB6BE5A9@PH0PR04MB7493.namprd04.prod.outlook.com>
 <20221005230608.793c8b9f@rolf-Latitude-E7470>
 <PH0PR04MB7493CE9332F02B56C0AFE31FBE5D9@PH0PR04MB7493.namprd04.prod.outlook.com>
Message-ID: <20221006112802.6897cd27@rolf-Latitude-E7470>



Your code is still much too complex for my feeble brain.

Without trying to understand very much, I get the impression that the
example is *not* reproducible.  It requires reading in Excel (yeucchh!)
files to which no-one but you has access.

Skip the reading-in completely.  Create toy data using rnorm() instead.
Then someone may be able to help you.

On Wed, 5 Oct 2022 13:32:00 +0000
"Deramus, Thomas Patrick" <tderamus at partners.org> wrote:

> Hi Rolf.
> 
> I followed your suggestion (though it's probably not as trimmed as it
> could be), but the problem unfortunately persists.

If the problem *didn't* persist, then *that* would have been
unfortunate!  The idea is to reproduce the problem in a simpler context
so that one can deduce what is causing the problem!

> Does this make it any clearer or still too many moving parts to make
> sense of?

There are still (far) too many moving parts, for me anyway.  Someone
cleverer than I might be able to see what the problem is.

cheers,

Rolf

> 
> rm(list = ls(all.names = TRUE)) #will clear all objects includes
> hidden objects.
> 
> #Loads the packages
> library(plyr)
> library(dplyr)
> library(ggplot2)
> library(Kendall)
> library(lubridate)
> library(xts)
> library(TTR)
> library(trend)
> library(forecast)
> library(openxlsx)
> 
> #Uses the learningCurve Package from Github:
> #https://github.com/AFIT-R/learningCurve
> library(learningCurve)
> 
> #Only load this if using VS Studio because it changes the plot
> function
> #https://stackoverflow.com/questions/52284345/how-to-show-r-graph-from-visual-studio-code
> library(httpgd) library(languageserver)
> 
> #Loads the Excel files to Dataframes and cleans the data
> Game_Metrics_Word_Task <-
> read.xlsx("GamePack_Analytics_ALL_TIME_Short.xlsx", "Boggle")
> Game_Metrics_Word_Task <- Game_Metrics_Word_Task %>%
> filter(grepl('1440', StudyId)) Game_Metrics_Word_Task$DeviceTime <-
> ymd_hms(Game_Metrics_Word_Task$DeviceTime,  tz = "America/New_York")
> Game_Metrics_Word_Task <-
> Game_Metrics_Word_Task[!duplicated(Game_Metrics_Word_Task[1:2,])]
> 
> #Splits the dataframe into a tibble containing each participant
> Participant_Word_Task <-
> split(arrange(Game_Metrics_Word_Task,StudyId,DeviceTime),
> arrange(Game_Metrics_Word_Task,StudyId,DeviceTime,StudyId,DeviceTime)$StudyId)
> 
> #Generates a blank output dataframe
> WordFrame <- data.frame(Participant = c(0), Task = c(0),
> MannKendall_Tau = c(0), MannKendall_P = c(0), Sen_Slope_Value = c(0),
> Sen_Slope_Pval = c(0), Pettitts_CIV = c(0), Pettitts_Pval = c(0),
> ARIMA_Model = c(0), Time_to_Petit = c(0), Number_of_Trials_to_Pettitt
> = c(0), Playtime_to_Petit_seconds = c(0), Time_Start_to_end_days =
> c(0), Number_of_Total_Trials = c(0), Total_Playtime_seconds = c(0),
> Learning_rate_days = c(0), Learning_rate_seconds = c(0), Learned_Task
> = c(0))
> 
> #The number of subjects in the xlsx file
> #Reduced to 2 for ease of use
> for (i in 1:2){
>   #This timeseries only includes the trials where the participant
> completed the task success_series <-
> xts(filter(Participant_Word_Task[[i]], GameEndReason ==
> "TIMER_UP")$NumberOfSuccesfulWords ,
> order.by=as.POSIXct(filter(Participant_Word_Task[[i]], GameEndReason
> == "TIMER_UP")$DeviceTime)) #This timeseries includes ALL the trials
> for the sake of plotting original_series <-
> xts(Participant_Word_Task[[i]]$NumberOfSuccesfulWords,
> order.by=as.POSIXct(Participant_Word_Task[[i]]$DeviceTime))
> 
>   #This is a decomposing process that xts seems to need for plotting.
>   #nweeks is needed for xts to plot the x-axis
>   success_decomp <- ts(success_series, frequency =
> nweeks(success_series)) original_decomp <- ts(original_series,
> frequency = nweeks(success_series))
> 
>   #Values which will be included in the plots
>   WordFrame[i,1] <- unique(Participant_Word_Task[[i]]$StudyId)
>   WordFrame[i,5] <- sens.slope(success_decomp)$estimates
>   WordFrame[i,6] <- sens.slope(success_decomp)$p.value
>   WordFrame[i,7] <- pettitt.test(success_decomp)$estimate
>   WordFrame[i,8] <- pettitt.test(success_decomp)$p.value
> 
>   #The simple moving average that will be overlayed with the plotted
> data simplemovingaverage <- SMA(original_series, n =
> nweeks(original_series))
> 
>   #If the three tests are statistically significant, add a green
> horizontal like to value WordFrame[i,7] #Which would be where the
> slope changes in the series #Fluid variables have been removed from
> all pdf() and paste() functions for ease-of-use if (WordFrame[i,4] <=
> 0.05 & WordFrame[i,6] <= 0.05 & WordFrame[i,8] <= 0.05){ {
>       pdf(file = "Word_Task_Acquisition.pdf")
>       plout <- plot(original_series)
>       lines(simplemovingaverage)
>       abline(v = index(original_series[WordFrame[i,7]]),lty=2,
> col='green', lwd=3) title(paste("Word Task Acquisition for Subject"))
>       dev.off()
>      }
>   #If the three tests are NOT statistically significant, generate a
> plot with NO horizontal line at WordFrame[i,7] } else {
>     {
>       pdf(file = "Word_Task_Acquisition.pdf")
>       plout <- plot(original_series)
>       lines(simplemovingaverage)
>       title(paste("Word Task Acquisition for Subject"))
>       dev.off()
>     }
>   }
> }
> 
> ________________________________
> From: Rolf Turner <r.turner at auckland.ac.nz>
> Sent: Wednesday, October 5, 2022 6:06 AM
> To: Deramus, Thomas Patrick <tderamus at partners.org>
> Cc: r-help at r-project.org <r-help at r-project.org>
> Subject: Re: [R] Getting "Error in ect, plot.new has not been called
> yet" despite grouping plot call
> 
>         External Email - Use Caution
> 
> What you doing or trying to do is far too complex for my poor feeble
> and senile brain to come anywhere near comprehending.  The code that
> you present exceeds my complexity tolerance by many orders of
> magnitude.
> 
> I have a suggestion, but.  Strip your code down to the *essentials*.
> Construct a simple sequence of plotting commands, with *simple* names
> for the pdf files involved.  You should require only two or three such
> files and two or three index levels associated with each of your
> nested loops.
> 
> Run the stripped down code and the source of the problem will almost
> surely become clear.
> 
> cheers,
> 
> Rolf Turner
> 
> On Tue, 4 Oct 2022 23:35:09 +0000
> "Deramus, Thomas Patrick" <tderamus at partners.org> wrote:
> 
> > Sorry to cross-post on Stackoverflow and here but I'm having some
> > difficulty.
> > https://secure-web.cisco.com/1_juqv4RvefQFJofsnOQcQA3Ixge89s4uC26pjoPBaYOSxSLGisKtgUTZkanxeHNRqNmjl30B8wYKfsppHje4T8Su77i7t8UbMKzs3GBKEyQva4yTjPH76Q9-l6tT24bB4qNMPQeFAxrkG5lpozNpGrDIAjfKCMvgS-5Qjs-QmvhWZfo84_3SK9rHhJjJvO9CqXb0MewWwI-dEmkZemjxnliGe_D9nooo7Ebjuw0dpBuMnrdaTzQxDdivsbkujPnrGurdjLARh93RW5IWPszNwaoziRD7P-30McF1PrAP8_yjWrhxQ_S3AgG6k40EoQJU/https%3A%2F%2Fstackoverflow.com%2Fquestions%2F73942794%2Fstill-getting-error-in-ect-plot-new-has-not-been-called-yet-despite-grouping
> >
> > Trying to make a nested loop that produces PDFs off different
> > graphs, one for ACF/PACF diagnostics and another for the actual
> > data, based on some time-series analyses I'm doing.
> >
> > Unfortunately, I keep getting the dreaded: Error plot.new has not
> > been called yet
> >
> > The code is meant to write a PDF containing the ACF and PACF graphs,
> > then do some analyses on the timeseries, and then make a separate
> > PDF containing a plot describing the timeseries based on the
> > p-values of each test for each individual.
> >
> > library(plyr)
> > library(dplyr)
> > library(ggplot2)
> > library(Kendall)
> > library(lubridate)
> > library(xts)
> > library(TTR)
> > library(trend)
> > library(forecast)
> > library(openxlsx)
> >
> > Game_Metrics_Word_Task <-
> > read.xlsx("GamePack_Analytics_ALL_TIME_Short.xlsx", "Boggle")
> > Game_Metrics_Word_Task <- Game_Metrics_Word_Task %>%
> > filter(grepl('1440', StudyId)) Game_Metrics_Word_Task$DeviceTime <-
> > ymd_hms(Game_Metrics_Word_Task$DeviceTime,  tz = "America/New_York")
> > Game_Metrics_Word_Task <-
> > Game_Metrics_Word_Task[!duplicated(Game_Metrics_Word_Task[1:2,])]
> >
> > Participant_Word_Task <-
> > split(arrange(Game_Metrics_Word_Task,StudyId,DeviceTime),
> > arrange(Game_Metrics_Word_Task,StudyId,DeviceTime,StudyId,DeviceTime)$StudyId)
> >
> > WordFrame <- data.frame(Participant = c(0), Task = c(0),
> > MannKendall_Tau = c(0), MannKendall_P = c(0), Sen_Slope_Value =
> > c(0), Sen_Slope_Pval = c(0), Pettitts_CIV = c(0), Pettitts_Pval =
> > c(0), ARIMA_Model = c(0), Time_to_Petit = c(0),
> > Number_of_Trials_to_Pettitt = c(0), Playtime_to_Petit_seconds =
> > c(0), Time_Start_to_end_days = c(0), Number_of_Total_Trials = c(0),
> > Total_Playtime_seconds = c(0), Learning_rate_days = c(0),
> > Learning_rate_seconds = c(0), Learned_Task = c(0))
> >
> > for (i in 1:length(Participant_Word_Task)){
> >     success_series <- xts(filter(Participant_Word_Task[[i]],
> > GameEndReason == "TIMER_UP")$NumberOfSuccesfulWords ,
> > order.by=as.POSIXct(filter(Participant_Word_Task[[i]], GameEndReason
> > == "TIMER_UP")$DeviceTime)) original_series <-
> > xts(Participant_Word_Task[[i]]$NumberOfSuccesfulWords,
> > order.by=as.POSIXct(Participant_Word_Task[[i]]$DeviceTime))
> > success_decomp <- ts(success_series, frequency =
> > nweeks(success_series)) original_decomp <- ts(original_series,
> > frequency = nweeks(success_series))
> >
> >     pdf(paste("Word_Task_Autocorrelation_plots_for_subject_",unique(Participant_Word_Task[[i]]$StudyId),".pdf"
> > ,collapse = NULL, sep = "")) par(mfrow=c(1,2))
> >     Autocorrelationplot <- acf(success_decomp, main=paste(""))
> >     PartialAutocorrelationplot <- pacf(success_decomp,
> > main=paste("")) mtext(paste("Word Task Auto and Partialauto
> > correlations for subject
> > ",unique(Participant_Word_Task[[i]]$StudyId)), side = 3, line = -3,
> > outer = TRUE) dev.off()
> >
> >     AutomatedArimaoutputs <- auto.arima(success_decomp)
> >     p <- length(AutomatedArimaoutputs$model$phi)
> >     #AR component
> >     q <- length(AutomatedArimaoutputs$model$theta)
> >     #MA component
> >     d <- AutomatedArimaoutputs$model$Delta
> >     #order of difference
> >     WordFrame[i,1] <- unique(Participant_Word_Task[[i]]$StudyId)
> >     WordFrame[i,2] <- "Word"
> >     WordFrame[i,3] <- MannKendall(success_decomp)$tau[1]
> >     WordFrame[i,4] <- MannKendall(success_decomp)$sl[1]
> >     WordFrame[i,5] <- sens.slope(success_decomp)$estimates
> >     WordFrame[i,6] <- sens.slope(success_decomp)$p.value
> >     WordFrame[i,7] <- pettitt.test(success_decomp)$estimate
> >     WordFrame[i,8] <- pettitt.test(success_decomp)$p.value
> >     WordFrame[i,9] <- paste("ARIMA(",p,",",q,",",d,")", collapse =
> > NULL, sep = "") WordFrame[i,10] <-
> > difftime(time(success_series[WordFrame[i,7]]),time(original_series[1]))
> > WordFrame[i,11] <- tail(which(grepl(success_series[WordFrame[i,7]],
> > original_series)), n=1) WordFrame[i,12] <-
> > sum(Participant_Word_Task[[i]]$TotalDuration[1:WordFrame[i,11]])-sum(Participant_Word_Task[[i]]$TotalTimePaused[1:WordFrame[i,11]])
> > WordFrame[i,13] <-
> > difftime(time(original_series[length(original_series)]),time(original_series[1]))
> > WordFrame[i,14] <- length(original_series) WordFrame[i,15] <-
> > sum(Participant_Word_Task[[i]]$TotalDuration[1:length(original_series)])-sum(Participant_Word_Task[[i]]$TotalTimePaused[1:length(original_series)])
> >
> >
> >     simplemovingaverage <- SMA(original_series, n =
> > nweeks(original_series))
> >
> >     if (WordFrame[i,4] <= 0.05 & WordFrame[i,6] <= 0.05 &
> > WordFrame[i,8] <= 0.05){ {
> >               pdf(paste(WordFrame[i,1],"_Word_Task_Acquisition.pdf",collapse
> > = NULL, sep = "")) plout <-
> > plot(original_series,type='l',col='blue',xlab="Date of
> > Play",ylab="Number of Successful Words")
> > lines(simplemovingaverage,type='l',col='red') title(paste("Word Task
> > Acquisition for Subject", WordFrame[i,1])) abline(v =
> > index(original_series[WordFrame[i,7]]),lty=2, col='green', lwd=3)
> > dev.off() } WordFrame[i,18] <- T
> >               WordFrame[i,16] <-
> > (1-(WordFrame[i,10]/WordFrame[i,13])) WordFrame[i,17] <-
> > (1-(WordFrame[i,12]/WordFrame[i,15])) } else {
> >               {
> >               pdf(paste(WordFrame[i,1],"_Word_Task_Acquisition.pdf",collapse
> > = NULL, sep = "")) plout <-
> > plot(original_series,type='l',col='blue',xlab="Date of
> > Play",ylab="Number of Successful Words")
> > lines(simplemovingaverage,type='l',col='red') title(paste("Word Task
> > Acquisition for Subject", WordFrame[i,1])) dev.off() }
> >               WordFrame[i,18] <- F
> >               WordFrame[i,16] <- 0
> >               WordFrame[i,17] <- 0
> >     }
> > }
> >
> > It will work just fine if I run the lines individually (e.g. set i =
> > 1, 2, ect), and if I comment out abline and title (lines seems to
> > work fine). But it will throw the error everytime I try to run the
> > loop without these commented.
> >
> > Have tried just about everything I could find on the Stack forums to
> > run everything as a single argument and I'm just not sure what is
> > wrong with it.
> >
> > dev.list() spits out:
> >
> > pdf
> >   2
> > following the error.
> >
> > With abline and title commented out and lines run individually it's
> > NULL.
> >
> > Happens in both RStudio
> >
> > 2022.07.2+576 "Spotted Wakerobin" Release
> > (e7373ef832b49b2a9b88162cfe7eac5f22c40b34, 2022-09-06) for Ubuntu
> > Bionic Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML,
> > like Gecko) QtWebEngine/5.12.8 Chrome/69.0.3497.128 Safari/537.36
> >
> > And R:
> >
> > platform       x86_64-pc-linux-gnu
> > arch           x86_64
> > os             linux-gnu
> > system         x86_64, linux-gnu
> > status
> > major          4
> > minor          2.1
> > year           2022
> > month          06
> > day            23
> > svn rev        82513
> > language       R
> > version.string R version 4.2.1 (2022-06-23)
> > nickname       Funny-Looking Kid
> >
> >
> > My OS:
> > PRETTY_NAME="Debian GNU/Linux 11 (bullseye)"
> > NAME="Debian GNU/Linux"
> > VERSION_ID="11"
> > VERSION="11 (bullseye)"
> > VERSION_CODENAME=bullseye
> > ID=debian
> > HOME_URL="https://secure-web.cisco.com/1Ruvt90Q90ixR-GE-RDiKJgzRpfDjlNz-lZTqQQGM8Tf4GAoj5QOfE2vXMaMWxMoexuf1npQrX7uAjFuU2viz28h42RPmHQK7jGDX7BpRLkTNcERyxHVKJTxgYegXo-n9N7rqegcKsrr47xlGmTcMOJcBAqH7SpTPQlYDOGgjz1ErtetQRzUsd-eKs9l4oCVPiF6SKV40C7s_NXm0tuCswL2Jhyfv70-edCtBO_4j9-3dSi5ZdFLYaWsMScnwwxNIGYU2n0vw5NH4GJcZNsv6Scu-r6W8ndJaGL4UmX9J3PX0LrdFyjLbGtA7RqPpKFUQ/https%3A%2F%2Fwww.debian.org"
> > SUPPORT_URL="https://secure-web.cisco.com/1gveQttVrJNRSM85857IiydpLraxrrtJobMyCNkRvQ4V2f00DH67Z0hEa50LLpCVYQvIjMsQZxHAVMZvYQV_Cp2-e82TDZzPY4aSR2td2th3bwuXGxtI7CTgSUudOWgPpmnwVLT5r34EnwXEmwnMoiPVnOEC7slpF1fLGq11wSynuyttcTagMfpN6qdYfgtbu_mz0JOBUecQ-etUQYw5BDmXEKv5JZ_y5Uyt8Q89Kirhi7Hk8FMbCVcxRZpOZZmghxlPMxYaNVIOnln-R0H8J2QIzqE49cQQPKkFZ9O29zpr8odlBXqjObKn24ReYPDhH/https%3A%2F%2Fwww.debian.org%2Fsupport"
> > BUG_REPORT_URL="https://secure-web.cisco.com/1tepDnCjDgHsmvw9Eth-7nfyKi3doVSOFKVzz83wskdyf8lsrEVkG2NYw7am6ePhSFfjQXdDyceMyc21Un-vqTirSQYKdPavRdKJy85HgHMP66Xk-OgxFf-5KXiPzmFreDfuuJlYizGSUNOLcADyNVTCo47xFfRgtB83Hs8j3yYAJFrff7TqNOFWzSzTcfrycio_WSSfbQkLpUl-1xGzg-dvP16tKuwkRr62bkPeydXJC_iH1FfnWv5b1G04au3aFmRTem8t2RS40LPMS9Mh0UmMvHD_9qwX16cFMHQ8U4x9Sp9IUcAFhgnbffOyPQm1C/https%3A%2F%2Fbugs.debian.org"
> > No LSB modules are available.
> > Distributor ID:???Debian
> > Description:??????Debian GNU/Linux 11 (bullseye)
> > Release:????11
> > Codename:???bullseye
> >          Icon name: computer-desktop
> >            Chassis: desktop
> >         Machine ID: 053ebf23707f49c8ad4e0684f4cf19d3
> >            Boot ID: d0e6294d3b944286bef10e76c21e6401
> >   Operating System: Debian GNU/Linux 11 (bullseye)
> >             Kernel: Linux 5.10.0-18-amd64
> >       Architecture: x86-64
> >
> >
> > Any suggestions would be greatly appreciated.
> >
> > --
> >
> > Thomas DeRamus (He/Him/His)
> >
> > Data Analyst
> >
> > Massachusetts General Hospital Brigham
> >
> > Alzheimer?s Clinical & Translational Research Unit
> >
> > 149 13th Street
> >
> > Charlestown, MA 02129
> >
> > Phone: 205-834-5066
> >
> > Email: tderamus at partners.org<mailto:tderamus at partners.org>,
> > tpderamus at gmail.com<mailto:tpderamus at gmail.com>
> >
> >
> > [https://secure-web.cisco.com/1AI4S4rz4bDZGM8naa-19GTAeSORO5ZmNe056Q_nhPRk4JVAzPiRKUBWitBK5TpxoKBLoLvNfoMDanGd1n5Bnf4SJFT7l7HnaLcjjH7oVk2BZdDfCLHo8a8eePvD4XrF2Fw3iuxKgIZY5dwdesP3P8pSvkmVGvyZ-HiEKRetk4uJHhRa6gSgOQ8MbCVKmi6XP1dtozTEH1RpDrFJ4EyevPO52UzaTAY6CR8USLWNbsxXJsnsjUz1G6_4P7B3ULuMu9mEPeQz_GnTrSXTrGZooK_idhoEougti7I8NYV0CS09Yahmp4Fe_vh9wu4Jkdal3/https://ci3.googleusercontent.com/mail-sig/AIorK4we2sU30P2HyfDQF5hpEjYTt-9FTBK7cAVsP7EenrZ0nsKCf48fuYMtElj6Szn_2fpSPWr66eQ][https://ci3.googleusercontent.com/mail-sig/AIorK4yyY0DlImU0UONJrHTbPc5T3lJj8Kmu8SbDKJJ3XjcX6CgvVsvSueYKwficYFz4zXt6fZV8YIY]
> >
> > ?If knowledge can create problems, it is not through ignorance that
> > we can solve them.?
> >
> > ?Issac Asimo


From jo@h@m@u|r|ch @end|ng |rom gm@||@com  Thu Oct  6 03:16:18 2022
From: jo@h@m@u|r|ch @end|ng |rom gm@||@com (Joshua Ulrich)
Date: Wed, 5 Oct 2022 20:16:18 -0500
Subject: [R] Getting "Error in ect,
 plot.new has not been called yet" despite grouping plot call
In-Reply-To: <PH0PR04MB7493E39389D0196BEC260CB6BE5A9@PH0PR04MB7493.namprd04.prod.outlook.com>
References: <PH0PR04MB7493E39389D0196BEC260CB6BE5A9@PH0PR04MB7493.namprd04.prod.outlook.com>
Message-ID: <CAPPM_gRn-HVg2oc8fkNDsJtqm1VSpa4C68z0tCHxPN7b7qQWEw@mail.gmail.com>

Hi,

My hunch is that you need to add print(plout) before you call dev.off().
See https://stackoverflow.com/a/39853861

Try that and let me know if that works. If not, I'll take a closer look
later.

Best,
Josh


On Wed, Oct 5, 2022, 1:40 AM Deramus, Thomas Patrick <tderamus at partners.org>
wrote:

> Sorry to cross-post on Stackoverflow and here but I'm having some
> difficulty.
>
> https://stackoverflow.com/questions/73942794/still-getting-error-in-ect-plot-new-has-not-been-called-yet-despite-grouping
>
> Trying to make a nested loop that produces PDFs off different graphs, one
> for ACF/PACF diagnostics and another for the actual data, based on some
> time-series analyses I'm doing.
>
> Unfortunately, I keep getting the dreaded: Error plot.new has not been
> called yet
>
> The code is meant to write a PDF containing the ACF and PACF graphs, then
> do some analyses on the timeseries, and then make a separate PDF containing
> a plot describing the timeseries based on the p-values of each test for
> each individual.
>
> library(plyr)
> library(dplyr)
> library(ggplot2)
> library(Kendall)
> library(lubridate)
> library(xts)
> library(TTR)
> library(trend)
> library(forecast)
> library(openxlsx)
>
> Game_Metrics_Word_Task <-
> read.xlsx("GamePack_Analytics_ALL_TIME_Short.xlsx", "Boggle")
> Game_Metrics_Word_Task <- Game_Metrics_Word_Task %>% filter(grepl('1440',
> StudyId))
> Game_Metrics_Word_Task$DeviceTime <-
> ymd_hms(Game_Metrics_Word_Task$DeviceTime,  tz = "America/New_York")
> Game_Metrics_Word_Task <-
> Game_Metrics_Word_Task[!duplicated(Game_Metrics_Word_Task[1:2,])]
>
> Participant_Word_Task <-
> split(arrange(Game_Metrics_Word_Task,StudyId,DeviceTime),
> arrange(Game_Metrics_Word_Task,StudyId,DeviceTime,StudyId,DeviceTime)$StudyId)
>
> WordFrame <- data.frame(Participant = c(0), Task = c(0), MannKendall_Tau =
> c(0), MannKendall_P = c(0), Sen_Slope_Value = c(0), Sen_Slope_Pval = c(0),
> Pettitts_CIV = c(0), Pettitts_Pval = c(0), ARIMA_Model = c(0),
> Time_to_Petit = c(0), Number_of_Trials_to_Pettitt = c(0),
> Playtime_to_Petit_seconds = c(0), Time_Start_to_end_days = c(0),
> Number_of_Total_Trials = c(0), Total_Playtime_seconds = c(0),
> Learning_rate_days = c(0), Learning_rate_seconds = c(0), Learned_Task =
> c(0))
>
> for (i in 1:length(Participant_Word_Task)){
>     success_series <- xts(filter(Participant_Word_Task[[i]], GameEndReason
> == "TIMER_UP")$NumberOfSuccesfulWords , order.by=as.POSIXct(filter(Participant_Word_Task[[i]],
> GameEndReason == "TIMER_UP")$DeviceTime))
>     original_series <-
> xts(Participant_Word_Task[[i]]$NumberOfSuccesfulWords, order.by
> =as.POSIXct(Participant_Word_Task[[i]]$DeviceTime))
>     success_decomp <- ts(success_series, frequency =
> nweeks(success_series))
>     original_decomp <- ts(original_series, frequency =
> nweeks(success_series))
>
>
> pdf(paste("Word_Task_Autocorrelation_plots_for_subject_",unique(Participant_Word_Task[[i]]$StudyId),".pdf"
> ,collapse = NULL, sep = ""))
>     par(mfrow=c(1,2))
>     Autocorrelationplot <- acf(success_decomp, main=paste(""))
>     PartialAutocorrelationplot <- pacf(success_decomp, main=paste(""))
>     mtext(paste("Word Task Auto and Partialauto correlations for subject
> ",unique(Participant_Word_Task[[i]]$StudyId)), side = 3, line = -3, outer =
> TRUE)
>     dev.off()
>
>     AutomatedArimaoutputs <- auto.arima(success_decomp)
>     p <- length(AutomatedArimaoutputs$model$phi)
>     #AR component
>     q <- length(AutomatedArimaoutputs$model$theta)
>     #MA component
>     d <- AutomatedArimaoutputs$model$Delta
>     #order of difference
>     WordFrame[i,1] <- unique(Participant_Word_Task[[i]]$StudyId)
>     WordFrame[i,2] <- "Word"
>     WordFrame[i,3] <- MannKendall(success_decomp)$tau[1]
>     WordFrame[i,4] <- MannKendall(success_decomp)$sl[1]
>     WordFrame[i,5] <- sens.slope(success_decomp)$estimates
>     WordFrame[i,6] <- sens.slope(success_decomp)$p.value
>     WordFrame[i,7] <- pettitt.test(success_decomp)$estimate
>     WordFrame[i,8] <- pettitt.test(success_decomp)$p.value
>     WordFrame[i,9] <- paste("ARIMA(",p,",",q,",",d,")", collapse = NULL,
> sep = "")
>     WordFrame[i,10] <-
> difftime(time(success_series[WordFrame[i,7]]),time(original_series[1]))
>     WordFrame[i,11] <- tail(which(grepl(success_series[WordFrame[i,7]],
> original_series)), n=1)
>     WordFrame[i,12] <-
> sum(Participant_Word_Task[[i]]$TotalDuration[1:WordFrame[i,11]])-sum(Participant_Word_Task[[i]]$TotalTimePaused[1:WordFrame[i,11]])
>     WordFrame[i,13] <-
> difftime(time(original_series[length(original_series)]),time(original_series[1]))
>     WordFrame[i,14] <- length(original_series)
>     WordFrame[i,15] <-
> sum(Participant_Word_Task[[i]]$TotalDuration[1:length(original_series)])-sum(Participant_Word_Task[[i]]$TotalTimePaused[1:length(original_series)])
>
>
>     simplemovingaverage <- SMA(original_series, n =
> nweeks(original_series))
>
>     if (WordFrame[i,4] <= 0.05 & WordFrame[i,6] <= 0.05 & WordFrame[i,8]
> <= 0.05){
>               {
>
> pdf(paste(WordFrame[i,1],"_Word_Task_Acquisition.pdf",collapse = NULL, sep
> = ""))
>               plout <- plot(original_series,type='l',col='blue',xlab="Date
> of Play",ylab="Number of Successful Words")
>               lines(simplemovingaverage,type='l',col='red')
>               title(paste("Word Task Acquisition for Subject",
> WordFrame[i,1]))
>               abline(v = index(original_series[WordFrame[i,7]]),lty=2,
> col='green', lwd=3)
>               dev.off()
>               }
>               WordFrame[i,18] <- T
>               WordFrame[i,16] <- (1-(WordFrame[i,10]/WordFrame[i,13]))
>               WordFrame[i,17] <- (1-(WordFrame[i,12]/WordFrame[i,15]))
>     } else {
>               {
>
> pdf(paste(WordFrame[i,1],"_Word_Task_Acquisition.pdf",collapse = NULL, sep
> = ""))
>               plout <- plot(original_series,type='l',col='blue',xlab="Date
> of Play",ylab="Number of Successful Words")
>               lines(simplemovingaverage,type='l',col='red')
>               title(paste("Word Task Acquisition for Subject",
> WordFrame[i,1]))
>               dev.off()
>               }
>               WordFrame[i,18] <- F
>               WordFrame[i,16] <- 0
>               WordFrame[i,17] <- 0
>     }
> }
>
> It will work just fine if I run the lines individually (e.g. set i = 1, 2,
> ect), and if I comment out abline and title (lines seems to work fine). But
> it will throw the error everytime I try to run the loop without these
> commented.
>
> Have tried just about everything I could find on the Stack forums to run
> everything as a single argument and I'm just not sure what is wrong with it.
>
> dev.list() spits out:
>
> pdf
>   2
> following the error.
>
> With abline and title commented out and lines run individually it's NULL.
>
> Happens in both RStudio
>
> 2022.07.2+576 "Spotted Wakerobin" Release
> (e7373ef832b49b2a9b88162cfe7eac5f22c40b34, 2022-09-06) for Ubuntu Bionic
> Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko)
> QtWebEngine/5.12.8 Chrome/69.0.3497.128 Safari/537.36
>
> And R:
>
> platform       x86_64-pc-linux-gnu
> arch           x86_64
> os             linux-gnu
> system         x86_64, linux-gnu
> status
> major          4
> minor          2.1
> year           2022
> month          06
> day            23
> svn rev        82513
> language       R
> version.string R version 4.2.1 (2022-06-23)
> nickname       Funny-Looking Kid
>
>
> My OS:
> PRETTY_NAME="Debian GNU/Linux 11 (bullseye)"
> NAME="Debian GNU/Linux"
> VERSION_ID="11"
> VERSION="11 (bullseye)"
> VERSION_CODENAME=bullseye
> ID=debian
> HOME_URL="https://www.debian.org/"
> SUPPORT_URL="https://www.debian.org/support"
> BUG_REPORT_URL="https://bugs.debian.org/"
> No LSB modules are available.
> Distributor ID: Debian
> Description: Debian GNU/Linux 11 (bullseye)
> Release: 11
> Codename: bullseye
>          Icon name: computer-desktop
>            Chassis: desktop
>         Machine ID: 053ebf23707f49c8ad4e0684f4cf19d3
>            Boot ID: d0e6294d3b944286bef10e76c21e6401
>   Operating System: Debian GNU/Linux 11 (bullseye)
>             Kernel: Linux 5.10.0-18-amd64
>       Architecture: x86-64
>
>
> Any suggestions would be greatly appreciated.
>
> --
>
> Thomas DeRamus (He/Him/His)
>
> Data Analyst
>
> Massachusetts General Hospital Brigham
>
> Alzheimer?s Clinical & Translational Research Unit
>
> 149 13th Street
>
> Charlestown, MA 02129
>
> Phone: 205-834-5066
>
> Email: tderamus at partners.org<mailto:tderamus at partners.org>,
> tpderamus at gmail.com<mailto:tpderamus at gmail.com>
>
>
> [
> https://ci3.googleusercontent.com/mail-sig/AIorK4we2sU30P2HyfDQF5hpEjYTt-9FTBK7cAVsP7EenrZ0nsKCf48fuYMtElj6Szn_2fpSPWr66eQ][https://ci3.googleusercontent.com/mail-sig/AIorK4yyY0DlImU0UONJrHTbPc5T3lJj8Kmu8SbDKJJ3XjcX6CgvVsvSueYKwficYFz4zXt6fZV8YIY
> ]
>
> ?If knowledge can create problems, it is not through ignorance that we can
> solve them.?
>
> ?Issac Asimov
> The information in this e-mail is intended only for th...{{dropped:22}}


From Er|c@RhonC@|deron @end|ng |rom pennmed|c|ne@upenn@edu  Wed Oct  5 22:02:02 2022
From: Er|c@RhonC@|deron @end|ng |rom pennmed|c|ne@upenn@edu (Rhon Calderon, Eric)
Date: Wed, 5 Oct 2022 20:02:02 +0000
Subject: [R] Help installing devtools plus other packages in R terminal
Message-ID: <MN2PR04MB6400967EAC2449BB0F2A528BCB5D9@MN2PR04MB6400.namprd04.prod.outlook.com>

Hi,

I am using R in my HPC terminal. After many tries, I was able to install and exec successfully R on my HPC but now I cannot install devtools and other dependencies. I need some of theses packages to install some others from bioconductor. I was wondering if anybody has a solution.

The script I got from my R session is (the highlighted part is the errors I keep getting):

> install.packages('devtools')
Installing package into ?/home/ericrhon/R/x86_64-pc-linux-gnu-library/4.2?
(as ?lib? is unspecified)
--- Please select a CRAN mirror for use in this session ---
Secure CRAN mirrors

 1: 0-Cloud [https]
 2: Australia (Canberra) [https]
 3: Australia (Melbourne 1) [https]
 4: Australia (Melbourne 2) [https]
 5: Australia (Perth) [https]
 6: Austria [https]
 7: Belgium (Brussels) [https]
 8: Brazil (PR) [https]
 9: Brazil (RJ) [https]
10: Brazil (SP 1) [https]
11: Brazil (SP 2) [https]
12: Bulgaria [https]
13: Canada (MB) [https]
14: Canada (ON 3) [https]
15: Chile (Santiago) [https]
16: China (Beijing 2) [https]
17: China (Beijing 3) [https]
18: China (Hefei) [https]
19: China (Hong Kong) [https]
20: China (Guangzhou) [https]
21: China (Lanzhou) [https]
22: China (Nanjing) [https]
23: China (Shanghai 2) [https]
24: China (Shenzhen) [https]
25: Colombia (Cali) [https]
26: Costa Rica [https]
27: Cyprus [https]
28: Czech Republic [https]
29: Denmark [https]
30: East Asia [https]
31: Ecuador (Cuenca) [https]
32: Ecuador (Quito) [https]
33: France (Lyon 1) [https]
34: France (Lyon 2) [https]
35: France (Marseille) [https]
36: France (Paris 1) [https]
37: Germany (Erlangen) [https]
38: Germany (Leipzig) [https]
39: Germany (G?ttingen) [https]
40: Germany (M?nster) [https]
41: Germany (Regensburg) [https]
42: Greece [https]
43: Hungary [https]
44: Iceland [https]
45: India [https]
46: Indonesia (Banda Aceh) [https]
47: Iran (Mashhad) [https]
48: Italy (Milano) [https]
49: Italy (Padua) [https]
50: Japan (Tokyo) [https]
51: Japan (Yonezawa) [https]
52: Korea (Gyeongsan-si) [https]
53: Korea (Ulsan) [https]
54: Malaysia [https]
55: Mexico (Mexico City) [https]
56: Mexico (Texcoco) [https]
57: Morocco [https]
58: Netherlands (Dronten) [https]
59: New Zealand [https]
60: Norway [https]
61: South Africa (Johannesburg) [https]
62: Spain (A Coru?a) [https]
63: Spain (Madrid) [https]
64: Sweden (Bor?s) [https]
65: Sweden (Ume?) [https]
66: Switzerland [https]
67: Taiwan (Taipei) [https]
68: Turkey (Denizli) [https]
69: Turkey (Istanbul) [https]
70: Turkey (Mersin) [https]
71: UK (Bristol) [https]
72: UK (London 1) [https]
73: USA (IA) [https]
74: USA (MI) [https]
75: USA (MO) [https]
76: USA (OH) [https]
77: USA (OR) [https]
78: USA (TN) [https]
79: USA (TX 1) [https]
80: Uruguay [https]
81: (other mirrors)

Selection: 1
also installing the dependencies ?httpuv?, ?shiny?, ?miniUI?

trying URL 'https://cloud.r-project.org/src/contrib/httpuv_1.6.6.tar.gz'
Content type 'application/x-gzip' length 1875264 bytes (1.8 MB)
==================================================
downloaded 1.8 MB

trying URL 'https://cloud.r-project.org/src/contrib/shiny_1.7.2.tar.gz'
Content type 'application/x-gzip' length 2982507 bytes (2.8 MB)
==================================================
downloaded 2.8 MB

trying URL 'https://cloud.r-project.org/src/contrib/miniUI_0.1.1.1.tar.gz'
Content type 'application/x-gzip' length 97958 bytes (95 KB)
==================================================
downloaded 95 KB

trying URL 'https://cloud.r-project.org/src/contrib/devtools_2.4.4.tar.gz'
Content type 'application/x-gzip' length 374492 bytes (365 KB)
==================================================
downloaded 365 KB

* installing *source* package ?httpuv? ...
** package ?httpuv? successfully unpacked and MD5 sums checked
** using staged installation
** libs
g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c RcppExports-legacy.cpp -o RcppExports-legacy.o

g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c RcppExports.cpp -o RcppExports.o
g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c callback.cpp -o callback.o
g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c callbackqueue.cpp -o callbackqueue.o
g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c filedatasource-unix.cpp -o filedatasource-unix.o
g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c filedatasource-win.cpp -o filedatasource-win.o
g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c fs.cpp -o fs.o
g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c gzipdatasource.cpp -o gzipdatasource.o
g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c http.cpp -o http.o
g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c httprequest.cpp -o httprequest.o
g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c httpresponse.cpp -o httpresponse.o
g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c httpuv.cpp -o httpuv.o
gcc -std=gnu11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c md5.c -o md5.o
g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c mime.cpp -o mime.o
g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c socket.cpp -o socket.o
g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c staticpath.cpp -o staticpath.o
g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c thread.cpp -o thread.o
g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c timegm.cpp -o timegm.o
g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c utils.cpp -o utils.o
g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c uvutil.cpp -o uvutil.o
g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c webapplication.cpp -o webapplication.o
g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c websockets-base.cpp -o websockets-base.o
g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c websockets-hixie76.cpp -o websockets-hixie76.o
g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c websockets-hybi03.cpp -o websockets-hybi03.o
g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c websockets-ietf.cpp -o websockets-ietf.o
g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c websockets.cpp -o websockets.o
g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c winutils.cpp -o winutils.o
cp -p -f libuv/m4/lt_obsolete.m4 libuv/m4/lt~obsolete.m4
cd libuv; \
if ! command -v automake >/dev/null 2>&1 ; then \
??????echo "automake not found. Touching files so configure will not try to run automake."; \
??????touch aclocal.m4; \
??????touch -r aclocal.m4 configure Makefile.in; \
else \
??????echo "automake found. Running autoupdate and autogen.sh."; \
??????autoupdate; \
??????sh autogen.sh; \
fi; \
chmod +x configure; \
CC="gcc -std=gnu11" CFLAGS="-g -O2  -fpic -fvisibility=hidden" AR="ar" RANLIB="ranlib" LDFLAGS="-L/usr/local/lib64" ./configure "--quiet"
automake found. Running autoupdate and autogen.sh.
aclocal.m4:17: warning: this file was generated for autoconf 2.71.
You have another version of autoconf.  It may work, but is not guaranteed to.
If you have problems, you may need to regenerate the build system entirely.
To do so, use the procedure documented by the package, typically 'autoreconf'.
+ libtoolize --copy
autogen.sh: line 43: libtoolize: command not found
make --directory=libuv \
??????HAVE_DTRACE=0
make[1]: Entering directory `/tmp/RtmpMjF6Ns/R.INSTALL4a3cb2204b0da/httpuv/src/libuv'
CDPATH="${ZSH_VERSION+.}:" && cd . && /bin/sh '/tmp/RtmpMjF6Ns/R.INSTALL4a3cb2204b0da/httpuv/src/libuv/missing' aclocal-1.16 -I m4
/tmp/RtmpMjF6Ns/R.INSTALL4a3cb2204b0da/httpuv/src/libuv/missing: line 81: aclocal-1.16: command not found
WARNING: 'aclocal-1.16' is missing on your system.
         You should only need it if you modified 'acinclude.m4' or
         'configure.ac' or m4 files included by 'configure.ac'.
         The 'aclocal' program is part of the GNU Automake package:
         <https://www.gnu.org/software/automake>
         It also requires GNU Autoconf, GNU m4 and Perl in order to run:
         <https://www.gnu.org/software/autoconf>
         <https://www.gnu.org/software/m4/>
         <https://www.perl.org/>
make[1]: *** [aclocal.m4] Error 127
make[1]: Leaving directory `/tmp/RtmpMjF6Ns/R.INSTALL4a3cb2204b0da/httpuv/src/libuv'
make: *** [libuv/.libs/libuv.a] Error 2
ERROR: compilation failed for package ?httpuv?
* removing ?/home/ericrhon/R/x86_64-pc-linux-gnu-library/4.2/httpuv?
ERROR: dependency ?httpuv? is not available for package ?shiny?
* removing ?/home/ericrhon/R/x86_64-pc-linux-gnu-library/4.2/shiny?
ERROR: dependency ?shiny? is not available for package ?miniUI?
* removing ?/home/ericrhon/R/x86_64-pc-linux-gnu-library/4.2/miniUI?
ERROR: dependency ?miniUI? is not available for package ?devtools?
* removing ?/home/ericrhon/R/x86_64-pc-linux-gnu-library/4.2/devtools?

The downloaded source packages are in
???????/tmp/RtmpZELkpr/downloaded_packages?
Warning messages:
1: In install.packages("devtools") :
  installation of package ?httpuv? had non-zero exit status
2: In install.packages("devtools") :
  installation of package ?shiny? had non-zero exit status
3: In install.packages("devtools") :
  installation of package ?miniUI? had non-zero exit status
4: In install.packages("devtools") :
  installation of package ?devtools? had non-zero exit status


Thanks.

Eric


	[[alternative HTML version deleted]]


From @kw@|mmo @end|ng |rom gm@||@com  Thu Oct  6 08:57:41 2022
From: @kw@|mmo @end|ng |rom gm@||@com (Andrew Simmons)
Date: Thu, 6 Oct 2022 02:57:41 -0400
Subject: [R] Help installing devtools plus other packages in R terminal
In-Reply-To: <MN2PR04MB6400967EAC2449BB0F2A528BCB5D9@MN2PR04MB6400.namprd04.prod.outlook.com>
References: <MN2PR04MB6400967EAC2449BB0F2A528BCB5D9@MN2PR04MB6400.namprd04.prod.outlook.com>
Message-ID: <CAPcHnpSiNdFcZ4OtoFeyNo3_T7GhiajpN--Azg+gm7H4ALWp+A@mail.gmail.com>

To install the packages from source, you need to install make, gcc, and g++:
?sudo apt install make?
?sudo apt install gcc?
?sudo apt install g++

then try installing them again

On Thu, Oct 6, 2022 at 2:54 AM Rhon Calderon, Eric
<Eric.RhonCalderon at pennmedicine.upenn.edu> wrote:
>
> Hi,
>
> I am using R in my HPC terminal. After many tries, I was able to install and exec successfully R on my HPC but now I cannot install devtools and other dependencies. I need some of theses packages to install some others from bioconductor. I was wondering if anybody has a solution.
>
> The script I got from my R session is (the highlighted part is the errors I keep getting):
>
> > install.packages('devtools')
> Installing package into ?/home/ericrhon/R/x86_64-pc-linux-gnu-library/4.2?
> (as ?lib? is unspecified)
> --- Please select a CRAN mirror for use in this session ---
> Secure CRAN mirrors
>
>  1: 0-Cloud [https]
>  2: Australia (Canberra) [https]
>  3: Australia (Melbourne 1) [https]
>  4: Australia (Melbourne 2) [https]
>  5: Australia (Perth) [https]
>  6: Austria [https]
>  7: Belgium (Brussels) [https]
>  8: Brazil (PR) [https]
>  9: Brazil (RJ) [https]
> 10: Brazil (SP 1) [https]
> 11: Brazil (SP 2) [https]
> 12: Bulgaria [https]
> 13: Canada (MB) [https]
> 14: Canada (ON 3) [https]
> 15: Chile (Santiago) [https]
> 16: China (Beijing 2) [https]
> 17: China (Beijing 3) [https]
> 18: China (Hefei) [https]
> 19: China (Hong Kong) [https]
> 20: China (Guangzhou) [https]
> 21: China (Lanzhou) [https]
> 22: China (Nanjing) [https]
> 23: China (Shanghai 2) [https]
> 24: China (Shenzhen) [https]
> 25: Colombia (Cali) [https]
> 26: Costa Rica [https]
> 27: Cyprus [https]
> 28: Czech Republic [https]
> 29: Denmark [https]
> 30: East Asia [https]
> 31: Ecuador (Cuenca) [https]
> 32: Ecuador (Quito) [https]
> 33: France (Lyon 1) [https]
> 34: France (Lyon 2) [https]
> 35: France (Marseille) [https]
> 36: France (Paris 1) [https]
> 37: Germany (Erlangen) [https]
> 38: Germany (Leipzig) [https]
> 39: Germany (G?ttingen) [https]
> 40: Germany (M?nster) [https]
> 41: Germany (Regensburg) [https]
> 42: Greece [https]
> 43: Hungary [https]
> 44: Iceland [https]
> 45: India [https]
> 46: Indonesia (Banda Aceh) [https]
> 47: Iran (Mashhad) [https]
> 48: Italy (Milano) [https]
> 49: Italy (Padua) [https]
> 50: Japan (Tokyo) [https]
> 51: Japan (Yonezawa) [https]
> 52: Korea (Gyeongsan-si) [https]
> 53: Korea (Ulsan) [https]
> 54: Malaysia [https]
> 55: Mexico (Mexico City) [https]
> 56: Mexico (Texcoco) [https]
> 57: Morocco [https]
> 58: Netherlands (Dronten) [https]
> 59: New Zealand [https]
> 60: Norway [https]
> 61: South Africa (Johannesburg) [https]
> 62: Spain (A Coru?a) [https]
> 63: Spain (Madrid) [https]
> 64: Sweden (Bor?s) [https]
> 65: Sweden (Ume?) [https]
> 66: Switzerland [https]
> 67: Taiwan (Taipei) [https]
> 68: Turkey (Denizli) [https]
> 69: Turkey (Istanbul) [https]
> 70: Turkey (Mersin) [https]
> 71: UK (Bristol) [https]
> 72: UK (London 1) [https]
> 73: USA (IA) [https]
> 74: USA (MI) [https]
> 75: USA (MO) [https]
> 76: USA (OH) [https]
> 77: USA (OR) [https]
> 78: USA (TN) [https]
> 79: USA (TX 1) [https]
> 80: Uruguay [https]
> 81: (other mirrors)
>
> Selection: 1
> also installing the dependencies ?httpuv?, ?shiny?, ?miniUI?
>
> trying URL 'https://cloud.r-project.org/src/contrib/httpuv_1.6.6.tar.gz'
> Content type 'application/x-gzip' length 1875264 bytes (1.8 MB)
> ==================================================
> downloaded 1.8 MB
>
> trying URL 'https://cloud.r-project.org/src/contrib/shiny_1.7.2.tar.gz'
> Content type 'application/x-gzip' length 2982507 bytes (2.8 MB)
> ==================================================
> downloaded 2.8 MB
>
> trying URL 'https://cloud.r-project.org/src/contrib/miniUI_0.1.1.1.tar.gz'
> Content type 'application/x-gzip' length 97958 bytes (95 KB)
> ==================================================
> downloaded 95 KB
>
> trying URL 'https://cloud.r-project.org/src/contrib/devtools_2.4.4.tar.gz'
> Content type 'application/x-gzip' length 374492 bytes (365 KB)
> ==================================================
> downloaded 365 KB
>
> * installing *source* package ?httpuv? ...
> ** package ?httpuv? successfully unpacked and MD5 sums checked
> ** using staged installation
> ** libs
> g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c RcppExports-legacy.cpp -o RcppExports-legacy.o
>
> g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c RcppExports.cpp -o RcppExports.o
> g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c callback.cpp -o callback.o
> g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c callbackqueue.cpp -o callbackqueue.o
> g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c filedatasource-unix.cpp -o filedatasource-unix.o
> g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c filedatasource-win.cpp -o filedatasource-win.o
> g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c fs.cpp -o fs.o
> g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c gzipdatasource.cpp -o gzipdatasource.o
> g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c http.cpp -o http.o
> g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c httprequest.cpp -o httprequest.o
> g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c httpresponse.cpp -o httpresponse.o
> g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c httpuv.cpp -o httpuv.o
> gcc -std=gnu11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c md5.c -o md5.o
> g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c mime.cpp -o mime.o
> g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c socket.cpp -o socket.o
> g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c staticpath.cpp -o staticpath.o
> g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c thread.cpp -o thread.o
> g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c timegm.cpp -o timegm.o
> g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c utils.cpp -o utils.o
> g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c uvutil.cpp -o uvutil.o
> g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c webapplication.cpp -o webapplication.o
> g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c websockets-base.cpp -o websockets-base.o
> g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c websockets-hixie76.cpp -o websockets-hixie76.o
> g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c websockets-hybi03.cpp -o websockets-hybi03.o
> g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c websockets-ietf.cpp -o websockets-ietf.o
> g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c websockets.cpp -o websockets.o
> g++ -std=gnu++11 -I"/home/ericrhon/R/4.2/R-4.2.1/include" -DNDEBUG -Ilibuv/include -pthread -I'/home/ericrhon/R/4.2/R-4.2.1/library/Rcpp/include' -I'/home/ericrhon/R/4.2/R-4.2.1/library/later/include' -I/usr/local/include  -fvisibility=hidden -DSTRICT_R_HEADERS -fpic  -g -O2  -c winutils.cpp -o winutils.o
> cp -p -f libuv/m4/lt_obsolete.m4 libuv/m4/lt~obsolete.m4
> cd libuv; \
> if ! command -v automake >/dev/null 2>&1 ; then \
> echo "automake not found. Touching files so configure will not try to run automake."; \
> touch aclocal.m4; \
> touch -r aclocal.m4 configure Makefile.in; \
> else \
> echo "automake found. Running autoupdate and autogen.sh."; \
> autoupdate; \
> sh autogen.sh; \
> fi; \
> chmod +x configure; \
> CC="gcc -std=gnu11" CFLAGS="-g -O2  -fpic -fvisibility=hidden" AR="ar" RANLIB="ranlib" LDFLAGS="-L/usr/local/lib64" ./configure "--quiet"
> automake found. Running autoupdate and autogen.sh.
> aclocal.m4:17: warning: this file was generated for autoconf 2.71.
> You have another version of autoconf.  It may work, but is not guaranteed to.
> If you have problems, you may need to regenerate the build system entirely.
> To do so, use the procedure documented by the package, typically 'autoreconf'.
> + libtoolize --copy
> autogen.sh: line 43: libtoolize: command not found
> make --directory=libuv \
> HAVE_DTRACE=0
> make[1]: Entering directory `/tmp/RtmpMjF6Ns/R.INSTALL4a3cb2204b0da/httpuv/src/libuv'
> CDPATH="${ZSH_VERSION+.}:" && cd . && /bin/sh '/tmp/RtmpMjF6Ns/R.INSTALL4a3cb2204b0da/httpuv/src/libuv/missing' aclocal-1.16 -I m4
> /tmp/RtmpMjF6Ns/R.INSTALL4a3cb2204b0da/httpuv/src/libuv/missing: line 81: aclocal-1.16: command not found
> WARNING: 'aclocal-1.16' is missing on your system.
>          You should only need it if you modified 'acinclude.m4' or
>          'configure.ac' or m4 files included by 'configure.ac'.
>          The 'aclocal' program is part of the GNU Automake package:
>          <https://www.gnu.org/software/automake>
>          It also requires GNU Autoconf, GNU m4 and Perl in order to run:
>          <https://www.gnu.org/software/autoconf>
>          <https://www.gnu.org/software/m4/>
>          <https://www.perl.org/>
> make[1]: *** [aclocal.m4] Error 127
> make[1]: Leaving directory `/tmp/RtmpMjF6Ns/R.INSTALL4a3cb2204b0da/httpuv/src/libuv'
> make: *** [libuv/.libs/libuv.a] Error 2
> ERROR: compilation failed for package ?httpuv?
> * removing ?/home/ericrhon/R/x86_64-pc-linux-gnu-library/4.2/httpuv?
> ERROR: dependency ?httpuv? is not available for package ?shiny?
> * removing ?/home/ericrhon/R/x86_64-pc-linux-gnu-library/4.2/shiny?
> ERROR: dependency ?shiny? is not available for package ?miniUI?
> * removing ?/home/ericrhon/R/x86_64-pc-linux-gnu-library/4.2/miniUI?
> ERROR: dependency ?miniUI? is not available for package ?devtools?
> * removing ?/home/ericrhon/R/x86_64-pc-linux-gnu-library/4.2/devtools?
>
> The downloaded source packages are in
> ?/tmp/RtmpZELkpr/downloaded_packages?
> Warning messages:
> 1: In install.packages("devtools") :
>   installation of package ?httpuv? had non-zero exit status
> 2: In install.packages("devtools") :
>   installation of package ?shiny? had non-zero exit status
> 3: In install.packages("devtools") :
>   installation of package ?miniUI? had non-zero exit status
> 4: In install.packages("devtools") :
>   installation of package ?devtools? had non-zero exit status
>
>
> Thanks.
>
> Eric
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kry|ov@r00t @end|ng |rom gm@||@com  Thu Oct  6 09:26:47 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Thu, 6 Oct 2022 10:26:47 +0300
Subject: [R] Help installing devtools plus other packages in R terminal
In-Reply-To: <MN2PR04MB6400967EAC2449BB0F2A528BCB5D9@MN2PR04MB6400.namprd04.prod.outlook.com>
References: <MN2PR04MB6400967EAC2449BB0F2A528BCB5D9@MN2PR04MB6400.namprd04.prod.outlook.com>
Message-ID: <20221006102647.11bca9b5@Tarkus>

On Wed, 5 Oct 2022 20:02:02 +0000
"Rhon Calderon, Eric" <Eric.RhonCalderon at pennmedicine.upenn.edu> wrote:

> automake found. Running autoupdate and autogen.sh.
<...>
> + libtoolize --copy
> autogen.sh: line 43: libtoolize: command not found

Since you have automake installed, you also need libtool
<https://www.gnu.org/software/libtool/> installed in order to compile
this particular package from source. Depending on the HPC, there may be
a particular command to "activate" the installation already made by the
HPC administrator.

I guess you could also report this as a bug in devtools: they check for
automake but not libtool. If you can temporarily chmod -x automake, the
installation should succeed too, because then the package will not try
to regenerate its build system. I don't see why they even try to do
that, but maybe that's a workaround for some kind of compatibility
problem.

> CDPATH="${ZSH_VERSION+.}:" && cd . && /bin/sh
> '/tmp/RtmpMjF6Ns/R.INSTALL4a3cb2204b0da/httpuv/src/libuv/missing'
> aclocal-1.16 -I m4
> /tmp/RtmpMjF6Ns/R.INSTALL4a3cb2204b0da/httpuv/src/libuv/missing: line
> 81: aclocal-1.16: command not found

Make sure your automake installation is working. I think the error is
caused by the previous error and may go away once you install libtool,
but I may be mistaken regarding that.

Do Bioconductor packages really depend on devtools? What do their
errors look like?

-- 
Best regards,
Ivan


From tder@mu@ @end|ng |rom p@rtner@@org  Wed Oct  5 15:32:00 2022
From: tder@mu@ @end|ng |rom p@rtner@@org (Deramus, Thomas Patrick)
Date: Wed, 5 Oct 2022 13:32:00 +0000
Subject: [R] Getting "Error in ect,
 plot.new has not been called yet" despite grouping plot call
In-Reply-To: <20221005230608.793c8b9f@rolf-Latitude-E7470>
References: <PH0PR04MB7493E39389D0196BEC260CB6BE5A9@PH0PR04MB7493.namprd04.prod.outlook.com>
 <20221005230608.793c8b9f@rolf-Latitude-E7470>
Message-ID: <PH0PR04MB7493CE9332F02B56C0AFE31FBE5D9@PH0PR04MB7493.namprd04.prod.outlook.com>

Hi Rolf.

I followed your suggestion (though it's probably not as trimmed as it could be), but the problem unfortunately persists.

Does this make it any clearer or still too many moving parts to make sense of?

rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden objects.

#Loads the packages
library(plyr)
library(dplyr)
library(ggplot2)
library(Kendall)
library(lubridate)
library(xts)
library(TTR)
library(trend)
library(forecast)
library(openxlsx)

#Uses the learningCurve Package from Github:
#https://github.com/AFIT-R/learningCurve
library(learningCurve)

#Only load this if using VS Studio because it changes the plot function
#https://stackoverflow.com/questions/52284345/how-to-show-r-graph-from-visual-studio-code
library(httpgd)
library(languageserver)

#Loads the Excel files to Dataframes and cleans the data
Game_Metrics_Word_Task <- read.xlsx("GamePack_Analytics_ALL_TIME_Short.xlsx", "Boggle")
Game_Metrics_Word_Task <- Game_Metrics_Word_Task %>% filter(grepl('1440', StudyId))
Game_Metrics_Word_Task$DeviceTime <- ymd_hms(Game_Metrics_Word_Task$DeviceTime,  tz = "America/New_York")
Game_Metrics_Word_Task <- Game_Metrics_Word_Task[!duplicated(Game_Metrics_Word_Task[1:2,])]

#Splits the dataframe into a tibble containing each participant
Participant_Word_Task <- split(arrange(Game_Metrics_Word_Task,StudyId,DeviceTime), arrange(Game_Metrics_Word_Task,StudyId,DeviceTime,StudyId,DeviceTime)$StudyId)

#Generates a blank output dataframe
WordFrame <- data.frame(Participant = c(0), Task = c(0), MannKendall_Tau = c(0), MannKendall_P = c(0), Sen_Slope_Value = c(0), Sen_Slope_Pval = c(0), Pettitts_CIV = c(0), Pettitts_Pval = c(0), ARIMA_Model = c(0), Time_to_Petit = c(0), Number_of_Trials_to_Pettitt = c(0), Playtime_to_Petit_seconds = c(0), Time_Start_to_end_days = c(0), Number_of_Total_Trials = c(0), Total_Playtime_seconds = c(0), Learning_rate_days = c(0), Learning_rate_seconds = c(0), Learned_Task = c(0))

#The number of subjects in the xlsx file
#Reduced to 2 for ease of use
for (i in 1:2){
  #This timeseries only includes the trials where the participant completed the task
  success_series <- xts(filter(Participant_Word_Task[[i]], GameEndReason == "TIMER_UP")$NumberOfSuccesfulWords , order.by=as.POSIXct(filter(Participant_Word_Task[[i]], GameEndReason == "TIMER_UP")$DeviceTime))
  #This timeseries includes ALL the trials for the sake of plotting
  original_series <- xts(Participant_Word_Task[[i]]$NumberOfSuccesfulWords, order.by=as.POSIXct(Participant_Word_Task[[i]]$DeviceTime))

  #This is a decomposing process that xts seems to need for plotting.
  #nweeks is needed for xts to plot the x-axis
  success_decomp <- ts(success_series, frequency = nweeks(success_series))
  original_decomp <- ts(original_series, frequency = nweeks(success_series))

  #Values which will be included in the plots
  WordFrame[i,1] <- unique(Participant_Word_Task[[i]]$StudyId)
  WordFrame[i,5] <- sens.slope(success_decomp)$estimates
  WordFrame[i,6] <- sens.slope(success_decomp)$p.value
  WordFrame[i,7] <- pettitt.test(success_decomp)$estimate
  WordFrame[i,8] <- pettitt.test(success_decomp)$p.value

  #The simple moving average that will be overlayed with the plotted data
  simplemovingaverage <- SMA(original_series, n = nweeks(original_series))

  #If the three tests are statistically significant, add a green horizontal like to value WordFrame[i,7]
  #Which would be where the slope changes in the series
  #Fluid variables have been removed from all pdf() and paste() functions for ease-of-use
  if (WordFrame[i,4] <= 0.05 & WordFrame[i,6] <= 0.05 & WordFrame[i,8] <= 0.05){
     {
      pdf(file = "Word_Task_Acquisition.pdf")
      plout <- plot(original_series)
      lines(simplemovingaverage)
      abline(v = index(original_series[WordFrame[i,7]]),lty=2, col='green', lwd=3)
      title(paste("Word Task Acquisition for Subject"))
      dev.off()
     }
  #If the three tests are NOT statistically significant, generate a plot with NO horizontal line at WordFrame[i,7]
  } else {
    {
      pdf(file = "Word_Task_Acquisition.pdf")
      plout <- plot(original_series)
      lines(simplemovingaverage)
      title(paste("Word Task Acquisition for Subject"))
      dev.off()
    }
  }
}

________________________________
From: Rolf Turner <r.turner at auckland.ac.nz>
Sent: Wednesday, October 5, 2022 6:06 AM
To: Deramus, Thomas Patrick <tderamus at partners.org>
Cc: r-help at r-project.org <r-help at r-project.org>
Subject: Re: [R] Getting "Error in ect, plot.new has not been called yet" despite grouping plot call

        External Email - Use Caution

What you doing or trying to do is far too complex for my poor feeble
and senile brain to come anywhere near comprehending.  The code that
you present exceeds my complexity tolerance by many orders of magnitude.

I have a suggestion, but.  Strip your code down to the *essentials*.
Construct a simple sequence of plotting commands, with *simple* names
for the pdf files involved.  You should require only two or three such
files and two or three index levels associated with each of your
nested loops.

Run the stripped down code and the source of the problem will almost
surely become clear.

cheers,

Rolf Turner

On Tue, 4 Oct 2022 23:35:09 +0000
"Deramus, Thomas Patrick" <tderamus at partners.org> wrote:

> Sorry to cross-post on Stackoverflow and here but I'm having some
> difficulty.
> https://secure-web.cisco.com/1_juqv4RvefQFJofsnOQcQA3Ixge89s4uC26pjoPBaYOSxSLGisKtgUTZkanxeHNRqNmjl30B8wYKfsppHje4T8Su77i7t8UbMKzs3GBKEyQva4yTjPH76Q9-l6tT24bB4qNMPQeFAxrkG5lpozNpGrDIAjfKCMvgS-5Qjs-QmvhWZfo84_3SK9rHhJjJvO9CqXb0MewWwI-dEmkZemjxnliGe_D9nooo7Ebjuw0dpBuMnrdaTzQxDdivsbkujPnrGurdjLARh93RW5IWPszNwaoziRD7P-30McF1PrAP8_yjWrhxQ_S3AgG6k40EoQJU/https%3A%2F%2Fstackoverflow.com%2Fquestions%2F73942794%2Fstill-getting-error-in-ect-plot-new-has-not-been-called-yet-despite-grouping
>
> Trying to make a nested loop that produces PDFs off different graphs,
> one for ACF/PACF diagnostics and another for the actual data, based
> on some time-series analyses I'm doing.
>
> Unfortunately, I keep getting the dreaded: Error plot.new has not
> been called yet
>
> The code is meant to write a PDF containing the ACF and PACF graphs,
> then do some analyses on the timeseries, and then make a separate PDF
> containing a plot describing the timeseries based on the p-values of
> each test for each individual.
>
> library(plyr)
> library(dplyr)
> library(ggplot2)
> library(Kendall)
> library(lubridate)
> library(xts)
> library(TTR)
> library(trend)
> library(forecast)
> library(openxlsx)
>
> Game_Metrics_Word_Task <-
> read.xlsx("GamePack_Analytics_ALL_TIME_Short.xlsx", "Boggle")
> Game_Metrics_Word_Task <- Game_Metrics_Word_Task %>%
> filter(grepl('1440', StudyId)) Game_Metrics_Word_Task$DeviceTime <-
> ymd_hms(Game_Metrics_Word_Task$DeviceTime,  tz = "America/New_York")
> Game_Metrics_Word_Task <-
> Game_Metrics_Word_Task[!duplicated(Game_Metrics_Word_Task[1:2,])]
>
> Participant_Word_Task <-
> split(arrange(Game_Metrics_Word_Task,StudyId,DeviceTime),
> arrange(Game_Metrics_Word_Task,StudyId,DeviceTime,StudyId,DeviceTime)$StudyId)
>
> WordFrame <- data.frame(Participant = c(0), Task = c(0),
> MannKendall_Tau = c(0), MannKendall_P = c(0), Sen_Slope_Value = c(0),
> Sen_Slope_Pval = c(0), Pettitts_CIV = c(0), Pettitts_Pval = c(0),
> ARIMA_Model = c(0), Time_to_Petit = c(0), Number_of_Trials_to_Pettitt
> = c(0), Playtime_to_Petit_seconds = c(0), Time_Start_to_end_days =
> c(0), Number_of_Total_Trials = c(0), Total_Playtime_seconds = c(0),
> Learning_rate_days = c(0), Learning_rate_seconds = c(0), Learned_Task
> = c(0))
>
> for (i in 1:length(Participant_Word_Task)){
>     success_series <- xts(filter(Participant_Word_Task[[i]],
> GameEndReason == "TIMER_UP")$NumberOfSuccesfulWords ,
> order.by=as.POSIXct(filter(Participant_Word_Task[[i]], GameEndReason
> == "TIMER_UP")$DeviceTime)) original_series <-
> xts(Participant_Word_Task[[i]]$NumberOfSuccesfulWords,
> order.by=as.POSIXct(Participant_Word_Task[[i]]$DeviceTime))
> success_decomp <- ts(success_series, frequency =
> nweeks(success_series)) original_decomp <- ts(original_series,
> frequency = nweeks(success_series))
>
>     pdf(paste("Word_Task_Autocorrelation_plots_for_subject_",unique(Participant_Word_Task[[i]]$StudyId),".pdf"
> ,collapse = NULL, sep = "")) par(mfrow=c(1,2))
>     Autocorrelationplot <- acf(success_decomp, main=paste(""))
>     PartialAutocorrelationplot <- pacf(success_decomp, main=paste(""))
>     mtext(paste("Word Task Auto and Partialauto correlations for
> subject ",unique(Participant_Word_Task[[i]]$StudyId)), side = 3, line
> = -3, outer = TRUE) dev.off()
>
>     AutomatedArimaoutputs <- auto.arima(success_decomp)
>     p <- length(AutomatedArimaoutputs$model$phi)
>     #AR component
>     q <- length(AutomatedArimaoutputs$model$theta)
>     #MA component
>     d <- AutomatedArimaoutputs$model$Delta
>     #order of difference
>     WordFrame[i,1] <- unique(Participant_Word_Task[[i]]$StudyId)
>     WordFrame[i,2] <- "Word"
>     WordFrame[i,3] <- MannKendall(success_decomp)$tau[1]
>     WordFrame[i,4] <- MannKendall(success_decomp)$sl[1]
>     WordFrame[i,5] <- sens.slope(success_decomp)$estimates
>     WordFrame[i,6] <- sens.slope(success_decomp)$p.value
>     WordFrame[i,7] <- pettitt.test(success_decomp)$estimate
>     WordFrame[i,8] <- pettitt.test(success_decomp)$p.value
>     WordFrame[i,9] <- paste("ARIMA(",p,",",q,",",d,")", collapse =
> NULL, sep = "") WordFrame[i,10] <-
> difftime(time(success_series[WordFrame[i,7]]),time(original_series[1]))
> WordFrame[i,11] <- tail(which(grepl(success_series[WordFrame[i,7]],
> original_series)), n=1) WordFrame[i,12] <-
> sum(Participant_Word_Task[[i]]$TotalDuration[1:WordFrame[i,11]])-sum(Participant_Word_Task[[i]]$TotalTimePaused[1:WordFrame[i,11]])
> WordFrame[i,13] <-
> difftime(time(original_series[length(original_series)]),time(original_series[1]))
> WordFrame[i,14] <- length(original_series) WordFrame[i,15] <-
> sum(Participant_Word_Task[[i]]$TotalDuration[1:length(original_series)])-sum(Participant_Word_Task[[i]]$TotalTimePaused[1:length(original_series)])
>
>
>     simplemovingaverage <- SMA(original_series, n =
> nweeks(original_series))
>
>     if (WordFrame[i,4] <= 0.05 & WordFrame[i,6] <= 0.05 &
> WordFrame[i,8] <= 0.05){ {
>               pdf(paste(WordFrame[i,1],"_Word_Task_Acquisition.pdf",collapse
> = NULL, sep = "")) plout <-
> plot(original_series,type='l',col='blue',xlab="Date of
> Play",ylab="Number of Successful Words")
> lines(simplemovingaverage,type='l',col='red') title(paste("Word Task
> Acquisition for Subject", WordFrame[i,1])) abline(v =
> index(original_series[WordFrame[i,7]]),lty=2, col='green', lwd=3)
> dev.off() } WordFrame[i,18] <- T
>               WordFrame[i,16] <- (1-(WordFrame[i,10]/WordFrame[i,13]))
>               WordFrame[i,17] <- (1-(WordFrame[i,12]/WordFrame[i,15]))
>     } else {
>               {
>               pdf(paste(WordFrame[i,1],"_Word_Task_Acquisition.pdf",collapse
> = NULL, sep = "")) plout <-
> plot(original_series,type='l',col='blue',xlab="Date of
> Play",ylab="Number of Successful Words")
> lines(simplemovingaverage,type='l',col='red') title(paste("Word Task
> Acquisition for Subject", WordFrame[i,1])) dev.off() }
>               WordFrame[i,18] <- F
>               WordFrame[i,16] <- 0
>               WordFrame[i,17] <- 0
>     }
> }
>
> It will work just fine if I run the lines individually (e.g. set i =
> 1, 2, ect), and if I comment out abline and title (lines seems to
> work fine). But it will throw the error everytime I try to run the
> loop without these commented.
>
> Have tried just about everything I could find on the Stack forums to
> run everything as a single argument and I'm just not sure what is
> wrong with it.
>
> dev.list() spits out:
>
> pdf
>   2
> following the error.
>
> With abline and title commented out and lines run individually it's
> NULL.
>
> Happens in both RStudio
>
> 2022.07.2+576 "Spotted Wakerobin" Release
> (e7373ef832b49b2a9b88162cfe7eac5f22c40b34, 2022-09-06) for Ubuntu
> Bionic Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML,
> like Gecko) QtWebEngine/5.12.8 Chrome/69.0.3497.128 Safari/537.36
>
> And R:
>
> platform       x86_64-pc-linux-gnu
> arch           x86_64
> os             linux-gnu
> system         x86_64, linux-gnu
> status
> major          4
> minor          2.1
> year           2022
> month          06
> day            23
> svn rev        82513
> language       R
> version.string R version 4.2.1 (2022-06-23)
> nickname       Funny-Looking Kid
>
>
> My OS:
> PRETTY_NAME="Debian GNU/Linux 11 (bullseye)"
> NAME="Debian GNU/Linux"
> VERSION_ID="11"
> VERSION="11 (bullseye)"
> VERSION_CODENAME=bullseye
> ID=debian
> HOME_URL="https://secure-web.cisco.com/1Ruvt90Q90ixR-GE-RDiKJgzRpfDjlNz-lZTqQQGM8Tf4GAoj5QOfE2vXMaMWxMoexuf1npQrX7uAjFuU2viz28h42RPmHQK7jGDX7BpRLkTNcERyxHVKJTxgYegXo-n9N7rqegcKsrr47xlGmTcMOJcBAqH7SpTPQlYDOGgjz1ErtetQRzUsd-eKs9l4oCVPiF6SKV40C7s_NXm0tuCswL2Jhyfv70-edCtBO_4j9-3dSi5ZdFLYaWsMScnwwxNIGYU2n0vw5NH4GJcZNsv6Scu-r6W8ndJaGL4UmX9J3PX0LrdFyjLbGtA7RqPpKFUQ/https%3A%2F%2Fwww.debian.org"
> SUPPORT_URL="https://secure-web.cisco.com/1gveQttVrJNRSM85857IiydpLraxrrtJobMyCNkRvQ4V2f00DH67Z0hEa50LLpCVYQvIjMsQZxHAVMZvYQV_Cp2-e82TDZzPY4aSR2td2th3bwuXGxtI7CTgSUudOWgPpmnwVLT5r34EnwXEmwnMoiPVnOEC7slpF1fLGq11wSynuyttcTagMfpN6qdYfgtbu_mz0JOBUecQ-etUQYw5BDmXEKv5JZ_y5Uyt8Q89Kirhi7Hk8FMbCVcxRZpOZZmghxlPMxYaNVIOnln-R0H8J2QIzqE49cQQPKkFZ9O29zpr8odlBXqjObKn24ReYPDhH/https%3A%2F%2Fwww.debian.org%2Fsupport"
> BUG_REPORT_URL="https://secure-web.cisco.com/1tepDnCjDgHsmvw9Eth-7nfyKi3doVSOFKVzz83wskdyf8lsrEVkG2NYw7am6ePhSFfjQXdDyceMyc21Un-vqTirSQYKdPavRdKJy85HgHMP66Xk-OgxFf-5KXiPzmFreDfuuJlYizGSUNOLcADyNVTCo47xFfRgtB83Hs8j3yYAJFrff7TqNOFWzSzTcfrycio_WSSfbQkLpUl-1xGzg-dvP16tKuwkRr62bkPeydXJC_iH1FfnWv5b1G04au3aFmRTem8t2RS40LPMS9Mh0UmMvHD_9qwX16cFMHQ8U4x9Sp9IUcAFhgnbffOyPQm1C/https%3A%2F%2Fbugs.debian.org"
> No LSB modules are available.
> Distributor ID:???Debian
> Description:??????Debian GNU/Linux 11 (bullseye)
> Release:????11
> Codename:???bullseye
>          Icon name: computer-desktop
>            Chassis: desktop
>         Machine ID: 053ebf23707f49c8ad4e0684f4cf19d3
>            Boot ID: d0e6294d3b944286bef10e76c21e6401
>   Operating System: Debian GNU/Linux 11 (bullseye)
>             Kernel: Linux 5.10.0-18-amd64
>       Architecture: x86-64
>
>
> Any suggestions would be greatly appreciated.
>
> --
>
> Thomas DeRamus (He/Him/His)
>
> Data Analyst
>
> Massachusetts General Hospital Brigham
>
> Alzheimer?s Clinical & Translational Research Unit
>
> 149 13th Street
>
> Charlestown, MA 02129
>
> Phone: 205-834-5066
>
> Email: tderamus at partners.org<mailto:tderamus at partners.org>,
> tpderamus at gmail.com<mailto:tpderamus at gmail.com>
>
>
> [https://secure-web.cisco.com/1AI4S4rz4bDZGM8naa-19GTAeSORO5ZmNe056Q_nhPRk4JVAzPiRKUBWitBK5TpxoKBLoLvNfoMDanGd1n5Bnf4SJFT7l7HnaLcjjH7oVk2BZdDfCLHo8a8eePvD4XrF2Fw3iuxKgIZY5dwdesP3P8pSvkmVGvyZ-HiEKRetk4uJHhRa6gSgOQ8MbCVKmi6XP1dtozTEH1RpDrFJ4EyevPO52UzaTAY6CR8USLWNbsxXJsnsjUz1G6_4P7B3ULuMu9mEPeQz_GnTrSXTrGZooK_idhoEougti7I8NYV0CS09Yahmp4Fe_vh9wu4Jkdal3/https%3A%2F%2Fci3.googleusercontent.com%2Fmail-sig%2FAIorK4we2sU30P2HyfDQF5hpEjYTt-9FTBK7cAVsP7EenrZ0nsKCf48fuYMtElj6Szn_2fpSPWr66eQ][https://ci3.googleusercontent.com/mail-sig/AIorK4yyY0DlImU0UONJrHTbPc5T3lJj8Kmu8SbDKJJ3XjcX6CgvVsvSueYKwficYFz4zXt6fZV8YIY]
>
> ?If knowledge can create problems, it is not through ignorance that
> we can solve them.?
>
> ?Issac Asimov

The information in this e-mail is intended only for the person to whom it is addressed.  If you believe this e-mail was sent to you in error and the e-mail contains patient information, please contact the Mass General Brigham Compliance HelpLine at https://www.massgeneralbrigham.org/complianceline <https://www.massgeneralbrigham.org/complianceline> .
Please note that this e-mail is not secure (encrypted).  If you do not wish to continue communication over unencrypted e-mail, please notify the sender of this message immediately.  Continuing to send or respond to e-mail after receiving this message means you understand and accept this risk and wish to continue to communicate over unencrypted e-mail. 

From tder@mu@ @end|ng |rom p@rtner@@org  Thu Oct  6 02:38:51 2022
From: tder@mu@ @end|ng |rom p@rtner@@org (Deramus, Thomas Patrick)
Date: Thu, 6 Oct 2022 00:38:51 +0000
Subject: [R] Getting "Error in ect,
 plot.new has not been called yet" despite grouping plot call
In-Reply-To: <20221006112802.6897cd27@rolf-Latitude-E7470>
References: <PH0PR04MB7493E39389D0196BEC260CB6BE5A9@PH0PR04MB7493.namprd04.prod.outlook.com>
 <20221005230608.793c8b9f@rolf-Latitude-E7470>
 <PH0PR04MB7493CE9332F02B56C0AFE31FBE5D9@PH0PR04MB7493.namprd04.prod.outlook.com>
 <20221006112802.6897cd27@rolf-Latitude-E7470>
Message-ID: <PH0PR04MB7493C8F0A1BA20AF9840BCD0BE5C9@PH0PR04MB7493.namprd04.prod.outlook.com>

Odd. Thought I had attached it.

Would love to go that route, but the problem is a lot of the sub-bits are actually dependent on the values of the timeseries analysis, which has its own dependencies......

Would using the following link to download the excel file help at all?
https://docs.google.com/spreadsheets/d/1rPd8bv4WADCdEUhmem-u1-6HWUXKne7b/edit?usp=sharing&ouid=110307531005009211602&rtpof=true&sd=true


________________________________
From: Rolf Turner <r.turner at auckland.ac.nz>
Sent: Wednesday, October 5, 2022 6:28 PM
To: Deramus, Thomas Patrick <tderamus at partners.org>
Cc: r-help at r-project.org <r-help at r-project.org>
Subject: Re: [R] Getting "Error in ect, plot.new has not been called yet" despite grouping plot call

        External Email - Use Caution


Your code is still much too complex for my feeble brain.

Without trying to understand very much, I get the impression that the
example is *not* reproducible.  It requires reading in Excel (yeucchh!)
files to which no-one but you has access.

Skip the reading-in completely.  Create toy data using rnorm() instead.
Then someone may be able to help you.

On Wed, 5 Oct 2022 13:32:00 +0000
"Deramus, Thomas Patrick" <tderamus at partners.org> wrote:

> Hi Rolf.
>
> I followed your suggestion (though it's probably not as trimmed as it
> could be), but the problem unfortunately persists.

If the problem *didn't* persist, then *that* would have been
unfortunate!  The idea is to reproduce the problem in a simpler context
so that one can deduce what is causing the problem!

> Does this make it any clearer or still too many moving parts to make
> sense of?

There are still (far) too many moving parts, for me anyway.  Someone
cleverer than I might be able to see what the problem is.

cheers,

Rolf

>
> rm(list = ls(all.names = TRUE)) #will clear all objects includes
> hidden objects.
>
> #Loads the packages
> library(plyr)
> library(dplyr)
> library(ggplot2)
> library(Kendall)
> library(lubridate)
> library(xts)
> library(TTR)
> library(trend)
> library(forecast)
> library(openxlsx)
>
> #Uses the learningCurve Package from Github:
> #https://secure-web.cisco.com/1GUXNs4DRqUHykKAjZUB89_m2M_KU7oUJ6jl9VAWbtn8YCzSy8qRCHe-LJf3ovhQXKpQcXQe9Bf_BwKHFn4-A8AvtoD_tuXR-jsEcSsEQp-B3sET59hXmBKs_B1M7u2zUxnGNqVZnxYNeip71STXGupngENp0IjZfxd48SZHkztp5CLHFpsdHgz7wHHwePlSTMG8yKmYcS7N6OSkoxENvsL-vCxACXlyPFQTynaQNNjFjV7Ngl8mJpBP0G8pXX8WbogbQlE9ArbYCph6j_3IoVIN8Y6dKqRe44yoi8S3hjJ1PFgdr4JW7nve07XYaC_M-/https%3A%2F%2Fgithub.com%2FAFIT-R%2FlearningCurve
> library(learningCurve)
>
> #Only load this if using VS Studio because it changes the plot
> function
> #https://secure-web.cisco.com/14TdkUQ3Ymy411VwAMhagZmvgDM4nborDvLmLccRSdK1n3ZgXfjjdH9Xn1dVxO2s5Y9R4fZJoitgys453O-kPVFt73W5s3Qa_D078MPMxoTGV6UP55ozAuPwt9nzMGBqak6abbcX1Er2q8CwEMGQJA8AmcdQf0GyGCz8b1qYV-ck9_L4N-Yq5eTWLs2NHrklR0XpUzWvbUBGRH2LpeWPHRLtMZjW8-9T3_1sGyvCHTXDhQ-FXzifBiFtE13_qL50iO1kl8A6p3EeOR0e0-AgW-kGEfpBHGgA53VBlscnA9nqfb60sCgLaAeMz-Pc49ITI/https%3A%2F%2Fstackoverflow.com%2Fquestions%2F52284345%2Fhow-to-show-r-graph-from-visual-studio-code
> library(httpgd) library(languageserver)
>
> #Loads the Excel files to Dataframes and cleans the data
> Game_Metrics_Word_Task <-
> read.xlsx("GamePack_Analytics_ALL_TIME_Short.xlsx", "Boggle")
> Game_Metrics_Word_Task <- Game_Metrics_Word_Task %>%
> filter(grepl('1440', StudyId)) Game_Metrics_Word_Task$DeviceTime <-
> ymd_hms(Game_Metrics_Word_Task$DeviceTime,  tz = "America/New_York")
> Game_Metrics_Word_Task <-
> Game_Metrics_Word_Task[!duplicated(Game_Metrics_Word_Task[1:2,])]
>
> #Splits the dataframe into a tibble containing each participant
> Participant_Word_Task <-
> split(arrange(Game_Metrics_Word_Task,StudyId,DeviceTime),
> arrange(Game_Metrics_Word_Task,StudyId,DeviceTime,StudyId,DeviceTime)$StudyId)
>
> #Generates a blank output dataframe
> WordFrame <- data.frame(Participant = c(0), Task = c(0),
> MannKendall_Tau = c(0), MannKendall_P = c(0), Sen_Slope_Value = c(0),
> Sen_Slope_Pval = c(0), Pettitts_CIV = c(0), Pettitts_Pval = c(0),
> ARIMA_Model = c(0), Time_to_Petit = c(0), Number_of_Trials_to_Pettitt
> = c(0), Playtime_to_Petit_seconds = c(0), Time_Start_to_end_days =
> c(0), Number_of_Total_Trials = c(0), Total_Playtime_seconds = c(0),
> Learning_rate_days = c(0), Learning_rate_seconds = c(0), Learned_Task
> = c(0))
>
> #The number of subjects in the xlsx file
> #Reduced to 2 for ease of use
> for (i in 1:2){
>   #This timeseries only includes the trials where the participant
> completed the task success_series <-
> xts(filter(Participant_Word_Task[[i]], GameEndReason ==
> "TIMER_UP")$NumberOfSuccesfulWords ,
> order.by=as.POSIXct(filter(Participant_Word_Task[[i]], GameEndReason
> == "TIMER_UP")$DeviceTime)) #This timeseries includes ALL the trials
> for the sake of plotting original_series <-
> xts(Participant_Word_Task[[i]]$NumberOfSuccesfulWords,
> order.by=as.POSIXct(Participant_Word_Task[[i]]$DeviceTime))
>
>   #This is a decomposing process that xts seems to need for plotting.
>   #nweeks is needed for xts to plot the x-axis
>   success_decomp <- ts(success_series, frequency =
> nweeks(success_series)) original_decomp <- ts(original_series,
> frequency = nweeks(success_series))
>
>   #Values which will be included in the plots
>   WordFrame[i,1] <- unique(Participant_Word_Task[[i]]$StudyId)
>   WordFrame[i,5] <- sens.slope(success_decomp)$estimates
>   WordFrame[i,6] <- sens.slope(success_decomp)$p.value
>   WordFrame[i,7] <- pettitt.test(success_decomp)$estimate
>   WordFrame[i,8] <- pettitt.test(success_decomp)$p.value
>
>   #The simple moving average that will be overlayed with the plotted
> data simplemovingaverage <- SMA(original_series, n =
> nweeks(original_series))
>
>   #If the three tests are statistically significant, add a green
> horizontal like to value WordFrame[i,7] #Which would be where the
> slope changes in the series #Fluid variables have been removed from
> all pdf() and paste() functions for ease-of-use if (WordFrame[i,4] <=
> 0.05 & WordFrame[i,6] <= 0.05 & WordFrame[i,8] <= 0.05){ {
>       pdf(file = "Word_Task_Acquisition.pdf")
>       plout <- plot(original_series)
>       lines(simplemovingaverage)
>       abline(v = index(original_series[WordFrame[i,7]]),lty=2,
> col='green', lwd=3) title(paste("Word Task Acquisition for Subject"))
>       dev.off()
>      }
>   #If the three tests are NOT statistically significant, generate a
> plot with NO horizontal line at WordFrame[i,7] } else {
>     {
>       pdf(file = "Word_Task_Acquisition.pdf")
>       plout <- plot(original_series)
>       lines(simplemovingaverage)
>       title(paste("Word Task Acquisition for Subject"))
>       dev.off()
>     }
>   }
> }
>
> ________________________________
> From: Rolf Turner <r.turner at auckland.ac.nz>
> Sent: Wednesday, October 5, 2022 6:06 AM
> To: Deramus, Thomas Patrick <tderamus at partners.org>
> Cc: r-help at r-project.org <r-help at r-project.org>
> Subject: Re: [R] Getting "Error in ect, plot.new has not been called
> yet" despite grouping plot call
>
>         External Email - Use Caution
>
> What you doing or trying to do is far too complex for my poor feeble
> and senile brain to come anywhere near comprehending.  The code that
> you present exceeds my complexity tolerance by many orders of
> magnitude.
>
> I have a suggestion, but.  Strip your code down to the *essentials*.
> Construct a simple sequence of plotting commands, with *simple* names
> for the pdf files involved.  You should require only two or three such
> files and two or three index levels associated with each of your
> nested loops.
>
> Run the stripped down code and the source of the problem will almost
> surely become clear.
>
> cheers,
>
> Rolf Turner
>
> On Tue, 4 Oct 2022 23:35:09 +0000
> "Deramus, Thomas Patrick" <tderamus at partners.org> wrote:
>
> > Sorry to cross-post on Stackoverflow and here but I'm having some
> > difficulty.
> > https://secure-web.cisco.com/1_juqv4RvefQFJofsnOQcQA3Ixge89s4uC26pjoPBaYOSxSLGisKtgUTZkanxeHNRqNmjl30B8wYKfsppHje4T8Su77i7t8UbMKzs3GBKEyQva4yTjPH76Q9-l6tT24bB4qNMPQeFAxrkG5lpozNpGrDIAjfKCMvgS-5Qjs-QmvhWZfo84_3SK9rHhJjJvO9CqXb0MewWwI-dEmkZemjxnliGe_D9nooo7Ebjuw0dpBuMnrdaTzQxDdivsbkujPnrGurdjLARh93RW5IWPszNwaoziRD7P-30McF1PrAP8_yjWrhxQ_S3AgG6k40EoQJU/https%3A%2F%2Fstackoverflow.com%2Fquestions%2F73942794%2Fstill-getting-error-in-ect-plot-new-has-not-been-called-yet-despite-grouping
> >
> > Trying to make a nested loop that produces PDFs off different
> > graphs, one for ACF/PACF diagnostics and another for the actual
> > data, based on some time-series analyses I'm doing.
> >
> > Unfortunately, I keep getting the dreaded: Error plot.new has not
> > been called yet
> >
> > The code is meant to write a PDF containing the ACF and PACF graphs,
> > then do some analyses on the timeseries, and then make a separate
> > PDF containing a plot describing the timeseries based on the
> > p-values of each test for each individual.
> >
> > library(plyr)
> > library(dplyr)
> > library(ggplot2)
> > library(Kendall)
> > library(lubridate)
> > library(xts)
> > library(TTR)
> > library(trend)
> > library(forecast)
> > library(openxlsx)
> >
> > Game_Metrics_Word_Task <-
> > read.xlsx("GamePack_Analytics_ALL_TIME_Short.xlsx", "Boggle")
> > Game_Metrics_Word_Task <- Game_Metrics_Word_Task %>%
> > filter(grepl('1440', StudyId)) Game_Metrics_Word_Task$DeviceTime <-
> > ymd_hms(Game_Metrics_Word_Task$DeviceTime,  tz = "America/New_York")
> > Game_Metrics_Word_Task <-
> > Game_Metrics_Word_Task[!duplicated(Game_Metrics_Word_Task[1:2,])]
> >
> > Participant_Word_Task <-
> > split(arrange(Game_Metrics_Word_Task,StudyId,DeviceTime),
> > arrange(Game_Metrics_Word_Task,StudyId,DeviceTime,StudyId,DeviceTime)$StudyId)
> >
> > WordFrame <- data.frame(Participant = c(0), Task = c(0),
> > MannKendall_Tau = c(0), MannKendall_P = c(0), Sen_Slope_Value =
> > c(0), Sen_Slope_Pval = c(0), Pettitts_CIV = c(0), Pettitts_Pval =
> > c(0), ARIMA_Model = c(0), Time_to_Petit = c(0),
> > Number_of_Trials_to_Pettitt = c(0), Playtime_to_Petit_seconds =
> > c(0), Time_Start_to_end_days = c(0), Number_of_Total_Trials = c(0),
> > Total_Playtime_seconds = c(0), Learning_rate_days = c(0),
> > Learning_rate_seconds = c(0), Learned_Task = c(0))
> >
> > for (i in 1:length(Participant_Word_Task)){
> >     success_series <- xts(filter(Participant_Word_Task[[i]],
> > GameEndReason == "TIMER_UP")$NumberOfSuccesfulWords ,
> > order.by=as.POSIXct(filter(Participant_Word_Task[[i]], GameEndReason
> > == "TIMER_UP")$DeviceTime)) original_series <-
> > xts(Participant_Word_Task[[i]]$NumberOfSuccesfulWords,
> > order.by=as.POSIXct(Participant_Word_Task[[i]]$DeviceTime))
> > success_decomp <- ts(success_series, frequency =
> > nweeks(success_series)) original_decomp <- ts(original_series,
> > frequency = nweeks(success_series))
> >
> >     pdf(paste("Word_Task_Autocorrelation_plots_for_subject_",unique(Participant_Word_Task[[i]]$StudyId),".pdf"
> > ,collapse = NULL, sep = "")) par(mfrow=c(1,2))
> >     Autocorrelationplot <- acf(success_decomp, main=paste(""))
> >     PartialAutocorrelationplot <- pacf(success_decomp,
> > main=paste("")) mtext(paste("Word Task Auto and Partialauto
> > correlations for subject
> > ",unique(Participant_Word_Task[[i]]$StudyId)), side = 3, line = -3,
> > outer = TRUE) dev.off()
> >
> >     AutomatedArimaoutputs <- auto.arima(success_decomp)
> >     p <- length(AutomatedArimaoutputs$model$phi)
> >     #AR component
> >     q <- length(AutomatedArimaoutputs$model$theta)
> >     #MA component
> >     d <- AutomatedArimaoutputs$model$Delta
> >     #order of difference
> >     WordFrame[i,1] <- unique(Participant_Word_Task[[i]]$StudyId)
> >     WordFrame[i,2] <- "Word"
> >     WordFrame[i,3] <- MannKendall(success_decomp)$tau[1]
> >     WordFrame[i,4] <- MannKendall(success_decomp)$sl[1]
> >     WordFrame[i,5] <- sens.slope(success_decomp)$estimates
> >     WordFrame[i,6] <- sens.slope(success_decomp)$p.value
> >     WordFrame[i,7] <- pettitt.test(success_decomp)$estimate
> >     WordFrame[i,8] <- pettitt.test(success_decomp)$p.value
> >     WordFrame[i,9] <- paste("ARIMA(",p,",",q,",",d,")", collapse =
> > NULL, sep = "") WordFrame[i,10] <-
> > difftime(time(success_series[WordFrame[i,7]]),time(original_series[1]))
> > WordFrame[i,11] <- tail(which(grepl(success_series[WordFrame[i,7]],
> > original_series)), n=1) WordFrame[i,12] <-
> > sum(Participant_Word_Task[[i]]$TotalDuration[1:WordFrame[i,11]])-sum(Participant_Word_Task[[i]]$TotalTimePaused[1:WordFrame[i,11]])
> > WordFrame[i,13] <-
> > difftime(time(original_series[length(original_series)]),time(original_series[1]))
> > WordFrame[i,14] <- length(original_series) WordFrame[i,15] <-
> > sum(Participant_Word_Task[[i]]$TotalDuration[1:length(original_series)])-sum(Participant_Word_Task[[i]]$TotalTimePaused[1:length(original_series)])
> >
> >
> >     simplemovingaverage <- SMA(original_series, n =
> > nweeks(original_series))
> >
> >     if (WordFrame[i,4] <= 0.05 & WordFrame[i,6] <= 0.05 &
> > WordFrame[i,8] <= 0.05){ {
> >               pdf(paste(WordFrame[i,1],"_Word_Task_Acquisition.pdf",collapse
> > = NULL, sep = "")) plout <-
> > plot(original_series,type='l',col='blue',xlab="Date of
> > Play",ylab="Number of Successful Words")
> > lines(simplemovingaverage,type='l',col='red') title(paste("Word Task
> > Acquisition for Subject", WordFrame[i,1])) abline(v =
> > index(original_series[WordFrame[i,7]]),lty=2, col='green', lwd=3)
> > dev.off() } WordFrame[i,18] <- T
> >               WordFrame[i,16] <-
> > (1-(WordFrame[i,10]/WordFrame[i,13])) WordFrame[i,17] <-
> > (1-(WordFrame[i,12]/WordFrame[i,15])) } else {
> >               {
> >               pdf(paste(WordFrame[i,1],"_Word_Task_Acquisition.pdf",collapse
> > = NULL, sep = "")) plout <-
> > plot(original_series,type='l',col='blue',xlab="Date of
> > Play",ylab="Number of Successful Words")
> > lines(simplemovingaverage,type='l',col='red') title(paste("Word Task
> > Acquisition for Subject", WordFrame[i,1])) dev.off() }
> >               WordFrame[i,18] <- F
> >               WordFrame[i,16] <- 0
> >               WordFrame[i,17] <- 0
> >     }
> > }
> >
> > It will work just fine if I run the lines individually (e.g. set i =
> > 1, 2, ect), and if I comment out abline and title (lines seems to
> > work fine). But it will throw the error everytime I try to run the
> > loop without these commented.
> >
> > Have tried just about everything I could find on the Stack forums to
> > run everything as a single argument and I'm just not sure what is
> > wrong with it.
> >
> > dev.list() spits out:
> >
> > pdf
> >   2
> > following the error.
> >
> > With abline and title commented out and lines run individually it's
> > NULL.
> >
> > Happens in both RStudio
> >
> > 2022.07.2+576 "Spotted Wakerobin" Release
> > (e7373ef832b49b2a9b88162cfe7eac5f22c40b34, 2022-09-06) for Ubuntu
> > Bionic Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML,
> > like Gecko) QtWebEngine/5.12.8 Chrome/69.0.3497.128 Safari/537.36
> >
> > And R:
> >
> > platform       x86_64-pc-linux-gnu
> > arch           x86_64
> > os             linux-gnu
> > system         x86_64, linux-gnu
> > status
> > major          4
> > minor          2.1
> > year           2022
> > month          06
> > day            23
> > svn rev        82513
> > language       R
> > version.string R version 4.2.1 (2022-06-23)
> > nickname       Funny-Looking Kid
> >
> >
> > My OS:
> > PRETTY_NAME="Debian GNU/Linux 11 (bullseye)"
> > NAME="Debian GNU/Linux"
> > VERSION_ID="11"
> > VERSION="11 (bullseye)"
> > VERSION_CODENAME=bullseye
> > ID=debian
> > HOME_URL="https://secure-web.cisco.com/1Ruvt90Q90ixR-GE-RDiKJgzRpfDjlNz-lZTqQQGM8Tf4GAoj5QOfE2vXMaMWxMoexuf1npQrX7uAjFuU2viz28h42RPmHQK7jGDX7BpRLkTNcERyxHVKJTxgYegXo-n9N7rqegcKsrr47xlGmTcMOJcBAqH7SpTPQlYDOGgjz1ErtetQRzUsd-eKs9l4oCVPiF6SKV40C7s_NXm0tuCswL2Jhyfv70-edCtBO_4j9-3dSi5ZdFLYaWsMScnwwxNIGYU2n0vw5NH4GJcZNsv6Scu-r6W8ndJaGL4UmX9J3PX0LrdFyjLbGtA7RqPpKFUQ/https%3A%2F%2Fwww.debian.org"
> > SUPPORT_URL="https://secure-web.cisco.com/1gveQttVrJNRSM85857IiydpLraxrrtJobMyCNkRvQ4V2f00DH67Z0hEa50LLpCVYQvIjMsQZxHAVMZvYQV_Cp2-e82TDZzPY4aSR2td2th3bwuXGxtI7CTgSUudOWgPpmnwVLT5r34EnwXEmwnMoiPVnOEC7slpF1fLGq11wSynuyttcTagMfpN6qdYfgtbu_mz0JOBUecQ-etUQYw5BDmXEKv5JZ_y5Uyt8Q89Kirhi7Hk8FMbCVcxRZpOZZmghxlPMxYaNVIOnln-R0H8J2QIzqE49cQQPKkFZ9O29zpr8odlBXqjObKn24ReYPDhH/https%3A%2F%2Fwww.debian.org%2Fsupport"
> > BUG_REPORT_URL="https://secure-web.cisco.com/1tepDnCjDgHsmvw9Eth-7nfyKi3doVSOFKVzz83wskdyf8lsrEVkG2NYw7am6ePhSFfjQXdDyceMyc21Un-vqTirSQYKdPavRdKJy85HgHMP66Xk-OgxFf-5KXiPzmFreDfuuJlYizGSUNOLcADyNVTCo47xFfRgtB83Hs8j3yYAJFrff7TqNOFWzSzTcfrycio_WSSfbQkLpUl-1xGzg-dvP16tKuwkRr62bkPeydXJC_iH1FfnWv5b1G04au3aFmRTem8t2RS40LPMS9Mh0UmMvHD_9qwX16cFMHQ8U4x9Sp9IUcAFhgnbffOyPQm1C/https%3A%2F%2Fbugs.debian.org"
> > No LSB modules are available.
> > Distributor ID:   Debian
> > Description:      Debian GNU/Linux 11 (bullseye)
> > Release:    11
> > Codename:   bullseye
> >          Icon name: computer-desktop
> >            Chassis: desktop
> >         Machine ID: 053ebf23707f49c8ad4e0684f4cf19d3
> >            Boot ID: d0e6294d3b944286bef10e76c21e6401
> >   Operating System: Debian GNU/Linux 11 (bullseye)
> >             Kernel: Linux 5.10.0-18-amd64
> >       Architecture: x86-64
> >
> >
> > Any suggestions would be greatly appreciated.
> >
> > --
> >
> > Thomas DeRamus (He/Him/His)
> >
> > Data Analyst
> >
> > Massachusetts General Hospital Brigham
> >
> > Alzheimer's Clinical & Translational Research Unit
> >
> > 149 13th Street
> >
> > Charlestown, MA 02129
> >
> > Phone: 205-834-5066
> >
> > Email: tderamus at partners.org<mailto:tderamus at partners.org>,
> > tpderamus at gmail.com<mailto:tpderamus at gmail.com>
> >
> >
> > [https://secure-web.cisco.com/1AI4S4rz4bDZGM8naa-19GTAeSORO5ZmNe056Q_nhPRk4JVAzPiRKUBWitBK5TpxoKBLoLvNfoMDanGd1n5Bnf4SJFT7l7HnaLcjjH7oVk2BZdDfCLHo8a8eePvD4XrF2Fw3iuxKgIZY5dwdesP3P8pSvkmVGvyZ-HiEKRetk4uJHhRa6gSgOQ8MbCVKmi6XP1dtozTEH1RpDrFJ4EyevPO52UzaTAY6CR8USLWNbsxXJsnsjUz1G6_4P7B3ULuMu9mEPeQz_GnTrSXTrGZooK_idhoEougti7I8NYV0CS09Yahmp4Fe_vh9wu4Jkdal3/https://ci3.googleusercontent.com/mail-sig/AIorK4we2sU30P2HyfDQF5hpEjYTt-9FTBK7cAVsP7EenrZ0nsKCf48fuYMtElj6Szn_2fpSPWr66eQ][https://ci3.googleusercontent.com/mail-sig/AIorK4yyY0DlImU0UONJrHTbPc5T3lJj8Kmu8SbDKJJ3XjcX6CgvVsvSueYKwficYFz4zXt6fZV8YIY]
> >
> > "If knowledge can create problems, it is not through ignorance that
> > we can solve them."
> >
> > -Issac Asimo

The information in this e-mail is intended only for the ...{{dropped:14}}


From tder@mu@ @end|ng |rom p@rtner@@org  Thu Oct  6 03:32:31 2022
From: tder@mu@ @end|ng |rom p@rtner@@org (Deramus, Thomas Patrick)
Date: Thu, 6 Oct 2022 01:32:31 +0000
Subject: [R] Getting "Error in ect,
 plot.new has not been called yet" despite grouping plot call
In-Reply-To: <CAPPM_gRn-HVg2oc8fkNDsJtqm1VSpa4C68z0tCHxPN7b7qQWEw@mail.gmail.com>
References: <PH0PR04MB7493E39389D0196BEC260CB6BE5A9@PH0PR04MB7493.namprd04.prod.outlook.com>
 <CAPPM_gRn-HVg2oc8fkNDsJtqm1VSpa4C68z0tCHxPN7b7qQWEw@mail.gmail.com>
Message-ID: <PH0PR04MB74936D008822D2D660E2392ABE5C9@PH0PR04MB7493.namprd04.prod.outlook.com>

I had to place it right before the title and abline functions like so:

for (i in 1:length(Participant_Word_Task)){
    success_series <- xts(filter(Participant_Word_Task[[i]], GameEndReason == "TIMER_UP")$NumberOfSuccesfulWords , order.by=as.POSIXct(filter(Participant_Word_Task[[i]], GameEndReason == "TIMER_UP")$DeviceTime))
    original_series <- xts(Participant_Word_Task[[i]]$NumberOfSuccesfulWords, order.by=as.POSIXct(Participant_Word_Task[[i]]$DeviceTime))
    success_decomp <- ts(success_series, frequency = nweeks(success_series))
    original_decomp <- ts(original_series, frequency = nweeks(success_series))
    WordFrame[i,1] <- unique(Participant_Word_Task[[i]]$StudyId)
    WordFrame[i,2] <- "Boggle"
    WordFrame[i,3] <- MannKendall(success_decomp)$tau[1]
    WordFrame[i,4] <- MannKendall(success_decomp)$sl[1]
    WordFrame[i,5] <- sens.slope(success_decomp)$estimates
    WordFrame[i,6] <- sens.slope(success_decomp)$p.value
    WordFrame[i,7] <- pettitt.test(success_decomp)$estimate
    WordFrame[i,8] <- pettitt.test(success_decomp)$p.value
    WordFrame[i,10] <- difftime(time(success_series[WordFrame[i,7]]),time(original_series[1]))
    WordFrame[i,11] <- tail(which(grepl(success_series[WordFrame[i,7]], original_series)), n=1)
    WordFrame[i,12] <- sum(Participant_Word_Task[[i]]$TotalDuration[1:WordFrame[i,11]])-sum(Participant_Word_Task[[i]]$TotalTimePaused[1:WordFrame[i,11]])
    WordFrame[i,13] <- difftime(time(original_series[length(original_series)]),time(original_series[1]))
    WordFrame[i,14] <- length(original_series)
    WordFrame[i,15] <- sum(Participant_Word_Task[[i]]$TotalDuration[1:length(original_series)])-sum(Participant_Word_Task[[i]]$TotalTimePaused[1:length(original_series)])


    simplemovingaverage <- SMA(original_series, n = nweeks(original_series))
    if (WordFrame[i,4] <= 0.05 & WordFrame[i,6] <= 0.05 & WordFrame[i,8] <= 0.05){

 lines(simplemovingaverage,type='l',col='red'); title(paste("Word Task Acquisition for Subject", WordFrame[i,1])); abline(v = index(original_series[WordFrame[i,7]]),lty=2, col='green', lwd=3); dev.off()
      {
      pdf(file = paste(WordFrame[i,1],"_Word_Task_Acquisition.pdf",collapse = NULL, sep = ""))
      plout <- plot(original_series,type='l',col='blue',xlab="Date of Play",ylab="Number of Successful Words")
      lines(simplemovingaverage,type='l',col='red')
      print(plout)
      title(paste("Word Task Acquisition for Subject", WordFrame[i,1]))
      abline(v = index(original_series[WordFrame[i,7]]),lty=2, col='green', lwd=3)
      dev.off()
      }

      WordFrame[i,18] <- T
      WordFrame[i,16] <- (1-(WordFrame[i,10]/WordFrame[i,13]))
      WordFrame[i,17] <- (1-(WordFrame[i,12]/WordFrame[i,15]))
    } else {
      {
      pdf(file = paste(WordFrame[i,1],"_Word_Task_Acquisition.pdf",collapse = NULL, sep = ""))
      plout <- plot(original_series,type='l',col='blue',xlab="Date of Play",ylab="Number of Successful Words")
      lines(simplemovingaverage,type='l',col='red')
      print(plout)
      title(paste("Word Task Acquisition for Subject", WordFrame[i,1]))
      dev.off()
      }

      WordFrame[i,18] <- F
      WordFrame[i,16] <- 0
      WordFrame[i,17] <- 0
    }
}
?
But as soon as I did that it worked!

Thank you so much!
________________________________
From: Joshua Ulrich <josh.m.ulrich at gmail.com>
Sent: Wednesday, October 5, 2022 9:16 PM
To: Deramus, Thomas Patrick <tderamus at partners.org>
Cc: R-Help <r-help at r-project.org>
Subject: Re: [R] Getting "Error in ect, plot.new has not been called yet" despite grouping plot call


        External Email - Use Caution

Hi,

My hunch is that you need to add print(plout) before you call dev.off(). See https://stackoverflow.com/a/39853861<https://secure-web.cisco.com/1hPT2Maoird0h5FIvJrkRlN2QFkkujjs4YnHgtB5wYLuhRcHZGZ5SmvPC6x4VQ-rT2HqRBreJ_YeWM8Ug8HtScdp7g_E7nS4BfkHFtjiAKRId_AjYMKIvoJa-YojoOECa97gbnLx2QU535CBNKtd0Z-dzQns8z-C4Du8Jh6K3rEvmlP25DscJvrNcRUbisHQ67um6b6a-H9bqYYN-7QtBp2OGBjnh4LBzDR3TnMNVEF0dbhYTuP5zgP2NsHtCvRrwRUUApS1ZqUT0iiiQCrto3zWrSVlQ6aVOqTBgneUBEk_-8SkwVLgOccgGZyw37JTo/https%3A%2F%2Fstackoverflow.com%2Fa%2F39853861>

Try that and let me know if that works. If not, I'll take a closer look later.

Best,
Josh


On Wed, Oct 5, 2022, 1:40 AM Deramus, Thomas Patrick <tderamus at partners.org<mailto:tderamus at partners.org>> wrote:
Sorry to cross-post on Stackoverflow and here but I'm having some difficulty.
https://stackoverflow.com/questions/73942794/still-getting-error-in-ect-plot-new-has-not-been-called-yet-despite-grouping<https://secure-web.cisco.com/1Xaq1EClv5yIy5MQnXyJBRP44YCvR9TkouPyPXmenkL1IktK5tDxQ_MynVlVIbnlxMlCViUOwZZPfM6GNcEI1NlAqV7y-6RhsR6Qy1m90ENv5mp19zbOX-f-IqNkbFHuGZZLCBFkq0sMS_waWZZSj3Su0bNo5Y1b3zCkVoVLl1Go2J2A1jWX3fvSvOP2ArzpHWt9qX8HZpoGVkadBfUmANamoUw5ucuBsXvvaWdl1skYiJzSVyLOaudIgsCzzRq71RtSGcI0wu7pqSjecwy87CNo2IwYi4hzHW45NiTjzbVUsvvb2AXC4G3Ctoh9c15CM/https%3A%2F%2Fstackoverflow.com%2Fquestions%2F73942794%2Fstill-getting-error-in-ect-plot-new-has-not-been-called-yet-despite-grouping>

Trying to make a nested loop that produces PDFs off different graphs, one for ACF/PACF diagnostics and another for the actual data, based on some time-series analyses I'm doing.

Unfortunately, I keep getting the dreaded: Error plot.new has not been called yet

The code is meant to write a PDF containing the ACF and PACF graphs, then do some analyses on the timeseries, and then make a separate PDF containing a plot describing the timeseries based on the p-values of each test for each individual.

library(plyr)
library(dplyr)
library(ggplot2)
library(Kendall)
library(lubridate)
library(xts)
library(TTR)
library(trend)
library(forecast)
library(openxlsx)

Game_Metrics_Word_Task <- read.xlsx("GamePack_Analytics_ALL_TIME_Short.xlsx", "Boggle")
Game_Metrics_Word_Task <- Game_Metrics_Word_Task %>% filter(grepl('1440', StudyId))
Game_Metrics_Word_Task$DeviceTime <- ymd_hms(Game_Metrics_Word_Task$DeviceTime,  tz = "America/New_York")
Game_Metrics_Word_Task <- Game_Metrics_Word_Task[!duplicated(Game_Metrics_Word_Task[1:2,])]

Participant_Word_Task <- split(arrange(Game_Metrics_Word_Task,StudyId,DeviceTime), arrange(Game_Metrics_Word_Task,StudyId,DeviceTime,StudyId,DeviceTime)$StudyId)

WordFrame <- data.frame(Participant = c(0), Task = c(0), MannKendall_Tau = c(0), MannKendall_P = c(0), Sen_Slope_Value = c(0), Sen_Slope_Pval = c(0), Pettitts_CIV = c(0), Pettitts_Pval = c(0), ARIMA_Model = c(0), Time_to_Petit = c(0), Number_of_Trials_to_Pettitt = c(0), Playtime_to_Petit_seconds = c(0), Time_Start_to_end_days = c(0), Number_of_Total_Trials = c(0), Total_Playtime_seconds = c(0), Learning_rate_days = c(0), Learning_rate_seconds = c(0), Learned_Task = c(0))

for (i in 1:length(Participant_Word_Task)){
    success_series <- xts(filter(Participant_Word_Task[[i]], GameEndReason == "TIMER_UP")$NumberOfSuccesfulWords , order.by<http://secure-web.cisco.com/10boIOil_1j37yFHh_eAQC6S-GAWujDCUxF8SFXlL05I4ABkjAjfCpv636hC2_D9ZcnRJNo07NJLs1husggxCVibrINE_e4DkPNcX0JYVosd5gut0FGPSMyIREh9RQoZW3GPaCVyAjIqzeAuKYHJz1C9DZqEdN-SFLGFqZaWzvaYwep785sKgQJCb4FlZA7G7jjr42MjSg97lgbRnFXj7vopsZ3gXb_EoSNtkIHNP7y5bMYQio505DE0WHrz1FFFbt_WehSBrNEAx5UXdrD5gkNwp1jzLMONBJA_2Dj3gZUhAP1AQOyHrI_qYEQKtFpiO/http%3A%2F%2Forder.by>=as.POSIXct(filter(Participant_Word_Task[[i]], GameEndReason == "TIMER_UP")$DeviceTime))
    original_series <- xts(Participant_Word_Task[[i]]$NumberOfSuccesfulWords, order.by<http://secure-web.cisco.com/10boIOil_1j37yFHh_eAQC6S-GAWujDCUxF8SFXlL05I4ABkjAjfCpv636hC2_D9ZcnRJNo07NJLs1husggxCVibrINE_e4DkPNcX0JYVosd5gut0FGPSMyIREh9RQoZW3GPaCVyAjIqzeAuKYHJz1C9DZqEdN-SFLGFqZaWzvaYwep785sKgQJCb4FlZA7G7jjr42MjSg97lgbRnFXj7vopsZ3gXb_EoSNtkIHNP7y5bMYQio505DE0WHrz1FFFbt_WehSBrNEAx5UXdrD5gkNwp1jzLMONBJA_2Dj3gZUhAP1AQOyHrI_qYEQKtFpiO/http%3A%2F%2Forder.by>=as.POSIXct(Participant_Word_Task[[i]]$DeviceTime))
    success_decomp <- ts(success_series, frequency = nweeks(success_series))
    original_decomp <- ts(original_series, frequency = nweeks(success_series))

    pdf(paste("Word_Task_Autocorrelation_plots_for_subject_",unique(Participant_Word_Task[[i]]$StudyId),".pdf" ,collapse = NULL, sep = ""))
    par(mfrow=c(1,2))
    Autocorrelationplot <- acf(success_decomp, main=paste(""))
    PartialAutocorrelationplot <- pacf(success_decomp, main=paste(""))
    mtext(paste("Word Task Auto and Partialauto correlations for subject ",unique(Participant_Word_Task[[i]]$StudyId)), side = 3, line = -3, outer = TRUE)
    dev.off()

    AutomatedArimaoutputs <- auto.arima(success_decomp)
    p <- length(AutomatedArimaoutputs$model$phi)
    #AR component
    q <- length(AutomatedArimaoutputs$model$theta)
    #MA component
    d <- AutomatedArimaoutputs$model$Delta
    #order of difference
    WordFrame[i,1] <- unique(Participant_Word_Task[[i]]$StudyId)
    WordFrame[i,2] <- "Word"
    WordFrame[i,3] <- MannKendall(success_decomp)$tau[1]
    WordFrame[i,4] <- MannKendall(success_decomp)$sl[1]
    WordFrame[i,5] <- sens.slope(success_decomp)$estimates
    WordFrame[i,6] <- sens.slope(success_decomp)$p.value
    WordFrame[i,7] <- pettitt.test(success_decomp)$estimate
    WordFrame[i,8] <- pettitt.test(success_decomp)$p.value
    WordFrame[i,9] <- paste("ARIMA(",p,",",q,",",d,")", collapse = NULL, sep = "")
    WordFrame[i,10] <- difftime(time(success_series[WordFrame[i,7]]),time(original_series[1]))
    WordFrame[i,11] <- tail(which(grepl(success_series[WordFrame[i,7]], original_series)), n=1)
    WordFrame[i,12] <- sum(Participant_Word_Task[[i]]$TotalDuration[1:WordFrame[i,11]])-sum(Participant_Word_Task[[i]]$TotalTimePaused[1:WordFrame[i,11]])
    WordFrame[i,13] <- difftime(time(original_series[length(original_series)]),time(original_series[1]))
    WordFrame[i,14] <- length(original_series)
    WordFrame[i,15] <- sum(Participant_Word_Task[[i]]$TotalDuration[1:length(original_series)])-sum(Participant_Word_Task[[i]]$TotalTimePaused[1:length(original_series)])


    simplemovingaverage <- SMA(original_series, n = nweeks(original_series))

    if (WordFrame[i,4] <= 0.05 & WordFrame[i,6] <= 0.05 & WordFrame[i,8] <= 0.05){
              {
              pdf(paste(WordFrame[i,1],"_Word_Task_Acquisition.pdf",collapse = NULL, sep = ""))
              plout <- plot(original_series,type='l',col='blue',xlab="Date of Play",ylab="Number of Successful Words")
              lines(simplemovingaverage,type='l',col='red')
              title(paste("Word Task Acquisition for Subject", WordFrame[i,1]))
              abline(v = index(original_series[WordFrame[i,7]]),lty=2, col='green', lwd=3)
              dev.off()
              }
              WordFrame[i,18] <- T
              WordFrame[i,16] <- (1-(WordFrame[i,10]/WordFrame[i,13]))
              WordFrame[i,17] <- (1-(WordFrame[i,12]/WordFrame[i,15]))
    } else {
              {
              pdf(paste(WordFrame[i,1],"_Word_Task_Acquisition.pdf",collapse = NULL, sep = ""))
              plout <- plot(original_series,type='l',col='blue',xlab="Date of Play",ylab="Number of Successful Words")
              lines(simplemovingaverage,type='l',col='red')
              title(paste("Word Task Acquisition for Subject", WordFrame[i,1]))
              dev.off()
              }
              WordFrame[i,18] <- F
              WordFrame[i,16] <- 0
              WordFrame[i,17] <- 0
    }
}

It will work just fine if I run the lines individually (e.g. set i = 1, 2, ect), and if I comment out abline and title (lines seems to work fine). But it will throw the error everytime I try to run the loop without these commented.

Have tried just about everything I could find on the Stack forums to run everything as a single argument and I'm just not sure what is wrong with it.

dev.list() spits out:

pdf
  2
following the error.

With abline and title commented out and lines run individually it's NULL.

Happens in both RStudio

2022.07.2+576 "Spotted Wakerobin" Release (e7373ef832b49b2a9b88162cfe7eac5f22c40b34, 2022-09-06) for Ubuntu Bionic
Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) QtWebEngine/5.12.8 Chrome/69.0.3497.128 Safari/537.36

And R:

platform       x86_64-pc-linux-gnu
arch           x86_64
os             linux-gnu
system         x86_64, linux-gnu
status
major          4
minor          2.1
year           2022
month          06
day            23
svn rev        82513
language       R
version.string R version 4.2.1 (2022-06-23)
nickname       Funny-Looking Kid


My OS:
PRETTY_NAME="Debian GNU/Linux 11 (bullseye)"
NAME="Debian GNU/Linux"
VERSION_ID="11"
VERSION="11 (bullseye)"
VERSION_CODENAME=bullseye
ID=debian
HOME_URL="https://www.debian.org/<https://secure-web.cisco.com/1ACDhN-pLD9mzYG0v4VTzMKxAyLmTIADEHLJIuzQBX8KrUHWm1giGPYPmZCHAPpLY42jxDLfqh6eM_dWl9xJg-NmLD-dzpJqBQ-Yy3WuhZONfcn8ZwoK19G46Dm_hBu-Hrl9eV2uzZsEDY_38eQoRMVILy98SEEufRocF9YyjPAW8Y-euSSmPOLDK2PF9CGMABP9qNF6O_sYhykJnPf2_2ptZHvGAEuDDwY925wnRVsvLdc7Rl5zSJE5n45yGOXFaeihwRearfnxKPi8vufhoDC0LOKRYIVSTRAPJJEq3dqTgtDJXkq4UKyJToMfCtF0x/https%3A%2F%2Fwww.debian.org%2F>"
SUPPORT_URL="https://www.debian.org/support<https://secure-web.cisco.com/1Ck4yTAQD273G1LHpBEXmkgIu4kavtz3379Nq-aX3Btcot2VBSq9lKAZN5X2tWi6yT-GMfbuJYp3U621mE6Vk4vf9MJQ3SNMkBn19QcLWgLVnsQvOupmnVd31EWpgYIsutKyJ6Gro4S47Ac8b0GQLFE8VZNrWlbs5YKY3hcPuctYD13LVyjL5zlhP5zvg8wbUX73GBYMHp94c2qKPUfNnsUH1VxXudeB4ZtlnPl66TcO8gJAIYdQmVlw0tIOTdr5VVJ6EbdrRRHKJ7AJvsJWMIn8SAHHusAf7Kc8kCGc0obyScRr-5hU-ImcSro2vFhUe/https%3A%2F%2Fwww.debian.org%2Fsupport>"
BUG_REPORT_URL="https://bugs.debian.org/<https://secure-web.cisco.com/1Kma-rbfMkalSm7CWHd2_J7JxCIrLBWgbW7-6BMP4GaNfBdSR7Y1Cb-8OMMnZjLZbNWg60FnjHKbHrwdsX_noY5nvLC_EaTbhL883q3UtHb3j3i0-Ebdd1vMvHvgn-xWeuYwRTmIZjWV8elT_g_phphQB7EMdaPCS6lHSGC1wkpOKYg9V_cNlEHHMsrtuRMXD-kkjj9h_ziH6Nu-25zVvTIfUbr0ODIxrtThOkJ4wopWByCBXPKInKG_-1gBNV8q_oPar_NJDH3N6D8Zil9T2dPkgZrSUkvP42xw2XnvQ_fYD1x9_57P8KPtPpCik1Sdc/https%3A%2F%2Fbugs.debian.org%2F>"
No LSB modules are available.
Distributor ID:???Debian
Description:??????Debian GNU/Linux 11 (bullseye)
Release:????11
Codename:???bullseye
         Icon name: computer-desktop
           Chassis: desktop
        Machine ID: 053ebf23707f49c8ad4e0684f4cf19d3
           Boot ID: d0e6294d3b944286bef10e76c21e6401
  Operating System: Debian GNU/Linux 11 (bullseye)
            Kernel: Linux 5.10.0-18-amd64
      Architecture: x86-64


Any suggestions would be greatly appreciated.

--

Thomas DeRamus (He/Him/His)

Data Analyst

Massachusetts General Hospital Brigham

Alzheimer?s Clinical & Translational Research Unit

149 13th Street

Charlestown, MA 02129

Phone: 205-834-5066

Email: tderamus at partners.org<mailto:tderamus at partners.org><mailto:tderamus at partners.org<mailto:tderamus at partners.org>>, tpderamus at gmail.com<mailto:tpderamus at gmail.com><mailto:tpderamus at gmail.com<mailto:tpderamus at gmail.com>>


[https://ci3.googleusercontent.com/mail-sig/AIorK4we2sU30P2HyfDQF5hpEjYTt-9FTBK7cAVsP7EenrZ0nsKCf48fuYMtElj6Szn_2fpSPWr66eQ][https://ci3.googleusercontent.com/mail-sig/AIorK4yyY0DlImU0UONJrHTbPc5T3lJj8Kmu8SbDKJJ3XjcX6CgvVsvSueYKwficYFz4zXt6fZV8YIY<https://secure-web.cisco.com/1p4CoOEfGfFgyADIKdZuTyxCAxu1iAL4dl_xBOs0kNACeZBlKqxOU1hdF4bmbj_pz-ZhvRQyetDE_Br_g_kCZNaTln8L0uSdieFdFVX6W2p81hni5pzndOTrQPuenlZezHkcZDaXhr566__QDE7iZutarcm6bGONz_PdpQMeFGoqy9DtDbvmJLEf8x4C_4H1cFd1xYpj4sXozZ1vhTpbayy4IHfK9qLHsnzyPWDEtccLFMO2DjOQu1Kguw_rBvVlQlef7u_XufAbLPWJ5c6FUUC8K1vLFg1xB4-YJctdg4he3hvvz_e8kue-C0qn7a_Iw/https%3A%2F%2Fci3.googleusercontent.com%2Fmail-sig%2FAIorK4we2sU30P2HyfDQF5hpEjYTt-9FTBK7cAVsP7EenrZ0nsKCf48fuYMtElj6Szn_2fpSPWr66eQ%255D%255Bhttps%3A%2F%2Fci3.googleusercontent.com%2Fmail-sig%2FAIorK4yyY0DlImU0UONJrHTbPc5T3lJj8Kmu8SbDKJJ3XjcX6CgvVsvSueYKwficYFz4zXt6fZV8YIY>]

?If knowledge can create problems, it is not through ignorance that we can solve them.?

?Issac Asimov
The information in this e-mail is intended only for the person to whom it is addressed.  If you believe this e-mail was sent to you in error and the e-mail contains patient information, please contact the Mass General Brigham Compliance HelpLine at https://www.massgeneralbrigham.org/complianceline<https://secure-web.cisco.com/1nLR3j5jLEy6A5yyLXTgiSEPglT5zpYBKY0XNFwmEgtrG9PV13Lfd015mRGeFTVsVSFliuG7VXmI-O3Fw0DpFvFKA0GR9lj4jtJ3BQL8MblvkUTO-F6rUjk5jgtDZtSmOeRU6wInl00IqoCwYR3FSQD9_XBe3uQzm6mAviB2SqvIE4u4BFQbNnhQSh-z6E6eGVGAIuG64OGuTByh1AYgf2O3xP3PcXwQiUa6M504snWIaHca1eJ7HB03HRx91JqKUnwhXhOMXidWvZ8djcHw59faZKzc68R55-8RkBTvcDJ1Ln_5ouA6Z0VgC2oHGWPkW/https%3A%2F%2Fwww.massgeneralbrigham.org%2Fcomplianceline> <https://www.massgeneralbrigham.org/complianceline<https://secure-web.cisco.com/1nLR3j5jLEy6A5yyLXTgiSEPglT5zpYBKY0XNFwmEgtrG9PV13Lfd015mRGeFTVsVSFliuG7VXmI-O3Fw0DpFvFKA0GR9lj4jtJ3BQL8MblvkUTO-F6rUjk5jgtDZtSmOeRU6wInl00IqoCwYR3FSQD9_XBe3uQzm6mAviB2SqvIE4u4BFQbNnhQSh-z6E6eGVGAIuG64OGuTByh1AYgf2O3xP3PcXwQiUa6M504snWIaHca1eJ7HB03HRx91JqKUnwhXhOMXidWvZ8djcHw59faZKzc68R55-8RkBTvcDJ1Ln_5ouA6Z0VgC2oHGWPkW/https%3A%2F%2Fwww.massgeneralbrigham.org%2Fcomplianceline>> .
Please note that this e-mail is not secure (encrypted).  If you do not wish to continue communication over unencrypted e-mail, please notify the sender of this message immediately.  Continuing to send or respond to e-mail after receiving this message means you understand and accept this risk and wish to continue to communicate over unencrypted e-mail.
______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://secure-web.cisco.com/169zqX-6K1A_ERyLXXpVduo-L_bdP58wU0tW6976VBgCPzCLprqR3-s8od_SWvcEnJWclWMXLbDu8eHwBNlKcyrCpUuuMxKuz3xGbpVjkqDLLHD7C45e3EKTiUq5JIEFLQ8XvR-IsvhuHJjqfmHKzaeEzciR71ac-nMIG0ZJHmMuQyVv3Yuety2ReZ0Xa5vdHW5zcq0HUKH16bzLXeqSWc6rRkE-i-y9WK_OX959hz6gDnIMSu8RNuwe0TndTxMQyHcG-fK9Ph0sG_12ZjFdw3qL2yzWsEI3sXZ6mFU2v7npLKE1634X53nJ-FnqFhRQ6/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://secure-web.cisco.com/1q--2yVlI7EkpVlbb7cUxHfn03FTKwZsan7XtRgYCrbX98T0WAQn7WNr8Hqt2ZVUuBgmAA5i5zh5M8nfzRoj6CFtWvdyzMvxMdS6eXYA3rlGcZ8LsHDHoUQbsEE9ui-hVicew7e5Ocd1Ed5OSDVeGDecKIEjUUZwTmS3DDa_ilt8dNQOGZaBGOdbnjk0bNYRDT_FiB077ShZRBmKmTX8838zgtFk-hVIGcfvbywCmhpGibHuQ7zyZhd-5wgj9b-c8d2XA6A8yno_2I9DNltls3YoqZcjFoczsuvvTx24DjXJGmaz8wRm3CEg1fuTONU0a/http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html>
and provide commented, minimal, self-contained, reproducible code.
The information in this e-mail is intended only for the person to whom it is addressed.  If you believe this e-mail was sent to you in error and the e-mail contains patient information, please contact the Mass General Brigham Compliance HelpLine at https://www.massgeneralbrigham.org/complianceline <https://www.massgeneralbrigham.org/complianceline> .
Please note that this e-mail is not secure (encrypted).  If you do not wish to continue communication over unencrypted e-mail, please notify the sender of this message immediately.  Continuing to send or respond to e-mail after receiving this message means you understand and accept this risk and wish to continue to communicate over unencrypted e-mail. 

	[[alternative HTML version deleted]]


From t|m@how@rd @end|ng |rom dec@ny@gov  Thu Oct  6 13:08:51 2022
From: t|m@how@rd @end|ng |rom dec@ny@gov (Howard, Tim G (DEC))
Date: Thu, 6 Oct 2022 11:08:51 +0000
Subject: [R] 
 =?iso-8859-1?q?R_version_4=2E2=2E1_install=2Epackages_does_n?=
 =?iso-8859-1?q?ot_work_with_IE_proxy_setting?=
In-Reply-To: <mailman.367970.1.1665050401.59673.r-help@r-project.org>
References: <mailman.367970.1.1665050401.59673.r-help@r-project.org>
Message-ID: <SA1PR09MB7792998783FE251D30BB58A6A85C9@SA1PR09MB7792.namprd09.prod.outlook.com>

Petr, 
You also might want to check out the bug reported here:

https://bugs.r-project.org/show_bug.cgi?id=18379

it was fixed and the last two comments discuss how to handle it in Windows:

you add a new User Environment Variable:
R_LIBCURL_SSL_REVOKE_BEST_EFFORT and set it to TRUE

This fix is in R-4.2.1 Patched (I don't know if it has made it out to the full distribution) and works in my 'corporate' environment.  Perhaps it also applies to your environment. 

Tim


Date: Wed, 5 Oct 2022 10:34:02 +0000
From: PIKAL Petr <petr.pikal at precheza.cz>
To: Ivan Krylov <krylov.r00t at gmail.com>
Cc: r-help mailing list <r-help at r-project.org>
Subject: Re: [R]? R version 4.2.1 install.packages does not work with
??????? IE proxy setting
Message-ID:
??????? <9b38aacf51d746bb87a9cc3765a16b99 at SRVEXCHCM1302.precheza.cz>
Content-Type: text/plain; charset="us-ascii"

Thanks,

the workaround works but we need try the "permanent" solution with
Renviron.site file in future.

Cheers
Petr

> -----Original Message-----
> From: Ivan Krylov <krylov.r00t at gmail.com>
> Sent: Tuesday, October 4, 2022 5:43 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] R version 4.2.1 install.packages does not work with IE
proxy
> setting
>
> On Tue, 4 Oct 2022 11:01:14 +0000
> PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> > After we installed new R version R 4.2.1 installing packages through
> > IE proxy setting is compromised with warning that R could not connect
> > to server (tested in vanilla R).
>
> R 4.1 deprecated the use of download.file(method = 'wininet'). R 4.2
switched
> the default download method to 'libcurl' and started giving warnings for
> 'wininet' and http[s]:// URLs.
>
> A workaround to get it working right now would be to set
> options(download.file.method = 'wininet') and live with the resulting
warnings
> while R downloads the files, but a next version of R may remove 'wininet'
> support altogether.
>
> In order to get it working with the 'libcurl' method, you'll need to
provide some
> environment variables to curl:
> https://gcc02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fpipermail%2Fr-help%2F2022-September%2F475917.html&amp;data=05%7C01%7Ctim.howard%40dec.ny.gov%7C1b8601d6e602486b347508daa781d26e%7Cf46cb8ea79004d108ceb80e8c1c81ee7%7C0%7C0%7C638006473285010034%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=7w1P6Sfu7V3DUM4a3Ezgmf87bXn8CnC%2FipTvXfBpI0c%3D&amp;reserved=0
>
> Not sure if libcurl would accept a patch to discover the Windows proxy
settings
> automatically, but I don't think it does that now.
>
> --
> Best regards,
> Ivan



From @c|@bo|@zz@ @end|ng |rom gm@||@com  Thu Oct  6 13:23:23 2022
From: @c|@bo|@zz@ @end|ng |rom gm@||@com (Valerio Leone Sciabolazza)
Date: Thu, 6 Oct 2022 13:23:23 +0200
Subject: [R] Fixed effect model: different estimation approaches with R
 return different results
Message-ID: <CABZtLWwwgUfZ24tLA-Ub2w6kzMwsSuDWkCkWu2rapS7Gs+psaw@mail.gmail.com>

Good morning,
I am trying to use R to estimate a fixed effects model (i.e., a panel
regression model controlling for unobserved time-invariant
heterogeneities across agents) using different estimation approaches
(e.g. replicating xtreg from Stata, see e.g.
https://www.stata.com/support/faqs/statistics/intercept-in-fixed-effects-model/).
I have already asked this question on different stacks exchange forums
and contacted package creators who dealt with this issue before, but I
wasn't able to obtain an answer to my doubts.
I hope to have better luck on this list.

Let me introduce the problem, and note that I am using an unbalanced panel.

The easiest way to estimate my fixed effect model is using the function lm.

Example:

# load packages
library(dplyr)
# set seed for replication purposes
set.seed(123)
# create toy dataset
x <- rnorm(4000)
x2 <- rnorm(length(x))
id <- factor(sample(500,length(x),replace=TRUE))
firm <- data.frame(id = id) %>%
group_by(id) %>%
mutate(firm = 1:n()) %>%
pull(firm)
id.eff <- rlnorm(nlevels(id))
firm.eff <- rexp(length(unique(firm)))
y <- x + 0.25*x2 + id.eff[id] + firm.eff[firm] + rnorm(length(x))
db = data.frame(y = y, x = x, id = id, firm = firm)
rm <- db %>% group_by(id) %>% summarise(firm = max(firm)) %>%
filter(firm == 1) %>% pull(id)
db = db[-which(db$id %in% rm), ]
# Run regression
test <- lm(y ~ x + id, data = db)

Another approach is demeaning the variables included into the model
specification.
In this way, one can exclude the fixed effects from the model. Of
course, point estimates will be correct, while standard errors will be
not (because we are not accounting for the degrees of freedom used in
the demeaning).

# demean data
dbm <- as_tibble(db) %>%
group_by(id) %>%
mutate(y = y - mean(y),
       x = x - mean(x)) %>%
ungroup()
# run regression
test2 <- lm(y ~ x, data = dbm)
# compare results
summary(test)$coefficients[2,1]
> 0.9753364
summary(test2)$coefficients[2,1]
> 0.9753364

Another way to do this is to demean the variables and add their grand
average (I believe that this is what xtreg from Stata does)

# create data
n = length(unique(db$id))
dbh <- dbm %>%
mutate(yh = y + (sum(db$y)/n),
       xh = x + (sum(db$x)/n))
# run regression
test3 <- lm(yh ~ xh, dbh)
# compare results
summary(test)$coefficients[2,1]
> 0.9753364
summary(test2)$coefficients[2,1]
> 0.9753364
summary(test3)$coefficients[2,1]
> 0.9753364

As one can see, the three approaches report the same point estimates
(again, standard errors will be different instead).

When I include an additional set of fixed effects in the model
specification, the three approaches no longer return the same point
estimate. However, differences seem to be negligible and they could be
due to rounding.

db$firm <- as.factor(db$firm)
dbm$firm <- as.factor(dbm$firm)
dbh$firm <- as.factor(dbh$firm)
testB <- lm(y ~ x + id + firm, data = db)
testB2 <- lm(y ~ x + firm, data = dbm)
testB3 <- lm(yh ~ xh + firm, data = dbh)
summary(testB)$coefficients[2,1]
> 0.9834414
summary(testB2)$coefficients[2,1]
> 0.9833334
summary(testB3)$coefficients[2,1]
> 0.9833334

A similar behavior occurs if I use a dummy variable rather than a
continous one. For the only purpose of the example, I show this by
transforming my target variable x from a continuous to a dummy
variable.

# create data
x3 <- ifelse(db$x > 0, 1, 0)
db <- db %>% mutate(x3 = x3)
dbm <- dbm %>%
mutate(x3 = x3) %>%
group_by(id) %>%
mutate(x3 = x3 - mean(x3)) %>%
ungroup()
dbh <- dbh %>% mutate(x3 = dbm$x3) %>%
mutate(x3 = x3 + (sum(db$x3)/n)) %>%
ungroup()
# Run regressions
testC <- lm(y ~ x3 + id + firm, data = db)
testC2 <- lm(y ~ x3 + firm, data = dbm)
testC3 <- lm(yh ~ x3 + firm, data = dbh)
summary(testC)$coefficients[2, 1]
> 1.579883
summary(testC2)$coefficients[2, 1]
> 1.579159
summary(testC3)$coefficients[2, 1]
> 1.579159

Now, I want to estimate both the impact of x when this is higher than
0 (i.e., x3) and when this is lower or equal to zero (call it x4).
Again, observe that x3 might as well be a real dummy variable, not a
transformation of a continuous variable.

In order to do that, I exclude the intercept from my model.
Specifically, I do the following:

# create data
x4 <- ifelse(db$x <= 0, 1, 0)
db <- db %>% mutate(x4 = x4)
dbm <- dbm %>%
mutate(x4 = x4) %>%
group_by(id) %>%
mutate(x4 = x4 - mean(x4)) %>%
ungroup()
dbh <- dbh %>% mutate(x4 = dbm$x4) %>%
mutate(x4 = x4 + (sum(db$x4)/n)) %>%
ungroup()
testD <- lm(y ~ x3 + x4 + id + firm - 1, data = db)
testD2 <- lm(y ~ x3 + x4 + firm - 1, data = dbm)
testD3 <- lm(yh ~ x3 + x4 + firm - 1, data = dbh)
summary(testD)$coefficients[1:2, ]
> 1.2372816 -0.3426011
summary(testD2)
> Call:
lm(formula = y ~ x3 + x4 + firm - 1, data = dbm)

Residuals:
    Min      1Q  Median      3Q     Max
-3.8794 -0.7497  0.0010  0.7442  3.8486

Coefficients: (1 not defined because of singularities)
       Estimate Std. Error t value Pr(>|t|)
x3      1.57916    0.03779  41.788  < 2e-16 ***
x4           NA         NA      NA       NA
... redacted
summary(testD3)$coefficients[1:2]
> 3.254654 1.675495

As you can see, the second approach is not able to estimate the impact
of x4 on y. At the same time, the first and the third approach return
very different point estimates.

Is anyone able to explain me why I cannot obtain the same point
estimates for this last exercise?

Is there anything wrong in the way I include the second set of fixed effects?
Is there anything wrong in the way I include the variables x3 and x4?
Or this is simply a problem due to some internal functions in R?

Any hint would be much appreciated.

Best,
Valerio


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Oct  6 13:51:53 2022
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 6 Oct 2022 11:51:53 +0000
Subject: [R] 
 =?iso-8859-2?q?R_version_4=2E2=2E1_install=2Epackages_does_n?=
 =?iso-8859-2?q?ot_work_with_IE_proxy_setting?=
In-Reply-To: <SA1PR09MB7792998783FE251D30BB58A6A85C9@SA1PR09MB7792.namprd09.prod.outlook.com>
References: <mailman.367970.1.1665050401.59673.r-help@r-project.org>
 <SA1PR09MB7792998783FE251D30BB58A6A85C9@SA1PR09MB7792.namprd09.prod.outlook.com>
Message-ID: <64b4637a750d43bbbd7a31a593c30921@SRVEXCHCM1302.precheza.cz>

Hallo Howard

Thanks, for the time being the previous workaround with wininet options
works for me. I will wait for the new R version and then try to persuade our
IT to make relevant changes.

Cheers
Petr

> -----Original Message-----
> From: Howard, Tim G (DEC) <tim.howard at dec.ny.gov>
> Sent: Thursday, October 6, 2022 1:09 PM
> To: r-help at r-project.org; PIKAL Petr <petr.pikal at precheza.cz>
> Subject: Re: [R]? R version 4.2.1 install.packages does not work with IE
proxy
> setting
> 
> Petr,
> You also might want to check out the bug reported here:
> 
> https://bugs.r-project.org/show_bug.cgi?id=18379
> 
> it was fixed and the last two comments discuss how to handle it in
Windows:
> 
> you add a new User Environment Variable:
> R_LIBCURL_SSL_REVOKE_BEST_EFFORT and set it to TRUE
> 
> This fix is in R-4.2.1 Patched (I don't know if it has made it out to the
full
> distribution) and works in my 'corporate' environment.  Perhaps it also
applies
> to your environment.
> 
> Tim
> 
> 
> Date: Wed, 5 Oct 2022 10:34:02 +0000
> From: PIKAL Petr <petr.pikal at precheza.cz>
> To: Ivan Krylov <krylov.r00t at gmail.com>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R]? R version 4.2.1 install.packages does not work with
> ??????? IE proxy setting
> Message-ID:
> ??????? <9b38aacf51d746bb87a9cc3765a16b99 at SRVEXCHCM1302.precheza.cz>
> Content-Type: text/plain; charset="us-ascii"
> 
> Thanks,
> 
> the workaround works but we need try the "permanent" solution with
> Renviron.site file in future.
> 
> Cheers
> Petr
> 
> > -----Original Message-----
> > From: Ivan Krylov <krylov.r00t at gmail.com>
> > Sent: Tuesday, October 4, 2022 5:43 PM
> > To: PIKAL Petr <petr.pikal at precheza.cz>
> > Cc: r-help mailing list <r-help at r-project.org>
> > Subject: Re: [R] R version 4.2.1 install.packages does not work with
> > IE
> proxy
> > setting
> >
> > On Tue, 4 Oct 2022 11:01:14 +0000
> > PIKAL Petr <petr.pikal at precheza.cz> wrote:
> >
> > > After we installed new R version R 4.2.1 installing packages through
> > > IE proxy setting is compromised with warning that R could not
> > > connect to server (tested in vanilla R).
> >
> > R 4.1 deprecated the use of download.file(method = 'wininet'). R 4.2
> switched
> > the default download method to 'libcurl' and started giving warnings
> > for 'wininet' and http[s]:// URLs.
> >
> > A workaround to get it working right now would be to set
> > options(download.file.method = 'wininet') and live with the resulting
> warnings
> > while R downloads the files, but a next version of R may remove
'wininet'
> > support altogether.
> >
> > In order to get it working with the 'libcurl' method, you'll need to
> provide some
> > environment variables to curl:
> > https://gcc02.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat
> > .ethz.ch%2Fpipermail%2Fr-help%2F2022-
> September%2F475917.html&amp;data=
> >
> 05%7C01%7Ctim.howard%40dec.ny.gov%7C1b8601d6e602486b347508daa7
> 81d26e%7
> >
> Cf46cb8ea79004d108ceb80e8c1c81ee7%7C0%7C0%7C63800647328501003
> 4%7CUnkno
> >
> wn%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1ha
> WwiL
> >
> CJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=7w1P6Sfu7V3DUM4a3Ez
> gmf87bXn8Cn
> > C%2FipTvXfBpI0c%3D&amp;reserved=0
> >
> > Not sure if libcurl would accept a patch to discover the Windows proxy
> settings
> > automatically, but I don't think it does that now.
> >
> > --
> > Best regards,
> > Ivan


From bgunter@4567 @end|ng |rom gm@||@com  Thu Oct  6 16:31:26 2022
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 6 Oct 2022 07:31:26 -0700
Subject: [R] Fixed effect model: different estimation approaches with R
 return different results
In-Reply-To: <CABZtLWwwgUfZ24tLA-Ub2w6kzMwsSuDWkCkWu2rapS7Gs+psaw@mail.gmail.com>
References: <CABZtLWwwgUfZ24tLA-Ub2w6kzMwsSuDWkCkWu2rapS7Gs+psaw@mail.gmail.com>
Message-ID: <CAGxFJbR_ACsLpms9VgPeN18FgHk5F6iNqhfsSvusrcdMxh_Xeg@mail.gmail.com>

You could get lucky here, but strictly speaking, this list is about R
programming and statistical issues are typically off topic Someone might
respond privately, though.

Cheers,
Bert

On Thu, Oct 6, 2022 at 4:24 AM Valerio Leone Sciabolazza <
sciabolazza at gmail.com> wrote:

> Good morning,
> I am trying to use R to estimate a fixed effects model (i.e., a panel
> regression model controlling for unobserved time-invariant
> heterogeneities across agents) using different estimation approaches
> (e.g. replicating xtreg from Stata, see e.g.
>
> https://www.stata.com/support/faqs/statistics/intercept-in-fixed-effects-model/
> ).
> I have already asked this question on different stacks exchange forums
> and contacted package creators who dealt with this issue before, but I
> wasn't able to obtain an answer to my doubts.
> I hope to have better luck on this list.
>
> Let me introduce the problem, and note that I am using an unbalanced panel.
>
> The easiest way to estimate my fixed effect model is using the function lm.
>
> Example:
>
> # load packages
> library(dplyr)
> # set seed for replication purposes
> set.seed(123)
> # create toy dataset
> x <- rnorm(4000)
> x2 <- rnorm(length(x))
> id <- factor(sample(500,length(x),replace=TRUE))
> firm <- data.frame(id = id) %>%
> group_by(id) %>%
> mutate(firm = 1:n()) %>%
> pull(firm)
> id.eff <- rlnorm(nlevels(id))
> firm.eff <- rexp(length(unique(firm)))
> y <- x + 0.25*x2 + id.eff[id] + firm.eff[firm] + rnorm(length(x))
> db = data.frame(y = y, x = x, id = id, firm = firm)
> rm <- db %>% group_by(id) %>% summarise(firm = max(firm)) %>%
> filter(firm == 1) %>% pull(id)
> db = db[-which(db$id %in% rm), ]
> # Run regression
> test <- lm(y ~ x + id, data = db)
>
> Another approach is demeaning the variables included into the model
> specification.
> In this way, one can exclude the fixed effects from the model. Of
> course, point estimates will be correct, while standard errors will be
> not (because we are not accounting for the degrees of freedom used in
> the demeaning).
>
> # demean data
> dbm <- as_tibble(db) %>%
> group_by(id) %>%
> mutate(y = y - mean(y),
>        x = x - mean(x)) %>%
> ungroup()
> # run regression
> test2 <- lm(y ~ x, data = dbm)
> # compare results
> summary(test)$coefficients[2,1]
> > 0.9753364
> summary(test2)$coefficients[2,1]
> > 0.9753364
>
> Another way to do this is to demean the variables and add their grand
> average (I believe that this is what xtreg from Stata does)
>
> # create data
> n = length(unique(db$id))
> dbh <- dbm %>%
> mutate(yh = y + (sum(db$y)/n),
>        xh = x + (sum(db$x)/n))
> # run regression
> test3 <- lm(yh ~ xh, dbh)
> # compare results
> summary(test)$coefficients[2,1]
> > 0.9753364
> summary(test2)$coefficients[2,1]
> > 0.9753364
> summary(test3)$coefficients[2,1]
> > 0.9753364
>
> As one can see, the three approaches report the same point estimates
> (again, standard errors will be different instead).
>
> When I include an additional set of fixed effects in the model
> specification, the three approaches no longer return the same point
> estimate. However, differences seem to be negligible and they could be
> due to rounding.
>
> db$firm <- as.factor(db$firm)
> dbm$firm <- as.factor(dbm$firm)
> dbh$firm <- as.factor(dbh$firm)
> testB <- lm(y ~ x + id + firm, data = db)
> testB2 <- lm(y ~ x + firm, data = dbm)
> testB3 <- lm(yh ~ xh + firm, data = dbh)
> summary(testB)$coefficients[2,1]
> > 0.9834414
> summary(testB2)$coefficients[2,1]
> > 0.9833334
> summary(testB3)$coefficients[2,1]
> > 0.9833334
>
> A similar behavior occurs if I use a dummy variable rather than a
> continous one. For the only purpose of the example, I show this by
> transforming my target variable x from a continuous to a dummy
> variable.
>
> # create data
> x3 <- ifelse(db$x > 0, 1, 0)
> db <- db %>% mutate(x3 = x3)
> dbm <- dbm %>%
> mutate(x3 = x3) %>%
> group_by(id) %>%
> mutate(x3 = x3 - mean(x3)) %>%
> ungroup()
> dbh <- dbh %>% mutate(x3 = dbm$x3) %>%
> mutate(x3 = x3 + (sum(db$x3)/n)) %>%
> ungroup()
> # Run regressions
> testC <- lm(y ~ x3 + id + firm, data = db)
> testC2 <- lm(y ~ x3 + firm, data = dbm)
> testC3 <- lm(yh ~ x3 + firm, data = dbh)
> summary(testC)$coefficients[2, 1]
> > 1.579883
> summary(testC2)$coefficients[2, 1]
> > 1.579159
> summary(testC3)$coefficients[2, 1]
> > 1.579159
>
> Now, I want to estimate both the impact of x when this is higher than
> 0 (i.e., x3) and when this is lower or equal to zero (call it x4).
> Again, observe that x3 might as well be a real dummy variable, not a
> transformation of a continuous variable.
>
> In order to do that, I exclude the intercept from my model.
> Specifically, I do the following:
>
> # create data
> x4 <- ifelse(db$x <= 0, 1, 0)
> db <- db %>% mutate(x4 = x4)
> dbm <- dbm %>%
> mutate(x4 = x4) %>%
> group_by(id) %>%
> mutate(x4 = x4 - mean(x4)) %>%
> ungroup()
> dbh <- dbh %>% mutate(x4 = dbm$x4) %>%
> mutate(x4 = x4 + (sum(db$x4)/n)) %>%
> ungroup()
> testD <- lm(y ~ x3 + x4 + id + firm - 1, data = db)
> testD2 <- lm(y ~ x3 + x4 + firm - 1, data = dbm)
> testD3 <- lm(yh ~ x3 + x4 + firm - 1, data = dbh)
> summary(testD)$coefficients[1:2, ]
> > 1.2372816 -0.3426011
> summary(testD2)
> > Call:
> lm(formula = y ~ x3 + x4 + firm - 1, data = dbm)
>
> Residuals:
>     Min      1Q  Median      3Q     Max
> -3.8794 -0.7497  0.0010  0.7442  3.8486
>
> Coefficients: (1 not defined because of singularities)
>        Estimate Std. Error t value Pr(>|t|)
> x3      1.57916    0.03779  41.788  < 2e-16 ***
> x4           NA         NA      NA       NA
> ... redacted
> summary(testD3)$coefficients[1:2]
> > 3.254654 1.675495
>
> As you can see, the second approach is not able to estimate the impact
> of x4 on y. At the same time, the first and the third approach return
> very different point estimates.
>
> Is anyone able to explain me why I cannot obtain the same point
> estimates for this last exercise?
>
> Is there anything wrong in the way I include the second set of fixed
> effects?
> Is there anything wrong in the way I include the variables x3 and x4?
> Or this is simply a problem due to some internal functions in R?
>
> Any hint would be much appreciated.
>
> Best,
> Valerio
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From w||||@mwdun|@p @end|ng |rom gm@||@com  Thu Oct  6 16:43:56 2022
From: w||||@mwdun|@p @end|ng |rom gm@||@com (Bill Dunlap)
Date: Thu, 6 Oct 2022 07:43:56 -0700
Subject: [R] Getting "Error in ect,
 plot.new has not been called yet" despite grouping plot call
In-Reply-To: <PH0PR04MB7493CE9332F02B56C0AFE31FBE5D9@PH0PR04MB7493.namprd04.prod.outlook.com>
References: <PH0PR04MB7493E39389D0196BEC260CB6BE5A9@PH0PR04MB7493.namprd04.prod.outlook.com>
 <20221005230608.793c8b9f@rolf-Latitude-E7470>
 <PH0PR04MB7493CE9332F02B56C0AFE31FBE5D9@PH0PR04MB7493.namprd04.prod.outlook.com>
Message-ID: <CAHqSRuQmJoXwhho2KcHijv9PcEo1fARQZ824OeqV_2X3aFmNmg@mail.gmail.com>

Here is how you could have made an example that helpers could easily run.
It also includes the fix.

f <- function(print.it = FALSE) {
   pdf(file.pdf <- tempfile(fileext=".pdf"))
   series <- as.xts(setNames(sin(seq(0,10,by=.1)),
seq(as.Date("2022-10-06"),by="weeks",len=101)))
   p <- plot(series)
   if (print.it) {
       print(p)
   }
   sm_series_2 <- smooth(series / 2)
   lines(sm_series_2, col="red")
   abline(h=0.1, col="blue")
   dev.off()
   file.pdf
}
> f()
Error in plot.xy(xy.coords(x, y), type = type, ...) :
  plot.new has not been called yet
> f(TRUE)
[1]
"C:\\Users\\willi\\AppData\\Local\\Temp\\Rtmp0wX7rO\\file34843df652c.pdf"

If you remove the pdf() and dev.off() I think you will see that the added
lines do not show up.  I think plot.xts fiddles with the coordinate system
before and after it plots so that add-ons must be done in a special way.

-Bill

On Thu, Oct 6, 2022 at 12:42 AM Deramus, Thomas Patrick <
tderamus at partners.org> wrote:

> Hi Rolf.
>
> I followed your suggestion (though it's probably not as trimmed as it
> could be), but the problem unfortunately persists.
>
> Does this make it any clearer or still too many moving parts to make sense
> of?
>
> rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden
> objects.
>
> #Loads the packages
> library(plyr)
> library(dplyr)
> library(ggplot2)
> library(Kendall)
> library(lubridate)
> library(xts)
> library(TTR)
> library(trend)
> library(forecast)
> library(openxlsx)
>
> #Uses the learningCurve Package from Github:
> #https://github.com/AFIT-R/learningCurve
> library(learningCurve)
>
> #Only load this if using VS Studio because it changes the plot function
> #
> https://stackoverflow.com/questions/52284345/how-to-show-r-graph-from-visual-studio-code
> library(httpgd)
> library(languageserver)
>
> #Loads the Excel files to Dataframes and cleans the data
> Game_Metrics_Word_Task <-
> read.xlsx("GamePack_Analytics_ALL_TIME_Short.xlsx", "Boggle")
> Game_Metrics_Word_Task <- Game_Metrics_Word_Task %>% filter(grepl('1440',
> StudyId))
> Game_Metrics_Word_Task$DeviceTime <-
> ymd_hms(Game_Metrics_Word_Task$DeviceTime,  tz = "America/New_York")
> Game_Metrics_Word_Task <-
> Game_Metrics_Word_Task[!duplicated(Game_Metrics_Word_Task[1:2,])]
>
> #Splits the dataframe into a tibble containing each participant
> Participant_Word_Task <-
> split(arrange(Game_Metrics_Word_Task,StudyId,DeviceTime),
> arrange(Game_Metrics_Word_Task,StudyId,DeviceTime,StudyId,DeviceTime)$StudyId)
>
> #Generates a blank output dataframe
> WordFrame <- data.frame(Participant = c(0), Task = c(0), MannKendall_Tau =
> c(0), MannKendall_P = c(0), Sen_Slope_Value = c(0), Sen_Slope_Pval = c(0),
> Pettitts_CIV = c(0), Pettitts_Pval = c(0), ARIMA_Model = c(0),
> Time_to_Petit = c(0), Number_of_Trials_to_Pettitt = c(0),
> Playtime_to_Petit_seconds = c(0), Time_Start_to_end_days = c(0),
> Number_of_Total_Trials = c(0), Total_Playtime_seconds = c(0),
> Learning_rate_days = c(0), Learning_rate_seconds = c(0), Learned_Task =
> c(0))
>
> #The number of subjects in the xlsx file
> #Reduced to 2 for ease of use
> for (i in 1:2){
>   #This timeseries only includes the trials where the participant
> completed the task
>   success_series <- xts(filter(Participant_Word_Task[[i]], GameEndReason
> == "TIMER_UP")$NumberOfSuccesfulWords , order.by=as.POSIXct(filter(Participant_Word_Task[[i]],
> GameEndReason == "TIMER_UP")$DeviceTime))
>   #This timeseries includes ALL the trials for the sake of plotting
>   original_series <-
> xts(Participant_Word_Task[[i]]$NumberOfSuccesfulWords, order.by
> =as.POSIXct(Participant_Word_Task[[i]]$DeviceTime))
>
>   #This is a decomposing process that xts seems to need for plotting.
>   #nweeks is needed for xts to plot the x-axis
>   success_decomp <- ts(success_series, frequency = nweeks(success_series))
>   original_decomp <- ts(original_series, frequency =
> nweeks(success_series))
>
>   #Values which will be included in the plots
>   WordFrame[i,1] <- unique(Participant_Word_Task[[i]]$StudyId)
>   WordFrame[i,5] <- sens.slope(success_decomp)$estimates
>   WordFrame[i,6] <- sens.slope(success_decomp)$p.value
>   WordFrame[i,7] <- pettitt.test(success_decomp)$estimate
>   WordFrame[i,8] <- pettitt.test(success_decomp)$p.value
>
>   #The simple moving average that will be overlayed with the plotted data
>   simplemovingaverage <- SMA(original_series, n = nweeks(original_series))
>
>   #If the three tests are statistically significant, add a green
> horizontal like to value WordFrame[i,7]
>   #Which would be where the slope changes in the series
>   #Fluid variables have been removed from all pdf() and paste() functions
> for ease-of-use
>   if (WordFrame[i,4] <= 0.05 & WordFrame[i,6] <= 0.05 & WordFrame[i,8] <=
> 0.05){
>      {
>       pdf(file = "Word_Task_Acquisition.pdf")
>       plout <- plot(original_series)
>       lines(simplemovingaverage)
>       abline(v = index(original_series[WordFrame[i,7]]),lty=2,
> col='green', lwd=3)
>       title(paste("Word Task Acquisition for Subject"))
>       dev.off()
>      }
>   #If the three tests are NOT statistically significant, generate a plot
> with NO horizontal line at WordFrame[i,7]
>   } else {
>     {
>       pdf(file = "Word_Task_Acquisition.pdf")
>       plout <- plot(original_series)
>       lines(simplemovingaverage)
>       title(paste("Word Task Acquisition for Subject"))
>       dev.off()
>     }
>   }
> }
>
> ________________________________
> From: Rolf Turner <r.turner at auckland.ac.nz>
> Sent: Wednesday, October 5, 2022 6:06 AM
> To: Deramus, Thomas Patrick <tderamus at partners.org>
> Cc: r-help at r-project.org <r-help at r-project.org>
> Subject: Re: [R] Getting "Error in ect, plot.new has not been called yet"
> despite grouping plot call
>
>         External Email - Use Caution
>
> What you doing or trying to do is far too complex for my poor feeble
> and senile brain to come anywhere near comprehending.  The code that
> you present exceeds my complexity tolerance by many orders of magnitude.
>
> I have a suggestion, but.  Strip your code down to the *essentials*.
> Construct a simple sequence of plotting commands, with *simple* names
> for the pdf files involved.  You should require only two or three such
> files and two or three index levels associated with each of your
> nested loops.
>
> Run the stripped down code and the source of the problem will almost
> surely become clear.
>
> cheers,
>
> Rolf Turner
>
> On Tue, 4 Oct 2022 23:35:09 +0000
> "Deramus, Thomas Patrick" <tderamus at partners.org> wrote:
>
> > Sorry to cross-post on Stackoverflow and here but I'm having some
> > difficulty.
> >
> https://secure-web.cisco.com/1_juqv4RvefQFJofsnOQcQA3Ixge89s4uC26pjoPBaYOSxSLGisKtgUTZkanxeHNRqNmjl30B8wYKfsppHje4T8Su77i7t8UbMKzs3GBKEyQva4yTjPH76Q9-l6tT24bB4qNMPQeFAxrkG5lpozNpGrDIAjfKCMvgS-5Qjs-QmvhWZfo84_3SK9rHhJjJvO9CqXb0MewWwI-dEmkZemjxnliGe_D9nooo7Ebjuw0dpBuMnrdaTzQxDdivsbkujPnrGurdjLARh93RW5IWPszNwaoziRD7P-30McF1PrAP8_yjWrhxQ_S3AgG6k40EoQJU/https%3A%2F%2Fstackoverflow.com%2Fquestions%2F73942794%2Fstill-getting-error-in-ect-plot-new-has-not-been-called-yet-despite-grouping
> >
> > Trying to make a nested loop that produces PDFs off different graphs,
> > one for ACF/PACF diagnostics and another for the actual data, based
> > on some time-series analyses I'm doing.
> >
> > Unfortunately, I keep getting the dreaded: Error plot.new has not
> > been called yet
> >
> > The code is meant to write a PDF containing the ACF and PACF graphs,
> > then do some analyses on the timeseries, and then make a separate PDF
> > containing a plot describing the timeseries based on the p-values of
> > each test for each individual.
> >
> > library(plyr)
> > library(dplyr)
> > library(ggplot2)
> > library(Kendall)
> > library(lubridate)
> > library(xts)
> > library(TTR)
> > library(trend)
> > library(forecast)
> > library(openxlsx)
> >
> > Game_Metrics_Word_Task <-
> > read.xlsx("GamePack_Analytics_ALL_TIME_Short.xlsx", "Boggle")
> > Game_Metrics_Word_Task <- Game_Metrics_Word_Task %>%
> > filter(grepl('1440', StudyId)) Game_Metrics_Word_Task$DeviceTime <-
> > ymd_hms(Game_Metrics_Word_Task$DeviceTime,  tz = "America/New_York")
> > Game_Metrics_Word_Task <-
> > Game_Metrics_Word_Task[!duplicated(Game_Metrics_Word_Task[1:2,])]
> >
> > Participant_Word_Task <-
> > split(arrange(Game_Metrics_Word_Task,StudyId,DeviceTime),
> >
> arrange(Game_Metrics_Word_Task,StudyId,DeviceTime,StudyId,DeviceTime)$StudyId)
> >
> > WordFrame <- data.frame(Participant = c(0), Task = c(0),
> > MannKendall_Tau = c(0), MannKendall_P = c(0), Sen_Slope_Value = c(0),
> > Sen_Slope_Pval = c(0), Pettitts_CIV = c(0), Pettitts_Pval = c(0),
> > ARIMA_Model = c(0), Time_to_Petit = c(0), Number_of_Trials_to_Pettitt
> > = c(0), Playtime_to_Petit_seconds = c(0), Time_Start_to_end_days =
> > c(0), Number_of_Total_Trials = c(0), Total_Playtime_seconds = c(0),
> > Learning_rate_days = c(0), Learning_rate_seconds = c(0), Learned_Task
> > = c(0))
> >
> > for (i in 1:length(Participant_Word_Task)){
> >     success_series <- xts(filter(Participant_Word_Task[[i]],
> > GameEndReason == "TIMER_UP")$NumberOfSuccesfulWords ,
> > order.by=as.POSIXct(filter(Participant_Word_Task[[i]], GameEndReason
> > == "TIMER_UP")$DeviceTime)) original_series <-
> > xts(Participant_Word_Task[[i]]$NumberOfSuccesfulWords,
> > order.by=as.POSIXct(Participant_Word_Task[[i]]$DeviceTime))
> > success_decomp <- ts(success_series, frequency =
> > nweeks(success_series)) original_decomp <- ts(original_series,
> > frequency = nweeks(success_series))
> >
> >
>  pdf(paste("Word_Task_Autocorrelation_plots_for_subject_",unique(Participant_Word_Task[[i]]$StudyId),".pdf"
> > ,collapse = NULL, sep = "")) par(mfrow=c(1,2))
> >     Autocorrelationplot <- acf(success_decomp, main=paste(""))
> >     PartialAutocorrelationplot <- pacf(success_decomp, main=paste(""))
> >     mtext(paste("Word Task Auto and Partialauto correlations for
> > subject ",unique(Participant_Word_Task[[i]]$StudyId)), side = 3, line
> > = -3, outer = TRUE) dev.off()
> >
> >     AutomatedArimaoutputs <- auto.arima(success_decomp)
> >     p <- length(AutomatedArimaoutputs$model$phi)
> >     #AR component
> >     q <- length(AutomatedArimaoutputs$model$theta)
> >     #MA component
> >     d <- AutomatedArimaoutputs$model$Delta
> >     #order of difference
> >     WordFrame[i,1] <- unique(Participant_Word_Task[[i]]$StudyId)
> >     WordFrame[i,2] <- "Word"
> >     WordFrame[i,3] <- MannKendall(success_decomp)$tau[1]
> >     WordFrame[i,4] <- MannKendall(success_decomp)$sl[1]
> >     WordFrame[i,5] <- sens.slope(success_decomp)$estimates
> >     WordFrame[i,6] <- sens.slope(success_decomp)$p.value
> >     WordFrame[i,7] <- pettitt.test(success_decomp)$estimate
> >     WordFrame[i,8] <- pettitt.test(success_decomp)$p.value
> >     WordFrame[i,9] <- paste("ARIMA(",p,",",q,",",d,")", collapse =
> > NULL, sep = "") WordFrame[i,10] <-
> > difftime(time(success_series[WordFrame[i,7]]),time(original_series[1]))
> > WordFrame[i,11] <- tail(which(grepl(success_series[WordFrame[i,7]],
> > original_series)), n=1) WordFrame[i,12] <-
> >
> sum(Participant_Word_Task[[i]]$TotalDuration[1:WordFrame[i,11]])-sum(Participant_Word_Task[[i]]$TotalTimePaused[1:WordFrame[i,11]])
> > WordFrame[i,13] <-
> >
> difftime(time(original_series[length(original_series)]),time(original_series[1]))
> > WordFrame[i,14] <- length(original_series) WordFrame[i,15] <-
> >
> sum(Participant_Word_Task[[i]]$TotalDuration[1:length(original_series)])-sum(Participant_Word_Task[[i]]$TotalTimePaused[1:length(original_series)])
> >
> >
> >     simplemovingaverage <- SMA(original_series, n =
> > nweeks(original_series))
> >
> >     if (WordFrame[i,4] <= 0.05 & WordFrame[i,6] <= 0.05 &
> > WordFrame[i,8] <= 0.05){ {
> >
>  pdf(paste(WordFrame[i,1],"_Word_Task_Acquisition.pdf",collapse
> > = NULL, sep = "")) plout <-
> > plot(original_series,type='l',col='blue',xlab="Date of
> > Play",ylab="Number of Successful Words")
> > lines(simplemovingaverage,type='l',col='red') title(paste("Word Task
> > Acquisition for Subject", WordFrame[i,1])) abline(v =
> > index(original_series[WordFrame[i,7]]),lty=2, col='green', lwd=3)
> > dev.off() } WordFrame[i,18] <- T
> >               WordFrame[i,16] <- (1-(WordFrame[i,10]/WordFrame[i,13]))
> >               WordFrame[i,17] <- (1-(WordFrame[i,12]/WordFrame[i,15]))
> >     } else {
> >               {
> >
>  pdf(paste(WordFrame[i,1],"_Word_Task_Acquisition.pdf",collapse
> > = NULL, sep = "")) plout <-
> > plot(original_series,type='l',col='blue',xlab="Date of
> > Play",ylab="Number of Successful Words")
> > lines(simplemovingaverage,type='l',col='red') title(paste("Word Task
> > Acquisition for Subject", WordFrame[i,1])) dev.off() }
> >               WordFrame[i,18] <- F
> >               WordFrame[i,16] <- 0
> >               WordFrame[i,17] <- 0
> >     }
> > }
> >
> > It will work just fine if I run the lines individually (e.g. set i =
> > 1, 2, ect), and if I comment out abline and title (lines seems to
> > work fine). But it will throw the error everytime I try to run the
> > loop without these commented.
> >
> > Have tried just about everything I could find on the Stack forums to
> > run everything as a single argument and I'm just not sure what is
> > wrong with it.
> >
> > dev.list() spits out:
> >
> > pdf
> >   2
> > following the error.
> >
> > With abline and title commented out and lines run individually it's
> > NULL.
> >
> > Happens in both RStudio
> >
> > 2022.07.2+576 "Spotted Wakerobin" Release
> > (e7373ef832b49b2a9b88162cfe7eac5f22c40b34, 2022-09-06) for Ubuntu
> > Bionic Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML,
> > like Gecko) QtWebEngine/5.12.8 Chrome/69.0.3497.128 Safari/537.36
> >
> > And R:
> >
> > platform       x86_64-pc-linux-gnu
> > arch           x86_64
> > os             linux-gnu
> > system         x86_64, linux-gnu
> > status
> > major          4
> > minor          2.1
> > year           2022
> > month          06
> > day            23
> > svn rev        82513
> > language       R
> > version.string R version 4.2.1 (2022-06-23)
> > nickname       Funny-Looking Kid
> >
> >
> > My OS:
> > PRETTY_NAME="Debian GNU/Linux 11 (bullseye)"
> > NAME="Debian GNU/Linux"
> > VERSION_ID="11"
> > VERSION="11 (bullseye)"
> > VERSION_CODENAME=bullseye
> > ID=debian
> > HOME_URL="
> https://secure-web.cisco.com/1Ruvt90Q90ixR-GE-RDiKJgzRpfDjlNz-lZTqQQGM8Tf4GAoj5QOfE2vXMaMWxMoexuf1npQrX7uAjFuU2viz28h42RPmHQK7jGDX7BpRLkTNcERyxHVKJTxgYegXo-n9N7rqegcKsrr47xlGmTcMOJcBAqH7SpTPQlYDOGgjz1ErtetQRzUsd-eKs9l4oCVPiF6SKV40C7s_NXm0tuCswL2Jhyfv70-edCtBO_4j9-3dSi5ZdFLYaWsMScnwwxNIGYU2n0vw5NH4GJcZNsv6Scu-r6W8ndJaGL4UmX9J3PX0LrdFyjLbGtA7RqPpKFUQ/https%3A%2F%2Fwww.debian.org
> "
> > SUPPORT_URL="
> https://secure-web.cisco.com/1gveQttVrJNRSM85857IiydpLraxrrtJobMyCNkRvQ4V2f00DH67Z0hEa50LLpCVYQvIjMsQZxHAVMZvYQV_Cp2-e82TDZzPY4aSR2td2th3bwuXGxtI7CTgSUudOWgPpmnwVLT5r34EnwXEmwnMoiPVnOEC7slpF1fLGq11wSynuyttcTagMfpN6qdYfgtbu_mz0JOBUecQ-etUQYw5BDmXEKv5JZ_y5Uyt8Q89Kirhi7Hk8FMbCVcxRZpOZZmghxlPMxYaNVIOnln-R0H8J2QIzqE49cQQPKkFZ9O29zpr8odlBXqjObKn24ReYPDhH/https%3A%2F%2Fwww.debian.org%2Fsupport
> "
> > BUG_REPORT_URL="
> https://secure-web.cisco.com/1tepDnCjDgHsmvw9Eth-7nfyKi3doVSOFKVzz83wskdyf8lsrEVkG2NYw7am6ePhSFfjQXdDyceMyc21Un-vqTirSQYKdPavRdKJy85HgHMP66Xk-OgxFf-5KXiPzmFreDfuuJlYizGSUNOLcADyNVTCo47xFfRgtB83Hs8j3yYAJFrff7TqNOFWzSzTcfrycio_WSSfbQkLpUl-1xGzg-dvP16tKuwkRr62bkPeydXJC_iH1FfnWv5b1G04au3aFmRTem8t2RS40LPMS9Mh0UmMvHD_9qwX16cFMHQ8U4x9Sp9IUcAFhgnbffOyPQm1C/https%3A%2F%2Fbugs.debian.org
> "
> > No LSB modules are available.
> > Distributor ID: Debian
> > Description: Debian GNU/Linux 11 (bullseye)
> > Release: 11
> > Codename: bullseye
> >          Icon name: computer-desktop
> >            Chassis: desktop
> >         Machine ID: 053ebf23707f49c8ad4e0684f4cf19d3
> >            Boot ID: d0e6294d3b944286bef10e76c21e6401
> >   Operating System: Debian GNU/Linux 11 (bullseye)
> >             Kernel: Linux 5.10.0-18-amd64
> >       Architecture: x86-64
> >
> >
> > Any suggestions would be greatly appreciated.
> >
> > --
> >
> > Thomas DeRamus (He/Him/His)
> >
> > Data Analyst
> >
> > Massachusetts General Hospital Brigham
> >
> > Alzheimer?s Clinical & Translational Research Unit
> >
> > 149 13th Street
> >
> > Charlestown, MA 02129
> >
> > Phone: 205-834-5066
> >
> > Email: tderamus at partners.org<mailto:tderamus at partners.org>,
> > tpderamus at gmail.com<mailto:tpderamus at gmail.com>
> >
> >
> > [
> https://secure-web.cisco.com/1AI4S4rz4bDZGM8naa-19GTAeSORO5ZmNe056Q_nhPRk4JVAzPiRKUBWitBK5TpxoKBLoLvNfoMDanGd1n5Bnf4SJFT7l7HnaLcjjH7oVk2BZdDfCLHo8a8eePvD4XrF2Fw3iuxKgIZY5dwdesP3P8pSvkmVGvyZ-HiEKRetk4uJHhRa6gSgOQ8MbCVKmi6XP1dtozTEH1RpDrFJ4EyevPO52UzaTAY6CR8USLWNbsxXJsnsjUz1G6_4P7B3ULuMu9mEPeQz_GnTrSXTrGZooK_idhoEougti7I8NYV0CS09Yahmp4Fe_vh9wu4Jkdal3/https%3A%2F%2Fci3.googleusercontent.com%2Fmail-sig%2FAIorK4we2sU30P2HyfDQF5hpEjYTt-9FTBK7cAVsP7EenrZ0nsKCf48fuYMtElj6Szn_2fpSPWr66eQ][https://ci3.googleusercontent.com/mail-sig/AIorK4yyY0DlImU0UONJrHTbPc5T3lJj8Kmu8SbDKJJ3XjcX6CgvVsvSueYKwficYFz4zXt6fZV8YIY
> <https://secure-web.cisco.com/1AI4S4rz4bDZGM8naa-19GTAeSORO5ZmNe056Q_nhPRk4JVAzPiRKUBWitBK5TpxoKBLoLvNfoMDanGd1n5Bnf4SJFT7l7HnaLcjjH7oVk2BZdDfCLHo8a8eePvD4XrF2Fw3iuxKgIZY5dwdesP3P8pSvkmVGvyZ-HiEKRetk4uJHhRa6gSgOQ8MbCVKmi6XP1dtozTEH1RpDrFJ4EyevPO52UzaTAY6CR8USLWNbsxXJsnsjUz1G6_4P7B3ULuMu9mEPeQz_GnTrSXTrGZooK_idhoEougti7I8NYV0CS09Yahmp4Fe_vh9wu4Jkdal3/https%3A%2F%2Fci3.googleusercontent.com%2Fmail-sig%2FAIorK4we2sU30P2HyfDQF5hpEjYTt-9FTBK7cAVsP7EenrZ0nsKCf48fuYMtElj6Szn_2fpSPWr66eQ%5D%5Bhttps://ci3.googleusercontent.com/mail-sig/AIorK4yyY0DlImU0UONJrHTbPc5T3lJj8Kmu8SbDKJJ3XjcX6CgvVsvSueYKwficYFz4zXt6fZV8YIY>
> ]
> >
> > ?If knowledge can create problems, it is not through ignorance that
> > we can solve them.?
> >
> > ?Issac Asimov
>
> The information in this e-mail is intended only for th...{{dropped:22}}


From @c|@bo|@zz@ @end|ng |rom gm@||@com  Thu Oct  6 16:45:18 2022
From: @c|@bo|@zz@ @end|ng |rom gm@||@com (Valerio Leone Sciabolazza)
Date: Thu, 6 Oct 2022 16:45:18 +0200
Subject: [R] Fixed effect model: different estimation approaches with R
 return different results
In-Reply-To: <CAGxFJbR_ACsLpms9VgPeN18FgHk5F6iNqhfsSvusrcdMxh_Xeg@mail.gmail.com>
References: <CABZtLWwwgUfZ24tLA-Ub2w6kzMwsSuDWkCkWu2rapS7Gs+psaw@mail.gmail.com>
 <CAGxFJbR_ACsLpms9VgPeN18FgHk5F6iNqhfsSvusrcdMxh_Xeg@mail.gmail.com>
Message-ID: <CABZtLWwPtnFKhOjEeR7V3aU4SCoq=5VgaZLWQdcVCBwy-iiONA@mail.gmail.com>

Thank you Bert, I see your point.
The problem is that I am not sure if this is a statistical issue -
i.e., there is something wrong with my procedure - or, in a manner of
speaking, a software issue: e.g. lm is not expected to return the same
estimates for different approaches because of the way in which the
function estimates the solution, and it should not be used the way I
do. Maybe I should have better stressed this.
Valerio


On Thu, Oct 6, 2022 at 4:31 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> You could get lucky here, but strictly speaking, this list is about R programming and statistical issues are typically off topic Someone might respond privately, though.
>
> Cheers,
> Bert
>
> On Thu, Oct 6, 2022 at 4:24 AM Valerio Leone Sciabolazza <sciabolazza at gmail.com> wrote:
>>
>> Good morning,
>> I am trying to use R to estimate a fixed effects model (i.e., a panel
>> regression model controlling for unobserved time-invariant
>> heterogeneities across agents) using different estimation approaches
>> (e.g. replicating xtreg from Stata, see e.g.
>> https://www.stata.com/support/faqs/statistics/intercept-in-fixed-effects-model/).
>> I have already asked this question on different stacks exchange forums
>> and contacted package creators who dealt with this issue before, but I
>> wasn't able to obtain an answer to my doubts.
>> I hope to have better luck on this list.
>>
>> Let me introduce the problem, and note that I am using an unbalanced panel.
>>
>> The easiest way to estimate my fixed effect model is using the function lm.
>>
>> Example:
>>
>> # load packages
>> library(dplyr)
>> # set seed for replication purposes
>> set.seed(123)
>> # create toy dataset
>> x <- rnorm(4000)
>> x2 <- rnorm(length(x))
>> id <- factor(sample(500,length(x),replace=TRUE))
>> firm <- data.frame(id = id) %>%
>> group_by(id) %>%
>> mutate(firm = 1:n()) %>%
>> pull(firm)
>> id.eff <- rlnorm(nlevels(id))
>> firm.eff <- rexp(length(unique(firm)))
>> y <- x + 0.25*x2 + id.eff[id] + firm.eff[firm] + rnorm(length(x))
>> db = data.frame(y = y, x = x, id = id, firm = firm)
>> rm <- db %>% group_by(id) %>% summarise(firm = max(firm)) %>%
>> filter(firm == 1) %>% pull(id)
>> db = db[-which(db$id %in% rm), ]
>> # Run regression
>> test <- lm(y ~ x + id, data = db)
>>
>> Another approach is demeaning the variables included into the model
>> specification.
>> In this way, one can exclude the fixed effects from the model. Of
>> course, point estimates will be correct, while standard errors will be
>> not (because we are not accounting for the degrees of freedom used in
>> the demeaning).
>>
>> # demean data
>> dbm <- as_tibble(db) %>%
>> group_by(id) %>%
>> mutate(y = y - mean(y),
>>        x = x - mean(x)) %>%
>> ungroup()
>> # run regression
>> test2 <- lm(y ~ x, data = dbm)
>> # compare results
>> summary(test)$coefficients[2,1]
>> > 0.9753364
>> summary(test2)$coefficients[2,1]
>> > 0.9753364
>>
>> Another way to do this is to demean the variables and add their grand
>> average (I believe that this is what xtreg from Stata does)
>>
>> # create data
>> n = length(unique(db$id))
>> dbh <- dbm %>%
>> mutate(yh = y + (sum(db$y)/n),
>>        xh = x + (sum(db$x)/n))
>> # run regression
>> test3 <- lm(yh ~ xh, dbh)
>> # compare results
>> summary(test)$coefficients[2,1]
>> > 0.9753364
>> summary(test2)$coefficients[2,1]
>> > 0.9753364
>> summary(test3)$coefficients[2,1]
>> > 0.9753364
>>
>> As one can see, the three approaches report the same point estimates
>> (again, standard errors will be different instead).
>>
>> When I include an additional set of fixed effects in the model
>> specification, the three approaches no longer return the same point
>> estimate. However, differences seem to be negligible and they could be
>> due to rounding.
>>
>> db$firm <- as.factor(db$firm)
>> dbm$firm <- as.factor(dbm$firm)
>> dbh$firm <- as.factor(dbh$firm)
>> testB <- lm(y ~ x + id + firm, data = db)
>> testB2 <- lm(y ~ x + firm, data = dbm)
>> testB3 <- lm(yh ~ xh + firm, data = dbh)
>> summary(testB)$coefficients[2,1]
>> > 0.9834414
>> summary(testB2)$coefficients[2,1]
>> > 0.9833334
>> summary(testB3)$coefficients[2,1]
>> > 0.9833334
>>
>> A similar behavior occurs if I use a dummy variable rather than a
>> continous one. For the only purpose of the example, I show this by
>> transforming my target variable x from a continuous to a dummy
>> variable.
>>
>> # create data
>> x3 <- ifelse(db$x > 0, 1, 0)
>> db <- db %>% mutate(x3 = x3)
>> dbm <- dbm %>%
>> mutate(x3 = x3) %>%
>> group_by(id) %>%
>> mutate(x3 = x3 - mean(x3)) %>%
>> ungroup()
>> dbh <- dbh %>% mutate(x3 = dbm$x3) %>%
>> mutate(x3 = x3 + (sum(db$x3)/n)) %>%
>> ungroup()
>> # Run regressions
>> testC <- lm(y ~ x3 + id + firm, data = db)
>> testC2 <- lm(y ~ x3 + firm, data = dbm)
>> testC3 <- lm(yh ~ x3 + firm, data = dbh)
>> summary(testC)$coefficients[2, 1]
>> > 1.579883
>> summary(testC2)$coefficients[2, 1]
>> > 1.579159
>> summary(testC3)$coefficients[2, 1]
>> > 1.579159
>>
>> Now, I want to estimate both the impact of x when this is higher than
>> 0 (i.e., x3) and when this is lower or equal to zero (call it x4).
>> Again, observe that x3 might as well be a real dummy variable, not a
>> transformation of a continuous variable.
>>
>> In order to do that, I exclude the intercept from my model.
>> Specifically, I do the following:
>>
>> # create data
>> x4 <- ifelse(db$x <= 0, 1, 0)
>> db <- db %>% mutate(x4 = x4)
>> dbm <- dbm %>%
>> mutate(x4 = x4) %>%
>> group_by(id) %>%
>> mutate(x4 = x4 - mean(x4)) %>%
>> ungroup()
>> dbh <- dbh %>% mutate(x4 = dbm$x4) %>%
>> mutate(x4 = x4 + (sum(db$x4)/n)) %>%
>> ungroup()
>> testD <- lm(y ~ x3 + x4 + id + firm - 1, data = db)
>> testD2 <- lm(y ~ x3 + x4 + firm - 1, data = dbm)
>> testD3 <- lm(yh ~ x3 + x4 + firm - 1, data = dbh)
>> summary(testD)$coefficients[1:2, ]
>> > 1.2372816 -0.3426011
>> summary(testD2)
>> > Call:
>> lm(formula = y ~ x3 + x4 + firm - 1, data = dbm)
>>
>> Residuals:
>>     Min      1Q  Median      3Q     Max
>> -3.8794 -0.7497  0.0010  0.7442  3.8486
>>
>> Coefficients: (1 not defined because of singularities)
>>        Estimate Std. Error t value Pr(>|t|)
>> x3      1.57916    0.03779  41.788  < 2e-16 ***
>> x4           NA         NA      NA       NA
>> ... redacted
>> summary(testD3)$coefficients[1:2]
>> > 3.254654 1.675495
>>
>> As you can see, the second approach is not able to estimate the impact
>> of x4 on y. At the same time, the first and the third approach return
>> very different point estimates.
>>
>> Is anyone able to explain me why I cannot obtain the same point
>> estimates for this last exercise?
>>
>> Is there anything wrong in the way I include the second set of fixed effects?
>> Is there anything wrong in the way I include the variables x3 and x4?
>> Or this is simply a problem due to some internal functions in R?
>>
>> Any hint would be much appreciated.
>>
>> Best,
>> Valerio
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jo@h@m@u|r|ch @end|ng |rom gm@||@com  Thu Oct  6 17:26:11 2022
From: jo@h@m@u|r|ch @end|ng |rom gm@||@com (Joshua Ulrich)
Date: Thu, 6 Oct 2022 10:26:11 -0500
Subject: [R] Getting "Error in ect,
 plot.new has not been called yet" despite grouping plot call
In-Reply-To: <CAHqSRuQmJoXwhho2KcHijv9PcEo1fARQZ824OeqV_2X3aFmNmg@mail.gmail.com>
References: <PH0PR04MB7493E39389D0196BEC260CB6BE5A9@PH0PR04MB7493.namprd04.prod.outlook.com>
 <20221005230608.793c8b9f@rolf-Latitude-E7470>
 <PH0PR04MB7493CE9332F02B56C0AFE31FBE5D9@PH0PR04MB7493.namprd04.prod.outlook.com>
 <CAHqSRuQmJoXwhho2KcHijv9PcEo1fARQZ824OeqV_2X3aFmNmg@mail.gmail.com>
Message-ID: <CAPPM_gSq9VLwEiyB6HkfdUj6gMRtJTJKW4nWFFqB-K=ta9ny_w@mail.gmail.com>

On Thu, Oct 6, 2022 at 9:44 AM Bill Dunlap <williamwdunlap at gmail.com> wrote:
>
> Here is how you could have made an example that helpers could easily run.
> It also includes the fix.
>
> f <- function(print.it = FALSE) {
>    pdf(file.pdf <- tempfile(fileext=".pdf"))
>    series <- as.xts(setNames(sin(seq(0,10,by=.1)),
> seq(as.Date("2022-10-06"),by="weeks",len=101)))
>    p <- plot(series)
>    if (print.it) {
>        print(p)
>    }
>    sm_series_2 <- smooth(series / 2)
>    lines(sm_series_2, col="red")
>    abline(h=0.1, col="blue")
>    dev.off()
>    file.pdf
> }
> > f()
> Error in plot.xy(xy.coords(x, y), type = type, ...) :
>   plot.new has not been called yet
> > f(TRUE)
> [1]
> "C:\\Users\\willi\\AppData\\Local\\Temp\\Rtmp0wX7rO\\file34843df652c.pdf"
>
> If you remove the pdf() and dev.off() I think you will see that the added
> lines do not show up.  I think plot.xts fiddles with the coordinate system
> before and after it plots so that add-ons must be done in a special way.
>

plot.xts() waits until the plot is rendered before calculating the
coordinate system. That allows users to add multiple series that have
different values for the index (x-axis) and data (y-axis).

lines() doesn't show up in your example because it's called after the
plot is rendered, and it's not rendered again after they're added.
`sm_series_2` also needs to be an xts object, otherwise lines.xts() is
not dispatched.

title() and abline() need to be called after the plot is rendered
because they are standard graphics functions. I admit that's very
confusing... I'll see what I can do to fix that.

Here's a revised example that works for me:

f <- function(print.it = FALSE)
{
    pdf(file.pdf <- tempfile(fileext=".pdf"))
    series <- xts(sin(seq(0,10,by=.1)),
seq(as.Date("2022-10-06"),by="weeks",length.out=101))
    p <- plot(series)
    sm2 <- xts(smooth(series/2), index(series))
    lines(sm2, col="red")
    if (print.it) {
        print(p)
        title("Sine curve example")
        abline(h=0.1, col="green")
    }
    dev.off()
    file.pdf
}
f(TRUE)



> -Bill
>
> On Thu, Oct 6, 2022 at 12:42 AM Deramus, Thomas Patrick <
> tderamus at partners.org> wrote:
>
> > Hi Rolf.
> >
> > I followed your suggestion (though it's probably not as trimmed as it
> > could be), but the problem unfortunately persists.
> >
> > Does this make it any clearer or still too many moving parts to make sense
> > of?
> >
> > rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden
> > objects.
> >
> > #Loads the packages
> > library(plyr)
> > library(dplyr)
> > library(ggplot2)
> > library(Kendall)
> > library(lubridate)
> > library(xts)
> > library(TTR)
> > library(trend)
> > library(forecast)
> > library(openxlsx)
> >
> > #Uses the learningCurve Package from Github:
> > #https://github.com/AFIT-R/learningCurve
> > library(learningCurve)
> >
> > #Only load this if using VS Studio because it changes the plot function
> > #
> > https://stackoverflow.com/questions/52284345/how-to-show-r-graph-from-visual-studio-code
> > library(httpgd)
> > library(languageserver)
> >
> > #Loads the Excel files to Dataframes and cleans the data
> > Game_Metrics_Word_Task <-
> > read.xlsx("GamePack_Analytics_ALL_TIME_Short.xlsx", "Boggle")
> > Game_Metrics_Word_Task <- Game_Metrics_Word_Task %>% filter(grepl('1440',
> > StudyId))
> > Game_Metrics_Word_Task$DeviceTime <-
> > ymd_hms(Game_Metrics_Word_Task$DeviceTime,  tz = "America/New_York")
> > Game_Metrics_Word_Task <-
> > Game_Metrics_Word_Task[!duplicated(Game_Metrics_Word_Task[1:2,])]
> >
> > #Splits the dataframe into a tibble containing each participant
> > Participant_Word_Task <-
> > split(arrange(Game_Metrics_Word_Task,StudyId,DeviceTime),
> > arrange(Game_Metrics_Word_Task,StudyId,DeviceTime,StudyId,DeviceTime)$StudyId)
> >
> > #Generates a blank output dataframe
> > WordFrame <- data.frame(Participant = c(0), Task = c(0), MannKendall_Tau =
> > c(0), MannKendall_P = c(0), Sen_Slope_Value = c(0), Sen_Slope_Pval = c(0),
> > Pettitts_CIV = c(0), Pettitts_Pval = c(0), ARIMA_Model = c(0),
> > Time_to_Petit = c(0), Number_of_Trials_to_Pettitt = c(0),
> > Playtime_to_Petit_seconds = c(0), Time_Start_to_end_days = c(0),
> > Number_of_Total_Trials = c(0), Total_Playtime_seconds = c(0),
> > Learning_rate_days = c(0), Learning_rate_seconds = c(0), Learned_Task =
> > c(0))
> >
> > #The number of subjects in the xlsx file
> > #Reduced to 2 for ease of use
> > for (i in 1:2){
> >   #This timeseries only includes the trials where the participant
> > completed the task
> >   success_series <- xts(filter(Participant_Word_Task[[i]], GameEndReason
> > == "TIMER_UP")$NumberOfSuccesfulWords , order.by=as.POSIXct(filter(Participant_Word_Task[[i]],
> > GameEndReason == "TIMER_UP")$DeviceTime))
> >   #This timeseries includes ALL the trials for the sake of plotting
> >   original_series <-
> > xts(Participant_Word_Task[[i]]$NumberOfSuccesfulWords, order.by
> > =as.POSIXct(Participant_Word_Task[[i]]$DeviceTime))
> >
> >   #This is a decomposing process that xts seems to need for plotting.
> >   #nweeks is needed for xts to plot the x-axis
> >   success_decomp <- ts(success_series, frequency = nweeks(success_series))
> >   original_decomp <- ts(original_series, frequency =
> > nweeks(success_series))
> >
> >   #Values which will be included in the plots
> >   WordFrame[i,1] <- unique(Participant_Word_Task[[i]]$StudyId)
> >   WordFrame[i,5] <- sens.slope(success_decomp)$estimates
> >   WordFrame[i,6] <- sens.slope(success_decomp)$p.value
> >   WordFrame[i,7] <- pettitt.test(success_decomp)$estimate
> >   WordFrame[i,8] <- pettitt.test(success_decomp)$p.value
> >
> >   #The simple moving average that will be overlayed with the plotted data
> >   simplemovingaverage <- SMA(original_series, n = nweeks(original_series))
> >
> >   #If the three tests are statistically significant, add a green
> > horizontal like to value WordFrame[i,7]
> >   #Which would be where the slope changes in the series
> >   #Fluid variables have been removed from all pdf() and paste() functions
> > for ease-of-use
> >   if (WordFrame[i,4] <= 0.05 & WordFrame[i,6] <= 0.05 & WordFrame[i,8] <=
> > 0.05){
> >      {
> >       pdf(file = "Word_Task_Acquisition.pdf")
> >       plout <- plot(original_series)
> >       lines(simplemovingaverage)
> >       abline(v = index(original_series[WordFrame[i,7]]),lty=2,
> > col='green', lwd=3)
> >       title(paste("Word Task Acquisition for Subject"))
> >       dev.off()
> >      }
> >   #If the three tests are NOT statistically significant, generate a plot
> > with NO horizontal line at WordFrame[i,7]
> >   } else {
> >     {
> >       pdf(file = "Word_Task_Acquisition.pdf")
> >       plout <- plot(original_series)
> >       lines(simplemovingaverage)
> >       title(paste("Word Task Acquisition for Subject"))
> >       dev.off()
> >     }
> >   }
> > }
> >
> > ________________________________
> > From: Rolf Turner <r.turner at auckland.ac.nz>
> > Sent: Wednesday, October 5, 2022 6:06 AM
> > To: Deramus, Thomas Patrick <tderamus at partners.org>
> > Cc: r-help at r-project.org <r-help at r-project.org>
> > Subject: Re: [R] Getting "Error in ect, plot.new has not been called yet"
> > despite grouping plot call
> >
> >         External Email - Use Caution
> >
> > What you doing or trying to do is far too complex for my poor feeble
> > and senile brain to come anywhere near comprehending.  The code that
> > you present exceeds my complexity tolerance by many orders of magnitude.
> >
> > I have a suggestion, but.  Strip your code down to the *essentials*.
> > Construct a simple sequence of plotting commands, with *simple* names
> > for the pdf files involved.  You should require only two or three such
> > files and two or three index levels associated with each of your
> > nested loops.
> >
> > Run the stripped down code and the source of the problem will almost
> > surely become clear.
> >
> > cheers,
> >
> > Rolf Turner
> >
> > On Tue, 4 Oct 2022 23:35:09 +0000
> > "Deramus, Thomas Patrick" <tderamus at partners.org> wrote:
> >
<snip>
> > > ?Issac Asimov
> >
> > The information in this e-mail is intended only for th...{{dropped:22}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From jcough||n @end|ng |rom um@@@@edu  Thu Oct  6 16:58:51 2022
From: jcough||n @end|ng |rom um@@@@edu (Julie Coughlin)
Date: Thu, 6 Oct 2022 10:58:51 -0400
Subject: [R] (no subject)
Message-ID: <CAAsvtakY89Vi5Uk0rZJtXfBy1-4AvpYEe7fBbRWoKD_t+7sqAQ@mail.gmail.com>

Hi ,
Can you send me a later version of r programming to use on my macos version
10.12.6? The newest r program is not compatible with my macbook.
Thank you, Julie :)

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Thu Oct  6 17:42:59 2022
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Thu, 6 Oct 2022 16:42:59 +0100
Subject: [R] (no subject)
In-Reply-To: <CAAsvtakY89Vi5Uk0rZJtXfBy1-4AvpYEe7fBbRWoKD_t+7sqAQ@mail.gmail.com>
References: <CAAsvtakY89Vi5Uk0rZJtXfBy1-4AvpYEe7fBbRWoKD_t+7sqAQ@mail.gmail.com>
Message-ID: <c073357c-4d2b-fb20-3633-f1993b1c6d36@sapo.pt>

Hello,

I am not a Mac user but have you tried the official R downloads web 
site, The Comprehensive R Archive Network - CRAN?
Here is the link:

https://cran.r-project.org/

Hope this helps,

Rui Barradas

?s 15:58 de 06/10/2022, Julie Coughlin escreveu:
> Hi ,
> Can you send me a later version of r programming to use on my macos version
> 10.12.6? The newest r program is not compatible with my macbook.
> Thank you, Julie :)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tder@mu@ @end|ng |rom p@rtner@@org  Thu Oct  6 17:49:11 2022
From: tder@mu@ @end|ng |rom p@rtner@@org (Deramus, Thomas Patrick)
Date: Thu, 6 Oct 2022 15:49:11 +0000
Subject: [R] Getting "Error in ect,
 plot.new has not been called yet" despite grouping plot call
In-Reply-To: <CAPPM_gSq9VLwEiyB6HkfdUj6gMRtJTJKW4nWFFqB-K=ta9ny_w@mail.gmail.com>
References: <PH0PR04MB7493E39389D0196BEC260CB6BE5A9@PH0PR04MB7493.namprd04.prod.outlook.com>
 <20221005230608.793c8b9f@rolf-Latitude-E7470>
 <PH0PR04MB7493CE9332F02B56C0AFE31FBE5D9@PH0PR04MB7493.namprd04.prod.outlook.com>
 <CAHqSRuQmJoXwhho2KcHijv9PcEo1fARQZ824OeqV_2X3aFmNmg@mail.gmail.com>
 <CAPPM_gSq9VLwEiyB6HkfdUj6gMRtJTJKW4nWFFqB-K=ta9ny_w@mail.gmail.com>
Message-ID: <PH0PR04MB74937BB697BA2C3F61868804BE5C9@PH0PR04MB7493.namprd04.prod.outlook.com>

Truly appreciate it Bill.

Will try to make something more trimmed down in the future, but unfortunately have to admit I am more of an R neophyte than I would like to be.
________________________________
From: Joshua Ulrich <josh.m.ulrich at gmail.com>
Sent: Thursday, October 6, 2022 11:26 AM
To: Bill Dunlap <williamwdunlap at gmail.com>
Cc: Deramus, Thomas Patrick <tderamus at partners.org>; r-help at r-project.org <r-help at r-project.org>
Subject: Re: [R] Getting "Error in ect, plot.new has not been called yet" despite grouping plot call

        External Email - Use Caution

On Thu, Oct 6, 2022 at 9:44 AM Bill Dunlap <williamwdunlap at gmail.com> wrote:
>
> Here is how you could have made an example that helpers could easily run.
> It also includes the fix.
>
> f <- function(print.it = FALSE) {
>    pdf(file.pdf <- tempfile(fileext=".pdf"))
>    series <- as.xts(setNames(sin(seq(0,10,by=.1)),
> seq(as.Date("2022-10-06"),by="weeks",len=101)))
>    p <- plot(series)
>    if (print.it) {
>        print(p)
>    }
>    sm_series_2 <- smooth(series / 2)
>    lines(sm_series_2, col="red")
>    abline(h=0.1, col="blue")
>    dev.off()
>    file.pdf
> }
> > f()
> Error in plot.xy(xy.coords(x, y), type = type, ...) :
>   plot.new has not been called yet
> > f(TRUE)
> [1]
> "C:\\Users\\willi\\AppData\\Local\\Temp\\Rtmp0wX7rO\\file34843df652c.pdf"
>
> If you remove the pdf() and dev.off() I think you will see that the added
> lines do not show up.  I think plot.xts fiddles with the coordinate system
> before and after it plots so that add-ons must be done in a special way.
>

plot.xts() waits until the plot is rendered before calculating the
coordinate system. That allows users to add multiple series that have
different values for the index (x-axis) and data (y-axis).

lines() doesn't show up in your example because it's called after the
plot is rendered, and it's not rendered again after they're added.
`sm_series_2` also needs to be an xts object, otherwise lines.xts() is
not dispatched.

title() and abline() need to be called after the plot is rendered
because they are standard graphics functions. I admit that's very
confusing... I'll see what I can do to fix that.

Here's a revised example that works for me:

f <- function(print.it = FALSE)
{
    pdf(file.pdf <- tempfile(fileext=".pdf"))
    series <- xts(sin(seq(0,10,by=.1)),
seq(as.Date("2022-10-06"),by="weeks",length.out=101))
    p <- plot(series)
    sm2 <- xts(smooth(series/2), index(series))
    lines(sm2, col="red")
    if (print.it) {
        print(p)
        title("Sine curve example")
        abline(h=0.1, col="green")
    }
    dev.off()
    file.pdf
}
f(TRUE)



> -Bill
>
> On Thu, Oct 6, 2022 at 12:42 AM Deramus, Thomas Patrick <
> tderamus at partners.org> wrote:
>
> > Hi Rolf.
> >
> > I followed your suggestion (though it's probably not as trimmed as it
> > could be), but the problem unfortunately persists.
> >
> > Does this make it any clearer or still too many moving parts to make sense
> > of?
> >
> > rm(list = ls(all.names = TRUE)) #will clear all objects includes hidden
> > objects.
> >
> > #Loads the packages
> > library(plyr)
> > library(dplyr)
> > library(ggplot2)
> > library(Kendall)
> > library(lubridate)
> > library(xts)
> > library(TTR)
> > library(trend)
> > library(forecast)
> > library(openxlsx)
> >
> > #Uses the learningCurve Package from Github:
> > #https://secure-web.cisco.com/1GC2a24rvTQn4ZsRD2yEzdiU8p0VcreF81tS2HTnyYa7VJF5IpO2yI1E7CRvAjkTDIaj6KEYqjTGRSAenLfIdC6jV3OEUiCZS17V58pTwQ-55guIdhru6Sek8uJuW1ts44qoo8ZbniSWEwzzch1DcQTxCe9raR3xZavXdeOins1Yzg7le2LJWuRBEk8s9CxpKUsKa9l3qmWmjRszIWVX7nZSBTjnNOFTcJgqc8MQu8qZojb4GwCZ8mlP7U4dQdClXlDxxlTL6kF-Awi1NmycuaWn8MYEjxDTpdyqw97MAkHjESJbjB7Hfv93No-E5_9cp/https%3A%2F%2Fgithub.com%2FAFIT-R%2FlearningCurve
> > library(learningCurve)
> >
> > #Only load this if using VS Studio because it changes the plot function
> > #
> > https://secure-web.cisco.com/19uRRA2OdQiP-LFePtct8U8sQ1opEP7PrOFLjX3GDTAREApng8FFteGdDY-n8lnkoclvIekYRw4YgvqG24Tsovdeq3hKnKx6iBpWoAy-tOijBFwH0AKBvugicSxwCStU9yZANYx2BTYDd8bYZoEkwTYnthGTH4AKLybu5ek_wJMX0hCEzx9IxjRZ-03ISDvocEUUspf4uxi841j1qW7mAZ3WMj4pjTUa8mlUznIxtkTeEdGYN0X4j3Q5iiwLin6l0gntobwjoaTMv_0kq8hQe6_cYJCxBVxU-CEYcY8KPjsM9YBC-oYeFhUt13Wqlj-mO/https%3A%2F%2Fstackoverflow.com%2Fquestions%2F52284345%2Fhow-to-show-r-graph-from-visual-studio-code
> > library(httpgd)
> > library(languageserver)
> >
> > #Loads the Excel files to Dataframes and cleans the data
> > Game_Metrics_Word_Task <-
> > read.xlsx("GamePack_Analytics_ALL_TIME_Short.xlsx", "Boggle")
> > Game_Metrics_Word_Task <- Game_Metrics_Word_Task %>% filter(grepl('1440',
> > StudyId))
> > Game_Metrics_Word_Task$DeviceTime <-
> > ymd_hms(Game_Metrics_Word_Task$DeviceTime,  tz = "America/New_York")
> > Game_Metrics_Word_Task <-
> > Game_Metrics_Word_Task[!duplicated(Game_Metrics_Word_Task[1:2,])]
> >
> > #Splits the dataframe into a tibble containing each participant
> > Participant_Word_Task <-
> > split(arrange(Game_Metrics_Word_Task,StudyId,DeviceTime),
> > arrange(Game_Metrics_Word_Task,StudyId,DeviceTime,StudyId,DeviceTime)$StudyId)
> >
> > #Generates a blank output dataframe
> > WordFrame <- data.frame(Participant = c(0), Task = c(0), MannKendall_Tau =
> > c(0), MannKendall_P = c(0), Sen_Slope_Value = c(0), Sen_Slope_Pval = c(0),
> > Pettitts_CIV = c(0), Pettitts_Pval = c(0), ARIMA_Model = c(0),
> > Time_to_Petit = c(0), Number_of_Trials_to_Pettitt = c(0),
> > Playtime_to_Petit_seconds = c(0), Time_Start_to_end_days = c(0),
> > Number_of_Total_Trials = c(0), Total_Playtime_seconds = c(0),
> > Learning_rate_days = c(0), Learning_rate_seconds = c(0), Learned_Task =
> > c(0))
> >
> > #The number of subjects in the xlsx file
> > #Reduced to 2 for ease of use
> > for (i in 1:2){
> >   #This timeseries only includes the trials where the participant
> > completed the task
> >   success_series <- xts(filter(Participant_Word_Task[[i]], GameEndReason
> > == "TIMER_UP")$NumberOfSuccesfulWords , order.by=as.POSIXct(filter(Participant_Word_Task[[i]],
> > GameEndReason == "TIMER_UP")$DeviceTime))
> >   #This timeseries includes ALL the trials for the sake of plotting
> >   original_series <-
> > xts(Participant_Word_Task[[i]]$NumberOfSuccesfulWords, order.by
> > =as.POSIXct(Participant_Word_Task[[i]]$DeviceTime))
> >
> >   #This is a decomposing process that xts seems to need for plotting.
> >   #nweeks is needed for xts to plot the x-axis
> >   success_decomp <- ts(success_series, frequency = nweeks(success_series))
> >   original_decomp <- ts(original_series, frequency =
> > nweeks(success_series))
> >
> >   #Values which will be included in the plots
> >   WordFrame[i,1] <- unique(Participant_Word_Task[[i]]$StudyId)
> >   WordFrame[i,5] <- sens.slope(success_decomp)$estimates
> >   WordFrame[i,6] <- sens.slope(success_decomp)$p.value
> >   WordFrame[i,7] <- pettitt.test(success_decomp)$estimate
> >   WordFrame[i,8] <- pettitt.test(success_decomp)$p.value
> >
> >   #The simple moving average that will be overlayed with the plotted data
> >   simplemovingaverage <- SMA(original_series, n = nweeks(original_series))
> >
> >   #If the three tests are statistically significant, add a green
> > horizontal like to value WordFrame[i,7]
> >   #Which would be where the slope changes in the series
> >   #Fluid variables have been removed from all pdf() and paste() functions
> > for ease-of-use
> >   if (WordFrame[i,4] <= 0.05 & WordFrame[i,6] <= 0.05 & WordFrame[i,8] <=
> > 0.05){
> >      {
> >       pdf(file = "Word_Task_Acquisition.pdf")
> >       plout <- plot(original_series)
> >       lines(simplemovingaverage)
> >       abline(v = index(original_series[WordFrame[i,7]]),lty=2,
> > col='green', lwd=3)
> >       title(paste("Word Task Acquisition for Subject"))
> >       dev.off()
> >      }
> >   #If the three tests are NOT statistically significant, generate a plot
> > with NO horizontal line at WordFrame[i,7]
> >   } else {
> >     {
> >       pdf(file = "Word_Task_Acquisition.pdf")
> >       plout <- plot(original_series)
> >       lines(simplemovingaverage)
> >       title(paste("Word Task Acquisition for Subject"))
> >       dev.off()
> >     }
> >   }
> > }
> >
> > ________________________________
> > From: Rolf Turner <r.turner at auckland.ac.nz>
> > Sent: Wednesday, October 5, 2022 6:06 AM
> > To: Deramus, Thomas Patrick <tderamus at partners.org>
> > Cc: r-help at r-project.org <r-help at r-project.org>
> > Subject: Re: [R] Getting "Error in ect, plot.new has not been called yet"
> > despite grouping plot call
> >
> >         External Email - Use Caution
> >
> > What you doing or trying to do is far too complex for my poor feeble
> > and senile brain to come anywhere near comprehending.  The code that
> > you present exceeds my complexity tolerance by many orders of magnitude.
> >
> > I have a suggestion, but.  Strip your code down to the *essentials*.
> > Construct a simple sequence of plotting commands, with *simple* names
> > for the pdf files involved.  You should require only two or three such
> > files and two or three index levels associated with each of your
> > nested loops.
> >
> > Run the stripped down code and the source of the problem will almost
> > surely become clear.
> >
> > cheers,
> >
> > Rolf Turner
> >
> > On Tue, 4 Oct 2022 23:35:09 +0000
> > "Deramus, Thomas Patrick" <tderamus at partners.org> wrote:
> >
<snip>
> > > ?Issac Asimov
> >
> > The information in this e-mail is intended only for th...{{dropped:22}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://secure-web.cisco.com/1SgVzv3MhZxjS8lVtL-AremtzH9si_AP6nzXeP88cMer7WPpSbOcW6bQxA1_OS8tZfnCR4A2dnkLji0Xp6WSmRSij8pKrLyRC88Hs_VerYcbpwTmmsgMvWy-fJqib7KS0Pe3sz6uw8bjRWL1kqrus4AEumxFWNkTUdne-TFZJSuNOREO0uZ2-TQIu-Xb6N4Dts3snQ7ChYqiEZbiv009G2CofS-41urHFmbmtfEXay8g9SlLFflx1YVNoU2VK8lToEb-0BFCetotnxGlK_wLqGKAF11eE4HGUA_uZuBHB9zwWAiNpEPZ0RaZ5oleTjlRY/https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help
> PLEASE do read the posting guide http://secure-web.cisco.com/128DnoUBGpXNKPpn-_IIbo2_5a9sLNJXREjbFp3cT2Ho_IxpgACzE8mFRNc3SzHQtfOzJ7UGe-7kbG4pMAw6xbxdx5U0P4WtBPr4etT4P1F4zmWvXwthbNt1gleb4i2WNnIXgrne6n5jGt0Aj3mZCVuUft56CCVyopOOVaA-8O093biCfDFWuT2Mgi0UZC6jKiUoBb4jpGoAwrvWIt8BatRnhER5zyL4EeEjR4Hztxlw0sdOQX71AT7bclT9UtV7ZcYPpCw8MSPYNEXd2rUIeYqbPaYwwLJYIfhpMCq2fimy6N1BLxClytQzF1IUo77Rv/http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  http://secure-web.cisco.com/1a6xFSrjm-kcAD3kFpY-MqFccS9tOSo60B0iS6Vc-3YL2jcoq-n2LgKPqVzbQ5ir8uo_2QTYF5GdGxAAniCa47MXagKCxQLoHf-QDEpHuk0HUSvYaXhf3mMKt6FA9Gyao_ZDezq8FCdAeyqdDbuf2UpRQWX7h6AlgMfRZgoxY1j7cr15jkXNPjs7nR9Jr6S5VH37YmzyrbIfBlYqY2rIPUt2BgnyqUDbXknZbB2JVHKw5giicByw9dzXuIhiEm357Wjcy5vwCvn8BuoAuymq17BRKc98dGSO1cbflw94gPWR5m8x6kZq1sa-Li8l7BB62/http%3A%2F%2Fwww.fosstrading.com
The information in this e-mail is intended only for the ...{{dropped:15}}


From kry|ov@r00t @end|ng |rom gm@||@com  Thu Oct  6 17:52:46 2022
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Thu, 6 Oct 2022 18:52:46 +0300
Subject: [R] (no subject)
In-Reply-To: <CAAsvtakY89Vi5Uk0rZJtXfBy1-4AvpYEe7fBbRWoKD_t+7sqAQ@mail.gmail.com>
References: <CAAsvtakY89Vi5Uk0rZJtXfBy1-4AvpYEe7fBbRWoKD_t+7sqAQ@mail.gmail.com>
Message-ID: <20221006185246.5bec0ea9@arachnoid>

Hi Julie,

? Thu, 6 Oct 2022 10:58:51 -0400
Julie Coughlin <jcoughlin at umass.edu> ?????:

> Can you send me a later version of r programming to use on my macos
> version 10.12.6? The newest r program is not compatible with my
> macbook.

Since R 4.0.0, the official builds of R require macOS ? 10.13. The
Homebrew project doesn't seem to have any binaries for 10.12 either,
but it should be able to build R for you:
https://formulae.brew.sh/formula/r#default

Alternatively, you can follow the guide at
https://cran.r-project.org/doc/manuals/r-release/R-admin.html and build
the source code yourself.

We have a special mailing list dedicated to Mac-related questions:
r-sig-mac at r-project.org

-- 
Best regards,
Ivan


From m@r|ne@@nder@@on @end|ng |rom k|@@e  Fri Oct  7 13:57:36 2022
From: m@r|ne@@nder@@on @end|ng |rom k|@@e (Marine Andersson)
Date: Fri, 7 Oct 2022 11:57:36 +0000
Subject: [R] Ids with matching number combinations?
Message-ID: <GV3P280MB0691B68DAEE14884207FEDE88F5F9@GV3P280MB0691.SWEP280.PROD.OUTLOOK.COM>

Hi,

If I have two datasets like this:
df=data.frame("id"=rep(1:10,10, each=10), "item1"=sample(1:20, 100, replace=T)
df2=data.frame("a"=c(8, 8,10,9, 5, 1,2,1), "b"=c(16,18,11, 19,18, 11,17,12))

How do I find out which ids in the df dataset that has a match for both the numbers occuring in the same row in the df2 dataframe? In the output I would like to get the matching id and the rownumber from the df2.

Output something like this
Id                        Rownr
2                         1
5                         1
7                         4

My actual problem is more complex with even more columns to be matched and the datasets are large, hence the solution needs to be efficient.

Kind regards,





N?r du skickar e-post till Karolinska Institutet (KI) inneb?r detta att KI kommer att behandla dina personuppgifter. H?r finns information om hur KI behandlar personuppgifter<https://ki.se/medarbetare/integritetsskyddspolicy>.


Sending email to Karolinska Institutet (KI) will result in KI processing your personal data. You can read more about KI's processing of personal data here<https://ki.se/en/staff/data-protection-policy>.

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Fri Oct  7 16:02:01 2022
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Fri, 7 Oct 2022 14:02:01 +0000
Subject: [R] Ids with matching number combinations?
In-Reply-To: <GV3P280MB0691B68DAEE14884207FEDE88F5F9@GV3P280MB0691.SWEP280.PROD.OUTLOOK.COM>
References: <GV3P280MB0691B68DAEE14884207FEDE88F5F9@GV3P280MB0691.SWEP280.PROD.OUTLOOK.COM>
Message-ID: <c6b363da531c457d92349b90d9622562@SRVEXCHCM1302.precheza.cz>

Hallo Marine

Could you please make your example more reproducible by using set.seed (and
maybe smaller)?

If I understand correctly, you want to know if let say row 1 items from df2
(8,16) are both in item column of specific id?

If I am correct in guessing, I cannot find another solution than split your
df according to id
x <- split(df, df$id)[[1]]

and for each row of df2 test if within the specified id you can find both
numbers.
sum(is.element(df2[1,], x$item))==2
[1] FALSE

So basically 2 cycles, one for df ids and the other for df2 rows.

But maybe somebody will give you more ingenious answer.

Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Marine Andersson
> Sent: Friday, October 7, 2022 1:58 PM
> To: r-help at r-project.org
> Subject: [R] Ids with matching number combinations?
> 
> Hi,
> 
> If I have two datasets like this:
> df=data.frame("id"=rep(1:10,10, each=10), "item1"=sample(1:20, 100,
> replace=T)
> df2=data.frame("a"=c(8, 8,10,9, 5, 1,2,1), "b"=c(16,18,11, 19,18,
11,17,12))
> 
> How do I find out which ids in the df dataset that has a match for both
the
> numbers occuring in the same row in the df2 dataframe? In the output I
would
> like to get the matching id and the rownumber from the df2.
> 
> Output something like this
> Id                        Rownr
> 2                         1
> 5                         1
> 7                         4
> 
> My actual problem is more complex with even more columns to be matched and
> the datasets are large, hence the solution needs to be efficient.
> 
> Kind regards,
> 
> 
> 
> 
> 
> N?r du skickar e-post till Karolinska Institutet (KI) inneb?r detta att KI
kommer
> att behandla dina personuppgifter. H?r finns information om hur KI
behandlar
> personuppgifter<https://ki.se/medarbetare/integritetsskyddspolicy>.
> 
> 
> Sending email to Karolinska Institutet (KI) will result in KI processing
your
> personal data. You can read more about KI's processing of personal data
> here<https://ki.se/en/staff/data-protection-policy>.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From tebert @end|ng |rom u||@edu  Fri Oct  7 17:16:11 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Fri, 7 Oct 2022 15:16:11 +0000
Subject: [R] Ids with matching number combinations?
In-Reply-To: <c6b363da531c457d92349b90d9622562@SRVEXCHCM1302.precheza.cz>
References: <GV3P280MB0691B68DAEE14884207FEDE88F5F9@GV3P280MB0691.SWEP280.PROD.OUTLOOK.COM>
 <c6b363da531c457d92349b90d9622562@SRVEXCHCM1302.precheza.cz>
Message-ID: <BN6PR2201MB1553C2DAEB2446765597435CCF5F9@BN6PR2201MB1553.namprd22.prod.outlook.com>

Would an inner_join work? If not, please describe why so that we can improve our answer. This answer requires the dplyr package.
https://statisticsglobe.com/r-dplyr-join-inner-left-right-full-semi-anti

Regards,
Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of PIKAL Petr
Sent: Friday, October 7, 2022 10:02 AM
To: Marine Andersson <marine.andersson at ki.se>; r-help at r-project.org
Subject: Re: [R] Ids with matching number combinations?

[External Email]

Hallo Marine

Could you please make your example more reproducible by using set.seed (and maybe smaller)?

If I understand correctly, you want to know if let say row 1 items from df2
(8,16) are both in item column of specific id?

If I am correct in guessing, I cannot find another solution than split your df according to id x <- split(df, df$id)[[1]]

and for each row of df2 test if within the specified id you can find both numbers.
sum(is.element(df2[1,], x$item))==2
[1] FALSE

So basically 2 cycles, one for df ids and the other for df2 rows.

But maybe somebody will give you more ingenious answer.

Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Marine 
> Andersson
> Sent: Friday, October 7, 2022 1:58 PM
> To: r-help at r-project.org
> Subject: [R] Ids with matching number combinations?
>
> Hi,
>
> If I have two datasets like this:
> df=data.frame("id"=rep(1:10,10, each=10), "item1"=sample(1:20, 100,
> replace=T)
> df2=data.frame("a"=c(8, 8,10,9, 5, 1,2,1), "b"=c(16,18,11, 19,18,
11,17,12))
>
> How do I find out which ids in the df dataset that has a match for 
> both
the
> numbers occuring in the same row in the df2 dataframe? In the output I
would
> like to get the matching id and the rownumber from the df2.
>
> Output something like this
> Id                        Rownr
> 2                         1
> 5                         1
> 7                         4
>
> My actual problem is more complex with even more columns to be matched 
> and the datasets are large, hence the solution needs to be efficient.
>
> Kind regards,
>
>
>
>
>
> N?r du skickar e-post till Karolinska Institutet (KI) inneb?r detta 
> att KI
kommer
> att behandla dina personuppgifter. H?r finns information om hur KI
behandlar
> personuppgifter<https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fki.se%2Fmedarbetare%2Fintegritetsskyddspolicy&amp;data=05%7C01%7Ctebert%40ufl.edu%7C7346e6bc695846d7264508daa86cac5a%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638007482638899002%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000%7C%7C%7C&amp;sdata=%2F17yDHhLyAUZFLVC9g73jTSLvncGW89KB5SiBpMo1u8%3D&amp;reserved=0>.
>
>
> Sending email to Karolinska Institutet (KI) will result in KI 
> processing
your
> personal data. You can read more about KI's processing of personal 
> data here<https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fki.se%2Fen%2Fstaff%2Fdata-protection-policy&amp;data=05%7C01%7Ctebert%40ufl.edu%7C7346e6bc695846d7264508daa86cac5a%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638007482638899002%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000%7C%7C%7C&amp;sdata=E6valRizvf2Ff5TSUUp6ut30E6D3BF%2BiMNDrmDOZxfs%3D&amp;reserved=0>.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat
> .ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=05%7C01%7Ctebert%40ufl
> .edu%7C7346e6bc695846d7264508daa86cac5a%7C0d4da0f84a314d76ace60a62331e
> 1b84%7C0%7C0%7C638007482638899002%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4w
> LjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000%7C%7C%7C
> &amp;sdata=hKFMIJOKSUHjM7GRTn9RkTAMocHRQQwO5lB6tUMe%2FUI%3D&amp;reserv
> ed=0
> PLEASE do read the posting guide
https://nam10.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=05%7C01%7Ctebert%40ufl.edu%7C7346e6bc695846d7264508daa86cac5a%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638007482638899002%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000%7C%7C%7C&amp;sdata=dM%2BvORlAYU2%2F0uHF9d%2F3sEl4GdurEGDjgk%2Bs6QxazZQ%3D&amp;reserved=0
> and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Oct  7 17:20:28 2022
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 07 Oct 2022 08:20:28 -0700
Subject: [R] Ids with matching number combinations?
In-Reply-To: <BN6PR2201MB1553C2DAEB2446765597435CCF5F9@BN6PR2201MB1553.namprd22.prod.outlook.com>
References: <GV3P280MB0691B68DAEE14884207FEDE88F5F9@GV3P280MB0691.SWEP280.PROD.OUTLOOK.COM>
 <c6b363da531c457d92349b90d9622562@SRVEXCHCM1302.precheza.cz>
 <BN6PR2201MB1553C2DAEB2446765597435CCF5F9@BN6PR2201MB1553.namprd22.prod.outlook.com>
Message-ID: <880DC400-42AF-40E2-9AFD-A1CA1F20A831@dcn.davis.ca.us>

The merge function doesn't require a package.

But inner_join may be faster than merge.

On October 7, 2022 8:16:11 AM PDT, "Ebert,Timothy Aaron" <tebert at ufl.edu> wrote:
>Would an inner_join work? If not, please describe why so that we can improve our answer. This answer requires the dplyr package.
>https://statisticsglobe.com/r-dplyr-join-inner-left-right-full-semi-anti
>
>Regards,
>Tim
>
>-----Original Message-----
>From: R-help <r-help-bounces at r-project.org> On Behalf Of PIKAL Petr
>Sent: Friday, October 7, 2022 10:02 AM
>To: Marine Andersson <marine.andersson at ki.se>; r-help at r-project.org
>Subject: Re: [R] Ids with matching number combinations?
>
>[External Email]
>
>Hallo Marine
>
>Could you please make your example more reproducible by using set.seed (and maybe smaller)?
>
>If I understand correctly, you want to know if let say row 1 items from df2
>(8,16) are both in item column of specific id?
>
>If I am correct in guessing, I cannot find another solution than split your df according to id x <- split(df, df$id)[[1]]
>
>and for each row of df2 test if within the specified id you can find both numbers.
>sum(is.element(df2[1,], x$item))==2
>[1] FALSE
>
>So basically 2 cycles, one for df ids and the other for df2 rows.
>
>But maybe somebody will give you more ingenious answer.
>
>Cheers
>Petr
>
>
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Marine 
>> Andersson
>> Sent: Friday, October 7, 2022 1:58 PM
>> To: r-help at r-project.org
>> Subject: [R] Ids with matching number combinations?
>>
>> Hi,
>>
>> If I have two datasets like this:
>> df=data.frame("id"=rep(1:10,10, each=10), "item1"=sample(1:20, 100,
>> replace=T)
>> df2=data.frame("a"=c(8, 8,10,9, 5, 1,2,1), "b"=c(16,18,11, 19,18,
>11,17,12))
>>
>> How do I find out which ids in the df dataset that has a match for 
>> both
>the
>> numbers occuring in the same row in the df2 dataframe? In the output I
>would
>> like to get the matching id and the rownumber from the df2.
>>
>> Output something like this
>> Id                        Rownr
>> 2                         1
>> 5                         1
>> 7                         4
>>
>> My actual problem is more complex with even more columns to be matched 
>> and the datasets are large, hence the solution needs to be efficient.
>>
>> Kind regards,
>>
>>
>>
>>
>>
>> N?r du skickar e-post till Karolinska Institutet (KI) inneb?r detta 
>> att KI
>kommer
>> att behandla dina personuppgifter. H?r finns information om hur KI
>behandlar
>> personuppgifter<https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fki.se%2Fmedarbetare%2Fintegritetsskyddspolicy&amp;data=05%7C01%7Ctebert%40ufl.edu%7C7346e6bc695846d7264508daa86cac5a%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638007482638899002%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000%7C%7C%7C&amp;sdata=%2F17yDHhLyAUZFLVC9g73jTSLvncGW89KB5SiBpMo1u8%3D&amp;reserved=0>.
>>
>>
>> Sending email to Karolinska Institutet (KI) will result in KI 
>> processing
>your
>> personal data. You can read more about KI's processing of personal 
>> data here<https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fki.se%2Fen%2Fstaff%2Fdata-protection-policy&amp;data=05%7C01%7Ctebert%40ufl.edu%7C7346e6bc695846d7264508daa86cac5a%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638007482638899002%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000%7C%7C%7C&amp;sdata=E6valRizvf2Ff5TSUUp6ut30E6D3BF%2BiMNDrmDOZxfs%3D&amp;reserved=0>.
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat
>> .ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=05%7C01%7Ctebert%40ufl
>> .edu%7C7346e6bc695846d7264508daa86cac5a%7C0d4da0f84a314d76ace60a62331e
>> 1b84%7C0%7C0%7C638007482638899002%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4w
>> LjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000%7C%7C%7C
>> &amp;sdata=hKFMIJOKSUHjM7GRTn9RkTAMocHRQQwO5lB6tUMe%2FUI%3D&amp;reserv
>> ed=0
>> PLEASE do read the posting guide
>https://nam10.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=05%7C01%7Ctebert%40ufl.edu%7C7346e6bc695846d7264508daa86cac5a%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638007482638899002%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C2000%7C%7C%7C&amp;sdata=dM%2BvORlAYU2%2F0uHF9d%2F3sEl4GdurEGDjgk%2Bs6QxazZQ%3D&amp;reserved=0
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Fri Oct  7 18:19:16 2022
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 7 Oct 2022 09:19:16 -0700
Subject: [R] Ids with matching number combinations?
In-Reply-To: <GV3P280MB0691B68DAEE14884207FEDE88F5F9@GV3P280MB0691.SWEP280.PROD.OUTLOOK.COM>
References: <GV3P280MB0691B68DAEE14884207FEDE88F5F9@GV3P280MB0691.SWEP280.PROD.OUTLOOK.COM>
Message-ID: <CAGxFJbQb1LOy3X5LeOHMLS+E66fYCMy4969iPztwN_UCE6dh+A@mail.gmail.com>

Well, for a start, you might give us a reproducible example that actually
runs -- yours doesn't. Did you check? You seem to b.e missing a final
")"(Also, you do not need to quote the column names in data.frame(), though
it works fine also if you do).

Also note that in df, your id column has length 1000 and item1 column has
length 100 and will be replicated to match id. This seems to me likely to
be misspecified. Or is this what you meant?

Finally, note that that none of the rows in df2 have identical numbers, so
there is no id in df that can match both members of the row. So did you
mean that the 'id' and 'item1' value in a row of df must match the
corresponding 'a' and 'b' values of some row in df2 ?

Under the above interpretation and with the following reprex(note the use
of set.seed() to make it reproducible)...

set.seed(1234)  ## for reproducibility
df=data.frame(id=c(10,rep(1:10, each=10), item1=sample(1:20, 100,
replace=T))
df2=data.frame(a=c(8, 8,10,9, 5, 1,2,1), b=c(16,18,11, 19,18, 11,17,12))

... you can paste0() the column vectors together in each data frame(as
character values) and then just match on the single character vectors, like
this:

both <- match(do.call(paste0,df),  do.call(paste0, df2))
## subscript the data frames if you have more columns that are not used for
matching

> both
  [1] NA NA  8 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
 [21] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
 [41] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
 [61] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
 [81] NA NA NA NA NA NA NA NA NA NA  3 NA NA NA NA NA NA NA NA  3

Then
> both[!is.na(both)] ## the rows of df2 that matched
[1] 8 3 3

> which(!is.na(both)) ## the rows of df that were matched
[1]   3  91 100

This should be very efficient, as hashing is used for matching.

I think there is a slicker way to do this that combines the paste and match
functions together (other than using merge() or the like, as has already
been suggested). But I have forgotten the details or I may just be thinking
of merge(), which may indeed be a better option.

All presuming this is what you meant, of course, which it may not be. :-(

Cheers,
Bert









On Fri, Oct 7, 2022 at 5:57 AM Marine Andersson <marine.andersson at ki.se>
wrote:

> Hi,
>
> If I have two datasets like this:
> df=data.frame("id"=rep(1:10,10, each=10), "item1"=sample(1:20, 100,
> replace=T)
> df2=data.frame("a"=c(8, 8,10,9, 5, 1,2,1), "b"=c(16,18,11, 19,18,
> 11,17,12))
>
> How do I find out which ids in the df dataset that has a match for both
> the numbers occuring in the same row in the df2 dataframe? In the output I
> would like to get the matching id and the rownumber from the df2.
>
> Output something like this
> Id                        Rownr
> 2                         1
> 5                         1
> 7                         4
>
> My actual problem is more complex with even more columns to be matched and
> the datasets are large, hence the solution needs to be efficient.
>
> Kind regards,
>
>
>
>
>
> N?r du skickar e-post till Karolinska Institutet (KI) inneb?r detta att KI
> kommer att behandla dina personuppgifter. H?r finns information om hur KI
> behandlar personuppgifter<
> https://ki.se/medarbetare/integritetsskyddspolicy>.
>
>
> Sending email to Karolinska Institutet (KI) will result in KI processing
> your personal data. You can read more about KI's processing of personal
> data here<https://ki.se/en/staff/data-protection-policy>.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Sat Oct  8 12:58:03 2022
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 8 Oct 2022 21:58:03 +1100
Subject: [R] Ids with matching number combinations?
In-Reply-To: <GV3P280MB0691B68DAEE14884207FEDE88F5F9@GV3P280MB0691.SWEP280.PROD.OUTLOOK.COM>
References: <GV3P280MB0691B68DAEE14884207FEDE88F5F9@GV3P280MB0691.SWEP280.PROD.OUTLOOK.COM>
Message-ID: <CA+8X3fWzADdqGdxbFo2rifQOgNSuD5jNZi386=cFKuTSP0wf=Q@mail.gmail.com>

Hi Marine,
I'm not sure that I have the right idea, but this worked for me and may help.

# I had to fix this line
df<-data.frame(id=rep(1:10,each=10),item1=sample(1:20, 100, replace=TRUE))
df2<-data.frame(a=c(8, 8,10,9, 5, 1,2,1),b=c(16,18,11, 19,18, 11,17,12))
result<-data.frame(id=df[,1],rown=1:dim(df)[1],matched=rep(FALSE,dim(dfw)[1]))
# function that checks that all entries in vector a exist in vector x
match_all_a<-function(a,x,index) {
 inx<-TRUE
 for(i in 1:length(a)) inx <- inx && a[i] %in% x[-1]
 return(list(id=x[1],rown=index,matched=inx))
}
# step through the data frame
for(i in df[,1]) result[i,]<-match_all_a(df2[i,],df[i,],i)
# display the result id, row in df, whether matched
result
# select the rows of result for which matched is TRUE

Jim

On Fri, Oct 7, 2022 at 11:57 PM Marine Andersson <marine.andersson at ki.se> wrote:
>
> Hi,
>
> If I have two datasets like this:
> df=data.frame("id"=rep(1:10,10, each=10), "item1"=sample(1:20, 100, replace=T)
> df2=data.frame("a"=c(8, 8,10,9, 5, 1,2,1), "b"=c(16,18,11, 19,18, 11,17,12))
>
> How do I find out which ids in the df dataset that has a match for both the numbers occuring in the same row in the df2 dataframe? In the output I would like to get the matching id and the rownumber from the df2.
>
> Output something like this
> Id                        Rownr
> 2                         1
> 5                         1
> 7                         4
>
> My actual problem is more complex with even more columns to be matched and the datasets are large, hence the solution needs to be efficient.
>
> Kind regards,
>
>
>
>
>
> N?r du skickar e-post till Karolinska Institutet (KI) inneb?r detta att KI kommer att behandla dina personuppgifter. H?r finns information om hur KI behandlar personuppgifter<https://ki.se/medarbetare/integritetsskyddspolicy>.
>
>
> Sending email to Karolinska Institutet (KI) will result in KI processing your personal data. You can read more about KI's processing of personal data here<https://ki.se/en/staff/data-protection-policy>.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


