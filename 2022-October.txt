From @v|@e@gro@@ @end|ng |rom gm@||@com  Sat Oct  1 01:01:28 2022
From: @v|@e@gro@@ @end|ng |rom gm@||@com (Avi Gross)
Date: Fri, 30 Sep 2022 19:01:28 -0400
Subject: [R] Reading very large text files into R
In-Reply-To: <BN6PR2201MB15533DA430761C7B4A46AD15CF569@BN6PR2201MB1553.namprd22.prod.outlook.com>
References: <CABxY9BMk+Y82OV8Rcaoe-r+GeheN9ji6hvGpjVjejKD0h0=E+A@mail.gmail.com>
 <CABcYAdKtUWnUdpMBOZ6R_EajctOtVAHa=DUd6X4ytEr9H_acVQ@mail.gmail.com>
 <BN6PR2201MB155318FFE325C623BE53AAC2CF569@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <004e01d8d501$12d6f2f0$3884d8d0$@gmail.com>
 <BN6PR2201MB15533DA430761C7B4A46AD15CF569@BN6PR2201MB1553.namprd22.prod.outlook.com>
Message-ID: <CABaFrRZkz8td3gzznUbSkmy=F5gacnCigGkGpnpiY7xiwKDMBQ@mail.gmail.com>

Those are valid reasons as examining data and cleaning or fixing it is a
major thing to do before making an analysis or plots. Indeed, an extra
column caused by something in an earlier column mat have messed up all
columns to the right.

My point was about replicating a problem like this may require many more
lines from the file.

On Fri, Sep 30, 2022, 5:58 PM Ebert,Timothy Aaron <tebert at ufl.edu> wrote:

> The point was more to figure out why most lines have 15 values and some
> give an error indicating that there are 16. Are there notes, or an extra
> comma? Some weather stations fail and give interesting data at, before, or
> after failure. Are the problem lines indicating machine failure? Typically
> code does not randomly enter extra data. Most answers appear to assume that
> the 16th column has been entered at the end of the data, but no evidence
> indicates this is true. If there is an initial value at the beginning of
> the row, then all of the data for that row will be in error if the "16"
> value is deleted. I am just paranoid enough to suggest looking at one case
> to make sure all is as assumed.
>    Another way to address the problem is to test the data. Are there
> temperatures less than -100 C or greater than 60 C? Why would one ever get
> such a thing? Machine error, or a column misaligned so that humidity values
> are in the temperature column.
>
> Tim
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of
> avi.e.gross at gmail.com
> Sent: Friday, September 30, 2022 3:16 PM
> Cc: r-help at r-project.org
> Subject: Re: [R] Reading very large text files into R
>
> [External Email]
>
> Tim and others,
>
> A point to consider is that there are various algorithms in the functions
> used to read in formatted data into data.frame form and they vary. Some do
> a look-ahead of some size to determine things and if they find a column
> that LOOKS LIKE all integers for say the first thousand lines, they go and
> read in that column as integer. If the first floating point value is
> thousands of lines further along, things may go wrong.
>
> So asking for line/row 16 to have an extra 16th entry/column may work fine
> for an algorithm that looks ahead and concludes there are 16 columns
> throughout. Yet a file where the first time a sixteenth entry is seen is at
> line/row 31,459 may well just set the algorithm to expect exactly 15
> columns and then be surprised as noted above.
>
> I have stayed out of this discussion and others have supplied pretty much
> what I would have said. I also see the data as flawed and ask which rows
> are the valid ones. If a sixteenth column is allowed, it would be better if
> all other rows had an empty sixteenth column. If not allowed, none should
> have it.
>
> The approach I might take, again as others have noted, is to preprocess
> the data file using some form of stream editor such as AWK that
> automagically reads in a line at a time and parses lines into a collection
> of tokens based on what separates them such as a comma. You can then either
> write out just the first 15 to the output stream if your choice is to
> ignore a spurious sixteenth, or write out all sixteen for every line, with
> the last being some form of null most of the time. And, of course, to be
> more general, you could make two passes through the file with the first one
> determining the maximum number of entries as well as what the most common
> number of entries is, and a second pass using that info to normalize the
> file the way you want. And note some of what was mentioned could often be
> done in this preprocessing such as removing any columns you do not want to
> read into R later. Do note such filters may need to handle edge cases like
> skipping comment lines or treating the row of headers differently.
>
> As some have shown, you can create your own filters within a language like
> R too and either read in lines and pre-process them as discussed or
> continue on to making your own data.frame and skip the read.table() type of
> functionality. For very large files, though, having multiple variations in
> memory at once may be an issue, especially if they are not removed and
> further processing and analysis continues.
>
> Perhaps it might be sensible to contact those maintaining the data and
> point out the anomaly and ask if their files might be saved alternately in
> a format that can be used without anomalies.
>
> Avi
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Ebert,Timothy
> Aaron
> Sent: Friday, September 30, 2022 7:27 AM
> To: Richard O'Keefe <raoknz at gmail.com>; Nick Wray <nickmwray at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] Reading very large text files into R
>
> Hi Nick,
>    Can you post one line of data with 15 entries followed by the next line
> of data with 16 entries?
>
> Tim
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=05%7C01%7Ctebert%40ufl.edu%7C3d75da30d3744c13847308daa3184c98%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638001622016765705%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=5w0Yrih%2Fxf09zpgabscAzMTVzcw4nhjNKX5%2FgWEPVWk%3D&amp;reserved=0
> PLEASE do read the posting guide
> https://nam10.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=05%7C01%7Ctebert%40ufl.edu%7C3d75da30d3744c13847308daa3184c98%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638001622016765705%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=K4ddCaLbSB5XU8TELCMhDEFsG4drevbeRp2YKPxY2ag%3D&amp;reserved=0
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tebert @end|ng |rom u||@edu  Sat Oct  1 01:43:01 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Fri, 30 Sep 2022 23:43:01 +0000
Subject: [R] Reading very large text files into R
In-Reply-To: <CABaFrRZkz8td3gzznUbSkmy=F5gacnCigGkGpnpiY7xiwKDMBQ@mail.gmail.com>
References: <CABxY9BMk+Y82OV8Rcaoe-r+GeheN9ji6hvGpjVjejKD0h0=E+A@mail.gmail.com>
 <CABcYAdKtUWnUdpMBOZ6R_EajctOtVAHa=DUd6X4ytEr9H_acVQ@mail.gmail.com>
 <BN6PR2201MB155318FFE325C623BE53AAC2CF569@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <004e01d8d501$12d6f2f0$3884d8d0$@gmail.com>
 <BN6PR2201MB15533DA430761C7B4A46AD15CF569@BN6PR2201MB1553.namprd22.prod.outlook.com>
 <CABaFrRZkz8td3gzznUbSkmy=F5gacnCigGkGpnpiY7xiwKDMBQ@mail.gmail.com>
Message-ID: <BN6PR2201MB1553B86BFEE83B5EDD382CD9CF569@BN6PR2201MB1553.namprd22.prod.outlook.com>

Truth

Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Avi Gross
Sent: Friday, September 30, 2022 7:01 PM
Cc: R help Mailing list <r-help at r-project.org>
Subject: Re: [R] Reading very large text files into R

[External Email]

Those are valid reasons as examining data and cleaning or fixing it is a major thing to do before making an analysis or plots. Indeed, an extra column caused by something in an earlier column mat have messed up all columns to the right.

My point was about replicating a problem like this may require many more lines from the file.

On Fri, Sep 30, 2022, 5:58 PM Ebert,Timothy Aaron <tebert at ufl.edu> wrote:

> The point was more to figure out why most lines have 15 values and 
> some give an error indicating that there are 16. Are there notes, or 
> an extra comma? Some weather stations fail and give interesting data 
> at, before, or after failure. Are the problem lines indicating machine 
> failure? Typically code does not randomly enter extra data. Most 
> answers appear to assume that the 16th column has been entered at the 
> end of the data, but no evidence indicates this is true. If there is 
> an initial value at the beginning of the row, then all of the data for that row will be in error if the "16"
> value is deleted. I am just paranoid enough to suggest looking at one 
> case to make sure all is as assumed.
>    Another way to address the problem is to test the data. Are there 
> temperatures less than -100 C or greater than 60 C? Why would one ever 
> get such a thing? Machine error, or a column misaligned so that 
> humidity values are in the temperature column.
>
> Tim
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of 
> avi.e.gross at gmail.com
> Sent: Friday, September 30, 2022 3:16 PM
> Cc: r-help at r-project.org
> Subject: Re: [R] Reading very large text files into R
>
> [External Email]
>
> Tim and others,
>
> A point to consider is that there are various algorithms in the 
> functions used to read in formatted data into data.frame form and they 
> vary. Some do a look-ahead of some size to determine things and if 
> they find a column that LOOKS LIKE all integers for say the first 
> thousand lines, they go and read in that column as integer. If the 
> first floating point value is thousands of lines further along, things may go wrong.
>
> So asking for line/row 16 to have an extra 16th entry/column may work 
> fine for an algorithm that looks ahead and concludes there are 16 
> columns throughout. Yet a file where the first time a sixteenth entry 
> is seen is at line/row 31,459 may well just set the algorithm to 
> expect exactly 15 columns and then be surprised as noted above.
>
> I have stayed out of this discussion and others have supplied pretty 
> much what I would have said. I also see the data as flawed and ask 
> which rows are the valid ones. If a sixteenth column is allowed, it 
> would be better if all other rows had an empty sixteenth column. If 
> not allowed, none should have it.
>
> The approach I might take, again as others have noted, is to 
> preprocess the data file using some form of stream editor such as AWK 
> that automagically reads in a line at a time and parses lines into a 
> collection of tokens based on what separates them such as a comma. You 
> can then either write out just the first 15 to the output stream if 
> your choice is to ignore a spurious sixteenth, or write out all 
> sixteen for every line, with the last being some form of null most of 
> the time. And, of course, to be more general, you could make two 
> passes through the file with the first one determining the maximum 
> number of entries as well as what the most common number of entries 
> is, and a second pass using that info to normalize the file the way 
> you want. And note some of what was mentioned could often be done in 
> this preprocessing such as removing any columns you do not want to 
> read into R later. Do note such filters may need to handle edge cases like skipping comment lines or treating the row of headers differently.
>
> As some have shown, you can create your own filters within a language 
> like R too and either read in lines and pre-process them as discussed 
> or continue on to making your own data.frame and skip the read.table() 
> type of functionality. For very large files, though, having multiple 
> variations in memory at once may be an issue, especially if they are 
> not removed and further processing and analysis continues.
>
> Perhaps it might be sensible to contact those maintaining the data and 
> point out the anomaly and ask if their files might be saved 
> alternately in a format that can be used without anomalies.
>
> Avi
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Ebert,Timothy 
> Aaron
> Sent: Friday, September 30, 2022 7:27 AM
> To: Richard O'Keefe <raoknz at gmail.com>; Nick Wray 
> <nickmwray at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] Reading very large text files into R
>
> Hi Nick,
>    Can you post one line of data with 15 entries followed by the next 
> line of data with 16 entries?
>
> Tim
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat
> .ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=05%7C01%7Ctebert%40ufl
> .edu%7C5044822c1b7f45f2b5f408daa337cc46%7C0d4da0f84a314d76ace60a62331e
> 1b84%7C0%7C0%7C638001757304040018%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4w
> LjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C
> &amp;sdata=s1Vx7PfKdb12NTQFAsGPQ5k8oXBylcFyD30xtAnHqYQ%3D&amp;reserved
> =0
> PLEASE do read the posting guide
> https://nam10.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r
> -project.org%2Fposting-guide.html&amp;data=05%7C01%7Ctebert%40ufl.edu%
> 7C5044822c1b7f45f2b5f408daa337cc46%7C0d4da0f84a314d76ace60a62331e1b84%
> 7C0%7C0%7C638001757304040018%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwM
> DAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;
> sdata=Q3cceHqosMsjflLn5cPgBE58EGdE%2B7riPYhubX%2BwEL8%3D&amp;reserved=
> 0 and provide commented, minimal, self-contained, reproducible code.
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=05%7C01%7Ctebert%40ufl.edu%7C5044822c1b7f45f2b5f408daa337cc46%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638001757304040018%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=s1Vx7PfKdb12NTQFAsGPQ5k8oXBylcFyD30xtAnHqYQ%3D&amp;reserved=0
PLEASE do read the posting guide https://nam10.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=05%7C01%7Ctebert%40ufl.edu%7C5044822c1b7f45f2b5f408daa337cc46%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638001757304040018%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=Q3cceHqosMsjflLn5cPgBE58EGdE%2B7riPYhubX%2BwEL8%3D&amp;reserved=0
and provide commented, minimal, self-contained, reproducible code.


From dr@@|@m@o|@ng| @end|ng |rom gm@||@com  Sat Oct  1 14:53:00 2022
From: dr@@|@m@o|@ng| @end|ng |rom gm@||@com (Shah Alam)
Date: Sat, 1 Oct 2022 14:53:00 +0200
Subject: [R] could not find function "flexsurvreg"
Message-ID: <CA+bivFj5M5HeVawxZXeZ4S9JgZUAY2eF8DCUb_JXyNiNoLk59A@mail.gmail.com>

Dear All,
I am analyzing trial data for survival. During the loading of the R package
"flexsurv", the following error message appeared.

"Loading required package: survival
Error: package or namespace load failed for ?flexsurv? in loadNamespace(j
<- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):
 there is no package called ?lifecycle?

Despite installing lifecycle package, loading lifecycle package results in
the following error message:

Error in library(lifecycle) : there is no package called ?lifecycle?

Moreover, the flexsurvreg function in the flexsurv library also produces an
error:

Error in flexsurvreg(Surv(Time, Event) ~ 1, anc = NULL, data = data1,  :
  could not find function "flexsurvreg"

Several times I have installed and uninstalled packages, re-started R, but
the error persists.

Could anyone help me with the flexsurv package, why is it not working?

Best regards,
Shah

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Oct  1 15:29:15 2022
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sat, 1 Oct 2022 14:29:15 +0100
Subject: [R] could not find function "flexsurvreg"
In-Reply-To: <CA+bivFj5M5HeVawxZXeZ4S9JgZUAY2eF8DCUb_JXyNiNoLk59A@mail.gmail.com>
References: <CA+bivFj5M5HeVawxZXeZ4S9JgZUAY2eF8DCUb_JXyNiNoLk59A@mail.gmail.com>
Message-ID: <2975651c-bf02-4f2c-a44d-9f49b7f84deb@sapo.pt>

Hello,

Not knowing which system you have, here is a way that usually works.

1. If you are using an IDE sych as RStudio or RGui, save your work and 
exit. This is because when the packages' namepaces are loaded, the 
shared libs, if they exist, are blocked,

2. Open a terminal window
3. Run

R -q -e "install.packages(c('lifecycle', 'flexsurv'))"


The packages should now be installed.


Hope this helps,

Rui Barradas

?s 13:53 de 01/10/2022, Shah Alam escreveu:
> Dear All,
> I am analyzing trial data for survival. During the loading of the R package
> "flexsurv", the following error message appeared.
> 
> "Loading required package: survival
> Error: package or namespace load failed for ?flexsurv? in loadNamespace(j
> <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]):
>   there is no package called ?lifecycle?
> 
> Despite installing lifecycle package, loading lifecycle package results in
> the following error message:
> 
> Error in library(lifecycle) : there is no package called ?lifecycle?
> 
> Moreover, the flexsurvreg function in the flexsurv library also produces an
> error:
> 
> Error in flexsurvreg(Surv(Time, Event) ~ 1, anc = NULL, data = data1,  :
>    could not find function "flexsurvreg"
> 
> Several times I have installed and uninstalled packages, re-started R, but
> the error persists.
> 
> Could anyone help me with the flexsurv package, why is it not working?
> 
> Best regards,
> Shah
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From t@r|qkh@@|r| @end|ng |rom gm@||@com  Sun Oct  2 14:06:02 2022
From: t@r|qkh@@|r| @end|ng |rom gm@||@com (Tariq Khasiri)
Date: Sun, 2 Oct 2022 07:06:02 -0500
Subject: [R] Help with steam graph
Message-ID: <CAFy_oHAn0RGPVXG=ypbxHM_idX08=c94QOh+gpqwXVEEKYnuSw@mail.gmail.com>

Hi, i'm trying to create a steamgraph with the following data by creating a
unit indicator by combing the year and month. But, I'm getting error as :

Error in `group_by()`:
! Must group by variables found in `.data`.
? Column `com_num` is not found.
Run `rlang::last_error()` to see where the error occurred.

### Packages needed for the code
devtools::install_github("hrbrmstr/streamgraph")

library(tidyverse)
library(ggplot2)
library(dplyr)
library(steamgraph)

### Code ( The following code can be found on creator's account
https://hrbrmstr.github.io/streamgraph/  )

dat %>%
select(year, month, company, share, com_num) %>%
  tidyr::gather(company, share, -year) %>%
  group_by(year, com_num) %>%
  tally(wt=share) %>%
  ungroup %>%
  streamgraph("com_num", "n", "year") %>%
  sg_axis_x(0.8) %>%
  sg_fill_brewer("PuOr") %>%
  sg_legend(show=TRUE, label="Share: ")


### data is like the following

dput(dat)
structure(list(year = c(2018, 2019, 2019, 2019, 2019, 2019, 2019,
2019, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017,
2017, 2017, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018,
2018, 2018, 2018, 2019, 2019, 2019, 2019, 2019), month = c(12,
1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1,
2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5), company = c("ABC",
"ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "FGH", "FGH",
"FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
"FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
"FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH"
), share = c(20, 16.5, 15, 15.5, 15.5, 16, 17, 16.5, 61, 55,
53, 53, 54, 53, 58, 54, 50, 47, 55, 50, 52, 51, 51.5, 52, 53,
54, 55, 53, 54, 50, 42, 48, 41, 40, 39, 36.5, 35), com_name = c(1,
1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)), row.names = c(NA,
-37L), spec = structure(list(cols = list(year = structure(list(), class =
c("collector_double",
"collector")), month = structure(list(), class = c("collector_double",
"collector")), company = structure(list(), class = c("collector_character",
"collector")), share = structure(list(), class = c("collector_double",
"collector")), com_name = structure(list(), class = c("collector_double",
"collector"))), default = structure(list(), class = c("collector_guess",
"collector")), delim = ","), class = "col_spec"), problems = <pointer:
0x7fd732028680>, class = c("spec_tbl_df",
"tbl_df", "tbl", "data.frame"))

	[[alternative HTML version deleted]]


From m@@c|@@|mone99 @end|ng |rom gm@||@com  Sun Oct  2 12:56:44 2022
From: m@@c|@@|mone99 @end|ng |rom gm@||@com (Simone Mascia)
Date: Sun, 2 Oct 2022 12:56:44 +0200
Subject: [R] Robust standard error
Message-ID: <CAPkN0fY32F=b=RFsTuCnDytg4i=++CkB_Bw7VLN+i=0rvaBQtQ@mail.gmail.com>

Is there a way to estimate Robust standard errors when using a nls()
function? I'm trying to fit some data to a complicated model and everything
works fine with nls() but I also wanted to obtain a robust estimate of my
errors.

I tried "coeftest(m, vcov=sandwich)" and it seems to work, but so does
"coeftest(m, vcov = NeweyWest(m, lag = 4))" or "coeftest(m, vcov =
kernHAC(m, kernel = "Bartlett", bw = 5, prewhite = FALSE, adjust =
FALSE))". They return different error estimates so I wanted you to help me
understand what I should do, if I'm doing something wrong and other stuff.

Thank you

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Sun Oct  2 16:11:55 2022
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sun, 2 Oct 2022 07:11:55 -0700
Subject: [R] Help with steam graph
In-Reply-To: <CAFy_oHAn0RGPVXG=ypbxHM_idX08=c94QOh+gpqwXVEEKYnuSw@mail.gmail.com>
References: <CAFy_oHAn0RGPVXG=ypbxHM_idX08=c94QOh+gpqwXVEEKYnuSw@mail.gmail.com>
Message-ID: <0073C340-0152-48CF-BB4B-1890BFD1DDF3@comcast.net>

I don?t see a column with the name ?com_num?, so the error message makes complete sense. 

? 
David

Sent from my iPhone

> On Oct 2, 2022, at 5:06 AM, Tariq Khasiri <tariqkhasiri at gmail.com> wrote:
> 
> ?Hi, i'm trying to create a steamgraph with the following data by creating a
> unit indicator by combing the year and month. But, I'm getting error as :
> 
> Error in `group_by()`:
> ! Must group by variables found in `.data`.
> ? Column `com_num` is not found.
> Run `rlang::last_error()` to see where the error occurred.
> 
> ### Packages needed for the code
> devtools::install_github("hrbrmstr/streamgraph")
> 
> library(tidyverse)
> library(ggplot2)
> library(dplyr)
> library(steamgraph)
> 
> ### Code ( The following code can be found on creator's account
> https://hrbrmstr.github.io/streamgraph/  )
> 
> dat %>%
> select(year, month, company, share, com_num) %>%
>  tidyr::gather(company, share, -year) %>%
>  group_by(year, com_num) %>%
>  tally(wt=share) %>%
>  ungroup %>%
>  streamgraph("com_num", "n", "year") %>%
>  sg_axis_x(0.8) %>%
>  sg_fill_brewer("PuOr") %>%
>  sg_legend(show=TRUE, label="Share: ")
> 
> 
> ### data is like the following
> 
> dput(dat)
> structure(list(year = c(2018, 2019, 2019, 2019, 2019, 2019, 2019,
> 2019, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017,
> 2017, 2017, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018,
> 2018, 2018, 2018, 2019, 2019, 2019, 2019, 2019), month = c(12,
> 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1,
> 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5), company = c("ABC",
> "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "FGH", "FGH",
> "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
> "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
> "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH"
> ), share = c(20, 16.5, 15, 15.5, 15.5, 16, 17, 16.5, 61, 55,
> 53, 53, 54, 53, 58, 54, 50, 47, 55, 50, 52, 51, 51.5, 52, 53,
> 54, 55, 53, 54, 50, 42, 48, 41, 40, 39, 36.5, 35), com_name = c(1,
> 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)), row.names = c(NA,
> -37L), spec = structure(list(cols = list(year = structure(list(), class =
> c("collector_double",
> "collector")), month = structure(list(), class = c("collector_double",
> "collector")), company = structure(list(), class = c("collector_character",
> "collector")), share = structure(list(), class = c("collector_double",
> "collector")), com_name = structure(list(), class = c("collector_double",
> "collector"))), default = structure(list(), class = c("collector_guess",
> "collector")), delim = ","), class = "col_spec"), problems = <pointer:
> 0x7fd732028680>, class = c("spec_tbl_df",
> "tbl_df", "tbl", "data.frame"))
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Sun Oct  2 16:43:00 2022
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 2 Oct 2022 07:43:00 -0700
Subject: [R] Robust standard error
In-Reply-To: <CAPkN0fY32F=b=RFsTuCnDytg4i=++CkB_Bw7VLN+i=0rvaBQtQ@mail.gmail.com>
References: <CAPkN0fY32F=b=RFsTuCnDytg4i=++CkB_Bw7VLN+i=0rvaBQtQ@mail.gmail.com>
Message-ID: <CAGxFJbSTKN5C4SbGh4XRNTe95WArNd2m5XaE1gi8YgfC4ajnrg@mail.gmail.com>

You may get a helpful response here, but generally speaking, this list is
about R **programming**, and statistical issues/tutorials are off topic.
You might try
https://stackoverflow.com/questions/tagged/statistics
if you don't get adequate help here.

-- Bert

On Sun, Oct 2, 2022 at 6:42 AM Simone Mascia <masciasimone99 at gmail.com>
wrote:

> Is there a way to estimate Robust standard errors when using a nls()
> function? I'm trying to fit some data to a complicated model and everything
> works fine with nls() but I also wanted to obtain a robust estimate of my
> errors.
>
> I tried "coeftest(m, vcov=sandwich)" and it seems to work, but so does
> "coeftest(m, vcov = NeweyWest(m, lag = 4))" or "coeftest(m, vcov =
> kernHAC(m, kernel = "Bartlett", bw = 5, prewhite = FALSE, adjust =
> FALSE))". They return different error estimates so I wanted you to help me
> understand what I should do, if I'm doing something wrong and other stuff.
>
> Thank you
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From e@ @end|ng |rom enr|co@chum@nn@net  Sun Oct  2 17:59:32 2022
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Sun, 02 Oct 2022 17:59:32 +0200
Subject: [R] Robust standard error
In-Reply-To: <CAGxFJbSTKN5C4SbGh4XRNTe95WArNd2m5XaE1gi8YgfC4ajnrg@mail.gmail.com>
 (Bert Gunter's message of "Sun, 2 Oct 2022 07:43:00 -0700")
References: <CAPkN0fY32F=b=RFsTuCnDytg4i=++CkB_Bw7VLN+i=0rvaBQtQ@mail.gmail.com>
 <CAGxFJbSTKN5C4SbGh4XRNTe95WArNd2m5XaE1gi8YgfC4ajnrg@mail.gmail.com>
Message-ID: <87lepykyhn.fsf@enricoschumann.net>

On Sun, 02 Oct 2022, Bert Gunter writes:

> On Sun, Oct 2, 2022 at 6:42 AM Simone Mascia <masciasimone99 at gmail.com>
> wrote:
>
>> Is there a way to estimate Robust standard errors when using a nls()
>> function? I'm trying to fit some data to a complicated model and everything
>> works fine with nls() but I also wanted to obtain a robust estimate of my
>> errors.
>>
>> I tried "coeftest(m, vcov=sandwich)" and it seems to work, but so does
>> "coeftest(m, vcov = NeweyWest(m, lag = 4))" or "coeftest(m, vcov =
>> kernHAC(m, kernel = "Bartlett", bw = 5, prewhite = FALSE, adjust =
>> FALSE))". They return different error estimates so I wanted you to help me
>> understand what I should do, if I'm doing something wrong and other stuff.
>>
>> Thank you
>>
>
> You may get a helpful response here, but generally speaking, this list is
> about R **programming**, and statistical issues/tutorials are off topic.
> You might try
> https://stackoverflow.com/questions/tagged/statistics
> if you don't get adequate help here.
>
> -- Bert
>

Additionally, there is also
https://stat.ethz.ch/mailman/listinfo/R-sig-Robust .

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From t@r|qkh@@|r| @end|ng |rom gm@||@com  Sun Oct  2 19:03:51 2022
From: t@r|qkh@@|r| @end|ng |rom gm@||@com (Tariq Khasiri)
Date: Sun, 2 Oct 2022 12:03:51 -0500
Subject: [R] Help with steam graph
In-Reply-To: <0073C340-0152-48CF-BB4B-1890BFD1DDF3@comcast.net>
References: <CAFy_oHAn0RGPVXG=ypbxHM_idX08=c94QOh+gpqwXVEEKYnuSw@mail.gmail.com>
 <0073C340-0152-48CF-BB4B-1890BFD1DDF3@comcast.net>
Message-ID: <CAFy_oHCNXkHGOXGixzyee74TRKsxjeaozwuR2Y2OY4T4236Kag@mail.gmail.com>

Actually in my main data the column name is com_num ( where mistakenly I
pasted the sample data here under the com_name ). So, when I run the
command successfully this is the error shows up -

    ?
  1. ??... %>% sg_legend(show = TRUE, label = "Share: ")
  2. ??streamgraph::sg_legend(., show = TRUE, label = "Share: ")
  3. ??streamgraph::sg_fill_brewer(., "PuOr")
  4. ??streamgraph::sg_axis_x(., 0.8)
  5. ??streamgraph::streamgraph(., "com_num", "n", "year")
  6. ? ??base::data.frame(data)
  7. ??dplyr::ungroup(.)
  8. ??dplyr::tally(., wt = share)
  9. ??dplyr::group_by(., year, com_num)
 10. ??dplyr:::group_by.data.frame(., year, com_num)
 11.   ??dplyr::group_by_prepare(.data, ..., .add = .add, caller_env =
caller_env())
 12.     ??rlang::abort(bullets, call = error_call)

Any suggestions on how I can fix it ??

On Sun, 2 Oct 2022 at 09:12, David Winsemius <dwinsemius at comcast.net> wrote:

> I don?t see a column with the name ?com_num?, so the error message makes
> complete sense.
>
> ?
> David
>
> Sent from my iPhone
>
> > On Oct 2, 2022, at 5:06 AM, Tariq Khasiri <tariqkhasiri at gmail.com>
> wrote:
> >
> > ?Hi, i'm trying to create a steamgraph with the following data by
> creating a
> > unit indicator by combing the year and month. But, I'm getting error as :
> >
> > Error in `group_by()`:
> > ! Must group by variables found in `.data`.
> > ? Column `com_num` is not found.
> > Run `rlang::last_error()` to see where the error occurred.
> >
> > ### Packages needed for the code
> > devtools::install_github("hrbrmstr/streamgraph")
> >
> > library(tidyverse)
> > library(ggplot2)
> > library(dplyr)
> > library(steamgraph)
> >
> > ### Code ( The following code can be found on creator's account
> > https://hrbrmstr.github.io/streamgraph/  )
> >
> > dat %>%
> > select(year, month, company, share, com_num) %>%
> >  tidyr::gather(company, share, -year) %>%
> >  group_by(year, com_num) %>%
> >  tally(wt=share) %>%
> >  ungroup %>%
> >  streamgraph("com_num", "n", "year") %>%
> >  sg_axis_x(0.8) %>%
> >  sg_fill_brewer("PuOr") %>%
> >  sg_legend(show=TRUE, label="Share: ")
> >
> >
> > ### data is like the following
> >
> > dput(dat)
> > structure(list(year = c(2018, 2019, 2019, 2019, 2019, 2019, 2019,
> > 2019, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017,
> > 2017, 2017, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018,
> > 2018, 2018, 2018, 2019, 2019, 2019, 2019, 2019), month = c(12,
> > 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1,
> > 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5), company = c("ABC",
> > "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "FGH", "FGH",
> > "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
> > "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
> > "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH"
> > ), share = c(20, 16.5, 15, 15.5, 15.5, 16, 17, 16.5, 61, 55,
> > 53, 53, 54, 53, 58, 54, 50, 47, 55, 50, 52, 51, 51.5, 52, 53,
> > 54, 55, 53, 54, 50, 42, 48, 41, 40, 39, 36.5, 35), com_name = c(1,
> > 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> > 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)), row.names = c(NA,
> > -37L), spec = structure(list(cols = list(year = structure(list(), class =
> > c("collector_double",
> > "collector")), month = structure(list(), class = c("collector_double",
> > "collector")), company = structure(list(), class =
> c("collector_character",
> > "collector")), share = structure(list(), class = c("collector_double",
> > "collector")), com_name = structure(list(), class = c("collector_double",
> > "collector"))), default = structure(list(), class = c("collector_guess",
> > "collector")), delim = ","), class = "col_spec"), problems = <pointer:
> > 0x7fd732028680>, class = c("spec_tbl_df",
> > "tbl_df", "tbl", "data.frame"))
> >
> >    [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From tebert @end|ng |rom u||@edu  Sun Oct  2 23:27:10 2022
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Sun, 2 Oct 2022 21:27:10 +0000
Subject: [R] Robust standard error
In-Reply-To: <87lepykyhn.fsf@enricoschumann.net>
References: <CAPkN0fY32F=b=RFsTuCnDytg4i=++CkB_Bw7VLN+i=0rvaBQtQ@mail.gmail.com>
 <CAGxFJbSTKN5C4SbGh4XRNTe95WArNd2m5XaE1gi8YgfC4ajnrg@mail.gmail.com>
 <87lepykyhn.fsf@enricoschumann.net>
Message-ID: <BN6PR2201MB1553F98BC7B6CD7D3134E849CF589@BN6PR2201MB1553.namprd22.prod.outlook.com>

Most computer code will take a pile of numbers and return a pile of numbers. Reading the documentation should help you figure out where each measure is appropriate. It all depends on the purpose of a specific method and its assumptions and how those relate to your data, application, and model assumptions. It is important to know that information because it could change if you change your model or find other questions to ask of your data. There is no universal right answer.

Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Enrico Schumann
Sent: Sunday, October 2, 2022 12:00 PM
To: Simone Mascia <masciasimone99 at gmail.com>
Cc: r-help at r-project.org
Subject: Re: [R] Robust standard error

[External Email]

On Sun, 02 Oct 2022, Bert Gunter writes:

> On Sun, Oct 2, 2022 at 6:42 AM Simone Mascia 
> <masciasimone99 at gmail.com>
> wrote:
>
>> Is there a way to estimate Robust standard errors when using a nls() 
>> function? I'm trying to fit some data to a complicated model and 
>> everything works fine with nls() but I also wanted to obtain a robust 
>> estimate of my errors.
>>
>> I tried "coeftest(m, vcov=sandwich)" and it seems to work, but so 
>> does "coeftest(m, vcov = NeweyWest(m, lag = 4))" or "coeftest(m, vcov 
>> = kernHAC(m, kernel = "Bartlett", bw = 5, prewhite = FALSE, adjust = 
>> FALSE))". They return different error estimates so I wanted you to 
>> help me understand what I should do, if I'm doing something wrong and other stuff.
>>
>> Thank you
>>
>
> You may get a helpful response here, but generally speaking, this list 
> is about R **programming**, and statistical issues/tutorials are off topic.
> You might try
> https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstac
> koverflow.com%2Fquestions%2Ftagged%2Fstatistics&amp;data=05%7C01%7Cteb
> ert%40ufl.edu%7C86352d688e094b941f6108daa48f2bb0%7C0d4da0f84a314d76ace
> 60a62331e1b84%7C0%7C0%7C638003232071609206%7CUnknown%7CTWFpbGZsb3d8eyJ
> WIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000
> %7C%7C%7C&amp;sdata=yFTdmRZyRqZd9F3XNsg12IvYlnWE2P6TTkRvNL6U4ZI%3D&amp
> ;reserved=0
> if you don't get adequate help here.
>
> -- Bert
>

Additionally, there is also
https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2FR-sig-Robust&amp;data=05%7C01%7Ctebert%40ufl.edu%7C86352d688e094b941f6108daa48f2bb0%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638003232071609206%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=WJY8zHOxsMLUv1uiHJ91q04mGVvkPi0Kg%2BYydMZMKhs%3D&amp;reserved=0 .

--
Enrico Schumann
Lucerne, Switzerland
https://nam10.safelinks.protection.outlook.com/?url=http%3A%2F%2Fenricoschumann.net%2F&amp;data=05%7C01%7Ctebert%40ufl.edu%7C86352d688e094b941f6108daa48f2bb0%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638003232071609206%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=nntdbtWzMra1ZsSrTR2ZEuDNndB6J5GJ%2B1WSC%2Bhweqo%3D&amp;reserved=0

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://nam10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&amp;data=05%7C01%7Ctebert%40ufl.edu%7C86352d688e094b941f6108daa48f2bb0%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638003232071609206%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=6J1gU7dtTJexvDxujaA10nKYYxypFk1CMjN8qc8NQZM%3D&amp;reserved=0
PLEASE do read the posting guide https://nam10.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwww.r-project.org%2Fposting-guide.html&amp;data=05%7C01%7Ctebert%40ufl.edu%7C86352d688e094b941f6108daa48f2bb0%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7C638003232071609206%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&amp;sdata=qd99tAhjS4vz7SemhzyXKvpSDG%2FZD%2FtQ4BYbCtt%2Fsu8%3D&amp;reserved=0
and provide commented, minimal, self-contained, reproducible code.


From t@r|qkh@@|r| @end|ng |rom gm@||@com  Mon Oct  3 01:04:24 2022
From: t@r|qkh@@|r| @end|ng |rom gm@||@com (Tariq Khasiri)
Date: Sun, 2 Oct 2022 18:04:24 -0500
Subject: [R] Creating a year-month indicator and groupby with category
Message-ID: <CAFy_oHDGR7cnNwcTW3mNknKvHhRz+LC4v4XSeKrKEOUjMTcsmA@mail.gmail.com>

Hello,

I have the following data. I want to show in a line plot how each different
company is earning over the timeline of my data sample.

I'm not sure how I can create the *year-month indicator* to plot it nicely
in my horizontal axis out of my dataset.

After creating the *year-month* indicator ( which will be in my x axis) I
want to create a dataframe where I can groupby companies over the
year-month indicator by putting *share *in the y axis as variables.

### data is like the following

dput(dat)
structure(list(year = c(2018, 2019, 2019, 2019, 2019, 2019, 2019,
2019, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017, 2017,
2017, 2017, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018, 2018,
2018, 2018, 2018, 2019, 2019, 2019, 2019, 2019), month = c(12,
1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1,
2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 1, 2, 3, 4, 5), company = c("ABC",
"ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "ABC", "FGH", "FGH",
"FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
"FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH",
"FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH", "FGH"
), share = c(20, 16.5, 15, 15.5, 15.5, 16, 17, 16.5, 61, 55,
53, 53, 54, 53, 58, 54, 50, 47, 55, 50, 52, 51, 51.5, 52, 53,
54, 55, 53, 54, 50, 42, 48, 41, 40, 39, 36.5, 35), com_name = c(1,
1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2)), row.names = c(NA,
-37L), spec = structure(list(cols = list(year = structure(list(), class =
c("collector_double",
"collector")), month = structure(list(), class = c("collector_double",
"collector")), company = structure(list(), class = c("collector_character",
"collector")), share = structure(list(), class = c("collector_double",
"collector")), com_name = structure(list(), class = c("collector_double",
"collector"))), default = structure(list(), class = c("collector_guess",
"collector")), delim = ","), class = "col_spec"), problems = <pointer:
0x7fd732028680>, class = c("spec_tbl_df",
"tbl_df", "tbl", "data.frame"))

	[[alternative HTML version deleted]]


