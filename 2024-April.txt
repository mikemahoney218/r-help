From k|mmo@e|o @end|ng |rom utu@||  Tue Apr  2 09:00:00 2024
From: k|mmo@e|o @end|ng |rom utu@|| (Kimmo Elo)
Date: Tue, 2 Apr 2024 07:00:00 +0000
Subject: [R] split a factor into single elements
In-Reply-To: <CH3PR22MB4514C06AF9230DF23066EB02CF3B2@CH3PR22MB4514.namprd22.prod.outlook.com>
References: <9bc23d07aefe431a9ab87d18c97805ef@regione.marche.it>	,
 <CADUGNTyhGD-yAAXrep2uUjtcCOU9fQrN0yuw-rb9vDxucaywEQ@mail.gmail.com>
 <75993e80f96448d380b25f3c327a4076@regione.marche.it>
 <CH3PR22MB4514C06AF9230DF23066EB02CF3B2@CH3PR22MB4514.namprd22.prod.outlook.com>
Message-ID: <9979f3aac552d86f0455dad3678cf0cbf15c6c51.camel@utu.fi>

Hi,

why would this simple procedure not work?

--- snip ---
mydf <- data.frame(id_station = 1234, string_data = c(2024, 12, 1, 0, 0),
rainfall_value= 55)

mydf$string_data <- as.factor(mydf$string_data)

values<-as.integer(levels(mydf$string_data))

for (i in 1:length(values)) {?
	assign(paste("VAR_", i, sep=""), values[i])?
}

--- snip ---

Best,

Kimmo

to, 2024-03-28 kello 14:17 +0000, Ebert,Timothy Aaron kirjoitti:
> Here are some pieces of working code. I assume you want the second one or
> the third one that is functionally the same but all in one statement. I
> do not understand why it is a factor, but I will assume that there is a
> current and future reason for that. This means I cannot alter the
> string_data variable, or you can simplify by not making the variable a
> factor only to turn it back into character.
> 
> mydf <- data.frame(id_station = 1234, string_data = c(2024, 12, 1, 0, 0),
> rainfall_value= 55)
> mydf$string_data <- as.factor(mydf$string_data)
> 
> mydf <- data.frame(id_station = 1234, string_data = "2024, 12, 1, 0, 0",
> rainfall_value= 55)
> mydf$string_data <- as.factor(mydf$string_data)
> 
> mydf <- data.frame(id_station = 1234, string_data = as.factor("2024, 12,
> 1, 0, 0"), rainfall_value= 55)
> 
> mydf <- data.frame(id_station = 1234, string_data = as.factor("2024, 12,
> 1, 0, 0"), rainfall_value= 55)
> mydf$string_data2 <- as.character(mydf$string_data)
> 
> #I assume there are many records in the data frame and your example is
> for demonstration only.
> #I cannot assume that all records are the same, though you may be able to
> simplify if that is true.
> #Split the string based on commas.
> split_values <- strsplit(mydf$string_data2, ",")
> 
> # find the maximum string length
> max_length <- max(lengths(split_values))
> 
> # Add new variables to the data frame
> for (i in 1:max_length) {
> ? new_var_name <- paste0("VAR_", i)
> ? mydf[[new_var_name]] <- sapply(split_values, function(x)
> ifelse(length(x) >= i, x[i], NA))
> }
> 
> # Convert to numeric
> ?for (i in 1:max_length) {
> ?? new_var_name <- paste0("VAR_", i)
> ?? mydf[[new_var_name]] <- as.numeric(mydf[[new_var_name]])
> ?}
> # remove trash
> mydf <- mydf[,-4]
> # Provide more useful names
> colnames(mydf) <- c("id_station", "string_data", "rainfall_mm", "Year",
> "Month", "Day", "hour", "minute")
> 
> Regards,
> Tim
> 
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Stefano Sofia
> Sent: Thursday, March 28, 2024 7:48 AM
> To: Fabio D'Agostino <dagostinofabi at gmail.com>; r-help at R-project.org
> Subject: Re: [R] split a factor into single elements
> 
> [External Email]
> 
> Sorry for my hurry.
> 
> The correct reproducible code is different from the initial one. The
> correct example is
> 
> 
> mydf <- data.frame(id_station = 1234, string_data = as.factor(2024, 12,
> 1, 0, 0), rainfall_value= 55)
> 
> 
> In this case mydf$string_data is a factor, but of length 1 (and not 5
> like in the initial example).
> 
> Therefore the suggestion offered by Fabio does not work.
> 
> 
> Any suggestion?
> 
> Sorry again for my mistake
> 
> Stefano
> 
> 
> 
> ???????? (oo)
> --oOO--( )--OOo--------------------------------------
> Stefano Sofia PhD
> Civil Protection - Marche Region - Italy Meteo Section Snow Section Via
> del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona (AN)
> Uff: +39 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------------------------------
> 
> 
> ________________________________
> Da: Fabio D'Agostino <dagostinofabi at gmail.com>
> Inviato: gioved? 28 marzo 2024 12:20
> A: Stefano Sofia; r-help at R-project.org
> Oggetto: Re: [R] split a factor into single elements
> 
> 
> Non si ricevono spesso messaggi di posta elettronica da
> dagostinofabi at gmail.com. Informazioni sul perch???
> importante<https://aka.ms/LearnAboutSenderIdentification>
> 
> Hi Stefano,
> maybe something like this can help you?
> 
> myfactor <- as.factor(c(2024, 2, 1, 0, 0))
> 
> # Convert factor values to integers
> first_element <- as.integer(as.character(myfactor)[1])
> second_element <- as.integer(as.character(myfactor)[2])
> third_element <- as.integer(as.character(myfactor)[3])
> 
> # Print the results
> first_element
> [1] 2024
> second_element
> [1] 2
> third_element
> [1] 1
> 
> # Check the type of the object
> typeof(first_element)
> [1] "integer"
> 
> Fabio
> 
> Il giorno gio 28 mar 2024 alle ore 11:29 Stefano Sofia
> <stefano.sofia at regione.marche.it<mailto:stefano.sofia at regione.marche.it>>
> ha scritto:
> Dear R-list users,
> 
> forgive me for this silly question, I did my best to find a solution with
> no success.
> 
> Suppose I have a factor type like
> 
> 
> myfactor <- as.factor(2024, 2, 1, 0, 0)
> 
> 
> There are no characters (and therefore strsplit for eample does not
> work).
> 
> I need to store separately the 1st, 2nd and 3rd elements as integers. How
> can I do?
> 
> 
> Thank you for your help
> 
> Stefano
> 
> 
> ???????? (oo)
> --oOO--( )--OOo--------------------------------------
> Stefano Sofia PhD
> Civil Protection - Marche Region - Italy Meteo Section Snow Section Via
> del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona (AN)
> Uff: +39 071 806 7743
> E-mail:
> stefano.sofia at regione.marche.it<mailto:stefano.sofia at regione.marche.it>
> ---Oo---------oO----------------------------------------
> 
> ________________________________
> 
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere
> informazioni confidenziali, pertanto?? destinato solo a persone
> autorizzate alla ricezione. I messaggi di posta elettronica per i client
> di Regione Marche possono contenere informazioni confidenziali e con
> privilegi legali. Se non si?? il destinatario specificato, non leggere,
> copiare, inoltrare o archiviare questo messaggio. Se si?? ricevuto questo
> messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente
> dal sistema del proprio computer. Ai sensi dell'art. 6 della DGR n.
> 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al
> presente messaggio di posta elettronica pu? essere visionata da persone
> estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by
> persons entitled to receive the confidential information it may contain.
> E-mail messages to clients of Regione Marche may contain information that
> is confidential and legally privileged. Please do not read, copy,
> forward, or store this message unless you are an intended recipient of
> it. If you have received this message in error, please forward it to the
> sender and delete it completely from your computer system.
> 
> ??????? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help
> >
> PLEASE do read the posting guide
> http://www.r-project.org/posting-guide.html<
> http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
> 
> ________________________________
> 
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere
> informazioni confidenziali, pertanto?? destinato solo a persone
> autorizzate alla ricezione. I messaggi di posta elettronica per i client
> di Regione Marche possono contenere informazioni confidenziali e con
> privilegi legali. Se non si?? il destinatario specificato, non leggere,
> copiare, inoltrare o archiviare questo messaggio. Se si?? ricevuto questo
> messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente
> dal sistema del proprio computer. Ai sensi dell'art. 6 della DGR n.
> 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al
> presente messaggio di posta elettronica pu? essere visionata da persone
> estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by
> persons entitled to receive the confidential information it may contain.
> E-mail messages to clients of Regione Marche may contain information that
> is confidential and legally privileged. Please do not read, copy,
> forward, or store this message unless you are an intended recipient of
> it. If you have received this message in error, please forward it to the
> sender and delete it completely from your computer system.
> 
> ??????? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org?mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Apr  2 10:26:29 2024
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 2 Apr 2024 10:26:29 +0200
Subject: [R] How to tweak genomic plot with genoPlotR?
Message-ID: <CAMk+s2QBherJTKkzOeJDJ4B4B1mBGsHMv3RSY-C+aeN3d=PJeg@mail.gmail.com>

I would like to use your genoPlotR package
(doi:10.1093/bioinformatics/btq413) to compare the genomes of two
isolates of E. coli K-12 that I have. One is a K-12 that was in my
lab's fridge; the other is a derivative of K-12 bought some time ago,
HB101.
I tried to use genoPlotR, but I could not understand some functions
from your vignette. I would like to ask you whether you could help me
with this.

I aligned the genomes (reference K-12 plus my isolates) with
`progressiveMauve --weight=15 --output=./K12_Aln.fa K12_multi.fa`,
where K12_multi.fa contains the fasta sequences of the reference and
the consensuses I obtained from my isolates after Illumina NGS. I then
ran this script:

```
## get data
bbone_file = "./K12_Aln.backbone"
bbone = read_mauve_backbone(bbone_file, ref=2)
names(bbone$dna_segs) = c("K-12 ref.", "K-12 Ho", "HB101 Ho")

## calculate lengths
for (i in 1:length(bbone$comparisons)) {
  cmp = bbone$comparisons[[i]]
  bbone$comparisons[[i]]$length = abs(cmp$end1 - cmp$end1) +
                                  abs(cmp$end2 - cmp$end2)
}

## plot
plot_gene_map(dna_segs = bbone$dna_segs,
              comparisons = bbone$comparisons,
              global_color_scheme = c("length", "increasing", "red_blue", 0.7),
              override_color_schemes = TRUE)
```
I got the following plot: https://u.cubeupload.com/Gigiux/Rplot.png
My questions are:
- How can I load the annotations? I have the K-12 annotations in gff3
and genebank formats, but how do I load them in the system so that I
plot it here?
- Is it possible to zoom in?
- Is it possible to change the color scheme?
Thank you




--
Best regards,
Luigi


From er|cjberger @end|ng |rom gm@||@com  Tue Apr  2 10:45:02 2024
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 2 Apr 2024 11:45:02 +0300
Subject: [R] How to tweak genomic plot with genoPlotR?
In-Reply-To: <CAMk+s2QBherJTKkzOeJDJ4B4B1mBGsHMv3RSY-C+aeN3d=PJeg@mail.gmail.com>
References: <CAMk+s2QBherJTKkzOeJDJ4B4B1mBGsHMv3RSY-C+aeN3d=PJeg@mail.gmail.com>
Message-ID: <CAGgJW76_HG2_RPYXsd2VxB-QpvNVBcrWHFvoSNjBCqtJquou8A@mail.gmail.com>

According to https://cran.r-project.org/web/packages/genoPlotR/index.html
the maintainer of genoPlotR is

Lionel Guy <lionel.guy at imbim.uu.se>

Send your question also to him.

On Tue, Apr 2, 2024 at 11:27?AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> I would like to use your genoPlotR package
> (doi:10.1093/bioinformatics/btq413) to compare the genomes of two
> isolates of E. coli K-12 that I have. One is a K-12 that was in my
> lab's fridge; the other is a derivative of K-12 bought some time ago,
> HB101.
> I tried to use genoPlotR, but I could not understand some functions
> from your vignette. I would like to ask you whether you could help me
> with this.
>
> I aligned the genomes (reference K-12 plus my isolates) with
> `progressiveMauve --weight=15 --output=./K12_Aln.fa K12_multi.fa`,
> where K12_multi.fa contains the fasta sequences of the reference and
> the consensuses I obtained from my isolates after Illumina NGS. I then
> ran this script:
>
> ```
> ## get data
> bbone_file = "./K12_Aln.backbone"
> bbone = read_mauve_backbone(bbone_file, ref=2)
> names(bbone$dna_segs) = c("K-12 ref.", "K-12 Ho", "HB101 Ho")
>
> ## calculate lengths
> for (i in 1:length(bbone$comparisons)) {
>   cmp = bbone$comparisons[[i]]
>   bbone$comparisons[[i]]$length = abs(cmp$end1 - cmp$end1) +
>                                   abs(cmp$end2 - cmp$end2)
> }
>
> ## plot
> plot_gene_map(dna_segs = bbone$dna_segs,
>               comparisons = bbone$comparisons,
>               global_color_scheme = c("length", "increasing", "red_blue", 0.7),
>               override_color_schemes = TRUE)
> ```
> I got the following plot: https://u.cubeupload.com/Gigiux/Rplot.png
> My questions are:
> - How can I load the annotations? I have the K-12 annotations in gff3
> and genebank formats, but how do I load them in the system so that I
> plot it here?
> - Is it possible to zoom in?
> - Is it possible to change the color scheme?
> Thank you
>
>
>
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Apr  2 10:47:00 2024
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 2 Apr 2024 10:47:00 +0200
Subject: [R] How to tweak genomic plot with genoPlotR?
In-Reply-To: <CAGgJW76_HG2_RPYXsd2VxB-QpvNVBcrWHFvoSNjBCqtJquou8A@mail.gmail.com>
References: <CAMk+s2QBherJTKkzOeJDJ4B4B1mBGsHMv3RSY-C+aeN3d=PJeg@mail.gmail.com>
 <CAGgJW76_HG2_RPYXsd2VxB-QpvNVBcrWHFvoSNjBCqtJquou8A@mail.gmail.com>
Message-ID: <CAMk+s2Qk3CDWK31Uj7s0wMGO0suGnY1GM7DpguDYkpfEq9s-OA@mail.gmail.com>

Already did...

On Tue, Apr 2, 2024 at 10:45?AM Eric Berger <ericjberger at gmail.com> wrote:
>
> According to https://cran.r-project.org/web/packages/genoPlotR/index.html
> the maintainer of genoPlotR is
>
> Lionel Guy <lionel.guy at imbim.uu.se>
>
> Send your question also to him.
>
> On Tue, Apr 2, 2024 at 11:27?AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > I would like to use your genoPlotR package
> > (doi:10.1093/bioinformatics/btq413) to compare the genomes of two
> > isolates of E. coli K-12 that I have. One is a K-12 that was in my
> > lab's fridge; the other is a derivative of K-12 bought some time ago,
> > HB101.
> > I tried to use genoPlotR, but I could not understand some functions
> > from your vignette. I would like to ask you whether you could help me
> > with this.
> >
> > I aligned the genomes (reference K-12 plus my isolates) with
> > `progressiveMauve --weight=15 --output=./K12_Aln.fa K12_multi.fa`,
> > where K12_multi.fa contains the fasta sequences of the reference and
> > the consensuses I obtained from my isolates after Illumina NGS. I then
> > ran this script:
> >
> > ```
> > ## get data
> > bbone_file = "./K12_Aln.backbone"
> > bbone = read_mauve_backbone(bbone_file, ref=2)
> > names(bbone$dna_segs) = c("K-12 ref.", "K-12 Ho", "HB101 Ho")
> >
> > ## calculate lengths
> > for (i in 1:length(bbone$comparisons)) {
> >   cmp = bbone$comparisons[[i]]
> >   bbone$comparisons[[i]]$length = abs(cmp$end1 - cmp$end1) +
> >                                   abs(cmp$end2 - cmp$end2)
> > }
> >
> > ## plot
> > plot_gene_map(dna_segs = bbone$dna_segs,
> >               comparisons = bbone$comparisons,
> >               global_color_scheme = c("length", "increasing", "red_blue", 0.7),
> >               override_color_schemes = TRUE)
> > ```
> > I got the following plot: https://u.cubeupload.com/Gigiux/Rplot.png
> > My questions are:
> > - How can I load the annotations? I have the K-12 annotations in gff3
> > and genebank formats, but how do I load them in the system so that I
> > plot it here?
> > - Is it possible to zoom in?
> > - Is it possible to change the color scheme?
> > Thank you
> >
> >
> >
> >
> > --
> > Best regards,
> > Luigi
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.



-- 
Best regards,
Luigi


From tebert @end|ng |rom u||@edu  Tue Apr  2 14:26:43 2024
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Tue, 2 Apr 2024 12:26:43 +0000
Subject: [R] split a factor into single elements
In-Reply-To: <9979f3aac552d86f0455dad3678cf0cbf15c6c51.camel@utu.fi>
References: <9bc23d07aefe431a9ab87d18c97805ef@regione.marche.it>	,
 <CADUGNTyhGD-yAAXrep2uUjtcCOU9fQrN0yuw-rb9vDxucaywEQ@mail.gmail.com>
 <75993e80f96448d380b25f3c327a4076@regione.marche.it>
 <CH3PR22MB4514C06AF9230DF23066EB02CF3B2@CH3PR22MB4514.namprd22.prod.outlook.com>
 <9979f3aac552d86f0455dad3678cf0cbf15c6c51.camel@utu.fi>
Message-ID: <CH3PR22MB45146439750D17948DF9D4B7CF3E2@CH3PR22MB4514.namprd22.prod.outlook.com>

Using levels rather than length might cause problems. 2024 1, 1, 0, 0 will have a different number of levels than 2024, 3, 8, 0, 0 and I cannot assume that the two tailing zeros are zero for all records. The code can be simplified if you can assume more. It might require more work if I have assumed too much. Maybe there is another data set where the string is something like 2, 2, 2024, 0, 0? Then you need code to figure out the order of values in the string, reorganize it into a common format before trying to merge the data.

The other thing is that values of the string are now different rows. You will need a bit more code to reshape mydf from long to wide. If all of the last two elements of the string are zero, I would remove these from the data first before reshaping.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Kimmo Elo
Sent: Tuesday, April 2, 2024 3:00 AM
To: r-help at r-project.org
Subject: Re: [R] split a factor into single elements

[External Email]

Hi,

why would this simple procedure not work?

--- snip ---
mydf <- data.frame(id_station = 1234, string_data = c(2024, 12, 1, 0, 0), rainfall_value= 55)

mydf$string_data <- as.factor(mydf$string_data)

values<-as.integer(levels(mydf$string_data))

for (i in 1:length(values)) {
        assign(paste("VAR_", i, sep=""), values[i]) }

--- snip ---

Best,

Kimmo

to, 2024-03-28 kello 14:17 +0000, Ebert,Timothy Aaron kirjoitti:
> Here are some pieces of working code. I assume you want the second one
> or the third one that is functionally the same but all in one
> statement. I do not understand why it is a factor, but I will assume
> that there is a current and future reason for that. This means I
> cannot alter the string_data variable, or you can simplify by not
> making the variable a factor only to turn it back into character.
>
> mydf <- data.frame(id_station = 1234, string_data = c(2024, 12, 1, 0,
> 0), rainfall_value= 55) mydf$string_data <-
> as.factor(mydf$string_data)
>
> mydf <- data.frame(id_station = 1234, string_data = "2024, 12, 1, 0,
> 0", rainfall_value= 55) mydf$string_data <-
> as.factor(mydf$string_data)
>
> mydf <- data.frame(id_station = 1234, string_data = as.factor("2024,
> 12, 1, 0, 0"), rainfall_value= 55)
>
> mydf <- data.frame(id_station = 1234, string_data = as.factor("2024,
> 12, 1, 0, 0"), rainfall_value= 55)
> mydf$string_data2 <- as.character(mydf$string_data)
>
> #I assume there are many records in the data frame and your example is
> for demonstration only.
> #I cannot assume that all records are the same, though you may be able
> to simplify if that is true.
> #Split the string based on commas.
> split_values <- strsplit(mydf$string_data2, ",")
>
> # find the maximum string length
> max_length <- max(lengths(split_values))
>
> # Add new variables to the data frame
> for (i in 1:max_length) {
>   new_var_name <- paste0("VAR_", i)
>   mydf[[new_var_name]] <- sapply(split_values, function(x)
> ifelse(length(x) >= i, x[i], NA))
> }
>
> # Convert to numeric
>  for (i in 1:max_length) {
>    new_var_name <- paste0("VAR_", i)
>    mydf[[new_var_name]] <- as.numeric(mydf[[new_var_name]])  } #
> remove trash mydf <- mydf[,-4] # Provide more useful names
> colnames(mydf) <- c("id_station", "string_data", "rainfall_mm",
> "Year", "Month", "Day", "hour", "minute")
>
> Regards,
> Tim
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Stefano Sofia
> Sent: Thursday, March 28, 2024 7:48 AM
> To: Fabio D'Agostino <dagostinofabi at gmail.com>; r-help at R-project.org
> Subject: Re: [R] split a factor into single elements
>
> [External Email]
>
> Sorry for my hurry.
>
> The correct reproducible code is different from the initial one. The
> correct example is
>
>
> mydf <- data.frame(id_station = 1234, string_data = as.factor(2024,
> 12, 1, 0, 0), rainfall_value= 55)
>
>
> In this case mydf$string_data is a factor, but of length 1 (and not 5
> like in the initial example).
>
> Therefore the suggestion offered by Fabio does not work.
>
>
> Any suggestion?
>
> Sorry again for my mistake
>
> Stefano
>
>
>
>          (oo)
> --oOO--( )--OOo--------------------------------------
> Stefano Sofia PhD
> Civil Protection - Marche Region - Italy Meteo Section Snow Section
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona (AN)
> Uff: +39 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------------------------------
>
>
> ________________________________
> Da: Fabio D'Agostino <dagostinofabi at gmail.com>
> Inviato: gioved  28 marzo 2024 12:20
> A: Stefano Sofia; r-help at R-project.org
> Oggetto: Re: [R] split a factor into single elements
>
>
> Non si ricevono spesso messaggi di posta elettronica da
> dagostinofabi at gmail.com. Informazioni sul perch
> importante<https://aka.ms/LearnAboutSenderIdentification>
>
> Hi Stefano,
> maybe something like this can help you?
>
> myfactor <- as.factor(c(2024, 2, 1, 0, 0))
>
> # Convert factor values to integers
> first_element <- as.integer(as.character(myfactor)[1])
> second_element <- as.integer(as.character(myfactor)[2])
> third_element <- as.integer(as.character(myfactor)[3])
>
> # Print the results
> first_element
> [1] 2024
> second_element
> [1] 2
> third_element
> [1] 1
>
> # Check the type of the object
> typeof(first_element)
> [1] "integer"
>
> Fabio
>
> Il giorno gio 28 mar 2024 alle ore 11:29 Stefano Sofia
> <stefano.sofia at regione.marche.it<mailto:stefano.sofia at regione.marche.i
> t>>
> ha scritto:
> Dear R-list users,
>
> forgive me for this silly question, I did my best to find a solution
> with no success.
>
> Suppose I have a factor type like
>
>
> myfactor <- as.factor(2024, 2, 1, 0, 0)
>
>
> There are no characters (and therefore strsplit for eample does not
> work).
>
> I need to store separately the 1st, 2nd and 3rd elements as integers.
> How can I do?
>
>
> Thank you for your help
>
> Stefano
>
>
>          (oo)
> --oOO--( )--OOo--------------------------------------
> Stefano Sofia PhD
> Civil Protection - Marche Region - Italy Meteo Section Snow Section
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona (AN)
> Uff: +39 071 806 7743
> E-mail:
> stefano.sofia at regione.marche.it<mailto:stefano.sofia at regione.marche.it
> >
> ---Oo---------oO----------------------------------------
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu  contenere
> informazioni confidenziali, pertanto   destinato solo a persone
> autorizzate alla ricezione. I messaggi di posta elettronica per i
> client di Regione Marche possono contenere informazioni confidenziali e con
> privilegi legali. Se non si   il destinatario specificato, non leggere,
> copiare, inoltrare o archiviare questo messaggio. Se si   ricevuto questo
> messaggio per errore, inoltrarlo al mittente ed eliminarlo
> completamente dal sistema del proprio computer. Ai sensi dell'art. 6 della DGR n.
> 1394/2008 si segnala che, in caso di necessit  ed urgenza, la risposta
> al presente messaggio di posta elettronica pu  essere visionata da
> persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only
> by persons entitled to receive the confidential information it may contain.
> E-mail messages to clients of Regione Marche may contain information
> that is confidential and legally privileged. Please do not read, copy,
> forward, or store this message unless you are an intended recipient of
> it. If you have received this message in error, please forward it to
> the sender and delete it completely from your computer system.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> https://stat/
> .ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=05%7C02%7Ctebert%40ufl.edu
> %7Cdbd7f13c10474cb2851508dc52e29e32%7C0d4da0f84a314d76ace60a62331e1b84
> %7C0%7C0%7C638476380496113535%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAw
> MDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&sdata=
> GBENusBta3YK3Q83zemIAJaoNRmTOBGiDVZ%2F0AU6ZQA%3D&reserved=0<https://na
> m10.safelinks.protection.outlook.com/?url=https%3A%2F%2Fstat.ethz.ch%2
> Fmailman%2Flistinfo%2Fr-help&data=05%7C02%7Ctebert%40ufl.edu%7Cdbd7f13
> c10474cb2851508dc52e29e32%7C0d4da0f84a314d76ace60a62331e1b84%7C0%7C0%7
> C638476380496121002%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIj
> oiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&sdata=mj60KcP7So
> nvRKwkAEngxG%2FQKs7aWOtyg%2Bvu2StXdR8%3D&reserved=0
> >
> PLEASE do read the posting guide
> http://www.r/
> -project.org%2Fposting-guide.html&data=05%7C02%7Ctebert%40ufl.edu%7Cdb
> d7f13c10474cb2851508dc52e29e32%7C0d4da0f84a314d76ace60a62331e1b84%7C0%
> 7C0%7C638476380496124909%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiL
> CJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&sdata=%2FR%
> 2Fi3BOm8mXGKcPXJ8LZBH%2BO%2B8CjN5%2F%2BMR5gVcRi0P4%3D&reserved=0<
> http://www.r/
> -project.org%2Fposting-guide.html&data=05%7C02%7Ctebert%40ufl.edu%7Cdb
> d7f13c10474cb2851508dc52e29e32%7C0d4da0f84a314d76ace60a62331e1b84%7C0%
> 7C0%7C638476380496128675%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiL
> CJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&sdata=cdU7U
> e81pXp83kvsS5Z%2BJblcq1vBUpAmfhxeG1tl%2Fd4%3D&reserved=0>
> and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu  contenere
> informazioni confidenziali, pertanto   destinato solo a persone
> autorizzate alla ricezione. I messaggi di posta elettronica per i
> client di Regione Marche possono contenere informazioni confidenziali e con
> privilegi legali. Se non si   il destinatario specificato, non leggere,
> copiare, inoltrare o archiviare questo messaggio. Se si   ricevuto questo
> messaggio per errore, inoltrarlo al mittente ed eliminarlo
> completamente dal sistema del proprio computer. Ai sensi dell'art. 6 della DGR n.
> 1394/2008 si segnala che, in caso di necessit  ed urgenza, la risposta
> al presente messaggio di posta elettronica pu  essere visionata da
> persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only
> by persons entitled to receive the confidential information it may contain.
> E-mail messages to clients of Regione Marche may contain information
> that is confidential and legally privileged. Please do not read, copy,
> forward, or store this message unless you are an intended recipient of
> it. If you have received this message in error, please forward it to
> the sender and delete it completely from your computer system.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat/
> .ethz.ch%2Fmailman%2Flistinfo%2Fr-help&data=05%7C02%7Ctebert%40ufl.edu
> %7Cdbd7f13c10474cb2851508dc52e29e32%7C0d4da0f84a314d76ace60a62331e1b84
> %7C0%7C0%7C638476380496132394%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAw
> MDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&sdata=
> kUJash%2B7S88lJd%2BY8tDluxiVb6TlNgLpo18lqmlbDCE%3D&reserved=0
> PLEASE do read the posting guide
> http://www.r/
> -project.org%2Fposting-guide.html&data=05%7C02%7Ctebert%40ufl.edu%7Cdb
> d7f13c10474cb2851508dc52e29e32%7C0d4da0f84a314d76ace60a62331e1b84%7C0%
> 7C0%7C638476380496135909%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiL
> CJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C0%7C%7C%7C&sdata=%2FMk
> 2GR1hMdE%2FLyZwJvS5TnH%2B%2FDqu9P6jXiFNSsvduto%3D&reserved=0
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Tue Apr  2 16:53:12 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 2 Apr 2024 07:53:12 -0700
Subject: [R] split a factor into single elements
In-Reply-To: <9979f3aac552d86f0455dad3678cf0cbf15c6c51.camel@utu.fi>
References: <9bc23d07aefe431a9ab87d18c97805ef@regione.marche.it>
 <CADUGNTyhGD-yAAXrep2uUjtcCOU9fQrN0yuw-rb9vDxucaywEQ@mail.gmail.com>
 <75993e80f96448d380b25f3c327a4076@regione.marche.it>
 <CH3PR22MB4514C06AF9230DF23066EB02CF3B2@CH3PR22MB4514.namprd22.prod.outlook.com>
 <9979f3aac552d86f0455dad3678cf0cbf15c6c51.camel@utu.fi>
Message-ID: <CAGxFJbQigFJF7eqyt0zRDQM3pO97Y-biA4kKSCNjn7-ZwoEGLw@mail.gmail.com>

Note:
> levels(factor(c(0,0,1)))  ## just gives you the levels attribute
[1] "0" "1"
> as.character(factor(c(0,0,1))) ## gives you the level of each value in
the vector
[1] "0" "0" "1"

Does that answer your question or have I misunderstood.

Cheers,
Bert



On Tue, Apr 2, 2024 at 12:00?AM Kimmo Elo <kimmo.elo at utu.fi> wrote:

> Hi,
>
> why would this simple procedure not work?
>
> --- snip ---
> mydf <- data.frame(id_station = 1234, string_data = c(2024, 12, 1, 0, 0),
> rainfall_value= 55)
>
> mydf$string_data <- as.factor(mydf$string_data)
>
> values<-as.integer(levels(mydf$string_data))
>
> for (i in 1:length(values)) {
>         assign(paste("VAR_", i, sep=""), values[i])
> }
>
> --- snip ---
>
> Best,
>
> Kimmo
>
> to, 2024-03-28 kello 14:17 +0000, Ebert,Timothy Aaron kirjoitti:
> > Here are some pieces of working code. I assume you want the second one or
> > the third one that is functionally the same but all in one statement. I
> > do not understand why it is a factor, but I will assume that there is a
> > current and future reason for that. This means I cannot alter the
> > string_data variable, or you can simplify by not making the variable a
> > factor only to turn it back into character.
> >
> > mydf <- data.frame(id_station = 1234, string_data = c(2024, 12, 1, 0, 0),
> > rainfall_value= 55)
> > mydf$string_data <- as.factor(mydf$string_data)
> >
> > mydf <- data.frame(id_station = 1234, string_data = "2024, 12, 1, 0, 0",
> > rainfall_value= 55)
> > mydf$string_data <- as.factor(mydf$string_data)
> >
> > mydf <- data.frame(id_station = 1234, string_data = as.factor("2024, 12,
> > 1, 0, 0"), rainfall_value= 55)
> >
> > mydf <- data.frame(id_station = 1234, string_data = as.factor("2024, 12,
> > 1, 0, 0"), rainfall_value= 55)
> > mydf$string_data2 <- as.character(mydf$string_data)
> >
> > #I assume there are many records in the data frame and your example is
> > for demonstration only.
> > #I cannot assume that all records are the same, though you may be able to
> > simplify if that is true.
> > #Split the string based on commas.
> > split_values <- strsplit(mydf$string_data2, ",")
> >
> > # find the maximum string length
> > max_length <- max(lengths(split_values))
> >
> > # Add new variables to the data frame
> > for (i in 1:max_length) {
> >   new_var_name <- paste0("VAR_", i)
> >   mydf[[new_var_name]] <- sapply(split_values, function(x)
> > ifelse(length(x) >= i, x[i], NA))
> > }
> >
> > # Convert to numeric
> >  for (i in 1:max_length) {
> >    new_var_name <- paste0("VAR_", i)
> >    mydf[[new_var_name]] <- as.numeric(mydf[[new_var_name]])
> >  }
> > # remove trash
> > mydf <- mydf[,-4]
> > # Provide more useful names
> > colnames(mydf) <- c("id_station", "string_data", "rainfall_mm", "Year",
> > "Month", "Day", "hour", "minute")
> >
> > Regards,
> > Tim
> >
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Stefano Sofia
> > Sent: Thursday, March 28, 2024 7:48 AM
> > To: Fabio D'Agostino <dagostinofabi at gmail.com>; r-help at R-project.org
> > Subject: Re: [R] split a factor into single elements
> >
> > [External Email]
> >
> > Sorry for my hurry.
> >
> > The correct reproducible code is different from the initial one. The
> > correct example is
> >
> >
> > mydf <- data.frame(id_station = 1234, string_data = as.factor(2024, 12,
> > 1, 0, 0), rainfall_value= 55)
> >
> >
> > In this case mydf$string_data is a factor, but of length 1 (and not 5
> > like in the initial example).
> >
> > Therefore the suggestion offered by Fabio does not work.
> >
> >
> > Any suggestion?
> >
> > Sorry again for my mistake
> >
> > Stefano
> >
> >
> >
> >          (oo)
> > --oOO--( )--OOo--------------------------------------
> > Stefano Sofia PhD
> > Civil Protection - Marche Region - Italy Meteo Section Snow Section Via
> > del Colle Ameno 5
> > 60126 Torrette di Ancona, Ancona (AN)
> > Uff: +39 071 806 7743
> > E-mail: stefano.sofia at regione.marche.it
> > ---Oo---------oO----------------------------------------
> >
> >
> > ________________________________
> > Da: Fabio D'Agostino <dagostinofabi at gmail.com>
> > Inviato: gioved  28 marzo 2024 12:20
> > A: Stefano Sofia; r-help at R-project.org
> > Oggetto: Re: [R] split a factor into single elements
> >
> >
> > Non si ricevono spesso messaggi di posta elettronica da
> > dagostinofabi at gmail.com. Informazioni sul perch
> > importante<https://aka.ms/LearnAboutSenderIdentification>
> >
> > Hi Stefano,
> > maybe something like this can help you?
> >
> > myfactor <- as.factor(c(2024, 2, 1, 0, 0))
> >
> > # Convert factor values to integers
> > first_element <- as.integer(as.character(myfactor)[1])
> > second_element <- as.integer(as.character(myfactor)[2])
> > third_element <- as.integer(as.character(myfactor)[3])
> >
> > # Print the results
> > first_element
> > [1] 2024
> > second_element
> > [1] 2
> > third_element
> > [1] 1
> >
> > # Check the type of the object
> > typeof(first_element)
> > [1] "integer"
> >
> > Fabio
> >
> > Il giorno gio 28 mar 2024 alle ore 11:29 Stefano Sofia
> > <stefano.sofia at regione.marche.it<mailto:stefano.sofia at regione.marche.it
> >>
> > ha scritto:
> > Dear R-list users,
> >
> > forgive me for this silly question, I did my best to find a solution with
> > no success.
> >
> > Suppose I have a factor type like
> >
> >
> > myfactor <- as.factor(2024, 2, 1, 0, 0)
> >
> >
> > There are no characters (and therefore strsplit for eample does not
> > work).
> >
> > I need to store separately the 1st, 2nd and 3rd elements as integers. How
> > can I do?
> >
> >
> > Thank you for your help
> >
> > Stefano
> >
> >
> >          (oo)
> > --oOO--( )--OOo--------------------------------------
> > Stefano Sofia PhD
> > Civil Protection - Marche Region - Italy Meteo Section Snow Section Via
> > del Colle Ameno 5
> > 60126 Torrette di Ancona, Ancona (AN)
> > Uff: +39 071 806 7743
> > E-mail:
> > stefano.sofia at regione.marche.it<mailto:stefano.sofia at regione.marche.it>
> > ---Oo---------oO----------------------------------------
> >
> > ________________________________
> >
> > AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu  contenere
> > informazioni confidenziali, pertanto   destinato solo a persone
> > autorizzate alla ricezione. I messaggi di posta elettronica per i client
> > di Regione Marche possono contenere informazioni confidenziali e con
> > privilegi legali. Se non si   il destinatario specificato, non leggere,
> > copiare, inoltrare o archiviare questo messaggio. Se si   ricevuto questo
> > messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente
> > dal sistema del proprio computer. Ai sensi dell'art. 6 della DGR n.
> > 1394/2008 si segnala che, in caso di necessit  ed urgenza, la risposta al
> > presente messaggio di posta elettronica pu  essere visionata da persone
> > estranee al destinatario.
> > IMPORTANT NOTICE: This e-mail message is intended to be received only by
> > persons entitled to receive the confidential information it may contain.
> > E-mail messages to clients of Regione Marche may contain information that
> > is confidential and legally privileged. Please do not read, copy,
> > forward, or store this message unless you are an intended recipient of
> > it. If you have received this message in error, please forward it to the
> > sender and delete it completely from your computer system.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> > UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help<
> https://stat.ethz.ch/mailman/listinfo/r-help
> > >
> > PLEASE do read the posting guide
> > http://www.r-project.org/posting-guide.html<
> > http://www.r-project.org/posting-guide.html>
> > and provide commented, minimal, self-contained, reproducible code.
> >
> > ________________________________
> >
> > AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu  contenere
> > informazioni confidenziali, pertanto   destinato solo a persone
> > autorizzate alla ricezione. I messaggi di posta elettronica per i client
> > di Regione Marche possono contenere informazioni confidenziali e con
> > privilegi legali. Se non si   il destinatario specificato, non leggere,
> > copiare, inoltrare o archiviare questo messaggio. Se si   ricevuto questo
> > messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente
> > dal sistema del proprio computer. Ai sensi dell'art. 6 della DGR n.
> > 1394/2008 si segnala che, in caso di necessit  ed urgenza, la risposta al
> > presente messaggio di posta elettronica pu  essere visionata da persone
> > estranee al destinatario.
> > IMPORTANT NOTICE: This e-mail message is intended to be received only by
> > persons entitled to receive the confidential information it may contain.
> > E-mail messages to clients of Regione Marche may contain information that
> > is confidential and legally privileged. Please do not read, copy,
> > forward, or store this message unless you are an intended recipient of
> > it. If you have received this message in error, please forward it to the
> > sender and delete it completely from your computer system.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@rkweb@ter204 @end|ng |rom y@hoo@co@uk  Fri Apr  5 05:58:36 2024
From: m@rkweb@ter204 @end|ng |rom y@hoo@co@uk (Mark Webster)
Date: Fri, 5 Apr 2024 03:58:36 +0000 (UTC)
Subject: [R] duplicated() on zero-column data frames returns empty vector
References: <1006764782.7826419.1712289516806.ref@mail.yahoo.com>
Message-ID: <1006764782.7826419.1712289516806@mail.yahoo.com>

Hello,
I found what looks to me like an odd edge case for duplicated(), unique() etc. on data frames with zero columns, due to duplicated() returning a zero-length vector for them, regardless of the number of rows:
df <- data.frame(a = 1:5)df$a <- NULLnrow(df) # 5 (row count preserved by row.names)duplicated(df) # logical(0), should be c(FALSE, TRUE, TRUE, TRUE, TRUE)anyDuplicated(df) # 0, should be 2nrow(unique(df)) # 0, should be 1
This behaviour isn't mentioned in the documentation; is there a reason for it to work like this?I'm struggling to see this as anything other than unintended behaviour, as a consequence of the do.call(Map, `names<-(c(list, x), NULL)`) expression in duplicated.data.frame returning an empty list instead of a list of empty lists.
Other data frame libraries have similar behaviour: tibble does the same; data.table, Python's pandas and Rust's polars drop all the rows as soon as there are zero columns, because they don't preserve the row count via the row names.
---
I admit this is a case we rarely care about.However, for an example of this being an issue,?I've been running into it when treating data frames as database relations, where they have one or more candidate keys (irreducible subsets of the columns for which every row must have a unique value set).Sometimes, a generated relation can have an empty candidate key, which limits it to only having zero or one rows.Usually, I can check a relation contains no duplicated key values by using anyDuplicated:
df2 <- unique(ChickWeight[, c("Chick", "Diet")])keycols <- "Chick"?# Each chick only has one diet (Chick -> Diet)!anyDuplicated(df2[, keycols, drop = FALSE]) # TRUE, so Chick values are unique
When the key is empty, any row after the first must be a duplicate, but anyDuplicated doesn't detect these because of the above edge case, so I have to add special handling:
df3 <- data.frame(a = rep(1, 5)) # relations shouldn't have duplicate rowskeycols <- character(0) # a is constant, so key is empty!anyDuplicated(df3[, keycols, drop = FALSE]) # TRUE because equivalent to !any(logical(0)) by above, should be FALSE
---
Best Regards,Mark
	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Fri Apr  5 10:17:37 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Fri, 5 Apr 2024 11:17:37 +0300
Subject: [R] 
 duplicated() on zero-column data frames returns empty vector
In-Reply-To: <1006764782.7826419.1712289516806@mail.yahoo.com>
References: <1006764782.7826419.1712289516806.ref@mail.yahoo.com>
 <1006764782.7826419.1712289516806@mail.yahoo.com>
Message-ID: <20240405111737.2b7e4c3a@arachnoid>

Hello Mark,

? Fri, 5 Apr 2024 03:58:36 +0000 (UTC)
Mark Webster via R-help <r-help at r-project.org> ?????:

> I found what looks to me like an odd edge case for duplicated(),
> unique() etc. on data frames with zero columns, due to duplicated()
> returning a zero-length vector for them, regardless of the number of
> rows:

> df <- data.frame(a = 1:5)
> df$a <- NULLnrow(df)
> # 5 (row count preserved by row.names)
> duplicated(df)
> # logical(0), should be c(FALSE, TRUE, TRUE, TRUE, TRUE)
> anyDuplicated(df)
> # 0, should be 2

> This behaviour isn't mentioned in the documentation; is there a
> reason for it to work like this?

<...>

> I admit this is a case we rarely care about.However, for an example
> of this being an issue,?I've been running into it when treating data
> frames as database relations, where they have one or more candidate
> keys (irreducible subsets of the columns for which every row must
> have a unique value set).

Part of the problem is that it's not obvious what should be a
zero-column but non-zero-row data.frame mean.

On the one hand, your database relation use case is entirely valid. On
the other hand, if data.frames are considered to be tables of data with
row.names as their identifiers, then duplicated(d) should be returning
logical(nrow(d)) for zero-column data.frames, since row.names are
required to be unique. I'm sure that more interpretations can be
devised, requiring some other behaviour for duplicated() and friends.

Thankfully, duplicated() and anyDuplicated() are generic functions, and
you can subclass your data frames to change their behaviour:

duplicated.database_relation <- function(x, incomparables = FALSE, ...)
 if (length(x)) return(NextMethod()) else c(
  FALSE, rep(TRUE, nrow(x) - 1)
 )
.S3method('duplicated', 'database_relation')

anyDuplicated.database_relation <- function(
 x, incomparables = FALSE, ...
) if (nrow(x) > 1) 2 else 0
.S3method('anyDuplicated', 'database_relation')

x <- data.frame(row.names = 1:5)
class(x) <- c('database_relation', class(x))

duplicated(x)
# [1] FALSE  TRUE  TRUE  TRUE  TRUE
anyDuplicated(x)
# [1] 2
unique(x)
# data frame with 0 columns and 1 row

> [[alternative HTML version deleted]]

Since this mailing list eats the HTML parts of the e-mails, we only get
the plain text version automatically prepared by your mailer. This one
didn't look so good:
https://stat.ethz.ch/pipermail/r-help/2024-April/479143.html

Composing your messages to the list in plain text will help avoid the
problem.

-- 
Best regards,
Ivan


From m@rkweb@ter204 @end|ng |rom y@hoo@co@uk  Fri Apr  5 10:40:52 2024
From: m@rkweb@ter204 @end|ng |rom y@hoo@co@uk (Mark Webster)
Date: Fri, 5 Apr 2024 08:40:52 +0000 (UTC)
Subject: [R] 
 duplicated() on zero-column data frames returns empty vector
In-Reply-To: <20240405111737.2b7e4c3a@arachnoid>
References: <1006764782.7826419.1712289516806.ref@mail.yahoo.com>
 <1006764782.7826419.1712289516806@mail.yahoo.com>
 <20240405111737.2b7e4c3a@arachnoid>
Message-ID: <1379736116.7985600.1712306452176@mail.yahoo.com>

 Hello Ivan, thanks for this.
   > Part of the problem is that it's not obvious what should be a
> zero-column but non-zero-row data.frame mean.
>?
> On the one hand, your database relation use case is entirely valid. On
> the other hand, if data.frames are considered to be tables of data with
> row.names as their identifiers, then duplicated(d) should be returning
> logical(nrow(d)) for zero-column data.frames, since row.names are
> required to be unique. I'm sure that more interpretations can be
> devised, requiring some other behaviour for duplicated() and friends.

Do you mean the row names should mean all the rows should be counted as non-duplicates?Yes, I can see the argument for that, thanks.I must say I'm still puzzled at what interpretation would motivate the current behaviour of returning a logical(0), however.

> Thankfully, duplicated() and anyDuplicated() are generic functions, and
> you can subclass your data frames to change their behaviour:
>?> ...
Indeed, I'm already doing something along these lines!
Best Regards,Mark  
	[[alternative HTML version deleted]]


From JH@rm@e @end|ng |rom roku@com  Fri Apr  5 18:08:13 2024
From: JH@rm@e @end|ng |rom roku@com (Jorgen Harmse)
Date: Fri, 5 Apr 2024 16:08:13 +0000
Subject: [R] duplicated() on zero-column data frames returns empty
In-Reply-To: <mailman.371140.1.1712311201.19074.r-help@r-project.org>
References: <mailman.371140.1.1712311201.19074.r-help@r-project.org>
Message-ID: <BL0PR01MB44340DF8EBC763E92A991302DC032@BL0PR01MB4434.prod.exchangelabs.com>

(I do not know how to make Outlook send plain text, so I avoid apostrophes.)

For what it is worth, I agree with Mark Webster. The discussion by Ivan Krylov is interesting, but if duplicated really treated a row name as part of the row then any(duplicated(data.frame(?))) would always be FALSE. My expectation is that if key1 is a subset of key2 then all(duplicated(df[key1]) >= duplicated(df[key2])) should always be TRUE.

Incidentally, the examples for duplicated and the documentation of unique hint that unique(x) is the same as (but more efficient than) x[!duplicated(x)] (for a vector) or x[!duplicated(x)],,drop=FALSE] (for a data frame), and this seems to be true even in the corner case (with what I consider incorrect output from both functions) . On the other hand, I do not see any explicit guarantee about the order of entries in unique(x) (or setdiff(?) or intersect(?)). Code using these functions could be more efficient with explicit guarantees, but maybe the core team wants to preserve its own flexibility. My suggestion is to include some options so users can at least lock in the current behaviour (with a note that future versions may achieve it less efficiently). Other options might include sort=TRUE in case the core team develops something more efficient than sort(unique(?)).

Regards,
Jorgen.

------------------------------

Message: 2
Date: Fri, 5 Apr 2024 11:17:37 +0300
From: Ivan Krylov <ikrylov at disroot.org>
To: Mark Webster via R-help <r-help at r-project.org>
Cc: Mark Webster <markwebster204 at yahoo.co.uk>
Subject: Re: [R]  duplicated() on zero-column data frames returns
        empty vector
Message-ID: <20240405111737.2b7e4c3a at arachnoid>
Content-Type: text/plain; charset="utf-8"

Hello Mark,

? Fri, 5 Apr 2024 03:58:36 +0000 (UTC)
Mark Webster via R-help <r-help at r-project.org> ?????:

> I found what looks to me like an odd edge case for duplicated(),
> unique() etc. on data frames with zero columns, due to duplicated()
> returning a zero-length vector for them, regardless of the number of
> rows:

> df <- data.frame(a = 1:5)
> df$a <- NULLnrow(df)
> # 5 (row count preserved by row.names)
> duplicated(df)
> # logical(0), should be c(FALSE, TRUE, TRUE, TRUE, TRUE)
> anyDuplicated(df)
> # 0, should be 2

> This behaviour isn't mentioned in the documentation; is there a
> reason for it to work like this?

<...>

> I admit this is a case we rarely care about.However, for an example
> of this being an issue, I've been running into it when treating data
> frames as database relations, where they have one or more candidate
> keys (irreducible subsets of the columns for which every row must
> have a unique value set).

Part of the problem is that it's not obvious what should be a
zero-column but non-zero-row data.frame mean.

On the one hand, your database relation use case is entirely valid. On
the other hand, if data.frames are considered to be tables of data with
row.names as their identifiers, then duplicated(d) should be returning
logical(nrow(d)) for zero-column data.frames, since row.names are
required to be unique. I'm sure that more interpretations can be
devised, requiring some other behaviour for duplicated() and friends.

Thankfully, duplicated() and anyDuplicated() are generic functions, and
you can subclass your data frames to change their behaviour:

duplicated.database_relation <- function(x, incomparables = FALSE, ...)
 if (length(x)) return(NextMethod()) else c(
  FALSE, rep(TRUE, nrow(x) - 1)
 )
.S3method('duplicated', 'database_relation')

anyDuplicated.database_relation <- function(
 x, incomparables = FALSE, ...
) if (nrow(x) > 1) 2 else 0
.S3method('anyDuplicated', 'database_relation')

x <- data.frame(row.names = 1:5)
class(x) <- c('database_relation', class(x))

duplicated(x)
# [1] FALSE  TRUE  TRUE  TRUE  TRUE
anyDuplicated(x)
# [1] 2
unique(x)
# data frame with 0 columns and 1 row

> [[alternative HTML version deleted]]

Since this mailing list eats the HTML parts of the e-mails, we only get
the plain text version automatically prepared by your mailer. This one
didn't look so good:
https://stat.ethz.ch/pipermail/r-help/2024-April/479143.html

Composing your messages to the list in plain text will help avoid the
problem.

--
Best regards,
Ivan



	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Sun Apr  7 10:00:51 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Sun, 7 Apr 2024 11:00:51 +0300
Subject: [R] duplicated() on zero-column data frames returns empty
In-Reply-To: <BL0PR01MB44340DF8EBC763E92A991302DC032@BL0PR01MB4434.prod.exchangelabs.com>
References: <mailman.371140.1.1712311201.19074.r-help@r-project.org>
 <BL0PR01MB44340DF8EBC763E92A991302DC032@BL0PR01MB4434.prod.exchangelabs.com>
Message-ID: <20240407110051.7924c03c@Tarkus>

? Fri, 5 Apr 2024 16:08:13 +0000
Jorgen Harmse <JHarmse at roku.com> ?????:

> if duplicated really treated a row name as part of the row then
> any(duplicated(data.frame(?))) would always be FALSE. My expectation
> is that if key1 is a subset of key2 then all(duplicated(df[key1]) >=
> duplicated(df[key2])) should always be TRUE.

That's a good argument, thank you!

Would you suggest similar changes to duplicated.matrix too? Currently
it too returns 0-length output for 0-column inputs:

# 0-column matrix for 0-column input
str(duplicated(matrix(0, 5, 0)))
# logi[1:5, 0 ] 

# 1-column matrix for 1-column input
str(duplicated(matrix(0, 5, 1)))
# logi [1:5, 1] FALSE TRUE TRUE TRUE TRUE

# a dim-1 array for >1-column input
str(duplicated(matrix(0, 5, 10)))
# logi [1:5(1d)] FALSE TRUE TRUE TRUE TRUE

-- 
Best regards,
Ivan


From j@b@y@t194 @end|ng |rom gm@||@com  Sun Apr  7 14:27:18 2024
From: j@b@y@t194 @end|ng |rom gm@||@com (javad bayat)
Date: Sun, 7 Apr 2024 15:57:18 +0330
Subject: [R] Question regarding reservoir volume and water level
Message-ID: <CANTxAmJrvE5tHoyU1dgs0epeKrMv4tqg-R9K53CPA_TcR8sOvQ@mail.gmail.com>

Dear all;
I have a question about the water level of a reservoir, when the volume
changed or doubled.
There is a DEM file with the highest elevation 1267 m. The lowest elevation
is 1230 m. The current volume of the reservoir is 7,000,000 m3 at 1240 m.
Now I want to know what would be the water level if the volume rises to
1250 m? or what would be the water level if the volume doubled (14,000,000
m3)?

Is there any way to write codes to do this in R?
I would be more than happy if anyone could help me.
Sincerely








-- 
Best Regards
Javad Bayat
M.Sc. Environment Engineering
Alternative Mail: bayat194 at yahoo.com

	[[alternative HTML version deleted]]


From cry@n @end|ng |rom b|ngh@mton@edu  Sun Apr  7 15:25:42 2024
From: cry@n @end|ng |rom b|ngh@mton@edu (Chris Ryan)
Date: Sun, 07 Apr 2024 09:25:42 -0400
Subject: [R] Question regarding reservoir volume and water level
In-Reply-To: <CANTxAmJrvE5tHoyU1dgs0epeKrMv4tqg-R9K53CPA_TcR8sOvQ@mail.gmail.com>
References: <CANTxAmJrvE5tHoyU1dgs0epeKrMv4tqg-R9K53CPA_TcR8sOvQ@mail.gmail.com>
Message-ID: <30847199-462E-4BCE-8BC5-01F22692A6AE@binghamton.edu>

Homework?
-- 
Sent from my Android device with K-9 Mail. Please excuse my brevity.

On April 7, 2024 8:27:18 AM EDT, javad bayat <j.bayat194 at gmail.com> wrote:
>Dear all;
>I have a question about the water level of a reservoir, when the volume
>changed or doubled.
>There is a DEM file with the highest elevation 1267 m. The lowest elevation
>is 1230 m. The current volume of the reservoir is 7,000,000 m3 at 1240 m.
>Now I want to know what would be the water level if the volume rises to
>1250 m? or what would be the water level if the volume doubled (14,000,000
>m3)?
>
>Is there any way to write codes to do this in R?
>I would be more than happy if anyone could help me.
>Sincerely
>
>
>
>
>
>
>
>


From cry@n @end|ng |rom b|ngh@mton@edu  Sun Apr  7 15:25:42 2024
From: cry@n @end|ng |rom b|ngh@mton@edu (Chris Ryan)
Date: Sun, 07 Apr 2024 09:25:42 -0400
Subject: [R] Question regarding reservoir volume and water level
In-Reply-To: <CANTxAmJrvE5tHoyU1dgs0epeKrMv4tqg-R9K53CPA_TcR8sOvQ@mail.gmail.com>
References: <CANTxAmJrvE5tHoyU1dgs0epeKrMv4tqg-R9K53CPA_TcR8sOvQ@mail.gmail.com>
Message-ID: <30847199-462E-4BCE-8BC5-01F22692A6AE@binghamton.edu>

Homework?
-- 
Sent from my Android device with K-9 Mail. Please excuse my brevity.

On April 7, 2024 8:27:18 AM EDT, javad bayat <j.bayat194 at gmail.com> wrote:
>Dear all;
>I have a question about the water level of a reservoir, when the volume
>changed or doubled.
>There is a DEM file with the highest elevation 1267 m. The lowest elevation
>is 1230 m. The current volume of the reservoir is 7,000,000 m3 at 1240 m.
>Now I want to know what would be the water level if the volume rises to
>1250 m? or what would be the water level if the volume doubled (14,000,000
>m3)?
>
>Is there any way to write codes to do this in R?
>I would be more than happy if anyone could help me.
>Sincerely
>
>
>
>
>
>
>
>


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Apr  7 16:53:02 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 7 Apr 2024 15:53:02 +0100
Subject: [R] Question regarding reservoir volume and water level
In-Reply-To: <CANTxAmJrvE5tHoyU1dgs0epeKrMv4tqg-R9K53CPA_TcR8sOvQ@mail.gmail.com>
References: <CANTxAmJrvE5tHoyU1dgs0epeKrMv4tqg-R9K53CPA_TcR8sOvQ@mail.gmail.com>
Message-ID: <9155638a-7a32-4b20-bc1b-e171d72a053c@sapo.pt>

?s 13:27 de 07/04/2024, javad bayat escreveu:
> Dear all;
> I have a question about the water level of a reservoir, when the volume
> changed or doubled.
> There is a DEM file with the highest elevation 1267 m. The lowest elevation
> is 1230 m. The current volume of the reservoir is 7,000,000 m3 at 1240 m.
> Now I want to know what would be the water level if the volume rises to
> 1250 m? or what would be the water level if the volume doubled (14,000,000
> m3)?
> 
> Is there any way to write codes to do this in R?
> I would be more than happy if anyone could help me.
> Sincerely
> 
> 
> 
> 
> 
> 
> 
> 
Hello,

This is a simple rule of three.
If you know the level l the argument doesn't need to be named but if you 
know the volume v then it must be named.


water_level <- function(l, v, level = 1240, volume = 7e6) {
   if(missing(v)) {
     volume * l / level
   } else level * v / volume
}

lev <- 1250
vol <- 14e6

water_level(l = lev)
#> [1] 7056452
water_level(v = vol)
#> [1] 2480


Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From j@ork|n @end|ng |rom @om@um@ry|@nd@edu  Sun Apr  7 21:07:34 2024
From: j@ork|n @end|ng |rom @om@um@ry|@nd@edu (Sorkin, John)
Date: Sun, 7 Apr 2024 19:07:34 +0000
Subject: [R] Question regarding reservoir volume and water level
In-Reply-To: <9155638a-7a32-4b20-bc1b-e171d72a053c@sapo.pt>
References: <CANTxAmJrvE5tHoyU1dgs0epeKrMv4tqg-R9K53CPA_TcR8sOvQ@mail.gmail.com>
 <9155638a-7a32-4b20-bc1b-e171d72a053c@sapo.pt>
Message-ID: <DM6PR03MB5049C4C70B571CD3DD9B25F2E2012@DM6PR03MB5049.namprd03.prod.outlook.com>

Aside from the fact that the original question might well be a class exercise (or homework), the question is unanswerable given the data given by the original poster. One needs to know the dimensions of the reservoir, above and below the current waterline. Are the sides, above and below the waterline smooth? Is the region currently above the waterline that can store water a mirror image of the region below the waterline? Is the region above the reservoir include a flood plane? Will the additional water go into the flood plane?

The lack of required detail in the question posed by the original poster suggests that there are strong assumptions, assumptions that typically would be made in a class-room example or exercise.

John

John David Sorkin M.D., Ph.D.
Professor of Medicine, University of Maryland School of Medicine;
Associate Director for Biostatistics and Informatics, Baltimore VA Medical Center Geriatrics Research, Education, and Clinical Center;
PI Biostatistics and Informatics Core, University of Maryland School of Medicine Claude D. Pepper Older Americans Independence Center;
Senior Statistician University of Maryland Center for Vascular Research;

Division of Gerontology and Paliative Care,
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
Cell phone 443-418-5382




________________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Rui Barradas <ruipbarradas at sapo.pt>
Sent: Sunday, April 7, 2024 10:53 AM
To: javad bayat; R-help
Subject: Re: [R] Question regarding reservoir volume and water level

?s 13:27 de 07/04/2024, javad bayat escreveu:
> Dear all;
> I have a question about the water level of a reservoir, when the volume
> changed or doubled.
> There is a DEM file with the highest elevation 1267 m. The lowest elevation
> is 1230 m. The current volume of the reservoir is 7,000,000 m3 at 1240 m.
> Now I want to know what would be the water level if the volume rises to
> 1250 m? or what would be the water level if the volume doubled (14,000,000
> m3)?
>
> Is there any way to write codes to do this in R?
> I would be more than happy if anyone could help me.
> Sincerely
>
>
>
>
>
>
>
>
Hello,

This is a simple rule of three.
If you know the level l the argument doesn't need to be named but if you
know the volume v then it must be named.


water_level <- function(l, v, level = 1240, volume = 7e6) {
   if(missing(v)) {
     volume * l / level
   } else level * v / volume
}

lev <- 1250
vol <- 14e6

water_level(l = lev)
#> [1] 7056452
water_level(v = vol)
#> [1] 2480


Hope this helps,

Rui Barradas


--
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
http://www.avg.com/

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From @vi@e@gross m@iii@g oii gm@ii@com  Sun Apr  7 22:41:49 2024
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Sun, 7 Apr 2024 16:41:49 -0400
Subject: [R] Question regarding reservoir volume and water level
In-Reply-To: <30847199-462E-4BCE-8BC5-01F22692A6AE@binghamton.edu>
References: <CANTxAmJrvE5tHoyU1dgs0epeKrMv4tqg-R9K53CPA_TcR8sOvQ@mail.gmail.com>
 <30847199-462E-4BCE-8BC5-01F22692A6AE@binghamton.edu>
Message-ID: <008f01da892c$03dccfa0$0b966ee0$@gmail.com>

Chris, since it does indeed look like homework, albeit a deeper looks
suggests it may not beI think we can safely answer the question:

>Is there any way to write codes to do this in R?

The answer is YES.

And before you ask, it can be done in Python, Java, C++, Javascript, BASIC,
FORTRAN and probably even COBOL and many forms of assembler.

And, it can be done even without a computer using your mind and pencil and
paper.

I have seen similar problems discussed using a search and wonder if that is
where you should go, or perhaps consult your textbook or class notes.

OK, levity aside, what is the real question? 

If you want help designing an algorithm that solves the problem, that is
outside the scope of this forum and may indeed count as helping someone for
free with their homework or other work.

If this was a place for tutoring help you might  be asked to try to show
some work and point out where one step seems stuck. You might get answers.

Perhaps a better question is to look at your problem and see what it might
need and ask if someone knows of one or more R packages that handle your
needs.

But as I read your message, assume people reading it have no idea what a DEM
file is. I looked it up and it a Digital Elevation Model. I then searched to
see if anyone discussed how to bring the contents of the file into an R
session and found some suggestions but note I have not, nor plan, to try any
of them.

Your request does not specify any particular shape for the containment of
existing water or what is above. If it is from a DES file, it would have
info about what likely may be quite irregular surfaces that vary with depth.
That is not as simple a calculation as asking what happens if the container
is a cylinder or cone . It depends on the data we cannot see. It sounds way
beyond basic R as it likely involves working with 3-D matrices or something
similar.

So I looked for packages you can search for too and I see one called,
appropriately, DEM. I see other packages called Terra and CopernicusDEM  and
whitebox and you may want to do searching and see if anything solves parts
of your problem.

And, of course, it may be something you find will do it easily for you if
someone has provided say a module for Python.

Good Luck.


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Chris Ryan via
R-help
Sent: Sunday, April 7, 2024 9:26 AM
To: r-help at r-project.org; javad bayat <j.bayat194 at gmail.com>; R-help
<R-help at r-project.org>
Subject: Re: [R] Question regarding reservoir volume and water level

Homework?
-- 
Sent from my Android device with K-9 Mail. Please excuse my brevity.

On April 7, 2024 8:27:18 AM EDT, javad bayat <j.bayat194 at gmail.com> wrote:
>Dear all;
>I have a question about the water level of a reservoir, when the volume
>changed or doubled.
>There is a DEM file with the highest elevation 1267 m. The lowest elevation
>is 1230 m. The current volume of the reservoir is 7,000,000 m3 at 1240 m.
>Now I want to know what would be the water level if the volume rises to
>1250 m? or what would be the water level if the volume doubled (14,000,000
>m3)?
>
>Is there any way to write codes to do this in R?
>I would be more than happy if anyone could help me.
>Sincerely
>
>
>
>
>
>
>
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From m@rkweb@ter204 @end|ng |rom y@hoo@co@uk  Sun Apr  7 22:44:26 2024
From: m@rkweb@ter204 @end|ng |rom y@hoo@co@uk (Mark Webster)
Date: Sun, 7 Apr 2024 20:44:26 +0000 (UTC)
Subject: [R] duplicated() on zero-column data frames returns empty
In-Reply-To: <20240407110051.7924c03c@Tarkus>
References: <mailman.371140.1.1712311201.19074.r-help@r-project.org>
 <BL0PR01MB44340DF8EBC763E92A991302DC032@BL0PR01MB4434.prod.exchangelabs.com>
 <20240407110051.7924c03c@Tarkus>
Message-ID: <603481690.9150754.1712522666289@mail.yahoo.com>

 With respect to duplicated.data.frame taking account of row names to return all the rows as unique: thinking about this some more, I can see that making sense in isolation, but it's at odds with the usual behaviour of duplicated for other classes, e.g. primitive vectors, where it doesn't take account of names.
> Would you suggest similar changes to duplicated.matrix too? Currently
> it too returns 0-length output for 0-column inputs:

duplicated.matrix is an interesting one. I think a similar change would make sense, because it would have the dimensions that people would expect when using the default MARGIN = 1. However, it could be argued that it's not a needed change, because the Value section of its documentation only guarantees the dimensions of the output when using MARGIN = 0. In that case, duplicated.matrix does indeed return the expected 5x0 matrix for your example:
str(duplicated(matrix(0, 5, 0), MARGIN = 0))# logi[1:5, 0 ]
Best Regards,
Mark Webster  
	[[alternative HTML version deleted]]


From @vi@e@gross m@iii@g oii gm@ii@com  Sun Apr  7 22:53:00 2024
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Sun, 7 Apr 2024 16:53:00 -0400
Subject: [R] Question regarding reservoir volume and water level
In-Reply-To: <DM6PR03MB5049C4C70B571CD3DD9B25F2E2012@DM6PR03MB5049.namprd03.prod.outlook.com>
References: <CANTxAmJrvE5tHoyU1dgs0epeKrMv4tqg-R9K53CPA_TcR8sOvQ@mail.gmail.com>
 <9155638a-7a32-4b20-bc1b-e171d72a053c@sapo.pt>
 <DM6PR03MB5049C4C70B571CD3DD9B25F2E2012@DM6PR03MB5049.namprd03.prod.outlook.com>
Message-ID: <009101da892d$93a3cc50$baeb64f0$@gmail.com>

John,

Your reaction was what my original reaction was until I realized I had to
find out what a DEM file was and that contains enough of the kind of
depth-dimension data you describe albeit what may be a very irregular cross
section to calculate for areas and thence volumes.

If I read it correctly, this can be a very real-world problem worthy of a
solution, such as in places like California where they had a tad more rain
than usual and some reservoirs may overflow. Someone else provided what
sounds like a mathematical algorithm but my guess is what is needed here is
perhaps less analytic since there may be no trivial way to create formulas
and take integrals and so on, but simply an approximate way to calculate
incremental volumes for each horizontal "slice" and keep adding or
subtracting them till you reach a target and then read off another variable
at that point such as depth.

Some care must be taken as water level has to be relative to something and
many natural reservoirs have no unique bottom level. Some water may also be
stored underground and to the side and pour in if the level lowers or can be
used to escape if the level rises.


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Sorkin, John
Sent: Sunday, April 7, 2024 3:08 PM
To: Rui Barradas <ruipbarradas at sapo.pt>; javad bayat <j.bayat194 at gmail.com>;
R-help <R-help at r-project.org>
Subject: Re: [R] Question regarding reservoir volume and water level

Aside from the fact that the original question might well be a class
exercise (or homework), the question is unanswerable given the data given by
the original poster. One needs to know the dimensions of the reservoir,
above and below the current waterline. Are the sides, above and below the
waterline smooth? Is the region currently above the waterline that can store
water a mirror image of the region below the waterline? Is the region above
the reservoir include a flood plane? Will the additional water go into the
flood plane?

The lack of required detail in the question posed by the original poster
suggests that there are strong assumptions, assumptions that typically would
be made in a class-room example or exercise.

John

John David Sorkin M.D., Ph.D.
Professor of Medicine, University of Maryland School of Medicine;
Associate Director for Biostatistics and Informatics, Baltimore VA Medical
Center Geriatrics Research, Education, and Clinical Center;
PI Biostatistics and Informatics Core, University of Maryland School of
Medicine Claude D. Pepper Older Americans Independence Center;
Senior Statistician University of Maryland Center for Vascular Research;

Division of Gerontology and Paliative Care,
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
Cell phone 443-418-5382




________________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Rui Barradas
<ruipbarradas at sapo.pt>
Sent: Sunday, April 7, 2024 10:53 AM
To: javad bayat; R-help
Subject: Re: [R] Question regarding reservoir volume and water level

?s 13:27 de 07/04/2024, javad bayat escreveu:
> Dear all;
> I have a question about the water level of a reservoir, when the volume
> changed or doubled.
> There is a DEM file with the highest elevation 1267 m. The lowest
elevation
> is 1230 m. The current volume of the reservoir is 7,000,000 m3 at 1240 m.
> Now I want to know what would be the water level if the volume rises to
> 1250 m? or what would be the water level if the volume doubled (14,000,000
> m3)?
>
> Is there any way to write codes to do this in R?
> I would be more than happy if anyone could help me.
> Sincerely
>
>
>
>
>
>
>
>
Hello,

This is a simple rule of three.
If you know the level l the argument doesn't need to be named but if you
know the volume v then it must be named.


water_level <- function(l, v, level = 1240, volume = 7e6) {
   if(missing(v)) {
     volume * l / level
   } else level * v / volume
}

lev <- 1250
vol <- 14e6

water_level(l = lev)
#> [1] 7056452
water_level(v = vol)
#> [1] 2480


Hope this helps,

Rui Barradas


--
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
presen?a de v?rus.
http://www.avg.com/

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From j@b@y@t194 @end|ng |rom gm@||@com  Mon Apr  8 05:55:59 2024
From: j@b@y@t194 @end|ng |rom gm@||@com (javad bayat)
Date: Mon, 8 Apr 2024 07:25:59 +0330
Subject: [R] Question regarding reservoir volume and water level
In-Reply-To: <009101da892d$93a3cc50$baeb64f0$@gmail.com>
References: <CANTxAmJrvE5tHoyU1dgs0epeKrMv4tqg-R9K53CPA_TcR8sOvQ@mail.gmail.com>
 <9155638a-7a32-4b20-bc1b-e171d72a053c@sapo.pt>
 <DM6PR03MB5049C4C70B571CD3DD9B25F2E2012@DM6PR03MB5049.namprd03.prod.outlook.com>
 <009101da892d$93a3cc50$baeb64f0$@gmail.com>
Message-ID: <CANTxAmJzd2n8C0a=LhJzDU6K8GFr7p6q9hXP=zcthQqvitusvw@mail.gmail.com>

Dear all;
Many thanks for your replies. This was not homework. I apologize.
Let me explain more.
There is a dam constructed in a valley with the highest elevation of 1255
m. The area of its reservoir can be calculated by drawing a polygon around
the water and it is known.
I have the Digital Elevation Model (DEM) of the region (reservoir and its
surrounding area). I have calculated the volume of the current reservoir
(7e6 m3) using the following codes.
library(raster)
library(terra)
library(exactextractr)
library(dplyr)
library(sf)
# Calculate volume for polygon
# Read the DEM raster file
r <- rast("E:/...DEM.tif")
# Read the polygon shapefile
p <- st_read("E:/...Dam.shp")

r <- crop(r, extent(p))
r <- mask(r, p)

# Extract the cells in each polygon and calculate the area of each cell
x <- exact_extract(r, p, coverage_area = TRUE)
# Extract polygon values as a dataframe
x1 = as.data.frame(x[1])
head(x1)
x1 = na.omit(x1)
# Calculate the height above the minimum elevation in the polygon
x1$Height = max(x1[,1]) - x1[,1]
# Calculate the volume of each cell
x1$Vol = x1[,2] * x1[,3]
sum(x1$Vol)
x2 = x1[,c(1,2,4)]
x2 = sort(x2,'value')
head(x2)
x3 <- aggregate(Vol ~ value, data = x2, FUN = sum)
x4 <- aggregate(coverage_area ~ value, data = x2, FUN = sum)
x5 = cbind(x3, Area = x4[,2])
library(dplyr)
x6 <- x5 %>%
  mutate(V_sum = cumsum(Vol)) %>%
  mutate(A_sum = cumsum(Area))
plot(x6$value~x6$V_sum)

And I thought that it is possible to get the elevation for a specific
volume by linear model between elevation and volume, as follow:

# Get a linear model between elevation and the volume
lm1 <- lm(value ~ V_sum, data = x6)
d <- data.frame(V_sum = 14e6)  #
predict(lm1, newdata = d)

But it is not possible through the LM.
Now I want to know what would be the water level in the reservoir if the
reservoir volume doubled or we adding a known volume to it?
Also what would be the volume if the water level increases to 1250 m?

I would be more than happy if you help me to do this.
Sincerely

On Mon, Apr 8, 2024 at 12:23?AM <avi.e.gross at gmail.com> wrote:

> John,
>
> Your reaction was what my original reaction was until I realized I had to
> find out what a DEM file was and that contains enough of the kind of
> depth-dimension data you describe albeit what may be a very irregular cross
> section to calculate for areas and thence volumes.
>
> If I read it correctly, this can be a very real-world problem worthy of a
> solution, such as in places like California where they had a tad more rain
> than usual and some reservoirs may overflow. Someone else provided what
> sounds like a mathematical algorithm but my guess is what is needed here is
> perhaps less analytic since there may be no trivial way to create formulas
> and take integrals and so on, but simply an approximate way to calculate
> incremental volumes for each horizontal "slice" and keep adding or
> subtracting them till you reach a target and then read off another variable
> at that point such as depth.
>
> Some care must be taken as water level has to be relative to something and
> many natural reservoirs have no unique bottom level. Some water may also be
> stored underground and to the side and pour in if the level lowers or can
> be
> used to escape if the level rises.
>
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Sorkin, John
> Sent: Sunday, April 7, 2024 3:08 PM
> To: Rui Barradas <ruipbarradas at sapo.pt>; javad bayat <j.bayat194 at gmail.com
> >;
> R-help <R-help at r-project.org>
> Subject: Re: [R] Question regarding reservoir volume and water level
>
> Aside from the fact that the original question might well be a class
> exercise (or homework), the question is unanswerable given the data given
> by
> the original poster. One needs to know the dimensions of the reservoir,
> above and below the current waterline. Are the sides, above and below the
> waterline smooth? Is the region currently above the waterline that can
> store
> water a mirror image of the region below the waterline? Is the region above
> the reservoir include a flood plane? Will the additional water go into the
> flood plane?
>
> The lack of required detail in the question posed by the original poster
> suggests that there are strong assumptions, assumptions that typically
> would
> be made in a class-room example or exercise.
>
> John
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine, University of Maryland School of Medicine;
> Associate Director for Biostatistics and Informatics, Baltimore VA Medical
> Center Geriatrics Research, Education, and Clinical Center;
> PI Biostatistics and Informatics Core, University of Maryland School of
> Medicine Claude D. Pepper Older Americans Independence Center;
> Senior Statistician University of Maryland Center for Vascular Research;
>
> Division of Gerontology and Paliative Care,
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> Cell phone 443-418-5382
>
>
>
>
> ________________________________________
> From: R-help <r-help-bounces at r-project.org> on behalf of Rui Barradas
> <ruipbarradas at sapo.pt>
> Sent: Sunday, April 7, 2024 10:53 AM
> To: javad bayat; R-help
> Subject: Re: [R] Question regarding reservoir volume and water level
>
> ?s 13:27 de 07/04/2024, javad bayat escreveu:
> > Dear all;
> > I have a question about the water level of a reservoir, when the volume
> > changed or doubled.
> > There is a DEM file with the highest elevation 1267 m. The lowest
> elevation
> > is 1230 m. The current volume of the reservoir is 7,000,000 m3 at 1240 m.
> > Now I want to know what would be the water level if the volume rises to
> > 1250 m? or what would be the water level if the volume doubled
> (14,000,000
> > m3)?
> >
> > Is there any way to write codes to do this in R?
> > I would be more than happy if anyone could help me.
> > Sincerely
> >
> >
> >
> >
> >
> >
> >
> >
> Hello,
>
> This is a simple rule of three.
> If you know the level l the argument doesn't need to be named but if you
> know the volume v then it must be named.
>
>
> water_level <- function(l, v, level = 1240, volume = 7e6) {
>    if(missing(v)) {
>      volume * l / level
>    } else level * v / volume
> }
>
> lev <- 1250
> vol <- 14e6
>
> water_level(l = lev)
> #> [1] 7056452
> water_level(v = vol)
> #> [1] 2480
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> --
> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> presen?a de v?rus.
> http://www.avg.com/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.r-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

-- 
Best Regards
Javad Bayat
M.Sc. Environment Engineering
Alternative Mail: bayat194 at yahoo.com

	[[alternative HTML version deleted]]


From ger@ophii m@iii@g oii gmx@@et  Mon Apr  8 10:29:53 2024
From: ger@ophii m@iii@g oii gmx@@et (ger@ophii m@iii@g oii gmx@@et)
Date: Mon, 8 Apr 2024 10:29:53 +0200
Subject: [R] How to set the correct libomp for R
Message-ID: <trinity-16663902-ac9a-41c0-ba5e-ebe725249518-1712564993044@3c-app-gmx-bap10>

Hey everyone,

I have some weird issue with using multithreaded data.table in macOS and I am trying to figure out, if it?s connected to my libomp.dylib. I started using libomp as stated here: https://mac.r-project.org/openmp/
?
Everything worked fine till beginning of this year, but all of a sudden, I get random fatal errors, when using data.table with multithreading. I figured that R (used in RStudio) is not loading this libomp.dylib (located at /usr/local/lib/libomp.dylib), but the one bundled with R (/Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libomp.dylib). I sued this command to check for this:

system(paste("lsof -p", Sys.getpid(), "| grep dylib"))
?
I never checked, which one was used before, but this raised some questions for me:
?
1. Was libomp.dylib always bundled with R and if yes, what?s the point of this separate libomp.dylib from this page (https://mac.r-project.org/openmp/)?
2. Is there a way to set the libomp.dylib to another path and does this even make sense or should I always use the one bundled with R?
3. Could it be that one of the libraries is used for installing packages by Xcode?s clang and the other is used during usage of the package?
?
Maybe someone could shed some light onto this topic :).
?
P.S.: If you need some more details about the actual issue with data.table you can also check here (https://github.com/rstudio/rstudio/issues/14517) and here (https://github.com/Rdatatable/data.table/issues/5957). Or you can of course ask me, but it would be a little overkill to share everything that has been tried yet :).


From |kry|ov @end|ng |rom d|@root@org  Mon Apr  8 11:13:45 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Mon, 8 Apr 2024 12:13:45 +0300
Subject: [R] How to set the correct libomp for R
In-Reply-To: <trinity-16663902-ac9a-41c0-ba5e-ebe725249518-1712564993044@3c-app-gmx-bap10>
References: <trinity-16663902-ac9a-41c0-ba5e-ebe725249518-1712564993044@3c-app-gmx-bap10>
Message-ID: <20240408121345.4f3f15e4@arachnoid>

? Mon, 8 Apr 2024 10:29:53 +0200
gernophil--- via R-help <r-help at r-project.org> ?????:

> I have some weird issue with using multithreaded data.table in macOS
> and I am trying to figure out, if it?s connected to my libomp.dylib.
> I started using libomp as stated here:
> https://mac.r-project.org/openmp/

Does the behaviour change if you temporarily move away
/usr/local/lib/libomp.dylib? 

> P.S.: If you need some more details about the actual issue with
> data.table you can also check here
> (https://github.com/rstudio/rstudio/issues/14517) and here
> (https://github.com/Rdatatable/data.table/issues/5957)

The debugger may be able to shed more light on the problem than just
"yes, this is due to OpenMP":
https://github.com/rstudio/rstudio/issues/14517#issuecomment-2040231196

When you reproduce the crash, what does the backtrace say?

-- 
Best regards,
Ivan


From dd|xon @end|ng |rom @wcp@com  Mon Apr  8 07:47:52 2024
From: dd|xon @end|ng |rom @wcp@com (Dave Dixon)
Date: Sun, 7 Apr 2024 23:47:52 -0600
Subject: [R] Exceptional slowness with read.csv
Message-ID: <2a1f4ec9-26ae-4e80-bd40-10c4a919849f@swcp.com>

Greetings,

I have a csv file of 76 fields and about 4 million records. I know that 
some of the records have errors - unmatched quotes, specifically.? 
Reading the file with readLines and parsing the lines with read.csv(text 
= ...) is really slow. I know that the first 2459465 records are good. 
So I try this:

 > startTime <- Sys.time()
 > first_records <- read.csv(file_name, nrows = 2459465)
 > endTime <- Sys.time()
 > cat("elapsed time = ", endTime - startTime, "\n")

elapsed time = ? 24.12598

 > startTime <- Sys.time()
 > second_records <- read.csv(file_name, skip = 2459465, nrows = 5)
 > endTime <- Sys.time()
 > cat("elapsed time = ", endTime - startTime, "\n")

This appears to never finish. I have been waiting over 20 minutes.

So why would (skip = 2459465, nrows = 5) take orders of magnitude longer 
than (nrows = 2459465) ?

Thanks!

-dave

PS: readLines(n=2459470) takes 10.42731 seconds.


From @tephen@peder@on@@u @end|ng |rom gm@||@com  Mon Apr  8 17:18:46 2024
From: @tephen@peder@on@@u @end|ng |rom gm@||@com (Stevie Pederson)
Date: Tue, 9 Apr 2024 00:48:46 +0930
Subject: [R] Exceptional slowness with read.csv
In-Reply-To: <2a1f4ec9-26ae-4e80-bd40-10c4a919849f@swcp.com>
References: <2a1f4ec9-26ae-4e80-bd40-10c4a919849f@swcp.com>
Message-ID: <CAGCDhaVgEmWJXapLZJRU_1BegB-=1KyaT2wDNHNqKTs5VSrhvw@mail.gmail.com>

Hi Dave,

That's rather frustrating. I've found vroom (from the package vroom) to be
helpful with large files like this.

Does the following give you any better luck?

vroom(file_name, delim = ",", skip = 2459465, n_max = 5)

Of course, when you know you've got errors & the files are big like that it
can take a bit of work resolving things. The command line tools awk & sed
might even be a good plan for finding lines that have errors & figuring out
a fix, but I certainly don't envy you.

All the best

Stevie

On Tue, 9 Apr 2024 at 00:36, Dave Dixon <ddixon at swcp.com> wrote:

> Greetings,
>
> I have a csv file of 76 fields and about 4 million records. I know that
> some of the records have errors - unmatched quotes, specifically.
> Reading the file with readLines and parsing the lines with read.csv(text
> = ...) is really slow. I know that the first 2459465 records are good.
> So I try this:
>
>  > startTime <- Sys.time()
>  > first_records <- read.csv(file_name, nrows = 2459465)
>  > endTime <- Sys.time()
>  > cat("elapsed time = ", endTime - startTime, "\n")
>
> elapsed time =   24.12598
>
>  > startTime <- Sys.time()
>  > second_records <- read.csv(file_name, skip = 2459465, nrows = 5)
>  > endTime <- Sys.time()
>  > cat("elapsed time = ", endTime - startTime, "\n")
>
> This appears to never finish. I have been waiting over 20 minutes.
>
> So why would (skip = 2459465, nrows = 5) take orders of magnitude longer
> than (nrows = 2459465) ?
>
> Thanks!
>
> -dave
>
> PS: readLines(n=2459470) takes 10.42731 seconds.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From z|y@n@22 @end|ng |rom |nt|@zju@edu@cn  Sun Apr  7 10:18:40 2024
From: z|y@n@22 @end|ng |rom |nt|@zju@edu@cn (Jin, Ziyan)
Date: Sun, 7 Apr 2024 08:18:40 +0000
Subject: [R] Questions about ks.test function {stats}
Message-ID: <TYYP286MB19073D6D7978CD95E7BDF6F39C012@TYYP286MB1907.JPNP286.PROD.OUTLOOK.COM>

Dear R-help,

Hope this email finds you well. My name is Ziyan. I am a graduate student in Zhejiang University. My subject research involves ks.test in stats-package {stats}. Based on the code,  I have two main questions. Could you provide me some more information?

I download different versions of the r language source code through r language website (https://www.r-project.org/). By reading R-4.3.3/src/library/stats/R/ks.test.R, I encounter the following problem: before call the default psmirnov function (in two-sample case), z <- NULL. According to the T and F the TIES, determines the value of z assigned to w or not. However, when psmirnov is called, z=w is always used. I am curious whether the TIES parameter can be omitted.

Compared with the previous ks.test, such as version 4.1.3, the method of calculating p value in version 4.3.3 has changed a lot. ks.test() now provides exact p-values also with ties. For the psmirnov_exact_uniq_upper function in the ks.c file (R-4.3.3/src/stats/src/ks.c), could you please provide some details for the mathematical basis used to calculate the p-value? If you could provide me with some references, I would be grateful .

Thank you for your patience. I am eagerly awaiting your response.

Best,
Ziyan

	[[alternative HTML version deleted]]


From JH@rm@e @end|ng |rom roku@com  Mon Apr  8 19:03:00 2024
From: JH@rm@e @end|ng |rom roku@com (Jorgen Harmse)
Date: Mon, 8 Apr 2024 17:03:00 +0000
Subject: [R] duplicated() on zero-column data frames returns empty
In-Reply-To: <mailman.371154.1.1712570401.39107.r-help@r-project.org>
References: <mailman.371154.1.1712570401.39107.r-help@r-project.org>
Message-ID: <BL0PR01MB44344C7BE5F045434E49B7E9DC002@BL0PR01MB4434.prod.exchangelabs.com>

I appreciate the compliment from Ivan and still share the puzzlement at the empty return.

What is the policy for changing something that is wrong? There is a trade-off between breaking old code that worked around a problem and breaking new code written by people who make reasonable assumptions. Mathematically, it seems obvious to me that duplicated.matrix(A) should do something like this:

v <- matrix(FALSE, nrow = nrow(A) -> nr, ncol=1L) # or an ordinary vector?
if (nr > 1L) # Check because 2:0 & 2:1 do not do what we want.
{ for (i in 2:nr)
  { for (j in 1:(i-1))
    if (identical(A[i,],A[j,])) # or something more complicated to handle incomparables
    { v[i] <- TRUE; break}
  }
}
v

Of course my code is horribly inefficient, but the difference should be just in computing the same result faster. An empty vector of some type is identical to an empty vector of the same type, so this computes

      [,1]

[1,] FALSE

[2,]  TRUE

[3,]  TRUE

[4,]  TRUE

[5,]  TRUE
, and I argue that that is correct.

A gap in documentation makes a change to the correct behaviour easier. (If the current behaviour were documented then the first step in changing the behaviour would be to issue a warning that the change is coming in a future version.) The protection for old code could be just a warning that can be turned off with a call to options. The new documentation should be more explicit.

Regards,
Jorgen.

From: Mark Webster <markwebster204 at yahoo.co.uk>
To: Jorgen Harmse <jharmse at roku.com>, Ivan Krylov
        <ikrylov at disroot.org>
Cc: "r-help at r-project.org" <r-help at r-project.org>
Subject: Re: [R] duplicated() on zero-column data frames returns empty
Message-ID: <603481690.9150754.1712522666289 at mail.yahoo.com>
Content-Type: text/plain; charset="utf-8"

 duplicated.matrix is an interesting one. I think a similar change would make sense, because it would have the dimensions that people would expect when using the default MARGIN = 1. However, it could be argued that it's not a needed change, because the Value section of its documentation only guarantees the dimensions of the output when using MARGIN = 0. In that case, duplicated.matrix does indeed return the expected 5x0 matrix for your example:
str(duplicated(matrix(0, 5, 0), MARGIN = 0))# logi[1:5, 0 ]
Best Regards,
Mark Webster
        [[alternative HTML version deleted]]

From: Mark Webster markwebster204 at yahoo.co.uk<mailto:markwebster204 at yahoo.co.uk>
To: Ivan Krylov ikrylov at disroot.org<mailto:ikrylov at disroot.org>,  r-help at r-project.org<mailto:r-help at r-project.org>
        r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R]  duplicated() on zero-column data frames returns
        empty vector
Message-ID: 1379736116.7985600.1712306452176 at mail.yahoo.com<mailto:1379736116.7985600.1712306452176 at mail.yahoo.com>
Content-Type: text/plain; charset="utf-8"

 Do you mean the row names should mean all the rows should be counted as non-duplicates?Yes, I can see the argument for that, thanks.I must say I'm still puzzled at what interpretation would motivate the current behaviour of returning a logical(0), however.

Date: Sun, 7 Apr 2024 11:00:51 +0300
From: Ivan Krylov <ikrylov at disroot.org<mailto:ikrylov at disroot.org>>
To: Jorgen Harmse <JHarmse at roku.com<mailto:JHarmse at roku.com>>
Cc: "r-help at r-project.org<mailto:r-help at r-project.org>" <r-help at r-project.org<mailto:r-help at r-project.org>>,
        "markwebster204 at yahoo.co.uk<mailto:markwebster204 at yahoo.co.uk>" <markwebster204 at yahoo.co.uk<mailto:markwebster204 at yahoo.co.uk>>
Subject: Re: [R] duplicated() on zero-column data frames returns empty
Message-ID: 20240407110051.7924c03c at Tarkus<mailto:20240407110051.7924c03c at Tarkus>
Content-Type: text/plain; charset="utf-8"

? Fri, 5 Apr 2024 16:08:13 +0000
Jorgen Harmse <JHarmse at roku.com<mailto:JHarmse at roku.com>> ?????:

> if duplicated really treated a row name as part of the row then
> any(duplicated(data.frame(?))) would always be FALSE. My expectation
> is that if key1 is a subset of key2 then all(duplicated(df[key1]) >=
> duplicated(df[key2])) should always be TRUE.

That's a good argument, thank you!

Would you suggest similar changes to duplicated.matrix too? Currently
it too returns 0-length output for 0-column inputs:

# 0-column matrix for 0-column input
str(duplicated(matrix(0, 5, 0)))
# logi[1:5, 0 ]

# 1-column matrix for 1-column input
str(duplicated(matrix(0, 5, 1)))
# logi [1:5, 1] FALSE TRUE TRUE TRUE TRUE

# a dim-1 array for >1-column input
str(duplicated(matrix(0, 5, 10)))
# logi [1:5(1d)] FALSE TRUE TRUE TRUE TRUE

--
Best regards,
Ivan




	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Apr  8 19:49:22 2024
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 8 Apr 2024 10:49:22 -0700
Subject: [R] Exceptional slowness with read.csv
In-Reply-To: <2a1f4ec9-26ae-4e80-bd40-10c4a919849f@swcp.com>
References: <2a1f4ec9-26ae-4e80-bd40-10c4a919849f@swcp.com>
Message-ID: <CAGxFJbSPZTFqrrjht3pyKFz-QmX1DfOfd86tkMHxNBB2FLpXVA@mail.gmail.com>

No idea, but have you tried using ?scan to read those next 5 rows? It might
give you a better idea of the pathologies that are causing problems. For
example, an unmatched quote might result in some huge number of characters
trying to be read into a single element of a character variable. As your
previous respondent said, resolving such problems can be a challenge.

Cheers,
Bert



On Mon, Apr 8, 2024 at 8:06?AM Dave Dixon <ddixon at swcp.com> wrote:

> Greetings,
>
> I have a csv file of 76 fields and about 4 million records. I know that
> some of the records have errors - unmatched quotes, specifically.
> Reading the file with readLines and parsing the lines with read.csv(text
> = ...) is really slow. I know that the first 2459465 records are good.
> So I try this:
>
>  > startTime <- Sys.time()
>  > first_records <- read.csv(file_name, nrows = 2459465)
>  > endTime <- Sys.time()
>  > cat("elapsed time = ", endTime - startTime, "\n")
>
> elapsed time =   24.12598
>
>  > startTime <- Sys.time()
>  > second_records <- read.csv(file_name, skip = 2459465, nrows = 5)
>  > endTime <- Sys.time()
>  > cat("elapsed time = ", endTime - startTime, "\n")
>
> This appears to never finish. I have been waiting over 20 minutes.
>
> So why would (skip = 2459465, nrows = 5) take orders of magnitude longer
> than (nrows = 2459465) ?
>
> Thanks!
>
> -dave
>
> PS: readLines(n=2459470) takes 10.42731 seconds.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From po|c1410 @end|ng |rom gm@||@com  Mon Apr  8 20:14:06 2024
From: po|c1410 @end|ng |rom gm@||@com (CALUM POLWART)
Date: Mon, 8 Apr 2024 19:14:06 +0100
Subject: [R] Exceptional slowness with read.csv
In-Reply-To: <CAGCDhaVgEmWJXapLZJRU_1BegB-=1KyaT2wDNHNqKTs5VSrhvw@mail.gmail.com>
References: <2a1f4ec9-26ae-4e80-bd40-10c4a919849f@swcp.com>
 <CAGCDhaVgEmWJXapLZJRU_1BegB-=1KyaT2wDNHNqKTs5VSrhvw@mail.gmail.com>
Message-ID: <CA+etgPnYTPkuwcFkOfdPZPXazgg6UMVnYcJjoHaWG=Ki2_AUiw@mail.gmail.com>

data.table's fread is also fast. Not sure about error handling. But I can
merge 300 csvs with a total of 0.5m lines and 50 columns in a couple of
minutes versus a lifetime with read.csv or readr::read_csv



On Mon, 8 Apr 2024, 16:19 Stevie Pederson, <stephen.pederson.au at gmail.com>
wrote:

> Hi Dave,
>
> That's rather frustrating. I've found vroom (from the package vroom) to be
> helpful with large files like this.
>
> Does the following give you any better luck?
>
> vroom(file_name, delim = ",", skip = 2459465, n_max = 5)
>
> Of course, when you know you've got errors & the files are big like that it
> can take a bit of work resolving things. The command line tools awk & sed
> might even be a good plan for finding lines that have errors & figuring out
> a fix, but I certainly don't envy you.
>
> All the best
>
> Stevie
>
> On Tue, 9 Apr 2024 at 00:36, Dave Dixon <ddixon at swcp.com> wrote:
>
> > Greetings,
> >
> > I have a csv file of 76 fields and about 4 million records. I know that
> > some of the records have errors - unmatched quotes, specifically.
> > Reading the file with readLines and parsing the lines with read.csv(text
> > = ...) is really slow. I know that the first 2459465 records are good.
> > So I try this:
> >
> >  > startTime <- Sys.time()
> >  > first_records <- read.csv(file_name, nrows = 2459465)
> >  > endTime <- Sys.time()
> >  > cat("elapsed time = ", endTime - startTime, "\n")
> >
> > elapsed time =   24.12598
> >
> >  > startTime <- Sys.time()
> >  > second_records <- read.csv(file_name, skip = 2459465, nrows = 5)
> >  > endTime <- Sys.time()
> >  > cat("elapsed time = ", endTime - startTime, "\n")
> >
> > This appears to never finish. I have been waiting over 20 minutes.
> >
> > So why would (skip = 2459465, nrows = 5) take orders of magnitude longer
> > than (nrows = 2459465) ?
> >
> > Thanks!
> >
> > -dave
> >
> > PS: readLines(n=2459470) takes 10.42731 seconds.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Mon Apr  8 20:32:43 2024
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 8 Apr 2024 11:32:43 -0700 (PDT)
Subject: [R] Building R-4,3,3 fails
Message-ID: <2d4e6da0-bc51-4cab-8b84-f7631744b17@appl-ecosys.com>

I've been building R versions for years with no issues. Now I'm trying to
build R-4.3.3 on Slackware64-15.0 (fully patched) with TeXLive2024 (fully
patched) installed. The error occurs building a vignette.

Is this mail list the appropriate place to ask for help or should I post the
request on stackoverflow.com?

TIA,

Rich


From |kry|ov @end|ng |rom d|@root@org  Mon Apr  8 20:38:59 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Mon, 8 Apr 2024 21:38:59 +0300
Subject: [R] Building R-4,3,3 fails
In-Reply-To: <2d4e6da0-bc51-4cab-8b84-f7631744b17@appl-ecosys.com>
References: <2d4e6da0-bc51-4cab-8b84-f7631744b17@appl-ecosys.com>
Message-ID: <20240408213859.78c94c34@Tarkus>

Hello Rich,

? Mon, 8 Apr 2024 11:32:43 -0700 (PDT)
Rich Shepard <rshepard at appl-ecosys.com> ?????:

> I've been building R versions for years with no issues. Now I'm
> trying to build R-4.3.3 on Slackware64-15.0 (fully patched) with
> TeXLive2024 (fully patched) installed. The error occurs building a
> vignette.

Questions about building R do get asked here and R-devel. Since you're
compiling a released version of R and we don't have an R-SIG-Slackware
mailing list, R-help sounds like the right place.

What are the last lines of the build log, containing the error message?
If it's a LaTeX error, it may be that you need some extra TeX Live
packages, there is a list in R-admin:
https://cran.r-project.org/doc/manuals/R-admin.html#Making-the-manuals

-- 
Best regards,
Ivan


From |kry|ov @end|ng |rom d|@root@org  Mon Apr  8 20:42:33 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Mon, 8 Apr 2024 21:42:33 +0300
Subject: [R] Exceptional slowness with read.csv
In-Reply-To: <2a1f4ec9-26ae-4e80-bd40-10c4a919849f@swcp.com>
References: <2a1f4ec9-26ae-4e80-bd40-10c4a919849f@swcp.com>
Message-ID: <20240408214233.7f70549f@Tarkus>

? Sun, 7 Apr 2024 23:47:52 -0600
Dave Dixon <ddixon at swcp.com> ?????:

>  > second_records <- read.csv(file_name, skip = 2459465, nrows = 5)

It may or may not be important that read.csv defaults to header =
TRUE. Having skipped 2459465 lines, it may attempt to parse the next
one as a header, so the second call read.csv() should probably include
header = FALSE.

Bert's advice to try scan() is on point, though. It's likely that the
default-enabled header is not the most serious problem here.

-- 
Best regards,
Ivan


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Mon Apr  8 20:51:42 2024
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 8 Apr 2024 11:51:42 -0700 (PDT)
Subject: [R] Building R-4,3,3 fails
In-Reply-To: <20240408213859.78c94c34@Tarkus>
References: <2d4e6da0-bc51-4cab-8b84-f7631744b17@appl-ecosys.com>
 <20240408213859.78c94c34@Tarkus>
Message-ID: <7a7ddee-5da4-a48-f5c-328436577d6@appl-ecosys.com>

On Mon, 8 Apr 2024, Ivan Krylov wrote:

> Questions about building R do get asked here and R-devel. Since you're
> compiling a released version of R and we don't have an R-SIG-Slackware
> mailing list, R-help sounds like the right place.

Ivan,

Okay:

> What are the last lines of the build log, containing the error message? If
> it's a LaTeX error, it may be that you need some extra TeX Live packages,
> there is a list in R-admin:
> https://cran.r-project.org/doc/manuals/R-admin.html#Making-the-manuals

* DONE (mgcv)
make[2]: Leaving directory '/tmp/SBo/R-4.3.3/src/library/Recommended'
make[1]: Leaving directory '/tmp/SBo/R-4.3.3/src/library/Recommended'
make[1]: Entering directory '/tmp/SBo/R-4.3.3/src/library'
building/updating vignettes for package 'grid' ...
building/updating vignettes for package 'parallel' ...
building/updating vignettes for package 'utils' ...
building/updating vignettes for package 'stats' ...
processing 'reshape.Rnw'
Error: compiling TeX file 'reshape.tex' failed with message:
Running 'texi2dvi' on 'reshape.tex' failed.
Messages:
/usr/bin/texi2dvi: TeX neither supports -recorder nor outputs \openout lines in its log file
Execution halted
make[1]: *** [Makefile:103: vignettes] Error 1
make[1]: Leaving directory '/tmp/SBo/R-4.3.3/src/library'
make: *** [Makefile:81: vignettes] Error 2
# (running time: 12m3.057s)

I don't know why /usr/bin/texi2dvi doesn't support -recorder nor the other
error. TeXLive2023 had no issues building R-4.1.1.

Thanks,

Rich


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Mon Apr  8 21:14:52 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Mon, 8 Apr 2024 20:14:52 +0100
Subject: [R] Exceptional slowness with read.csv
In-Reply-To: <20240408214233.7f70549f@Tarkus>
References: <2a1f4ec9-26ae-4e80-bd40-10c4a919849f@swcp.com>
 <20240408214233.7f70549f@Tarkus>
Message-ID: <01f08462-b4a7-4b76-b7b9-f65641073d49@sapo.pt>

?s 19:42 de 08/04/2024, Ivan Krylov via R-help escreveu:
> ? Sun, 7 Apr 2024 23:47:52 -0600
> Dave Dixon <ddixon at swcp.com> ?????:
> 
>>   > second_records <- read.csv(file_name, skip = 2459465, nrows = 5)
> 
> It may or may not be important that read.csv defaults to header =
> TRUE. Having skipped 2459465 lines, it may attempt to parse the next
> one as a header, so the second call read.csv() should probably include
> header = FALSE.


This will throw an error, call read.table with sep="," instead.


> 
> Bert's advice to try scan() is on point, though. It's likely that the
> default-enabled header is not the most serious problem here.
> 

Hoep this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From |kry|ov @end|ng |rom d|@root@org  Mon Apr  8 21:27:32 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Mon, 8 Apr 2024 22:27:32 +0300
Subject: [R] Building R-4,3,3 fails
In-Reply-To: <7a7ddee-5da4-a48-f5c-328436577d6@appl-ecosys.com>
References: <2d4e6da0-bc51-4cab-8b84-f7631744b17@appl-ecosys.com>
 <20240408213859.78c94c34@Tarkus>
 <7a7ddee-5da4-a48-f5c-328436577d6@appl-ecosys.com>
Message-ID: <20240408222732.1a4b3be4@parabola>

? Mon, 8 Apr 2024 11:51:42 -0700 (PDT)
Rich Shepard <rshepard at appl-ecosys.com> ?????:

> processing 'reshape.Rnw'
> Error: compiling TeX file 'reshape.tex' failed with message:
> Running 'texi2dvi' on 'reshape.tex' failed.
> Messages:
> /usr/bin/texi2dvi: TeX neither supports -recorder nor outputs
> \openout lines in its log file
> Execution halted

A Web search suggests that texi2dvi may output this message by mistake
when the TeX installation is subject to a different problem:
https://web.archive.org/web/20191006123002/https://lists.gnu.org/r/bug-texinfo/2016-10/msg00036.html

Find the reshape.Rnw file and try running bin/R CMD Sweave
path/to/reshape.Rnw. It should produce reshape.tex. When you run
pdflatex reshape.tex, do you get a more useful error message?

-- 
Best regards,
Ivan


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Mon Apr  8 22:13:39 2024
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Mon, 8 Apr 2024 13:13:39 -0700 (PDT)
Subject: [R] Building R-4,3,3 fails
In-Reply-To: <20240408222732.1a4b3be4@parabola>
References: <2d4e6da0-bc51-4cab-8b84-f7631744b17@appl-ecosys.com>
 <20240408213859.78c94c34@Tarkus>
 <7a7ddee-5da4-a48-f5c-328436577d6@appl-ecosys.com>
 <20240408222732.1a4b3be4@parabola>
Message-ID: <9d3127ec-f236-adf-765d-96d65a2b60ec@appl-ecosys.com>

On Mon, 8 Apr 2024, Ivan Krylov wrote:

> A Web search suggests that texi2dvi may output this message by mistake
> when the TeX installation is subject to a different problem:
> https://web.archive.org/web/20191006123002/https://lists.gnu.org/r/bug-texinfo/2016-10/msg00036.html

Ivan,

That thread is 8 years old and may no longer apply to TeXLive2024.

> Find the reshape.Rnw file and try running bin/R CMD Sweave
> path/to/reshape.Rnw. It should produce reshape.tex. When you run pdflatex
> reshape.tex, do you get a more useful error message?

The error occurs when building R. Since R's not installed I cannot run it to
build reshape.tex.

Thanks,

Rich


From dd|xon @end|ng |rom @wcp@com  Mon Apr  8 22:21:49 2024
From: dd|xon @end|ng |rom @wcp@com (Dave Dixon)
Date: Mon, 8 Apr 2024 14:21:49 -0600
Subject: [R] Exceptional slowness with read.csv
In-Reply-To: <CAGCDhaVgEmWJXapLZJRU_1BegB-=1KyaT2wDNHNqKTs5VSrhvw@mail.gmail.com>
References: <2a1f4ec9-26ae-4e80-bd40-10c4a919849f@swcp.com>
 <CAGCDhaVgEmWJXapLZJRU_1BegB-=1KyaT2wDNHNqKTs5VSrhvw@mail.gmail.com>
Message-ID: <ed0e6ed0-6f15-4e76-8a4f-a946838f6e28@swcp.com>

I solved the mystery, but not the problem. The problem is that there's 
an unclosed quote somewhere in those 5 additional records I'm trying to 
access. So read.csv is reading million-character fields. It's slow at 
that. That mystery solved.

However, the the problem persists: how to fix what is obvious to the 
naked eye - a quote not adjacent to a comma - but that read.csv can't 
handle. readLines followed by read.csv(text= ) works great because, in 
that case, read.csv knows where the record terminates. Meaning, read.csv 
throws an exception that I can catch and handle with a quick and clean 
regex expression.

Thanks, I'll take a look at vroom.

-dave

On 4/8/24 09:18, Stevie Pederson wrote:
> Hi Dave,
>
> That's rather frustrating. I've found vroom (from the package vroom) 
> to be helpful with large files like this.
>
> Does the following give you any better luck?
>
> vroom(file_name, delim = ",", skip = 2459465, n_max = 5)
>
> Of course, when you know you've got errors & the files are big like 
> that it can take a bit of work resolving things. The command line 
> tools awk & sed might even be a good plan for finding lines that have 
> errors & figuring out a fix, but I certainly don't envy you.
>
> All the best
>
> Stevie
>
> On Tue, 9 Apr 2024 at 00:36, Dave Dixon <ddixon at swcp.com> wrote:
>
>     Greetings,
>
>     I have a csv file of 76 fields and about 4 million records. I know
>     that
>     some of the records have errors - unmatched quotes, specifically.
>     Reading the file with readLines and parsing the lines with
>     read.csv(text
>     = ...) is really slow. I know that the first 2459465 records are
>     good.
>     So I try this:
>
>     ?> startTime <- Sys.time()
>     ?> first_records <- read.csv(file_name, nrows = 2459465)
>     ?> endTime <- Sys.time()
>     ?> cat("elapsed time = ", endTime - startTime, "\n")
>
>     elapsed time = ? 24.12598
>
>     ?> startTime <- Sys.time()
>     ?> second_records <- read.csv(file_name, skip = 2459465, nrows = 5)
>     ?> endTime <- Sys.time()
>     ?> cat("elapsed time = ", endTime - startTime, "\n")
>
>     This appears to never finish. I have been waiting over 20 minutes.
>
>     So why would (skip = 2459465, nrows = 5) take orders of magnitude
>     longer
>     than (nrows = 2459465) ?
>
>     Thanks!
>
>     -dave
>
>     PS: readLines(n=2459470) takes 10.42731 seconds.
>
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
	[[alternative HTML version deleted]]


From dd|xon @end|ng |rom @wcp@com  Mon Apr  8 22:22:20 2024
From: dd|xon @end|ng |rom @wcp@com (Dave Dixon)
Date: Mon, 8 Apr 2024 14:22:20 -0600
Subject: [R] Exceptional slowness with read.csv
In-Reply-To: <CAGxFJbSPZTFqrrjht3pyKFz-QmX1DfOfd86tkMHxNBB2FLpXVA@mail.gmail.com>
References: <2a1f4ec9-26ae-4e80-bd40-10c4a919849f@swcp.com>
 <CAGxFJbSPZTFqrrjht3pyKFz-QmX1DfOfd86tkMHxNBB2FLpXVA@mail.gmail.com>
Message-ID: <44f9eb27-a12f-4b0f-8432-5c70470cce85@swcp.com>

Thanks, yeah, I think scan is more promising. I'll check it out.

On 4/8/24 11:49, Bert Gunter wrote:
> No idea, but have you tried using ?scan to read those next 5 rows? It 
> might give you a better idea of the pathologies that are causing 
> problems. For example, an unmatched quote might result in some huge 
> number of characters trying to be read into a single element of a 
> character variable. As your previous respondent said, resolving such 
> problems can be a challenge.
>
> Cheers,
> Bert
>
>
>
> On Mon, Apr 8, 2024 at 8:06?AM Dave Dixon <ddixon at swcp.com> wrote:
>
>     Greetings,
>
>     I have a csv file of 76 fields and about 4 million records. I know
>     that
>     some of the records have errors - unmatched quotes, specifically.
>     Reading the file with readLines and parsing the lines with
>     read.csv(text
>     = ...) is really slow. I know that the first 2459465 records are
>     good.
>     So I try this:
>
>     ?> startTime <- Sys.time()
>     ?> first_records <- read.csv(file_name, nrows = 2459465)
>     ?> endTime <- Sys.time()
>     ?> cat("elapsed time = ", endTime - startTime, "\n")
>
>     elapsed time = ? 24.12598
>
>     ?> startTime <- Sys.time()
>     ?> second_records <- read.csv(file_name, skip = 2459465, nrows = 5)
>     ?> endTime <- Sys.time()
>     ?> cat("elapsed time = ", endTime - startTime, "\n")
>
>     This appears to never finish. I have been waiting over 20 minutes.
>
>     So why would (skip = 2459465, nrows = 5) take orders of magnitude
>     longer
>     than (nrows = 2459465) ?
>
>     Thanks!
>
>     -dave
>
>     PS: readLines(n=2459470) takes 10.42731 seconds.
>
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
	[[alternative HTML version deleted]]


From dd|xon @end|ng |rom @wcp@com  Mon Apr  8 22:23:41 2024
From: dd|xon @end|ng |rom @wcp@com (Dave Dixon)
Date: Mon, 8 Apr 2024 14:23:41 -0600
Subject: [R] Exceptional slowness with read.csv
In-Reply-To: <CA+etgPnYTPkuwcFkOfdPZPXazgg6UMVnYcJjoHaWG=Ki2_AUiw@mail.gmail.com>
References: <2a1f4ec9-26ae-4e80-bd40-10c4a919849f@swcp.com>
 <CAGCDhaVgEmWJXapLZJRU_1BegB-=1KyaT2wDNHNqKTs5VSrhvw@mail.gmail.com>
 <CA+etgPnYTPkuwcFkOfdPZPXazgg6UMVnYcJjoHaWG=Ki2_AUiw@mail.gmail.com>
Message-ID: <418eeb84-db64-4694-96cd-5ab5c8947908@swcp.com>

Good suggestion - I'll look into data.table.

On 4/8/24 12:14, CALUM POLWART wrote:
> data.table's fread is also fast. Not sure about error handling. But I 
> can merge 300 csvs with a total of 0.5m lines and 50 columns in a 
> couple of minutes versus a lifetime with read.csv or readr::read_csv
>
>
>
> On Mon, 8 Apr 2024, 16:19 Stevie Pederson, 
> <stephen.pederson.au at gmail.com> wrote:
>
>     Hi Dave,
>
>     That's rather frustrating. I've found vroom (from the package
>     vroom) to be
>     helpful with large files like this.
>
>     Does the following give you any better luck?
>
>     vroom(file_name, delim = ",", skip = 2459465, n_max = 5)
>
>     Of course, when you know you've got errors & the files are big
>     like that it
>     can take a bit of work resolving things. The command line tools
>     awk & sed
>     might even be a good plan for finding lines that have errors &
>     figuring out
>     a fix, but I certainly don't envy you.
>
>     All the best
>
>     Stevie
>
>     On Tue, 9 Apr 2024 at 00:36, Dave Dixon <ddixon at swcp.com> wrote:
>
>     > Greetings,
>     >
>     > I have a csv file of 76 fields and about 4 million records. I
>     know that
>     > some of the records have errors - unmatched quotes, specifically.
>     > Reading the file with readLines and parsing the lines with
>     read.csv(text
>     > = ...) is really slow. I know that the first 2459465 records are
>     good.
>     > So I try this:
>     >
>     >? > startTime <- Sys.time()
>     >? > first_records <- read.csv(file_name, nrows = 2459465)
>     >? > endTime <- Sys.time()
>     >? > cat("elapsed time = ", endTime - startTime, "\n")
>     >
>     > elapsed time =? ?24.12598
>     >
>     >? > startTime <- Sys.time()
>     >? > second_records <- read.csv(file_name, skip = 2459465, nrows = 5)
>     >? > endTime <- Sys.time()
>     >? > cat("elapsed time = ", endTime - startTime, "\n")
>     >
>     > This appears to never finish. I have been waiting over 20 minutes.
>     >
>     > So why would (skip = 2459465, nrows = 5) take orders of
>     magnitude longer
>     > than (nrows = 2459465) ?
>     >
>     > Thanks!
>     >
>     > -dave
>     >
>     > PS: readLines(n=2459470) takes 10.42731 seconds.
>     >
>     > ______________________________________________
>     > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
>     > http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     > and provide commented, minimal, self-contained, reproducible code.
>     >
>
>     ? ? ? ? [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
	[[alternative HTML version deleted]]


From dd|xon @end|ng |rom @wcp@com  Mon Apr  8 22:25:07 2024
From: dd|xon @end|ng |rom @wcp@com (Dave Dixon)
Date: Mon, 8 Apr 2024 14:25:07 -0600
Subject: [R] Exceptional slowness with read.csv
In-Reply-To: <20240408214233.7f70549f@Tarkus>
References: <2a1f4ec9-26ae-4e80-bd40-10c4a919849f@swcp.com>
 <20240408214233.7f70549f@Tarkus>
Message-ID: <97f52a33-8071-48ba-bb7c-711168a8c892@swcp.com>

Right, I meant to add header=FALSE. And, it looks now like the next line 
is the one with the unclosed quote, so read.csv is trying to read 
million-character headers!

On 4/8/24 12:42, Ivan Krylov wrote:
> ? Sun, 7 Apr 2024 23:47:52 -0600
> Dave Dixon <ddixon at swcp.com> ?????:
>
>>   > second_records <- read.csv(file_name, skip = 2459465, nrows = 5)
> It may or may not be important that read.csv defaults to header =
> TRUE. Having skipped 2459465 lines, it may attempt to parse the next
> one as a header, so the second call read.csv() should probably include
> header = FALSE.
>
> Bert's advice to try scan() is on point, though. It's likely that the
> default-enabled header is not the most serious problem here.
>


From no@p@m @end|ng |rom ||@@e@NA  Tue Apr  9 01:17:22 2024
From: no@p@m @end|ng |rom ||@@e@NA (Eberhard W Lisse)
Date: Tue, 9 Apr 2024 01:17:22 +0200
Subject: [R] Exceptional slowness with read.csv
In-Reply-To: <ed0e6ed0-6f15-4e76-8a4f-a946838f6e28@swcp.com>
References: <2a1f4ec9-26ae-4e80-bd40-10c4a919849f@swcp.com>
 <CAGCDhaVgEmWJXapLZJRU_1BegB-=1KyaT2wDNHNqKTs5VSrhvw@mail.gmail.com>
 <ed0e6ed0-6f15-4e76-8a4f-a946838f6e28@swcp.com>
Message-ID: <uv1tu2$ns9$1@ciao.gmane.io>

I find QSV very helpful.

el

On 08/04/2024 22:21, Dave Dixon wrote:
> I solved the mystery, but not the problem. The problem is that
> there's an unclosed quote somewhere in those 5 additional records I'm
> trying to access. So read.csv is reading million-character fields.
> It's slow at that. That mystery solved.
> 
> However, the the problem persists: how to fix what is obvious to the
> naked eye - a quote not adjacent to a comma - but that read.csv
> can't handle. readLines followed by read.csv(text= ) works great
> because, in that case, read.csv knows where the record terminates.
> Meaning, read.csv throws an exception that I can catch and handle
> with a quick and clean regex expression.
> 
> Thanks, I'll take a look at vroom.
[...]


From jho|tm@n @end|ng |rom gm@||@com  Tue Apr  9 01:31:01 2024
From: jho|tm@n @end|ng |rom gm@||@com (jim holtman)
Date: Mon, 8 Apr 2024 18:31:01 -0500
Subject: [R] Exceptional slowness with read.csv
In-Reply-To: <ed0e6ed0-6f15-4e76-8a4f-a946838f6e28@swcp.com>
References: <2a1f4ec9-26ae-4e80-bd40-10c4a919849f@swcp.com>
 <CAGCDhaVgEmWJXapLZJRU_1BegB-=1KyaT2wDNHNqKTs5VSrhvw@mail.gmail.com>
 <ed0e6ed0-6f15-4e76-8a4f-a946838f6e28@swcp.com>
Message-ID: <CAAxdm-7TE7JQ_eTMiwwzXO0OdSkcmgfdw993=Ls+uj49yYqXUg@mail.gmail.com>

Try reading the lines in (readLines), count the number of both types of
quotes in each line. Find out which are not even and investigate.

On Mon, Apr 8, 2024, 15:24 Dave Dixon <ddixon at swcp.com> wrote:

> I solved the mystery, but not the problem. The problem is that there's
> an unclosed quote somewhere in those 5 additional records I'm trying to
> access. So read.csv is reading million-character fields. It's slow at
> that. That mystery solved.
>
> However, the the problem persists: how to fix what is obvious to the
> naked eye - a quote not adjacent to a comma - but that read.csv can't
> handle. readLines followed by read.csv(text= ) works great because, in
> that case, read.csv knows where the record terminates. Meaning, read.csv
> throws an exception that I can catch and handle with a quick and clean
> regex expression.
>
> Thanks, I'll take a look at vroom.
>
> -dave
>
> On 4/8/24 09:18, Stevie Pederson wrote:
> > Hi Dave,
> >
> > That's rather frustrating. I've found vroom (from the package vroom)
> > to be helpful with large files like this.
> >
> > Does the following give you any better luck?
> >
> > vroom(file_name, delim = ",", skip = 2459465, n_max = 5)
> >
> > Of course, when you know you've got errors & the files are big like
> > that it can take a bit of work resolving things. The command line
> > tools awk & sed might even be a good plan for finding lines that have
> > errors & figuring out a fix, but I certainly don't envy you.
> >
> > All the best
> >
> > Stevie
> >
> > On Tue, 9 Apr 2024 at 00:36, Dave Dixon <ddixon at swcp.com> wrote:
> >
> >     Greetings,
> >
> >     I have a csv file of 76 fields and about 4 million records. I know
> >     that
> >     some of the records have errors - unmatched quotes, specifically.
> >     Reading the file with readLines and parsing the lines with
> >     read.csv(text
> >     = ...) is really slow. I know that the first 2459465 records are
> >     good.
> >     So I try this:
> >
> >      > startTime <- Sys.time()
> >      > first_records <- read.csv(file_name, nrows = 2459465)
> >      > endTime <- Sys.time()
> >      > cat("elapsed time = ", endTime - startTime, "\n")
> >
> >     elapsed time =   24.12598
> >
> >      > startTime <- Sys.time()
> >      > second_records <- read.csv(file_name, skip = 2459465, nrows = 5)
> >      > endTime <- Sys.time()
> >      > cat("elapsed time = ", endTime - startTime, "\n")
> >
> >     This appears to never finish. I have been waiting over 20 minutes.
> >
> >     So why would (skip = 2459465, nrows = 5) take orders of magnitude
> >     longer
> >     than (nrows = 2459465) ?
> >
> >     Thanks!
> >
> >     -dave
> >
> >     PS: readLines(n=2459470) takes 10.42731 seconds.
> >
> >     ______________________________________________
> >     R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >     https://stat.ethz.ch/mailman/listinfo/r-help
> >     PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >     <http://www.R-project.org/posting-guide.html>
> >     and provide commented, minimal, self-contained, reproducible code.
> >
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Tue Apr  9 07:56:17 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Tue, 9 Apr 2024 08:56:17 +0300
Subject: [R] Building R-4,3,3 fails
In-Reply-To: <9d3127ec-f236-adf-765d-96d65a2b60ec@appl-ecosys.com>
References: <2d4e6da0-bc51-4cab-8b84-f7631744b17@appl-ecosys.com>
 <20240408213859.78c94c34@Tarkus>
 <7a7ddee-5da4-a48-f5c-328436577d6@appl-ecosys.com>
 <20240408222732.1a4b3be4@parabola>
 <9d3127ec-f236-adf-765d-96d65a2b60ec@appl-ecosys.com>
Message-ID: <20240409085617.2ae6bdb1@Tarkus>

? Mon, 8 Apr 2024 13:13:39 -0700 (PDT)
Rich Shepard <rshepard at appl-ecosys.com> ?????:

> That thread is 8 years old and may no longer apply to TeXLive2024.

True, but the /usr/bin/texi2dvi from GNU Texinfo 6.8 (2021) on my
Debian Bookworm system still contains this error message:

  case $TEXI2DVI_USE_RECORDER in
    yes) set_aux_files_from_fls;;

    no)	set_aux_files_from_log;;

    yesmaybe)
      if check_recorder_support; then
        set_aux_files_from_fls
      elif check_openout_in_log_support; then
        set_aux_files_from_log
      else
        error 1 "TeX neither supports -recorder nor outputs \\openout lines in its log file"
      fi

And even if the problem is somewhere else, the steps to debug it are
the same: use Sweave to obtain the *.tex file that fails to compile
using texi2pdf, then check what happens inside check_recorder_support
or check_openout_in_log_support to find out why. It's probably pdflatex
that fails, so we'll likely save some time by going straight for it.

> The error occurs when building R. Since R's not installed I cannot
> run it to build reshape.tex.

At this point in the build, R already exists, is quite operable and
even has all the recommended packages installed. The build system then
uses this freshly compiled R to run Sweave on the vignettes. Let me
break the build in a similar manner and see what happens:

sed -i.bak '8i\\\xlerb' src/library/stats/vignettes/reshape.Rnw
./configure
make
# Error: compiling TeX file 'reshape.tex' failed with message:
# Running 'texi2dvi' on 'reshape.tex' failed.
# LaTeX errors:
# ! Undefined control sequence.
# l.8 \xlerb
<...>
# Execution halted
# make[1]: *** [Makefile:103: vignettes] Error 1
bin/R CMD Sweave src/library/stats/vignettes/reshape.Rnw 
# Output file:  reshape.tex
pdflatex reshape.tex
# This is pdfTeX, Version 3.141592653-2.6-1.40.24 (TeX Live 2022/Debian)
# (preloaded format=pdflatex)
<...>
# ! Undefined control sequence.
# l.8 \xlerb
#           
# ?

If pdflatex reshape.tex does succeed on your system, try texi2pdf -V
reshape.rex. If that doesn't fail either, we'll have to read the
makefiles and reconstruct the exact command used by the build system.

-- 
Best regards,
Ivan


From ger@ophii m@iii@g oii gmx@@et  Tue Apr  9 09:47:36 2024
From: ger@ophii m@iii@g oii gmx@@et (ger@ophii m@iii@g oii gmx@@et)
Date: Tue, 9 Apr 2024 09:47:36 +0200
Subject: [R] How to set the correct libomp for R
Message-ID: <trinity-209a2008-97b9-4c14-a46c-89d317ec58d7-1712648856444@3c-app-gmx-bs03>


Sorry fort he late reply, your mail ended up in my spam and I've just seen it recently.

> Does the behaviour change if you temporarily move away
> /usr/local/lib/libomp.dylib?

It does not change the behavior after loading (or attaching) data.table using "library(data.table)". It is still loaded with multiple threads:
"data.table 1.15.4 using 4 threads (see ?getDTthreads). Latest news: r-datatable.com"

It does however make it impossible to install data.table from source with these flags (set in ~/.R/Makevars; I also temporarily removed the omp files from /usr/local/include that are bundled in the tarball)
"""
CPPFLAGS += -Xclang -fopenmp
LDFLAGS += -lomp
"""

This is the error that happens then:
"""
...
In file included from ./data.table.h:1:
./myomp.h:2:12: fatal error: 'omp.h' file not found
#include <omp.h>
^~~~~~~
1 error generated.
make: *** [assign.o] Error 1
ERROR: compilation failed for package ?data.table?
* removing ?/Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library/data.table?
* restoring previous ?/Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library/data.table?
Warning in install.packages :
installation of package ?data.table? had non-zero exit status
"""
So, the libomp.dylib does indeed seem to be necessary for installing from source with OpenMP support, but not for executing the code


> When you reproduce the crash, what does the backtrace say?

I haven't done that yet, since I was on the non-OpenMP version right now. I'll come back to you once I tried.

Thanks,
Philipp



?Am 08.04.24, 11:13 schrieb "Ivan Krylov" <ikrylov at disroot.org <mailto:ikrylov at disroot.org>>:


? Mon, 8 Apr 2024 10:29:53 +0200
gernophil--- via R-help <r-help at r-project.org <mailto:r-help at r-project.org>> ?????:


> I have some weird issue with using multithreaded data.table in macOS
> and I am trying to figure out, if it?s connected to my libomp.dylib.
> I started using libomp as stated here:
> https://mac.r-project.org/openmp/ <https://mac.r-project.org/openmp/[https://mac.r-project.org/openmp/]>


Does the behaviour change if you temporarily move away
/usr/local/lib/libomp.dylib?


> P.S.: If you need some more details about the actual issue with
> data.table you can also check here
> (https://github.com/rstudio/rstudio/issues/14517[https://github.com/rstudio/rstudio/issues/14517] <https://github.com/rstudio/rstudio/issues/14517[https://github.com/rstudio/rstudio/issues/14517]>) and here
> (https://github.com/Rdatatable/data.table/issues/5957[https://github.com/Rdatatable/data.table/issues/5957] <https://github.com/Rdatatable/data.table/issues/5957[https://github.com/Rdatatable/data.table/issues/5957]>)


The debugger may be able to shed more light on the problem than just
"yes, this is due to OpenMP":
https://github.com/rstudio/rstudio/issues/14517#issuecomment-2040231196[https://github.com/rstudio/rstudio/issues/14517#issuecomment-2040231196] <https://github.com/rstudio/rstudio/issues/14517#issuecomment-2040231196[https://github.com/rstudio/rstudio/issues/14517#issuecomment-2040231196]>


When you reproduce the crash, what does the backtrace say?


--
Best regards,
Ivan


?


From ger@ophii m@iii@g oii gmx@@et  Tue Apr  9 09:55:06 2024
From: ger@ophii m@iii@g oii gmx@@et (ger@ophii m@iii@g oii gmx@@et)
Date: Tue, 9 Apr 2024 09:55:06 +0200
Subject: [R] How to set the correct libomp for R
In-Reply-To: <trinity-209a2008-97b9-4c14-a46c-89d317ec58d7-1712648856444@3c-app-gmx-bs03>
References: <trinity-209a2008-97b9-4c14-a46c-89d317ec58d7-1712648856444@3c-app-gmx-bs03>
Message-ID: <trinity-dcf5da2d-0931-462e-9f46-bd63b3b05b04-1712649306412@3c-app-gmx-bs03>

Sorry, if have to correct this. If I only move away /usr/local/lib/libomp.dylib, I can still install it. So it seems that also here the internal libomp.dylib from R is used. Just the bundled omp files at /usr/local/include (omp-tools.h, omp.h, ompt.h)?seem to be used. So maybe this is caused by a mismatch of these file and the used libomp.dylib?
?
?

Gesendet:?Dienstag, 09. April 2024 um 09:47 Uhr
Von:?gernophil at gmx.net
An:?"Ivan Krylov" <ikrylov at disroot.org>, "gernophil--- via R-help" <r-help at r-project.org>
Cc:?gernophil at gmx.net
Betreff:?Re: [R] How to set the correct libomp for R
Sorry fort he late reply, your mail ended up in my spam and I've just seen it recently.

> Does the behaviour change if you temporarily move away
> /usr/local/lib/libomp.dylib?

It does not change the behavior after loading (or attaching) data.table using "library(data.table)". It is still loaded with multiple threads:
"data.table 1.15.4 using 4 threads (see ?getDTthreads). Latest news: r-datatable.com"

It does however make it impossible to install data.table from source with these flags (set in ~/.R/Makevars; I also temporarily removed the omp files from /usr/local/include that are bundled in the tarball)
"""
CPPFLAGS += -Xclang -fopenmp
LDFLAGS += -lomp
"""

This is the error that happens then:
"""
...
In file included from ./data.table.h:1:
./myomp.h:2:12: fatal error: 'omp.h' file not found
#include <omp.h>
^~~~~~~
1 error generated.
make: *** [assign.o] Error 1
ERROR: compilation failed for package ?data.table?
* removing ?/Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library/data.table?
* restoring previous ?/Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/library/data.table?
Warning in install.packages :
installation of package ?data.table? had non-zero exit status
"""
So, the libomp.dylib does indeed seem to be necessary for installing from source with OpenMP support, but not for executing the code


> When you reproduce the crash, what does the backtrace say?

I haven't done that yet, since I was on the non-OpenMP version right now. I'll come back to you once I tried.

Thanks,
Philipp



?Am 08.04.24, 11:13 schrieb "Ivan Krylov" <ikrylov at disroot.org <mailto:ikrylov at disroot.org>>:


? Mon, 8 Apr 2024 10:29:53 +0200
gernophil--- via R-help <r-help at r-project.org <mailto:r-help at r-project.org>> ?????:


> I have some weird issue with using multithreaded data.table in macOS
> and I am trying to figure out, if it?s connected to my libomp.dylib.
> I started using libomp as stated here:
> https://mac.r-project.org/openmp/ <https://mac.r-project.org/openmp/[https://mac.r-project.org/openmp/][https://mac.r-project.org/openmp/[https://mac.r-project.org/openmp/]]>


Does the behaviour change if you temporarily move away
/usr/local/lib/libomp.dylib?


> P.S.: If you need some more details about the actual issue with
> data.table you can also check here
> (https://github.com/rstudio/rstudio/issues/14517[https://github.com/rstudio/rstudio/issues/14517][https://github.com/rstudio/rstudio/issues/14517[https://github.com/rstudio/rstudio/issues/14517]] <https://github.com/rstudio/rstudio/issues/14517[https://github.com/rstudio/rstudio/issues/14517][https://github.com/rstudio/rstudio/issues/14517[https://github.com/rstudio/rstudio/issues/14517]]>) and here
> (https://github.com/Rdatatable/data.table/issues/5957[https://github.com/Rdatatable/data.table/issues/5957][https://github.com/Rdatatable/data.table/issues/5957[https://github.com/Rdatatable/data.table/issues/5957]] <https://github.com/Rdatatable/data.table/issues/5957[https://github.com/Rdatatable/data.table/issues/5957][https://github.com/Rdatatable/data.table/issues/5957[https://github.com/Rdatatable/data.table/issues/5957]]>)


The debugger may be able to shed more light on the problem than just
"yes, this is due to OpenMP":
https://github.com/rstudio/rstudio/issues/14517#issuecomment-2040231196[https://github.com/rstudio/rstudio/issues/14517#issuecomment-2040231196][https://github.com/rstudio/rstudio/issues/14517#issuecomment-2040231196[https://github.com/rstudio/rstudio/issues/14517#issuecomment-2040231196]] <https://github.com/rstudio/rstudio/issues/14517#issuecomment-2040231196[https://github.com/rstudio/rstudio/issues/14517#issuecomment-2040231196][https://github.com/rstudio/rstudio/issues/14517#issuecomment-2040231196[https://github.com/rstudio/rstudio/issues/14517#issuecomment-2040231196]]>


When you reproduce the crash, what does the backtrace say?


--
Best regards,
Ivan


?


From @zz@||n| @end|ng |rom @t@t@un|pd@|t  Tue Apr  9 12:04:26 2024
From: @zz@||n| @end|ng |rom @t@t@un|pd@|t (Adelchi Azzalini)
Date: Tue, 9 Apr 2024 12:04:26 +0200
Subject: [R] CEoptim problems
Message-ID: <ADB924D2-5C1C-478B-9B95-E4FFCB23C179@stat.unipd.it>

In the attempt to explore the usage of package CEoptim, I have run the code listed at the end of this message. This code is nothing but the one associated to example 5.7 in the main reference of the package, available at https://www.jstatsoft.org/article/view/v076i08
and is included in the associated file  v76i08.R

Unfortunately, the call to CEoptim stops with error message 

Error in is.null(A) || is.na(A) : 
  'length = 18' in coercion to 'logical(1)?

On 2024?04-03, I have written about this problem to 
Maintainer: Benoit Liquet <b.liquet at uq.edu.au>
but so far no reply has reached me. 

Could anyone help?

Best regards,

Adelchi Azzalini
http://azzalini.stat.unipd.it

////////////////////////////////////////////////////////////////////////

library(CEoptim)
## 5.7 AR(1) Model with Regime Switching
set.seed(123)

sumsqrs <- function(theta, rm1, x) {
  N <- length(x)  #without x[0]
  r <- 1 + sort(rm1)  # internal end points of regimes
  if (r[1] == r[2]) {
    # test for dupes -> invalid regime
    return(Inf)
  }
     thetas <- rep(theta, times = c(r, N) - c(1, r + 1) + 1)
  xhat <- c(0, head(x, -1)) * thetas
  ## Compute sum of squared errors
  sum((x - xhat)^2)
}

## Read the data from CEoptim package
data("yt", package = "CEoptim")
xt <- yt - c(0, yt[-300])
A <- rbind(diag(3), -diag(3))
b <- rep(1, 6)

res <- CEoptim(sumsqrs, f.arg = list(xt), continuous = list(mean = c(0, 0, 0), sd = rep(1,    3), conMat = A, conVec = b), discrete = list(categories = c(298L, 298L), smoothProb = 0.5),    N = 10000, rho = 0.001)

Error in is.null(A) || is.na(A) : 
  'length = 18' in coercion to 'logical(1)'

R> sessionInfo()
R version 4.3.3 (2024-02-29)
Platform: aarch64-apple-darwin20 (64-bit)
Running under: macOS Ventura 13.0

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib 
LAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

time zone: Europe/Rome
tzcode source: internal

attached base packages:
[1] stats     utils     datasets  grDevices graphics  methods   base     

other attached packages:
[1] CEoptim_1.3          sna_2.7-2            network_1.18.2       statnet.common_4.9.0
[5] msm_1.7.1            MASS_7.3-60.0.1     

loaded via a namespace (and not attached):
 [1] vctrs_0.6.2        cli_3.6.1          rlang_1.1.1        generics_0.1.3    
 [5] jsonlite_1.8.4     glue_1.6.2         colorspace_2.1-0   scales_1.2.1      
 [9] fansi_1.0.4        dlstats_0.1.7      grid_4.3.3         expm_0.999-9      
[13] munsell_0.5.0      tibble_3.2.1       mvtnorm_1.1-3      lifecycle_1.0.3   
[17] compiler_4.3.3     dplyr_1.1.2        coda_0.19-4.1      RColorBrewer_1.1-3
[21] pkgconfig_2.0.3    lattice_0.22-5     R6_2.5.1           tidyselect_1.2.0  
[25] utf8_1.2.3         splines_4.3.3      pillar_1.9.0       magrittr_2.0.3    
[29] Matrix_1.6-5       tools_4.3.3        gtable_0.3.3       survival_3.5-8    
[33] ggplot2_3.4.2     
R> 


From |kry|ov @end|ng |rom d|@root@org  Tue Apr  9 12:22:04 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Tue, 9 Apr 2024 13:22:04 +0300
Subject: [R] CEoptim problems
In-Reply-To: <ADB924D2-5C1C-478B-9B95-E4FFCB23C179@stat.unipd.it>
References: <ADB924D2-5C1C-478B-9B95-E4FFCB23C179@stat.unipd.it>
Message-ID: <20240409132204.5b64f713@arachnoid>

? Tue, 9 Apr 2024 12:04:26 +0200
Adelchi Azzalini <azzalini at stat.unipd.it> ?????:

> res <- CEoptim(sumsqrs, f.arg = list(xt), continuous = list(mean =
> c(0, 0, 0), sd = rep(1,    3), conMat = A, conVec = b), discrete =
> list(categories = c(298L, 298L), smoothProb = 0.5),    N = 10000, rho
> = 0.001)
> 
> Error in is.null(A) || is.na(A) : 
>   'length = 18' in coercion to 'logical(1)'

There is a book titled "The R Inferno" with lots of debugging tips for
R: https://www.burns-stat.com/documents/books/the-r-inferno/

Start with a traceback(). Which function gave a matrix to the ||
operator (which accepts only logical scalars)?

If traceback is not enough, use options(error = recover). Once the
error happens, you will be able to inspect local variables inside any
of the active call frames, which may help understand where did A come
from and why it was given to the || operator.

Good luck!

-- 
Best regards,
Ivan


From |kry|ov @end|ng |rom d|@root@org  Tue Apr  9 12:50:26 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Tue, 9 Apr 2024 13:50:26 +0300
Subject: [R] How to set the correct libomp for R
In-Reply-To: <trinity-dcf5da2d-0931-462e-9f46-bd63b3b05b04-1712649306412@3c-app-gmx-bs03>
References: <trinity-209a2008-97b9-4c14-a46c-89d317ec58d7-1712648856444@3c-app-gmx-bs03>
 <trinity-dcf5da2d-0931-462e-9f46-bd63b3b05b04-1712649306412@3c-app-gmx-bs03>
Message-ID: <20240409135026.6ed7bb0e@arachnoid>

? Tue, 9 Apr 2024 09:55:06 +0200
gernophil at gmx.net ?????:

> If I only move away /usr/local/lib/libomp.dylib, I can still install
> it. So it seems that also here the internal libomp.dylib from R is
> used. Just the bundled omp files at /usr/local/include (omp-tools.h,
> omp.h, ompt.h)?seem to be used. So maybe this is caused by a mismatch
> of these file and the used libomp.dylib?

This is valuable information, thank you. This is evidence in favour of
libomp.dylib mismatch causing the problem. I hope that the backtrace
will help shine more light on the problem.

I'm out of ideas for now, but if I get any, I'll send another message.
If you don't get an answer here, try R-SIG-Mac at r-project.org.

-- 
Best regards,
Ivan


From pd@|gd @end|ng |rom gm@||@com  Tue Apr  9 14:54:46 2024
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Tue, 9 Apr 2024 14:54:46 +0200
Subject: [R] CEoptim problems
In-Reply-To: <ADB924D2-5C1C-478B-9B95-E4FFCB23C179@stat.unipd.it>
References: <ADB924D2-5C1C-478B-9B95-E4FFCB23C179@stat.unipd.it>
Message-ID: <0A9C199F-C68F-4B40-B035-EC7ECCC93829@gmail.com>

Hi, Adelchi,

Depends on what you want help with... 

The proximate cause would seem to be that the code ought to have "is.null(A) || any(is.NA(A))", which I presume you could fairly easily fix for yourself in the package sources or even locally in an R session. Vector-valued logicals in flow control constructions have gone through an elborate deprecation process before getting turned into errors.

If the problem is how to activate a dormant maintainer and fix the issue for everyone, I don't really have a clue,  but you might consider cantacting the CRAN team.

Best,
Peter D.

> On 9 Apr 2024, at 12:04 , Adelchi Azzalini <azzalini at stat.unipd.it> wrote:
> 
> In the attempt to explore the usage of package CEoptim, I have run the code listed at the end of this message. This code is nothing but the one associated to example 5.7 in the main reference of the package, available at https://www.jstatsoft.org/article/view/v076i08
> and is included in the associated file  v76i08.R
> 
> Unfortunately, the call to CEoptim stops with error message 
> 
> Error in is.null(A) || is.na(A) : 
>  'length = 18' in coercion to 'logical(1)?
> 
> On 2024?04-03, I have written about this problem to 
> Maintainer: Benoit Liquet <b.liquet at uq.edu.au>
> but so far no reply has reached me. 
> 
> Could anyone help?
> 
> Best regards,
> 
> Adelchi Azzalini
> http://azzalini.stat.unipd.it
> 
> ////////////////////////////////////////////////////////////////////////
> 
> library(CEoptim)
> ## 5.7 AR(1) Model with Regime Switching
> set.seed(123)
> 
> sumsqrs <- function(theta, rm1, x) {
>  N <- length(x)  #without x[0]
>  r <- 1 + sort(rm1)  # internal end points of regimes
>  if (r[1] == r[2]) {
>    # test for dupes -> invalid regime
>    return(Inf)
>  }
>     thetas <- rep(theta, times = c(r, N) - c(1, r + 1) + 1)
>  xhat <- c(0, head(x, -1)) * thetas
>  ## Compute sum of squared errors
>  sum((x - xhat)^2)
> }
> 
> ## Read the data from CEoptim package
> data("yt", package = "CEoptim")
> xt <- yt - c(0, yt[-300])
> A <- rbind(diag(3), -diag(3))
> b <- rep(1, 6)
> 
> res <- CEoptim(sumsqrs, f.arg = list(xt), continuous = list(mean = c(0, 0, 0), sd = rep(1,    3), conMat = A, conVec = b), discrete = list(categories = c(298L, 298L), smoothProb = 0.5),    N = 10000, rho = 0.001)
> 
> Error in is.null(A) || is.na(A) : 
>  'length = 18' in coercion to 'logical(1)'
> 
> R> sessionInfo()
> R version 4.3.3 (2024-02-29)
> Platform: aarch64-apple-darwin20 (64-bit)
> Running under: macOS Ventura 13.0
> 
> Matrix products: default
> BLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib 
> LAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> time zone: Europe/Rome
> tzcode source: internal
> 
> attached base packages:
> [1] stats     utils     datasets  grDevices graphics  methods   base     
> 
> other attached packages:
> [1] CEoptim_1.3          sna_2.7-2            network_1.18.2       statnet.common_4.9.0
> [5] msm_1.7.1            MASS_7.3-60.0.1     
> 
> loaded via a namespace (and not attached):
> [1] vctrs_0.6.2        cli_3.6.1          rlang_1.1.1        generics_0.1.3    
> [5] jsonlite_1.8.4     glue_1.6.2         colorspace_2.1-0   scales_1.2.1      
> [9] fansi_1.0.4        dlstats_0.1.7      grid_4.3.3         expm_0.999-9      
> [13] munsell_0.5.0      tibble_3.2.1       mvtnorm_1.1-3      lifecycle_1.0.3   
> [17] compiler_4.3.3     dplyr_1.1.2        coda_0.19-4.1      RColorBrewer_1.1-3
> [21] pkgconfig_2.0.3    lattice_0.22-5     R6_2.5.1           tidyselect_1.2.0  
> [25] utf8_1.2.3         splines_4.3.3      pillar_1.9.0       magrittr_2.0.3    
> [29] Matrix_1.6-5       tools_4.3.3        gtable_0.3.3       survival_3.5-8    
> [33] ggplot2_3.4.2     
> R> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pd@|gd @end|ng |rom gm@||@com  Tue Apr  9 16:01:50 2024
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Tue, 9 Apr 2024 16:01:50 +0200
Subject: [R] Question regarding reservoir volume and water level
In-Reply-To: <CANTxAmJzd2n8C0a=LhJzDU6K8GFr7p6q9hXP=zcthQqvitusvw@mail.gmail.com>
References: <CANTxAmJrvE5tHoyU1dgs0epeKrMv4tqg-R9K53CPA_TcR8sOvQ@mail.gmail.com>
 <9155638a-7a32-4b20-bc1b-e171d72a053c@sapo.pt>
 <DM6PR03MB5049C4C70B571CD3DD9B25F2E2012@DM6PR03MB5049.namprd03.prod.outlook.com>
 <009101da892d$93a3cc50$baeb64f0$@gmail.com>
 <CANTxAmJzd2n8C0a=LhJzDU6K8GFr7p6q9hXP=zcthQqvitusvw@mail.gmail.com>
Message-ID: <D6742E57-4A8A-46DD-9F22-A85F2503A9E0@gmail.com>

So, you know how to get volume for given water level. 

For the reverse problem, you get in trouble because of the nonlinearity inherent in the dependence of surface area on the level. 

I don't think there is a simple solution to this, save for mapping out the volume as a function of water level and solving equations for the water level using (say) uniroot(). Which may actually suffice for practical purposes.

For small changes, finding the derivative of the relation is easy: d(volume) = Area * d(level) and this can be used as an approximate relation as long as the Area remains nearly constant. 

However generic questions like doubling the volume are impossible to answer without knowledge of the reservoir shape. E.g. in a cylindrical reservoir halving the water level also halves the volume, but in a conical reservoir, halving the level leaves only 1/8 of the volume.

-pd



> On 8 Apr 2024, at 05:55 , javad bayat <j.bayat194 at gmail.com> wrote:
> 
> Dear all;
> Many thanks for your replies. This was not homework. I apologize.
> Let me explain more.
> There is a dam constructed in a valley with the highest elevation of 1255
> m. The area of its reservoir can be calculated by drawing a polygon around
> the water and it is known.
> I have the Digital Elevation Model (DEM) of the region (reservoir and its
> surrounding area). I have calculated the volume of the current reservoir
> (7e6 m3) using the following codes.
> library(raster)
> library(terra)
> library(exactextractr)
> library(dplyr)
> library(sf)
> # Calculate volume for polygon
> # Read the DEM raster file
> r <- rast("E:/...DEM.tif")
> # Read the polygon shapefile
> p <- st_read("E:/...Dam.shp")
> 
> r <- crop(r, extent(p))
> r <- mask(r, p)
> 
> # Extract the cells in each polygon and calculate the area of each cell
> x <- exact_extract(r, p, coverage_area = TRUE)
> # Extract polygon values as a dataframe
> x1 = as.data.frame(x[1])
> head(x1)
> x1 = na.omit(x1)
> # Calculate the height above the minimum elevation in the polygon
> x1$Height = max(x1[,1]) - x1[,1]
> # Calculate the volume of each cell
> x1$Vol = x1[,2] * x1[,3]
> sum(x1$Vol)
> x2 = x1[,c(1,2,4)]
> x2 = sort(x2,'value')
> head(x2)
> x3 <- aggregate(Vol ~ value, data = x2, FUN = sum)
> x4 <- aggregate(coverage_area ~ value, data = x2, FUN = sum)
> x5 = cbind(x3, Area = x4[,2])
> library(dplyr)
> x6 <- x5 %>%
>  mutate(V_sum = cumsum(Vol)) %>%
>  mutate(A_sum = cumsum(Area))
> plot(x6$value~x6$V_sum)
> 
> And I thought that it is possible to get the elevation for a specific
> volume by linear model between elevation and volume, as follow:
> 
> # Get a linear model between elevation and the volume
> lm1 <- lm(value ~ V_sum, data = x6)
> d <- data.frame(V_sum = 14e6)  #
> predict(lm1, newdata = d)
> 
> But it is not possible through the LM.
> Now I want to know what would be the water level in the reservoir if the
> reservoir volume doubled or we adding a known volume to it?
> Also what would be the volume if the water level increases to 1250 m?
> 
> I would be more than happy if you help me to do this.
> Sincerely
> 
> On Mon, Apr 8, 2024 at 12:23?AM <avi.e.gross at gmail.com> wrote:
> 
>> John,
>> 
>> Your reaction was what my original reaction was until I realized I had to
>> find out what a DEM file was and that contains enough of the kind of
>> depth-dimension data you describe albeit what may be a very irregular cross
>> section to calculate for areas and thence volumes.
>> 
>> If I read it correctly, this can be a very real-world problem worthy of a
>> solution, such as in places like California where they had a tad more rain
>> than usual and some reservoirs may overflow. Someone else provided what
>> sounds like a mathematical algorithm but my guess is what is needed here is
>> perhaps less analytic since there may be no trivial way to create formulas
>> and take integrals and so on, but simply an approximate way to calculate
>> incremental volumes for each horizontal "slice" and keep adding or
>> subtracting them till you reach a target and then read off another variable
>> at that point such as depth.
>> 
>> Some care must be taken as water level has to be relative to something and
>> many natural reservoirs have no unique bottom level. Some water may also be
>> stored underground and to the side and pour in if the level lowers or can
>> be
>> used to escape if the level rises.
>> 
>> 
>> -----Original Message-----
>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Sorkin, John
>> Sent: Sunday, April 7, 2024 3:08 PM
>> To: Rui Barradas <ruipbarradas at sapo.pt>; javad bayat <j.bayat194 at gmail.com
>>> ;
>> R-help <R-help at r-project.org>
>> Subject: Re: [R] Question regarding reservoir volume and water level
>> 
>> Aside from the fact that the original question might well be a class
>> exercise (or homework), the question is unanswerable given the data given
>> by
>> the original poster. One needs to know the dimensions of the reservoir,
>> above and below the current waterline. Are the sides, above and below the
>> waterline smooth? Is the region currently above the waterline that can
>> store
>> water a mirror image of the region below the waterline? Is the region above
>> the reservoir include a flood plane? Will the additional water go into the
>> flood plane?
>> 
>> The lack of required detail in the question posed by the original poster
>> suggests that there are strong assumptions, assumptions that typically
>> would
>> be made in a class-room example or exercise.
>> 
>> John
>> 
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine, University of Maryland School of Medicine;
>> Associate Director for Biostatistics and Informatics, Baltimore VA Medical
>> Center Geriatrics Research, Education, and Clinical Center;
>> PI Biostatistics and Informatics Core, University of Maryland School of
>> Medicine Claude D. Pepper Older Americans Independence Center;
>> Senior Statistician University of Maryland Center for Vascular Research;
>> 
>> Division of Gerontology and Paliative Care,
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> Cell phone 443-418-5382
>> 
>> 
>> 
>> 
>> ________________________________________
>> From: R-help <r-help-bounces at r-project.org> on behalf of Rui Barradas
>> <ruipbarradas at sapo.pt>
>> Sent: Sunday, April 7, 2024 10:53 AM
>> To: javad bayat; R-help
>> Subject: Re: [R] Question regarding reservoir volume and water level
>> 
>> ?s 13:27 de 07/04/2024, javad bayat escreveu:
>>> Dear all;
>>> I have a question about the water level of a reservoir, when the volume
>>> changed or doubled.
>>> There is a DEM file with the highest elevation 1267 m. The lowest
>> elevation
>>> is 1230 m. The current volume of the reservoir is 7,000,000 m3 at 1240 m.
>>> Now I want to know what would be the water level if the volume rises to
>>> 1250 m? or what would be the water level if the volume doubled
>> (14,000,000
>>> m3)?
>>> 
>>> Is there any way to write codes to do this in R?
>>> I would be more than happy if anyone could help me.
>>> Sincerely
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>> Hello,
>> 
>> This is a simple rule of three.
>> If you know the level l the argument doesn't need to be named but if you
>> know the volume v then it must be named.
>> 
>> 
>> water_level <- function(l, v, level = 1240, volume = 7e6) {
>>   if(missing(v)) {
>>     volume * l / level
>>   } else level * v / volume
>> }
>> 
>> lev <- 1250
>> vol <- 14e6
>> 
>> water_level(l = lev)
>> #> [1] 7056452
>> water_level(v = vol)
>> #> [1] 2480
>> 
>> 
>> Hope this helps,
>> 
>> Rui Barradas
>> 
>> 
>> --
>> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
>> presen?a de v?rus.
>> http://www.avg.com/
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.r-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
> 
> -- 
> Best Regards
> Javad Bayat
> M.Sc. Environment Engineering
> Alternative Mail: bayat194 at yahoo.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From @zz@||n| @end|ng |rom @t@t@un|pd@|t  Tue Apr  9 16:23:35 2024
From: @zz@||n| @end|ng |rom @t@t@un|pd@|t (Adelchi Azzalini)
Date: Tue, 9 Apr 2024 16:23:35 +0200
Subject: [R] CEoptim problems
In-Reply-To: <0A9C199F-C68F-4B40-B035-EC7ECCC93829@gmail.com>
References: <ADB924D2-5C1C-478B-9B95-E4FFCB23C179@stat.unipd.it>
 <0A9C199F-C68F-4B40-B035-EC7ECCC93829@gmail.com>
Message-ID: <F82FCD75-9872-4421-B26C-41047B80B3F0@stat.unipd.it>



> On 9 Apr 2024, at 14:54, peter dalgaard <pdalgd at gmail.com> wrote:
> 
> Hi, Adelchi,
> 
> Depends on what you want help with... 
> 
> The proximate cause would seem to be that the code ought to have "is.null(A) || any(is.NA(A))", which I presume you could fairly easily fix for yourself in the package sources or even locally in an R session. Vector-valued logicals in flow control constructions have gone through an elborate deprecation process before getting turned into errors.

Thanks, Peter. This has actually solved the problem.
I should have thought about this fix.

It surprises me that problems of this sort are not caught by the extensive automatic checks which a package goes through when is submitted to CRAN. Probably it happens because the only example within the CEoptim documentation is quite basic, while the more substantial examples are in the accompanying paper, but these are not checked by CRAN.

Best regards,

Adelchi

> 
> If the problem is how to activate a dormant maintainer and fix the issue for everyone, I don't really have a clue,  but you might consider cantacting the CRAN team.
> 
> Best,
> Peter D.
> 
>> On 9 Apr 2024, at 12:04 , Adelchi Azzalini <azzalini at stat.unipd.it> wrote:
>> 
>> In the attempt to explore the usage of package CEoptim, I have run the code listed at the end of this message. This code is nothing but the one associated to example 5.7 in the main reference of the package, available at https://www.jstatsoft.org/article/view/v076i08
>> and is included in the associated file  v76i08.R
>> 
>> Unfortunately, the call to CEoptim stops with error message 
>> 
>> Error in is.null(A) || is.na(A) : 
>> 'length = 18' in coercion to 'logical(1)?
>> 
>> On 2024?04-03, I have written about this problem to 
>> Maintainer: Benoit Liquet <b.liquet at uq.edu.au>
>> but so far no reply has reached me. 
>> 
>> Could anyone help?
>> 
>> Best regards,
>> 
>> Adelchi Azzalini
>> http://azzalini.stat.unipd.it
>> 
>> ////////////////////////////////////////////////////////////////////////
>> 
>> library(CEoptim)
>> ## 5.7 AR(1) Model with Regime Switching
>> set.seed(123)
>> 
>> sumsqrs <- function(theta, rm1, x) {
>> N <- length(x)  #without x[0]
>> r <- 1 + sort(rm1)  # internal end points of regimes
>> if (r[1] == r[2]) {
>>   # test for dupes -> invalid regime
>>   return(Inf)
>> }
>>    thetas <- rep(theta, times = c(r, N) - c(1, r + 1) + 1)
>> xhat <- c(0, head(x, -1)) * thetas
>> ## Compute sum of squared errors
>> sum((x - xhat)^2)
>> }
>> 
>> ## Read the data from CEoptim package
>> data("yt", package = "CEoptim")
>> xt <- yt - c(0, yt[-300])
>> A <- rbind(diag(3), -diag(3))
>> b <- rep(1, 6)
>> 
>> res <- CEoptim(sumsqrs, f.arg = list(xt), continuous = list(mean = c(0, 0, 0), sd = rep(1,    3), conMat = A, conVec = b), discrete = list(categories = c(298L, 298L), smoothProb = 0.5),    N = 10000, rho = 0.001)
>> 
>> Error in is.null(A) || is.na(A) : 
>> 'length = 18' in coercion to 'logical(1)'
>> 
>> R> sessionInfo()
>> R version 4.3.3 (2024-02-29)
>> Platform: aarch64-apple-darwin20 (64-bit)
>> Running under: macOS Ventura 13.0
>> 
>> Matrix products: default
>> BLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib 
>> LAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0
>> 
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>> 
>> time zone: Europe/Rome
>> tzcode source: internal
>> 
>> attached base packages:
>> [1] stats     utils     datasets  grDevices graphics  methods   base     
>> 
>> other attached packages:
>> [1] CEoptim_1.3          sna_2.7-2            network_1.18.2       statnet.common_4.9.0
>> [5] msm_1.7.1            MASS_7.3-60.0.1     
>> 
>> loaded via a namespace (and not attached):
>> [1] vctrs_0.6.2        cli_3.6.1          rlang_1.1.1        generics_0.1.3    
>> [5] jsonlite_1.8.4     glue_1.6.2         colorspace_2.1-0   scales_1.2.1      
>> [9] fansi_1.0.4        dlstats_0.1.7      grid_4.3.3         expm_0.999-9      
>> [13] munsell_0.5.0      tibble_3.2.1       mvtnorm_1.1-3      lifecycle_1.0.3   
>> [17] compiler_4.3.3     dplyr_1.1.2        coda_0.19-4.1      RColorBrewer_1.1-3
>> [21] pkgconfig_2.0.3    lattice_0.22-5     R6_2.5.1           tidyselect_1.2.0  
>> [25] utf8_1.2.3         splines_4.3.3      pillar_1.9.0       magrittr_2.0.3    
>> [29] Matrix_1.6-5       tools_4.3.3        gtable_0.3.3       survival_3.5-8    
>> [33] ggplot2_3.4.2     
>> R> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 


From @zz@||n| @end|ng |rom @t@t@un|pd@|t  Tue Apr  9 16:36:53 2024
From: @zz@||n| @end|ng |rom @t@t@un|pd@|t (Adelchi Azzalini)
Date: Tue, 9 Apr 2024 16:36:53 +0200
Subject: [R] CEoptim problems
In-Reply-To: <20240409132204.5b64f713@arachnoid>
References: <ADB924D2-5C1C-478B-9B95-E4FFCB23C179@stat.unipd.it>
 <20240409132204.5b64f713@arachnoid>
Message-ID: <F3E1427E-2588-4BC1-B596-7BAD06CB6309@stat.unipd.it>

Thanks for the suggestion, Ivan.

The issue has been overcome with a simple change of the code to the form

(is.null(A) || any(is.na(A))

following advice from Peter Dalgard.

However, I have kept a note of the R Inferno reference, for future problems.

Best wishes,

Adelchi


> On 9 Apr 2024, at 12:22, Ivan Krylov <ikrylov at disroot.org> wrote:
> 
> ? Tue, 9 Apr 2024 12:04:26 +0200
> Adelchi Azzalini <azzalini at stat.unipd.it> ?????:
> 
>> res <- CEoptim(sumsqrs, f.arg = list(xt), continuous = list(mean =
>> c(0, 0, 0), sd = rep(1,    3), conMat = A, conVec = b), discrete =
>> list(categories = c(298L, 298L), smoothProb = 0.5),    N = 10000, rho
>> = 0.001)
>> 
>> Error in is.null(A) || is.na(A) : 
>>  'length = 18' in coercion to 'logical(1)'
> 
> There is a book titled "The R Inferno" with lots of debugging tips for
> R: https://www.burns-stat.com/documents/books/the-r-inferno/
> 
> Start with a traceback(). Which function gave a matrix to the ||
> operator (which accepts only logical scalars)?
> 
> If traceback is not enough, use options(error = recover). Once the
> error happens, you will be able to inspect local variables inside any
> of the active call frames, which may help understand where did A come
> from and why it was given to the || operator.
> 
> Good luck!
> 
> -- 
> Best regards,
> Ivan


From d@v|d@@teven@ @end|ng |rom u@u@edu  Tue Apr  9 18:55:35 2024
From: d@v|d@@teven@ @end|ng |rom u@u@edu (David Stevens)
Date: Tue, 9 Apr 2024 16:55:35 +0000
Subject: [R] Question regarding reservoir volume and water level
In-Reply-To: <D6742E57-4A8A-46DD-9F22-A85F2503A9E0@gmail.com>
References: <CANTxAmJrvE5tHoyU1dgs0epeKrMv4tqg-R9K53CPA_TcR8sOvQ@mail.gmail.com>
 <9155638a-7a32-4b20-bc1b-e171d72a053c@sapo.pt>
 <DM6PR03MB5049C4C70B571CD3DD9B25F2E2012@DM6PR03MB5049.namprd03.prod.outlook.com>
 <009101da892d$93a3cc50$baeb64f0$@gmail.com>
 <CANTxAmJzd2n8C0a=LhJzDU6K8GFr7p6q9hXP=zcthQqvitusvw@mail.gmail.com>
 <D6742E57-4A8A-46DD-9F22-A85F2503A9E0@gmail.com>
Message-ID: <a979f03b-0273-4428-abd0-1d75d2048d88@usu.edu>

Water engineer here. The standard approach is to 1) get the storage vs. 
elevation data from the designers of the reservoir or, barring that, 2) 
get the bathymetry data from USBR or state DWR, or, if available, get 
the DEM data from USGS if the survey was done before the reservoir was 
built or 3) get a boat+sonar with GPS? +lots of time and survey the 
bottom elevation yourself. Put the xyz data into ArcGIS and have it 
create the bottom surface, then, with several elevations, integrate the 
xyz data from Z to the bottom to find the storage. Plot the storage at 
each water surface to get an idea of the shape and then use 
lm(Elevation~f(Storage) where f(Storage) may be a cubic or quartic 
polynomial. Then double the Storage and calculate Elevation. This type 
of thing is done everyday by hydrologists.

Good luck

David K Stevens, PhD, PE, Professor
Civil and Environmental Engineering
Utah Water Research Laboratory
Utah State University
8200 Old Main Hill
Logan, UT 84322-8200
david.stevens at usu.edu
(435) 797-3229 (office)

On 4/9/2024 8:01 AM, peter dalgaard wrote:
> So, you know how to get volume for given water level.
>
> For the reverse problem, you get in trouble because of the nonlinearity inherent in the dependence of surface area on the level.
>
> I don't think there is a simple solution to this, save for mapping out the volume as a function of water level and solving equations for the water level using (say) uniroot(). Which may actually suffice for practical purposes.
>
> For small changes, finding the derivative of the relation is easy: d(volume) = Area * d(level) and this can be used as an approximate relation as long as the Area remains nearly constant.
>
> However generic questions like doubling the volume are impossible to answer without knowledge of the reservoir shape. E.g. in a cylindrical reservoir halving the water level also halves the volume, but in a conical reservoir, halving the level leaves only 1/8 of the volume.
>
> -pd
>
>
>
>> On 8 Apr 2024, at 05:55 , javad bayat <j.bayat194 at gmail.com> wrote:
>>
>> Dear all;
>> Many thanks for your replies. This was not homework. I apologize.
>> Let me explain more.
>> There is a dam constructed in a valley with the highest elevation of 1255
>> m. The area of its reservoir can be calculated by drawing a polygon around
>> the water and it is known.
>> I have the Digital Elevation Model (DEM) of the region (reservoir and its
>> surrounding area). I have calculated the volume of the current reservoir
>> (7e6 m3) using the following codes.
>> library(raster)
>> library(terra)
>> library(exactextractr)
>> library(dplyr)
>> library(sf)
>> # Calculate volume for polygon
>> # Read the DEM raster file
>> r <- rast("E:/...DEM.tif")
>> # Read the polygon shapefile
>> p <- st_read("E:/...Dam.shp")
>>
>> r <- crop(r, extent(p))
>> r <- mask(r, p)
>>
>> # Extract the cells in each polygon and calculate the area of each cell
>> x <- exact_extract(r, p, coverage_area = TRUE)
>> # Extract polygon values as a dataframe
>> x1 = as.data.frame(x[1])
>> head(x1)
>> x1 = na.omit(x1)
>> # Calculate the height above the minimum elevation in the polygon
>> x1$Height = max(x1[,1]) - x1[,1]
>> # Calculate the volume of each cell
>> x1$Vol = x1[,2] * x1[,3]
>> sum(x1$Vol)
>> x2 = x1[,c(1,2,4)]
>> x2 = sort(x2,'value')
>> head(x2)
>> x3 <- aggregate(Vol ~ value, data = x2, FUN = sum)
>> x4 <- aggregate(coverage_area ~ value, data = x2, FUN = sum)
>> x5 = cbind(x3, Area = x4[,2])
>> library(dplyr)
>> x6 <- x5 %>%
>>   mutate(V_sum = cumsum(Vol)) %>%
>>   mutate(A_sum = cumsum(Area))
>> plot(x6$value~x6$V_sum)
>>
>> And I thought that it is possible to get the elevation for a specific
>> volume by linear model between elevation and volume, as follow:
>>
>> # Get a linear model between elevation and the volume
>> lm1 <- lm(value ~ V_sum, data = x6)
>> d <- data.frame(V_sum = 14e6)  #
>> predict(lm1, newdata = d)
>>
>> But it is not possible through the LM.
>> Now I want to know what would be the water level in the reservoir if the
>> reservoir volume doubled or we adding a known volume to it?
>> Also what would be the volume if the water level increases to 1250 m?
>>
>> I would be more than happy if you help me to do this.
>> Sincerely
>>
>> On Mon, Apr 8, 2024 at 12:23?AM <avi.e.gross at gmail.com> wrote:
>>
>>> John,
>>>
>>> Your reaction was what my original reaction was until I realized I had to
>>> find out what a DEM file was and that contains enough of the kind of
>>> depth-dimension data you describe albeit what may be a very irregular cross
>>> section to calculate for areas and thence volumes.
>>>
>>> If I read it correctly, this can be a very real-world problem worthy of a
>>> solution, such as in places like California where they had a tad more rain
>>> than usual and some reservoirs may overflow. Someone else provided what
>>> sounds like a mathematical algorithm but my guess is what is needed here is
>>> perhaps less analytic since there may be no trivial way to create formulas
>>> and take integrals and so on, but simply an approximate way to calculate
>>> incremental volumes for each horizontal "slice" and keep adding or
>>> subtracting them till you reach a target and then read off another variable
>>> at that point such as depth.
>>>
>>> Some care must be taken as water level has to be relative to something and
>>> many natural reservoirs have no unique bottom level. Some water may also be
>>> stored underground and to the side and pour in if the level lowers or can
>>> be
>>> used to escape if the level rises.
>>>
>>>
>>> -----Original Message-----
>>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Sorkin, John
>>> Sent: Sunday, April 7, 2024 3:08 PM
>>> To: Rui Barradas <ruipbarradas at sapo.pt>; javad bayat <j.bayat194 at gmail.com
>>>> ;
>>> R-help <R-help at r-project.org>
>>> Subject: Re: [R] Question regarding reservoir volume and water level
>>>
>>> Aside from the fact that the original question might well be a class
>>> exercise (or homework), the question is unanswerable given the data given
>>> by
>>> the original poster. One needs to know the dimensions of the reservoir,
>>> above and below the current waterline. Are the sides, above and below the
>>> waterline smooth? Is the region currently above the waterline that can
>>> store
>>> water a mirror image of the region below the waterline? Is the region above
>>> the reservoir include a flood plane? Will the additional water go into the
>>> flood plane?
>>>
>>> The lack of required detail in the question posed by the original poster
>>> suggests that there are strong assumptions, assumptions that typically
>>> would
>>> be made in a class-room example or exercise.
>>>
>>> John
>>>
>>> John David Sorkin M.D., Ph.D.
>>> Professor of Medicine, University of Maryland School of Medicine;
>>> Associate Director for Biostatistics and Informatics, Baltimore VA Medical
>>> Center Geriatrics Research, Education, and Clinical Center;
>>> PI Biostatistics and Informatics Core, University of Maryland School of
>>> Medicine Claude D. Pepper Older Americans Independence Center;
>>> Senior Statistician University of Maryland Center for Vascular Research;
>>>
>>> Division of Gerontology and Paliative Care,
>>> 10 North Greene Street
>>> GRECC (BT/18/GR)
>>> Baltimore, MD 21201-1524
>>> Cell phone 443-418-5382
>>>
>>>
>>>
>>>
>>> ________________________________________
>>> From: R-help <r-help-bounces at r-project.org> on behalf of Rui Barradas
>>> <ruipbarradas at sapo.pt>
>>> Sent: Sunday, April 7, 2024 10:53 AM
>>> To: javad bayat; R-help
>>> Subject: Re: [R] Question regarding reservoir volume and water level
>>>
>>> ?s 13:27 de 07/04/2024, javad bayat escreveu:
>>>> Dear all;
>>>> I have a question about the water level of a reservoir, when the volume
>>>> changed or doubled.
>>>> There is a DEM file with the highest elevation 1267 m. The lowest
>>> elevation
>>>> is 1230 m. The current volume of the reservoir is 7,000,000 m3 at 1240 m.
>>>> Now I want to know what would be the water level if the volume rises to
>>>> 1250 m? or what would be the water level if the volume doubled
>>> (14,000,000
>>>> m3)?
>>>>
>>>> Is there any way to write codes to do this in R?
>>>> I would be more than happy if anyone could help me.
>>>> Sincerely
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>> Hello,
>>>
>>> This is a simple rule of three.
>>> If you know the level l the argument doesn't need to be named but if you
>>> know the volume v then it must be named.
>>>
>>>
>>> water_level <- function(l, v, level = 1240, volume = 7e6) {
>>>    if(missing(v)) {
>>>      volume * l / level
>>>    } else level * v / volume
>>> }
>>>
>>> lev <- 1250
>>> vol <- 14e6
>>>
>>> water_level(l = lev)
>>> #> [1] 7056452
>>> water_level(v = vol)
>>> #> [1] 2480
>>>
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>>
>>> --
>>> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
>>> presen?a de v?rus.
>>> http://www.avg.com/
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.r-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>> -- 
>> Best Regards
>> Javad Bayat
>> M.Sc. Environment Engineering
>> Alternative Mail: bayat194 at yahoo.com
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

From |@urentrhe|p @end|ng |rom |ree@|r  Tue Apr  9 19:48:51 2024
From: |@urentrhe|p @end|ng |rom |ree@|r (laurentRhelp)
Date: Tue, 9 Apr 2024 19:48:51 +0200
Subject: [R] cpgram: confidence band with a chirp signal
Message-ID: <c177eeec-5f6a-480b-ae21-41d1b0ba9c31@free.fr>

Dear RHelp-list,

 ?? I generate a swept sine signal using the signal library. I can see 
using the spec.pgram command that the spectrum of this signal is white. 
But when I am calculating the cumulative periodogram using the command 
cpgram the process doesn't stay inside the confidence band (cf. code 
below). I missed something.

May you please explain to me why the process don not stay inside the 
confidence band ?

Thank you

Laurent


library(signal)

t1 <- 2
f0 <- 0
f1 <- 15000
Fs <- 44100
Ts <- 1/Fs
t <- seq(0,t1-Ts,by=Ts)
y <- signal::chirp(t=t,f0=f0,t1=t1,f1=f1
 ?????????????????? ,form="linear")
y.ts <- ts(y,frequency=Fs,start=0)
par( mfrow=c(1,2))
spec.pgram(y.ts)
cpgram(y.ts)


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Tue Apr  9 19:58:43 2024
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Tue, 9 Apr 2024 10:58:43 -0700 (PDT)
Subject: [R] Building R-4,3,3 fails
In-Reply-To: <20240409085617.2ae6bdb1@Tarkus>
References: <2d4e6da0-bc51-4cab-8b84-f7631744b17@appl-ecosys.com>
 <20240408213859.78c94c34@Tarkus>
 <7a7ddee-5da4-a48-f5c-328436577d6@appl-ecosys.com>
 <20240408222732.1a4b3be4@parabola>
 <9d3127ec-f236-adf-765d-96d65a2b60ec@appl-ecosys.com>
 <20240409085617.2ae6bdb1@Tarkus>
Message-ID: <806a3233-15fd-c985-9ae9-6f665d6fdc9@appl-ecosys.com>

On Tue, 9 Apr 2024, Ivan Krylov wrote:

> At this point in the build, R already exists, is quite operable and
> even has all the recommended packages installed. The build system then
> uses this freshly compiled R to run Sweave on the vignettes. Let me
> break the build in a similar manner and see what happens:

Ivan,

The R.SlackBuild script does not install a package unless the build
compeletes with exit code 0. Because building the vignettes failed it exited
with a non-0 exit code and is not installed. This is standard
SlackBuilds.org practice for non-core packages.

I could send you the build script off the mail list, but like all linux
distros each has a reason for building packages as they do.

Thanks,

Rich


From |kry|ov @end|ng |rom d|@root@org  Tue Apr  9 20:34:16 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Tue, 9 Apr 2024 21:34:16 +0300
Subject: [R] Building R-4,3,3 fails
In-Reply-To: <806a3233-15fd-c985-9ae9-6f665d6fdc9@appl-ecosys.com>
References: <2d4e6da0-bc51-4cab-8b84-f7631744b17@appl-ecosys.com>
 <20240408213859.78c94c34@Tarkus>
 <7a7ddee-5da4-a48-f5c-328436577d6@appl-ecosys.com>
 <20240408222732.1a4b3be4@parabola>
 <9d3127ec-f236-adf-765d-96d65a2b60ec@appl-ecosys.com>
 <20240409085617.2ae6bdb1@Tarkus>
 <806a3233-15fd-c985-9ae9-6f665d6fdc9@appl-ecosys.com>
Message-ID: <20240409213416.7fed08c8@parabola>

? Tue, 9 Apr 2024 10:58:43 -0700 (PDT)
Rich Shepard <rshepard at appl-ecosys.com> ?????:

> The R.SlackBuild script does not install a package unless the build
> compeletes with exit code 0.

That's fine, R will run straight from the build directory. It has to do
so in order to compile the vignettes.

But let's skip this step. Here's reshape.tex from R-4.3.3:
https://0x0.st/XidU.tex/reshape.tex

(Feel free to inspect the plain text before running LaTeX on it. TeX
has primitives that may execute arbitrary commands.)

If you run texi2pdf -V reshape.tex on your system, does it break in a
similar manner? What about pdflatex reshape.tex?

-- 
Best regards,
Ivan


From r@hep@rd @end|ng |rom @pp|-eco@y@@com  Tue Apr  9 20:43:49 2024
From: r@hep@rd @end|ng |rom @pp|-eco@y@@com (Rich Shepard)
Date: Tue, 9 Apr 2024 11:43:49 -0700 (PDT)
Subject: [R] Building R-4,3,3 fails
In-Reply-To: <20240409213416.7fed08c8@parabola>
References: <2d4e6da0-bc51-4cab-8b84-f7631744b17@appl-ecosys.com>
 <20240408213859.78c94c34@Tarkus>
 <7a7ddee-5da4-a48-f5c-328436577d6@appl-ecosys.com>
 <20240408222732.1a4b3be4@parabola>
 <9d3127ec-f236-adf-765d-96d65a2b60ec@appl-ecosys.com>
 <20240409085617.2ae6bdb1@Tarkus>
 <806a3233-15fd-c985-9ae9-6f665d6fdc9@appl-ecosys.com>
 <20240409213416.7fed08c8@parabola>
Message-ID: <1dcae547-8124-9dda-c035-d4829375328@appl-ecosys.com>

On Tue, 9 Apr 2024, Ivan Krylov wrote:

> That's fine, R will run straight from the build directory. It has to do
> so in order to compile the vignettes.

Ivan,

That's good to know. Thanks.

> But let's skip this step. Here's reshape.tex from R-4.3.3:
> https://0x0.st/XidU.tex/reshape.tex
>
> (Feel free to inspect the plain text before running LaTeX on it. TeX
> has primitives that may execute arbitrary commands.)
>
> If you run texi2pdf -V reshape.tex on your system, does it break in a
> similar manner? What about pdflatex reshape.tex?

Will do. Busy this week, probably get back to this on the weekend.

Regards,

Rich


From L@urentRHe|p @end|ng |rom |ree@|r  Tue Apr  9 20:58:21 2024
From: L@urentRHe|p @end|ng |rom |ree@|r (Laurent Rhelp)
Date: Tue, 9 Apr 2024 20:58:21 +0200
Subject: [R] cpgram: confidence band with a chirp signal
In-Reply-To: <c177eeec-5f6a-480b-ae21-41d1b0ba9c31@free.fr>
References: <c177eeec-5f6a-480b-ae21-41d1b0ba9c31@free.fr>
Message-ID: <fe109fc1-af51-480e-8cdf-c2091e3f8908@free.fr>

I answer to myself: I have to generate my signal up to f1 = Fs/2 in 
order to have a flat response over the entire frequency range.

Le 09/04/2024 ? 19:48, laurentRhelp a ?crit?:
> Dear RHelp-list,
>
> ?? I generate a swept sine signal using the signal library. I can see 
> using the spec.pgram command that the spectrum of this signal is 
> white. But when I am calculating the cumulative periodogram using the 
> command cpgram the process doesn't stay inside the confidence band 
> (cf. code below). I missed something.
>
> May you please explain to me why the process don not stay inside the 
> confidence band ?
>
> Thank you
>
> Laurent
>
>
> library(signal)
>
> t1 <- 2
> f0 <- 0
> f1 <- 15000
> Fs <- 44100
> Ts <- 1/Fs
> t <- seq(0,t1-Ts,by=Ts)
> y <- signal::chirp(t=t,f0=f0,t1=t1,f1=f1
> ?????????????????? ,form="linear")
> y.ts <- ts(y,frequency=Fs,start=0)
> par( mfrow=c(1,2))
> spec.pgram(y.ts)
> cpgram(y.ts)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




-- 
Cet e-mail a ?t? v?rifi? par le logiciel antivirus d'Avast.
www.avast.com


From @|gbert @end|ng |rom w|w|@hu-ber||n@de  Wed Apr 10 09:33:19 2024
From: @|gbert @end|ng |rom w|w|@hu-ber||n@de (Sigbert Klinke)
Date: Wed, 10 Apr 2024 09:33:19 +0200
Subject: [R] Problem with base::order
Message-ID: <b0eb827a-1099-4c90-ac95-e41cb627446f@wiwi.hu-berlin.de>

Hi,

when I execute

order(letters, LETTERS, 1:26)

then everything is fine. But if I execute

order(letters, LETTERS, 1:26, na.last=c(T,T,T), decreasing=c(F,F,F))

I get the error message

Error in method != "radix" && !is.na(na.last) :
'length = 3' in constraint to 'logical(1)'

Shouldn't both give the same result?

Sigbert


From |kry|ov @end|ng |rom d|@root@org  Wed Apr 10 10:29:11 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Wed, 10 Apr 2024 11:29:11 +0300
Subject: [R] Problem with base::order
In-Reply-To: <b0eb827a-1099-4c90-ac95-e41cb627446f@wiwi.hu-berlin.de>
References: <b0eb827a-1099-4c90-ac95-e41cb627446f@wiwi.hu-berlin.de>
Message-ID: <20240410112911.4f1e8ff2@arachnoid>

? Wed, 10 Apr 2024 09:33:19 +0200
Sigbert Klinke <sigbert at wiwi.hu-berlin.de> ?????:

> decreasing=c(F,F,F)

This is only documented to work with method = 'radix':

>> For the ?"radix"? method, this can be a vector of length equal to
>> the number of arguments in ?...? and the elements are recycled as
>> necessary.  For the other methods, it must be length one.

> na.last=c(T,T,T), 

I think this is supposed to be a scalar, no matter the sort method. At
the very least, I don't see it documented to accept a logical vector,
and the C code in both src/main/sort.c and src/main/radixsort.c treats
the argument as a scalar (using asLogical(...), not LOGICAL(...) on the
R value).

-- 
Best regards,
Ivan


From @|gbert @end|ng |rom w|w|@hu-ber||n@de  Wed Apr 10 10:55:06 2024
From: @|gbert @end|ng |rom w|w|@hu-ber||n@de (Sigbert Klinke)
Date: Wed, 10 Apr 2024 10:55:06 +0200
Subject: [R] Problem with base::order
In-Reply-To: <20240410112911.4f1e8ff2@arachnoid>
References: <b0eb827a-1099-4c90-ac95-e41cb627446f@wiwi.hu-berlin.de>
 <20240410112911.4f1e8ff2@arachnoid>
Message-ID: <a423426e-8f28-428d-b293-ca77726de39e@wiwi.hu-berlin.de>

Hi,

you are unfortunately right. Executing

x <- sample(c(1,2,NA), 26, replace=TRUE)
y <- sample(c(1,2,NA), 26, replace=TRUE)
o <- order(x, y, decreasing = c(T,F), na.last=c(F,T))
cbind(x[o], y[o])

shows that the second entry of na.last is ignored without warning.

Thanks Sigbert

Am 10.04.24 um 10:29 schrieb Ivan Krylov:
> ? Wed, 10 Apr 2024 09:33:19 +0200
> Sigbert Klinke <sigbert at wiwi.hu-berlin.de> ?????:
> 
>> decreasing=c(F,F,F)
> 
> This is only documented to work with method = 'radix':
> 
>>> For the ?"radix"? method, this can be a vector of length equal to
>>> the number of arguments in ?...? and the elements are recycled as
>>> necessary.  For the other methods, it must be length one.
> 
>> na.last=c(T,T,T),
> 
> I think this is supposed to be a scalar, no matter the sort method. At
> the very least, I don't see it documented to accept a logical vector,
> and the C code in both src/main/sort.c and src/main/radixsort.c treats
> the argument as a scalar (using asLogical(...), not LOGICAL(...) on the
> R value).
> 

-- 
https://hu.berlin/sk
https://hu.berlin/mmstat
https://hu.berlin/mmstat-ar


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Wed Apr 10 15:46:00 2024
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Wed, 10 Apr 2024 14:46:00 +0100
Subject: [R] Exceptional slowness with read.csv
In-Reply-To: <2a1f4ec9-26ae-4e80-bd40-10c4a919849f@swcp.com>
References: <2a1f4ec9-26ae-4e80-bd40-10c4a919849f@swcp.com>
Message-ID: <1f29531b-7404-4196-89c0-d4475c5f8a2c@sapo.pt>

?s 06:47 de 08/04/2024, Dave Dixon escreveu:
> Greetings,
> 
> I have a csv file of 76 fields and about 4 million records. I know that 
> some of the records have errors - unmatched quotes, specifically. 
> Reading the file with readLines and parsing the lines with read.csv(text 
> = ...) is really slow. I know that the first 2459465 records are good. 
> So I try this:
> 
>  > startTime <- Sys.time()
>  > first_records <- read.csv(file_name, nrows = 2459465)
>  > endTime <- Sys.time()
>  > cat("elapsed time = ", endTime - startTime, "\n")
> 
> elapsed time = ? 24.12598
> 
>  > startTime <- Sys.time()
>  > second_records <- read.csv(file_name, skip = 2459465, nrows = 5)
>  > endTime <- Sys.time()
>  > cat("elapsed time = ", endTime - startTime, "\n")
> 
> This appears to never finish. I have been waiting over 20 minutes.
> 
> So why would (skip = 2459465, nrows = 5) take orders of magnitude longer 
> than (nrows = 2459465) ?
> 
> Thanks!
> 
> -dave
> 
> PS: readLines(n=2459470) takes 10.42731 seconds.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

Can the following function be of help?
After reading the data setting argument quote=FALSE, call a function 
applying gregexpr to its character columns, then transforming the output 
in a two column data.frame with columns

  Col - the column processed;
  Unbalanced - the rows with unbalanced double quotes.

I am assuming the quotes are double quotes. It shouldn't be difficult to 
adapt it to other cas, single quotes, both cases.




unbalanced_dquotes <- function(x) {
   char_cols <- sapply(x, is.character) |> which()
   lapply(char_cols, \(i) {
     y <- x[[i]]
     Unbalanced <- gregexpr('"', y) |>
       sapply(\(x) attr(x, "match.length") |> length()) |>
       {\(x) (x %% 2L) == 1L}() |>
       which()
     data.frame(Col = i, Unbalanced = Unbalanced)
   }) |>
   do.call(rbind, args = _)
}

# read the data disregardin g quoted strings
df1 <- read.csv(fl, quote = "")
# determine which strings have unbalanced quotes and
# where
unbalanced_dquotes(df1)


Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com


From @vi@e@gross m@iii@g oii gm@ii@com  Wed Apr 10 17:11:31 2024
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Wed, 10 Apr 2024 11:11:31 -0400
Subject: [R] Exceptional slowness with read.csv
In-Reply-To: <1f29531b-7404-4196-89c0-d4475c5f8a2c@sapo.pt>
References: <2a1f4ec9-26ae-4e80-bd40-10c4a919849f@swcp.com>
 <1f29531b-7404-4196-89c0-d4475c5f8a2c@sapo.pt>
Message-ID: <003e01da8b59$5ec61140$1c5233c0$@gmail.com>

It sounds like the discussion is now on how to clean your data, with a twist. You want to clean it before you can properly read it in using standard methods.

Some of those standard methods already do quite a bit as they parse the data such as looking ahead to determine the data type for a column.

The specific problem being discussed seems to be related to a lack of balance in individual lines of a CSV file related to double quotes that then mess up that row and following rows for a while. I am not clear on the meaning of the quotes to the user but wonder if they can simply not be viewed as quotes. Functions like read.csv() or the tidyverse variant of read_csv() allow you to specify the quote character or disable it.

So what would happen to the damaged line/row in your case, or any row with both quotes intact if you tried reading it in with an argument disabling processing quoted regions? It may cause problems but in your case, maybe it won't.

If so, after reading in the file, you can march through it and make fixes, such as discussed. The other alternative seems to be to read the lines in the old-fashioned way, do some surgery on whole lines rather than individual row/column entries, and perhaps feed the huge amount of data in some form to read.csv as text=TEXT or write it out to another file and read it in again.

And, of course, if there is just one bad line, then you might just open it with a program such as EXCEL or anything that lets you edit it once, ...




-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Rui Barradas
Sent: Wednesday, April 10, 2024 9:46 AM
To: Dave Dixon <ddixon at swcp.com>; r-help at r-project.org
Subject: Re: [R] Exceptional slowness with read.csv

?s 06:47 de 08/04/2024, Dave Dixon escreveu:
> Greetings,
> 
> I have a csv file of 76 fields and about 4 million records. I know that 
> some of the records have errors - unmatched quotes, specifically. 
> Reading the file with readLines and parsing the lines with read.csv(text 
> = ...) is really slow. I know that the first 2459465 records are good. 
> So I try this:
> 
>  > startTime <- Sys.time()
>  > first_records <- read.csv(file_name, nrows = 2459465)
>  > endTime <- Sys.time()
>  > cat("elapsed time = ", endTime - startTime, "\n")
> 
> elapsed time =   24.12598
> 
>  > startTime <- Sys.time()
>  > second_records <- read.csv(file_name, skip = 2459465, nrows = 5)
>  > endTime <- Sys.time()
>  > cat("elapsed time = ", endTime - startTime, "\n")
> 
> This appears to never finish. I have been waiting over 20 minutes.
> 
> So why would (skip = 2459465, nrows = 5) take orders of magnitude longer 
> than (nrows = 2459465) ?
> 
> Thanks!
> 
> -dave
> 
> PS: readLines(n=2459470) takes 10.42731 seconds.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
Hello,

Can the following function be of help?
After reading the data setting argument quote=FALSE, call a function 
applying gregexpr to its character columns, then transforming the output 
in a two column data.frame with columns

  Col - the column processed;
  Unbalanced - the rows with unbalanced double quotes.

I am assuming the quotes are double quotes. It shouldn't be difficult to 
adapt it to other cas, single quotes, both cases.




unbalanced_dquotes <- function(x) {
   char_cols <- sapply(x, is.character) |> which()
   lapply(char_cols, \(i) {
     y <- x[[i]]
     Unbalanced <- gregexpr('"', y) |>
       sapply(\(x) attr(x, "match.length") |> length()) |>
       {\(x) (x %% 2L) == 1L}() |>
       which()
     data.frame(Col = i, Unbalanced = Unbalanced)
   }) |>
   do.call(rbind, args = _)
}

# read the data disregardin g quoted strings
df1 <- read.csv(fl, quote = "")
# determine which strings have unbalanced quotes and
# where
unbalanced_dquotes(df1)


Hope this helps,

Rui Barradas


-- 
Este e-mail foi analisado pelo software antiv?rus AVG para verificar a presen?a de v?rus.
www.avg.com

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dd|xon @end|ng |rom @wcp@com  Wed Apr 10 18:19:52 2024
From: dd|xon @end|ng |rom @wcp@com (Dave Dixon)
Date: Wed, 10 Apr 2024 10:19:52 -0600
Subject: [R] Exceptional slowness with read.csv
In-Reply-To: <1f29531b-7404-4196-89c0-d4475c5f8a2c@sapo.pt>
References: <2a1f4ec9-26ae-4e80-bd40-10c4a919849f@swcp.com>
 <1f29531b-7404-4196-89c0-d4475c5f8a2c@sapo.pt>
Message-ID: <2ca5db09-cb1a-4d9d-9ba3-0466b0ce680d@swcp.com>

That's basically what I did

1. Get text lines using readLines
2. use tryCatch to parse each line using read.csv(text=...)
3. in the catch, use?gregexpr to find any quotes not adjacent to a comma 
(gregexpr("[^,]\"[^,]",...)
4. escape any quotes found by adding a second quote (using str_sub from 
stringr)
6. parse the patched text using read.csv(text=...)
7. write out the parsed fields as I go along using write.table(..., 
append=TRUE) so I'm not keeping too much in memory.

I went directly to tryCatch because there were 3.5 million records, and 
I only expected a few to have errors.

I found only 6 bad records, but it had to be done to make the datafile 
usable with read.csv(), for the benefit of other researchers using these 
data.


On 4/10/24 07:46, Rui Barradas wrote:
> ?s 06:47 de 08/04/2024, Dave Dixon escreveu:
>> Greetings,
>>
>> I have a csv file of 76 fields and about 4 million records. I know 
>> that some of the records have errors - unmatched quotes, 
>> specifically. Reading the file with readLines and parsing the lines 
>> with read.csv(text = ...) is really slow. I know that the first 
>> 2459465 records are good. So I try this:
>>
>> ?> startTime <- Sys.time()
>> ?> first_records <- read.csv(file_name, nrows = 2459465)
>> ?> endTime <- Sys.time()
>> ?> cat("elapsed time = ", endTime - startTime, "\n")
>>
>> elapsed time = ? 24.12598
>>
>> ?> startTime <- Sys.time()
>> ?> second_records <- read.csv(file_name, skip = 2459465, nrows = 5)
>> ?> endTime <- Sys.time()
>> ?> cat("elapsed time = ", endTime - startTime, "\n")
>>
>> This appears to never finish. I have been waiting over 20 minutes.
>>
>> So why would (skip = 2459465, nrows = 5) take orders of magnitude 
>> longer than (nrows = 2459465) ?
>>
>> Thanks!
>>
>> -dave
>>
>> PS: readLines(n=2459470) takes 10.42731 seconds.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> Hello,
>
> Can the following function be of help?
> After reading the data setting argument quote=FALSE, call a function 
> applying gregexpr to its character columns, then transforming the 
> output in a two column data.frame with columns
>
> ?Col - the column processed;
> ?Unbalanced - the rows with unbalanced double quotes.
>
> I am assuming the quotes are double quotes. It shouldn't be difficult 
> to adapt it to other cas, single quotes, both cases.
>
>
>
>
> unbalanced_dquotes <- function(x) {
> ? char_cols <- sapply(x, is.character) |> which()
> ? lapply(char_cols, \(i) {
> ??? y <- x[[i]]
> ??? Unbalanced <- gregexpr('"', y) |>
> ????? sapply(\(x) attr(x, "match.length") |> length()) |>
> ????? {\(x) (x %% 2L) == 1L}() |>
> ????? which()
> ??? data.frame(Col = i, Unbalanced = Unbalanced)
> ? }) |>
> ? do.call(rbind, args = _)
> }
>
> # read the data disregardin g quoted strings
> df1 <- read.csv(fl, quote = "")
> # determine which strings have unbalanced quotes and
> # where
> unbalanced_dquotes(df1)
>
>
> Hope this helps,
>
> Rui Barradas
>
>


From @vi@e@gross m@iii@g oii gm@ii@com  Wed Apr 10 20:38:36 2024
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Wed, 10 Apr 2024 14:38:36 -0400
Subject: [R] Exceptional slowness with read.csv
In-Reply-To: <2ca5db09-cb1a-4d9d-9ba3-0466b0ce680d@swcp.com>
References: <2a1f4ec9-26ae-4e80-bd40-10c4a919849f@swcp.com>
 <1f29531b-7404-4196-89c0-d4475c5f8a2c@sapo.pt>
 <2ca5db09-cb1a-4d9d-9ba3-0466b0ce680d@swcp.com>
Message-ID: <008601da8b76$4c9e1040$e5da30c0$@gmail.com>

Dave,

Your method works for you and seems to be a one-time fix of a corrupted data file so please accept what I write not as a criticism but explaining my alternate reasoning which I suspect may work faster in some situations.

Here is my understanding of what you are doing:

You have a file in CSV format containing N rows with commas to make M columns. A few rows have a glitch in that there is a double quote character at the beginning or end (meaning between commas adjacent to one, or perhaps at the beginning or end of the line of text) that mess things up. This may be in a specific known column or in several.

So your algorithm is to read the entire file in, or alternately you could do one at a time. Note the types of the columns may not be apparent to you when you start as you are not allowing read.csv() see what it needs to or perform all kinds of processing like dealing with a comment.
You then call functions millions of times (N) such as read.csv(). Argh!

You do that by setting up an environment N times to catch errors. Of course, most lines are fine and no error.

Only on error lines do you check for a regular expression that checks for quotes not immediately adjacent to a comma. I am not sure what you used albeit I imagine sometimes spaces could intervene. You fix any such lines and re-evaluate.

It seems your goal was to rewrite a corrected file so you are doing so while appending to it a row/line at a time.

My strategy was a bit different.

- Call read.csv() just once with no error checking but an option to not treat a quote specially. Note if the quoted region may contain commas, this is a bad strategy. If all it has is spaces or other non-comma items, it may be fine. 

There is now a data.frame or other similar data structure in memory if it works with N rows and M columns.

- Pick only columns that may have this issue, meaning the ones containing say text as compared to numbers or logical values.
- Using those columns, perhaps one at a time, evaluate them all at once for a regular expression that tests the entry for the presence of exactly one quote either at the start or end (the commas you used as anchors are not in this version.) So you are looking for something like:

"words perhaps including, commas
Or
words perhaps including, commas"

but not for:

words perhaps including, commas
"words perhaps including, commas"

You can save the query as a Boolean vector of TRUE/FALSE as one method, to mark which rows need fixing. Or you might use an ifelse() or the equivalent in which you selectively apply a fix to the rows. One method is to use something like sub() to both match all text except an initial or terminal quote and replace it with a quote followed by the match followed by a quote, if any quotes were found.

Whatever you choose can be done in a vectorized manner that may be more efficient. You do not need to check for failures, let alone N times. And you only need process those columns that need it.

When done, you may want to make sure all the columns are of the type you want as who knows if read.csv() made a bad choice on those columns, or others.

Note again, this is only a suggestion and it fails if commas can be part of the quoted parts or even misquoted parts.

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Dave Dixon
Sent: Wednesday, April 10, 2024 12:20 PM
To: Rui Barradas <ruipbarradas at sapo.pt>; r-help at r-project.org
Subject: Re: [R] Exceptional slowness with read.csv

That's basically what I did

1. Get text lines using readLines
2. use tryCatch to parse each line using read.csv(text=...)
3. in the catch, use gregexpr to find any quotes not adjacent to a comma 
(gregexpr("[^,]\"[^,]",...)
4. escape any quotes found by adding a second quote (using str_sub from 
stringr)
6. parse the patched text using read.csv(text=...)
7. write out the parsed fields as I go along using write.table(..., 
append=TRUE) so I'm not keeping too much in memory.

I went directly to tryCatch because there were 3.5 million records, and 
I only expected a few to have errors.

I found only 6 bad records, but it had to be done to make the datafile 
usable with read.csv(), for the benefit of other researchers using these 
data.


On 4/10/24 07:46, Rui Barradas wrote:
> ?s 06:47 de 08/04/2024, Dave Dixon escreveu:
>> Greetings,
>>
>> I have a csv file of 76 fields and about 4 million records. I know 
>> that some of the records have errors - unmatched quotes, 
>> specifically. Reading the file with readLines and parsing the lines 
>> with read.csv(text = ...) is really slow. I know that the first 
>> 2459465 records are good. So I try this:
>>
>>  > startTime <- Sys.time()
>>  > first_records <- read.csv(file_name, nrows = 2459465)
>>  > endTime <- Sys.time()
>>  > cat("elapsed time = ", endTime - startTime, "\n")
>>
>> elapsed time =   24.12598
>>
>>  > startTime <- Sys.time()
>>  > second_records <- read.csv(file_name, skip = 2459465, nrows = 5)
>>  > endTime <- Sys.time()
>>  > cat("elapsed time = ", endTime - startTime, "\n")
>>
>> This appears to never finish. I have been waiting over 20 minutes.
>>
>> So why would (skip = 2459465, nrows = 5) take orders of magnitude 
>> longer than (nrows = 2459465) ?
>>
>> Thanks!
>>
>> -dave
>>
>> PS: readLines(n=2459470) takes 10.42731 seconds.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> Hello,
>
> Can the following function be of help?
> After reading the data setting argument quote=FALSE, call a function 
> applying gregexpr to its character columns, then transforming the 
> output in a two column data.frame with columns
>
>  Col - the column processed;
>  Unbalanced - the rows with unbalanced double quotes.
>
> I am assuming the quotes are double quotes. It shouldn't be difficult 
> to adapt it to other cas, single quotes, both cases.
>
>
>
>
> unbalanced_dquotes <- function(x) {
>   char_cols <- sapply(x, is.character) |> which()
>   lapply(char_cols, \(i) {
>     y <- x[[i]]
>     Unbalanced <- gregexpr('"', y) |>
>       sapply(\(x) attr(x, "match.length") |> length()) |>
>       {\(x) (x %% 2L) == 1L}() |>
>       which()
>     data.frame(Col = i, Unbalanced = Unbalanced)
>   }) |>
>   do.call(rbind, args = _)
> }
>
> # read the data disregardin g quoted strings
> df1 <- read.csv(fl, quote = "")
> # determine which strings have unbalanced quotes and
> # where
> unbalanced_dquotes(df1)
>
>
> Hope this helps,
>
> Rui Barradas
>
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From j@b@y@t194 @end|ng |rom gm@||@com  Wed Apr 10 21:35:39 2024
From: j@b@y@t194 @end|ng |rom gm@||@com (javad bayat)
Date: Wed, 10 Apr 2024 23:05:39 +0330
Subject: [R] Question regarding reservoir volume and water level
In-Reply-To: <a979f03b-0273-4428-abd0-1d75d2048d88@usu.edu>
References: <CANTxAmJrvE5tHoyU1dgs0epeKrMv4tqg-R9K53CPA_TcR8sOvQ@mail.gmail.com>
 <9155638a-7a32-4b20-bc1b-e171d72a053c@sapo.pt>
 <DM6PR03MB5049C4C70B571CD3DD9B25F2E2012@DM6PR03MB5049.namprd03.prod.outlook.com>
 <009101da892d$93a3cc50$baeb64f0$@gmail.com>
 <CANTxAmJzd2n8C0a=LhJzDU6K8GFr7p6q9hXP=zcthQqvitusvw@mail.gmail.com>
 <D6742E57-4A8A-46DD-9F22-A85F2503A9E0@gmail.com>
 <a979f03b-0273-4428-abd0-1d75d2048d88@usu.edu>
Message-ID: <CANTxAmLoCHLuiLWNZyTNgdc8k1O5MnwE29btQEB3mx63TGcQ4g@mail.gmail.com>

Dear all;
Thank you for your reply.
David has explained an interesting method.
David I have DEM file of the region and I have extracted the xyz data from
that.
Also I can extract bathymetry data as xyz file.
I have calculated the storage (volume) of reservoir at the current
elevation.
But the method I have used to calculate the volume is different from your
method. I have crop DEM by the reservoir boundary and then calculate the
volume.
I would be more than happy if you please please explain more or write codes
for me how to get volume at different elevation.
And also about the following function, especially f(Storage).

lm(Elevation~f(Storage)
Sincerely

On Tue, 9 Apr 2024, 21:26 David Stevens via R-help, <r-help at r-project.org>
wrote:

> Water engineer here. The standard approach is to 1) get the storage vs.
> elevation data from the designers of the reservoir or, barring that, 2)
> get the bathymetry data from USBR or state DWR, or, if available, get
> the DEM data from USGS if the survey was done before the reservoir was
> built or 3) get a boat+sonar with GPS  +lots of time and survey the
> bottom elevation yourself. Put the xyz data into ArcGIS and have it
> create the bottom surface, then, with several elevations, integrate the
> xyz data from Z to the bottom to find the storage. Plot the storage at
> each water surface to get an idea of the shape and then use
> lm(Elevation~f(Storage) where f(Storage) may be a cubic or quartic
> polynomial. Then double the Storage and calculate Elevation. This type
> of thing is done everyday by hydrologists.
>
> Good luck
>
> David K Stevens, PhD, PE, Professor
> Civil and Environmental Engineering
> Utah Water Research Laboratory
> Utah State University
> 8200 Old Main Hill
> Logan, UT 84322-8200
> david.stevens at usu.edu
> (435) 797-3229 (office)
>
> On 4/9/2024 8:01 AM, peter dalgaard wrote:
> > So, you know how to get volume for given water level.
> >
> > For the reverse problem, you get in trouble because of the nonlinearity
> inherent in the dependence of surface area on the level.
> >
> > I don't think there is a simple solution to this, save for mapping out
> the volume as a function of water level and solving equations for the water
> level using (say) uniroot(). Which may actually suffice for practical
> purposes.
> >
> > For small changes, finding the derivative of the relation is easy:
> d(volume) = Area * d(level) and this can be used as an approximate relation
> as long as the Area remains nearly constant.
> >
> > However generic questions like doubling the volume are impossible to
> answer without knowledge of the reservoir shape. E.g. in a cylindrical
> reservoir halving the water level also halves the volume, but in a conical
> reservoir, halving the level leaves only 1/8 of the volume.
> >
> > -pd
> >
> >
> >
> >> On 8 Apr 2024, at 05:55 , javad bayat <j.bayat194 at gmail.com> wrote:
> >>
> >> Dear all;
> >> Many thanks for your replies. This was not homework. I apologize.
> >> Let me explain more.
> >> There is a dam constructed in a valley with the highest elevation of
> 1255
> >> m. The area of its reservoir can be calculated by drawing a polygon
> around
> >> the water and it is known.
> >> I have the Digital Elevation Model (DEM) of the region (reservoir and
> its
> >> surrounding area). I have calculated the volume of the current reservoir
> >> (7e6 m3) using the following codes.
> >> library(raster)
> >> library(terra)
> >> library(exactextractr)
> >> library(dplyr)
> >> library(sf)
> >> # Calculate volume for polygon
> >> # Read the DEM raster file
> >> r <- rast("E:/...DEM.tif")
> >> # Read the polygon shapefile
> >> p <- st_read("E:/...Dam.shp")
> >>
> >> r <- crop(r, extent(p))
> >> r <- mask(r, p)
> >>
> >> # Extract the cells in each polygon and calculate the area of each cell
> >> x <- exact_extract(r, p, coverage_area = TRUE)
> >> # Extract polygon values as a dataframe
> >> x1 = as.data.frame(x[1])
> >> head(x1)
> >> x1 = na.omit(x1)
> >> # Calculate the height above the minimum elevation in the polygon
> >> x1$Height = max(x1[,1]) - x1[,1]
> >> # Calculate the volume of each cell
> >> x1$Vol = x1[,2] * x1[,3]
> >> sum(x1$Vol)
> >> x2 = x1[,c(1,2,4)]
> >> x2 = sort(x2,'value')
> >> head(x2)
> >> x3 <- aggregate(Vol ~ value, data = x2, FUN = sum)
> >> x4 <- aggregate(coverage_area ~ value, data = x2, FUN = sum)
> >> x5 = cbind(x3, Area = x4[,2])
> >> library(dplyr)
> >> x6 <- x5 %>%
> >>   mutate(V_sum = cumsum(Vol)) %>%
> >>   mutate(A_sum = cumsum(Area))
> >> plot(x6$value~x6$V_sum)
> >>
> >> And I thought that it is possible to get the elevation for a specific
> >> volume by linear model between elevation and volume, as follow:
> >>
> >> # Get a linear model between elevation and the volume
> >> lm1 <- lm(value ~ V_sum, data = x6)
> >> d <- data.frame(V_sum = 14e6)  #
> >> predict(lm1, newdata = d)
> >>
> >> But it is not possible through the LM.
> >> Now I want to know what would be the water level in the reservoir if the
> >> reservoir volume doubled or we adding a known volume to it?
> >> Also what would be the volume if the water level increases to 1250 m?
> >>
> >> I would be more than happy if you help me to do this.
> >> Sincerely
> >>
> >> On Mon, Apr 8, 2024 at 12:23?AM <avi.e.gross at gmail.com> wrote:
> >>
> >>> John,
> >>>
> >>> Your reaction was what my original reaction was until I realized I had
> to
> >>> find out what a DEM file was and that contains enough of the kind of
> >>> depth-dimension data you describe albeit what may be a very irregular
> cross
> >>> section to calculate for areas and thence volumes.
> >>>
> >>> If I read it correctly, this can be a very real-world problem worthy
> of a
> >>> solution, such as in places like California where they had a tad more
> rain
> >>> than usual and some reservoirs may overflow. Someone else provided what
> >>> sounds like a mathematical algorithm but my guess is what is needed
> here is
> >>> perhaps less analytic since there may be no trivial way to create
> formulas
> >>> and take integrals and so on, but simply an approximate way to
> calculate
> >>> incremental volumes for each horizontal "slice" and keep adding or
> >>> subtracting them till you reach a target and then read off another
> variable
> >>> at that point such as depth.
> >>>
> >>> Some care must be taken as water level has to be relative to something
> and
> >>> many natural reservoirs have no unique bottom level. Some water may
> also be
> >>> stored underground and to the side and pour in if the level lowers or
> can
> >>> be
> >>> used to escape if the level rises.
> >>>
> >>>
> >>> -----Original Message-----
> >>> From: R-help <r-help-bounces at r-project.org> On Behalf Of Sorkin, John
> >>> Sent: Sunday, April 7, 2024 3:08 PM
> >>> To: Rui Barradas <ruipbarradas at sapo.pt>; javad bayat <
> j.bayat194 at gmail.com
> >>>> ;
> >>> R-help <R-help at r-project.org>
> >>> Subject: Re: [R] Question regarding reservoir volume and water level
> >>>
> >>> Aside from the fact that the original question might well be a class
> >>> exercise (or homework), the question is unanswerable given the data
> given
> >>> by
> >>> the original poster. One needs to know the dimensions of the reservoir,
> >>> above and below the current waterline. Are the sides, above and below
> the
> >>> waterline smooth? Is the region currently above the waterline that can
> >>> store
> >>> water a mirror image of the region below the waterline? Is the region
> above
> >>> the reservoir include a flood plane? Will the additional water go into
> the
> >>> flood plane?
> >>>
> >>> The lack of required detail in the question posed by the original
> poster
> >>> suggests that there are strong assumptions, assumptions that typically
> >>> would
> >>> be made in a class-room example or exercise.
> >>>
> >>> John
> >>>
> >>> John David Sorkin M.D., Ph.D.
> >>> Professor of Medicine, University of Maryland School of Medicine;
> >>> Associate Director for Biostatistics and Informatics, Baltimore VA
> Medical
> >>> Center Geriatrics Research, Education, and Clinical Center;
> >>> PI Biostatistics and Informatics Core, University of Maryland School of
> >>> Medicine Claude D. Pepper Older Americans Independence Center;
> >>> Senior Statistician University of Maryland Center for Vascular
> Research;
> >>>
> >>> Division of Gerontology and Paliative Care,
> >>> 10 North Greene Street
> >>> GRECC (BT/18/GR)
> >>> Baltimore, MD 21201-1524
> >>> Cell phone 443-418-5382
> >>>
> >>>
> >>>
> >>>
> >>> ________________________________________
> >>> From: R-help <r-help-bounces at r-project.org> on behalf of Rui Barradas
> >>> <ruipbarradas at sapo.pt>
> >>> Sent: Sunday, April 7, 2024 10:53 AM
> >>> To: javad bayat; R-help
> >>> Subject: Re: [R] Question regarding reservoir volume and water level
> >>>
> >>> ?s 13:27 de 07/04/2024, javad bayat escreveu:
> >>>> Dear all;
> >>>> I have a question about the water level of a reservoir, when the
> volume
> >>>> changed or doubled.
> >>>> There is a DEM file with the highest elevation 1267 m. The lowest
> >>> elevation
> >>>> is 1230 m. The current volume of the reservoir is 7,000,000 m3 at
> 1240 m.
> >>>> Now I want to know what would be the water level if the volume rises
> to
> >>>> 1250 m? or what would be the water level if the volume doubled
> >>> (14,000,000
> >>>> m3)?
> >>>>
> >>>> Is there any way to write codes to do this in R?
> >>>> I would be more than happy if anyone could help me.
> >>>> Sincerely
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>> Hello,
> >>>
> >>> This is a simple rule of three.
> >>> If you know the level l the argument doesn't need to be named but if
> you
> >>> know the volume v then it must be named.
> >>>
> >>>
> >>> water_level <- function(l, v, level = 1240, volume = 7e6) {
> >>>    if(missing(v)) {
> >>>      volume * l / level
> >>>    } else level * v / volume
> >>> }
> >>>
> >>> lev <- 1250
> >>> vol <- 14e6
> >>>
> >>> water_level(l = lev)
> >>> #> [1] 7056452
> >>> water_level(v = vol)
> >>> #> [1] 2480
> >>>
> >>>
> >>> Hope this helps,
> >>>
> >>> Rui Barradas
> >>>
> >>>
> >>> --
> >>> Este e-mail foi analisado pelo software antiv?rus AVG para verificar a
> >>> presen?a de v?rus.
> >>> http://www.avg.com/
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.r-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>>
> >> --
> >> Best Regards
> >> Javad Bayat
> >> M.Sc. Environment Engineering
> >> Alternative Mail: bayat194 at yahoo.com
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mbudh|r@j@ @end|ng |rom um@@@@edu  Wed Apr 10 21:16:12 2024
From: mbudh|r@j@ @end|ng |rom um@@@@edu (Manya Budhiraja)
Date: Wed, 10 Apr 2024 15:16:12 -0400
Subject: [R] seeking help with splicing in R
Message-ID: <CAPNKbsAk9Gag2k4diGMqwKEMHo7Tu-UvvrMxAkYYFw-uqzhzHA@mail.gmail.com>

Hello!

I was trying to splice two wholesale price index deflators series which
have different base years. One of them is called wpi_def_nic2004(from 2005
to 2012), and another is called wpi_def_nic2008(from 2012 to 2019). I am
trying to create a single series such that the base year prices are
consistent with wpi_def_nic2008. The common year is 2012, which is used for
starting the splicing.

I would like to keep the values in the nic2008 series unchanged. The
nic2004 starts in 2005, and I would like to make the nic2004 series
consistent with nic2008. Moreover, I need to do this for each 2 digit
industry. I tried the following code, *but the problem I encounter is that
R only splices the nic2004 series only for the year 2011.* It does not
understand from my code that it can use the spliced value of 2011 in the
nic2004 series to go further back in the nic2004 series to splice the
remaining values from 2005-2011. This is the code I am using:

 merged <- full_join(wpi_def_nic2004,wpi_def_nic2008)

merged <- merged |> group_by(IND_CD_2D) |>
  mutate(spliced = case_when(year >= 2012 ~ def_value_nic2008,
                             year <= 2011 ~

 def_value_nic2004*(lead(def_value_nic2008)/lead(def_value_nic2004))))

Thanks a lot!
Manya

	[[alternative HTML version deleted]]


From tebert @end|ng |rom u||@edu  Thu Apr 11 14:13:06 2024
From: tebert @end|ng |rom u||@edu (Ebert,Timothy Aaron)
Date: Thu, 11 Apr 2024 12:13:06 +0000
Subject: [R] seeking help with splicing in R
In-Reply-To: <CAPNKbsAk9Gag2k4diGMqwKEMHo7Tu-UvvrMxAkYYFw-uqzhzHA@mail.gmail.com>
References: <CAPNKbsAk9Gag2k4diGMqwKEMHo7Tu-UvvrMxAkYYFw-uqzhzHA@mail.gmail.com>
Message-ID: <CH3PR22MB451495823E04A55BB102E3FACF052@CH3PR22MB4514.namprd22.prod.outlook.com>

Whatever you had as HTML was deleted. If that was data we did not get it.
1) manipulate wpi_def_nic2004 and wpi_def_nic2008 first so that the data are compatible, then join them.
2) The full_join statement should explicitly state the columns to join by. Using by=NULL joins by all the columns with the same name and that is risky. I might want to reuse code or I might change things and suddenly the code does not behave in the same way because I have used the default. That might be the answer: if both data frames have year as a common variable then they will be joined by year, but the years do not overlap. Look at your "merged" data frame carefully. Are you sure it is in the right format?
3) Are you sure you want a full_join, or do you want an inner_join where you get back only industries that are in both.
4) A stupid question: why not adjust the 2005-2012 data for inflation to "convert" base years?

Tim

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Manya Budhiraja
Sent: Wednesday, April 10, 2024 3:16 PM
To: r-help at r-project.org
Subject: [R] seeking help with splicing in R

[External Email]

Hello!

I was trying to splice two wholesale price index deflators series which have different base years. One of them is called wpi_def_nic2004(from 2005 to 2012), and another is called wpi_def_nic2008(from 2012 to 2019). I am trying to create a single series such that the base year prices are consistent with wpi_def_nic2008. The common year is 2012, which is used for starting the splicing.

I would like to keep the values in the nic2008 series unchanged. The
nic2004 starts in 2005, and I would like to make the nic2004 series consistent with nic2008. Moreover, I need to do this for each 2 digit industry. I tried the following code, *but the problem I encounter is that R only splices the nic2004 series only for the year 2011.* It does not understand from my code that it can use the spliced value of 2011 in the
nic2004 series to go further back in the nic2004 series to splice the remaining values from 2005-2011. This is the code I am using:

 merged <- full_join(wpi_def_nic2004,wpi_def_nic2008)

merged <- merged |> group_by(IND_CD_2D) |>
  mutate(spliced = case_when(year >= 2012 ~ def_value_nic2008,
                             year <= 2011 ~

 def_value_nic2004*(lead(def_value_nic2008)/lead(def_value_nic2004))))

Thanks a lot!
Manya

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Apr 11 18:35:31 2024
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 11 Apr 2024 12:35:31 -0400
Subject: [R] Regexp pattern but fixed replacement?
Message-ID: <17ff868c-3e2c-4901-8214-5e8d9cdb6d03@gmail.com>

I noticed this issue in stringr::str_replace, but it also affects sub() 
in base R.

If the pattern in a call to one of these needs to be a regular 
expression, then backslashes in the replacement text are treated specially.

For example,

   gsub("a|b", "\\", "abcdef")

gives "def", not "\\\\def" as I wanted.  To get the latter, I need to 
escape the replacement backslashes, e.g.

   gsub("a|b", "\\\\", "abcdef")

which gives "\\\\cdef".

I have two questions:

1.  Is there a variant on sub or str_replace which allows the pattern to 
be declared as a regular expression, but the replacement to be declared 
as fixed?

2.  To get what I want, I can double the backslashes in the replacement 
text.  This would do that:

    replacement <- gsub("\\\\", "\\\\\\\\", replacement)

Are there any other special characters to worry about besides backslashes?

Duncan Murdoch


From dd|xon @end|ng |rom @wcp@com  Thu Apr 11 18:57:07 2024
From: dd|xon @end|ng |rom @wcp@com (Dave Dixon)
Date: Thu, 11 Apr 2024 10:57:07 -0600
Subject: [R] Regexp pattern but fixed replacement?
In-Reply-To: <17ff868c-3e2c-4901-8214-5e8d9cdb6d03@gmail.com>
References: <17ff868c-3e2c-4901-8214-5e8d9cdb6d03@gmail.com>
Message-ID: <8f76f68c-ddd3-4214-a9b2-81fc980e49e8@swcp.com>

Backslashes in regex expressions in R are maddening, but they make sense.

R string handling interprets your replacement string "\\" as just one 
backslash. Your string is received by gsub as "\" - that is, just the 
control backslash, NOT the character backslash. gsub is expecting to see 
\0, \1, \2, or some other control starting with backslash.

If you want gsub to replace with a backslash character, you have to send 
it as "\\". In order to get two backslash characters in an R string, you 
have to double them ALL: "\\\\".

The string that is output is an R string: the backslashes are escaped 
with a backslash, so "\\\\" really means two backslashes.

There are lots of special characters in the search string, but only one 
in the replacement string: backslash.

Here's my favorite resource on this topic is 
https://www.regular-expressions.info/replacecharacters.html


On 4/11/24 10:35, Duncan Murdoch wrote:
> I noticed this issue in stringr::str_replace, but it also affects 
> sub() in base R.
>
> If the pattern in a call to one of these needs to be a regular 
> expression, then backslashes in the replacement text are treated 
> specially.
>
> For example,
>
> ? gsub("a|b", "\\", "abcdef")
>
> gives "def", not "\\\\def" as I wanted.? To get the latter, I need to 
> escape the replacement backslashes, e.g.
>
> ? gsub("a|b", "\\\\", "abcdef")
>
> which gives "\\\\cdef".
>
> I have two questions:
>
> 1.? Is there a variant on sub or str_replace which allows the pattern 
> to be declared as a regular expression, but the replacement to be 
> declared as fixed?
>
> 2.? To get what I want, I can double the backslashes in the 
> replacement text.? This would do that:
>
> ?? replacement <- gsub("\\\\", "\\\\\\\\", replacement)
>
> Are there any other special characters to worry about besides 
> backslashes?
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |kw@|mmo @end|ng |rom gm@||@com  Thu Apr 11 18:58:11 2024
From: |kw@|mmo @end|ng |rom gm@||@com (Iris Simmons)
Date: Thu, 11 Apr 2024 12:58:11 -0400
Subject: [R] Regexp pattern but fixed replacement?
In-Reply-To: <17ff868c-3e2c-4901-8214-5e8d9cdb6d03@gmail.com>
References: <17ff868c-3e2c-4901-8214-5e8d9cdb6d03@gmail.com>
Message-ID: <CADNULg8udxTTwNbFGJebycRRYVra-G0ryyQbM8x2oi8wDyB4Xg@mail.gmail.com>

Hi Duncan,


I only know about sub() and gsub().

There is no way to have pattern be a regular expression and replacement be
a fixed string.

Backslash is the only special character in replacement. If you need a
reference, see this file:
https://github.com/wch/r-source/blob/04650eddd6d844963b6d7aac02bd8d13cbf440d4/src/main/grep.c
particularly functions R_pcre_string_adj and wstring_adj. So just double
the backslashes in replacement and you'll be good to go.

On Thu, Apr 11, 2024, 12:36 Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> I noticed this issue in stringr::str_replace, but it also affects sub()
> in base R.
>
> If the pattern in a call to one of these needs to be a regular
> expression, then backslashes in the replacement text are treated specially.
>
> For example,
>
>    gsub("a|b", "\\", "abcdef")
>
> gives "def", not "\\\\def" as I wanted.  To get the latter, I need to
> escape the replacement backslashes, e.g.
>
>    gsub("a|b", "\\\\", "abcdef")
>
> which gives "\\\\cdef".
>
> I have two questions:
>
> 1.  Is there a variant on sub or str_replace which allows the pattern to
> be declared as a regular expression, but the replacement to be declared
> as fixed?
>
> 2.  To get what I want, I can double the backslashes in the replacement
> text.  This would do that:
>
>     replacement <- gsub("\\\\", "\\\\\\\\", replacement)
>
> Are there any other special characters to worry about besides backslashes?
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Apr 11 19:08:41 2024
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 11 Apr 2024 13:08:41 -0400
Subject: [R] Regexp pattern but fixed replacement?
In-Reply-To: <8f76f68c-ddd3-4214-a9b2-81fc980e49e8@swcp.com>
References: <17ff868c-3e2c-4901-8214-5e8d9cdb6d03@gmail.com>
 <8f76f68c-ddd3-4214-a9b2-81fc980e49e8@swcp.com>
Message-ID: <a372c42e-6265-46b9-8489-679548a1c90a@gmail.com>

On 11/04/2024 12:57 p.m., Dave Dixon wrote:
> Backslashes in regex expressions in R are maddening, but they make sense.
> 
> R string handling interprets your replacement string "\\" as just one
> backslash. Your string is received by gsub as "\" - that is, just the
> control backslash, NOT the character backslash. gsub is expecting to see
> \0, \1, \2, or some other control starting with backslash.
> 
> If you want gsub to replace with a backslash character, you have to send
> it as "\\". In order to get two backslash characters in an R string, you
> have to double them ALL: "\\\\".

You can use "\\" if the pattern is declared as "fixed", via

   sub("a", "\\", "abcdef", fixed = TRUE)

or

   stringr::str_replace("abcdef", fixed("a"), "\\")

My first question was whether there is a sub-like function with a way to 
declare the pattern as a regexp, but the replacement as fixed.  Thanks 
for your answer to my second question.

Duncan Murdoch

> 
> The string that is output is an R string: the backslashes are escaped
> with a backslash, so "\\\\" really means two backslashes.
> 
> There are lots of special characters in the search string, but only one
> in the replacement string: backslash.
> 
> Here's my favorite resource on this topic is
> https://www.regular-expressions.info/replacecharacters.html
> 
> 
> On 4/11/24 10:35, Duncan Murdoch wrote:
>> I noticed this issue in stringr::str_replace, but it also affects
>> sub() in base R.
>>
>> If the pattern in a call to one of these needs to be a regular
>> expression, then backslashes in the replacement text are treated
>> specially.
>>
>> For example,
>>
>>  ? gsub("a|b", "\\", "abcdef")
>>
>> gives "def", not "\\\\def" as I wanted.? To get the latter, I need to
>> escape the replacement backslashes, e.g.
>>
>>  ? gsub("a|b", "\\\\", "abcdef")
>>
>> which gives "\\\\cdef".
>>
>> I have two questions:
>>
>> 1.? Is there a variant on sub or str_replace which allows the pattern
>> to be declared as a regular expression, but the replacement to be
>> declared as fixed?
>>
>> 2.? To get what I want, I can double the backslashes in the
>> replacement text.? This would do that:
>>
>>  ?? replacement <- gsub("\\\\", "\\\\\\\\", replacement)
>>
>> Are there any other special characters to worry about besides
>> backslashes?
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Apr 11 19:11:11 2024
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 11 Apr 2024 13:11:11 -0400
Subject: [R] Regexp pattern but fixed replacement?
In-Reply-To: <CADNULg8udxTTwNbFGJebycRRYVra-G0ryyQbM8x2oi8wDyB4Xg@mail.gmail.com>
References: <17ff868c-3e2c-4901-8214-5e8d9cdb6d03@gmail.com>
 <CADNULg8udxTTwNbFGJebycRRYVra-G0ryyQbM8x2oi8wDyB4Xg@mail.gmail.com>
Message-ID: <f628af15-35a4-4092-bfac-6d4cfabd45ea@gmail.com>

On 11/04/2024 12:58 p.m., Iris Simmons wrote:
> Hi?Duncan,
> 
> 
> I only know about sub() and gsub().
> 
> There is no way to have pattern be a regular expression and replacement 
> be a fixed string.
> 
> Backslash is the only special character in replacement. If you need a 
> reference, see this file:
> https://github.com/wch/r-source/blob/04650eddd6d844963b6d7aac02bd8d13cbf440d4/src/main/grep.c <https://github.com/wch/r-source/blob/04650eddd6d844963b6d7aac02bd8d13cbf440d4/src/main/grep.c>
> particularly functions R_pcre_string_adj and wstring_adj. So just double 
> the backslashes in replacement and you'll be good to go.

Thanks, that's what I've done.

Duncan Murdoch

> 
> On Thu, Apr 11, 2024, 12:36 Duncan Murdoch <murdoch.duncan at gmail.com 
> <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>     I noticed this issue in stringr::str_replace, but it also affects sub()
>     in base R.
> 
>     If the pattern in a call to one of these needs to be a regular
>     expression, then backslashes in the replacement text are treated
>     specially.
> 
>     For example,
> 
>      ? ?gsub("a|b", "\\", "abcdef")
> 
>     gives "def", not "\\\\def" as I wanted.? To get the latter, I need to
>     escape the replacement backslashes, e.g.
> 
>      ? ?gsub("a|b", "\\\\", "abcdef")
> 
>     which gives "\\\\cdef".
> 
>     I have two questions:
> 
>     1.? Is there a variant on sub or str_replace which allows the
>     pattern to
>     be declared as a regular expression, but the replacement to be declared
>     as fixed?
> 
>     2.? To get what I want, I can double the backslashes in the replacement
>     text.? This would do that:
> 
>      ? ? replacement <- gsub("\\\\", "\\\\\\\\", replacement)
> 
>     Are there any other special characters to worry about besides
>     backslashes?
> 
>     Duncan Murdoch
> 
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>


From |@go@g|ne @end|ng |rom @jd@e@  Fri Apr 12 14:15:07 2024
From: |@go@g|ne @end|ng |rom @jd@e@ (=?iso-8859-1?Q?Iago_Gin=E9_V=E1zquez?=)
Date: Fri, 12 Apr 2024 12:15:07 +0000
Subject: [R] Debugging functions defined (locally) inside another functions
Message-ID: <AM0PR02MB4420AA5EEAB875377371849994042@AM0PR02MB4420.eurprd02.prod.outlook.com>

Hi all, I am trying to debug an error of a function g defined and used inside another function f of a package.
So I have

f <- function(whatever){
   ...
   g <- function(whatever2){
     ...
   }
   ...
}

If I wanted to debug some thing directly inside f I would do debug(f). But this does not go inside g code. On the other hand, debug(g) does not work as g is not a defined function in the namespace of the package.

Is there some way to debug errors inside g?

Thank you in advance.

All the best,
Iago

	[[alternative HTML version deleted]]


From |@go@g|ne @end|ng |rom @jd@e@  Fri Apr 12 14:22:03 2024
From: |@go@g|ne @end|ng |rom @jd@e@ (=?Windows-1252?Q?Iago_Gin=E9_V=E1zquez?=)
Date: Fri, 12 Apr 2024 12:22:03 +0000
Subject: [R] 
 Debugging functions defined (locally) inside another functions
In-Reply-To: <AM0PR02MB4420AA5EEAB875377371849994042@AM0PR02MB4420.eurprd02.prod.outlook.com>
References: <AM0PR02MB4420AA5EEAB875377371849994042@AM0PR02MB4420.eurprd02.prod.outlook.com>
Message-ID: <AM0PR02MB4420063E22452480AA3CFA8894042@AM0PR02MB4420.eurprd02.prod.outlook.com>

To be precise, in the case I am looking this time f is not a function, but

f <- ggplot2::ggproto(...)

So debug(f) produces
Error in debug(f) : argument must be a function

Iago
________________________________
De: R-help <r-help-bounces at r-project.org> de part de Iago Gin? V?zquez <iago.gine at sjd.es>
Enviat el: divendres, 12 d?abril de 2024 14:15
Per a: r-help at r-project.org <r-help at r-project.org>
Tema: [R] Debugging functions defined (locally) inside another functions

Hi all, I am trying to debug an error of a function g defined and used inside another function f of a package.
So I have

f <- function(whatever){
   ...
   g <- function(whatever2){
     ...
   }
   ...
}

If I wanted to debug some thing directly inside f I would do debug(f). But this does not go inside g code. On the other hand, debug(g) does not work as g is not a defined function in the namespace of the package.

Is there some way to debug errors inside g?

Thank you in advance.

All the best,
Iago

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Fri Apr 12 14:38:13 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Fri, 12 Apr 2024 15:38:13 +0300
Subject: [R] 
 Debugging functions defined (locally) inside another functions
In-Reply-To: <AM0PR02MB4420AA5EEAB875377371849994042@AM0PR02MB4420.eurprd02.prod.outlook.com>
References: <AM0PR02MB4420AA5EEAB875377371849994042@AM0PR02MB4420.eurprd02.prod.outlook.com>
Message-ID: <20240412153813.2b384e89@arachnoid>

? Fri, 12 Apr 2024 12:15:07 +0000
Iago Gin? V?zquez <iago.gine at sjd.es> ?????:

> f <- function(whatever){
>    ...
>    g <- function(whatever2){
>      ...
>    }
>    ...
> }
> 
> If I wanted to debug some thing directly inside f I would do
> debug(f). But this does not go inside g code. On the other hand,
> debug(g) does not work as g is not a defined function in the
> namespace of the package.

Moreover, `g` doesn't exist at all until f() is evaluated and reaches
this point. If `f` was a function, it would be possible to trace() it,
inserting a call to debug(g) after it's created.

> f <- ggplot2::ggproto(...)
> 
> So debug(f) produces
> Error in debug(f) : argument must be a function

Can you show more information about the call that produces `f`? Where
does `g` come into play? Following ?ggplot2::ggproto, I can trigger the
browser if I reach into the environment of the publicly available
method:

Adder <- ggproto(...) # from the example
debug(environment(Adder$add)$add)
Adder$add(1234)
# debugging in: add(..., self = self)
# debug ?? #3: {
#     self$x <- self$x + n
#     self$x
# }

-- 
Best regards,
Ivan


From |@go@g|ne @end|ng |rom @jd@e@  Fri Apr 12 14:53:02 2024
From: |@go@g|ne @end|ng |rom @jd@e@ (=?gb2312?B?SWFnbyBHaW6opiBWqKJ6cXVleg==?=)
Date: Fri, 12 Apr 2024 12:53:02 +0000
Subject: [R] 
 Debugging functions defined (locally) inside another functions
In-Reply-To: <20240412153813.2b384e89@arachnoid>
References: <AM0PR02MB4420AA5EEAB875377371849994042@AM0PR02MB4420.eurprd02.prod.outlook.com>
 <20240412153813.2b384e89@arachnoid>
Message-ID: <AM0PR02MB4420C9EA577899CC58EA045094042@AM0PR02MB4420.eurprd02.prod.outlook.com>

Thank you Ivan, your example solves my issue this time through

debug(environment(Adder$add)$add)


Just for the future, you say

    Moreover, `g` doesn't exist at all until f() is evaluated and reaches
    this point. If `f` was a function, it would be possible to trace() it,
    inserting a call to debug(g) after it's created.

How should I call trace() if f was a function?


Best regards,
Iago

________________________________
De: Ivan Krylov <ikrylov at disroot.org>
Enviat el: divendres, 12 d??abril de 2024 14:38
Per a: Iago Gin?? V??zquez <iago.gine at sjd.es>
A/c: r-help at r-project.org <r-help at r-project.org>
Tema: Re: [R] Debugging functions defined (locally) inside another functions

?? Fri, 12 Apr 2024 12:15:07 +0000
Iago Gin?? V??zquez <iago.gine at sjd.es> ??????:

> f <- function(whatever){
>    ...
>    g <- function(whatever2){
>      ...
>    }
>    ...
> }
>
> If I wanted to debug some thing directly inside f I would do
> debug(f). But this does not go inside g code. On the other hand,
> debug(g) does not work as g is not a defined function in the
> namespace of the package.

Moreover, `g` doesn't exist at all until f() is evaluated and reaches
this point. If `f` was a function, it would be possible to trace() it,
inserting a call to debug(g) after it's created.

> f <- ggplot2::ggproto(...)
>
> So debug(f) produces
> Error in debug(f) : argument must be a function

Can you show more information about the call that produces `f`? Where
does `g` come into play? Following ?ggplot2::ggproto, I can trigger the
browser if I reach into the environment of the publicly available
method:

Adder <- ggproto(...) # from the example
debug(environment(Adder$add)$add)
Adder$add(1234)
# debugging in: add(..., self = self)
# debug ??? #3: {
#     self$x <- self$x + n
#     self$x
# }

--
Best regards,
Ivan

	[[alternative HTML version deleted]]


From |kry|ov @end|ng |rom d|@root@org  Fri Apr 12 15:32:17 2024
From: |kry|ov @end|ng |rom d|@root@org (Ivan Krylov)
Date: Fri, 12 Apr 2024 16:32:17 +0300
Subject: [R] 
 Debugging functions defined (locally) inside another functions
In-Reply-To: <AM0PR02MB4420C9EA577899CC58EA045094042@AM0PR02MB4420.eurprd02.prod.outlook.com>
References: <AM0PR02MB4420AA5EEAB875377371849994042@AM0PR02MB4420.eurprd02.prod.outlook.com>
 <20240412153813.2b384e89@arachnoid>
 <AM0PR02MB4420C9EA577899CC58EA045094042@AM0PR02MB4420.eurprd02.prod.outlook.com>
Message-ID: <20240412163217.4d99204a@arachnoid>

? Fri, 12 Apr 2024 12:53:02 +0000
Iago Gin? V?zquez <iago.gine at sjd.es> ?????:

> How should I call trace() if f was a function?

Let the tracer be quote(debug(g)) and use as.list(body(f)) to determine
where it should be injected:

f <- function() {
 message('exists("g") so far is ', exists('g'))
 g <- function() {
  flag <- TRUE
  if (flag) stop('an error')
 }
 message('about to run g()')
 g()
}

In this example, step number 4 is message("about to run g()"), so
injecting a call to debug() before it should work:

trace(f, quote(debug(g)), at = 4)
f()
# exists("g") so far is FALSE
# Tracing f() step 4 # <-- at this point debug(g) is run
# about to run g()
# debugging in: g()
# debug at #3: {
#    flag <- TRUE
#     if (flag)
#         stop("an error")
# }

help(trace) has an extensive example showing how to use it for many
similar purposes.

-- 
Best regards,
Ivan


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Apr 12 15:36:00 2024
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 12 Apr 2024 09:36:00 -0400
Subject: [R] 
 Debugging functions defined (locally) inside another functions
In-Reply-To: <AM0PR02MB4420AA5EEAB875377371849994042@AM0PR02MB4420.eurprd02.prod.outlook.com>
References: <AM0PR02MB4420AA5EEAB875377371849994042@AM0PR02MB4420.eurprd02.prod.outlook.com>
Message-ID: <4110467b-3405-4c52-90ce-93c63546a2c9@gmail.com>

On 12/04/2024 8:15 a.m., Iago Gin? V?zquez wrote:
> Hi all, I am trying to debug an error of a function g defined and used inside another function f of a package.
> So I have
> 
> f <- function(whatever){
>     ...
>     g <- function(whatever2){
>       ...
>     }
>     ...
> }
> 
> If I wanted to debug some thing directly inside f I would do debug(f). But this does not go inside g code. On the other hand, debug(g) does not work as g is not a defined function in the namespace of the package.
> 
> Is there some way to debug errors inside g?

The easiest case is if you have access to the source code.  Just put a 
browser() statement at the start of g, i.e. change it to

      g <- function(whatever2){
        browser()
        ...
      }

and it will break very similarly to what happens if you have set debug(g).

Another possibility if you have the source but don't want to edit it is 
to use trace.  Suppose that the definition of g is in source.R at lines 
100 to 120.  Then you can run

   setBreakpoint("source.R#101")

to set a breakpoint via trace() just before line 101 runs.  trace() has 
lots of options; it can just print things, or call browser(), etc.  They 
are available in setBreakpoint().

If you are executing code from a package and you don't have the source 
handy it's a bit tedious, but you can still do the search that 
setBreakpoint() does to find the source.  For example, let's set a 
breakpoint just before the print statement in g in this example:

  f <- function() {
    g <- function() {
      print("this is g")
    }
    print("this is f")
    g()
  }

You need to find the location of that line in f.  Look at as.list(body(f)):

 > as.list(body(f))
[[1]]
`{`

[[2]]
g <- function() {
     print("this is g")
}

[[3]]
print("this is f")

[[4]]
g()

So we need to look within entry 2:

 > as.list(body(f)[[2]])
[[1]]
`<-`

[[2]]
g

[[3]]
function() {
     print("this is g")
}

Continue drilling down:

 > as.list(body(f)[[c(2,3)]])
[[1]]
`function`

[[2]]
NULL

[[3]]
{
     print("this is g")
}

[[4]]
function() {
      print("this is g")
    }

 > as.list(body(f)[[c(2,3, 3)]])
[[1]]
`{`

[[2]]
print("this is g")

So now we know the print statement is at location c(2,3,3,2).  Set a 
browser call there:

 > trace(f, at=list(c(2,3,3,2)), tracer = quote(browser()))
[1] "f"
 > body(f)
{
     g <- function() {
         {
             .doTrace(browser(), "step 2,3,3,2")
             print("this is g")
         }
     }
     print("this is f")
     g()
}

Note that the "at" argument needs to be a list to drill down; if you 
just said at=c(2,3,3,2) it would set breakpoints at step 2 and 3.

Duncan Murdoch


From |@go@g|ne @end|ng |rom @jd@e@  Fri Apr 12 19:08:41 2024
From: |@go@g|ne @end|ng |rom @jd@e@ (=?Windows-1252?Q?Iago_Gin=E9_V=E1zquez?=)
Date: Fri, 12 Apr 2024 17:08:41 +0000
Subject: [R] 
 Debugging functions defined (locally) inside another functions
In-Reply-To: <4110467b-3405-4c52-90ce-93c63546a2c9@gmail.com>
References: <AM0PR02MB4420AA5EEAB875377371849994042@AM0PR02MB4420.eurprd02.prod.outlook.com>
 <4110467b-3405-4c52-90ce-93c63546a2c9@gmail.com>
Message-ID: <AM0PR02MB442037EEE4BC6A035337B22E94042@AM0PR02MB4420.eurprd02.prod.outlook.com>

Thanks a lot both Duncan and Ivan,

I will keep that example in mind, Duncan, great!

Best  regards,
Iago

________________________________
De: Duncan Murdoch <murdoch.duncan at gmail.com>
Enviat el: divendres, 12 d?abril de 2024 15:36
Per a: Iago Gin? V?zquez <iago.gine at sjd.es>; r-help at r-project.org <r-help at r-project.org>
Tema: Re: [R] Debugging functions defined (locally) inside another functions

On 12/04/2024 8:15 a.m., Iago Gin? V?zquez wrote:
> Hi all, I am trying to debug an error of a function g defined and used inside another function f of a package.
> So I have
>
> f <- function(whatever){
>     ...
>     g <- function(whatever2){
>       ...
>     }
>     ...
> }
>
> If I wanted to debug some thing directly inside f I would do debug(f). But this does not go inside g code. On the other hand, debug(g) does not work as g is not a defined function in the namespace of the package.
>
> Is there some way to debug errors inside g?

The easiest case is if you have access to the source code.  Just put a
browser() statement at the start of g, i.e. change it to

      g <- function(whatever2){
        browser()
        ...
      }

and it will break very similarly to what happens if you have set debug(g).

Another possibility if you have the source but don't want to edit it is
to use trace.  Suppose that the definition of g is in source.R at lines
100 to 120.  Then you can run

   setBreakpoint("source.R#101")

to set a breakpoint via trace() just before line 101 runs.  trace() has
lots of options; it can just print things, or call browser(), etc.  They
are available in setBreakpoint().

If you are executing code from a package and you don't have the source
handy it's a bit tedious, but you can still do the search that
setBreakpoint() does to find the source.  For example, let's set a
breakpoint just before the print statement in g in this example:

  f <- function() {
    g <- function() {
      print("this is g")
    }
    print("this is f")
    g()
  }

You need to find the location of that line in f.  Look at as.list(body(f)):

 > as.list(body(f))
[[1]]
`{`

[[2]]
g <- function() {
     print("this is g")
}

[[3]]
print("this is f")

[[4]]
g()

So we need to look within entry 2:

 > as.list(body(f)[[2]])
[[1]]
`<-`

[[2]]
g

[[3]]
function() {
     print("this is g")
}

Continue drilling down:

 > as.list(body(f)[[c(2,3)]])
[[1]]
`function`

[[2]]
NULL

[[3]]
{
     print("this is g")
}

[[4]]
function() {
      print("this is g")
    }

 > as.list(body(f)[[c(2,3, 3)]])
[[1]]
`{`

[[2]]
print("this is g")

So now we know the print statement is at location c(2,3,3,2).  Set a
browser call there:

 > trace(f, at=list(c(2,3,3,2)), tracer = quote(browser()))
[1] "f"
 > body(f)
{
     g <- function() {
         {
             .doTrace(browser(), "step 2,3,3,2")
             print("this is g")
         }
     }
     print("this is f")
     g()
}

Note that the "at" argument needs to be a list to drill down; if you
just said at=c(2,3,3,2) it would set breakpoints at step 2 and 3.

Duncan Murdoch

	[[alternative HTML version deleted]]


From @vi@e@gross m@iii@g oii gm@ii@com  Fri Apr 12 21:52:28 2024
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Fri, 12 Apr 2024 15:52:28 -0400
Subject: [R] any and all
Message-ID: <013601da8d12$f36a2b00$da3e8100$@gmail.com>

Base R has generic functions called any() and all() that I am having trouble
using.
 
It works fine when I play with it in a base R context as in:
 
> all(any(TRUE, TRUE), any(TRUE, FALSE))
[1] TRUE
> all(any(TRUE, TRUE), any(FALSE, FALSE))
[1] FALSE
 
But in a tidyverse/dplyr environment, it returns wrong answers.
 
Consider this example. I have data I have joined together with pairs of
columns representing a first generation and several other pairs representing
additional generations. I want to consider any pair where at least one of
the pair is not NA as a success. But in order to keep the entire row, I want
all three pairs to have some valid data. This seems like a fairly common
reasonable thing often needed when evaluating data.
 
So to make it very general, I chose to do something a bit like this:
 
result <- filter(mydata,
                 all(
                   any(!is.na(first.a), !is.na(first.b)),
                   any(!is.na(second.a), !is.na(second.b)),
                   any(!is.na(third.a), !is.na(third.b))))
 
I apologize if the formatting is not seen properly. The above logically
should work. And it should be extendable to scenarios where you want at
least one of M columns to contain data as a group with N such groups of any
size.
 
But since it did not work, I tried a plan that did work and feels silly. I
used mutate() to make new columns such as:
 
result <-
  mydata |>
  mutate(
    usable.1 = (!is.na(first.a) | !is.na(first.b)),
    usable.2 = (!is.na(second.a) | !is.na(second.b)),
    usable.3 = (!is.na(third.a) | !is.na(third.b)),
    usable = (usable.1 & usable.2 & usable.3)
  ) |>
  filter(usable == TRUE)
 
The above wastes time and effort making new columns so I can check the
calculations then uses the combined columns to make a Boolean that can be
used to filter the result.
 
I know this is not the place to discuss dplyr. I want to check first if I am
doing anything wrong in how I use any/all. One guess is that the generic is
messed with by dplyr or other packages I libraried.
 
And, of course, some aspects of delayed evaluation can interfere in subtle
ways.
 
I note I have had other problems with these base R functions before and
generally solved them by not using them, as shown above. I would much rather
use them, or something similar.
 
 
Avi
 
 

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Apr 12 23:59:33 2024
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 12 Apr 2024 17:59:33 -0400
Subject: [R] any and all
In-Reply-To: <013601da8d12$f36a2b00$da3e8100$@gmail.com>
References: <013601da8d12$f36a2b00$da3e8100$@gmail.com>
Message-ID: <a81ec2d7-817d-4b2c-ab66-e09a13c8dbc1@gmail.com>

On 12/04/2024 3:52 p.m., avi.e.gross at gmail.com wrote:
> Base R has generic functions called any() and all() that I am having trouble
> using.
>   
> It works fine when I play with it in a base R context as in:
>   
>> all(any(TRUE, TRUE), any(TRUE, FALSE))
> [1] TRUE
>> all(any(TRUE, TRUE), any(FALSE, FALSE))
> [1] FALSE
>   
> But in a tidyverse/dplyr environment, it returns wrong answers.
>   
> Consider this example. I have data I have joined together with pairs of
> columns representing a first generation and several other pairs representing
> additional generations. I want to consider any pair where at least one of
> the pair is not NA as a success. But in order to keep the entire row, I want
> all three pairs to have some valid data. This seems like a fairly common
> reasonable thing often needed when evaluating data.
>   
> So to make it very general, I chose to do something a bit like this:

We can't really help you without a reproducible example.  It's not 
enough to show us something that doesn't run but is a bit like the real 
code.

Duncan Murdoch

>   
> result <- filter(mydata,
>                   all(
>                     any(!is.na(first.a), !is.na(first.b)),
>                     any(!is.na(second.a), !is.na(second.b)),
>                     any(!is.na(third.a), !is.na(third.b))))
>   
> I apologize if the formatting is not seen properly. The above logically
> should work. And it should be extendable to scenarios where you want at
> least one of M columns to contain data as a group with N such groups of any
> size.
>   
> But since it did not work, I tried a plan that did work and feels silly. I
> used mutate() to make new columns such as:
>   
> result <-
>    mydata |>
>    mutate(
>      usable.1 = (!is.na(first.a) | !is.na(first.b)),
>      usable.2 = (!is.na(second.a) | !is.na(second.b)),
>      usable.3 = (!is.na(third.a) | !is.na(third.b)),
>      usable = (usable.1 & usable.2 & usable.3)
>    ) |>
>    filter(usable == TRUE)
>   
> The above wastes time and effort making new columns so I can check the
> calculations then uses the combined columns to make a Boolean that can be
> used to filter the result.
>   
> I know this is not the place to discuss dplyr. I want to check first if I am
> doing anything wrong in how I use any/all. One guess is that the generic is
> messed with by dplyr or other packages I libraried.
>   
> And, of course, some aspects of delayed evaluation can interfere in subtle
> ways.
>   
> I note I have had other problems with these base R functions before and
> generally solved them by not using them, as shown above. I would much rather
> use them, or something similar.
>   
>   
> Avi
>   
>   
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From toth@dene@ @end|ng |rom kogentum@hu  Sat Apr 13 00:42:59 2024
From: toth@dene@ @end|ng |rom kogentum@hu (=?UTF-8?B?RMOpbmVzIFTDs3Ro?=)
Date: Sat, 13 Apr 2024 00:42:59 +0200
Subject: [R] any and all
In-Reply-To: <a81ec2d7-817d-4b2c-ab66-e09a13c8dbc1@gmail.com>
References: <013601da8d12$f36a2b00$da3e8100$@gmail.com>
 <a81ec2d7-817d-4b2c-ab66-e09a13c8dbc1@gmail.com>
Message-ID: <8c941713-454b-a3c7-30db-2869f9af93eb@kogentum.hu>

Hi Avi,

As Duncan already mentioned, a reproducible example would be helpful to 
assist you better. Having said that, I think you misunderstand how 
`dplyr::filter` works: it performs row-wise filtering, so the filtering 
expression shall return a logical vector of the same length as the 
data.frame, or must be a single boolean value meaning "keep all" (TRUE) 
or "drop all" (FALSE). If you use `any()` or `all()`, they return a 
single boolean value, so you have an all-or-nothing filter in the end, 
which is probably not what you want.

Note also that you do not need to use `mutate` to use `filter` (read 
?dpylr::filter carefully):
```
filter(
   .data = mydata,
   !is.na(first.a) | !is.na(first.b),
   !is.na(second.a) | !is.na(second.b),
   !is.na(third.a) | !is.na(third.b)
)
```

Or you can use `base::subset()`:
```
subset(
   mydata,
   (!is.na(first.a) | !is.na(first.b))
   & (!is.na(second.a) | !is.na(second.b))
   & (!is.na(third.a) | !is.na(third.b))
)
```

Regards,
Denes

On 4/12/24 23:59, Duncan Murdoch wrote:
> On 12/04/2024 3:52 p.m., avi.e.gross at gmail.com wrote:
>> Base R has generic functions called any() and all() that I am having 
>> trouble
>> using.
>> It works fine when I play with it in a base R context as in:
>>> all(any(TRUE, TRUE), any(TRUE, FALSE))
>> [1] TRUE
>>> all(any(TRUE, TRUE), any(FALSE, FALSE))
>> [1] FALSE
>> But in a tidyverse/dplyr environment, it returns wrong answers.
>> Consider this example. I have data I have joined together with pairs of
>> columns representing a first generation and several other pairs 
>> representing
>> additional generations. I want to consider any pair where at least one of
>> the pair is not NA as a success. But in order to keep the entire row, 
>> I want
>> all three pairs to have some valid data. This seems like a fairly common
>> reasonable thing often needed when evaluating data.
>> So to make it very general, I chose to do something a bit like this:
> 
> We can't really help you without a reproducible example.? It's not 
> enough to show us something that doesn't run but is a bit like the real 
> code.
> 
> Duncan Murdoch
> 
>> result <- filter(mydata,
>> ????????????????? all(
>> ??????????????????? any(!is.na(first.a), !is.na(first.b)),
>> ??????????????????? any(!is.na(second.a), !is.na(second.b)),
>> ??????????????????? any(!is.na(third.a), !is.na(third.b))))
>> I apologize if the formatting is not seen properly. The above logically
>> should work. And it should be extendable to scenarios where you want at
>> least one of M columns to contain data as a group with N such groups 
>> of any
>> size.
>> But since it did not work, I tried a plan that did work and feels 
>> silly. I
>> used mutate() to make new columns such as:
>> result <-
>> ?? mydata |>
>> ?? mutate(
>> ???? usable.1 = (!is.na(first.a) | !is.na(first.b)),
>> ???? usable.2 = (!is.na(second.a) | !is.na(second.b)),
>> ???? usable.3 = (!is.na(third.a) | !is.na(third.b)),
>> ???? usable = (usable.1 & usable.2 & usable.3)
>> ?? ) |>
>> ?? filter(usable == TRUE)
>> The above wastes time and effort making new columns so I can check the
>> calculations then uses the combined columns to make a Boolean that can be
>> used to filter the result.
>> I know this is not the place to discuss dplyr. I want to check first 
>> if I am
>> doing anything wrong in how I use any/all. One guess is that the 
>> generic is
>> messed with by dplyr or other packages I libraried.
>> And, of course, some aspects of delayed evaluation can interfere in 
>> subtle
>> ways.
>> I note I have had other problems with these base R functions before and
>> generally solved them by not using them, as shown above. I would much 
>> rather
>> use them, or something similar.
>> Avi
>>
>> ????[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @vi@e@gross m@iii@g oii gm@ii@com  Sat Apr 13 04:24:30 2024
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Fri, 12 Apr 2024 22:24:30 -0400
Subject: [R] any and all
In-Reply-To: <8c941713-454b-a3c7-30db-2869f9af93eb@kogentum.hu>
References: <013601da8d12$f36a2b00$da3e8100$@gmail.com>
 <a81ec2d7-817d-4b2c-ab66-e09a13c8dbc1@gmail.com>
 <8c941713-454b-a3c7-30db-2869f9af93eb@kogentum.hu>
Message-ID: <001501da8d49$b79400b0$26bc0210$@gmail.com>

Thanks everyone and any/all reading this. I think I got my answer. And, no, I suspected I did not need to provide a very specific example, at least not yet.

The answer is that my experiment was not vectorized while using dplyr verbs like mutate do their work implicitly in a vectorized way. 

This is in some ways similar to the difference between using an if/else type of statement or using the ifelse() function in base R that works on all elements of a vector at once. Some changes to R have been looking at not allowing a vector of length greater than 1 to be used in contexts where formerly only the first element was read and used and the rest ignored.

D?nes asked some other questions about dplyr that I can reply to in private (and if he wishes in Hungarian or other languages we share) as this forum is mainly focused on base R and not on various packages and apparently especially not on the tidyverse that some see as being closely related to a company. Speaking for myself, I see no reason to be wedded to base R and use what I like.

Thanks again. I knew it was simple. And, if anyone cares, I can now look more carefully for functions that do what any/all do but are vectorized because that is basically what I did in my example code where I primitively created new columns in vectorized fashion to impact all rows "at once" as that is one major style of doing things in R. 

Having said that, it is indeed an issue to be cautious with in R as sometimes vectors being used may not be the same length and may even be automatically extended to be so. I also often program in Python and we had a discussion there of what exactly some modules should do if given multiple vectors (or lists or other data structures including generators) and zip the results into tuples when one or another runs out first.

I note that using | versus || and similarly & and && often messes up programs if used wrong. A vectorized any/all and other such verbs as at_least_n() can be very useful but only when used carefully.



-----Original Message-----
From: D?nes T?th <toth.denes at kogentum.hu> 
Sent: Friday, April 12, 2024 6:43 PM
To: Duncan Murdoch <murdoch.duncan at gmail.com>; avi.e.gross at gmail.com; r-help at r-project.org
Subject: Re: [R] any and all

Hi Avi,

As Duncan already mentioned, a reproducible example would be helpful to 
assist you better. Having said that, I think you misunderstand how 
`dplyr::filter` works: it performs row-wise filtering, so the filtering 
expression shall return a logical vector of the same length as the 
data.frame, or must be a single boolean value meaning "keep all" (TRUE) 
or "drop all" (FALSE). If you use `any()` or `all()`, they return a 
single boolean value, so you have an all-or-nothing filter in the end, 
which is probably not what you want.

Note also that you do not need to use `mutate` to use `filter` (read 
?dpylr::filter carefully):
```
filter(
   .data = mydata,
   !is.na(first.a) | !is.na(first.b),
   !is.na(second.a) | !is.na(second.b),
   !is.na(third.a) | !is.na(third.b)
)
```

Or you can use `base::subset()`:
```
subset(
   mydata,
   (!is.na(first.a) | !is.na(first.b))
   & (!is.na(second.a) | !is.na(second.b))
   & (!is.na(third.a) | !is.na(third.b))
)
```

Regards,
Denes

On 4/12/24 23:59, Duncan Murdoch wrote:
> On 12/04/2024 3:52 p.m., avi.e.gross at gmail.com wrote:
>> Base R has generic functions called any() and all() that I am having 
>> trouble
>> using.
>> It works fine when I play with it in a base R context as in:
>>> all(any(TRUE, TRUE), any(TRUE, FALSE))
>> [1] TRUE
>>> all(any(TRUE, TRUE), any(FALSE, FALSE))
>> [1] FALSE
>> But in a tidyverse/dplyr environment, it returns wrong answers.
>> Consider this example. I have data I have joined together with pairs of
>> columns representing a first generation and several other pairs 
>> representing
>> additional generations. I want to consider any pair where at least one of
>> the pair is not NA as a success. But in order to keep the entire row, 
>> I want
>> all three pairs to have some valid data. This seems like a fairly common
>> reasonable thing often needed when evaluating data.
>> So to make it very general, I chose to do something a bit like this:
> 
> We can't really help you without a reproducible example.  It's not 
> enough to show us something that doesn't run but is a bit like the real 
> code.
> 
> Duncan Murdoch
> 
>> result <- filter(mydata,
>>                   all(
>>                     any(!is.na(first.a), !is.na(first.b)),
>>                     any(!is.na(second.a), !is.na(second.b)),
>>                     any(!is.na(third.a), !is.na(third.b))))
>> I apologize if the formatting is not seen properly. The above logically
>> should work. And it should be extendable to scenarios where you want at
>> least one of M columns to contain data as a group with N such groups 
>> of any
>> size.
>> But since it did not work, I tried a plan that did work and feels 
>> silly. I
>> used mutate() to make new columns such as:
>> result <-
>>    mydata |>
>>    mutate(
>>      usable.1 = (!is.na(first.a) | !is.na(first.b)),
>>      usable.2 = (!is.na(second.a) | !is.na(second.b)),
>>      usable.3 = (!is.na(third.a) | !is.na(third.b)),
>>      usable = (usable.1 & usable.2 & usable.3)
>>    ) |>
>>    filter(usable == TRUE)
>> The above wastes time and effort making new columns so I can check the
>> calculations then uses the combined columns to make a Boolean that can be
>> used to filter the result.
>> I know this is not the place to discuss dplyr. I want to check first 
>> if I am
>> doing anything wrong in how I use any/all. One guess is that the 
>> generic is
>> messed with by dplyr or other packages I libraried.
>> And, of course, some aspects of delayed evaluation can interfere in 
>> subtle
>> ways.
>> I note I have had other problems with these base R functions before and
>> generally solved them by not using them, as shown above. I would much 
>> rather
>> use them, or something similar.
>> Avi
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From r@oknz @end|ng |rom gm@||@com  Sat Apr 13 11:54:09 2024
From: r@oknz @end|ng |rom gm@||@com (Richard O'Keefe)
Date: Sat, 13 Apr 2024 21:54:09 +1200
Subject: [R] Just for your (a|be)musement.
Message-ID: <CABcYAdKVc8NiAtKDwACiY6vhPNU41taqEP+Lm=Ur5qsAVH5qaQ@mail.gmail.com>

I recently had the chance to read a book explaining how to use
ChatGPT with a certain programming language.  (I'm not going
to describe the book any more than that because I don't want to
embarrass whoever wrote it.)

They have appendix material showing three queries to ChatGPT
and the answers.  Paraphrased, the queries are "if I throw 2 (3, 4)
fair dice, what is the probability I get 7 or 11?  Show the reasoning."
I thought those questions would make a nice little example,
maybe something for Exercism or RosettaCode.  Here's the R version:

> faces <- 1:6
> sum(rowSums(expand.grid(faces, faces)) %in% c(7,11))/6^2
[1] 0.2222222
> sum(rowSums(expand.grid(faces, faces, faces)) %in% c(7,11))/6^3
[1] 0.1944444
> sum(rowSums(expand.grid(faces, faces, faces, faces)) %in% c(7,11))/6^4
[1] 0.09567901

Here's where it gets amusing.  ChatGPT explained its answers with
great thoroughness.  But its answer to the 3 dice problem, with what
was supposedly a list of success cases, was quite wrong.  ChatGPT
claimed the answer was 33/216 instead of 42/216.

Here's where it gets bemusing.  Whoever wrote the book included
the interaction in the book WITHOUT CHECKING the results, or at
least without commenting on the wrongness of one of them.

I actually wrote the program in 6 other programming languages,
and was startled at how simple and direct it was in base R.
Well done, R.


From |enn@rt@k@@@err@ @end|ng |rom gm@||@com  Sat Apr 13 09:17:11 2024
From: |enn@rt@k@@@err@ @end|ng |rom gm@||@com (Lennart Kasserra)
Date: Sat, 13 Apr 2024 09:17:11 +0200
Subject: [R] any and all
In-Reply-To: <013601da8d12$f36a2b00$da3e8100$@gmail.com>
References: <013601da8d12$f36a2b00$da3e8100$@gmail.com>
Message-ID: <58e33676-8c12-4a0e-9030-15bf4f7391c0@gmail.com>

Hi Avi,


As D?nes T?th has rightly diagnosed, you are building an "all or 
nothing" filter. However, you do not need to explicitly spell out all 
columns that you want to filter for; the "tidy" way would be to use a 
helper function like `if_all()` or `if_any()`. Consider this example (I 
hope I understand your intentions correctly):

```

library(dplyr)


data <- tribble(
 ? ~first.a, ~first.b, ~first.c,
 ? 1L,????? ? 1L,?????? 0L,
 ? NA,?????? 1L,?????? 0L,
 ? 1L,??????? 0L,?????? NA,
 ? NA,?????? NA,?????? 1L
)

```

Let's say we only want to keep rows that have a non-missing value for 
either `first.a` or `first.b` (or hypothetical later generations like 
`second.a` and `second.b` etc.):

```

data |>
 ? filter(if_any(ends_with(c(".a", ".b")), \(x) !is.na(x)))

```

So: `filter()` (keep observations) `if_any` of the columns ending with 
.a or .b is not `NA` (we have to wrap `!is.na` into an anonymous 
function for it to be a valid argument type). This would yield

```

# A tibble: 3 ? 3
 ? first.a first.b first.c
 ??? <int>?? <int>?? <int>
1?????? 1?????? 1?????? 0
2????? NA?????? 1?????? 0
3?????? 1?????? 0????? NA

```

Discarding only the row where both of them are missing. Another way of 
writing this would be

```

data |>
 ? filter(!if_all(ends_with(c(".a", ".b")), is.na))

```

i.e. don't keep rows where all columns ending in .a or .b are `NA`, 
which returns the same result. Hope this helps,

Lennart Kasserra

Am 12.04.24 um 21:52 schrieb avi.e.gross at gmail.com:
> Base R has generic functions called any() and all() that I am having trouble
> using.
>   
> It works fine when I play with it in a base R context as in:
>   
>> all(any(TRUE, TRUE), any(TRUE, FALSE))
> [1] TRUE
>> all(any(TRUE, TRUE), any(FALSE, FALSE))
> [1] FALSE
>   
> But in a tidyverse/dplyr environment, it returns wrong answers.
>   
> Consider this example. I have data I have joined together with pairs of
> columns representing a first generation and several other pairs representing
> additional generations. I want to consider any pair where at least one of
> the pair is not NA as a success. But in order to keep the entire row, I want
> all three pairs to have some valid data. This seems like a fairly common
> reasonable thing often needed when evaluating data.
>   
> So to make it very general, I chose to do something a bit like this:
>   
> result <- filter(mydata,
>                   all(
>                     any(!is.na(first.a), !is.na(first.b)),
>                     any(!is.na(second.a), !is.na(second.b)),
>                     any(!is.na(third.a), !is.na(third.b))))
>   
> I apologize if the formatting is not seen properly. The above logically
> should work. And it should be extendable to scenarios where you want at
> least one of M columns to contain data as a group with N such groups of any
> size.
>   
> But since it did not work, I tried a plan that did work and feels silly. I
> used mutate() to make new columns such as:
>   
> result <-
>    mydata |>
>    mutate(
>      usable.1 = (!is.na(first.a) | !is.na(first.b)),
>      usable.2 = (!is.na(second.a) | !is.na(second.b)),
>      usable.3 = (!is.na(third.a) | !is.na(third.b)),
>      usable = (usable.1 & usable.2 & usable.3)
>    ) |>
>    filter(usable == TRUE)
>   
> The above wastes time and effort making new columns so I can check the
> calculations then uses the combined columns to make a Boolean that can be
> used to filter the result.
>   
> I know this is not the place to discuss dplyr. I want to check first if I am
> doing anything wrong in how I use any/all. One guess is that the generic is
> messed with by dplyr or other packages I libraried.
>   
> And, of course, some aspects of delayed evaluation can interfere in subtle
> ways.
>   
> I note I have had other problems with these base R functions before and
> generally solved them by not using them, as shown above. I would much rather
> use them, or something similar.
>   
>   
> Avi
>   
>   
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @vi@e@gross m@iii@g oii gm@ii@com  Sat Apr 13 16:44:22 2024
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Sat, 13 Apr 2024 10:44:22 -0400
Subject: [R] Just for your (a|be)musement.
In-Reply-To: <CABcYAdKVc8NiAtKDwACiY6vhPNU41taqEP+Lm=Ur5qsAVH5qaQ@mail.gmail.com>
References: <CABcYAdKVc8NiAtKDwACiY6vhPNU41taqEP+Lm=Ur5qsAVH5qaQ@mail.gmail.com>
Message-ID: <003801da8db1$134e0920$39ea1b60$@gmail.com>

Richard,

The code you show is correct and it does not include where you say ChatGTP
explained it was 33/26 rather than the correct 42/216.

I gather it have the proper fraction for the other two scenarios.

So what would cause such a localized error?

The method chosen is to try all possible combinations and count how many
times they add up to a winning combo and then divide by the possible
combinations. Why would that go wrong?

As a human, at least most days, I would calculate using the first part of
the formula it used to just get a numerator.

> sum(rowSums(expand.grid(faces, faces, faces)) %in% c(7,11))
[1] 42

So is this perhaps a case where ChatGTP, instead, did some kind of reverse
engineering and used something else to estimate what 0.1944444 might be as a
fraction with an integral numerator and denominator? There are often many
ways to do this including some that allow an approximation of 7/36 or 42/170
or so. Include the fact that floating point representations are not exact
and it may be it used an algorithm in which it neglected to say it should be
a fraction with a denominator of 216.

If my guess is correct, you could argue this is partially an issue of
comprehension. Humans, to a limited extent, can look at a problem and see
that a solution to a second issue is already almost visible in what they did
to solve the first. A machine who searches data they were fed, may see your
question as having several parts and solves them sequentially using advice
from two places and has an imperfect understanding of what it read in the
second place, or perhaps there was an error there.

This reminds me a bit of the way some computer languages have a sort of
in-line assignment operator in python that was added. The walrus operator
allows parts of an expression to be evaluated and the result stored in a
variable for use elsewhere in that expression or later.  So it you have an
expression that effectively needs to do some calculation two or more times,
such as the sum of some numbers or their average, you do it once and ask for
the number to be saved and then just state you want it elsewhere in the
expression.

Or consider something like the quadratic formula where you calculate the
square root part twice because the two answer are + or - the same thing.

It is often easy for humans to see and extract such commonalities but
programs written so far often are not really designed with examining things
this way.

I note that the above method can be a tad slow and expensive for very large
cases like rolling a hundred dice as you end up making a huge data structure
in which all the entries must sum above 11 if the minimum roll is 1. Again,
a human may realize this and skip using the method. The chances of rolling
100 die and getting a 7 or 11 or even a 99 are absolutely zero. For some
other problems, such as rolling 8 die, there are only solutions for 11, not
for 7. And, rather than generating all possible combinations in advance,
there may be an algorithm that builds a tree with pruning so that a first
toss of 6 or 5 or anything where having all remaining dice at 1 each makes
it go too high (such as 12, makes it skip any further exploration in that
direction. If the current sum is such that the only valid solution is all
ones, again, you can declare that result and prune any further progress
along the tree.

But would chatGTP be flexible enough to suggest using such an algorithm or
know to switch to it for dice above some level?

Can anyone explain better what went wrong? I have heard statements before
about how some of these pseudo-AI make simple mathematical errors and this
sounds like one.



-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Richard O'Keefe
Sent: Saturday, April 13, 2024 5:54 AM
To: R Project Help <r-help at r-project.org>
Subject: [R] Just for your (a|be)musement.

I recently had the chance to read a book explaining how to use
ChatGPT with a certain programming language.  (I'm not going
to describe the book any more than that because I don't want to
embarrass whoever wrote it.)

They have appendix material showing three queries to ChatGPT
and the answers.  Paraphrased, the queries are "if I throw 2 (3, 4)
fair dice, what is the probability I get 7 or 11?  Show the reasoning."
I thought those questions would make a nice little example,
maybe something for Exercism or RosettaCode.  Here's the R version:

> faces <- 1:6
> sum(rowSums(expand.grid(faces, faces)) %in% c(7,11))/6^2
[1] 0.2222222
> sum(rowSums(expand.grid(faces, faces, faces)) %in% c(7,11))/6^3
[1] 0.1944444
> sum(rowSums(expand.grid(faces, faces, faces, faces)) %in% c(7,11))/6^4
[1] 0.09567901

Here's where it gets amusing.  ChatGPT explained its answers with
great thoroughness.  But its answer to the 3 dice problem, with what
was supposedly a list of success cases, was quite wrong.  ChatGPT
claimed the answer was 33/216 instead of 42/216.

Here's where it gets bemusing.  Whoever wrote the book included
the interaction in the book WITHOUT CHECKING the results, or at
least without commenting on the wrongness of one of them.

I actually wrote the program in 6 other programming languages,
and was startled at how simple and direct it was in base R.
Well done, R.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From @vi@e@gross m@iii@g oii gm@ii@com  Sun Apr 14 05:18:06 2024
From: @vi@e@gross m@iii@g oii gm@ii@com (@vi@e@gross m@iii@g oii gm@ii@com)
Date: Sat, 13 Apr 2024 23:18:06 -0400
Subject: [R] any and all
In-Reply-To: <58e33676-8c12-4a0e-9030-15bf4f7391c0@gmail.com>
References: <013601da8d12$f36a2b00$da3e8100$@gmail.com>
 <58e33676-8c12-4a0e-9030-15bf4f7391c0@gmail.com>
Message-ID: <01a601da8e1a$5ee63510$1cb29f30$@gmail.com>

Yes, Lennart, I have been looking at doing something like you say by using the vectorized ways the tidyverse is now offering. 

For my application, if the naming was consistent, an approach like yours is good, albeit has to be typed carefully. When I cannot control the names  but have to lump them into multiple groups that each require at least one to not be NA, I would need to probably spell them out rather than checking what it ends with.

Since the default for filter() is to do an AND when it sees a comma and another condition, I can simply repeat the if_any() with changes several times without using an if_all() but I have concerns over handing over fairly complex code to anyone who may modify it a bit later and have problems.

So, I am tempted to just use things they already know such as one of the ifelse() variations that are vectorized.

The tidyverse keeps evolving and regularly replacing old functionality that seemed to work fine with new and improved but extremely abstract functionality that is both very powerful and at the same time can be a pain to use or even explain when you just want to do something fairly simple. 

And I notice how some packages have been trying to move away from using delayed interpretation features or removing functions people use (or deprecating them) as so many things in R were cobbled together and then constantly changed. Much of the tidyverse is an example of functionality which might have been designed into the base portion of a new language as compared to add-ons to a language they want to keep simpler and more stable. It took a long while just to add a native pipe to R but once done, I wonder if many other ideas and functions people use regularly through packages, might also enter the mainstream.

Your code reminds me of the importance of choosing names, as in column names, that have patterns built-in to allow some abstract operations. In your example, applied to the kind of data I am being given, I can even imagine a step that re-arranges the order of the columns in such a way that the groupings I am talking about are adjacent. (I mean a group of columns where at least one is non-NA.) Such groups can use methods of specifying all at once as in first:last even when I have no control over the names.

Thanks for the feedback.

Avi

-----Original Message-----
From: Lennart Kasserra <lennart.kasserra at gmail.com> 
Sent: Saturday, April 13, 2024 3:17 AM
To: avi.e.gross at gmail.com; murdoch.duncan at gmail.com; toth.denes at kogentum.hu; r-help at r-project.org
Subject: Re: [R] any and all

Hi Avi,


As D?nes T?th has rightly diagnosed, you are building an "all or 
nothing" filter. However, you do not need to explicitly spell out all 
columns that you want to filter for; the "tidy" way would be to use a 
helper function like `if_all()` or `if_any()`. Consider this example (I 
hope I understand your intentions correctly):

```

library(dplyr)


data <- tribble(
   ~first.a, ~first.b, ~first.c,
   1L,        1L,       0L,
   NA,       1L,       0L,
   1L,        0L,       NA,
   NA,       NA,       1L
)

```

Let's say we only want to keep rows that have a non-missing value for 
either `first.a` or `first.b` (or hypothetical later generations like 
`second.a` and `second.b` etc.):

```

data |>
   filter(if_any(ends_with(c(".a", ".b")), \(x) !is.na(x)))

```

So: `filter()` (keep observations) `if_any` of the columns ending with 
.a or .b is not `NA` (we have to wrap `!is.na` into an anonymous 
function for it to be a valid argument type). This would yield

```

# A tibble: 3 ? 3
   first.a first.b first.c
     <int>   <int>   <int>
1       1       1       0
2      NA       1       0
3       1       0      NA

```

Discarding only the row where both of them are missing. Another way of 
writing this would be

```

data |>
   filter(!if_all(ends_with(c(".a", ".b")), is.na))

```

i.e. don't keep rows where all columns ending in .a or .b are `NA`, 
which returns the same result. Hope this helps,

Lennart Kasserra

Am 12.04.24 um 21:52 schrieb avi.e.gross at gmail.com:
> Base R has generic functions called any() and all() that I am having trouble
> using.
>   
> It works fine when I play with it in a base R context as in:
>   
>> all(any(TRUE, TRUE), any(TRUE, FALSE))
> [1] TRUE
>> all(any(TRUE, TRUE), any(FALSE, FALSE))
> [1] FALSE
>   
> But in a tidyverse/dplyr environment, it returns wrong answers.
>   
> Consider this example. I have data I have joined together with pairs of
> columns representing a first generation and several other pairs representing
> additional generations. I want to consider any pair where at least one of
> the pair is not NA as a success. But in order to keep the entire row, I want
> all three pairs to have some valid data. This seems like a fairly common
> reasonable thing often needed when evaluating data.
>   
> So to make it very general, I chose to do something a bit like this:
>   
> result <- filter(mydata,
>                   all(
>                     any(!is.na(first.a), !is.na(first.b)),
>                     any(!is.na(second.a), !is.na(second.b)),
>                     any(!is.na(third.a), !is.na(third.b))))
>   
> I apologize if the formatting is not seen properly. The above logically
> should work. And it should be extendable to scenarios where you want at
> least one of M columns to contain data as a group with N such groups of any
> size.
>   
> But since it did not work, I tried a plan that did work and feels silly. I
> used mutate() to make new columns such as:
>   
> result <-
>    mydata |>
>    mutate(
>      usable.1 = (!is.na(first.a) | !is.na(first.b)),
>      usable.2 = (!is.na(second.a) | !is.na(second.b)),
>      usable.3 = (!is.na(third.a) | !is.na(third.b)),
>      usable = (usable.1 & usable.2 & usable.3)
>    ) |>
>    filter(usable == TRUE)
>   
> The above wastes time and effort making new columns so I can check the
> calculations then uses the combined columns to make a Boolean that can be
> used to filter the result.
>   
> I know this is not the place to discuss dplyr. I want to check first if I am
> doing anything wrong in how I use any/all. One guess is that the generic is
> messed with by dplyr or other packages I libraried.
>   
> And, of course, some aspects of delayed evaluation can interfere in subtle
> ways.
>   
> I note I have had other problems with these base R functions before and
> generally solved them by not using them, as shown above. I would much rather
> use them, or something similar.
>   
>   
> Avi
>   
>   
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


