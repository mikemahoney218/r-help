From jenny@||u00 @end|ng |rom gm@||@com  Mon Apr  1 01:09:35 2019
From: jenny@||u00 @end|ng |rom gm@||@com (Jenny Liu)
Date: Sun, 31 Mar 2019 23:09:35 +0000
Subject: [R] Pairwise testing with pairwise.prop.test
Message-ID: <3c076943-5717-9d2d-42cd-364e5a6f1da7@mixmax.com>

Hi all,

I have a few questions about the pairwise.prop.test function.
I run the test using on the attached dataset (EggMortNoTemp) using the following
code:
EggMatrix<-as.matrix(EggMortNoTemp) #making the egg mortality data a matrix.
pairwise.prop.test needs it to be a matrix 
EggResults<-pairwise.prop.test(EggMatrix) EggResults
I get the attached result (EggResults).
My questions:1) Why is there a "-" instead of a numerical result for pairs 1-2,
1-16, and 2-16?
2) Is there an easy way to export/convert the result to a list with two columns
instead of the matrix? Column 1 would be the pair being compared, and column 2
would be the p-value. For example, Column 1 would say "6-8" so column 2 would
say "0.9532".
3) Is there a way to assign the numbers to the treatment group that they were
originally in? For example, "1" in the result should be "3", indicating that
that was the temperature the experiment took place at. Pairwise.prop.test
doesn't seem to accept matrices with more than 2 columns.
Any help would be greatly appreciated! Thank you in advance.
Cheers,Jenny
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: EggMortNoTemp.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20190331/28163843/attachment.txt>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: EggResults.PNG
Type: image/png
Size: 18797 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20190331/28163843/attachment.png>

From c||35 @end|ng |rom |@u@edu  Mon Apr  1 03:09:16 2019
From: c||35 @end|ng |rom |@u@edu (Chaoyang Li)
Date: Mon, 1 Apr 2019 01:09:16 +0000
Subject: [R] Problems install R package "Caret" in Rstudio version 3.3.3
Message-ID: <10D93FDA-EC62-472C-89FB-277BC342AAA0@lsu.edu>

Hi, everyone,
	I was trying to use the ?caret? for splitting dataset and cross validation function, but I couldn?t install this package and it always gives me following warning:
	Warning in install.packages :
 	 package ?caretEnsembles? is not available (for R version 3.3.3).
	Thank you so much!!

Chaoyang

From jrkr|de@u @end|ng |rom gm@||@com  Mon Apr  1 11:25:22 2019
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Mon, 1 Apr 2019 05:25:22 -0400
Subject: [R] Problems install R package "Caret" in Rstudio version 3.3.3
In-Reply-To: <10D93FDA-EC62-472C-89FB-277BC342AAA0@lsu.edu>
References: <10D93FDA-EC62-472C-89FB-277BC342AAA0@lsu.edu>
Message-ID: <CAKZQJMBWoPrWZcu21suKvFXjuhHfHsxmqF6uf4xhZQ0w+uCuQQ@mail.gmail.com>

Hi Chaoyang,
R 3.3.3 is rather old. If possible you should upgrade to 3.5.3. I
believe 'caret' will install properly under R 3.5.3

On Mon, 1 Apr 2019 at 02:49, Chaoyang Li <cli35 at lsu.edu> wrote:
>
> Hi, everyone,
>         I was trying to use the ?caret? for splitting dataset and cross validation function, but I couldn?t install this package and it always gives me following warning:
>         Warning in install.packages :
>          package ?caretEnsembles? is not available (for R version 3.3.3).
>         Thank you so much!!
>
> Chaoyang
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
John Kane
Kingston ON Canada


From @|mr|t@r@tt@n @end|ng |rom gm@||@com  Mon Apr  1 12:37:17 2019
From: @|mr|t@r@tt@n @end|ng |rom gm@||@com (Simrit Rattan)
Date: Mon, 1 Apr 2019 12:37:17 +0200
Subject: [R] Fwd: Error message: object of type 'closure' is not subsettable
In-Reply-To: <mailman.354171.4127.1554069907.8486.r-help@r-project.org>
References: <mailman.354171.4127.1554069907.8486.r-help@r-project.org>
Message-ID: <CANXqhEBTeNLKEJ_FNr5-Hx2-0PsStknHpDstLodDvRjuS=0YHg@mail.gmail.com>

hey everyone :),
Subject: Re: Error message: object of type 'closure' is not subsettable
I am writing a package which should calculate the binary logistic
regression.
The function itself work perfectly, but if I want to load the function from
my package it gives me the above mentioned error. I have tried a lot of
things, googled and so on, but I can not figure out what to change so it
works. I also found out the mistake lies in the first function
(logisticRegression)

logisticRegression <- function(x,y, threshold = 1e-10, maxIter = 100)
{
  calcPi <- function(x,betaCoef)
  {
    betaCoef <- as.matrix(betaCoef)
    return(exp(x%*%betaCoef)/(1 + exp(x%*%betaCoef)))
  }
  #initial guess for beta (mostly we start with 0)
  betaCoef <- rep(0, ncol(x))

  #some initial value which is bigger than the threshold for the loop
  initialValue <- 10000

  #count of iteration to make sure its not an infinite loop
  iterCount <- 0

  #iteration process (loop)
  while(initialValue > threshold) #convergence test
  {
    #calculates probabilities using the current estimate of beta
    p <- as.vector(calcPi(x, betaCoef))

    #calculates W which is needed for the Hessian
    W <- diag(p*(1-p))

    #calculates the gradient
    gradient <- t(x)%*%(y-p)

    #calculates the hessian
    hessian <- -(t(x)%*%W)%*%x

    #calculates beta
    betaCoef <- betaCoef - solve(hessian) %*% gradient

    #how much did we change beta?
    initialValue <- sum((solve(hessian) %*% gradient)^2)

    #to see if we reached the max # of iteration
    iterCount <- iterCount + 1
    if(iterCount > maxIter) {
      stop("This is not converging")

    }
  }
  #df
  Totaldf <- length(y) - 1
  Residualdf <- length(y) - length(betaCoef)
  degreesOfFreedom <- cbind(Totaldf, Residualdf)
  #fisher information, variance, standard error
  fisherInformation <- -hessian
  vCov <- solve(fisherInformation)
  stdError <- sqrt(diag(vCov))

  #wald test statistic
  waldTestStatistic <- betaCoef/stdError
  pValue <- 2 * pnorm(-abs(waldTestStatistic), mean = 0, sd = 1)

  #loglikelihood and deviance
  logLikelihoodFunction <-  y%*%x%*%betaCoef - sum(log(1+exp(x%*%betaCoef)))
  residualDeviance <- -2*logLikelihoodFunction

  #AIC
  akaikeIC <- residualDeviance + 2*ncol(betaCoef)
  #for R2
  cV <- 2/nrow(x) #for C&S R2

  #deviance residual
  sign1 <- replace(y, y == 0, -1)
  devianceResiduals <- sign1*sqrt(-2*(y*log(p) + (1-y)*log(1-p)))
  residualQuantiles <- summary(devianceResiduals)

  #fitted values
  fittedValues <- log(p/(1-p))
  #what to return
  coefficients <- betaCoef
  output <- list()
  output$degreesF <- Residualdf
  output$nulldf <- Totaldf
  output$fittedValues <- fittedValues
  output$devianceResiduals <- devianceResiduals
  output$residualQuantiles <- residualQuantiles
  output$coefficients <- coefficients
  output$vCov <- vCov
  output$coefMat <- cbind(coefficients,
                          stdError,
                          waldTestStatistic,
                          pValue)
  colnames(output$coefMat) <- c("Estimate",
                                "Std.Err",
                                "z value",
                                "Pr(>|z|)")
  output$logLikelihoodFunction <- logLikelihoodFunction
  output$residualDeviance <- residualDeviance
  output$akaikeIC <- akaikeIC
  output$iterCount <- iterCount -1
  output$p <- p
  output$cV <- cV
  output


}

logReg <- function(formula, data) {
  x <- model.matrix(formula, data)
  regressant <- model.frame(formula, data)
  y <- regressant[,1]
  constant <- matrix(rep(1, length(y)))
  nulllog <- logisticRegression(constant,y)
  nullDeviance <- nulllog$residualDeviance
  nullLogLikelihood <- nulllog$logLikelihoodFunction

  output <- list()
  output <- logisticRegression(x,y)
  output$formula <- formula
  output$nullDeviance <- nullDeviance
  output$nullLogLikelihood <- nullLogLikelihood
  output$call <- match.call()

  #define the S3 class

  class(output) <- "logReg"
  print(output)

}

logReg.default <- function(x, ...) UseMethod("logReg")

print.logReg <- function(x, ...) {
  cat("\nCall:\n")
  print(x$call)
  cat("\nCoefficients:\n")
  colnames(x$coefficients) <- ""
  print(t(x$coefficients), digits = 5)
  cat("\nDegrees of Freedom:",
  paste(x$nulldf, "Total (i.e. Null);", x$degreesF, "Residual"))
  cat("\nNull Deviance:", paste(round(x$nullDeviance, digits = 2)))
  cat("\nResidual Deviance:", paste(round(x$residualDeviance, digits = 2)))
  invisible(x)
}

Thanks for your help! :D




--
Sent from: http://r.789695.n4.nabble.com/R-help-f789696.html

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Mon Apr  1 16:53:59 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 1 Apr 2019 17:53:59 +0300
Subject: [R] 
 Fwd: Error message: object of type 'closure' is not subsettable
In-Reply-To: <CANXqhEBTeNLKEJ_FNr5-Hx2-0PsStknHpDstLodDvRjuS=0YHg@mail.gmail.com>
References: <mailman.354171.4127.1554069907.8486.r-help@r-project.org>
 <CANXqhEBTeNLKEJ_FNr5-Hx2-0PsStknHpDstLodDvRjuS=0YHg@mail.gmail.com>
Message-ID: <CAGgJW77iM8oZ4FmLN4z=UNJrwoAQv=eJ_pdmVwh0h1iBZoHmjA@mail.gmail.com>

You may be calling a function when you think you are referring to an array.
You can reproduce this error message as follows:

f <- function(x) {x}
f[1]

HTH,
Eric


On Mon, Apr 1, 2019 at 5:49 PM Simrit Rattan <simrit.rattan at gmail.com>
wrote:

> hey everyone :),
> Subject: Re: Error message: object of type 'closure' is not subsettable
> I am writing a package which should calculate the binary logistic
> regression.
> The function itself work perfectly, but if I want to load the function from
> my package it gives me the above mentioned error. I have tried a lot of
> things, googled and so on, but I can not figure out what to change so it
> works. I also found out the mistake lies in the first function
> (logisticRegression)
>
> logisticRegression <- function(x,y, threshold = 1e-10, maxIter = 100)
> {
>   calcPi <- function(x,betaCoef)
>   {
>     betaCoef <- as.matrix(betaCoef)
>     return(exp(x%*%betaCoef)/(1 + exp(x%*%betaCoef)))
>   }
>   #initial guess for beta (mostly we start with 0)
>   betaCoef <- rep(0, ncol(x))
>
>   #some initial value which is bigger than the threshold for the loop
>   initialValue <- 10000
>
>   #count of iteration to make sure its not an infinite loop
>   iterCount <- 0
>
>   #iteration process (loop)
>   while(initialValue > threshold) #convergence test
>   {
>     #calculates probabilities using the current estimate of beta
>     p <- as.vector(calcPi(x, betaCoef))
>
>     #calculates W which is needed for the Hessian
>     W <- diag(p*(1-p))
>
>     #calculates the gradient
>     gradient <- t(x)%*%(y-p)
>
>     #calculates the hessian
>     hessian <- -(t(x)%*%W)%*%x
>
>     #calculates beta
>     betaCoef <- betaCoef - solve(hessian) %*% gradient
>
>     #how much did we change beta?
>     initialValue <- sum((solve(hessian) %*% gradient)^2)
>
>     #to see if we reached the max # of iteration
>     iterCount <- iterCount + 1
>     if(iterCount > maxIter) {
>       stop("This is not converging")
>
>     }
>   }
>   #df
>   Totaldf <- length(y) - 1
>   Residualdf <- length(y) - length(betaCoef)
>   degreesOfFreedom <- cbind(Totaldf, Residualdf)
>   #fisher information, variance, standard error
>   fisherInformation <- -hessian
>   vCov <- solve(fisherInformation)
>   stdError <- sqrt(diag(vCov))
>
>   #wald test statistic
>   waldTestStatistic <- betaCoef/stdError
>   pValue <- 2 * pnorm(-abs(waldTestStatistic), mean = 0, sd = 1)
>
>   #loglikelihood and deviance
>   logLikelihoodFunction <-  y%*%x%*%betaCoef -
> sum(log(1+exp(x%*%betaCoef)))
>   residualDeviance <- -2*logLikelihoodFunction
>
>   #AIC
>   akaikeIC <- residualDeviance + 2*ncol(betaCoef)
>   #for R2
>   cV <- 2/nrow(x) #for C&S R2
>
>   #deviance residual
>   sign1 <- replace(y, y == 0, -1)
>   devianceResiduals <- sign1*sqrt(-2*(y*log(p) + (1-y)*log(1-p)))
>   residualQuantiles <- summary(devianceResiduals)
>
>   #fitted values
>   fittedValues <- log(p/(1-p))
>   #what to return
>   coefficients <- betaCoef
>   output <- list()
>   output$degreesF <- Residualdf
>   output$nulldf <- Totaldf
>   output$fittedValues <- fittedValues
>   output$devianceResiduals <- devianceResiduals
>   output$residualQuantiles <- residualQuantiles
>   output$coefficients <- coefficients
>   output$vCov <- vCov
>   output$coefMat <- cbind(coefficients,
>                           stdError,
>                           waldTestStatistic,
>                           pValue)
>   colnames(output$coefMat) <- c("Estimate",
>                                 "Std.Err",
>                                 "z value",
>                                 "Pr(>|z|)")
>   output$logLikelihoodFunction <- logLikelihoodFunction
>   output$residualDeviance <- residualDeviance
>   output$akaikeIC <- akaikeIC
>   output$iterCount <- iterCount -1
>   output$p <- p
>   output$cV <- cV
>   output
>
>
> }
>
> logReg <- function(formula, data) {
>   x <- model.matrix(formula, data)
>   regressant <- model.frame(formula, data)
>   y <- regressant[,1]
>   constant <- matrix(rep(1, length(y)))
>   nulllog <- logisticRegression(constant,y)
>   nullDeviance <- nulllog$residualDeviance
>   nullLogLikelihood <- nulllog$logLikelihoodFunction
>
>   output <- list()
>   output <- logisticRegression(x,y)
>   output$formula <- formula
>   output$nullDeviance <- nullDeviance
>   output$nullLogLikelihood <- nullLogLikelihood
>   output$call <- match.call()
>
>   #define the S3 class
>
>   class(output) <- "logReg"
>   print(output)
>
> }
>
> logReg.default <- function(x, ...) UseMethod("logReg")
>
> print.logReg <- function(x, ...) {
>   cat("\nCall:\n")
>   print(x$call)
>   cat("\nCoefficients:\n")
>   colnames(x$coefficients) <- ""
>   print(t(x$coefficients), digits = 5)
>   cat("\nDegrees of Freedom:",
>   paste(x$nulldf, "Total (i.e. Null);", x$degreesF, "Residual"))
>   cat("\nNull Deviance:", paste(round(x$nullDeviance, digits = 2)))
>   cat("\nResidual Deviance:", paste(round(x$residualDeviance, digits = 2)))
>   invisible(x)
> }
>
> Thanks for your help! :D
>
>
>
>
> --
> Sent from: http://r.789695.n4.nabble.com/R-help-f789696.html
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dc@r|@on @end|ng |rom t@mu@edu  Mon Apr  1 17:53:37 2019
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Mon, 1 Apr 2019 15:53:37 +0000
Subject: [R] Pairwise testing with pairwise.prop.test
In-Reply-To: <3c076943-5717-9d2d-42cd-364e5a6f1da7@mixmax.com>
References: <3c076943-5717-9d2d-42cd-364e5a6f1da7@mixmax.com>
Message-ID: <55bede8d0e454545a9bf7c5014013bf0@tamu.edu>

Inline

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Jenny Liu
> Sent: Sunday, March 31, 2019 6:10 PM
> To: r-help at r-project.org
> Subject: [R] Pairwise testing with pairwise.prop.test
>
> Hi all,
>
> I have a few questions about the pairwise.prop.test function.
> I run the test using on the attached dataset (EggMortNoTemp) using the following
> code:
> EggMatrix<-as.matrix(EggMortNoTemp) #making the egg mortality data a matrix.
> pairwise.prop.test needs it to be a matrix 
> EggResults<-pairwise.prop.test(EggMatrix) EggResults
> I get the attached result (EggResults).
> My questions:1) Why is there a "-" instead of a numerical result for pairs 1-2,
> 1-16, and 2-16?

When the difference between the pair is zero, the p.value is NaN (not a number).

> 2) Is there an easy way to export/convert the result to a list with two columns
> instead of the matrix? Column 1 would be the pair being compared, and column 2
> would be the p-value. For example, Column 1 would say "6-8" so column 2 would
> say "0.9532".

Fairly easy:

idx <- expand.grid(2:16, 1:15)
pair <- as.matrix(idx[idx[,1] > idx[,2], ])
mode(pair) <- "character"
comp <- apply(pair, 1, paste0, collapse="-")
tbl <- data.frame(comp, p.value=EggResults$p.value[pair])
head(tbl)
#   comp      p.value
# 1  2-1          NaN
# 2  3-1 2.706354e-24
# 3  4-1 1.487240e-23
# 4  5-1 1.946384e-31
# 5  6-1 4.888537e-25
# 6  7-1 7.683167e-41

> 3) Is there a way to assign the numbers to the treatment group that they were
> originally in? For example, "1" in the result should be "3", indicating that
> that was the temperature the experiment took place at. Pairwise.prop.test
> doesn't seem to accept matrices with more than 2 columns.

No. The test is to do the pairwise comparisons between the samples. The treatment group is not considered. You would have to use another test that compared the samples by treatment group (instead of pairwise comparisons).

> Any help would be greatly appreciated! Thank you in advance.
> Cheers,Jenny


From jenny@||u00 @end|ng |rom gm@||@com  Mon Apr  1 17:56:21 2019
From: jenny@||u00 @end|ng |rom gm@||@com (Jenny Liu)
Date: Mon, 1 Apr 2019 11:56:21 -0400
Subject: [R] Pairwise testing with pairwise.prop.test
In-Reply-To: <55bede8d0e454545a9bf7c5014013bf0@tamu.edu>
References: <3c076943-5717-9d2d-42cd-364e5a6f1da7@mixmax.com>
 <55bede8d0e454545a9bf7c5014013bf0@tamu.edu>
Message-ID: <CANmGPfDehP12=tezoxVNK1ndYrB_fyNG8=4SJSiADO3D1McWJA@mail.gmail.com>

Thank you very much David, your answers are so clear and helpful!!

Have a great week.

Cheers,
Jenny

On Mon, Apr 1, 2019, 11:53 AM David L Carlson, <dcarlson at tamu.edu> wrote:

> Inline
>
> ----------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77843-4352
>
> -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Jenny Liu
> > Sent: Sunday, March 31, 2019 6:10 PM
> > To: r-help at r-project.org
> > Subject: [R] Pairwise testing with pairwise.prop.test
> >
> > Hi all,
> >
> > I have a few questions about the pairwise.prop.test function.
> > I run the test using on the attached dataset (EggMortNoTemp) using the
> following
> > code:
> > EggMatrix<-as.matrix(EggMortNoTemp) #making the egg mortality data a
> matrix.
> > pairwise.prop.test needs it to be a matrix
> > EggResults<-pairwise.prop.test(EggMatrix) EggResults
> > I get the attached result (EggResults).
> > My questions:1) Why is there a "-" instead of a numerical result for
> pairs 1-2,
> > 1-16, and 2-16?
>
> When the difference between the pair is zero, the p.value is NaN (not a
> number).
>
> > 2) Is there an easy way to export/convert the result to a list with two
> columns
> > instead of the matrix? Column 1 would be the pair being compared, and
> column 2
> > would be the p-value. For example, Column 1 would say "6-8" so column 2
> would
> > say "0.9532".
>
> Fairly easy:
>
> idx <- expand.grid(2:16, 1:15)
> pair <- as.matrix(idx[idx[,1] > idx[,2], ])
> mode(pair) <- "character"
> comp <- apply(pair, 1, paste0, collapse="-")
> tbl <- data.frame(comp, p.value=EggResults$p.value[pair])
> head(tbl)
> #   comp      p.value
> # 1  2-1          NaN
> # 2  3-1 2.706354e-24
> # 3  4-1 1.487240e-23
> # 4  5-1 1.946384e-31
> # 5  6-1 4.888537e-25
> # 6  7-1 7.683167e-41
>
> > 3) Is there a way to assign the numbers to the treatment group that they
> were
> > originally in? For example, "1" in the result should be "3", indicating
> that
> > that was the temperature the experiment took place at. Pairwise.prop.test
> > doesn't seem to accept matrices with more than 2 columns.
>
> No. The test is to do the pairwise comparisons between the samples. The
> treatment group is not considered. You would have to use another test that
> compared the samples by treatment group (instead of pairwise comparisons).
>
> > Any help would be greatly appreciated! Thank you in advance.
> > Cheers,Jenny
>
>

	[[alternative HTML version deleted]]


From S@E|||@on @end|ng |rom LGCGroup@com  Mon Apr  1 18:32:49 2019
From: S@E|||@on @end|ng |rom LGCGroup@com (Stephen Ellison)
Date: Mon, 1 Apr 2019 16:32:49 +0000
Subject: [R] Pairwise testing with pairwise.prop.test
In-Reply-To: <55bede8d0e454545a9bf7c5014013bf0@tamu.edu>
References: <3c076943-5717-9d2d-42cd-364e5a6f1da7@mixmax.com>
 <55bede8d0e454545a9bf7c5014013bf0@tamu.edu>
Message-ID: <ca9eeb6c9b3147ba95e510ef555818f7@GBDCVPEXC04.corp.lgc-group.com>

> > 3) Is there a way to assign the numbers to the treatment group that they
> were
> > originally in? For example, "1" in the result should be "3", indicating that
> > that was the temperature the experiment took place at. Pairwise.prop.test
> > doesn't seem to accept matrices with more than 2 columns.
> 
> No. The test is to do the pairwise comparisons between the samples. 

A possible wrinkle, there: If you know the treatment labels for your group numbers (1...n in a simple htest  p-value matrix), you could relabel the htest p-value matrix via its dimnames property. For example, in the smokers example under ?pairwise.prop.test:

smk.pwtst <- pairwise.prop.test(smokers, patients)
groupnames <- paste("group", 1:4) #This would have to be manual for your example

new.dims <- list(groupnames[1:3],       #we know this is from 1:(n-1)
                                 groupnames[2:4])       #and this is 2:n

dimnames(smk.pwtst$p.value) <- new.dims

smk.pwtst
#         group 1 group 2 group 3
# group 2 1.000   -       -      
# group 3 1.000   1.000   -      
# group 4 0.119   0.093   0.124  

Steve Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From c||35 @end|ng |rom |@u@edu  Tue Apr  2 04:56:51 2019
From: c||35 @end|ng |rom |@u@edu (Chaoyang Li)
Date: Tue, 2 Apr 2019 02:56:51 +0000
Subject: [R] Problem in using train() function in Caret
Message-ID: <DED0134D-D59E-4DFB-89E5-85E9FFC606CF@lsu.edu>

Hi, Everyone,
I have another question with using train() function in Caret package. When I coded 
tree.spam.cv <- train(Label~., data = train_spam_toke_df, methods = "rpart", trControl = cv_spam_control, 
                   tuneLenght = 7)
it gave the error as follow,
Error in terms.formula(formula, data = data) : 
  duplicated name 's.i.m' in data frame using ?.'
I am not sure if there is any bug with my software. I used to have no problem when I wrote lm(y~., data = data1)

Can someone help me with this problem? Thank you so much!

Chaoyang

From pd@|gd @end|ng |rom gm@||@com  Tue Apr  2 13:10:26 2019
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Tue, 2 Apr 2019 13:10:26 +0200
Subject: [R] Pairwise testing with pairwise.prop.test
In-Reply-To: <55bede8d0e454545a9bf7c5014013bf0@tamu.edu>
References: <3c076943-5717-9d2d-42cd-364e5a6f1da7@mixmax.com>
 <55bede8d0e454545a9bf7c5014013bf0@tamu.edu>
Message-ID: <43204B1E-A76F-4D60-B7A0-90E9F0730FC2@gmail.com>

>> My questions:1) Why is there a "-" instead of a numerical result for pairs 1-2,
>> 1-16, and 2-16?
> 
> When the difference between the pair is zero, the p.value is NaN (not a number).
> 

Not quite: When both groups have 0 successes (or both 0 failures), the test stat has a divide-by-zero condition.

>> 2) Is there an easy way to export/convert the result to a list with two columns
>> instead of the matrix? Column 1 would be the pair being compared, and column 2
>> would be the p-value. For example, Column 1 would say "6-8" so column 2 would
>> say "0.9532".
> 
> Fairly easy:
> 
> idx <- expand.grid(2:16, 1:15)
> pair <- as.matrix(idx[idx[,1] > idx[,2], ])
> mode(pair) <- "character"
> comp <- apply(pair, 1, paste0, collapse="-")
> tbl <- data.frame(comp, p.value=EggResults$p.value[pair])
> head(tbl)
> #   comp      p.value
> # 1  2-1          NaN
> # 2  3-1 2.706354e-24
> # 3  4-1 1.487240e-23
> # 4  5-1 1.946384e-31
> # 5  6-1 4.888537e-25
> # 6  7-1 7.683167e-41
> 

Somewhat neater:

> out <- pairwise.prop.test(smokers, patients)
[....]
> pmat <- out$p.value
> ix <- lower.tri(pmat, diag=TRUE)
> R <- rownames(pmat)[row(pmat)[ix]]
> C <- colnames(pmat)[col(pmat)[ix]]
> data.frame(row.vs.col = paste(R,C,sep="-"), adj.p = pmat[ix])
  row.vs.col      adj.p
1        2-1 1.00000000
2        3-1 1.00000000
3        4-1 0.11856482
4        3-2 1.00000000
5        4-2 0.09321728
6        4-3 0.12376805

Also, labeling seems to work if you label the original data appropriately, e.g.

> names(smokers) <- names(patients) <- as.roman(1:4)
> out <- pairwise.prop.test(smokers, patients)
[....]
> ix <- lower.tri(pmat, diag=TRUE)
> pmat <- out$p.value
> R <- rownames(pmat)[row(pmat)[ix]]
> C <- colnames(pmat)[col(pmat)[ix]]
> data.frame(row.vs.col = paste(R,C,sep="-"), adj.p = pmat[ix])
  row.vs.col      adj.p
1       II-I 1.00000000
2      III-I 1.00000000
3       IV-I 0.11856482
4     III-II 1.00000000
5      IV-II 0.09321728
6     IV-III 0.12376805

-pd

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jenny@||u00 @end|ng |rom gm@||@com  Tue Apr  2 19:47:51 2019
From: jenny@||u00 @end|ng |rom gm@||@com (Jenny Liu)
Date: Tue, 02 Apr 2019 17:47:51 +0000
Subject: [R] Pairwise testing with pairwise.prop.test
In-Reply-To: <43204B1E-A76F-4D60-B7A0-90E9F0730FC2@gmail.com>
References: <3c076943-5717-9d2d-42cd-364e5a6f1da7@mixmax.com>
 <55bede8d0e454545a9bf7c5014013bf0@tamu.edu>
 <43204B1E-A76F-4D60-B7A0-90E9F0730FC2@gmail.com>
Message-ID: <882bb849-6a39-4fdc-f2dd-a939fee07f34@mixmax.com>

Thank you Stephen and Peter for your code and your answers!
Stephen, your NaN explanation makes sense - thank you for putting it so clearly.
Cheers,
Jenny






On Tue, Apr 2, 2019 11:10 AM, peter dalgaard pdalgd at gmail.com  wrote:
>> My questions:1) Why is there a "-" instead of a numerical result for pairs
1-2,

>> 1-16, and 2-16?

> 

> When the difference between the pair is zero, the p.value is NaN (not a
number).

> 




Not quite: When both groups have 0 successes (or both 0 failures), the test stat
has a divide-by-zero condition.




>> 2) Is there an easy way to export/convert the result to a list with two
columns

>> instead of the matrix? Column 1 would be the pair being compared, and column
2

>> would be the p-value. For example, Column 1 would say "6-8" so column 2 would

>> say "0.9532".

> 

> Fairly easy:

> 

> idx <- expand.grid(2:16, 1:15)

> pair <- as.matrix(idx[idx[,1] > idx[,2], ])

> mode(pair) <- "character"

> comp <- apply(pair, 1, paste0, collapse="-")

> tbl <- data.frame(comp, p.value=EggResults$p.value[pair])

> head(tbl)

> # comp p.value

> # 1 2-1 NaN

> # 2 3-1 2.706354e-24

> # 3 4-1 1.487240e-23

> # 4 5-1 1.946384e-31

> # 5 6-1 4.888537e-25

> # 6 7-1 7.683167e-41

> 




Somewhat neater:




> out <- pairwise.prop.test(smokers, patients)

[....]

> pmat <- out$p.value

> ix <- lower.tri(pmat, diag=TRUE)

> R <- rownames(pmat)[row(pmat)[ix]]

> C <- colnames(pmat)[col(pmat)[ix]]

> data.frame(row.vs.col = paste(R,C,sep="-"), adj.p = pmat[ix])

  row.vs.col adj.p

1 2-1 1.00000000

2 3-1 1.00000000

3 4-1 0.11856482

4 3-2 1.00000000

5 4-2 0.09321728

6 4-3 0.12376805




Also, labeling seems to work if you label the original data appropriately, e.g.




> names(smokers) <- names(patients) <- as.roman(1:4)

> out <- pairwise.prop.test(smokers, patients)

[....]

> ix <- lower.tri(pmat, diag=TRUE)

> pmat <- out$p.value

> R <- rownames(pmat)[row(pmat)[ix]]

> C <- colnames(pmat)[col(pmat)[ix]]

> data.frame(row.vs.col = paste(R,C,sep="-"), adj.p = pmat[ix])

  row.vs.col adj.p

1 II-I 1.00000000

2 III-I 1.00000000

3 IV-I 0.11856482

4 III-II 1.00000000

5 IV-II 0.09321728

6 IV-III 0.12376805




-pd




-- 

Peter Dalgaard, Professor,

Center for Statistics, Copenhagen Business School

Solbjerg Plads 3, 2000 Frederiksberg, Denmark

Phone: (+45)38153501

Office: A 4.23

Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com
	[[alternative HTML version deleted]]


From er|cwb95 @end|ng |rom gm@||@com  Tue Apr  2 11:12:11 2019
From: er|cwb95 @end|ng |rom gm@||@com (Eric Bridgeford)
Date: Tue, 2 Apr 2019 05:12:11 -0400
Subject: [R] Fwd: Potential Issue with lm.influence
In-Reply-To: <CAGfc6q2VGpAyymnDRVoMij2zD2-ayu+u4WhLRK4EHo4_mT2Xdg@mail.gmail.com>
References: <CAGfc6q2VGpAyymnDRVoMij2zD2-ayu+u4WhLRK4EHo4_mT2Xdg@mail.gmail.com>
Message-ID: <CAGfc6q3V1FgeZT-AaKsrXL13WEYXbduZG3NweE64XGe19Xbeig@mail.gmail.com>

Hi R core team,

I experienced the following issue with the attached data/code snippet,
where the studentized residual for a single observation appears to be NaN
given finite predictors/responses, which appears to be driven by the
glm.influence method in the stats package. I am curious to whether this is
a consequence of the specific implementation used for computing the
influence, which it would appear is the driving force for the NaN influence
for the point, that I was ultimately able to trace back through the
lm.influence method to this specific line
<https://github.com/SurajGupta/r-source/blob/a28e609e72ed7c47f6ddfbb86c85279a0750f0b7/src/library/stats/R/lm.influence.R#L67>
which
calls C code which calls iminfl.f
<https://github.com/SurajGupta/r-source/blob/master/src/library/stats/src/lminfl.f>
(I
don't know fortran so I can't debug further). My understanding is that the
specific issue would have to do with the leave-one-out variance estimate
associated with this particular point, which it seems based on my
understanding should be finite given finite predictors/responses. Let me
know. Thanks!

Sincerely,

-- 
Eric Bridgeford
ericwb.me

From bgunter@4567 @end|ng |rom gm@||@com  Tue Apr  2 21:34:42 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 2 Apr 2019 12:34:42 -0700
Subject: [R] Fwd: Potential Issue with lm.influence
In-Reply-To: <CAGfc6q3V1FgeZT-AaKsrXL13WEYXbduZG3NweE64XGe19Xbeig@mail.gmail.com>
References: <CAGfc6q2VGpAyymnDRVoMij2zD2-ayu+u4WhLRK4EHo4_mT2Xdg@mail.gmail.com>
 <CAGfc6q3V1FgeZT-AaKsrXL13WEYXbduZG3NweE64XGe19Xbeig@mail.gmail.com>
Message-ID: <CAGxFJbR0j6asRCE21Btr+u5-nV0u0LBo63fvqajQinL38qECqw@mail.gmail.com>

Nothing was attached. The r-help server strips most attachments. Include
your code inline.

Also note that

> 0/0
[1] NaN

so maybe something like that occurs in the course of your calculations. But
that's just a guess, so feel free to disregard.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 2, 2019 at 11:32 AM Eric Bridgeford <ericwb95 at gmail.com> wrote:

> Hi R core team,
>
> I experienced the following issue with the attached data/code snippet,
> where the studentized residual for a single observation appears to be NaN
> given finite predictors/responses, which appears to be driven by the
> glm.influence method in the stats package. I am curious to whether this is
> a consequence of the specific implementation used for computing the
> influence, which it would appear is the driving force for the NaN influence
> for the point, that I was ultimately able to trace back through the
> lm.influence method to this specific line
> <
> https://github.com/SurajGupta/r-source/blob/a28e609e72ed7c47f6ddfbb86c85279a0750f0b7/src/library/stats/R/lm.influence.R#L67
> >
> which
> calls C code which calls iminfl.f
> <
> https://github.com/SurajGupta/r-source/blob/master/src/library/stats/src/lminfl.f
> >
> (I
> don't know fortran so I can't debug further). My understanding is that the
> specific issue would have to do with the leave-one-out variance estimate
> associated with this particular point, which it seems based on my
> understanding should be finite given finite predictors/responses. Let me
> know. Thanks!
>
> Sincerely,
>
> --
> Eric Bridgeford
> ericwb.me
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Apr  2 22:29:20 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 2 Apr 2019 13:29:20 -0700
Subject: [R] Fwd: Potential Issue with lm.influence
In-Reply-To: <CAGfc6q0agc=wAQhT6q91LYnO_Qr29CuPB5-OmN-_rwn1QGBsYw@mail.gmail.com>
References: <CAGfc6q2VGpAyymnDRVoMij2zD2-ayu+u4WhLRK4EHo4_mT2Xdg@mail.gmail.com>
 <CAGfc6q3V1FgeZT-AaKsrXL13WEYXbduZG3NweE64XGe19Xbeig@mail.gmail.com>
 <CAGxFJbR0j6asRCE21Btr+u5-nV0u0LBo63fvqajQinL38qECqw@mail.gmail.com>
 <CAGfc6q0agc=wAQhT6q91LYnO_Qr29CuPB5-OmN-_rwn1QGBsYw@mail.gmail.com>
Message-ID: <CAGxFJbRfEPmLYEPqk0ksqi-WGaT4A8Mx2eEdjWJx9W46=tMY8A@mail.gmail.com>

I told you already: **Include code inline **

See ?dput for how to include a text version of objects, such as data
frames, inline.

Otherwise, I believe .txt text files are not stripped if you insist on
*attaching* data or code. Others may have better advice.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 2, 2019 at 1:21 PM Eric Bridgeford <ericwb95 at gmail.com> wrote:

> How can I add attachments? The following two files were attached in the
> initial message
>
> On Tue, Apr 2, 2019 at 3:34 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
>> Nothing was attached. The r-help server strips most attachments. Include
>> your code inline.
>>
>> Also note that
>>
>> > 0/0
>> [1] NaN
>>
>> so maybe something like that occurs in the course of your calculations.
>> But that's just a guess, so feel free to disregard.
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Tue, Apr 2, 2019 at 11:32 AM Eric Bridgeford <ericwb95 at gmail.com>
>> wrote:
>>
>>> Hi R core team,
>>>
>>> I experienced the following issue with the attached data/code snippet,
>>> where the studentized residual for a single observation appears to be NaN
>>> given finite predictors/responses, which appears to be driven by the
>>> glm.influence method in the stats package. I am curious to whether this
>>> is
>>> a consequence of the specific implementation used for computing the
>>> influence, which it would appear is the driving force for the NaN
>>> influence
>>> for the point, that I was ultimately able to trace back through the
>>> lm.influence method to this specific line
>>> <
>>> https://github.com/SurajGupta/r-source/blob/a28e609e72ed7c47f6ddfbb86c85279a0750f0b7/src/library/stats/R/lm.influence.R#L67
>>> >
>>> which
>>> calls C code which calls iminfl.f
>>> <
>>> https://github.com/SurajGupta/r-source/blob/master/src/library/stats/src/lminfl.f
>>> >
>>> (I
>>> don't know fortran so I can't debug further). My understanding is that
>>> the
>>> specific issue would have to do with the leave-one-out variance estimate
>>> associated with this particular point, which it seems based on my
>>> understanding should be finite given finite predictors/responses. Let me
>>> know. Thanks!
>>>
>>> Sincerely,
>>>
>>> --
>>> Eric Bridgeford
>>> ericwb.me
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>
> --
> Eric Bridgeford
> ericwb.me
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Apr  2 22:38:00 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 2 Apr 2019 13:38:00 -0700
Subject: [R] Fwd: Potential Issue with lm.influence
In-Reply-To: <CAGxFJbRfEPmLYEPqk0ksqi-WGaT4A8Mx2eEdjWJx9W46=tMY8A@mail.gmail.com>
References: <CAGfc6q2VGpAyymnDRVoMij2zD2-ayu+u4WhLRK4EHo4_mT2Xdg@mail.gmail.com>
 <CAGfc6q3V1FgeZT-AaKsrXL13WEYXbduZG3NweE64XGe19Xbeig@mail.gmail.com>
 <CAGxFJbR0j6asRCE21Btr+u5-nV0u0LBo63fvqajQinL38qECqw@mail.gmail.com>
 <CAGfc6q0agc=wAQhT6q91LYnO_Qr29CuPB5-OmN-_rwn1QGBsYw@mail.gmail.com>
 <CAGxFJbRfEPmLYEPqk0ksqi-WGaT4A8Mx2eEdjWJx9W46=tMY8A@mail.gmail.com>
Message-ID: <CAGxFJbSJMF2PQY+9HDzczn0omhySK=nAOb2X2G9ZJZeFLSwMWw@mail.gmail.com>

Also, I suggest you read ?influence which may explain the source of your
NaN's .

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 2, 2019 at 1:29 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> I told you already: **Include code inline **
>
> See ?dput for how to include a text version of objects, such as data
> frames, inline.
>
> Otherwise, I believe .txt text files are not stripped if you insist on
> *attaching* data or code. Others may have better advice.
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Apr 2, 2019 at 1:21 PM Eric Bridgeford <ericwb95 at gmail.com> wrote:
>
>> How can I add attachments? The following two files were attached in the
>> initial message
>>
>> On Tue, Apr 2, 2019 at 3:34 PM Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>>
>>> Nothing was attached. The r-help server strips most attachments. Include
>>> your code inline.
>>>
>>> Also note that
>>>
>>> > 0/0
>>> [1] NaN
>>>
>>> so maybe something like that occurs in the course of your calculations.
>>> But that's just a guess, so feel free to disregard.
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Tue, Apr 2, 2019 at 11:32 AM Eric Bridgeford <ericwb95 at gmail.com>
>>> wrote:
>>>
>>>> Hi R core team,
>>>>
>>>> I experienced the following issue with the attached data/code snippet,
>>>> where the studentized residual for a single observation appears to be
>>>> NaN
>>>> given finite predictors/responses, which appears to be driven by the
>>>> glm.influence method in the stats package. I am curious to whether this
>>>> is
>>>> a consequence of the specific implementation used for computing the
>>>> influence, which it would appear is the driving force for the NaN
>>>> influence
>>>> for the point, that I was ultimately able to trace back through the
>>>> lm.influence method to this specific line
>>>> <
>>>> https://github.com/SurajGupta/r-source/blob/a28e609e72ed7c47f6ddfbb86c85279a0750f0b7/src/library/stats/R/lm.influence.R#L67
>>>> >
>>>> which
>>>> calls C code which calls iminfl.f
>>>> <
>>>> https://github.com/SurajGupta/r-source/blob/master/src/library/stats/src/lminfl.f
>>>> >
>>>> (I
>>>> don't know fortran so I can't debug further). My understanding is that
>>>> the
>>>> specific issue would have to do with the leave-one-out variance estimate
>>>> associated with this particular point, which it seems based on my
>>>> understanding should be finite given finite predictors/responses. Let me
>>>> know. Thanks!
>>>>
>>>> Sincerely,
>>>>
>>>> --
>>>> Eric Bridgeford
>>>> ericwb.me
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>
>> --
>> Eric Bridgeford
>> ericwb.me
>>
>

	[[alternative HTML version deleted]]


From @gent@ @end|ng |rom medd@t@|nc@com  Mon Apr  1 21:18:00 2019
From: @gent@ @end|ng |rom medd@t@|nc@com (H)
Date: Mon, 1 Apr 2019 15:18:00 -0400
Subject: [R] Free financial data - equities,
 equity options and ETFs - for quantmod package (or other packages)
Message-ID: <d4164bfa-cc12-6164-1b5c-fcb3a82837e2@meddatainc.com>

I am relatively new to analyzing financial data but have some experience with R. I understand that the data available from Yahoo Finance via its API is often questionable in quality and Google Finance is no longer available.

Although Googling pointed me to some other sources such as Quandl etc., I am curious which other data sources quantmod itself supports for data retrieval, ie via an API, not via downloading and importing CSV-files?

My interest is really US equities, stock options and ETFs - if possible from the same data source...

Pointers to favorite data sources appreciated!

Thank you.


From er|cwb95 @end|ng |rom gm@||@com  Tue Apr  2 22:21:00 2019
From: er|cwb95 @end|ng |rom gm@||@com (Eric Bridgeford)
Date: Tue, 2 Apr 2019 16:21:00 -0400
Subject: [R] Fwd: Potential Issue with lm.influence
In-Reply-To: <CAGxFJbR0j6asRCE21Btr+u5-nV0u0LBo63fvqajQinL38qECqw@mail.gmail.com>
References: <CAGfc6q2VGpAyymnDRVoMij2zD2-ayu+u4WhLRK4EHo4_mT2Xdg@mail.gmail.com>
 <CAGfc6q3V1FgeZT-AaKsrXL13WEYXbduZG3NweE64XGe19Xbeig@mail.gmail.com>
 <CAGxFJbR0j6asRCE21Btr+u5-nV0u0LBo63fvqajQinL38qECqw@mail.gmail.com>
Message-ID: <CAGfc6q0agc=wAQhT6q91LYnO_Qr29CuPB5-OmN-_rwn1QGBsYw@mail.gmail.com>

How can I add attachments? The following two files were attached in the
initial message

On Tue, Apr 2, 2019 at 3:34 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Nothing was attached. The r-help server strips most attachments. Include
> your code inline.
>
> Also note that
>
> > 0/0
> [1] NaN
>
> so maybe something like that occurs in the course of your calculations.
> But that's just a guess, so feel free to disregard.
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Apr 2, 2019 at 11:32 AM Eric Bridgeford <ericwb95 at gmail.com>
> wrote:
>
>> Hi R core team,
>>
>> I experienced the following issue with the attached data/code snippet,
>> where the studentized residual for a single observation appears to be NaN
>> given finite predictors/responses, which appears to be driven by the
>> glm.influence method in the stats package. I am curious to whether this is
>> a consequence of the specific implementation used for computing the
>> influence, which it would appear is the driving force for the NaN
>> influence
>> for the point, that I was ultimately able to trace back through the
>> lm.influence method to this specific line
>> <
>> https://github.com/SurajGupta/r-source/blob/a28e609e72ed7c47f6ddfbb86c85279a0750f0b7/src/library/stats/R/lm.influence.R#L67
>> >
>> which
>> calls C code which calls iminfl.f
>> <
>> https://github.com/SurajGupta/r-source/blob/master/src/library/stats/src/lminfl.f
>> >
>> (I
>> don't know fortran so I can't debug further). My understanding is that the
>> specific issue would have to do with the leave-one-out variance estimate
>> associated with this particular point, which it seems based on my
>> understanding should be finite given finite predictors/responses. Let me
>> know. Thanks!
>>
>> Sincerely,
>>
>> --
>> Eric Bridgeford
>> ericwb.me
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

-- 
Eric Bridgeford
ericwb.me

From er|cwb95 @end|ng |rom gm@||@com  Tue Apr  2 23:00:37 2019
From: er|cwb95 @end|ng |rom gm@||@com (Eric Bridgeford)
Date: Tue, 2 Apr 2019 17:00:37 -0400
Subject: [R] Fwd: Potential Issue with lm.influence
In-Reply-To: <CAGxFJbSJMF2PQY+9HDzczn0omhySK=nAOb2X2G9ZJZeFLSwMWw@mail.gmail.com>
References: <CAGfc6q2VGpAyymnDRVoMij2zD2-ayu+u4WhLRK4EHo4_mT2Xdg@mail.gmail.com>
 <CAGfc6q3V1FgeZT-AaKsrXL13WEYXbduZG3NweE64XGe19Xbeig@mail.gmail.com>
 <CAGxFJbR0j6asRCE21Btr+u5-nV0u0LBo63fvqajQinL38qECqw@mail.gmail.com>
 <CAGfc6q0agc=wAQhT6q91LYnO_Qr29CuPB5-OmN-_rwn1QGBsYw@mail.gmail.com>
 <CAGxFJbRfEPmLYEPqk0ksqi-WGaT4A8Mx2eEdjWJx9W46=tMY8A@mail.gmail.com>
 <CAGxFJbSJMF2PQY+9HDzczn0omhySK=nAOb2X2G9ZJZeFLSwMWw@mail.gmail.com>
Message-ID: <CAGfc6q1-k6jTcTe17BM-9b6_Tcx2bxXP6r9iZsAFBMuRUEoSJQ@mail.gmail.com>

I agree the influence documentation suggests NaNs may result; however, as
these can be manually computed and are, indeed, finite/existing (ie,
computing the held-out influence by manually training n models for n points
to obtain n leave one out influence measures), I don't possibly see how the
function SHOULD return NaN, and given that it is returning NaN, that
suggests to me that there should be either a) Providing an alternative
method to compute them that (may be slower) that returns the correct
results in the even that lm.influence does not return a good approximation
(ie, a command line argument for type="approx" that does the approximation
strategy employed currently, or an alternative type="direct" or something
like that that computes them manually), or b) a heuristic to suggest why
NaNs might result from one's particular inputs/what can be done to fix it
(if the approximation strategy is the source of the problem) or what the
issue is with the data that will cause NaNs. Hence I was looking to start a
discussion around the specific strategy employed to compute the elements.

Below is the code:
moon_data <- structure(list(Name = structure(c(8L, 13L, 2L, 7L, 1L, 5L,
11L,
                                               12L, 9L, 10L, 4L, 6L, 3L),
.Label = c("Ceres ", "Earth", "Eris ",

         "Haumea ", "Jupiter ", "Makemake ", "Mars ", "Mercury ", "Neptune
",

         "Pluto ", "Saturn ", "Uranus ", "Venus "), class = "factor"),
                            Distance = c(0.39, 0.72, 1, 1.52, 2.75, 5.2,
9.54, 19.22,
                                         30.06, 39.5, 43.35, 45.8, 67.7),
Diameter = c(0.382, 0.949,

           1, 0.532, 0.08, 11.209, 9.449, 4.007, 3.883, 0.18, 0.15,

           0.12, 0.19), Mass = c(0.06, 0.82, 1, 0.11, 2e-04, 317.8,

                                 95.2, 14.6, 17.2, 0.0022, 7e-04, 7e-04,
0.0025), Moons = c(0L,


                0L, 1L, 2L, 0L, 64L, 62L, 27L, 13L, 4L, 2L, 0L, 1L), Volume
= c(0.0291869497930152,



    0.447504348276571, 0.523598775598299, 0.0788376225681443,



    0.000268082573106329, 737.393372232996, 441.729261571372,



    33.6865588825666, 30.6549628355953, 0.00305362805928928,



    0.00176714586764426, 0.00090477868423386, 0.00359136400182873


                )), row.names = c(NA, -13L), class = "data.frame")

fit <- glm.nb(Moons ~ Volume, data = moon_data)
rstudent(fit)

fit2 <- update(fit, subset = Name != "Jupiter ")
rstudent(fit2)

influence(fit2)$sigma

#        1        2        3        4        5        7        8        9
     10       11       12       13
# 1.077945 1.077813 1.165025 1.181685 1.077954      NaN 1.044454 1.152110
1.187586 1.181696 1.077954 1.165147

Sincerely,
Eric

On Tue, Apr 2, 2019 at 4:38 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Also, I suggest you read ?influence which may explain the source of your
> NaN's .
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Apr 2, 2019 at 1:29 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
>> I told you already: **Include code inline **
>>
>> See ?dput for how to include a text version of objects, such as data
>> frames, inline.
>>
>> Otherwise, I believe .txt text files are not stripped if you insist on
>> *attaching* data or code. Others may have better advice.
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Tue, Apr 2, 2019 at 1:21 PM Eric Bridgeford <ericwb95 at gmail.com>
>> wrote:
>>
>>> How can I add attachments? The following two files were attached in the
>>> initial message
>>>
>>> On Tue, Apr 2, 2019 at 3:34 PM Bert Gunter <bgunter.4567 at gmail.com>
>>> wrote:
>>>
>>>> Nothing was attached. The r-help server strips most attachments.
>>>> Include your code inline.
>>>>
>>>> Also note that
>>>>
>>>> > 0/0
>>>> [1] NaN
>>>>
>>>> so maybe something like that occurs in the course of your calculations.
>>>> But that's just a guess, so feel free to disregard.
>>>>
>>>>
>>>> Bert Gunter
>>>>
>>>> "The trouble with having an open mind is that people keep coming along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>
>>>>
>>>> On Tue, Apr 2, 2019 at 11:32 AM Eric Bridgeford <ericwb95 at gmail.com>
>>>> wrote:
>>>>
>>>>> Hi R core team,
>>>>>
>>>>> I experienced the following issue with the attached data/code snippet,
>>>>> where the studentized residual for a single observation appears to be
>>>>> NaN
>>>>> given finite predictors/responses, which appears to be driven by the
>>>>> glm.influence method in the stats package. I am curious to whether
>>>>> this is
>>>>> a consequence of the specific implementation used for computing the
>>>>> influence, which it would appear is the driving force for the NaN
>>>>> influence
>>>>> for the point, that I was ultimately able to trace back through the
>>>>> lm.influence method to this specific line
>>>>> <
>>>>> https://github.com/SurajGupta/r-source/blob/a28e609e72ed7c47f6ddfbb86c85279a0750f0b7/src/library/stats/R/lm.influence.R#L67
>>>>> >
>>>>> which
>>>>> calls C code which calls iminfl.f
>>>>> <
>>>>> https://github.com/SurajGupta/r-source/blob/master/src/library/stats/src/lminfl.f
>>>>> >
>>>>> (I
>>>>> don't know fortran so I can't debug further). My understanding is that
>>>>> the
>>>>> specific issue would have to do with the leave-one-out variance
>>>>> estimate
>>>>> associated with this particular point, which it seems based on my
>>>>> understanding should be finite given finite predictors/responses. Let
>>>>> me
>>>>> know. Thanks!
>>>>>
>>>>> Sincerely,
>>>>>
>>>>> --
>>>>> Eric Bridgeford
>>>>> ericwb.me
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>
>>> --
>>> Eric Bridgeford
>>> ericwb.me
>>>
>>

-- 
Eric Bridgeford
ericwb.me

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Wed Apr  3 00:36:08 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 3 Apr 2019 09:36:08 +1100
Subject: [R] Fwd: Potential Issue with lm.influence
In-Reply-To: <CAGfc6q1-k6jTcTe17BM-9b6_Tcx2bxXP6r9iZsAFBMuRUEoSJQ@mail.gmail.com>
References: <CAGfc6q2VGpAyymnDRVoMij2zD2-ayu+u4WhLRK4EHo4_mT2Xdg@mail.gmail.com>
 <CAGfc6q3V1FgeZT-AaKsrXL13WEYXbduZG3NweE64XGe19Xbeig@mail.gmail.com>
 <CAGxFJbR0j6asRCE21Btr+u5-nV0u0LBo63fvqajQinL38qECqw@mail.gmail.com>
 <CAGfc6q0agc=wAQhT6q91LYnO_Qr29CuPB5-OmN-_rwn1QGBsYw@mail.gmail.com>
 <CAGxFJbRfEPmLYEPqk0ksqi-WGaT4A8Mx2eEdjWJx9W46=tMY8A@mail.gmail.com>
 <CAGxFJbSJMF2PQY+9HDzczn0omhySK=nAOb2X2G9ZJZeFLSwMWw@mail.gmail.com>
 <CAGfc6q1-k6jTcTe17BM-9b6_Tcx2bxXP6r9iZsAFBMuRUEoSJQ@mail.gmail.com>
Message-ID: <CA+8X3fXKgsjj+5BQ8GAZiZdBYyMU-fbhaTT=7aRZ6wB5v3Bc-g@mail.gmail.com>

Hi Eric,
When I run your code (using the MASS library) I find that
rstudent(fit2) also returns NaN in the seventh position. Perhaps the
problem is occurring there and not in the "influence" function.

Jim

On Wed, Apr 3, 2019 at 9:12 AM Eric Bridgeford <ericwb95 at gmail.com> wrote:
>
> I agree the influence documentation suggests NaNs may result; however, as
> these can be manually computed and are, indeed, finite/existing (ie,
> computing the held-out influence by manually training n models for n points
> to obtain n leave one out influence measures), I don't possibly see how the
> function SHOULD return NaN, and given that it is returning NaN, that
> suggests to me that there should be either a) Providing an alternative
> method to compute them that (may be slower) that returns the correct
> results in the even that lm.influence does not return a good approximation
> (ie, a command line argument for type="approx" that does the approximation
> strategy employed currently, or an alternative type="direct" or something
> like that that computes them manually), or b) a heuristic to suggest why
> NaNs might result from one's particular inputs/what can be done to fix it
> (if the approximation strategy is the source of the problem) or what the
> issue is with the data that will cause NaNs. Hence I was looking to start a
> discussion around the specific strategy employed to compute the elements.
>
> Below is the code:
> moon_data <- structure(list(Name = structure(c(8L, 13L, 2L, 7L, 1L, 5L,
> 11L,
>                                                12L, 9L, 10L, 4L, 6L, 3L),
> .Label = c("Ceres ", "Earth", "Eris ",
>
>          "Haumea ", "Jupiter ", "Makemake ", "Mars ", "Mercury ", "Neptune
> ",
>
>          "Pluto ", "Saturn ", "Uranus ", "Venus "), class = "factor"),
>                             Distance = c(0.39, 0.72, 1, 1.52, 2.75, 5.2,
> 9.54, 19.22,
>                                          30.06, 39.5, 43.35, 45.8, 67.7),
> Diameter = c(0.382, 0.949,
>
>            1, 0.532, 0.08, 11.209, 9.449, 4.007, 3.883, 0.18, 0.15,
>
>            0.12, 0.19), Mass = c(0.06, 0.82, 1, 0.11, 2e-04, 317.8,
>
>                                  95.2, 14.6, 17.2, 0.0022, 7e-04, 7e-04,
> 0.0025), Moons = c(0L,
>
>
>                 0L, 1L, 2L, 0L, 64L, 62L, 27L, 13L, 4L, 2L, 0L, 1L), Volume
> = c(0.0291869497930152,
>
>
>
>     0.447504348276571, 0.523598775598299, 0.0788376225681443,
>
>
>
>     0.000268082573106329, 737.393372232996, 441.729261571372,
>
>
>
>     33.6865588825666, 30.6549628355953, 0.00305362805928928,
>
>
>
>     0.00176714586764426, 0.00090477868423386, 0.00359136400182873
>
>
>                 )), row.names = c(NA, -13L), class = "data.frame")
>
> fit <- glm.nb(Moons ~ Volume, data = moon_data)
> rstudent(fit)
>
> fit2 <- update(fit, subset = Name != "Jupiter ")
> rstudent(fit2)
>
> influence(fit2)$sigma
>
> #        1        2        3        4        5        7        8        9
>      10       11       12       13
> # 1.077945 1.077813 1.165025 1.181685 1.077954      NaN 1.044454 1.152110
> 1.187586 1.181696 1.077954 1.165147
>
> Sincerely,
> Eric
>


From j|ox @end|ng |rom mcm@@ter@c@  Wed Apr  3 01:53:44 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Tue, 2 Apr 2019 23:53:44 +0000
Subject: [R] Fwd: Potential Issue with lm.influence
In-Reply-To: <23230_1554243133_x32MCCLX018357_CAGfc6q1-k6jTcTe17BM-9b6_Tcx2bxXP6r9iZsAFBMuRUEoSJQ@mail.gmail.com>
References: <CAGfc6q2VGpAyymnDRVoMij2zD2-ayu+u4WhLRK4EHo4_mT2Xdg@mail.gmail.com>
 <CAGfc6q3V1FgeZT-AaKsrXL13WEYXbduZG3NweE64XGe19Xbeig@mail.gmail.com>
 <CAGxFJbR0j6asRCE21Btr+u5-nV0u0LBo63fvqajQinL38qECqw@mail.gmail.com>
 <CAGfc6q0agc=wAQhT6q91LYnO_Qr29CuPB5-OmN-_rwn1QGBsYw@mail.gmail.com>
 <CAGxFJbRfEPmLYEPqk0ksqi-WGaT4A8Mx2eEdjWJx9W46=tMY8A@mail.gmail.com>
 <CAGxFJbSJMF2PQY+9HDzczn0omhySK=nAOb2X2G9ZJZeFLSwMWw@mail.gmail.com>
 <23230_1554243133_x32MCCLX018357_CAGfc6q1-k6jTcTe17BM-9b6_Tcx2bxXP6r9iZsAFBMuRUEoSJQ@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836B3FEE1@FHSDB2D11-2.csu.mcmaster.ca>

Dear Eric,

Have you looked at your data? -- for example:

	plot(log(Moons) ~ Volume, data = moon_data)
	text(log(Moons) ~ Volume, data = moon_data, labels=Name, adj=1, subset = Volume > 400)

The negative-binomial model doesn't look reasonable, does it?

After you eliminate Jupiter there's one very high leverage point left, Saturn. Computing studentized residuals entails an approximation to deleting that as well from the model, so try fitting

	fit3 <- update(fit, subset = !(Name %in% c("Jupiter ", "Saturn ")))
	summary(fit3)

which runs into numeric difficulties.

Then look at:

	plot(log(Moons) ~ Volume, data = moon_data, subset = Volume < 400)

Finally, try

	plot(log(Moons) ~ log(Volume), data = moon_data)
	fit4 <- update(fit2, . ~ log(Volume))
	rstudent(fit4)

I hope this helps,
 John

-----------------------------------------------------------------
John Fox
Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: https://socialsciences.mcmaster.ca/jfox/




> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Eric
> Bridgeford
> Sent: Tuesday, April 2, 2019 5:01 PM
> To: Bert Gunter <bgunter.4567 at gmail.com>
> Cc: R-help <r-help at r-project.org>
> Subject: Re: [R] Fwd: Potential Issue with lm.influence
> 
> I agree the influence documentation suggests NaNs may result; however, as
> these can be manually computed and are, indeed, finite/existing (ie,
> computing the held-out influence by manually training n models for n points
> to obtain n leave one out influence measures), I don't possibly see how the
> function SHOULD return NaN, and given that it is returning NaN, that
> suggests to me that there should be either a) Providing an alternative
> method to compute them that (may be slower) that returns the correct
> results in the even that lm.influence does not return a good approximation
> (ie, a command line argument for type="approx" that does the
> approximation strategy employed currently, or an alternative type="direct"
> or something like that that computes them manually), or b) a heuristic to
> suggest why NaNs might result from one's particular inputs/what can be
> done to fix it (if the approximation strategy is the source of the problem) or
> what the issue is with the data that will cause NaNs. Hence I was looking to
> start a discussion around the specific strategy employed to compute the
> elements.
> 
> Below is the code:
> moon_data <- structure(list(Name = structure(c(8L, 13L, 2L, 7L, 1L, 5L, 11L,
>                                                12L, 9L, 10L, 4L, 6L, 3L), .Label = c("Ceres ", "Earth",
> "Eris ",
> 
>          "Haumea ", "Jupiter ", "Makemake ", "Mars ", "Mercury ", "Neptune ",
> 
>          "Pluto ", "Saturn ", "Uranus ", "Venus "), class = "factor"),
>                             Distance = c(0.39, 0.72, 1, 1.52, 2.75, 5.2, 9.54, 19.22,
>                                          30.06, 39.5, 43.35, 45.8, 67.7), Diameter = c(0.382, 0.949,
> 
>            1, 0.532, 0.08, 11.209, 9.449, 4.007, 3.883, 0.18, 0.15,
> 
>            0.12, 0.19), Mass = c(0.06, 0.82, 1, 0.11, 2e-04, 317.8,
> 
>                                  95.2, 14.6, 17.2, 0.0022, 7e-04, 7e-04, 0.0025), Moons = c(0L,
> 
> 
>                 0L, 1L, 2L, 0L, 64L, 62L, 27L, 13L, 4L, 2L, 0L, 1L), Volume =
> c(0.0291869497930152,
> 
> 
> 
>     0.447504348276571, 0.523598775598299, 0.0788376225681443,
> 
> 
> 
>     0.000268082573106329, 737.393372232996, 441.729261571372,
> 
> 
> 
>     33.6865588825666, 30.6549628355953, 0.00305362805928928,
> 
> 
> 
>     0.00176714586764426, 0.00090477868423386, 0.00359136400182873
> 
> 
>                 )), row.names = c(NA, -13L), class = "data.frame")
> 
> fit <- glm.nb(Moons ~ Volume, data = moon_data)
> rstudent(fit)
> 
> fit2 <- update(fit, subset = Name != "Jupiter ")
> rstudent(fit2)
> 
> influence(fit2)$sigma
> 
> #        1        2        3        4        5        7        8        9
>      10       11       12       13
> # 1.077945 1.077813 1.165025 1.181685 1.077954      NaN 1.044454 1.152110
> 1.187586 1.181696 1.077954 1.165147
> 
> Sincerely,
> Eric
> 
> On Tue, Apr 2, 2019 at 4:38 PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> 
> > Also, I suggest you read ?influence which may explain the source of
> > your NaN's .
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> > and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Tue, Apr 2, 2019 at 1:29 PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >
> >> I told you already: **Include code inline **
> >>
> >> See ?dput for how to include a text version of objects, such as data
> >> frames, inline.
> >>
> >> Otherwise, I believe .txt text files are not stripped if you insist
> >> on
> >> *attaching* data or code. Others may have better advice.
> >>
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming
> >> along and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Tue, Apr 2, 2019 at 1:21 PM Eric Bridgeford <ericwb95 at gmail.com>
> >> wrote:
> >>
> >>> How can I add attachments? The following two files were attached in
> >>> the initial message
> >>>
> >>> On Tue, Apr 2, 2019 at 3:34 PM Bert Gunter <bgunter.4567 at gmail.com>
> >>> wrote:
> >>>
> >>>> Nothing was attached. The r-help server strips most attachments.
> >>>> Include your code inline.
> >>>>
> >>>> Also note that
> >>>>
> >>>> > 0/0
> >>>> [1] NaN
> >>>>
> >>>> so maybe something like that occurs in the course of your calculations.
> >>>> But that's just a guess, so feel free to disregard.
> >>>>
> >>>>
> >>>> Bert Gunter
> >>>>
> >>>> "The trouble with having an open mind is that people keep coming
> >>>> along and sticking things into it."
> >>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>>
> >>>>
> >>>> On Tue, Apr 2, 2019 at 11:32 AM Eric Bridgeford
> >>>> <ericwb95 at gmail.com>
> >>>> wrote:
> >>>>
> >>>>> Hi R core team,
> >>>>>
> >>>>> I experienced the following issue with the attached data/code
> >>>>> snippet, where the studentized residual for a single observation
> >>>>> appears to be NaN given finite predictors/responses, which appears
> >>>>> to be driven by the glm.influence method in the stats package. I
> >>>>> am curious to whether this is a consequence of the specific
> >>>>> implementation used for computing the influence, which it would
> >>>>> appear is the driving force for the NaN influence for the point,
> >>>>> that I was ultimately able to trace back through the lm.influence
> >>>>> method to this specific line <
> >>>>> https://github.com/SurajGupta/r-
> source/blob/a28e609e72ed7c47f6ddfb
> >>>>> b86c85279a0750f0b7/src/library/stats/R/lm.influence.R#L67
> >>>>> >
> >>>>> which
> >>>>> calls C code which calls iminfl.f
> >>>>> <
> >>>>> https://github.com/SurajGupta/r-source/blob/master/src/library/sta
> >>>>> ts/src/lminfl.f
> >>>>> >
> >>>>> (I
> >>>>> don't know fortran so I can't debug further). My understanding is
> >>>>> that the specific issue would have to do with the leave-one-out
> >>>>> variance estimate associated with this particular point, which it
> >>>>> seems based on my understanding should be finite given finite
> >>>>> predictors/responses. Let me know. Thanks!
> >>>>>
> >>>>> Sincerely,
> >>>>>
> >>>>> --
> >>>>> Eric Bridgeford
> >>>>> ericwb.me
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide
> >>>>> http://www.R-project.org/posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>
> >>>>
> >>>
> >>> --
> >>> Eric Bridgeford
> >>> ericwb.me
> >>>
> >>
> 
> --
> Eric Bridgeford
> ericwb.me
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From er|cjberger @end|ng |rom gm@||@com  Wed Apr  3 09:12:56 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 3 Apr 2019 10:12:56 +0300
Subject: [R] Free financial data - equities,
 equity options and ETFs - for quantmod package (or other packages)
In-Reply-To: <d4164bfa-cc12-6164-1b5c-fcb3a82837e2@meddatainc.com>
References: <d4164bfa-cc12-6164-1b5c-fcb3a82837e2@meddatainc.com>
Message-ID: <CAGgJW75usFVG9HmNQHQsodnNhhc9o5f2s2a5PYOj9r=bkkOwaA@mail.gmail.com>

You might want to post this to the group R-Sig-Finance
https://stat.ethz.ch/mailman/listinfo/r-sig-finance

 and also check their archives


On Wed, Apr 3, 2019 at 1:11 AM H <agents at meddatainc.com> wrote:

> I am relatively new to analyzing financial data but have some experience
> with R. I understand that the data available from Yahoo Finance via its API
> is often questionable in quality and Google Finance is no longer available.
>
> Although Googling pointed me to some other sources such as Quandl etc., I
> am curious which other data sources quantmod itself supports for data
> retrieval, ie via an API, not via downloading and importing CSV-files?
>
> My interest is really US equities, stock options and ETFs - if possible
> from the same data source...
>
> Pointers to favorite data sources appreciated!
>
> Thank you.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Wed Apr  3 11:36:02 2019
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Wed, 3 Apr 2019 11:36:02 +0200
Subject: [R] Fwd: Potential Issue with lm.influence
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836B3FEE1@FHSDB2D11-2.csu.mcmaster.ca>
References: <CAGfc6q2VGpAyymnDRVoMij2zD2-ayu+u4WhLRK4EHo4_mT2Xdg@mail.gmail.com>
 <CAGfc6q3V1FgeZT-AaKsrXL13WEYXbduZG3NweE64XGe19Xbeig@mail.gmail.com>
 <CAGxFJbR0j6asRCE21Btr+u5-nV0u0LBo63fvqajQinL38qECqw@mail.gmail.com>
 <CAGfc6q0agc=wAQhT6q91LYnO_Qr29CuPB5-OmN-_rwn1QGBsYw@mail.gmail.com>
 <CAGxFJbRfEPmLYEPqk0ksqi-WGaT4A8Mx2eEdjWJx9W46=tMY8A@mail.gmail.com>
 <CAGxFJbSJMF2PQY+9HDzczn0omhySK=nAOb2X2G9ZJZeFLSwMWw@mail.gmail.com>
 <23230_1554243133_x32MCCLX018357_CAGfc6q1-k6jTcTe17BM-9b6_Tcx2bxXP6r9iZsAFBMuRUEoSJQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836B3FEE1@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <327629FB-15B2-4CF8-90B5-8221068BC099@gmail.com>

Yes, also notice that 

> predict(fit3, new=moon_data, type="resp")
           1            2            3            4            5            6 
1.060694e+00 1.102008e+00 1.109695e+00 1.065515e+00 1.057896e+00 1.892312e+29 
           7            8            9           10           11           12 
3.531271e+17 2.295015e+01 1.739889e+01 1.058165e+00 1.058041e+00 1.057957e+00 
          13 
1.058217e+00 


so the model of fit3 predicts that Jupiter and Saturn should have several bazillions of moons each!

-pd



> On 3 Apr 2019, at 01:53 , Fox, John <jfox at mcmaster.ca> wrote:
> 
> Dear Eric,
> 
> Have you looked at your data? -- for example:
> 
> 	plot(log(Moons) ~ Volume, data = moon_data)
> 	text(log(Moons) ~ Volume, data = moon_data, labels=Name, adj=1, subset = Volume > 400)
> 
> The negative-binomial model doesn't look reasonable, does it?
> 
> After you eliminate Jupiter there's one very high leverage point left, Saturn. Computing studentized residuals entails an approximation to deleting that as well from the model, so try fitting
> 
> 	fit3 <- update(fit, subset = !(Name %in% c("Jupiter ", "Saturn ")))
> 	summary(fit3)
> 
> which runs into numeric difficulties.
> 
> Then look at:
> 
> 	plot(log(Moons) ~ Volume, data = moon_data, subset = Volume < 400)
> 
> Finally, try
> 
> 	plot(log(Moons) ~ log(Volume), data = moon_data)
> 	fit4 <- update(fit2, . ~ log(Volume))
> 	rstudent(fit4)
> 
> I hope this helps,
> John
> 
> -----------------------------------------------------------------
> John Fox
> Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> Web: https://socialsciences.mcmaster.ca/jfox/
> 
> 
> 
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Eric
>> Bridgeford
>> Sent: Tuesday, April 2, 2019 5:01 PM
>> To: Bert Gunter <bgunter.4567 at gmail.com>
>> Cc: R-help <r-help at r-project.org>
>> Subject: Re: [R] Fwd: Potential Issue with lm.influence
>> 
>> I agree the influence documentation suggests NaNs may result; however, as
>> these can be manually computed and are, indeed, finite/existing (ie,
>> computing the held-out influence by manually training n models for n points
>> to obtain n leave one out influence measures), I don't possibly see how the
>> function SHOULD return NaN, and given that it is returning NaN, that
>> suggests to me that there should be either a) Providing an alternative
>> method to compute them that (may be slower) that returns the correct
>> results in the even that lm.influence does not return a good approximation
>> (ie, a command line argument for type="approx" that does the
>> approximation strategy employed currently, or an alternative type="direct"
>> or something like that that computes them manually), or b) a heuristic to
>> suggest why NaNs might result from one's particular inputs/what can be
>> done to fix it (if the approximation strategy is the source of the problem) or
>> what the issue is with the data that will cause NaNs. Hence I was looking to
>> start a discussion around the specific strategy employed to compute the
>> elements.
>> 
>> Below is the code:
>> moon_data <- structure(list(Name = structure(c(8L, 13L, 2L, 7L, 1L, 5L, 11L,
>>                                               12L, 9L, 10L, 4L, 6L, 3L), .Label = c("Ceres ", "Earth",
>> "Eris ",
>> 
>>         "Haumea ", "Jupiter ", "Makemake ", "Mars ", "Mercury ", "Neptune ",
>> 
>>         "Pluto ", "Saturn ", "Uranus ", "Venus "), class = "factor"),
>>                            Distance = c(0.39, 0.72, 1, 1.52, 2.75, 5.2, 9.54, 19.22,
>>                                         30.06, 39.5, 43.35, 45.8, 67.7), Diameter = c(0.382, 0.949,
>> 
>>           1, 0.532, 0.08, 11.209, 9.449, 4.007, 3.883, 0.18, 0.15,
>> 
>>           0.12, 0.19), Mass = c(0.06, 0.82, 1, 0.11, 2e-04, 317.8,
>> 
>>                                 95.2, 14.6, 17.2, 0.0022, 7e-04, 7e-04, 0.0025), Moons = c(0L,
>> 
>> 
>>                0L, 1L, 2L, 0L, 64L, 62L, 27L, 13L, 4L, 2L, 0L, 1L), Volume =
>> c(0.0291869497930152,
>> 
>> 
>> 
>>    0.447504348276571, 0.523598775598299, 0.0788376225681443,
>> 
>> 
>> 
>>    0.000268082573106329, 737.393372232996, 441.729261571372,
>> 
>> 
>> 
>>    33.6865588825666, 30.6549628355953, 0.00305362805928928,
>> 
>> 
>> 
>>    0.00176714586764426, 0.00090477868423386, 0.00359136400182873
>> 
>> 
>>                )), row.names = c(NA, -13L), class = "data.frame")
>> 
>> fit <- glm.nb(Moons ~ Volume, data = moon_data)
>> rstudent(fit)
>> 
>> fit2 <- update(fit, subset = Name != "Jupiter ")
>> rstudent(fit2)
>> 
>> influence(fit2)$sigma
>> 
>> #        1        2        3        4        5        7        8        9
>>     10       11       12       13
>> # 1.077945 1.077813 1.165025 1.181685 1.077954      NaN 1.044454 1.152110
>> 1.187586 1.181696 1.077954 1.165147
>> 
>> Sincerely,
>> Eric
>> 
>> On Tue, Apr 2, 2019 at 4:38 PM Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>> 
>>> Also, I suggest you read ?influence which may explain the source of
>>> your NaN's .
>>> 
>>> Bert Gunter
>>> 
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> 
>>> 
>>> On Tue, Apr 2, 2019 at 1:29 PM Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>>> 
>>>> I told you already: **Include code inline **
>>>> 
>>>> See ?dput for how to include a text version of objects, such as data
>>>> frames, inline.
>>>> 
>>>> Otherwise, I believe .txt text files are not stripped if you insist
>>>> on
>>>> *attaching* data or code. Others may have better advice.
>>>> 
>>>> 
>>>> Bert Gunter
>>>> 
>>>> "The trouble with having an open mind is that people keep coming
>>>> along and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>> 
>>>> 
>>>> On Tue, Apr 2, 2019 at 1:21 PM Eric Bridgeford <ericwb95 at gmail.com>
>>>> wrote:
>>>> 
>>>>> How can I add attachments? The following two files were attached in
>>>>> the initial message
>>>>> 
>>>>> On Tue, Apr 2, 2019 at 3:34 PM Bert Gunter <bgunter.4567 at gmail.com>
>>>>> wrote:
>>>>> 
>>>>>> Nothing was attached. The r-help server strips most attachments.
>>>>>> Include your code inline.
>>>>>> 
>>>>>> Also note that
>>>>>> 
>>>>>>> 0/0
>>>>>> [1] NaN
>>>>>> 
>>>>>> so maybe something like that occurs in the course of your calculations.
>>>>>> But that's just a guess, so feel free to disregard.
>>>>>> 
>>>>>> 
>>>>>> Bert Gunter
>>>>>> 
>>>>>> "The trouble with having an open mind is that people keep coming
>>>>>> along and sticking things into it."
>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>> 
>>>>>> 
>>>>>> On Tue, Apr 2, 2019 at 11:32 AM Eric Bridgeford
>>>>>> <ericwb95 at gmail.com>
>>>>>> wrote:
>>>>>> 
>>>>>>> Hi R core team,
>>>>>>> 
>>>>>>> I experienced the following issue with the attached data/code
>>>>>>> snippet, where the studentized residual for a single observation
>>>>>>> appears to be NaN given finite predictors/responses, which appears
>>>>>>> to be driven by the glm.influence method in the stats package. I
>>>>>>> am curious to whether this is a consequence of the specific
>>>>>>> implementation used for computing the influence, which it would
>>>>>>> appear is the driving force for the NaN influence for the point,
>>>>>>> that I was ultimately able to trace back through the lm.influence
>>>>>>> method to this specific line <
>>>>>>> https://github.com/SurajGupta/r-
>> source/blob/a28e609e72ed7c47f6ddfb
>>>>>>> b86c85279a0750f0b7/src/library/stats/R/lm.influence.R#L67
>>>>>>>> 
>>>>>>> which
>>>>>>> calls C code which calls iminfl.f
>>>>>>> <
>>>>>>> https://github.com/SurajGupta/r-source/blob/master/src/library/sta
>>>>>>> ts/src/lminfl.f
>>>>>>>> 
>>>>>>> (I
>>>>>>> don't know fortran so I can't debug further). My understanding is
>>>>>>> that the specific issue would have to do with the leave-one-out
>>>>>>> variance estimate associated with this particular point, which it
>>>>>>> seems based on my understanding should be finite given finite
>>>>>>> predictors/responses. Let me know. Thanks!
>>>>>>> 
>>>>>>> Sincerely,
>>>>>>> 
>>>>>>> --
>>>>>>> Eric Bridgeford
>>>>>>> ericwb.me
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>> 
>>>>>> 
>>>>> 
>>>>> --
>>>>> Eric Bridgeford
>>>>> ericwb.me
>>>>> 
>>>> 
>> 
>> --
>> Eric Bridgeford
>> ericwb.me
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From er|cwb95 @end|ng |rom gm@||@com  Wed Apr  3 00:53:11 2019
From: er|cwb95 @end|ng |rom gm@||@com (Eric Bridgeford)
Date: Tue, 2 Apr 2019 18:53:11 -0400
Subject: [R] Fwd: Potential Issue with lm.influence
In-Reply-To: <CA+8X3fXKgsjj+5BQ8GAZiZdBYyMU-fbhaTT=7aRZ6wB5v3Bc-g@mail.gmail.com>
References: <CAGfc6q2VGpAyymnDRVoMij2zD2-ayu+u4WhLRK4EHo4_mT2Xdg@mail.gmail.com>
 <CAGfc6q3V1FgeZT-AaKsrXL13WEYXbduZG3NweE64XGe19Xbeig@mail.gmail.com>
 <CAGxFJbR0j6asRCE21Btr+u5-nV0u0LBo63fvqajQinL38qECqw@mail.gmail.com>
 <CAGfc6q0agc=wAQhT6q91LYnO_Qr29CuPB5-OmN-_rwn1QGBsYw@mail.gmail.com>
 <CAGxFJbRfEPmLYEPqk0ksqi-WGaT4A8Mx2eEdjWJx9W46=tMY8A@mail.gmail.com>
 <CAGxFJbSJMF2PQY+9HDzczn0omhySK=nAOb2X2G9ZJZeFLSwMWw@mail.gmail.com>
 <CAGfc6q1-k6jTcTe17BM-9b6_Tcx2bxXP6r9iZsAFBMuRUEoSJQ@mail.gmail.com>
 <CA+8X3fXKgsjj+5BQ8GAZiZdBYyMU-fbhaTT=7aRZ6wB5v3Bc-g@mail.gmail.com>
Message-ID: <CAGfc6q2T3_qpDEW52u+JTxgLgMKt90bOivgxaeV4sVRx=7XtSQ@mail.gmail.com>

rstudent calls influence, to my knowledge, and all of the results passed by
rstudent are dependent on values returned by influence (other than the
weights, which I can't imagine are NaN), so I believe that influence is the
issue. See the line
https://github.com/SurajGupta/r-source/blob/a28e609e72ed7c47f6ddfbb86c85279a0750f0b7/src/library/stats/R/lm.influence.R#L135
.

Eric

On Tue, Apr 2, 2019 at 6:36 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Eric,
> When I run your code (using the MASS library) I find that
> rstudent(fit2) also returns NaN in the seventh position. Perhaps the
> problem is occurring there and not in the "influence" function.
>
> Jim
>
> On Wed, Apr 3, 2019 at 9:12 AM Eric Bridgeford <ericwb95 at gmail.com> wrote:
> >
> > I agree the influence documentation suggests NaNs may result; however, as
> > these can be manually computed and are, indeed, finite/existing (ie,
> > computing the held-out influence by manually training n models for n
> points
> > to obtain n leave one out influence measures), I don't possibly see how
> the
> > function SHOULD return NaN, and given that it is returning NaN, that
> > suggests to me that there should be either a) Providing an alternative
> > method to compute them that (may be slower) that returns the correct
> > results in the even that lm.influence does not return a good
> approximation
> > (ie, a command line argument for type="approx" that does the
> approximation
> > strategy employed currently, or an alternative type="direct" or something
> > like that that computes them manually), or b) a heuristic to suggest why
> > NaNs might result from one's particular inputs/what can be done to fix it
> > (if the approximation strategy is the source of the problem) or what the
> > issue is with the data that will cause NaNs. Hence I was looking to
> start a
> > discussion around the specific strategy employed to compute the elements.
> >
> > Below is the code:
> > moon_data <- structure(list(Name = structure(c(8L, 13L, 2L, 7L, 1L, 5L,
> > 11L,
> >                                                12L, 9L, 10L, 4L, 6L, 3L),
> > .Label = c("Ceres ", "Earth", "Eris ",
> >
> >          "Haumea ", "Jupiter ", "Makemake ", "Mars ", "Mercury ",
> "Neptune
> > ",
> >
> >          "Pluto ", "Saturn ", "Uranus ", "Venus "), class = "factor"),
> >                             Distance = c(0.39, 0.72, 1, 1.52, 2.75, 5.2,
> > 9.54, 19.22,
> >                                          30.06, 39.5, 43.35, 45.8, 67.7),
> > Diameter = c(0.382, 0.949,
> >
> >            1, 0.532, 0.08, 11.209, 9.449, 4.007, 3.883, 0.18, 0.15,
> >
> >            0.12, 0.19), Mass = c(0.06, 0.82, 1, 0.11, 2e-04, 317.8,
> >
> >                                  95.2, 14.6, 17.2, 0.0022, 7e-04, 7e-04,
> > 0.0025), Moons = c(0L,
> >
> >
> >                 0L, 1L, 2L, 0L, 64L, 62L, 27L, 13L, 4L, 2L, 0L, 1L),
> Volume
> > = c(0.0291869497930152,
> >
> >
> >
> >     0.447504348276571, 0.523598775598299, 0.0788376225681443,
> >
> >
> >
> >     0.000268082573106329, 737.393372232996, 441.729261571372,
> >
> >
> >
> >     33.6865588825666, 30.6549628355953, 0.00305362805928928,
> >
> >
> >
> >     0.00176714586764426, 0.00090477868423386, 0.00359136400182873
> >
> >
> >                 )), row.names = c(NA, -13L), class = "data.frame")
> >
> > fit <- glm.nb(Moons ~ Volume, data = moon_data)
> > rstudent(fit)
> >
> > fit2 <- update(fit, subset = Name != "Jupiter ")
> > rstudent(fit2)
> >
> > influence(fit2)$sigma
> >
> > #        1        2        3        4        5        7        8        9
> >      10       11       12       13
> > # 1.077945 1.077813 1.165025 1.181685 1.077954      NaN 1.044454 1.152110
> > 1.187586 1.181696 1.077954 1.165147
> >
> > Sincerely,
> > Eric
> >
>


-- 
Eric Bridgeford
ericwb.me

	[[alternative HTML version deleted]]


From er|cwb95 @end|ng |rom gm@||@com  Wed Apr  3 03:08:59 2019
From: er|cwb95 @end|ng |rom gm@||@com (Eric Bridgeford)
Date: Tue, 2 Apr 2019 21:08:59 -0400
Subject: [R] Fwd: Potential Issue with lm.influence
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836B3FEE1@FHSDB2D11-2.csu.mcmaster.ca>
References: <CAGfc6q2VGpAyymnDRVoMij2zD2-ayu+u4WhLRK4EHo4_mT2Xdg@mail.gmail.com>
 <CAGfc6q3V1FgeZT-AaKsrXL13WEYXbduZG3NweE64XGe19Xbeig@mail.gmail.com>
 <CAGxFJbR0j6asRCE21Btr+u5-nV0u0LBo63fvqajQinL38qECqw@mail.gmail.com>
 <CAGfc6q0agc=wAQhT6q91LYnO_Qr29CuPB5-OmN-_rwn1QGBsYw@mail.gmail.com>
 <CAGxFJbRfEPmLYEPqk0ksqi-WGaT4A8Mx2eEdjWJx9W46=tMY8A@mail.gmail.com>
 <CAGxFJbSJMF2PQY+9HDzczn0omhySK=nAOb2X2G9ZJZeFLSwMWw@mail.gmail.com>
 <23230_1554243133_x32MCCLX018357_CAGfc6q1-k6jTcTe17BM-9b6_Tcx2bxXP6r9iZsAFBMuRUEoSJQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836B3FEE1@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CAGfc6q1FCfdpRAkjCA0imYi6nrgjf5orWwvm_g3P1iBCBc=Ffg@mail.gmail.com>

Hey John,

I am aware they are high leverage points, and that the model is not the
best for them. The purpose of this dataset was to explore high leverage
points, and diagnostic statistics through which one would identify them.

What I am saying is that the current behavior of the function seems a
little non-specific to me; the influence for this problem is
finite/computable manually by fitting n models to n-1 points (manually
holding out each point individually to obtain the loo-variance, and
computing the influence in the non-approximate way).

I am just suggesting that it seems the function could be improved by, say,
throwing specific warnings when NaNs may arise. Ie, "Your have points that
are very high leverage. The approximation technique is not numerically
stable for these points and the results should be used with caution"
etc...; I am sure there are other also pre-hoc approaches to diagnose other
ways in which this function could fail). The approximation technique not
behaving well for points that are ultra high leverage just seems peculiar
that that would return an NaN with no other recommendations/advice/specific
warnings, especially since the influence is frequently used to diagnosing
this specific issue.

Alternatively, one could afford an optional argument type="manual" that
computes the held-out variance manually rather than the approximate
fashion, and add a comment to use this in the help menu when you have high
leverage points (this is what I ended up doing to obtain the true influence
and the externally studentized residual).

 I just think some more specificity could be of use for future users, to
make the R:stats community even better :) Does that make sense?

Sincerely,
Eric

On Tue, Apr 2, 2019 at 7:53 PM Fox, John <jfox at mcmaster.ca> wrote:

> Dear Eric,
>
> Have you looked at your data? -- for example:
>
>         plot(log(Moons) ~ Volume, data = moon_data)
>         text(log(Moons) ~ Volume, data = moon_data, labels=Name, adj=1,
> subset = Volume > 400)
>
> The negative-binomial model doesn't look reasonable, does it?
>
> After you eliminate Jupiter there's one very high leverage point left,
> Saturn. Computing studentized residuals entails an approximation to
> deleting that as well from the model, so try fitting
>
>         fit3 <- update(fit, subset = !(Name %in% c("Jupiter ", "Saturn ")))
>         summary(fit3)
>
> which runs into numeric difficulties.
>
> Then look at:
>
>         plot(log(Moons) ~ Volume, data = moon_data, subset = Volume < 400)
>
> Finally, try
>
>         plot(log(Moons) ~ log(Volume), data = moon_data)
>         fit4 <- update(fit2, . ~ log(Volume))
>         rstudent(fit4)
>
> I hope this helps,
>  John
>
> -----------------------------------------------------------------
> John Fox
> Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> Web: https://socialsciences.mcmaster.ca/jfox/
>
>
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Eric
> > Bridgeford
> > Sent: Tuesday, April 2, 2019 5:01 PM
> > To: Bert Gunter <bgunter.4567 at gmail.com>
> > Cc: R-help <r-help at r-project.org>
> > Subject: Re: [R] Fwd: Potential Issue with lm.influence
> >
> > I agree the influence documentation suggests NaNs may result; however, as
> > these can be manually computed and are, indeed, finite/existing (ie,
> > computing the held-out influence by manually training n models for n
> points
> > to obtain n leave one out influence measures), I don't possibly see how
> the
> > function SHOULD return NaN, and given that it is returning NaN, that
> > suggests to me that there should be either a) Providing an alternative
> > method to compute them that (may be slower) that returns the correct
> > results in the even that lm.influence does not return a good
> approximation
> > (ie, a command line argument for type="approx" that does the
> > approximation strategy employed currently, or an alternative
> type="direct"
> > or something like that that computes them manually), or b) a heuristic to
> > suggest why NaNs might result from one's particular inputs/what can be
> > done to fix it (if the approximation strategy is the source of the
> problem) or
> > what the issue is with the data that will cause NaNs. Hence I was
> looking to
> > start a discussion around the specific strategy employed to compute the
> > elements.
> >
> > Below is the code:
> > moon_data <- structure(list(Name = structure(c(8L, 13L, 2L, 7L, 1L, 5L,
> 11L,
> >                                                12L, 9L, 10L, 4L, 6L,
> 3L), .Label = c("Ceres ", "Earth",
> > "Eris ",
> >
> >          "Haumea ", "Jupiter ", "Makemake ", "Mars ", "Mercury ",
> "Neptune ",
> >
> >          "Pluto ", "Saturn ", "Uranus ", "Venus "), class = "factor"),
> >                             Distance = c(0.39, 0.72, 1, 1.52, 2.75, 5.2,
> 9.54, 19.22,
> >                                          30.06, 39.5, 43.35, 45.8,
> 67.7), Diameter = c(0.382, 0.949,
> >
> >            1, 0.532, 0.08, 11.209, 9.449, 4.007, 3.883, 0.18, 0.15,
> >
> >            0.12, 0.19), Mass = c(0.06, 0.82, 1, 0.11, 2e-04, 317.8,
> >
> >                                  95.2, 14.6, 17.2, 0.0022, 7e-04, 7e-04,
> 0.0025), Moons = c(0L,
> >
> >
> >                 0L, 1L, 2L, 0L, 64L, 62L, 27L, 13L, 4L, 2L, 0L, 1L),
> Volume =
> > c(0.0291869497930152,
> >
> >
> >
> >     0.447504348276571, 0.523598775598299, 0.0788376225681443,
> >
> >
> >
> >     0.000268082573106329, 737.393372232996, 441.729261571372,
> >
> >
> >
> >     33.6865588825666, 30.6549628355953, 0.00305362805928928,
> >
> >
> >
> >     0.00176714586764426, 0.00090477868423386, 0.00359136400182873
> >
> >
> >                 )), row.names = c(NA, -13L), class = "data.frame")
> >
> > fit <- glm.nb(Moons ~ Volume, data = moon_data)
> > rstudent(fit)
> >
> > fit2 <- update(fit, subset = Name != "Jupiter ")
> > rstudent(fit2)
> >
> > influence(fit2)$sigma
> >
> > #        1        2        3        4        5        7        8        9
> >      10       11       12       13
> > # 1.077945 1.077813 1.165025 1.181685 1.077954      NaN 1.044454 1.152110
> > 1.187586 1.181696 1.077954 1.165147
> >
> > Sincerely,
> > Eric
> >
> > On Tue, Apr 2, 2019 at 4:38 PM Bert Gunter <bgunter.4567 at gmail.com>
> > wrote:
> >
> > > Also, I suggest you read ?influence which may explain the source of
> > > your NaN's .
> > >
> > > Bert Gunter
> > >
> > > "The trouble with having an open mind is that people keep coming along
> > > and sticking things into it."
> > > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > >
> > >
> > > On Tue, Apr 2, 2019 at 1:29 PM Bert Gunter <bgunter.4567 at gmail.com>
> > wrote:
> > >
> > >> I told you already: **Include code inline **
> > >>
> > >> See ?dput for how to include a text version of objects, such as data
> > >> frames, inline.
> > >>
> > >> Otherwise, I believe .txt text files are not stripped if you insist
> > >> on
> > >> *attaching* data or code. Others may have better advice.
> > >>
> > >>
> > >> Bert Gunter
> > >>
> > >> "The trouble with having an open mind is that people keep coming
> > >> along and sticking things into it."
> > >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > >>
> > >>
> > >> On Tue, Apr 2, 2019 at 1:21 PM Eric Bridgeford <ericwb95 at gmail.com>
> > >> wrote:
> > >>
> > >>> How can I add attachments? The following two files were attached in
> > >>> the initial message
> > >>>
> > >>> On Tue, Apr 2, 2019 at 3:34 PM Bert Gunter <bgunter.4567 at gmail.com>
> > >>> wrote:
> > >>>
> > >>>> Nothing was attached. The r-help server strips most attachments.
> > >>>> Include your code inline.
> > >>>>
> > >>>> Also note that
> > >>>>
> > >>>> > 0/0
> > >>>> [1] NaN
> > >>>>
> > >>>> so maybe something like that occurs in the course of your
> calculations.
> > >>>> But that's just a guess, so feel free to disregard.
> > >>>>
> > >>>>
> > >>>> Bert Gunter
> > >>>>
> > >>>> "The trouble with having an open mind is that people keep coming
> > >>>> along and sticking things into it."
> > >>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > >>>>
> > >>>>
> > >>>> On Tue, Apr 2, 2019 at 11:32 AM Eric Bridgeford
> > >>>> <ericwb95 at gmail.com>
> > >>>> wrote:
> > >>>>
> > >>>>> Hi R core team,
> > >>>>>
> > >>>>> I experienced the following issue with the attached data/code
> > >>>>> snippet, where the studentized residual for a single observation
> > >>>>> appears to be NaN given finite predictors/responses, which appears
> > >>>>> to be driven by the glm.influence method in the stats package. I
> > >>>>> am curious to whether this is a consequence of the specific
> > >>>>> implementation used for computing the influence, which it would
> > >>>>> appear is the driving force for the NaN influence for the point,
> > >>>>> that I was ultimately able to trace back through the lm.influence
> > >>>>> method to this specific line <
> > >>>>> https://github.com/SurajGupta/r-
> > source/blob/a28e609e72ed7c47f6ddfb
> > >>>>> b86c85279a0750f0b7/src/library/stats/R/lm.influence.R#L67
> > >>>>> >
> > >>>>> which
> > >>>>> calls C code which calls iminfl.f
> > >>>>> <
> > >>>>> https://github.com/SurajGupta/r-source/blob/master/src/library/sta
> > >>>>> ts/src/lminfl.f
> > >>>>> >
> > >>>>> (I
> > >>>>> don't know fortran so I can't debug further). My understanding is
> > >>>>> that the specific issue would have to do with the leave-one-out
> > >>>>> variance estimate associated with this particular point, which it
> > >>>>> seems based on my understanding should be finite given finite
> > >>>>> predictors/responses. Let me know. Thanks!
> > >>>>>
> > >>>>> Sincerely,
> > >>>>>
> > >>>>> --
> > >>>>> Eric Bridgeford
> > >>>>> ericwb.me
> > >>>>> ______________________________________________
> > >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>>> PLEASE do read the posting guide
> > >>>>> http://www.R-project.org/posting-guide.html
> > >>>>> and provide commented, minimal, self-contained, reproducible code.
> > >>>>>
> > >>>>
> > >>>
> > >>> --
> > >>> Eric Bridgeford
> > >>> ericwb.me
> > >>>
> > >>
> >
> > --
> > Eric Bridgeford
> > ericwb.me
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


-- 
Eric Bridgeford
ericwb.me

	[[alternative HTML version deleted]]


From n@|@r@@p|nto @end|ng |rom jp|@n@@@@gov  Wed Apr  3 04:13:34 2019
From: n@|@r@@p|nto @end|ng |rom jp|@n@@@@gov (Pinto, Naiara (334F))
Date: Wed, 3 Apr 2019 02:13:34 +0000
Subject: [R] Advice for speeding up optim()
Message-ID: <D6426608-D283-4996-BCF4-B77B760A2F50@contoso.com>

Hi all,

I?m calling optim() and getting correct results, but need help to upscale it. I need to call it on a matrix that?s 3000x5000. I know the SANN option is slow but I get similar results with all other options. Perhaps there?s another package..I also heard about implementing my loss function in the cpp core but I?m not sure what this entails. I do have bounds for both parameters. My function is below ? thank you in advance for your patience and suggestions!

rvog = function(x){
                ext = x[1]
                height = x[2]
                ext_linear = ext * log(10)/20 #change units to nepers per meter
                inc_radians = myinc *pi/180
                p1 = 2*ext/cos(inc_radians)
              p2 = p1 + 1i*mykz
                #minimize distance to a provided coherence value
              coh = abs(mycoh - ((p1 / p2) * ((exp(p2*height)-1) / (exp(p1*height)-1))))
                return (coh)
}

#ancillary variables
mykz = kz[i,j]
myinc = inc
mycoh = volume

#call optimization function
myoptim = optim(c(0.05,30), rvog, method = "SANN", control = list(maxit = 30000, temp = 2000, trace = FALSE))

~Naiara.

	[[alternative HTML version deleted]]


From pro|jcn@@h @end|ng |rom gm@||@com  Wed Apr  3 14:24:34 2019
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Wed, 3 Apr 2019 08:24:34 -0400
Subject: [R] Advice for speeding up optim()
In-Reply-To: <D6426608-D283-4996-BCF4-B77B760A2F50@contoso.com>
References: <D6426608-D283-4996-BCF4-B77B760A2F50@contoso.com>
Message-ID: <9ebd399f-d1df-c709-154c-958c7cf2a41f@gmail.com>

Really should always look at Task Views

There's optimx package.

JN

On 2019-04-02 10:13 p.m., Pinto, Naiara (334F) via R-help wrote:
> Hi all,
> 
> I?m calling optim() and getting correct results, but need help to upscale it. I need to call it on a matrix that?s 3000x5000. I know the SANN option is slow but I get similar results with all other options. Perhaps there?s another package..I also heard about implementing my loss function in the cpp core but I?m not sure what this entails. I do have bounds for both parameters. My function is below ? thank you in advance for your patience and suggestions!
> 
> rvog = function(x){
>                 ext = x[1]
>                 height = x[2]
>                 ext_linear = ext * log(10)/20 #change units to nepers per meter
>                 inc_radians = myinc *pi/180
>                 p1 = 2*ext/cos(inc_radians)
>               p2 = p1 + 1i*mykz
>                 #minimize distance to a provided coherence value
>               coh = abs(mycoh - ((p1 / p2) * ((exp(p2*height)-1) / (exp(p1*height)-1))))
>                 return (coh)
> }
> 
> #ancillary variables
> mykz = kz[i,j]
> myinc = inc
> mycoh = volume
> 
> #call optimization function
> myoptim = optim(c(0.05,30), rvog, method = "SANN", control = list(maxit = 30000, temp = 2000, trace = FALSE))
> 
> ~Naiara.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From j|ox @end|ng |rom mcm@@ter@c@  Wed Apr  3 16:03:38 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Wed, 3 Apr 2019 14:03:38 +0000
Subject: [R] Potential Issue with lm.influence
In-Reply-To: <327629FB-15B2-4CF8-90B5-8221068BC099@gmail.com>
References: <CAGfc6q2VGpAyymnDRVoMij2zD2-ayu+u4WhLRK4EHo4_mT2Xdg@mail.gmail.com>
 <CAGfc6q3V1FgeZT-AaKsrXL13WEYXbduZG3NweE64XGe19Xbeig@mail.gmail.com>
 <CAGxFJbR0j6asRCE21Btr+u5-nV0u0LBo63fvqajQinL38qECqw@mail.gmail.com>
 <CAGfc6q0agc=wAQhT6q91LYnO_Qr29CuPB5-OmN-_rwn1QGBsYw@mail.gmail.com>
 <CAGxFJbRfEPmLYEPqk0ksqi-WGaT4A8Mx2eEdjWJx9W46=tMY8A@mail.gmail.com>
 <CAGxFJbSJMF2PQY+9HDzczn0omhySK=nAOb2X2G9ZJZeFLSwMWw@mail.gmail.com>
 <23230_1554243133_x32MCCLX018357_CAGfc6q1-k6jTcTe17BM-9b6_Tcx2bxXP6r9iZsAFBMuRUEoSJQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836B3FEE1@FHSDB2D11-2.csu.mcmaster.ca>
 <327629FB-15B2-4CF8-90B5-8221068BC099@gmail.com>
Message-ID: <9EF4D56D-06BE-4851-88D1-D606CD848360@mcmaster.ca>

Hi Peter,

Yes, that's another reflection of the degree to which Jupiter and Saturn are out of line with the data for the other planet when you fit the very unreasonable negative binomial model with Volume untransformed.

Best,
 John

> On Apr 3, 2019, at 5:36 AM, peter dalgaard <pdalgd at gmail.com> wrote:
> 
> Yes, also notice that 
> 
>> predict(fit3, new=moon_data, type="resp")
>           1            2            3            4            5            6 
> 1.060694e+00 1.102008e+00 1.109695e+00 1.065515e+00 1.057896e+00 1.892312e+29 
>           7            8            9           10           11           12 
> 3.531271e+17 2.295015e+01 1.739889e+01 1.058165e+00 1.058041e+00 1.057957e+00 
>          13 
> 1.058217e+00 
> 
> 
> so the model of fit3 predicts that Jupiter and Saturn should have several bazillions of moons each!
> 
> -pd
> 
> 
> 
>> On 3 Apr 2019, at 01:53 , Fox, John <jfox at mcmaster.ca> wrote:
>> 
>> Dear Eric,
>> 
>> Have you looked at your data? -- for example:
>> 
>> 	plot(log(Moons) ~ Volume, data = moon_data)
>> 	text(log(Moons) ~ Volume, data = moon_data, labels=Name, adj=1, subset = Volume > 400)
>> 
>> The negative-binomial model doesn't look reasonable, does it?
>> 
>> After you eliminate Jupiter there's one very high leverage point left, Saturn. Computing studentized residuals entails an approximation to deleting that as well from the model, so try fitting
>> 
>> 	fit3 <- update(fit, subset = !(Name %in% c("Jupiter ", "Saturn ")))
>> 	summary(fit3)
>> 
>> which runs into numeric difficulties.
>> 
>> Then look at:
>> 
>> 	plot(log(Moons) ~ Volume, data = moon_data, subset = Volume < 400)
>> 
>> Finally, try
>> 
>> 	plot(log(Moons) ~ log(Volume), data = moon_data)
>> 	fit4 <- update(fit2, . ~ log(Volume))
>> 	rstudent(fit4)
>> 
>> I hope this helps,
>> John
>> 
>> -----------------------------------------------------------------
>> John Fox
>> Professor Emeritus
>> McMaster University
>> Hamilton, Ontario, Canada
>> Web: https://socialsciences.mcmaster.ca/jfox/
>> 
>> 
>> 
>> 
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Eric
>>> Bridgeford
>>> Sent: Tuesday, April 2, 2019 5:01 PM
>>> To: Bert Gunter <bgunter.4567 at gmail.com>
>>> Cc: R-help <r-help at r-project.org>
>>> Subject: Re: [R] Fwd: Potential Issue with lm.influence
>>> 
>>> I agree the influence documentation suggests NaNs may result; however, as
>>> these can be manually computed and are, indeed, finite/existing (ie,
>>> computing the held-out influence by manually training n models for n points
>>> to obtain n leave one out influence measures), I don't possibly see how the
>>> function SHOULD return NaN, and given that it is returning NaN, that
>>> suggests to me that there should be either a) Providing an alternative
>>> method to compute them that (may be slower) that returns the correct
>>> results in the even that lm.influence does not return a good approximation
>>> (ie, a command line argument for type="approx" that does the
>>> approximation strategy employed currently, or an alternative type="direct"
>>> or something like that that computes them manually), or b) a heuristic to
>>> suggest why NaNs might result from one's particular inputs/what can be
>>> done to fix it (if the approximation strategy is the source of the problem) or
>>> what the issue is with the data that will cause NaNs. Hence I was looking to
>>> start a discussion around the specific strategy employed to compute the
>>> elements.
>>> 
>>> Below is the code:
>>> moon_data <- structure(list(Name = structure(c(8L, 13L, 2L, 7L, 1L, 5L, 11L,
>>>                                              12L, 9L, 10L, 4L, 6L, 3L), .Label = c("Ceres ", "Earth",
>>> "Eris ",
>>> 
>>>        "Haumea ", "Jupiter ", "Makemake ", "Mars ", "Mercury ", "Neptune ",
>>> 
>>>        "Pluto ", "Saturn ", "Uranus ", "Venus "), class = "factor"),
>>>                           Distance = c(0.39, 0.72, 1, 1.52, 2.75, 5.2, 9.54, 19.22,
>>>                                        30.06, 39.5, 43.35, 45.8, 67.7), Diameter = c(0.382, 0.949,
>>> 
>>>          1, 0.532, 0.08, 11.209, 9.449, 4.007, 3.883, 0.18, 0.15,
>>> 
>>>          0.12, 0.19), Mass = c(0.06, 0.82, 1, 0.11, 2e-04, 317.8,
>>> 
>>>                                95.2, 14.6, 17.2, 0.0022, 7e-04, 7e-04, 0.0025), Moons = c(0L,
>>> 
>>> 
>>>               0L, 1L, 2L, 0L, 64L, 62L, 27L, 13L, 4L, 2L, 0L, 1L), Volume =
>>> c(0.0291869497930152,
>>> 
>>> 
>>> 
>>>   0.447504348276571, 0.523598775598299, 0.0788376225681443,
>>> 
>>> 
>>> 
>>>   0.000268082573106329, 737.393372232996, 441.729261571372,
>>> 
>>> 
>>> 
>>>   33.6865588825666, 30.6549628355953, 0.00305362805928928,
>>> 
>>> 
>>> 
>>>   0.00176714586764426, 0.00090477868423386, 0.00359136400182873
>>> 
>>> 
>>>               )), row.names = c(NA, -13L), class = "data.frame")
>>> 
>>> fit <- glm.nb(Moons ~ Volume, data = moon_data)
>>> rstudent(fit)
>>> 
>>> fit2 <- update(fit, subset = Name != "Jupiter ")
>>> rstudent(fit2)
>>> 
>>> influence(fit2)$sigma
>>> 
>>> #        1        2        3        4        5        7        8        9
>>>    10       11       12       13
>>> # 1.077945 1.077813 1.165025 1.181685 1.077954      NaN 1.044454 1.152110
>>> 1.187586 1.181696 1.077954 1.165147
>>> 
>>> Sincerely,
>>> Eric
>>> 
>>> On Tue, Apr 2, 2019 at 4:38 PM Bert Gunter <bgunter.4567 at gmail.com>
>>> wrote:
>>> 
>>>> Also, I suggest you read ?influence which may explain the source of
>>>> your NaN's .
>>>> 
>>>> Bert Gunter
>>>> 
>>>> "The trouble with having an open mind is that people keep coming along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>> 
>>>> 
>>>> On Tue, Apr 2, 2019 at 1:29 PM Bert Gunter <bgunter.4567 at gmail.com>
>>> wrote:
>>>> 
>>>>> I told you already: **Include code inline **
>>>>> 
>>>>> See ?dput for how to include a text version of objects, such as data
>>>>> frames, inline.
>>>>> 
>>>>> Otherwise, I believe .txt text files are not stripped if you insist
>>>>> on
>>>>> *attaching* data or code. Others may have better advice.
>>>>> 
>>>>> 
>>>>> Bert Gunter
>>>>> 
>>>>> "The trouble with having an open mind is that people keep coming
>>>>> along and sticking things into it."
>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>> 
>>>>> 
>>>>> On Tue, Apr 2, 2019 at 1:21 PM Eric Bridgeford <ericwb95 at gmail.com>
>>>>> wrote:
>>>>> 
>>>>>> How can I add attachments? The following two files were attached in
>>>>>> the initial message
>>>>>> 
>>>>>> On Tue, Apr 2, 2019 at 3:34 PM Bert Gunter <bgunter.4567 at gmail.com>
>>>>>> wrote:
>>>>>> 
>>>>>>> Nothing was attached. The r-help server strips most attachments.
>>>>>>> Include your code inline.
>>>>>>> 
>>>>>>> Also note that
>>>>>>> 
>>>>>>>> 0/0
>>>>>>> [1] NaN
>>>>>>> 
>>>>>>> so maybe something like that occurs in the course of your calculations.
>>>>>>> But that's just a guess, so feel free to disregard.
>>>>>>> 
>>>>>>> 
>>>>>>> Bert Gunter
>>>>>>> 
>>>>>>> "The trouble with having an open mind is that people keep coming
>>>>>>> along and sticking things into it."
>>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>>> 
>>>>>>> 
>>>>>>> On Tue, Apr 2, 2019 at 11:32 AM Eric Bridgeford
>>>>>>> <ericwb95 at gmail.com>
>>>>>>> wrote:
>>>>>>> 
>>>>>>>> Hi R core team,
>>>>>>>> 
>>>>>>>> I experienced the following issue with the attached data/code
>>>>>>>> snippet, where the studentized residual for a single observation
>>>>>>>> appears to be NaN given finite predictors/responses, which appears
>>>>>>>> to be driven by the glm.influence method in the stats package. I
>>>>>>>> am curious to whether this is a consequence of the specific
>>>>>>>> implementation used for computing the influence, which it would
>>>>>>>> appear is the driving force for the NaN influence for the point,
>>>>>>>> that I was ultimately able to trace back through the lm.influence
>>>>>>>> method to this specific line <
>>>>>>>> https://github.com/SurajGupta/r-
>>> source/blob/a28e609e72ed7c47f6ddfb
>>>>>>>> b86c85279a0750f0b7/src/library/stats/R/lm.influence.R#L67
>>>>>>>>> 
>>>>>>>> which
>>>>>>>> calls C code which calls iminfl.f
>>>>>>>> <
>>>>>>>> https://github.com/SurajGupta/r-source/blob/master/src/library/sta
>>>>>>>> ts/src/lminfl.f
>>>>>>>>> 
>>>>>>>> (I
>>>>>>>> don't know fortran so I can't debug further). My understanding is
>>>>>>>> that the specific issue would have to do with the leave-one-out
>>>>>>>> variance estimate associated with this particular point, which it
>>>>>>>> seems based on my understanding should be finite given finite
>>>>>>>> predictors/responses. Let me know. Thanks!
>>>>>>>> 
>>>>>>>> Sincerely,
>>>>>>>> 
>>>>>>>> --
>>>>>>>> Eric Bridgeford
>>>>>>>> ericwb.me
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>> 
>>>>>>> 
>>>>>> 
>>>>>> --
>>>>>> Eric Bridgeford
>>>>>> ericwb.me
>>>>>> 
>>>>> 
>>> 
>>> --
>>> Eric Bridgeford
>>> ericwb.me
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 
> 


From j|ox @end|ng |rom mcm@@ter@c@  Wed Apr  3 16:18:05 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Wed, 3 Apr 2019 14:18:05 +0000
Subject: [R] Potential Issue with lm.influence
In-Reply-To: <9998_1554287833_x33AbC1o016465_CAGfc6q1FCfdpRAkjCA0imYi6nrgjf5orWwvm_g3P1iBCBc=Ffg@mail.gmail.com>
References: <CAGfc6q2VGpAyymnDRVoMij2zD2-ayu+u4WhLRK4EHo4_mT2Xdg@mail.gmail.com>
 <CAGfc6q3V1FgeZT-AaKsrXL13WEYXbduZG3NweE64XGe19Xbeig@mail.gmail.com>
 <CAGxFJbR0j6asRCE21Btr+u5-nV0u0LBo63fvqajQinL38qECqw@mail.gmail.com>
 <CAGfc6q0agc=wAQhT6q91LYnO_Qr29CuPB5-OmN-_rwn1QGBsYw@mail.gmail.com>
 <CAGxFJbRfEPmLYEPqk0ksqi-WGaT4A8Mx2eEdjWJx9W46=tMY8A@mail.gmail.com>
 <CAGxFJbSJMF2PQY+9HDzczn0omhySK=nAOb2X2G9ZJZeFLSwMWw@mail.gmail.com>
 <23230_1554243133_x32MCCLX018357_CAGfc6q1-k6jTcTe17BM-9b6_Tcx2bxXP6r9iZsAFBMuRUEoSJQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836B3FEE1@FHSDB2D11-2.csu.mcmaster.ca>
 <9998_1554287833_x33AbC1o016465_CAGfc6q1FCfdpRAkjCA0imYi6nrgjf5orWwvm_g3P1iBCBc=Ffg@mail.gmail.com>
Message-ID: <D5989BEF-59D9-46A0-9D8C-07DECED39791@mcmaster.ca>

Dear Eric,

I'm afraid that your argument doesn't make sense to me. As you saw when you tried

	fit3 <- update(fit, subset = !(Name %in% c("Jupiter ", "Saturn ")))

glm.nb() effectively wasn't able to estimate the theta parameter of the negative binomial model. So why would it be better to base deletion diagnostics on actually refitting the model?

The lesson to me here is that if you fit a sufficiently unreasonable model to data, the computations may break down. Other than drawing attention to the NaN with an explicit warning, I don't see what more could usefully be done.

Best,
 John

> On Apr 2, 2019, at 9:08 PM, Eric Bridgeford <ericwb95 at gmail.com> wrote:
> 
> Hey John,
> 
> I am aware they are high leverage points, and that the model is not the
> best for them. The purpose of this dataset was to explore high leverage
> points, and diagnostic statistics through which one would identify them.
> 
> What I am saying is that the current behavior of the function seems a
> little non-specific to me; the influence for this problem is
> finite/computable manually by fitting n models to n-1 points (manually
> holding out each point individually to obtain the loo-variance, and
> computing the influence in the non-approximate way).
> 
> I am just suggesting that it seems the function could be improved by, say,
> throwing specific warnings when NaNs may arise. Ie, "Your have points that
> are very high leverage. The approximation technique is not numerically
> stable for these points and the results should be used with caution"
> etc...; I am sure there are other also pre-hoc approaches to diagnose other
> ways in which this function could fail). The approximation technique not
> behaving well for points that are ultra high leverage just seems peculiar
> that that would return an NaN with no other recommendations/advice/specific
> warnings, especially since the influence is frequently used to diagnosing
> this specific issue.
> 
> Alternatively, one could afford an optional argument type="manual" that
> computes the held-out variance manually rather than the approximate
> fashion, and add a comment to use this in the help menu when you have high
> leverage points (this is what I ended up doing to obtain the true influence
> and the externally studentized residual).
> 
> I just think some more specificity could be of use for future users, to
> make the R:stats community even better :) Does that make sense?
> 
> Sincerely,
> Eric
> 
> On Tue, Apr 2, 2019 at 7:53 PM Fox, John <jfox at mcmaster.ca> wrote:
> 
>> Dear Eric,
>> 
>> Have you looked at your data? -- for example:
>> 
>>        plot(log(Moons) ~ Volume, data = moon_data)
>>        text(log(Moons) ~ Volume, data = moon_data, labels=Name, adj=1,
>> subset = Volume > 400)
>> 
>> The negative-binomial model doesn't look reasonable, does it?
>> 
>> After you eliminate Jupiter there's one very high leverage point left,
>> Saturn. Computing studentized residuals entails an approximation to
>> deleting that as well from the model, so try fitting
>> 
>>        fit3 <- update(fit, subset = !(Name %in% c("Jupiter ", "Saturn ")))
>>        summary(fit3)
>> 
>> which runs into numeric difficulties.
>> 
>> Then look at:
>> 
>>        plot(log(Moons) ~ Volume, data = moon_data, subset = Volume < 400)
>> 
>> Finally, try
>> 
>>        plot(log(Moons) ~ log(Volume), data = moon_data)
>>        fit4 <- update(fit2, . ~ log(Volume))
>>        rstudent(fit4)
>> 
>> I hope this helps,
>> John
>> 
>> -----------------------------------------------------------------
>> John Fox
>> Professor Emeritus
>> McMaster University
>> Hamilton, Ontario, Canada
>> Web: https://socialsciences.mcmaster.ca/jfox/
>> 
>> 
>> 
>> 
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Eric
>>> Bridgeford
>>> Sent: Tuesday, April 2, 2019 5:01 PM
>>> To: Bert Gunter <bgunter.4567 at gmail.com>
>>> Cc: R-help <r-help at r-project.org>
>>> Subject: Re: [R] Fwd: Potential Issue with lm.influence
>>> 
>>> I agree the influence documentation suggests NaNs may result; however, as
>>> these can be manually computed and are, indeed, finite/existing (ie,
>>> computing the held-out influence by manually training n models for n
>> points
>>> to obtain n leave one out influence measures), I don't possibly see how
>> the
>>> function SHOULD return NaN, and given that it is returning NaN, that
>>> suggests to me that there should be either a) Providing an alternative
>>> method to compute them that (may be slower) that returns the correct
>>> results in the even that lm.influence does not return a good
>> approximation
>>> (ie, a command line argument for type="approx" that does the
>>> approximation strategy employed currently, or an alternative
>> type="direct"
>>> or something like that that computes them manually), or b) a heuristic to
>>> suggest why NaNs might result from one's particular inputs/what can be
>>> done to fix it (if the approximation strategy is the source of the
>> problem) or
>>> what the issue is with the data that will cause NaNs. Hence I was
>> looking to
>>> start a discussion around the specific strategy employed to compute the
>>> elements.
>>> 
>>> Below is the code:
>>> moon_data <- structure(list(Name = structure(c(8L, 13L, 2L, 7L, 1L, 5L,
>> 11L,
>>>                                               12L, 9L, 10L, 4L, 6L,
>> 3L), .Label = c("Ceres ", "Earth",
>>> "Eris ",
>>> 
>>>         "Haumea ", "Jupiter ", "Makemake ", "Mars ", "Mercury ",
>> "Neptune ",
>>> 
>>>         "Pluto ", "Saturn ", "Uranus ", "Venus "), class = "factor"),
>>>                            Distance = c(0.39, 0.72, 1, 1.52, 2.75, 5.2,
>> 9.54, 19.22,
>>>                                         30.06, 39.5, 43.35, 45.8,
>> 67.7), Diameter = c(0.382, 0.949,
>>> 
>>>           1, 0.532, 0.08, 11.209, 9.449, 4.007, 3.883, 0.18, 0.15,
>>> 
>>>           0.12, 0.19), Mass = c(0.06, 0.82, 1, 0.11, 2e-04, 317.8,
>>> 
>>>                                 95.2, 14.6, 17.2, 0.0022, 7e-04, 7e-04,
>> 0.0025), Moons = c(0L,
>>> 
>>> 
>>>                0L, 1L, 2L, 0L, 64L, 62L, 27L, 13L, 4L, 2L, 0L, 1L),
>> Volume =
>>> c(0.0291869497930152,
>>> 
>>> 
>>> 
>>>    0.447504348276571, 0.523598775598299, 0.0788376225681443,
>>> 
>>> 
>>> 
>>>    0.000268082573106329, 737.393372232996, 441.729261571372,
>>> 
>>> 
>>> 
>>>    33.6865588825666, 30.6549628355953, 0.00305362805928928,
>>> 
>>> 
>>> 
>>>    0.00176714586764426, 0.00090477868423386, 0.00359136400182873
>>> 
>>> 
>>>                )), row.names = c(NA, -13L), class = "data.frame")
>>> 
>>> fit <- glm.nb(Moons ~ Volume, data = moon_data)
>>> rstudent(fit)
>>> 
>>> fit2 <- update(fit, subset = Name != "Jupiter ")
>>> rstudent(fit2)
>>> 
>>> influence(fit2)$sigma
>>> 
>>> #        1        2        3        4        5        7        8        9
>>>     10       11       12       13
>>> # 1.077945 1.077813 1.165025 1.181685 1.077954      NaN 1.044454 1.152110
>>> 1.187586 1.181696 1.077954 1.165147
>>> 
>>> Sincerely,
>>> Eric
>>> 
>>> On Tue, Apr 2, 2019 at 4:38 PM Bert Gunter <bgunter.4567 at gmail.com>
>>> wrote:
>>> 
>>>> Also, I suggest you read ?influence which may explain the source of
>>>> your NaN's .
>>>> 
>>>> Bert Gunter
>>>> 
>>>> "The trouble with having an open mind is that people keep coming along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>> 
>>>> 
>>>> On Tue, Apr 2, 2019 at 1:29 PM Bert Gunter <bgunter.4567 at gmail.com>
>>> wrote:
>>>> 
>>>>> I told you already: **Include code inline **
>>>>> 
>>>>> See ?dput for how to include a text version of objects, such as data
>>>>> frames, inline.
>>>>> 
>>>>> Otherwise, I believe .txt text files are not stripped if you insist
>>>>> on
>>>>> *attaching* data or code. Others may have better advice.
>>>>> 
>>>>> 
>>>>> Bert Gunter
>>>>> 
>>>>> "The trouble with having an open mind is that people keep coming
>>>>> along and sticking things into it."
>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>> 
>>>>> 
>>>>> On Tue, Apr 2, 2019 at 1:21 PM Eric Bridgeford <ericwb95 at gmail.com>
>>>>> wrote:
>>>>> 
>>>>>> How can I add attachments? The following two files were attached in
>>>>>> the initial message
>>>>>> 
>>>>>> On Tue, Apr 2, 2019 at 3:34 PM Bert Gunter <bgunter.4567 at gmail.com>
>>>>>> wrote:
>>>>>> 
>>>>>>> Nothing was attached. The r-help server strips most attachments.
>>>>>>> Include your code inline.
>>>>>>> 
>>>>>>> Also note that
>>>>>>> 
>>>>>>>> 0/0
>>>>>>> [1] NaN
>>>>>>> 
>>>>>>> so maybe something like that occurs in the course of your
>> calculations.
>>>>>>> But that's just a guess, so feel free to disregard.
>>>>>>> 
>>>>>>> 
>>>>>>> Bert Gunter
>>>>>>> 
>>>>>>> "The trouble with having an open mind is that people keep coming
>>>>>>> along and sticking things into it."
>>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>>> 
>>>>>>> 
>>>>>>> On Tue, Apr 2, 2019 at 11:32 AM Eric Bridgeford
>>>>>>> <ericwb95 at gmail.com>
>>>>>>> wrote:
>>>>>>> 
>>>>>>>> Hi R core team,
>>>>>>>> 
>>>>>>>> I experienced the following issue with the attached data/code
>>>>>>>> snippet, where the studentized residual for a single observation
>>>>>>>> appears to be NaN given finite predictors/responses, which appears
>>>>>>>> to be driven by the glm.influence method in the stats package. I
>>>>>>>> am curious to whether this is a consequence of the specific
>>>>>>>> implementation used for computing the influence, which it would
>>>>>>>> appear is the driving force for the NaN influence for the point,
>>>>>>>> that I was ultimately able to trace back through the lm.influence
>>>>>>>> method to this specific line <
>>>>>>>> https://github.com/SurajGupta/r-
>>> source/blob/a28e609e72ed7c47f6ddfb
>>>>>>>> b86c85279a0750f0b7/src/library/stats/R/lm.influence.R#L67
>>>>>>>>> 
>>>>>>>> which
>>>>>>>> calls C code which calls iminfl.f
>>>>>>>> <
>>>>>>>> https://github.com/SurajGupta/r-source/blob/master/src/library/sta
>>>>>>>> ts/src/lminfl.f
>>>>>>>>> 
>>>>>>>> (I
>>>>>>>> don't know fortran so I can't debug further). My understanding is
>>>>>>>> that the specific issue would have to do with the leave-one-out
>>>>>>>> variance estimate associated with this particular point, which it
>>>>>>>> seems based on my understanding should be finite given finite
>>>>>>>> predictors/responses. Let me know. Thanks!
>>>>>>>> 
>>>>>>>> Sincerely,
>>>>>>>> 
>>>>>>>> --
>>>>>>>> Eric Bridgeford
>>>>>>>> ericwb.me
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>> 
>>>>>>> 
>>>>>> 
>>>>>> --
>>>>>> Eric Bridgeford
>>>>>> ericwb.me
>>>>>> 
>>>>> 
>>> 
>>> --
>>> Eric Bridgeford
>>> ericwb.me
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> -- 
> Eric Bridgeford
> ericwb.me
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh @end|ng |rom temp|e@edu  Wed Apr  3 18:34:31 2019
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Wed, 3 Apr 2019 12:34:31 -0400
Subject: [R] Potential Issue with lm.influence
In-Reply-To: <D5989BEF-59D9-46A0-9D8C-07DECED39791@mcmaster.ca>
References: <CAGfc6q2VGpAyymnDRVoMij2zD2-ayu+u4WhLRK4EHo4_mT2Xdg@mail.gmail.com>
 <CAGfc6q3V1FgeZT-AaKsrXL13WEYXbduZG3NweE64XGe19Xbeig@mail.gmail.com>
 <CAGxFJbR0j6asRCE21Btr+u5-nV0u0LBo63fvqajQinL38qECqw@mail.gmail.com>
 <CAGfc6q0agc=wAQhT6q91LYnO_Qr29CuPB5-OmN-_rwn1QGBsYw@mail.gmail.com>
 <CAGxFJbRfEPmLYEPqk0ksqi-WGaT4A8Mx2eEdjWJx9W46=tMY8A@mail.gmail.com>
 <CAGxFJbSJMF2PQY+9HDzczn0omhySK=nAOb2X2G9ZJZeFLSwMWw@mail.gmail.com>
 <23230_1554243133_x32MCCLX018357_CAGfc6q1-k6jTcTe17BM-9b6_Tcx2bxXP6r9iZsAFBMuRUEoSJQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836B3FEE1@FHSDB2D11-2.csu.mcmaster.ca>
 <9998_1554287833_x33AbC1o016465_CAGfc6q1FCfdpRAkjCA0imYi6nrgjf5orWwvm_g3P1iBCBc=Ffg@mail.gmail.com>
 <D5989BEF-59D9-46A0-9D8C-07DECED39791@mcmaster.ca>
Message-ID: <CAGx1TMB721VDxCeO9CS8Td+MsPmoWyWEc0tW92v65yz5nxj5LQ@mail.gmail.com>

fortune nomination.


The lesson to me here is that if you fit a sufficiently unreasonable
model to data, the computations may break down.

On Wed, Apr 3, 2019 at 10:18 AM Fox, John <jfox at mcmaster.ca> wrote:
>
> Dear Eric,
>
> I'm afraid that your argument doesn't make sense to me. As you saw when you tried
>
>         fit3 <- update(fit, subset = !(Name %in% c("Jupiter ", "Saturn ")))
>
> glm.nb() effectively wasn't able to estimate the theta parameter of the negative binomial model. So why would it be better to base deletion diagnostics on actually refitting the model?
>
> The lesson to me here is that if you fit a sufficiently unreasonable model to data, the computations may break down. Other than drawing attention to the NaN with an explicit warning, I don't see what more could usefully be done.
>
> Best,
>  John
>
> > On Apr 2, 2019, at 9:08 PM, Eric Bridgeford <ericwb95 at gmail.com> wrote:
> >
> > Hey John,
> >
> > I am aware they are high leverage points, and that the model is not the
> > best for them. The purpose of this dataset was to explore high leverage
> > points, and diagnostic statistics through which one would identify them.
> >
> > What I am saying is that the current behavior of the function seems a
> > little non-specific to me; the influence for this problem is
> > finite/computable manually by fitting n models to n-1 points (manually
> > holding out each point individually to obtain the loo-variance, and
> > computing the influence in the non-approximate way).
> >
> > I am just suggesting that it seems the function could be improved by, say,
> > throwing specific warnings when NaNs may arise. Ie, "Your have points that
> > are very high leverage. The approximation technique is not numerically
> > stable for these points and the results should be used with caution"
> > etc...; I am sure there are other also pre-hoc approaches to diagnose other
> > ways in which this function could fail). The approximation technique not
> > behaving well for points that are ultra high leverage just seems peculiar
> > that that would return an NaN with no other recommendations/advice/specific
> > warnings, especially since the influence is frequently used to diagnosing
> > this specific issue.
> >
> > Alternatively, one could afford an optional argument type="manual" that
> > computes the held-out variance manually rather than the approximate
> > fashion, and add a comment to use this in the help menu when you have high
> > leverage points (this is what I ended up doing to obtain the true influence
> > and the externally studentized residual).
> >
> > I just think some more specificity could be of use for future users, to
> > make the R:stats community even better :) Does that make sense?
> >
> > Sincerely,
> > Eric
> >
> > On Tue, Apr 2, 2019 at 7:53 PM Fox, John <jfox at mcmaster.ca> wrote:
> >
> >> Dear Eric,
> >>
> >> Have you looked at your data? -- for example:
> >>
> >>        plot(log(Moons) ~ Volume, data = moon_data)
> >>        text(log(Moons) ~ Volume, data = moon_data, labels=Name, adj=1,
> >> subset = Volume > 400)
> >>
> >> The negative-binomial model doesn't look reasonable, does it?
> >>
> >> After you eliminate Jupiter there's one very high leverage point left,
> >> Saturn. Computing studentized residuals entails an approximation to
> >> deleting that as well from the model, so try fitting
> >>
> >>        fit3 <- update(fit, subset = !(Name %in% c("Jupiter ", "Saturn ")))
> >>        summary(fit3)
> >>
> >> which runs into numeric difficulties.
> >>
> >> Then look at:
> >>
> >>        plot(log(Moons) ~ Volume, data = moon_data, subset = Volume < 400)
> >>
> >> Finally, try
> >>
> >>        plot(log(Moons) ~ log(Volume), data = moon_data)
> >>        fit4 <- update(fit2, . ~ log(Volume))
> >>        rstudent(fit4)
> >>
> >> I hope this helps,
> >> John
> >>
> >> -----------------------------------------------------------------
> >> John Fox
> >> Professor Emeritus
> >> McMaster University
> >> Hamilton, Ontario, Canada
> >> Web: https://socialsciences.mcmaster.ca/jfox/
> >>
> >>
> >>
> >>
> >>> -----Original Message-----
> >>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Eric
> >>> Bridgeford
> >>> Sent: Tuesday, April 2, 2019 5:01 PM
> >>> To: Bert Gunter <bgunter.4567 at gmail.com>
> >>> Cc: R-help <r-help at r-project.org>
> >>> Subject: Re: [R] Fwd: Potential Issue with lm.influence
> >>>
> >>> I agree the influence documentation suggests NaNs may result; however, as
> >>> these can be manually computed and are, indeed, finite/existing (ie,
> >>> computing the held-out influence by manually training n models for n
> >> points
> >>> to obtain n leave one out influence measures), I don't possibly see how
> >> the
> >>> function SHOULD return NaN, and given that it is returning NaN, that
> >>> suggests to me that there should be either a) Providing an alternative
> >>> method to compute them that (may be slower) that returns the correct
> >>> results in the even that lm.influence does not return a good
> >> approximation
> >>> (ie, a command line argument for type="approx" that does the
> >>> approximation strategy employed currently, or an alternative
> >> type="direct"
> >>> or something like that that computes them manually), or b) a heuristic to
> >>> suggest why NaNs might result from one's particular inputs/what can be
> >>> done to fix it (if the approximation strategy is the source of the
> >> problem) or
> >>> what the issue is with the data that will cause NaNs. Hence I was
> >> looking to
> >>> start a discussion around the specific strategy employed to compute the
> >>> elements.
> >>>
> >>> Below is the code:
> >>> moon_data <- structure(list(Name = structure(c(8L, 13L, 2L, 7L, 1L, 5L,
> >> 11L,
> >>>                                               12L, 9L, 10L, 4L, 6L,
> >> 3L), .Label = c("Ceres ", "Earth",
> >>> "Eris ",
> >>>
> >>>         "Haumea ", "Jupiter ", "Makemake ", "Mars ", "Mercury ",
> >> "Neptune ",
> >>>
> >>>         "Pluto ", "Saturn ", "Uranus ", "Venus "), class = "factor"),
> >>>                            Distance = c(0.39, 0.72, 1, 1.52, 2.75, 5.2,
> >> 9.54, 19.22,
> >>>                                         30.06, 39.5, 43.35, 45.8,
> >> 67.7), Diameter = c(0.382, 0.949,
> >>>
> >>>           1, 0.532, 0.08, 11.209, 9.449, 4.007, 3.883, 0.18, 0.15,
> >>>
> >>>           0.12, 0.19), Mass = c(0.06, 0.82, 1, 0.11, 2e-04, 317.8,
> >>>
> >>>                                 95.2, 14.6, 17.2, 0.0022, 7e-04, 7e-04,
> >> 0.0025), Moons = c(0L,
> >>>
> >>>
> >>>                0L, 1L, 2L, 0L, 64L, 62L, 27L, 13L, 4L, 2L, 0L, 1L),
> >> Volume =
> >>> c(0.0291869497930152,
> >>>
> >>>
> >>>
> >>>    0.447504348276571, 0.523598775598299, 0.0788376225681443,
> >>>
> >>>
> >>>
> >>>    0.000268082573106329, 737.393372232996, 441.729261571372,
> >>>
> >>>
> >>>
> >>>    33.6865588825666, 30.6549628355953, 0.00305362805928928,
> >>>
> >>>
> >>>
> >>>    0.00176714586764426, 0.00090477868423386, 0.00359136400182873
> >>>
> >>>
> >>>                )), row.names = c(NA, -13L), class = "data.frame")
> >>>
> >>> fit <- glm.nb(Moons ~ Volume, data = moon_data)
> >>> rstudent(fit)
> >>>
> >>> fit2 <- update(fit, subset = Name != "Jupiter ")
> >>> rstudent(fit2)
> >>>
> >>> influence(fit2)$sigma
> >>>
> >>> #        1        2        3        4        5        7        8        9
> >>>     10       11       12       13
> >>> # 1.077945 1.077813 1.165025 1.181685 1.077954      NaN 1.044454 1.152110
> >>> 1.187586 1.181696 1.077954 1.165147
> >>>
> >>> Sincerely,
> >>> Eric
> >>>
> >>> On Tue, Apr 2, 2019 at 4:38 PM Bert Gunter <bgunter.4567 at gmail.com>
> >>> wrote:
> >>>
> >>>> Also, I suggest you read ?influence which may explain the source of
> >>>> your NaN's .
> >>>>
> >>>> Bert Gunter
> >>>>
> >>>> "The trouble with having an open mind is that people keep coming along
> >>>> and sticking things into it."
> >>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>>
> >>>>
> >>>> On Tue, Apr 2, 2019 at 1:29 PM Bert Gunter <bgunter.4567 at gmail.com>
> >>> wrote:
> >>>>
> >>>>> I told you already: **Include code inline **
> >>>>>
> >>>>> See ?dput for how to include a text version of objects, such as data
> >>>>> frames, inline.
> >>>>>
> >>>>> Otherwise, I believe .txt text files are not stripped if you insist
> >>>>> on
> >>>>> *attaching* data or code. Others may have better advice.
> >>>>>
> >>>>>
> >>>>> Bert Gunter
> >>>>>
> >>>>> "The trouble with having an open mind is that people keep coming
> >>>>> along and sticking things into it."
> >>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>>>
> >>>>>
> >>>>> On Tue, Apr 2, 2019 at 1:21 PM Eric Bridgeford <ericwb95 at gmail.com>
> >>>>> wrote:
> >>>>>
> >>>>>> How can I add attachments? The following two files were attached in
> >>>>>> the initial message
> >>>>>>
> >>>>>> On Tue, Apr 2, 2019 at 3:34 PM Bert Gunter <bgunter.4567 at gmail.com>
> >>>>>> wrote:
> >>>>>>
> >>>>>>> Nothing was attached. The r-help server strips most attachments.
> >>>>>>> Include your code inline.
> >>>>>>>
> >>>>>>> Also note that
> >>>>>>>
> >>>>>>>> 0/0
> >>>>>>> [1] NaN
> >>>>>>>
> >>>>>>> so maybe something like that occurs in the course of your
> >> calculations.
> >>>>>>> But that's just a guess, so feel free to disregard.
> >>>>>>>
> >>>>>>>
> >>>>>>> Bert Gunter
> >>>>>>>
> >>>>>>> "The trouble with having an open mind is that people keep coming
> >>>>>>> along and sticking things into it."
> >>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>>>>>
> >>>>>>>
> >>>>>>> On Tue, Apr 2, 2019 at 11:32 AM Eric Bridgeford
> >>>>>>> <ericwb95 at gmail.com>
> >>>>>>> wrote:
> >>>>>>>
> >>>>>>>> Hi R core team,
> >>>>>>>>
> >>>>>>>> I experienced the following issue with the attached data/code
> >>>>>>>> snippet, where the studentized residual for a single observation
> >>>>>>>> appears to be NaN given finite predictors/responses, which appears
> >>>>>>>> to be driven by the glm.influence method in the stats package. I
> >>>>>>>> am curious to whether this is a consequence of the specific
> >>>>>>>> implementation used for computing the influence, which it would
> >>>>>>>> appear is the driving force for the NaN influence for the point,
> >>>>>>>> that I was ultimately able to trace back through the lm.influence
> >>>>>>>> method to this specific line <
> >>>>>>>> https://github.com/SurajGupta/r-
> >>> source/blob/a28e609e72ed7c47f6ddfb
> >>>>>>>> b86c85279a0750f0b7/src/library/stats/R/lm.influence.R#L67
> >>>>>>>>>
> >>>>>>>> which
> >>>>>>>> calls C code which calls iminfl.f
> >>>>>>>> <
> >>>>>>>> https://github.com/SurajGupta/r-source/blob/master/src/library/sta
> >>>>>>>> ts/src/lminfl.f
> >>>>>>>>>
> >>>>>>>> (I
> >>>>>>>> don't know fortran so I can't debug further). My understanding is
> >>>>>>>> that the specific issue would have to do with the leave-one-out
> >>>>>>>> variance estimate associated with this particular point, which it
> >>>>>>>> seems based on my understanding should be finite given finite
> >>>>>>>> predictors/responses. Let me know. Thanks!
> >>>>>>>>
> >>>>>>>> Sincerely,
> >>>>>>>>
> >>>>>>>> --
> >>>>>>>> Eric Bridgeford
> >>>>>>>> ericwb.me
> >>>>>>>> ______________________________________________
> >>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>> PLEASE do read the posting guide
> >>>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>>>>
> >>>>>>>
> >>>>>>
> >>>>>> --
> >>>>>> Eric Bridgeford
> >>>>>> ericwb.me
> >>>>>>
> >>>>>
> >>>
> >>> --
> >>> Eric Bridgeford
> >>> ericwb.me
> >>>
> >>>      [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posting-
> >>> guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
> > --
> > Eric Bridgeford
> > ericwb.me
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Wed Apr  3 18:57:29 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 3 Apr 2019 09:57:29 -0700
Subject: [R] Potential Issue with lm.influence
In-Reply-To: <CAGx1TMB721VDxCeO9CS8Td+MsPmoWyWEc0tW92v65yz5nxj5LQ@mail.gmail.com>
References: <CAGfc6q2VGpAyymnDRVoMij2zD2-ayu+u4WhLRK4EHo4_mT2Xdg@mail.gmail.com>
 <CAGfc6q3V1FgeZT-AaKsrXL13WEYXbduZG3NweE64XGe19Xbeig@mail.gmail.com>
 <CAGxFJbR0j6asRCE21Btr+u5-nV0u0LBo63fvqajQinL38qECqw@mail.gmail.com>
 <CAGfc6q0agc=wAQhT6q91LYnO_Qr29CuPB5-OmN-_rwn1QGBsYw@mail.gmail.com>
 <CAGxFJbRfEPmLYEPqk0ksqi-WGaT4A8Mx2eEdjWJx9W46=tMY8A@mail.gmail.com>
 <CAGxFJbSJMF2PQY+9HDzczn0omhySK=nAOb2X2G9ZJZeFLSwMWw@mail.gmail.com>
 <23230_1554243133_x32MCCLX018357_CAGfc6q1-k6jTcTe17BM-9b6_Tcx2bxXP6r9iZsAFBMuRUEoSJQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836B3FEE1@FHSDB2D11-2.csu.mcmaster.ca>
 <9998_1554287833_x33AbC1o016465_CAGfc6q1FCfdpRAkjCA0imYi6nrgjf5orWwvm_g3P1iBCBc=Ffg@mail.gmail.com>
 <D5989BEF-59D9-46A0-9D8C-07DECED39791@mcmaster.ca>
 <CAGx1TMB721VDxCeO9CS8Td+MsPmoWyWEc0tW92v65yz5nxj5LQ@mail.gmail.com>
Message-ID: <CAGxFJbRSvVDDyqMj5k2vQ9g6byXCH9UPWStoD4UYJz+ksVmBxA@mail.gmail.com>

Second!

Bert Gunter



On Wed, Apr 3, 2019 at 9:35 AM Richard M. Heiberger <rmh at temple.edu> wrote:

> fortune nomination.
>
>
> The lesson to me here is that if you fit a sufficiently unreasonable
> model to data, the computations may break down.
>
> On Wed, Apr 3, 2019 at 10:18 AM Fox, John <jfox at mcmaster.ca> wrote:
> >
> > Dear Eric,
> >
> > I'm afraid that your argument doesn't make sense to me. As you saw when
> you tried
> >
> >         fit3 <- update(fit, subset = !(Name %in% c("Jupiter ", "Saturn
> ")))
> >
> > glm.nb() effectively wasn't able to estimate the theta parameter of the
> negative binomial model. So why would it be better to base deletion
> diagnostics on actually refitting the model?
> >
> > The lesson to me here is that if you fit a sufficiently unreasonable
> model to data, the computations may break down. Other than drawing
> attention to the NaN with an explicit warning, I don't see what more could
> usefully be done.
> >
> > Best,
> >  John
> >
> > > On Apr 2, 2019, at 9:08 PM, Eric Bridgeford <ericwb95 at gmail.com>
> wrote:
> > >
> > > Hey John,
> > >
> > > I am aware they are high leverage points, and that the model is not the
> > > best for them. The purpose of this dataset was to explore high leverage
> > > points, and diagnostic statistics through which one would identify
> them.
> > >
> > > What I am saying is that the current behavior of the function seems a
> > > little non-specific to me; the influence for this problem is
> > > finite/computable manually by fitting n models to n-1 points (manually
> > > holding out each point individually to obtain the loo-variance, and
> > > computing the influence in the non-approximate way).
> > >
> > > I am just suggesting that it seems the function could be improved by,
> say,
> > > throwing specific warnings when NaNs may arise. Ie, "Your have points
> that
> > > are very high leverage. The approximation technique is not numerically
> > > stable for these points and the results should be used with caution"
> > > etc...; I am sure there are other also pre-hoc approaches to diagnose
> other
> > > ways in which this function could fail). The approximation technique
> not
> > > behaving well for points that are ultra high leverage just seems
> peculiar
> > > that that would return an NaN with no other
> recommendations/advice/specific
> > > warnings, especially since the influence is frequently used to
> diagnosing
> > > this specific issue.
> > >
> > > Alternatively, one could afford an optional argument type="manual" that
> > > computes the held-out variance manually rather than the approximate
> > > fashion, and add a comment to use this in the help menu when you have
> high
> > > leverage points (this is what I ended up doing to obtain the true
> influence
> > > and the externally studentized residual).
> > >
> > > I just think some more specificity could be of use for future users, to
> > > make the R:stats community even better :) Does that make sense?
> > >
> > > Sincerely,
> > > Eric
> > >
> > > On Tue, Apr 2, 2019 at 7:53 PM Fox, John <jfox at mcmaster.ca> wrote:
> > >
> > >> Dear Eric,
> > >>
> > >> Have you looked at your data? -- for example:
> > >>
> > >>        plot(log(Moons) ~ Volume, data = moon_data)
> > >>        text(log(Moons) ~ Volume, data = moon_data, labels=Name, adj=1,
> > >> subset = Volume > 400)
> > >>
> > >> The negative-binomial model doesn't look reasonable, does it?
> > >>
> > >> After you eliminate Jupiter there's one very high leverage point left,
> > >> Saturn. Computing studentized residuals entails an approximation to
> > >> deleting that as well from the model, so try fitting
> > >>
> > >>        fit3 <- update(fit, subset = !(Name %in% c("Jupiter ", "Saturn
> ")))
> > >>        summary(fit3)
> > >>
> > >> which runs into numeric difficulties.
> > >>
> > >> Then look at:
> > >>
> > >>        plot(log(Moons) ~ Volume, data = moon_data, subset = Volume <
> 400)
> > >>
> > >> Finally, try
> > >>
> > >>        plot(log(Moons) ~ log(Volume), data = moon_data)
> > >>        fit4 <- update(fit2, . ~ log(Volume))
> > >>        rstudent(fit4)
> > >>
> > >> I hope this helps,
> > >> John
> > >>
> > >> -----------------------------------------------------------------
> > >> John Fox
> > >> Professor Emeritus
> > >> McMaster University
> > >> Hamilton, Ontario, Canada
> > >> Web: https://socialsciences.mcmaster.ca/jfox/
> > >>
> > >>
> > >>
> > >>
> > >>> -----Original Message-----
> > >>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Eric
> > >>> Bridgeford
> > >>> Sent: Tuesday, April 2, 2019 5:01 PM
> > >>> To: Bert Gunter <bgunter.4567 at gmail.com>
> > >>> Cc: R-help <r-help at r-project.org>
> > >>> Subject: Re: [R] Fwd: Potential Issue with lm.influence
> > >>>
> > >>> I agree the influence documentation suggests NaNs may result;
> however, as
> > >>> these can be manually computed and are, indeed, finite/existing (ie,
> > >>> computing the held-out influence by manually training n models for n
> > >> points
> > >>> to obtain n leave one out influence measures), I don't possibly see
> how
> > >> the
> > >>> function SHOULD return NaN, and given that it is returning NaN, that
> > >>> suggests to me that there should be either a) Providing an
> alternative
> > >>> method to compute them that (may be slower) that returns the correct
> > >>> results in the even that lm.influence does not return a good
> > >> approximation
> > >>> (ie, a command line argument for type="approx" that does the
> > >>> approximation strategy employed currently, or an alternative
> > >> type="direct"
> > >>> or something like that that computes them manually), or b) a
> heuristic to
> > >>> suggest why NaNs might result from one's particular inputs/what can
> be
> > >>> done to fix it (if the approximation strategy is the source of the
> > >> problem) or
> > >>> what the issue is with the data that will cause NaNs. Hence I was
> > >> looking to
> > >>> start a discussion around the specific strategy employed to compute
> the
> > >>> elements.
> > >>>
> > >>> Below is the code:
> > >>> moon_data <- structure(list(Name = structure(c(8L, 13L, 2L, 7L, 1L,
> 5L,
> > >> 11L,
> > >>>                                               12L, 9L, 10L, 4L, 6L,
> > >> 3L), .Label = c("Ceres ", "Earth",
> > >>> "Eris ",
> > >>>
> > >>>         "Haumea ", "Jupiter ", "Makemake ", "Mars ", "Mercury ",
> > >> "Neptune ",
> > >>>
> > >>>         "Pluto ", "Saturn ", "Uranus ", "Venus "), class = "factor"),
> > >>>                            Distance = c(0.39, 0.72, 1, 1.52, 2.75,
> 5.2,
> > >> 9.54, 19.22,
> > >>>                                         30.06, 39.5, 43.35, 45.8,
> > >> 67.7), Diameter = c(0.382, 0.949,
> > >>>
> > >>>           1, 0.532, 0.08, 11.209, 9.449, 4.007, 3.883, 0.18, 0.15,
> > >>>
> > >>>           0.12, 0.19), Mass = c(0.06, 0.82, 1, 0.11, 2e-04, 317.8,
> > >>>
> > >>>                                 95.2, 14.6, 17.2, 0.0022, 7e-04,
> 7e-04,
> > >> 0.0025), Moons = c(0L,
> > >>>
> > >>>
> > >>>                0L, 1L, 2L, 0L, 64L, 62L, 27L, 13L, 4L, 2L, 0L, 1L),
> > >> Volume =
> > >>> c(0.0291869497930152,
> > >>>
> > >>>
> > >>>
> > >>>    0.447504348276571, 0.523598775598299, 0.0788376225681443,
> > >>>
> > >>>
> > >>>
> > >>>    0.000268082573106329, 737.393372232996, 441.729261571372,
> > >>>
> > >>>
> > >>>
> > >>>    33.6865588825666, 30.6549628355953, 0.00305362805928928,
> > >>>
> > >>>
> > >>>
> > >>>    0.00176714586764426, 0.00090477868423386, 0.00359136400182873
> > >>>
> > >>>
> > >>>                )), row.names = c(NA, -13L), class = "data.frame")
> > >>>
> > >>> fit <- glm.nb(Moons ~ Volume, data = moon_data)
> > >>> rstudent(fit)
> > >>>
> > >>> fit2 <- update(fit, subset = Name != "Jupiter ")
> > >>> rstudent(fit2)
> > >>>
> > >>> influence(fit2)$sigma
> > >>>
> > >>> #        1        2        3        4        5        7        8
>     9
> > >>>     10       11       12       13
> > >>> # 1.077945 1.077813 1.165025 1.181685 1.077954      NaN 1.044454
> 1.152110
> > >>> 1.187586 1.181696 1.077954 1.165147
> > >>>
> > >>> Sincerely,
> > >>> Eric
> > >>>
> > >>> On Tue, Apr 2, 2019 at 4:38 PM Bert Gunter <bgunter.4567 at gmail.com>
> > >>> wrote:
> > >>>
> > >>>> Also, I suggest you read ?influence which may explain the source of
> > >>>> your NaN's .
> > >>>>
> > >>>> Bert Gunter
> > >>>>
> > >>>> "The trouble with having an open mind is that people keep coming
> along
> > >>>> and sticking things into it."
> > >>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > >>>>
> > >>>>
> > >>>> On Tue, Apr 2, 2019 at 1:29 PM Bert Gunter <bgunter.4567 at gmail.com>
> > >>> wrote:
> > >>>>
> > >>>>> I told you already: **Include code inline **
> > >>>>>
> > >>>>> See ?dput for how to include a text version of objects, such as
> data
> > >>>>> frames, inline.
> > >>>>>
> > >>>>> Otherwise, I believe .txt text files are not stripped if you insist
> > >>>>> on
> > >>>>> *attaching* data or code. Others may have better advice.
> > >>>>>
> > >>>>>
> > >>>>> Bert Gunter
> > >>>>>
> > >>>>> "The trouble with having an open mind is that people keep coming
> > >>>>> along and sticking things into it."
> > >>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > >>>>>
> > >>>>>
> > >>>>> On Tue, Apr 2, 2019 at 1:21 PM Eric Bridgeford <ericwb95 at gmail.com
> >
> > >>>>> wrote:
> > >>>>>
> > >>>>>> How can I add attachments? The following two files were attached
> in
> > >>>>>> the initial message
> > >>>>>>
> > >>>>>> On Tue, Apr 2, 2019 at 3:34 PM Bert Gunter <
> bgunter.4567 at gmail.com>
> > >>>>>> wrote:
> > >>>>>>
> > >>>>>>> Nothing was attached. The r-help server strips most attachments.
> > >>>>>>> Include your code inline.
> > >>>>>>>
> > >>>>>>> Also note that
> > >>>>>>>
> > >>>>>>>> 0/0
> > >>>>>>> [1] NaN
> > >>>>>>>
> > >>>>>>> so maybe something like that occurs in the course of your
> > >> calculations.
> > >>>>>>> But that's just a guess, so feel free to disregard.
> > >>>>>>>
> > >>>>>>>
> > >>>>>>> Bert Gunter
> > >>>>>>>
> > >>>>>>> "The trouble with having an open mind is that people keep coming
> > >>>>>>> along and sticking things into it."
> > >>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip
> )
> > >>>>>>>
> > >>>>>>>
> > >>>>>>> On Tue, Apr 2, 2019 at 11:32 AM Eric Bridgeford
> > >>>>>>> <ericwb95 at gmail.com>
> > >>>>>>> wrote:
> > >>>>>>>
> > >>>>>>>> Hi R core team,
> > >>>>>>>>
> > >>>>>>>> I experienced the following issue with the attached data/code
> > >>>>>>>> snippet, where the studentized residual for a single observation
> > >>>>>>>> appears to be NaN given finite predictors/responses, which
> appears
> > >>>>>>>> to be driven by the glm.influence method in the stats package. I
> > >>>>>>>> am curious to whether this is a consequence of the specific
> > >>>>>>>> implementation used for computing the influence, which it would
> > >>>>>>>> appear is the driving force for the NaN influence for the point,
> > >>>>>>>> that I was ultimately able to trace back through the
> lm.influence
> > >>>>>>>> method to this specific line <
> > >>>>>>>> https://github.com/SurajGupta/r-
> > >>> source/blob/a28e609e72ed7c47f6ddfb
> > >>>>>>>> b86c85279a0750f0b7/src/library/stats/R/lm.influence.R#L67
> > >>>>>>>>>
> > >>>>>>>> which
> > >>>>>>>> calls C code which calls iminfl.f
> > >>>>>>>> <
> > >>>>>>>>
> https://github.com/SurajGupta/r-source/blob/master/src/library/sta
> > >>>>>>>> ts/src/lminfl.f
> > >>>>>>>>>
> > >>>>>>>> (I
> > >>>>>>>> don't know fortran so I can't debug further). My understanding
> is
> > >>>>>>>> that the specific issue would have to do with the leave-one-out
> > >>>>>>>> variance estimate associated with this particular point, which
> it
> > >>>>>>>> seems based on my understanding should be finite given finite
> > >>>>>>>> predictors/responses. Let me know. Thanks!
> > >>>>>>>>
> > >>>>>>>> Sincerely,
> > >>>>>>>>
> > >>>>>>>> --
> > >>>>>>>> Eric Bridgeford
> > >>>>>>>> ericwb.me
> > >>>>>>>> ______________________________________________
> > >>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> > >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>>>>>> PLEASE do read the posting guide
> > >>>>>>>> http://www.R-project.org/posting-guide.html
> > >>>>>>>> and provide commented, minimal, self-contained, reproducible
> code.
> > >>>>>>>>
> > >>>>>>>
> > >>>>>>
> > >>>>>> --
> > >>>>>> Eric Bridgeford
> > >>>>>> ericwb.me
> > >>>>>>
> > >>>>>
> > >>>
> > >>> --
> > >>> Eric Bridgeford
> > >>> ericwb.me
> > >>>
> > >>>      [[alternative HTML version deleted]]
> > >>>
> > >>> ______________________________________________
> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>> PLEASE do read the posting guide http://www.R-project.org/posting-
> > >>> guide.html
> > >>> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >
> > >
> > > --
> > > Eric Bridgeford
> > > ericwb.me
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From gr@h@m_|e@@k @end|ng |rom y@hoo@com  Wed Apr  3 16:01:37 2019
From: gr@h@m_|e@@k @end|ng |rom y@hoo@com (Graham Leask)
Date: Wed, 3 Apr 2019 15:01:37 +0100
Subject: [R] String replace
Message-ID: <CFA12739-C1CE-4033-B143-E8A923D37F6F@yahoo.com>


I?m attempting to replace a string variable that normally works fine. However when trying to
do this with a string in the form of a date the output becomes corrupted.

See below:

BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_1" , "01-03-2017"))
BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_2" , "01-04-2017"))
BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_3" , "01-05-2017"))
BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_4" , "01-06-2017"))
BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_5" , "01-07-2017"))
BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_6" , "01-08-2017"))
BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_7" , "01-09-2017"))
BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_8" , "01-10-2017"))
BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_9" , "01-11-2017"))
BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_10" , "01-12-2017"))
BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_11" , "01-01-2018"))
BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_12" , "01-02-2018"))
BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_13" , "01-03-2018"))
BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_14" , "01-04-2018"))
BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_15" , "01-05-2018"))
BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_16" , "01-06-2018"))
BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_17" , "01-07-2018"))
BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_18" , "01-08-2018"))
BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_19" , "01-09-2018"))
BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_20" , "01-10-2018"))
BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_21" , "01-11-2018"))
BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_22" , "01-12-2018"))
BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_23" , "01-01-2019"))
BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_24" , "01-02-2019"))

The first line works fine but by the end the output is corrupted to

"01-03-20174"


Any thoughts what I?m doing wrong here?


From @@r@h@go@|ee @end|ng |rom gm@||@com  Wed Apr  3 19:28:09 2019
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Wed, 3 Apr 2019 13:28:09 -0400
Subject: [R] String replace
In-Reply-To: <CFA12739-C1CE-4033-B143-E8A923D37F6F@yahoo.com>
References: <CFA12739-C1CE-4033-B143-E8A923D37F6F@yahoo.com>
Message-ID: <CAM_vjukX35u6OX_tVe=od5wVPRMhWaNoPgdpDfC+3oJ59Ut35w@mail.gmail.com>

Try reversing the order, or extending the to-replace bit.

"M_1" is finding and replacing "M_10", "M_11", etc.
"M_2" is finding and replacing "M_20", "M_21", etc.

So M_14 becomes "01-03-20174"

In the future, a toy dataset would help with the reproducible example
aspect, and make your question easier to answer.

Sarah

On Wed, Apr 3, 2019 at 1:24 PM Graham Leask via R-help
<r-help at r-project.org> wrote:
>
>
> I?m attempting to replace a string variable that normally works fine. However when trying to
> do this with a string in the form of a date the output becomes corrupted.
>
> See below:
>
> BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_1" , "01-03-2017"))
> BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_2" , "01-04-2017"))
> BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_3" , "01-05-2017"))
> BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_4" , "01-06-2017"))
> BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_5" , "01-07-2017"))
> BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_6" , "01-08-2017"))
> BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_7" , "01-09-2017"))
> BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_8" , "01-10-2017"))
> BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_9" , "01-11-2017"))
> BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_10" , "01-12-2017"))
> BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_11" , "01-01-2018"))
> BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_12" , "01-02-2018"))
> BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_13" , "01-03-2018"))
> BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_14" , "01-04-2018"))
> BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_15" , "01-05-2018"))
> BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_16" , "01-06-2018"))
> BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_17" , "01-07-2018"))
> BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_18" , "01-08-2018"))
> BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_19" , "01-09-2018"))
> BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_20" , "01-10-2018"))
> BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_21" , "01-11-2018"))
> BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_22" , "01-12-2018"))
> BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_23" , "01-01-2019"))
> BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_24" , "01-02-2019"))
>
> The first line works fine but by the end the output is corrupted to
>
> "01-03-20174"
>
>
> Any thoughts what I?m doing wrong here?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From kry|ov@r00t @end|ng |rom gm@||@com  Wed Apr  3 19:38:35 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Wed, 3 Apr 2019 20:38:35 +0300
Subject: [R] String replace
In-Reply-To: <CFA12739-C1CE-4033-B143-E8A923D37F6F@yahoo.com>
References: <CFA12739-C1CE-4033-B143-E8A923D37F6F@yahoo.com>
Message-ID: <20190403203835.65a44a76@trisector>

On Wed, 3 Apr 2019 15:01:37 +0100
Graham Leask via R-help <r-help at r-project.org> wrote:

Suppose that `BHC$Date` contains a string "M_24".

You do:

> BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date , "M_2" ,
> "01-04-2017"))

before you have a chance to do:

> BHC <-BHC %>% mutate ( Date = stringr :: str_replace ( Date ,
> "M_24" , "01-02-2019"))

So now it has "01-04-20174" because the first expression had a
successful match and already made a replacement.

help() for stringi::stringi-search-regex says that look-around
expressions are supported, so one of the ways to prevent this would be
to modify your patterns to look like e.g. 'M_2(?!\\d)' to match
'M_2' that is *not* followed by a digit.

-- 
Best regards,
Ivan


From m|ch|b567 @end|ng |rom gm@||@com  Wed Apr  3 15:58:10 2019
From: m|ch|b567 @end|ng |rom gm@||@com (Michaela Berndl)
Date: Wed, 3 Apr 2019 15:58:10 +0200
Subject: [R] function predict
In-Reply-To: <5c9119a6.1c69fb81.1264d.fa3a@mx.google.com>
References: <5c9119a6.1c69fb81.1264d.fa3a@mx.google.com>
Message-ID: <CAD2h5ZhwEk5E97UWOdzo0o3JsHYkwDVZy8vv_3oCkGPT6KdThQ@mail.gmail.com>

Dear Sir or Madam,



we are statistic students at the Johannes Kepler University in Linz,
Austria.

In a project we had to analyse the time series influenza from the package
tscount and make a prediction for one year. For the prediction we used the
function predict from the package raster.

Since our data ends not at the end of a year, but at week 23 in the year
2012, we need to predict till the 23th week of 2013.



As identified in the Figure (boxplot of the original data) attached, in the
first months of

every year the recorded cases were always higher than in the rest of the
year.

The other figure shows the prediction with three models (the 3 colored
lines) from week 23 in the year 2012 to week 22 in the year 2013 and the
original data (the black line) for the same time. Due to the fact that the
the peaks of the prediction lines are not even close to the original data,
we are not sure whether the predict function is correct. We suspect that
the predict function just works for a prediction of exactly one year, which
starts at week 1 and ends at week 52.





Kind regards,
Doris Kuttner, Michaela Berndl

-------------- next part --------------
A non-text attachment was scrubbed...
Name: prediction.png
Type: image/png
Size: 6267 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20190403/f9353e59/attachment.png>

From er|cwb95 @end|ng |rom gm@||@com  Wed Apr  3 16:10:49 2019
From: er|cwb95 @end|ng |rom gm@||@com (Eric Bridgeford)
Date: Wed, 3 Apr 2019 10:10:49 -0400
Subject: [R] Potential Issue with lm.influence
In-Reply-To: <9EF4D56D-06BE-4851-88D1-D606CD848360@mcmaster.ca>
References: <CAGfc6q2VGpAyymnDRVoMij2zD2-ayu+u4WhLRK4EHo4_mT2Xdg@mail.gmail.com>
 <CAGfc6q3V1FgeZT-AaKsrXL13WEYXbduZG3NweE64XGe19Xbeig@mail.gmail.com>
 <CAGxFJbR0j6asRCE21Btr+u5-nV0u0LBo63fvqajQinL38qECqw@mail.gmail.com>
 <CAGfc6q0agc=wAQhT6q91LYnO_Qr29CuPB5-OmN-_rwn1QGBsYw@mail.gmail.com>
 <CAGxFJbRfEPmLYEPqk0ksqi-WGaT4A8Mx2eEdjWJx9W46=tMY8A@mail.gmail.com>
 <CAGxFJbSJMF2PQY+9HDzczn0omhySK=nAOb2X2G9ZJZeFLSwMWw@mail.gmail.com>
 <23230_1554243133_x32MCCLX018357_CAGfc6q1-k6jTcTe17BM-9b6_Tcx2bxXP6r9iZsAFBMuRUEoSJQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836B3FEE1@FHSDB2D11-2.csu.mcmaster.ca>
 <327629FB-15B2-4CF8-90B5-8221068BC099@gmail.com>
 <9EF4D56D-06BE-4851-88D1-D606CD848360@mcmaster.ca>
Message-ID: <CAGfc6q3m5ARSmuBMbfBnbYSvarcTOnpA10AFRjHQ_w69+2jcNg@mail.gmail.com>

Hey guys,

I appreciate the replies.

I agree the issue is easy to catch; wouldn't it make sense to make a
warning given that these types of errors (I am sure there are other ways to
make the lm.influence have similar NaN performance, simply due to points
radically not fitting the data) are relatively easy to forecast? Seems like
the output is just a bit vague from lm.influence.

Sincerely,
Eric

On Wed, Apr 3, 2019 at 10:03 AM Fox, John <jfox at mcmaster.ca> wrote:

> Hi Peter,
>
> Yes, that's another reflection of the degree to which Jupiter and Saturn
> are out of line with the data for the other planet when you fit the very
> unreasonable negative binomial model with Volume untransformed.
>
> Best,
>  John
>
> > On Apr 3, 2019, at 5:36 AM, peter dalgaard <pdalgd at gmail.com> wrote:
> >
> > Yes, also notice that
> >
> >> predict(fit3, new=moon_data, type="resp")
> >           1            2            3            4            5
>   6
> > 1.060694e+00 1.102008e+00 1.109695e+00 1.065515e+00 1.057896e+00
> 1.892312e+29
> >           7            8            9           10           11
>  12
> > 3.531271e+17 2.295015e+01 1.739889e+01 1.058165e+00 1.058041e+00
> 1.057957e+00
> >          13
> > 1.058217e+00
> >
> >
> > so the model of fit3 predicts that Jupiter and Saturn should have
> several bazillions of moons each!
> >
> > -pd
> >
> >
> >
> >> On 3 Apr 2019, at 01:53 , Fox, John <jfox at mcmaster.ca> wrote:
> >>
> >> Dear Eric,
> >>
> >> Have you looked at your data? -- for example:
> >>
> >>      plot(log(Moons) ~ Volume, data = moon_data)
> >>      text(log(Moons) ~ Volume, data = moon_data, labels=Name, adj=1,
> subset = Volume > 400)
> >>
> >> The negative-binomial model doesn't look reasonable, does it?
> >>
> >> After you eliminate Jupiter there's one very high leverage point left,
> Saturn. Computing studentized residuals entails an approximation to
> deleting that as well from the model, so try fitting
> >>
> >>      fit3 <- update(fit, subset = !(Name %in% c("Jupiter ", "Saturn ")))
> >>      summary(fit3)
> >>
> >> which runs into numeric difficulties.
> >>
> >> Then look at:
> >>
> >>      plot(log(Moons) ~ Volume, data = moon_data, subset = Volume < 400)
> >>
> >> Finally, try
> >>
> >>      plot(log(Moons) ~ log(Volume), data = moon_data)
> >>      fit4 <- update(fit2, . ~ log(Volume))
> >>      rstudent(fit4)
> >>
> >> I hope this helps,
> >> John
> >>
> >> -----------------------------------------------------------------
> >> John Fox
> >> Professor Emeritus
> >> McMaster University
> >> Hamilton, Ontario, Canada
> >> Web: https://socialsciences.mcmaster.ca/jfox/
> >>
> >>
> >>
> >>
> >>> -----Original Message-----
> >>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Eric
> >>> Bridgeford
> >>> Sent: Tuesday, April 2, 2019 5:01 PM
> >>> To: Bert Gunter <bgunter.4567 at gmail.com>
> >>> Cc: R-help <r-help at r-project.org>
> >>> Subject: Re: [R] Fwd: Potential Issue with lm.influence
> >>>
> >>> I agree the influence documentation suggests NaNs may result; however,
> as
> >>> these can be manually computed and are, indeed, finite/existing (ie,
> >>> computing the held-out influence by manually training n models for n
> points
> >>> to obtain n leave one out influence measures), I don't possibly see
> how the
> >>> function SHOULD return NaN, and given that it is returning NaN, that
> >>> suggests to me that there should be either a) Providing an alternative
> >>> method to compute them that (may be slower) that returns the correct
> >>> results in the even that lm.influence does not return a good
> approximation
> >>> (ie, a command line argument for type="approx" that does the
> >>> approximation strategy employed currently, or an alternative
> type="direct"
> >>> or something like that that computes them manually), or b) a heuristic
> to
> >>> suggest why NaNs might result from one's particular inputs/what can be
> >>> done to fix it (if the approximation strategy is the source of the
> problem) or
> >>> what the issue is with the data that will cause NaNs. Hence I was
> looking to
> >>> start a discussion around the specific strategy employed to compute the
> >>> elements.
> >>>
> >>> Below is the code:
> >>> moon_data <- structure(list(Name = structure(c(8L, 13L, 2L, 7L, 1L,
> 5L, 11L,
> >>>                                              12L, 9L, 10L, 4L, 6L,
> 3L), .Label = c("Ceres ", "Earth",
> >>> "Eris ",
> >>>
> >>>        "Haumea ", "Jupiter ", "Makemake ", "Mars ", "Mercury ",
> "Neptune ",
> >>>
> >>>        "Pluto ", "Saturn ", "Uranus ", "Venus "), class = "factor"),
> >>>                           Distance = c(0.39, 0.72, 1, 1.52, 2.75, 5.2,
> 9.54, 19.22,
> >>>                                        30.06, 39.5, 43.35, 45.8,
> 67.7), Diameter = c(0.382, 0.949,
> >>>
> >>>          1, 0.532, 0.08, 11.209, 9.449, 4.007, 3.883, 0.18, 0.15,
> >>>
> >>>          0.12, 0.19), Mass = c(0.06, 0.82, 1, 0.11, 2e-04, 317.8,
> >>>
> >>>                                95.2, 14.6, 17.2, 0.0022, 7e-04, 7e-04,
> 0.0025), Moons = c(0L,
> >>>
> >>>
> >>>               0L, 1L, 2L, 0L, 64L, 62L, 27L, 13L, 4L, 2L, 0L, 1L),
> Volume =
> >>> c(0.0291869497930152,
> >>>
> >>>
> >>>
> >>>   0.447504348276571, 0.523598775598299, 0.0788376225681443,
> >>>
> >>>
> >>>
> >>>   0.000268082573106329, 737.393372232996, 441.729261571372,
> >>>
> >>>
> >>>
> >>>   33.6865588825666, 30.6549628355953, 0.00305362805928928,
> >>>
> >>>
> >>>
> >>>   0.00176714586764426, 0.00090477868423386, 0.00359136400182873
> >>>
> >>>
> >>>               )), row.names = c(NA, -13L), class = "data.frame")
> >>>
> >>> fit <- glm.nb(Moons ~ Volume, data = moon_data)
> >>> rstudent(fit)
> >>>
> >>> fit2 <- update(fit, subset = Name != "Jupiter ")
> >>> rstudent(fit2)
> >>>
> >>> influence(fit2)$sigma
> >>>
> >>> #        1        2        3        4        5        7        8
>   9
> >>>    10       11       12       13
> >>> # 1.077945 1.077813 1.165025 1.181685 1.077954      NaN 1.044454
> 1.152110
> >>> 1.187586 1.181696 1.077954 1.165147
> >>>
> >>> Sincerely,
> >>> Eric
> >>>
> >>> On Tue, Apr 2, 2019 at 4:38 PM Bert Gunter <bgunter.4567 at gmail.com>
> >>> wrote:
> >>>
> >>>> Also, I suggest you read ?influence which may explain the source of
> >>>> your NaN's .
> >>>>
> >>>> Bert Gunter
> >>>>
> >>>> "The trouble with having an open mind is that people keep coming along
> >>>> and sticking things into it."
> >>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>>
> >>>>
> >>>> On Tue, Apr 2, 2019 at 1:29 PM Bert Gunter <bgunter.4567 at gmail.com>
> >>> wrote:
> >>>>
> >>>>> I told you already: **Include code inline **
> >>>>>
> >>>>> See ?dput for how to include a text version of objects, such as data
> >>>>> frames, inline.
> >>>>>
> >>>>> Otherwise, I believe .txt text files are not stripped if you insist
> >>>>> on
> >>>>> *attaching* data or code. Others may have better advice.
> >>>>>
> >>>>>
> >>>>> Bert Gunter
> >>>>>
> >>>>> "The trouble with having an open mind is that people keep coming
> >>>>> along and sticking things into it."
> >>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>>>
> >>>>>
> >>>>> On Tue, Apr 2, 2019 at 1:21 PM Eric Bridgeford <ericwb95 at gmail.com>
> >>>>> wrote:
> >>>>>
> >>>>>> How can I add attachments? The following two files were attached in
> >>>>>> the initial message
> >>>>>>
> >>>>>> On Tue, Apr 2, 2019 at 3:34 PM Bert Gunter <bgunter.4567 at gmail.com>
> >>>>>> wrote:
> >>>>>>
> >>>>>>> Nothing was attached. The r-help server strips most attachments.
> >>>>>>> Include your code inline.
> >>>>>>>
> >>>>>>> Also note that
> >>>>>>>
> >>>>>>>> 0/0
> >>>>>>> [1] NaN
> >>>>>>>
> >>>>>>> so maybe something like that occurs in the course of your
> calculations.
> >>>>>>> But that's just a guess, so feel free to disregard.
> >>>>>>>
> >>>>>>>
> >>>>>>> Bert Gunter
> >>>>>>>
> >>>>>>> "The trouble with having an open mind is that people keep coming
> >>>>>>> along and sticking things into it."
> >>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>>>>>
> >>>>>>>
> >>>>>>> On Tue, Apr 2, 2019 at 11:32 AM Eric Bridgeford
> >>>>>>> <ericwb95 at gmail.com>
> >>>>>>> wrote:
> >>>>>>>
> >>>>>>>> Hi R core team,
> >>>>>>>>
> >>>>>>>> I experienced the following issue with the attached data/code
> >>>>>>>> snippet, where the studentized residual for a single observation
> >>>>>>>> appears to be NaN given finite predictors/responses, which appears
> >>>>>>>> to be driven by the glm.influence method in the stats package. I
> >>>>>>>> am curious to whether this is a consequence of the specific
> >>>>>>>> implementation used for computing the influence, which it would
> >>>>>>>> appear is the driving force for the NaN influence for the point,
> >>>>>>>> that I was ultimately able to trace back through the lm.influence
> >>>>>>>> method to this specific line <
> >>>>>>>> https://github.com/SurajGupta/r-
> >>> source/blob/a28e609e72ed7c47f6ddfb
> >>>>>>>> b86c85279a0750f0b7/src/library/stats/R/lm.influence.R#L67
> >>>>>>>>>
> >>>>>>>> which
> >>>>>>>> calls C code which calls iminfl.f
> >>>>>>>> <
> >>>>>>>>
> https://github.com/SurajGupta/r-source/blob/master/src/library/sta
> >>>>>>>> ts/src/lminfl.f
> >>>>>>>>>
> >>>>>>>> (I
> >>>>>>>> don't know fortran so I can't debug further). My understanding is
> >>>>>>>> that the specific issue would have to do with the leave-one-out
> >>>>>>>> variance estimate associated with this particular point, which it
> >>>>>>>> seems based on my understanding should be finite given finite
> >>>>>>>> predictors/responses. Let me know. Thanks!
> >>>>>>>>
> >>>>>>>> Sincerely,
> >>>>>>>>
> >>>>>>>> --
> >>>>>>>> Eric Bridgeford
> >>>>>>>> ericwb.me
> >>>>>>>> ______________________________________________
> >>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>> PLEASE do read the posting guide
> >>>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>>>>
> >>>>>>>
> >>>>>>
> >>>>>> --
> >>>>>> Eric Bridgeford
> >>>>>> ericwb.me
> >>>>>>
> >>>>>
> >>>
> >>> --
> >>> Eric Bridgeford
> >>> ericwb.me
> >>>
> >>>     [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posting-
> >>> guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Peter Dalgaard, Professor,
> > Center for Statistics, Copenhagen Business School
> > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> > Phone: (+45)38153501
> > Office: A 4.23
> > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> >
> >
> >
> >
> >
> >
> >
> >
> >
>
>

-- 
Eric Bridgeford
ericwb.me

	[[alternative HTML version deleted]]


From er|cwb95 @end|ng |rom gm@||@com  Wed Apr  3 16:20:45 2019
From: er|cwb95 @end|ng |rom gm@||@com (Eric Bridgeford)
Date: Wed, 3 Apr 2019 10:20:45 -0400
Subject: [R] Potential Issue with lm.influence
In-Reply-To: <D5989BEF-59D9-46A0-9D8C-07DECED39791@mcmaster.ca>
References: <CAGfc6q2VGpAyymnDRVoMij2zD2-ayu+u4WhLRK4EHo4_mT2Xdg@mail.gmail.com>
 <CAGfc6q3V1FgeZT-AaKsrXL13WEYXbduZG3NweE64XGe19Xbeig@mail.gmail.com>
 <CAGxFJbR0j6asRCE21Btr+u5-nV0u0LBo63fvqajQinL38qECqw@mail.gmail.com>
 <CAGfc6q0agc=wAQhT6q91LYnO_Qr29CuPB5-OmN-_rwn1QGBsYw@mail.gmail.com>
 <CAGxFJbRfEPmLYEPqk0ksqi-WGaT4A8Mx2eEdjWJx9W46=tMY8A@mail.gmail.com>
 <CAGxFJbSJMF2PQY+9HDzczn0omhySK=nAOb2X2G9ZJZeFLSwMWw@mail.gmail.com>
 <23230_1554243133_x32MCCLX018357_CAGfc6q1-k6jTcTe17BM-9b6_Tcx2bxXP6r9iZsAFBMuRUEoSJQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836B3FEE1@FHSDB2D11-2.csu.mcmaster.ca>
 <9998_1554287833_x33AbC1o016465_CAGfc6q1FCfdpRAkjCA0imYi6nrgjf5orWwvm_g3P1iBCBc=Ffg@mail.gmail.com>
 <D5989BEF-59D9-46A0-9D8C-07DECED39791@mcmaster.ca>
Message-ID: <CAGfc6q3b8eWbYFrJ=5ssVwajqEEYEXP11dOQivOs2_2F3-t6mA@mail.gmail.com>

Hey John,

Seems fair, and, I agree a more explicit or clear (ie, giving users
indications as to why/when the lm.influence is going to misfit the data)
warning makes sense in context.

Sincerely,
Eric

On Wed, Apr 3, 2019 at 10:18 AM Fox, John <jfox at mcmaster.ca> wrote:

> Dear Eric,
>
> I'm afraid that your argument doesn't make sense to me. As you saw when
> you tried
>
>         fit3 <- update(fit, subset = !(Name %in% c("Jupiter ", "Saturn ")))
>
> glm.nb() effectively wasn't able to estimate the theta parameter of the
> negative binomial model. So why would it be better to base deletion
> diagnostics on actually refitting the model?
>
> The lesson to me here is that if you fit a sufficiently unreasonable model
> to data, the computations may break down. Other than drawing attention to
> the NaN with an explicit warning, I don't see what more could usefully be
> done.
>
> Best,
>  John
>
> > On Apr 2, 2019, at 9:08 PM, Eric Bridgeford <ericwb95 at gmail.com> wrote:
> >
> > Hey John,
> >
> > I am aware they are high leverage points, and that the model is not the
> > best for them. The purpose of this dataset was to explore high leverage
> > points, and diagnostic statistics through which one would identify them.
> >
> > What I am saying is that the current behavior of the function seems a
> > little non-specific to me; the influence for this problem is
> > finite/computable manually by fitting n models to n-1 points (manually
> > holding out each point individually to obtain the loo-variance, and
> > computing the influence in the non-approximate way).
> >
> > I am just suggesting that it seems the function could be improved by,
> say,
> > throwing specific warnings when NaNs may arise. Ie, "Your have points
> that
> > are very high leverage. The approximation technique is not numerically
> > stable for these points and the results should be used with caution"
> > etc...; I am sure there are other also pre-hoc approaches to diagnose
> other
> > ways in which this function could fail). The approximation technique not
> > behaving well for points that are ultra high leverage just seems peculiar
> > that that would return an NaN with no other
> recommendations/advice/specific
> > warnings, especially since the influence is frequently used to diagnosing
> > this specific issue.
> >
> > Alternatively, one could afford an optional argument type="manual" that
> > computes the held-out variance manually rather than the approximate
> > fashion, and add a comment to use this in the help menu when you have
> high
> > leverage points (this is what I ended up doing to obtain the true
> influence
> > and the externally studentized residual).
> >
> > I just think some more specificity could be of use for future users, to
> > make the R:stats community even better :) Does that make sense?
> >
> > Sincerely,
> > Eric
> >
> > On Tue, Apr 2, 2019 at 7:53 PM Fox, John <jfox at mcmaster.ca> wrote:
> >
> >> Dear Eric,
> >>
> >> Have you looked at your data? -- for example:
> >>
> >>        plot(log(Moons) ~ Volume, data = moon_data)
> >>        text(log(Moons) ~ Volume, data = moon_data, labels=Name, adj=1,
> >> subset = Volume > 400)
> >>
> >> The negative-binomial model doesn't look reasonable, does it?
> >>
> >> After you eliminate Jupiter there's one very high leverage point left,
> >> Saturn. Computing studentized residuals entails an approximation to
> >> deleting that as well from the model, so try fitting
> >>
> >>        fit3 <- update(fit, subset = !(Name %in% c("Jupiter ", "Saturn
> ")))
> >>        summary(fit3)
> >>
> >> which runs into numeric difficulties.
> >>
> >> Then look at:
> >>
> >>        plot(log(Moons) ~ Volume, data = moon_data, subset = Volume <
> 400)
> >>
> >> Finally, try
> >>
> >>        plot(log(Moons) ~ log(Volume), data = moon_data)
> >>        fit4 <- update(fit2, . ~ log(Volume))
> >>        rstudent(fit4)
> >>
> >> I hope this helps,
> >> John
> >>
> >> -----------------------------------------------------------------
> >> John Fox
> >> Professor Emeritus
> >> McMaster University
> >> Hamilton, Ontario, Canada
> >> Web: https://socialsciences.mcmaster.ca/jfox/
> >>
> >>
> >>
> >>
> >>> -----Original Message-----
> >>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Eric
> >>> Bridgeford
> >>> Sent: Tuesday, April 2, 2019 5:01 PM
> >>> To: Bert Gunter <bgunter.4567 at gmail.com>
> >>> Cc: R-help <r-help at r-project.org>
> >>> Subject: Re: [R] Fwd: Potential Issue with lm.influence
> >>>
> >>> I agree the influence documentation suggests NaNs may result; however,
> as
> >>> these can be manually computed and are, indeed, finite/existing (ie,
> >>> computing the held-out influence by manually training n models for n
> >> points
> >>> to obtain n leave one out influence measures), I don't possibly see how
> >> the
> >>> function SHOULD return NaN, and given that it is returning NaN, that
> >>> suggests to me that there should be either a) Providing an alternative
> >>> method to compute them that (may be slower) that returns the correct
> >>> results in the even that lm.influence does not return a good
> >> approximation
> >>> (ie, a command line argument for type="approx" that does the
> >>> approximation strategy employed currently, or an alternative
> >> type="direct"
> >>> or something like that that computes them manually), or b) a heuristic
> to
> >>> suggest why NaNs might result from one's particular inputs/what can be
> >>> done to fix it (if the approximation strategy is the source of the
> >> problem) or
> >>> what the issue is with the data that will cause NaNs. Hence I was
> >> looking to
> >>> start a discussion around the specific strategy employed to compute the
> >>> elements.
> >>>
> >>> Below is the code:
> >>> moon_data <- structure(list(Name = structure(c(8L, 13L, 2L, 7L, 1L, 5L,
> >> 11L,
> >>>                                               12L, 9L, 10L, 4L, 6L,
> >> 3L), .Label = c("Ceres ", "Earth",
> >>> "Eris ",
> >>>
> >>>         "Haumea ", "Jupiter ", "Makemake ", "Mars ", "Mercury ",
> >> "Neptune ",
> >>>
> >>>         "Pluto ", "Saturn ", "Uranus ", "Venus "), class = "factor"),
> >>>                            Distance = c(0.39, 0.72, 1, 1.52, 2.75, 5.2,
> >> 9.54, 19.22,
> >>>                                         30.06, 39.5, 43.35, 45.8,
> >> 67.7), Diameter = c(0.382, 0.949,
> >>>
> >>>           1, 0.532, 0.08, 11.209, 9.449, 4.007, 3.883, 0.18, 0.15,
> >>>
> >>>           0.12, 0.19), Mass = c(0.06, 0.82, 1, 0.11, 2e-04, 317.8,
> >>>
> >>>                                 95.2, 14.6, 17.2, 0.0022, 7e-04, 7e-04,
> >> 0.0025), Moons = c(0L,
> >>>
> >>>
> >>>                0L, 1L, 2L, 0L, 64L, 62L, 27L, 13L, 4L, 2L, 0L, 1L),
> >> Volume =
> >>> c(0.0291869497930152,
> >>>
> >>>
> >>>
> >>>    0.447504348276571, 0.523598775598299, 0.0788376225681443,
> >>>
> >>>
> >>>
> >>>    0.000268082573106329, 737.393372232996, 441.729261571372,
> >>>
> >>>
> >>>
> >>>    33.6865588825666, 30.6549628355953, 0.00305362805928928,
> >>>
> >>>
> >>>
> >>>    0.00176714586764426, 0.00090477868423386, 0.00359136400182873
> >>>
> >>>
> >>>                )), row.names = c(NA, -13L), class = "data.frame")
> >>>
> >>> fit <- glm.nb(Moons ~ Volume, data = moon_data)
> >>> rstudent(fit)
> >>>
> >>> fit2 <- update(fit, subset = Name != "Jupiter ")
> >>> rstudent(fit2)
> >>>
> >>> influence(fit2)$sigma
> >>>
> >>> #        1        2        3        4        5        7        8
>   9
> >>>     10       11       12       13
> >>> # 1.077945 1.077813 1.165025 1.181685 1.077954      NaN 1.044454
> 1.152110
> >>> 1.187586 1.181696 1.077954 1.165147
> >>>
> >>> Sincerely,
> >>> Eric
> >>>
> >>> On Tue, Apr 2, 2019 at 4:38 PM Bert Gunter <bgunter.4567 at gmail.com>
> >>> wrote:
> >>>
> >>>> Also, I suggest you read ?influence which may explain the source of
> >>>> your NaN's .
> >>>>
> >>>> Bert Gunter
> >>>>
> >>>> "The trouble with having an open mind is that people keep coming along
> >>>> and sticking things into it."
> >>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>>
> >>>>
> >>>> On Tue, Apr 2, 2019 at 1:29 PM Bert Gunter <bgunter.4567 at gmail.com>
> >>> wrote:
> >>>>
> >>>>> I told you already: **Include code inline **
> >>>>>
> >>>>> See ?dput for how to include a text version of objects, such as data
> >>>>> frames, inline.
> >>>>>
> >>>>> Otherwise, I believe .txt text files are not stripped if you insist
> >>>>> on
> >>>>> *attaching* data or code. Others may have better advice.
> >>>>>
> >>>>>
> >>>>> Bert Gunter
> >>>>>
> >>>>> "The trouble with having an open mind is that people keep coming
> >>>>> along and sticking things into it."
> >>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>>>
> >>>>>
> >>>>> On Tue, Apr 2, 2019 at 1:21 PM Eric Bridgeford <ericwb95 at gmail.com>
> >>>>> wrote:
> >>>>>
> >>>>>> How can I add attachments? The following two files were attached in
> >>>>>> the initial message
> >>>>>>
> >>>>>> On Tue, Apr 2, 2019 at 3:34 PM Bert Gunter <bgunter.4567 at gmail.com>
> >>>>>> wrote:
> >>>>>>
> >>>>>>> Nothing was attached. The r-help server strips most attachments.
> >>>>>>> Include your code inline.
> >>>>>>>
> >>>>>>> Also note that
> >>>>>>>
> >>>>>>>> 0/0
> >>>>>>> [1] NaN
> >>>>>>>
> >>>>>>> so maybe something like that occurs in the course of your
> >> calculations.
> >>>>>>> But that's just a guess, so feel free to disregard.
> >>>>>>>
> >>>>>>>
> >>>>>>> Bert Gunter
> >>>>>>>
> >>>>>>> "The trouble with having an open mind is that people keep coming
> >>>>>>> along and sticking things into it."
> >>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>>>>>
> >>>>>>>
> >>>>>>> On Tue, Apr 2, 2019 at 11:32 AM Eric Bridgeford
> >>>>>>> <ericwb95 at gmail.com>
> >>>>>>> wrote:
> >>>>>>>
> >>>>>>>> Hi R core team,
> >>>>>>>>
> >>>>>>>> I experienced the following issue with the attached data/code
> >>>>>>>> snippet, where the studentized residual for a single observation
> >>>>>>>> appears to be NaN given finite predictors/responses, which appears
> >>>>>>>> to be driven by the glm.influence method in the stats package. I
> >>>>>>>> am curious to whether this is a consequence of the specific
> >>>>>>>> implementation used for computing the influence, which it would
> >>>>>>>> appear is the driving force for the NaN influence for the point,
> >>>>>>>> that I was ultimately able to trace back through the lm.influence
> >>>>>>>> method to this specific line <
> >>>>>>>> https://github.com/SurajGupta/r-
> >>> source/blob/a28e609e72ed7c47f6ddfb
> >>>>>>>> b86c85279a0750f0b7/src/library/stats/R/lm.influence.R#L67
> >>>>>>>>>
> >>>>>>>> which
> >>>>>>>> calls C code which calls iminfl.f
> >>>>>>>> <
> >>>>>>>>
> https://github.com/SurajGupta/r-source/blob/master/src/library/sta
> >>>>>>>> ts/src/lminfl.f
> >>>>>>>>>
> >>>>>>>> (I
> >>>>>>>> don't know fortran so I can't debug further). My understanding is
> >>>>>>>> that the specific issue would have to do with the leave-one-out
> >>>>>>>> variance estimate associated with this particular point, which it
> >>>>>>>> seems based on my understanding should be finite given finite
> >>>>>>>> predictors/responses. Let me know. Thanks!
> >>>>>>>>
> >>>>>>>> Sincerely,
> >>>>>>>>
> >>>>>>>> --
> >>>>>>>> Eric Bridgeford
> >>>>>>>> ericwb.me
> >>>>>>>> ______________________________________________
> >>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>> PLEASE do read the posting guide
> >>>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>>>>
> >>>>>>>
> >>>>>>
> >>>>>> --
> >>>>>> Eric Bridgeford
> >>>>>> ericwb.me
> >>>>>>
> >>>>>
> >>>
> >>> --
> >>> Eric Bridgeford
> >>> ericwb.me
> >>>
> >>>      [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posting-
> >>> guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
> > --
> > Eric Bridgeford
> > ericwb.me
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

-- 
Eric Bridgeford
ericwb.me

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Apr  3 21:57:13 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 3 Apr 2019 12:57:13 -0700
Subject: [R] function predict
In-Reply-To: <CAD2h5ZhwEk5E97UWOdzo0o3JsHYkwDVZy8vv_3oCkGPT6KdThQ@mail.gmail.com>
References: <5c9119a6.1c69fb81.1264d.fa3a@mx.google.com>
 <CAD2h5ZhwEk5E97UWOdzo0o3JsHYkwDVZy8vv_3oCkGPT6KdThQ@mail.gmail.com>
Message-ID: <CAGxFJbSOoed-Ws4NSM99+UTedGu-qTsUpk1Q33GXOA1uk3kZmw@mail.gmail.com>

This list has *no homework* policy. I would assume that the purpose of your
"project" is for you to learn how to deal with exactly the sorts of issues
you describe.

(But you might get lucky with a response anyway).

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Apr 3, 2019 at 12:48 PM Michaela Berndl <michib567 at gmail.com> wrote:

> Dear Sir or Madam,
>
>
>
> we are statistic students at the Johannes Kepler University in Linz,
> Austria.
>
> In a project we had to analyse the time series influenza from the package
> tscount and make a prediction for one year. For the prediction we used the
> function predict from the package raster.
>
> Since our data ends not at the end of a year, but at week 23 in the year
> 2012, we need to predict till the 23th week of 2013.
>
>
>
> As identified in the Figure (boxplot of the original data) attached, in the
> first months of
>
> every year the recorded cases were always higher than in the rest of the
> year.
>
> The other figure shows the prediction with three models (the 3 colored
> lines) from week 23 in the year 2012 to week 22 in the year 2013 and the
> original data (the black line) for the same time. Due to the fact that the
> the peaks of the prediction lines are not even close to the original data,
> we are not sure whether the predict function is correct. We suspect that
> the predict function just works for a prediction of exactly one year, which
> starts at week 1 and ends at week 52.
>
>
>
>
>
> Kind regards,
> Doris Kuttner, Michaela Berndl
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Wed Apr  3 22:17:01 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Thu, 4 Apr 2019 09:17:01 +1300
Subject: [R] [FORGED] Re:  Potential Issue with lm.influence
In-Reply-To: <CAGx1TMB721VDxCeO9CS8Td+MsPmoWyWEc0tW92v65yz5nxj5LQ@mail.gmail.com>
References: <CAGfc6q2VGpAyymnDRVoMij2zD2-ayu+u4WhLRK4EHo4_mT2Xdg@mail.gmail.com>
 <CAGfc6q3V1FgeZT-AaKsrXL13WEYXbduZG3NweE64XGe19Xbeig@mail.gmail.com>
 <CAGxFJbR0j6asRCE21Btr+u5-nV0u0LBo63fvqajQinL38qECqw@mail.gmail.com>
 <CAGfc6q0agc=wAQhT6q91LYnO_Qr29CuPB5-OmN-_rwn1QGBsYw@mail.gmail.com>
 <CAGxFJbRfEPmLYEPqk0ksqi-WGaT4A8Mx2eEdjWJx9W46=tMY8A@mail.gmail.com>
 <CAGxFJbSJMF2PQY+9HDzczn0omhySK=nAOb2X2G9ZJZeFLSwMWw@mail.gmail.com>
 <23230_1554243133_x32MCCLX018357_CAGfc6q1-k6jTcTe17BM-9b6_Tcx2bxXP6r9iZsAFBMuRUEoSJQ@mail.gmail.com>
 <ACD1644AA6C67E4FBD0C350625508EC836B3FEE1@FHSDB2D11-2.csu.mcmaster.ca>
 <9998_1554287833_x33AbC1o016465_CAGfc6q1FCfdpRAkjCA0imYi6nrgjf5orWwvm_g3P1iBCBc=Ffg@mail.gmail.com>
 <D5989BEF-59D9-46A0-9D8C-07DECED39791@mcmaster.ca>
 <CAGx1TMB721VDxCeO9CS8Td+MsPmoWyWEc0tW92v65yz5nxj5LQ@mail.gmail.com>
Message-ID: <9bc87d30-1206-b6d3-3354-e863764282dd@auckland.ac.nz>

On 4/04/19 5:34 AM, Richard M. Heiberger wrote:
> fortune nomination.
> 
> 
> The lesson to me here is that if you fit a sufficiently unreasonable
> model to data, the computations may break down.

<SNIP>

I second the nomination!

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From pro|jcn@@h @end|ng |rom gm@||@com  Thu Apr  4 04:13:03 2019
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Wed, 3 Apr 2019 22:13:03 -0400
Subject: [R] function predict
In-Reply-To: <CAGxFJbSOoed-Ws4NSM99+UTedGu-qTsUpk1Q33GXOA1uk3kZmw@mail.gmail.com>
References: <5c9119a6.1c69fb81.1264d.fa3a@mx.google.com>
 <CAD2h5ZhwEk5E97UWOdzo0o3JsHYkwDVZy8vv_3oCkGPT6KdThQ@mail.gmail.com>
 <CAGxFJbSOoed-Ws4NSM99+UTedGu-qTsUpk1Q33GXOA1uk3kZmw@mail.gmail.com>
Message-ID: <7e8a1d8a-975b-c87f-8329-cc5c06930bd1@gmail.com>

I was about to reply to the item with a similar msg as Bert, but then
realized that the students were pointing out that the function (possibly
less than perfectly documented -- I didn't check) only works for complete
years. I've encountered that issue myself when teaching forecasting. So
I was prepared to accept the item more as a feature request or at least
a documentation request.

It would, of course, be useful for both homework and research use to have
a function able to do partial year forecasts, and I suspect there is that
capability in R somewhere. I've built custom scripts for that, but more than
a decade and a half ago. It takes time and care.

JN

On 2019-04-03 3:57 p.m., Bert Gunter wrote:
> This list has *no homework* policy. I would assume that the purpose of your
> "project" is for you to learn how to deal with exactly the sorts of issues
> you describe.
> 
> (But you might get lucky with a response anyway).
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Wed, Apr 3, 2019 at 12:48 PM Michaela Berndl <michib567 at gmail.com> wrote:
> 
>> Dear Sir or Madam,
>>
>>
>>
>> we are statistic students at the Johannes Kepler University in Linz,
>> Austria.
>>
>> In a project we had to analyse the time series influenza from the package
>> tscount and make a prediction for one year. For the prediction we used the
>> function predict from the package raster.
>>
>> Since our data ends not at the end of a year, but at week 23 in the year
>> 2012, we need to predict till the 23th week of 2013.
>>
>>
>>
>> As identified in the Figure (boxplot of the original data) attached, in the
>> first months of
>>
>> every year the recorded cases were always higher than in the rest of the
>> year.
>>
>> The other figure shows the prediction with three models (the 3 colored
>> lines) from week 23 in the year 2012 to week 22 in the year 2013 and the
>> original data (the black line) for the same time. Due to the fact that the
>> the peaks of the prediction lines are not even close to the original data,
>> we are not sure whether the predict function is correct. We suspect that
>> the predict function just works for a prediction of exactly one year, which
>> starts at week 1 and ends at week 52.
>>
>>
>>
>>
>>
>> Kind regards,
>> Doris Kuttner, Michaela Berndl
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @gent@ @end|ng |rom medd@t@|nc@com  Thu Apr  4 04:54:46 2019
From: @gent@ @end|ng |rom medd@t@|nc@com (H)
Date: Wed, 3 Apr 2019 22:54:46 -0400
Subject: [R] Free financial data - equities,
 equity options and ETFs - for quantmod package (or other packages)
In-Reply-To: <CAGgJW75usFVG9HmNQHQsodnNhhc9o5f2s2a5PYOj9r=bkkOwaA@mail.gmail.com>
References: <d4164bfa-cc12-6164-1b5c-fcb3a82837e2@meddatainc.com>
 <CAGgJW75usFVG9HmNQHQsodnNhhc9o5f2s2a5PYOj9r=bkkOwaA@mail.gmail.com>
Message-ID: <36a6d0a5-8e8f-8bf4-eb57-5dbd11f3a44f@meddatainc.com>

On 04/03/2019 03:12 AM, Eric Berger wrote:
> You might want to post this to the group R-Sig-Finance
> https://stat.ethz.ch/mailman/listinfo/r-sig-finance?
>
> ?and also check their archives
>
>
> On Wed, Apr 3, 2019 at 1:11 AM H <agents at meddatainc.com <mailto:agents at meddatainc.com>> wrote:
>
>     I am relatively new to analyzing financial data but have some experience with R. I understand that the data available from Yahoo Finance via its API is often questionable in quality and Google Finance is no longer available.
>
>     Although Googling pointed me to some other sources such as Quandl etc., I am curious which other data sources quantmod itself supports for data retrieval, ie via an API, not via downloading and importing CSV-files?
>
>     My interest is really US equities, stock options and ETFs - if possible from the same data source...
>
>     Pointers to favorite data sources appreciated!
>
>     Thank you.
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
Thank you, will do.


	[[alternative HTML version deleted]]


From @||redo@rocc@to @end|ng |rom |@@twebnet@|t  Thu Apr  4 10:56:58 2019
From: @||redo@rocc@to @end|ng |rom |@@twebnet@|t (Alfredo)
Date: Thu, 4 Apr 2019 10:56:58 +0200
Subject: [R] R: Structuring data for Correspondence Analysis
In-Reply-To: <e7fce186-379d-620d-291c-f3f989972db8@yorku.ca>
References: <005201d4e634$3f537930$bdfa6b90$@fastwebnet.it>
 <e7fce186-379d-620d-291c-f3f989972db8@yorku.ca>
Message-ID: <002001d4eac4$5cac6ac0$16054040$@fastwebnet.it>

Hi Michael et al,

I solved by myself simply running the code below.

Thanks anyway for the answers

Alfredo

 

 

t <- read.csv(file="C:\\Temp\\radio_survey.csv", header=TRUE, sep=",")

 

t1 <- table(t$Preference, t$Sex)

t2 <- table(t$Preference, t$Age)

t3 <- table(t$Preference, t$Time)

 

ct <- cbind(t1, t2, t3)

 

ca <- ca(ct)

 

 

 

 

-----Messaggio originale-----
Da: Michael Friendly <friendly at yorku.ca> 
Inviato: sabato 30 marzo 2019 16:52
A: Alfredo <alfredo.roccato at fastwebnet.it>; r-help at R-project.org
Oggetto: Re: Structuring data for Correspondence Analysis

 

I think something like table(Preference, Sex, data=table) will get you started. With 3+ variables, you are probably looking for a MCA analysis or simple CA using the stacked approach.

 

Your SAS table statement,

 

table Preference, Sex Age Time;

 

treats Preference vs. all combinations of Sex, Age & Time.  This corresponds to a loglinear model asserting Preference is jointly independent of the other three.

 

See the vignette for the vcdExtra package for this kind of thing more generally.

 

install.packages("vcdExtra")

browseVignettes("vcdExtra")

 

See my book, Discrete Data Analysis with R,  <http://ddar.datavis.ca/> http://ddar.datavis.ca/

 

best,

-Michael

 

On 3/29/2019 9:35 AM, Alfredo wrote:

> Hi, I am very new to r and need help from you to do a correspondence 

> analysis because I don't know how to structure the following data:

> 

> Thank you.

> 

> Alfredo

> 

>   

> 

> library(ca,lib.loc=folder)

> 

> table <- read.csv(file="C:\\Temp\\Survey_Data.csv", header=TRUE, 

> sep=",")

> 

> head (table, n=20)

> 

>                  Preference   Sex        Age   Time

> 

> 1           News/Info/Talk     M      25-30  06-09

> 

> 2                Classical     F      >35    09-12

> 

> 3          Rock and Top 40     F      21-25  12-13

> 

> 4                     Jazz     M      >35    13-16

> 

> 5           News/Info/Talk     F      25-30  16-18

> 

> 6             Don't listen     F      30-35  18-20

> 

> ...

> 

> 19         Rock and Top 40     M      25-30  16-18

> 

> 20          Easy Listening     F      >35    18-20

> 

>   

> 

> In SAS I would simply do this:

> 

> proc corresp data=table dim=2 outc=_coord;

> 

>     table Preference, Sex Age Time;

> 

> run;

> 

>   

> 

> I don't know how convert in R a data frame to a frequency table to 

> execute properly this function:

> 

> ca <- ca(<frequency table>, graph=FALSE)

> 

> 

>          [[alternative HTML version deleted]]

> 

 

 

-- 

Michael Friendly     Email: friendly AT yorku DOT ca

Professor, Psychology Dept. & Chair, ASA Statistical Graphics Section

York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814

4700 Keele Street    Web:    <http://www.datavis.ca> http://www.datavis.ca  |  @datavisFriendly

Toronto, ONT  M3J 1P3 CANADA


	[[alternative HTML version deleted]]


From m@t|r|m| @end|ng |rom gm@||@com  Thu Apr  4 01:31:59 2019
From: m@t|r|m| @end|ng |rom gm@||@com (Matty A)
Date: Thu, 4 Apr 2019 00:31:59 +0100
Subject: [R] Help interpreting data
Message-ID: <CAFXsueZ1KOW6MJvMFxRZffX3fyk+R+gVkOUps0LLCWccj744fQ@mail.gmail.com>

Message rejected by filter rule match




---------- Forwarded message ----------
From: matty <matirimi at gmail.com>
To: r-help at r-project.org
Cc:
Bcc:
Date: Wed, 3 Apr 2019 18:21:28 -0500 (CDT)
Subject: res intepretation help
Hi.. im a complete novice and am using R for my dissertation which is a
meta-analysis... im using res would like some advice on
understanding my results and what I can do with them.. the original data is
h' values (linearity of social hierarchies) i have 11
samples with 2 h' values that i am looking at my each res code has only one
h' value the h' value is places where r would be in the code... below is a
few of mu outputs.... thank you


> res(1, var.r=NULL, 6, level=95, dig = 4, verbose = TRUE, id=NULL, data =
> NULL) ?
Bonanni et al 2017 La Rustica   Free-ranging submission
Mean Differences ES:

 d [ 95 %CI] = Inf [ NaN , NaN ]
  var(d) = NaN
  p-value(d) = NaN
  U3(d) = 100 %
  CLES(d) = 100 %
  Cliff's Delta = 1

 Correlation ES:

 r [ 95 %CI] = 1 [ NaN , NaN ]
  var(r) = 0
  p-value(r) = 0

 z [ 95 %CI] = Inf [ Inf , Inf ]
  var(z) = 0.3333
  p-value(z) = 0

 Odds Ratio ES:

 OR [ 95 %CI] = Inf [ NaN , NaN ]
  p-value(OR) = NaN

 Log OR [ 95 %CI] = Inf [ NaN , NaN ]
  var(lOR) = NaN
  p-value(Log OR) = NaN

 Other:

 NNT = 1.25
 Total N = 6
> res(0.860, var.r=NULL, 6, level=95, dig = 4, verbose = TRUE, id=NULL, data
> = NULL) ?
Bonanni et al 2017 La Rustica Free-ranging aggression
Mean Differences ES:

 d [ 95 %CI] = 3.3706 [ -1.135 , 7.8762 ]
  var(d) = 3.0722
  p-value(d) = 0.1125
  U3(d) = 99.9625 %
  CLES(d) = 99.1423 %
  Cliff's Delta = 0.9828

 Correlation ES:

 r [ 95 %CI] = 0.86 [ -0.1885 , 0.9923 ]
  var(r) = 0.0136
  p-value(r) = 0.0752

 z [ 95 %CI] = 1.2933 [ -0.1908 , 2.7775 ]
  var(z) = 0.3333
  p-value(z) = 0.0752

 Odds Ratio ES:

 OR [ 95 %CI] = 451.964 [ 0.1276 , 1600648 ]
  p-value(OR) = 0.1125

 Log OR [ 95 %CI] = 6.1136 [ -2.0587 , 14.2859 ]
  var(lOR) = 10.1071
  p-value(Log OR) = 0.1125

 Other:

 NNT = 1.259
 Total N =

	[[alternative HTML version deleted]]


From cry@n @end|ng |rom b|ngh@mton@edu  Thu Apr  4 18:12:08 2019
From: cry@n @end|ng |rom b|ngh@mton@edu (Chris Ryan)
Date: Thu, 04 Apr 2019 12:12:08 -0400
Subject: [R] Help interpreting data
In-Reply-To: <CAFXsueZ1KOW6MJvMFxRZffX3fyk+R+gVkOUps0LLCWccj744fQ@mail.gmail.com>
References: <CAFXsueZ1KOW6MJvMFxRZffX3fyk+R+gVkOUps0LLCWccj744fQ@mail.gmail.com>
Message-ID: <0EE6E2B5-1479-4E7D-8FF6-A7B8645A778C@binghamton.edu>

Your dissertation advisor would probably be the best place to start.

Chris Ryan
-- 
Sent from my Android device with K-9 Mail. Please excuse my brevity.

On April 3, 2019 7:31:59 PM EDT, Matty A <matirimi at gmail.com> wrote:
>Message rejected by filter rule match
>
>
>
>
>---------- Forwarded message ----------
>From: matty <matirimi at gmail.com>
>To: r-help at r-project.org
>Cc:
>Bcc:
>Date: Wed, 3 Apr 2019 18:21:28 -0500 (CDT)
>Subject: res intepretation help
>Hi.. im a complete novice and am using R for my dissertation which is a
>meta-analysis... im using res would like some advice on
>understanding my results and what I can do with them.. the original
>data is
>h' values (linearity of social hierarchies) i have 11
>samples with 2 h' values that i am looking at my each res code has only
>one
>h' value the h' value is places where r would be in the code... below
>is a
>few of mu outputs.... thank you
>
>
>> res(1, var.r=NULL, 6, level=95, dig = 4, verbose = TRUE, id=NULL,
>data =
>> NULL) ?
>Bonanni et al 2017 La Rustica   Free-ranging submission
>Mean Differences ES:
>
> d [ 95 %CI] = Inf [ NaN , NaN ]
>  var(d) = NaN
>  p-value(d) = NaN
>  U3(d) = 100 %
>  CLES(d) = 100 %
>  Cliff's Delta = 1
>
> Correlation ES:
>
> r [ 95 %CI] = 1 [ NaN , NaN ]
>  var(r) = 0
>  p-value(r) = 0
>
> z [ 95 %CI] = Inf [ Inf , Inf ]
>  var(z) = 0.3333
>  p-value(z) = 0
>
> Odds Ratio ES:
>
> OR [ 95 %CI] = Inf [ NaN , NaN ]
>  p-value(OR) = NaN
>
> Log OR [ 95 %CI] = Inf [ NaN , NaN ]
>  var(lOR) = NaN
>  p-value(Log OR) = NaN
>
> Other:
>
> NNT = 1.25
> Total N = 6
>> res(0.860, var.r=NULL, 6, level=95, dig = 4, verbose = TRUE, id=NULL,
>data
>> = NULL) ?
>Bonanni et al 2017 La Rustica Free-ranging aggression
>Mean Differences ES:
>
> d [ 95 %CI] = 3.3706 [ -1.135 , 7.8762 ]
>  var(d) = 3.0722
>  p-value(d) = 0.1125
>  U3(d) = 99.9625 %
>  CLES(d) = 99.1423 %
>  Cliff's Delta = 0.9828
>
> Correlation ES:
>
> r [ 95 %CI] = 0.86 [ -0.1885 , 0.9923 ]
>  var(r) = 0.0136
>  p-value(r) = 0.0752
>
> z [ 95 %CI] = 1.2933 [ -0.1908 , 2.7775 ]
>  var(z) = 0.3333
>  p-value(z) = 0.0752
>
> Odds Ratio ES:
>
> OR [ 95 %CI] = 451.964 [ 0.1276 , 1600648 ]
>  p-value(OR) = 0.1125
>
> Log OR [ 95 %CI] = 6.1136 [ -2.0587 , 14.2859 ]
>  var(lOR) = 10.1071
>  p-value(Log OR) = 0.1125
>
> Other:
>
> NNT = 1.259
> Total N =
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From e@@w|ek @end|ng |rom gm@||@com  Thu Apr  4 18:33:10 2019
From: e@@w|ek @end|ng |rom gm@||@com (Ek Esawi)
Date: Thu, 4 Apr 2019 12:33:10 -0400
Subject: [R] Alternative to loops
Message-ID: <CA+ZkTxuCvTzRHLeSPBLoGRPwmwWQu0=3datq6JVM1Fx0kaKNuQ@mail.gmail.com>

Hi All

Her is a sample of my data. A data frame (MyDF) and a list (MyList).  My
own data frame has over 10,000 rows. I want to find out which elements of
MyDF$B contain any element(s) of MYList; then change MyDF$C to the name of
the vector of the list that has match.

I solved this via loops and if statements, using &in&  but I am hoping for
a better solution using the apply family functions. I tried something like
this but did not work.

lapply(strsplit(MyDF$B," "),function(x) lapply(MyList,function(y)  if(sum(y
%in% x)>0,x$Code==y[[1]]))



Thanks in advance--EK

My Sample data

> MyDF

  A    B        C
1 1 aa ab ac 0
2 2 bb bc bd 0
3 3    cc cf 0
4 4       dd 0
5 5       ee 0



> MyList

$X

[1] "a"  "ba" "cc"



$Y

[1] "abs" "aa"  "BA"  "BB"



$z

[1] "ab" "bb" "xy" "zy" "gh"



Desired results.



> MyDF

A        B   C

1 1 aa ab ac Y

2 2 bb bc bd Y

3 3    cc cf X

4 4       dd 0

5 5       ee 0

	[[alternative HTML version deleted]]


From e@@w|ek @end|ng |rom gm@||@com  Thu Apr  4 18:41:43 2019
From: e@@w|ek @end|ng |rom gm@||@com (Ek Esawi)
Date: Thu, 4 Apr 2019 12:41:43 -0400
Subject: [R] Alternative to lops
Message-ID: <CA+ZkTxtWq9iK+mwp36fCU4jHQKNL2i5xPvtaiceD0MtOUyNZNA@mail.gmail.com>

Hi All--

Sorry i sent the one inadvertently

Her is a sample of my data. A data frame (MyDF) and a list (MyList).  My
own data frame has over 10,000 rows. I want to find out which elements of
MyDF$B contain any element(s) of MYList; then change MyDF$C to the name of
the vector of the list that has match.

I solved this via loops and if statements, using &in&  but I am hoping for
a better solution using the apply family functions. I tried something like
this but did not work.

lapply(strsplit(MyDF$B," "),function(x) lapply(MyList,function(y)  if(sum(y
%in% x)>0,x$Code==y[[1]]))

Thanks in advance--EK

My Sample data

> MyDF

    A     B        C
1 1 aa ab ac  0
2 2 bb bc bd  0
3 3    cc cf     0
4 4       dd     0
5 5       ee     0

> MyList

$X
[1] "a"  "ba" "cc"

$Y
[1] "abs" "aa"  "BA"  "BB"

$z
[1] "ab" "bb" "xy" "zy" "gh"



Desired results.



> MyDF

A        B   C
1 1 aa ab ac Y
2 2 bb bc bd Y
3 3    cc cf    X
4 4       dd     0
5 5       ee     0

	[[alternative HTML version deleted]]


From ccberry @end|ng |rom uc@d@edu  Thu Apr  4 20:01:16 2019
From: ccberry @end|ng |rom uc@d@edu (Berry, Charles)
Date: Thu, 4 Apr 2019 18:01:16 +0000
Subject: [R] Alternative to lops
In-Reply-To: <CA+ZkTxtWq9iK+mwp36fCU4jHQKNL2i5xPvtaiceD0MtOUyNZNA@mail.gmail.com>
References: <CA+ZkTxtWq9iK+mwp36fCU4jHQKNL2i5xPvtaiceD0MtOUyNZNA@mail.gmail.com>
Message-ID: <7CBB6971-3A90-46BB-B483-8923A237DE21@ucsd.edu>

Comments inline, but first:

Please review the posting guide and follow the instructions there, especially:

1) "No HTML posting..."

2) "When providing examples, it is best to give an R command that constructs the data,..."

> On Apr 4, 2019, at 9:41 AM, Ek Esawi <esawiek at gmail.com> wrote:
> 
> Hi All--
> 
> Sorry i sent the one inadvertently
> 
> Her is a sample of my data. A data frame (MyDF) and a list (MyList).  My
> own data frame has over 10,000 rows. I want to find out which elements of
> MyDF$B contain any element(s) of MYList; then change MyDF$C to the name of
> the vector of the list that has match.
> 
> I solved this via loops and if statements, using &in&  but I am hoping for
> a better solution using the apply family functions. I tried something like
> this but did not work.
> 
> lapply(strsplit(MyDF$B," "),function(x) lapply(MyList,function(y)  if(sum(y
> %in% x)>0,x$Code==y[[1]]))
> 
> Thanks in advance--EK
> 
> My Sample data
> 
>> MyDF
> 
>    A     B        C
> 1 1 aa ab ac  0
> 2 2 bb bc bd  0
> 3 3    cc cf     0
> 4 4       dd     0
> 5 5       ee     0


Note: You did not tell us if myDF$B is a factor, in which case strsplit needs to accommodate multiple blanks:

 levels(MyDF$B)
[1] "      dd" "      ee" "   cc cf" "aa ab ac" "bb bc bd"
> 

> 
>> MyList
> 
> $X
> [1] "a"  "ba" "cc"
> 
> $Y
> [1] "abs" "aa"  "BA"  "BB"
> 
> $z
> [1] "ab" "bb" "xy" "zy" "gh"
> 
> 
> 
> Desired results.
> 
> 
> 
>> MyDF
> 
> A        B   C
> 1 1 aa ab ac Y

'aa' matches Y, 'ab' matches z, 'cc' does not match

> 2 2 bb bc bd Y

Huh? 'bb' matches z, 'bc' and 'bd' do not match, 

> 3 3    cc cf    X

'cc' matches X, 'cf' does not match

> 4 4       dd     0
> 5 5       ee     0
> 

Neither match.


You need to clarify what it is you seek. The example is hard to penetrate.

Maybe this helps you:

> queries <- strsplit(as.character(MyDF$B), "[ ]+")
> matches <- match( unlist(queries), unlist(MyList), 0)
> hits <- findInterval( matches, 1+cumsum(c(0,lengths(MyList))))
> hitList <- relist(hits, queries)
> hitList
[[1]]
[1] 2 3 0

[[2]]
[1] 3 0 0

[[3]]
[1] 0 1 0

[[4]]
[1] 0 0

[[5]]
[1] 0 0

You can now process hitList to get the desired vector.

HTH,

Chuck

From du|c@|m@ @end|ng |rom b|gpond@com  Fri Apr  5 03:47:48 2019
From: du|c@|m@ @end|ng |rom b|gpond@com (Duncan Mackay)
Date: Fri, 5 Apr 2019 12:47:48 +1100
Subject: [R] add points to lattice cloud plot (3D scatter)
In-Reply-To: <CAMk+s2T=6kcbJ9VCfR3dQfHHMF0qVVjjTt3UcYXXdnPvUqQaoA@mail.gmail.com>
References: <CAMk+s2Te3OtxiXH4uszCcsSiTZiqTBbBvLMm4iFxtYgpv6Q3Bw@mail.gmail.com>
 <b771fd81-b24c-298c-d66d-9adada547cf9@gmail.com>
 <CAMk+s2T=6kcbJ9VCfR3dQfHHMF0qVVjjTt3UcYXXdnPvUqQaoA@mail.gmail.com>
Message-ID: <001c01d4eb51$92a7b610$b7f72230$@bigpond.com>


Hi all

I know it is a bit late but I have been on other things.

This is a custom solution as it requires manual tweeking for further use in
getting the letter positioning

As cloud is fairly rigid I made a duplicate dataset and reduced the x and y
values by 0.1 as a trial.
Will need tweeking possibly in the z direction if needed.
I then combinded the 2 to form a third to which I assigned a grouping factor
G

df = data.frame(Name = c("A", "B", "C", "D", "E"),
              x_axis = c(-0.591, 0.384, -0.384, -0.032, 0.754),
              y_axis = c(-1.302, 1.652, -1.652, 0.326, 0.652),
              z_axis = c(1.33, 1.33, 2.213, 0.032, -0.754),
              stringsAsFactors = FALSE)
df2 = df
df2[,2] <- df2[,2]-.1
df2[,3] <- df2[,3]-.1
df3 <- rbind(df,df2)
df3$G <- rep(letters[1:2],ea= 5)

After trying to use groups with cloud but this did not work even with
distribute.type = TRUE, I then tried panel.superpose but failed.

Using trellis.print works but ALL the axes must be the same it then it was a
simple matter of superimposing them

x1 =
cloud(z_axis ~ x_axis * y_axis, data = df,
      xlab = "X",
      ylab = "Y",
      zlab = "Z",
      xlim = c(-0.691,0.754),
      ylim = c(-1.752,1.652),
      zlim = c(-0.754,2.213),
      scales = list(arrows = FALSE),
      pch = c(rep(16,5), 64:69),
      type = "b",
      col = "red",
      cex = 1.5)
x2 =
cloud(z_axis ~ x_axis * y_axis, data = df2,
      xlab = "X",
      ylab = "Y",
      zlab = "Z",
      xlim = c(-0.691,0.754),
      ylim = c(-1.752,1.652),
      zlim = c(-0.754,2.213),
      scales = list(arrows = FALSE),
      pch = 65:70,
      col = "black",
      type = "p",
      cex = 1.5)
      )

print(x1, position = c(0,0,1,1), more = TRUE)
print(x2, position = c(0,0,1,1), more = FALSE)


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi
Marongiu
Sent: Friday, 1 March 2019 02:39
To: Duncan Murdoch
Cc: r-help
Subject: Re: [R] add points to lattice cloud plot (3D scatter)

I see. I have been thinking of superimposing two plots with
par(new=TRUE), but how could I remove all the graphic parameters
(axes, background etc) keeping only the actual points in lattice? (if
possible).
Tx

On Thu, Feb 28, 2019 at 3:53 PM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:
>
> On 28/02/2019 5:39 a.m., Luigi Marongiu wrote:
> > Dear all,
> > is it possible to add points to a lattice cloud plot (3D scatter)? I
> > can plot the main data, but what if I wanted to add another point. In
> > R there is the high level plotting function plot(), then the low level
> > points() or lines() etc. What is the equivalent for lattice?
>
> I don't know for sure, but I don't think you can do that in lattice.
> The scatterplot3d::scatterplot3d function returns enough information to
> do this, but I don't think lattice::cloud does.  But even
> scatterplot3d::scatterplot3d won't necessarily get it right if points
> hide others that are behind them.  It uses the "painter's algorithm",
> and that needs everything to be drawn in just the right order, which you
> probably won't get if you draw things in several calls.
>
> You can draw things in arbitrary order using rgl::plot3d or related
> functions, but you'll need to do more work yourself to get an array of
> plots like lattice gives.
>
> Duncan Murdoch
>
>
> >
> > Thank you
> >
> >
> >>>>
> >
> > df = data.frame(Name = c("A", "B", "C", "D", "E"),
> >                x_axis = c(-0.591, 0.384, -0.384, -0.032, 0.754),
> >                y_axis = c(-1.302, 1.652, -1.652, 0.326, 0.652),
> >                z_axis = c(1.33, 1.33, 2.213, 0.032, -0.754),
> >                stringsAsFactors = FALSE)
> >
> > cloud(z_axis ~ x_axis * y_axis, data = df,
> >        xlab = "X", ylab = "Y", zlab = "Z",
> >        pch = 16, col = "red", type = "b", cex = 1.5,
> >        ltext(x=df$x_axis, y=df$y_axis, z=df$z_axis,
> >              labels=df$Names, pos=1, offset=1, cex=0.8)
> > )
> >
> > df2 = data.frame(Name = "F",
> >                  x_axis = 0.891,
> >                  y_axis = 2.302
> >                  z_axis = -1.83,
> >                  stringsAsFactors = FALSE)
> >
>


-- 
Best regards,
Luigi

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From du|c@|m@ @end|ng |rom b|gpond@com  Fri Apr  5 03:54:45 2019
From: du|c@|m@ @end|ng |rom b|gpond@com (Duncan Mackay)
Date: Fri, 5 Apr 2019 12:54:45 +1100
Subject: [R] add points to lattice cloud plot (3D scatter)
References: <CAMk+s2Te3OtxiXH4uszCcsSiTZiqTBbBvLMm4iFxtYgpv6Q3Bw@mail.gmail.com>
 <b771fd81-b24c-298c-d66d-9adada547cf9@gmail.com>
 <CAMk+s2T=6kcbJ9VCfR3dQfHHMF0qVVjjTt3UcYXXdnPvUqQaoA@mail.gmail.com> 
Message-ID: <001e01d4eb52$8b0dcc90$a12965b0$@bigpond.com>

Sorry my fingers slipped and hit the send button.

One further thing is that I do not know why distribute.type = TRUE for cloud
did not work

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2350

-----Original Message-----
From: Duncan Mackay [mailto:dulcalma at bigpond.com] 
Sent: Friday, 5 April 2019 12:48
To: 'Luigi Marongiu'
Cc: 'r-help'
Subject: RE: [R] add points to lattice cloud plot (3D scatter)


Hi all

I know it is a bit late but I have been on other things.

This is a custom solution as it requires manual tweeking for further use in
getting the letter positioning

As cloud is fairly rigid I made a duplicate dataset and reduced the x and y
values by 0.1 as a trial.
Will need tweeking possibly in the z direction if needed.
I then combinded the 2 to form a third to which I assigned a grouping factor
G

df = data.frame(Name = c("A", "B", "C", "D", "E"),
              x_axis = c(-0.591, 0.384, -0.384, -0.032, 0.754),
              y_axis = c(-1.302, 1.652, -1.652, 0.326, 0.652),
              z_axis = c(1.33, 1.33, 2.213, 0.032, -0.754),
              stringsAsFactors = FALSE)
df2 = df
df2[,2] <- df2[,2]-.1
df2[,3] <- df2[,3]-.1
df3 <- rbind(df,df2)
df3$G <- rep(letters[1:2],ea= 5)

After trying to use groups with cloud but this did not work even with
distribute.type = TRUE, I then tried panel.superpose but failed.

Using trellis.print works but ALL the axes must be the same it then it was a
simple matter of superimposing them

x1 =
cloud(z_axis ~ x_axis * y_axis, data = df,
      xlab = "X",
      ylab = "Y",
      zlab = "Z",
      xlim = c(-0.691,0.754),
      ylim = c(-1.752,1.652),
      zlim = c(-0.754,2.213),
      scales = list(arrows = FALSE),
      pch = c(rep(16,5), 64:69),
      type = "b",
      col = "red",
      cex = 1.5)
x2 =
cloud(z_axis ~ x_axis * y_axis, data = df2,
      xlab = "X",
      ylab = "Y",
      zlab = "Z",
      xlim = c(-0.691,0.754),
      ylim = c(-1.752,1.652),
      zlim = c(-0.754,2.213),
      scales = list(arrows = FALSE),
      pch = 65:70,
      col = "black",
      type = "p",
      cex = 1.5)
      )

print(x1, position = c(0,0,1,1), more = TRUE)
print(x2, position = c(0,0,1,1), more = FALSE)


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi
Marongiu
Sent: Friday, 1 March 2019 02:39
To: Duncan Murdoch
Cc: r-help
Subject: Re: [R] add points to lattice cloud plot (3D scatter)

I see. I have been thinking of superimposing two plots with
par(new=TRUE), but how could I remove all the graphic parameters
(axes, background etc) keeping only the actual points in lattice? (if
possible).
Tx

On Thu, Feb 28, 2019 at 3:53 PM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:
>
> On 28/02/2019 5:39 a.m., Luigi Marongiu wrote:
> > Dear all,
> > is it possible to add points to a lattice cloud plot (3D scatter)? I
> > can plot the main data, but what if I wanted to add another point. In
> > R there is the high level plotting function plot(), then the low level
> > points() or lines() etc. What is the equivalent for lattice?
>
> I don't know for sure, but I don't think you can do that in lattice.
> The scatterplot3d::scatterplot3d function returns enough information to
> do this, but I don't think lattice::cloud does.  But even
> scatterplot3d::scatterplot3d won't necessarily get it right if points
> hide others that are behind them.  It uses the "painter's algorithm",
> and that needs everything to be drawn in just the right order, which you
> probably won't get if you draw things in several calls.
>
> You can draw things in arbitrary order using rgl::plot3d or related
> functions, but you'll need to do more work yourself to get an array of
> plots like lattice gives.
>
> Duncan Murdoch
>
>
> >
> > Thank you
> >
> >
> >>>>
> >
> > df = data.frame(Name = c("A", "B", "C", "D", "E"),
> >                x_axis = c(-0.591, 0.384, -0.384, -0.032, 0.754),
> >                y_axis = c(-1.302, 1.652, -1.652, 0.326, 0.652),
> >                z_axis = c(1.33, 1.33, 2.213, 0.032, -0.754),
> >                stringsAsFactors = FALSE)
> >
> > cloud(z_axis ~ x_axis * y_axis, data = df,
> >        xlab = "X", ylab = "Y", zlab = "Z",
> >        pch = 16, col = "red", type = "b", cex = 1.5,
> >        ltext(x=df$x_axis, y=df$y_axis, z=df$z_axis,
> >              labels=df$Names, pos=1, offset=1, cex=0.8)
> > )
> >
> > df2 = data.frame(Name = "F",
> >                  x_axis = 0.891,
> >                  y_axis = 2.302
> >                  z_axis = -1.83,
> >                  stringsAsFactors = FALSE)
> >
>


-- 
Best regards,
Luigi

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From @gent@ @end|ng |rom medd@t@|nc@com  Fri Apr  5 05:33:57 2019
From: @gent@ @end|ng |rom medd@t@|nc@com (H)
Date: Thu, 04 Apr 2019 23:33:57 -0400
Subject: [R] R SIG mailing lists
Message-ID: <F0866F3F-6025-4D87-AAC4-B726D66DC7BD@meddatainc.com>

Are there any SIGs for the use of R in healthcare or in genomics or biology?
	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Apr  5 06:39:27 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 4 Apr 2019 21:39:27 -0700
Subject: [R] R SIG mailing lists
In-Reply-To: <F0866F3F-6025-4D87-AAC4-B726D66DC7BD@meddatainc.com>
References: <F0866F3F-6025-4D87-AAC4-B726D66DC7BD@meddatainc.com>
Message-ID: <CAGxFJbQW6Bnvx7JR4u+Y-uuNVCDGLiNxA705B6S_TLa7A8hRTQ@mail.gmail.com>

https://www.r-project.org/mail.html

Found immediately by a web search on "R Mailing lists" . Please make a
minimal effort yourself before posting, or let us know if you have already
done so but came up empty.

You might try here for genomics:
https://www.bioconductor.org/help/support/

"Healtrhcare" and "Biology" are far too vague and all-encompassing, imo.
This might be of some use to you, however:
https://cran.r-project.org/web/views/

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Apr 4, 2019 at 8:34 PM H <agents at meddatainc.com> wrote:

> Are there any SIGs for the use of R in healthcare or in genomics or
> biology?
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wewo|@k| @end|ng |rom gm@||@com  Fri Apr  5 12:14:34 2019
From: wewo|@k| @end|ng |rom gm@||@com (Witold E Wolski)
Date: Fri, 5 Apr 2019 12:14:34 +0200
Subject: [R] isSingular for lm?
Message-ID: <CAAjnpdjZrXjk4H7-C_LYAOm351FNah4YBwfiYvvJ=r57P_p5aw@mail.gmail.com>

lme4 has a function isSingular to check if the fitted model is Singular,

Although lm has the parameter singular.ok = TRUE by defualt, I could
not find a function to check if the fitted model is singular.

What would be the correct way to implement such a function for and lm object?
Check if df.residuals == 0

Thanks
Witek





-- 
Witold Eryk Wolski


From pd@|gd @end|ng |rom gm@||@com  Fri Apr  5 13:22:06 2019
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Fri, 5 Apr 2019 13:22:06 +0200
Subject: [R] isSingular for lm?
In-Reply-To: <CAAjnpdjZrXjk4H7-C_LYAOm351FNah4YBwfiYvvJ=r57P_p5aw@mail.gmail.com>
References: <CAAjnpdjZrXjk4H7-C_LYAOm351FNah4YBwfiYvvJ=r57P_p5aw@mail.gmail.com>
Message-ID: <5FCCA435-8117-44CE-9927-F1B9F911462C@gmail.com>

Can't you just check for NA coefficients?

> y <- rnorm(10) ; x <- rep(0,10)
> coef(lm(y~x))
(Intercept)           x 
 -0.0962404          NA 

so 

> any(is.na(coef(lm(y~x))))
[1] TRUE

I have a vague recollection that at some point there might have been dragons lurking in there (? - NA coefs silently removed), but I can't see a problem with it presently.

-pd

> On 5 Apr 2019, at 12:14 , Witold E Wolski <wewolski at gmail.com> wrote:
> 
> lme4 has a function isSingular to check if the fitted model is Singular,
> 
> Although lm has the parameter singular.ok = TRUE by defualt, I could
> not find a function to check if the fitted model is singular.
> 
> What would be the correct way to implement such a function for and lm object?
> Check if df.residuals == 0
> 
> Thanks
> Witek
> 
> 
> 
> 
> 
> -- 
> Witold Eryk Wolski
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From m@rc_@chw@rtz @end|ng |rom me@com  Fri Apr  5 14:04:22 2019
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Fri, 5 Apr 2019 08:04:22 -0400
Subject: [R] R SIG mailing lists
In-Reply-To: <CAGxFJbQW6Bnvx7JR4u+Y-uuNVCDGLiNxA705B6S_TLa7A8hRTQ@mail.gmail.com>
References: <F0866F3F-6025-4D87-AAC4-B726D66DC7BD@meddatainc.com>
 <CAGxFJbQW6Bnvx7JR4u+Y-uuNVCDGLiNxA705B6S_TLa7A8hRTQ@mail.gmail.com>
Message-ID: <F7969853-1108-4271-BDBE-D7EEFB9DA643@me.com>

Hi,

To supplement Bert's reply, there is not a specific SIG list for R in healthcare, however, there are a number of us, both in the pre-clinical and clinical realm, that participate here on R-Help.

As Bert noted, for genomic applications, the Bioconductor folks have their own lists.

If you have specific R programming related queries that are for applications such as clinical trials and related study types, feel free to ask here.

If you have more conceptual queries regarding statistical methodologies and related topics, those would be off-topic here, and you might wish to check out:

1. The MedStats group on Google
https://groups.google.com/forum/#!forum/medstats

2. datamethods group
https://discourse.datamethods.org


Regards,

Marc Schwartz


> On Apr 5, 2019, at 12:39 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> https://www.r-project.org/mail.html
> 
> Found immediately by a web search on "R Mailing lists" . Please make a
> minimal effort yourself before posting, or let us know if you have already
> done so but came up empty.
> 
> You might try here for genomics:
> https://www.bioconductor.org/help/support/
> 
> "Healtrhcare" and "Biology" are far too vague and all-encompassing, imo.
> This might be of some use to you, however:
> https://cran.r-project.org/web/views/
> 
> -- Bert
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Thu, Apr 4, 2019 at 8:34 PM H <agents at meddatainc.com> wrote:
> 
>> Are there any SIGs for the use of R in healthcare or in genomics or
>> biology?
>>        [[alternative HTML version deleted]]


From Power@@R@nd@|| @end|ng |rom b|@@gov  Fri Apr  5 14:23:35 2019
From: Power@@R@nd@|| @end|ng |rom b|@@gov (Powers, Randall - BLS)
Date: Fri, 5 Apr 2019 12:23:35 +0000
Subject: [R] R SIG mailing lists
In-Reply-To: <CAGxFJbQW6Bnvx7JR4u+Y-uuNVCDGLiNxA705B6S_TLa7A8hRTQ@mail.gmail.com>
References: <F0866F3F-6025-4D87-AAC4-B726D66DC7BD@meddatainc.com>
 <CAGxFJbQW6Bnvx7JR4u+Y-uuNVCDGLiNxA705B6S_TLa7A8hRTQ@mail.gmail.com>
Message-ID: <ee58bd67d3af4a04b687686338a90801@BLSMX04.psb.bls.gov>

I think you mean "Healthcare" not "Healthrcare."

Please take minimal time to check your spelling before replying to a post. :)

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
Sent: Friday, April 5, 2019 12:39 AM
To: H <agents at meddatainc.com>
Cc: R Mailing List <r-help at r-project.org>
Subject: Re: [R] R SIG mailing lists

https://www.r-project.org/mail.html

Found immediately by a web search on "R Mailing lists" . Please make a minimal effort yourself before posting, or let us know if you have already done so but came up empty.

You might try here for genomics:
https://www.bioconductor.org/help/support/

"Healtrhcare" and "Biology" are far too vague and all-encompassing, imo.
This might be of some use to you, however:
https://cran.r-project.org/web/views/

-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Apr 4, 2019 at 8:34 PM H <agents at meddatainc.com> wrote:

> Are there any SIGs for the use of R in healthcare or in genomics or 
> biology?
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From j|ox @end|ng |rom mcm@@ter@c@  Fri Apr  5 16:26:19 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Fri, 5 Apr 2019 14:26:19 +0000
Subject: [R] isSingular for lm?
In-Reply-To: <7178_1554463340_x35BMKWH031668_5FCCA435-8117-44CE-9927-F1B9F911462C@gmail.com>
References: <CAAjnpdjZrXjk4H7-C_LYAOm351FNah4YBwfiYvvJ=r57P_p5aw@mail.gmail.com>
 <7178_1554463340_x35BMKWH031668_5FCCA435-8117-44CE-9927-F1B9F911462C@gmail.com>
Message-ID: <FEF688B8-F6A6-4D4A-BB4E-B617512CBB10@mcmaster.ca>

Hi Peter,


> On Apr 5, 2019, at 7:22 AM, peter dalgaard <pdalgd at gmail.com> wrote:
> 
> Can't you just check for NA coefficients?
> 
>> y <- rnorm(10) ; x <- rep(0,10)
>> coef(lm(y~x))
> (Intercept)           x 
> -0.0962404          NA 
> 
> so 
> 
>> any(is.na(coef(lm(y~x))))
> [1] TRUE
> 
> I have a vague recollection that at some point there might have been dragons lurking in there (? - NA coefs silently removed), but I can't see a problem with it presently.

I think that the problem you recall related to vcov.lm() and not coef(). vcov.lm() silently removed NAs, which motivated the introduction of the complete argument, defaulting to TRUE. AFAIK, coef() always included NAs in the coefficient vector for a singular fit.

Best,
 John

  -------------------------------------------------
  John Fox, Professor Emeritus
  McMaster University
  Hamilton, Ontario, Canada
  Web: http::/socserv.mcmaster.ca/jfox

> 
> -pd
> 
>> On 5 Apr 2019, at 12:14 , Witold E Wolski <wewolski at gmail.com> wrote:
>> 
>> lme4 has a function isSingular to check if the fitted model is Singular,
>> 
>> Although lm has the parameter singular.ok = TRUE by defualt, I could
>> not find a function to check if the fitted model is singular.
>> 
>> What would be the correct way to implement such a function for and lm object?
>> Check if df.residuals == 0
>> 
>> Thanks
>> Witek
>> 
>> 
>> 
>> 
>> 
>> -- 
>> Witold Eryk Wolski
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @gent@ @end|ng |rom medd@t@|nc@com  Fri Apr  5 16:31:52 2019
From: @gent@ @end|ng |rom medd@t@|nc@com (H)
Date: Fri, 5 Apr 2019 10:31:52 -0400
Subject: [R] R SIG mailing lists
In-Reply-To: <CAGxFJbQW6Bnvx7JR4u+Y-uuNVCDGLiNxA705B6S_TLa7A8hRTQ@mail.gmail.com>
References: <F0866F3F-6025-4D87-AAC4-B726D66DC7BD@meddatainc.com>
 <CAGxFJbQW6Bnvx7JR4u+Y-uuNVCDGLiNxA705B6S_TLa7A8hRTQ@mail.gmail.com>
Message-ID: <642dafac-7649-6558-54cf-e5d24e4652d9@meddatainc.com>

On 04/05/2019 12:39 AM, Bert Gunter wrote:
> https://www.r-project.org/mail.html
>
> Found immediately by a web search on "R Mailing lists" . Please make a minimal effort yourself before posting, or let us know if you have already done so but came up empty.
>
> You might try here for genomics:
> https://www.bioconductor.org/help/support/
>
> "Healtrhcare" and "Biology" are far too vague and all-encompassing, imo. This might be of some use to you, however:
> https://cran.r-project.org/web/views/
>
> -- Bert
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Apr 4, 2019 at 8:34 PM H <agents at meddatainc.com <mailto:agents at meddatainc.com>> wrote:
>
>     Are there any SIGs for the use of R in healthcare or in genomics or biology?
>     ? ? ? ? [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
I had already looked at the page with mailing lists, of course. Thank you for the other pointers.


	[[alternative HTML version deleted]]


From m|ch@e|@e|@enr|ng @end|ng |rom gmx@ch  Sat Apr  6 01:53:44 2019
From: m|ch@e|@e|@enr|ng @end|ng |rom gmx@ch (Michael Eisenring)
Date: Fri, 5 Apr 2019 18:53:44 -0500
Subject: [R] Color-coding data points in complex dotplot (ggplot2)
Message-ID: <000201d4ec0a$cedc28f0$6c947ad0$@gmx.ch>

Dear R-List members,

I produced a dot plot (see attachment 1) on 6 different treatments (trees
under 6 different conditions; in column " Location.Treatment " in my raw
data). For each of these " Location.treatment" categories, I calculated a
mean value and the SE for a specific compound (%CT).

I am able to produce a plot where all the 6 treatments (in column "
Location.Treatment") are separated (see code and Fig. 1) so that each of two
"con" and "exp" treatments (in the column "treatment") are nested within one
of the three locations (High, mid, low; in the column "Location") (see plot
that the code produces). This is the plot structure I want.

Now I would like to assign colors to the raw data points ( the "point cloud"
next to each mean +SE value). Each of these points stems from a different
"Genotype" and I would like to color code the points with regard to the
genotypes (e.g. all points from Genotype A should be green, all points from
Genotype B should be red etc.) I would like to use my own specified colors
in the code (not the standard palette).

I tried did the following (without success)

1.      I added "aes(color=Genotype,.." into "geom_point(..)"

2.      I added my specific colors to "scale_color_manual"

scale_color_manual(labels=c("Control","Damaged"),values=c("red","black","#06
7c43","#89b651","#dc5b09","#e4a710","#92c5de","grey","#1d71b4","#7873a3"....
..



However, if I do that my "nested" plot structure disappears (i.e. I cannot
visually differentiate between "con" and "exp" treatments nested within mid
/high/. See Fig. 2)

Basically, all I want is to produce a plot that looks like the one from my
actual code( Fig.1) but where the individual data points are colored
according to "Genotypes"

Below is my code and my raw data.

Help is very much appreciated!

Thanks a lot,

Mike



#CODE-----------------------------------------------------

require(ggplot2)



#REMOVE START FOR ANALYSIS

dta<-subset(dta_complete,Time=="Stop")

dta



#Calculation of SE

data_summary <- function(x) {

  m <- mean(x)

  ymin <- m-sd(x)/sqrt(length(x))

  ymax <- m+sd(x)/sqrt(length(x))

  return(c(y=m,ymin=ymin,ymax=ymax))

}



pd1 = position_dodge(0.5)



plot_CT<- ggplot(dta, aes(x=Location, y=CT,
colour=Treatment,shape=Treatment)) +

  stat_summary(fun.data=data_summary, position=pd1, geom="errorbar",
width=0.05) +

  stat_summary(fun.data=data_summary, position=pd1, geom="point", size=2) +

  geom_point(position=position_jitterdodge(dodge.width=0.8, jitter.height=0,
jitter.width=0.2),

             alpha=0.7) +

  labs(title="", x="", y = "CT (% dw)")+

  scale_color_manual(labels=c("Control",
"Damaged"),values=c("red","black"),guide = guide_legend(reverse = TRUE) )+

  scale_shape_manual(labels=c("Control", "Damaged"),name="Treatment",values
= c(16,16),guide = guide_legend(reverse = TRUE) )+

  #Style of background

  theme_classic()+

  #Change title

  theme(plot.title = element_text(color="black", size=17, face="bold"))+

  #Font size axis

  theme(axis.text=element_text(size=12),

        axis.title=element_text(size=17))+

  scale_x_discrete("Location",labels = c("Low", "Mid", "High"),expand=c(0.1,
0.5))+

  coord_flip()



plot_CT



#DATA-----------------------------------------------------------------------
-----------------

structure(list(Location = structure(c(2L, 3L, 1L, 2L, 3L, 1L,

2L, 3L, 1L, 2L, 3L, 1L, 2L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L,

1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L,

2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L,

3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L,

1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L,

3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L,

1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L,

2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L,

3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L,

1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L,

2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L,

3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L), .Label = c("High", "Low", "Mid"

), class = "factor"), Treatment = structure(c(2L, 2L, 2L, 1L,

1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L,

1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L,

2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L,

1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L,

1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L,

2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L,

2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L,

1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L,

2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L,

2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L,

1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L,

2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L), .Label = c("Con", "Exp"

), class = "factor"), Time = structure(c(2L, 2L, 2L, 2L, 2L,

2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,

2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,

2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,

2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,

2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,

2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,

2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,

2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,

2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,

2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,

2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,

2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("Start", "Stop"

), class = "factor"), Genotype = structure(c(7L, 7L, 7L, 7L,

7L, 7L, 4L, 4L, 4L, 4L, 4L, 4L, 6L, 6L, 6L, 6L, 6L, 2L, 2L, 2L,

2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 8L, 8L, 8L, 8L, 8L, 8L, 1L,

1L, 1L, 1L, 1L, 1L, 5L, 5L, 5L, 5L, 5L, 5L, 4L, 4L, 4L, 4L, 4L,

4L, 3L, 3L, 3L, 3L, 3L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 6L, 6L, 6L,

6L, 6L, 6L, 8L, 8L, 8L, 8L, 8L, 8L, 5L, 5L, 5L, 5L, 5L, 5L, 7L,

7L, 7L, 7L, 7L, 1L, 1L, 1L, 1L, 1L, 1L, 5L, 5L, 5L, 5L, 5L, 5L,

1L, 1L, 1L, 1L, 1L, 1L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L,

4L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L,

7L, 7L, 7L, 7L, 6L, 6L, 6L, 6L, 6L, 6L, 8L, 8L, 8L, 8L, 8L, 8L,

2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L,

1L, 1L, 5L, 5L, 5L, 5L, 5L, 5L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L,

8L, 8L, 8L, 8L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("A", "B",

"C", "D", "E", "F", "G", "H"), class = "factor"), Time.Location =
structure(c(5L,

6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 4L, 5L, 6L, 4L,

5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L,

6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L,

4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L,

5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L,

6L, 4L, 5L, 6L, 4L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L,

5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L,

6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L,

4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L,

5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L,

6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L,

4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L), .Label = c("StartHigh",


"StartLow", "StartMid", "StopHigh", "StopLow", "StopMid"), class =
"factor"),

    Location.Treatment = structure(c(4L, 6L, 2L, 3L, 5L, 1L,

    4L, 6L, 2L, 3L, 5L, 1L, 4L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L,

    5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L,

    6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L,

    5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L,

    6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L,

    5L, 1L, 4L, 6L, 2L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L,

    2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L,

    1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L,

    2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L,

    1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L,

    2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L,

    1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L,

    2L, 3L, 5L, 1L), .Label = c("HighCon", "HighExp", "LowCon",

    "LowExp", "MidCon", "MidExp"), class = "factor"), CT = c(4.61538,

    3.96739, 7.34797, 3.58108, 2.89655, 2.7993, 10.56122, 10.68396,

    15.57252, 6.79245, 9.23469, 9.18, 1.1087, 4.26136, 1.14504,

    2.20238, 3.15789, 9.54082, 11.05263, 15.84783, 10.48986,

    12.62195, 15.12931, 5.51471, 8.20313, 11.85811, 3.38115,

    7.5, 9.69512, 8.64407, 11.30597, 14.42797, 8.8125, 11.82482,

    11.53061, 6.97674, 9.62766, 10.88028, 5.50403, 9.73558, 8.56419,

    11.84524, 16.34892, 18.15789, 10.58036, 14.80932, 12.06081,

    12.96992, 9.86014, 12.45652, 6.625, 6.93396, 9.10714, 3.66142,

    9.19811, 10.88346, 2.88851, 6.85096, 10.27778, 8.29787, 13.00885,

    14.38017, 7.5, 11.77734, 13.84615, 2.22772, 5.28, 5.25641,

    1.0514, 2.73256, 4.11111, 11.39098, 11.10236, 13.00781, 7.95259,

    10.15748, 13.16327, 8.90625, 10.04587, 13.625, 6.27049, 9.27966,

    10.94037, 5.80189, 7.76978, 7.34266, 3.80952, 3.75, 7.29545,

    10.45872, 16.83206, 5.95238, 7.70833, 10.92391, 11.03659,

    14.39338, 14.88281, 8.22917, 11.63603, 14.7561, 11.9469,

    14.65649, 16.84615, 8.37209, 13.27982, 13.69128, 7.77778,

    12.59124, 12.32955, 7.00472, 8.41121, 7.22222, 9.43878, 10.33613,

    14.16667, 9.60526, 8.77232, 11.91589, 7.01786, 12.29592,

    11.83673, 8.55634, 11.17347, 12.68836, 2.7551, 6, 7.21374,

    2.52101, 4.03846, 4.80634, 5.49569, 4.78723, 6.02273, 3.04511,

    3.59244, 2.48239, 1.54412, 5.74219, 7.68595, 1.33065, 2.625,

    4.42164, 9.66942, 11.875, 17.91667, 10.81731, 13.05288, 16.23853,

    11.93662, 14.31818, 14.09396, 7.82374, 15.5042, 10.86207,

    6.87023, 11.69492, 12.65957, 3.48684, 5.29018, 7.89474, 10.53309,

    17.05479, 16.63866, 7.43119, 12.06522, 12.05607, 6.14865,

    10.44, 14.69512, 9.24757, 9.04018, 12.38255, 2.22222, 3.90756,

    5.85616, 2.23958, 3.8125, 3.01056, 11.60256, 12.22222, 11.8007,

    7.76316, 10.08197, 12.78777, 9.20455, 12.1875, 16.59449,

    6.82331, 10.91518, 11.5748)), row.names = 192:381, class = "data.frame")












From jrkr|de@u @end|ng |rom gm@||@com  Sat Apr  6 14:23:15 2019
From: jrkr|de@u @end|ng |rom gm@||@com (John Kane)
Date: Sat, 6 Apr 2019 08:23:15 -0400
Subject: [R] Color-coding data points in complex dotplot (ggplot2)
In-Reply-To: <000201d4ec0a$cedc28f0$6c947ad0$@gmx.ch>
References: <000201d4ec0a$cedc28f0$6c947ad0$@gmx.ch>
Message-ID: <CAKZQJMAEG+r5hstaNfSwLC2g=Hz_Y7Oe5gahzg2806dmDYmpWA@mail.gmail.com>

HI Michael
Your code runs but we did not get any attached figure.  You might want
to try sending it as a .pdf file. They usually make it through the
spam filters

On Sat, 6 Apr 2019 at 08:09, Michael Eisenring <michael.eisenring at gmx.ch> wrote:
>
> Dear R-List members,
>
> I produced a dot plot (see attachment 1) on 6 different treatments (trees
> under 6 different conditions; in column " Location.Treatment " in my raw
> data). For each of these " Location.treatment" categories, I calculated a
> mean value and the SE for a specific compound (%CT).
>
> I am able to produce a plot where all the 6 treatments (in column "
> Location.Treatment") are separated (see code and Fig. 1) so that each of two
> "con" and "exp" treatments (in the column "treatment") are nested within one
> of the three locations (High, mid, low; in the column "Location") (see plot
> that the code produces). This is the plot structure I want.
>
> Now I would like to assign colors to the raw data points ( the "point cloud"
> next to each mean +SE value). Each of these points stems from a different
> "Genotype" and I would like to color code the points with regard to the
> genotypes (e.g. all points from Genotype A should be green, all points from
> Genotype B should be red etc.) I would like to use my own specified colors
> in the code (not the standard palette).
>
> I tried did the following (without success)
>
> 1.      I added "aes(color=Genotype,.." into "geom_point(..)"
>
> 2.      I added my specific colors to "scale_color_manual"
>
> scale_color_manual(labels=c("Control","Damaged"),values=c("red","black","#06
> 7c43","#89b651","#dc5b09","#e4a710","#92c5de","grey","#1d71b4","#7873a3"....
> ..
>
>
>
> However, if I do that my "nested" plot structure disappears (i.e. I cannot
> visually differentiate between "con" and "exp" treatments nested within mid
> /high/. See Fig. 2)
>
> Basically, all I want is to produce a plot that looks like the one from my
> actual code( Fig.1) but where the individual data points are colored
> according to "Genotypes"
>
> Below is my code and my raw data.
>
> Help is very much appreciated!
>
> Thanks a lot,
>
> Mike
>
>
>
> #CODE-----------------------------------------------------
>
> require(ggplot2)
>
>
>
> #REMOVE START FOR ANALYSIS
>
> dta<-subset(dta_complete,Time=="Stop")
>
> dta
>
>
>
> #Calculation of SE
>
> data_summary <- function(x) {
>
>   m <- mean(x)
>
>   ymin <- m-sd(x)/sqrt(length(x))
>
>   ymax <- m+sd(x)/sqrt(length(x))
>
>   return(c(y=m,ymin=ymin,ymax=ymax))
>
> }
>
>
>
> pd1 = position_dodge(0.5)
>
>
>
> plot_CT<- ggplot(dta, aes(x=Location, y=CT,
> colour=Treatment,shape=Treatment)) +
>
>   stat_summary(fun.data=data_summary, position=pd1, geom="errorbar",
> width=0.05) +
>
>   stat_summary(fun.data=data_summary, position=pd1, geom="point", size=2) +
>
>   geom_point(position=position_jitterdodge(dodge.width=0.8, jitter.height=0,
> jitter.width=0.2),
>
>              alpha=0.7) +
>
>   labs(title="", x="", y = "CT (% dw)")+
>
>   scale_color_manual(labels=c("Control",
> "Damaged"),values=c("red","black"),guide = guide_legend(reverse = TRUE) )+
>
>   scale_shape_manual(labels=c("Control", "Damaged"),name="Treatment",values
> = c(16,16),guide = guide_legend(reverse = TRUE) )+
>
>   #Style of background
>
>   theme_classic()+
>
>   #Change title
>
>   theme(plot.title = element_text(color="black", size=17, face="bold"))+
>
>   #Font size axis
>
>   theme(axis.text=element_text(size=12),
>
>         axis.title=element_text(size=17))+
>
>   scale_x_discrete("Location",labels = c("Low", "Mid", "High"),expand=c(0.1,
> 0.5))+
>
>   coord_flip()
>
>
>
> plot_CT
>
>
>
> #DATA-----------------------------------------------------------------------
> -----------------
>
> structure(list(Location = structure(c(2L, 3L, 1L, 2L, 3L, 1L,
>
> 2L, 3L, 1L, 2L, 3L, 1L, 2L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L,
>
> 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L,
>
> 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L,
>
> 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L,
>
> 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L,
>
> 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L,
>
> 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L,
>
> 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L,
>
> 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L,
>
> 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L,
>
> 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L,
>
> 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L), .Label = c("High", "Low", "Mid"
>
> ), class = "factor"), Treatment = structure(c(2L, 2L, 2L, 1L,
>
> 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L,
>
> 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L,
>
> 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L,
>
> 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L,
>
> 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L,
>
> 2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L,
>
> 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L,
>
> 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L,
>
> 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L,
>
> 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L,
>
> 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L,
>
> 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L), .Label = c("Con", "Exp"
>
> ), class = "factor"), Time = structure(c(2L, 2L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("Start", "Stop"
>
> ), class = "factor"), Genotype = structure(c(7L, 7L, 7L, 7L,
>
> 7L, 7L, 4L, 4L, 4L, 4L, 4L, 4L, 6L, 6L, 6L, 6L, 6L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 8L, 8L, 8L, 8L, 8L, 8L, 1L,
>
> 1L, 1L, 1L, 1L, 1L, 5L, 5L, 5L, 5L, 5L, 5L, 4L, 4L, 4L, 4L, 4L,
>
> 4L, 3L, 3L, 3L, 3L, 3L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 6L, 6L, 6L,
>
> 6L, 6L, 6L, 8L, 8L, 8L, 8L, 8L, 8L, 5L, 5L, 5L, 5L, 5L, 5L, 7L,
>
> 7L, 7L, 7L, 7L, 1L, 1L, 1L, 1L, 1L, 1L, 5L, 5L, 5L, 5L, 5L, 5L,
>
> 1L, 1L, 1L, 1L, 1L, 1L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L,
>
> 4L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L,
>
> 7L, 7L, 7L, 7L, 6L, 6L, 6L, 6L, 6L, 6L, 8L, 8L, 8L, 8L, 8L, 8L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L,
>
> 1L, 1L, 5L, 5L, 5L, 5L, 5L, 5L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L,
>
> 8L, 8L, 8L, 8L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("A", "B",
>
> "C", "D", "E", "F", "G", "H"), class = "factor"), Time.Location =
> structure(c(5L,
>
> 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 4L, 5L, 6L, 4L,
>
> 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L,
>
> 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L,
>
> 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L,
>
> 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L,
>
> 6L, 4L, 5L, 6L, 4L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L,
>
> 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L,
>
> 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L,
>
> 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L,
>
> 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L,
>
> 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L,
>
> 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L), .Label = c("StartHigh",
>
>
> "StartLow", "StartMid", "StopHigh", "StopLow", "StopMid"), class =
> "factor"),
>
>     Location.Treatment = structure(c(4L, 6L, 2L, 3L, 5L, 1L,
>
>     4L, 6L, 2L, 3L, 5L, 1L, 4L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L,
>
>     5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L,
>
>     6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L,
>
>     5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L,
>
>     6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L,
>
>     5L, 1L, 4L, 6L, 2L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L,
>
>     2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L,
>
>     1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L,
>
>     2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L,
>
>     1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L,
>
>     2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L,
>
>     1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L,
>
>     2L, 3L, 5L, 1L), .Label = c("HighCon", "HighExp", "LowCon",
>
>     "LowExp", "MidCon", "MidExp"), class = "factor"), CT = c(4.61538,
>
>     3.96739, 7.34797, 3.58108, 2.89655, 2.7993, 10.56122, 10.68396,
>
>     15.57252, 6.79245, 9.23469, 9.18, 1.1087, 4.26136, 1.14504,
>
>     2.20238, 3.15789, 9.54082, 11.05263, 15.84783, 10.48986,
>
>     12.62195, 15.12931, 5.51471, 8.20313, 11.85811, 3.38115,
>
>     7.5, 9.69512, 8.64407, 11.30597, 14.42797, 8.8125, 11.82482,
>
>     11.53061, 6.97674, 9.62766, 10.88028, 5.50403, 9.73558, 8.56419,
>
>     11.84524, 16.34892, 18.15789, 10.58036, 14.80932, 12.06081,
>
>     12.96992, 9.86014, 12.45652, 6.625, 6.93396, 9.10714, 3.66142,
>
>     9.19811, 10.88346, 2.88851, 6.85096, 10.27778, 8.29787, 13.00885,
>
>     14.38017, 7.5, 11.77734, 13.84615, 2.22772, 5.28, 5.25641,
>
>     1.0514, 2.73256, 4.11111, 11.39098, 11.10236, 13.00781, 7.95259,
>
>     10.15748, 13.16327, 8.90625, 10.04587, 13.625, 6.27049, 9.27966,
>
>     10.94037, 5.80189, 7.76978, 7.34266, 3.80952, 3.75, 7.29545,
>
>     10.45872, 16.83206, 5.95238, 7.70833, 10.92391, 11.03659,
>
>     14.39338, 14.88281, 8.22917, 11.63603, 14.7561, 11.9469,
>
>     14.65649, 16.84615, 8.37209, 13.27982, 13.69128, 7.77778,
>
>     12.59124, 12.32955, 7.00472, 8.41121, 7.22222, 9.43878, 10.33613,
>
>     14.16667, 9.60526, 8.77232, 11.91589, 7.01786, 12.29592,
>
>     11.83673, 8.55634, 11.17347, 12.68836, 2.7551, 6, 7.21374,
>
>     2.52101, 4.03846, 4.80634, 5.49569, 4.78723, 6.02273, 3.04511,
>
>     3.59244, 2.48239, 1.54412, 5.74219, 7.68595, 1.33065, 2.625,
>
>     4.42164, 9.66942, 11.875, 17.91667, 10.81731, 13.05288, 16.23853,
>
>     11.93662, 14.31818, 14.09396, 7.82374, 15.5042, 10.86207,
>
>     6.87023, 11.69492, 12.65957, 3.48684, 5.29018, 7.89474, 10.53309,
>
>     17.05479, 16.63866, 7.43119, 12.06522, 12.05607, 6.14865,
>
>     10.44, 14.69512, 9.24757, 9.04018, 12.38255, 2.22222, 3.90756,
>
>     5.85616, 2.23958, 3.8125, 3.01056, 11.60256, 12.22222, 11.8007,
>
>     7.76316, 10.08197, 12.78777, 9.20455, 12.1875, 16.59449,
>
>     6.82331, 10.91518, 11.5748)), row.names = 192:381, class = "data.frame")
>
>
>
>
>
>
>
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
John Kane
Kingston ON Canada


From B|||@Po||ng @end|ng |rom ze||@@com  Sat Apr  6 15:42:01 2019
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Sat, 6 Apr 2019 13:42:01 +0000
Subject: [R] Help with use RMarkdown and knitr in an rdm output to word.doc
Message-ID: <BN7PR02MB50739C8385C0A8C912BBF1BFEA520@BN7PR02MB5073.namprd02.prod.outlook.com>

Hello:

#sessionInfo()
#R version 3.5.3 (2019-03-11)
#Platform: x86_64-w64-mingw32/x64 (64-bit)
#Running under: Windows >= 8 x64 (build 9200)

#I have been struggling with learning how to use RMarkdown and knitr in an rdm while following this tutorial using my own data.
#I Tried many months ago to self-teach but it drove me nuts, however, I am now at a point where it is essential I get this figured out.

#The tutorial
#https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/

#I have googled and googled but cannot solve the problem of "how to get my rdm output" word doc to look like the tutorial examples.

#Many googles
#https://stackoverflow.com/questions/20060370/in-rstudio-is-there-a-way-to-specify-a-fig-path-for-all-figures-for-this-file
#https://rstudio.github.io/distill/figures.html
#https://kbroman.org/knitr_knutshell/pages/Rmarkdown.html

#And the list goes on. UGH!

#I attach my rmd code and the word doc output, hopefully they get through. Please let me know, and if not how I might improvise please.

#Here is the basic procedure from the tutorial which runs fine into the console, however, I am trying to output it with the suggested formatting in the tutorial
explanatory = c("TBCat","ClaimType","drgcode2","typeofbillid2")
dependent = "Autodist2"
tmp %>%
summary_factorlist(dependent, explanatory, p=TRUE, add_dependent_label=TRUE)

#Here is a sample of my data.

#I am sure there are also basic formatting inconsistencies or redundancies in the rdm and would appreciate any advice or suggestion for that as well, happy Saturday.

sample <- tmp %>% slice(1:35)
> dput(sample)
structure(list(Autodist2 = structure(c(2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("No",
"Yes"), class = "factor"), TBCat = structure(c(4L, 10L, 6L, 8L,
9L, 4L, 6L, 8L, 4L, 8L, 5L, 10L, 9L, 6L, 7L, 4L, 3L, 8L, 7L,
4L, 10L, 7L, 8L, 8L, 7L, 4L, 10L, 9L, 3L, 4L, 9L, 8L, 5L, 2L,
8L), .Label = c("1", "2", "3", "4", "5", "6", "7", "8", "9",
"10"), class = "factor"), RestictedPayorID = structure(c(2L,
2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L,
2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"), ClaimType = structure(c(1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L), .Label = c("1", "2"), class = "factor"), ClaimStatus_Non_Acceptance = structure(c(1L,
1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 1L, 2L,
1L, 1L), .Label = c("0", "1"), class = "factor"), ClaimStatus_Accepted = structure(c(2L,
2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 1L,
2L, 2L), .Label = c("0", "1"), class = "factor"), ClaimManagerID3 = structure(c(2L,
1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), ClaimStatus_In_Process = structure(c(1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L), .Label = c("0", "1"), class = "factor"), Appeals2 = structure(c(2L,
2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), drgcode2 = structure(c(1L,
1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L,
2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L,
1L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), edi2 = structure(c(1L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L,
2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), typeofbillid2 = structure(c(2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"), ExternalNetworkID2 = structure(c(1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), AdjustmentType2 = structure(c(2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"), CustomEOPLanguage2 = structure(c(2L,
2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor")), row.names = c(NA,
-35L), class = "data.frame")



Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Apr  6 16:42:06 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 06 Apr 2019 07:42:06 -0700
Subject: [R] 
 Help with use RMarkdown and knitr in an rdm output to word.doc
In-Reply-To: <BN7PR02MB50739C8385C0A8C912BBF1BFEA520@BN7PR02MB5073.namprd02.prod.outlook.com>
References: <BN7PR02MB50739C8385C0A8C912BBF1BFEA520@BN7PR02MB5073.namprd02.prod.outlook.com>
Message-ID: <67DB3C8E-84B5-4C28-835B-5D4BFFDEB5BA@dcn.davis.ca.us>

No surprise, the attachments did not come through. There are a limited few MIME types that are allowed, but most email programs don't let you have direct control over that, making embedding your entire reproducible plain-text example in the main body of the email the most sure path to successful communication on this mailing list.

I did skim through what you wrote below, scratching my head over what "rdm" was, until it dawned on me that you might mean a file with an ".Rmd" extension (are-mark-down) and that failing to use the correct extension might have something to do with your failure.

Anyway, the topic on this mailing list is the R language, and contributed packages  are (according to the Posting Guide) technically supposed to have support resources of their own [2] listed in their DESCRIPTION files [1]. I think the "how it works" discussion there could be useful in clarifying which other packages rmarkdown is using and which functions you might find useful documentation about. They also have a community forum over there I think.

FWIW my own experience with rmarkdown has been that that most of its power comes from augmenting it with other packages, and those packages are often very specific to which final output format you are using. The Word output format is much less extensively supported than HTML or PDF (via LaTeX) are. Don't fall into the trap of using HTML or LaTeX features when generating Word output.

[1] https://cran.r-project.org/web/packages/rmarkdown/index.html
[2] https://rmarkdown.rstudio.com

On April 6, 2019 6:42:01 AM PDT, Bill Poling <Bill.Poling at zelis.com> wrote:
>Hello:
>
>#sessionInfo()
>#R version 3.5.3 (2019-03-11)
>#Platform: x86_64-w64-mingw32/x64 (64-bit)
>#Running under: Windows >= 8 x64 (build 9200)
>
>#I have been struggling with learning how to use RMarkdown and knitr in
>an rdm while following this tutorial using my own data.
>#I Tried many months ago to self-teach but it drove me nuts, however, I
>am now at a point where it is essential I get this figured out.
>
>#The tutorial
>#https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/
>
>#I have googled and googled but cannot solve the problem of "how to get
>my rdm output" word doc to look like the tutorial examples.
>
>#Many googles
>#https://stackoverflow.com/questions/20060370/in-rstudio-is-there-a-way-to-specify-a-fig-path-for-all-figures-for-this-file
>#https://rstudio.github.io/distill/figures.html
>#https://kbroman.org/knitr_knutshell/pages/Rmarkdown.html
>
>#And the list goes on. UGH!
>
>#I attach my rmd code and the word doc output, hopefully they get
>through. Please let me know, and if not how I might improvise please.
>
>#Here is the basic procedure from the tutorial which runs fine into the
>console, however, I am trying to output it with the suggested
>formatting in the tutorial
>explanatory = c("TBCat","ClaimType","drgcode2","typeofbillid2")
>dependent = "Autodist2"
>tmp %>%
>summary_factorlist(dependent, explanatory, p=TRUE,
>add_dependent_label=TRUE)
>
>#Here is a sample of my data.
>
>#I am sure there are also basic formatting inconsistencies or
>redundancies in the rdm and would appreciate any advice or suggestion
>for that as well, happy Saturday.
>
>sample <- tmp %>% slice(1:35)
>> dput(sample)
>structure(list(Autodist2 = structure(c(2L, 2L, 2L, 2L, 2L, 2L,
>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("No",
>"Yes"), class = "factor"), TBCat = structure(c(4L, 10L, 6L, 8L,
>9L, 4L, 6L, 8L, 4L, 8L, 5L, 10L, 9L, 6L, 7L, 4L, 3L, 8L, 7L,
>4L, 10L, 7L, 8L, 8L, 7L, 4L, 10L, 9L, 3L, 4L, 9L, 8L, 5L, 2L,
>8L), .Label = c("1", "2", "3", "4", "5", "6", "7", "8", "9",
>"10"), class = "factor"), RestictedPayorID = structure(c(2L,
>2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L,
>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"), ClaimType =
>structure(c(1L,
>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L), .Label = c("1", "2"), class = "factor"),
>ClaimStatus_Non_Acceptance = structure(c(1L,
>1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 1L, 2L,
>1L, 1L), .Label = c("0", "1"), class = "factor"), ClaimStatus_Accepted
>= structure(c(2L,
>2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 1L,
>2L, 2L), .Label = c("0", "1"), class = "factor"), ClaimManagerID3 =
>structure(c(2L,
>1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L,
>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"),
>ClaimStatus_In_Process = structure(c(1L,
>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L), .Label = c("0", "1"), class = "factor"), Appeals2 =
>structure(c(2L,
>2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), drgcode2 =
>structure(c(1L,
>1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L,
>2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L,
>1L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), edi2 =
>structure(c(1L,
>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
>2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L,
>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), typeofbillid2
>= structure(c(2L,
>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"),
>ExternalNetworkID2 = structure(c(1L,
>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"),
>AdjustmentType2 = structure(c(2L,
>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L,
>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"),
>CustomEOPLanguage2 = structure(c(2L,
>2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor")), row.names =
>c(NA,
>-35L), class = "data.frame")
>
>
>
>Confidentiality Notice This message is sent from Zelis. This
>transmission may contain information which is privileged and
>confidential and is intended for the personal and confidential use of
>the named recipient only. Such information may be protected by
>applicable State and Federal laws from this disclosure or unauthorized
>use. If the reader of this message is not the intended recipient, or
>the employee or agent responsible for delivering the message to the
>intended recipient, you are hereby notified that any disclosure,
>review, discussion, copying, or taking any action in reliance on the
>contents of this transmission is strictly prohibited. If you have
>received this transmission in error, please contact the sender
>immediately. Zelis, 2018.
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From e@@w|ek @end|ng |rom gm@||@com  Sat Apr  6 19:44:55 2019
From: e@@w|ek @end|ng |rom gm@||@com (Ek Esawi)
Date: Sat, 6 Apr 2019 13:44:55 -0400
Subject: [R] Alternative to loops
Message-ID: <CA+ZkTxvY0_2OR7Ryccbo0-31J-HOUdb01y8OFY8M6asww90gKg@mail.gmail.com>

Thank you. Sorry i forgot to turn off the html

Below is a sample of my data. My original data frame has over 10,000 rows.
I want to check each element on my data frame column B
(MyDF$B) to see if it contains any element(s) of MYList. if os, change
the value of MyDF$C to the name of the vector of the list that has
match(s).

I solved this via loops and if statements, using &in&  but I am hoping for
a more compact solution using the apply family functions. I tried something like
this but did not work.

lapply(strsplit(MyDF$B," "),function(x) lapply(MyList,function(y)  if(sum(y
%in% x)>0,x$Code==y[[1]]))

Thanks in advance--EK

Sample data
MyList <- list(X=c("a","ba","cc"),Y=c("abs","aa","BA","BB"),z=c("ab","bb","xy","zy","gh"))
MyDF <- data.frame(A=c(1,2,3,4,5),B=c("aa ab ac","bb bc bd","cc
cf","dd","ee"), C= c(0,0,0,0,0), stringsAsFactors = FALSE)

> MyDF

    A     B      C
1 1 aa ab ac  0
2 2 bb bc bd  0
3 3    cc cf     0
4 4       dd     0
5 5       ee     0

> MyList

$X
[1] "a"  "ba" "cc"

$Y
[1] "abs" "aa"  "BA"  "BB"

$z
[1] "ab" "bb" "xy" "zy" "gh"


Desired results.

> MyDF

   A     B        C
1 1 aa ab ac Y
2 2 bb bc bd Y
3 3    cc cf    X
4 4       dd     0
5 5       ee     0


From B|||@Po||ng @end|ng |rom ze||@@com  Sat Apr  6 19:58:53 2019
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Sat, 6 Apr 2019 17:58:53 +0000
Subject: [R] 
 Help with use RMarkdown and knitr in an rdm output to word.doc
In-Reply-To: <67DB3C8E-84B5-4C28-835B-5D4BFFDEB5BA@dcn.davis.ca.us>
References: <BN7PR02MB50739C8385C0A8C912BBF1BFEA520@BN7PR02MB5073.namprd02.prod.outlook.com>
 <67DB3C8E-84B5-4C28-835B-5D4BFFDEB5BA@dcn.davis.ca.us>
Message-ID: <BN7PR02MB5073C9AD60B344B0180E736CEA520@BN7PR02MB5073.namprd02.prod.outlook.com>

Hello Jeff,as always, thank you for your response.

Yes .Rmd, and here I thought I was being so thorough about providing as much detail as possible, my apologies.

I have an open .Rmd file from the File ->New File menu in RStudio, so I think that part is correct.

My code is this.
---
title: "AutoDist Analysis"
author: "WHP"
date: "April 6, 2019"
output:
 word_document: default
  ---

```{r ElegantRegress, include = FALSE}
knitr::opts_chunk$set(echo = FALSE)
```
```{r global_options, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE,align=c("l", "l", "r", "r", "r", "r"))
```

```{r message=FALSE,warning=FALSE}
library(finalfit)
library(dplyr)
library(knitr)
library(memisc)
load("C:/WHP/Revenue Development Products//BRA AutoDistribution/Autodist RegTests V1.RData")
setwd("C:/WHP/Revenue Development Products/BRA AutoDistribution")
```

```{r echo=FALSE, results='asis'}
explanatory = c("TBCat","ClaimType","drgcode2","typeofbillid2")
dependent = "Autodist2"
tmp %>% summary_factorlist(dependent, explanatory, p=TRUE, add_dependent_label=TRUE)
```

I do get a word.doc file output from the above code  (attachment did not survive the communication as you mentioned) however, it is not in the format described in the tutorial.
Here is the output I do get:

AutoDist Analysis
WHP

April 6, 2019

Dependent: Autodist2 No Yes p 5 TBCat 1 6257 (96.6) 222 (3.4) <0.001 6 2 5780 (89.1) 709 (10.9)
7 3 5424 (83.9) 1042 (16.1)
8 4 5324 (82.2) 1156 (17.8)
9 5 5120 (79.0) 1360 (21.0)
10 6 5158 (79.6) 1322 (20.4)
11 7 5022 (77.5) 1459 (22.5)
12 8 5081 (78.4) 1398 (21.6)
13 9 4905 (75.7) 1575 (24.3)
14 10 5011 (77.3) 1469 (22.7)
1 ClaimType 1 48113 (80.6) 11566 (19.4) <0.001 2 2 4969 (97.1) 146 (2.9)
3 drgcode2 FALSE 41015 (80.8) 9734 (19.2) <0.001 4 TRUE 12067 (85.9) 1978 (14.1)
15 typeofbillid2 FALSE 4560 (90.3) 490 (9.7) <0.001 16 TRUE 48522 (81.2) 11222 (18.8)

I will revisit the links you provide once again.
I have tried to find my problem solution in these earlier.
Not surprisingly given the breadth and depth of information these links provide I have probably overlooked something nuanced yet highly important to the formatting issue I am having.

Once again thank you for your response Sir.

WHP


From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: Saturday, April 6, 2019 10:42 AM
To: r-help at r-project.org; Bill Poling <Bill.Poling at zelis.com>; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help with use RMarkdown and knitr in an rdm output to word.doc

No surprise, the attachments did not come through. There are a limited few MIME types that are allowed, but most email programs don't let you have direct control over that, making embedding your entire reproducible plain-text example in the main body of the email the most sure path to successful communication on this mailing list.

I did skim through what you wrote below, scratching my head over what "rdm" was, until it dawned on me that you might mean a file with an ".Rmd" extension (are-mark-down) and that failing to use the correct extension might have something to do with your failure.

Anyway, the topic on this mailing list is the R language, and contributed packages are (according to the Posting Guide) technically supposed to have support resources of their own [2] listed in their DESCRIPTION files [1]. I think the "how it works" discussion there could be useful in clarifying which other packages rmarkdown is using and which functions you might find useful documentation about. They also have a community forum over there I think.

FWIW my own experience with rmarkdown has been that that most of its power comes from augmenting it with other packages, and those packages are often very specific to which final output format you are using. The Word output format is much less extensively supported than HTML or PDF (via LaTeX) are. Don't fall into the trap of using HTML or LaTeX features when generating Word output.

[1] https://cran.r-project.org/web/packages/rmarkdown/index.html
[2] https://rmarkdown.rstudio.com

On April 6, 2019 6:42:01 AM PDT, Bill Poling <mailto:Bill.Poling at zelis.com> wrote:
>Hello:
>
>#sessionInfo()
>#R version 3.5.3 (2019-03-11)
>#Platform: x86_64-w64-mingw32/x64 (64-bit)
>#Running under: Windows >= 8 x64 (build 9200)
>
>#I have been struggling with learning how to use RMarkdown and knitr in
>an rdm while following this tutorial using my own data.
>#I Tried many months ago to self-teach but it drove me nuts, however, I
>am now at a point where it is essential I get this figured out.
>
>#The tutorial
>#https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/
>
>#I have googled and googled but cannot solve the problem of "how to get
>my rdm output" word doc to look like the tutorial examples.
>
>#Many googles
>#https://stackoverflow.com/questions/20060370/in-rstudio-is-there-a-way-to-specify-a-fig-path-for-all-figures-for-this-file
>#https://rstudio.github.io/distill/figures.html
>#https://kbroman.org/knitr_knutshell/pages/Rmarkdown.html
>
>#And the list goes on. UGH!
>
>#I attach my rmd code and the word doc output, hopefully they get
>through. Please let me know, and if not how I might improvise please.
>
>#Here is the basic procedure from the tutorial which runs fine into the
>console, however, I am trying to output it with the suggested
>formatting in the tutorial
>explanatory = c("TBCat","ClaimType","drgcode2","typeofbillid2")
>dependent = "Autodist2"
>tmp %>%
>summary_factorlist(dependent, explanatory, p=TRUE,
>add_dependent_label=TRUE)
>
>#Here is a sample of my data.
>
>#I am sure there are also basic formatting inconsistencies or
>redundancies in the rdm and would appreciate any advice or suggestion
>for that as well, happy Saturday.
>
>sample <- tmp %>% slice(1:35)
>> dput(sample)
>structure(list(Autodist2 = structure(c(2L, 2L, 2L, 2L, 2L, 2L,
>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("No",
>"Yes"), class = "factor"), TBCat = structure(c(4L, 10L, 6L, 8L,
>9L, 4L, 6L, 8L, 4L, 8L, 5L, 10L, 9L, 6L, 7L, 4L, 3L, 8L, 7L,
>4L, 10L, 7L, 8L, 8L, 7L, 4L, 10L, 9L, 3L, 4L, 9L, 8L, 5L, 2L,
>8L), .Label = c("1", "2", "3", "4", "5", "6", "7", "8", "9",
>"10"), class = "factor"), RestictedPayorID = structure(c(2L,
>2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L,
>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"), ClaimType =
>structure(c(1L,
>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L), .Label = c("1", "2"), class = "factor"),
>ClaimStatus_Non_Acceptance = structure(c(1L,
>1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 1L, 2L,
>1L, 1L), .Label = c("0", "1"), class = "factor"), ClaimStatus_Accepted
>= structure(c(2L,
>2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 1L,
>2L, 2L), .Label = c("0", "1"), class = "factor"), ClaimManagerID3 =
>structure(c(2L,
>1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L,
>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"),
>ClaimStatus_In_Process = structure(c(1L,
>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L), .Label = c("0", "1"), class = "factor"), Appeals2 =
>structure(c(2L,
>2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), drgcode2 =
>structure(c(1L,
>1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L,
>2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L,
>1L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), edi2 =
>structure(c(1L,
>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
>2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L,
>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), typeofbillid2
>= structure(c(2L,
>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"),
>ExternalNetworkID2 = structure(c(1L,
>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"),
>AdjustmentType2 = structure(c(2L,
>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L,
>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"),
>CustomEOPLanguage2 = structure(c(2L,
>2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor")), row.names =
>c(NA,
>-35L), class = "data.frame")
>
>
>
>Confidentiality Notice This message is sent from Zelis. This
>transmission may contain information which is privileged and
>confidential and is intended for the personal and confidential use of
>the named recipient only. Such information may be protected by
>applicable State and Federal laws from this disclosure or unauthorized
>use. If the reader of this message is not the intended recipient, or
>the employee or agent responsible for delivering the message to the
>intended recipient, you are hereby notified that any disclosure,
>review, discussion, copying, or taking any action in reliance on the
>contents of this transmission is strictly prohibited. If you have
>received this transmission in error, please contact the sender
>immediately. Zelis, 2018.
>______________________________________________
>mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Apr  6 20:24:56 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 06 Apr 2019 11:24:56 -0700
Subject: [R] 
 Help with use RMarkdown and knitr in an rdm output to word.doc
In-Reply-To: <BN7PR02MB5073C9AD60B344B0180E736CEA520@BN7PR02MB5073.namprd02.prod.outlook.com>
References: <BN7PR02MB50739C8385C0A8C912BBF1BFEA520@BN7PR02MB5073.namprd02.prod.outlook.com>
 <67DB3C8E-84B5-4C28-835B-5D4BFFDEB5BA@dcn.davis.ca.us>
 <BN7PR02MB5073C9AD60B344B0180E736CEA520@BN7PR02MB5073.namprd02.prod.outlook.com>
Message-ID: <5A96F01B-E18C-4687-A265-DF94A6FBA450@dcn.davis.ca.us>

Maybe you need to format the data frame as markdown before it gets displayed.

tmp %>%
  summary_factorlist(dependent, explanatory, p=TRUE, add_dependent_label=TRUE) %>%
  knitr::kable()

You can also tune how the columns are formatted a bit with arguments to the kable function.

On April 6, 2019 10:58:53 AM PDT, Bill Poling <Bill.Poling at zelis.com> wrote:
>Hello Jeff,as always, thank you for your response.
>
>Yes .Rmd, and here I thought I was being so thorough about providing as
>much detail as possible, my apologies.
>
>I have an open .Rmd file from the File ->New File menu in RStudio, so I
>think that part is correct.
>
>My code is this.
>---
>title: "AutoDist Analysis"
>author: "WHP"
>date: "April 6, 2019"
>output:
> word_document: default
>  ---
>
>```{r ElegantRegress, include = FALSE}
>knitr::opts_chunk$set(echo = FALSE)
>```
>```{r global_options, include=FALSE}
>knitr::opts_chunk$set(echo=FALSE, warning=FALSE,
>message=FALSE,align=c("l", "l", "r", "r", "r", "r"))
>```
>
>```{r message=FALSE,warning=FALSE}
>library(finalfit)
>library(dplyr)
>library(knitr)
>library(memisc)
>load("C:/WHP/Revenue Development Products//BRA
>AutoDistribution/Autodist RegTests V1.RData")
>setwd("C:/WHP/Revenue Development Products/BRA AutoDistribution")
>```
>
>```{r echo=FALSE, results='asis'}
>explanatory = c("TBCat","ClaimType","drgcode2","typeofbillid2")
>dependent = "Autodist2"
>tmp %>% summary_factorlist(dependent, explanatory, p=TRUE,
>add_dependent_label=TRUE)
>```
>
>I do get a word.doc file output from the above code  (attachment did
>not survive the communication as you mentioned) however, it is not in
>the format described in the tutorial.
>Here is the output I do get:
>
>AutoDist Analysis
>WHP
>
>April 6, 2019
>
>Dependent: Autodist2 No Yes p 5 TBCat 1 6257 (96.6) 222 (3.4) <0.001 6
>2 5780 (89.1) 709 (10.9)
>7 3 5424 (83.9) 1042 (16.1)
>8 4 5324 (82.2) 1156 (17.8)
>9 5 5120 (79.0) 1360 (21.0)
>10 6 5158 (79.6) 1322 (20.4)
>11 7 5022 (77.5) 1459 (22.5)
>12 8 5081 (78.4) 1398 (21.6)
>13 9 4905 (75.7) 1575 (24.3)
>14 10 5011 (77.3) 1469 (22.7)
>1 ClaimType 1 48113 (80.6) 11566 (19.4) <0.001 2 2 4969 (97.1) 146
>(2.9)
>3 drgcode2 FALSE 41015 (80.8) 9734 (19.2) <0.001 4 TRUE 12067 (85.9)
>1978 (14.1)
>15 typeofbillid2 FALSE 4560 (90.3) 490 (9.7) <0.001 16 TRUE 48522
>(81.2) 11222 (18.8)
>
>I will revisit the links you provide once again.
>I have tried to find my problem solution in these earlier.
>Not surprisingly given the breadth and depth of information these links
>provide I have probably overlooked something nuanced yet highly
>important to the formatting issue I am having.
>
>Once again thank you for your response Sir.
>
>WHP
>
>
>From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>Sent: Saturday, April 6, 2019 10:42 AM
>To: r-help at r-project.org; Bill Poling <Bill.Poling at zelis.com>; r-help
>(r-help at r-project.org) <r-help at r-project.org>
>Subject: Re: [R] Help with use RMarkdown and knitr in an rdm output to
>word.doc
>
>No surprise, the attachments did not come through. There are a limited
>few MIME types that are allowed, but most email programs don't let you
>have direct control over that, making embedding your entire
>reproducible plain-text example in the main body of the email the most
>sure path to successful communication on this mailing list.
>
>I did skim through what you wrote below, scratching my head over what
>"rdm" was, until it dawned on me that you might mean a file with an
>".Rmd" extension (are-mark-down) and that failing to use the correct
>extension might have something to do with your failure.
>
>Anyway, the topic on this mailing list is the R language, and
>contributed packages are (according to the Posting Guide) technically
>supposed to have support resources of their own [2] listed in their
>DESCRIPTION files [1]. I think the "how it works" discussion there
>could be useful in clarifying which other packages rmarkdown is using
>and which functions you might find useful documentation about. They
>also have a community forum over there I think.
>
>FWIW my own experience with rmarkdown has been that that most of its
>power comes from augmenting it with other packages, and those packages
>are often very specific to which final output format you are using. The
>Word output format is much less extensively supported than HTML or PDF
>(via LaTeX) are. Don't fall into the trap of using HTML or LaTeX
>features when generating Word output.
>
>[1] https://cran.r-project.org/web/packages/rmarkdown/index.html
>[2] https://rmarkdown.rstudio.com
>
>On April 6, 2019 6:42:01 AM PDT, Bill Poling
><mailto:Bill.Poling at zelis.com> wrote:
>>Hello:
>>
>>#sessionInfo()
>>#R version 3.5.3 (2019-03-11)
>>#Platform: x86_64-w64-mingw32/x64 (64-bit)
>>#Running under: Windows >= 8 x64 (build 9200)
>>
>>#I have been struggling with learning how to use RMarkdown and knitr
>in
>>an rdm while following this tutorial using my own data.
>>#I Tried many months ago to self-teach but it drove me nuts, however,
>I
>>am now at a point where it is essential I get this figured out.
>>
>>#The tutorial
>>#https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/
>>
>>#I have googled and googled but cannot solve the problem of "how to
>get
>>my rdm output" word doc to look like the tutorial examples.
>>
>>#Many googles
>>#https://stackoverflow.com/questions/20060370/in-rstudio-is-there-a-way-to-specify-a-fig-path-for-all-figures-for-this-file
>>#https://rstudio.github.io/distill/figures.html
>>#https://kbroman.org/knitr_knutshell/pages/Rmarkdown.html
>>
>>#And the list goes on. UGH!
>>
>>#I attach my rmd code and the word doc output, hopefully they get
>>through. Please let me know, and if not how I might improvise please.
>>
>>#Here is the basic procedure from the tutorial which runs fine into
>the
>>console, however, I am trying to output it with the suggested
>>formatting in the tutorial
>>explanatory = c("TBCat","ClaimType","drgcode2","typeofbillid2")
>>dependent = "Autodist2"
>>tmp %>%
>>summary_factorlist(dependent, explanatory, p=TRUE,
>>add_dependent_label=TRUE)
>>
>>#Here is a sample of my data.
>>
>>#I am sure there are also basic formatting inconsistencies or
>>redundancies in the rdm and would appreciate any advice or suggestion
>>for that as well, happy Saturday.
>>
>>sample <- tmp %>% slice(1:35)
>>> dput(sample)
>>structure(list(Autodist2 = structure(c(2L, 2L, 2L, 2L, 2L, 2L,
>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("No",
>>"Yes"), class = "factor"), TBCat = structure(c(4L, 10L, 6L, 8L,
>>9L, 4L, 6L, 8L, 4L, 8L, 5L, 10L, 9L, 6L, 7L, 4L, 3L, 8L, 7L,
>>4L, 10L, 7L, 8L, 8L, 7L, 4L, 10L, 9L, 3L, 4L, 9L, 8L, 5L, 2L,
>>8L), .Label = c("1", "2", "3", "4", "5", "6", "7", "8", "9",
>>"10"), class = "factor"), RestictedPayorID = structure(c(2L,
>>2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L,
>>1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L,
>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"), ClaimType =
>>structure(c(1L,
>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>1L, 1L), .Label = c("1", "2"), class = "factor"),
>>ClaimStatus_Non_Acceptance = structure(c(1L,
>>1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 1L, 2L,
>>1L, 1L), .Label = c("0", "1"), class = "factor"), ClaimStatus_Accepted
>>= structure(c(2L,
>>2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 1L,
>>2L, 2L), .Label = c("0", "1"), class = "factor"), ClaimManagerID3 =
>>structure(c(2L,
>>1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L,
>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>ClaimStatus_In_Process = structure(c(1L,
>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>1L, 1L), .Label = c("0", "1"), class = "factor"), Appeals2 =
>>structure(c(2L,
>>2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L,
>>1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), drgcode2 =
>>structure(c(1L,
>>1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L,
>>2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L,
>>1L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), edi2 =
>>structure(c(1L,
>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
>>2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L,
>>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), typeofbillid2
>>= structure(c(2L,
>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>ExternalNetworkID2 = structure(c(1L,
>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>1L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>AdjustmentType2 = structure(c(2L,
>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L,
>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>CustomEOPLanguage2 = structure(c(2L,
>>2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor")), row.names =
>>c(NA,
>>-35L), class = "data.frame")
>>
>>
>>
>>Confidentiality Notice This message is sent from Zelis. This
>>transmission may contain information which is privileged and
>>confidential and is intended for the personal and confidential use of
>>the named recipient only. Such information may be protected by
>>applicable State and Federal laws from this disclosure or unauthorized
>>use. If the reader of this message is not the intended recipient, or
>>the employee or agent responsible for delivering the message to the
>>intended recipient, you are hereby notified that any disclosure,
>>review, discussion, copying, or taking any action in reliance on the
>>contents of this transmission is strictly prohibited. If you have
>>received this transmission in error, please contact the sender
>>immediately. Zelis, 2018.
>>______________________________________________
>>mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>--
>Sent from my phone. Please excuse my brevity.
>
>Confidentiality Notice This message is sent from Zelis. This
>transmission may contain information which is privileged and
>confidential and is intended for the personal and confidential use of
>the named recipient only. Such information may be protected by
>applicable State and Federal laws from this disclosure or unauthorized
>use. If the reader of this message is not the intended recipient, or
>the employee or agent responsible for delivering the message to the
>intended recipient, you are hereby notified that any disclosure,
>review, discussion, copying, or taking any action in reliance on the
>contents of this transmission is strictly prohibited. If you have
>received this transmission in error, please contact the sender
>immediately. Zelis, 2018.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Sat Apr  6 23:06:55 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 6 Apr 2019 14:06:55 -0700
Subject: [R] Alternative to loops
In-Reply-To: <CA+ZkTxvY0_2OR7Ryccbo0-31J-HOUdb01y8OFY8M6asww90gKg@mail.gmail.com>
References: <CA+ZkTxvY0_2OR7Ryccbo0-31J-HOUdb01y8OFY8M6asww90gKg@mail.gmail.com>
Message-ID: <CAGxFJbRPwPC5GGz7RqOoAstxZ512Z0PtQqkzMkgWSSJhOsttNw@mail.gmail.com>

I skipped pre-populating MyDF$C as unnecessary:

> MyDF <- data.frame(A=c(1,2,3,4,5),B=c("aa ab ac","bb bc bd","cc
cf","dd","ee"),
+ stringsAsFactors = FALSE)

## I think this does what you want:

> choices<- sapply(MyDF$B, strsplit, split = " +")
> nm <- names(MyList)
> MyDF$C <- nm[sapply(choices, function(x)match(TRUE,
sapply(MyList,function(tbl)any(x %in% tbl))))]
> MyDF$C
[1] "Y" "z" "X" NA  NA

You could of course make this even more opaque by making it a one-liner. ;-)

Cheers,
Bert



On Sat, Apr 6, 2019 at 10:45 AM Ek Esawi <esawiek at gmail.com> wrote:

> Thank you. Sorry i forgot to turn off the html
>
> Below is a sample of my data. My original data frame has over 10,000 rows.
> I want to check each element on my data frame column B
> (MyDF$B) to see if it contains any element(s) of MYList. if os, change
> the value of MyDF$C to the name of the vector of the list that has
> match(s).
>
> I solved this via loops and if statements, using &in&  but I am hoping for
> a more compact solution using the apply family functions. I tried
> something like
> this but did not work.
>
> lapply(strsplit(MyDF$B," "),function(x) lapply(MyList,function(y)  if(sum(y
> %in% x)>0,x$Code==y[[1]]))
>
> Thanks in advance--EK
>
> Sample data
> MyList <-
> list(X=c("a","ba","cc"),Y=c("abs","aa","BA","BB"),z=c("ab","bb","xy","zy","gh"))
> MyDF <- data.frame(A=c(1,2,3,4,5),B=c("aa ab ac","bb bc bd","cc
> cf","dd","ee"), C= c(0,0,0,0,0), stringsAsFactors = FALSE)
>
> > MyDF
>
>     A     B      C
> 1 1 aa ab ac  0
> 2 2 bb bc bd  0
> 3 3    cc cf     0
> 4 4       dd     0
> 5 5       ee     0
>
> > MyList
>
> $X
> [1] "a"  "ba" "cc"
>
> $Y
> [1] "abs" "aa"  "BA"  "BB"
>
> $z
> [1] "ab" "bb" "xy" "zy" "gh"
>
>
> Desired results.
>
> > MyDF
>
>    A     B        C
> 1 1 aa ab ac Y
> 2 2 bb bc bd Y
> 3 3    cc cf    X
> 4 4       dd     0
> 5 5       ee     0
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From B|||@Po||ng @end|ng |rom ze||@@com  Sat Apr  6 23:44:55 2019
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Sat, 6 Apr 2019 21:44:55 +0000
Subject: [R] 
 Help with use RMarkdown and knitr in an rdm output to word.doc
In-Reply-To: <5A96F01B-E18C-4687-A265-DF94A6FBA450@dcn.davis.ca.us>
References: <BN7PR02MB50739C8385C0A8C912BBF1BFEA520@BN7PR02MB5073.namprd02.prod.outlook.com>
 <67DB3C8E-84B5-4C28-835B-5D4BFFDEB5BA@dcn.davis.ca.us>
 <BN7PR02MB5073C9AD60B344B0180E736CEA520@BN7PR02MB5073.namprd02.prod.outlook.com>
 <5A96F01B-E18C-4687-A265-DF94A6FBA450@dcn.davis.ca.us>
Message-ID: <BN7PR02MB50733CC23D6BBEA96EEC2475EA520@BN7PR02MB5073.namprd02.prod.outlook.com>

Thank you Jeff, I am so darn close, I solve one problem and another emerges!

However, I realized that back in July when I made my first and, up until this weekend, only attempt at this I was following the original url that was reposted by R-Bloggers that I mentioned in my original post earlier.
#https://www.datasurg.net/2018/05/16/elegant-regression-results-tables-and-plots-the-finalfit-package/

Low and behold realized I had asked the author (Ewen Harrison with DataSurg) these questions back then in the comments, UGH!
But since I ditched the idea in frustrationback then and I did not follow-up I hadn't realized the author created a companion url for this very topic, how to get from .Rmd to word/PDF etc..

I located his companion reference url to the original.

#https://www.datasurg.net/2018/05/22/finalfit-knitr-and-r-markdown-for-quick-results/

So following his further instructions I have made more progress, however, as I mention above the final document remains elusive.

SO I did some further googling and perused these sites as well

#https://rmarkdown.rstudio.com/articles_docx.html
#https://ourcodingclub.github.io/2016/11/24/rmarkdown-1.html

Between the companion url of Harrison and https://rmarkdown.rstudio.com/articles_docx.html I have almost got it.

---
title: "AutoDist Analysis"
author: "WHP"
date: "4/6/2018"
output:
    word_document:
    reference_docx: word-styles-reference-01.docx

---
```{r setup, include=FALSE}
# Load data into global environment.
library(finalfit)
library(dplyr)
library(knitr)
library(kableExtra)
load("C:/WHP/Revenue Development Products//BRA AutoDistribution/Test1.rda")
```

## Table 1 - Associations between Autodist Yes/No and other explanatory variables
```{r table1, echo = FALSE, results='asis'}
kable(table1, row.names=FALSE, align=c("l", "l", "r", "r", "r", "r"),
booktabs=TRUE)
```

## Table 2 - Logistic regression table
```{r table2, echo = FALSE, results='asis'}
kable(table2, row.names=FALSE, align=c("l", "l", "r", "r", "r", "r"),
booktabs=TRUE) %>%
kable_styling(font_size=8)
```

## Figure 1 - Odds Ratio Plot
```{r figure1, echo = FALSE, warning=FALSE, message=FALSE, fig.width=10}
tmp %>%
  or_plot(dependent, explanatory)

However, now the issue is:
"Error: Functions that produce HTML output found in document targeting docx output.
Please change the output type of this document to HTML. Alternatively, you can allow
HTML output in non-HTML formats by adding this option to the YAML front-matter of
your rmarkdown file:
  always_allow_html: yes
Note however that the HTML output will not be visible in non-HTML formats.
Execution halted"

This is confusing as heck, however, I tried adding that to the YAML but I get the same error
---
title: "AutoDist Analysis"
author: "WHP"
date: "4/6/2018"
output:
    word_document:
    reference_docx: word-styles-reference-01.docx
    always_allow_html: yes
---

SO needless to say  am really disappointed!

Whole Saturday on this, sheesh!

Thanks for listening

WHP


From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: Saturday, April 6, 2019 2:25 PM
To: Bill Poling <Bill.Poling at zelis.com>; r-help at r-project.org; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: RE: [R] Help with use RMarkdown and knitr in an rdm output to word.doc

Maybe you need to format the data frame as markdown before it gets displayed.

tmp %>%
summary_factorlist(dependent, explanatory, p=TRUE, add_dependent_label=TRUE) %>%
knitr::kable()

You can also tune how the columns are formatted a bit with arguments to the kable function.

On April 6, 2019 10:58:53 AM PDT, Bill Poling <mailto:Bill.Poling at zelis.com> wrote:
>Hello Jeff,as always, thank you for your response.
>
>Yes .Rmd, and here I thought I was being so thorough about providing as
>much detail as possible, my apologies.
>
>I have an open .Rmd file from the File ->New File menu in RStudio, so I
>think that part is correct.
>
>My code is this.
>---
>title: "AutoDist Analysis"
>author: "WHP"
>date: "April 6, 2019"
>output:
> word_document: default
> ---
>
>```{r ElegantRegress, include = FALSE}
>knitr::opts_chunk$set(echo = FALSE)
>```
>```{r global_options, include=FALSE}
>knitr::opts_chunk$set(echo=FALSE, warning=FALSE,
>message=FALSE,align=c("l", "l", "r", "r", "r", "r"))
>```
>
>```{r message=FALSE,warning=FALSE}
>library(finalfit)
>library(dplyr)
>library(knitr)
>library(memisc)
>load("C:/WHP/Revenue Development Products//BRA
>AutoDistribution/Autodist RegTests V1.RData")
>setwd("C:/WHP/Revenue Development Products/BRA AutoDistribution")
>```
>
>```{r echo=FALSE, results='asis'}
>explanatory = c("TBCat","ClaimType","drgcode2","typeofbillid2")
>dependent = "Autodist2"
>tmp %>% summary_factorlist(dependent, explanatory, p=TRUE,
>add_dependent_label=TRUE)
>```
>
>I do get a word.doc file output from the above code (attachment did
>not survive the communication as you mentioned) however, it is not in
>the format described in the tutorial.
>Here is the output I do get:
>
>AutoDist Analysis
>WHP
>
>April 6, 2019
>
>Dependent: Autodist2 No Yes p 5 TBCat 1 6257 (96.6) 222 (3.4) <0.001 6
>2 5780 (89.1) 709 (10.9)
>7 3 5424 (83.9) 1042 (16.1)
>8 4 5324 (82.2) 1156 (17.8)
>9 5 5120 (79.0) 1360 (21.0)
>10 6 5158 (79.6) 1322 (20.4)
>11 7 5022 (77.5) 1459 (22.5)
>12 8 5081 (78.4) 1398 (21.6)
>13 9 4905 (75.7) 1575 (24.3)
>14 10 5011 (77.3) 1469 (22.7)
>1 ClaimType 1 48113 (80.6) 11566 (19.4) <0.001 2 2 4969 (97.1) 146
>(2.9)
>3 drgcode2 FALSE 41015 (80.8) 9734 (19.2) <0.001 4 TRUE 12067 (85.9)
>1978 (14.1)
>15 typeofbillid2 FALSE 4560 (90.3) 490 (9.7) <0.001 16 TRUE 48522
>(81.2) 11222 (18.8)
>
>I will revisit the links you provide once again.
>I have tried to find my problem solution in these earlier.
>Not surprisingly given the breadth and depth of information these links
>provide I have probably overlooked something nuanced yet highly
>important to the formatting issue I am having.
>
>Once again thank you for your response Sir.
>
>WHP
>
>
>From: Jeff Newmiller <mailto:jdnewmil at dcn.davis.ca.us>
>Sent: Saturday, April 6, 2019 10:42 AM
>To: mailto:r-help at r-project.org; Bill Poling <mailto:Bill.Poling at zelis.com>; r-help
>(mailto:r-help at r-project.org) <mailto:r-help at r-project.org>
>Subject: Re: [R] Help with use RMarkdown and knitr in an rdm output to
>word.doc
>
>No surprise, the attachments did not come through. There are a limited
>few MIME types that are allowed, but most email programs don't let you
>have direct control over that, making embedding your entire
>reproducible plain-text example in the main body of the email the most
>sure path to successful communication on this mailing list.
>
>I did skim through what you wrote below, scratching my head over what
>"rdm" was, until it dawned on me that you might mean a file with an
>".Rmd" extension (are-mark-down) and that failing to use the correct
>extension might have something to do with your failure.
>
>Anyway, the topic on this mailing list is the R language, and
>contributed packages are (according to the Posting Guide) technically
>supposed to have support resources of their own [2] listed in their
>DESCRIPTION files [1]. I think the "how it works" discussion there
>could be useful in clarifying which other packages rmarkdown is using
>and which functions you might find useful documentation about. They
>also have a community forum over there I think.
>
>FWIW my own experience with rmarkdown has been that that most of its
>power comes from augmenting it with other packages, and those packages
>are often very specific to which final output format you are using. The
>Word output format is much less extensively supported than HTML or PDF
>(via LaTeX) are. Don't fall into the trap of using HTML or LaTeX
>features when generating Word output.
>
>[1] https://cran.r-project.org/web/packages/rmarkdown/index.html
>[2] https://rmarkdown.rstudio.com
>
>On April 6, 2019 6:42:01 AM PDT, Bill Poling
><mailto:Bill.Poling at zelis.com> wrote:
>>Hello:
>>
>>#sessionInfo()
>>#R version 3.5.3 (2019-03-11)
>>#Platform: x86_64-w64-mingw32/x64 (64-bit)
>>#Running under: Windows >= 8 x64 (build 9200)
>>
>>#I have been struggling with learning how to use RMarkdown and knitr
>in
>>an rdm while following this tutorial using my own data.
>>#I Tried many months ago to self-teach but it drove me nuts, however,
>I
>>am now at a point where it is essential I get this figured out.
>>
>>#The tutorial
>>#https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/
>>
>>#I have googled and googled but cannot solve the problem of "how to
>get
>>my rdm output" word doc to look like the tutorial examples.
>>
>>#Many googles
>>#https://stackoverflow.com/questions/20060370/in-rstudio-is-there-a-way-to-specify-a-fig-path-for-all-figures-for-this-file
>>#https://rstudio.github.io/distill/figures.html
>>#https://kbroman.org/knitr_knutshell/pages/Rmarkdown.html
>>
>>#And the list goes on. UGH!
>>
>>#I attach my rmd code and the word doc output, hopefully they get
>>through. Please let me know, and if not how I might improvise please.
>>
>>#Here is the basic procedure from the tutorial which runs fine into
>the
>>console, however, I am trying to output it with the suggested
>>formatting in the tutorial
>>explanatory = c("TBCat","ClaimType","drgcode2","typeofbillid2")
>>dependent = "Autodist2"
>>tmp %>%
>>summary_factorlist(dependent, explanatory, p=TRUE,
>>add_dependent_label=TRUE)
>>
>>#Here is a sample of my data.
>>
>>#I am sure there are also basic formatting inconsistencies or
>>redundancies in the rdm and would appreciate any advice or suggestion
>>for that as well, happy Saturday.
>>
>>sample <- tmp %>% slice(1:35)
>>> dput(sample)
>>structure(list(Autodist2 = structure(c(2L, 2L, 2L, 2L, 2L, 2L,
>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("No",
>>"Yes"), class = "factor"), TBCat = structure(c(4L, 10L, 6L, 8L,
>>9L, 4L, 6L, 8L, 4L, 8L, 5L, 10L, 9L, 6L, 7L, 4L, 3L, 8L, 7L,
>>4L, 10L, 7L, 8L, 8L, 7L, 4L, 10L, 9L, 3L, 4L, 9L, 8L, 5L, 2L,
>>8L), .Label = c("1", "2", "3", "4", "5", "6", "7", "8", "9",
>>"10"), class = "factor"), RestictedPayorID = structure(c(2L,
>>2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L,
>>1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L,
>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"), ClaimType =
>>structure(c(1L,
>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>1L, 1L), .Label = c("1", "2"), class = "factor"),
>>ClaimStatus_Non_Acceptance = structure(c(1L,
>>1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 1L, 2L,
>>1L, 1L), .Label = c("0", "1"), class = "factor"), ClaimStatus_Accepted
>>= structure(c(2L,
>>2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 1L,
>>2L, 2L), .Label = c("0", "1"), class = "factor"), ClaimManagerID3 =
>>structure(c(2L,
>>1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L,
>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>ClaimStatus_In_Process = structure(c(1L,
>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>1L, 1L), .Label = c("0", "1"), class = "factor"), Appeals2 =
>>structure(c(2L,
>>2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L,
>>1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), drgcode2 =
>>structure(c(1L,
>>1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L,
>>2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L,
>>1L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), edi2 =
>>structure(c(1L,
>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
>>2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L,
>>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), typeofbillid2
>>= structure(c(2L,
>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>ExternalNetworkID2 = structure(c(1L,
>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>1L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>AdjustmentType2 = structure(c(2L,
>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L,
>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>CustomEOPLanguage2 = structure(c(2L,
>>2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor")), row.names =
>>c(NA,
>>-35L), class = "data.frame")
>>
>>
>>
>>Confidentiality Notice This message is sent from Zelis. This
>>transmission may contain information which is privileged and
>>confidential and is intended for the personal and confidential use of
>>the named recipient only. Such information may be protected by
>>applicable State and Federal laws from this disclosure or unauthorized
>>use. If the reader of this message is not the intended recipient, or
>>the employee or agent responsible for delivering the message to the
>>intended recipient, you are hereby notified that any disclosure,
>>review, discussion, copying, or taking any action in reliance on the
>>contents of this transmission is strictly prohibited. If you have
>>received this transmission in error, please contact the sender
>>immediately. Zelis, 2018.
>>______________________________________________
>>mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>--
>Sent from my phone. Please excuse my brevity.
>
>Confidentiality Notice This message is sent from Zelis. This
>transmission may contain information which is privileged and
>confidential and is intended for the personal and confidential use of
>the named recipient only. Such information may be protected by
>applicable State and Federal laws from this disclosure or unauthorized
>use. If the reader of this message is not the intended recipient, or
>the employee or agent responsible for delivering the message to the
>intended recipient, you are hereby notified that any disclosure,
>review, discussion, copying, or taking any action in reliance on the
>contents of this transmission is strictly prohibited. If you have
>received this transmission in error, please contact the sender
>immediately. Zelis, 2018.

--
Sent from my phone. Please excuse my brevity.

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Apr  7 00:51:12 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 06 Apr 2019 15:51:12 -0700
Subject: [R] 
 Help with use RMarkdown and knitr in an rdm output to word.doc
In-Reply-To: <BN7PR02MB50733CC23D6BBEA96EEC2475EA520@BN7PR02MB5073.namprd02.prod.outlook.com>
References: <BN7PR02MB50739C8385C0A8C912BBF1BFEA520@BN7PR02MB5073.namprd02.prod.outlook.com>
 <67DB3C8E-84B5-4C28-835B-5D4BFFDEB5BA@dcn.davis.ca.us>
 <BN7PR02MB5073C9AD60B344B0180E736CEA520@BN7PR02MB5073.namprd02.prod.outlook.com>
 <5A96F01B-E18C-4687-A265-DF94A6FBA450@dcn.davis.ca.us>
 <BN7PR02MB50733CC23D6BBEA96EEC2475EA520@BN7PR02MB5073.namprd02.prod.outlook.com>
Message-ID: <1A6E7A13-1CCE-4085-9D1F-E6C120A55BEC@dcn.davis.ca.us>

Read the help files for the functions in each code block that are actually producing output that will be displayed. One of them is not compatible with docx file output.

On April 6, 2019 2:44:55 PM PDT, Bill Poling <Bill.Poling at zelis.com> wrote:
>Thank you Jeff, I am so darn close, I solve one problem and another
>emerges!
>
>However, I realized that back in July when I made my first and, up
>until this weekend, only attempt at this I was following the original
>url that was reposted by R-Bloggers that I mentioned in my original
>post earlier.
>#https://www.datasurg.net/2018/05/16/elegant-regression-results-tables-and-plots-the-finalfit-package/
>
>Low and behold realized I had asked the author (Ewen Harrison with
>DataSurg) these questions back then in the comments, UGH!
>But since I ditched the idea in frustrationback then and I did not
>follow-up I hadn't realized the author created a companion url for this
>very topic, how to get from .Rmd to word/PDF etc..
>
>I located his companion reference url to the original.
>
>#https://www.datasurg.net/2018/05/22/finalfit-knitr-and-r-markdown-for-quick-results/
>
>So following his further instructions I have made more progress,
>however, as I mention above the final document remains elusive.
>
>SO I did some further googling and perused these sites as well
>
>#https://rmarkdown.rstudio.com/articles_docx.html
>#https://ourcodingclub.github.io/2016/11/24/rmarkdown-1.html
>
>Between the companion url of Harrison and
>https://rmarkdown.rstudio.com/articles_docx.html I have almost got it.
>
>---
>title: "AutoDist Analysis"
>author: "WHP"
>date: "4/6/2018"
>output:
>    word_document:
>    reference_docx: word-styles-reference-01.docx
>
>---
>```{r setup, include=FALSE}
># Load data into global environment.
>library(finalfit)
>library(dplyr)
>library(knitr)
>library(kableExtra)
>load("C:/WHP/Revenue Development Products//BRA
>AutoDistribution/Test1.rda")
>```
>
>## Table 1 - Associations between Autodist Yes/No and other explanatory
>variables
>```{r table1, echo = FALSE, results='asis'}
>kable(table1, row.names=FALSE, align=c("l", "l", "r", "r", "r", "r"),
>booktabs=TRUE)
>```
>
>## Table 2 - Logistic regression table
>```{r table2, echo = FALSE, results='asis'}
>kable(table2, row.names=FALSE, align=c("l", "l", "r", "r", "r", "r"),
>booktabs=TRUE) %>%
>kable_styling(font_size=8)
>```
>
>## Figure 1 - Odds Ratio Plot
>```{r figure1, echo = FALSE, warning=FALSE, message=FALSE,
>fig.width=10}
>tmp %>%
>  or_plot(dependent, explanatory)
>
>However, now the issue is:
>"Error: Functions that produce HTML output found in document targeting
>docx output.
>Please change the output type of this document to HTML. Alternatively,
>you can allow
>HTML output in non-HTML formats by adding this option to the YAML
>front-matter of
>your rmarkdown file:
>  always_allow_html: yes
>Note however that the HTML output will not be visible in non-HTML
>formats.
>Execution halted"
>
>This is confusing as heck, however, I tried adding that to the YAML but
>I get the same error
>---
>title: "AutoDist Analysis"
>author: "WHP"
>date: "4/6/2018"
>output:
>    word_document:
>    reference_docx: word-styles-reference-01.docx
>    always_allow_html: yes
>---
>
>SO needless to say  am really disappointed!
>
>Whole Saturday on this, sheesh!
>
>Thanks for listening
>
>WHP
>
>
>From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>Sent: Saturday, April 6, 2019 2:25 PM
>To: Bill Poling <Bill.Poling at zelis.com>; r-help at r-project.org; r-help
>(r-help at r-project.org) <r-help at r-project.org>
>Subject: RE: [R] Help with use RMarkdown and knitr in an rdm output to
>word.doc
>
>Maybe you need to format the data frame as markdown before it gets
>displayed.
>
>tmp %>%
>summary_factorlist(dependent, explanatory, p=TRUE,
>add_dependent_label=TRUE) %>%
>knitr::kable()
>
>You can also tune how the columns are formatted a bit with arguments to
>the kable function.
>
>On April 6, 2019 10:58:53 AM PDT, Bill Poling
><mailto:Bill.Poling at zelis.com> wrote:
>>Hello Jeff,as always, thank you for your response.
>>
>>Yes .Rmd, and here I thought I was being so thorough about providing
>as
>>much detail as possible, my apologies.
>>
>>I have an open .Rmd file from the File ->New File menu in RStudio, so
>I
>>think that part is correct.
>>
>>My code is this.
>>---
>>title: "AutoDist Analysis"
>>author: "WHP"
>>date: "April 6, 2019"
>>output:
>> word_document: default
>> ---
>>
>>```{r ElegantRegress, include = FALSE}
>>knitr::opts_chunk$set(echo = FALSE)
>>```
>>```{r global_options, include=FALSE}
>>knitr::opts_chunk$set(echo=FALSE, warning=FALSE,
>>message=FALSE,align=c("l", "l", "r", "r", "r", "r"))
>>```
>>
>>```{r message=FALSE,warning=FALSE}
>>library(finalfit)
>>library(dplyr)
>>library(knitr)
>>library(memisc)
>>load("C:/WHP/Revenue Development Products//BRA
>>AutoDistribution/Autodist RegTests V1.RData")
>>setwd("C:/WHP/Revenue Development Products/BRA AutoDistribution")
>>```
>>
>>```{r echo=FALSE, results='asis'}
>>explanatory = c("TBCat","ClaimType","drgcode2","typeofbillid2")
>>dependent = "Autodist2"
>>tmp %>% summary_factorlist(dependent, explanatory, p=TRUE,
>>add_dependent_label=TRUE)
>>```
>>
>>I do get a word.doc file output from the above code (attachment did
>>not survive the communication as you mentioned) however, it is not in
>>the format described in the tutorial.
>>Here is the output I do get:
>>
>>AutoDist Analysis
>>WHP
>>
>>April 6, 2019
>>
>>Dependent: Autodist2 No Yes p 5 TBCat 1 6257 (96.6) 222 (3.4) <0.001 6
>>2 5780 (89.1) 709 (10.9)
>>7 3 5424 (83.9) 1042 (16.1)
>>8 4 5324 (82.2) 1156 (17.8)
>>9 5 5120 (79.0) 1360 (21.0)
>>10 6 5158 (79.6) 1322 (20.4)
>>11 7 5022 (77.5) 1459 (22.5)
>>12 8 5081 (78.4) 1398 (21.6)
>>13 9 4905 (75.7) 1575 (24.3)
>>14 10 5011 (77.3) 1469 (22.7)
>>1 ClaimType 1 48113 (80.6) 11566 (19.4) <0.001 2 2 4969 (97.1) 146
>>(2.9)
>>3 drgcode2 FALSE 41015 (80.8) 9734 (19.2) <0.001 4 TRUE 12067 (85.9)
>>1978 (14.1)
>>15 typeofbillid2 FALSE 4560 (90.3) 490 (9.7) <0.001 16 TRUE 48522
>>(81.2) 11222 (18.8)
>>
>>I will revisit the links you provide once again.
>>I have tried to find my problem solution in these earlier.
>>Not surprisingly given the breadth and depth of information these
>links
>>provide I have probably overlooked something nuanced yet highly
>>important to the formatting issue I am having.
>>
>>Once again thank you for your response Sir.
>>
>>WHP
>>
>>
>>From: Jeff Newmiller <mailto:jdnewmil at dcn.davis.ca.us>
>>Sent: Saturday, April 6, 2019 10:42 AM
>>To: mailto:r-help at r-project.org; Bill Poling
><mailto:Bill.Poling at zelis.com>; r-help
>>(mailto:r-help at r-project.org) <mailto:r-help at r-project.org>
>>Subject: Re: [R] Help with use RMarkdown and knitr in an rdm output to
>>word.doc
>>
>>No surprise, the attachments did not come through. There are a limited
>>few MIME types that are allowed, but most email programs don't let you
>>have direct control over that, making embedding your entire
>>reproducible plain-text example in the main body of the email the most
>>sure path to successful communication on this mailing list.
>>
>>I did skim through what you wrote below, scratching my head over what
>>"rdm" was, until it dawned on me that you might mean a file with an
>>".Rmd" extension (are-mark-down) and that failing to use the correct
>>extension might have something to do with your failure.
>>
>>Anyway, the topic on this mailing list is the R language, and
>>contributed packages are (according to the Posting Guide) technically
>>supposed to have support resources of their own [2] listed in their
>>DESCRIPTION files [1]. I think the "how it works" discussion there
>>could be useful in clarifying which other packages rmarkdown is using
>>and which functions you might find useful documentation about. They
>>also have a community forum over there I think.
>>
>>FWIW my own experience with rmarkdown has been that that most of its
>>power comes from augmenting it with other packages, and those packages
>>are often very specific to which final output format you are using.
>The
>>Word output format is much less extensively supported than HTML or PDF
>>(via LaTeX) are. Don't fall into the trap of using HTML or LaTeX
>>features when generating Word output.
>>
>>[1] https://cran.r-project.org/web/packages/rmarkdown/index.html
>>[2] https://rmarkdown.rstudio.com
>>
>>On April 6, 2019 6:42:01 AM PDT, Bill Poling
>><mailto:Bill.Poling at zelis.com> wrote:
>>>Hello:
>>>
>>>#sessionInfo()
>>>#R version 3.5.3 (2019-03-11)
>>>#Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>#Running under: Windows >= 8 x64 (build 9200)
>>>
>>>#I have been struggling with learning how to use RMarkdown and knitr
>>in
>>>an rdm while following this tutorial using my own data.
>>>#I Tried many months ago to self-teach but it drove me nuts, however,
>>I
>>>am now at a point where it is essential I get this figured out.
>>>
>>>#The tutorial
>>>#https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/
>>>
>>>#I have googled and googled but cannot solve the problem of "how to
>>get
>>>my rdm output" word doc to look like the tutorial examples.
>>>
>>>#Many googles
>>>#https://stackoverflow.com/questions/20060370/in-rstudio-is-there-a-way-to-specify-a-fig-path-for-all-figures-for-this-file
>>>#https://rstudio.github.io/distill/figures.html
>>>#https://kbroman.org/knitr_knutshell/pages/Rmarkdown.html
>>>
>>>#And the list goes on. UGH!
>>>
>>>#I attach my rmd code and the word doc output, hopefully they get
>>>through. Please let me know, and if not how I might improvise please.
>>>
>>>#Here is the basic procedure from the tutorial which runs fine into
>>the
>>>console, however, I am trying to output it with the suggested
>>>formatting in the tutorial
>>>explanatory = c("TBCat","ClaimType","drgcode2","typeofbillid2")
>>>dependent = "Autodist2"
>>>tmp %>%
>>>summary_factorlist(dependent, explanatory, p=TRUE,
>>>add_dependent_label=TRUE)
>>>
>>>#Here is a sample of my data.
>>>
>>>#I am sure there are also basic formatting inconsistencies or
>>>redundancies in the rdm and would appreciate any advice or suggestion
>>>for that as well, happy Saturday.
>>>
>>>sample <- tmp %>% slice(1:35)
>>>> dput(sample)
>>>structure(list(Autodist2 = structure(c(2L, 2L, 2L, 2L, 2L, 2L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("No",
>>>"Yes"), class = "factor"), TBCat = structure(c(4L, 10L, 6L, 8L,
>>>9L, 4L, 6L, 8L, 4L, 8L, 5L, 10L, 9L, 6L, 7L, 4L, 3L, 8L, 7L,
>>>4L, 10L, 7L, 8L, 8L, 7L, 4L, 10L, 9L, 3L, 4L, 9L, 8L, 5L, 2L,
>>>8L), .Label = c("1", "2", "3", "4", "5", "6", "7", "8", "9",
>>>"10"), class = "factor"), RestictedPayorID = structure(c(2L,
>>>2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L,
>>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"), ClaimType =
>>>structure(c(1L,
>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L), .Label = c("1", "2"), class = "factor"),
>>>ClaimStatus_Non_Acceptance = structure(c(1L,
>>>1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 1L, 2L,
>>>1L, 1L), .Label = c("0", "1"), class = "factor"),
>ClaimStatus_Accepted
>>>= structure(c(2L,
>>>2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 1L,
>>>2L, 2L), .Label = c("0", "1"), class = "factor"), ClaimManagerID3 =
>>>structure(c(2L,
>>>1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>>ClaimStatus_In_Process = structure(c(1L,
>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L), .Label = c("0", "1"), class = "factor"), Appeals2 =
>>>structure(c(2L,
>>>2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), drgcode2 =
>>>structure(c(1L,
>>>1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L,
>>>2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L,
>>>1L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), edi2 =
>>>structure(c(1L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
>>>2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L,
>>>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"),
>typeofbillid2
>>>= structure(c(2L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>>ExternalNetworkID2 = structure(c(1L,
>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>>AdjustmentType2 = structure(c(2L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>>CustomEOPLanguage2 = structure(c(2L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor")), row.names =
>>>c(NA,
>>>-35L), class = "data.frame")
>>>
>>>
>>>
>>>Confidentiality Notice This message is sent from Zelis. This
>>>transmission may contain information which is privileged and
>>>confidential and is intended for the personal and confidential use of
>>>the named recipient only. Such information may be protected by
>>>applicable State and Federal laws from this disclosure or
>unauthorized
>>>use. If the reader of this message is not the intended recipient, or
>>>the employee or agent responsible for delivering the message to the
>>>intended recipient, you are hereby notified that any disclosure,
>>>review, discussion, copying, or taking any action in reliance on the
>>>contents of this transmission is strictly prohibited. If you have
>>>received this transmission in error, please contact the sender
>>>immediately. Zelis, 2018.
>>>______________________________________________
>>>mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>see
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>
>>--
>>Sent from my phone. Please excuse my brevity.
>>
>>Confidentiality Notice This message is sent from Zelis. This
>>transmission may contain information which is privileged and
>>confidential and is intended for the personal and confidential use of
>>the named recipient only. Such information may be protected by
>>applicable State and Federal laws from this disclosure or unauthorized
>>use. If the reader of this message is not the intended recipient, or
>>the employee or agent responsible for delivering the message to the
>>intended recipient, you are hereby notified that any disclosure,
>>review, discussion, copying, or taking any action in reliance on the
>>contents of this transmission is strictly prohibited. If you have
>>received this transmission in error, please contact the sender
>>immediately. Zelis, 2018.
>
>--
>Sent from my phone. Please excuse my brevity.
>
>Confidentiality Notice This message is sent from Zelis. This
>transmission may contain information which is privileged and
>confidential and is intended for the personal and confidential use of
>the named recipient only. Such information may be protected by
>applicable State and Federal laws from this disclosure or unauthorized
>use. If the reader of this message is not the intended recipient, or
>the employee or agent responsible for delivering the message to the
>intended recipient, you are hereby notified that any disclosure,
>review, discussion, copying, or taking any action in reliance on the
>contents of this transmission is strictly prohibited. If you have
>received this transmission in error, please contact the sender
>immediately. Zelis, 2018.

-- 
Sent from my phone. Please excuse my brevity.
-- 
Sent from my phone. Please excuse my brevity.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Apr  7 00:47:58 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 06 Apr 2019 15:47:58 -0700
Subject: [R] 
 Help with use RMarkdown and knitr in an rdm output to word.doc
In-Reply-To: <BN7PR02MB50733CC23D6BBEA96EEC2475EA520@BN7PR02MB5073.namprd02.prod.outlook.com>
References: <BN7PR02MB50739C8385C0A8C912BBF1BFEA520@BN7PR02MB5073.namprd02.prod.outlook.com>
 <67DB3C8E-84B5-4C28-835B-5D4BFFDEB5BA@dcn.davis.ca.us>
 <BN7PR02MB5073C9AD60B344B0180E736CEA520@BN7PR02MB5073.namprd02.prod.outlook.com>
 <5A96F01B-E18C-4687-A265-DF94A6FBA450@dcn.davis.ca.us>
 <BN7PR02MB50733CC23D6BBEA96EEC2475EA520@BN7PR02MB5073.namprd02.prod.outlook.com>
Message-ID: <1E7FE896-1D67-4536-A242-0AE54119C6B8@dcn.davis.ca.us>

Read the help files for the functions in each code block that are actually producing output that will be displayed. One of them is not compatible with docx file output.

On April 6, 2019 2:44:55 PM PDT, Bill Poling <Bill.Poling at zelis.com> wrote:
>Thank you Jeff, I am so darn close, I solve one problem and another
>emerges!
>
>However, I realized that back in July when I made my first and, up
>until this weekend, only attempt at this I was following the original
>url that was reposted by R-Bloggers that I mentioned in my original
>post earlier.
>#https://www.datasurg.net/2018/05/16/elegant-regression-results-tables-and-plots-the-finalfit-package/
>
>Low and behold realized I had asked the author (Ewen Harrison with
>DataSurg) these questions back then in the comments, UGH!
>But since I ditched the idea in frustrationback then and I did not
>follow-up I hadn't realized the author created a companion url for this
>very topic, how to get from .Rmd to word/PDF etc..
>
>I located his companion reference url to the original.
>
>#https://www.datasurg.net/2018/05/22/finalfit-knitr-and-r-markdown-for-quick-results/
>
>So following his further instructions I have made more progress,
>however, as I mention above the final document remains elusive.
>
>SO I did some further googling and perused these sites as well
>
>#https://rmarkdown.rstudio.com/articles_docx.html
>#https://ourcodingclub.github.io/2016/11/24/rmarkdown-1.html
>
>Between the companion url of Harrison and
>https://rmarkdown.rstudio.com/articles_docx.html I have almost got it.
>
>---
>title: "AutoDist Analysis"
>author: "WHP"
>date: "4/6/2018"
>output:
>    word_document:
>    reference_docx: word-styles-reference-01.docx
>
>---
>```{r setup, include=FALSE}
># Load data into global environment.
>library(finalfit)
>library(dplyr)
>library(knitr)
>library(kableExtra)
>load("C:/WHP/Revenue Development Products//BRA
>AutoDistribution/Test1.rda")
>```
>
>## Table 1 - Associations between Autodist Yes/No and other explanatory
>variables
>```{r table1, echo = FALSE, results='asis'}
>kable(table1, row.names=FALSE, align=c("l", "l", "r", "r", "r", "r"),
>booktabs=TRUE)
>```
>
>## Table 2 - Logistic regression table
>```{r table2, echo = FALSE, results='asis'}
>kable(table2, row.names=FALSE, align=c("l", "l", "r", "r", "r", "r"),
>booktabs=TRUE) %>%
>kable_styling(font_size=8)
>```
>
>## Figure 1 - Odds Ratio Plot
>```{r figure1, echo = FALSE, warning=FALSE, message=FALSE,
>fig.width=10}
>tmp %>%
>  or_plot(dependent, explanatory)
>
>However, now the issue is:
>"Error: Functions that produce HTML output found in document targeting
>docx output.
>Please change the output type of this document to HTML. Alternatively,
>you can allow
>HTML output in non-HTML formats by adding this option to the YAML
>front-matter of
>your rmarkdown file:
>  always_allow_html: yes
>Note however that the HTML output will not be visible in non-HTML
>formats.
>Execution halted"
>
>This is confusing as heck, however, I tried adding that to the YAML but
>I get the same error
>---
>title: "AutoDist Analysis"
>author: "WHP"
>date: "4/6/2018"
>output:
>    word_document:
>    reference_docx: word-styles-reference-01.docx
>    always_allow_html: yes
>---
>
>SO needless to say  am really disappointed!
>
>Whole Saturday on this, sheesh!
>
>Thanks for listening
>
>WHP
>
>
>From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>Sent: Saturday, April 6, 2019 2:25 PM
>To: Bill Poling <Bill.Poling at zelis.com>; r-help at r-project.org; r-help
>(r-help at r-project.org) <r-help at r-project.org>
>Subject: RE: [R] Help with use RMarkdown and knitr in an rdm output to
>word.doc
>
>Maybe you need to format the data frame as markdown before it gets
>displayed.
>
>tmp %>%
>summary_factorlist(dependent, explanatory, p=TRUE,
>add_dependent_label=TRUE) %>%
>knitr::kable()
>
>You can also tune how the columns are formatted a bit with arguments to
>the kable function.
>
>On April 6, 2019 10:58:53 AM PDT, Bill Poling
><mailto:Bill.Poling at zelis.com> wrote:
>>Hello Jeff,as always, thank you for your response.
>>
>>Yes .Rmd, and here I thought I was being so thorough about providing
>as
>>much detail as possible, my apologies.
>>
>>I have an open .Rmd file from the File ->New File menu in RStudio, so
>I
>>think that part is correct.
>>
>>My code is this.
>>---
>>title: "AutoDist Analysis"
>>author: "WHP"
>>date: "April 6, 2019"
>>output:
>> word_document: default
>> ---
>>
>>```{r ElegantRegress, include = FALSE}
>>knitr::opts_chunk$set(echo = FALSE)
>>```
>>```{r global_options, include=FALSE}
>>knitr::opts_chunk$set(echo=FALSE, warning=FALSE,
>>message=FALSE,align=c("l", "l", "r", "r", "r", "r"))
>>```
>>
>>```{r message=FALSE,warning=FALSE}
>>library(finalfit)
>>library(dplyr)
>>library(knitr)
>>library(memisc)
>>load("C:/WHP/Revenue Development Products//BRA
>>AutoDistribution/Autodist RegTests V1.RData")
>>setwd("C:/WHP/Revenue Development Products/BRA AutoDistribution")
>>```
>>
>>```{r echo=FALSE, results='asis'}
>>explanatory = c("TBCat","ClaimType","drgcode2","typeofbillid2")
>>dependent = "Autodist2"
>>tmp %>% summary_factorlist(dependent, explanatory, p=TRUE,
>>add_dependent_label=TRUE)
>>```
>>
>>I do get a word.doc file output from the above code (attachment did
>>not survive the communication as you mentioned) however, it is not in
>>the format described in the tutorial.
>>Here is the output I do get:
>>
>>AutoDist Analysis
>>WHP
>>
>>April 6, 2019
>>
>>Dependent: Autodist2 No Yes p 5 TBCat 1 6257 (96.6) 222 (3.4) <0.001 6
>>2 5780 (89.1) 709 (10.9)
>>7 3 5424 (83.9) 1042 (16.1)
>>8 4 5324 (82.2) 1156 (17.8)
>>9 5 5120 (79.0) 1360 (21.0)
>>10 6 5158 (79.6) 1322 (20.4)
>>11 7 5022 (77.5) 1459 (22.5)
>>12 8 5081 (78.4) 1398 (21.6)
>>13 9 4905 (75.7) 1575 (24.3)
>>14 10 5011 (77.3) 1469 (22.7)
>>1 ClaimType 1 48113 (80.6) 11566 (19.4) <0.001 2 2 4969 (97.1) 146
>>(2.9)
>>3 drgcode2 FALSE 41015 (80.8) 9734 (19.2) <0.001 4 TRUE 12067 (85.9)
>>1978 (14.1)
>>15 typeofbillid2 FALSE 4560 (90.3) 490 (9.7) <0.001 16 TRUE 48522
>>(81.2) 11222 (18.8)
>>
>>I will revisit the links you provide once again.
>>I have tried to find my problem solution in these earlier.
>>Not surprisingly given the breadth and depth of information these
>links
>>provide I have probably overlooked something nuanced yet highly
>>important to the formatting issue I am having.
>>
>>Once again thank you for your response Sir.
>>
>>WHP
>>
>>
>>From: Jeff Newmiller <mailto:jdnewmil at dcn.davis.ca.us>
>>Sent: Saturday, April 6, 2019 10:42 AM
>>To: mailto:r-help at r-project.org; Bill Poling
><mailto:Bill.Poling at zelis.com>; r-help
>>(mailto:r-help at r-project.org) <mailto:r-help at r-project.org>
>>Subject: Re: [R] Help with use RMarkdown and knitr in an rdm output to
>>word.doc
>>
>>No surprise, the attachments did not come through. There are a limited
>>few MIME types that are allowed, but most email programs don't let you
>>have direct control over that, making embedding your entire
>>reproducible plain-text example in the main body of the email the most
>>sure path to successful communication on this mailing list.
>>
>>I did skim through what you wrote below, scratching my head over what
>>"rdm" was, until it dawned on me that you might mean a file with an
>>".Rmd" extension (are-mark-down) and that failing to use the correct
>>extension might have something to do with your failure.
>>
>>Anyway, the topic on this mailing list is the R language, and
>>contributed packages are (according to the Posting Guide) technically
>>supposed to have support resources of their own [2] listed in their
>>DESCRIPTION files [1]. I think the "how it works" discussion there
>>could be useful in clarifying which other packages rmarkdown is using
>>and which functions you might find useful documentation about. They
>>also have a community forum over there I think.
>>
>>FWIW my own experience with rmarkdown has been that that most of its
>>power comes from augmenting it with other packages, and those packages
>>are often very specific to which final output format you are using.
>The
>>Word output format is much less extensively supported than HTML or PDF
>>(via LaTeX) are. Don't fall into the trap of using HTML or LaTeX
>>features when generating Word output.
>>
>>[1] https://cran.r-project.org/web/packages/rmarkdown/index.html
>>[2] https://rmarkdown.rstudio.com
>>
>>On April 6, 2019 6:42:01 AM PDT, Bill Poling
>><mailto:Bill.Poling at zelis.com> wrote:
>>>Hello:
>>>
>>>#sessionInfo()
>>>#R version 3.5.3 (2019-03-11)
>>>#Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>#Running under: Windows >= 8 x64 (build 9200)
>>>
>>>#I have been struggling with learning how to use RMarkdown and knitr
>>in
>>>an rdm while following this tutorial using my own data.
>>>#I Tried many months ago to self-teach but it drove me nuts, however,
>>I
>>>am now at a point where it is essential I get this figured out.
>>>
>>>#The tutorial
>>>#https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/
>>>
>>>#I have googled and googled but cannot solve the problem of "how to
>>get
>>>my rdm output" word doc to look like the tutorial examples.
>>>
>>>#Many googles
>>>#https://stackoverflow.com/questions/20060370/in-rstudio-is-there-a-way-to-specify-a-fig-path-for-all-figures-for-this-file
>>>#https://rstudio.github.io/distill/figures.html
>>>#https://kbroman.org/knitr_knutshell/pages/Rmarkdown.html
>>>
>>>#And the list goes on. UGH!
>>>
>>>#I attach my rmd code and the word doc output, hopefully they get
>>>through. Please let me know, and if not how I might improvise please.
>>>
>>>#Here is the basic procedure from the tutorial which runs fine into
>>the
>>>console, however, I am trying to output it with the suggested
>>>formatting in the tutorial
>>>explanatory = c("TBCat","ClaimType","drgcode2","typeofbillid2")
>>>dependent = "Autodist2"
>>>tmp %>%
>>>summary_factorlist(dependent, explanatory, p=TRUE,
>>>add_dependent_label=TRUE)
>>>
>>>#Here is a sample of my data.
>>>
>>>#I am sure there are also basic formatting inconsistencies or
>>>redundancies in the rdm and would appreciate any advice or suggestion
>>>for that as well, happy Saturday.
>>>
>>>sample <- tmp %>% slice(1:35)
>>>> dput(sample)
>>>structure(list(Autodist2 = structure(c(2L, 2L, 2L, 2L, 2L, 2L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("No",
>>>"Yes"), class = "factor"), TBCat = structure(c(4L, 10L, 6L, 8L,
>>>9L, 4L, 6L, 8L, 4L, 8L, 5L, 10L, 9L, 6L, 7L, 4L, 3L, 8L, 7L,
>>>4L, 10L, 7L, 8L, 8L, 7L, 4L, 10L, 9L, 3L, 4L, 9L, 8L, 5L, 2L,
>>>8L), .Label = c("1", "2", "3", "4", "5", "6", "7", "8", "9",
>>>"10"), class = "factor"), RestictedPayorID = structure(c(2L,
>>>2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L,
>>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"), ClaimType =
>>>structure(c(1L,
>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L), .Label = c("1", "2"), class = "factor"),
>>>ClaimStatus_Non_Acceptance = structure(c(1L,
>>>1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 1L, 2L,
>>>1L, 1L), .Label = c("0", "1"), class = "factor"),
>ClaimStatus_Accepted
>>>= structure(c(2L,
>>>2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 1L,
>>>2L, 2L), .Label = c("0", "1"), class = "factor"), ClaimManagerID3 =
>>>structure(c(2L,
>>>1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>>ClaimStatus_In_Process = structure(c(1L,
>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L), .Label = c("0", "1"), class = "factor"), Appeals2 =
>>>structure(c(2L,
>>>2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), drgcode2 =
>>>structure(c(1L,
>>>1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L,
>>>2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L,
>>>1L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), edi2 =
>>>structure(c(1L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
>>>2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L,
>>>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"),
>typeofbillid2
>>>= structure(c(2L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>>ExternalNetworkID2 = structure(c(1L,
>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>>AdjustmentType2 = structure(c(2L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>>CustomEOPLanguage2 = structure(c(2L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor")), row.names =
>>>c(NA,
>>>-35L), class = "data.frame")
>>>
>>>
>>>
>>>Confidentiality Notice This message is sent from Zelis. This
>>>transmission may contain information which is privileged and
>>>confidential and is intended for the personal and confidential use of
>>>the named recipient only. Such information may be protected by
>>>applicable State and Federal laws from this disclosure or
>unauthorized
>>>use. If the reader of this message is not the intended recipient, or
>>>the employee or agent responsible for delivering the message to the
>>>intended recipient, you are hereby notified that any disclosure,
>>>review, discussion, copying, or taking any action in reliance on the
>>>contents of this transmission is strictly prohibited. If you have
>>>received this transmission in error, please contact the sender
>>>immediately. Zelis, 2018.
>>>______________________________________________
>>>mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>see
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>
>>--
>>Sent from my phone. Please excuse my brevity.
>>
>>Confidentiality Notice This message is sent from Zelis. This
>>transmission may contain information which is privileged and
>>confidential and is intended for the personal and confidential use of
>>the named recipient only. Such information may be protected by
>>applicable State and Federal laws from this disclosure or unauthorized
>>use. If the reader of this message is not the intended recipient, or
>>the employee or agent responsible for delivering the message to the
>>intended recipient, you are hereby notified that any disclosure,
>>review, discussion, copying, or taking any action in reliance on the
>>contents of this transmission is strictly prohibited. If you have
>>received this transmission in error, please contact the sender
>>immediately. Zelis, 2018.
>
>--
>Sent from my phone. Please excuse my brevity.
>
>Confidentiality Notice This message is sent from Zelis. This
>transmission may contain information which is privileged and
>confidential and is intended for the personal and confidential use of
>the named recipient only. Such information may be protected by
>applicable State and Federal laws from this disclosure or unauthorized
>use. If the reader of this message is not the intended recipient, or
>the employee or agent responsible for delivering the message to the
>intended recipient, you are hereby notified that any disclosure,
>review, discussion, copying, or taking any action in reliance on the
>contents of this transmission is strictly prohibited. If you have
>received this transmission in error, please contact the sender
>immediately. Zelis, 2018.

-- 
Sent from my phone. Please excuse my brevity.


From B|||@Po||ng @end|ng |rom ze||@@com  Sun Apr  7 12:07:53 2019
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Sun, 7 Apr 2019 10:07:53 +0000
Subject: [R] 
 Help with use RMarkdown and knitr in an rdm output to word.doc
In-Reply-To: <1A6E7A13-1CCE-4085-9D1F-E6C120A55BEC@dcn.davis.ca.us>
References: <BN7PR02MB50739C8385C0A8C912BBF1BFEA520@BN7PR02MB5073.namprd02.prod.outlook.com>
 <67DB3C8E-84B5-4C28-835B-5D4BFFDEB5BA@dcn.davis.ca.us>
 <BN7PR02MB5073C9AD60B344B0180E736CEA520@BN7PR02MB5073.namprd02.prod.outlook.com>
 <5A96F01B-E18C-4687-A265-DF94A6FBA450@dcn.davis.ca.us>
 <BN7PR02MB50733CC23D6BBEA96EEC2475EA520@BN7PR02MB5073.namprd02.prod.outlook.com>
 <1A6E7A13-1CCE-4085-9D1F-E6C120A55BEC@dcn.davis.ca.us>
Message-ID: <BN7PR02MB5073967567A5940CDC6F414BEA530@BN7PR02MB5073.namprd02.prod.outlook.com>

Thanks Jeff, yes well I have followed the Harrison tutorial and my chunks are the same as his examples which appear to work fine for him?
I am stymied.

#https://www.datasurg.net/2018/05/22/finalfit-knitr-and-r-markdown-for-quick-results/

I will keep working on it though, many thanks.

WHP




From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: Saturday, April 6, 2019 6:51 PM
To: Bill Poling <Bill.Poling at zelis.com>; r-help at r-project.org; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: RE: [R] Help with use RMarkdown and knitr in an rdm output to word.doc

Read the help files for the functions in each code block that are actually producing output that will be displayed. One of them is not compatible with docx file output.

On April 6, 2019 2:44:55 PM PDT, Bill Poling <mailto:Bill.Poling at zelis.com> wrote:
>Thank you Jeff, I am so darn close, I solve one problem and another
>emerges!
>
>However, I realized that back in July when I made my first and, up
>until this weekend, only attempt at this I was following the original
>url that was reposted by R-Bloggers that I mentioned in my original
>post earlier.
>#https://www.datasurg.net/2018/05/16/elegant-regression-results-tables-and-plots-the-finalfit-package/
>
>Low and behold realized I had asked the author (Ewen Harrison with
>DataSurg) these questions back then in the comments, UGH!
>But since I ditched the idea in frustrationback then and I did not
>follow-up I hadn't realized the author created a companion url for this
>very topic, how to get from .Rmd to word/PDF etc..
>
>I located his companion reference url to the original.
>
>#https://www.datasurg.net/2018/05/22/finalfit-knitr-and-r-markdown-for-quick-results/
>
>So following his further instructions I have made more progress,
>however, as I mention above the final document remains elusive.
>
>SO I did some further googling and perused these sites as well
>
>#https://rmarkdown.rstudio.com/articles_docx.html
>#https://ourcodingclub.github.io/2016/11/24/rmarkdown-1.html
>
>Between the companion url of Harrison and
>https://rmarkdown.rstudio.com/articles_docx.html I have almost got it.
>
>---
>title: "AutoDist Analysis"
>author: "WHP"
>date: "4/6/2018"
>output:
> word_document:
> reference_docx: word-styles-reference-01.docx
>
>---
>```{r setup, include=FALSE}
># Load data into global environment.
>library(finalfit)
>library(dplyr)
>library(knitr)
>library(kableExtra)
>load("C:/WHP/Revenue Development Products//BRA
>AutoDistribution/Test1.rda")
>```
>
>## Table 1 - Associations between Autodist Yes/No and other explanatory
>variables
>```{r table1, echo = FALSE, results='asis'}
>kable(table1, row.names=FALSE, align=c("l", "l", "r", "r", "r", "r"),
>booktabs=TRUE)
>```
>
>## Table 2 - Logistic regression table
>```{r table2, echo = FALSE, results='asis'}
>kable(table2, row.names=FALSE, align=c("l", "l", "r", "r", "r", "r"),
>booktabs=TRUE) %>%
>kable_styling(font_size=8)
>```
>
>## Figure 1 - Odds Ratio Plot
>```{r figure1, echo = FALSE, warning=FALSE, message=FALSE,
>fig.width=10}
>tmp %>%
> or_plot(dependent, explanatory)
>
>However, now the issue is:
>"Error: Functions that produce HTML output found in document targeting
>docx output.
>Please change the output type of this document to HTML. Alternatively,
>you can allow
>HTML output in non-HTML formats by adding this option to the YAML
>front-matter of
>your rmarkdown file:
> always_allow_html: yes
>Note however that the HTML output will not be visible in non-HTML
>formats.
>Execution halted"
>
>This is confusing as heck, however, I tried adding that to the YAML but
>I get the same error
>---
>title: "AutoDist Analysis"
>author: "WHP"
>date: "4/6/2018"
>output:
> word_document:
> reference_docx: word-styles-reference-01.docx
> always_allow_html: yes
>---
>
>SO needless to say am really disappointed!
>
>Whole Saturday on this, sheesh!
>
>Thanks for listening
>
>WHP
>
>
>From: Jeff Newmiller <mailto:jdnewmil at dcn.davis.ca.us>
>Sent: Saturday, April 6, 2019 2:25 PM
>To: Bill Poling <mailto:Bill.Poling at zelis.com>; mailto:r-help at r-project.org; r-help
>(mailto:r-help at r-project.org) <mailto:r-help at r-project.org>
>Subject: RE: [R] Help with use RMarkdown and knitr in an rdm output to
>word.doc
>
>Maybe you need to format the data frame as markdown before it gets
>displayed.
>
>tmp %>%
>summary_factorlist(dependent, explanatory, p=TRUE,
>add_dependent_label=TRUE) %>%
>knitr::kable()
>
>You can also tune how the columns are formatted a bit with arguments to
>the kable function.
>
>On April 6, 2019 10:58:53 AM PDT, Bill Poling
><mailto:Bill.Poling at zelis.com> wrote:
>>Hello Jeff,as always, thank you for your response.
>>
>>Yes .Rmd, and here I thought I was being so thorough about providing
>as
>>much detail as possible, my apologies.
>>
>>I have an open .Rmd file from the File ->New File menu in RStudio, so
>I
>>think that part is correct.
>>
>>My code is this.
>>---
>>title: "AutoDist Analysis"
>>author: "WHP"
>>date: "April 6, 2019"
>>output:
>> word_document: default
>> ---
>>
>>```{r ElegantRegress, include = FALSE}
>>knitr::opts_chunk$set(echo = FALSE)
>>```
>>```{r global_options, include=FALSE}
>>knitr::opts_chunk$set(echo=FALSE, warning=FALSE,
>>message=FALSE,align=c("l", "l", "r", "r", "r", "r"))
>>```
>>
>>```{r message=FALSE,warning=FALSE}
>>library(finalfit)
>>library(dplyr)
>>library(knitr)
>>library(memisc)
>>load("C:/WHP/Revenue Development Products//BRA
>>AutoDistribution/Autodist RegTests V1.RData")
>>setwd("C:/WHP/Revenue Development Products/BRA AutoDistribution")
>>```
>>
>>```{r echo=FALSE, results='asis'}
>>explanatory = c("TBCat","ClaimType","drgcode2","typeofbillid2")
>>dependent = "Autodist2"
>>tmp %>% summary_factorlist(dependent, explanatory, p=TRUE,
>>add_dependent_label=TRUE)
>>```
>>
>>I do get a word.doc file output from the above code (attachment did
>>not survive the communication as you mentioned) however, it is not in
>>the format described in the tutorial.
>>Here is the output I do get:
>>
>>AutoDist Analysis
>>WHP
>>
>>April 6, 2019
>>
>>Dependent: Autodist2 No Yes p 5 TBCat 1 6257 (96.6) 222 (3.4) <0.001 6
>>2 5780 (89.1) 709 (10.9)
>>7 3 5424 (83.9) 1042 (16.1)
>>8 4 5324 (82.2) 1156 (17.8)
>>9 5 5120 (79.0) 1360 (21.0)
>>10 6 5158 (79.6) 1322 (20.4)
>>11 7 5022 (77.5) 1459 (22.5)
>>12 8 5081 (78.4) 1398 (21.6)
>>13 9 4905 (75.7) 1575 (24.3)
>>14 10 5011 (77.3) 1469 (22.7)
>>1 ClaimType 1 48113 (80.6) 11566 (19.4) <0.001 2 2 4969 (97.1) 146
>>(2.9)
>>3 drgcode2 FALSE 41015 (80.8) 9734 (19.2) <0.001 4 TRUE 12067 (85.9)
>>1978 (14.1)
>>15 typeofbillid2 FALSE 4560 (90.3) 490 (9.7) <0.001 16 TRUE 48522
>>(81.2) 11222 (18.8)
>>
>>I will revisit the links you provide once again.
>>I have tried to find my problem solution in these earlier.
>>Not surprisingly given the breadth and depth of information these
>links
>>provide I have probably overlooked something nuanced yet highly
>>important to the formatting issue I am having.
>>
>>Once again thank you for your response Sir.
>>
>>WHP
>>
>>
>>From: Jeff Newmiller <mailto:jdnewmil at dcn.davis.ca.us>
>>Sent: Saturday, April 6, 2019 10:42 AM
>>To: mailto:r-help at r-project.org; Bill Poling
><mailto:Bill.Poling at zelis.com>; r-help
>>(mailto:r-help at r-project.org) <mailto:r-help at r-project.org>
>>Subject: Re: [R] Help with use RMarkdown and knitr in an rdm output to
>>word.doc
>>
>>No surprise, the attachments did not come through. There are a limited
>>few MIME types that are allowed, but most email programs don't let you
>>have direct control over that, making embedding your entire
>>reproducible plain-text example in the main body of the email the most
>>sure path to successful communication on this mailing list.
>>
>>I did skim through what you wrote below, scratching my head over what
>>"rdm" was, until it dawned on me that you might mean a file with an
>>".Rmd" extension (are-mark-down) and that failing to use the correct
>>extension might have something to do with your failure.
>>
>>Anyway, the topic on this mailing list is the R language, and
>>contributed packages are (according to the Posting Guide) technically
>>supposed to have support resources of their own [2] listed in their
>>DESCRIPTION files [1]. I think the "how it works" discussion there
>>could be useful in clarifying which other packages rmarkdown is using
>>and which functions you might find useful documentation about. They
>>also have a community forum over there I think.
>>
>>FWIW my own experience with rmarkdown has been that that most of its
>>power comes from augmenting it with other packages, and those packages
>>are often very specific to which final output format you are using.
>The
>>Word output format is much less extensively supported than HTML or PDF
>>(via LaTeX) are. Don't fall into the trap of using HTML or LaTeX
>>features when generating Word output.
>>
>>[1] https://cran.r-project.org/web/packages/rmarkdown/index.html
>>[2] https://rmarkdown.rstudio.com
>>
>>On April 6, 2019 6:42:01 AM PDT, Bill Poling
>><mailto:Bill.Poling at zelis.com> wrote:
>>>Hello:
>>>
>>>#sessionInfo()
>>>#R version 3.5.3 (2019-03-11)
>>>#Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>#Running under: Windows >= 8 x64 (build 9200)
>>>
>>>#I have been struggling with learning how to use RMarkdown and knitr
>>in
>>>an rdm while following this tutorial using my own data.
>>>#I Tried many months ago to self-teach but it drove me nuts, however,
>>I
>>>am now at a point where it is essential I get this figured out.
>>>
>>>#The tutorial
>>>#https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/
>>>
>>>#I have googled and googled but cannot solve the problem of "how to
>>get
>>>my rdm output" word doc to look like the tutorial examples.
>>>
>>>#Many googles
>>>#https://stackoverflow.com/questions/20060370/in-rstudio-is-there-a-way-to-specify-a-fig-path-for-all-figures-for-this-file
>>>#https://rstudio.github.io/distill/figures.html
>>>#https://kbroman.org/knitr_knutshell/pages/Rmarkdown.html
>>>
>>>#And the list goes on. UGH!
>>>
>>>#I attach my rmd code and the word doc output, hopefully they get
>>>through. Please let me know, and if not how I might improvise please.
>>>
>>>#Here is the basic procedure from the tutorial which runs fine into
>>the
>>>console, however, I am trying to output it with the suggested
>>>formatting in the tutorial
>>>explanatory = c("TBCat","ClaimType","drgcode2","typeofbillid2")
>>>dependent = "Autodist2"
>>>tmp %>%
>>>summary_factorlist(dependent, explanatory, p=TRUE,
>>>add_dependent_label=TRUE)
>>>
>>>#Here is a sample of my data.
>>>
>>>#I am sure there are also basic formatting inconsistencies or
>>>redundancies in the rdm and would appreciate any advice or suggestion
>>>for that as well, happy Saturday.
>>>
>>>sample <- tmp %>% slice(1:35)
>>>> dput(sample)
>>>structure(list(Autodist2 = structure(c(2L, 2L, 2L, 2L, 2L, 2L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("No",
>>>"Yes"), class = "factor"), TBCat = structure(c(4L, 10L, 6L, 8L,
>>>9L, 4L, 6L, 8L, 4L, 8L, 5L, 10L, 9L, 6L, 7L, 4L, 3L, 8L, 7L,
>>>4L, 10L, 7L, 8L, 8L, 7L, 4L, 10L, 9L, 3L, 4L, 9L, 8L, 5L, 2L,
>>>8L), .Label = c("1", "2", "3", "4", "5", "6", "7", "8", "9",
>>>"10"), class = "factor"), RestictedPayorID = structure(c(2L,
>>>2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L,
>>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"), ClaimType =
>>>structure(c(1L,
>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L), .Label = c("1", "2"), class = "factor"),
>>>ClaimStatus_Non_Acceptance = structure(c(1L,
>>>1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 1L, 2L,
>>>1L, 1L), .Label = c("0", "1"), class = "factor"),
>ClaimStatus_Accepted
>>>= structure(c(2L,
>>>2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 1L,
>>>2L, 2L), .Label = c("0", "1"), class = "factor"), ClaimManagerID3 =
>>>structure(c(2L,
>>>1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>>ClaimStatus_In_Process = structure(c(1L,
>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L), .Label = c("0", "1"), class = "factor"), Appeals2 =
>>>structure(c(2L,
>>>2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), drgcode2 =
>>>structure(c(1L,
>>>1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L,
>>>2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L,
>>>1L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), edi2 =
>>>structure(c(1L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
>>>2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L,
>>>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"),
>typeofbillid2
>>>= structure(c(2L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>>ExternalNetworkID2 = structure(c(1L,
>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>1L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>>AdjustmentType2 = structure(c(2L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>>CustomEOPLanguage2 = structure(c(2L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor")), row.names =
>>>c(NA,
>>>-35L), class = "data.frame")
>>>
>>>
>>>
>>>Confidentiality Notice This message is sent from Zelis. This
>>>transmission may contain information which is privileged and
>>>confidential and is intended for the personal and confidential use of
>>>the named recipient only. Such information may be protected by
>>>applicable State and Federal laws from this disclosure or
>unauthorized
>>>use. If the reader of this message is not the intended recipient, or
>>>the employee or agent responsible for delivering the message to the
>>>intended recipient, you are hereby notified that any disclosure,
>>>review, discussion, copying, or taking any action in reliance on the
>>>contents of this transmission is strictly prohibited. If you have
>>>received this transmission in error, please contact the sender
>>>immediately. Zelis, 2018.
>>>______________________________________________
>>>mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>see
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>
>>--
>>Sent from my phone. Please excuse my brevity.
>>
>>Confidentiality Notice This message is sent from Zelis. This
>>transmission may contain information which is privileged and
>>confidential and is intended for the personal and confidential use of
>>the named recipient only. Such information may be protected by
>>applicable State and Federal laws from this disclosure or unauthorized
>>use. If the reader of this message is not the intended recipient, or
>>the employee or agent responsible for delivering the message to the
>>intended recipient, you are hereby notified that any disclosure,
>>review, discussion, copying, or taking any action in reliance on the
>>contents of this transmission is strictly prohibited. If you have
>>received this transmission in error, please contact the sender
>>immediately. Zelis, 2018.
>
>--
>Sent from my phone. Please excuse my brevity.
>
>Confidentiality Notice This message is sent from Zelis. This
>transmission may contain information which is privileged and
>confidential and is intended for the personal and confidential use of
>the named recipient only. Such information may be protected by
>applicable State and Federal laws from this disclosure or unauthorized
>use. If the reader of this message is not the intended recipient, or
>the employee or agent responsible for delivering the message to the
>intended recipient, you are hereby notified that any disclosure,
>review, discussion, copying, or taking any action in reliance on the
>contents of this transmission is strictly prohibited. If you have
>received this transmission in error, please contact the sender
>immediately. Zelis, 2018.

--
Sent from my phone. Please excuse my brevity.
--
Sent from my phone. Please excuse my brevity.

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Apr  7 15:05:23 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 07 Apr 2019 06:05:23 -0700
Subject: [R] 
 Help with use RMarkdown and knitr in an rdm output to word.doc
In-Reply-To: <BN7PR02MB5073967567A5940CDC6F414BEA530@BN7PR02MB5073.namprd02.prod.outlook.com>
References: <BN7PR02MB50739C8385C0A8C912BBF1BFEA520@BN7PR02MB5073.namprd02.prod.outlook.com>
 <67DB3C8E-84B5-4C28-835B-5D4BFFDEB5BA@dcn.davis.ca.us>
 <BN7PR02MB5073C9AD60B344B0180E736CEA520@BN7PR02MB5073.namprd02.prod.outlook.com>
 <5A96F01B-E18C-4687-A265-DF94A6FBA450@dcn.davis.ca.us>
 <BN7PR02MB50733CC23D6BBEA96EEC2475EA520@BN7PR02MB5073.namprd02.prod.outlook.com>
 <1A6E7A13-1CCE-4085-9D1F-E6C120A55BEC@dcn.davis.ca.us>
 <BN7PR02MB5073967567A5940CDC6F414BEA530@BN7PR02MB5073.namprd02.prod.outlook.com>
Message-ID: <76816F5B-6F4E-41C9-B37A-095B7240A13F@dcn.davis.ca.us>

The kable_styling function in your code does not appear in the example docx howto, so no, they are not the same.

Bill, at some point you have to stop depending on copying snippets from blogs and read the function documentation, especially the arguments and values sections. The docs for the kable_styling function specifically mention only HTML and LaTeX that I warned you about. It has to generate pure markdown to be converted to docx.

Also, you probably shouldn't use the results='asis' chunk setting in most cases for docx output.

For example, if you read the help page for the rmarkdown::word_document function you should find a keep_md argument. Rmarkdown uses the YAML to setup the call to this function so you can write

output:
    word_document:
        keep_md: yes

for the purpose of looking at the raw markdown after knitr is done processing chunks. Applied to your code with the kable_styling function, you should see an extra md output file as it looks just before being converted to docx, with a bunch of HTML code in the md file where that chunk used to be. This would be fine if the final destination was a web browser, but not for converting to word. If you remove that function then the md file should have a plain markdown table... you can tell because it is much simpler to read than the html in raw form is.

Note that markdown is intentionally simple... there is a lot that you cannot convey through it about appearance. You are shackling yourself to a lower standard of appearance by using it. I inevitably have to manually reformat the results if I share the file for further editing. If that is unacceptable for your case then consider using the officer package... but your finalfit package won't play well with that.

On April 7, 2019 3:07:53 AM PDT, Bill Poling <Bill.Poling at zelis.com> wrote:
>Thanks Jeff, yes well I have followed the Harrison tutorial and my
>chunks are the same as his examples which appear to work fine for him?
>I am stymied.
>
>#https://www.datasurg.net/2018/05/22/finalfit-knitr-and-r-markdown-for-quick-results/
>
>I will keep working on it though, many thanks.
>
>WHP
>
>
>
>
>From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>Sent: Saturday, April 6, 2019 6:51 PM
>To: Bill Poling <Bill.Poling at zelis.com>; r-help at r-project.org; r-help
>(r-help at r-project.org) <r-help at r-project.org>
>Subject: RE: [R] Help with use RMarkdown and knitr in an rdm output to
>word.doc
>
>Read the help files for the functions in each code block that are
>actually producing output that will be displayed. One of them is not
>compatible with docx file output.
>
>On April 6, 2019 2:44:55 PM PDT, Bill Poling
><mailto:Bill.Poling at zelis.com> wrote:
>>Thank you Jeff, I am so darn close, I solve one problem and another
>>emerges!
>>
>>However, I realized that back in July when I made my first and, up
>>until this weekend, only attempt at this I was following the original
>>url that was reposted by R-Bloggers that I mentioned in my original
>>post earlier.
>>#https://www.datasurg.net/2018/05/16/elegant-regression-results-tables-and-plots-the-finalfit-package/
>>
>>Low and behold realized I had asked the author (Ewen Harrison with
>>DataSurg) these questions back then in the comments, UGH!
>>But since I ditched the idea in frustrationback then and I did not
>>follow-up I hadn't realized the author created a companion url for
>this
>>very topic, how to get from .Rmd to word/PDF etc..
>>
>>I located his companion reference url to the original.
>>
>>#https://www.datasurg.net/2018/05/22/finalfit-knitr-and-r-markdown-for-quick-results/
>>
>>So following his further instructions I have made more progress,
>>however, as I mention above the final document remains elusive.
>>
>>SO I did some further googling and perused these sites as well
>>
>>#https://rmarkdown.rstudio.com/articles_docx.html
>>#https://ourcodingclub.github.io/2016/11/24/rmarkdown-1.html
>>
>>Between the companion url of Harrison and
>>https://rmarkdown.rstudio.com/articles_docx.html I have almost got it.
>>
>>---
>>title: "AutoDist Analysis"
>>author: "WHP"
>>date: "4/6/2018"
>>output:
>> word_document:
>> reference_docx: word-styles-reference-01.docx
>>
>>---
>>```{r setup, include=FALSE}
>># Load data into global environment.
>>library(finalfit)
>>library(dplyr)
>>library(knitr)
>>library(kableExtra)
>>load("C:/WHP/Revenue Development Products//BRA
>>AutoDistribution/Test1.rda")
>>```
>>
>>## Table 1 - Associations between Autodist Yes/No and other
>explanatory
>>variables
>>```{r table1, echo = FALSE, results='asis'}
>>kable(table1, row.names=FALSE, align=c("l", "l", "r", "r", "r", "r"),
>>booktabs=TRUE)
>>```
>>
>>## Table 2 - Logistic regression table
>>```{r table2, echo = FALSE, results='asis'}
>>kable(table2, row.names=FALSE, align=c("l", "l", "r", "r", "r", "r"),
>>booktabs=TRUE) %>%
>>kable_styling(font_size=8)
>>```
>>
>>## Figure 1 - Odds Ratio Plot
>>```{r figure1, echo = FALSE, warning=FALSE, message=FALSE,
>>fig.width=10}
>>tmp %>%
>> or_plot(dependent, explanatory)
>>
>>However, now the issue is:
>>"Error: Functions that produce HTML output found in document targeting
>>docx output.
>>Please change the output type of this document to HTML. Alternatively,
>>you can allow
>>HTML output in non-HTML formats by adding this option to the YAML
>>front-matter of
>>your rmarkdown file:
>> always_allow_html: yes
>>Note however that the HTML output will not be visible in non-HTML
>>formats.
>>Execution halted"
>>
>>This is confusing as heck, however, I tried adding that to the YAML
>but
>>I get the same error
>>---
>>title: "AutoDist Analysis"
>>author: "WHP"
>>date: "4/6/2018"
>>output:
>> word_document:
>> reference_docx: word-styles-reference-01.docx
>> always_allow_html: yes
>>---
>>
>>SO needless to say am really disappointed!
>>
>>Whole Saturday on this, sheesh!
>>
>>Thanks for listening
>>
>>WHP
>>
>>
>>From: Jeff Newmiller <mailto:jdnewmil at dcn.davis.ca.us>
>>Sent: Saturday, April 6, 2019 2:25 PM
>>To: Bill Poling <mailto:Bill.Poling at zelis.com>;
>mailto:r-help at r-project.org; r-help
>>(mailto:r-help at r-project.org) <mailto:r-help at r-project.org>
>>Subject: RE: [R] Help with use RMarkdown and knitr in an rdm output to
>>word.doc
>>
>>Maybe you need to format the data frame as markdown before it gets
>>displayed.
>>
>>tmp %>%
>>summary_factorlist(dependent, explanatory, p=TRUE,
>>add_dependent_label=TRUE) %>%
>>knitr::kable()
>>
>>You can also tune how the columns are formatted a bit with arguments
>to
>>the kable function.
>>
>>On April 6, 2019 10:58:53 AM PDT, Bill Poling
>><mailto:Bill.Poling at zelis.com> wrote:
>>>Hello Jeff,as always, thank you for your response.
>>>
>>>Yes .Rmd, and here I thought I was being so thorough about providing
>>as
>>>much detail as possible, my apologies.
>>>
>>>I have an open .Rmd file from the File ->New File menu in RStudio, so
>>I
>>>think that part is correct.
>>>
>>>My code is this.
>>>---
>>>title: "AutoDist Analysis"
>>>author: "WHP"
>>>date: "April 6, 2019"
>>>output:
>>> word_document: default
>>> ---
>>>
>>>```{r ElegantRegress, include = FALSE}
>>>knitr::opts_chunk$set(echo = FALSE)
>>>```
>>>```{r global_options, include=FALSE}
>>>knitr::opts_chunk$set(echo=FALSE, warning=FALSE,
>>>message=FALSE,align=c("l", "l", "r", "r", "r", "r"))
>>>```
>>>
>>>```{r message=FALSE,warning=FALSE}
>>>library(finalfit)
>>>library(dplyr)
>>>library(knitr)
>>>library(memisc)
>>>load("C:/WHP/Revenue Development Products//BRA
>>>AutoDistribution/Autodist RegTests V1.RData")
>>>setwd("C:/WHP/Revenue Development Products/BRA AutoDistribution")
>>>```
>>>
>>>```{r echo=FALSE, results='asis'}
>>>explanatory = c("TBCat","ClaimType","drgcode2","typeofbillid2")
>>>dependent = "Autodist2"
>>>tmp %>% summary_factorlist(dependent, explanatory, p=TRUE,
>>>add_dependent_label=TRUE)
>>>```
>>>
>>>I do get a word.doc file output from the above code (attachment did
>>>not survive the communication as you mentioned) however, it is not in
>>>the format described in the tutorial.
>>>Here is the output I do get:
>>>
>>>AutoDist Analysis
>>>WHP
>>>
>>>April 6, 2019
>>>
>>>Dependent: Autodist2 No Yes p 5 TBCat 1 6257 (96.6) 222 (3.4) <0.001
>6
>>>2 5780 (89.1) 709 (10.9)
>>>7 3 5424 (83.9) 1042 (16.1)
>>>8 4 5324 (82.2) 1156 (17.8)
>>>9 5 5120 (79.0) 1360 (21.0)
>>>10 6 5158 (79.6) 1322 (20.4)
>>>11 7 5022 (77.5) 1459 (22.5)
>>>12 8 5081 (78.4) 1398 (21.6)
>>>13 9 4905 (75.7) 1575 (24.3)
>>>14 10 5011 (77.3) 1469 (22.7)
>>>1 ClaimType 1 48113 (80.6) 11566 (19.4) <0.001 2 2 4969 (97.1) 146
>>>(2.9)
>>>3 drgcode2 FALSE 41015 (80.8) 9734 (19.2) <0.001 4 TRUE 12067 (85.9)
>>>1978 (14.1)
>>>15 typeofbillid2 FALSE 4560 (90.3) 490 (9.7) <0.001 16 TRUE 48522
>>>(81.2) 11222 (18.8)
>>>
>>>I will revisit the links you provide once again.
>>>I have tried to find my problem solution in these earlier.
>>>Not surprisingly given the breadth and depth of information these
>>links
>>>provide I have probably overlooked something nuanced yet highly
>>>important to the formatting issue I am having.
>>>
>>>Once again thank you for your response Sir.
>>>
>>>WHP
>>>
>>>
>>>From: Jeff Newmiller <mailto:jdnewmil at dcn.davis.ca.us>
>>>Sent: Saturday, April 6, 2019 10:42 AM
>>>To: mailto:r-help at r-project.org; Bill Poling
>><mailto:Bill.Poling at zelis.com>; r-help
>>>(mailto:r-help at r-project.org) <mailto:r-help at r-project.org>
>>>Subject: Re: [R] Help with use RMarkdown and knitr in an rdm output
>to
>>>word.doc
>>>
>>>No surprise, the attachments did not come through. There are a
>limited
>>>few MIME types that are allowed, but most email programs don't let
>you
>>>have direct control over that, making embedding your entire
>>>reproducible plain-text example in the main body of the email the
>most
>>>sure path to successful communication on this mailing list.
>>>
>>>I did skim through what you wrote below, scratching my head over what
>>>"rdm" was, until it dawned on me that you might mean a file with an
>>>".Rmd" extension (are-mark-down) and that failing to use the correct
>>>extension might have something to do with your failure.
>>>
>>>Anyway, the topic on this mailing list is the R language, and
>>>contributed packages are (according to the Posting Guide) technically
>>>supposed to have support resources of their own [2] listed in their
>>>DESCRIPTION files [1]. I think the "how it works" discussion there
>>>could be useful in clarifying which other packages rmarkdown is using
>>>and which functions you might find useful documentation about. They
>>>also have a community forum over there I think.
>>>
>>>FWIW my own experience with rmarkdown has been that that most of its
>>>power comes from augmenting it with other packages, and those
>packages
>>>are often very specific to which final output format you are using.
>>The
>>>Word output format is much less extensively supported than HTML or
>PDF
>>>(via LaTeX) are. Don't fall into the trap of using HTML or LaTeX
>>>features when generating Word output.
>>>
>>>[1] https://cran.r-project.org/web/packages/rmarkdown/index.html
>>>[2] https://rmarkdown.rstudio.com
>>>
>>>On April 6, 2019 6:42:01 AM PDT, Bill Poling
>>><mailto:Bill.Poling at zelis.com> wrote:
>>>>Hello:
>>>>
>>>>#sessionInfo()
>>>>#R version 3.5.3 (2019-03-11)
>>>>#Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>>#Running under: Windows >= 8 x64 (build 9200)
>>>>
>>>>#I have been struggling with learning how to use RMarkdown and knitr
>>>in
>>>>an rdm while following this tutorial using my own data.
>>>>#I Tried many months ago to self-teach but it drove me nuts,
>however,
>>>I
>>>>am now at a point where it is essential I get this figured out.
>>>>
>>>>#The tutorial
>>>>#https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/
>>>>
>>>>#I have googled and googled but cannot solve the problem of "how to
>>>get
>>>>my rdm output" word doc to look like the tutorial examples.
>>>>
>>>>#Many googles
>>>>#https://stackoverflow.com/questions/20060370/in-rstudio-is-there-a-way-to-specify-a-fig-path-for-all-figures-for-this-file
>>>>#https://rstudio.github.io/distill/figures.html
>>>>#https://kbroman.org/knitr_knutshell/pages/Rmarkdown.html
>>>>
>>>>#And the list goes on. UGH!
>>>>
>>>>#I attach my rmd code and the word doc output, hopefully they get
>>>>through. Please let me know, and if not how I might improvise
>please.
>>>>
>>>>#Here is the basic procedure from the tutorial which runs fine into
>>>the
>>>>console, however, I am trying to output it with the suggested
>>>>formatting in the tutorial
>>>>explanatory = c("TBCat","ClaimType","drgcode2","typeofbillid2")
>>>>dependent = "Autodist2"
>>>>tmp %>%
>>>>summary_factorlist(dependent, explanatory, p=TRUE,
>>>>add_dependent_label=TRUE)
>>>>
>>>>#Here is a sample of my data.
>>>>
>>>>#I am sure there are also basic formatting inconsistencies or
>>>>redundancies in the rdm and would appreciate any advice or
>suggestion
>>>>for that as well, happy Saturday.
>>>>
>>>>sample <- tmp %>% slice(1:35)
>>>>> dput(sample)
>>>>structure(list(Autodist2 = structure(c(2L, 2L, 2L, 2L, 2L, 2L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label =
>c("No",
>>>>"Yes"), class = "factor"), TBCat = structure(c(4L, 10L, 6L, 8L,
>>>>9L, 4L, 6L, 8L, 4L, 8L, 5L, 10L, 9L, 6L, 7L, 4L, 3L, 8L, 7L,
>>>>4L, 10L, 7L, 8L, 8L, 7L, 4L, 10L, 9L, 3L, 4L, 9L, 8L, 5L, 2L,
>>>>8L), .Label = c("1", "2", "3", "4", "5", "6", "7", "8", "9",
>>>>"10"), class = "factor"), RestictedPayorID = structure(c(2L,
>>>>2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L,
>>>>1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L,
>>>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"), ClaimType =
>>>>structure(c(1L,
>>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>>1L, 1L), .Label = c("1", "2"), class = "factor"),
>>>>ClaimStatus_Non_Acceptance = structure(c(1L,
>>>>1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>>2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 1L, 2L,
>>>>1L, 1L), .Label = c("0", "1"), class = "factor"),
>>ClaimStatus_Accepted
>>>>= structure(c(2L,
>>>>2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>>1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 1L,
>>>>2L, 2L), .Label = c("0", "1"), class = "factor"), ClaimManagerID3 =
>>>>structure(c(2L,
>>>>1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>>>ClaimStatus_In_Process = structure(c(1L,
>>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>>1L, 1L), .Label = c("0", "1"), class = "factor"), Appeals2 =
>>>>structure(c(2L,
>>>>2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L,
>>>>1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), drgcode2 =
>>>>structure(c(1L,
>>>>1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L,
>>>>2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L,
>>>>1L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), edi2 =
>>>>structure(c(1L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
>>>>2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L,
>>>>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>typeofbillid2
>>>>= structure(c(2L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>>>ExternalNetworkID2 = structure(c(1L,
>>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>>1L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>>>AdjustmentType2 = structure(c(2L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>>>CustomEOPLanguage2 = structure(c(2L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor")), row.names
>=
>>>>c(NA,
>>>>-35L), class = "data.frame")
>>>>
>>>>
>>>>
>>>>Confidentiality Notice This message is sent from Zelis. This
>>>>transmission may contain information which is privileged and
>>>>confidential and is intended for the personal and confidential use
>of
>>>>the named recipient only. Such information may be protected by
>>>>applicable State and Federal laws from this disclosure or
>>unauthorized
>>>>use. If the reader of this message is not the intended recipient, or
>>>>the employee or agent responsible for delivering the message to the
>>>>intended recipient, you are hereby notified that any disclosure,
>>>>review, discussion, copying, or taking any action in reliance on the
>>>>contents of this transmission is strictly prohibited. If you have
>>>>received this transmission in error, please contact the sender
>>>>immediately. Zelis, 2018.
>>>>______________________________________________
>>>>mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>see
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide
>>>>http://www.R-project.org/posting-guide.html
>>>>and provide commented, minimal, self-contained, reproducible code.
>>>
>>>--
>>>Sent from my phone. Please excuse my brevity.
>>>
>>>Confidentiality Notice This message is sent from Zelis. This
>>>transmission may contain information which is privileged and
>>>confidential and is intended for the personal and confidential use of
>>>the named recipient only. Such information may be protected by
>>>applicable State and Federal laws from this disclosure or
>unauthorized
>>>use. If the reader of this message is not the intended recipient, or
>>>the employee or agent responsible for delivering the message to the
>>>intended recipient, you are hereby notified that any disclosure,
>>>review, discussion, copying, or taking any action in reliance on the
>>>contents of this transmission is strictly prohibited. If you have
>>>received this transmission in error, please contact the sender
>>>immediately. Zelis, 2018.
>>
>>--
>>Sent from my phone. Please excuse my brevity.
>>
>>Confidentiality Notice This message is sent from Zelis. This
>>transmission may contain information which is privileged and
>>confidential and is intended for the personal and confidential use of
>>the named recipient only. Such information may be protected by
>>applicable State and Federal laws from this disclosure or unauthorized
>>use. If the reader of this message is not the intended recipient, or
>>the employee or agent responsible for delivering the message to the
>>intended recipient, you are hereby notified that any disclosure,
>>review, discussion, copying, or taking any action in reliance on the
>>contents of this transmission is strictly prohibited. If you have
>>received this transmission in error, please contact the sender
>>immediately. Zelis, 2018.
>
>--
>Sent from my phone. Please excuse my brevity.
>--
>Sent from my phone. Please excuse my brevity.
>
>Confidentiality Notice This message is sent from Zelis. This
>transmission may contain information which is privileged and
>confidential and is intended for the personal and confidential use of
>the named recipient only. Such information may be protected by
>applicable State and Federal laws from this disclosure or unauthorized
>use. If the reader of this message is not the intended recipient, or
>the employee or agent responsible for delivering the message to the
>intended recipient, you are hereby notified that any disclosure,
>review, discussion, copying, or taking any action in reliance on the
>contents of this transmission is strictly prohibited. If you have
>received this transmission in error, please contact the sender
>immediately. Zelis, 2018.

-- 
Sent from my phone. Please excuse my brevity.


From B|||@Po||ng @end|ng |rom ze||@@com  Sun Apr  7 17:16:39 2019
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Sun, 7 Apr 2019 15:16:39 +0000
Subject: [R] 
 Help with use RMarkdown and knitr in an rdm output to word.doc
In-Reply-To: <76816F5B-6F4E-41C9-B37A-095B7240A13F@dcn.davis.ca.us>
References: <BN7PR02MB50739C8385C0A8C912BBF1BFEA520@BN7PR02MB5073.namprd02.prod.outlook.com>
 <67DB3C8E-84B5-4C28-835B-5D4BFFDEB5BA@dcn.davis.ca.us>
 <BN7PR02MB5073C9AD60B344B0180E736CEA520@BN7PR02MB5073.namprd02.prod.outlook.com>
 <5A96F01B-E18C-4687-A265-DF94A6FBA450@dcn.davis.ca.us>
 <BN7PR02MB50733CC23D6BBEA96EEC2475EA520@BN7PR02MB5073.namprd02.prod.outlook.com>
 <1A6E7A13-1CCE-4085-9D1F-E6C120A55BEC@dcn.davis.ca.us>
 <BN7PR02MB5073967567A5940CDC6F414BEA530@BN7PR02MB5073.namprd02.prod.outlook.com>
 <76816F5B-6F4E-41C9-B37A-095B7240A13F@dcn.davis.ca.us>
Message-ID: <BN7PR02MB5073C33A8C17011CCDAA5DE1EA530@BN7PR02MB5073.namprd02.prod.outlook.com>

Hi Jeff, yes guilty as charged, I do depend on copying snippets too much, then look for the documentation when it blows up.

I will heed your advice and review further the help page for the rmarkdown::word_document and the other resources as well.

Thanks again for taking the time Jeff I really have learned a lot from your assistance.

WHP


From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: Sunday, April 7, 2019 9:05 AM
To: Bill Poling <Bill.Poling at zelis.com>; r-help at r-project.org; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: RE: [R] Help with use RMarkdown and knitr in an rdm output to word.doc

The kable_styling function in your code does not appear in the example docx howto, so no, they are not the same.

Bill, at some point you have to stop depending on copying snippets from blogs and read the function documentation, especially the arguments and values sections. The docs for the kable_styling function specifically mention only HTML and LaTeX that I warned you about. It has to generate pure markdown to be converted to docx.

Also, you probably shouldn't use the results='asis' chunk setting in most cases for docx output.

For example, if you read the help page for the rmarkdown::word_document function you should find a keep_md argument. Rmarkdown uses the YAML to setup the call to this function so you can write

output:
word_document:
keep_md: yes

for the purpose of looking at the raw markdown after knitr is done processing chunks. Applied to your code with the kable_styling function, you should see an extra md output file as it looks just before being converted to docx, with a bunch of HTML code in the md file where that chunk used to be. This would be fine if the final destination was a web browser, but not for converting to word. If you remove that function then the md file should have a plain markdown table... you can tell because it is much simpler to read than the html in raw form is.

Note that markdown is intentionally simple... there is a lot that you cannot convey through it about appearance. You are shackling yourself to a lower standard of appearance by using it. I inevitably have to manually reformat the results if I share the file for further editing. If that is unacceptable for your case then consider using the officer package... but your finalfit package won't play well with that.

On April 7, 2019 3:07:53 AM PDT, Bill Poling <mailto:Bill.Poling at zelis.com> wrote:
>Thanks Jeff, yes well I have followed the Harrison tutorial and my
>chunks are the same as his examples which appear to work fine for him?
>I am stymied.
>
>#https://www.datasurg.net/2018/05/22/finalfit-knitr-and-r-markdown-for-quick-results/
>
>I will keep working on it though, many thanks.
>
>WHP
>
>
>
>
>From: Jeff Newmiller <mailto:jdnewmil at dcn.davis.ca.us>
>Sent: Saturday, April 6, 2019 6:51 PM
>To: Bill Poling <mailto:Bill.Poling at zelis.com>; mailto:r-help at r-project.org; r-help
>(mailto:r-help at r-project.org) <mailto:r-help at r-project.org>
>Subject: RE: [R] Help with use RMarkdown and knitr in an rdm output to
>word.doc
>
>Read the help files for the functions in each code block that are
>actually producing output that will be displayed. One of them is not
>compatible with docx file output.
>
>On April 6, 2019 2:44:55 PM PDT, Bill Poling
><mailto:Bill.Poling at zelis.com> wrote:
>>Thank you Jeff, I am so darn close, I solve one problem and another
>>emerges!
>>
>>However, I realized that back in July when I made my first and, up
>>until this weekend, only attempt at this I was following the original
>>url that was reposted by R-Bloggers that I mentioned in my original
>>post earlier.
>>#https://www.datasurg.net/2018/05/16/elegant-regression-results-tables-and-plots-the-finalfit-package/
>>
>>Low and behold realized I had asked the author (Ewen Harrison with
>>DataSurg) these questions back then in the comments, UGH!
>>But since I ditched the idea in frustrationback then and I did not
>>follow-up I hadn't realized the author created a companion url for
>this
>>very topic, how to get from .Rmd to word/PDF etc..
>>
>>I located his companion reference url to the original.
>>
>>#https://www.datasurg.net/2018/05/22/finalfit-knitr-and-r-markdown-for-quick-results/
>>
>>So following his further instructions I have made more progress,
>>however, as I mention above the final document remains elusive.
>>
>>SO I did some further googling and perused these sites as well
>>
>>#https://rmarkdown.rstudio.com/articles_docx.html
>>#https://ourcodingclub.github.io/2016/11/24/rmarkdown-1.html
>>
>>Between the companion url of Harrison and
>>https://rmarkdown.rstudio.com/articles_docx.html I have almost got it.
>>
>>---
>>title: "AutoDist Analysis"
>>author: "WHP"
>>date: "4/6/2018"
>>output:
>> word_document:
>> reference_docx: word-styles-reference-01.docx
>>
>>---
>>```{r setup, include=FALSE}
>># Load data into global environment.
>>library(finalfit)
>>library(dplyr)
>>library(knitr)
>>library(kableExtra)
>>load("C:/WHP/Revenue Development Products//BRA
>>AutoDistribution/Test1.rda")
>>```
>>
>>## Table 1 - Associations between Autodist Yes/No and other
>explanatory
>>variables
>>```{r table1, echo = FALSE, results='asis'}
>>kable(table1, row.names=FALSE, align=c("l", "l", "r", "r", "r", "r"),
>>booktabs=TRUE)
>>```
>>
>>## Table 2 - Logistic regression table
>>```{r table2, echo = FALSE, results='asis'}
>>kable(table2, row.names=FALSE, align=c("l", "l", "r", "r", "r", "r"),
>>booktabs=TRUE) %>%
>>kable_styling(font_size=8)
>>```
>>
>>## Figure 1 - Odds Ratio Plot
>>```{r figure1, echo = FALSE, warning=FALSE, message=FALSE,
>>fig.width=10}
>>tmp %>%
>> or_plot(dependent, explanatory)
>>
>>However, now the issue is:
>>"Error: Functions that produce HTML output found in document targeting
>>docx output.
>>Please change the output type of this document to HTML. Alternatively,
>>you can allow
>>HTML output in non-HTML formats by adding this option to the YAML
>>front-matter of
>>your rmarkdown file:
>> always_allow_html: yes
>>Note however that the HTML output will not be visible in non-HTML
>>formats.
>>Execution halted"
>>
>>This is confusing as heck, however, I tried adding that to the YAML
>but
>>I get the same error
>>---
>>title: "AutoDist Analysis"
>>author: "WHP"
>>date: "4/6/2018"
>>output:
>> word_document:
>> reference_docx: word-styles-reference-01.docx
>> always_allow_html: yes
>>---
>>
>>SO needless to say am really disappointed!
>>
>>Whole Saturday on this, sheesh!
>>
>>Thanks for listening
>>
>>WHP
>>
>>
>>From: Jeff Newmiller <mailto:jdnewmil at dcn.davis.ca.us>
>>Sent: Saturday, April 6, 2019 2:25 PM
>>To: Bill Poling <mailto:Bill.Poling at zelis.com>;
>mailto:r-help at r-project.org; r-help
>>(mailto:r-help at r-project.org) <mailto:r-help at r-project.org>
>>Subject: RE: [R] Help with use RMarkdown and knitr in an rdm output to
>>word.doc
>>
>>Maybe you need to format the data frame as markdown before it gets
>>displayed.
>>
>>tmp %>%
>>summary_factorlist(dependent, explanatory, p=TRUE,
>>add_dependent_label=TRUE) %>%
>>knitr::kable()
>>
>>You can also tune how the columns are formatted a bit with arguments
>to
>>the kable function.
>>
>>On April 6, 2019 10:58:53 AM PDT, Bill Poling
>><mailto:Bill.Poling at zelis.com> wrote:
>>>Hello Jeff,as always, thank you for your response.
>>>
>>>Yes .Rmd, and here I thought I was being so thorough about providing
>>as
>>>much detail as possible, my apologies.
>>>
>>>I have an open .Rmd file from the File ->New File menu in RStudio, so
>>I
>>>think that part is correct.
>>>
>>>My code is this.
>>>---
>>>title: "AutoDist Analysis"
>>>author: "WHP"
>>>date: "April 6, 2019"
>>>output:
>>> word_document: default
>>> ---
>>>
>>>```{r ElegantRegress, include = FALSE}
>>>knitr::opts_chunk$set(echo = FALSE)
>>>```
>>>```{r global_options, include=FALSE}
>>>knitr::opts_chunk$set(echo=FALSE, warning=FALSE,
>>>message=FALSE,align=c("l", "l", "r", "r", "r", "r"))
>>>```
>>>
>>>```{r message=FALSE,warning=FALSE}
>>>library(finalfit)
>>>library(dplyr)
>>>library(knitr)
>>>library(memisc)
>>>load("C:/WHP/Revenue Development Products//BRA
>>>AutoDistribution/Autodist RegTests V1.RData")
>>>setwd("C:/WHP/Revenue Development Products/BRA AutoDistribution")
>>>```
>>>
>>>```{r echo=FALSE, results='asis'}
>>>explanatory = c("TBCat","ClaimType","drgcode2","typeofbillid2")
>>>dependent = "Autodist2"
>>>tmp %>% summary_factorlist(dependent, explanatory, p=TRUE,
>>>add_dependent_label=TRUE)
>>>```
>>>
>>>I do get a word.doc file output from the above code (attachment did
>>>not survive the communication as you mentioned) however, it is not in
>>>the format described in the tutorial.
>>>Here is the output I do get:
>>>
>>>AutoDist Analysis
>>>WHP
>>>
>>>April 6, 2019
>>>
>>>Dependent: Autodist2 No Yes p 5 TBCat 1 6257 (96.6) 222 (3.4) <0.001
>6
>>>2 5780 (89.1) 709 (10.9)
>>>7 3 5424 (83.9) 1042 (16.1)
>>>8 4 5324 (82.2) 1156 (17.8)
>>>9 5 5120 (79.0) 1360 (21.0)
>>>10 6 5158 (79.6) 1322 (20.4)
>>>11 7 5022 (77.5) 1459 (22.5)
>>>12 8 5081 (78.4) 1398 (21.6)
>>>13 9 4905 (75.7) 1575 (24.3)
>>>14 10 5011 (77.3) 1469 (22.7)
>>>1 ClaimType 1 48113 (80.6) 11566 (19.4) <0.001 2 2 4969 (97.1) 146
>>>(2.9)
>>>3 drgcode2 FALSE 41015 (80.8) 9734 (19.2) <0.001 4 TRUE 12067 (85.9)
>>>1978 (14.1)
>>>15 typeofbillid2 FALSE 4560 (90.3) 490 (9.7) <0.001 16 TRUE 48522
>>>(81.2) 11222 (18.8)
>>>
>>>I will revisit the links you provide once again.
>>>I have tried to find my problem solution in these earlier.
>>>Not surprisingly given the breadth and depth of information these
>>links
>>>provide I have probably overlooked something nuanced yet highly
>>>important to the formatting issue I am having.
>>>
>>>Once again thank you for your response Sir.
>>>
>>>WHP
>>>
>>>
>>>From: Jeff Newmiller <mailto:jdnewmil at dcn.davis.ca.us>
>>>Sent: Saturday, April 6, 2019 10:42 AM
>>>To: mailto:r-help at r-project.org; Bill Poling
>><mailto:Bill.Poling at zelis.com>; r-help
>>>(mailto:r-help at r-project.org) <mailto:r-help at r-project.org>
>>>Subject: Re: [R] Help with use RMarkdown and knitr in an rdm output
>to
>>>word.doc
>>>
>>>No surprise, the attachments did not come through. There are a
>limited
>>>few MIME types that are allowed, but most email programs don't let
>you
>>>have direct control over that, making embedding your entire
>>>reproducible plain-text example in the main body of the email the
>most
>>>sure path to successful communication on this mailing list.
>>>
>>>I did skim through what you wrote below, scratching my head over what
>>>"rdm" was, until it dawned on me that you might mean a file with an
>>>".Rmd" extension (are-mark-down) and that failing to use the correct
>>>extension might have something to do with your failure.
>>>
>>>Anyway, the topic on this mailing list is the R language, and
>>>contributed packages are (according to the Posting Guide) technically
>>>supposed to have support resources of their own [2] listed in their
>>>DESCRIPTION files [1]. I think the "how it works" discussion there
>>>could be useful in clarifying which other packages rmarkdown is using
>>>and which functions you might find useful documentation about. They
>>>also have a community forum over there I think.
>>>
>>>FWIW my own experience with rmarkdown has been that that most of its
>>>power comes from augmenting it with other packages, and those
>packages
>>>are often very specific to which final output format you are using.
>>The
>>>Word output format is much less extensively supported than HTML or
>PDF
>>>(via LaTeX) are. Don't fall into the trap of using HTML or LaTeX
>>>features when generating Word output.
>>>
>>>[1] https://cran.r-project.org/web/packages/rmarkdown/index.html
>>>[2] https://rmarkdown.rstudio.com
>>>
>>>On April 6, 2019 6:42:01 AM PDT, Bill Poling
>>><mailto:Bill.Poling at zelis.com> wrote:
>>>>Hello:
>>>>
>>>>#sessionInfo()
>>>>#R version 3.5.3 (2019-03-11)
>>>>#Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>>#Running under: Windows >= 8 x64 (build 9200)
>>>>
>>>>#I have been struggling with learning how to use RMarkdown and knitr
>>>in
>>>>an rdm while following this tutorial using my own data.
>>>>#I Tried many months ago to self-teach but it drove me nuts,
>however,
>>>I
>>>>am now at a point where it is essential I get this figured out.
>>>>
>>>>#The tutorial
>>>>#https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/
>>>>
>>>>#I have googled and googled but cannot solve the problem of "how to
>>>get
>>>>my rdm output" word doc to look like the tutorial examples.
>>>>
>>>>#Many googles
>>>>#https://stackoverflow.com/questions/20060370/in-rstudio-is-there-a-way-to-specify-a-fig-path-for-all-figures-for-this-file
>>>>#https://rstudio.github.io/distill/figures.html
>>>>#https://kbroman.org/knitr_knutshell/pages/Rmarkdown.html
>>>>
>>>>#And the list goes on. UGH!
>>>>
>>>>#I attach my rmd code and the word doc output, hopefully they get
>>>>through. Please let me know, and if not how I might improvise
>please.
>>>>
>>>>#Here is the basic procedure from the tutorial which runs fine into
>>>the
>>>>console, however, I am trying to output it with the suggested
>>>>formatting in the tutorial
>>>>explanatory = c("TBCat","ClaimType","drgcode2","typeofbillid2")
>>>>dependent = "Autodist2"
>>>>tmp %>%
>>>>summary_factorlist(dependent, explanatory, p=TRUE,
>>>>add_dependent_label=TRUE)
>>>>
>>>>#Here is a sample of my data.
>>>>
>>>>#I am sure there are also basic formatting inconsistencies or
>>>>redundancies in the rdm and would appreciate any advice or
>suggestion
>>>>for that as well, happy Saturday.
>>>>
>>>>sample <- tmp %>% slice(1:35)
>>>>> dput(sample)
>>>>structure(list(Autodist2 = structure(c(2L, 2L, 2L, 2L, 2L, 2L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label =
>c("No",
>>>>"Yes"), class = "factor"), TBCat = structure(c(4L, 10L, 6L, 8L,
>>>>9L, 4L, 6L, 8L, 4L, 8L, 5L, 10L, 9L, 6L, 7L, 4L, 3L, 8L, 7L,
>>>>4L, 10L, 7L, 8L, 8L, 7L, 4L, 10L, 9L, 3L, 4L, 9L, 8L, 5L, 2L,
>>>>8L), .Label = c("1", "2", "3", "4", "5", "6", "7", "8", "9",
>>>>"10"), class = "factor"), RestictedPayorID = structure(c(2L,
>>>>2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L,
>>>>1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L,
>>>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"), ClaimType =
>>>>structure(c(1L,
>>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>>1L, 1L), .Label = c("1", "2"), class = "factor"),
>>>>ClaimStatus_Non_Acceptance = structure(c(1L,
>>>>1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>>2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 1L, 1L, 2L,
>>>>1L, 1L), .Label = c("0", "1"), class = "factor"),
>>ClaimStatus_Accepted
>>>>= structure(c(2L,
>>>>2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>>1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 1L,
>>>>2L, 2L), .Label = c("0", "1"), class = "factor"), ClaimManagerID3 =
>>>>structure(c(2L,
>>>>1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>>>ClaimStatus_In_Process = structure(c(1L,
>>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>>1L, 1L), .Label = c("0", "1"), class = "factor"), Appeals2 =
>>>>structure(c(2L,
>>>>2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L,
>>>>1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), drgcode2 =
>>>>structure(c(1L,
>>>>1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L,
>>>>2L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L,
>>>>1L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"), edi2 =
>>>>structure(c(1L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
>>>>2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L,
>>>>2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>typeofbillid2
>>>>= structure(c(2L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>>>ExternalNetworkID2 = structure(c(1L,
>>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>>1L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>>>AdjustmentType2 = structure(c(2L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>>>CustomEOPLanguage2 = structure(c(2L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>>2L, 2L), .Label = c("FALSE", "TRUE"), class = "factor")), row.names
>=
>>>>c(NA,
>>>>-35L), class = "data.frame")
>>>>
>>>>
>>>>
>>>>Confidentiality Notice This message is sent from Zelis. This
>>>>transmission may contain information which is privileged and
>>>>confidential and is intended for the personal and confidential use
>of
>>>>the named recipient only. Such information may be protected by
>>>>applicable State and Federal laws from this disclosure or
>>unauthorized
>>>>use. If the reader of this message is not the intended recipient, or
>>>>the employee or agent responsible for delivering the message to the
>>>>intended recipient, you are hereby notified that any disclosure,
>>>>review, discussion, copying, or taking any action in reliance on the
>>>>contents of this transmission is strictly prohibited. If you have
>>>>received this transmission in error, please contact the sender
>>>>immediately. Zelis, 2018.
>>>>______________________________________________
>>>>mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>see
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide
>>>>http://www.R-project.org/posting-guide.html
>>>>and provide commented, minimal, self-contained, reproducible code.
>>>
>>>--
>>>Sent from my phone. Please excuse my brevity.
>>>
>>>Confidentiality Notice This message is sent from Zelis. This
>>>transmission may contain information which is privileged and
>>>confidential and is intended for the personal and confidential use of
>>>the named recipient only. Such information may be protected by
>>>applicable State and Federal laws from this disclosure or
>unauthorized
>>>use. If the reader of this message is not the intended recipient, or
>>>the employee or agent responsible for delivering the message to the
>>>intended recipient, you are hereby notified that any disclosure,
>>>review, discussion, copying, or taking any action in reliance on the
>>>contents of this transmission is strictly prohibited. If you have
>>>received this transmission in error, please contact the sender
>>>immediately. Zelis, 2018.
>>
>>--
>>Sent from my phone. Please excuse my brevity.
>>
>>Confidentiality Notice This message is sent from Zelis. This
>>transmission may contain information which is privileged and
>>confidential and is intended for the personal and confidential use of
>>the named recipient only. Such information may be protected by
>>applicable State and Federal laws from this disclosure or unauthorized
>>use. If the reader of this message is not the intended recipient, or
>>the employee or agent responsible for delivering the message to the
>>intended recipient, you are hereby notified that any disclosure,
>>review, discussion, copying, or taking any action in reliance on the
>>contents of this transmission is strictly prohibited. If you have
>>received this transmission in error, please contact the sender
>>immediately. Zelis, 2018.
>
>--
>Sent from my phone. Please excuse my brevity.
>--
>Sent from my phone. Please excuse my brevity.
>
>Confidentiality Notice This message is sent from Zelis. This
>transmission may contain information which is privileged and
>confidential and is intended for the personal and confidential use of
>the named recipient only. Such information may be protected by
>applicable State and Federal laws from this disclosure or unauthorized
>use. If the reader of this message is not the intended recipient, or
>the employee or agent responsible for delivering the message to the
>intended recipient, you are hereby notified that any disclosure,
>review, discussion, copying, or taking any action in reliance on the
>contents of this transmission is strictly prohibited. If you have
>received this transmission in error, please contact the sender
>immediately. Zelis, 2018.

--
Sent from my phone. Please excuse my brevity.

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

From @m|t@c@03 @end|ng |rom gm@||@com  Sat Apr  6 16:03:01 2019
From: @m|t@c@03 @end|ng |rom gm@||@com (Amit Govil)
Date: Sat, 6 Apr 2019 22:03:01 +0800
Subject: [R] Unable to read csv files with comma in values
Message-ID: <CAPf9UMoEpz4GDPJuDRO=ugSHybPreA3dwnpZD_AK2BbLbptV4w@mail.gmail.com>

Hi,

I have a bunch of csv files to read in R. I'm unable to read them correctly
because in some of the files, there is a column ("Role") which has comma in
the values.

Sample data:

User, Role, Rule, GAPId
Sam, [HadoopAnalyst, DBA, Developer], R46443

I'm trying to play with the below code but it doesnt work:

files <- list.files(pattern='.*REDUNDANT(.*).csv$')

tbl <- sapply(files, function(f) {
  gsub('\\[|\\]', '"', readLines(f)) %>%
    read.csv(text = ., check.names = FALSE)
}) %>%
  bind_rows(.id = "id") %>%
  select(id, User, Rule) %>%
  distinct()

Please assist.

Thanks

	[[alternative HTML version deleted]]


From m|ch@e|@e|@enr|ng @end|ng |rom gmx@ch  Sat Apr  6 22:09:32 2019
From: m|ch@e|@e|@enr|ng @end|ng |rom gmx@ch (Michael Eisenring)
Date: Sat, 6 Apr 2019 15:09:32 -0500
Subject: [R] Color-coding data points in complex dotplot (ggplot2)
In-Reply-To: <CAKZQJMAEG+r5hstaNfSwLC2g=Hz_Y7Oe5gahzg2806dmDYmpWA@mail.gmail.com>
References: <000201d4ec0a$cedc28f0$6c947ad0$@gmx.ch>
 <CAKZQJMAEG+r5hstaNfSwLC2g=Hz_Y7Oe5gahzg2806dmDYmpWA@mail.gmail.com>
Message-ID: <000801d4ecb4$a6d71950$f4854bf0$@gmx.ch>

Hi John,
Thanks for this informantion.
Attached are the figures in a single PDF

Mike

-----Urspr?ngliche Nachricht-----
Von: John Kane [mailto:jrkrideau at gmail.com] 
Gesendet: Samstag, 6. April 2019 07:23
An: Michael Eisenring <michael.eisenring at gmx.ch>
Cc: R. Help Mailing List <r-help at r-project.org>
Betreff: Re: [R] Color-coding data points in complex dotplot (ggplot2)

HI Michael
Your code runs but we did not get any attached figure.  You might want to try sending it as a .pdf file. They usually make it through the spam filters

On Sat, 6 Apr 2019 at 08:09, Michael Eisenring <michael.eisenring at gmx.ch> wrote:
>
> Dear R-List members,
>
> I produced a dot plot (see attachment 1) on 6 different treatments 
> (trees under 6 different conditions; in column " Location.Treatment " 
> in my raw data). For each of these " Location.treatment" categories, I 
> calculated a mean value and the SE for a specific compound (%CT).
>
> I am able to produce a plot where all the 6 treatments (in column "
> Location.Treatment") are separated (see code and Fig. 1) so that each 
> of two "con" and "exp" treatments (in the column "treatment") are 
> nested within one of the three locations (High, mid, low; in the 
> column "Location") (see plot that the code produces). This is the plot structure I want.
>
> Now I would like to assign colors to the raw data points ( the "point cloud"
> next to each mean +SE value). Each of these points stems from a 
> different "Genotype" and I would like to color code the points with 
> regard to the genotypes (e.g. all points from Genotype A should be 
> green, all points from Genotype B should be red etc.) I would like to 
> use my own specified colors in the code (not the standard palette).
>
> I tried did the following (without success)
>
> 1.      I added "aes(color=Genotype,.." into "geom_point(..)"
>
> 2.      I added my specific colors to "scale_color_manual"
>
> scale_color_manual(labels=c("Control","Damaged"),values=c("red","black
> ","#06 
> 7c43","#89b651","#dc5b09","#e4a710","#92c5de","grey","#1d71b4","#7873a3"....
> ..
>
>
>
> However, if I do that my "nested" plot structure disappears (i.e. I 
> cannot visually differentiate between "con" and "exp" treatments 
> nested within mid /high/. See Fig. 2)
>
> Basically, all I want is to produce a plot that looks like the one 
> from my actual code( Fig.1) but where the individual data points are 
> colored according to "Genotypes"
>
> Below is my code and my raw data.
>
> Help is very much appreciated!
>
> Thanks a lot,
>
> Mike
>
>
>
> #CODE-----------------------------------------------------
>
> require(ggplot2)
>
>
>
> #REMOVE START FOR ANALYSIS
>
> dta<-subset(dta_complete,Time=="Stop")
>
> dta
>
>
>
> #Calculation of SE
>
> data_summary <- function(x) {
>
>   m <- mean(x)
>
>   ymin <- m-sd(x)/sqrt(length(x))
>
>   ymax <- m+sd(x)/sqrt(length(x))
>
>   return(c(y=m,ymin=ymin,ymax=ymax))
>
> }
>
>
>
> pd1 = position_dodge(0.5)
>
>
>
> plot_CT<- ggplot(dta, aes(x=Location, y=CT,
> colour=Treatment,shape=Treatment)) +
>
>   stat_summary(fun.data=data_summary, position=pd1, geom="errorbar",
> width=0.05) +
>
>   stat_summary(fun.data=data_summary, position=pd1, geom="point", 
> size=2) +
>
>   geom_point(position=position_jitterdodge(dodge.width=0.8, 
> jitter.height=0, jitter.width=0.2),
>
>              alpha=0.7) +
>
>   labs(title="", x="", y = "CT (% dw)")+
>
>   scale_color_manual(labels=c("Control",
> "Damaged"),values=c("red","black"),guide = guide_legend(reverse = 
> TRUE) )+
>
>   scale_shape_manual(labels=c("Control", 
> "Damaged"),name="Treatment",values
> = c(16,16),guide = guide_legend(reverse = TRUE) )+
>
>   #Style of background
>
>   theme_classic()+
>
>   #Change title
>
>   theme(plot.title = element_text(color="black", size=17, 
> face="bold"))+
>
>   #Font size axis
>
>   theme(axis.text=element_text(size=12),
>
>         axis.title=element_text(size=17))+
>
>   scale_x_discrete("Location",labels = c("Low", "Mid", 
> "High"),expand=c(0.1, 0.5))+
>
>   coord_flip()
>
>
>
> plot_CT
>
>
>
> #DATA-----------------------------------------------------------------
> ------
> -----------------
>
> structure(list(Location = structure(c(2L, 3L, 1L, 2L, 3L, 1L,
>
> 2L, 3L, 1L, 2L, 3L, 1L, 2L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L,
>
> 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L,
>
> 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L,
>
> 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L,
>
> 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L,
>
> 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L,
>
> 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L,
>
> 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L,
>
> 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L,
>
> 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L,
>
> 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L,
>
> 3L, 1L, 2L, 3L, 1L, 2L, 3L, 1L), .Label = c("High", "Low", "Mid"
>
> ), class = "factor"), Treatment = structure(c(2L, 2L, 2L, 1L,
>
> 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L,
>
> 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L,
>
> 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L,
>
> 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L,
>
> 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L,
>
> 2L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L,
>
> 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L,
>
> 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L,
>
> 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L,
>
> 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L,
>
> 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 2L,
>
> 2L, 1L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 1L), .Label = c("Con", "Exp"
>
> ), class = "factor"), Time = structure(c(2L, 2L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("Start", "Stop"
>
> ), class = "factor"), Genotype = structure(c(7L, 7L, 7L, 7L,
>
> 7L, 7L, 4L, 4L, 4L, 4L, 4L, 4L, 6L, 6L, 6L, 6L, 6L, 2L, 2L, 2L,
>
> 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 8L, 8L, 8L, 8L, 8L, 8L, 1L,
>
> 1L, 1L, 1L, 1L, 1L, 5L, 5L, 5L, 5L, 5L, 5L, 4L, 4L, 4L, 4L, 4L,
>
> 4L, 3L, 3L, 3L, 3L, 3L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 6L, 6L, 6L,
>
> 6L, 6L, 6L, 8L, 8L, 8L, 8L, 8L, 8L, 5L, 5L, 5L, 5L, 5L, 5L, 7L,
>
> 7L, 7L, 7L, 7L, 1L, 1L, 1L, 1L, 1L, 1L, 5L, 5L, 5L, 5L, 5L, 5L,
>
> 1L, 1L, 1L, 1L, 1L, 1L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L,
>
> 4L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L,
>
> 7L, 7L, 7L, 7L, 6L, 6L, 6L, 6L, 6L, 6L, 8L, 8L, 8L, 8L, 8L, 8L,
>
> 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L,
>
> 1L, 1L, 5L, 5L, 5L, 5L, 5L, 5L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L,
>
> 8L, 8L, 8L, 8L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("A", "B",
>
> "C", "D", "E", "F", "G", "H"), class = "factor"), Time.Location = 
> structure(c(5L,
>
> 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 4L, 5L, 6L, 4L,
>
> 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L,
>
> 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L,
>
> 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L,
>
> 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L,
>
> 6L, 4L, 5L, 6L, 4L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L,
>
> 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L,
>
> 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L,
>
> 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L,
>
> 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L,
>
> 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L,
>
> 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L, 5L, 6L, 4L), .Label = 
> c("StartHigh",
>
>
> "StartLow", "StartMid", "StopHigh", "StopLow", "StopMid"), class = 
> "factor"),
>
>     Location.Treatment = structure(c(4L, 6L, 2L, 3L, 5L, 1L,
>
>     4L, 6L, 2L, 3L, 5L, 1L, 4L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L,
>
>     5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L,
>
>     6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L,
>
>     5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L,
>
>     6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L,
>
>     5L, 1L, 4L, 6L, 2L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L,
>
>     2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L,
>
>     1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L,
>
>     2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L,
>
>     1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L,
>
>     2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L,
>
>     1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L, 2L, 3L, 5L, 1L, 4L, 6L,
>
>     2L, 3L, 5L, 1L), .Label = c("HighCon", "HighExp", "LowCon",
>
>     "LowExp", "MidCon", "MidExp"), class = "factor"), CT = c(4.61538,
>
>     3.96739, 7.34797, 3.58108, 2.89655, 2.7993, 10.56122, 10.68396,
>
>     15.57252, 6.79245, 9.23469, 9.18, 1.1087, 4.26136, 1.14504,
>
>     2.20238, 3.15789, 9.54082, 11.05263, 15.84783, 10.48986,
>
>     12.62195, 15.12931, 5.51471, 8.20313, 11.85811, 3.38115,
>
>     7.5, 9.69512, 8.64407, 11.30597, 14.42797, 8.8125, 11.82482,
>
>     11.53061, 6.97674, 9.62766, 10.88028, 5.50403, 9.73558, 8.56419,
>
>     11.84524, 16.34892, 18.15789, 10.58036, 14.80932, 12.06081,
>
>     12.96992, 9.86014, 12.45652, 6.625, 6.93396, 9.10714, 3.66142,
>
>     9.19811, 10.88346, 2.88851, 6.85096, 10.27778, 8.29787, 13.00885,
>
>     14.38017, 7.5, 11.77734, 13.84615, 2.22772, 5.28, 5.25641,
>
>     1.0514, 2.73256, 4.11111, 11.39098, 11.10236, 13.00781, 7.95259,
>
>     10.15748, 13.16327, 8.90625, 10.04587, 13.625, 6.27049, 9.27966,
>
>     10.94037, 5.80189, 7.76978, 7.34266, 3.80952, 3.75, 7.29545,
>
>     10.45872, 16.83206, 5.95238, 7.70833, 10.92391, 11.03659,
>
>     14.39338, 14.88281, 8.22917, 11.63603, 14.7561, 11.9469,
>
>     14.65649, 16.84615, 8.37209, 13.27982, 13.69128, 7.77778,
>
>     12.59124, 12.32955, 7.00472, 8.41121, 7.22222, 9.43878, 10.33613,
>
>     14.16667, 9.60526, 8.77232, 11.91589, 7.01786, 12.29592,
>
>     11.83673, 8.55634, 11.17347, 12.68836, 2.7551, 6, 7.21374,
>
>     2.52101, 4.03846, 4.80634, 5.49569, 4.78723, 6.02273, 3.04511,
>
>     3.59244, 2.48239, 1.54412, 5.74219, 7.68595, 1.33065, 2.625,
>
>     4.42164, 9.66942, 11.875, 17.91667, 10.81731, 13.05288, 16.23853,
>
>     11.93662, 14.31818, 14.09396, 7.82374, 15.5042, 10.86207,
>
>     6.87023, 11.69492, 12.65957, 3.48684, 5.29018, 7.89474, 10.53309,
>
>     17.05479, 16.63866, 7.43119, 12.06522, 12.05607, 6.14865,
>
>     10.44, 14.69512, 9.24757, 9.04018, 12.38255, 2.22222, 3.90756,
>
>     5.85616, 2.23958, 3.8125, 3.01056, 11.60256, 12.22222, 11.8007,
>
>     7.76316, 10.08197, 12.78777, 9.20455, 12.1875, 16.59449,
>
>     6.82331, 10.91518, 11.5748)), row.names = 192:381, class = 
> "data.frame")
>
>
>
>
>
>
>
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



--
John Kane
Kingston ON Canada

-------------- next part --------------
A non-text attachment was scrubbed...
Name: FIG 1 and FIG 2.pdf
Type: application/pdf
Size: 252813 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20190406/95b5c29b/attachment.pdf>

From murdoch@dunc@n @end|ng |rom gm@||@com  Sun Apr  7 17:56:25 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 7 Apr 2019 11:56:25 -0400
Subject: [R] Unable to read csv files with comma in values
In-Reply-To: <CAPf9UMoEpz4GDPJuDRO=ugSHybPreA3dwnpZD_AK2BbLbptV4w@mail.gmail.com>
References: <CAPf9UMoEpz4GDPJuDRO=ugSHybPreA3dwnpZD_AK2BbLbptV4w@mail.gmail.com>
Message-ID: <4f76546b-f376-cb75-80c3-14126d2dcfff@gmail.com>

On 06/04/2019 10:03 a.m., Amit Govil wrote:
> Hi,
> 
> I have a bunch of csv files to read in R. I'm unable to read them correctly
> because in some of the files, there is a column ("Role") which has comma in
> the values.
> 
> Sample data:
> 
> User, Role, Rule, GAPId
> Sam, [HadoopAnalyst, DBA, Developer], R46443
> 
> I'm trying to play with the below code but it doesnt work:

Since you didn't give a reproducible example, you should at least say 
what "doesn't work" means.

But here's some general advice:  if you want to debug code, don't write 
huge expressions like the chain of functions below, put things in 
temporary variables and make sure you get what you were expecting at 
each stage.

Instead of
> 
> files <- list.files(pattern='.*REDUNDANT(.*).csv$')
> 
> tbl <- sapply(files, function(f) {
>    gsub('\\[|\\]', '"', readLines(f)) %>%
>      read.csv(text = ., check.names = FALSE)
> }) %>%
>    bind_rows(.id = "id") %>%
>    select(id, User, Rule) %>%
>    distinct()

try


files <- list.files(pattern='.*REDUNDANT(.*).csv$')

tmp1 <- sapply(files, function(f) {
   gsub('\\[|\\]', '"', readLines(f)) %>%
     read.csv(text = ., check.names = FALSE)
})

tmp2 <- tmp1 %>% bind_rows(.id = "id")

tmp3 <- tmp2 %>% select(id, User, Rule)

tbl <- tmp3 %>% distinct()

(You don't need pipes here, but it will make it easier to put the giant 
expression back together at the end.)

Then look at tmp1, tmp2, tmp3 as well as tbl to see where things went 
wrong.

Duncan Murdoch


From bgunter@4567 @end|ng |rom gm@||@com  Sun Apr  7 18:55:54 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 7 Apr 2019 09:55:54 -0700
Subject: [R] Unable to read csv files with comma in values
In-Reply-To: <4f76546b-f376-cb75-80c3-14126d2dcfff@gmail.com>
References: <CAPf9UMoEpz4GDPJuDRO=ugSHybPreA3dwnpZD_AK2BbLbptV4w@mail.gmail.com>
 <4f76546b-f376-cb75-80c3-14126d2dcfff@gmail.com>
Message-ID: <CAGxFJbRfKdf76opwL2er=crJQxFxSvx9yE3K2edaLQK+1m9owg@mail.gmail.com>

(Note: This follows an earlier mistaken reply just to Duncan)

Multiple "amens!" to Duncan's comments...

However:

Here is a start at my interpretation of how to do what you want. Note first
that your "example" listed 4 fields in the line, but you showed only 3. I
modified your example for 3 text fields, only one of which has brackets
([...]) in it I assume. Here is a little example of how to use regex's to
replace the commas within the brackets by "-", which would presumably then
allow you to easily convert the text into a data frame e.g. using
textConnection() and read.csv. Obviously, if this is not what you meant,
read no further.

##Example
txt <-c("Sam, [HadoopAnalyst, DBA, Developer], R46443 ","Jan, DBA, R101",
        "Mary, [Stats, Designer, R], t14")

wh <- grep("\\[.+\\]",txt)  ## which records need to be modified?
fixup <- gsub(" *, *","-",sub(".+(\\[.+\\]).+","\\1",txt[wh])) ## bracketed
expressions, changing "," to "-"

## Unfortunately, the "replacement" argument in sub() is not vectorized, se
we need a loop:

for(i in wh) txt[wh[i]] <- sub("\\[.+\\]",fixup[i],txt[wh[i]]) ## replace
original bracketed text with fixed up bracketed text

> txt
[1] "Sam, [HadoopAnalyst-DBA-Developer], R46443 "
[2] "Jan, DBA, R101"
[3] "Mary, [HadoopAnalyst-DBA-Developer], t14"


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Apr 7, 2019 at 9:00 AM Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 06/04/2019 10:03 a.m., Amit Govil wrote:
> > Hi,
> >
> > I have a bunch of csv files to read in R. I'm unable to read them
> correctly
> > because in some of the files, there is a column ("Role") which has comma
> in
> > the values.
> >
> > Sample data:
> >
> > User, Role, Rule, GAPId
> > Sam, [HadoopAnalyst, DBA, Developer], R46443
> >
> > I'm trying to play with the below code but it doesnt work:
>
> Since you didn't give a reproducible example, you should at least say
> what "doesn't work" means.
>
> But here's some general advice:  if you want to debug code, don't write
> huge expressions like the chain of functions below, put things in
> temporary variables and make sure you get what you were expecting at
> each stage.
>
> Instead of
> >
> > files <- list.files(pattern='.*REDUNDANT(.*).csv$')
> >
> > tbl <- sapply(files, function(f) {
> >    gsub('\\[|\\]', '"', readLines(f)) %>%
> >      read.csv(text = ., check.names = FALSE)
> > }) %>%
> >    bind_rows(.id = "id") %>%
> >    select(id, User, Rule) %>%
> >    distinct()
>
> try
>
>
> files <- list.files(pattern='.*REDUNDANT(.*).csv$')
>
> tmp1 <- sapply(files, function(f) {
>    gsub('\\[|\\]', '"', readLines(f)) %>%
>      read.csv(text = ., check.names = FALSE)
> })
>
> tmp2 <- tmp1 %>% bind_rows(.id = "id")
>
> tmp3 <- tmp2 %>% select(id, User, Rule)
>
> tbl <- tmp3 %>% distinct()
>
> (You don't need pipes here, but it will make it easier to put the giant
> expression back together at the end.)
>
> Then look at tmp1, tmp2, tmp3 as well as tbl to see where things went
> wrong.
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sun Apr  7 19:35:06 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 7 Apr 2019 10:35:06 -0700
Subject: [R] Unable to read csv files with comma in values
In-Reply-To: <CAGxFJbRfKdf76opwL2er=crJQxFxSvx9yE3K2edaLQK+1m9owg@mail.gmail.com>
References: <CAPf9UMoEpz4GDPJuDRO=ugSHybPreA3dwnpZD_AK2BbLbptV4w@mail.gmail.com>
 <4f76546b-f376-cb75-80c3-14126d2dcfff@gmail.com>
 <CAGxFJbRfKdf76opwL2er=crJQxFxSvx9yE3K2edaLQK+1m9owg@mail.gmail.com>
Message-ID: <CAGxFJbRSYpWmh=zYkQ1kOe3tspMpL6-KkWE0xREjgKzEsJkAdw@mail.gmail.com>

... and here's another perhaps simpler, perhaps more efficient (??) way of
doing it using strsplit().Note that it uses the fixed field position, 2, of
the bracketed roles. Adjust as needed.

A better solution would be a regex that avoids the loops (here, the sapply)
altogether, but I don't know how to do this. Maybe someone cleverer will
offer such a solution.

txt <-c("Sam, [HadoopAnalyst, DBA, Developer], R46443 ","Jan, DBA, R101",
        "Mary, [Stats, Designer, R], t14")

wh <-  grep("\\[.+\\]", txt)
spl <-  strsplit(txt[wh], "\\[|\\]")
txt[wh] <-  sapply(spl, function(y)
   paste0(y[1], gsub(" *, *","-", y[2]), y[-(1:2)]))

> txt
[1] "Sam, HadoopAnalyst-DBA-Developer, R46443 "
[2] "Jan, DBA, R101"
[3] "Mary, Stats-Designer-R, t14"

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Apr 7, 2019 at 9:55 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> (Note: This follows an earlier mistaken reply just to Duncan)
>
> Multiple "amens!" to Duncan's comments...
>
> However:
>
> Here is a start at my interpretation of how to do what you want. Note
> first that your "example" listed 4 fields in the line, but you showed only
> 3. I modified your example for 3 text fields, only one of which has
> brackets ([...]) in it I assume. Here is a little example of how to use
> regex's to replace the commas within the brackets by "-", which would
> presumably then allow you to easily convert the text into a data frame e.g.
> using textConnection() and read.csv. Obviously, if this is not what you
> meant, read no further.
>
> ##Example
> txt <-c("Sam, [HadoopAnalyst, DBA, Developer], R46443 ","Jan, DBA, R101",
>         "Mary, [Stats, Designer, R], t14")
>
> wh <- grep("\\[.+\\]",txt)  ## which records need to be modified?
> fixup <- gsub(" *, *","-",sub(".+(\\[.+\\]).+","\\1",txt[wh])) ##
> bracketed expressions, changing "," to "-"
>
> ## Unfortunately, the "replacement" argument in sub() is not vectorized,
> se we need a loop:
>
> for(i in wh) txt[wh[i]] <- sub("\\[.+\\]",fixup[i],txt[wh[i]]) ## replace
> original bracketed text with fixed up bracketed text
>
> > txt
> [1] "Sam, [HadoopAnalyst-DBA-Developer], R46443 "
> [2] "Jan, DBA, R101"
> [3] "Mary, [HadoopAnalyst-DBA-Developer], t14"
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, Apr 7, 2019 at 9:00 AM Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
>> On 06/04/2019 10:03 a.m., Amit Govil wrote:
>> > Hi,
>> >
>> > I have a bunch of csv files to read in R. I'm unable to read them
>> correctly
>> > because in some of the files, there is a column ("Role") which has
>> comma in
>> > the values.
>> >
>> > Sample data:
>> >
>> > User, Role, Rule, GAPId
>> > Sam, [HadoopAnalyst, DBA, Developer], R46443
>> >
>> > I'm trying to play with the below code but it doesnt work:
>>
>> Since you didn't give a reproducible example, you should at least say
>> what "doesn't work" means.
>>
>> But here's some general advice:  if you want to debug code, don't write
>> huge expressions like the chain of functions below, put things in
>> temporary variables and make sure you get what you were expecting at
>> each stage.
>>
>> Instead of
>> >
>> > files <- list.files(pattern='.*REDUNDANT(.*).csv$')
>> >
>> > tbl <- sapply(files, function(f) {
>> >    gsub('\\[|\\]', '"', readLines(f)) %>%
>> >      read.csv(text = ., check.names = FALSE)
>> > }) %>%
>> >    bind_rows(.id = "id") %>%
>> >    select(id, User, Rule) %>%
>> >    distinct()
>>
>> try
>>
>>
>> files <- list.files(pattern='.*REDUNDANT(.*).csv$')
>>
>> tmp1 <- sapply(files, function(f) {
>>    gsub('\\[|\\]', '"', readLines(f)) %>%
>>      read.csv(text = ., check.names = FALSE)
>> })
>>
>> tmp2 <- tmp1 %>% bind_rows(.id = "id")
>>
>> tmp3 <- tmp2 %>% select(id, User, Rule)
>>
>> tbl <- tmp3 %>% distinct()
>>
>> (You don't need pipes here, but it will make it easier to put the giant
>> expression back together at the end.)
>>
>> Then look at tmp1, tmp2, tmp3 as well as tbl to see where things went
>> wrong.
>>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sun Apr  7 21:30:41 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 7 Apr 2019 12:30:41 -0700
Subject: [R] Unable to read csv files with comma in values
In-Reply-To: <CAGxFJbRSYpWmh=zYkQ1kOe3tspMpL6-KkWE0xREjgKzEsJkAdw@mail.gmail.com>
References: <CAPf9UMoEpz4GDPJuDRO=ugSHybPreA3dwnpZD_AK2BbLbptV4w@mail.gmail.com>
 <4f76546b-f376-cb75-80c3-14126d2dcfff@gmail.com>
 <CAGxFJbRfKdf76opwL2er=crJQxFxSvx9yE3K2edaLQK+1m9owg@mail.gmail.com>
 <CAGxFJbRSYpWmh=zYkQ1kOe3tspMpL6-KkWE0xREjgKzEsJkAdw@mail.gmail.com>
Message-ID: <CAGxFJbQc3Mj2TGpqymk+XvsqE0V+PesyVVAsXOTjVASnGqLGKw@mail.gmail.com>

... and if anyone cares, here's a way to do it using vectorization (no
loops) by working only on the subvector containing bracketed text  and
using the brackets to break up the strings into 3 separate pieces,
replacing the commas in the middle piece with dashes, and then
reassembling. Quite clumsy, so a better solution is still needed, but here
it is:

txt <-c("Sam, [HadoopAnalyst, DBA, Developer], R46443 ","Jan, DBA, R101",
        "Mary, [Stats, Designer, R], t14")
wh <- grep("\\[.+\\]",txt)
txt1 <- sub("(.+), *\\[.+","\\1",txt[wh]) ## before "["
txt2 <- gsub(" *, *","-",sub(".+(\\[.+\\]).+","\\1",txt[wh])) ## bracketed
part
txt3 <- sub(".*\\], *(.+?) *$","\\1",txt[wh]) ## after "]"
txt[wh]<- paste(txt1, txt2, txt3, sep = ", ")

> txt
[1] "Sam, [HadoopAnalyst-DBA-Developer], R46443"
[2] "Jan, DBA, R101"
[3] "Mary, [Stats-Designer-R], t14"


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Apr 7, 2019 at 10:35 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> ... and here's another perhaps simpler, perhaps more efficient (??) way of
> doing it using strsplit().Note that it uses the fixed field position, 2, of
> the bracketed roles. Adjust as needed.
>
> A better solution would be a regex that avoids the loops (here, the
> sapply) altogether, but I don't know how to do this. Maybe someone cleverer
> will offer such a solution.
>
> txt <-c("Sam, [HadoopAnalyst, DBA, Developer], R46443 ","Jan, DBA, R101",
>         "Mary, [Stats, Designer, R], t14")
>
> wh <-  grep("\\[.+\\]", txt)
> spl <-  strsplit(txt[wh], "\\[|\\]")
> txt[wh] <-  sapply(spl, function(y)
>    paste0(y[1], gsub(" *, *","-", y[2]), y[-(1:2)]))
>
> > txt
> [1] "Sam, HadoopAnalyst-DBA-Developer, R46443 "
> [2] "Jan, DBA, R101"
> [3] "Mary, Stats-Designer-R, t14"
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, Apr 7, 2019 at 9:55 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
>> (Note: This follows an earlier mistaken reply just to Duncan)
>>
>> Multiple "amens!" to Duncan's comments...
>>
>> However:
>>
>> Here is a start at my interpretation of how to do what you want. Note
>> first that your "example" listed 4 fields in the line, but you showed only
>> 3. I modified your example for 3 text fields, only one of which has
>> brackets ([...]) in it I assume. Here is a little example of how to use
>> regex's to replace the commas within the brackets by "-", which would
>> presumably then allow you to easily convert the text into a data frame e.g.
>> using textConnection() and read.csv. Obviously, if this is not what you
>> meant, read no further.
>>
>> ##Example
>> txt <-c("Sam, [HadoopAnalyst, DBA, Developer], R46443 ","Jan, DBA, R101",
>>         "Mary, [Stats, Designer, R], t14")
>>
>> wh <- grep("\\[.+\\]",txt)  ## which records need to be modified?
>> fixup <- gsub(" *, *","-",sub(".+(\\[.+\\]).+","\\1",txt[wh])) ##
>> bracketed expressions, changing "," to "-"
>>
>> ## Unfortunately, the "replacement" argument in sub() is not vectorized,
>> se we need a loop:
>>
>> for(i in wh) txt[wh[i]] <- sub("\\[.+\\]",fixup[i],txt[wh[i]]) ## replace
>> original bracketed text with fixed up bracketed text
>>
>> > txt
>> [1] "Sam, [HadoopAnalyst-DBA-Developer], R46443 "
>> [2] "Jan, DBA, R101"
>> [3] "Mary, [HadoopAnalyst-DBA-Developer], t14"
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sun, Apr 7, 2019 at 9:00 AM Duncan Murdoch <murdoch.duncan at gmail.com>
>> wrote:
>>
>>> On 06/04/2019 10:03 a.m., Amit Govil wrote:
>>> > Hi,
>>> >
>>> > I have a bunch of csv files to read in R. I'm unable to read them
>>> correctly
>>> > because in some of the files, there is a column ("Role") which has
>>> comma in
>>> > the values.
>>> >
>>> > Sample data:
>>> >
>>> > User, Role, Rule, GAPId
>>> > Sam, [HadoopAnalyst, DBA, Developer], R46443
>>> >
>>> > I'm trying to play with the below code but it doesnt work:
>>>
>>> Since you didn't give a reproducible example, you should at least say
>>> what "doesn't work" means.
>>>
>>> But here's some general advice:  if you want to debug code, don't write
>>> huge expressions like the chain of functions below, put things in
>>> temporary variables and make sure you get what you were expecting at
>>> each stage.
>>>
>>> Instead of
>>> >
>>> > files <- list.files(pattern='.*REDUNDANT(.*).csv$')
>>> >
>>> > tbl <- sapply(files, function(f) {
>>> >    gsub('\\[|\\]', '"', readLines(f)) %>%
>>> >      read.csv(text = ., check.names = FALSE)
>>> > }) %>%
>>> >    bind_rows(.id = "id") %>%
>>> >    select(id, User, Rule) %>%
>>> >    distinct()
>>>
>>> try
>>>
>>>
>>> files <- list.files(pattern='.*REDUNDANT(.*).csv$')
>>>
>>> tmp1 <- sapply(files, function(f) {
>>>    gsub('\\[|\\]', '"', readLines(f)) %>%
>>>      read.csv(text = ., check.names = FALSE)
>>> })
>>>
>>> tmp2 <- tmp1 %>% bind_rows(.id = "id")
>>>
>>> tmp3 <- tmp2 %>% select(id, User, Rule)
>>>
>>> tbl <- tmp3 %>% distinct()
>>>
>>> (You don't need pipes here, but it will make it easier to put the giant
>>> expression back together at the end.)
>>>
>>> Then look at tmp1, tmp2, tmp3 as well as tbl to see where things went
>>> wrong.
>>>
>>> Duncan Murdoch
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From e@@w|ek @end|ng |rom gm@||@com  Mon Apr  8 02:02:57 2019
From: e@@w|ek @end|ng |rom gm@||@com (Ek Esawi)
Date: Sun, 7 Apr 2019 20:02:57 -0400
Subject: [R] Alternative to loops
In-Reply-To: <CAGxFJbRPwPC5GGz7RqOoAstxZ512Z0PtQqkzMkgWSSJhOsttNw@mail.gmail.com>
References: <CA+ZkTxvY0_2OR7Ryccbo0-31J-HOUdb01y8OFY8M6asww90gKg@mail.gmail.com>
 <CAGxFJbRPwPC5GGz7RqOoAstxZ512Z0PtQqkzMkgWSSJhOsttNw@mail.gmail.com>
Message-ID: <CA+ZkTxvCtTHVhG5NBrn_TAj-62WXhM-gnvjLVjaXKwQ2pVHnmw@mail.gmail.com>

Thank you Bert. It did indeed work and i put it in one line as well.
The match(TRUE..) through me off a little on the beginning, but i
realized why it's there.
Thanks for your continuous comments on mine and many other posts.

EK

On Sat, Apr 6, 2019 at 5:07 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> I skipped pre-populating MyDF$C as unnecessary:
>
> > MyDF <- data.frame(A=c(1,2,3,4,5),B=c("aa ab ac","bb bc bd","cc cf","dd","ee"),
> + stringsAsFactors = FALSE)
>
> ## I think this does what you want:
>
> > choices<- sapply(MyDF$B, strsplit, split = " +")
> > nm <- names(MyList)
> > MyDF$C <- nm[sapply(choices, function(x)match(TRUE, sapply(MyList,function(tbl)any(x %in% tbl))))]
> > MyDF$C
> [1] "Y" "z" "X" NA  NA
>
> You could of course make this even more opaque by making it a one-liner. ;-)
>
> Cheers,
> Bert
>
>
>
> On Sat, Apr 6, 2019 at 10:45 AM Ek Esawi <esawiek at gmail.com> wrote:
>>
>> Thank you. Sorry i forgot to turn off the html
>>
>> Below is a sample of my data. My original data frame has over 10,000 rows.
>> I want to check each element on my data frame column B
>> (MyDF$B) to see if it contains any element(s) of MYList. if os, change
>> the value of MyDF$C to the name of the vector of the list that has
>> match(s).
>>
>> I solved this via loops and if statements, using &in&  but I am hoping for
>> a more compact solution using the apply family functions. I tried something like
>> this but did not work.
>>
>> lapply(strsplit(MyDF$B," "),function(x) lapply(MyList,function(y)  if(sum(y
>> %in% x)>0,x$Code==y[[1]]))
>>
>> Thanks in advance--EK
>>
>> Sample data
>> MyList <- list(X=c("a","ba","cc"),Y=c("abs","aa","BA","BB"),z=c("ab","bb","xy","zy","gh"))
>> MyDF <- data.frame(A=c(1,2,3,4,5),B=c("aa ab ac","bb bc bd","cc
>> cf","dd","ee"), C= c(0,0,0,0,0), stringsAsFactors = FALSE)
>>
>> > MyDF
>>
>>     A     B      C
>> 1 1 aa ab ac  0
>> 2 2 bb bc bd  0
>> 3 3    cc cf     0
>> 4 4       dd     0
>> 5 5       ee     0
>>
>> > MyList
>>
>> $X
>> [1] "a"  "ba" "cc"
>>
>> $Y
>> [1] "abs" "aa"  "BA"  "BB"
>>
>> $z
>> [1] "ab" "bb" "xy" "zy" "gh"
>>
>>
>> Desired results.
>>
>> > MyDF
>>
>>    A     B        C
>> 1 1 aa ab ac Y
>> 2 2 bb bc bd Y
>> 3 3    cc cf    X
>> 4 4       dd     0
>> 5 5       ee     0
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From @jebru|jn|k@ @end|ng |rom hotm@||@com  Mon Apr  8 12:41:56 2019
From: @jebru|jn|k@ @end|ng |rom hotm@||@com (Sanne Bruijniks)
Date: Mon, 8 Apr 2019 10:41:56 +0000
Subject: [R] Message for forum
In-Reply-To: <72D3C286-812B-450D-BA66-AF1316DDA755@hotmail.com>
References: <72D3C286-812B-450D-BA66-AF1316DDA755@hotmail.com>
Message-ID: <AM5PR0501MB2578574626392FE3EA8499DBCA2C0@AM5PR0501MB2578.eurprd05.prod.outlook.com>


Dear r-help,

Would it be possible to post the following message on the forum?

Best regards, Sanne Bruijniks


Subject: Error in unserialize(node$con) : error reading from connection while running Mobforest<https://stackoverflow.com/questions/55532353/error-in-unserializenodecon-error-reading-from-connection-while-running-mob>
Message:
Error in unserialize(node$con) : error reading from connection while running Mobforest<https://stackoverflow.com/questions/55532353/error-in-unserializenodecon-error-reading-from-connection-while-running-mob>

I am trying to run a mobforest code (mobforest.analysis, n= +-150, number of predictors=+- 30, ntree=10000mtry=10) on a 16-core external system (using surfsara). However, after 20 minutes I get the following error:

Error in unserialize(node$con) : error reading from connection

I already looked into other topics and websites, such as http://gforge.se/2015/02/how-to-go-parallel-in-r-basics-tips/ but I still have a problem knowing what the problem is, and, thus, how to solve it.

Does anybody know what goes wrong in my code?

Kind regards,

Sanne Bruijniks

	[[alternative HTML version deleted]]


From B|||@Po||ng @end|ng |rom ze||@@com  Mon Apr  8 13:19:12 2019
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Mon, 8 Apr 2019 11:19:12 +0000
Subject: [R] 
 Help with use RMarkdown and knitr in an rdm output to word.doc
In-Reply-To: <BN7PR02MB5073C33A8C17011CCDAA5DE1EA530@BN7PR02MB5073.namprd02.prod.outlook.com>
References: <BN7PR02MB50739C8385C0A8C912BBF1BFEA520@BN7PR02MB5073.namprd02.prod.outlook.com>
 <67DB3C8E-84B5-4C28-835B-5D4BFFDEB5BA@dcn.davis.ca.us>
 <BN7PR02MB5073C9AD60B344B0180E736CEA520@BN7PR02MB5073.namprd02.prod.outlook.com>
 <5A96F01B-E18C-4687-A265-DF94A6FBA450@dcn.davis.ca.us>
 <BN7PR02MB50733CC23D6BBEA96EEC2475EA520@BN7PR02MB5073.namprd02.prod.outlook.com>
 <1A6E7A13-1CCE-4085-9D1F-E6C120A55BEC@dcn.davis.ca.us>
 <BN7PR02MB5073967567A5940CDC6F414BEA530@BN7PR02MB5073.namprd02.prod.outlook.com>
 <76816F5B-6F4E-41C9-B37A-095B7240A13F@dcn.davis.ca.us>
 <BN7PR02MB5073C33A8C17011CCDAA5DE1EA530@BN7PR02MB5073.namprd02.prod.outlook.com>
Message-ID: <BN7PR02MB5073482AF1362B25D1731246EA2C0@BN7PR02MB5073.namprd02.prod.outlook.com>

Good morning Jeff.

It's not elegant, nuts actually, but it works.

A temporary solution to my time sensitive report while I work on my RMarkdown to Word.docx skills.

I run the routine in knit to HTML, save that to PDF, then convert PDF to the Word doc and go from there.

Thanks again for all your advice.

WHP

-----Original Message-----
From: Bill Poling
Sent: Sunday, April 7, 2019 11:17 AM
To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; r-help at r-project.org; r-help (r-help at r-project.org) <r-help at r-project.org>
Cc: Bill Poling <Bill.Poling at zelis.com>
Subject: RE: [R] Help with use RMarkdown and knitr in an rdm output to word.doc

Hi Jeff, yes guilty as charged, I do depend on copying snippets too much, then look for the documentation when it blows up.

I will heed your advice and review further the help page for the rmarkdown::word_document and the other resources as well.

Thanks again for taking the time Jeff I really have learned a lot from your assistance.

WHP


From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: Sunday, April 7, 2019 9:05 AM
To: Bill Poling <Bill.Poling at zelis.com>; r-help at r-project.org; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: RE: [R] Help with use RMarkdown and knitr in an rdm output to word.doc

The kable_styling function in your code does not appear in the example docx howto, so no, they are not the same.

Bill, at some point you have to stop depending on copying snippets from blogs and read the function documentation, especially the arguments and values sections. The docs for the kable_styling function specifically mention only HTML and LaTeX that I warned you about. It has to generate pure markdown to be converted to docx.

Also, you probably shouldn't use the results='asis' chunk setting in most cases for docx output.

For example, if you read the help page for the rmarkdown::word_document function you should find a keep_md argument. Rmarkdown uses the YAML to setup the call to this function so you can write

output:
word_document:
keep_md: yes

for the purpose of looking at the raw markdown after knitr is done processing chunks. Applied to your code with the kable_styling function, you should see an extra md output file as it looks just before being converted to docx, with a bunch of HTML code in the md file where that chunk used to be. This would be fine if the final destination was a web browser, but not for converting to word. If you remove that function then the md file should have a plain markdown table... you can tell because it is much simpler to read than the html in raw form is.

Note that markdown is intentionally simple... there is a lot that you cannot convey through it about appearance. You are shackling yourself to a lower standard of appearance by using it. I inevitably have to manually reformat the results if I share the file for further editing. If that is unacceptable for your case then consider using the officer package... but your finalfit package won't play well with that.

On April 7, 2019 3:07:53 AM PDT, Bill Poling <mailto:Bill.Poling at zelis.com> wrote:
>Thanks Jeff, yes well I have followed the Harrison tutorial and my
>chunks are the same as his examples which appear to work fine for him?
>I am stymied.
>
>#https://www.datasurg.net/2018/05/22/finalfit-knitr-and-r-markdown-for-quick-results/
>rg.net
>
>I will keep working on it though, many thanks.
>
>WHP
>
>
>
>
>From: Jeff Newmiller <mailto:jdnewmil at dcn.davis.ca.us>
>Sent: Saturday, April 6, 2019 6:51 PM
>To: Bill Poling <mailto:Bill.Poling at zelis.com>;
>mailto:r-help at r-project.org; r-help
>(mailto:r-help at r-project.org) <mailto:r-help at r-project.org>
>Subject: RE: [R] Help with use RMarkdown and knitr in an rdm output to
>word.doc
>
>Read the help files for the functions in each code block that are
>actually producing output that will be displayed. One of them is not
>compatible with docx file output.
>
>On April 6, 2019 2:44:55 PM PDT, Bill Poling
><mailto:Bill.Poling at zelis.com> wrote:
>>Thank you Jeff, I am so darn close, I solve one problem and another
>>emerges!
>>
>>However, I realized that back in July when I made my first and, up
>>until this weekend, only attempt at this I was following the original
>>url that was reposted by R-Bloggers that I mentioned in my original
>>post earlier.
>>#https://www.datasurg.net/2018/05/16/elegant-regression-results-tables-and-plots-the-finalfit-package/
>>urg.net
>>
>>Low and behold realized I had asked the author (Ewen Harrison with
>>DataSurg) these questions back then in the comments, UGH!
>>But since I ditched the idea in frustrationback then and I did not
>>follow-up I hadn't realized the author created a companion url for
>this
>>very topic, how to get from .Rmd to word/PDF etc..
>>
>>I located his companion reference url to the original.
>>
>>#https://www.datasurg.net/2018/05/22/finalfit-knitr-and-r-markdown-for-quick-results/
>>urg.net
>>
>>So following his further instructions I have made more progress,
>>however, as I mention above the final document remains elusive.
>>
>>SO I did some further googling and perused these sites as well
>>
>>#https://rmarkdown.rstudio.com/articles_docx.html
>>down.rstudio.com
>>#https://ourcodingclub.github.io/2016/11/24/rmarkdown-1.html
>>dingclub.github.io
>>
>>Between the companion url of Harrison and
>>https://rmarkdown.rstudio.com/articles_docx.html I have almost got it.
>>
>>---
>>title: "AutoDist Analysis"
>>author: "WHP"
>>date: "4/6/2018"
>>output:
>> word_document:
>> reference_docx: word-styles-reference-01.docx
>>
>>---
>>```{r setup, include=FALSE}
>># Load data into global environment.
>>library(finalfit)
>>library(dplyr)
>>library(knitr)
>>library(kableExtra)
>>load("C:/WHP/Revenue Development Products//BRA
>>AutoDistribution/Test1.rda")
>>```
>>
>>## Table 1 - Associations between Autodist Yes/No and other
>explanatory
>>variables
>>```{r table1, echo = FALSE, results='asis'} kable(table1,
>>row.names=FALSE, align=c("l", "l", "r", "r", "r", "r"),
>>booktabs=TRUE)
>>```
>>
>>## Table 2 - Logistic regression table ```{r table2, echo = FALSE,
>>results='asis'} kable(table2, row.names=FALSE, align=c("l", "l", "r",
>>"r", "r", "r"),
>>booktabs=TRUE) %>%
>>kable_styling(font_size=8)
>>```
>>
>>## Figure 1 - Odds Ratio Plot
>>```{r figure1, echo = FALSE, warning=FALSE, message=FALSE,
>>fig.width=10} tmp %>%  or_plot(dependent, explanatory)
>>
>>However, now the issue is:
>>"Error: Functions that produce HTML output found in document targeting
>>docx output.
>>Please change the output type of this document to HTML. Alternatively,
>>you can allow HTML output in non-HTML formats by adding this option to
>>the YAML front-matter of your rmarkdown file:
>> always_allow_html: yes
>>Note however that the HTML output will not be visible in non-HTML
>>formats.
>>Execution halted"
>>
>>This is confusing as heck, however, I tried adding that to the YAML
>but
>>I get the same error
>>---
>>title: "AutoDist Analysis"
>>author: "WHP"
>>date: "4/6/2018"
>>output:
>> word_document:
>> reference_docx: word-styles-reference-01.docx
>> always_allow_html: yes
>>---
>>
>>SO needless to say am really disappointed!
>>
>>Whole Saturday on this, sheesh!
>>
>>Thanks for listening
>>
>>WHP
>>
>>
>>From: Jeff Newmiller <mailto:jdnewmil at dcn.davis.ca.us>
>>Sent: Saturday, April 6, 2019 2:25 PM
>>To: Bill Poling <mailto:Bill.Poling at zelis.com>;
>mailto:r-help at r-project.org; r-help
>>(mailto:r-help at r-project.org) <mailto:r-help at r-project.org>
>>Subject: RE: [R] Help with use RMarkdown and knitr in an rdm output to
>>word.doc
>>
>>Maybe you need to format the data frame as markdown before it gets
>>displayed.
>>
>>tmp %>%
>>summary_factorlist(dependent, explanatory, p=TRUE,
>>add_dependent_label=TRUE) %>%
>>knitr::kable()
>>
>>You can also tune how the columns are formatted a bit with arguments
>to
>>the kable function.
>>
>>On April 6, 2019 10:58:53 AM PDT, Bill Poling
>><mailto:Bill.Poling at zelis.com> wrote:
>>>Hello Jeff,as always, thank you for your response.
>>>
>>>Yes .Rmd, and here I thought I was being so thorough about providing
>>as
>>>much detail as possible, my apologies.
>>>
>>>I have an open .Rmd file from the File ->New File menu in RStudio, so
>>I
>>>think that part is correct.
>>>
>>>My code is this.
>>>---
>>>title: "AutoDist Analysis"
>>>author: "WHP"
>>>date: "April 6, 2019"
>>>output:
>>> word_document: default
>>> ---
>>>
>>>```{r ElegantRegress, include = FALSE} knitr::opts_chunk$set(echo =
>>>FALSE) ``` ```{r global_options, include=FALSE}
>>>knitr::opts_chunk$set(echo=FALSE, warning=FALSE,
>>>message=FALSE,align=c("l", "l", "r", "r", "r", "r")) ```
>>>
>>>```{r message=FALSE,warning=FALSE}
>>>library(finalfit)
>>>library(dplyr)
>>>library(knitr)
>>>library(memisc)
>>>load("C:/WHP/Revenue Development Products//BRA
>>>AutoDistribution/Autodist RegTests V1.RData") setwd("C:/WHP/Revenue
>>>Development Products/BRA AutoDistribution") ```
>>>
>>>```{r echo=FALSE, results='asis'}
>>>explanatory = c("TBCat","ClaimType","drgcode2","typeofbillid2")
>>>dependent = "Autodist2"
>>>tmp %>% summary_factorlist(dependent, explanatory, p=TRUE,
>>>add_dependent_label=TRUE)
>>>```
>>>
>>>I do get a word.doc file output from the above code (attachment did
>>>not survive the communication as you mentioned) however, it is not in
>>>the format described in the tutorial.
>>>Here is the output I do get:
>>>
>>>AutoDist Analysis
>>>WHP
>>>
>>>April 6, 2019
>>>
>>>Dependent: Autodist2 No Yes p 5 TBCat 1 6257 (96.6) 222 (3.4) <0.001
>6
>>>2 5780 (89.1) 709 (10.9)
>>>7 3 5424 (83.9) 1042 (16.1)
>>>8 4 5324 (82.2) 1156 (17.8)
>>>9 5 5120 (79.0) 1360 (21.0)
>>>10 6 5158 (79.6) 1322 (20.4)
>>>11 7 5022 (77.5) 1459 (22.5)
>>>12 8 5081 (78.4) 1398 (21.6)
>>>13 9 4905 (75.7) 1575 (24.3)
>>>14 10 5011 (77.3) 1469 (22.7)
>>>1 ClaimType 1 48113 (80.6) 11566 (19.4) <0.001 2 2 4969 (97.1) 146
>>>(2.9)
>>>3 drgcode2 FALSE 41015 (80.8) 9734 (19.2) <0.001 4 TRUE 12067 (85.9)
>>>1978 (14.1)
>>>15 typeofbillid2 FALSE 4560 (90.3) 490 (9.7) <0.001 16 TRUE 48522
>>>(81.2) 11222 (18.8)
>>>
>>>I will revisit the links you provide once again.
>>>I have tried to find my problem solution in these earlier.
>>>Not surprisingly given the breadth and depth of information these
>>links
>>>provide I have probably overlooked something nuanced yet highly
>>>important to the formatting issue I am having.
>>>
>>>Once again thank you for your response Sir.
>>>
>>>WHP
>>>
>>>
>>>From: Jeff Newmiller <mailto:jdnewmil at dcn.davis.ca.us>
>>>Sent: Saturday, April 6, 2019 10:42 AM
>>>To: mailto:r-help at r-project.org; Bill Poling
>><mailto:Bill.Poling at zelis.com>; r-help
>>>(mailto:r-help at r-project.org) <mailto:r-help at r-project.org>
>>>Subject: Re: [R] Help with use RMarkdown and knitr in an rdm output
>to
>>>word.doc
>>>
>>>No surprise, the attachments did not come through. There are a
>limited
>>>few MIME types that are allowed, but most email programs don't let
>you
>>>have direct control over that, making embedding your entire
>>>reproducible plain-text example in the main body of the email the
>most
>>>sure path to successful communication on this mailing list.
>>>
>>>I did skim through what you wrote below, scratching my head over what
>>>"rdm" was, until it dawned on me that you might mean a file with an
>>>".Rmd" extension (are-mark-down) and that failing to use the correct
>>>extension might have something to do with your failure.
>>>
>>>Anyway, the topic on this mailing list is the R language, and
>>>contributed packages are (according to the Posting Guide) technically
>>>supposed to have support resources of their own [2] listed in their
>>>DESCRIPTION files [1]. I think the "how it works" discussion there
>>>could be useful in clarifying which other packages rmarkdown is using
>>>and which functions you might find useful documentation about. They
>>>also have a community forum over there I think.
>>>
>>>FWIW my own experience with rmarkdown has been that that most of its
>>>power comes from augmenting it with other packages, and those
>packages
>>>are often very specific to which final output format you are using.
>>The
>>>Word output format is much less extensively supported than HTML or
>PDF
>>>(via LaTeX) are. Don't fall into the trap of using HTML or LaTeX
>>>features when generating Word output.
>>>
>>>[1]
>>>https://cran.r-project.org/web/packages/rmarkdown/index.html.
>>>r-project.org [2]
>>>https://rmarkdown.rstudio.com
>>>down.rstudio.com
>>>
>>>On April 6, 2019 6:42:01 AM PDT, Bill Poling
>>><mailto:Bill.Poling at zelis.com> wrote:
>>>>Hello:
>>>>
>>>>#sessionInfo()
>>>>#R version 3.5.3 (2019-03-11)
>>>>#Platform: x86_64-w64-mingw32/x64 (64-bit) #Running under: Windows
>>>>>= 8 x64 (build 9200)
>>>>
>>>>#I have been struggling with learning how to use RMarkdown and knitr
>>>in
>>>>an rdm while following this tutorial using my own data.
>>>>#I Tried many months ago to self-teach but it drove me nuts,
>however,
>>>I
>>>>am now at a point where it is essential I get this figured out.
>>>>
>>>>#The tutorial
>>>>#https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/
>>>>loggers.com
>>>>
>>>>#I have googled and googled but cannot solve the problem of "how to
>>>get
>>>>my rdm output" word doc to look like the tutorial examples.
>>>>
>>>>#Many googles
>>>>#https://stackoverflow.com/questions/20060370/in-rstudio-is-there-a-way-to-specify-a-fig-path-for-all-figures-for-this-file
>>>>ckoverflow.com
>>>>#https://rstudio.github.io/distill/figures.html
>>>>udio.github.io
>>>>#https://kbroman.org/knitr_knutshell/pages/Rmarkdown.html
>>>>oman.org
>>>>
>>>>#And the list goes on. UGH!
>>>>
>>>>#I attach my rmd code and the word doc output, hopefully they get
>>>>through. Please let me know, and if not how I might improvise
>please.
>>>>
>>>>#Here is the basic procedure from the tutorial which runs fine into
>>>the
>>>>console, however, I am trying to output it with the suggested
>>>>formatting in the tutorial explanatory =
>>>>c("TBCat","ClaimType","drgcode2","typeofbillid2")
>>>>dependent = "Autodist2"
>>>>tmp %>%
>>>>summary_factorlist(dependent, explanatory, p=TRUE,
>>>>add_dependent_label=TRUE)
>>>>
>>>>#Here is a sample of my data.
>>>>
>>>>#I am sure there are also basic formatting inconsistencies or
>>>>redundancies in the rdm and would appreciate any advice or
>suggestion
>>>>for that as well, happy Saturday.
>>>>
>>>>sample <- tmp %>% slice(1:35)
>>>>> dput(sample)
>>>>structure(list(Autodist2 = structure(c(2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label =
>c("No",
>>>>"Yes"), class = "factor"), TBCat = structure(c(4L, 10L, 6L, 8L, 9L,
>>>>4L, 6L, 8L, 4L, 8L, 5L, 10L, 9L, 6L, 7L, 4L, 3L, 8L, 7L, 4L, 10L,
>>>>7L, 8L, 8L, 7L, 4L, 10L, 9L, 3L, 4L, 9L, 8L, 5L, 2L, 8L), .Label =
>>>>c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10"), class =
>>>>"factor"), RestictedPayorID = structure(c(2L, 2L, 1L, 1L, 1L, 1L,
>>>>1L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L,
>>>>1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 2L, 2L), .Label = c("FALSE",
>>>>"TRUE"), class = "factor"), ClaimType = structure(c(1L, 1L, 1L, 1L,
>>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label =
>>>>c("1", "2"), class = "factor"), ClaimStatus_Non_Acceptance =
>>>>structure(c(1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L,
>>>>2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 1L,
>>>>1L, 2L, 1L, 1L), .Label = c("0", "1"), class = "factor"),
>>ClaimStatus_Accepted
>>>>= structure(c(2L,
>>>>2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>>1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 2L),
>>>>.Label = c("0", "1"), class = "factor"), ClaimManagerID3 =
>>>>structure(c(2L, 1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 1L, 2L,
>>>>2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L,
>>>>2L, 2L, 2L, 1L), .Label = c("FALSE", "TRUE"), class = "factor"),
>>>>ClaimStatus_In_Process = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", "1"), class
>>>>= "factor"), Appeals2 = structure(c(2L, 2L, 1L, 2L, 1L, 1L, 1L, 1L,
>>>>1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L,
>>>>2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L), .Label = c("FALSE",
>>>>"TRUE"), class = "factor"), drgcode2 = structure(c(1L, 1L, 1L, 1L,
>>>>2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 2L, 1L, 1L,
>>>>2L, 2L, 1L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 2L, 1L, 1L), .Label =
>>>>c("FALSE", "TRUE"), class = "factor"), edi2 = structure(c(1L, 2L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,
>>>>1L, 1L, 2L, 2L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L),
>>>>.Label = c("FALSE", "TRUE"), class = "factor"),
>>typeofbillid2
>>>>= structure(c(2L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L),
>>>>.Label = c("FALSE", "TRUE"), class = "factor"),
>>>>ExternalNetworkID2 = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("FALSE", "TRUE"),
>>>>class = "factor"),
>>>>AdjustmentType2 = structure(c(2L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L),
>>>>.Label = c("FALSE", "TRUE"), class = "factor"),
>>>>CustomEOPLanguage2 = structure(c(2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L,
>>>>2L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("FALSE", "TRUE"),
>>>>class = "factor")), row.names
>=
>>>>c(NA,
>>>>-35L), class = "data.frame")
>>>>
>>>>
>>>>
>>>>Confidentiality Notice This message is sent from Zelis. This
>>>>transmission may contain information which is privileged and
>>>>confidential and is intended for the personal and confidential use
>of
>>>>the named recipient only. Such information may be protected by
>>>>applicable State and Federal laws from this disclosure or
>>unauthorized
>>>>use. If the reader of this message is not the intended recipient, or
>>>>the employee or agent responsible for delivering the message to the
>>>>intended recipient, you are hereby notified that any disclosure,
>>>>review, discussion, copying, or taking any action in reliance on the
>>>>contents of this transmission is strictly prohibited. If you have
>>>>received this transmission in error, please contact the sender
>>>>immediately. Zelis, 2018.
>>>>______________________________________________
>>>>mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>>see
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>.ethz.ch
>>>>PLEASE do read the posting guide
>>>>http://www.R-project.org/posting-guide.html
>>>>oject.org and provide commented, minimal, self-contained,
>>>>reproducible code.
>>>
>>>--
>>>Sent from my phone. Please excuse my brevity.
>>>
>>>Confidentiality Notice This message is sent from Zelis. This
>>>transmission may contain information which is privileged and
>>>confidential and is intended for the personal and confidential use of
>>>the named recipient only. Such information may be protected by
>>>applicable State and Federal laws from this disclosure or
>unauthorized
>>>use. If the reader of this message is not the intended recipient, or
>>>the employee or agent responsible for delivering the message to the
>>>intended recipient, you are hereby notified that any disclosure,
>>>review, discussion, copying, or taking any action in reliance on the
>>>contents of this transmission is strictly prohibited. If you have
>>>received this transmission in error, please contact the sender
>>>immediately. Zelis, 2018.
>>
>>--
>>Sent from my phone. Please excuse my brevity.
>>
>>Confidentiality Notice This message is sent from Zelis. This
>>transmission may contain information which is privileged and
>>confidential and is intended for the personal and confidential use of
>>the named recipient only. Such information may be protected by
>>applicable State and Federal laws from this disclosure or unauthorized
>>use. If the reader of this message is not the intended recipient, or
>>the employee or agent responsible for delivering the message to the
>>intended recipient, you are hereby notified that any disclosure,
>>review, discussion, copying, or taking any action in reliance on the
>>contents of this transmission is strictly prohibited. If you have
>>received this transmission in error, please contact the sender
>>immediately. Zelis, 2018.
>
>--
>Sent from my phone. Please excuse my brevity.
>--
>Sent from my phone. Please excuse my brevity.
>
>Confidentiality Notice This message is sent from Zelis. This
>transmission may contain information which is privileged and
>confidential and is intended for the personal and confidential use of
>the named recipient only. Such information may be protected by
>applicable State and Federal laws from this disclosure or unauthorized
>use. If the reader of this message is not the intended recipient, or
>the employee or agent responsible for delivering the message to the
>intended recipient, you are hereby notified that any disclosure,
>review, discussion, copying, or taking any action in reliance on the
>contents of this transmission is strictly prohibited. If you have
>received this transmission in error, please contact the sender
>immediately. Zelis, 2018.

--
Sent from my phone. Please excuse my brevity.

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

From r-p@ck@ge@ @end|ng |rom r-project@org  Fri Apr  5 13:51:57 2019
From: r-p@ck@ge@ @end|ng |rom r-project@org (Krzysztof Bartoszek via R-packages)
Date: Fri, 05 Apr 2019 11:51:57 +0000
Subject: [R] [R-pkgs] new R packages for phylogenetic compartive methods
Message-ID: <AsoSsBYvyQ3-whlaUhLe6ss2y4wN83_AbvZlytyiScQLUqcyMgHh60TmpsQnpJ7_FNLRU-6BdHFFA3pmKh5m6Hs4kYWCte3dks7mLO53lDw=@protonmail.ch>

Dear all,
I wanted to let you know about four phylogenetic comparative methods (PCM) packages that have become available on (3 on CRAN and 1 on GitHub) recently that hopefully will be interesting to somebody. Three of them go significantly beyond the Brownian motion (BM) and Ornstein-Uhlenbeck (OU) processes.

1) There is a new version of mvSLOUCH available. The most important change is that
the inference engine has been completely rewritten. Instead of directly evaluating the multivariate normal density formula it uses the PCMBase (R package, see below) to obtain the value of the likelihood in linear (in number of tip species) instead of quadratic time. Furthermore, as there is no need to store the between-species-between-traits variance covariance matrix much larger clades, then previously can be handled. From the user's perspective the main changes are the interface and increased functionality:
a) the phylogeny has to be now in the phylo (instead of ouch) format,
b) the trait data has to be a matrix (and not a data frame),
c) the package can automatically compare multiple models (BM, OUOU, OUBM and different assumed structures on the drift and diffusion matrices of the multivariate OU procees), function  estimate.evolutionary.model(), and return the one with the lowest AICc (the set of models to consider can either be automatically generated or user defined, see generate.model.setups()),
d) the user can set entries of the OU model's parameters to desired values (e.g. 0) and this will be fixed through the whole estimation,
e) a number of control parameters to be passed to the estimation procedure and optim() are available for the user to manipulate

2) PCMFit: the goal of PCMFit is to provide a generic tool for inference and selection of phylogenetic comparative models (PCMs). Currently, the package implements Gaussian and mixed Gaussian phylogenetic models (MGPM) over all tree types (including non-ultrametric and polytomic trees). The package supports non-existing traits or missing measurements for some of the traits on some of the species. The package supports specifying measurement error associated with each tip of the tree or inferring a measurement error parameter for a group of tips. The Gaussian phylogenetic models include various parametrizations of Brownian motion (BM) and Ornstein-Uhlenbeck (OU) multivariate branching processes. The mixed Gaussian models represent models with shifts in the model parameters as well as the type of model at points of the tree. Each shift-point is described as a pair of a shift-node and associated type of model (e.g. OU or BM) driving the trait evolution from the beginning of the branch le
 ading to the shift-node toward the shift-node and its descendants until reaching a tip or another shift-point. The function PCMFit is used to fit a given PCM or a MGPM for a given tree with specified shift-points. The function PCMFitMixed is used to fit an ensemble of possible MGPMs over a tree for which the shift-points are unknown. This function can perform model selection of the best MGPM for a given tree and data according to an information loss function such as the Akaike information criterion (AIC). The package has been thoroughly tested and applied to real data in the related research article entitled "Automatic Generation of Evolutionary Hypotheses using Mixed Gaussian Phylogenetic Models" (currently in review). Currently, the package is available from https://github.com/venelin/PCMFit . The web-page https://venelin.github.io/PCMFit/ provides access to documentation and related resources.

3) PCMBase: the computational engine that mvSLOUCH uses. Given a phylogeny (phylo format), traits' (multivariate) measurements and a user provided model of the traits' evolution the package calculates the likelihood. The family of allowed models is rather general. The package can handle any model for which lineages after speciation do not interact and the density of the transition along a branch is:
i) Gaussian
ii) the mean at the end of the branch depends linearly on the trait value at the start of the branch
iii) the covariance matrix does not depend on the value at the start of the branch
The likelihood is calculated in linear in number of tip species time.
The package is described in
Venelin Mitov, Krzysztof Bartoszek, Georgios Asimomitis, Tanja Stadler (2018).
Fast likelihood evaluation for multivariate phylogenetic comparative methods: the PCMBase R package
arXiv URL https://arxiv.org/abs/1809.09014 .

3) pcmabc: a package that allows for simulation and ABC estimation under any model for which the user can provide a function to simulate trait (discrete/continuous, uni- or multivariate) evolution along a branch. Special support is given for SDE based models, using the yuima package.
Krzysztof Bartoszek, Pietro Lio' (2019) Modelling trait dependent speciation with Approximate Bayesian Computation. Acta Physica Polonica B Proceedings Supplement 12(1): 25-47.
URL https://www.actaphys.uj.edu.pl/fulltext?series=Sup&vol=12&page=25 .

Hope somebody will find these useful

Best wishes
Krzysztof Bartoszek

Sent with ProtonMail Secure Email.
	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From jwd @end|ng |rom @urewe@t@net  Mon Apr  8 19:48:25 2019
From: jwd @end|ng |rom @urewe@t@net (John)
Date: Mon, 8 Apr 2019 10:48:25 -0700
Subject: [R] 
 Help with use RMarkdown and knitr in an rdm output to word.doc
In-Reply-To: <BN7PR02MB5073482AF1362B25D1731246EA2C0@BN7PR02MB5073.namprd02.prod.outlook.com>
References: <BN7PR02MB50739C8385C0A8C912BBF1BFEA520@BN7PR02MB5073.namprd02.prod.outlook.com>
 <67DB3C8E-84B5-4C28-835B-5D4BFFDEB5BA@dcn.davis.ca.us>
 <BN7PR02MB5073C9AD60B344B0180E736CEA520@BN7PR02MB5073.namprd02.prod.outlook.com>
 <5A96F01B-E18C-4687-A265-DF94A6FBA450@dcn.davis.ca.us>
 <BN7PR02MB50733CC23D6BBEA96EEC2475EA520@BN7PR02MB5073.namprd02.prod.outlook.com>
 <1A6E7A13-1CCE-4085-9D1F-E6C120A55BEC@dcn.davis.ca.us>
 <BN7PR02MB5073967567A5940CDC6F414BEA530@BN7PR02MB5073.namprd02.prod.outlook.com>
 <76816F5B-6F4E-41C9-B37A-095B7240A13F@dcn.davis.ca.us>
 <BN7PR02MB5073C33A8C17011CCDAA5DE1EA530@BN7PR02MB5073.namprd02.prod.outlook.com>
 <BN7PR02MB5073482AF1362B25D1731246EA2C0@BN7PR02MB5073.namprd02.prod.outlook.com>
Message-ID: <20190408104825.6ef5fcad@Draco.localdomain>

On Mon, 8 Apr 2019 11:19:12 +0000
Bill Poling <Bill.Poling at zelis.com> wrote:

One solution to your problem may be to use an environment like
RStudio.  You can maintain multiple open documents including an rmd
document and using knitr and rmarkdown, add and then run code snippets
the output of which becomes embedded in the generated Word document.  I
use this approach, but the default Word styles are a nuisance and not
suitable for draft reports.  So, following generation of the Word
document you will need to reformat the document.  This works in both
Windows and Linux (where you need Libreoffice installed).

JWDougherty


From ko@t@@zogo @end|ng |rom gm@||@com  Mon Apr  8 17:41:16 2019
From: ko@t@@zogo @end|ng |rom gm@||@com (kostas zogopoulos)
Date: Mon, 8 Apr 2019 18:41:16 +0300
Subject: [R] Greek characters in R studio
Message-ID: <CAHhMU0MF5DJA89mNdnV7=gdAHV-Y83FqMhKDB1FEmYMT1pdbgg@mail.gmail.com>

How do you read a csv file that contains greek characters as part of the
header (i.e. ?, ? etc) in R studio?
 Thanks in advance!

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Tue Apr  9 11:17:33 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Tue, 9 Apr 2019 12:17:33 +0300
Subject: [R] Greek characters in R studio
In-Reply-To: <CAHhMU0MF5DJA89mNdnV7=gdAHV-Y83FqMhKDB1FEmYMT1pdbgg@mail.gmail.com>
References: <CAHhMU0MF5DJA89mNdnV7=gdAHV-Y83FqMhKDB1FEmYMT1pdbgg@mail.gmail.com>
Message-ID: <20190409121733.16dffb2f@Tarkus>

On Mon, 8 Apr 2019 18:41:16 +0300
kostas zogopoulos <kostaszogo at gmail.com> wrote:

> How do you read a csv file that contains greek characters as part of
> the header (i.e. ?, ? etc) in R studio?

Determine the character encoding used in the file (is it UTF-8,
ISO8859-7 or something else?) and pass it as fileEncoding="..."
parameter to read.csv() function.

-- 
Best regards,
Ivan


From bie@ve@idozom@ m@iii@g oii gm@ii@com  Tue Apr  9 13:15:52 2019
From: bie@ve@idozom@ m@iii@g oii gm@ii@com (bie@ve@idozom@ m@iii@g oii gm@ii@com)
Date: Tue, 9 Apr 2019 11:15:52 +0000 (UTC)
Subject: [R] Convert a character to numeric
References: <1735781849.463532.1554808552609.ref@mail.yahoo.com>
Message-ID: <1735781849.463532.1554808552609@mail.yahoo.com>

Hi,?

I am applyin function as.numeric to a vector having many values as NA?
and it is giving :?
Warning message:?
NAs introduced by coercion?

Can anyone help me to know how to remove this warning and sor it out??

Thanks?
Bienvenue
	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Tue Apr  9 13:30:23 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 9 Apr 2019 21:30:23 +1000
Subject: [R] Convert a character to numeric
In-Reply-To: <1735781849.463532.1554808552609@mail.yahoo.com>
References: <1735781849.463532.1554808552609.ref@mail.yahoo.com>
 <1735781849.463532.1554808552609@mail.yahoo.com>
Message-ID: <CA+8X3fWgBohLs+=7HTeC2gtfjoAz9OZJ=HrZv_em+fbvkBtmjQ@mail.gmail.com>

Hi Bienvenue,
Perhaps you should ask whether you really want to "sort it out". The
warning is telling you that you are converting the NA values to NA in
the returned numeric vector. I can't think of anything more sensible
to do with NA values. You may also have character strings that cannot
be converted into numbers, which will also generate NA values. Maybe a
little example will help us to understand:

charstr<-c("5","foot","2",NA,"eyes","of","blue")
as.numeric(charstr)
[1]  5 NA  2 NA NA NA NA

Jim

On Tue, Apr 9, 2019 at 9:16 PM bienvenidozoma at gmail.com
<bienvenidozoma at gmail.com> wrote:
>
> Hi,
>
> I am applyin function as.numeric to a vector having many values as NA
> and it is giving :
> Warning message:
> NAs introduced by coercion
>
> Can anyone help me to know how to remove this warning and sor it out?
>
> Thanks
> Bienvenue
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From coder634 @end|ng |rom gm@||@com  Tue Apr  9 13:32:52 2019
From: coder634 @end|ng |rom gm@||@com (Coder 634)
Date: Tue, 9 Apr 2019 12:32:52 +0100
Subject: [R] How can I solve this prediction problem?
Message-ID: <CALs29e-ivnqAhY2rX3CUNN6+j3-CSHB47Up8HO+AdySPRGyH8A@mail.gmail.com>

Hi, I'm new at R programming and I need help to solve this problem.


The objective is to predict the change of the value of the Close variable:
D(t) =Close(t) ? Close(t-1) for a given day t, using the known data until
t-1 to generate the prediction model.

We can use univariate and multivariate models of temporal series as well as
machine Learning/data mining.

All the data are available in the cotton2.csv (future prices of cotton) .

Date ? day of the values

Open ? value at market opening

High ? highest value from that day

Low ? lowest value from that day

Close ? value at market closing time

Volume ? total number of exchanges made (sale/trade) of cotton during that
day

Prices are in indian rupees (INR) for every cotton bale.

The many numerical variables can be assumed to be daily temporal series.

Cotton2.csv
<https://drive.google.com/file/d/1kksxDVqraLxMkJ4PcvHsZUfUx0imDne4/view?usp=sharing>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Apr  9 15:02:07 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 9 Apr 2019 09:02:07 -0400
Subject: [R] Convert a character to numeric
In-Reply-To: <CA+8X3fWgBohLs+=7HTeC2gtfjoAz9OZJ=HrZv_em+fbvkBtmjQ@mail.gmail.com>
References: <1735781849.463532.1554808552609.ref@mail.yahoo.com>
 <1735781849.463532.1554808552609@mail.yahoo.com>
 <CA+8X3fWgBohLs+=7HTeC2gtfjoAz9OZJ=HrZv_em+fbvkBtmjQ@mail.gmail.com>
Message-ID: <15d43114-5d33-06ae-a711-1b2a5f6753b3@gmail.com>

On 09/04/2019 7:30 a.m., Jim Lemon wrote:
> Hi Bienvenue,
> Perhaps you should ask whether you really want to "sort it out". The
> warning is telling you that you are converting the NA values to NA in
> the returned numeric vector.

I don't think that's what it is saying.  I think it is saying that a 
non-NA value is being converted to NA, because R can't figure out what 
number it is.  For example,

 > as.numeric(c("1", NA))
[1]  1 NA
 > as.numeric(c("1", NA, "one"))
[1]  1 NA NA
Warning message:
NAs introduced by coercion


  I can't think of anything more sensible
> to do with NA values. You may also have character strings that cannot
> be converted into numbers, which will also generate NA values.

I think that's the only way that message will appear.

Duncan Murdoch

  Maybe a
> little example will help us to understand:
> 
> charstr<-c("5","foot","2",NA,"eyes","of","blue")
> as.numeric(charstr)
> [1]  5 NA  2 NA NA NA NA
> 
> Jim
> 
> On Tue, Apr 9, 2019 at 9:16 PM bienvenidozoma at gmail.com
> <bienvenidozoma at gmail.com> wrote:
>>
>> Hi,
>>
>> I am applyin function as.numeric to a vector having many values as NA
>> and it is giving :
>> Warning message:
>> NAs introduced by coercion
>>
>> Can anyone help me to know how to remove this warning and sor it out?
>>
>> Thanks
>> Bienvenue
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bie@ve@idozom@ m@iii@g oii gm@ii@com  Tue Apr  9 15:07:39 2019
From: bie@ve@idozom@ m@iii@g oii gm@ii@com (bie@ve@idozom@ m@iii@g oii gm@ii@com)
Date: Tue, 9 Apr 2019 13:07:39 +0000 (UTC)
Subject: [R] Create a sequence
References: <1911031910.593229.1554815259473.ref@mail.yahoo.com>
Message-ID: <1911031910.593229.1554815259473@mail.yahoo.com>

how to create
u = (1, ?1, 2, ?2, . . . , 100, ?100)? in r

Thanks
Bienvenue
	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @end|ng |rom me@com  Tue Apr  9 15:20:48 2019
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Tue, 9 Apr 2019 09:20:48 -0400
Subject: [R] Create a sequence
In-Reply-To: <1911031910.593229.1554815259473@mail.yahoo.com>
References: <1911031910.593229.1554815259473.ref@mail.yahoo.com>
 <1911031910.593229.1554815259473@mail.yahoo.com>
Message-ID: <4C2FFCDC-36A6-4547-B41E-ACAF9276308F@me.com>



> On Apr 9, 2019, at 9:07 AM, bienvenidozoma at gmail.com wrote:
> 
> how to create
> u = (1, ?1, 2, ?2, . . . , 100, ?100)  in r
> 
> Thanks
> Bienvenue

Hi,

See ?seq and ?rep

> rep(seq(100), each = 2) * c(1, -1)
  [1]    1   -1    2   -2    3   -3    4   -4    5   -5    6   -6    7
 [14]   -7    8   -8    9   -9   10  -10   11  -11   12  -12   13  -13
 [27]   14  -14   15  -15   16  -16   17  -17   18  -18   19  -19   20
 [40]  -20   21  -21   22  -22   23  -23   24  -24   25  -25   26  -26
 [53]   27  -27   28  -28   29  -29   30  -30   31  -31   32  -32   33
 [66]  -33   34  -34   35  -35   36  -36   37  -37   38  -38   39  -39
 [79]   40  -40   41  -41   42  -42   43  -43   44  -44   45  -45   46
 [92]  -46   47  -47   48  -48   49  -49   50  -50   51  -51   52  -52
[105]   53  -53   54  -54   55  -55   56  -56   57  -57   58  -58   59
[118]  -59   60  -60   61  -61   62  -62   63  -63   64  -64   65  -65
[131]   66  -66   67  -67   68  -68   69  -69   70  -70   71  -71   72
[144]  -72   73  -73   74  -74   75  -75   76  -76   77  -77   78  -78
[157]   79  -79   80  -80   81  -81   82  -82   83  -83   84  -84   85
[170]  -85   86  -86   87  -87   88  -88   89  -89   90  -90   91  -91
[183]   92  -92   93  -93   94  -94   95  -95   96  -96   97  -97   98
[196]  -98   99  -99  100 -100


Regards,

Marc Schwartz


From @||redo@corte||@n|co|@u @end|ng |rom gm@||@com  Tue Apr  9 16:35:35 2019
From: @||redo@corte||@n|co|@u @end|ng |rom gm@||@com (Alfredo Cortell)
Date: Tue, 9 Apr 2019 16:35:35 +0200
Subject: [R] Convert a character to numeric
In-Reply-To: <15d43114-5d33-06ae-a711-1b2a5f6753b3@gmail.com>
References: <1735781849.463532.1554808552609.ref@mail.yahoo.com>
 <1735781849.463532.1554808552609@mail.yahoo.com>
 <CA+8X3fWgBohLs+=7HTeC2gtfjoAz9OZJ=HrZv_em+fbvkBtmjQ@mail.gmail.com>
 <15d43114-5d33-06ae-a711-1b2a5f6753b3@gmail.com>
Message-ID: <CAPxhGmjG=wjYwnABo1H9S4E6pZ7eTmgBPoRJGKJUHGMYv_8CZw@mail.gmail.com>

Hi Bienvenue,

I believe that your problem is that R can't translate "one" to a number,
because it is not a number. R could translate to numeric for example this
vector, where numbers are expressed as strings,

c("1","4","7")

but "one" is just letters put together, therefore R can't understand their
meaning, and returns NA.

I believe that your best shot is to go with gsub, so that you translate
your "string letters" to "string numbers", and then you can do as.numeric
no problem

Try this

vec<-c("1",NA,"one")
num_vec<-gsub("one",1,vec)
num_vec<-as.numeric(num_vec)

Good luck,

Alfredo


El mar., 9 abr. 2019 a las 15:07, Duncan Murdoch (<murdoch.duncan at gmail.com>)
escribi?:

> On 09/04/2019 7:30 a.m., Jim Lemon wrote:
> > Hi Bienvenue,
> > Perhaps you should ask whether you really want to "sort it out". The
> > warning is telling you that you are converting the NA values to NA in
> > the returned numeric vector.
>
> I don't think that's what it is saying.  I think it is saying that a
> non-NA value is being converted to NA, because R can't figure out what
> number it is.  For example,
>
>  > as.numeric(c("1", NA))
> [1]  1 NA
>  > as.numeric(c("1", NA, "one"))
> [1]  1 NA NA
> Warning message:
> NAs introduced by coercion
>
>
>   I can't think of anything more sensible
> > to do with NA values. You may also have character strings that cannot
> > be converted into numbers, which will also generate NA values.
>
> I think that's the only way that message will appear.
>
> Duncan Murdoch
>
>   Maybe a
> > little example will help us to understand:
> >
> > charstr<-c("5","foot","2",NA,"eyes","of","blue")
> > as.numeric(charstr)
> > [1]  5 NA  2 NA NA NA NA
> >
> > Jim
> >
> > On Tue, Apr 9, 2019 at 9:16 PM bienvenidozoma at gmail.com
> > <bienvenidozoma at gmail.com> wrote:
> >>
> >> Hi,
> >>
> >> I am applyin function as.numeric to a vector having many values as NA
> >> and it is giving :
> >> Warning message:
> >> NAs introduced by coercion
> >>
> >> Can anyone help me to know how to remove this warning and sor it out?
> >>
> >> Thanks
> >> Bienvenue
> >>          [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Tue Apr  9 16:39:38 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 9 Apr 2019 07:39:38 -0700
Subject: [R] How can I solve this prediction problem?
In-Reply-To: <CALs29e-ivnqAhY2rX3CUNN6+j3-CSHB47Up8HO+AdySPRGyH8A@mail.gmail.com>
References: <CALs29e-ivnqAhY2rX3CUNN6+j3-CSHB47Up8HO+AdySPRGyH8A@mail.gmail.com>
Message-ID: <CAGxFJbT9uGobmaV4jPsA5kA9Kdkm2c1y156Dcqz6Gz4VKvOgOQ@mail.gmail.com>

This looks like homework, and there is a no homework policy on this list.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 9, 2019 at 5:51 AM Coder 634 <coder634 at gmail.com> wrote:

> Hi, I'm new at R programming and I need help to solve this problem.
>
>
> The objective is to predict the change of the value of the Close variable:
> D(t) =Close(t) ? Close(t-1) for a given day t, using the known data until
> t-1 to generate the prediction model.
>
> We can use univariate and multivariate models of temporal series as well as
> machine Learning/data mining.
>
> All the data are available in the cotton2.csv (future prices of cotton) .
>
> Date ? day of the values
>
> Open ? value at market opening
>
> High ? highest value from that day
>
> Low ? lowest value from that day
>
> Close ? value at market closing time
>
> Volume ? total number of exchanges made (sale/trade) of cotton during that
> day
>
> Prices are in indian rupees (INR) for every cotton bale.
>
> The many numerical variables can be assumed to be daily temporal series.
>
> Cotton2.csv
> <
> https://drive.google.com/file/d/1kksxDVqraLxMkJ4PcvHsZUfUx0imDne4/view?usp=sharing
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rmh @end|ng |rom temp|e@edu  Tue Apr  9 17:02:59 2019
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Tue, 9 Apr 2019 11:02:59 -0400
Subject: [R] Convert a character to numeric
In-Reply-To: <CAPxhGmjG=wjYwnABo1H9S4E6pZ7eTmgBPoRJGKJUHGMYv_8CZw@mail.gmail.com>
References: <1735781849.463532.1554808552609.ref@mail.yahoo.com>
 <1735781849.463532.1554808552609@mail.yahoo.com>
 <CA+8X3fWgBohLs+=7HTeC2gtfjoAz9OZJ=HrZv_em+fbvkBtmjQ@mail.gmail.com>
 <15d43114-5d33-06ae-a711-1b2a5f6753b3@gmail.com>
 <CAPxhGmjG=wjYwnABo1H9S4E6pZ7eTmgBPoRJGKJUHGMYv_8CZw@mail.gmail.com>
Message-ID: <CAGx1TMASmBfkneM2BnyjVyePtXG8hxioJvyy4HRZSHK3Phd1mA@mail.gmail.com>

My guess is that numbers formatted with commas are causing an unwanted coercion.
Remove the commas with gsub before converting to numeric.

> as.numeric(NA)
[1] NA
> as.numeric("1,234,567")
[1] NA
Warning message:
NAs introduced by coercion
> as.numeric(gsub(",", "", "1,234,567"))
[1] 1234567
>

On Tue, Apr 9, 2019 at 10:36 AM Alfredo Cortell
<alfredo.cortell.nicolau at gmail.com> wrote:
>
> Hi Bienvenue,
>
> I believe that your problem is that R can't translate "one" to a number,
> because it is not a number. R could translate to numeric for example this
> vector, where numbers are expressed as strings,
>
> c("1","4","7")
>
> but "one" is just letters put together, therefore R can't understand their
> meaning, and returns NA.
>
> I believe that your best shot is to go with gsub, so that you translate
> your "string letters" to "string numbers", and then you can do as.numeric
> no problem
>
> Try this
>
> vec<-c("1",NA,"one")
> num_vec<-gsub("one",1,vec)
> num_vec<-as.numeric(num_vec)
>
> Good luck,
>
> Alfredo
>
>
> El mar., 9 abr. 2019 a las 15:07, Duncan Murdoch (<murdoch.duncan at gmail.com>)
> escribi?:
>
> > On 09/04/2019 7:30 a.m., Jim Lemon wrote:
> > > Hi Bienvenue,
> > > Perhaps you should ask whether you really want to "sort it out". The
> > > warning is telling you that you are converting the NA values to NA in
> > > the returned numeric vector.
> >
> > I don't think that's what it is saying.  I think it is saying that a
> > non-NA value is being converted to NA, because R can't figure out what
> > number it is.  For example,
> >
> >  > as.numeric(c("1", NA))
> > [1]  1 NA
> >  > as.numeric(c("1", NA, "one"))
> > [1]  1 NA NA
> > Warning message:
> > NAs introduced by coercion
> >
> >
> >   I can't think of anything more sensible
> > > to do with NA values. You may also have character strings that cannot
> > > be converted into numbers, which will also generate NA values.
> >
> > I think that's the only way that message will appear.
> >
> > Duncan Murdoch
> >
> >   Maybe a
> > > little example will help us to understand:
> > >
> > > charstr<-c("5","foot","2",NA,"eyes","of","blue")
> > > as.numeric(charstr)
> > > [1]  5 NA  2 NA NA NA NA
> > >
> > > Jim
> > >
> > > On Tue, Apr 9, 2019 at 9:16 PM bienvenidozoma at gmail.com
> > > <bienvenidozoma at gmail.com> wrote:
> > >>
> > >> Hi,
> > >>
> > >> I am applyin function as.numeric to a vector having many values as NA
> > >> and it is giving :
> > >> Warning message:
> > >> NAs introduced by coercion
> > >>
> > >> Can anyone help me to know how to remove this warning and sor it out?
> > >>
> > >> Thanks
> > >> Bienvenue
> > >>          [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bor|@@@te|pe @end|ng |rom utoronto@c@  Tue Apr  9 17:53:26 2019
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Tue, 9 Apr 2019 15:53:26 +0000
Subject: [R] Convert a character to numeric
In-Reply-To: <CAGx1TMASmBfkneM2BnyjVyePtXG8hxioJvyy4HRZSHK3Phd1mA@mail.gmail.com>
References: <1735781849.463532.1554808552609.ref@mail.yahoo.com>
 <1735781849.463532.1554808552609@mail.yahoo.com>
 <CA+8X3fWgBohLs+=7HTeC2gtfjoAz9OZJ=HrZv_em+fbvkBtmjQ@mail.gmail.com>
 <15d43114-5d33-06ae-a711-1b2a5f6753b3@gmail.com>
 <CAPxhGmjG=wjYwnABo1H9S4E6pZ7eTmgBPoRJGKJUHGMYv_8CZw@mail.gmail.com>
 <CAGx1TMASmBfkneM2BnyjVyePtXG8hxioJvyy4HRZSHK3Phd1mA@mail.gmail.com>
Message-ID: <9BEF9671-AF34-4E0B-AF40-28C56BD5EC05@utoronto.ca>

As there are many possible sources of the warning, to "sort it out" try something like

  which( is.na(<converted-vector>) & (! is.na(<original-vector>)))


B.



> On 2019-04-09, at 11:02, Richard M. Heiberger <rmh at temple.edu> wrote:
> 
> My guess is that numbers formatted with commas are causing an unwanted coercion.
> Remove the commas with gsub before converting to numeric.
> 
>> as.numeric(NA)
> [1] NA
>> as.numeric("1,234,567")
> [1] NA
> Warning message:
> NAs introduced by coercion
>> as.numeric(gsub(",", "", "1,234,567"))
> [1] 1234567
>> 
> 
> On Tue, Apr 9, 2019 at 10:36 AM Alfredo Cortell
> <alfredo.cortell.nicolau at gmail.com> wrote:
>> 
>> Hi Bienvenue,
>> 
>> I believe that your problem is that R can't translate "one" to a number,
>> because it is not a number. R could translate to numeric for example this
>> vector, where numbers are expressed as strings,
>> 
>> c("1","4","7")
>> 
>> but "one" is just letters put together, therefore R can't understand their
>> meaning, and returns NA.
>> 
>> I believe that your best shot is to go with gsub, so that you translate
>> your "string letters" to "string numbers", and then you can do as.numeric
>> no problem
>> 
>> Try this
>> 
>> vec<-c("1",NA,"one")
>> num_vec<-gsub("one",1,vec)
>> num_vec<-as.numeric(num_vec)
>> 
>> Good luck,
>> 
>> Alfredo
>> 
>> 
>> El mar., 9 abr. 2019 a las 15:07, Duncan Murdoch (<murdoch.duncan at gmail.com>)
>> escribi?:
>> 
>>> On 09/04/2019 7:30 a.m., Jim Lemon wrote:
>>>> Hi Bienvenue,
>>>> Perhaps you should ask whether you really want to "sort it out". The
>>>> warning is telling you that you are converting the NA values to NA in
>>>> the returned numeric vector.
>>> 
>>> I don't think that's what it is saying.  I think it is saying that a
>>> non-NA value is being converted to NA, because R can't figure out what
>>> number it is.  For example,
>>> 
>>>> as.numeric(c("1", NA))
>>> [1]  1 NA
>>>> as.numeric(c("1", NA, "one"))
>>> [1]  1 NA NA
>>> Warning message:
>>> NAs introduced by coercion
>>> 
>>> 
>>>  I can't think of anything more sensible
>>>> to do with NA values. You may also have character strings that cannot
>>>> be converted into numbers, which will also generate NA values.
>>> 
>>> I think that's the only way that message will appear.
>>> 
>>> Duncan Murdoch
>>> 
>>>  Maybe a
>>>> little example will help us to understand:
>>>> 
>>>> charstr<-c("5","foot","2",NA,"eyes","of","blue")
>>>> as.numeric(charstr)
>>>> [1]  5 NA  2 NA NA NA NA
>>>> 
>>>> Jim
>>>> 
>>>> On Tue, Apr 9, 2019 at 9:16 PM bienvenidozoma at gmail.com
>>>> <bienvenidozoma at gmail.com> wrote:
>>>>> 
>>>>> Hi,
>>>>> 
>>>>> I am applyin function as.numeric to a vector having many values as NA
>>>>> and it is giving :
>>>>> Warning message:
>>>>> NAs introduced by coercion
>>>>> 
>>>>> Can anyone help me to know how to remove this warning and sor it out?
>>>>> 
>>>>> Thanks
>>>>> Bienvenue
>>>>>         [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From M@A@Young @end|ng |rom @oton@@c@uk  Tue Apr  9 12:59:55 2019
From: M@A@Young @end|ng |rom @oton@@c@uk (Young M.A.)
Date: Tue, 9 Apr 2019 10:59:55 +0000
Subject: [R] [R-pkgs] New package to query  the OpenTripPlanner (OTP) API
Message-ID: <AM0PR04MB62917659F74A2A29392EF3E2E92D0@AM0PR04MB6291.eurprd04.prod.outlook.com>

Dear all

A new R package 'otpr' is now available on CRAN. It's a wrapper for the OpenTripPlanner (OTP) API and is primarily aimed at researchers and transport planners who want to use OTP to carry out accessibility studies or generate variables for transport models. The package consists of four main functions:

otp_connect() - defines and tests the connection to an OTP instance.
otp_get_distance() - gets the distance in metres between an origin and destination on the street and/or path network by specified mode. 
otp_get_times() - in its simplest use case gets the journey time between an origin and destination by specified mode(s). It can also return more detailed information, breaking down the journey by transit time, walking time, waiting time and the number of transfers. 
otp_get_isochrone() - returns one or more travel time isochrones for a location in GeoJSON format. These can be generated either from or to the specified location. 

The package currently supports a subset of the parameters that are available for the OTP 'planner' and 'isochrone' API resources. This is based on my experience of using OTP to generate this type of data and to keep the functions relatively simple from the user perspective. For a future release I will be allowing a larger range of parameters to be optionally passed through to the API query, giving greater flexibility but still keeping the external functions simple for users who don't need such detailed control. 

For more information, including code examples, take a look at the GitHub repository for the package: 

https://github.com/marcusyoung/otpr
 
I also have an OTP intermediate level tutorial - 'creating and querying your own multi-modal route planner' -  which incorporates use of the package:

https://github.com/marcusyoung/otp-tutorial

I'd welcome any feedback as well as suggestions for future development. 

Best wishes

Marcus

---------------------------------------------------
Dr Marcus Young
Research Fellow
Transportation Research Group
University of Southampton

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From dc@r|@on @end|ng |rom t@mu@edu  Tue Apr  9 20:51:12 2019
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Tue, 9 Apr 2019 18:51:12 +0000
Subject: [R] Create a sequence
In-Reply-To: <4C2FFCDC-36A6-4547-B41E-ACAF9276308F@me.com>
References: <1911031910.593229.1554815259473.ref@mail.yahoo.com>
 <1911031910.593229.1554815259473@mail.yahoo.com>
 <4C2FFCDC-36A6-4547-B41E-ACAF9276308F@me.com>
Message-ID: <8d6087403c4847949963be56c7cd0b50@tamu.edu>

Here's another approach:

> x <- c(rbind(1:100, -(1:100)))
> head(x); tail(x)
[1]  1 -1  2 -2  3 -3
[1]   98  -98   99  -99  100 -100

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Marc Schwartz via R-help
Sent: Tuesday, April 9, 2019 8:21 AM
To: bienvenidozoma at gmail.com
Cc: R-help <r-help at r-project.org>
Subject: Re: [R] Create a sequence



> On Apr 9, 2019, at 9:07 AM, bienvenidozoma at gmail.com wrote:
> 
> how to create
> u = (1, ?1, 2, ?2, . . . , 100, ?100)  in r
> 
> Thanks
> Bienvenue

Hi,

See ?seq and ?rep

> rep(seq(100), each = 2) * c(1, -1)
  [1]    1   -1    2   -2    3   -3    4   -4    5   -5    6   -6    7
 [14]   -7    8   -8    9   -9   10  -10   11  -11   12  -12   13  -13
 [27]   14  -14   15  -15   16  -16   17  -17   18  -18   19  -19   20
 [40]  -20   21  -21   22  -22   23  -23   24  -24   25  -25   26  -26
 [53]   27  -27   28  -28   29  -29   30  -30   31  -31   32  -32   33
 [66]  -33   34  -34   35  -35   36  -36   37  -37   38  -38   39  -39
 [79]   40  -40   41  -41   42  -42   43  -43   44  -44   45  -45   46
 [92]  -46   47  -47   48  -48   49  -49   50  -50   51  -51   52  -52
[105]   53  -53   54  -54   55  -55   56  -56   57  -57   58  -58   59
[118]  -59   60  -60   61  -61   62  -62   63  -63   64  -64   65  -65
[131]   66  -66   67  -67   68  -68   69  -69   70  -70   71  -71   72
[144]  -72   73  -73   74  -74   75  -75   76  -76   77  -77   78  -78
[157]   79  -79   80  -80   81  -81   82  -82   83  -83   84  -84   85
[170]  -85   86  -86   87  -87   88  -88   89  -89   90  -90   91  -91
[183]   92  -92   93  -93   94  -94   95  -95   96  -96   97  -97   98
[196]  -98   99  -99  100 -100


Regards,

Marc Schwartz

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From er|cjberger @end|ng |rom gm@||@com  Tue Apr  9 22:05:53 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 9 Apr 2019 23:05:53 +0300
Subject: [R] Create a sequence
In-Reply-To: <8d6087403c4847949963be56c7cd0b50@tamu.edu>
References: <1911031910.593229.1554815259473.ref@mail.yahoo.com>
 <1911031910.593229.1554815259473@mail.yahoo.com>
 <4C2FFCDC-36A6-4547-B41E-ACAF9276308F@me.com>
 <8d6087403c4847949963be56c7cd0b50@tamu.edu>
Message-ID: <CAGgJW76G2+47keu8detjsDXFr5oLWmgxwx6ejjgi3Xsh+9AOVw@mail.gmail.com>

And just for fun, yet another way

> cumsum((1:200)*c(1,-1))


On Tue, Apr 9, 2019 at 9:51 PM David L Carlson <dcarlson at tamu.edu> wrote:

> Here's another approach:
>
> > x <- c(rbind(1:100, -(1:100)))
> > head(x); tail(x)
> [1]  1 -1  2 -2  3 -3
> [1]   98  -98   99  -99  100 -100
>
> ----------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77843-4352
>
> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Marc Schwartz
> via R-help
> Sent: Tuesday, April 9, 2019 8:21 AM
> To: bienvenidozoma at gmail.com
> Cc: R-help <r-help at r-project.org>
> Subject: Re: [R] Create a sequence
>
>
>
> > On Apr 9, 2019, at 9:07 AM, bienvenidozoma at gmail.com wrote:
> >
> > how to create
> > u = (1, ?1, 2, ?2, . . . , 100, ?100)  in r
> >
> > Thanks
> > Bienvenue
>
> Hi,
>
> See ?seq and ?rep
>
> > rep(seq(100), each = 2) * c(1, -1)
>   [1]    1   -1    2   -2    3   -3    4   -4    5   -5    6   -6    7
>  [14]   -7    8   -8    9   -9   10  -10   11  -11   12  -12   13  -13
>  [27]   14  -14   15  -15   16  -16   17  -17   18  -18   19  -19   20
>  [40]  -20   21  -21   22  -22   23  -23   24  -24   25  -25   26  -26
>  [53]   27  -27   28  -28   29  -29   30  -30   31  -31   32  -32   33
>  [66]  -33   34  -34   35  -35   36  -36   37  -37   38  -38   39  -39
>  [79]   40  -40   41  -41   42  -42   43  -43   44  -44   45  -45   46
>  [92]  -46   47  -47   48  -48   49  -49   50  -50   51  -51   52  -52
> [105]   53  -53   54  -54   55  -55   56  -56   57  -57   58  -58   59
> [118]  -59   60  -60   61  -61   62  -62   63  -63   64  -64   65  -65
> [131]   66  -66   67  -67   68  -68   69  -69   70  -70   71  -71   72
> [144]  -72   73  -73   74  -74   75  -75   76  -76   77  -77   78  -78
> [157]   79  -79   80  -80   81  -81   82  -82   83  -83   84  -84   85
> [170]  -85   86  -86   87  -87   88  -88   89  -89   90  -90   91  -91
> [183]   92  -92   93  -93   94  -94   95  -95   96  -96   97  -97   98
> [196]  -98   99  -99  100 -100
>
>
> Regards,
>
> Marc Schwartz
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@nyder424 @end|ng |rom gm@||@com  Tue Apr  9 22:49:46 2019
From: m@nyder424 @end|ng |rom gm@||@com (Matthew Snyder)
Date: Tue, 9 Apr 2019 13:49:46 -0700
Subject: [R] Define pch and color based on two different columns
Message-ID: <CAP8t5PO=5jmH34vVmsLyCd08dngn1D7kxVzJYSE==A6=nkbmzg@mail.gmail.com>

I am making a lattice plot and I would like to use the value in one column
to define the pch and another column to define color of points. Something
like:

xyplot(mpg ~ wt | cyl,
       data=mtcars,
       col = gear,
       pch = carb
)

There are unique pch points in the second and third panels, but these
points are only unique within the plots, not among all the plots (as they
should be). You can see this if you use the following code:

xyplot(mpg ~ wt | cyl,
       data=mtcars,
       groups = carb
)

This plot looks great for one group, but if you try to invoke two groups
using c(gear, carb) I think it simply takes unique combinations of those
two variables and plots them as unique colors.

Another solution given by a StackExchange user:

mypch <- 1:6
mycol <- 1:3

xyplot(mpg ~ wt | cyl,
          panel = function(x, y, ..., groups, subscripts) {
              pch <- mypch[factor(carb[subscripts])]
              col <- mycol[factor(gear[subscripts])]
              grp <- c(gear,carb)
              panel.xyplot(x, y, pch = pch, col = col)
          }
)

This solution has the same problems as the code at the top. I think the
issue causing problems with both solutions is that not every value for each
group is present in each panel, and they are almost never in the same
order. I think R is just interpreting the appearance of unique values as a
signal to change to the next pch or color. My actual data file is very
large, and it's not possible to sort my way out of this mess. It would be
best if I could just use the value in two columns to actually define a
color or pch for each point on an entire plot. Is there a way to do this?

Ps, I had to post this via email because the Nabble site kept sending me an
error message: "Message rejected by filter rule match"

Thanks,
Matt



*Matthew R. Snyder*
*~~~~~~~~~~~~~~~~~*
PhD Candidate
University Fellow
University of Toledo
Computational biologist, ecologist, and bioinformatician
Sponsored Guest Researcher at NOAA PMEL, Seattle, WA.
Matthew.Snyder6 at rockets.utoledo.edu
MSnyder424 at gmail.com



[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
04/09/19,
1:49:27 PM

	[[alternative HTML version deleted]]


From @eb@@t|en@b|hore| @end|ng |rom cogn|gencorp@com  Tue Apr  9 23:46:37 2019
From: @eb@@t|en@b|hore| @end|ng |rom cogn|gencorp@com (Sebastien Bihorel)
Date: Tue, 9 Apr 2019 17:46:37 -0400 (EDT)
Subject: [R] Can one perform a dry run of a package installation?
Message-ID: <677247868.482015.1554846397475.JavaMail.zimbra@cognigencorp.com>

Hi,

Is there a way to do a dry run of install.packages() or update.packages() to simulate how an R environment would be modified by the installation or update of a particular set of packages (with their dependencies)? 

I am particularly interested in finding how dependencies would be recursively updated to newer versions.

Thanks


From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Apr 10 01:29:50 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 9 Apr 2019 19:29:50 -0400
Subject: [R] Can one perform a dry run of a package installation?
In-Reply-To: <677247868.482015.1554846397475.JavaMail.zimbra@cognigencorp.com>
References: <677247868.482015.1554846397475.JavaMail.zimbra@cognigencorp.com>
Message-ID: <0f20a5ce-2be0-e8fc-4ccb-c19f2dd6457e@gmail.com>

On 09/04/2019 5:46 p.m., Sebastien Bihorel wrote:
> Hi,
> 
> Is there a way to do a dry run of install.packages() or update.packages() to simulate how an R environment would be modified by the installation or update of a particular set of packages (with their dependencies)?
> 
> I am particularly interested in finding how dependencies would be recursively updated to newer versions.

Set the `lib` parameter of `install.packages` to an empty directory, and 
see what gets installed there.

Duncan Murdoch


From drj|m|emon @end|ng |rom gm@||@com  Wed Apr 10 01:53:24 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 10 Apr 2019 09:53:24 +1000
Subject: [R] Define pch and color based on two different columns
In-Reply-To: <CAP8t5PO=5jmH34vVmsLyCd08dngn1D7kxVzJYSE==A6=nkbmzg@mail.gmail.com>
References: <CAP8t5PO=5jmH34vVmsLyCd08dngn1D7kxVzJYSE==A6=nkbmzg@mail.gmail.com>
Message-ID: <CA+8X3fXuZ8g3p-x+Yq_jTFy=jnT34+xQjF8QzBp9zd8NLpejbg@mail.gmail.com>

Hi Matthew,
How about this?

library(lattice)
xyplot(mpg ~ wt | cyl,
       data=mtcars,
       col = mtcars$gear,
       pch = mtcars$carb
)
library(plotrix)
grange<-range(mtcars$gear)
xyplot(mpg ~ wt | cyl,
       data=mtcars,
       col = color.scale(mtcars$gear,extremes=c("blue","red"),xrange=grange),
       pch = as.character(mtcars$carb)
)

Jim

On Wed, Apr 10, 2019 at 7:43 AM Matthew Snyder <msnyder424 at gmail.com> wrote:
>
> I am making a lattice plot and I would like to use the value in one column
> to define the pch and another column to define color of points. Something
> like:
>
> xyplot(mpg ~ wt | cyl,
>        data=mtcars,
>        col = gear,
>        pch = carb
> )
>
> There are unique pch points in the second and third panels, but these
> points are only unique within the plots, not among all the plots (as they
> should be). You can see this if you use the following code:
>
> xyplot(mpg ~ wt | cyl,
>        data=mtcars,
>        groups = carb
> )
>
> This plot looks great for one group, but if you try to invoke two groups
> using c(gear, carb) I think it simply takes unique combinations of those
> two variables and plots them as unique colors.
>
> Another solution given by a StackExchange user:
>
> mypch <- 1:6
> mycol <- 1:3
>
> xyplot(mpg ~ wt | cyl,
>           panel = function(x, y, ..., groups, subscripts) {
>               pch <- mypch[factor(carb[subscripts])]
>               col <- mycol[factor(gear[subscripts])]
>               grp <- c(gear,carb)
>               panel.xyplot(x, y, pch = pch, col = col)
>           }
> )
>
> This solution has the same problems as the code at the top. I think the
> issue causing problems with both solutions is that not every value for each
> group is present in each panel, and they are almost never in the same
> order. I think R is just interpreting the appearance of unique values as a
> signal to change to the next pch or color. My actual data file is very
> large, and it's not possible to sort my way out of this mess. It would be
> best if I could just use the value in two columns to actually define a
> color or pch for each point on an entire plot. Is there a way to do this?
>
> Ps, I had to post this via email because the Nabble site kept sending me an
> error message: "Message rejected by filter rule match"
>
> Thanks,
> Matt
>
>
>
> *Matthew R. Snyder*
> *~~~~~~~~~~~~~~~~~*
> PhD Candidate
> University Fellow
> University of Toledo
> Computational biologist, ecologist, and bioinformatician
> Sponsored Guest Researcher at NOAA PMEL, Seattle, WA.
> Matthew.Snyder6 at rockets.utoledo.edu
> MSnyder424 at gmail.com
>
>
>
> [image: Mailtrack]
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
> Sender
> notified by
> Mailtrack
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
> 04/09/19,
> 1:49:27 PM
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@nyder424 @end|ng |rom gm@||@com  Wed Apr 10 05:09:43 2019
From: m@nyder424 @end|ng |rom gm@||@com (Matthew Snyder)
Date: Tue, 9 Apr 2019 20:09:43 -0700
Subject: [R] Define pch and color based on two different columns
In-Reply-To: <CA+8X3fXuZ8g3p-x+Yq_jTFy=jnT34+xQjF8QzBp9zd8NLpejbg@mail.gmail.com>
References: <CAP8t5PO=5jmH34vVmsLyCd08dngn1D7kxVzJYSE==A6=nkbmzg@mail.gmail.com>
 <CA+8X3fXuZ8g3p-x+Yq_jTFy=jnT34+xQjF8QzBp9zd8NLpejbg@mail.gmail.com>
Message-ID: <CAP8t5PO5+jhLQOnkk3D2i-6mP=cdoXpodw7H65BZOyfSBoF26Q@mail.gmail.com>

Thanks, Jim.

I appreciate your contributed answer, but neither of those make the desired
plot either. I'm actually kind of shocked this isn't an easier more
straightforward thing. It seems like this would be something that a user
would want to do frequently. I can actually do this for single plots in
ggplot. Maybe I should contact the authors of lattice and see if this is
something they can help me with or if they would like to add this as a
feature in the future...

Matt



*Matthew R. Snyder*
*~~~~~~~~~~~~~~~~~*
PhD Candidate
University Fellow
University of Toledo
Computational biologist, ecologist, and bioinformatician
Sponsored Guest Researcher at NOAA PMEL, Seattle, WA.
Matthew.Snyder6 at rockets.utoledo.edu
MSnyder424 at gmail.com



[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
04/09/19,
7:52:27 PM

On Tue, Apr 9, 2019 at 4:53 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Matthew,
> How about this?
>
> library(lattice)
> xyplot(mpg ~ wt | cyl,
>        data=mtcars,
>        col = mtcars$gear,
>        pch = mtcars$carb
> )
> library(plotrix)
> grange<-range(mtcars$gear)
> xyplot(mpg ~ wt | cyl,
>        data=mtcars,
>        col =
> color.scale(mtcars$gear,extremes=c("blue","red"),xrange=grange),
>        pch = as.character(mtcars$carb)
> )
>
> Jim
>
> On Wed, Apr 10, 2019 at 7:43 AM Matthew Snyder <msnyder424 at gmail.com>
> wrote:
> >
> > I am making a lattice plot and I would like to use the value in one
> column
> > to define the pch and another column to define color of points. Something
> > like:
> >
> > xyplot(mpg ~ wt | cyl,
> >        data=mtcars,
> >        col = gear,
> >        pch = carb
> > )
> >
> > There are unique pch points in the second and third panels, but these
> > points are only unique within the plots, not among all the plots (as they
> > should be). You can see this if you use the following code:
> >
> > xyplot(mpg ~ wt | cyl,
> >        data=mtcars,
> >        groups = carb
> > )
> >
> > This plot looks great for one group, but if you try to invoke two groups
> > using c(gear, carb) I think it simply takes unique combinations of those
> > two variables and plots them as unique colors.
> >
> > Another solution given by a StackExchange user:
> >
> > mypch <- 1:6
> > mycol <- 1:3
> >
> > xyplot(mpg ~ wt | cyl,
> >           panel = function(x, y, ..., groups, subscripts) {
> >               pch <- mypch[factor(carb[subscripts])]
> >               col <- mycol[factor(gear[subscripts])]
> >               grp <- c(gear,carb)
> >               panel.xyplot(x, y, pch = pch, col = col)
> >           }
> > )
> >
> > This solution has the same problems as the code at the top. I think the
> > issue causing problems with both solutions is that not every value for
> each
> > group is present in each panel, and they are almost never in the same
> > order. I think R is just interpreting the appearance of unique values as
> a
> > signal to change to the next pch or color. My actual data file is very
> > large, and it's not possible to sort my way out of this mess. It would be
> > best if I could just use the value in two columns to actually define a
> > color or pch for each point on an entire plot. Is there a way to do this?
> >
> > Ps, I had to post this via email because the Nabble site kept sending me
> an
> > error message: "Message rejected by filter rule match"
> >
> > Thanks,
> > Matt
> >
> >
> >
> > *Matthew R. Snyder*
> > *~~~~~~~~~~~~~~~~~*
> > PhD Candidate
> > University Fellow
> > University of Toledo
> > Computational biologist, ecologist, and bioinformatician
> > Sponsored Guest Researcher at NOAA PMEL, Seattle, WA.
> > Matthew.Snyder6 at rockets.utoledo.edu
> > MSnyder424 at gmail.com
> >
> >
> >
> > [image: Mailtrack]
> > <
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
> >
> > Sender
> > notified by
> > Mailtrack
> > <
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
> >
> > 04/09/19,
> > 1:49:27 PM
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Apr 10 05:18:14 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 09 Apr 2019 20:18:14 -0700
Subject: [R] Define pch and color based on two different columns
In-Reply-To: <CAP8t5PO5+jhLQOnkk3D2i-6mP=cdoXpodw7H65BZOyfSBoF26Q@mail.gmail.com>
References: <CAP8t5PO=5jmH34vVmsLyCd08dngn1D7kxVzJYSE==A6=nkbmzg@mail.gmail.com>
 <CA+8X3fXuZ8g3p-x+Yq_jTFy=jnT34+xQjF8QzBp9zd8NLpejbg@mail.gmail.com>
 <CAP8t5PO5+jhLQOnkk3D2i-6mP=cdoXpodw7H65BZOyfSBoF26Q@mail.gmail.com>
Message-ID: <6C389ADD-E6D6-46A5-87E9-0F4288E06C1B@dcn.davis.ca.us>

Maybe you should use factors rather than character columns.

On April 9, 2019 8:09:43 PM PDT, Matthew Snyder <msnyder424 at gmail.com> wrote:
>Thanks, Jim.
>
>I appreciate your contributed answer, but neither of those make the
>desired
>plot either. I'm actually kind of shocked this isn't an easier more
>straightforward thing. It seems like this would be something that a
>user
>would want to do frequently. I can actually do this for single plots in
>ggplot. Maybe I should contact the authors of lattice and see if this
>is
>something they can help me with or if they would like to add this as a
>feature in the future...
>
>Matt
>
>
>
>*Matthew R. Snyder*
>*~~~~~~~~~~~~~~~~~*
>PhD Candidate
>University Fellow
>University of Toledo
>Computational biologist, ecologist, and bioinformatician
>Sponsored Guest Researcher at NOAA PMEL, Seattle, WA.
>Matthew.Snyder6 at rockets.utoledo.edu
>MSnyder424 at gmail.com
>
>
>
>[image: Mailtrack]
><https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
>Sender
>notified by
>Mailtrack
><https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
>04/09/19,
>7:52:27 PM
>
>On Tue, Apr 9, 2019 at 4:53 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi Matthew,
>> How about this?
>>
>> library(lattice)
>> xyplot(mpg ~ wt | cyl,
>>        data=mtcars,
>>        col = mtcars$gear,
>>        pch = mtcars$carb
>> )
>> library(plotrix)
>> grange<-range(mtcars$gear)
>> xyplot(mpg ~ wt | cyl,
>>        data=mtcars,
>>        col =
>> color.scale(mtcars$gear,extremes=c("blue","red"),xrange=grange),
>>        pch = as.character(mtcars$carb)
>> )
>>
>> Jim
>>
>> On Wed, Apr 10, 2019 at 7:43 AM Matthew Snyder <msnyder424 at gmail.com>
>> wrote:
>> >
>> > I am making a lattice plot and I would like to use the value in one
>> column
>> > to define the pch and another column to define color of points.
>Something
>> > like:
>> >
>> > xyplot(mpg ~ wt | cyl,
>> >        data=mtcars,
>> >        col = gear,
>> >        pch = carb
>> > )
>> >
>> > There are unique pch points in the second and third panels, but
>these
>> > points are only unique within the plots, not among all the plots
>(as they
>> > should be). You can see this if you use the following code:
>> >
>> > xyplot(mpg ~ wt | cyl,
>> >        data=mtcars,
>> >        groups = carb
>> > )
>> >
>> > This plot looks great for one group, but if you try to invoke two
>groups
>> > using c(gear, carb) I think it simply takes unique combinations of
>those
>> > two variables and plots them as unique colors.
>> >
>> > Another solution given by a StackExchange user:
>> >
>> > mypch <- 1:6
>> > mycol <- 1:3
>> >
>> > xyplot(mpg ~ wt | cyl,
>> >           panel = function(x, y, ..., groups, subscripts) {
>> >               pch <- mypch[factor(carb[subscripts])]
>> >               col <- mycol[factor(gear[subscripts])]
>> >               grp <- c(gear,carb)
>> >               panel.xyplot(x, y, pch = pch, col = col)
>> >           }
>> > )
>> >
>> > This solution has the same problems as the code at the top. I think
>the
>> > issue causing problems with both solutions is that not every value
>for
>> each
>> > group is present in each panel, and they are almost never in the
>same
>> > order. I think R is just interpreting the appearance of unique
>values as
>> a
>> > signal to change to the next pch or color. My actual data file is
>very
>> > large, and it's not possible to sort my way out of this mess. It
>would be
>> > best if I could just use the value in two columns to actually
>define a
>> > color or pch for each point on an entire plot. Is there a way to do
>this?
>> >
>> > Ps, I had to post this via email because the Nabble site kept
>sending me
>> an
>> > error message: "Message rejected by filter rule match"
>> >
>> > Thanks,
>> > Matt
>> >
>> >
>> >
>> > *Matthew R. Snyder*
>> > *~~~~~~~~~~~~~~~~~*
>> > PhD Candidate
>> > University Fellow
>> > University of Toledo
>> > Computational biologist, ecologist, and bioinformatician
>> > Sponsored Guest Researcher at NOAA PMEL, Seattle, WA.
>> > Matthew.Snyder6 at rockets.utoledo.edu
>> > MSnyder424 at gmail.com
>> >
>> >
>> >
>> > [image: Mailtrack]
>> > <
>>
>https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>> >
>> > Sender
>> > notified by
>> > Mailtrack
>> > <
>>
>https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>> >
>> > 04/09/19,
>> > 1:49:27 PM
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Wed Apr 10 06:23:22 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 9 Apr 2019 21:23:22 -0700
Subject: [R] Define pch and color based on two different columns
In-Reply-To: <CAP8t5PO5+jhLQOnkk3D2i-6mP=cdoXpodw7H65BZOyfSBoF26Q@mail.gmail.com>
References: <CAP8t5PO=5jmH34vVmsLyCd08dngn1D7kxVzJYSE==A6=nkbmzg@mail.gmail.com>
 <CA+8X3fXuZ8g3p-x+Yq_jTFy=jnT34+xQjF8QzBp9zd8NLpejbg@mail.gmail.com>
 <CAP8t5PO5+jhLQOnkk3D2i-6mP=cdoXpodw7H65BZOyfSBoF26Q@mail.gmail.com>
Message-ID: <CAGxFJbQAAw+OBBQvS977x_f7kWB5-ZCWv5B3eqoiak6HbNKNEg@mail.gmail.com>

1. I am quite sure that whatever it is that you want to do can be done.
Probably straightforwardly. The various R graphics systems are mature and
extensive.

2. But I, for one, do not understand from your post what it is that you
want to do.  Nor does anyone else apparently.

Cheers,

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 9, 2019 at 8:10 PM Matthew Snyder <msnyder424 at gmail.com> wrote:

> Thanks, Jim.
>
> I appreciate your contributed answer, but neither of those make the desired
> plot either. I'm actually kind of shocked this isn't an easier more
> straightforward thing. It seems like this would be something that a user
> would want to do frequently. I can actually do this for single plots in
> ggplot. Maybe I should contact the authors of lattice and see if this is
> something they can help me with or if they would like to add this as a
> feature in the future...
>
> Matt
>
>
>
> *Matthew R. Snyder*
> *~~~~~~~~~~~~~~~~~*
> PhD Candidate
> University Fellow
> University of Toledo
> Computational biologist, ecologist, and bioinformatician
> Sponsored Guest Researcher at NOAA PMEL, Seattle, WA.
> Matthew.Snyder6 at rockets.utoledo.edu
> MSnyder424 at gmail.com
>
>
>
> [image: Mailtrack]
> <
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
> >
> Sender
> notified by
> Mailtrack
> <
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
> >
> 04/09/19,
> 7:52:27 PM
>
> On Tue, Apr 9, 2019 at 4:53 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> > Hi Matthew,
> > How about this?
> >
> > library(lattice)
> > xyplot(mpg ~ wt | cyl,
> >        data=mtcars,
> >        col = mtcars$gear,
> >        pch = mtcars$carb
> > )
> > library(plotrix)
> > grange<-range(mtcars$gear)
> > xyplot(mpg ~ wt | cyl,
> >        data=mtcars,
> >        col =
> > color.scale(mtcars$gear,extremes=c("blue","red"),xrange=grange),
> >        pch = as.character(mtcars$carb)
> > )
> >
> > Jim
> >
> > On Wed, Apr 10, 2019 at 7:43 AM Matthew Snyder <msnyder424 at gmail.com>
> > wrote:
> > >
> > > I am making a lattice plot and I would like to use the value in one
> > column
> > > to define the pch and another column to define color of points.
> Something
> > > like:
> > >
> > > xyplot(mpg ~ wt | cyl,
> > >        data=mtcars,
> > >        col = gear,
> > >        pch = carb
> > > )
> > >
> > > There are unique pch points in the second and third panels, but these
> > > points are only unique within the plots, not among all the plots (as
> they
> > > should be). You can see this if you use the following code:
> > >
> > > xyplot(mpg ~ wt | cyl,
> > >        data=mtcars,
> > >        groups = carb
> > > )
> > >
> > > This plot looks great for one group, but if you try to invoke two
> groups
> > > using c(gear, carb) I think it simply takes unique combinations of
> those
> > > two variables and plots them as unique colors.
> > >
> > > Another solution given by a StackExchange user:
> > >
> > > mypch <- 1:6
> > > mycol <- 1:3
> > >
> > > xyplot(mpg ~ wt | cyl,
> > >           panel = function(x, y, ..., groups, subscripts) {
> > >               pch <- mypch[factor(carb[subscripts])]
> > >               col <- mycol[factor(gear[subscripts])]
> > >               grp <- c(gear,carb)
> > >               panel.xyplot(x, y, pch = pch, col = col)
> > >           }
> > > )
> > >
> > > This solution has the same problems as the code at the top. I think the
> > > issue causing problems with both solutions is that not every value for
> > each
> > > group is present in each panel, and they are almost never in the same
> > > order. I think R is just interpreting the appearance of unique values
> as
> > a
> > > signal to change to the next pch or color. My actual data file is very
> > > large, and it's not possible to sort my way out of this mess. It would
> be
> > > best if I could just use the value in two columns to actually define a
> > > color or pch for each point on an entire plot. Is there a way to do
> this?
> > >
> > > Ps, I had to post this via email because the Nabble site kept sending
> me
> > an
> > > error message: "Message rejected by filter rule match"
> > >
> > > Thanks,
> > > Matt
> > >
> > >
> > >
> > > *Matthew R. Snyder*
> > > *~~~~~~~~~~~~~~~~~*
> > > PhD Candidate
> > > University Fellow
> > > University of Toledo
> > > Computational biologist, ecologist, and bioinformatician
> > > Sponsored Guest Researcher at NOAA PMEL, Seattle, WA.
> > > Matthew.Snyder6 at rockets.utoledo.edu
> > > MSnyder424 at gmail.com
> > >
> > >
> > >
> > > [image: Mailtrack]
> > > <
> >
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
> > >
> > > Sender
> > > notified by
> > > Mailtrack
> > > <
> >
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
> > >
> > > 04/09/19,
> > > 1:49:27 PM
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@nyder424 @end|ng |rom gm@||@com  Wed Apr 10 06:28:00 2019
From: m@nyder424 @end|ng |rom gm@||@com (Matthew Snyder)
Date: Tue, 9 Apr 2019 21:28:00 -0700
Subject: [R] Define pch and color based on two different columns
In-Reply-To: <CAGxFJbQAAw+OBBQvS977x_f7kWB5-ZCWv5B3eqoiak6HbNKNEg@mail.gmail.com>
References: <CAP8t5PO=5jmH34vVmsLyCd08dngn1D7kxVzJYSE==A6=nkbmzg@mail.gmail.com>
 <CA+8X3fXuZ8g3p-x+Yq_jTFy=jnT34+xQjF8QzBp9zd8NLpejbg@mail.gmail.com>
 <CAP8t5PO5+jhLQOnkk3D2i-6mP=cdoXpodw7H65BZOyfSBoF26Q@mail.gmail.com>
 <CAGxFJbQAAw+OBBQvS977x_f7kWB5-ZCWv5B3eqoiak6HbNKNEg@mail.gmail.com>
Message-ID: <CAP8t5PNYDGuKmQ9ircNxmUm=GUT1S0XDMRfqNFR6=0qOjGPrSA@mail.gmail.com>

I want to have one column in a dataframe define the color and another
define the pch.

This can be done easily with a single panel:

xyplot(mpg ~ wt,
       data=mtcars,
       col = mtcars$gear,
       pch = mtcars$carb
)

This produces the expected result: two pch that are the same color are
unique in the whole plot. But when you add cyl as a factor. Those two
points are only unique within their respective panels, and not across the
whole plot.

Matt



*Matthew R. Snyder*
*~~~~~~~~~~~~~~~~~*
PhD Candidate
University Fellow
University of Toledo
Computational biologist, ecologist, and bioinformatician
Sponsored Guest Researcher at NOAA PMEL, Seattle, WA.
Matthew.Snyder6 at rockets.utoledo.edu
MSnyder424 at gmail.com




[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
04/09/19,
9:26:09 PM

On Tue, Apr 9, 2019 at 9:23 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> 1. I am quite sure that whatever it is that you want to do can be done.
> Probably straightforwardly. The various R graphics systems are mature and
> extensive.
>
> 2. But I, for one, do not understand from your post what it is that you
> want to do.  Nor does anyone else apparently.
>
> Cheers,
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Apr 9, 2019 at 8:10 PM Matthew Snyder <msnyder424 at gmail.com>
> wrote:
>
>> Thanks, Jim.
>>
>> I appreciate your contributed answer, but neither of those make the
>> desired
>> plot either. I'm actually kind of shocked this isn't an easier more
>> straightforward thing. It seems like this would be something that a user
>> would want to do frequently. I can actually do this for single plots in
>> ggplot. Maybe I should contact the authors of lattice and see if this is
>> something they can help me with or if they would like to add this as a
>> feature in the future...
>>
>> Matt
>>
>>
>>
>> *Matthew R. Snyder*
>> *~~~~~~~~~~~~~~~~~*
>> PhD Candidate
>> University Fellow
>> University of Toledo
>> Computational biologist, ecologist, and bioinformatician
>> Sponsored Guest Researcher at NOAA PMEL, Seattle, WA.
>> Matthew.Snyder6 at rockets.utoledo.edu
>> MSnyder424 at gmail.com
>>
>>
>>
>> [image: Mailtrack]
>> <
>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>> >
>> Sender
>> notified by
>> Mailtrack
>> <
>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>> >
>> 04/09/19,
>> 7:52:27 PM
>>
>> On Tue, Apr 9, 2019 at 4:53 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> > Hi Matthew,
>> > How about this?
>> >
>> > library(lattice)
>> > xyplot(mpg ~ wt | cyl,
>> >        data=mtcars,
>> >        col = mtcars$gear,
>> >        pch = mtcars$carb
>> > )
>> > library(plotrix)
>> > grange<-range(mtcars$gear)
>> > xyplot(mpg ~ wt | cyl,
>> >        data=mtcars,
>> >        col =
>> > color.scale(mtcars$gear,extremes=c("blue","red"),xrange=grange),
>> >        pch = as.character(mtcars$carb)
>> > )
>> >
>> > Jim
>> >
>> > On Wed, Apr 10, 2019 at 7:43 AM Matthew Snyder <msnyder424 at gmail.com>
>> > wrote:
>> > >
>> > > I am making a lattice plot and I would like to use the value in one
>> > column
>> > > to define the pch and another column to define color of points.
>> Something
>> > > like:
>> > >
>> > > xyplot(mpg ~ wt | cyl,
>> > >        data=mtcars,
>> > >        col = gear,
>> > >        pch = carb
>> > > )
>> > >
>> > > There are unique pch points in the second and third panels, but these
>> > > points are only unique within the plots, not among all the plots (as
>> they
>> > > should be). You can see this if you use the following code:
>> > >
>> > > xyplot(mpg ~ wt | cyl,
>> > >        data=mtcars,
>> > >        groups = carb
>> > > )
>> > >
>> > > This plot looks great for one group, but if you try to invoke two
>> groups
>> > > using c(gear, carb) I think it simply takes unique combinations of
>> those
>> > > two variables and plots them as unique colors.
>> > >
>> > > Another solution given by a StackExchange user:
>> > >
>> > > mypch <- 1:6
>> > > mycol <- 1:3
>> > >
>> > > xyplot(mpg ~ wt | cyl,
>> > >           panel = function(x, y, ..., groups, subscripts) {
>> > >               pch <- mypch[factor(carb[subscripts])]
>> > >               col <- mycol[factor(gear[subscripts])]
>> > >               grp <- c(gear,carb)
>> > >               panel.xyplot(x, y, pch = pch, col = col)
>> > >           }
>> > > )
>> > >
>> > > This solution has the same problems as the code at the top. I think
>> the
>> > > issue causing problems with both solutions is that not every value for
>> > each
>> > > group is present in each panel, and they are almost never in the same
>> > > order. I think R is just interpreting the appearance of unique values
>> as
>> > a
>> > > signal to change to the next pch or color. My actual data file is very
>> > > large, and it's not possible to sort my way out of this mess. It
>> would be
>> > > best if I could just use the value in two columns to actually define a
>> > > color or pch for each point on an entire plot. Is there a way to do
>> this?
>> > >
>> > > Ps, I had to post this via email because the Nabble site kept sending
>> me
>> > an
>> > > error message: "Message rejected by filter rule match"
>> > >
>> > > Thanks,
>> > > Matt
>> > >
>> > >
>> > >
>> > > *Matthew R. Snyder*
>> > > *~~~~~~~~~~~~~~~~~*
>> > > PhD Candidate
>> > > University Fellow
>> > > University of Toledo
>> > > Computational biologist, ecologist, and bioinformatician
>> > > Sponsored Guest Researcher at NOAA PMEL, Seattle, WA.
>> > > Matthew.Snyder6 at rockets.utoledo.edu
>> > > MSnyder424 at gmail.com
>> > >
>> > >
>> > >
>> > > [image: Mailtrack]
>> > > <
>> >
>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>> > >
>> > > Sender
>> > > notified by
>> > > Mailtrack
>> > > <
>> >
>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>> > >
>> > > 04/09/19,
>> > > 1:49:27 PM
>> > >
>> > >         [[alternative HTML version deleted]]
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From m@nyder424 @end|ng |rom gm@||@com  Wed Apr 10 06:28:15 2019
From: m@nyder424 @end|ng |rom gm@||@com (Matthew Snyder)
Date: Tue, 9 Apr 2019 21:28:15 -0700
Subject: [R] Define pch and color based on two different columns
In-Reply-To: <6C389ADD-E6D6-46A5-87E9-0F4288E06C1B@dcn.davis.ca.us>
References: <CAP8t5PO=5jmH34vVmsLyCd08dngn1D7kxVzJYSE==A6=nkbmzg@mail.gmail.com>
 <CA+8X3fXuZ8g3p-x+Yq_jTFy=jnT34+xQjF8QzBp9zd8NLpejbg@mail.gmail.com>
 <CAP8t5PO5+jhLQOnkk3D2i-6mP=cdoXpodw7H65BZOyfSBoF26Q@mail.gmail.com>
 <6C389ADD-E6D6-46A5-87E9-0F4288E06C1B@dcn.davis.ca.us>
Message-ID: <CAP8t5PNBha8K3o_uVQ3-canMKA_Fh4q_0iQTYOv7JZ_Ba7Qo=g@mail.gmail.com>

I tried this too:

xyplot(mpg ~ wt | cyl, data=mtcars,
       # groups = carb,
       subscripts = TRUE,
       col = as.factor(mtcars$gear),
       pch = as.factor(mtcars$carb)
)

Same problem...


*Matthew R. Snyder*
*~~~~~~~~~~~~~~~~~*
PhD Candidate
University Fellow
University of Toledo
Computational biologist, ecologist, and bioinformatician
Sponsored Guest Researcher at NOAA PMEL, Seattle, WA.
Matthew.Snyder6 at rockets.utoledo.edu
MSnyder424 at gmail.com




[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
04/09/19,
9:28:11 PM

On Tue, Apr 9, 2019 at 8:18 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Maybe you should use factors rather than character columns.
>
> On April 9, 2019 8:09:43 PM PDT, Matthew Snyder <msnyder424 at gmail.com>
> wrote:
> >Thanks, Jim.
> >
> >I appreciate your contributed answer, but neither of those make the
> >desired
> >plot either. I'm actually kind of shocked this isn't an easier more
> >straightforward thing. It seems like this would be something that a
> >user
> >would want to do frequently. I can actually do this for single plots in
> >ggplot. Maybe I should contact the authors of lattice and see if this
> >is
> >something they can help me with or if they would like to add this as a
> >feature in the future...
> >
> >Matt
> >
> >
> >
> >*Matthew R. Snyder*
> >*~~~~~~~~~~~~~~~~~*
> >PhD Candidate
> >University Fellow
> >University of Toledo
> >Computational biologist, ecologist, and bioinformatician
> >Sponsored Guest Researcher at NOAA PMEL, Seattle, WA.
> >Matthew.Snyder6 at rockets.utoledo.edu
> >MSnyder424 at gmail.com
> >
> >
> >
> >[image: Mailtrack]
> ><
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
> >
> >Sender
> >notified by
> >Mailtrack
> ><
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
> >
> >04/09/19,
> >7:52:27 PM
> >
> >On Tue, Apr 9, 2019 at 4:53 PM Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> >> Hi Matthew,
> >> How about this?
> >>
> >> library(lattice)
> >> xyplot(mpg ~ wt | cyl,
> >>        data=mtcars,
> >>        col = mtcars$gear,
> >>        pch = mtcars$carb
> >> )
> >> library(plotrix)
> >> grange<-range(mtcars$gear)
> >> xyplot(mpg ~ wt | cyl,
> >>        data=mtcars,
> >>        col =
> >> color.scale(mtcars$gear,extremes=c("blue","red"),xrange=grange),
> >>        pch = as.character(mtcars$carb)
> >> )
> >>
> >> Jim
> >>
> >> On Wed, Apr 10, 2019 at 7:43 AM Matthew Snyder <msnyder424 at gmail.com>
> >> wrote:
> >> >
> >> > I am making a lattice plot and I would like to use the value in one
> >> column
> >> > to define the pch and another column to define color of points.
> >Something
> >> > like:
> >> >
> >> > xyplot(mpg ~ wt | cyl,
> >> >        data=mtcars,
> >> >        col = gear,
> >> >        pch = carb
> >> > )
> >> >
> >> > There are unique pch points in the second and third panels, but
> >these
> >> > points are only unique within the plots, not among all the plots
> >(as they
> >> > should be). You can see this if you use the following code:
> >> >
> >> > xyplot(mpg ~ wt | cyl,
> >> >        data=mtcars,
> >> >        groups = carb
> >> > )
> >> >
> >> > This plot looks great for one group, but if you try to invoke two
> >groups
> >> > using c(gear, carb) I think it simply takes unique combinations of
> >those
> >> > two variables and plots them as unique colors.
> >> >
> >> > Another solution given by a StackExchange user:
> >> >
> >> > mypch <- 1:6
> >> > mycol <- 1:3
> >> >
> >> > xyplot(mpg ~ wt | cyl,
> >> >           panel = function(x, y, ..., groups, subscripts) {
> >> >               pch <- mypch[factor(carb[subscripts])]
> >> >               col <- mycol[factor(gear[subscripts])]
> >> >               grp <- c(gear,carb)
> >> >               panel.xyplot(x, y, pch = pch, col = col)
> >> >           }
> >> > )
> >> >
> >> > This solution has the same problems as the code at the top. I think
> >the
> >> > issue causing problems with both solutions is that not every value
> >for
> >> each
> >> > group is present in each panel, and they are almost never in the
> >same
> >> > order. I think R is just interpreting the appearance of unique
> >values as
> >> a
> >> > signal to change to the next pch or color. My actual data file is
> >very
> >> > large, and it's not possible to sort my way out of this mess. It
> >would be
> >> > best if I could just use the value in two columns to actually
> >define a
> >> > color or pch for each point on an entire plot. Is there a way to do
> >this?
> >> >
> >> > Ps, I had to post this via email because the Nabble site kept
> >sending me
> >> an
> >> > error message: "Message rejected by filter rule match"
> >> >
> >> > Thanks,
> >> > Matt
> >> >
> >> >
> >> >
> >> > *Matthew R. Snyder*
> >> > *~~~~~~~~~~~~~~~~~*
> >> > PhD Candidate
> >> > University Fellow
> >> > University of Toledo
> >> > Computational biologist, ecologist, and bioinformatician
> >> > Sponsored Guest Researcher at NOAA PMEL, Seattle, WA.
> >> > Matthew.Snyder6 at rockets.utoledo.edu
> >> > MSnyder424 at gmail.com
> >> >
> >> >
> >> >
> >> > [image: Mailtrack]
> >> > <
> >>
> >
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
> >> >
> >> > Sender
> >> > notified by
> >> > Mailtrack
> >> > <
> >>
> >
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
> >> >
> >> > 04/09/19,
> >> > 1:49:27 PM
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From peter@|@ng|e|der @end|ng |rom gm@||@com  Wed Apr 10 06:36:48 2019
From: peter@|@ng|e|der @end|ng |rom gm@||@com (Peter Langfelder)
Date: Tue, 9 Apr 2019 21:36:48 -0700
Subject: [R] Define pch and color based on two different columns
In-Reply-To: <CAP8t5PO=5jmH34vVmsLyCd08dngn1D7kxVzJYSE==A6=nkbmzg@mail.gmail.com>
References: <CAP8t5PO=5jmH34vVmsLyCd08dngn1D7kxVzJYSE==A6=nkbmzg@mail.gmail.com>
Message-ID: <CA+hbrhX4x0P=5e=QAOa+rJ=udsZeFeKBpO3EpmN-06kg97fHkg@mail.gmail.com>

Sorry for being late to the party, but has anyone suggested a minor
but important modification of the code from stack exchange?

xyplot(mpg ~ wt | cyl,
          panel = function(x, y, ..., groups, subscripts) {
              pch <- mypch[factor(carb)[subscripts]]
              col <- mycol[factor(gear)[subscripts]]
              grp <- c(gear,carb)
              panel.xyplot(x, y, pch = pch, col = col)
          }
)

>From the little I understand about what you're trying to do, this may
just do the trick.

Peter

On Tue, Apr 9, 2019 at 2:43 PM Matthew Snyder <msnyder424 at gmail.com> wrote:
>
> I am making a lattice plot and I would like to use the value in one column
> to define the pch and another column to define color of points. Something
> like:
>
> xyplot(mpg ~ wt | cyl,
>        data=mtcars,
>        col = gear,
>        pch = carb
> )
>
> There are unique pch points in the second and third panels, but these
> points are only unique within the plots, not among all the plots (as they
> should be). You can see this if you use the following code:
>
> xyplot(mpg ~ wt | cyl,
>        data=mtcars,
>        groups = carb
> )
>
> This plot looks great for one group, but if you try to invoke two groups
> using c(gear, carb) I think it simply takes unique combinations of those
> two variables and plots them as unique colors.
>
> Another solution given by a StackExchange user:
>
> mypch <- 1:6
> mycol <- 1:3
>
> xyplot(mpg ~ wt | cyl,
>           panel = function(x, y, ..., groups, subscripts) {
>               pch <- mypch[factor(carb[subscripts])]
>               col <- mycol[factor(gear[subscripts])]
>               grp <- c(gear,carb)
>               panel.xyplot(x, y, pch = pch, col = col)
>           }
> )
>
> This solution has the same problems as the code at the top. I think the
> issue causing problems with both solutions is that not every value for each
> group is present in each panel, and they are almost never in the same
> order. I think R is just interpreting the appearance of unique values as a
> signal to change to the next pch or color. My actual data file is very
> large, and it's not possible to sort my way out of this mess. It would be
> best if I could just use the value in two columns to actually define a
> color or pch for each point on an entire plot. Is there a way to do this?
>
> Ps, I had to post this via email because the Nabble site kept sending me an
> error message: "Message rejected by filter rule match"
>
> Thanks,
> Matt
>
>
>
> *Matthew R. Snyder*
> *~~~~~~~~~~~~~~~~~*
> PhD Candidate
> University Fellow
> University of Toledo
> Computational biologist, ecologist, and bioinformatician
> Sponsored Guest Researcher at NOAA PMEL, Seattle, WA.
> Matthew.Snyder6 at rockets.utoledo.edu
> MSnyder424 at gmail.com
>
>
>
> [image: Mailtrack]
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
> Sender
> notified by
> Mailtrack
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
> 04/09/19,
> 1:49:27 PM
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@nyder424 @end|ng |rom gm@||@com  Wed Apr 10 07:02:47 2019
From: m@nyder424 @end|ng |rom gm@||@com (Matthew Snyder)
Date: Tue, 9 Apr 2019 22:02:47 -0700
Subject: [R] Define pch and color based on two different columns
In-Reply-To: <CA+hbrhX4x0P=5e=QAOa+rJ=udsZeFeKBpO3EpmN-06kg97fHkg@mail.gmail.com>
References: <CAP8t5PO=5jmH34vVmsLyCd08dngn1D7kxVzJYSE==A6=nkbmzg@mail.gmail.com>
 <CA+hbrhX4x0P=5e=QAOa+rJ=udsZeFeKBpO3EpmN-06kg97fHkg@mail.gmail.com>
Message-ID: <CAP8t5PN_DOBDncMEE+-zuDk9nni=jDUnT5n9L-Phtzuwxs6Epw@mail.gmail.com>

You are not late to the party. And you solved it!

Thank you very much. You just made my PhD a little closer to reality!

Matt



*Matthew R. Snyder*
*~~~~~~~~~~~~~~~~~*
PhD Candidate
University Fellow
University of Toledo
Computational biologist, ecologist, and bioinformatician
Sponsored Guest Researcher at NOAA PMEL, Seattle, WA.
Matthew.Snyder6 at rockets.utoledo.edu
MSnyder424 at gmail.com



[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
04/09/19,
10:01:53 PM

On Tue, Apr 9, 2019 at 9:37 PM Peter Langfelder <peter.langfelder at gmail.com>
wrote:

> Sorry for being late to the party, but has anyone suggested a minor
> but important modification of the code from stack exchange?
>
> xyplot(mpg ~ wt | cyl,
>           panel = function(x, y, ..., groups, subscripts) {
>               pch <- mypch[factor(carb)[subscripts]]
>               col <- mycol[factor(gear)[subscripts]]
>               grp <- c(gear,carb)
>               panel.xyplot(x, y, pch = pch, col = col)
>           }
> )
>
> From the little I understand about what you're trying to do, this may
> just do the trick.
>
> Peter
>
> On Tue, Apr 9, 2019 at 2:43 PM Matthew Snyder <msnyder424 at gmail.com>
> wrote:
> >
> > I am making a lattice plot and I would like to use the value in one
> column
> > to define the pch and another column to define color of points. Something
> > like:
> >
> > xyplot(mpg ~ wt | cyl,
> >        data=mtcars,
> >        col = gear,
> >        pch = carb
> > )
> >
> > There are unique pch points in the second and third panels, but these
> > points are only unique within the plots, not among all the plots (as they
> > should be). You can see this if you use the following code:
> >
> > xyplot(mpg ~ wt | cyl,
> >        data=mtcars,
> >        groups = carb
> > )
> >
> > This plot looks great for one group, but if you try to invoke two groups
> > using c(gear, carb) I think it simply takes unique combinations of those
> > two variables and plots them as unique colors.
> >
> > Another solution given by a StackExchange user:
> >
> > mypch <- 1:6
> > mycol <- 1:3
> >
> > xyplot(mpg ~ wt | cyl,
> >           panel = function(x, y, ..., groups, subscripts) {
> >               pch <- mypch[factor(carb[subscripts])]
> >               col <- mycol[factor(gear[subscripts])]
> >               grp <- c(gear,carb)
> >               panel.xyplot(x, y, pch = pch, col = col)
> >           }
> > )
> >
> > This solution has the same problems as the code at the top. I think the
> > issue causing problems with both solutions is that not every value for
> each
> > group is present in each panel, and they are almost never in the same
> > order. I think R is just interpreting the appearance of unique values as
> a
> > signal to change to the next pch or color. My actual data file is very
> > large, and it's not possible to sort my way out of this mess. It would be
> > best if I could just use the value in two columns to actually define a
> > color or pch for each point on an entire plot. Is there a way to do this?
> >
> > Ps, I had to post this via email because the Nabble site kept sending me
> an
> > error message: "Message rejected by filter rule match"
> >
> > Thanks,
> > Matt
> >
> >
> >
> > *Matthew R. Snyder*
> > *~~~~~~~~~~~~~~~~~*
> > PhD Candidate
> > University Fellow
> > University of Toledo
> > Computational biologist, ecologist, and bioinformatician
> > Sponsored Guest Researcher at NOAA PMEL, Seattle, WA.
> > Matthew.Snyder6 at rockets.utoledo.edu
> > MSnyder424 at gmail.com
> >
> >
> >
> > [image: Mailtrack]
> > <
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
> >
> > Sender
> > notified by
> > Mailtrack
> > <
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
> >
> > 04/09/19,
> > 1:49:27 PM
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rmh @end|ng |rom temp|e@edu  Wed Apr 10 07:03:39 2019
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Wed, 10 Apr 2019 01:03:39 -0400
Subject: [R] Define pch and color based on two different columns
In-Reply-To: <CA+hbrhX4x0P=5e=QAOa+rJ=udsZeFeKBpO3EpmN-06kg97fHkg@mail.gmail.com>
References: <CAP8t5PO=5jmH34vVmsLyCd08dngn1D7kxVzJYSE==A6=nkbmzg@mail.gmail.com>
 <CA+hbrhX4x0P=5e=QAOa+rJ=udsZeFeKBpO3EpmN-06kg97fHkg@mail.gmail.com>
Message-ID: <CAGx1TMBFk-3SBQZXwsY3h7U9ExKh4UmAc97979iqFUF_0Mar_g@mail.gmail.com>

conditions look better as factors (their values are displayed in the
strip label).
groups should be a factor to get the uniqueness over panels.
To use two factors together for groups, take their interaction.
col and pch should be integers


xyplot(mpg ~ wt | factor(cyl), data=mtcars,
       groups = factor(carb),
       col = mtcars$gear,
       pch = mtcars$carb
)
xyplot(mpg ~ wt | factor(cyl), data=mtcars,
       groups = interaction(factor(carb), factor(gear)),
       col = mtcars$gear,
       pch = mtcars$carb
)

On Wed, Apr 10, 2019 at 12:54 AM Peter Langfelder
<peter.langfelder at gmail.com> wrote:
>
> Sorry for being late to the party, but has anyone suggested a minor
> but important modification of the code from stack exchange?
>
> xyplot(mpg ~ wt | cyl,
>           panel = function(x, y, ..., groups, subscripts) {
>               pch <- mypch[factor(carb)[subscripts]]
>               col <- mycol[factor(gear)[subscripts]]
>               grp <- c(gear,carb)
>               panel.xyplot(x, y, pch = pch, col = col)
>           }
> )
>
> From the little I understand about what you're trying to do, this may
> just do the trick.
>
> Peter
>
> On Tue, Apr 9, 2019 at 2:43 PM Matthew Snyder <msnyder424 at gmail.com> wrote:
> >
> > I am making a lattice plot and I would like to use the value in one column
> > to define the pch and another column to define color of points. Something
> > like:
> >
> > xyplot(mpg ~ wt | cyl,
> >        data=mtcars,
> >        col = gear,
> >        pch = carb
> > )
> >
> > There are unique pch points in the second and third panels, but these
> > points are only unique within the plots, not among all the plots (as they
> > should be). You can see this if you use the following code:
> >
> > xyplot(mpg ~ wt | cyl,
> >        data=mtcars,
> >        groups = carb
> > )
> >
> > This plot looks great for one group, but if you try to invoke two groups
> > using c(gear, carb) I think it simply takes unique combinations of those
> > two variables and plots them as unique colors.
> >
> > Another solution given by a StackExchange user:
> >
> > mypch <- 1:6
> > mycol <- 1:3
> >
> > xyplot(mpg ~ wt | cyl,
> >           panel = function(x, y, ..., groups, subscripts) {
> >               pch <- mypch[factor(carb[subscripts])]
> >               col <- mycol[factor(gear[subscripts])]
> >               grp <- c(gear,carb)
> >               panel.xyplot(x, y, pch = pch, col = col)
> >           }
> > )
> >
> > This solution has the same problems as the code at the top. I think the
> > issue causing problems with both solutions is that not every value for each
> > group is present in each panel, and they are almost never in the same
> > order. I think R is just interpreting the appearance of unique values as a
> > signal to change to the next pch or color. My actual data file is very
> > large, and it's not possible to sort my way out of this mess. It would be
> > best if I could just use the value in two columns to actually define a
> > color or pch for each point on an entire plot. Is there a way to do this?
> >
> > Ps, I had to post this via email because the Nabble site kept sending me an
> > error message: "Message rejected by filter rule match"
> >
> > Thanks,
> > Matt
> >
> >
> >
> > *Matthew R. Snyder*
> > *~~~~~~~~~~~~~~~~~*
> > PhD Candidate
> > University Fellow
> > University of Toledo
> > Computational biologist, ecologist, and bioinformatician
> > Sponsored Guest Researcher at NOAA PMEL, Seattle, WA.
> > Matthew.Snyder6 at rockets.utoledo.edu
> > MSnyder424 at gmail.com
> >
> >
> >
> > [image: Mailtrack]
> > <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
> > Sender
> > notified by
> > Mailtrack
> > <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
> > 04/09/19,
> > 1:49:27 PM
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From peter@|@ng|e|der @end|ng |rom gm@||@com  Wed Apr 10 07:18:44 2019
From: peter@|@ng|e|der @end|ng |rom gm@||@com (Peter Langfelder)
Date: Tue, 9 Apr 2019 22:18:44 -0700
Subject: [R] Define pch and color based on two different columns
In-Reply-To: <CAP8t5PN_DOBDncMEE+-zuDk9nni=jDUnT5n9L-Phtzuwxs6Epw@mail.gmail.com>
References: <CAP8t5PO=5jmH34vVmsLyCd08dngn1D7kxVzJYSE==A6=nkbmzg@mail.gmail.com>
 <CA+hbrhX4x0P=5e=QAOa+rJ=udsZeFeKBpO3EpmN-06kg97fHkg@mail.gmail.com>
 <CAP8t5PN_DOBDncMEE+-zuDk9nni=jDUnT5n9L-Phtzuwxs6Epw@mail.gmail.com>
Message-ID: <CA+hbrhVH0dPENQGtaxLuFjMpuYyS8qChS3bSvZ4RLeX-1Cdybw@mail.gmail.com>

Glad to be of help.

Peter

On Tue, Apr 9, 2019 at 10:03 PM Matthew Snyder <msnyder424 at gmail.com> wrote:

> You are not late to the party. And you solved it!
>
> Thank you very much. You just made my PhD a little closer to reality!
>
> Matt
>
>
>
> *Matthew R. Snyder*
> *~~~~~~~~~~~~~~~~~*
> PhD Candidate
> University Fellow
> University of Toledo
> Computational biologist, ecologist, and bioinformatician
> Sponsored Guest Researcher at NOAA PMEL, Seattle, WA.
> Matthew.Snyder6 at rockets.utoledo.edu
> MSnyder424 at gmail.com
>
>
>
> [image: Mailtrack]
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> Sender
> notified by
> Mailtrack
> <https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&> 04/09/19,
> 10:01:53 PM
>
> On Tue, Apr 9, 2019 at 9:37 PM Peter Langfelder <
> peter.langfelder at gmail.com> wrote:
>
>> Sorry for being late to the party, but has anyone suggested a minor
>> but important modification of the code from stack exchange?
>>
>> xyplot(mpg ~ wt | cyl,
>>           panel = function(x, y, ..., groups, subscripts) {
>>               pch <- mypch[factor(carb)[subscripts]]
>>               col <- mycol[factor(gear)[subscripts]]
>>               grp <- c(gear,carb)
>>               panel.xyplot(x, y, pch = pch, col = col)
>>           }
>> )
>>
>> From the little I understand about what you're trying to do, this may
>> just do the trick.
>>
>> Peter
>>
>> On Tue, Apr 9, 2019 at 2:43 PM Matthew Snyder <msnyder424 at gmail.com>
>> wrote:
>> >
>> > I am making a lattice plot and I would like to use the value in one
>> column
>> > to define the pch and another column to define color of points.
>> Something
>> > like:
>> >
>> > xyplot(mpg ~ wt | cyl,
>> >        data=mtcars,
>> >        col = gear,
>> >        pch = carb
>> > )
>> >
>> > There are unique pch points in the second and third panels, but these
>> > points are only unique within the plots, not among all the plots (as
>> they
>> > should be). You can see this if you use the following code:
>> >
>> > xyplot(mpg ~ wt | cyl,
>> >        data=mtcars,
>> >        groups = carb
>> > )
>> >
>> > This plot looks great for one group, but if you try to invoke two groups
>> > using c(gear, carb) I think it simply takes unique combinations of those
>> > two variables and plots them as unique colors.
>> >
>> > Another solution given by a StackExchange user:
>> >
>> > mypch <- 1:6
>> > mycol <- 1:3
>> >
>> > xyplot(mpg ~ wt | cyl,
>> >           panel = function(x, y, ..., groups, subscripts) {
>> >               pch <- mypch[factor(carb[subscripts])]
>> >               col <- mycol[factor(gear[subscripts])]
>> >               grp <- c(gear,carb)
>> >               panel.xyplot(x, y, pch = pch, col = col)
>> >           }
>> > )
>> >
>> > This solution has the same problems as the code at the top. I think the
>> > issue causing problems with both solutions is that not every value for
>> each
>> > group is present in each panel, and they are almost never in the same
>> > order. I think R is just interpreting the appearance of unique values
>> as a
>> > signal to change to the next pch or color. My actual data file is very
>> > large, and it's not possible to sort my way out of this mess. It would
>> be
>> > best if I could just use the value in two columns to actually define a
>> > color or pch for each point on an entire plot. Is there a way to do
>> this?
>> >
>> > Ps, I had to post this via email because the Nabble site kept sending
>> me an
>> > error message: "Message rejected by filter rule match"
>> >
>> > Thanks,
>> > Matt
>> >
>> >
>> >
>> > *Matthew R. Snyder*
>> > *~~~~~~~~~~~~~~~~~*
>> > PhD Candidate
>> > University Fellow
>> > University of Toledo
>> > Computational biologist, ecologist, and bioinformatician
>> > Sponsored Guest Researcher at NOAA PMEL, Seattle, WA.
>> > Matthew.Snyder6 at rockets.utoledo.edu
>> > MSnyder424 at gmail.com
>> >
>> >
>> >
>> > [image: Mailtrack]
>> > <
>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>> >
>> > Sender
>> > notified by
>> > Mailtrack
>> > <
>> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
>> >
>> > 04/09/19,
>> > 1:49:27 PM
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Wed Apr 10 07:20:08 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 9 Apr 2019 22:20:08 -0700
Subject: [R] Define pch and color based on two different columns
In-Reply-To: <CA+hbrhX4x0P=5e=QAOa+rJ=udsZeFeKBpO3EpmN-06kg97fHkg@mail.gmail.com>
References: <CAP8t5PO=5jmH34vVmsLyCd08dngn1D7kxVzJYSE==A6=nkbmzg@mail.gmail.com>
 <CA+hbrhX4x0P=5e=QAOa+rJ=udsZeFeKBpO3EpmN-06kg97fHkg@mail.gmail.com>
Message-ID: <CAGxFJbQjue=YSrUv78R-rRLwESSu-md_ENK85iYbE_yQVKODCg@mail.gmail.com>

I believe this is unnecessarily complicated. What the OP did not seem to
get is that he had to specify the col's and pch's in the panel function
that were actually used via appropriate subscripting. He just passed in the
whole col and pch vector by default -- subscripting is not done unless
specified.So the following does what I think he wants very simply:

xyplot(mpg ~wt|cyl, data = mtcars,
      col = mtcars$gear,
      pch = mtcars$carb,
      panel = function(x,y, subscripts, col, pch,...)
      {
         panel.xyplot(x,y, col = col[subscripts], pch = pch[subscripts] )
      })

Cheers,
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 9, 2019 at 9:53 PM Peter Langfelder <peter.langfelder at gmail.com>
wrote:

> Sorry for being late to the party, but has anyone suggested a minor
> but important modification of the code from stack exchange?
>
> xyplot(mpg ~ wt | cyl,
>           panel = function(x, y, ..., groups, subscripts) {
>               pch <- mypch[factor(carb)[subscripts]]
>               col <- mycol[factor(gear)[subscripts]]
>               grp <- c(gear,carb)
>               panel.xyplot(x, y, pch = pch, col = col)
>           }
> )
>
> From the little I understand about what you're trying to do, this may
> just do the trick.
>
> Peter
>
> On Tue, Apr 9, 2019 at 2:43 PM Matthew Snyder <msnyder424 at gmail.com>
> wrote:
> >
> > I am making a lattice plot and I would like to use the value in one
> column
> > to define the pch and another column to define color of points. Something
> > like:
> >
> > xyplot(mpg ~ wt | cyl,
> >        data=mtcars,
> >        col = gear,
> >        pch = carb
> > )
> >
> > There are unique pch points in the second and third panels, but these
> > points are only unique within the plots, not among all the plots (as they
> > should be). You can see this if you use the following code:
> >
> > xyplot(mpg ~ wt | cyl,
> >        data=mtcars,
> >        groups = carb
> > )
> >
> > This plot looks great for one group, but if you try to invoke two groups
> > using c(gear, carb) I think it simply takes unique combinations of those
> > two variables and plots them as unique colors.
> >
> > Another solution given by a StackExchange user:
> >
> > mypch <- 1:6
> > mycol <- 1:3
> >
> > xyplot(mpg ~ wt | cyl,
> >           panel = function(x, y, ..., groups, subscripts) {
> >               pch <- mypch[factor(carb[subscripts])]
> >               col <- mycol[factor(gear[subscripts])]
> >               grp <- c(gear,carb)
> >               panel.xyplot(x, y, pch = pch, col = col)
> >           }
> > )
> >
> > This solution has the same problems as the code at the top. I think the
> > issue causing problems with both solutions is that not every value for
> each
> > group is present in each panel, and they are almost never in the same
> > order. I think R is just interpreting the appearance of unique values as
> a
> > signal to change to the next pch or color. My actual data file is very
> > large, and it's not possible to sort my way out of this mess. It would be
> > best if I could just use the value in two columns to actually define a
> > color or pch for each point on an entire plot. Is there a way to do this?
> >
> > Ps, I had to post this via email because the Nabble site kept sending me
> an
> > error message: "Message rejected by filter rule match"
> >
> > Thanks,
> > Matt
> >
> >
> >
> > *Matthew R. Snyder*
> > *~~~~~~~~~~~~~~~~~*
> > PhD Candidate
> > University Fellow
> > University of Toledo
> > Computational biologist, ecologist, and bioinformatician
> > Sponsored Guest Researcher at NOAA PMEL, Seattle, WA.
> > Matthew.Snyder6 at rockets.utoledo.edu
> > MSnyder424 at gmail.com
> >
> >
> >
> > [image: Mailtrack]
> > <
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
> >
> > Sender
> > notified by
> > Mailtrack
> > <
> https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&
> >
> > 04/09/19,
> > 1:49:27 PM
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From |||o|orn@@ero @end|ng |rom hotm@||@com  Wed Apr 10 10:35:23 2019
From: |||o|orn@@ero @end|ng |rom hotm@||@com (Ilio Fornasero)
Date: Wed, 10 Apr 2019 08:35:23 +0000
Subject: [R] R web-scraping a multiple-level page
Message-ID: <AM0PR04MB429052E176C032CF78E569F4B32E0@AM0PR04MB4290.eurprd04.prod.outlook.com>

Hello.

I am trying to scrape a FAO webpage including multiple links from any of which I would like to collect the "News" part.

Yet, I have done this:

fao_base = 'http://www.fao.org'
fao_second_level = paste0(stem, '/countryprofiles/en/')

all_children = read_html(fao_second_level) %>%
  html_nodes(xpath = '//a[contains(@href, "?iso3=")]/@href') %>%
  html_text %>% paste0(fao_base, .)

Any suggestion on how to go on? I guess with a loop but I didn't have any success, yet.
Thanks

	[[alternative HTML version deleted]]


From bor|@@@te|pe @end|ng |rom utoronto@c@  Wed Apr 10 12:34:15 2019
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Wed, 10 Apr 2019 10:34:15 +0000
Subject: [R] R web-scraping a multiple-level page
In-Reply-To: <AM0PR04MB429052E176C032CF78E569F4B32E0@AM0PR04MB4290.eurprd04.prod.outlook.com>
References: <AM0PR04MB429052E176C032CF78E569F4B32E0@AM0PR04MB4290.eurprd04.prod.outlook.com>
Message-ID: <7738D743-C3D2-4DF3-BD64-64C16910A03A@utoronto.ca>

For similar tasks I usually write a while loop operating on a queue. Conceptually:

initialize queue with first page
add first url to harvested urls

while queue not empty (2)
  unshift url from queue
  collect valid child pages that are not already in harvested list (1)
  add to harvested list
  add to queue

process all harvested pages



(1) - grep for the base url so you don't leave the site
    - use %in% to ensure you are not caught in a cycle

(2) Restrict the condition with a maximum number of cycles. More often than not assumptions about the world turn out to be overly rational.

Hope this helps,
B.




> On 2019-04-10, at 04:35, Ilio Fornasero <iliofornasero at hotmail.com> wrote:
> 
> Hello.
> 
> I am trying to scrape a FAO webpage including multiple links from any of which I would like to collect the "News" part.
> 
> Yet, I have done this:
> 
> fao_base = 'http://www.fao.org'
> fao_second_level = paste0(stem, '/countryprofiles/en/')
> 
> all_children = read_html(fao_second_level) %>%
>  html_nodes(xpath = '//a[contains(@href, "?iso3=")]/@href') %>%
>  html_text %>% paste0(fao_base, .)
> 
> Any suggestion on how to go on? I guess with a loop but I didn't have any success, yet.
> Thanks
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chr|@ho|d @end|ng |rom p@yctc@org  Wed Apr 10 13:05:28 2019
From: chr|@ho|d @end|ng |rom p@yctc@org (Chris Evans)
Date: Wed, 10 Apr 2019 12:05:28 +0100 (BST)
Subject: [R] R web-scraping a multiple-level page
In-Reply-To: <7738D743-C3D2-4DF3-BD64-64C16910A03A@utoronto.ca>
References: <AM0PR04MB429052E176C032CF78E569F4B32E0@AM0PR04MB4290.eurprd04.prod.outlook.com>
 <7738D743-C3D2-4DF3-BD64-64C16910A03A@utoronto.ca>
Message-ID: <1276728869.3160853.1554894328677.JavaMail.zimbra@psyctc.org>



----- Original Message -----
> From: "Boris Steipe" <boris.steipe at utoronto.ca>
> To: "Ilio Fornasero" <iliofornasero at hotmail.com>
> Cc: r-help at r-project.org
> Sent: Wednesday, 10 April, 2019 12:34:15
> Subject: Re: [R] R web-scraping a multiple-level page

[snip]
 
> (2) Restrict the condition with a maximum number of cycles. More often than not
> assumptions about the world turn out to be overly rational.

Brilliant!! Fortune nomination?

And the advice was useful to me too though I'm not the OQ.

Thanks,

Chris

-- 
Chris Evans <chris at psyctc.org> Skype: chris-psyctc
Visiting Professor, University of Sheffield <chris.evans at sheffield.ac.uk>
I do some consultation work for the University of Roehampton <chris.evans at roehampton.ac.uk> and other places but this <chris at psyctc.org> remains my main Email address.
I have "semigrated" to France, see: https://www.psyctc.org/pelerinage2016/semigrating-to-france/ if you want to book to talk, I am trying to keep that to Thursdays and my diary is now available at: https://www.psyctc.org/pelerinage2016/ecwd_calendar/calendar/
Beware: French time, generally an hour ahead of UK.  That page will also take you to my blog which started with earlier joys in France and Spain!


From b@row||ng@on @end|ng |rom |@nc@@ter@@c@uk  Wed Apr 10 13:35:58 2019
From: b@row||ng@on @end|ng |rom |@nc@@ter@@c@uk (Barry Rowlingson)
Date: Wed, 10 Apr 2019 12:35:58 +0100
Subject: [R] Greek characters in R studio
In-Reply-To: <3e75849032d04ccba4d4497361d1152e@CWXP265MB0775.GBRP265.PROD.OUTLOOK.COM>
References: <3e75849032d04ccba4d4497361d1152e@CWXP265MB0775.GBRP265.PROD.OUTLOOK.COM>
Message-ID: <CANVKczO0cpoNESyw-96EOhvV1G3Oie6cYQRTS61tawCSKS+f8g@mail.gmail.com>

What have you tried? read.table works perfectly for me with no language or
encoding arguments. Here's a text file at the Linux command line:

$ cat greek.csv
?, ?
1,2
3,4

I just have to tell it to use comma separators and there is a header line.
Here's R:

> read.table("./greek.csv",sep=",",head=TRUE)
  ? ?
1 1 2
2 3 4

and I can get the columns in the usual way:

> d[["?"]]
[1] 1 3
> d$?
[1] 1 3

But maybe this doesn't work for you. Did you try anything? What happened?

B

On Tue, Apr 9, 2019 at 3:13 AM kostas zogopoulos <kostaszogo at gmail.com>
wrote:

> How do you read a csv file that contains greek characters as part of the
> header (i.e. ?, ? etc) in R studio?
>  Thanks in advance!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From du|c@|m@ @end|ng |rom b|gpond@com  Thu Apr 11 01:04:54 2019
From: du|c@|m@ @end|ng |rom b|gpond@com (Duncan Mackay)
Date: Thu, 11 Apr 2019 09:04:54 +1000
Subject: [R] Define pch and color based on two different columns
In-Reply-To: <CAP8t5PN_DOBDncMEE+-zuDk9nni=jDUnT5n9L-Phtzuwxs6Epw@mail.gmail.com>
References: <CAP8t5PO=5jmH34vVmsLyCd08dngn1D7kxVzJYSE==A6=nkbmzg@mail.gmail.com>
 <CA+hbrhX4x0P=5e=QAOa+rJ=udsZeFeKBpO3EpmN-06kg97fHkg@mail.gmail.com>
 <CAP8t5PN_DOBDncMEE+-zuDk9nni=jDUnT5n9L-Phtzuwxs6Epw@mail.gmail.com>
Message-ID: <000c01d4eff1$cfe19010$6fa4b030$@bigpond.com>

Hi

Here is the caveat
If you want to repeat it with loess? or panel loess something else that is
not groups aware  (I have not checked to see if it has been up dated) have a
look at

https://stat.ethz.ch/pipermail/r-help/2010-August/250050.html

Regards

Duncan Mackay

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2350


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Matthew
Snyder
Sent: Wednesday, 10 April 2019 15:03
To: Peter Langfelder
Cc: r-help
Subject: Re: [R] Define pch and color based on two different columns

You are not late to the party. And you solved it!

Thank you very much. You just made my PhD a little closer to reality!

Matt



*Matthew R. Snyder*
*~~~~~~~~~~~~~~~~~*
PhD Candidate
University Fellow
University of Toledo
Computational biologist, ecologist, and bioinformatician
Sponsored Guest Researcher at NOAA PMEL, Seattle, WA.
Matthew.Snyder6 at rockets.utoledo.edu
MSnyder424 at gmail.com



[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=sig
naturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=sig
naturevirality5&>
04/09/19,
10:01:53 PM

On Tue, Apr 9, 2019 at 9:37 PM Peter Langfelder <peter.langfelder at gmail.com>
wrote:

> Sorry for being late to the party, but has anyone suggested a minor
> but important modification of the code from stack exchange?
>
> xyplot(mpg ~ wt | cyl,
>           panel = function(x, y, ..., groups, subscripts) {
>               pch <- mypch[factor(carb)[subscripts]]
>               col <- mycol[factor(gear)[subscripts]]
>               grp <- c(gear,carb)
>               panel.xyplot(x, y, pch = pch, col = col)
>           }
> )
>
> From the little I understand about what you're trying to do, this may
> just do the trick.
>
> Peter
>
> On Tue, Apr 9, 2019 at 2:43 PM Matthew Snyder <msnyder424 at gmail.com>
> wrote:
> >
> > I am making a lattice plot and I would like to use the value in one
> column
> > to define the pch and another column to define color of points.
Something
> > like:
> >
> > xyplot(mpg ~ wt | cyl,
> >        data=mtcars,
> >        col = gear,
> >        pch = carb
> > )
> >
> > There are unique pch points in the second and third panels, but these
> > points are only unique within the plots, not among all the plots (as
they
> > should be). You can see this if you use the following code:
> >
> > xyplot(mpg ~ wt | cyl,
> >        data=mtcars,
> >        groups = carb
> > )
> >
> > This plot looks great for one group, but if you try to invoke two groups
> > using c(gear, carb) I think it simply takes unique combinations of those
> > two variables and plots them as unique colors.
> >
> > Another solution given by a StackExchange user:
> >
> > mypch <- 1:6
> > mycol <- 1:3
> >
> > xyplot(mpg ~ wt | cyl,
> >           panel = function(x, y, ..., groups, subscripts) {
> >               pch <- mypch[factor(carb[subscripts])]
> >               col <- mycol[factor(gear[subscripts])]
> >               grp <- c(gear,carb)
> >               panel.xyplot(x, y, pch = pch, col = col)
> >           }
> > )
> >
> > This solution has the same problems as the code at the top. I think the
> > issue causing problems with both solutions is that not every value for
> each
> > group is present in each panel, and they are almost never in the same
> > order. I think R is just interpreting the appearance of unique values as
> a
> > signal to change to the next pch or color. My actual data file is very
> > large, and it's not possible to sort my way out of this mess. It would
be
> > best if I could just use the value in two columns to actually define a
> > color or pch for each point on an entire plot. Is there a way to do
this?
> >
> > Ps, I had to post this via email because the Nabble site kept sending me
> an
> > error message: "Message rejected by filter rule match"
> >
> > Thanks,
> > Matt
> >
> >
> >
> > *Matthew R. Snyder*
> > *~~~~~~~~~~~~~~~~~*
> > PhD Candidate
> > University Fellow
> > University of Toledo
> > Computational biologist, ecologist, and bioinformatician
> > Sponsored Guest Researcher at NOAA PMEL, Seattle, WA.
> > Matthew.Snyder6 at rockets.utoledo.edu
> > MSnyder424 at gmail.com
> >
> >
> >
> > [image: Mailtrack]
> > <
>
https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=sign
aturevirality5&
> >
> > Sender
> > notified by
> > Mailtrack
> > <
>
https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=sign
aturevirality5&
> >
> > 04/09/19,
> > 1:49:27 PM
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From @eb@@t|en@b|hore| @end|ng |rom cogn|gencorp@com  Thu Apr 11 03:38:52 2019
From: @eb@@t|en@b|hore| @end|ng |rom cogn|gencorp@com (Sebastien Bihorel)
Date: Wed, 10 Apr 2019 21:38:52 -0400 (EDT)
Subject: [R] Can one perform a dry run of a package installation?
In-Reply-To: <0f20a5ce-2be0-e8fc-4ccb-c19f2dd6457e@gmail.com>
References: <677247868.482015.1554846397475.JavaMail.zimbra@cognigencorp.com>
 <0f20a5ce-2be0-e8fc-4ccb-c19f2dd6457e@gmail.com>
Message-ID: <582771028.545460.1554946732191.JavaMail.zimbra@cognigencorp.com>

Thanks

----- Original Message -----
From: "Duncan Murdoch" <murdoch.duncan at gmail.com>
To: "Sebastien Bihorel" <sebastien.bihorel at cognigencorp.com>, r-help at r-project.org
Sent: Tuesday, April 9, 2019 7:29:50 PM
Subject: Re: [R] Can one perform a dry run of a package installation?

On 09/04/2019 5:46 p.m., Sebastien Bihorel wrote:
> Hi,
> 
> Is there a way to do a dry run of install.packages() or update.packages() to simulate how an R environment would be modified by the installation or update of a particular set of packages (with their dependencies)?
> 
> I am particularly interested in finding how dependencies would be recursively updated to newer versions.

Set the `lib` parameter of `install.packages` to an empty directory, and 
see what gets installed there.

Duncan Murdoch


From kr|@t|@g|over @end|ng |rom hotm@||@com  Thu Apr 11 13:28:31 2019
From: kr|@t|@g|over @end|ng |rom hotm@||@com (Kristi Glover)
Date: Thu, 11 Apr 2019 11:28:31 +0000
Subject: [R] How to overlay a vector map (polygon) on raster maps?
Message-ID: <MWHPR0201MB3449A12CFBA9F8D9C1720F65FA2F0@MWHPR0201MB3449.namprd02.prod.outlook.com>

He R users,
I have been struggling to plot a boundary map over the raster maps. I tried using the following example, but the boundary map could not be displayed over the three raster maps.
It works if we plot for a single raster. However when I want to plot the three maps using "levelplot" and add the boundary map it did not work.  I wanted to plot three raster same time because the "levelplot" so that we can compare the maps as they have only one legend.

My example code is given below, do you have any suggestions?


library(gridExtra)

library(raster)

library(sp)

library(rasterVis)

library(rgdal)

library(maptools)


boundary<- readShapeSpatial("boundrymap.shp")


minTemp<-raster("minTemp.tif")

maxTemp<-raster("maxTemp.tif")

averageTemp<-raster("averageTemp.tif")

Temp<-stack(minTemp,maxTemp,averageTemp)


levelplot(Temp, layout=c(1,3))+ layer(sp.polygons(boundary, col = "yellow"))

thanks


	[[alternative HTML version deleted]]


From btupper @end|ng |rom b|ge|ow@org  Thu Apr 11 15:13:49 2019
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Thu, 11 Apr 2019 09:13:49 -0400
Subject: [R] How to overlay a vector map (polygon) on raster maps?
In-Reply-To: <MWHPR0201MB3449A12CFBA9F8D9C1720F65FA2F0@MWHPR0201MB3449.namprd02.prod.outlook.com>
References: <MWHPR0201MB3449A12CFBA9F8D9C1720F65FA2F0@MWHPR0201MB3449.namprd02.prod.outlook.com>
Message-ID: <54621052-2672-490B-90C8-1BCE18E9428B@bigelow.org>

Hi,

I think you want to build a levelplot object with polygon overlaid for each layer.  Like the link below shows but with the added layer per your example.  

https://oscarperpinan.github.io/rastervis/FAQ.html#several_rasters

Also, you will get bucket loads of spatial-centric help using the r-sig-geo mailing list; check it out here https://stat.ethz.ch/mailman/listinfo/r-sig-geo.

Cheers,
Ben

### START
library(sp)
library(raster)
library(rasterVis)
library(RColorBrewer)

S <- raster::stack(system.file("external/rlogo.grd", package="raster"))

# make a polygon by shrinking the extent and casting object type
Poly <- as(raster::extent(S) + c(15, -32, 25, -10), "SpatialPolygons")

# build the layers in a list, adding the polygon to each layer
themes <- c("Reds", "Greens", "Blues")
PP <- lapply(seq_len(nlayers(S)),
	function(i) {
		levelplot(S[[i]], 
			par.settings = rasterVis::rasterTheme(region = RColorBrewer::brewer.pal(9, themes[i])), 	
			margin=FALSE) + 
		layer(sp.polygons(Poly, col = "orange", lwd = 2))
		}
	)
	
# print each layer, but specify the location within a layout scheme
print(PP[[1]], split=c(1, 1, 1, 3), more = TRUE)
print(PP[[2]], split=c(1, 2, 1, 3), more = TRUE)
print(PP[[3]], split=c(1, 3, 1, 3), more = FALSE)
### END



> On Apr 11, 2019, at 7:28 AM, Kristi Glover <kristi.glover at hotmail.com> wrote:
> 
> He R users,
> I have been struggling to plot a boundary map over the raster maps. I tried using the following example, but the boundary map could not be displayed over the three raster maps.
> It works if we plot for a single raster. However when I want to plot the three maps using "levelplot" and add the boundary map it did not work.  I wanted to plot three raster same time because the "levelplot" so that we can compare the maps as they have only one legend.
> 
> My example code is given below, do you have any suggestions?
> 
> 
> library(gridExtra)
> 
> library(raster)
> 
> library(sp)
> 
> library(rasterVis)
> 
> library(rgdal)
> 
> library(maptools)
> 
> 
> boundary<- readShapeSpatial("boundrymap.shp")
> 
> 
> minTemp<-raster("minTemp.tif")
> 
> maxTemp<-raster("maxTemp.tif")
> 
> averageTemp<-raster("averageTemp.tif")
> 
> Temp<-stack(minTemp,maxTemp,averageTemp)
> 
> 
> levelplot(Temp, layout=c(1,3))+ layer(sp.polygons(boundary, col = "yellow"))
> 
> thanks
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/


From kr|@t|@g|over @end|ng |rom hotm@||@com  Thu Apr 11 17:32:53 2019
From: kr|@t|@g|over @end|ng |rom hotm@||@com (Kristi Glover)
Date: Thu, 11 Apr 2019 15:32:53 +0000
Subject: [R] How to overlay a vector map (polygon) on raster maps?
In-Reply-To: <54621052-2672-490B-90C8-1BCE18E9428B@bigelow.org>
References: <MWHPR0201MB3449A12CFBA9F8D9C1720F65FA2F0@MWHPR0201MB3449.namprd02.prod.outlook.com>,
 <54621052-2672-490B-90C8-1BCE18E9428B@bigelow.org>
Message-ID: <MWHPR0201MB34492D64C74F491A4B7498F7FA2F0@MWHPR0201MB3449.namprd02.prod.outlook.com>

Dear Ben,
Thank you very much for the message. I run it and it produced three separate images with X and y Axis  and a legend for each image. I was thinking to plot all of these three images with a single legend and only X axis value at the bottom's image and y values for each image.

I added the following code on your code
grid.arrange(PP[[1]],PP[[2]],PP[[3]])

But, as I mentioned above, I can get three separate images with its own legend and X and Y axix
Thanks,

________________________________
From: Ben Tupper <btupper at bigelow.org>
Sent: April 11, 2019 7:13 AM
To: Kristi Glover
Cc: r-help at r-project.org
Subject: Re: [R] How to overlay a vector map (polygon) on raster maps?

Hi,

I think you want to build a levelplot object with polygon overlaid for each layer.  Like the link below shows but with the added layer per your example.

https://oscarperpinan.github.io/rastervis/FAQ.html#several_rasters

Also, you will get bucket loads of spatial-centric help using the r-sig-geo mailing list; check it out here https://stat.ethz.ch/mailman/listinfo/r-sig-geo.

Cheers,
Ben

### START
library(sp)
library(raster)
library(rasterVis)
library(RColorBrewer)

S <- raster::stack(system.file("external/rlogo.grd", package="raster"))

# make a polygon by shrinking the extent and casting object type
Poly <- as(raster::extent(S) + c(15, -32, 25, -10), "SpatialPolygons")

# build the layers in a list, adding the polygon to each layer
themes <- c("Reds", "Greens", "Blues")
PP <- lapply(seq_len(nlayers(S)),
        function(i) {
                levelplot(S[[i]],
                        par.settings = rasterVis::rasterTheme(region = RColorBrewer::brewer.pal(9, themes[i])),
                        margin=FALSE) +
                layer(sp.polygons(Poly, col = "orange", lwd = 2))
                }
        )

# print each layer, but specify the location within a layout scheme
print(PP[[1]], split=c(1, 1, 1, 3), more = TRUE)
print(PP[[2]], split=c(1, 2, 1, 3), more = TRUE)
print(PP[[3]], split=c(1, 3, 1, 3), more = FALSE)
### END



> On Apr 11, 2019, at 7:28 AM, Kristi Glover <kristi.glover at hotmail.com> wrote:
>
> He R users,
> I have been struggling to plot a boundary map over the raster maps. I tried using the following example, but the boundary map could not be displayed over the three raster maps.
> It works if we plot for a single raster. However when I want to plot the three maps using "levelplot" and add the boundary map it did not work.  I wanted to plot three raster same time because the "levelplot" so that we can compare the maps as they have only one legend.
>
> My example code is given below, do you have any suggestions?
>
>
> library(gridExtra)
>
> library(raster)
>
> library(sp)
>
> library(rasterVis)
>
> library(rgdal)
>
> library(maptools)
>
>
> boundary<- readShapeSpatial("boundrymap.shp")
>
>
> minTemp<-raster("minTemp.tif")
>
> maxTemp<-raster("maxTemp.tif")
>
> averageTemp<-raster("averageTemp.tif")
>
> Temp<-stack(minTemp,maxTemp,averageTemp)
>
>
> levelplot(Temp, layout=c(1,3))+ layer(sp.polygons(boundary, col = "yellow"))
>
> thanks
>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/






	[[alternative HTML version deleted]]


From btupper @end|ng |rom b|ge|ow@org  Thu Apr 11 17:43:35 2019
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Thu, 11 Apr 2019 11:43:35 -0400
Subject: [R] How to overlay a vector map (polygon) on raster maps?
In-Reply-To: <MWHPR0201MB34492D64C74F491A4B7498F7FA2F0@MWHPR0201MB3449.namprd02.prod.outlook.com>
References: <MWHPR0201MB3449A12CFBA9F8D9C1720F65FA2F0@MWHPR0201MB3449.namprd02.prod.outlook.com>
 <54621052-2672-490B-90C8-1BCE18E9428B@bigelow.org>
 <MWHPR0201MB34492D64C74F491A4B7498F7FA2F0@MWHPR0201MB3449.namprd02.prod.outlook.com>
Message-ID: <B441289B-32E1-45B9-B115-3BAB3448E0D6@bigelow.org>

Hi,

That's great topic to search on RSeek.org <http://rseek.org/>

https://rseek.org/?q=plot+multiple+rasters+with+one+legend <https://rseek.org/?q=plot+multiple+rasters+with+one+legend>

or to pose a question about on r-sig-geo

Cheers,
Ben

> On Apr 11, 2019, at 11:32 AM, Kristi Glover <kristi.glover at hotmail.com> wrote:
> 
> Dear Ben, 
> Thank you very much for the message. I run it and it produced three separate images with X and y Axis  and a legend for each image. I was thinking to plot all of these three images with a single legend and only X axis value at the bottom's image and y values for each image.  
> 
> I added the following code on your code
> grid.arrange(PP[[1]],PP[[2]],PP[[3]])
>  
> But, as I mentioned above, I can get three separate images with its own legend and X and Y axix
> Thanks,
> 
> From: Ben Tupper <btupper at bigelow.org>
> Sent: April 11, 2019 7:13 AM
> To: Kristi Glover
> Cc: r-help at r-project.org
> Subject: Re: [R] How to overlay a vector map (polygon) on raster maps?
>  
> Hi,
> 
> I think you want to build a levelplot object with polygon overlaid for each layer.  Like the link below shows but with the added layer per your example.  
> 
> https://oscarperpinan.github.io/rastervis/FAQ.html#several_rasters <https://oscarperpinan.github.io/rastervis/FAQ.html#several_rasters>
> 
> Also, you will get bucket loads of spatial-centric help using the r-sig-geo mailing list; check it out herehttps://stat.ethz.ch/mailman/listinfo/r-sig-geo <https://stat.ethz.ch/mailman/listinfo/r-sig-geo>.
> 
> Cheers,
> Ben
> 
> ### START
> library(sp)
> library(raster)
> library(rasterVis)
> library(RColorBrewer)
> 
> S <- raster::stack(system.file("external/rlogo.grd", package="raster"))
> 
> # make a polygon by shrinking the extent and casting object type
> Poly <- as(raster::extent(S) + c(15, -32, 25, -10), "SpatialPolygons")
> 
> # build the layers in a list, adding the polygon to each layer
> themes <- c("Reds", "Greens", "Blues")
> PP <- lapply(seq_len(nlayers(S)),
>         function(i) {
>                 levelplot(S[[i]], 
>                         par.settings = rasterVis::rasterTheme(region = RColorBrewer::brewer.pal(9, themes[i])),  
>                         margin=FALSE) + 
>                 layer(sp.polygons(Poly, col = "orange", lwd = 2))
>                 }
>         )
>         
> # print each layer, but specify the location within a layout scheme
> print(PP[[1]], split=c(1, 1, 1, 3), more = TRUE)
> print(PP[[2]], split=c(1, 2, 1, 3), more = TRUE)
> print(PP[[3]], split=c(1, 3, 1, 3), more = FALSE)
> ### END
> 
> 
> 
> > On Apr 11, 2019, at 7:28 AM, Kristi Glover <kristi.glover at hotmail.com> wrote:
> > 
> > He R users,
> > I have been struggling to plot a boundary map over the raster maps. I tried using the following example, but the boundary map could not be displayed over the three raster maps.
> > It works if we plot for a single raster. However when I want to plot the three maps using "levelplot" and add the boundary map it did not work.  I wanted to plot three raster same time because the "levelplot" so that we can compare the maps as they have only one legend.
> > 
> > My example code is given below, do you have any suggestions?
> > 
> > 
> > library(gridExtra)
> > 
> > library(raster)
> > 
> > library(sp)
> > 
> > library(rasterVis)
> > 
> > library(rgdal)
> > 
> > library(maptools)
> > 
> > 
> > boundary<- readShapeSpatial("boundrymap.shp")
> > 
> > 
> > minTemp<-raster("minTemp.tif")
> > 
> > maxTemp<-raster("maxTemp.tif")
> > 
> > averageTemp<-raster("averageTemp.tif")
> > 
> > Temp<-stack(minTemp,maxTemp,averageTemp)
> > 
> > 
> > levelplot(Temp, layout=c(1,3))+ layer(sp.polygons(boundary, col = "yellow"))
> > 
> > thanks
> > 
> > 
> >        [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> > and provide commented, minimal, self-contained, reproducible code.
> 
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org <http://www.bigelow.org/>
> 
> Ecological Forecasting: https://eco.bigelow.org/ <https://eco.bigelow.org/>
Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/






	[[alternative HTML version deleted]]


From btupper @end|ng |rom b|ge|ow@org  Thu Apr 11 18:15:44 2019
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Thu, 11 Apr 2019 12:15:44 -0400
Subject: [R] How to overlay a vector map (polygon) on raster maps?
In-Reply-To: <MWHPR0201MB344996FDEF3092FBD8B5C119FA2F0@MWHPR0201MB3449.namprd02.prod.outlook.com>
References: <MWHPR0201MB3449A12CFBA9F8D9C1720F65FA2F0@MWHPR0201MB3449.namprd02.prod.outlook.com>
 <54621052-2672-490B-90C8-1BCE18E9428B@bigelow.org>
 <MWHPR0201MB34492D64C74F491A4B7498F7FA2F0@MWHPR0201MB3449.namprd02.prod.outlook.com>
 <B441289B-32E1-45B9-B115-3BAB3448E0D6@bigelow.org>
 <MWHPR0201MB344996FDEF3092FBD8B5C119FA2F0@MWHPR0201MB3449.namprd02.prod.outlook.com>
Message-ID: <9CFBAE37-549E-4C80-974E-F6980CB68DE5@bigelow.org>

Hi,

It's best to keep all of the replies on the list - you will get better answers and leave a trail for others with similar questions to follow.  If you need more help, I strongly suggest that you start a fresh question on r-sig-geo.

I suppose you could try the panel argument to levelplot().  Using the panel argument will modify each raster - that is each rendering of elements of your raster stack - by performing what ever task you put in the panel function.  It's all a bit mysterious to me how it really works which is why I often gravitate toward the more obvious-to-me layering that the latticeExtra package provides with `levelplot(something) + layer(more stuff)`. 

library(rasterVis)
library(sp)

set.seed(10)
x = runif(2000000, -0.0005, .9875)
y = runif(2000000, -0.0008, .99)
xmat = matrix(x, nrow = 500)
ymat = matrix(x, nrow = 500)
xras = raster(xmat)
yras = raster(ymat)
min_ = min(minValue(xras), minValue(yras))
max_ = max(maxValue(xras), maxValue(yras))
r.range = c(min_, max_)
Poly <- as(raster::extent(xras) + c(.15, -.32, .25, -.10), "SpatialPolygons")
levelplot(stack(xras, yras), 
	col.regions = rev(rainbow(99, start=0, end=1)), 
	colorkey = list(space = "bottom"),
	panel = function(...){
		panel.levelplot(...)
		sp.polygons(Poly, col = 'black', lwd = 3)
		}
	)

Cheers,
Ben



> On Apr 11, 2019, at 11:50 AM, Kristi Glover <kristi.glover at hotmail.com> wrote:
> 
> Thank you Ben for the link. It has lots of the information. One of the example bellow, here how can we overlay a polygon (let's say river map) on the two raster images? The two raster images are of Maximum and Minimum temperature of a specific area. 
> library(rasterVis)
> 
> set.seed
> (10)
> 
> x 
> = runif(2000000, -0.0005, .9875)
> 
> y 
> = runif(2000000, -0.0008, .99)
> 
> xmat 
> = matrix(x, nrow = 500)
> 
> ymat 
> = matrix(x, nrow = 500)
> 
> xras 
> = raster(xmat)
> 
> yras 
> = raster(ymat)
> 
> min_ 
> = min(minValue(xras), minValue(yras))
> 
> max_ 
> = max(maxValue(xras), maxValue(yras))
> 
> r.range 
> = c(min_, max_)
> 
> 
> levelplot
> (stack(xras, yras), col.regions = rev(rainbow(99, start=0, end=1)), colorkey = list(space = "bottom"))
> thank you so much for your help.
> 
> 
> 
> From: Ben Tupper <btupper at bigelow.org>
> Sent: April 11, 2019 9:43 AM
> To: Kristi Glover
> Cc: r-help at r-project.org
> Subject: Re: [R] How to overlay a vector map (polygon) on raster maps?
>  
> Hi,
> 
> That's great topic to search on RSeek.org
> 
> https://rseek.org/?q=plot+multiple+rasters+with+one+legend
> 
> or to pose a question about on r-sig-geo
> 
> Cheers,
> Ben
> 
>> On Apr 11, 2019, at 11:32 AM, Kristi Glover <kristi.glover at hotmail.com> wrote:
>> 
>> Dear Ben, 
>> Thank you very much for the message. I run it and it produced three separate images with X and y Axis  and a legend for each image. I was thinking to plot all of these three images with a single legend and only X axis value at the bottom's image and y values for each image.  
>> 
>> I added the following code on your code
>> grid.arrange(PP[[1]],PP[[2]],PP[[3]])
>>  
>> But, as I mentioned above, I can get three separate images with its own legend and X and Y axix
>> Thanks,
>> 
>> From: Ben Tupper <btupper at bigelow.org>
>> Sent: April 11, 2019 7:13 AM
>> To: Kristi Glover
>> Cc: r-help at r-project.org
>> Subject: Re: [R] How to overlay a vector map (polygon) on raster maps?
>>  
>> Hi,
>> 
>> I think you want to build a levelplot object with polygon overlaid for each layer.  Like the link below shows but with the added layer per your example.  
>> 
>> https://oscarperpinan.github.io/rastervis/FAQ.html#several_rasters
>> 
>> Also, you will get bucket loads of spatial-centric help using the r-sig-geo mailing list; check it out herehttps://stat.ethz.ch/mailman/listinfo/r-sig-geo.
>> 
>> Cheers,
>> Ben
>> 
>> ### START
>> library(sp)
>> library(raster)
>> library(rasterVis)
>> library(RColorBrewer)
>> 
>> S <- raster::stack(system.file("external/rlogo.grd", package="raster"))
>> 
>> # make a polygon by shrinking the extent and casting object type
>> Poly <- as(raster::extent(S) + c(15, -32, 25, -10), "SpatialPolygons")
>> 
>> # build the layers in a list, adding the polygon to each layer
>> themes <- c("Reds", "Greens", "Blues")
>> PP <- lapply(seq_len(nlayers(S)),
>>         function(i) {
>>                 levelplot(S[[i]], 
>>                         par.settings = rasterVis::rasterTheme(region = RColorBrewer::brewer.pal(9, themes[i])),  
>>                         margin=FALSE) + 
>>                 layer(sp.polygons(Poly, col = "orange", lwd = 2))
>>                 }
>>         )
>>         
>> # print each layer, but specify the location within a layout scheme
>> print(PP[[1]], split=c(1, 1, 1, 3), more = TRUE)
>> print(PP[[2]], split=c(1, 2, 1, 3), more = TRUE)
>> print(PP[[3]], split=c(1, 3, 1, 3), more = FALSE)
>> ### END
>> 
>> 
>> 
>> > On Apr 11, 2019, at 7:28 AM, Kristi Glover <kristi.glover at hotmail.com> wrote:
>> > 
>> > He R users,
>> > I have been struggling to plot a boundary map over the raster maps. I tried using the following example, but the boundary map could not be displayed over the three raster maps.
>> > It works if we plot for a single raster. However when I want to plot the three maps using "levelplot" and add the boundary map it did not work.  I wanted to plot three raster same time because the "levelplot" so that we can compare the maps as they have only one legend.
>> > 
>> > My example code is given below, do you have any suggestions?
>> > 
>> > 
>> > library(gridExtra)
>> > 
>> > library(raster)
>> > 
>> > library(sp)
>> > 
>> > library(rasterVis)
>> > 
>> > library(rgdal)
>> > 
>> > library(maptools)
>> > 
>> > 
>> > boundary<- readShapeSpatial("boundrymap.shp")
>> > 
>> > 
>> > minTemp<-raster("minTemp.tif")
>> > 
>> > maxTemp<-raster("maxTemp.tif")
>> > 
>> > averageTemp<-raster("averageTemp.tif")
>> > 
>> > Temp<-stack(minTemp,maxTemp,averageTemp)
>> > 
>> > 
>> > levelplot(Temp, layout=c(1,3))+ layer(sp.polygons(boundary, col = "yellow"))
>> > 
>> > thanks
>> > 
>> > 
>> >        [[alternative HTML version deleted]]
>> > 
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> 
>> Ben Tupper
>> Bigelow Laboratory for Ocean Sciences
>> 60 Bigelow Drive, P.O. Box 380
>> East Boothbay, Maine 04544
>> http://www.bigelow.org
>> 
>> Ecological Forecasting: https://eco.bigelow.org/
> 
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
> 
> Ecological Forecasting: https://eco.bigelow.org/

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/


From @m|t@c@03 @end|ng |rom gm@||@com  Thu Apr 11 07:53:03 2019
From: @m|t@c@03 @end|ng |rom gm@||@com (Amit Govil)
Date: Thu, 11 Apr 2019 13:53:03 +0800
Subject: [R] Unable to read csv files with comma in values
In-Reply-To: <CAGxFJbQc3Mj2TGpqymk+XvsqE0V+PesyVVAsXOTjVASnGqLGKw@mail.gmail.com>
References: <CAPf9UMoEpz4GDPJuDRO=ugSHybPreA3dwnpZD_AK2BbLbptV4w@mail.gmail.com>
 <4f76546b-f376-cb75-80c3-14126d2dcfff@gmail.com>
 <CAGxFJbRfKdf76opwL2er=crJQxFxSvx9yE3K2edaLQK+1m9owg@mail.gmail.com>
 <CAGxFJbRSYpWmh=zYkQ1kOe3tspMpL6-KkWE0xREjgKzEsJkAdw@mail.gmail.com>
 <CAGxFJbQc3Mj2TGpqymk+XvsqE0V+PesyVVAsXOTjVASnGqLGKw@mail.gmail.com>
Message-ID: <CAPf9UMrwM=YgAKyFmkqrGCF689ZXFpK4x0_Y7U43HjQ3OvzsnA@mail.gmail.com>

Sorry for reverting back late (as I had some issues with my laptop) and
thank you Bert and Duncan for your suggestions and approach. I'll try the
solutions proposed and get back to you.

Thanks
Amit

On Mon, Apr 8, 2019 at 3:30 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> ... and if anyone cares, here's a way to do it using vectorization (no
> loops) by working only on the subvector containing bracketed text  and
> using the brackets to break up the strings into 3 separate pieces,
> replacing the commas in the middle piece with dashes, and then
> reassembling. Quite clumsy, so a better solution is still needed, but here
> it is:
>
> txt <-c("Sam, [HadoopAnalyst, DBA, Developer], R46443 ","Jan, DBA, R101",
>         "Mary, [Stats, Designer, R], t14")
> wh <- grep("\\[.+\\]",txt)
> txt1 <- sub("(.+), *\\[.+","\\1",txt[wh]) ## before "["
> txt2 <- gsub(" *, *","-",sub(".+(\\[.+\\]).+","\\1",txt[wh])) ##
> bracketed part
> txt3 <- sub(".*\\], *(.+?) *$","\\1",txt[wh]) ## after "]"
> txt[wh]<- paste(txt1, txt2, txt3, sep = ", ")
>
> > txt
> [1] "Sam, [HadoopAnalyst-DBA-Developer], R46443"
> [2] "Jan, DBA, R101"
> [3] "Mary, [Stats-Designer-R], t14"
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, Apr 7, 2019 at 10:35 AM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
>> ... and here's another perhaps simpler, perhaps more efficient (??) way
>> of doing it using strsplit().Note that it uses the fixed field position, 2,
>> of the bracketed roles. Adjust as needed.
>>
>> A better solution would be a regex that avoids the loops (here, the
>> sapply) altogether, but I don't know how to do this. Maybe someone cleverer
>> will offer such a solution.
>>
>> txt <-c("Sam, [HadoopAnalyst, DBA, Developer], R46443 ","Jan, DBA, R101",
>>         "Mary, [Stats, Designer, R], t14")
>>
>> wh <-  grep("\\[.+\\]", txt)
>> spl <-  strsplit(txt[wh], "\\[|\\]")
>> txt[wh] <-  sapply(spl, function(y)
>>    paste0(y[1], gsub(" *, *","-", y[2]), y[-(1:2)]))
>>
>> > txt
>> [1] "Sam, HadoopAnalyst-DBA-Developer, R46443 "
>> [2] "Jan, DBA, R101"
>> [3] "Mary, Stats-Designer-R, t14"
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sun, Apr 7, 2019 at 9:55 AM Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>>
>>> (Note: This follows an earlier mistaken reply just to Duncan)
>>>
>>> Multiple "amens!" to Duncan's comments...
>>>
>>> However:
>>>
>>> Here is a start at my interpretation of how to do what you want. Note
>>> first that your "example" listed 4 fields in the line, but you showed only
>>> 3. I modified your example for 3 text fields, only one of which has
>>> brackets ([...]) in it I assume. Here is a little example of how to use
>>> regex's to replace the commas within the brackets by "-", which would
>>> presumably then allow you to easily convert the text into a data frame e.g.
>>> using textConnection() and read.csv. Obviously, if this is not what you
>>> meant, read no further.
>>>
>>> ##Example
>>> txt <-c("Sam, [HadoopAnalyst, DBA, Developer], R46443 ","Jan, DBA, R101",
>>>         "Mary, [Stats, Designer, R], t14")
>>>
>>> wh <- grep("\\[.+\\]",txt)  ## which records need to be modified?
>>> fixup <- gsub(" *, *","-",sub(".+(\\[.+\\]).+","\\1",txt[wh])) ##
>>> bracketed expressions, changing "," to "-"
>>>
>>> ## Unfortunately, the "replacement" argument in sub() is not vectorized,
>>> se we need a loop:
>>>
>>> for(i in wh) txt[wh[i]] <- sub("\\[.+\\]",fixup[i],txt[wh[i]]) ##
>>> replace original bracketed text with fixed up bracketed text
>>>
>>> > txt
>>> [1] "Sam, [HadoopAnalyst-DBA-Developer], R46443 "
>>> [2] "Jan, DBA, R101"
>>> [3] "Mary, [HadoopAnalyst-DBA-Developer], t14"
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Sun, Apr 7, 2019 at 9:00 AM Duncan Murdoch <murdoch.duncan at gmail.com>
>>> wrote:
>>>
>>>> On 06/04/2019 10:03 a.m., Amit Govil wrote:
>>>> > Hi,
>>>> >
>>>> > I have a bunch of csv files to read in R. I'm unable to read them
>>>> correctly
>>>> > because in some of the files, there is a column ("Role") which has
>>>> comma in
>>>> > the values.
>>>> >
>>>> > Sample data:
>>>> >
>>>> > User, Role, Rule, GAPId
>>>> > Sam, [HadoopAnalyst, DBA, Developer], R46443
>>>> >
>>>> > I'm trying to play with the below code but it doesnt work:
>>>>
>>>> Since you didn't give a reproducible example, you should at least say
>>>> what "doesn't work" means.
>>>>
>>>> But here's some general advice:  if you want to debug code, don't write
>>>> huge expressions like the chain of functions below, put things in
>>>> temporary variables and make sure you get what you were expecting at
>>>> each stage.
>>>>
>>>> Instead of
>>>> >
>>>> > files <- list.files(pattern='.*REDUNDANT(.*).csv$')
>>>> >
>>>> > tbl <- sapply(files, function(f) {
>>>> >    gsub('\\[|\\]', '"', readLines(f)) %>%
>>>> >      read.csv(text = ., check.names = FALSE)
>>>> > }) %>%
>>>> >    bind_rows(.id = "id") %>%
>>>> >    select(id, User, Rule) %>%
>>>> >    distinct()
>>>>
>>>> try
>>>>
>>>>
>>>> files <- list.files(pattern='.*REDUNDANT(.*).csv$')
>>>>
>>>> tmp1 <- sapply(files, function(f) {
>>>>    gsub('\\[|\\]', '"', readLines(f)) %>%
>>>>      read.csv(text = ., check.names = FALSE)
>>>> })
>>>>
>>>> tmp2 <- tmp1 %>% bind_rows(.id = "id")
>>>>
>>>> tmp3 <- tmp2 %>% select(id, User, Rule)
>>>>
>>>> tbl <- tmp3 %>% distinct()
>>>>
>>>> (You don't need pipes here, but it will make it easier to put the giant
>>>> expression back together at the end.)
>>>>
>>>> Then look at tmp1, tmp2, tmp3 as well as tbl to see where things went
>>>> wrong.
>>>>
>>>> Duncan Murdoch
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>

	[[alternative HTML version deleted]]


From cr|@u@1 @end|ng |rom ||ve@|t  Thu Apr 11 18:47:21 2019
From: cr|@u@1 @end|ng |rom ||ve@|t (Alessandro Vesci)
Date: Thu, 11 Apr 2019 16:47:21 +0000
Subject: [R] Multi step ahead backtest
Message-ID: <AM6PR01MB58949743D154BB675E59B9A1E32F0@AM6PR01MB5894.eurprd01.prod.exchangelabs.com>

Hi all, this is my first post so sorry if there's something wrong.
I'm doing a project for university, and I should have to do the rolling windows forecasting for 2 or more step ahead.
Does anyone know a code (or a cycle "for") to overpass the problem of "n.ahead=1"? Thanks a lot for who will answer.

	[[alternative HTML version deleted]]


From kendej@n @end|ng |rom y@hoo@|r  Thu Apr 11 17:47:10 2019
From: kendej@n @end|ng |rom y@hoo@|r (kende jan)
Date: Thu, 11 Apr 2019 15:47:10 +0000 (UTC)
Subject: [R] Bifactor model and infit statistics?
References: <1969988708.143508.1554997630897.ref@mail.yahoo.com>
Message-ID: <1969988708.143508.1554997630897@mail.yahoo.com>


Goodafternoon, 

I amcurrently in the process of calibrating an item bank using a GPCM model. So, amI right to assume that the bifactor model allows me to work with my generalfactor by assimilating it to a one-factor model, without taking into account groupfactors? That is, I can estimate my item parameters from my factor loadings onthe general factor only?

If so, Ihave some questions about evaluating the fit of my model. The calculation of infitstatistics is specific to unidimensional models. Can I compute infit statisticsusing the general factor or do I have to do this separately for each of the groupfactors? Or is there a more appropriate method to evaluate the fit of my modelwhen calibration an item bank using a GPCM model?

Thank youin advance.


	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Apr 11 23:53:41 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 11 Apr 2019 14:53:41 -0700
Subject: [R] Bifactor model and infit statistics?
In-Reply-To: <1969988708.143508.1554997630897@mail.yahoo.com>
References: <1969988708.143508.1554997630897.ref@mail.yahoo.com>
 <1969988708.143508.1554997630897@mail.yahoo.com>
Message-ID: <CAGxFJbQKmx8uTbQAjtbvxu-pX7_StfHGNknAV_kp1tSfwh-3gw@mail.gmail.com>

This is essentially a statistics question, which are generally off topic
here. This list is about the R programming language. Try
stats.stackexchange.com instead for your question. To see what R offers
once you've decided what to do, see: https://cran.r-project.org/web/views/
  as well as searching at rseek.org  .


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Apr 11, 2019 at 2:23 PM kende jan via R-help <r-help at r-project.org>
wrote:

>
> Goodafternoon,
>
> I amcurrently in the process of calibrating an item bank using a GPCM
> model. So, amI right to assume that the bifactor model allows me to work
> with my generalfactor by assimilating it to a one-factor model, without
> taking into account groupfactors? That is, I can estimate my item
> parameters from my factor loadings onthe general factor only?
>
> If so, Ihave some questions about evaluating the fit of my model. The
> calculation of infitstatistics is specific to unidimensional models. Can I
> compute infit statisticsusing the general factor or do I have to do this
> separately for each of the groupfactors? Or is there a more appropriate
> method to evaluate the fit of my modelwhen calibration an item bank using a
> GPCM model?
>
> Thank youin advance.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From epurdom @end|ng |rom @t@t@berke|ey@edu  Fri Apr 12 02:38:55 2019
From: epurdom @end|ng |rom @t@t@berke|ey@edu (Elizabeth Purdom)
Date: Thu, 11 Apr 2019 17:38:55 -0700
Subject: [R] Question about behavior of sample.kind in set.seed (R 3.6)
Message-ID: <F890ABE6-F389-416A-A62A-1C824FAE346B@stat.berkeley.edu>

Hello,

I am trying to update a package for the upcoming release of R, and my unit tests are affected by the change in the sample. I understand that to reproduce the old sampling, I need to set sample.kind=?Rounding? in RNGkind or set.seed. But I am confused by the behavior of the sample.kind argument in set.seed, as it doesn?t seem to change my results. 

In particular, I was trying to understand what happens if you make a call to set.seed within a function to the global environment. So I set up a test as follows:

###Test set.seed
f<-function(n,sample.kind){   #="Rounding" or "Rejection"
	cat("RNG at beginning\n")
	print(RNGkind())
	# RNGkind(sample.kind=sample.kind)
	# cat("RNG at after set\n")
	# print(RNGkind())
	set.seed(23,sample.kind=sample.kind)
	cat("RNG at after set seed\n")
	print(RNGkind())
	sample(1:400000,size=n,replace=TRUE)
}

RNGkind(sample.kind="Rejection?)
print(RNGkind())
n<-1000000
y<-f(n,"Rounding?)
print(RNGkind())
y2<-f(n,"Rejection?)
print(RNGkind())
all(y==y2)

However, it didn?t do anything:
> RNGkind(sample.kind="Rejection")
> print(RNGkind())
[1] "Mersenne-Twister" "Inversion"        "Rejection"       
> n<-1000000
> y<-f(n,"Rounding")
RNG at beginning
[1] "Mersenne-Twister" "Inversion"        "Rejection"       
RNG at after set seed
[1] "Mersenne-Twister" "Inversion"        "Rejection"       
Warning message:
In set.seed(23, sample.kind = sample.kind) :
 non-uniform 'Rounding' sampler used
> print(RNGkind())
[1] "Mersenne-Twister" "Inversion"        "Rejection"       
> y2<-f(n,"Rejection")
RNG at beginning
[1] "Mersenne-Twister" "Inversion"        "Rejection"       
RNG at after set seed
[1] "Mersenne-Twister" "Inversion"        "Rejection"       
> print(RNGkind())
[1] "Mersenne-Twister" "Inversion"        "Rejection"       
> all(y==y2)
[1] TRUE

If I run the same test with calls to RNGkind, however, it does change the method (and I discovered in answer to my question, it appears to change the global method, which is an unfortunate fact for what I am trying to do).

###Test RNGkind
f<-function(n,sample.kind){   #="Rounding" or "Rejection"
	cat("RNG at beginning\n")
	print(RNGkind())
	RNGkind(sample.kind=sample.kind)
	cat("RNG at after set\n")
	print(RNGkind())
	set.seed(23)
	cat("RNG at after set seed\n")
	print(RNGkind())
	sample(1:400000,size=n,replace=TRUE)
}

RNGkind(sample.kind="Rejection?)
print(RNGkind())
n<-1000000
y<-f(n,"Rounding?)
print(RNGkind())
y2<-f(n,"Rejection?)
print(RNGkind())
all(y==y2)

> RNGkind(sample.kind="Rejection")
> print(RNGkind())
[1] "Mersenne-Twister" "Inversion"        "Rejection"       
> n<-1000000
> y<-f(n,"Rounding")
RNG at beginning
[1] "Mersenne-Twister" "Inversion"        "Rejection"       
RNG at after set
[1] "Mersenne-Twister" "Inversion"        "Rounding"        
RNG at after set seed
[1] "Mersenne-Twister" "Inversion"        "Rounding"        
Warning message:
In RNGkind(sample.kind = sample.kind) : non-uniform 'Rounding' sampler used
> print(RNGkind())
[1] "Mersenne-Twister" "Inversion"        "Rounding"        
> y2<-f(n,"Rejection")
RNG at beginning
[1] "Mersenne-Twister" "Inversion"        "Rounding"        
RNG at after set
[1] "Mersenne-Twister" "Inversion"        "Rejection"       
RNG at after set seed
[1] "Mersenne-Twister" "Inversion"        "Rejection"       
> print(RNGkind())
[1] "Mersenne-Twister" "Inversion"        "Rejection"       
> all(y==y2)
[1] FALSE

So clearly I should use RNGkind to change it, but what is the argument actually doing in set.seed?

Thanks,
Elizabeth Purdom

> sessionInfo()
R version 3.6.0 alpha (2019-04-09 r76363)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: OS X El Capitan 10.11.6

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] BiocManager_1.30.4 compiler_3.6.0     tools_3.6.0   

From Rom@n@M|nguez @end|ng |rom uc|m@e@  Thu Apr 11 12:54:23 2019
From: Rom@n@M|nguez @end|ng |rom uc|m@e@ (Roman Minguez Salido)
Date: Thu, 11 Apr 2019 10:54:23 +0000
Subject: [R] [R-pkgs] Releasing new package on CRAN
Message-ID: <DB7PR01MB442741969CBAE86F116AC225E32F0@DB7PR01MB4427.eurprd01.prod.exchangelabs.com>

Dear R-users:

First, we apologize for possible crossed messages.

It is a pleasure for us to have the opportunity to present a new R package, called 'spsur' available in  https://cran.r-project.org/web/packages/spsur/index.html

This is a specific R package for the estimation of Spatial Seemingly Unrelated Regression models by maximum likelihood or instrumental variable procedures. Moreover, 'spsur' implements a collection of Lagrange Multipliers and Likelihood Ratios to test for misspecifications in SUR models.

If you would like, you can install 'spsur' directly from CRAN repository. There you will find also a vignette including some examples, available also in https://cran.r-project.org/web/packages/spsur/vignettes/spsur-vignette.html

This is the first version of 'spsur'. We want to improve it in the future, therefore, any suggestions or comments related to the package would be very welcome. Your expertise and your feedback would be very important for us.

We hope you find this package interesting for your research and empirical work.

Thanks in advance for your feedback,

Fernando L?pez, Rom?n M?nguez and Jes?s Mur.



	[[alternative HTML version deleted]]


-------------- next part --------------
_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From r@i@1290 m@iii@g oii @im@com  Thu Apr 11 23:57:38 2019
From: r@i@1290 m@iii@g oii @im@com (r@i@1290 m@iii@g oii @im@com)
Date: Thu, 11 Apr 2019 21:57:38 +0000 (UTC)
Subject: [R] Creating a mean line plot
References: <958032223.2037452.1555019858964.ref@mail.yahoo.com>
Message-ID: <958032223.2037452.1555019858964@mail.yahoo.com>

Hi there,
I am trying to create a mean line plot that shows the mean of a series of separate line plots that correspond to two climate models. Let's first try getting the mean of two line plots. To create the separate line plots, here is what I did to set up the x and y axis variables:

####Getting cumulative emissions data for x-axis: 1-dimensional ####

#For CanESM model#

ncfname <- "cumulative_emissions_1pctCO2.nc"
Model1 <- nc_open(ncfname)
get <- ncvar_get(Model1, "cum_co2_emi-CanESM2") ? ? #units of terratones of carbon (TtC) for x-axis (140 values)
#For IPSL LR Model#
#Getting cumulative emissions data for x-axis?IPSL LR 1pctCO2?IPSL <- ncvar_get(Model1, "cum_co2_emi-IPSL-CM5A-LR") ? ? #units of terratones of carbon (TtC) for x-axis (140 values)

############################################################################################################

#####Getting precipitation data for y-axis - these are 3-dimensional####

#For CanESM2 model#
Model2 <- brick("MaxPrecCCCMACanESM21pctCO2.nc", var="onedaymax")


#For IPSL LR Model#
Model10 <- brick("MaxPrecIPSLIPSL-CM5A-LR1pctCO2.nc", var="onedaymax")
#############################################################################################################
To create plots for a specific location:
lonlat <- cbind(103,3) ? ? ? ?? #specifies a specific longitude and latitude
Hope2 <- extract(Model2,lonlat) ? ?? #CanESM2
Hope6 <- extract(Model10,lonlat) ? #start IPSL CM5A LR
plot(get,Hope2, type="l",col="green", lwd="3", xlab="Cumulative CO2 emissions (TtC)", ylab="One-day maximum precipitation (mm/day)", main="One-day maximum precipitation for random location for 1pctCO2 scenario")
lines(IPSL, Hope6, type="l", lwd="3", col="green")
#############################################################################################################
So, the idea would be to create a plot that shows the mean of these two plots. Given what I showed above, how should I go about creating the mean of these two green line plots? Would you have to get the mean of the x-values, and then obtain the mean of the y-values, and then plot these?
Thanks, and any help would be greatly appreciated!
	[[alternative HTML version deleted]]


From @|mon @end|ng |rom berreb|@net  Fri Apr 12 04:46:19 2019
From: @|mon @end|ng |rom berreb|@net (Simon Berrebi)
Date: Thu, 11 Apr 2019 22:46:19 -0400
Subject: [R] Are fitted.values available in pglm?
Message-ID: <65B6EF72-1FD2-4B20-A475-40F5F87DDA85@berrebi.net>

Hello everyone,

I am using the pglm function in R to fit a Poisson fixed-effects model. According to the documentation <https://cran.r-project.org/web/packages/pglm/pglm.pdf>, the pglm object should have fitted.values. However, fitted.values(mymodel) returns "NULL".

When I run AIC(mymodel) the AIC is followed by "attr(,"fitted.values")" and a long list of number. I have included an example below and attached a text file with the output.

Are these fitted values? If so, is there a way to obtain them directly? Can I also get fitted-values based on a synthetic dataset (i.e. predict())?

install.packages("pglm")
library(pglm)

data("PatentsRDUS", package="pglm")


     mymodel <- pglm(patents ~   log(rd)  + as.numeric(year)+ I(log(capital72)*as.numeric(year)) , PatentsRDUS,
     family = poisson(link=log), model = "within", index = c("cusip", "year"))

     fitted.values(mymodel)
     AIC(mymodel)

Cordially,
?
Dr. Simon J Berrebi
Postdoctoral Fellow 
Civil and Environmental Engineering
Georgia Institute of Technology









From bgunter@4567 @end|ng |rom gm@||@com  Fri Apr 12 16:44:36 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 12 Apr 2019 07:44:36 -0700
Subject: [R] Are fitted.values available in pglm?
In-Reply-To: <65B6EF72-1FD2-4B20-A475-40F5F87DDA85@berrebi.net>
References: <65B6EF72-1FD2-4B20-A475-40F5F87DDA85@berrebi.net>
Message-ID: <CAGxFJbQ0THXrKPzRUeaP=j9yopm4h80QFTTgKG-MeTg5nQw7Cg@mail.gmail.com>

?fitted
?predict
## This is what one usually does, but I have not checked pglm.

You also need to get friendly with ?str

... and probably also spend time with an R tutorial or two to become
familiar with R modeling conventions.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Apr 12, 2019 at 7:35 AM Simon Berrebi <simon at berrebi.net> wrote:

> Hello everyone,
>
> I am using the pglm function in R to fit a Poisson fixed-effects model.
> According to the documentation <
> https://cran.r-project.org/web/packages/pglm/pglm.pdf>, the pglm object
> should have fitted.values. However, fitted.values(mymodel) returns "NULL".
>
> When I run AIC(mymodel) the AIC is followed by "attr(,"fitted.values")"
> and a long list of number. I have included an example below and attached a
> text file with the output.
>
> Are these fitted values? If so, is there a way to obtain them directly?
> Can I also get fitted-values based on a synthetic dataset (i.e. predict())?
>
> install.packages("pglm")
> library(pglm)
>
> data("PatentsRDUS", package="pglm")
>
>
>      mymodel <- pglm(patents ~   log(rd)  + as.numeric(year)+
> I(log(capital72)*as.numeric(year)) , PatentsRDUS,
>      family = poisson(link=log), model = "within", index = c("cusip",
> "year"))
>
>      fitted.values(mymodel)
>      AIC(mymodel)
>
> Cordially,
> ?
> Dr. Simon J Berrebi
> Postdoctoral Fellow
> Civil and Environmental Engineering
> Georgia Institute of Technology
>
>
>
>
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Fri Apr 12 17:47:07 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Fri, 12 Apr 2019 18:47:07 +0300
Subject: [R] Creating a mean line plot
In-Reply-To: <958032223.2037452.1555019858964@mail.yahoo.com>
References: <958032223.2037452.1555019858964.ref@mail.yahoo.com>
 <958032223.2037452.1555019858964@mail.yahoo.com>
Message-ID: <CAGgJW766s7r3NxpScyhJfkRF6tdAutnOzDEHEUrfVY8rE76dxA@mail.gmail.com>

I don't have your data. Are the x-values the same in both plots?
Does this example cover the situation?

f1 <- function(x) { x^3 - 2 }
f2 <- function(x) { 2 - x^2 }

xV <- seq(from=0,to=2,length=50)
y1 <- f1(xV)
y2 <- f2(xV)
y3 <- .5*(y1+y2)
plot(x=xV,y=y1,col="blue",lwd=2,type='l',xlab="x",ylab="y")
lines(x=xV,y=y2,col="green",lwd=2)
lines(x=xV,y=y3,col="red",lwd=2)
legend("topleft",legend=c("y1","y2","mean"),col=c("blue","green","red"),lwd=rep(2,3))




On Fri, Apr 12, 2019 at 5:34 PM rain1290--- via R-help <r-help at r-project.org>
wrote:

> Hi there,
> I am trying to create a mean line plot that shows the mean of a series of
> separate line plots that correspond to two climate models. Let's first try
> getting the mean of two line plots. To create the separate line plots, here
> is what I did to set up the x and y axis variables:
>
> ####Getting cumulative emissions data for x-axis: 1-dimensional ####
>
> #For CanESM model#
>
> ncfname <- "cumulative_emissions_1pctCO2.nc"
> Model1 <- nc_open(ncfname)
> get <- ncvar_get(Model1, "cum_co2_emi-CanESM2")     #units of terratones
> of carbon (TtC) for x-axis (140 values)
> #For IPSL LR Model#
> #Getting cumulative emissions data for x-axis IPSL LR 1pctCO2 IPSL <-
> ncvar_get(Model1, "cum_co2_emi-IPSL-CM5A-LR")     #units of terratones of
> carbon (TtC) for x-axis (140 values)
>
>
> ############################################################################################################
>
> #####Getting precipitation data for y-axis - these are 3-dimensional####
>
> #For CanESM2 model#
> Model2 <- brick("MaxPrecCCCMACanESM21pctCO2.nc", var="onedaymax")
>
>
> #For IPSL LR Model#
> Model10 <- brick("MaxPrecIPSLIPSL-CM5A-LR1pctCO2.nc", var="onedaymax")
>
> #############################################################################################################
> To create plots for a specific location:
> lonlat <- cbind(103,3)          #specifies a specific longitude and
> latitude
> Hope2 <- extract(Model2,lonlat)      #CanESM2
> Hope6 <- extract(Model10,lonlat)   #start IPSL CM5A LR
> plot(get,Hope2, type="l",col="green", lwd="3", xlab="Cumulative CO2
> emissions (TtC)", ylab="One-day maximum precipitation (mm/day)",
> main="One-day maximum precipitation for random location for 1pctCO2
> scenario")
> lines(IPSL, Hope6, type="l", lwd="3", col="green")
>
> #############################################################################################################
> So, the idea would be to create a plot that shows the mean of these two
> plots. Given what I showed above, how should I go about creating the mean
> of these two green line plots? Would you have to get the mean of the
> x-values, and then obtain the mean of the y-values, and then plot these?
> Thanks, and any help would be greatly appreciated!
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bie@ve@idozom@ m@iii@g oii gm@ii@com  Fri Apr 12 18:50:24 2019
From: bie@ve@idozom@ m@iii@g oii gm@ii@com (bie@ve@idozom@ m@iii@g oii gm@ii@com)
Date: Fri, 12 Apr 2019 16:50:24 +0000 (UTC)
Subject: [R] Help for coding
References: <1660961647.2367522.1555087824392.ref@mail.yahoo.com>
Message-ID: <1660961647.2367522.1555087824392@mail.yahoo.com>

Dear all,
I am trying to write the script to calculate the mean and the standard deviation without using the functions mean and standard deviations since morning. Someone can help

These scripts below are what i did but when i run and check with the function mean and standard deviation it is not the same result
ind<-1:number of observations
Mean<-(1/number of observations*sum(Variable*ind))
Standard<-(1/Number of observations-1*sum(Variable - ((1/1312*sum(Variable*ind)))))

Thanks


	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Apr 12 19:12:27 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 12 Apr 2019 10:12:27 -0700
Subject: [R] Are fitted.values available in pglm?
In-Reply-To: <339BBA1B-F4A7-4776-85AE-364C6BF8FBA9@berrebi.net>
References: <65B6EF72-1FD2-4B20-A475-40F5F87DDA85@berrebi.net>
 <CAGxFJbQ0THXrKPzRUeaP=j9yopm4h80QFTTgKG-MeTg5nQw7Cg@mail.gmail.com>
 <339BBA1B-F4A7-4776-85AE-364C6BF8FBA9@berrebi.net>
Message-ID: <CAGxFJbT38QdJ1rP2c35a9LUaUMqJ2LDvcAS6Bt72da5kq5-wug@mail.gmail.com>

?fitted   Read and follow.

As I said, you appear to need to spend time with a tutorial. I do not
provide this service, though others may.

-- Bert


On Fri, Apr 12, 2019 at 10:07 AM Simon Berrebi <simon at berrebi.net> wrote:

> Thank you Bert,
>
> I wasn?t aware of ?str. The only mention of fitted-values is:
>
>  $ maximum    : atomic [1:1] -9824
>   ..- attr(*, "fitted.values")= num [1:3460] 1.39 1.3 1.3 1.32 1.27 ...
>
> When I try attr(mymodel$maximum,  ?fitted.values?), I get the same results
> as  attr(AIC(mymodel),  ?fitted.values?), which is a list of number
> starting with (1.39 1.3 1.3 1.32 1.27 ?). I don?t see how these can be
> fitted values for the response variable, patents, which are larger numbers
> (30, 3, 48, 1, 2, 32, ?). Is this output not supped to represent the fitted
> values for patents?
>
> Another way to obtain fitted values would be using residuals.?pglm also
> includes residuals in its list of elements. However, str(mymodel) does not
> mention residuals. Does that mean it?s just not there?
>
> - Simon
>
> On Apr 12, 2019, at 10:44 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> ?fitted
> ?predict
> ## This is what one usually does, but I have not checked pglm.
>
> You also need to get friendly with ?str
>
> ... and probably also spend time with an R tutorial or two to become
> familiar with R modeling conventions.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Apr 12, 2019 at 7:35 AM Simon Berrebi <simon at berrebi.net> wrote:
>
>> Hello everyone,
>>
>> I am using the pglm function in R to fit a Poisson fixed-effects model.
>> According to the documentation <
>> https://cran.r-project.org/web/packages/pglm/pglm.pdf>, the pglm object
>> should have fitted.values. However, fitted.values(mymodel) returns "NULL".
>>
>> When I run AIC(mymodel) the AIC is followed by "attr(,"fitted.values")"
>> and a long list of number. I have included an example below and attached a
>> text file with the output.
>>
>> Are these fitted values? If so, is there a way to obtain them directly?
>> Can I also get fitted-values based on a synthetic dataset (i.e. predict())?
>>
>> install.packages("pglm")
>> library(pglm)
>>
>> data("PatentsRDUS", package="pglm")
>>
>>
>>      mymodel <- pglm(patents ~   log(rd)  + as.numeric(year)+
>> I(log(capital72)*as.numeric(year)) , PatentsRDUS,
>>      family = poisson(link=log), model = "within", index = c("cusip",
>> "year"))
>>
>>      fitted.values(mymodel)
>>      AIC(mymodel)
>>
>> Cordially,
>> ?
>> Dr. Simon J Berrebi
>> Postdoctoral Fellow
>> Civil and Environmental Engineering
>> Georgia Institute of Technology
>>
>>
>>
>>
>>
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Apr 12 19:34:21 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 12 Apr 2019 18:34:21 +0100
Subject: [R] Help for coding
In-Reply-To: <1660961647.2367522.1555087824392@mail.yahoo.com>
References: <1660961647.2367522.1555087824392.ref@mail.yahoo.com>
 <1660961647.2367522.1555087824392@mail.yahoo.com>
Message-ID: <68676718-4057-d896-28fd-e3b1e4357506@sapo.pt>

Hello,

Remove ind from the calculations.
And maybe substitute length(Variable) for 1312.
And standard deviations is the square root of the variance, you are 
missing the square root.

Hope this helps,

Rui Barradas


?s 17:50 de 12/04/2019, bienvenidozoma at gmail.com escreveu:
> Dear all,
> I am trying to write the script to calculate the mean and the standard deviation without using the functions mean and standard deviations since morning. Someone can help
> 
> These scripts below are what i did but when i run and check with the function mean and standard deviation it is not the same result
> ind<-1:number of observations
> Mean<-(1/number of observations*sum(Variable*ind))
> Standard<-(1/Number of observations-1*sum(Variable - ((1/1312*sum(Variable*ind)))))
> 
> Thanks
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ur|edu@rdo @end|ng |rom gm@||@com  Fri Apr 12 18:28:14 2019
From: ur|edu@rdo @end|ng |rom gm@||@com (=?UTF-8?Q?Uri_Eduardo_Ram=C3=ADrez_Pasos?=)
Date: Fri, 12 Apr 2019 18:28:14 +0200
Subject: [R] Syntax differences between aov and lmer for 2-way repeated
 measures design using a mixed model
Message-ID: <CADO6phjg0VinkTpZaNgv_KAwiJpBBwdOoKjTgAky4CydevqM=Q@mail.gmail.com>

Hi everyone,

I'm working with the following data frame using R. It consists of
measurements obtained from 7 subjects with two independent variables (IV1
and IV2) with two levels each (OFF/ON, ALT/ISO, respectively):

>myData
Subject      DV         IV1     IV2
        1   2.567839      OFF      ALT
        1  58.708027       ON      ALT
        1  44.504265      OFF      ISO
        1 109.555701       ON      ISO
        2  99.043735      OFF      ALT
        2  75.958737       ON      ALT
        2 182.727396      OFF      ISO
        2 364.725795       ON      ISO
        3  45.788988      OFF      ALT
        3  52.941263       ON      ALT
        3  54.719013      OFF      ISO
        3  41.909909       ON      ISO
        4 116.145279      OFF      ALT
        4 162.927971       ON      ALT
        4  34.162077      OFF      ISO
        4  74.029748       ON      ISO
        5 114.412913      OFF      ALT
        5 121.127983       ON      ALT
        5 192.379708      OFF      ISO
        5 229.192453       ON      ISO
        6 213.421076      OFF      ALT
        6 526.739206       ON      ALT
        6 150.596812      OFF      ISO
        6 217.931951       ON      ISO
        7 117.931273      OFF      ALT
        7 102.467813       ON      ALT
        7  57.823062      OFF      ISO
        7  85.181033       ON      ISO
(1) Is this a repeated measures (RM) design? Some folks have mentioned that
it is not since it isn't a longitudinal study, but I thought that as long
as there are measurements from each experimental unit for every single
level of a factor, one can say this as a RM design. What is correct? Also,
is an RM design synonymous with having a within-subject factor?

(2) I'm interested in both the main and the interaction effects of IV1 and
IV2, but due to having measurements from each subject for all level
combinations, I think I have to include Subject as a random effect. I have
looked at aov and lmer but I'm confused about the difference in syntax:
This cheat sheet recommends:

m1<-aov(DV ~ IV1*IV2 + Error(Subject/(IV1*IV2)), myData)

However it's not clear to me whether Error(x/(y*z)) means x is a random
effect and y and z are nested in x. Is this interpretation correct? If so,
would m1 be inappropriate for my data since my data isn't nested, but fully
crossed? And if so, would

m2<-aov(DV ~ IV1*IV2 + Error(Subject), myData)

be the correct syntax? I have also been told that in m2 the Error term
should be dropped - is this correct?

(3) In a previous question I was told the linear mixed effects model

m3<-lmer(DV ~ IV1*IV2 + (1|Subject), myData)
was appropriate more my data. Just to better understand lmer syntax: if I
had n subjects and for each subject measurements were obtained for both
levels of IV2 but half of the subjects were OFF and the other half ON,
would the model be

m4<-lmer(DV ~ IV1*IV2 +(1|Subject/IV1), data=myData) ?

And if there was only one measurement per IV1*IV2 combination, would that
mean this is no longer a repeated-measures design and therefore the model
is just

m5<-lmer(DV ~ IV1*IV2, data=myData) ? In which case lm would probably
suffice.

Any help would be greatly appreciated,
Uri Ramirez

	[[alternative HTML version deleted]]


From r@i@1290 m@iii@g oii @im@com  Fri Apr 12 18:39:42 2019
From: r@i@1290 m@iii@g oii @im@com (r@i@1290 m@iii@g oii @im@com)
Date: Fri, 12 Apr 2019 16:39:42 +0000 (UTC)
Subject: [R] Creating a mean line plot
In-Reply-To: <CAGgJW766s7r3NxpScyhJfkRF6tdAutnOzDEHEUrfVY8rE76dxA@mail.gmail.com>
References: <958032223.2037452.1555019858964.ref@mail.yahoo.com>
 <958032223.2037452.1555019858964@mail.yahoo.com>
 <CAGgJW766s7r3NxpScyhJfkRF6tdAutnOzDEHEUrfVY8rE76dxA@mail.gmail.com>
Message-ID: <683389861.330190.1555087182209@mail.yahoo.com>

Hi Eric,

Ah, I apologize, and thank you for your response!?
I just figured out a way to average my x-values, so at least that is solved. I will still include the data for the two variables (1-dimensional) of interest that I was trying to average, just to show what was done:
get2.teratons #(90 values)
get5.teratons #(90 values)
Here is what get2.teratons looks like (same idea for get5.teratons):
? ? >print(get2.teratons)
??? [1] 0.4558545 0.4651129 0.4747509 0.4848242 0.4950900 0.5056109 0.5159335? 
??? 0.5262532 0.5372275 0.5481839 0.5586787 0.5694379 0.5802970
??? [14] 0.5909211 0.6015753 0.6124256 0.6237733 0.6353634 0.6467227 0.6582857 
??? 0.6702509 0.6817027 0.6935311 0.7060161 0.7182312 0.7301909
??? [27] 0.7422574 0.7544744 0.7665907 0.7786409 0.7907518 0.8032732 0.8158733 
??? 0.8284363 0.8413905 0.8545881 0.8674711 0.8797701 0.8927392
??? [40] 0.9059937 0.9189707 0.9317215 0.9438155 0.9558035 0.9673665 0.9784927 
??? 0.9900898 1.0020388 1.0132683 1.0240023 1.0347708 1.0456077
??? [53] 1.0570347 1.0682903 1.0793535 1.0901511 1.1001753 1.1101276 1.1199142 
??? 1.1293237 1.1384669 1.1470002 1.1547341 1.1622488 1.1697549
??? [66] 1.1777542 1.1857587 1.1930233 1.1999645 1.2067172 1.2132979 1.2199317?? 
??? 1.2265673 1.2328599 1.2390689 1.2446050 1.2495579 1.2546455
??? [79] 1.2599212 1.2648733 1.2700068 1.2753889 1.2807509 1.2856922 1.2905927 
??? 1.2953338 1.3000484 1.3045992 1.3091128 1.3144190?
The following worked in terms of averaging all of the elements of get2.teratons and get5.teratons:
rowMeans(cbind(get2.teratons,get5.teratons))
However, I am trying to do something similar for the values on my y-axis. So, for now, here are the two variables (3-dimensional) that I would like to average:
? ? subset? 
??? subset5
Using the print function for "subset" (same idea for subset5):? ??>print(subset)
??? class?????? : RasterStack 
??? dimensions? : 64, 128, 8192, 90? (nrow, ncol, ncell, nlayers)
??? resolution? : 2.8125, 2.789327? (x, y)
??? extent????? : -181.4062, 178.5938, -89.25846, 89.25846? (xmin, xmax, ymin,? 
??? ymax)
??? coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0 
??? names?????? : X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14,? 
??? X15, ... ? ??>dim(subset)
??? [1]? 64 128? 90>dim(subset5)
??? [1]? 64 128? 90
I tried `mean(subset,subset5)`, which works, BUT it combines the 90 layers into 1 layer. I want keep the number of layers at 90, but simply average each of the grid cell values of "subset" and "subset5" for each layer. So, for instance, I want to average the values of each grid cell of layer 1 of "subset" with the values of each grid cell of layer 1 of "subset5", and then average those values of layer 2 of "subset" with those values of layer 2 of "subset5"......all the way to layer 90. That way, I have 90 averages across all grid cells.
Here is what the data looks like for "subset":
>dput(head(subset,5))
??? structure(c(11.5447145886719, 11.2479725852609, 10.0223480723798, 
??? 11.4909216295928, 12.5930442474782, 15.0295264553279, 14.6107862703502, 
??? 13.3623332250863, 10.4473929153755, 13.262210553512, 13.3166334126145, 
??? 13.7211008928716, 10.594900790602, 11.7217378690839, 10.8397546224296, 
??? 14.2727348953485, 13.6185416020453, 12.7485566306859, 11.7246472276747, 
??? 10.6815265025944, 13.1605062168092, 12.9131189547479, 12.6493454910815, 
??? 11.6938022430986, 11.4522186107934, 8.84930260945112, 11.5785481408238, 
??? 12.9859233275056, 13.6702361516654, 11.863912967965, 11.6624090820551, 
??? 12.1465771459043, 12.9789240192622, 13.5916746687144, 15.0383287109435, 
??? 7.89674604311585, 8.14079332631081, 7.05628590658307, 6.99759456329048, 
??? 8.06435288395733, 8.00622920505702, 7.35754533670843, 6.57949370797724, 
??? 6.26998774241656, 6.10911303665489, 10.1576759945601, 9.83650996349752, 
??? 10.6277788057923, 10.3647025069222, 9.38627037685364, 28.411143925041, 
??? 27.3436004295945, 25.7670222781599, 24.1854049265385, 22.7183715440333, 
??? 10.8529561199248, 11.1584928352386, 11.4545458462089, 11.7570801638067, 
??? 11.6314635146409, 13.7268429156393, 12.4547378160059, 12.8433785866946, 
??? 10.282119596377, 9.66278391424567, 6.39572446234524, 8.4569685626775, 
??? 12.253624945879, 12.4784250743687, 13.6823802720755, 8.65540341474116, 
??? 8.34308553021401, 8.30261853989214, 7.9798299819231, 7.96007991302758, 
??? 13.3976918645203, 15.2056947816163, 15.3097502421588, 18.0296610575169, 
??? 17.918016621843, 14.121591579169, 14.3091559410095, 14.7470911033452, 
??? 15.414851764217, 15.8059203531593, 22.9126498103142, 21.5608592145145, 
??? 19.7303873486817, 17.5689237657934, 15.4688697773963, 10.2526041911915, 
??? 10.4463449679315, 9.85705149360001, 9.5394266070798, 9.17961853556335, 
??? 14.064371259883, 12.626935634762, 12.1540617663413, 10.9235350973904, 
??? 9.32216013316065, 12.3676003888249, 12.9718807060272, 14.5685050170869, 
??? 13.8497828040272, 14.0683455392718, 8.09576804749668, 8.54510050266981, 
??? 8.02388715092093, 8.6679536383599, 9.38348234631121, 11.6279292851686, 
??? 11.5998465567827, 11.6469369269907, 11.6286710835993, 10.8152111526579, 
??? 17.4072104506195, 18.9169261604548, 19.5168524980545, 19.0377978142351, 
??? 19.5594304706901, 9.74474258255213, 10.2144323755056, 10.9722976572812, 
??? 11.5369332488626, 12.0274581480771, 14.007618650794, 14.0536692459136, 
??? 14.4861201290041, 14.133819937706, 13.045089924708, 19.9330265633762, 
??? 20.3158976510167, 21.4452845044434, 19.9475897010416, 20.3566399868578, 
??? 15.703826257959, 14.8260951507837, 14.6203982178122, 14.0476305037737, 
??? 13.2086589932442, 6.5044054761529, 6.51829722337425, 6.59741191193461, 
??? 6.57343484926969, 7.07112564705312, 8.42645864468068, 9.15604883339256, 
??? 10.8542435802519, 8.57339131180197, 7.89698304142803, 10.6029914226383, 
??? 9.90388663485646, 8.46301421988755, 12.9162973724306, 9.06370310112834, 
??? 9.92726711556315, 11.5754703059793, 8.74886247329414, 8.99941809475422, 
??? 9.90840594749898, 11.1468604300171, 11.1322306562215, 10.49438144546, 
??? 9.50155213940889, 8.31737467087805, 5.76932597905397, 6.14411209244281, 
??? 7.39980584476143, 8.47632132936269, 8.00714262295514, 8.64454926922917, 
??? 7.79559868387878, 7.14818593114614, 7.42282171268016, 9.04718739911914, 
??? 12.0141573250294, 11.0411503817886, 11.7892528418452, 11.2668004352599, 
??? 10.5345542309806, 14.2355003859848, 12.4114783946425, 13.1144292186946, 
??? 14.3049817532301, 14.7282858844846, 9.90791183430701, 10.4058899218217, 
??? 12.0624131988734, 13.2521220948547, 13.9345653355122, 12.5256763771176, 
??? 12.3285478446633, 11.9927407242358, 11.6441268939525, 11.6448875516653, 
??? 30.5602320469916, 30.6964941322803, 27.3358505219221, 27.5474566966295, 
??? 24.3847575969994, 15.1250814087689, 15.0272130500525, 14.9795342702419, 
??? 14.2658210825175, 13.437497522682, 10.7001833617687, 10.0823557935655, 
??? 10.1298170629889, 9.99525294173509, 10.6919908896089, 9.04134479351342, 
??? 9.57930330187082, 9.58402880933136, 8.82056106347591, 9.06912200152874, 
??? 11.0435656271875, 12.827942892909, 14.6962288767099, 15.984565531835, 
??? 16.3673574104905, 17.7882182411849, 17.1887206379324, 16.4347139652818, 
??? 15.4833788517863, 14.3649869598448, 10.0324214436114, 10.9937381464988, 
??? 10.7803415972739, 10.64134365879, 10.3700830601156, 10.7242427766323, 
??? 10.1225153775886, 9.59254063200206, 9.67734202276915, 9.9705743137747, 
??? 6.15209711249918, 7.6417050557211, 9.55170588567853, 12.123644258827, 
??? 14.6793850231916, 13.8236853294075, 14.3564789090306, 13.6828002054244, 
??? 13.0476749036461, 12.3909330926836, 12.5938401091844, 12.5098232645541, 
??? 12.4792913440615, 10.5595408938825, 10.0890464382246, 9.20089432038367, 
??? 8.92592284362763, 8.59467086847872, 9.42603517323732, 10.0353622343391, 
??? 11.7311725392938, 12.4379832297564, 12.9343897104263, 12.9055073484778, 
??? 10.8944955747575, 13.6480727232993, 13.5285727679729, 13.1794585380703, 
??? 12.8222310449928, 12.3997843824327, 12.7413347829133, 14.3273916095495, 
??? 17.3931313678622, 18.2263168506324, 18.5841742437333, 6.59096706658602, 
??? 6.43405092414469, 6.25825286842883, 6.41100551001728, 6.47397979628295, 
??? 10.5375754879788, 11.7441980168223, 12.6210678834468, 13.6038213036954, 
??? 14.3639346119016, 14.6688716020435, 14.1826340463012, 15.2044224087149, 
??? 15.5630568042397, 15.0458208750933, 10.0154311163351, 9.7418615128845, 
??? 11.8866622913629, 10.4000290855765, 9.74880487192422, 12.071524746716, 
??? 11.5644979756325, 11.0723461490124, 10.6282578315586, 10.2157085202634, 
??? 14.5142644643784, 12.1188929770142, 12.3748247511685, 12.4087903182954, 
??? 11.9534945581108, 9.04913682024926, 10.3765605948865, 11.6044067312032, 
??? 11.8693192955106, 11.4852412138134, 9.60276927798986, 8.47671863157302, 
??? 6.53922976925969, 6.61022553686053, 6.93009907845408, 13.2296028546989, 
??? 13.0423339549452, 13.0597360432148, 12.6910961698741, 12.4157820828259, 
??? 10.1926731644198, 8.71818219311535, 7.08254557102919, 8.77621911931783, 
??? 10.0059285527095, 12.931788386777, 12.2630294412374, 11.4822425879538, 
??? 10.4378029704094, 9.7940765786916, 13.0133786704391, 11.9061049539596, 
??? 12.0638377033174, 12.3013137839735, 12.9490484017879, 13.2149957120419, 
??? 13.1087802350521, 12.6286820042878, 12.2278920840472, 11.8682594038546, 
??? 10.9492189250886, 12.2341319918633, 12.9464382771403, 12.5120461452752, 
??? 12.5263502821326, 12.6686599105597, 12.7322974149138, 12.1948833111674, 
??? 12.1215357910842, 11.9392029941082, 15.2677292469889, 16.3731585256755, 
??? 17.8960581310093, 18.6334447469562, 19.5818214677274, 8.80653981585056, 
??? 9.830889897421, 9.35642933472991, 8.49255602806807, 9.19627505354583, 
??? 9.56638909410685, 10.4608207242563, 11.0053240321577, 12.0839668437839, 
??? 12.6748947892338, 10.9087632503361, 11.0474556684494, 9.86553691327572, 
??? 11.7183218244463, 12.5948534812778, 9.51134513597935, 7.67265690956265, 
??? 8.47005187533796, 8.948102616705, 9.48919930960983, 8.92916852608323, 
??? 9.19180226046592, 9.93818349670619, 10.3347131051123, 9.19244724791497, 
??? 16.0914938896894, 16.6821955237538, 17.9938221350312, 19.0754321403801, 
??? 19.048942392692, 8.59134346246719, 8.39548541698605, 8.17942153662443, 
??? 8.02843223791569, 8.9953287737444, 7.97593365423381, 7.71139136049896, 
??? 7.85907462704927, 8.38070099707693, 9.28482818417251, 11.3056178670377, 
??? 11.601750086993, 11.2711317837238, 10.8186058234423, 10.7581429649144, 
??? 15.6826636288315, 16.9076268095523, 15.4331855010241, 15.1698420289904, 
??? 14.4226460717618, 11.3487603608519, 10.932231741026, 10.3945284616202, 
??? 9.96728525497019, 9.48596934322268, 10.508708213456, 10.0394641282037, 
??? 10.5090778553858, 10.1252990076318, 9.86525025218725, 21.985590364784, 
??? 22.3454732447863, 22.693102620542, 22.8635905310512, 23.2176823541522, 
??? 18.6908649746329, 16.1407203879207, 14.8633007425815, 13.0084274802357, 
??? 10.3990704054013, 6.98735397309065, 6.87530469149351, 8.9313744334504, 
??? 7.93048026971519, 8.05362006649375, 7.19595712143928, 6.09859018586576, 
??? 7.31170470826328, 8.58990701381117, 8.4448722191155, 10.6643167790025, 
??? 10.839969618246, 10.5106293456629, 10.4457534151152, 11.2185546196997, 
??? 12.6707960385829, 12.9902018699795, 12.9533659201115, 12.501154281199, 
??? 12.3501065187156, 25.9615670889616, 28.099115844816, 30.2258117124438, 
??? 32.2391155175865, 34.1092220507562, 13.0570391658694, 14.2825467512012, 
??? 11.1714780796319, 9.62660552468151, 13.1034480873495, 12.0462608523667, 
??? 12.1476030908525, 12.087664520368, 12.486698012799, 12.6554797869176, 
??? 12.9096878226846, 13.7426960282028, 15.2569429948926, 17.1046711038798, 
??? 17.0782153028995, 8.75586932525039, 8.82860643323511, 8.69223182089627, 
??? 9.15108947083354, 9.4462743261829, 8.55356580577791, 8.69411900639534, 
??? 8.9102350641042, 9.00506707839668, 8.75238287262619, 12.8364848904312, 
??? 14.6456281654537, 13.9498212374747, 14.5683591719717, 14.3893217202276, 
??? 15.1805742178112, 16.7262759525329, 17.7521643228829, 18.5243777465075, 
??? 18.8792126253247, 7.70680792629719, 7.47225251980126, 7.72799758706242, 
??? 7.68415729980916, 7.50800217501819, 9.68811193015426, 10.5253741610795, 
??? 10.922572016716, 10.9020531177521, 10.406608460471, 22.1927281469107, 
??? 21.7946967110038, 22.5350291468203, 22.0015277154744, 23.2784972526133, 
??? 25.1319196075201, 24.1645314730704, 23.0207713320851, 14.8746414575726, 
??? 12.5255933962762, 19.3960575386882, 19.3368871696293, 19.8454126249999, 
??? 19.8410699609667, 19.8172997217625, 12.1799279004335, 11.8857935070992, 
??? 11.4909932948649, 11.3612791523337, 10.8840802218765, 11.1973982769996, 
??? 11.6429010406137, 11.2867686431855, 11.5507948212326, 11.7122428491712, 
??? 13.8513946440071, 14.9497504346073, 14.425096521154, 13.2822252810001, 
??? 12.4311964027584, 18.864199379459, 17.5528808031231, 17.7616731729358, 
??? 17.1655979007483, 16.6251927148551, 29.3679255992174, 28.4771841019392, 
??? 27.9151875525713, 26.65377818048, 25.2528126351535, 10.6545137241483, 
??? 10.91169398278, 11.0310669522732, 11.1646522767842, 11.2674177624285, 
??? 13.7821182142943, 14.1553220339119, 15.0969068985432, 15.9642276819795, 
??? 16.6291657369584, 9.4556876225397, 9.84383365139365, 11.0380863770843, 
??? 10.6556000187993, 11.1149505246431, 8.38961955159903, 9.4479993218556, 
??? 10.1951210992411, 10.6412279885262, 10.8386783860624, 8.28430177643895, 
??? 8.50012865848839, 8.0173090333119, 8.15484160557389, 8.07647814508528, 
??? 10.3200965328142, 10.4913098970428, 10.3476996067911, 10.6061836704612, 
??? 12.1657092589885, 10.3872286621481, 9.38602960668504, 9.82730537652969, 
??? 9.79454554617405, 9.12395850755274, 12.1763132046908, 12.7074157353491, 
??? 12.6221365761012, 13.4234247263521, 15.5103187076747, 9.88674920517951, 
??? 9.41792191006243, 8.58000149019063, 7.98727499786764, 7.34257609583437, 
??? 13.8378750532866, 14.5356948953122, 14.5302697084844, 14.6059796679765, 
??? 14.1489790286869, 14.9558734148741, 15.146628767252, 15.4630133416504, 
??? 15.5585858970881, 15.4571908526123, 11.8359496816993, 11.2020426895469, 
??? 11.4698356948793, 11.8119870778173, 13.0321650300175, 17.7426278125495, 
??? 18.6734465416521, 18.8405636698008, 18.8715255819261, 18.9619445241988, 
??? 8.8628712343052, 8.674994437024, 9.01558804325759, 9.04601749498397, 
??? 8.85597188025713, 7.58305897470564, 7.92995095252991, 8.35649385116994, 
??? 9.23873609863222, 9.14969765581191, 12.9726023878902, 12.2728526126593, 
??? 13.0261426325887, 12.6654123421758, 11.5908016450703, 13.0077322013676, 
??? 12.6599280629307, 11.9994106236845, 10.1917257998139, 9.89739338401705, 
??? 10.7914459425956, 11.8336362764239, 11.7934257723391, 11.2242249771953, 
??? 11.4056261256337, 7.95377462636679, 7.26088020019233, 7.43080170359462, 
??? 7.50569254159927, 7.62218066956848, 11.2671461887658, 10.8180299866945, 
??? 9.43983325269073, 9.29652785416692, 10.826626047492, 14.3595944624394, 
??? 13.2217460777611, 12.7365244086832, 12.05212357454, 12.3027219437063, 
??? 13.1963438820094, 12.8045422956347, 13.7076315935701, 14.145736489445, 
??? 14.4983648322523, 14.3930621445179, 13.7241447810084, 13.0053710192442, 
??? 12.2289746068418, 11.4307265728712, 22.3180065862834, 17.3237380106002, 
??? 12.7182623371482, 13.0704908631742, 15.2839343994856, 11.1243085004389, 
??? 10.2472041500732, 10.5197993572801, 11.790946405381, 10.6045705731958, 
??? 15.1506495662034, 17.2426456119865, 18.0581725202501, 17.5418430939317, 
??? 16.011631116271, 16.6771751828492, 14.9888406973332, 14.0024574939162, 
??? 12.2754199896008, 10.462130815722, 14.700809167698, 14.7662508767098, 
??? 14.6368321962655, 13.8920741155744, 13.6426123324782, 7.52487180288881, 
??? 6.8714844295755, 7.11258086375892, 7.18187426682562, 7.26737848017365, 
??? 8.01721725147218, 9.51534896157682, 9.49199174065143, 9.66430208645761, 
??? 9.95999739971012, 12.6632636412978, 12.3405989259481, 12.1739520225674, 
??? 11.8746338412166, 11.4930238109082, 17.375064175576, 16.5855303872377, 
??? 14.6908791270107, 12.4465051107109, 10.6631374452263, 9.17110545560718, 
??? 8.15483720507473, 8.49230268504471, 9.13922635372728, 9.57141006365418, 
??? 16.033780714497, 17.3399481922388, 16.4341507013887, 15.3515323530883, 
??? 14.7840439807624, 18.8009101431817, 19.3318882025778, 20.5749990418553, 
??? 21.8101386912167, 21.9960610382259, 18.0659588892013, 17.8131891880184, 
??? 17.4943805672228, 17.3403216060251, 16.8955769855529, 12.620489532128, 
??? 12.2214950155467, 11.8860110174865, 11.3811555784196, 10.8314753975719, 
??? 13.4036011062562, 11.5633060690016, 11.6371187847108, 12.5311543699354, 
??? 13.4179203305393, 8.22134572081268, 7.50831649638712, 7.27005901280791, 
??? 7.60287002194673, 7.99200239125639, 7.90263516828418, 8.68863912764937, 
??? 10.4649641085416, 14.8291767574847, 13.2854715920985, 14.6683146245778, 
??? 15.3950218576938, 16.1753460299224, 18.3709637727588, 18.7799926847219, 
??? 9.85975402873009, 11.3263857085258, 14.0980262774974, 14.9891349021345, 
??? 15.565140126273, 17.7682626061141, 17.6397152245045, 18.1632375810295, 
??? 18.5020068660378, 18.6178280040622, 13.9469483401626, 13.3572864811867, 
??? 13.7237298768014, 15.0745737366378, 13.0753238685429, 7.80682750046253, 
??? 8.02811540197581, 8.54396957438439, 8.93615526147187, 9.23284823074937, 
??? 11.9208830874413, 11.34336409159, 9.64633170515299, 9.77506830822676, 
??? 9.60444209631532, 13.3866403251886, 13.6259520426393, 11.5198655985296, 
??? 10.6700826901942, 9.85463059041649, 16.529045579955, 14.2629016656429, 
??? 12.7639583777636, 13.6573225725442, 15.0617569684982, 9.50025964993984, 
??? 9.68771148473024, 9.27095026709139, 9.30016769561917, 9.69172285404056, 
??? 7.99956496339291, 7.4167326791212, 7.22712711431086, 8.56165643781424, 
??? 9.04990502167493, 16.1096038296819, 15.6424694694579, 16.1224633455276, 
??? 15.2468092739582, 15.2601830195636, 14.6924834232777, 15.2172856964171, 
??? 15.6576700508595, 15.8558295574039, 15.6930990982801, 10.0672576809302, 
??? 10.4989007581025, 10.7346505858004, 10.9321122989058, 10.1002658251673, 
??? 7.57602006196976, 8.28179977834225, 9.00425424333662, 8.75011347234249, 
??? 9.78429929818958, 8.22318575810641, 7.62580542359501, 7.52632019575685, 
??? 7.3945076437667, 8.00606575794518, 9.82791453134269, 10.3108039358631, 
??? 10.8194808941334, 11.0586643684655, 12.7866649534553, 16.4375944063067, 
??? 16.122004436329, 15.8343450631946, 15.183718688786, 14.59901179187, 
??? 13.086870778352, 13.8396339956671, 13.0286106839776, 12.6303931698203, 
??? 11.8594408035278, 12.4039673712105, 9.90002802573144, 9.60356576833874, 
??? 11.081666406244, 11.0487984493375, 15.9987502265722, 14.9749074596912, 
??? 13.8462209142745, 12.3910789377987, 11.7417626548558, 10.7962236274034, 
??? 11.77659323439, 11.0980827827007, 10.4603781597689, 10.4605271480978, 
??? 12.797769298777, 11.2864379771054, 9.58062659483403, 9.57864196971059, 
??? 9.7400170750916, 15.1035780552775, 15.3101249132305, 15.6179285142571, 
??? 14.4825984723866, 11.6881796624511, 11.791490809992, 11.2104086671025, 
??? 8.8539243908599, 8.34417999722064, 8.39954141993076, 9.41099112387747, 
??? 8.93235134426504, 9.60718737915158, 9.41101815551519, 9.83936337288469, 
??? 13.6638214811683, 14.4527215976268, 14.7365185897797, 13.2517122197896, 
??? 11.0009524505585, 9.60110148880631, 8.54964307509363, 8.75000974629074, 
??? 8.88564947526902, 7.84255138132721, 11.6202082950622, 12.075385870412, 
??? 12.8382677212358, 14.9491381365806, 20.0978868640959, 8.93126882147044, 
??? 9.09663643687963, 9.05409744009376, 8.98246862925589, 8.80278556142002, 
??? 8.68155935313553, 8.91096869017929, 7.71334832534194, 9.87222944386303, 
??? 11.2759735900909, 17.2249065712094, 17.9082475136966, 17.6210721954703, 
??? 16.7172310408205, 16.2506423424929, 12.9267014097422, 14.7103695664555, 
??? 19.504395313561, 22.4196153692901, 22.2453631460667, 8.23867111466825, 
??? 8.10000761412084, 7.8771845670417, 7.56322089582682, 7.14911003597081, 
??? 9.50618146453053, 8.6958515457809, 7.36113237217069, 6.79777669720352, 
??? 6.69330381788313), .Dim = c(10L, 90L), .Dimnames = list(NULL, 
??? c("X1", "X2", "X3", "X4", "X5", "X6", "X7", "X8", "X9", "X10", 
??? "X11", "X12", "X13", "X14", "X15", "X16", "X17", "X18", "X19", 
??? "X20", "X21", "X22", "X23", "X24", "X25", "X26", "X27", "X28", 
??? "X29", "X30", "X31", "X32", "X33", "X34", "X35", "X36", "X37", 
??? "X38", "X39", "X40", "X41", "X42", "X43", "X44", "X45", "X46", 
??? "X47", "X48", "X49", "X50", "X51", "X52", "X53", "X54", "X55", 
??? "X56", "X57", "X58", "X59", "X60", "X61", "X62", "X63", "X64", 
??? "X65", "X66", "X67", "X68", "X69", "X70", "X71", "X72", "X73", 
??? "X74", "X75", "X76", "X77", "X78", "X79", "X80", "X81", "X82", 
??? "X83", "X84", "X85", "X86", "X87", "X88", "X89", "X90")))

Is there any way to compute the means in this way? I just tried this, but I received the following error:
result <- rowMeans(cbind(c(subset), c(subset5)));dim(result) <- dim(subset);colnames(result) <- colnames(subset)

Error in rowMeans(cbind(c(subset), c(subset5))) : 'x' must be numeric

Thanks,
-----Original Message-----
From: Eric Berger <ericjberger at gmail.com>
To: rain1290 <rain1290 at aim.com>
Cc: r-sig-geo <r-sig-geo at r-project.org>; R mailing list <r-help at r-project.org>
Sent: Fri, Apr 12, 2019 11:47 am
Subject: Re: [R] Creating a mean line plot

I don't have your data. Are the x-values the same in both plots?Does this example cover the situation?
f1 <- function(x) { x^3 - 2 }f2 <- function(x) { 2 - x^2 }
xV <- seq(from=0,to=2,length=50)y1 <- f1(xV)y2 <- f2(xV)y3 <- .5*(y1+y2)plot(x=xV,y=y1,col="blue",lwd=2,type='l',xlab="x",ylab="y")lines(x=xV,y=y2,col="green",lwd=2)lines(x=xV,y=y3,col="red",lwd=2)legend("topleft",legend=c("y1","y2","mean"),col=c("blue","green","red"),lwd=rep(2,3))
? ? ? ?

On Fri, Apr 12, 2019 at 5:34 PM rain1290--- via R-help <r-help at r-project.org> wrote:

Hi there,
I am trying to create a mean line plot that shows the mean of a series of separate line plots that correspond to two climate models. Let's first try getting the mean of two line plots. To create the separate line plots, here is what I did to set up the x and y axis variables:

####Getting cumulative emissions data for x-axis: 1-dimensional ####

#For CanESM model#

ncfname <- "cumulative_emissions_1pctCO2.nc"
Model1 <- nc_open(ncfname)
get <- ncvar_get(Model1, "cum_co2_emi-CanESM2") ? ? #units of terratones of carbon (TtC) for x-axis (140 values)
#For IPSL LR Model#
#Getting cumulative emissions data for x-axis?IPSL LR 1pctCO2?IPSL <- ncvar_get(Model1, "cum_co2_emi-IPSL-CM5A-LR") ? ? #units of terratones of carbon (TtC) for x-axis (140 values)

############################################################################################################

#####Getting precipitation data for y-axis - these are 3-dimensional####

#For CanESM2 model#
Model2 <- brick("MaxPrecCCCMACanESM21pctCO2.nc", var="onedaymax")


#For IPSL LR Model#
Model10 <- brick("MaxPrecIPSLIPSL-CM5A-LR1pctCO2.nc", var="onedaymax")
#############################################################################################################
To create plots for a specific location:
lonlat <- cbind(103,3) ? ? ? ?? #specifies a specific longitude and latitude
Hope2 <- extract(Model2,lonlat) ? ?? #CanESM2
Hope6 <- extract(Model10,lonlat) ? #start IPSL CM5A LR
plot(get,Hope2, type="l",col="green", lwd="3", xlab="Cumulative CO2 emissions (TtC)", ylab="One-day maximum precipitation (mm/day)", main="One-day maximum precipitation for random location for 1pctCO2 scenario")
lines(IPSL, Hope6, type="l", lwd="3", col="green")
#############################################################################################################
So, the idea would be to create a plot that shows the mean of these two plots. Given what I showed above, how should I go about creating the mean of these two green line plots? Would you have to get the mean of the x-values, and then obtain the mean of the y-values, and then plot these?
Thanks, and any help would be greatly appreciated!
? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From @|mon @end|ng |rom berreb|@net  Fri Apr 12 19:07:14 2019
From: @|mon @end|ng |rom berreb|@net (Simon Berrebi)
Date: Fri, 12 Apr 2019 13:07:14 -0400
Subject: [R] Are fitted.values available in pglm?
In-Reply-To: <CAGxFJbQ0THXrKPzRUeaP=j9yopm4h80QFTTgKG-MeTg5nQw7Cg@mail.gmail.com>
References: <65B6EF72-1FD2-4B20-A475-40F5F87DDA85@berrebi.net>
 <CAGxFJbQ0THXrKPzRUeaP=j9yopm4h80QFTTgKG-MeTg5nQw7Cg@mail.gmail.com>
Message-ID: <339BBA1B-F4A7-4776-85AE-364C6BF8FBA9@berrebi.net>

Thank you Bert,

I wasn?t aware of ?str. The only mention of fitted-values is:

 $ maximum    : atomic [1:1] -9824
  ..- attr(*, "fitted.values")= num [1:3460] 1.39 1.3 1.3 1.32 1.27 ...

When I try attr(mymodel$maximum,  ?fitted.values?), I get the same results as  attr(AIC(mymodel),  ?fitted.values?), which is a list of number starting with (1.39 1.3 1.3 1.32 1.27 ?). I don?t see how these can be fitted values for the response variable, patents, which are larger numbers (30, 3, 48, 1, 2, 32, ?). Is this output not supped to represent the fitted values for patents?

Another way to obtain fitted values would be using residuals.?pglm also includes residuals in its list of elements. However, str(mymodel) does not mention residuals. Does that mean it?s just not there?

- Simon

> On Apr 12, 2019, at 10:44 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> ?fitted
> ?predict
> ## This is what one usually does, but I have not checked pglm.
> 
> You also need to get friendly with ?str
> 
> ... and probably also spend time with an R tutorial or two to become familiar with R modeling conventions.
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Fri, Apr 12, 2019 at 7:35 AM Simon Berrebi <simon at berrebi.net <mailto:simon at berrebi.net>> wrote:
> Hello everyone,
> 
> I am using the pglm function in R to fit a Poisson fixed-effects model. According to the documentation <https://cran.r-project.org/web/packages/pglm/pglm.pdf <https://cran.r-project.org/web/packages/pglm/pglm.pdf>>, the pglm object should have fitted.values. However, fitted.values(mymodel) returns "NULL".
> 
> When I run AIC(mymodel) the AIC is followed by "attr(,"fitted.values")" and a long list of number. I have included an example below and attached a text file with the output.
> 
> Are these fitted values? If so, is there a way to obtain them directly? Can I also get fitted-values based on a synthetic dataset (i.e. predict())?
> 
> install.packages("pglm")
> library(pglm)
> 
> data("PatentsRDUS", package="pglm")
> 
> 
>      mymodel <- pglm(patents ~   log(rd)  + as.numeric(year)+ I(log(capital72)*as.numeric(year)) , PatentsRDUS,
>      family = poisson(link=log), model = "within", index = c("cusip", "year"))
> 
>      fitted.values(mymodel)
>      AIC(mymodel)
> 
> Cordially,
> ?
> Dr. Simon J Berrebi
> Postdoctoral Fellow 
> Civil and Environmental Engineering
> Georgia Institute of Technology
> 
> 
> 
> 
> 
> 
> 
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From wdun|@p @end|ng |rom t|bco@com  Fri Apr 12 20:44:15 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 12 Apr 2019 11:44:15 -0700
Subject: [R] Are fitted.values available in pglm?
In-Reply-To: <339BBA1B-F4A7-4776-85AE-364C6BF8FBA9@berrebi.net>
References: <65B6EF72-1FD2-4B20-A475-40F5F87DDA85@berrebi.net>
 <CAGxFJbQ0THXrKPzRUeaP=j9yopm4h80QFTTgKG-MeTg5nQw7Cg@mail.gmail.com>
 <339BBA1B-F4A7-4776-85AE-364C6BF8FBA9@berrebi.net>
Message-ID: <CAF8bMca3kxAKwhxs-9HvG-N7qHXygVg5Fn6p4us0mQ5epc-6jA@mail.gmail.com>

You should ask the maintainer of the package about this:
bug.report(package="pglm") or maintainer("pglm") should give you contact
information.

The help file for pglm seems all wrong - it says pglm's output has class
"pglm" with components like "fitted.values", but the the example calls to
pglm return things of class c("maxLik", "maxim", "list").

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Apr 12, 2019 at 11:09 AM Simon Berrebi <simon at berrebi.net> wrote:

> Thank you Bert,
>
> I wasn?t aware of ?str. The only mention of fitted-values is:
>
>  $ maximum    : atomic [1:1] -9824
>   ..- attr(*, "fitted.values")= num [1:3460] 1.39 1.3 1.3 1.32 1.27 ...
>
> When I try attr(mymodel$maximum,  ?fitted.values?), I get the same results
> as  attr(AIC(mymodel),  ?fitted.values?), which is a list of number
> starting with (1.39 1.3 1.3 1.32 1.27 ?). I don?t see how these can be
> fitted values for the response variable, patents, which are larger numbers
> (30, 3, 48, 1, 2, 32, ?). Is this output not supped to represent the fitted
> values for patents?
>
> Another way to obtain fitted values would be using residuals.?pglm also
> includes residuals in its list of elements. However, str(mymodel) does not
> mention residuals. Does that mean it?s just not there?
>
> - Simon
>
> > On Apr 12, 2019, at 10:44 AM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >
> > ?fitted
> > ?predict
> > ## This is what one usually does, but I have not checked pglm.
> >
> > You also need to get friendly with ?str
> >
> > ... and probably also spend time with an R tutorial or two to become
> familiar with R modeling conventions.
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >
> > On Fri, Apr 12, 2019 at 7:35 AM Simon Berrebi <simon at berrebi.net
> <mailto:simon at berrebi.net>> wrote:
> > Hello everyone,
> >
> > I am using the pglm function in R to fit a Poisson fixed-effects model.
> According to the documentation <
> https://cran.r-project.org/web/packages/pglm/pglm.pdf <
> https://cran.r-project.org/web/packages/pglm/pglm.pdf>>, the pglm object
> should have fitted.values. However, fitted.values(mymodel) returns "NULL".
> >
> > When I run AIC(mymodel) the AIC is followed by "attr(,"fitted.values")"
> and a long list of number. I have included an example below and attached a
> text file with the output.
> >
> > Are these fitted values? If so, is there a way to obtain them directly?
> Can I also get fitted-values based on a synthetic dataset (i.e. predict())?
> >
> > install.packages("pglm")
> > library(pglm)
> >
> > data("PatentsRDUS", package="pglm")
> >
> >
> >      mymodel <- pglm(patents ~   log(rd)  + as.numeric(year)+
> I(log(capital72)*as.numeric(year)) , PatentsRDUS,
> >      family = poisson(link=log), model = "within", index = c("cusip",
> "year"))
> >
> >      fitted.values(mymodel)
> >      AIC(mymodel)
> >
> > Cordially,
> > ?
> > Dr. Simon J Berrebi
> > Postdoctoral Fellow
> > Civil and Environmental Engineering
> > Georgia Institute of Technology
> >
> >
> >
> >
> >
> >
> >
> >
> > ______________________________________________
> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help <
> https://stat.ethz.ch/mailman/listinfo/r-help>
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html <
> http://www.r-project.org/posting-guide.html>
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Fri Apr 12 21:50:40 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 12 Apr 2019 12:50:40 -0700
Subject: [R] Syntax differences between aov and lmer for 2-way repeated
 measures design using a mixed model
In-Reply-To: <CADO6phjg0VinkTpZaNgv_KAwiJpBBwdOoKjTgAky4CydevqM=Q@mail.gmail.com>
References: <CADO6phjg0VinkTpZaNgv_KAwiJpBBwdOoKjTgAky4CydevqM=Q@mail.gmail.com>
Message-ID: <CAGxFJbTWowfB3qLDafC=c-Ts2D3NQC94GXr-XzP1HVLpCrjSeQ@mail.gmail.com>

You should talk with your professor.  This list is about R programming.
Essentially statistical issues, which this appears mostly to be, are
generally off topic.

Questions about mixed effects models -- RM and longitudinal designs are
typically analysed as such -- and especially using the nlme and/or lme4
packages are usually better posted on the r-sig-mixed-models list.

... and if this is homework, this list has a no homework poilicy.

Cheers,

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Apr 12, 2019 at 11:08 AM Uri Eduardo Ram?rez Pasos <
urieduardo at gmail.com> wrote:

> Hi everyone,
>
> I'm working with the following data frame using R. It consists of
> measurements obtained from 7 subjects with two independent variables (IV1
> and IV2) with two levels each (OFF/ON, ALT/ISO, respectively):
>
> >myData
> Subject      DV         IV1     IV2
>         1   2.567839      OFF      ALT
>         1  58.708027       ON      ALT
>         1  44.504265      OFF      ISO
>         1 109.555701       ON      ISO
>         2  99.043735      OFF      ALT
>         2  75.958737       ON      ALT
>         2 182.727396      OFF      ISO
>         2 364.725795       ON      ISO
>         3  45.788988      OFF      ALT
>         3  52.941263       ON      ALT
>         3  54.719013      OFF      ISO
>         3  41.909909       ON      ISO
>         4 116.145279      OFF      ALT
>         4 162.927971       ON      ALT
>         4  34.162077      OFF      ISO
>         4  74.029748       ON      ISO
>         5 114.412913      OFF      ALT
>         5 121.127983       ON      ALT
>         5 192.379708      OFF      ISO
>         5 229.192453       ON      ISO
>         6 213.421076      OFF      ALT
>         6 526.739206       ON      ALT
>         6 150.596812      OFF      ISO
>         6 217.931951       ON      ISO
>         7 117.931273      OFF      ALT
>         7 102.467813       ON      ALT
>         7  57.823062      OFF      ISO
>         7  85.181033       ON      ISO
> (1) Is this a repeated measures (RM) design? Some folks have mentioned that
> it is not since it isn't a longitudinal study, but I thought that as long
> as there are measurements from each experimental unit for every single
> level of a factor, one can say this as a RM design. What is correct? Also,
> is an RM design synonymous with having a within-subject factor?
>
> (2) I'm interested in both the main and the interaction effects of IV1 and
> IV2, but due to having measurements from each subject for all level
> combinations, I think I have to include Subject as a random effect. I have
> looked at aov and lmer but I'm confused about the difference in syntax:
> This cheat sheet recommends:
>
> m1<-aov(DV ~ IV1*IV2 + Error(Subject/(IV1*IV2)), myData)
>
> However it's not clear to me whether Error(x/(y*z)) means x is a random
> effect and y and z are nested in x. Is this interpretation correct? If so,
> would m1 be inappropriate for my data since my data isn't nested, but fully
> crossed? And if so, would
>
> m2<-aov(DV ~ IV1*IV2 + Error(Subject), myData)
>
> be the correct syntax? I have also been told that in m2 the Error term
> should be dropped - is this correct?
>
> (3) In a previous question I was told the linear mixed effects model
>
> m3<-lmer(DV ~ IV1*IV2 + (1|Subject), myData)
> was appropriate more my data. Just to better understand lmer syntax: if I
> had n subjects and for each subject measurements were obtained for both
> levels of IV2 but half of the subjects were OFF and the other half ON,
> would the model be
>
> m4<-lmer(DV ~ IV1*IV2 +(1|Subject/IV1), data=myData) ?
>
> And if there was only one measurement per IV1*IV2 combination, would that
> mean this is no longer a repeated-measures design and therefore the model
> is just
>
> m5<-lmer(DV ~ IV1*IV2, data=myData) ? In which case lm would probably
> suffice.
>
> Any help would be greatly appreciated,
> Uri Ramirez
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Sat Apr 13 13:14:30 2019
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Sat, 13 Apr 2019 16:44:30 +0530
Subject: [R] Complete month name from as.yearmon()
Message-ID: <CA+dpOJkH9LCsMoSWdZK2XcFHX0aDfSrHFJhMoxrj+jQjcErL1Q@mail.gmail.com>

Hi,

I am wondering if there is any way to get the full name from as.yearmon()
function. Please consider below example:

library(quantmod)
as.yearmon(Sys.Date())

This gives: [1] "Apr 2019".

How can I extract the full name ie. 'April 2019'

Appreciate your pointer. Thanks,

	[[alternative HTML version deleted]]


From Ach|m@Ze||e|@ @end|ng |rom u|bk@@c@@t  Sat Apr 13 13:43:39 2019
From: Ach|m@Ze||e|@ @end|ng |rom u|bk@@c@@t (Achim Zeileis)
Date: Sat, 13 Apr 2019 13:43:39 +0200 (CEST)
Subject: [R] Complete month name from as.yearmon()
In-Reply-To: <CA+dpOJkH9LCsMoSWdZK2XcFHX0aDfSrHFJhMoxrj+jQjcErL1Q@mail.gmail.com>
References: <CA+dpOJkH9LCsMoSWdZK2XcFHX0aDfSrHFJhMoxrj+jQjcErL1Q@mail.gmail.com>
Message-ID: <alpine.DEB.2.21.1904131340240.5743@paninaro>

On Sat, 13 Apr 2019, Christofer Bogaso wrote:

> Hi,
>
> I am wondering if there is any way to get the full name from as.yearmon()
> function. Please consider below example:
>
> library(quantmod)
> as.yearmon(Sys.Date())
>
> This gives: [1] "Apr 2019".
>
> How can I extract the full name ie. 'April 2019'

Internally, printing/formatting of yearmon objects uses the format method 
for Date objects, see ?format.Date. The default is "%b %Y" where %b is the 
abbreviated month name in the current locale. %B gives you the full month 
name, both for Date directly and for yearmon:

R> format(Sys.Date(), "%B %Y")
[1] "April 2019"
R> format(as.yearmon(Sys.Date()), "%B %Y")
[1] "April 2019"


> Appreciate your pointer. Thanks,
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From e@ @end|ng |rom enr|co@chum@nn@net  Sat Apr 13 13:44:07 2019
From: e@ @end|ng |rom enr|co@chum@nn@net (Enrico Schumann)
Date: Sat, 13 Apr 2019 13:44:07 +0200
Subject: [R] Complete month name from as.yearmon()
In-Reply-To: <CA+dpOJkH9LCsMoSWdZK2XcFHX0aDfSrHFJhMoxrj+jQjcErL1Q@mail.gmail.com>
 (Christofer Bogaso's message of "Sat, 13 Apr 2019 16:44:30 +0530")
References: <CA+dpOJkH9LCsMoSWdZK2XcFHX0aDfSrHFJhMoxrj+jQjcErL1Q@mail.gmail.com>
Message-ID: <87sgum8708.fsf@enricoschumann.net>

>>>>> "CB" == Christofer Bogaso <bogaso.christofer at gmail.com> writes:

    CB> Hi,
    CB> I am wondering if there is any way to get the full name from as.yearmon()
    CB> function. Please consider below example:

    CB> library(quantmod)
    CB> as.yearmon(Sys.Date())

    CB> This gives: [1] "Apr 2019".

    CB> How can I extract the full name ie. 'April 2019'

    CB> Appreciate your pointer. Thanks,


library("zoo")   ## where 'as.yearmon' comes from
format(as.yearmon(Sys.Date()), "%B %Y")
## [1] "April 2019"

Note that this will give you the full monthname in your
locale.


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From @co|we|| @end|ng |rom uogue|ph@c@  Sat Apr 13 14:55:01 2019
From: @co|we|| @end|ng |rom uogue|ph@c@ (Scott Colwell)
Date: Sat, 13 Apr 2019 12:55:01 +0000
Subject: [R] 2019 Spring Workshops using R
Message-ID: <B7A9E59B-9A04-42CE-9B7E-E0431DD6862E@uoguelph.ca>

Apologies for any cross-postings.
Just a reminder that registration is open for four quantitative methods workshops in May of 2019. Each workshop features hands-on examples in Mplus and R, plus lots of opportunities to discuss the analysis for your own research.
For more information and to register, please see https://enablytics.com/workshop_events/
[1] Introductory Structural Equation Modeling - May 5, 2019
141 Adelaide Street West
Toronto, Ontario
M5H 3L5
This one-day hands-on workshop covers various introductory topics in structural equation modeling with continuous and categorical variables. Topics include, assumptions and data considerations, model creation, identification, and evaluation, multiple regression vs path analysis, path analysis, testing direct and indirect effects, and confirmatory factor analysis. Syntax and output for both Mplus and R will be provided for all examples covered in the workshop.
[2] Advanced Structural Equation Modeling - May 6, 2019
141 Adelaide Street West
Toronto, Ontario
M5H 3L5
This one-day hands-on workshop covers various advanced topics in structural equation modeling with continuous and categorical variables. Topics include, model creation, identification, and evaluation, testing moderation, mediation and moderated mediation, multiple group modeling, handling missing and messy data, measurement invariance and power analysis. Syntax and output for both Mplus and R will be provided for all examples covered in the workshop.
[3] Multilevel Modeling - May 7 and 8, 2019
141 Adelaide Street West
Toronto, Ontario
M5H 3L5
This two day hands-on workshop covers various topics in multilevel modeling with continuous and categorical variables. Topics include, when multilevel analysis is necessary, multilevel regression, random slopes and cross-level effects, multilevel confirmatory factor analysis and the MIMIC model, multilevel path analysis, multilevel mediation and moderation, multilevel latent variable modeling, longitudinal data, and power analysis. Syntax and output for both Mplus and R will be provided for all examples covered in the workshop.
[4] Growth Modeling - May 9 and 10, 2019
141 Adelaide Street West
Toronto, Ontario
M5H 3L5
This two-day hands-on workshop covers various topics in growth modeling (longitudinal modeling) with continuous and categorical variables. Topics include, growth modeling without covariates, growth modeling with time invariant and varying covariates, centering points, piecewise  growth modeling, autoregressive latent trajectory modeling (ALT


--
Scott R. Colwell, PhD, CStat, PStat


	[[alternative HTML version deleted]]


From motyoc@k@ @end|ng |rom y@hoo@com  Sat Apr 13 16:13:56 2019
From: motyoc@k@ @end|ng |rom y@hoo@com (Andras Farkas)
Date: Sat, 13 Apr 2019 14:13:56 +0000 (UTC)
Subject: [R] MuMIn package with gamlss error
References: <728248561.1182106.1555164836320.ref@mail.yahoo.com>
Message-ID: <728248561.1182106.1555164836320@mail.yahoo.com>

Hello,

could you please provide your thoughts on what I may be missing? gamlss models are supposedly supported by MuMIn yet this one fails:

library(MuMIn)

#this lm runs
linearMod <- lm(Sepal.Length ~ ., data=iris)?
options(na.action = "na.fail")
res <-dredge(linearMod,beta = T, evaluate = T)
confset.95p<-get.models(res, subset = cumsum(weight) <= .95)
avgm <- model.avg(confset.95p)
predict(avgm,se.fit = TRUE, type="response")

#this gamlss fails on dredge(), and writing out the formula does not solve the initial error...
gamlssMod <- gamlss(Sepal.Length ~ ., data=iris,)?
res <-dredge(gamlssMod,beta = T, evaluate = T)
confset.95p<-get.models(res, subset = cumsum(weight) <= .95)
avgm <- model.avg(confset.95p)
predict(avgm,se.fit = TRUE, type="response")
options(na.action = "na.omit")?


appreciate any thoughts you may have,

Andras?


From v@|kremk @end|ng |rom gm@||@com  Sun Apr 14 04:53:54 2019
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Sat, 13 Apr 2019 21:53:54 -0500
Subject: [R] create
Message-ID: <CAJOiR6a2FWtXNpR3qauimT55NssCPyiHt9F6f_qf9_qAeUUUUQ@mail.gmail.com>

Hi All,
I have a data frame  with several  columns  and I want to  create
another  column  by using  the values of the other columns.  My
problem is that some the row values  for some columns  have missing
values  and I could not get  the result I waned .

Here is the sample of my data and my attempt.

vdat<-read.table(text="obs, Year, x1, x2, x3
1,  2001, 25 ,10, 10
2,  2001,  ,  15, 25
3,  2001,  50, 10,
4,  2001,  20, , 60",sep=",",header=TRUE,stringsAsFactors=F)
vdat$xy <- 0
vdat$xy <- 2*(vdat$x1) + 5*(vdat$x2) + 3*(vdat$x3)
vdat

     obs Year x1 x2 x3  xy
1   1 2001 25 10 10 130
2   2 2001 NA 15 25  NA
3   3 2001 50 10 NA  NA
4   4 2001 20 NA 60  NA

The desired result si this,

   obs Year x1 x2 x3   xy
1   1 2001 25 10 10   130
2   2 2001 NA 15 25  150
3   3 2001 50 10 NA  150
4   4 2001 20 NA 60  220

How do I get my desired result?
Thank you


From drj|m|emon @end|ng |rom gm@||@com  Sun Apr 14 05:14:09 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sun, 14 Apr 2019 13:14:09 +1000
Subject: [R] create
In-Reply-To: <CAJOiR6a2FWtXNpR3qauimT55NssCPyiHt9F6f_qf9_qAeUUUUQ@mail.gmail.com>
References: <CAJOiR6a2FWtXNpR3qauimT55NssCPyiHt9F6f_qf9_qAeUUUUQ@mail.gmail.com>
Message-ID: <CA+8X3fVmnuA82t_hbOmk8SPP+zRMB-i-4OxmGL9Mff7zOuxExA@mail.gmail.com>

Hi Val,
For this particular problem, you can just replace NAs with zeros.

vdat[is.na(vdat)]<-0
vdat$xy <- 2*(vdat$x1) + 5*(vdat$x2) + 3*(vdat$x3)
vdat
 obs Year x1 x2 x3  xy
1   1 2001 25 10 10 130
2   2 2001  0 15 25 150
3   3 2001 50 10  0 150
4   4 2001 20  0 60 220

Note that this is not a general solution to the problem of NA values.

Jim

On Sun, Apr 14, 2019 at 12:54 PM Val <valkremk at gmail.com> wrote:
>
> Hi All,
> I have a data frame  with several  columns  and I want to  create
> another  column  by using  the values of the other columns.  My
> problem is that some the row values  for some columns  have missing
> values  and I could not get  the result I waned .
>
> Here is the sample of my data and my attempt.
>
> vdat<-read.table(text="obs, Year, x1, x2, x3
> 1,  2001, 25 ,10, 10
> 2,  2001,  ,  15, 25
> 3,  2001,  50, 10,
> 4,  2001,  20, , 60",sep=",",header=TRUE,stringsAsFactors=F)
> vdat$xy <- 0
> vdat$xy <- 2*(vdat$x1) + 5*(vdat$x2) + 3*(vdat$x3)
> vdat
>
>      obs Year x1 x2 x3  xy
> 1   1 2001 25 10 10 130
> 2   2 2001 NA 15 25  NA
> 3   3 2001 50 10 NA  NA
> 4   4 2001 20 NA 60  NA
>
> The desired result si this,
>
>    obs Year x1 x2 x3   xy
> 1   1 2001 25 10 10   130
> 2   2 2001 NA 15 25  150
> 3   3 2001 50 10 NA  150
> 4   4 2001 20 NA 60  220
>
> How do I get my desired result?
> Thank you
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Sun Apr 14 05:16:09 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 13 Apr 2019 20:16:09 -0700
Subject: [R] create
In-Reply-To: <CAJOiR6a2FWtXNpR3qauimT55NssCPyiHt9F6f_qf9_qAeUUUUQ@mail.gmail.com>
References: <CAJOiR6a2FWtXNpR3qauimT55NssCPyiHt9F6f_qf9_qAeUUUUQ@mail.gmail.com>
Message-ID: <CAGxFJbQE38DNUza1MTz7TOgrs_X9AJQjY6ct6BCf2mEFa5Fo1A@mail.gmail.com>

If the NA's are really 0's, replace them with 0 before doing the
calculation. (see ?is.na).
If they are not 0's, think again about doing this as the results would
probably mislead.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Apr 13, 2019 at 7:54 PM Val <valkremk at gmail.com> wrote:

> Hi All,
> I have a data frame  with several  columns  and I want to  create
> another  column  by using  the values of the other columns.  My
> problem is that some the row values  for some columns  have missing
> values  and I could not get  the result I waned .
>
> Here is the sample of my data and my attempt.
>
> vdat<-read.table(text="obs, Year, x1, x2, x3
> 1,  2001, 25 ,10, 10
> 2,  2001,  ,  15, 25
> 3,  2001,  50, 10,
> 4,  2001,  20, , 60",sep=",",header=TRUE,stringsAsFactors=F)
> vdat$xy <- 0
> vdat$xy <- 2*(vdat$x1) + 5*(vdat$x2) + 3*(vdat$x3)
> vdat
>
>      obs Year x1 x2 x3  xy
> 1   1 2001 25 10 10 130
> 2   2 2001 NA 15 25  NA
> 3   3 2001 50 10 NA  NA
> 4   4 2001 20 NA 60  NA
>
> The desired result si this,
>
>    obs Year x1 x2 x3   xy
> 1   1 2001 25 10 10   130
> 2   2 2001 NA 15 25  150
> 3   3 2001 50 10 NA  150
> 4   4 2001 20 NA 60  220
>
> How do I get my desired result?
> Thank you
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From v@|kremk @end|ng |rom gm@||@com  Sun Apr 14 05:29:59 2019
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Sat, 13 Apr 2019 22:29:59 -0500
Subject: [R] create
In-Reply-To: <CA+8X3fVmnuA82t_hbOmk8SPP+zRMB-i-4OxmGL9Mff7zOuxExA@mail.gmail.com>
References: <CAJOiR6a2FWtXNpR3qauimT55NssCPyiHt9F6f_qf9_qAeUUUUQ@mail.gmail.com>
 <CA+8X3fVmnuA82t_hbOmk8SPP+zRMB-i-4OxmGL9Mff7zOuxExA@mail.gmail.com>
Message-ID: <CAJOiR6bY5UU9SrAu4cSmV-MB9ZCBv+s27--kR=wEFLQex6jHMg@mail.gmail.com>

Hi Bert and Jim,
Thank you for the suggestion.
However, those missing values should not be replaced by 0's.
I want exclude those missing values from the calculation and create
the index using only the non-missing values.


On Sat, Apr 13, 2019 at 10:14 PM Jim Lemon <drjimlemon at gmail.com> wrote:
>
> Hi Val,
> For this particular problem, you can just replace NAs with zeros.
>
> vdat[is.na(vdat)]<-0
> vdat$xy <- 2*(vdat$x1) + 5*(vdat$x2) + 3*(vdat$x3)
> vdat
>  obs Year x1 x2 x3  xy
> 1   1 2001 25 10 10 130
> 2   2 2001  0 15 25 150
> 3   3 2001 50 10  0 150
> 4   4 2001 20  0 60 220
>
> Note that this is not a general solution to the problem of NA values.
>
> Jim
>
> On Sun, Apr 14, 2019 at 12:54 PM Val <valkremk at gmail.com> wrote:
> >
> > Hi All,
> > I have a data frame  with several  columns  and I want to  create
> > another  column  by using  the values of the other columns.  My
> > problem is that some the row values  for some columns  have missing
> > values  and I could not get  the result I waned .
> >
> > Here is the sample of my data and my attempt.
> >
> > vdat<-read.table(text="obs, Year, x1, x2, x3
> > 1,  2001, 25 ,10, 10
> > 2,  2001,  ,  15, 25
> > 3,  2001,  50, 10,
> > 4,  2001,  20, , 60",sep=",",header=TRUE,stringsAsFactors=F)
> > vdat$xy <- 0
> > vdat$xy <- 2*(vdat$x1) + 5*(vdat$x2) + 3*(vdat$x3)
> > vdat
> >
> >      obs Year x1 x2 x3  xy
> > 1   1 2001 25 10 10 130
> > 2   2 2001 NA 15 25  NA
> > 3   3 2001 50 10 NA  NA
> > 4   4 2001 20 NA 60  NA
> >
> > The desired result si this,
> >
> >    obs Year x1 x2 x3   xy
> > 1   1 2001 25 10 10   130
> > 2   2 2001 NA 15 25  150
> > 3   3 2001 50 10 NA  150
> > 4   4 2001 20 NA 60  220
> >
> > How do I get my desired result?
> > Thank you
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Apr 14 05:42:53 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 13 Apr 2019 20:42:53 -0700
Subject: [R] create
In-Reply-To: <CAJOiR6bY5UU9SrAu4cSmV-MB9ZCBv+s27--kR=wEFLQex6jHMg@mail.gmail.com>
References: <CAJOiR6a2FWtXNpR3qauimT55NssCPyiHt9F6f_qf9_qAeUUUUQ@mail.gmail.com>
 <CA+8X3fVmnuA82t_hbOmk8SPP+zRMB-i-4OxmGL9Mff7zOuxExA@mail.gmail.com>
 <CAJOiR6bY5UU9SrAu4cSmV-MB9ZCBv+s27--kR=wEFLQex6jHMg@mail.gmail.com>
Message-ID: <F9E47209-FF6A-4EBB-9681-BDAEFC1E9EAC@dcn.davis.ca.us>

Looks to me like your initial request contradicts your clarification. Can you explain this discrepancy?

On April 13, 2019 8:29:59 PM PDT, Val <valkremk at gmail.com> wrote:
>Hi Bert and Jim,
>Thank you for the suggestion.
>However, those missing values should not be replaced by 0's.
>I want exclude those missing values from the calculation and create
>the index using only the non-missing values.
>
>
>On Sat, Apr 13, 2019 at 10:14 PM Jim Lemon <drjimlemon at gmail.com>
>wrote:
>>
>> Hi Val,
>> For this particular problem, you can just replace NAs with zeros.
>>
>> vdat[is.na(vdat)]<-0
>> vdat$xy <- 2*(vdat$x1) + 5*(vdat$x2) + 3*(vdat$x3)
>> vdat
>>  obs Year x1 x2 x3  xy
>> 1   1 2001 25 10 10 130
>> 2   2 2001  0 15 25 150
>> 3   3 2001 50 10  0 150
>> 4   4 2001 20  0 60 220
>>
>> Note that this is not a general solution to the problem of NA values.
>>
>> Jim
>>
>> On Sun, Apr 14, 2019 at 12:54 PM Val <valkremk at gmail.com> wrote:
>> >
>> > Hi All,
>> > I have a data frame  with several  columns  and I want to  create
>> > another  column  by using  the values of the other columns.  My
>> > problem is that some the row values  for some columns  have missing
>> > values  and I could not get  the result I waned .
>> >
>> > Here is the sample of my data and my attempt.
>> >
>> > vdat<-read.table(text="obs, Year, x1, x2, x3
>> > 1,  2001, 25 ,10, 10
>> > 2,  2001,  ,  15, 25
>> > 3,  2001,  50, 10,
>> > 4,  2001,  20, , 60",sep=",",header=TRUE,stringsAsFactors=F)
>> > vdat$xy <- 0
>> > vdat$xy <- 2*(vdat$x1) + 5*(vdat$x2) + 3*(vdat$x3)
>> > vdat
>> >
>> >      obs Year x1 x2 x3  xy
>> > 1   1 2001 25 10 10 130
>> > 2   2 2001 NA 15 25  NA
>> > 3   3 2001 50 10 NA  NA
>> > 4   4 2001 20 NA 60  NA
>> >
>> > The desired result si this,
>> >
>> >    obs Year x1 x2 x3   xy
>> > 1   1 2001 25 10 10   130
>> > 2   2 2001 NA 15 25  150
>> > 3   3 2001 50 10 NA  150
>> > 4   4 2001 20 NA 60  220
>> >
>> > How do I get my desired result?
>> > Thank you
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From v@|kremk @end|ng |rom gm@||@com  Sun Apr 14 06:01:30 2019
From: v@|kremk @end|ng |rom gm@||@com (Val)
Date: Sat, 13 Apr 2019 23:01:30 -0500
Subject: [R] create
In-Reply-To: <F9E47209-FF6A-4EBB-9681-BDAEFC1E9EAC@dcn.davis.ca.us>
References: <CAJOiR6a2FWtXNpR3qauimT55NssCPyiHt9F6f_qf9_qAeUUUUQ@mail.gmail.com>
 <CA+8X3fVmnuA82t_hbOmk8SPP+zRMB-i-4OxmGL9Mff7zOuxExA@mail.gmail.com>
 <CAJOiR6bY5UU9SrAu4cSmV-MB9ZCBv+s27--kR=wEFLQex6jHMg@mail.gmail.com>
 <F9E47209-FF6A-4EBB-9681-BDAEFC1E9EAC@dcn.davis.ca.us>
Message-ID: <CAJOiR6ZmpuwrhUKSdgsEudHaZ322C=ZJbVvhfFf21UcCW-iAPA@mail.gmail.com>

Sorry for the confusion, my sample data  does not represent  the
actual data set.

The range of  value can be  from -ve to +ve values and 0 could be a
true value of an observation. So, instead of replacing  missing value
by zero, I want  exclude them  from the  calculation.

On Sat, Apr 13, 2019 at 10:42 PM Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
>
> Looks to me like your initial request contradicts your clarification. Can you explain this discrepancy?
>
> On April 13, 2019 8:29:59 PM PDT, Val <valkremk at gmail.com> wrote:
> >Hi Bert and Jim,
> >Thank you for the suggestion.
> >However, those missing values should not be replaced by 0's.
> >I want exclude those missing values from the calculation and create
> >the index using only the non-missing values.
> >
> >
> >On Sat, Apr 13, 2019 at 10:14 PM Jim Lemon <drjimlemon at gmail.com>
> >wrote:
> >>
> >> Hi Val,
> >> For this particular problem, you can just replace NAs with zeros.
> >>
> >> vdat[is.na(vdat)]<-0
> >> vdat$xy <- 2*(vdat$x1) + 5*(vdat$x2) + 3*(vdat$x3)
> >> vdat
> >>  obs Year x1 x2 x3  xy
> >> 1   1 2001 25 10 10 130
> >> 2   2 2001  0 15 25 150
> >> 3   3 2001 50 10  0 150
> >> 4   4 2001 20  0 60 220
> >>
> >> Note that this is not a general solution to the problem of NA values.
> >>
> >> Jim
> >>
> >> On Sun, Apr 14, 2019 at 12:54 PM Val <valkremk at gmail.com> wrote:
> >> >
> >> > Hi All,
> >> > I have a data frame  with several  columns  and I want to  create
> >> > another  column  by using  the values of the other columns.  My
> >> > problem is that some the row values  for some columns  have missing
> >> > values  and I could not get  the result I waned .
> >> >
> >> > Here is the sample of my data and my attempt.
> >> >
> >> > vdat<-read.table(text="obs, Year, x1, x2, x3
> >> > 1,  2001, 25 ,10, 10
> >> > 2,  2001,  ,  15, 25
> >> > 3,  2001,  50, 10,
> >> > 4,  2001,  20, , 60",sep=",",header=TRUE,stringsAsFactors=F)
> >> > vdat$xy <- 0
> >> > vdat$xy <- 2*(vdat$x1) + 5*(vdat$x2) + 3*(vdat$x3)
> >> > vdat
> >> >
> >> >      obs Year x1 x2 x3  xy
> >> > 1   1 2001 25 10 10 130
> >> > 2   2 2001 NA 15 25  NA
> >> > 3   3 2001 50 10 NA  NA
> >> > 4   4 2001 20 NA 60  NA
> >> >
> >> > The desired result si this,
> >> >
> >> >    obs Year x1 x2 x3   xy
> >> > 1   1 2001 25 10 10   130
> >> > 2   2 2001 NA 15 25  150
> >> > 3   3 2001 50 10 NA  150
> >> > 4   4 2001 20 NA 60  220
> >> >
> >> > How do I get my desired result?
> >> > Thank you
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.


From dd@|thorp @end|ng |rom u@g@@gov  Sun Apr 14 06:50:18 2019
From: dd@|thorp @end|ng |rom u@g@@gov (Dalthorp, Daniel)
Date: Sat, 13 Apr 2019 21:50:18 -0700
Subject: [R] [EXTERNAL] Re:  create
In-Reply-To: <CAJOiR6ZmpuwrhUKSdgsEudHaZ322C=ZJbVvhfFf21UcCW-iAPA@mail.gmail.com>
References: <CAJOiR6a2FWtXNpR3qauimT55NssCPyiHt9F6f_qf9_qAeUUUUQ@mail.gmail.com>
 <CA+8X3fVmnuA82t_hbOmk8SPP+zRMB-i-4OxmGL9Mff7zOuxExA@mail.gmail.com>
 <CAJOiR6bY5UU9SrAu4cSmV-MB9ZCBv+s27--kR=wEFLQex6jHMg@mail.gmail.com>
 <F9E47209-FF6A-4EBB-9681-BDAEFC1E9EAC@dcn.davis.ca.us>
 <CAJOiR6ZmpuwrhUKSdgsEudHaZ322C=ZJbVvhfFf21UcCW-iAPA@mail.gmail.com>
Message-ID: <CAJeYpE-xjeeyMBfw11brwjU7PL4gDrvG7Ve7Rfd5K8yQU-RE1Q@mail.gmail.com>

how about one of the following?

vdat$xy <- 2 * (ifelse(is.na(vdat$x1), 0, vdat$x1)) + 5 *
(ifelse(is.na(vdat$x2),
0, vdat$x2)) + 3 * (ifelse(is.na(vdat$x3), 0, vdat$x3))

vdat$xy <- ifelse(is.na(as.matrix(vdat[, paste0("x", 1:3)])), 0,
as.matrix(vdat[, paste0("x", 1:3)])) %*% c(2, 5, 3)

On Sat, Apr 13, 2019 at 9:02 PM Val <valkremk at gmail.com> wrote:

> Sorry for the confusion, my sample data  does not represent  the
> actual data set.
>
> The range of  value can be  from -ve to +ve values and 0 could be a
> true value of an observation. So, instead of replacing  missing value
> by zero, I want  exclude them  from the  calculation.
>
> On Sat, Apr 13, 2019 at 10:42 PM Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
> >
> > Looks to me like your initial request contradicts your clarification.
> Can you explain this discrepancy?
> >
> > On April 13, 2019 8:29:59 PM PDT, Val <valkremk at gmail.com> wrote:
> > >Hi Bert and Jim,
> > >Thank you for the suggestion.
> > >However, those missing values should not be replaced by 0's.
> > >I want exclude those missing values from the calculation and create
> > >the index using only the non-missing values.
> > >
> > >
> > >On Sat, Apr 13, 2019 at 10:14 PM Jim Lemon <drjimlemon at gmail.com>
> > >wrote:
> > >>
> > >> Hi Val,
> > >> For this particular problem, you can just replace NAs with zeros.
> > >>
> > >> vdat[is.na(vdat)]<-0
> > >> vdat$xy <- 2*(vdat$x1) + 5*(vdat$x2) + 3*(vdat$x3)
> > >> vdat
> > >>  obs Year x1 x2 x3  xy
> > >> 1   1 2001 25 10 10 130
> > >> 2   2 2001  0 15 25 150
> > >> 3   3 2001 50 10  0 150
> > >> 4   4 2001 20  0 60 220
> > >>
> > >> Note that this is not a general solution to the problem of NA values.
> > >>
> > >> Jim
> > >>
> > >> On Sun, Apr 14, 2019 at 12:54 PM Val <valkremk at gmail.com> wrote:
> > >> >
> > >> > Hi All,
> > >> > I have a data frame  with several  columns  and I want to  create
> > >> > another  column  by using  the values of the other columns.  My
> > >> > problem is that some the row values  for some columns  have missing
> > >> > values  and I could not get  the result I waned .
> > >> >
> > >> > Here is the sample of my data and my attempt.
> > >> >
> > >> > vdat<-read.table(text="obs, Year, x1, x2, x3
> > >> > 1,  2001, 25 ,10, 10
> > >> > 2,  2001,  ,  15, 25
> > >> > 3,  2001,  50, 10,
> > >> > 4,  2001,  20, , 60",sep=",",header=TRUE,stringsAsFactors=F)
> > >> > vdat$xy <- 0
> > >> > vdat$xy <- 2*(vdat$x1) + 5*(vdat$x2) + 3*(vdat$x3)
> > >> > vdat
> > >> >
> > >> >      obs Year x1 x2 x3  xy
> > >> > 1   1 2001 25 10 10 130
> > >> > 2   2 2001 NA 15 25  NA
> > >> > 3   3 2001 50 10 NA  NA
> > >> > 4   4 2001 20 NA 60  NA
> > >> >
> > >> > The desired result si this,
> > >> >
> > >> >    obs Year x1 x2 x3   xy
> > >> > 1   1 2001 25 10 10   130
> > >> > 2   2 2001 NA 15 25  150
> > >> > 3   3 2001 50 10 NA  150
> > >> > 4   4 2001 20 NA 60  220
> > >> >
> > >> > How do I get my desired result?
> > >> > Thank you
> > >> >
> > >> > ______________________________________________
> > >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> > https://stat.ethz.ch/mailman/listinfo/r-help
> > >> > PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >> > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Dan Dalthorp, PhD
USGS Forest and Rangeland Ecosystem Science Center
Forest Sciences Lab, Rm 311
3200 SW Jefferson Way
Corvallis, OR 97331
ph: 541-750-0953
ddalthorp at usgs.gov

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sun Apr 14 07:04:20 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 13 Apr 2019 22:04:20 -0700
Subject: [R] create
In-Reply-To: <CAJOiR6ZmpuwrhUKSdgsEudHaZ322C=ZJbVvhfFf21UcCW-iAPA@mail.gmail.com>
References: <CAJOiR6a2FWtXNpR3qauimT55NssCPyiHt9F6f_qf9_qAeUUUUQ@mail.gmail.com>
 <CA+8X3fVmnuA82t_hbOmk8SPP+zRMB-i-4OxmGL9Mff7zOuxExA@mail.gmail.com>
 <CAJOiR6bY5UU9SrAu4cSmV-MB9ZCBv+s27--kR=wEFLQex6jHMg@mail.gmail.com>
 <F9E47209-FF6A-4EBB-9681-BDAEFC1E9EAC@dcn.davis.ca.us>
 <CAJOiR6ZmpuwrhUKSdgsEudHaZ322C=ZJbVvhfFf21UcCW-iAPA@mail.gmail.com>
Message-ID: <CAGxFJbRqFE3mgwJSW8d+aboBWmU0V=cgMYTu_PtVswapVv=Apw@mail.gmail.com>

Just use a temporary variable!

## You should apply is.na() only to the numeric columns you need, not the
whole data frame
## see ?'[' for why.
vnew <- vdat[,3:5]
vnew[is.na(vnew)] <- 0
vdat$xy <- as.matrix(vnew) %*% c(2, 5, 3)
vdat

I still question whether this is wise; but that's for you to determine.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Apr 13, 2019 at 9:01 PM Val <valkremk at gmail.com> wrote:

> Sorry for the confusion, my sample data  does not represent  the
> actual data set.
>
> The range of  value can be  from -ve to +ve values and 0 could be a
> true value of an observation. So, instead of replacing  missing value
> by zero, I want  exclude them  from the  calculation.
>
> On Sat, Apr 13, 2019 at 10:42 PM Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
> >
> > Looks to me like your initial request contradicts your clarification.
> Can you explain this discrepancy?
> >
> > On April 13, 2019 8:29:59 PM PDT, Val <valkremk at gmail.com> wrote:
> > >Hi Bert and Jim,
> > >Thank you for the suggestion.
> > >However, those missing values should not be replaced by 0's.
> > >I want exclude those missing values from the calculation and create
> > >the index using only the non-missing values.
> > >
> > >
> > >On Sat, Apr 13, 2019 at 10:14 PM Jim Lemon <drjimlemon at gmail.com>
> > >wrote:
> > >>
> > >> Hi Val,
> > >> For this particular problem, you can just replace NAs with zeros.
> > >>
> > >> vdat[is.na(vdat)]<-0
> > >> vdat$xy <- 2*(vdat$x1) + 5*(vdat$x2) + 3*(vdat$x3)
> > >> vdat
> > >>  obs Year x1 x2 x3  xy
> > >> 1   1 2001 25 10 10 130
> > >> 2   2 2001  0 15 25 150
> > >> 3   3 2001 50 10  0 150
> > >> 4   4 2001 20  0 60 220
> > >>
> > >> Note that this is not a general solution to the problem of NA values.
> > >>
> > >> Jim
> > >>
> > >> On Sun, Apr 14, 2019 at 12:54 PM Val <valkremk at gmail.com> wrote:
> > >> >
> > >> > Hi All,
> > >> > I have a data frame  with several  columns  and I want to  create
> > >> > another  column  by using  the values of the other columns.  My
> > >> > problem is that some the row values  for some columns  have missing
> > >> > values  and I could not get  the result I waned .
> > >> >
> > >> > Here is the sample of my data and my attempt.
> > >> >
> > >> > vdat<-read.table(text="obs, Year, x1, x2, x3
> > >> > 1,  2001, 25 ,10, 10
> > >> > 2,  2001,  ,  15, 25
> > >> > 3,  2001,  50, 10,
> > >> > 4,  2001,  20, , 60",sep=",",header=TRUE,stringsAsFactors=F)
> > >> > vdat$xy <- 0
> > >> > vdat$xy <- 2*(vdat$x1) + 5*(vdat$x2) + 3*(vdat$x3)
> > >> > vdat
> > >> >
> > >> >      obs Year x1 x2 x3  xy
> > >> > 1   1 2001 25 10 10 130
> > >> > 2   2 2001 NA 15 25  NA
> > >> > 3   3 2001 50 10 NA  NA
> > >> > 4   4 2001 20 NA 60  NA
> > >> >
> > >> > The desired result si this,
> > >> >
> > >> >    obs Year x1 x2 x3   xy
> > >> > 1   1 2001 25 10 10   130
> > >> > 2   2 2001 NA 15 25  150
> > >> > 3   3 2001 50 10 NA  150
> > >> > 4   4 2001 20 NA 60  220
> > >> >
> > >> > How do I get my desired result?
> > >> > Thank you
> > >> >
> > >> > ______________________________________________
> > >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> > https://stat.ethz.ch/mailman/listinfo/r-help
> > >> > PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >> > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wjm1 @end|ng |rom c@@@co|umb|@@edu  Sun Apr 14 10:45:26 2019
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Sun, 14 Apr 2019 01:45:26 -0700
Subject: [R] Creating a mean line plot
In-Reply-To: <683389861.330190.1555087182209@mail.yahoo.com>
References: <958032223.2037452.1555019858964.ref@mail.yahoo.com>
 <958032223.2037452.1555019858964@mail.yahoo.com>
 <CAGgJW766s7r3NxpScyhJfkRF6tdAutnOzDEHEUrfVY8rE76dxA@mail.gmail.com>
 <683389861.330190.1555087182209@mail.yahoo.com>
Message-ID: <CAA99HCwymHC6Q_caQ2L1QaGwndWSpsWgu=mEjSzJx2wrTqDC2g@mail.gmail.com>

So you're saying rowMeans(cbind(matrix_a, matrix_b)) worked to obtain
your X-axis values?

Wild guess here, are you simply looking for:
colMeans(rbind(matrix_a, matrix_b)) to obtain your Y-axis values?

[Above assuming matrix_a and matrix_b have identical dimensions (nrow, ncol)].

--Bill

William Michels, Ph.D.


On Fri, Apr 12, 2019 at 11:09 AM rain1290--- via R-help






<r-help at r-project.org> wrote:
>
> Hi Eric,
>
> Ah, I apologize, and thank you for your response!
> I just figured out a way to average my x-values, so at least that is solved. I will still include the data for the two variables (1-dimensional) of interest that I was trying to average, just to show what was done:
> get2.teratons #(90 values)
> get5.teratons #(90 values)
> Here is what get2.teratons looks like (same idea for get5.teratons):
>     >print(get2.teratons)
>     [1] 0.4558545 0.4651129 0.4747509 0.4848242 0.4950900 0.5056109 0.5159335
>     0.5262532 0.5372275 0.5481839 0.5586787 0.5694379 0.5802970
>     [14] 0.5909211 0.6015753 0.6124256 0.6237733 0.6353634 0.6467227 0.6582857
>     0.6702509 0.6817027 0.6935311 0.7060161 0.7182312 0.7301909
>     [27] 0.7422574 0.7544744 0.7665907 0.7786409 0.7907518 0.8032732 0.8158733
>     0.8284363 0.8413905 0.8545881 0.8674711 0.8797701 0.8927392
>     [40] 0.9059937 0.9189707 0.9317215 0.9438155 0.9558035 0.9673665 0.9784927
>     0.9900898 1.0020388 1.0132683 1.0240023 1.0347708 1.0456077
>     [53] 1.0570347 1.0682903 1.0793535 1.0901511 1.1001753 1.1101276 1.1199142
>     1.1293237 1.1384669 1.1470002 1.1547341 1.1622488 1.1697549
>     [66] 1.1777542 1.1857587 1.1930233 1.1999645 1.2067172 1.2132979 1.2199317
>     1.2265673 1.2328599 1.2390689 1.2446050 1.2495579 1.2546455
>     [79] 1.2599212 1.2648733 1.2700068 1.2753889 1.2807509 1.2856922 1.2905927
>     1.2953338 1.3000484 1.3045992 1.3091128 1.3144190
> The following worked in terms of averaging all of the elements of get2.teratons and get5.teratons:
> rowMeans(cbind(get2.teratons,get5.teratons))
> However, I am trying to do something similar for the values on my y-axis. So, for now, here are the two variables (3-dimensional) that I would like to average:
>     subset
>     subset5
> Using the print function for "subset" (same idea for subset5):    >print(subset)
>     class       : RasterStack
>     dimensions  : 64, 128, 8192, 90  (nrow, ncol, ncell, nlayers)
>     resolution  : 2.8125, 2.789327  (x, y)
>     extent      : -181.4062, 178.5938, -89.25846, 89.25846  (xmin, xmax, ymin,
>     ymax)
>     coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
>     names       : X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14,
>     X15, ...     >dim(subset)
>     [1]  64 128  90>dim(subset5)
>     [1]  64 128  90
> I tried `mean(subset,subset5)`, which works, BUT it combines the 90 layers into 1 layer. I want keep the number of layers at 90, but simply average each of the grid cell values of "subset" and "subset5" for each layer. So, for instance, I want to average the values of each grid cell of layer 1 of "subset" with the values of each grid cell of layer 1 of "subset5", and then average those values of layer 2 of "subset" with those values of layer 2 of "subset5"......all the way to layer 90. That way, I have 90 averages across all grid cells.
> Here is what the data looks like for "subset":
> >dput(head(subset,5))
>     structure(c(11.5447145886719, 11.2479725852609, 10.0223480723798,
>     11.4909216295928, 12.5930442474782, 15.0295264553279, 14.6107862703502,
>     13.3623332250863, 10.4473929153755, 13.262210553512, 13.3166334126145,
>     13.7211008928716, 10.594900790602, 11.7217378690839, 10.8397546224296,
>     14.2727348953485, 13.6185416020453, 12.7485566306859, 11.7246472276747,
>     10.6815265025944, 13.1605062168092, 12.9131189547479, 12.6493454910815,
>     11.6938022430986, 11.4522186107934, 8.84930260945112, 11.5785481408238,
>     12.9859233275056, 13.6702361516654, 11.863912967965, 11.6624090820551,
>     12.1465771459043, 12.9789240192622, 13.5916746687144, 15.0383287109435,
>     7.89674604311585, 8.14079332631081, 7.05628590658307, 6.99759456329048,
>     8.06435288395733, 8.00622920505702, 7.35754533670843, 6.57949370797724,
>     6.26998774241656, 6.10911303665489, 10.1576759945601, 9.83650996349752,
>     10.6277788057923, 10.3647025069222, 9.38627037685364, 28.411143925041,
>     27.3436004295945, 25.7670222781599, 24.1854049265385, 22.7183715440333,
>     10.8529561199248, 11.1584928352386, 11.4545458462089, 11.7570801638067,
>     11.6314635146409, 13.7268429156393, 12.4547378160059, 12.8433785866946,
>     10.282119596377, 9.66278391424567, 6.39572446234524, 8.4569685626775,
>     12.253624945879, 12.4784250743687, 13.6823802720755, 8.65540341474116,
>     8.34308553021401, 8.30261853989214, 7.9798299819231, 7.96007991302758,
>     13.3976918645203, 15.2056947816163, 15.3097502421588, 18.0296610575169,
>     17.918016621843, 14.121591579169, 14.3091559410095, 14.7470911033452,
>     15.414851764217, 15.8059203531593, 22.9126498103142, 21.5608592145145,
>     19.7303873486817, 17.5689237657934, 15.4688697773963, 10.2526041911915,
>     10.4463449679315, 9.85705149360001, 9.5394266070798, 9.17961853556335,
>     14.064371259883, 12.626935634762, 12.1540617663413, 10.9235350973904,
>     9.32216013316065, 12.3676003888249, 12.9718807060272, 14.5685050170869,
>     13.8497828040272, 14.0683455392718, 8.09576804749668, 8.54510050266981,
>     8.02388715092093, 8.6679536383599, 9.38348234631121, 11.6279292851686,
>     11.5998465567827, 11.6469369269907, 11.6286710835993, 10.8152111526579,
>     17.4072104506195, 18.9169261604548, 19.5168524980545, 19.0377978142351,
>     19.5594304706901, 9.74474258255213, 10.2144323755056, 10.9722976572812,
>     11.5369332488626, 12.0274581480771, 14.007618650794, 14.0536692459136,
>     14.4861201290041, 14.133819937706, 13.045089924708, 19.9330265633762,
>     20.3158976510167, 21.4452845044434, 19.9475897010416, 20.3566399868578,
>     15.703826257959, 14.8260951507837, 14.6203982178122, 14.0476305037737,
>     13.2086589932442, 6.5044054761529, 6.51829722337425, 6.59741191193461,
>     6.57343484926969, 7.07112564705312, 8.42645864468068, 9.15604883339256,
>     10.8542435802519, 8.57339131180197, 7.89698304142803, 10.6029914226383,
>     9.90388663485646, 8.46301421988755, 12.9162973724306, 9.06370310112834,
>     9.92726711556315, 11.5754703059793, 8.74886247329414, 8.99941809475422,
>     9.90840594749898, 11.1468604300171, 11.1322306562215, 10.49438144546,
>     9.50155213940889, 8.31737467087805, 5.76932597905397, 6.14411209244281,
>     7.39980584476143, 8.47632132936269, 8.00714262295514, 8.64454926922917,
>     7.79559868387878, 7.14818593114614, 7.42282171268016, 9.04718739911914,
>     12.0141573250294, 11.0411503817886, 11.7892528418452, 11.2668004352599,
>     10.5345542309806, 14.2355003859848, 12.4114783946425, 13.1144292186946,
>     14.3049817532301, 14.7282858844846, 9.90791183430701, 10.4058899218217,
>     12.0624131988734, 13.2521220948547, 13.9345653355122, 12.5256763771176,
>     12.3285478446633, 11.9927407242358, 11.6441268939525, 11.6448875516653,
>     30.5602320469916, 30.6964941322803, 27.3358505219221, 27.5474566966295,
>     24.3847575969994, 15.1250814087689, 15.0272130500525, 14.9795342702419,
>     14.2658210825175, 13.437497522682, 10.7001833617687, 10.0823557935655,
>     10.1298170629889, 9.99525294173509, 10.6919908896089, 9.04134479351342,
>     9.57930330187082, 9.58402880933136, 8.82056106347591, 9.06912200152874,
>     11.0435656271875, 12.827942892909, 14.6962288767099, 15.984565531835,
>     16.3673574104905, 17.7882182411849, 17.1887206379324, 16.4347139652818,
>     15.4833788517863, 14.3649869598448, 10.0324214436114, 10.9937381464988,
>     10.7803415972739, 10.64134365879, 10.3700830601156, 10.7242427766323,
>     10.1225153775886, 9.59254063200206, 9.67734202276915, 9.9705743137747,
>     6.15209711249918, 7.6417050557211, 9.55170588567853, 12.123644258827,
>     14.6793850231916, 13.8236853294075, 14.3564789090306, 13.6828002054244,
>     13.0476749036461, 12.3909330926836, 12.5938401091844, 12.5098232645541,
>     12.4792913440615, 10.5595408938825, 10.0890464382246, 9.20089432038367,
>     8.92592284362763, 8.59467086847872, 9.42603517323732, 10.0353622343391,
>     11.7311725392938, 12.4379832297564, 12.9343897104263, 12.9055073484778,
>     10.8944955747575, 13.6480727232993, 13.5285727679729, 13.1794585380703,
>     12.8222310449928, 12.3997843824327, 12.7413347829133, 14.3273916095495,
>     17.3931313678622, 18.2263168506324, 18.5841742437333, 6.59096706658602,
>     6.43405092414469, 6.25825286842883, 6.41100551001728, 6.47397979628295,
>     10.5375754879788, 11.7441980168223, 12.6210678834468, 13.6038213036954,
>     14.3639346119016, 14.6688716020435, 14.1826340463012, 15.2044224087149,
>     15.5630568042397, 15.0458208750933, 10.0154311163351, 9.7418615128845,
>     11.8866622913629, 10.4000290855765, 9.74880487192422, 12.071524746716,
>     11.5644979756325, 11.0723461490124, 10.6282578315586, 10.2157085202634,
>     14.5142644643784, 12.1188929770142, 12.3748247511685, 12.4087903182954,
>     11.9534945581108, 9.04913682024926, 10.3765605948865, 11.6044067312032,
>     11.8693192955106, 11.4852412138134, 9.60276927798986, 8.47671863157302,
>     6.53922976925969, 6.61022553686053, 6.93009907845408, 13.2296028546989,
>     13.0423339549452, 13.0597360432148, 12.6910961698741, 12.4157820828259,
>     10.1926731644198, 8.71818219311535, 7.08254557102919, 8.77621911931783,
>     10.0059285527095, 12.931788386777, 12.2630294412374, 11.4822425879538,
>     10.4378029704094, 9.7940765786916, 13.0133786704391, 11.9061049539596,
>     12.0638377033174, 12.3013137839735, 12.9490484017879, 13.2149957120419,
>     13.1087802350521, 12.6286820042878, 12.2278920840472, 11.8682594038546,
>     10.9492189250886, 12.2341319918633, 12.9464382771403, 12.5120461452752,
>     12.5263502821326, 12.6686599105597, 12.7322974149138, 12.1948833111674,
>     12.1215357910842, 11.9392029941082, 15.2677292469889, 16.3731585256755,
>     17.8960581310093, 18.6334447469562, 19.5818214677274, 8.80653981585056,
>     9.830889897421, 9.35642933472991, 8.49255602806807, 9.19627505354583,
>     9.56638909410685, 10.4608207242563, 11.0053240321577, 12.0839668437839,
>     12.6748947892338, 10.9087632503361, 11.0474556684494, 9.86553691327572,
>     11.7183218244463, 12.5948534812778, 9.51134513597935, 7.67265690956265,
>     8.47005187533796, 8.948102616705, 9.48919930960983, 8.92916852608323,
>     9.19180226046592, 9.93818349670619, 10.3347131051123, 9.19244724791497,
>     16.0914938896894, 16.6821955237538, 17.9938221350312, 19.0754321403801,
>     19.048942392692, 8.59134346246719, 8.39548541698605, 8.17942153662443,
>     8.02843223791569, 8.9953287737444, 7.97593365423381, 7.71139136049896,
>     7.85907462704927, 8.38070099707693, 9.28482818417251, 11.3056178670377,
>     11.601750086993, 11.2711317837238, 10.8186058234423, 10.7581429649144,
>     15.6826636288315, 16.9076268095523, 15.4331855010241, 15.1698420289904,
>     14.4226460717618, 11.3487603608519, 10.932231741026, 10.3945284616202,
>     9.96728525497019, 9.48596934322268, 10.508708213456, 10.0394641282037,
>     10.5090778553858, 10.1252990076318, 9.86525025218725, 21.985590364784,
>     22.3454732447863, 22.693102620542, 22.8635905310512, 23.2176823541522,
>     18.6908649746329, 16.1407203879207, 14.8633007425815, 13.0084274802357,
>     10.3990704054013, 6.98735397309065, 6.87530469149351, 8.9313744334504,
>     7.93048026971519, 8.05362006649375, 7.19595712143928, 6.09859018586576,
>     7.31170470826328, 8.58990701381117, 8.4448722191155, 10.6643167790025,
>     10.839969618246, 10.5106293456629, 10.4457534151152, 11.2185546196997,
>     12.6707960385829, 12.9902018699795, 12.9533659201115, 12.501154281199,
>     12.3501065187156, 25.9615670889616, 28.099115844816, 30.2258117124438,
>     32.2391155175865, 34.1092220507562, 13.0570391658694, 14.2825467512012,
>     11.1714780796319, 9.62660552468151, 13.1034480873495, 12.0462608523667,
>     12.1476030908525, 12.087664520368, 12.486698012799, 12.6554797869176,
>     12.9096878226846, 13.7426960282028, 15.2569429948926, 17.1046711038798,
>     17.0782153028995, 8.75586932525039, 8.82860643323511, 8.69223182089627,
>     9.15108947083354, 9.4462743261829, 8.55356580577791, 8.69411900639534,
>     8.9102350641042, 9.00506707839668, 8.75238287262619, 12.8364848904312,
>     14.6456281654537, 13.9498212374747, 14.5683591719717, 14.3893217202276,
>     15.1805742178112, 16.7262759525329, 17.7521643228829, 18.5243777465075,
>     18.8792126253247, 7.70680792629719, 7.47225251980126, 7.72799758706242,
>     7.68415729980916, 7.50800217501819, 9.68811193015426, 10.5253741610795,
>     10.922572016716, 10.9020531177521, 10.406608460471, 22.1927281469107,
>     21.7946967110038, 22.5350291468203, 22.0015277154744, 23.2784972526133,
>     25.1319196075201, 24.1645314730704, 23.0207713320851, 14.8746414575726,
>     12.5255933962762, 19.3960575386882, 19.3368871696293, 19.8454126249999,
>     19.8410699609667, 19.8172997217625, 12.1799279004335, 11.8857935070992,
>     11.4909932948649, 11.3612791523337, 10.8840802218765, 11.1973982769996,
>     11.6429010406137, 11.2867686431855, 11.5507948212326, 11.7122428491712,
>     13.8513946440071, 14.9497504346073, 14.425096521154, 13.2822252810001,
>     12.4311964027584, 18.864199379459, 17.5528808031231, 17.7616731729358,
>     17.1655979007483, 16.6251927148551, 29.3679255992174, 28.4771841019392,
>     27.9151875525713, 26.65377818048, 25.2528126351535, 10.6545137241483,
>     10.91169398278, 11.0310669522732, 11.1646522767842, 11.2674177624285,
>     13.7821182142943, 14.1553220339119, 15.0969068985432, 15.9642276819795,
>     16.6291657369584, 9.4556876225397, 9.84383365139365, 11.0380863770843,
>     10.6556000187993, 11.1149505246431, 8.38961955159903, 9.4479993218556,
>     10.1951210992411, 10.6412279885262, 10.8386783860624, 8.28430177643895,
>     8.50012865848839, 8.0173090333119, 8.15484160557389, 8.07647814508528,
>     10.3200965328142, 10.4913098970428, 10.3476996067911, 10.6061836704612,
>     12.1657092589885, 10.3872286621481, 9.38602960668504, 9.82730537652969,
>     9.79454554617405, 9.12395850755274, 12.1763132046908, 12.7074157353491,
>     12.6221365761012, 13.4234247263521, 15.5103187076747, 9.88674920517951,
>     9.41792191006243, 8.58000149019063, 7.98727499786764, 7.34257609583437,
>     13.8378750532866, 14.5356948953122, 14.5302697084844, 14.6059796679765,
>     14.1489790286869, 14.9558734148741, 15.146628767252, 15.4630133416504,
>     15.5585858970881, 15.4571908526123, 11.8359496816993, 11.2020426895469,
>     11.4698356948793, 11.8119870778173, 13.0321650300175, 17.7426278125495,
>     18.6734465416521, 18.8405636698008, 18.8715255819261, 18.9619445241988,
>     8.8628712343052, 8.674994437024, 9.01558804325759, 9.04601749498397,
>     8.85597188025713, 7.58305897470564, 7.92995095252991, 8.35649385116994,
>     9.23873609863222, 9.14969765581191, 12.9726023878902, 12.2728526126593,
>     13.0261426325887, 12.6654123421758, 11.5908016450703, 13.0077322013676,
>     12.6599280629307, 11.9994106236845, 10.1917257998139, 9.89739338401705,
>     10.7914459425956, 11.8336362764239, 11.7934257723391, 11.2242249771953,
>     11.4056261256337, 7.95377462636679, 7.26088020019233, 7.43080170359462,
>     7.50569254159927, 7.62218066956848, 11.2671461887658, 10.8180299866945,
>     9.43983325269073, 9.29652785416692, 10.826626047492, 14.3595944624394,
>     13.2217460777611, 12.7365244086832, 12.05212357454, 12.3027219437063,
>     13.1963438820094, 12.8045422956347, 13.7076315935701, 14.145736489445,
>     14.4983648322523, 14.3930621445179, 13.7241447810084, 13.0053710192442,
>     12.2289746068418, 11.4307265728712, 22.3180065862834, 17.3237380106002,
>     12.7182623371482, 13.0704908631742, 15.2839343994856, 11.1243085004389,
>     10.2472041500732, 10.5197993572801, 11.790946405381, 10.6045705731958,
>     15.1506495662034, 17.2426456119865, 18.0581725202501, 17.5418430939317,
>     16.011631116271, 16.6771751828492, 14.9888406973332, 14.0024574939162,
>     12.2754199896008, 10.462130815722, 14.700809167698, 14.7662508767098,
>     14.6368321962655, 13.8920741155744, 13.6426123324782, 7.52487180288881,
>     6.8714844295755, 7.11258086375892, 7.18187426682562, 7.26737848017365,
>     8.01721725147218, 9.51534896157682, 9.49199174065143, 9.66430208645761,
>     9.95999739971012, 12.6632636412978, 12.3405989259481, 12.1739520225674,
>     11.8746338412166, 11.4930238109082, 17.375064175576, 16.5855303872377,
>     14.6908791270107, 12.4465051107109, 10.6631374452263, 9.17110545560718,
>     8.15483720507473, 8.49230268504471, 9.13922635372728, 9.57141006365418,
>     16.033780714497, 17.3399481922388, 16.4341507013887, 15.3515323530883,
>     14.7840439807624, 18.8009101431817, 19.3318882025778, 20.5749990418553,
>     21.8101386912167, 21.9960610382259, 18.0659588892013, 17.8131891880184,
>     17.4943805672228, 17.3403216060251, 16.8955769855529, 12.620489532128,
>     12.2214950155467, 11.8860110174865, 11.3811555784196, 10.8314753975719,
>     13.4036011062562, 11.5633060690016, 11.6371187847108, 12.5311543699354,
>     13.4179203305393, 8.22134572081268, 7.50831649638712, 7.27005901280791,
>     7.60287002194673, 7.99200239125639, 7.90263516828418, 8.68863912764937,
>     10.4649641085416, 14.8291767574847, 13.2854715920985, 14.6683146245778,
>     15.3950218576938, 16.1753460299224, 18.3709637727588, 18.7799926847219,
>     9.85975402873009, 11.3263857085258, 14.0980262774974, 14.9891349021345,
>     15.565140126273, 17.7682626061141, 17.6397152245045, 18.1632375810295,
>     18.5020068660378, 18.6178280040622, 13.9469483401626, 13.3572864811867,
>     13.7237298768014, 15.0745737366378, 13.0753238685429, 7.80682750046253,
>     8.02811540197581, 8.54396957438439, 8.93615526147187, 9.23284823074937,
>     11.9208830874413, 11.34336409159, 9.64633170515299, 9.77506830822676,
>     9.60444209631532, 13.3866403251886, 13.6259520426393, 11.5198655985296,
>     10.6700826901942, 9.85463059041649, 16.529045579955, 14.2629016656429,
>     12.7639583777636, 13.6573225725442, 15.0617569684982, 9.50025964993984,
>     9.68771148473024, 9.27095026709139, 9.30016769561917, 9.69172285404056,
>     7.99956496339291, 7.4167326791212, 7.22712711431086, 8.56165643781424,
>     9.04990502167493, 16.1096038296819, 15.6424694694579, 16.1224633455276,
>     15.2468092739582, 15.2601830195636, 14.6924834232777, 15.2172856964171,
>     15.6576700508595, 15.8558295574039, 15.6930990982801, 10.0672576809302,
>     10.4989007581025, 10.7346505858004, 10.9321122989058, 10.1002658251673,
>     7.57602006196976, 8.28179977834225, 9.00425424333662, 8.75011347234249,
>     9.78429929818958, 8.22318575810641, 7.62580542359501, 7.52632019575685,
>     7.3945076437667, 8.00606575794518, 9.82791453134269, 10.3108039358631,
>     10.8194808941334, 11.0586643684655, 12.7866649534553, 16.4375944063067,
>     16.122004436329, 15.8343450631946, 15.183718688786, 14.59901179187,
>     13.086870778352, 13.8396339956671, 13.0286106839776, 12.6303931698203,
>     11.8594408035278, 12.4039673712105, 9.90002802573144, 9.60356576833874,
>     11.081666406244, 11.0487984493375, 15.9987502265722, 14.9749074596912,
>     13.8462209142745, 12.3910789377987, 11.7417626548558, 10.7962236274034,
>     11.77659323439, 11.0980827827007, 10.4603781597689, 10.4605271480978,
>     12.797769298777, 11.2864379771054, 9.58062659483403, 9.57864196971059,
>     9.7400170750916, 15.1035780552775, 15.3101249132305, 15.6179285142571,
>     14.4825984723866, 11.6881796624511, 11.791490809992, 11.2104086671025,
>     8.8539243908599, 8.34417999722064, 8.39954141993076, 9.41099112387747,
>     8.93235134426504, 9.60718737915158, 9.41101815551519, 9.83936337288469,
>     13.6638214811683, 14.4527215976268, 14.7365185897797, 13.2517122197896,
>     11.0009524505585, 9.60110148880631, 8.54964307509363, 8.75000974629074,
>     8.88564947526902, 7.84255138132721, 11.6202082950622, 12.075385870412,
>     12.8382677212358, 14.9491381365806, 20.0978868640959, 8.93126882147044,
>     9.09663643687963, 9.05409744009376, 8.98246862925589, 8.80278556142002,
>     8.68155935313553, 8.91096869017929, 7.71334832534194, 9.87222944386303,
>     11.2759735900909, 17.2249065712094, 17.9082475136966, 17.6210721954703,
>     16.7172310408205, 16.2506423424929, 12.9267014097422, 14.7103695664555,
>     19.504395313561, 22.4196153692901, 22.2453631460667, 8.23867111466825,
>     8.10000761412084, 7.8771845670417, 7.56322089582682, 7.14911003597081,
>     9.50618146453053, 8.6958515457809, 7.36113237217069, 6.79777669720352,
>     6.69330381788313), .Dim = c(10L, 90L), .Dimnames = list(NULL,
>     c("X1", "X2", "X3", "X4", "X5", "X6", "X7", "X8", "X9", "X10",
>     "X11", "X12", "X13", "X14", "X15", "X16", "X17", "X18", "X19",
>     "X20", "X21", "X22", "X23", "X24", "X25", "X26", "X27", "X28",
>     "X29", "X30", "X31", "X32", "X33", "X34", "X35", "X36", "X37",
>     "X38", "X39", "X40", "X41", "X42", "X43", "X44", "X45", "X46",
>     "X47", "X48", "X49", "X50", "X51", "X52", "X53", "X54", "X55",
>     "X56", "X57", "X58", "X59", "X60", "X61", "X62", "X63", "X64",
>     "X65", "X66", "X67", "X68", "X69", "X70", "X71", "X72", "X73",
>     "X74", "X75", "X76", "X77", "X78", "X79", "X80", "X81", "X82",
>     "X83", "X84", "X85", "X86", "X87", "X88", "X89", "X90")))
>
> Is there any way to compute the means in this way? I just tried this, but I received the following error:
> result <- rowMeans(cbind(c(subset), c(subset5)));dim(result) <- dim(subset);colnames(result) <- colnames(subset)
>
> Error in rowMeans(cbind(c(subset), c(subset5))) : 'x' must be numeric
>
> Thanks,
> -----Original Message-----
> From: Eric Berger <ericjberger at gmail.com>
> To: rain1290 <rain1290 at aim.com>
> Cc: r-sig-geo <r-sig-geo at r-project.org>; R mailing list <r-help at r-project.org>
> Sent: Fri, Apr 12, 2019 11:47 am
> Subject: Re: [R] Creating a mean line plot
>
> I don't have your data. Are the x-values the same in both plots?Does this example cover the situation?
> f1 <- function(x) { x^3 - 2 }f2 <- function(x) { 2 - x^2 }
> xV <- seq(from=0,to=2,length=50)y1 <- f1(xV)y2 <- f2(xV)y3 <- .5*(y1+y2)plot(x=xV,y=y1,col="blue",lwd=2,type='l',xlab="x",ylab="y")lines(x=xV,y=y2,col="green",lwd=2)lines(x=xV,y=y3,col="red",lwd=2)legend("topleft",legend=c("y1","y2","mean"),col=c("blue","green","red"),lwd=rep(2,3))
>
>
> On Fri, Apr 12, 2019 at 5:34 PM rain1290--- via R-help <r-help at r-project.org> wrote:
>
> Hi there,
> I am trying to create a mean line plot that shows the mean of a series of separate line plots that correspond to two climate models. Let's first try getting the mean of two line plots. To create the separate line plots, here is what I did to set up the x and y axis variables:
>
> ####Getting cumulative emissions data for x-axis: 1-dimensional ####
>
> #For CanESM model#
>
> ncfname <- "cumulative_emissions_1pctCO2.nc"
> Model1 <- nc_open(ncfname)
> get <- ncvar_get(Model1, "cum_co2_emi-CanESM2")     #units of terratones of carbon (TtC) for x-axis (140 values)
> #For IPSL LR Model#
> #Getting cumulative emissions data for x-axis IPSL LR 1pctCO2 IPSL <- ncvar_get(Model1, "cum_co2_emi-IPSL-CM5A-LR")     #units of terratones of carbon (TtC) for x-axis (140 values)
>
> ############################################################################################################
>
> #####Getting precipitation data for y-axis - these are 3-dimensional####
>
> #For CanESM2 model#
> Model2 <- brick("MaxPrecCCCMACanESM21pctCO2.nc", var="onedaymax")
>
>
> #For IPSL LR Model#
> Model10 <- brick("MaxPrecIPSLIPSL-CM5A-LR1pctCO2.nc", var="onedaymax")
> #############################################################################################################
> To create plots for a specific location:
> lonlat <- cbind(103,3)          #specifies a specific longitude and latitude
> Hope2 <- extract(Model2,lonlat)      #CanESM2
> Hope6 <- extract(Model10,lonlat)   #start IPSL CM5A LR
> plot(get,Hope2, type="l",col="green", lwd="3", xlab="Cumulative CO2 emissions (TtC)", ylab="One-day maximum precipitation (mm/day)", main="One-day maximum precipitation for random location for 1pctCO2 scenario")
> lines(IPSL, Hope6, type="l", lwd="3", col="green")
> #############################################################################################################
> So, the idea would be to create a plot that shows the mean of these two plots. Given what I showed above, how should I go about creating the mean of these two green line plots? Would you have to get the mean of the x-values, and then obtain the mean of the y-values, and then plot these?
> Thanks, and any help would be greatly appreciated!
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |uke-t|erney @end|ng |rom u|ow@@edu  Sun Apr 14 18:01:04 2019
From: |uke-t|erney @end|ng |rom u|ow@@edu (Tierney, Luke)
Date: Sun, 14 Apr 2019 16:01:04 +0000
Subject: [R] 
 [External] Question about behavior of sample.kind in set.seed
 (R 3.6)
In-Reply-To: <F890ABE6-F389-416A-A62A-1C824FAE346B@stat.berkeley.edu>
References: <F890ABE6-F389-416A-A62A-1C824FAE346B@stat.berkeley.edu>
Message-ID: <alpine.DEB.2.21.1904141059590.2893@luke-Latitude-7480>

Thanks for the report. The sample.kind argument was not being passed
on to the .Internal. This is now fixed in R-devel and the R 3.6.0
branch.

Best,

luke

On Fri, 12 Apr 2019, Elizabeth Purdom wrote:

> Hello,
>
> I am trying to update a package for the upcoming release of R, and my unit tests are affected by the change in the sample. I understand that to reproduce the old sampling, I need to set sample.kind=?Rounding? in RNGkind or set.seed. But I am confused by the behavior of the sample.kind argument in set.seed, as it doesn?t seem to change my results.
>
> In particular, I was trying to understand what happens if you make a call to set.seed within a function to the global environment. So I set up a test as follows:
>
> ###Test set.seed
> f<-function(n,sample.kind){   #="Rounding" or "Rejection"
> 	cat("RNG at beginning\n")
> 	print(RNGkind())
> 	# RNGkind(sample.kind=sample.kind)
> 	# cat("RNG at after set\n")
> 	# print(RNGkind())
> 	set.seed(23,sample.kind=sample.kind)
> 	cat("RNG at after set seed\n")
> 	print(RNGkind())
> 	sample(1:400000,size=n,replace=TRUE)
> }
>
> RNGkind(sample.kind="Rejection?)
> print(RNGkind())
> n<-1000000
> y<-f(n,"Rounding?)
> print(RNGkind())
> y2<-f(n,"Rejection?)
> print(RNGkind())
> all(y==y2)
>
> However, it didn?t do anything:
>> RNGkind(sample.kind="Rejection")
>> print(RNGkind())
> [1] "Mersenne-Twister" "Inversion"        "Rejection"
>> n<-1000000
>> y<-f(n,"Rounding")
> RNG at beginning
> [1] "Mersenne-Twister" "Inversion"        "Rejection"
> RNG at after set seed
> [1] "Mersenne-Twister" "Inversion"        "Rejection"
> Warning message:
> In set.seed(23, sample.kind = sample.kind) :
> non-uniform 'Rounding' sampler used
>> print(RNGkind())
> [1] "Mersenne-Twister" "Inversion"        "Rejection"
>> y2<-f(n,"Rejection")
> RNG at beginning
> [1] "Mersenne-Twister" "Inversion"        "Rejection"
> RNG at after set seed
> [1] "Mersenne-Twister" "Inversion"        "Rejection"
>> print(RNGkind())
> [1] "Mersenne-Twister" "Inversion"        "Rejection"
>> all(y==y2)
> [1] TRUE
>
> If I run the same test with calls to RNGkind, however, it does change the method (and I discovered in answer to my question, it appears to change the global method, which is an unfortunate fact for what I am trying to do).
>
> ###Test RNGkind
> f<-function(n,sample.kind){   #="Rounding" or "Rejection"
> 	cat("RNG at beginning\n")
> 	print(RNGkind())
> 	RNGkind(sample.kind=sample.kind)
> 	cat("RNG at after set\n")
> 	print(RNGkind())
> 	set.seed(23)
> 	cat("RNG at after set seed\n")
> 	print(RNGkind())
> 	sample(1:400000,size=n,replace=TRUE)
> }
>
> RNGkind(sample.kind="Rejection?)
> print(RNGkind())
> n<-1000000
> y<-f(n,"Rounding?)
> print(RNGkind())
> y2<-f(n,"Rejection?)
> print(RNGkind())
> all(y==y2)
>
>> RNGkind(sample.kind="Rejection")
>> print(RNGkind())
> [1] "Mersenne-Twister" "Inversion"        "Rejection"
>> n<-1000000
>> y<-f(n,"Rounding")
> RNG at beginning
> [1] "Mersenne-Twister" "Inversion"        "Rejection"
> RNG at after set
> [1] "Mersenne-Twister" "Inversion"        "Rounding"
> RNG at after set seed
> [1] "Mersenne-Twister" "Inversion"        "Rounding"
> Warning message:
> In RNGkind(sample.kind = sample.kind) : non-uniform 'Rounding' sampler used
>> print(RNGkind())
> [1] "Mersenne-Twister" "Inversion"        "Rounding"
>> y2<-f(n,"Rejection")
> RNG at beginning
> [1] "Mersenne-Twister" "Inversion"        "Rounding"
> RNG at after set
> [1] "Mersenne-Twister" "Inversion"        "Rejection"
> RNG at after set seed
> [1] "Mersenne-Twister" "Inversion"        "Rejection"
>> print(RNGkind())
> [1] "Mersenne-Twister" "Inversion"        "Rejection"
>> all(y==y2)
> [1] FALSE
>
> So clearly I should use RNGkind to change it, but what is the argument actually doing in set.seed?
>
> Thanks,
> Elizabeth Purdom
>
>> sessionInfo()
> R version 3.6.0 alpha (2019-04-09 r76363)
> Platform: x86_64-apple-darwin15.6.0 (64-bit)
> Running under: OS X El Capitan 10.11.6
>
> Matrix products: default
> BLAS:   /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib
> LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] BiocManager_1.30.4 compiler_3.6.0     tools_3.6.0
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From |uc@@vdberghe @end|ng |rom hotm@||@com  Sat Apr 13 10:36:36 2019
From: |uc@@vdberghe @end|ng |rom hotm@||@com (Lucas Vandenberghe)
Date: Sat, 13 Apr 2019 08:36:36 +0000
Subject: [R] How to display coloured group correlations with
 scale_colour_manual in ggpairs (R)?
Message-ID: <AM5PR0901MB142593D85CE2A23A66E21F46AA290@AM5PR0901MB1425.eurprd09.prod.outlook.com>

I'm using ggpairs for data with 3 groups. The problem is that not all variables have all groups and therefore, some correlations only need to show 2 groups. Because of the automatic alphabetical ordering of the groups by ggpairs, the colouring is not consistent. The first colour is always assigned to the first factor level. (For example: group 1 = red, group 2 = blue, group 3 = green. But with variables having only the second and last group: group 2 = red and group 3 = blue.)

I tried to solve this problem myself by adding a scale_colour_manual in the following way:

scale_colour_manual(values = c("group1"="#F8766D", "group2"="#00BA38", "group3"="#619CFF"))

This seems to work for the density plots on the diagonal (ggally_densityDiag) and for the scatter plots in the lower part (ggally_points), but for the correlations (ggally_cor) I only get the overal (black) correlations and none of the coloured group correlations anymore. While they were displayed before, but with wrong matching of colours and groups. Why are they not displayed anymore?

Following code generates this plot<https://i.stack.imgur.com/Iw5s2.png>, the colours and groups are not matching.

ggpairs(output.b[,c(13,17,18)], aes(colour = as.factor(output.b$country), alpha = 0.4),
upper = list(continuous = function(data, mapping, ...) {
  ggally_cor(data = output.b, mapping = mapping) + scale_colour_manual(values = c("#F8766D", "#00BA38", "#619CFF"))}),
lower = list(continuous = function(data, mapping, ...) {
  ggally_points(data = output.b, mapping = mapping) + scale_colour_manual(values = c("#F8766D", "#00BA38", "#619CFF"))}),
diag = list(continuous = function(data, mapping, ...) {
  ggally_densityDiag(data = output.b, mapping = mapping) + scale_fill_manual(values = c("#F8766D", "#00BA38", "#619CFF"))}))


The adapted code generated this plot<https://i.stack.imgur.com/DVrCt.png>, the coloured group correlations are not displayed anymore.

ggpairs(output.b[,c(13,17,18)], aes(colour = as.factor(output.b$country), alpha = 0.4),
upper = list(continuous = function(data, mapping, ...) {
  ggally_cor(data = output.b, mapping = mapping) + scale_colour_manual(values = c("group1"="#F8766D", "group2"="#00BA38", "group3"="#619CFF"))}),
lower = list(continuous = function(data, mapping, ...) {
  ggally_points(data = output.b, mapping = mapping) + scale_colour_manual(values = c("group1"="#F8766D", "group2"="#00BA38", "group3"="#619CFF"))}),
diag = list(continuous = function(data, mapping, ...) {
  ggally_densityDiag(data = output.b, mapping = mapping) + scale_fill_manual(values = c("group1"="#F8766D", "group2"="#00BA38", "group3"="#619CFF"))}))


	[[alternative HTML version deleted]]


From r|c@rd @end|ng |rom ut@@edu  Sat Apr 13 22:56:20 2019
From: r|c@rd @end|ng |rom ut@@edu (Ricard, Mark D)
Date: Sat, 13 Apr 2019 20:56:20 +0000
Subject: [R] Run time error with afex package
Message-ID: <SN6PR01MB41262A891AB4DC7B7280EFF2CF290@SN6PR01MB4126.prod.exchangelabs.com>

Dear R Users:

When I attempt the run the package afex I get the following error:

require(afex)
Loading required package: afex
Error: package or namespace load failed for 'afex' in library.dynam(lib, package, package.lib):
DLL 'stringi' not found: maybe not installed for this architecture?

I have tried version 3.3, 3.4 and 3.53

Mark D. Ricard
Biomechanics Laboratory<https://na01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwweb.uta.edu%2Ffaculty%2Fricard%2FBiomechLab.html&data=02%7C01%7C%7Ceed3acbb15514be30bf108d6222b0941%7C5cdc5b43d7be4caa8173729e3b0a62d9%7C0%7C0%7C636733965559996367&sdata=Zne3UpVvzhB61%2FovgxVlzDPE%2BDjbbfAc2%2BhQcWeSFFw%3D&reserved=0>
Graduate Program Advisor
Department of Kinesiology Box 19259
500 W Nedderman Dr
The University of Texas at Arlington
Arlington , TX 76019-0259
Email: ricard at uta.edu<mailto:ricard at uta.edu>
Phone (817) 272-0764
Fax: (817) 272-3233
Website: http://wweb.uta.edu/faculty/ricard<https://na01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwweb.uta.edu%2Ffaculty%2Fricard&data=02%7C01%7C%7Ceed3acbb15514be30bf108d6222b0941%7C5cdc5b43d7be4caa8173729e3b0a62d9%7C0%7C0%7C636733965560006380&sdata=u7BPOp2cTfcsfl3J13ot1SL4O%2BteJHPtjsMT73OanLQ%3D&reserved=0>


	[[alternative HTML version deleted]]


From @|mon @end|ng |rom berreb|@net  Sun Apr 14 04:32:12 2019
From: @|mon @end|ng |rom berreb|@net (Simon Berrebi)
Date: Sat, 13 Apr 2019 22:32:12 -0400
Subject: [R] Are fitted.values available in pglm?
In-Reply-To: <CAF8bMca3kxAKwhxs-9HvG-N7qHXygVg5Fn6p4us0mQ5epc-6jA@mail.gmail.com>
References: <65B6EF72-1FD2-4B20-A475-40F5F87DDA85@berrebi.net>
 <CAGxFJbQ0THXrKPzRUeaP=j9yopm4h80QFTTgKG-MeTg5nQw7Cg@mail.gmail.com>
 <339BBA1B-F4A7-4776-85AE-364C6BF8FBA9@berrebi.net>
 <CAF8bMca3kxAKwhxs-9HvG-N7qHXygVg5Fn6p4us0mQ5epc-6jA@mail.gmail.com>
Message-ID: <41F4E2C0-BB03-4C42-8275-C3A5D35E71CC@berrebi.net>

Thank you both for your responses!

Bert - Are there specific tutorials you recommend on the subject?

William - I first contacted the pglm maintainer before posting here (and also Stack Exchange <https://stats.stackexchange.com/questions/401741/are-fitted-values-available-in-pglm>). Haven?t heard back.

- Simon

> On Apr 12, 2019, at 2:44 PM, William Dunlap <wdunlap at tibco.com> wrote:
> 
> You should ask the maintainer of the package about this: bug.report(package="pglm") or maintainer("pglm") should give you contact information.
> 
> The help file for pglm seems all wrong - it says pglm's output has class "pglm" with components like "fitted.values", but the the example calls to pglm return things of class c("maxLik", "maxim", "list").
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com/>
> 
> On Fri, Apr 12, 2019 at 11:09 AM Simon Berrebi <simon at berrebi.net <mailto:simon at berrebi.net>> wrote:
> Thank you Bert,
> 
> I wasn?t aware of ?str. The only mention of fitted-values is:
> 
>  $ maximum    : atomic [1:1] -9824
>   ..- attr(*, "fitted.values")= num [1:3460] 1.39 1.3 1.3 1.32 1.27 ...
> 
> When I try attr(mymodel$maximum,  ?fitted.values?), I get the same results as  attr(AIC(mymodel),  ?fitted.values?), which is a list of number starting with (1.39 1.3 1.3 1.32 1.27 ?). I don?t see how these can be fitted values for the response variable, patents, which are larger numbers (30, 3, 48, 1, 2, 32, ?). Is this output not supped to represent the fitted values for patents?
> 
> Another way to obtain fitted values would be using residuals.?pglm also includes residuals in its list of elements. However, str(mymodel) does not mention residuals. Does that mean it?s just not there?
> 
> - Simon
> 
> > On Apr 12, 2019, at 10:44 AM, Bert Gunter <bgunter.4567 at gmail.com <mailto:bgunter.4567 at gmail.com>> wrote:
> > 
> > ?fitted
> > ?predict
> > ## This is what one usually does, but I have not checked pglm.
> > 
> > You also need to get friendly with ?str
> > 
> > ... and probably also spend time with an R tutorial or two to become familiar with R modeling conventions.
> > 
> > Bert Gunter
> > 
> > "The trouble with having an open mind is that people keep coming along and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > 
> > 
> > On Fri, Apr 12, 2019 at 7:35 AM Simon Berrebi <simon at berrebi.net <mailto:simon at berrebi.net> <mailto:simon at berrebi.net <mailto:simon at berrebi.net>>> wrote:
> > Hello everyone,
> > 
> > I am using the pglm function in R to fit a Poisson fixed-effects model. According to the documentation <https://cran.r-project.org/web/packages/pglm/pglm.pdf <https://cran.r-project.org/web/packages/pglm/pglm.pdf> <https://cran.r-project.org/web/packages/pglm/pglm.pdf <https://cran.r-project.org/web/packages/pglm/pglm.pdf>>>, the pglm object should have fitted.values. However, fitted.values(mymodel) returns "NULL".
> > 
> > When I run AIC(mymodel) the AIC is followed by "attr(,"fitted.values")" and a long list of number. I have included an example below and attached a text file with the output.
> > 
> > Are these fitted values? If so, is there a way to obtain them directly? Can I also get fitted-values based on a synthetic dataset (i.e. predict())?
> > 
> > install.packages("pglm")
> > library(pglm)
> > 
> > data("PatentsRDUS", package="pglm")
> > 
> > 
> >      mymodel <- pglm(patents ~   log(rd)  + as.numeric(year)+ I(log(capital72)*as.numeric(year)) , PatentsRDUS,
> >      family = poisson(link=log), model = "within", index = c("cusip", "year"))
> > 
> >      fitted.values(mymodel)
> >      AIC(mymodel)
> > 
> > Cordially,
> > ?
> > Dr. Simon J Berrebi
> > Postdoctoral Fellow 
> > Civil and Environmental Engineering
> > Georgia Institute of Technology
> > 
> > 
> > 
> > 
> > 
> > 
> > 
> > 
> > ______________________________________________
> > R-help at r-project.org <mailto:R-help at r-project.org> <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help> <https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>>
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html> <http://www.r-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>>
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From r@i@1290 m@iii@g oii @im@com  Sun Apr 14 16:58:04 2019
From: r@i@1290 m@iii@g oii @im@com (r@i@1290 m@iii@g oii @im@com)
Date: Sun, 14 Apr 2019 14:58:04 +0000 (UTC)
Subject: [R] Creating a mean line plot
References: <616207014.431705.1555253884395.ref@mail.yahoo.com>
Message-ID: <616207014.431705.1555253884395@mail.yahoo.com>

Hi Bill,

For the x-axis variable, in this case, indeed, I used rowMeans(cbind(get2.teratons, get5.teratons)). This averaged each value between these two 1-dimensional variables (i.e. value#1 of "get2.teratons" was averaged with value#1 of "get5.teratons" - this was done for all 90 values).?
To obtain the means for the values of the y-axis variables, which are 3-dimensional, I simply took each variable and divided by 2, in this case. Thus: (variableA+variableB)/2. This took the mean of the variable for each grid cell for each layer (90 layers). So, for grid cell #1, doing this averaged all 90 values corresponding to the 90 layers between the two variables. For example, the values of layer 1 of variableA and layer 1 of variableB were averaged (and then layer 2 with layer 2, and then layer 3 with layer 3.....all the way to layer 90 with layer 90. This method simultaneously did this for all 8192 grid cells (128 lines of longitude and 64 lines of latitude). At the end, I obtained 90 averages for each grid cell. :)
~Trav.~
-----Original Message-----
From: William Michels <wjm1 at caa.columbia.edu>
To: rain1290 <rain1290 at aim.com>
Cc: r-help <r-help at r-project.org>; r-sig-geo <r-sig-geo at r-project.org>
Sent: Sun, Apr 14, 2019 4:46 am
Subject: Re: [R] Creating a mean line plot

So you're saying rowMeans(cbind(matrix_a, matrix_b)) worked to obtain
your X-axis values?

Wild guess here, are you simply looking for:
colMeans(rbind(matrix_a, matrix_b)) to obtain your Y-axis values?

[Above assuming matrix_a and matrix_b have identical dimensions (nrow, ncol)].

--Bill

William Michels, Ph.D.


On Fri, Apr 12, 2019 at 11:09 AM rain1290--- via R-help






<r-help at r-project.org> wrote:
>
> Hi Eric,
>
> Ah, I apologize, and thank you for your response!
> I just figured out a way to average my x-values, so at least that is solved. I will still include the data for the two variables (1-dimensional) of interest that I was trying to average, just to show what was done:
> get2.teratons #(90 values)
> get5.teratons #(90 values)
> Here is what get2.teratons looks like (same idea for get5.teratons):
>? ? >print(get2.teratons)
>? ? [1] 0.4558545 0.4651129 0.4747509 0.4848242 0.4950900 0.5056109 0.5159335
>? ? 0.5262532 0.5372275 0.5481839 0.5586787 0.5694379 0.5802970
>? ? [14] 0.5909211 0.6015753 0.6124256 0.6237733 0.6353634 0.6467227 0.6582857
>? ? 0.6702509 0.6817027 0.6935311 0.7060161 0.7182312 0.7301909
>? ? [27] 0.7422574 0.7544744 0.7665907 0.7786409 0.7907518 0.8032732 0.8158733
>? ? 0.8284363 0.8413905 0.8545881 0.8674711 0.8797701 0.8927392
>? ? [40] 0.9059937 0.9189707 0.9317215 0.9438155 0.9558035 0.9673665 0.9784927
>? ? 0.9900898 1.0020388 1.0132683 1.0240023 1.0347708 1.0456077
>? ? [53] 1.0570347 1.0682903 1.0793535 1.0901511 1.1001753 1.1101276 1.1199142
>? ? 1.1293237 1.1384669 1.1470002 1.1547341 1.1622488 1.1697549
>? ? [66] 1.1777542 1.1857587 1.1930233 1.1999645 1.2067172 1.2132979 1.2199317
>? ? 1.2265673 1.2328599 1.2390689 1.2446050 1.2495579 1.2546455
>? ? [79] 1.2599212 1.2648733 1.2700068 1.2753889 1.2807509 1.2856922 1.2905927
>? ? 1.2953338 1.3000484 1.3045992 1.3091128 1.3144190
> The following worked in terms of averaging all of the elements of get2.teratons and get5.teratons:
> rowMeans(cbind(get2.teratons,get5.teratons))
> However, I am trying to do something similar for the values on my y-axis. So, for now, here are the two variables (3-dimensional) that I would like to average:
>? ? subset
>? ? subset5
> Using the print function for "subset" (same idea for subset5):? ? >print(subset)
>? ? class? ? ? : RasterStack
>? ? dimensions? : 64, 128, 8192, 90? (nrow, ncol, ncell, nlayers)
>? ? resolution? : 2.8125, 2.789327? (x, y)
>? ? extent? ? ? : -181.4062, 178.5938, -89.25846, 89.25846? (xmin, xmax, ymin,
>? ? ymax)
>? ? coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
>? ? names? ? ? : X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14,
>? ? X15, ...? ? >dim(subset)
>? ? [1]? 64 128? 90>dim(subset5)
>? ? [1]? 64 128? 90
> I tried `mean(subset,subset5)`, which works, BUT it combines the 90 layers into 1 layer. I want keep the number of layers at 90, but simply average each of the grid cell values of "subset" and "subset5" for each layer. So, for instance, I want to average the values of each grid cell of layer 1 of "subset" with the values of each grid cell of layer 1 of "subset5", and then average those values of layer 2 of "subset" with those values of layer 2 of "subset5"......all the way to layer 90. That way, I have 90 averages across all grid cells.
> Here is what the data looks like for "subset":
> >dput(head(subset,5))
>? ? structure(c(11.5447145886719, 11.2479725852609, 10.0223480723798,
>? ? 11.4909216295928, 12.5930442474782, 15.0295264553279, 14.6107862703502,
>? ? 13.3623332250863, 10.4473929153755, 13.262210553512, 13.3166334126145,
>? ? 13.7211008928716, 10.594900790602, 11.7217378690839, 10.8397546224296,
>? ? 14.2727348953485, 13.6185416020453, 12.7485566306859, 11.7246472276747,
>? ? 10.6815265025944, 13.1605062168092, 12.9131189547479, 12.6493454910815,
>? ? 11.6938022430986, 11.4522186107934, 8.84930260945112, 11.5785481408238,
>? ? 12.9859233275056, 13.6702361516654, 11.863912967965, 11.6624090820551,
>? ? 12.1465771459043, 12.9789240192622, 13.5916746687144, 15.0383287109435,
>? ? 7.89674604311585, 8.14079332631081, 7.05628590658307, 6.99759456329048,
>? ? 8.06435288395733, 8.00622920505702, 7.35754533670843, 6.57949370797724,
>? ? 6.26998774241656, 6.10911303665489, 10.1576759945601, 9.83650996349752,
>? ? 10.6277788057923, 10.3647025069222, 9.38627037685364, 28.411143925041,
>? ? 27.3436004295945, 25.7670222781599, 24.1854049265385, 22.7183715440333,
>? ? 10.8529561199248, 11.1584928352386, 11.4545458462089, 11.7570801638067,
>? ? 11.6314635146409, 13.7268429156393, 12.4547378160059, 12.8433785866946,
>? ? 10.282119596377, 9.66278391424567, 6.39572446234524, 8.4569685626775,
>? ? 12.253624945879, 12.4784250743687, 13.6823802720755, 8.65540341474116,
>? ? 8.34308553021401, 8.30261853989214, 7.9798299819231, 7.96007991302758,
>? ? 13.3976918645203, 15.2056947816163, 15.3097502421588, 18.0296610575169,
>? ? 17.918016621843, 14.121591579169, 14.3091559410095, 14.7470911033452,
>? ? 15.414851764217, 15.8059203531593, 22.9126498103142, 21.5608592145145,
>? ? 19.7303873486817, 17.5689237657934, 15.4688697773963, 10.2526041911915,
>? ? 10.4463449679315, 9.85705149360001, 9.5394266070798, 9.17961853556335,
>? ? 14.064371259883, 12.626935634762, 12.1540617663413, 10.9235350973904,
>? ? 9.32216013316065, 12.3676003888249, 12.9718807060272, 14.5685050170869,
>? ? 13.8497828040272, 14.0683455392718, 8.09576804749668, 8.54510050266981,
>? ? 8.02388715092093, 8.6679536383599, 9.38348234631121, 11.6279292851686,
>? ? 11.5998465567827, 11.6469369269907, 11.6286710835993, 10.8152111526579,
>? ? 17.4072104506195, 18.9169261604548, 19.5168524980545, 19.0377978142351,
>? ? 19.5594304706901, 9.74474258255213, 10.2144323755056, 10.9722976572812,
>? ? 11.5369332488626, 12.0274581480771, 14.007618650794, 14.0536692459136,
>? ? 14.4861201290041, 14.133819937706, 13.045089924708, 19.9330265633762,
>? ? 20.3158976510167, 21.4452845044434, 19.9475897010416, 20.3566399868578,
>? ? 15.703826257959, 14.8260951507837, 14.6203982178122, 14.0476305037737,
>? ? 13.2086589932442, 6.5044054761529, 6.51829722337425, 6.59741191193461,
>? ? 6.57343484926969, 7.07112564705312, 8.42645864468068, 9.15604883339256,
>? ? 10.8542435802519, 8.57339131180197, 7.89698304142803, 10.6029914226383,
>? ? 9.90388663485646, 8.46301421988755, 12.9162973724306, 9.06370310112834,
>? ? 9.92726711556315, 11.5754703059793, 8.74886247329414, 8.99941809475422,
>? ? 9.90840594749898, 11.1468604300171, 11.1322306562215, 10.49438144546,
>? ? 9.50155213940889, 8.31737467087805, 5.76932597905397, 6.14411209244281,
>? ? 7.39980584476143, 8.47632132936269, 8.00714262295514, 8.64454926922917,
>? ? 7.79559868387878, 7.14818593114614, 7.42282171268016, 9.04718739911914,
>? ? 12.0141573250294, 11.0411503817886, 11.7892528418452, 11.2668004352599,
>? ? 10.5345542309806, 14.2355003859848, 12.4114783946425, 13.1144292186946,
>? ? 14.3049817532301, 14.7282858844846, 9.90791183430701, 10.4058899218217,
>? ? 12.0624131988734, 13.2521220948547, 13.9345653355122, 12.5256763771176,
>? ? 12.3285478446633, 11.9927407242358, 11.6441268939525, 11.6448875516653,
>? ? 30.5602320469916, 30.6964941322803, 27.3358505219221, 27.5474566966295,
>? ? 24.3847575969994, 15.1250814087689, 15.0272130500525, 14.9795342702419,
>? ? 14.2658210825175, 13.437497522682, 10.7001833617687, 10.0823557935655,
>? ? 10.1298170629889, 9.99525294173509, 10.6919908896089, 9.04134479351342,
>? ? 9.57930330187082, 9.58402880933136, 8.82056106347591, 9.06912200152874,
>? ? 11.0435656271875, 12.827942892909, 14.6962288767099, 15.984565531835,
>? ? 16.3673574104905, 17.7882182411849, 17.1887206379324, 16.4347139652818,
>? ? 15.4833788517863, 14.3649869598448, 10.0324214436114, 10.9937381464988,
>? ? 10.7803415972739, 10.64134365879, 10.3700830601156, 10.7242427766323,
>? ? 10.1225153775886, 9.59254063200206, 9.67734202276915, 9.9705743137747,
>? ? 6.15209711249918, 7.6417050557211, 9.55170588567853, 12.123644258827,
>? ? 14.6793850231916, 13.8236853294075, 14.3564789090306, 13.6828002054244,
>? ? 13.0476749036461, 12.3909330926836, 12.5938401091844, 12.5098232645541,
>? ? 12.4792913440615, 10.5595408938825, 10.0890464382246, 9.20089432038367,
>? ? 8.92592284362763, 8.59467086847872, 9.42603517323732, 10.0353622343391,
>? ? 11.7311725392938, 12.4379832297564, 12.9343897104263, 12.9055073484778,
>? ? 10.8944955747575, 13.6480727232993, 13.5285727679729, 13.1794585380703,
>? ? 12.8222310449928, 12.3997843824327, 12.7413347829133, 14.3273916095495,
>? ? 17.3931313678622, 18.2263168506324, 18.5841742437333, 6.59096706658602,
>? ? 6.43405092414469, 6.25825286842883, 6.41100551001728, 6.47397979628295,
>? ? 10.5375754879788, 11.7441980168223, 12.6210678834468, 13.6038213036954,
>? ? 14.3639346119016, 14.6688716020435, 14.1826340463012, 15.2044224087149,
>? ? 15.5630568042397, 15.0458208750933, 10.0154311163351, 9.7418615128845,
>? ? 11.8866622913629, 10.4000290855765, 9.74880487192422, 12.071524746716,
>? ? 11.5644979756325, 11.0723461490124, 10.6282578315586, 10.2157085202634,
>? ? 14.5142644643784, 12.1188929770142, 12.3748247511685, 12.4087903182954,
>? ? 11.9534945581108, 9.04913682024926, 10.3765605948865, 11.6044067312032,
>? ? 11.8693192955106, 11.4852412138134, 9.60276927798986, 8.47671863157302,
>? ? 6.53922976925969, 6.61022553686053, 6.93009907845408, 13.2296028546989,
>? ? 13.0423339549452, 13.0597360432148, 12.6910961698741, 12.4157820828259,
>? ? 10.1926731644198, 8.71818219311535, 7.08254557102919, 8.77621911931783,
>? ? 10.0059285527095, 12.931788386777, 12.2630294412374, 11.4822425879538,
>? ? 10.4378029704094, 9.7940765786916, 13.0133786704391, 11.9061049539596,
>? ? 12.0638377033174, 12.3013137839735, 12.9490484017879, 13.2149957120419,
>? ? 13.1087802350521, 12.6286820042878, 12.2278920840472, 11.8682594038546,
>? ? 10.9492189250886, 12.2341319918633, 12.9464382771403, 12.5120461452752,
>? ? 12.5263502821326, 12.6686599105597, 12.7322974149138, 12.1948833111674,
>? ? 12.1215357910842, 11.9392029941082, 15.2677292469889, 16.3731585256755,
>? ? 17.8960581310093, 18.6334447469562, 19.5818214677274, 8.80653981585056,
>? ? 9.830889897421, 9.35642933472991, 8.49255602806807, 9.19627505354583,
>? ? 9.56638909410685, 10.4608207242563, 11.0053240321577, 12.0839668437839,
>? ? 12.6748947892338, 10.9087632503361, 11.0474556684494, 9.86553691327572,
>? ? 11.7183218244463, 12.5948534812778, 9.51134513597935, 7.67265690956265,
>? ? 8.47005187533796, 8.948102616705, 9.48919930960983, 8.92916852608323,
>? ? 9.19180226046592, 9.93818349670619, 10.3347131051123, 9.19244724791497,
>? ? 16.0914938896894, 16.6821955237538, 17.9938221350312, 19.0754321403801,
>? ? 19.048942392692, 8.59134346246719, 8.39548541698605, 8.17942153662443,
>? ? 8.02843223791569, 8.9953287737444, 7.97593365423381, 7.71139136049896,
>? ? 7.85907462704927, 8.38070099707693, 9.28482818417251, 11.3056178670377,
>? ? 11.601750086993, 11.2711317837238, 10.8186058234423, 10.7581429649144,
>? ? 15.6826636288315, 16.9076268095523, 15.4331855010241, 15.1698420289904,
>? ? 14.4226460717618, 11.3487603608519, 10.932231741026, 10.3945284616202,
>? ? 9.96728525497019, 9.48596934322268, 10.508708213456, 10.0394641282037,
>? ? 10.5090778553858, 10.1252990076318, 9.86525025218725, 21.985590364784,
>? ? 22.3454732447863, 22.693102620542, 22.8635905310512, 23.2176823541522,
>? ? 18.6908649746329, 16.1407203879207, 14.8633007425815, 13.0084274802357,
>? ? 10.3990704054013, 6.98735397309065, 6.87530469149351, 8.9313744334504,
>? ? 7.93048026971519, 8.05362006649375, 7.19595712143928, 6.09859018586576,
>? ? 7.31170470826328, 8.58990701381117, 8.4448722191155, 10.6643167790025,
>? ? 10.839969618246, 10.5106293456629, 10.4457534151152, 11.2185546196997,
>? ? 12.6707960385829, 12.9902018699795, 12.9533659201115, 12.501154281199,
>? ? 12.3501065187156, 25.9615670889616, 28.099115844816, 30.2258117124438,
>? ? 32.2391155175865, 34.1092220507562, 13.0570391658694, 14.2825467512012,
>? ? 11.1714780796319, 9.62660552468151, 13.1034480873495, 12.0462608523667,
>? ? 12.1476030908525, 12.087664520368, 12.486698012799, 12.6554797869176,
>? ? 12.9096878226846, 13.7426960282028, 15.2569429948926, 17.1046711038798,
>? ? 17.0782153028995, 8.75586932525039, 8.82860643323511, 8.69223182089627,
>? ? 9.15108947083354, 9.4462743261829, 8.55356580577791, 8.69411900639534,
>? ? 8.9102350641042, 9.00506707839668, 8.75238287262619, 12.8364848904312,
>? ? 14.6456281654537, 13.9498212374747, 14.5683591719717, 14.3893217202276,
>? ? 15.1805742178112, 16.7262759525329, 17.7521643228829, 18.5243777465075,
>? ? 18.8792126253247, 7.70680792629719, 7.47225251980126, 7.72799758706242,
>? ? 7.68415729980916, 7.50800217501819, 9.68811193015426, 10.5253741610795,
>? ? 10.922572016716, 10.9020531177521, 10.406608460471, 22.1927281469107,
>? ? 21.7946967110038, 22.5350291468203, 22.0015277154744, 23.2784972526133,
>? ? 25.1319196075201, 24.1645314730704, 23.0207713320851, 14.8746414575726,
>? ? 12.5255933962762, 19.3960575386882, 19.3368871696293, 19.8454126249999,
>? ? 19.8410699609667, 19.8172997217625, 12.1799279004335, 11.8857935070992,
>? ? 11.4909932948649, 11.3612791523337, 10.8840802218765, 11.1973982769996,
>? ? 11.6429010406137, 11.2867686431855, 11.5507948212326, 11.7122428491712,
>? ? 13.8513946440071, 14.9497504346073, 14.425096521154, 13.2822252810001,
>? ? 12.4311964027584, 18.864199379459, 17.5528808031231, 17.7616731729358,
>? ? 17.1655979007483, 16.6251927148551, 29.3679255992174, 28.4771841019392,
>? ? 27.9151875525713, 26.65377818048, 25.2528126351535, 10.6545137241483,
>? ? 10.91169398278, 11.0310669522732, 11.1646522767842, 11.2674177624285,
>? ? 13.7821182142943, 14.1553220339119, 15.0969068985432, 15.9642276819795,
>? ? 16.6291657369584, 9.4556876225397, 9.84383365139365, 11.0380863770843,
>? ? 10.6556000187993, 11.1149505246431, 8.38961955159903, 9.4479993218556,
>? ? 10.1951210992411, 10.6412279885262, 10.8386783860624, 8.28430177643895,
>? ? 8.50012865848839, 8.0173090333119, 8.15484160557389, 8.07647814508528,
>? ? 10.3200965328142, 10.4913098970428, 10.3476996067911, 10.6061836704612,
>? ? 12.1657092589885, 10.3872286621481, 9.38602960668504, 9.82730537652969,
>? ? 9.79454554617405, 9.12395850755274, 12.1763132046908, 12.7074157353491,
>? ? 12.6221365761012, 13.4234247263521, 15.5103187076747, 9.88674920517951,
>? ? 9.41792191006243, 8.58000149019063, 7.98727499786764, 7.34257609583437,
>? ? 13.8378750532866, 14.5356948953122, 14.5302697084844, 14.6059796679765,
>? ? 14.1489790286869, 14.9558734148741, 15.146628767252, 15.4630133416504,
>? ? 15.5585858970881, 15.4571908526123, 11.8359496816993, 11.2020426895469,
>? ? 11.4698356948793, 11.8119870778173, 13.0321650300175, 17.7426278125495,
>? ? 18.6734465416521, 18.8405636698008, 18.8715255819261, 18.9619445241988,
>? ? 8.8628712343052, 8.674994437024, 9.01558804325759, 9.04601749498397,
>? ? 8.85597188025713, 7.58305897470564, 7.92995095252991, 8.35649385116994,
>? ? 9.23873609863222, 9.14969765581191, 12.9726023878902, 12.2728526126593,
>? ? 13.0261426325887, 12.6654123421758, 11.5908016450703, 13.0077322013676,
>? ? 12.6599280629307, 11.9994106236845, 10.1917257998139, 9.89739338401705,
>? ? 10.7914459425956, 11.8336362764239, 11.7934257723391, 11.2242249771953,
>? ? 11.4056261256337, 7.95377462636679, 7.26088020019233, 7.43080170359462,
>? ? 7.50569254159927, 7.62218066956848, 11.2671461887658, 10.8180299866945,
>? ? 9.43983325269073, 9.29652785416692, 10.826626047492, 14.3595944624394,
>? ? 13.2217460777611, 12.7365244086832, 12.05212357454, 12.3027219437063,
>? ? 13.1963438820094, 12.8045422956347, 13.7076315935701, 14.145736489445,
>? ? 14.4983648322523, 14.3930621445179, 13.7241447810084, 13.0053710192442,
>? ? 12.2289746068418, 11.4307265728712, 22.3180065862834, 17.3237380106002,
>? ? 12.7182623371482, 13.0704908631742, 15.2839343994856, 11.1243085004389,
>? ? 10.2472041500732, 10.5197993572801, 11.790946405381, 10.6045705731958,
>? ? 15.1506495662034, 17.2426456119865, 18.0581725202501, 17.5418430939317,
>? ? 16.011631116271, 16.6771751828492, 14.9888406973332, 14.0024574939162,
>? ? 12.2754199896008, 10.462130815722, 14.700809167698, 14.7662508767098,
>? ? 14.6368321962655, 13.8920741155744, 13.6426123324782, 7.52487180288881,
>? ? 6.8714844295755, 7.11258086375892, 7.18187426682562, 7.26737848017365,
>? ? 8.01721725147218, 9.51534896157682, 9.49199174065143, 9.66430208645761,
>? ? 9.95999739971012, 12.6632636412978, 12.3405989259481, 12.1739520225674,
>? ? 11.8746338412166, 11.4930238109082, 17.375064175576, 16.5855303872377,
>? ? 14.6908791270107, 12.4465051107109, 10.6631374452263, 9.17110545560718,
>? ? 8.15483720507473, 8.49230268504471, 9.13922635372728, 9.57141006365418,
>? ? 16.033780714497, 17.3399481922388, 16.4341507013887, 15.3515323530883,
>? ? 14.7840439807624, 18.8009101431817, 19.3318882025778, 20.5749990418553,
>? ? 21.8101386912167, 21.9960610382259, 18.0659588892013, 17.8131891880184,
>? ? 17.4943805672228, 17.3403216060251, 16.8955769855529, 12.620489532128,
>? ? 12.2214950155467, 11.8860110174865, 11.3811555784196, 10.8314753975719,
>? ? 13.4036011062562, 11.5633060690016, 11.6371187847108, 12.5311543699354,
>? ? 13.4179203305393, 8.22134572081268, 7.50831649638712, 7.27005901280791,
>? ? 7.60287002194673, 7.99200239125639, 7.90263516828418, 8.68863912764937,
>? ? 10.4649641085416, 14.8291767574847, 13.2854715920985, 14.6683146245778,
>? ? 15.3950218576938, 16.1753460299224, 18.3709637727588, 18.7799926847219,
>? ? 9.85975402873009, 11.3263857085258, 14.0980262774974, 14.9891349021345,
>? ? 15.565140126273, 17.7682626061141, 17.6397152245045, 18.1632375810295,
>? ? 18.5020068660378, 18.6178280040622, 13.9469483401626, 13.3572864811867,
>? ? 13.7237298768014, 15.0745737366378, 13.0753238685429, 7.80682750046253,
>? ? 8.02811540197581, 8.54396957438439, 8.93615526147187, 9.23284823074937,
>? ? 11.9208830874413, 11.34336409159, 9.64633170515299, 9.77506830822676,
>? ? 9.60444209631532, 13.3866403251886, 13.6259520426393, 11.5198655985296,
>? ? 10.6700826901942, 9.85463059041649, 16.529045579955, 14.2629016656429,
>? ? 12.7639583777636, 13.6573225725442, 15.0617569684982, 9.50025964993984,
>? ? 9.68771148473024, 9.27095026709139, 9.30016769561917, 9.69172285404056,
>? ? 7.99956496339291, 7.4167326791212, 7.22712711431086, 8.56165643781424,
>? ? 9.04990502167493, 16.1096038296819, 15.6424694694579, 16.1224633455276,
>? ? 15.2468092739582, 15.2601830195636, 14.6924834232777, 15.2172856964171,
>? ? 15.6576700508595, 15.8558295574039, 15.6930990982801, 10.0672576809302,
>? ? 10.4989007581025, 10.7346505858004, 10.9321122989058, 10.1002658251673,
>? ? 7.57602006196976, 8.28179977834225, 9.00425424333662, 8.75011347234249,
>? ? 9.78429929818958, 8.22318575810641, 7.62580542359501, 7.52632019575685,
>? ? 7.3945076437667, 8.00606575794518, 9.82791453134269, 10.3108039358631,
>? ? 10.8194808941334, 11.0586643684655, 12.7866649534553, 16.4375944063067,
>? ? 16.122004436329, 15.8343450631946, 15.183718688786, 14.59901179187,
>? ? 13.086870778352, 13.8396339956671, 13.0286106839776, 12.6303931698203,
>? ? 11.8594408035278, 12.4039673712105, 9.90002802573144, 9.60356576833874,
>? ? 11.081666406244, 11.0487984493375, 15.9987502265722, 14.9749074596912,
>? ? 13.8462209142745, 12.3910789377987, 11.7417626548558, 10.7962236274034,
>? ? 11.77659323439, 11.0980827827007, 10.4603781597689, 10.4605271480978,
>? ? 12.797769298777, 11.2864379771054, 9.58062659483403, 9.57864196971059,
>? ? 9.7400170750916, 15.1035780552775, 15.3101249132305, 15.6179285142571,
>? ? 14.4825984723866, 11.6881796624511, 11.791490809992, 11.2104086671025,
>? ? 8.8539243908599, 8.34417999722064, 8.39954141993076, 9.41099112387747,
>? ? 8.93235134426504, 9.60718737915158, 9.41101815551519, 9.83936337288469,
>? ? 13.6638214811683, 14.4527215976268, 14.7365185897797, 13.2517122197896,
>? ? 11.0009524505585, 9.60110148880631, 8.54964307509363, 8.75000974629074,
>? ? 8.88564947526902, 7.84255138132721, 11.6202082950622, 12.075385870412,
>? ? 12.8382677212358, 14.9491381365806, 20.0978868640959, 8.93126882147044,
>? ? 9.09663643687963, 9.05409744009376, 8.98246862925589, 8.80278556142002,
>? ? 8.68155935313553, 8.91096869017929, 7.71334832534194, 9.87222944386303,
>? ? 11.2759735900909, 17.2249065712094, 17.9082475136966, 17.6210721954703,
>? ? 16.7172310408205, 16.2506423424929, 12.9267014097422, 14.7103695664555,
>? ? 19.504395313561, 22.4196153692901, 22.2453631460667, 8.23867111466825,
>? ? 8.10000761412084, 7.8771845670417, 7.56322089582682, 7.14911003597081,
>? ? 9.50618146453053, 8.6958515457809, 7.36113237217069, 6.79777669720352,
>? ? 6.69330381788313), .Dim = c(10L, 90L), .Dimnames = list(NULL,
>? ? c("X1", "X2", "X3", "X4", "X5", "X6", "X7", "X8", "X9", "X10",
>? ? "X11", "X12", "X13", "X14", "X15", "X16", "X17", "X18", "X19",
>? ? "X20", "X21", "X22", "X23", "X24", "X25", "X26", "X27", "X28",
>? ? "X29", "X30", "X31", "X32", "X33", "X34", "X35", "X36", "X37",
>? ? "X38", "X39", "X40", "X41", "X42", "X43", "X44", "X45", "X46",
>? ? "X47", "X48", "X49", "X50", "X51", "X52", "X53", "X54", "X55",
>? ? "X56", "X57", "X58", "X59", "X60", "X61", "X62", "X63", "X64",
>? ? "X65", "X66", "X67", "X68", "X69", "X70", "X71", "X72", "X73",
>? ? "X74", "X75", "X76", "X77", "X78", "X79", "X80", "X81", "X82",
>? ? "X83", "X84", "X85", "X86", "X87", "X88", "X89", "X90")))
>
> Is there any way to compute the means in this way? I just tried this, but I received the following error:
> result <- rowMeans(cbind(c(subset), c(subset5)));dim(result) <- dim(subset);colnames(result) <- colnames(subset)
>
> Error in rowMeans(cbind(c(subset), c(subset5))) : 'x' must be numeric
>
> Thanks,
> -----Original Message-----
> From: Eric Berger <ericjberger at gmail.com>
> To: rain1290 <rain1290 at aim.com>
> Cc: r-sig-geo <r-sig-geo at r-project.org>; R mailing list <r-help at r-project.org>
> Sent: Fri, Apr 12, 2019 11:47 am
> Subject: Re: [R] Creating a mean line plot
>
> I don't have your data. Are the x-values the same in both plots?Does this example cover the situation?
> f1 <- function(x) { x^3 - 2 }f2 <- function(x) { 2 - x^2 }
> xV <- seq(from=0,to=2,length=50)y1 <- f1(xV)y2 <- f2(xV)y3 <- .5*(y1+y2)plot(x=xV,y=y1,col="blue",lwd=2,type='l',xlab="x",ylab="y")lines(x=xV,y=y2,col="green",lwd=2)lines(x=xV,y=y3,col="red",lwd=2)legend("topleft",legend=c("y1","y2","mean"),col=c("blue","green","red"),lwd=rep(2,3))
>
>
> On Fri, Apr 12, 2019 at 5:34 PM rain1290--- via R-help <r-help at r-project.org> wrote:
>
> Hi there,
> I am trying to create a mean line plot that shows the mean of a series of separate line plots that correspond to two climate models. Let's first try getting the mean of two line plots. To create the separate line plots, here is what I did to set up the x and y axis variables:
>
> ####Getting cumulative emissions data for x-axis: 1-dimensional ####
>
> #For CanESM model#
>
> ncfname <- "cumulative_emissions_1pctCO2.nc"
> Model1 <- nc_open(ncfname)
> get <- ncvar_get(Model1, "cum_co2_emi-CanESM2")? ? #units of terratones of carbon (TtC) for x-axis (140 values)
> #For IPSL LR Model#
> #Getting cumulative emissions data for x-axis IPSL LR 1pctCO2 IPSL <- ncvar_get(Model1, "cum_co2_emi-IPSL-CM5A-LR")? ? #units of terratones of carbon (TtC) for x-axis (140 values)
>
> ############################################################################################################
>
> #####Getting precipitation data for y-axis - these are 3-dimensional####
>
> #For CanESM2 model#
> Model2 <- brick("MaxPrecCCCMACanESM21pctCO2.nc", var="onedaymax")
>
>
> #For IPSL LR Model#
> Model10 <- brick("MaxPrecIPSLIPSL-CM5A-LR1pctCO2.nc", var="onedaymax")
> #############################################################################################################
> To create plots for a specific location:
> lonlat <- cbind(103,3)? ? ? ? ? #specifies a specific longitude and latitude
> Hope2 <- extract(Model2,lonlat)? ? ? #CanESM2
> Hope6 <- extract(Model10,lonlat)? #start IPSL CM5A LR
> plot(get,Hope2, type="l",col="green", lwd="3", xlab="Cumulative CO2 emissions (TtC)", ylab="One-day maximum precipitation (mm/day)", main="One-day maximum precipitation for random location for 1pctCO2 scenario")
> lines(IPSL, Hope6, type="l", lwd="3", col="green")
> #############################################################################################################
> So, the idea would be to create a plot that shows the mean of these two plots. Given what I showed above, how should I go about creating the mean of these two green line plots? Would you have to get the mean of the x-values, and then obtain the mean of the y-values, and then plot these?
> Thanks, and any help would be greatly appreciated!
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>? ? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From @@r@h@go@|ee @end|ng |rom gm@||@com  Sun Apr 14 23:39:11 2019
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Sun, 14 Apr 2019 17:39:11 -0400
Subject: [R] Run time error with afex package
In-Reply-To: <SN6PR01MB41262A891AB4DC7B7280EFF2CF290@SN6PR01MB4126.prod.exchangelabs.com>
References: <SN6PR01MB41262A891AB4DC7B7280EFF2CF290@SN6PR01MB4126.prod.exchangelabs.com>
Message-ID: <CAM_vjunTmxkCg1w-KvNS_pM0fqtG_Y3pA0gVPwK2=OqYr99Hig@mail.gmail.com>

Presumably you mean R versions by the 3.whatevers.

The current version of afex no longer requires stringi, but earlier
versions did. The best course is to update afex, but you could also
just install the stringi, as the error message you're getting
suggests.

Sarah

On Sun, Apr 14, 2019 at 1:14 PM Ricard, Mark D <ricard at uta.edu> wrote:
>
> Dear R Users:
>
> When I attempt the run the package afex I get the following error:
>
> require(afex)
> Loading required package: afex
> Error: package or namespace load failed for 'afex' in library.dynam(lib, package, package.lib):
> DLL 'stringi' not found: maybe not installed for this architecture?
>
> I have tried version 3.3, 3.4 and 3.53
>
> Mark D. Ricard
> Biomechanics Laboratory<https://na01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwweb.uta.edu%2Ffaculty%2Fricard%2FBiomechLab.html&data=02%7C01%7C%7Ceed3acbb15514be30bf108d6222b0941%7C5cdc5b43d7be4caa8173729e3b0a62d9%7C0%7C0%7C636733965559996367&sdata=Zne3UpVvzhB61%2FovgxVlzDPE%2BDjbbfAc2%2BhQcWeSFFw%3D&reserved=0>
> Graduate Program Advisor
> Department of Kinesiology Box 19259
> 500 W Nedderman Dr
> The University of Texas at Arlington
> Arlington , TX 76019-0259
> Email: ricard at uta.edu<mailto:ricard at uta.edu>
> Phone (817) 272-0764
> Fax: (817) 272-3233
> Website: http://wweb.uta.edu/faculty/ricard<https://na01.safelinks.protection.outlook.com/?url=http%3A%2F%2Fwweb.uta.edu%2Ffaculty%2Fricard&data=02%7C01%7C%7Ceed3acbb15514be30bf108d6222b0941%7C5cdc5b43d7be4caa8173729e3b0a62d9%7C0%7C0%7C636733965560006380&sdata=u7BPOp2cTfcsfl3J13ot1SL4O%2BteJHPtjsMT73OanLQ%3D&reserved=0>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Mon Apr 15 00:18:37 2019
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Sun, 14 Apr 2019 18:18:37 -0400
Subject: [R] Help installing netReg
Message-ID: <CAPQaxLO_G9Tcxrq3v-P6a0Tdo53hgYE3mrZWn99_72O4=hE2Og@mail.gmail.com>

Good evening,

 I am having problems with downloading the package used to generate
regression models on R. The following is the error message I received. I
tried installing BiocManager instead as suggested, but this too did not
work. Any ideas?

The downloaded binary packages are in
C:\Users\Spencer\AppData\Local\Temp\Rtmp8YKVqx\downloaded_packages
installation path not writeable, unable to update packages: class, cluster,
codetools, foreign,
  lattice, MASS, Matrix, mgcv, nlme, rpart, survival
Warning message:
'biocLite' is deprecated.
Use 'BiocManager::install' instead.
See help("Deprecated")

Best,

Spencer Brackett

	[[alternative HTML version deleted]]


From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Mon Apr 15 00:20:15 2019
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Sun, 14 Apr 2019 18:20:15 -0400
Subject: [R] Help installing netReg
Message-ID: <CAPQaxLPmhsdh5OaOErFQZXym7JpMY9EuPAjEL70-0DFbDks6LA@mail.gmail.com>

Good evening,

 I am having problems with downloading the package used to generate
regression models on R. The following is the error message I received. I
tried installing BiocManager instead as suggested, but this too did not
work. Any ideas?

The downloaded binary packages are in
C:\Users\Spencer\AppData\Local\Temp\Rtmp8YKVqx\downloaded_packages
installation path not writeable, unable to update packages: class, cluster,
codetools, foreign,
  lattice, MASS, Matrix, mgcv, nlme, rpart, survival
Warning message:
'biocLite' is deprecated.
Use 'BiocManager::install' instead.
See help("Deprecated")

Best,

Spencer

	[[alternative HTML version deleted]]


From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Mon Apr 15 00:36:41 2019
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Sun, 14 Apr 2019 18:36:41 -0400
Subject: [R] Downloading R Data
Message-ID: <CAPQaxLN-gpA_1j8wo9FiEya07uRw295cf7Lr3DR7gL13WL+Gfg@mail.gmail.com>

  I am also looking to be able to read this file on an appropriate
application. As of now, it?s too large to view directly in GoogleDrive or
word, and I can only get a mistranslated version of the script included as
a .txt file.



[image: File]
GBM_Data.RData
<https://drive.google.com/a/saintjosephhs.com/file/d/1vZup-A4ai2D2Ir_DxFlQb87kiYboW9AC/view?usp=drivesdk>

Best,

Spencer

	[[alternative HTML version deleted]]


From |eeko|n@n @end|ng |rom gm@||@com  Sat Apr 13 17:36:32 2019
From: |eeko|n@n @end|ng |rom gm@||@com (Leszek Nowina)
Date: Sat, 13 Apr 2019 17:36:32 +0200
Subject: [R] Why is it not possible to cut a tree returned by Agnes or Diana
 by height?
Message-ID: <CAH-+BmB=3XdtyKK4DiAjg9ve+D3whbRst4jj0v_sS8wW0MWM0Q@mail.gmail.com>

    > asdf = data.frame(x=c(1,2,3), y=c(4,5,6), z=c(7,8,9))
    > cutree(agnes(asdf), h=100)
    Error in cutree(agnes(asdf), h = 100) :
      the 'height' component of 'tree' is not sorted (increasingly)
    > cutree(diana(asdf), h=100)
    Error in cutree(diana(asdf), h = 100) :
      the 'height' component of 'tree' is not sorted (increasingly)

I'm not sure if I understand why this is the case.

This is what I want: Cluster stuff by the //distances//, **not** by
how many clusters I want to have.

If two things are further from each other than X, they should go to
different clusters. Otherwise, the same cluster.

Is it unreasonable what I'm asking for? I image if I was to manually
implement Agnes or Diana this would go like that: stop joining
clusters if the smallest distance between any pair of clusters is
larger than X (Agnes) or stop dividing clusters if the largest cluster
has a diameter of X (Diana); but since both methods always join/divide
to the very end I thought using cutree with a height parameter would
give me what I need. It won't.

Am I missing something?


From dw|n@em|u@ @end|ng |rom comc@@t@net  Mon Apr 15 01:20:49 2019
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sun, 14 Apr 2019 16:20:49 -0700
Subject: [R] Help installing netReg
In-Reply-To: <CAPQaxLPmhsdh5OaOErFQZXym7JpMY9EuPAjEL70-0DFbDks6LA@mail.gmail.com>
References: <CAPQaxLPmhsdh5OaOErFQZXym7JpMY9EuPAjEL70-0DFbDks6LA@mail.gmail.com>
Message-ID: <2826429b-ff8b-6606-a6ba-c27388075d7f@comcast.net>


On 4/14/19 3:20 PM, Spencer Brackett wrote:
> Good evening,
>
>   I am having problems with downloading the package used to generate
> regression models on R. The following is the error message I received. I
> tried installing BiocManager instead as suggested, but this too did not
> work. Any ideas?
>
> The downloaded binary packages are in
> C:\Users\Spencer\AppData\Local\Temp\Rtmp8YKVqx\downloaded_packages
> installation path not writeable, unable to update packages: class, cluster,
> codetools, foreign,
>    lattice, MASS, Matrix, mgcv, nlme, rpart, survival
> Warning message:
> 'biocLite' is deprecated.
> Use 'BiocManager::install' instead.
> See help("Deprecated")


Since you did not include the code that provoked this message we can 
only guess that you did in fact use `bioLite`. We also cannot tell what 
you mean by "problems with downloading the package used to generate 
regression models on R". The typical first step is to use the glm or lm 
function for this task and those are both in the stats package which is 
installed with the base version of R and is loaded by default when R is 
started up.

"

Have you tried following the suggestion at the end of the message?


And do read the Posting Guide and include "commented, minimal, 
self-contained, reproducible code."


-- 

David.

>
> Best,
>
> Spencer
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cry@n @end|ng |rom b|ngh@mton@edu  Mon Apr 15 01:21:52 2019
From: cry@n @end|ng |rom b|ngh@mton@edu (Chris Ryan)
Date: Sun, 14 Apr 2019 19:21:52 -0400
Subject: [R] Help installing netReg
In-Reply-To: <CAPQaxLO_G9Tcxrq3v-P6a0Tdo53hgYE3mrZWn99_72O4=hE2Og@mail.gmail.com>
References: <CAPQaxLO_G9Tcxrq3v-P6a0Tdo53hgYE3mrZWn99_72O4=hE2Og@mail.gmail.com>
Message-ID: <298B1376-AE07-4D20-A756-20FAEDE86CA5@binghamton.edu>

Spencer--

What is your compy set-up? Standalone, networked? Where is R installed? Do you have write privileges to that location?

Chris Ryan
-- 
Sent from my Android device with K-9 Mail. Please excuse my brevity.

On April 14, 2019 6:18:37 PM EDT, Spencer Brackett <spbrackett20 at saintjosephhs.com> wrote:
>Good evening,
>
> I am having problems with downloading the package used to generate
>regression models on R. The following is the error message I received.
>I
>tried installing BiocManager instead as suggested, but this too did not
>work. Any ideas?
>
>The downloaded binary packages are in
>C:\Users\Spencer\AppData\Local\Temp\Rtmp8YKVqx\downloaded_packages
>installation path not writeable, unable to update packages: class,
>cluster,
>codetools, foreign,
>  lattice, MASS, Matrix, mgcv, nlme, rpart, survival
>Warning message:
>'biocLite' is deprecated.
>Use 'BiocManager::install' instead.
>See help("Deprecated")
>
>Best,
>
>Spencer Brackett
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter@4567 @end|ng |rom gm@||@com  Mon Apr 15 01:30:42 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 14 Apr 2019 16:30:42 -0700
Subject: [R] 
 Why is it not possible to cut a tree returned by Agnes or Diana
 by height?
In-Reply-To: <CAH-+BmB=3XdtyKK4DiAjg9ve+D3whbRst4jj0v_sS8wW0MWM0Q@mail.gmail.com>
References: <CAH-+BmB=3XdtyKK4DiAjg9ve+D3whbRst4jj0v_sS8wW0MWM0Q@mail.gmail.com>
Message-ID: <CAGxFJbTp0CbFj_DrNMQj=x1WiAzsMi_CQ7BvvvzF9G2ePcT=Dg@mail.gmail.com>

Inline.

Bert Gunter


On Sun, Apr 14, 2019 at 4:12 PM Leszek Nowina <leekoinan at gmail.com> wrote:

>     > asdf = data.frame(x=c(1,2,3), y=c(4,5,6), z=c(7,8,9))
>     > cutree(agnes(asdf), h=100)
>     Error in cutree(agnes(asdf), h = 100) :
>       the 'height' component of 'tree' is not sorted (increasingly)
>     > cutree(diana(asdf), h=100)
>     Error in cutree(diana(asdf), h = 100) :
>       the 'height' component of 'tree' is not sorted (increasingly)
>
> I'm not sure if I understand why this is the case.
>
> This is what I want: Cluster stuff by the //distances//, **not** by
> how many clusters I want to have.
>
> If two things are further from each other than X, they should go to
> different clusters. Otherwise, the same cluster.
>
> Is it unreasonable what I'm asking for?

Yes.

X and Y are at a distance 2. Y and Z are at a distance 2. X and Z are at a
distance 4. Your idea cannot be consistently applied if 3 is the cutoff for
clustering: Xand Z would have to go in different clusters but both be in
the same cluster as Y.

Maybe you need to spend some time with the literature before trying to cook
up your own notions.

Cheers,
Bert



> I image if I was to manually
> implement Agnes or Diana this would go like that: stop joining
> clusters if the smallest distance between any pair of clusters is
> larger than X (Agnes) or stop dividing clusters if the largest cluster
> has a diameter of X (Diana); but since both methods always join/divide
> to the very end I thought using cutree with a height parameter would
> give me what I need. It won't.
>
> Am I missing something?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdun|@p @end|ng |rom t|bco@com  Mon Apr 15 01:47:55 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Sun, 14 Apr 2019 16:47:55 -0700
Subject: [R] 
 Why is it not possible to cut a tree returned by Agnes or Diana
 by height?
In-Reply-To: <CAH-+BmB=3XdtyKK4DiAjg9ve+D3whbRst4jj0v_sS8wW0MWM0Q@mail.gmail.com>
References: <CAH-+BmB=3XdtyKK4DiAjg9ve+D3whbRst4jj0v_sS8wW0MWM0Q@mail.gmail.com>
Message-ID: <CAF8bMcZ=9gR7QGCHYzHYmuMMTzai9u7HxM8YwhNKM2Ebgp19MA@mail.gmail.com>

I think cutree() only works on things inheriting from class 'hclust' and
agnes, et al do not produce such things.  There are as.hclust methods for
the output of agnes so you might try
    cutree( as.hclust( agnes(...)), h)
instead of
    cutree( agnes(...), h)

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sun, Apr 14, 2019 at 4:12 PM Leszek Nowina <leekoinan at gmail.com> wrote:

>     > asdf = data.frame(x=c(1,2,3), y=c(4,5,6), z=c(7,8,9))
>     > cutree(agnes(asdf), h=100)
>     Error in cutree(agnes(asdf), h = 100) :
>       the 'height' component of 'tree' is not sorted (increasingly)
>     > cutree(diana(asdf), h=100)
>     Error in cutree(diana(asdf), h = 100) :
>       the 'height' component of 'tree' is not sorted (increasingly)
>
> I'm not sure if I understand why this is the case.
>
> This is what I want: Cluster stuff by the //distances//, **not** by
> how many clusters I want to have.
>
> If two things are further from each other than X, they should go to
> different clusters. Otherwise, the same cluster.
>
> Is it unreasonable what I'm asking for? I image if I was to manually
> implement Agnes or Diana this would go like that: stop joining
> clusters if the smallest distance between any pair of clusters is
> larger than X (Agnes) or stop dividing clusters if the largest cluster
> has a diameter of X (Diana); but since both methods always join/divide
> to the very end I thought using cutree with a height parameter would
> give me what I need. It won't.
>
> Am I missing something?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Mon Apr 15 01:48:24 2019
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Sun, 14 Apr 2019 19:48:24 -0400
Subject: [R] Help installing netReg
In-Reply-To: <298B1376-AE07-4D20-A756-20FAEDE86CA5@binghamton.edu>
References: <CAPQaxLO_G9Tcxrq3v-P6a0Tdo53hgYE3mrZWn99_72O4=hE2Og@mail.gmail.com>
 <298B1376-AE07-4D20-A756-20FAEDE86CA5@binghamton.edu>
Message-ID: <CAPQaxLMVAcpJgL3OyTN39nDjS5YbsH4JzauWQPcM1bM38fCmcg@mail.gmail.com>

Mr. Ryan,

If you are referring to the CRAN mirror, my default is US (NY) [https]

On Sun, Apr 14, 2019 at 7:23 PM Chris Ryan <cryan at binghamton.edu> wrote:

> Spencer--
>
> What is your compy set-up? Standalone, networked? Where is R installed? Do
> you have write privileges to that location?
>
> Chris Ryan
> --
> Sent from my Android device with K-9 Mail. Please excuse my brevity.
>
> On April 14, 2019 6:18:37 PM EDT, Spencer Brackett <
> spbrackett20 at saintjosephhs.com> wrote:
> >Good evening,
> >
> > I am having problems with downloading the package used to generate
> >regression models on R. The following is the error message I received.
> >I
> >tried installing BiocManager instead as suggested, but this too did not
> >work. Any ideas?
> >
> >The downloaded binary packages are in
> >C:\Users\Spencer\AppData\Local\Temp\Rtmp8YKVqx\downloaded_packages
> >installation path not writeable, unable to update packages: class,
> >cluster,
> >codetools, foreign,
> >  lattice, MASS, Matrix, mgcv, nlme, rpart, survival
> >Warning message:
> >'biocLite' is deprecated.
> >Use 'BiocManager::install' instead.
> >See help("Deprecated")
> >
> >Best,
> >
> >Spencer Brackett
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Mon Apr 15 01:58:07 2019
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Sun, 14 Apr 2019 19:58:07 -0400
Subject: [R] Help installing netReg
In-Reply-To: <2826429b-ff8b-6606-a6ba-c27388075d7f@comcast.net>
References: <CAPQaxLPmhsdh5OaOErFQZXym7JpMY9EuPAjEL70-0DFbDks6LA@mail.gmail.com>
 <2826429b-ff8b-6606-a6ba-c27388075d7f@comcast.net>
Message-ID: <CAPQaxLM5aJM5uW9NsmXtG1Qbx4Mco7B=uiQ8kdRX+06kGZHCYg@mail.gmail.com>

My apologies... here is the full code in summary

install.packages("ggplot2")
install.packages("ggplot2")
source("https://bioconductor.org/biocLite.R")
?BiocUpgrade
source("https://bioconductor.org/biocLite.R")biocLite("BiocUpgrade")
source("https://bioconductor.org/biocLite.R")
biocLite("BiocUpgrade")
source("https://bioconductor.org/bioLite.R")
biocLite("netReg")
help("Deprecated")
'BiocManager::install'
biocLite("netReg")
help("oldName-deprecated")
???oldName-deprecated?
.Deprecated(new, package=NULL, msg,
old = as.character(sys.call(sys.parent()))[1L])

Best,

Spencer



On Sun, Apr 14, 2019 at 7:20 PM David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On 4/14/19 3:20 PM, Spencer Brackett wrote:
> > Good evening,
> >
> >   I am having problems with downloading the package used to generate
> > regression models on R. The following is the error message I received. I
> > tried installing BiocManager instead as suggested, but this too did not
> > work. Any ideas?
> >
> > The downloaded binary packages are in
> > C:\Users\Spencer\AppData\Local\Temp\Rtmp8YKVqx\downloaded_packages
> > installation path not writeable, unable to update packages: class,
> cluster,
> > codetools, foreign,
> >    lattice, MASS, Matrix, mgcv, nlme, rpart, survival
> > Warning message:
> > 'biocLite' is deprecated.
> > Use 'BiocManager::install' instead.
> > See help("Deprecated")
>
>
> Since you did not include the code that provoked this message we can
> only guess that you did in fact use `bioLite`. We also cannot tell what
> you mean by "problems with downloading the package used to generate
> regression models on R". The typical first step is to use the glm or lm
> function for this task and those are both in the stats package which is
> installed with the base version of R and is loaded by default when R is
> started up.
>
> "
>
> Have you tried following the suggestion at the end of the message?
>
>
> And do read the Posting Guide and include "commented, minimal,
> self-contained, reproducible code."
>
>
> --
>
> David.
>
> >
> > Best,
> >
> > Spencer
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From djnord|und @end|ng |rom gm@||@com  Mon Apr 15 03:10:02 2019
From: djnord|und @end|ng |rom gm@||@com (Daniel Nordlund)
Date: Sun, 14 Apr 2019 18:10:02 -0700
Subject: [R] Downloading R Data
In-Reply-To: <CAPQaxLN-gpA_1j8wo9FiEya07uRw295cf7Lr3DR7gL13WL+Gfg@mail.gmail.com>
References: <CAPQaxLN-gpA_1j8wo9FiEya07uRw295cf7Lr3DR7gL13WL+Gfg@mail.gmail.com>
Message-ID: <6e09fac5-546e-a2f1-7dea-a1fe0bf36f57@gmail.com>

On 4/14/2019 3:36 PM, Spencer Brackett wrote:
>    I am also looking to be able to read this file on an appropriate
> application. As of now, it?s too large to view directly in GoogleDrive or
> word, and I can only get a mistranslated version of the script included as
> a .txt file.
>
>
>
> [image: File]
> GBM_Data.RData
> <https://drive.google.com/a/saintjosephhs.com/file/d/1vZup-A4ai2D2Ir_DxFlQb87kiYboW9AC/view?usp=drivesdk>
>
> Best,
>
> Spencer
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Spencer,

this looks like an saved R workspace.? I went to provided link using 
Firefox and clicked on the icon to download a file.? Once the file was 
downloaded, I started the RGui and entered the following command

load(file.choose())

This opened a window in which I could browse to the file and load it 
into R.? Also, I could double click on the file and Rstudio would load 
the file into the workspace.

If you wish to do something else, you will need to be more specific 
about what you want.


Hope this is helpful,

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From drj|m|emon @end|ng |rom gm@||@com  Mon Apr 15 03:17:46 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 15 Apr 2019 11:17:46 +1000
Subject: [R] Downloading R Data
In-Reply-To: <CAPQaxLN-gpA_1j8wo9FiEya07uRw295cf7Lr3DR7gL13WL+Gfg@mail.gmail.com>
References: <CAPQaxLN-gpA_1j8wo9FiEya07uRw295cf7Lr3DR7gL13WL+Gfg@mail.gmail.com>
Message-ID: <CA+8X3fUm6HXDpG1PNqF1qNZ_Qc+0xpPwhwm3kHLNBQ0j1dn5qQ@mail.gmail.com>

Hi Spencer,
Just download it to your R working directory and:

load("GBM_data.Rdata")

Worked okay for me (all 53.9 Mb)

Jim

On Mon, Apr 15, 2019 at 8:39 AM Spencer Brackett
<spbrackett20 at saintjosephhs.com> wrote:
>
>   I am also looking to be able to read this file on an appropriate
> application. As of now, it?s too large to view directly in GoogleDrive or
> word, and I can only get a mistranslated version of the script included as
> a .txt file.
>
>
>
> [image: File]
> GBM_Data.RData
> <https://drive.google.com/a/saintjosephhs.com/file/d/1vZup-A4ai2D2Ir_DxFlQb87kiYboW9AC/view?usp=drivesdk>
>
> Best,
>
> Spencer
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cry@n @end|ng |rom b|ngh@mton@edu  Mon Apr 15 03:34:54 2019
From: cry@n @end|ng |rom b|ngh@mton@edu (Christopher W. Ryan)
Date: Sun, 14 Apr 2019 21:34:54 -0400
Subject: [R] Help installing netReg
In-Reply-To: <CAPQaxLMVAcpJgL3OyTN39nDjS5YbsH4JzauWQPcM1bM38fCmcg@mail.gmail.com>
References: <CAPQaxLO_G9Tcxrq3v-P6a0Tdo53hgYE3mrZWn99_72O4=hE2Og@mail.gmail.com>
 <298B1376-AE07-4D20-A756-20FAEDE86CA5@binghamton.edu>
 <CAPQaxLMVAcpJgL3OyTN39nDjS5YbsH4JzauWQPcM1bM38fCmcg@mail.gmail.com>
Message-ID: <54b7adb5-1062-91b0-6682-9ce0330f3cee-3322@binghamton.edu>


Sorry, was typing on my phone. Not "compy."  "Computer."  I was asking
whether you were working on your own, standalone, computer, or whether
perhaps this was an institutional, networked, machine, on which you
don't have write permissions that you need.

--Chris Ryan

Spencer Brackett wrote:
> Mr. Ryan,?
> 
> If you are referring to the CRAN mirror, my default is US (NY) [https]
> 
> On Sun, Apr 14, 2019 at 7:23 PM Chris Ryan <cryan at binghamton.edu
> <mailto:cryan at binghamton.edu>> wrote:
> 
>     Spencer--
> 
>     What is your compy set-up? Standalone, networked? Where is R
>     installed? Do you have write privileges to that location?
> 
>     Chris Ryan
>     -- 
>     Sent from my Android device with K-9 Mail. Please excuse my brevity.
> 
>     On April 14, 2019 6:18:37 PM EDT, Spencer Brackett
>     <spbrackett20 at saintjosephhs.com
>     <mailto:spbrackett20 at saintjosephhs.com>> wrote:
>     >Good evening,
>     >
>     > I am having problems with downloading the package used to generate
>     >regression models on R. The following is the error message I received.
>     >I
>     >tried installing BiocManager instead as suggested, but this too did not
>     >work. Any ideas?
>     >
>     >The downloaded binary packages are in
>     >C:\Users\Spencer\AppData\Local\Temp\Rtmp8YKVqx\downloaded_packages
>     >installation path not writeable, unable to update packages: class,
>     >cluster,
>     >codetools, foreign,
>     >? lattice, MASS, Matrix, mgcv, nlme, rpart, survival
>     >Warning message:
>     >'biocLite' is deprecated.
>     >Use 'BiocManager::install' instead.
>     >See help("Deprecated")
>     >
>     >Best,
>     >
>     >Spencer Brackett
>     >
>     >? ? ? ?[[alternative HTML version deleted]]
>     >
>     >______________________________________________
>     >R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     >https://stat.ethz.ch/mailman/listinfo/r-help
>     >PLEASE do read the posting guide
>     >http://www.R-project.org/posting-guide.html
>     >and provide commented, minimal, self-contained, reproducible code.
> 
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>


From |eeko|n@n @end|ng |rom gm@||@com  Mon Apr 15 15:10:15 2019
From: |eeko|n@n @end|ng |rom gm@||@com (Leszek Nowina)
Date: Mon, 15 Apr 2019 15:10:15 +0200
Subject: [R] 
 Why is it not possible to cut a tree returned by Agnes or Diana
 by height?
In-Reply-To: <CAGxFJbTp0CbFj_DrNMQj=x1WiAzsMi_CQ7BvvvzF9G2ePcT=Dg@mail.gmail.com>
References: <CAH-+BmB=3XdtyKK4DiAjg9ve+D3whbRst4jj0v_sS8wW0MWM0Q@mail.gmail.com>
 <CAGxFJbTp0CbFj_DrNMQj=x1WiAzsMi_CQ7BvvvzF9G2ePcT=Dg@mail.gmail.com>
Message-ID: <CAH-+BmDHn=yan7BspV7zxWGyQ0ONrpok9E+8hu-YkvNe71qtxQ@mail.gmail.com>

Either way, it would seem to me that cutree(tree, h=height) could be
easily implemented as cutree(tree, k=sum(tree$height>height)+1) - why
isn't it?

Or is this not really the same, despite what seems to me?

pon., 15 kwi 2019 o 01:30 Bert Gunter <bgunter.4567 at gmail.com> napisa?(a):
>
> Inline.
>
> Bert Gunter
>
>
> On Sun, Apr 14, 2019 at 4:12 PM Leszek Nowina <leekoinan at gmail.com> wrote:
>>
>>     > asdf = data.frame(x=c(1,2,3), y=c(4,5,6), z=c(7,8,9))
>>     > cutree(agnes(asdf), h=100)
>>     Error in cutree(agnes(asdf), h = 100) :
>>       the 'height' component of 'tree' is not sorted (increasingly)
>>     > cutree(diana(asdf), h=100)
>>     Error in cutree(diana(asdf), h = 100) :
>>       the 'height' component of 'tree' is not sorted (increasingly)
>>
>> I'm not sure if I understand why this is the case.
>>
>> This is what I want: Cluster stuff by the //distances//, **not** by
>> how many clusters I want to have.
>>
>> If two things are further from each other than X, they should go to
>> different clusters. Otherwise, the same cluster.
>>
>> Is it unreasonable what I'm asking for?
>
> Yes.
>
> X and Y are at a distance 2. Y and Z are at a distance 2. X and Z are at a distance 4. Your idea cannot be consistently applied if 3 is the cutoff for clustering: Xand Z would have to go in different clusters but both be in the same cluster as Y.
>
> Maybe you need to spend some time with the literature before trying to cook up your own notions.
>
> Cheers,
> Bert
>
>
>>
>> I image if I was to manually
>> implement Agnes or Diana this would go like that: stop joining
>> clusters if the smallest distance between any pair of clusters is
>> larger than X (Agnes) or stop dividing clusters if the largest cluster
>> has a diameter of X (Diana); but since both methods always join/divide
>> to the very end I thought using cutree with a height parameter would
>> give me what I need. It won't.
>>
>> Am I missing something?
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From @n@@nth@np|||@| @end|ng |rom gm@||@com  Mon Apr 15 17:06:05 2019
From: @n@@nth@np|||@| @end|ng |rom gm@||@com (Anaanthan Pillai)
Date: Mon, 15 Apr 2019 23:06:05 +0800
Subject: [R] Unable to load built In Datasets From Stat2Data package.
Message-ID: <04D80819-FE88-4095-9359-FA71FB195F88@gmail.com>

Hi,

I?ve been trying to load datasets from Stat2Data, but couldn?t proceed to do so. I can install the package though, but the datasets are not being loaded.

Is there any error that I do? 

Regards,

Anand

> library(Stat2Data)
> data <- ICU
Error: object 'ICU' not found
> Sparrows
Error: object 'Sparrows' not found
> SeaSlugs
Error: object 'SeaSlugs' not found

From ||@t@ @end|ng |rom dewey@myzen@co@uk  Mon Apr 15 17:15:23 2019
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Mon, 15 Apr 2019 16:15:23 +0100
Subject: [R] Unable to load built In Datasets From Stat2Data package.
In-Reply-To: <04D80819-FE88-4095-9359-FA71FB195F88@gmail.com>
References: <04D80819-FE88-4095-9359-FA71FB195F88@gmail.com>
Message-ID: <4a2e6f41-db87-8301-e555-c5e92c0fc24e@dewey.myzen.co.uk>

Did you mean to do

data(ICU)

and then use ICU

and so on

On 15/04/2019 16:06, Anaanthan Pillai wrote:
> Hi,
> 
> I?ve been trying to load datasets from Stat2Data, but couldn?t proceed to do so. I can install the package though, but the datasets are not being loaded.
> 
> Is there any error that I do?
> 
> Regards,
> 
> Anand
> 
>> library(Stat2Data)
>> data <- ICU
> Error: object 'ICU' not found
>> Sparrows
> Error: object 'Sparrows' not found
>> SeaSlugs
> Error: object 'SeaSlugs' not found
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ---
> This email has been checked for viruses by AVG.
> https://www.avg.com
> 
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From dc@r|@on @end|ng |rom t@mu@edu  Mon Apr 15 18:01:23 2019
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Mon, 15 Apr 2019 16:01:23 +0000
Subject: [R] 
 Why is it not possible to cut a tree returned by Agnes or Diana
 by height?
In-Reply-To: <CAH-+BmDHn=yan7BspV7zxWGyQ0ONrpok9E+8hu-YkvNe71qtxQ@mail.gmail.com>
References: <CAH-+BmB=3XdtyKK4DiAjg9ve+D3whbRst4jj0v_sS8wW0MWM0Q@mail.gmail.com>
 <CAGxFJbTp0CbFj_DrNMQj=x1WiAzsMi_CQ7BvvvzF9G2ePcT=Dg@mail.gmail.com>
 <CAH-+BmDHn=yan7BspV7zxWGyQ0ONrpok9E+8hu-YkvNe71qtxQ@mail.gmail.com>
Message-ID: <eeaa5ccc16d149e0968ff7d4a4ba2b0b@tamu.edu>

You can certainly use your computation to define the number of clusters.

Some clustering methods (e.g. Centroid, Median) use the distance to the centers of the clusters as the criterion for combining clusters, but these locations change as clusters are combined so that the distances between clusters can decrease as the clustering process continues. When this happens, the same height can refer to more than one number-of-clusters solution. These are referred to as dendrogram inversions. Only clustering methods that produce ultrametric trees guarantee to have a unique number-of-clusters at every height so the cutree() function uses the order of the heights to determine if the tree is ultrametric. Also the function was written before the cluster package so the documentation for that package should address this since it indicates that cutree() will work on an agnes object, but I haven't been able to find it so far. As Bill mentioned, the simplest solution is to use as.hclust():

> asdf.ag <- agnes(asdf)
> cutree(asdf.ag, h=2)
Error in cutree(asdf.ag, h = 2) : 
  the 'height' component of 'tree' is not sorted (increasingly)
> cutree(as.hclust(asdf.ag), h=2)
[1] 1 2 2

> asdf.di <- diana(asdf)
> cutree(asdf.di, h=2)
Error in cutree(asdf.di, h = 2) : 
  the 'height' component of 'tree' is not sorted (increasingly)
> cutree(as.hclust(asdf.di), h=2)
[1] 1 2 2

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Leszek Nowina
Sent: Monday, April 15, 2019 8:10 AM
To: Bert Gunter <bgunter.4567 at gmail.com>
Cc: R-help <r-help at r-project.org>
Subject: Re: [R] Why is it not possible to cut a tree returned by Agnes or Diana by height?

Either way, it would seem to me that cutree(tree, h=height) could be
easily implemented as cutree(tree, k=sum(tree$height>height)+1) - why
isn't it?

Or is this not really the same, despite what seems to me?

pon., 15 kwi 2019 o 01:30 Bert Gunter <bgunter.4567 at gmail.com> napisa?(a):
>
> Inline.
>
> Bert Gunter
>
>
> On Sun, Apr 14, 2019 at 4:12 PM Leszek Nowina <leekoinan at gmail.com> wrote:
>>
>>     > asdf = data.frame(x=c(1,2,3), y=c(4,5,6), z=c(7,8,9))
>>     > cutree(agnes(asdf), h=100)
>>     Error in cutree(agnes(asdf), h = 100) :
>>       the 'height' component of 'tree' is not sorted (increasingly)
>>     > cutree(diana(asdf), h=100)
>>     Error in cutree(diana(asdf), h = 100) :
>>       the 'height' component of 'tree' is not sorted (increasingly)
>>
>> I'm not sure if I understand why this is the case.
>>
>> This is what I want: Cluster stuff by the //distances//, **not** by
>> how many clusters I want to have.
>>
>> If two things are further from each other than X, they should go to
>> different clusters. Otherwise, the same cluster.
>>
>> Is it unreasonable what I'm asking for?
>
> Yes.
>
> X and Y are at a distance 2. Y and Z are at a distance 2. X and Z are at a distance 4. Your idea cannot be consistently applied if 3 is the cutoff for clustering: Xand Z would have to go in different clusters but both be in the same cluster as Y.
>
> Maybe you need to spend some time with the literature before trying to cook up your own notions.
>
> Cheers,
> Bert
>
>
>>
>> I image if I was to manually
>> implement Agnes or Diana this would go like that: stop joining
>> clusters if the smallest distance between any pair of clusters is
>> larger than X (Agnes) or stop dividing clusters if the largest cluster
>> has a diameter of X (Diana); but since both methods always join/divide
>> to the very end I thought using cutree with a height parameter would
>> give me what I need. It won't.
>>
>> Am I missing something?
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From m@|||P@dpo@t @end|ng |rom gm@||@com  Mon Apr 15 18:50:36 2019
From: m@|||P@dpo@t @end|ng |rom gm@||@com (Medic)
Date: Mon, 15 Apr 2019 19:50:36 +0300
Subject: [R] plot (cox)
Message-ID: <CAH6117KGnB_b7dW4QHUrLiRK45yUHczAbdJoc_VzTZDd1Gf1fw@mail.gmail.com>

In this code:

plot (cox, col=1:2, xscale=1, xlab="OS",  ylab="Probability")

the X scale is divided (by default) as:

 0 ... 50 ... 100 ... 150 ... 200

And I would like so:

0 ... 12 ... 24 ... 36 ... 48.

I looked ?plot(cox), but did not understand what argument is
responsible for this.

Pls, help me!


From @@r@h@go@|ee @end|ng |rom gm@||@com  Mon Apr 15 19:31:39 2019
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Mon, 15 Apr 2019 13:31:39 -0400
Subject: [R] plot (cox)
In-Reply-To: <CAH6117KGnB_b7dW4QHUrLiRK45yUHczAbdJoc_VzTZDd1Gf1fw@mail.gmail.com>
References: <CAH6117KGnB_b7dW4QHUrLiRK45yUHczAbdJoc_VzTZDd1Gf1fw@mail.gmail.com>
Message-ID: <CAM_vjuk3hM_bs0yX34y2MTUhA=z0URQW6zEkKvc7DSCqWFA61Q@mail.gmail.com>

You can presumably use xaxt="n" in your plot() statement (see ?par for
details), and then use axis() to make anything you'd like (see ?axis
for details).

Sarah

On Mon, Apr 15, 2019 at 12:51 PM Medic <mailiPadpost at gmail.com> wrote:
>
> In this code:
>
> plot (cox, col=1:2, xscale=1, xlab="OS",  ylab="Probability")
>
> the X scale is divided (by default) as:
>
>  0 ... 50 ... 100 ... 150 ... 200
>
> And I would like so:
>
> 0 ... 12 ... 24 ... 36 ... 48.
>
> I looked ?plot(cox), but did not understand what argument is
> responsible for this.
>
> Pls, help me!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From m@|||P@dpo@t @end|ng |rom gm@||@com  Mon Apr 15 21:01:22 2019
From: m@|||P@dpo@t @end|ng |rom gm@||@com (Medic)
Date: Mon, 15 Apr 2019 22:01:22 +0300
Subject: [R] plot (cox)
In-Reply-To: <CAM_vjuk3hM_bs0yX34y2MTUhA=z0URQW6zEkKvc7DSCqWFA61Q@mail.gmail.com>
References: <CAH6117KGnB_b7dW4QHUrLiRK45yUHczAbdJoc_VzTZDd1Gf1fw@mail.gmail.com>
 <CAM_vjuk3hM_bs0yX34y2MTUhA=z0URQW6zEkKvc7DSCqWFA61Q@mail.gmail.com>
Message-ID: <CAH6117JvWEiPmxU3cjtjn37C8NGdLdLmidH05oQG=4Gs-8vGQQ@mail.gmail.com>

Thanks, but too hard for me

Sarah Goslee <sarah.goslee at gmail.com>:
> You can presumably use xaxt="n" in your plot() statement (see ?par for
> details), and then use axis() to make anything you'd like (see ?axis
> for details).
----------------------------------
>> Medic <mailiPadpost at gmail.com> wrote:
>> In this code:
>> plot (cox, col=1:2, xscale=1, xlab="OS",  ylab="Probability")
>> the X scale is divided (by default) as:
>>  0 ... 50 ... 100 ... 150 ... 200
>> And I would like so:
>> 0 ... 12 ... 24 ... 36 ... 48.
>> I looked ?plot(cox), but did not understand what argument is
>> responsible for this.


From @@r@h@go@|ee @end|ng |rom gm@||@com  Mon Apr 15 21:43:25 2019
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Mon, 15 Apr 2019 15:43:25 -0400
Subject: [R] plot (cox)
In-Reply-To: <CAH6117JvWEiPmxU3cjtjn37C8NGdLdLmidH05oQG=4Gs-8vGQQ@mail.gmail.com>
References: <CAH6117KGnB_b7dW4QHUrLiRK45yUHczAbdJoc_VzTZDd1Gf1fw@mail.gmail.com>
 <CAM_vjuk3hM_bs0yX34y2MTUhA=z0URQW6zEkKvc7DSCqWFA61Q@mail.gmail.com>
 <CAH6117JvWEiPmxU3cjtjn37C8NGdLdLmidH05oQG=4Gs-8vGQQ@mail.gmail.com>
Message-ID: <CAM_vju=a_BrD0jpLtyE2c3ypm8Ad4Uk_mBkp8Q_WW=L=WaXrdA@mail.gmail.com>

Well, you don't provide a reproducible example, so there's only so
much we can do. The help for par is a lot, but I told you which option
to use.
Did you try reading the examples for ?axis at all?


plot (cox, col=1:2, xscale=1, xlab="OS",  ylab="Probability", xaxt="n")
axis(1, at=seq(0, 48, by=12))

Or whatever axis values you actually want.

Sarah

On Mon, Apr 15, 2019 at 3:02 PM Medic <mailiPadpost at gmail.com> wrote:
>
> Thanks, but too hard for me
>
> Sarah Goslee <sarah.goslee at gmail.com>:
> > You can presumably use xaxt="n" in your plot() statement (see ?par for
> > details), and then use axis() to make anything you'd like (see ?axis
> > for details).
> ----------------------------------
> >> Medic <mailiPadpost at gmail.com> wrote:
> >> In this code:
> >> plot (cox, col=1:2, xscale=1, xlab="OS",  ylab="Probability")
> >> the X scale is divided (by default) as:
> >>  0 ... 50 ... 100 ... 150 ... 200
> >> And I would like so:
> >> 0 ... 12 ... 24 ... 36 ... 48.
> >> I looked ?plot(cox), but did not understand what argument is
> >> responsible for this.



-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From m@|||P@dpo@t @end|ng |rom gm@||@com  Mon Apr 15 22:09:47 2019
From: m@|||P@dpo@t @end|ng |rom gm@||@com (Medic)
Date: Mon, 15 Apr 2019 23:09:47 +0300
Subject: [R] plot (cox)
In-Reply-To: <CAM_vju=a_BrD0jpLtyE2c3ypm8Ad4Uk_mBkp8Q_WW=L=WaXrdA@mail.gmail.com>
References: <CAH6117KGnB_b7dW4QHUrLiRK45yUHczAbdJoc_VzTZDd1Gf1fw@mail.gmail.com>
 <CAM_vjuk3hM_bs0yX34y2MTUhA=z0URQW6zEkKvc7DSCqWFA61Q@mail.gmail.com>
 <CAH6117JvWEiPmxU3cjtjn37C8NGdLdLmidH05oQG=4Gs-8vGQQ@mail.gmail.com>
 <CAM_vju=a_BrD0jpLtyE2c3ypm8Ad4Uk_mBkp8Q_WW=L=WaXrdA@mail.gmail.com>
Message-ID: <CAH6117Lt_c8NZsnd_RZb54GaPf1S_t5rSgRZS5Sf6PCNEn20GQ@mail.gmail.com>

Dear Sarah,
everything worked out! Thank You!!!
----------------------------------
Sarah Goslee <sarah.goslee at gmail.com>:
> Well, you don't provide a reproducible example, so there's only so
> much we can do. The help for par is a lot, but I told you which option
> to use. Did you try reading the examples for ?axis at all?
> plot (cox, col=1:2, xscale=1, xlab="OS",  ylab="Probability", xaxt="n")
> axis(1, at=seq(0, 48, by=12))
> Or whatever axis values you actually want.

> > Sarah Goslee <sarah.goslee at gmail.com>:
> > > You can presumably use xaxt="n" in your plot() statement (see ?par for
> > > details), and then use axis() to make anything you'd like (see ?axis
> > > for details).
> > ----------------------------------
> > >> Medic <mailiPadpost at gmail.com> wrote:
> > >> In this code:
> > >> plot (cox, col=1:2, xscale=1, xlab="OS",  ylab="Probability")
> > >> the X scale is divided (by default) as:
> > >>  0 ... 50 ... 100 ... 150 ... 200
> > >> And I would like so:
> > >> 0 ... 12 ... 24 ... 36 ... 48.
> > >> I looked ?plot(cox), but did not understand what argument is
> > >> responsible for this.


From Joe@F|eck @end|ng |rom Ter@d@t@@com  Mon Apr 15 17:50:44 2019
From: Joe@F|eck @end|ng |rom Ter@d@t@@com (Fieck, Joe)
Date: Mon, 15 Apr 2019 15:50:44 +0000
Subject: [R] Code driven data.frame naming question.
Message-ID: <CY4PR13MB1623CCBA1980F99AB7083E6E8B2B0@CY4PR13MB1623.namprd13.prod.outlook.com>

Hello R list.  I'm very new.  I have what I hope is a simple question that I have not been able to find a good solution for.
If this is common and clutters anyone's inbox my most sincere apologies in advance...

I am trying to use an argument from a function in the name of a data.frame.  But I seem to only be able to reference the arguments from the right hand side of the <- .

So something like this.  I would just want the function below to create a new data.frame named "myDataSet". 
Done on its own like "myDataSet <- data.frame()"

myFunction <- function(x){       # suppose x is just a collection with one value with is the name I want the data.frame create as.. c("myDataSet") for example
	name(x) <- data.frame()
}

But this of course doesn't work because I have not figured out how to reference the function argument from the left hand side of the <- .  
I have read about the "assign" function but from what I can tell (granted I'm new to R) the assign function works on the variable names not data.frame names which is what I need.

Ultimately what I'm trying accomplish to send a list of character strings then iterate it and create multiple new data.frames each having the name of one of the elements of the list passed to the function.

If there is even a better article out on the web that I'm obviously missing please orient me.   I have struck out so far but I know I may not be searching correctly either. 
Any help at all would be much appreciated...

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Apr 16 01:55:17 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 15 Apr 2019 16:55:17 -0700
Subject: [R] Code driven data.frame naming question.
In-Reply-To: <CY4PR13MB1623CCBA1980F99AB7083E6E8B2B0@CY4PR13MB1623.namprd13.prod.outlook.com>
References: <CY4PR13MB1623CCBA1980F99AB7083E6E8B2B0@CY4PR13MB1623.namprd13.prod.outlook.com>
Message-ID: <10F1951E-7F9F-43A0-8F6F-E8140C1FACA2@dcn.davis.ca.us>

While the assign function is in fact the function you are looking for, I would strongly advise that you cease and desist in this endeavour and instead make a list of data frames rather than littering your global environment with many individual data frames.

If you have a vector of names of files you can use lapply to read them all into a list of data frames. You can then use the filenames as "names" with which to look up the appropriate data. E.g.

dtadir <- "datadir"
myfiles <- list.files( dtadir )
dtalist <- lapply( myfiles, function(fn) {
   read.csv( file.path( dtadir, fn ), stringsAsFactors=FALSE )
  }
names( dtalist ) <- myfiles

str(dtalist$file001.csv)
str(dtalist[[ "file001.csv" ]])
str( dtalist[[ 1 ]] )

If the filenames have unusual characters in them then you may have to use back-tick quotes when using the dollar-sign operator.

On April 15, 2019 8:50:44 AM PDT, "Fieck, Joe" <Joe.Fieck at Teradata.com> wrote:
>Hello R list.  I'm very new.  I have what I hope is a simple question
>that I have not been able to find a good solution for.
>If this is common and clutters anyone's inbox my most sincere apologies
>in advance...
>
>I am trying to use an argument from a function in the name of a
>data.frame.  But I seem to only be able to reference the arguments from
>the right hand side of the <- .
>
>So something like this.  I would just want the function below to create
>a new data.frame named "myDataSet". 
>Done on its own like "myDataSet <- data.frame()"
>
>myFunction <- function(x){       # suppose x is just a collection with
>one value with is the name I want the data.frame create as..
>c("myDataSet") for example
>	name(x) <- data.frame()
>}
>
>But this of course doesn't work because I have not figured out how to
>reference the function argument from the left hand side of the <- .  
>I have read about the "assign" function but from what I can tell
>(granted I'm new to R) the assign function works on the variable names
>not data.frame names which is what I need.
>
>Ultimately what I'm trying accomplish to send a list of character
>strings then iterate it and create multiple new data.frames each having
>the name of one of the elements of the list passed to the function.
>
>If there is even a better article out on the web that I'm obviously
>missing please orient me.   I have struck out so far but I know I may
>not be searching correctly either. 
>Any help at all would be much appreciated...
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From Joe@F|eck @end|ng |rom Ter@d@t@@com  Tue Apr 16 02:09:51 2019
From: Joe@F|eck @end|ng |rom Ter@d@t@@com (Fieck, Joe)
Date: Tue, 16 Apr 2019 00:09:51 +0000
Subject: [R] Code driven data.frame naming question.
In-Reply-To: <10F1951E-7F9F-43A0-8F6F-E8140C1FACA2@dcn.davis.ca.us>
References: <CY4PR13MB1623CCBA1980F99AB7083E6E8B2B0@CY4PR13MB1623.namprd13.prod.outlook.com>
 <10F1951E-7F9F-43A0-8F6F-E8140C1FACA2@dcn.davis.ca.us>
Message-ID: <CY4PR13MB1623D87D833A4B861039B5CA8B240@CY4PR13MB1623.namprd13.prod.outlook.com>

Thanks for the reply Jeff.  I will play around with your code example and see where it takes me.

-----Original Message-----
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 
Sent: Monday, April 15, 2019 4:55 PM
To: r-help at r-project.org; Fieck, Joe <Joe.Fieck at Teradata.com>; R-help at r-project.org
Subject: Re: [R] Code driven data.frame naming question.

[External Email]
________________________________

While the assign function is in fact the function you are looking for, I would strongly advise that you cease and desist in this endeavour and instead make a list of data frames rather than littering your global environment with many individual data frames.

If you have a vector of names of files you can use lapply to read them all into a list of data frames. You can then use the filenames as "names" with which to look up the appropriate data. E.g.

dtadir <- "datadir"
myfiles <- list.files( dtadir )
dtalist <- lapply( myfiles, function(fn) {
   read.csv( file.path( dtadir, fn ), stringsAsFactors=FALSE )
  }
names( dtalist ) <- myfiles

str(dtalist$file001.csv)
str(dtalist[[ "file001.csv" ]])
str( dtalist[[ 1 ]] )

If the filenames have unusual characters in them then you may have to use back-tick quotes when using the dollar-sign operator.

On April 15, 2019 8:50:44 AM PDT, "Fieck, Joe" <Joe.Fieck at Teradata.com> wrote:
>Hello R list.  I'm very new.  I have what I hope is a simple question 
>that I have not been able to find a good solution for.
>If this is common and clutters anyone's inbox my most sincere apologies 
>in advance...
>
>I am trying to use an argument from a function in the name of a 
>data.frame.  But I seem to only be able to reference the arguments from 
>the right hand side of the <- .
>
>So something like this.  I would just want the function below to create 
>a new data.frame named "myDataSet".
>Done on its own like "myDataSet <- data.frame()"
>
>myFunction <- function(x){       # suppose x is just a collection with
>one value with is the name I want the data.frame create as..
>c("myDataSet") for example
>       name(x) <- data.frame()
>}
>
>But this of course doesn't work because I have not figured out how to 
>reference the function argument from the left hand side of the <- .
>I have read about the "assign" function but from what I can tell 
>(granted I'm new to R) the assign function works on the variable names 
>not data.frame names which is what I need.
>
>Ultimately what I'm trying accomplish to send a list of character 
>strings then iterate it and create multiple new data.frames each having 
>the name of one of the elements of the list passed to the function.
>
>If there is even a better article out on the web that I'm obviously
>missing please orient me.   I have struck out so far but I know I may
>not be searching correctly either.
>Any help at all would be much appreciated...
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

--
Sent from my phone. Please excuse my brevity.

From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Tue Apr 16 15:06:25 2019
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Tue, 16 Apr 2019 18:36:25 +0530
Subject: [R] Snapshot of a shiny app
Message-ID: <CA+dpOJmLgay1GKL51h-bTWNH8mdzrTPuh_0_crW7HUKE-FJDVQ@mail.gmail.com>

Hi,

I have a Shiny app with address like http://xx.xx.xx.xx:1080/remotepp/

When I try to get a PDF snapshot of this app using webshot() function from
webshot package, I see a blank PDF file saved.

I also tried with appshot() function as below, however getting error:

appshot(" http://xx.xx.xx.xx/remotepp  ", "a.pdf", port = 1080)
Error in process_initialize(self, private, command, args, stdout, stderr,
:
  Command not found

Any pointer on how to take snapshot properly would be highly appreciated.

	[[alternative HTML version deleted]]


From epurdom @end|ng |rom @t@t@berke|ey@edu  Tue Apr 16 18:12:49 2019
From: epurdom @end|ng |rom @t@t@berke|ey@edu (Elizabeth Purdom)
Date: Tue, 16 Apr 2019 09:12:49 -0700
Subject: [R] Limiting the scope of RNGkind/set.seed
Message-ID: <71BF8BB4-CD39-4FFD-8671-0F8DEFE9B088@stat.berkeley.edu>

Hello,

I have a package, and inside of it I have a small function that selects a random palette of colors for graphing purposes. It?s a large number of colors, which is why I don?t manually select them, but I did want them to stay constant so I set the seed before doing so. So I had a little function in my package that does this:

.rcolors<-function(){
	set.seed(23589)
	x<-sample(colors()[-c(152:361)])
	return(x)
}
massivePalette<-unique(c(bigPalette,.rcolors()))

Now that the sample function has been changed in R 3.6, I would need to use `sample.kind=?Rounding?` to get the same set of colors as I had previously. However, I don?t want to do that in my package, because that appears to change the global environment sampling:

> RNGkind()
[1] "Mersenne-Twister" "Inversion"        "Rejection"       
> RNGkind(sample.kind="Rejection")
> x<-clusterExperiment:::.rcolors() #now I have changed the function so that sample.kind=?Rounding? ? I?ve suppressed the warnings
> RNGkind()
[1] "Mersenne-Twister" "Inversion"        "Rounding?  

So I could do something like this:

.rcolors<-function(){
	currentRNG<-RNGkind()
	suppressWarnings(RNGkind(sample.kind="Rounding"))
	set.seed(23589)
	x<-sample(colors()[-c(152:361)])
	#set it back to default
	suppressWarnings(RNGkind(sample.kind=currentRNG[3]))
	return(x)
}

But is there a way to change the random sampling in the function environment and not change it in the global environment? (For this function, I can just break down and accept that I will have different colors from this point on, but I?d like to know more generally; especially since it means that my `fixed` colors are not really fixed since they depend on the user?s setting of random sampling techniques, which I hadn?t considered before). 

All of the best,
Elizabeth Purdom


From bgunter@4567 @end|ng |rom gm@||@com  Tue Apr 16 18:36:40 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 16 Apr 2019 09:36:40 -0700
Subject: [R] Limiting the scope of RNGkind/set.seed
In-Reply-To: <71BF8BB4-CD39-4FFD-8671-0F8DEFE9B088@stat.berkeley.edu>
References: <71BF8BB4-CD39-4FFD-8671-0F8DEFE9B088@stat.berkeley.edu>
Message-ID: <CAGxFJbQ7Gq0_0yLpdx-aCYoWiW=SbjuPO+pq8ABJNnP8MpfFbA@mail.gmail.com>

I think I'm missing something. Why does something like this not do what you
want:

> RNGkind()
[1] "Mersenne-Twister" "Inversion"
> f <- function(){
+    cur <- RNGkind(NULL)[1]
+    RNGkind("Super-Duper")
+    print(RNGkind())
+    RNGkind(cur)
+ }
> f()
[1] "Super-Duper" "Inversion"
> RNGkind()
[1] "Mersenne-Twister" "Inversion"

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 16, 2019 at 9:13 AM Elizabeth Purdom <epurdom at stat.berkeley.edu>
wrote:

> Hello,
>
> I have a package, and inside of it I have a small function that selects a
> random palette of colors for graphing purposes. It?s a large number of
> colors, which is why I don?t manually select them, but I did want them to
> stay constant so I set the seed before doing so. So I had a little function
> in my package that does this:
>
> .rcolors<-function(){
>         set.seed(23589)
>         x<-sample(colors()[-c(152:361)])
>         return(x)
> }
> massivePalette<-unique(c(bigPalette,.rcolors()))
>
> Now that the sample function has been changed in R 3.6, I would need to
> use `sample.kind=?Rounding?` to get the same set of colors as I had
> previously. However, I don?t want to do that in my package, because that
> appears to change the global environment sampling:
>
> > RNGkind()
> [1] "Mersenne-Twister" "Inversion"        "Rejection"
> > RNGkind(sample.kind="Rejection")
> > x<-clusterExperiment:::.rcolors() #now I have changed the function so
> that sample.kind=?Rounding? ? I?ve suppressed the warnings
> > RNGkind()
> [1] "Mersenne-Twister" "Inversion"        "Rounding?
>
> So I could do something like this:
>
> .rcolors<-function(){
>         currentRNG<-RNGkind()
>         suppressWarnings(RNGkind(sample.kind="Rounding"))
>         set.seed(23589)
>         x<-sample(colors()[-c(152:361)])
>         #set it back to default
>         suppressWarnings(RNGkind(sample.kind=currentRNG[3]))
>         return(x)
> }
>
> But is there a way to change the random sampling in the function
> environment and not change it in the global environment? (For this
> function, I can just break down and accept that I will have different
> colors from this point on, but I?d like to know more generally; especially
> since it means that my `fixed` colors are not really fixed since they
> depend on the user?s setting of random sampling techniques, which I hadn?t
> considered before).
>
> All of the best,
> Elizabeth Purdom
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From epurdom @end|ng |rom @t@t@berke|ey@edu  Tue Apr 16 18:45:45 2019
From: epurdom @end|ng |rom @t@t@berke|ey@edu (Elizabeth Purdom)
Date: Tue, 16 Apr 2019 09:45:45 -0700
Subject: [R] Limiting the scope of RNGkind/set.seed
In-Reply-To: <CAGxFJbQ7Gq0_0yLpdx-aCYoWiW=SbjuPO+pq8ABJNnP8MpfFbA@mail.gmail.com>
References: <71BF8BB4-CD39-4FFD-8671-0F8DEFE9B088@stat.berkeley.edu>
 <CAGxFJbQ7Gq0_0yLpdx-aCYoWiW=SbjuPO+pq8ABJNnP8MpfFbA@mail.gmail.com>
Message-ID: <79BA8111-2BCC-4A1C-A8EA-812C539E2D4A@stat.berkeley.edu>

Hi Bert,
Thanks for your response. What you suggest is more or less the fix I suggested in my email (my second version of .rcolors). I writing more because I was wondering if there was a better way to work with RNG that would avoid doing that. It doesn?t feel very friendly for my package to be making changes to the user?s global environment, even though I am setting them back (and if it weren?t for the fact that setting the new R 3.6 argument `sample.kind=?Rounding?` creates a warning, I wouldn?t have even realized I was affecting the user?s settings, so it seems potentially hazardous that packages could be changing users settings without them being aware of it). So I was wondering if there was a way to more fully isolate the command. 
Thanks,
Elizabeth

> On Apr 16, 2019, at 9:36 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> I think I'm missing something. Why does something like this not do what you want:
> 
> > RNGkind()
> [1] "Mersenne-Twister" "Inversion"       
> > f <- function(){
> +    cur <- RNGkind(NULL)[1]
> +    RNGkind("Super-Duper")
> +    print(RNGkind())
> +    RNGkind(cur)
> + }
> > f()
> [1] "Super-Duper" "Inversion"  
> > RNGkind()
> [1] "Mersenne-Twister" "Inversion"
> 
> Cheers,
> Bert
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Tue, Apr 16, 2019 at 9:13 AM Elizabeth Purdom <epurdom at stat.berkeley.edu <mailto:epurdom at stat.berkeley.edu>> wrote:
> Hello,
> 
> I have a package, and inside of it I have a small function that selects a random palette of colors for graphing purposes. It?s a large number of colors, which is why I don?t manually select them, but I did want them to stay constant so I set the seed before doing so. So I had a little function in my package that does this:
> 
> .rcolors<-function(){
>         set.seed(23589)
>         x<-sample(colors()[-c(152:361)])
>         return(x)
> }
> massivePalette<-unique(c(bigPalette,.rcolors()))
> 
> Now that the sample function has been changed in R 3.6, I would need to use `sample.kind=?Rounding?` to get the same set of colors as I had previously. However, I don?t want to do that in my package, because that appears to change the global environment sampling:
> 
> > RNGkind()
> [1] "Mersenne-Twister" "Inversion"        "Rejection"       
> > RNGkind(sample.kind="Rejection")
> > x<-clusterExperiment:::.rcolors() #now I have changed the function so that sample.kind=?Rounding? ? I?ve suppressed the warnings
> > RNGkind()
> [1] "Mersenne-Twister" "Inversion"        "Rounding?  
> 
> So I could do something like this:
> 
> .rcolors<-function(){
>         currentRNG<-RNGkind()
>         suppressWarnings(RNGkind(sample.kind="Rounding"))
>         set.seed(23589)
>         x<-sample(colors()[-c(152:361)])
>         #set it back to default
>         suppressWarnings(RNGkind(sample.kind=currentRNG[3]))
>         return(x)
> }
> 
> But is there a way to change the random sampling in the function environment and not change it in the global environment? (For this function, I can just break down and accept that I will have different colors from this point on, but I?d like to know more generally; especially since it means that my `fixed` colors are not really fixed since they depend on the user?s setting of random sampling techniques, which I hadn?t considered before). 
> 
> All of the best,
> Elizabeth Purdom
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Apr 16 19:22:34 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 16 Apr 2019 19:22:34 +0200
Subject: [R] Limiting the scope of RNGkind/set.seed
In-Reply-To: <79BA8111-2BCC-4A1C-A8EA-812C539E2D4A@stat.berkeley.edu>
References: <71BF8BB4-CD39-4FFD-8671-0F8DEFE9B088@stat.berkeley.edu>
 <CAGxFJbQ7Gq0_0yLpdx-aCYoWiW=SbjuPO+pq8ABJNnP8MpfFbA@mail.gmail.com>
 <79BA8111-2BCC-4A1C-A8EA-812C539E2D4A@stat.berkeley.edu>
Message-ID: <23734.3930.10744.126501@stat.math.ethz.ch>

>>>>> Elizabeth Purdom 
>>>>>     on Tue, 16 Apr 2019 09:45:45 -0700 writes:

    > Hi Bert, Thanks for your response. What you suggest is
    > more or less the fix I suggested in my email (my second
    > version of .rcolors). I writing more because I was
    > wondering if there was a better way to work with RNG that
    > would avoid doing that. It doesn?t feel very friendly for
    > my package to be making changes to the user?s global
    > environment, even though I am setting them back (and if it
    > weren?t for the fact that setting the new R 3.6 argument
    > `sample.kind=?Rounding?` creates a warning, I wouldn?t
    > have even realized I was affecting the user?s settings, so
    > it seems potentially hazardous that packages could be
    > changing users settings without them being aware of
    > it). So I was wondering if there was a way to more fully
    > isolate the command.  Thanks, Elizabeth

Hi Elizabeth,

there's actually something better -- I think -- that you can do:

You store .Random.seed  before doing an RNGkind() & set.seed()
setting, do all that, and make sure that .Random.seed is
restored when leaving your function.

This works because the (typically quite long) .Random.seed
stores the full state of the RNG, i.e., all RNGkind() settings
*and* the result of set.seed() , calling r<foo>(n, ..)  etc.

If you additionally use  on.exit()  instead of manually reset
things, you have the additional advantage, that things are also
reset when your functions ends because the user interrupts its
computations, or an error happens, etc.

So, your function would more elegantly (and robustly!)  look like

.rcolors <- function(seed = 23589) {
    if(!exists(".Random.seed", envir = .GlobalEnv)) {
        message("calling runif(1)"); runif(1) }
    old.R.s <- .Random.seed
    ## will reset everything on exiting this function:
    on.exit(assign(".Random.seed", old.R.s, envir=.GlobalEnv))
    ## set seed for sample() "back compatibly":
    suppressWarnings(RNGversion("3.5.0"))
    set.seed(seed)
    ## return random permutation of "my colors"
    sample(colors()[-c(152:361)])
}

BTW, you can look at  simulate() methods in standard R, e.g.,

  stats:::simulate.lm

to see the same method use [optionally, with slightly more sophistication]


Best,
Martin

Martin M?chler
ETH Zurich, Switzerland


From e||@e625 @end|ng |rom bu@edu  Wed Apr 17 03:40:20 2019
From: e||@e625 @end|ng |rom bu@edu (Elise Lim)
Date: Tue, 16 Apr 2019 21:40:20 -0400
Subject: [R] variance estimation in coxme
Message-ID: <CAN+hiSrYGsK3s+LgH+Yy=Bfjc8T+E145RWkT4G4E4Ecw3-1fsw@mail.gmail.com>

Hello~

I'm fitting a random effects model using coxme and I was wondering how are
the variance components estimated? Are the fixed and random effects
estimated iteratively using Fisher scoring method?

I referred to the coxme manual but it didn't specify how the parameters are
estimated
(https://cran.r-project.org/web/packages/coxme/vignettes/coxme.pdf)

Thank you!!

-- 

Elise Lim
PhD Candidate in Biostatistics

Department of Biostatistics

Boston University School of Public Health
801 Massachusetts Avenue, 3rd floor,  336C

Boston, MA 02118

	[[alternative HTML version deleted]]


From r-p@ck@ge@ @end|ng |rom r-project@org  Wed Apr 17 10:59:56 2019
From: r-p@ck@ge@ @end|ng |rom r-project@org (mohammed ibrahim via R-packages)
Date: Wed, 17 Apr 2019 08:59:56 +0000 (UTC)
Subject: [R] [R-pkgs] dbparser v1.0.1: DrugBank XML Database Parser
References: <1898397232.797436.1555491596663.ref@mail.yahoo.com>
Message-ID: <1898397232.797436.1555491596663@mail.yahoo.com>

Hello,I am pleased to announce the release of dbparser v1.0.1 on CRAN https://cran.r-project.org/web/packages/dbparser/index.htmlThe new release include:? ? * Check if drugbank database exist before parsing? ? * Add support for international_brands and salts elements? ? * Properly rename some features to have clear names? ? * Reduce datasets size by getting unique rows only? ? * Support reading zip file containing DrugBank xml database? ? * Fix previous version CRAN Note? ? * Improve functions documentation? ? * Refactor unused functions? ? * Remove Count features from drug data set? ? * Fix several typos in documentation and code? ? * Fix consistency issue of CLASS of Data Frames Returned by dbparser
As always, contributions and bug reports are welcome on https://dainanahan.github.io/dbparser/index.html

Best Regards,Mohammed Ali
MSc in Applied Data Science & Big Data
mohammed.ali at edu.dsti.institute
+20 01000481973
eg.linkedin.com/in/mohammedali85
	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From m@k@hho||y @end|ng |rom gm@||@com  Wed Apr 17 19:19:48 2019
From: m@k@hho||y @end|ng |rom gm@||@com (greg holly)
Date: Wed, 17 Apr 2019 12:19:48 -0500
Subject: [R] Why I can not get work the "tidyverse" and "corrr" libraries
Message-ID: <CAM9Qe4jpO6ZtEBTRCS0h3xKk7PCKE73+V6NyGGHY=xG=j36jtg@mail.gmail.com>

;

I need work on libraries "tidyverse" and "corrr". When I cal these, I am
getting the following error message. What can be done? Your help is highly
appreciated.

Greg

Error: package or namespace load failed for ?tidyverse? in loadNamespace(i,
c(lib.loc, .libPaths()), versionCheck = vI[[i]]):
 namespace ?rlang? 0.3.0 is already loaded, but >= 0.3.1 is required
In addition: Warning message:
package ?tidyverse? was built under R version 3.5.3

	[[alternative HTML version deleted]]


From pg||bert902 @end|ng |rom gm@||@com  Wed Apr 17 19:38:17 2019
From: pg||bert902 @end|ng |rom gm@||@com (Paul Gilbert)
Date: Wed, 17 Apr 2019 13:38:17 -0400
Subject: [R] Limiting the scope of RNGkind/set.seed
Message-ID: <3a9b3b16-8ed4-dc79-c86f-60bc27303e7f@gmail.com>

Elizabeth

There is a package (of mine) setRNG on CRAN that may be a helpful 
example (code/tests/examples/vignette). Most of the package is testing 
designed to fail if the RNG in R is changed in a way that will affect my 
other package testing. Martin's function in the previous reply has most 
of the import parts and adds warning suppression, so you might want to 
consider small adjustments on a combination of the two. Just to 
summarize the issues, from memory:

0/ Using a preset default seed in a function's argument makes the 
function not random by default. If you are doing that then maybe you 
need to consider carefully whether the function should be using random 
number generation.

1/ It is good practice to use on.exit() in your function to reset 
things, so the state remains unaltered if your function fails.

2/ Saving the old seed does not work when it is unset, as it is by 
default in a new session, so you need to do something that insures it is 
set.

3/ You may need to save and reset not only the seed but also the RNG 
kind and the normal.kind, and possibly the kind for some other 
distributions. (setRNG does not handle other distributions.) It looks 
like you need to save and reset sample.kind.

4/ You should add the capability to pass all settings to your functions 
so that you can reproduce things when you want.

5/ I have found it useful to always pass back the settings in objects 
returned by functions like simulations. That way you always have a 
record when you discover something you want to reproduce.

6/ If parallel computing is considered then for reproducibility you need 
to save the number of nodes in the cluster. (I think this point is not 
as widely known as it should be.)

No doubt I have forgotten a few things.

Paul Gilbert

On 4/17/19 6:00 AM, r-help-request at r-project.org wrote:
 > Date: Tue, 16 Apr 2019 19:22:34 +0200
 > From: Martin Maechler<maechler at stat.math.ethz.ch>
 > To: Elizabeth Purdom<epurdom at stat.berkeley.edu>
 > Cc: Bert Gunter<bgunter.4567 at gmail.com>, R-help
 >     <r-help at r-project.org>
 > Subject: Re: [R] Limiting the scope of RNGkind/set.seed
 > Message-ID:<23734.3930.10744.126501 at stat.math.ethz.ch>
 > Content-Type: text/plain; charset="utf-8"
 >
 >>>>>> Elizabeth Purdom
 >>>>>>      on Tue, 16 Apr 2019 09:45:45 -0700 writes:
 >      > Hi Bert, Thanks for your response. What you suggest is
 >      > more or less the fix I suggested in my email (my second
 >      > version of .rcolors). I writing more because I was
 >      > wondering if there was a better way to work with RNG that
 >      > would avoid doing that. It doesn?t feel very friendly for
 >      > my package to be making changes to the user?s global
 >      > environment, even though I am setting them back (and if it
 >      > weren?t for the fact that setting the new R 3.6 argument
 >      > `sample.kind=?Rounding?` creates a warning, I wouldn?t
 >      > have even realized I was affecting the user?s settings, so
 >      > it seems potentially hazardous that packages could be
 >      > changing users settings without them being aware of
 >      > it). So I was wondering if there was a way to more fully
 >      > isolate the command.  Thanks, Elizabeth
 >
 > Hi Elizabeth,
 >
 > there's actually something better -- I think -- that you can do:
 >
 > You store .Random.seed  before doing an RNGkind() & set.seed()
 > setting, do all that, and make sure that .Random.seed is
 > restored when leaving your function.
 >
 > This works because the (typically quite long) .Random.seed
 > stores the full state of the RNG, i.e., all RNGkind() settings
 > *and*  the result of set.seed() , calling r<foo>(n, ..)  etc.
 >
 > If you additionally use  on.exit()  instead of manually reset
 > things, you have the additional advantage, that things are also
 > reset when your functions ends because the user interrupts its
 > computations, or an error happens, etc.
 >
 > So, your function would more elegantly (and robustly!)  look like
 >
 > .rcolors <- function(seed = 23589) {
 >      if(!exists(".Random.seed", envir = .GlobalEnv)) {
 >          message("calling runif(1)"); runif(1) }
 >      old.R.s <- .Random.seed
 >      ## will reset everything on exiting this function:
 >      on.exit(assign(".Random.seed", old.R.s, envir=.GlobalEnv))
 >      ## set seed for sample() "back compatibly":
 >      suppressWarnings(RNGversion("3.5.0"))
 >      set.seed(seed)
 >      ## return random permutation of "my colors"
 >      sample(colors()[-c(152:361)])
 > }
 >
 > BTW, you can look at  simulate() methods in standard R, e.g.,
 >
 >    stats:::simulate.lm
 >
 > to see the same method use [optionally, with slightly more 
sophistication]
 >
 >
 > Best,
 > Martin
 >
 > Martin M?chler
 > ETH Zurich, Switzerland


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Apr 17 20:06:33 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 17 Apr 2019 11:06:33 -0700
Subject: [R] 
 Why I can not get work the "tidyverse" and "corrr" libraries
In-Reply-To: <CAM9Qe4jpO6ZtEBTRCS0h3xKk7PCKE73+V6NyGGHY=xG=j36jtg@mail.gmail.com>
References: <CAM9Qe4jpO6ZtEBTRCS0h3xKk7PCKE73+V6NyGGHY=xG=j36jtg@mail.gmail.com>
Message-ID: <928AE54C-9A66-426A-A094-65D34C8B6C82@dcn.davis.ca.us>

From reading

> namespace ?rlang? 0.3.0 is already loaded, but >= 0.3.1 is required

it would seem that you need to upgrade your rlang package...

On April 17, 2019 10:19:48 AM PDT, greg holly <mak.hholly at gmail.com> wrote:
>;
>
>I need work on libraries "tidyverse" and "corrr". When I cal these, I
>am
>getting the following error message. What can be done? Your help is
>highly
>appreciated.
>
>Greg
>
>Error: package or namespace load failed for ?tidyverse? in
>loadNamespace(i,
>c(lib.loc, .libPaths()), versionCheck = vI[[i]]):
> namespace ?rlang? 0.3.0 is already loaded, but >= 0.3.1 is required
>In addition: Warning message:
>package ?tidyverse? was built under R version 3.5.3
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From h@w|ckh@m @end|ng |rom gm@||@com  Wed Apr 17 21:17:07 2019
From: h@w|ckh@m @end|ng |rom gm@||@com (Hadley Wickham)
Date: Wed, 17 Apr 2019 14:17:07 -0500
Subject: [R] 
 Why I can not get work the "tidyverse" and "corrr" libraries
In-Reply-To: <928AE54C-9A66-426A-A094-65D34C8B6C82@dcn.davis.ca.us>
References: <CAM9Qe4jpO6ZtEBTRCS0h3xKk7PCKE73+V6NyGGHY=xG=j36jtg@mail.gmail.com>
 <928AE54C-9A66-426A-A094-65D34C8B6C82@dcn.davis.ca.us>
Message-ID: <CABdHhvH6VfyT5Pm_zw0FEjWDLh7_wzMbO8_Q=0VQv9cO0GRdHw@mail.gmail.com>

On Wed, Apr 17, 2019 at 1:06 PM Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
> From reading
>
> > namespace ?rlang? 0.3.0 is already loaded, but >= 0.3.1 is required
>
> it would seem that you need to upgrade your rlang package...

Typically this indicates you need to restart R.

Hadley

-- 
http://hadley.nz


From epurdom @end|ng |rom @t@t@berke|ey@edu  Wed Apr 17 22:40:24 2019
From: epurdom @end|ng |rom @t@t@berke|ey@edu (Elizabeth Purdom)
Date: Wed, 17 Apr 2019 13:40:24 -0700
Subject: [R] Limiting the scope of RNGkind/set.seed
In-Reply-To: <23734.3930.10744.126501@stat.math.ethz.ch>
References: <71BF8BB4-CD39-4FFD-8671-0F8DEFE9B088@stat.berkeley.edu>
 <CAGxFJbQ7Gq0_0yLpdx-aCYoWiW=SbjuPO+pq8ABJNnP8MpfFbA@mail.gmail.com>
 <79BA8111-2BCC-4A1C-A8EA-812C539E2D4A@stat.berkeley.edu>
 <23734.3930.10744.126501@stat.math.ethz.ch>
Message-ID: <5316D251-AFAC-468A-B334-B246EAE211C6@stat.berkeley.edu>

Thanks Martin, this seems much better. All of the best, Elizabeth

> On Apr 16, 2019, at 10:22 AM, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> 
>>>>>> Elizabeth Purdom 
>>>>>>    on Tue, 16 Apr 2019 09:45:45 -0700 writes:
> 
>> Hi Bert, Thanks for your response. What you suggest is
>> more or less the fix I suggested in my email (my second
>> version of .rcolors). I writing more because I was
>> wondering if there was a better way to work with RNG that
>> would avoid doing that. It doesn?t feel very friendly for
>> my package to be making changes to the user?s global
>> environment, even though I am setting them back (and if it
>> weren?t for the fact that setting the new R 3.6 argument
>> `sample.kind=?Rounding?` creates a warning, I wouldn?t
>> have even realized I was affecting the user?s settings, so
>> it seems potentially hazardous that packages could be
>> changing users settings without them being aware of
>> it). So I was wondering if there was a way to more fully
>> isolate the command.  Thanks, Elizabeth
> 
> Hi Elizabeth,
> 
> there's actually something better -- I think -- that you can do:
> 
> You store .Random.seed  before doing an RNGkind() & set.seed()
> setting, do all that, and make sure that .Random.seed is
> restored when leaving your function.
> 
> This works because the (typically quite long) .Random.seed
> stores the full state of the RNG, i.e., all RNGkind() settings
> *and* the result of set.seed() , calling r<foo>(n, ..)  etc.
> 
> If you additionally use  on.exit()  instead of manually reset
> things, you have the additional advantage, that things are also
> reset when your functions ends because the user interrupts its
> computations, or an error happens, etc.
> 
> So, your function would more elegantly (and robustly!)  look like
> 
> .rcolors <- function(seed = 23589) {
>    if(!exists(".Random.seed", envir = .GlobalEnv)) {
>        message("calling runif(1)"); runif(1) }
>    old.R.s <- .Random.seed
>    ## will reset everything on exiting this function:
>    on.exit(assign(".Random.seed", old.R.s, envir=.GlobalEnv))
>    ## set seed for sample() "back compatibly":
>    suppressWarnings(RNGversion("3.5.0"))
>    set.seed(seed)
>    ## return random permutation of "my colors"
>    sample(colors()[-c(152:361)])
> }
> 
> BTW, you can look at  simulate() methods in standard R, e.g.,
> 
>  stats:::simulate.lm
> 
> to see the same method use [optionally, with slightly more sophistication]
> 
> 
> Best,
> Martin
> 
> Martin M?chler
> ETH Zurich, Switzerland


From j_j@zb@ @end|ng |rom y@hoo@com  Wed Apr 17 07:14:10 2019
From: j_j@zb@ @end|ng |rom y@hoo@com (jawad hussain)
Date: Wed, 17 Apr 2019 05:14:10 +0000 (UTC)
Subject: [R] Problem to find the Maximum likelihood estimates of generalized
 normal distribution in R
References: <1786116829.740273.1555478050830.ref@mail.yahoo.com>
Message-ID: <1786116829.740273.1555478050830@mail.yahoo.com>


First I estimated the parameters of exponentiated generalized normal distribution using the dataset (data1: generated from normal distribution). Then I used real dataset (data2) and tried to find the maximum likelihood estimates (MLE) using the AdequacyModel packages. It gives the error message (mentioned right below the code). 
Why does the same code estimate for first dataset (data1), but it doesn't estimate for the second dataset (data2)?
Is my way of plugging the baseline distribution (normal) in generalized class of distributions F(x)= [1-(1-G(x))^beta]^gamma introduced by Cordeiro et al.(2013) in R environment right? Am I defining the cdf and pdf of an generalized normal distribution in R in right way?

# First Problem

library(AdequacyModel)

data1 <- rnorm(100)

pdf_exps <- function(par,x){
beta = par[1]
gamma= par[2]
mean = par[3]
sd = par[4]
             ( beta*gamma* ((1-(1-(pnorm(x,mean,sd)))^beta)^(gamma-1)) * ((1-(pnorm(x,mean,sd)))^(beta-1)) ) * (dnorm(x,mean,sd)) 
}


cdf_exps <- function(par,x){
beta = par[1]
gamma= par[2]
mean = par[3]
sd = par[4]
( 1-(1-(pnorm(x,mean,sd)))^beta)^gamma 
}


set.seed(1)
result_1 = goodness.fit(pdf = pdf_exps, cdf = cdf_exps,
starts = c(1,1,1,1),data = data1  , method = "BFGS",
domain = c(-Inf,Inf), lim_inf = c(0,0,0,0),
lim_sup = c(2,2,2,2), S = 250, prop=0.1, N=50)
result_1$mle

 5.688120 4.413153 1.115777 1.996108

#----------------------------------------

data2 <-c( 20.56, 20.67, 21.86, 21.88, 18.96, 21.04, 21.69, 20.62, 22.64, 19.44, 25.75, 21.20,
  22.03, 25.44, 22.63, 21.86, 22.27, 21.27, 23.47, 23.19, 23.17, 24.54, 22.96, 19.76,
  23.36, 22.67, 24.24, 24.21, 20.46, 20.81, 20.17, 23.06, 24.40, 23.97, 22.62, 19.16,
  21.15, 21.40, 21.03, 21.77, 21.38, 21.47, 24.45, 22.63, 22.80, 23.58, 20.06, 23.01,
  24.64, 18.26, 24.47, 23.99, 26.24, 20.04, 25.72, 25.64, 19.87, 23.35, 22.42, 20.42,
  22.13, 25.17, 23.72, 21.28, 20.87, 19.00, 22.04, 20.12, 21.35, 28.57, 26.95, 28.13,
  26.85, 25.27, 31.93, 16.75, 19.54, 20.42, 22.76, 20.12, 22.35, 19.16, 20.77, 19.37,
  22.37, 17.54, 19.06, 20.30, 20.15, 25.36, 22.12, 21.25, 20.53, 17.06, 18.29, 18.37,
  18.93, 17.79, 17.05, 20.31, 22.46, 23.88, 23.68, 23.15, 22.32, 24.02, 23.29, 25.11,
 22.81, 26.25, 21.38, 22.52, 26.73, 23.57, 25.84, 24.06, 23.85, 25.09, 23.84, 25.31,
 19.69, 26.07, 25.50, 23.69, 26.79, 25.61, 25.06, 24.93, 22.96, 20.69, 23.97, 24.64,
 25.93, 23.69, 25.38, 22.68, 23.36, 22.44, 22.57, 19.81, 21.19, 20.39, 21.12, 21.89,
 29.97, 27.39, 23.11, 21.75, 20.89, 22.83, 22.02, 20.07, 20.15, 21.24, 19.63, 23.58,
 21.65, 25.17, 23.25, 32.52, 22.59, 30.18, 34.42, 21.86, 23.99, 24.81, 21.68, 21.04,
 23.12, 20.76, 23.13, 22.35, 22.28, 23.55, 19.85, 26.51, 24.78, 33.73, 30.18, 23.31,
 24.51, 25.37, 23.67, 24.28, 25.82, 21.93, 23.38, 23.07, 25.21, 23.25, 22.93, 26.86,
 21.26, 25.43, 24.54, 27.79, 23.58, 27.56, 23.76, 22.01, 22.34, 21.07)


set.seed(1)
result_2 = goodness.fit(pdf = pdf_exps, cdf = cdf_exps,
starts = c(1,1,1,1),data = data2  , method = "BFGS",
domain = c(-Inf,Inf), lim_inf = c(0,0,0,0),
lim_sup = c(2,2,2,2), S = 250, prop=0.1, N=50)
result_2$mle

Error in optim(par = starts, fn = likelihood, x = data, method = "BFGS",  : 
  non-finite finite-difference value [1]


JAWAD HUSSAIN ASHRAF


From dr@ke@go@@| @end|ng |rom gm@||@com  Thu Apr 18 01:24:13 2019
From: dr@ke@go@@| @end|ng |rom gm@||@com (Drake Gossi)
Date: Wed, 17 Apr 2019 16:24:13 -0700
Subject: [R] combining data.frames with is.na & match (), two questions
Message-ID: <CAPSTy5e_6-_p1OwVBN6WmKi6oju24PnEmaHBPvDh4B34c3AEkg@mail.gmail.com>

Hello everyone,

I'm working through this book, *Humanities Data in R* (Arnold & Tilton),
and I'm just having trouble understanding this maneuver.

In sum, I'm trying to combine data in two different data.frames.

This data.frame is called fruitNutr

Fruit  Calories
1 banana 100
2 pear 100
3 mango 200

And this data.frame is called fruitData

Fruit Color Shape Juice
1 apple red round 1
2 banana yellow oblong 0
3 pear green pear 0.5
4 orange orange round 1
5 kiwi green round 0

So, as you can see, these two data.frames overlap insofar as they both have
banana and pear. So, what happens next is the book suggests this:

fruitData$calories <- NA


As a result, I've created a new column for the fruitData data.frame:

Fruit Color Shape Juice Calories
1 apple red round 1            N/A
2 banana yellow oblong 0            N/A
3 pear green pear 0.5            N/A
4 orange orange round 1            N/A
5 kiwi green round 0            N/A

Then:

> index <- match (x=fruitData$Fruit, table=fruitNutr$Fruit)
> index
  [1]    NA       1       2      NA      NA
> is.na(index)
  [1]    TRUE   FALSE    FALSE   TRUE    TRUE
> fruitData$Calories [!is.na(index)] <- fruitNutr$Calories[index[!is.na
(index)]]
> fruitData

Fruit Color Shape Juice Calories
1 apple red round 1            N/A
2 banana yellow oblong 0 100
3 pear green pear 0.5 100
4 orange orange round 1            N/A
5 kiwi green round 0            N/A

I get what the first part means, that first part being this:
fruitData$Calories [!is.na(index)]
go into the fruitData data.frame, specifically into the calories column,
and only for what's true according to is.na(index). But I just literally
can't understand this last part.  fruitNutr$Calories[index[!is.na(index)]]

Two questions.


   1. I just literally don't understand how this code works. It does work,
   of course, but I don't know what it's doing, specifically this [index[!
   is.na(index)]] part. Could someone explain it to me like I'm five? I'm
   new at this...
   2. And then: is there any other way to combine these two data.frames so
   that we get this same result? maybe an easier to understand method?

That same result, again, is

Fruit Color Shape Juice Calories
1 apple red round 1            N/A
2 banana yellow oblong 0 100
3 pear green pear 0.5 100
4 orange orange round 1            N/A
5 kiwi green round 0            N/A


Drake

	[[alternative HTML version deleted]]


From bie@ve@idozom@ m@iii@g oii gm@ii@com  Thu Apr 18 09:04:17 2019
From: bie@ve@idozom@ m@iii@g oii gm@ii@com (bie@ve@idozom@ m@iii@g oii gm@ii@com)
Date: Thu, 18 Apr 2019 07:04:17 +0000 (UTC)
Subject: [R] Helping for approrpriate test
References: <396453529.2027623.1555571057099.ref@mail.yahoo.com>
Message-ID: <396453529.2027623.1555571057099@mail.yahoo.com>

Dear All,
I have in field and collect some data and i need your help for the appropriate test to analyze the data.
Indeed, i collected data from 200 farmers. From cluster analysis, i found four type or clusters of farmers. During the survey, i asked all the farmers to rank the different constraints from their activity from 1 to 4 (1= low importance and 4 = very important constraints). I would like to make a comparaison among these four clusters or groups to know if there is any difference between each cluster belong the differents constraints.?
There is four (4) groups of farmers and 16 constraints. All the 200 farmers ranked all the constraints.

Thanks,
Bienvenue
	[[alternative HTML version deleted]]


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Thu Apr 18 10:04:31 2019
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Thu, 18 Apr 2019 09:04:31 +0100
Subject: [R] combining data.frames with is.na & match (), two questions
In-Reply-To: <CAPSTy5e_6-_p1OwVBN6WmKi6oju24PnEmaHBPvDh4B34c3AEkg@mail.gmail.com>
References: <CAPSTy5e_6-_p1OwVBN6WmKi6oju24PnEmaHBPvDh4B34c3AEkg@mail.gmail.com>
Message-ID: <a77058c2-91a1-e6e8-2902-f583c1662438@dewey.myzen.co.uk>

Dear Drake

See in-line comments

On 18/04/2019 00:24, Drake Gossi wrote:
> Hello everyone,
> 
> I'm working through this book, *Humanities Data in R* (Arnold & Tilton),
> and I'm just having trouble understanding this maneuver.
> 
> In sum, I'm trying to combine data in two different data.frames.
> 
> This data.frame is called fruitNutr
> 
> Fruit  Calories
> 1 banana 100
> 2 pear 100
> 3 mango 200
> 
> And this data.frame is called fruitData
> 
> Fruit Color Shape Juice
> 1 apple red round 1
> 2 banana yellow oblong 0
> 3 pear green pear 0.5
> 4 orange orange round 1
> 5 kiwi green round 0
> 
> So, as you can see, these two data.frames overlap insofar as they both have
> banana and pear. So, what happens next is the book suggests this:
> 
> fruitData$calories <- NA
> 
> 
> As a result, I've created a new column for the fruitData data.frame:
> 
> Fruit Color Shape Juice Calories
> 1 apple red round 1            N/A
> 2 banana yellow oblong 0            N/A
> 3 pear green pear 0.5            N/A
> 4 orange orange round 1            N/A
> 5 kiwi green round 0            N/A
> 
> Then:
> 
>> index <- match (x=fruitData$Fruit, table=fruitNutr$Fruit)
>> index
>    [1]    NA       1       2      NA      NA
>> is.na(index)
>    [1]    TRUE   FALSE    FALSE   TRUE    TRUE
>> fruitData$Calories [!is.na(index)] <- fruitNutr$Calories[index[!is.na
> (index)]]
>> fruitData
> 
> Fruit Color Shape Juice Calories
> 1 apple red round 1            N/A
> 2 banana yellow oblong 0 100
> 3 pear green pear 0.5 100
> 4 orange orange round 1            N/A
> 5 kiwi green round 0            N/A
> 
> I get what the first part means, that first part being this:
> fruitData$Calories [!is.na(index)]
> go into the fruitData data.frame, specifically into the calories column,
> and only for what's true according to is.na(index). But I just literally
> can't understand this last part.  fruitNutr$Calories[index[!is.na(index)]]
> 
> Two questions.
> 
> 
>     1. I just literally don't understand how this code works. It does work,
>     of course, but I don't know what it's doing, specifically this [index[!
>     is.na(index)]] part. Could someone explain it to me like I'm five? I'm
>     new at this...

Decompose it from the inside out. So

!is.na(index)

gives you a vector the same length as index which is true if index has a 
value and false if it is NA

index[ something ]

gives you a vector of all the values of index corresponding to something 
being true (in this case). Note this vector may be shorter than 
something if that contains FALSE.

That should help you get started. My personal opinion is that it is much 
clearer with these things to do it in separate stages.

keep <= !is.na(index)
index[keep]

and check the value of keep if it seems to have gone wrong
>     2. And then: is there any other way to combine these two data.frames so
>     that we get this same result? maybe an easier to understand method?
> 
> That same result, again, is
> 
> Fruit Color Shape Juice Calories
> 1 apple red round 1            N/A
> 2 banana yellow oblong 0 100
> 3 pear green pear 0.5 100
> 4 orange orange round 1            N/A
> 5 kiwi green round 0            N/A
> 
> 
> Drake
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ---
> This email has been checked for viruses by AVG.
> https://www.avg.com
> 
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From pd@|gd @end|ng |rom gm@||@com  Thu Apr 18 10:29:52 2019
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Thu, 18 Apr 2019 10:29:52 +0200
Subject: [R] combining data.frames with is.na & match (), two questions
In-Reply-To: <CAPSTy5e_6-_p1OwVBN6WmKi6oju24PnEmaHBPvDh4B34c3AEkg@mail.gmail.com>
References: <CAPSTy5e_6-_p1OwVBN6WmKi6oju24PnEmaHBPvDh4B34c3AEkg@mail.gmail.com>
Message-ID: <CBC5580C-A8C1-4326-B325-705596CCB79C@gmail.com>

The whole thing is a merge operation, i.e.

> FruitNutr <- read.table(text="
+ Fruit  Calories
+ 1 banana 100
+ 2 pear 100
+ 3 mango 200
+ ")
> FruitData <- read.table(text="
+ Fruit Color Shape Juice
+ 1 apple red round 1
+ 2 banana yellow oblong 0
+ 3 pear green pear 0.5
+ 4 orange orange round 1
+ 5 kiwi green round 0
+ ")
> merge(FruitData, FruitNutr)
   Fruit  Color  Shape Juice Calories
1 banana yellow oblong   0.0      100
2   pear  green   pear   0.5      100
> merge(FruitData, FruitNutr, all.x=TRUE)
   Fruit  Color  Shape Juice Calories
1  apple    red  round   1.0       NA
2 banana yellow oblong   0.0      100
3   kiwi  green  round   0.0       NA
4 orange orange  round   1.0       NA
5   pear  green   pear   0.5      100

Mind you, merge() comes with its own set of confusing options in the more complex cases, which may be why the authors have chosen a more elementary approach.

-pd

> On 18 Apr 2019, at 01:24 , Drake Gossi <drake.gossi at gmail.com> wrote:
> 
> Hello everyone,
> 
> I'm working through this book, *Humanities Data in R* (Arnold & Tilton),
> and I'm just having trouble understanding this maneuver.
> 
> In sum, I'm trying to combine data in two different data.frames.
> 
> This data.frame is called fruitNutr
> 
> Fruit  Calories
> 1 banana 100
> 2 pear 100
> 3 mango 200
> 
> And this data.frame is called fruitData
> 
> Fruit Color Shape Juice
> 1 apple red round 1
> 2 banana yellow oblong 0
> 3 pear green pear 0.5
> 4 orange orange round 1
> 5 kiwi green round 0
> 
> So, as you can see, these two data.frames overlap insofar as they both have
> banana and pear. So, what happens next is the book suggests this:
> 
> fruitData$calories <- NA
> 
> 
> As a result, I've created a new column for the fruitData data.frame:
> 
> Fruit Color Shape Juice Calories
> 1 apple red round 1            N/A
> 2 banana yellow oblong 0            N/A
> 3 pear green pear 0.5            N/A
> 4 orange orange round 1            N/A
> 5 kiwi green round 0            N/A
> 
> Then:
> 
>> index <- match (x=fruitData$Fruit, table=fruitNutr$Fruit)
>> index
>  [1]    NA       1       2      NA      NA
>> is.na(index)
>  [1]    TRUE   FALSE    FALSE   TRUE    TRUE
>> fruitData$Calories [!is.na(index)] <- fruitNutr$Calories[index[!is.na
> (index)]]
>> fruitData
> 
> Fruit Color Shape Juice Calories
> 1 apple red round 1            N/A
> 2 banana yellow oblong 0 100
> 3 pear green pear 0.5 100
> 4 orange orange round 1            N/A
> 5 kiwi green round 0            N/A
> 
> I get what the first part means, that first part being this:
> fruitData$Calories [!is.na(index)]
> go into the fruitData data.frame, specifically into the calories column,
> and only for what's true according to is.na(index). But I just literally
> can't understand this last part.  fruitNutr$Calories[index[!is.na(index)]]
> 
> Two questions.
> 
> 
>   1. I just literally don't understand how this code works. It does work,
>   of course, but I don't know what it's doing, specifically this [index[!
>   is.na(index)]] part. Could someone explain it to me like I'm five? I'm
>   new at this...
>   2. And then: is there any other way to combine these two data.frames so
>   that we get this same result? maybe an easier to understand method?
> 
> That same result, again, is
> 
> Fruit Color Shape Juice Calories
> 1 apple red round 1            N/A
> 2 banana yellow oblong 0 100
> 3 pear green pear 0.5 100
> 4 orange orange round 1            N/A
> 5 kiwi green round 0            N/A
> 
> 
> Drake
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From petr@p|k@| @end|ng |rom prechez@@cz  Thu Apr 18 10:31:41 2019
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 18 Apr 2019 08:31:41 +0000
Subject: [R] combining data.frames with is.na & match (), two questions
In-Reply-To: <CAPSTy5e_6-_p1OwVBN6WmKi6oju24PnEmaHBPvDh4B34c3AEkg@mail.gmail.com>
References: <CAPSTy5e_6-_p1OwVBN6WmKi6oju24PnEmaHBPvDh4B34c3AEkg@mail.gmail.com>
Message-ID: <f3b067bd7b674f51ac3b6347e39af02d@SRVEXCHCM1301.precheza.cz>

Hi

I wonder why such combination is so complicated in your text book.

Having data frames fr1 and fr2

> dput(fr1)
structure(list(Fruit = structure(c(1L, 3L, 2L), .Label = c("banana",
"mango", "pear"), class = "factor"), Calories = c(100L, 100L,
200L)), class = "data.frame", row.names = c("1", "2", "3"))
> dput(fr2)
structure(list(Fruit = structure(c(1L, 2L, 5L, 4L, 3L), .Label = c("apple",
"banana", "kiwi", "orange", "pear"), class = "factor"), Color = structure(c(3L,
4L, 1L, 2L, 1L), .Label = c("green", "orange", "red", "yellow"
), class = "factor"), Shape = structure(c(3L, 1L, 2L, 3L, 3L), .Label = c("oblong",
"pear", "round"), class = "factor"), Juice = c(1, 0, 0.5, 1,
0)), class = "data.frame", row.names = c("1", "2", "3", "4",
"5"))
>

> fr1
   Fruit Calories
1 banana      100
2   pear      100
3  mango      200
>

you can use merge to combine those 2 data frames to get either all values from both

> merge(fr2, fr1, all=T)
   Fruit  Color  Shape Juice Calories
1  apple    red  round   1.0       NA
2 banana yellow oblong   0.0      100
3   kiwi  green  round   0.0       NA
4 orange orange  round   1.0       NA
5   pear  green   pear   0.5      100
6  mango   <NA>   <NA>    NA      200

just values from data frame with calories

> merge(fr2, fr1, all.y=T)
   Fruit  Color  Shape Juice Calories
1 banana yellow oblong   0.0      100
2   pear  green   pear   0.5      100
3  mango   <NA>   <NA>    NA      200

or just values from data frame with colours

> merge(fr2, fr1, all.x=T)
   Fruit  Color  Shape Juice Calories
1  apple    red  round   1.0       NA
2 banana yellow oblong   0.0      100
3   kiwi  green  round   0.0       NA
4 orange orange  round   1.0       NA
5   pear  green   pear   0.5      100

Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Drake Gossi
> Sent: Thursday, April 18, 2019 1:24 AM
> To: r-help at r-project.org
> Subject: [R] combining data.frames with is.na & match (), two questions
>
> Hello everyone,
>
> I'm working through this book, *Humanities Data in R* (Arnold & Tilton), and
> I'm just having trouble understanding this maneuver.
>
> In sum, I'm trying to combine data in two different data.frames.
>
> This data.frame is called fruitNutr
>
> Fruit  Calories
> 1 banana 100
> 2 pear 100
> 3 mango 200
>
> And this data.frame is called fruitData
>
> Fruit Color Shape Juice
> 1 apple red round 1
> 2 banana yellow oblong 0
> 3 pear green pear 0.5
> 4 orange orange round 1
> 5 kiwi green round 0
>
> So, as you can see, these two data.frames overlap insofar as they both have
> banana and pear. So, what happens next is the book suggests this:
>
> fruitData$calories <- NA
>
>
> As a result, I've created a new column for the fruitData data.frame:
>
> Fruit Color Shape Juice Calories
> 1 apple red round 1            N/A
> 2 banana yellow oblong 0            N/A
> 3 pear green pear 0.5            N/A
> 4 orange orange round 1            N/A
> 5 kiwi green round 0            N/A
>
> Then:
>
> > index <- match (x=fruitData$Fruit, table=fruitNutr$Fruit) index
>   [1]    NA       1       2      NA      NA
> > is.na(index)
>   [1]    TRUE   FALSE    FALSE   TRUE    TRUE
> > fruitData$Calories [!is.na(index)] <- fruitNutr$Calories[index[!is.na
> (index)]]
> > fruitData
>
> Fruit Color Shape Juice Calories
> 1 apple red round 1            N/A
> 2 banana yellow oblong 0 100
> 3 pear green pear 0.5 100
> 4 orange orange round 1            N/A
> 5 kiwi green round 0            N/A
>
> I get what the first part means, that first part being this:
> fruitData$Calories [!is.na(index)]
> go into the fruitData data.frame, specifically into the calories column, and only
> for what's true according to is.na(index). But I just literally can't understand
> this last part.  fruitNutr$Calories[index[!is.na(index)]]
>
> Two questions.
>
>
>    1. I just literally don't understand how this code works. It does work,
>    of course, but I don't know what it's doing, specifically this [index[!
>    is.na(index)]] part. Could someone explain it to me like I'm five? I'm
>    new at this...
>    2. And then: is there any other way to combine these two data.frames so
>    that we get this same result? maybe an easier to understand method?
>
> That same result, again, is
>
> Fruit Color Shape Juice Calories
> 1 apple red round 1            N/A
> 2 banana yellow oblong 0 100
> 3 pear green pear 0.5 100
> 4 orange orange round 1            N/A
> 5 kiwi green round 0            N/A
>
>
> Drake
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From |||o|orn@@ero @end|ng |rom hotm@||@com  Thu Apr 18 10:35:36 2019
From: |||o|orn@@ero @end|ng |rom hotm@||@com (Ilio Fornasero)
Date: Thu, 18 Apr 2019 08:35:36 +0000
Subject: [R] webscraping a multi-level website
Message-ID: <AM0PR04MB42908BC72497B9BEBD04C830B3260@AM0PR04MB4290.eurprd04.prod.outlook.com>

Hello.
I am trying to webscrape a website including some link from which I have to pick info.This is a thing going on since some day.

## Yet, I am getting the page and the urls I am interested in.
url <- "http://www.fao.org/countryprofiles/en/"
webscrape <- read_html(url)

urls <- webscrape %>%
  html_nodes(".linkcountry") %>%
  html_attr("href") %>%
  as.character()


## This is a chance to get the single links
urls <- paste0("http://www.fao.org", urls)



## Nevertheless, I prefere this option:
urls <- paste0("http://www.fao.org", urls_country <- data.frame(country=character(), country_url=character()))


## Then I loop to attain News

for (i in urls) {
  webscrape1 <- read_html(i)
  country <- webscrape1 %>%
    html_nodes(".#newsItems") %>%
    html_text() %>%
    as.character()

  country_url <- webscrape1 %>%
    html_nodes(".#newsItems") %>%
    html_attr("href") %>%
    as.character()

  temp_fao <- data.frame(country,country_url)

  urls_country <- rbind(urls_country,temp_fao)

  cat("*")
}



In any case, I get the following message:

Error in open.connection(x, "rb") :
  Could not resolve host: www.fao.orginteger(0)

Any hint?
Thanks in advance

	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Thu Apr 18 10:53:07 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 18 Apr 2019 11:53:07 +0300
Subject: [R] combining data.frames with is.na & match (), two questions
In-Reply-To: <f3b067bd7b674f51ac3b6347e39af02d@SRVEXCHCM1301.precheza.cz>
References: <CAPSTy5e_6-_p1OwVBN6WmKi6oju24PnEmaHBPvDh4B34c3AEkg@mail.gmail.com>
 <f3b067bd7b674f51ac3b6347e39af02d@SRVEXCHCM1301.precheza.cz>
Message-ID: <CAGgJW759FnAJtwYXSrTBLmL2Qx=5fr_Q_Kuh=eZBr3ubk+-HRg@mail.gmail.com>

Hi Drake,
Petr's suggestion to use the merge() function is good.
Another (possibly overkill) approach is to use functions from the dplyr
package, which is a fantastic package to get familiar with.
For example, the last alternative that Petr suggests is an example of what
is called a "left join" (meaning, when joining structures x and y,  keep
all the x rows, even if there is no corresponding row for y).
You can do this via dplyr as follows:

dplyr::left_join( fr2, fr1, by="Fruit")

HTH,
Eric


On Thu, Apr 18, 2019 at 11:40 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> I wonder why such combination is so complicated in your text book.
>
> Having data frames fr1 and fr2
>
> > dput(fr1)
> structure(list(Fruit = structure(c(1L, 3L, 2L), .Label = c("banana",
> "mango", "pear"), class = "factor"), Calories = c(100L, 100L,
> 200L)), class = "data.frame", row.names = c("1", "2", "3"))
> > dput(fr2)
> structure(list(Fruit = structure(c(1L, 2L, 5L, 4L, 3L), .Label = c("apple",
> "banana", "kiwi", "orange", "pear"), class = "factor"), Color =
> structure(c(3L,
> 4L, 1L, 2L, 1L), .Label = c("green", "orange", "red", "yellow"
> ), class = "factor"), Shape = structure(c(3L, 1L, 2L, 3L, 3L), .Label =
> c("oblong",
> "pear", "round"), class = "factor"), Juice = c(1, 0, 0.5, 1,
> 0)), class = "data.frame", row.names = c("1", "2", "3", "4",
> "5"))
> >
>
> > fr1
>    Fruit Calories
> 1 banana      100
> 2   pear      100
> 3  mango      200
> >
>
> you can use merge to combine those 2 data frames to get either all values
> from both
>
> > merge(fr2, fr1, all=T)
>    Fruit  Color  Shape Juice Calories
> 1  apple    red  round   1.0       NA
> 2 banana yellow oblong   0.0      100
> 3   kiwi  green  round   0.0       NA
> 4 orange orange  round   1.0       NA
> 5   pear  green   pear   0.5      100
> 6  mango   <NA>   <NA>    NA      200
>
> just values from data frame with calories
>
> > merge(fr2, fr1, all.y=T)
>    Fruit  Color  Shape Juice Calories
> 1 banana yellow oblong   0.0      100
> 2   pear  green   pear   0.5      100
> 3  mango   <NA>   <NA>    NA      200
>
> or just values from data frame with colours
>
> > merge(fr2, fr1, all.x=T)
>    Fruit  Color  Shape Juice Calories
> 1  apple    red  round   1.0       NA
> 2 banana yellow oblong   0.0      100
> 3   kiwi  green  round   0.0       NA
> 4 orange orange  round   1.0       NA
> 5   pear  green   pear   0.5      100
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Drake Gossi
> > Sent: Thursday, April 18, 2019 1:24 AM
> > To: r-help at r-project.org
> > Subject: [R] combining data.frames with is.na & match (), two questions
> >
> > Hello everyone,
> >
> > I'm working through this book, *Humanities Data in R* (Arnold & Tilton),
> and
> > I'm just having trouble understanding this maneuver.
> >
> > In sum, I'm trying to combine data in two different data.frames.
> >
> > This data.frame is called fruitNutr
> >
> > Fruit  Calories
> > 1 banana 100
> > 2 pear 100
> > 3 mango 200
> >
> > And this data.frame is called fruitData
> >
> > Fruit Color Shape Juice
> > 1 apple red round 1
> > 2 banana yellow oblong 0
> > 3 pear green pear 0.5
> > 4 orange orange round 1
> > 5 kiwi green round 0
> >
> > So, as you can see, these two data.frames overlap insofar as they both
> have
> > banana and pear. So, what happens next is the book suggests this:
> >
> > fruitData$calories <- NA
> >
> >
> > As a result, I've created a new column for the fruitData data.frame:
> >
> > Fruit Color Shape Juice Calories
> > 1 apple red round 1            N/A
> > 2 banana yellow oblong 0            N/A
> > 3 pear green pear 0.5            N/A
> > 4 orange orange round 1            N/A
> > 5 kiwi green round 0            N/A
> >
> > Then:
> >
> > > index <- match (x=fruitData$Fruit, table=fruitNutr$Fruit) index
> >   [1]    NA       1       2      NA      NA
> > > is.na(index)
> >   [1]    TRUE   FALSE    FALSE   TRUE    TRUE
> > > fruitData$Calories [!is.na(index)] <- fruitNutr$Calories[index[!is.na
> > (index)]]
> > > fruitData
> >
> > Fruit Color Shape Juice Calories
> > 1 apple red round 1            N/A
> > 2 banana yellow oblong 0 100
> > 3 pear green pear 0.5 100
> > 4 orange orange round 1            N/A
> > 5 kiwi green round 0            N/A
> >
> > I get what the first part means, that first part being this:
> > fruitData$Calories [!is.na(index)]
> > go into the fruitData data.frame, specifically into the calories column,
> and only
> > for what's true according to is.na(index). But I just literally can't
> understand
> > this last part.  fruitNutr$Calories[index[!is.na(index)]]
> >
> > Two questions.
> >
> >
> >    1. I just literally don't understand how this code works. It does
> work,
> >    of course, but I don't know what it's doing, specifically this
> [index[!
> >    is.na(index)]] part. Could someone explain it to me like I'm five?
> I'm
> >    new at this...
> >    2. And then: is there any other way to combine these two data.frames
> so
> >    that we get this same result? maybe an easier to understand method?
> >
> > That same result, again, is
> >
> > Fruit Color Shape Juice Calories
> > 1 apple red round 1            N/A
> > 2 banana yellow oblong 0 100
> > 3 pear green pear 0.5 100
> > 4 orange orange round 1            N/A
> > 5 kiwi green round 0            N/A
> >
> >
> > Drake
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch
> partner? PRECHEZA a.s. jsou zve?ejn?ny na:
> https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information
> about processing and protection of business partner?s personal data are
> available on website:
> https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en?
> odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any
> documents attached to it may be confidential and are subject to the legally
> binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From p_conno||y @end|ng |rom @||ng@hot@co@nz  Thu Apr 18 11:52:25 2019
From: p_conno||y @end|ng |rom @||ng@hot@co@nz (Patrick Connolly)
Date: Thu, 18 Apr 2019 21:52:25 +1200
Subject: [R] Debugging Rmarkdown
Message-ID: <20190418095225.GA4472@slingshot.co.nz>

I have a function that works in ESS, but it fails if I include it in
an .Rmd file that I tried to knit using Rstudio.  I found advice at:
https://www.rstudio.com/products/rstudio/release-notes/debugging-with-rstudio/

It seems to be not referring to markdown files.  Somewhere else
suggested calling render() in the console pane.  I tried that.  The
browser() function interrupts correctly, but I can't find out what the
object zzz in the code below looks like.  Nothing prints the way it
would in a "normal" R buffer.

code outline:  making zzz out of two dataframes xx and yy

## 
    zzz <- NULL
    for(i in xx$Sample){
        raw.i <- <stuff> 

        etc. etc.

        zzz <- rbind(zzz, wide.i)
}
   browser()  

    names(zzz) <- c("Cultivar", "Test", "Change")
That line fails, with a complaint about zzz being NULL.

It appears as though the rbind doesn't do anything, but I can't see
what wide.i looks like to get an idea what could be the cause.  

Ideas what I should try are welcome.  I have no idea why the code
works in an R environment but not an Rmd one.


R-3.5.2, 
platform       x86_64-pc-linux-gnu         
arch           x86_64                      
os             linux-gnu                   
system         x86_64, linux-gnu           

Rstudio Version 1.1.383



-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From @k@h@y_e4 @end|ng |rom hotm@||@com  Thu Apr 18 12:36:10 2019
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Thu, 18 Apr 2019 10:36:10 +0000
Subject: [R] picewise function in nls....
Message-ID: <SL2P216MB00917CB471C1477FC9B0FDCDC8260@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                            I have two predictors, x1 and x2, and one response variable, y. Moreover, a step function models the relationship between y and x1:

fx <-   (x1 <= -2)*(x1^2) + (x1 > -2 && x1 < 2)*(x1^3) + (x1 > = 2)*(x1^4)

Can I include fx in an nls call  to create something like this:

NLS1 <- nls(y ~ a*(sin(x2) + fx), start = list(a = 2))   ?

Will the above work? Or should I do something like this:

if(x1 <= -2) {

NLS2 <- nls(y[x1 <= -2] ~ a*(sin(x2[x1 <= -2]) + x1^2),start = list(a = 3))   }

if(x1 > -2 && x1 < 2)  {

NLS3 <- nls(y[x1 > -2 && x1 < 2] ~ a*(sin(x2[x1  > -2 && x1 < 2]) + x1^3),start = list(a = 4))   }

if(x1 > = 2) {

NLS4 <- nls(y[x1 >= 2] ~ a*(sin(x2[x1 >= 2]) + x1^4),start = list(a = 5))   }


If the first case doesn't work, is there any other method to include the step function in the nls call without resorting to the if statements?

Also, the coefficient, a , gotten from the above two cases are different. Will this affect the precision of the nonlinear fir between
y ~ (f(x1),f(x2)) ?


very many thanks for your time and effort
yours sincerely,

AKSHAY M KULKARNI

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Thu Apr 18 13:20:39 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Thu, 18 Apr 2019 14:20:39 +0300
Subject: [R] picewise function in nls....
In-Reply-To: <SL2P216MB00917CB471C1477FC9B0FDCDC8260@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00917CB471C1477FC9B0FDCDC8260@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <20190418142039.660f3ed1@trisector>

On Thu, 18 Apr 2019 10:36:10 +0000
akshay kulkarni <akshay_e4 at hotmail.com> wrote:

> fx <-   (x1 <= -2)*(x1^2) + (x1 > -2 && x1 < 2)*(x1^3) + (x1 > =
> 2)*(x1^4)
> 
> Can I include fx in an nls call  to create something like this:
> 
> NLS1 <- nls(y ~ a*(sin(x2) + fx), start = list(a = 2))   ?

For now, you can, since fx does not depend on any of the parameters you
optimize in the nls() call. (Actually, the model as presented should be
solveable by lm(y ~ I(sin(x2) + fx) + 0), since it is linear in its
only parameter.)

If you make fx a function and use ifelse() to provide different
outcomes depending on a condition in a vectorized fashion, you would
make it easier to add new parameters later, should the need arise:

fx <- function(x1, x2)
	ifelse(x1 <= -2, EXPR_IF_TRUE..., EXPR_IF_FALSE...)

NLS1 <- nls(y ~ a*(sin(x2) + fx(x1, x2)), ...)

-- 
Best regards,
Ivan


From th|erry@onke||nx @end|ng |rom |nbo@be  Thu Apr 18 14:13:24 2019
From: th|erry@onke||nx @end|ng |rom |nbo@be (Thierry Onkelinx)
Date: Thu, 18 Apr 2019 14:13:24 +0200
Subject: [R] Debugging Rmarkdown
In-Reply-To: <20190418095225.GA4472@slingshot.co.nz>
References: <20190418095225.GA4472@slingshot.co.nz>
Message-ID: <CAJuCY5y4EAw1-uSyz0JGP2D9N8b4dTgGuLwwfKn2QBzyzRRkzg@mail.gmail.com>

Dear Patrick,

This is not easy to debug without a reprex

I would check the content of zzz and wide.i in the loop

str(wide.i)
 zzz <- rbind(zzz, wide.i)
str(zzz)

Note that the Rmd always runs in a clean environment. This might explain
the difference

Best regards,

ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>


Op do 18 apr. 2019 om 11:53 schreef Patrick Connolly <
p_connolly at slingshot.co.nz>:

> I have a function that works in ESS, but it fails if I include it in
> an .Rmd file that I tried to knit using Rstudio.  I found advice at:
>
> https://www.rstudio.com/products/rstudio/release-notes/debugging-with-rstudio/
>
> It seems to be not referring to markdown files.  Somewhere else
> suggested calling render() in the console pane.  I tried that.  The
> browser() function interrupts correctly, but I can't find out what the
> object zzz in the code below looks like.  Nothing prints the way it
> would in a "normal" R buffer.
>
> code outline:  making zzz out of two dataframes xx and yy
>
> ##
>     zzz <- NULL
>     for(i in xx$Sample){
>         raw.i <- <stuff>
>
>         etc. etc.
>
>         zzz <- rbind(zzz, wide.i)
> }
>    browser()
>
>     names(zzz) <- c("Cultivar", "Test", "Change")
> That line fails, with a complaint about zzz being NULL.
>
> It appears as though the rbind doesn't do anything, but I can't see
> what wide.i looks like to get an idea what could be the cause.
>
> Ideas what I should try are welcome.  I have no idea why the code
> works in an R environment but not an Rmd one.
>
>
> R-3.5.2,
> platform       x86_64-pc-linux-gnu
> arch           x86_64
> os             linux-gnu
> system         x86_64, linux-gnu
>
> Rstudio Version 1.1.383
>
>
>
> --
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>    ___    Patrick Connolly
>  {~._.~}                   Great minds discuss ideas
>  _( Y )_                 Average minds discuss events
> (:_~*~_:)                  Small minds discuss people
>  (_)-(_)                              ..... Eleanor Roosevelt
>
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From B|||@Po||ng @end|ng |rom ze||@@com  Thu Apr 18 14:39:02 2019
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Thu, 18 Apr 2019 12:39:02 +0000
Subject: [R] Help with a setting some values of a df vector to 0 but not all
 values
Message-ID: <BN7PR02MB5073DF0401D32B8C2507D572EA260@BN7PR02MB5073.namprd02.prod.outlook.com>

Good morning.

#RStudio Version 1.1.456
sessionInfo()
#R version 3.5.3 (2019-03-11)
#Platform: x86_64-w64-mingw32/x64 (64-bit)
#Running under: Windows >= 8 x64 (build 9200)

I have a df column that looks like the below.

#68 ID's including the 0 value

I want to set all the values to 0 with the exception of 5 which are c(1565, 1569, 1674, 415, 1564))

I realize its basic but the routine eludes me, I have googled and there are plenty of
urls for setting to NA, etc.. but nothing I found, yet, where it is a subset routine excluding a few values.

I expect the routine would be something like --

set df1$ClaimManagerID = 0 where df$ClaimManagerID NOT IN c(1565,1569,1674,415,1564)

str(df$ClaimManagerID)
 int [1:18015] 1558 0 1565 1565 1565 1565 1565 0 1565 1565 ...

|ClaimManagerID |       cnt|       pct|   cum_pct|
|:--------------           |--------:|--------       -:|--------       -:|
|1565                      | 11412| 0.6334721| 0.6334721|
|0                            |  6120| 0.3397169| 0.9731890|
|1569                     |    162| 0.0089925| 0.9821815|
|1674                     |      25| 0.0013877| 0.9835692|
|415                       |      21| 0.0011657| 0.9847349|
|1564                     |      20| 0.0011102| 0.9858451|
|234                       |      19| 0.0010547| 0.9868998|
|521                       |      17| 0.0009437| 0.9878435|

etc....= 68 ID's

Thank you for any help.

WHP



Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}


From er|cjberger @end|ng |rom gm@||@com  Thu Apr 18 14:46:40 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 18 Apr 2019 15:46:40 +0300
Subject: [R] 
 Help with a setting some values of a df vector to 0 but not all
 values
In-Reply-To: <BN7PR02MB5073DF0401D32B8C2507D572EA260@BN7PR02MB5073.namprd02.prod.outlook.com>
References: <BN7PR02MB5073DF0401D32B8C2507D572EA260@BN7PR02MB5073.namprd02.prod.outlook.com>
Message-ID: <CAGgJW76DJ3SChYzqLvFOxTCgvBr19hcnCawZ+80XFHea6bC3Hw@mail.gmail.com>

df$ClaimManagerID[ !(df$ClaimManagerID %in% c(1565,1569,1674,415,1564))] <-
0


On Thu, Apr 18, 2019 at 3:39 PM Bill Poling <Bill.Poling at zelis.com> wrote:

> Good morning.
>
> #RStudio Version 1.1.456
> sessionInfo()
> #R version 3.5.3 (2019-03-11)
> #Platform: x86_64-w64-mingw32/x64 (64-bit)
> #Running under: Windows >= 8 x64 (build 9200)
>
> I have a df column that looks like the below.
>
> #68 ID's including the 0 value
>
> I want to set all the values to 0 with the exception of 5 which are
> c(1565, 1569, 1674, 415, 1564))
>
> I realize its basic but the routine eludes me, I have googled and there
> are plenty of
> urls for setting to NA, etc.. but nothing I found, yet, where it is a
> subset routine excluding a few values.
>
> I expect the routine would be something like --
>
> set df1$ClaimManagerID = 0 where df$ClaimManagerID NOT IN
> c(1565,1569,1674,415,1564)
>
> str(df$ClaimManagerID)
>  int [1:18015] 1558 0 1565 1565 1565 1565 1565 0 1565 1565 ...
>
> |ClaimManagerID |       cnt|       pct|   cum_pct|
> |:--------------           |--------:|--------       -:|--------       -:|
> |1565                      | 11412| 0.6334721| 0.6334721|
> |0                            |  6120| 0.3397169| 0.9731890|
> |1569                     |    162| 0.0089925| 0.9821815|
> |1674                     |      25| 0.0013877| 0.9835692|
> |415                       |      21| 0.0011657| 0.9847349|
> |1564                     |      20| 0.0011102| 0.9858451|
> |234                       |      19| 0.0010547| 0.9868998|
> |521                       |      17| 0.0009437| 0.9878435|
>
> etc....= 68 ID's
>
> Thank you for any help.
>
> WHP
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From B|||@Po||ng @end|ng |rom ze||@@com  Thu Apr 18 14:52:37 2019
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Thu, 18 Apr 2019 12:52:37 +0000
Subject: [R] 
 Help with a setting some values of a df vector to 0 but not all
 values
In-Reply-To: <CAGgJW76DJ3SChYzqLvFOxTCgvBr19hcnCawZ+80XFHea6bC3Hw@mail.gmail.com>
References: <BN7PR02MB5073DF0401D32B8C2507D572EA260@BN7PR02MB5073.namprd02.prod.outlook.com>
 <CAGgJW76DJ3SChYzqLvFOxTCgvBr19hcnCawZ+80XFHea6bC3Hw@mail.gmail.com>
Message-ID: <BN7PR02MB507351318DDCE9072C70E36BEA260@BN7PR02MB5073.namprd02.prod.outlook.com>

Yes, thank you Eric, that's got it, sheesh, I knew it was simple.

Many thanks.

WHP

From: Eric Berger <ericjberger at gmail.com>
Sent: Thursday, April 18, 2019 8:47 AM
To: Bill Poling <Bill.Poling at zelis.com>
Cc: r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help with a setting some values of a df vector to 0 but not all values

df$ClaimManagerID[ !(df$ClaimManagerID %in% c(1565,1569,1674,415,1564))] <- 0


On Thu, Apr 18, 2019 at 3:39 PM Bill Poling <mailto:Bill.Poling at zelis.com> wrote:
Good morning.

#RStudio Version 1.1.456
sessionInfo()
#R version 3.5.3 (2019-03-11)
#Platform: x86_64-w64-mingw32/x64 (64-bit)
#Running under: Windows >= 8 x64 (build 9200)

I have a df column that looks like the below.

#68 ID's including the 0 value

I want to set all the values to 0 with the exception of 5 which are c(1565, 1569, 1674, 415, 1564))

I realize its basic but the routine eludes me, I have googled and there are plenty of
urls for setting to NA, etc.. but nothing I found, yet, where it is a subset routine excluding a few values.

I expect the routine would be something like --

set df1$ClaimManagerID = 0 where df$ClaimManagerID NOT IN c(1565,1569,1674,415,1564)

str(df$ClaimManagerID)
 int [1:18015] 1558 0 1565 1565 1565 1565 1565 0 1565 1565 ...

|ClaimManagerID |       cnt|       pct|   cum_pct|
|:--------------           |--------:|--------       -:|--------       -:|
|1565                      | 11412| 0.6334721| 0.6334721|
|0                            |  6120| 0.3397169| 0.9731890|
|1569                     |    162| 0.0089925| 0.9821815|
|1674                     |      25| 0.0013877| 0.9835692|
|415                       |      21| 0.0011657| 0.9847349|
|1564                     |      20| 0.0011102| 0.9858451|
|234                       |      19| 0.0010547| 0.9868998|
|521                       |      17| 0.0009437| 0.9878435|

etc....= 68 ID's

Thank you for any help.

WHP



Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}

______________________________________________
mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

From petr@p|k@| @end|ng |rom prechez@@cz  Thu Apr 18 14:54:29 2019
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Thu, 18 Apr 2019 12:54:29 +0000
Subject: [R] 
 Help with a setting some values of a df vector to 0 but not all
 values
In-Reply-To: <BN7PR02MB5073DF0401D32B8C2507D572EA260@BN7PR02MB5073.namprd02.prod.outlook.com>
References: <BN7PR02MB5073DF0401D32B8C2507D572EA260@BN7PR02MB5073.namprd02.prod.outlook.com>
Message-ID: <8ba4c3a9597145308e6d1fa359f06918@SRVEXCHCM1301.precheza.cz>

Hi

seems to me simple

Sample data
> nozero <- c(1565, 1569, 1674, 415, 1564)
> test <- sample(c(1:10, nozero), 250, replace=T)
> test
  [1]   10    2    6    4  415    5    9 1565 1569    2   10 1569  415 1569    3
 [16]    4    9   10    1    1    5   10    1    3   10    9 1564    4   10    8
 [31]    6 1674   10    2    9  415 1674    4 1674 1569    6    6 1565    6    5
...

change all except nozero to zero

> test[!test %in% nozero] <- 0
> test
  [1]    0    0    0    0  415    0    0 1565 1569    0    0 1569  415 1569    0
 [16]    0    0    0    0    0    0    0    0    0    0    0 1564    0    0    0
 [31]    0 1674    0    0    0  415 1674    0 1674 1569    0    0 1565    0    0
...

Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Bill Poling
> Sent: Thursday, April 18, 2019 2:39 PM
> To: r-help (r-help at r-project.org) <r-help at r-project.org>
> Subject: [R] Help with a setting some values of a df vector to 0 but not all
> values
>
> Good morning.
>
> #RStudio Version 1.1.456
> sessionInfo()
> #R version 3.5.3 (2019-03-11)
> #Platform: x86_64-w64-mingw32/x64 (64-bit) #Running under: Windows >= 8
> x64 (build 9200)
>
> I have a df column that looks like the below.
>
> #68 ID's including the 0 value
>
> I want to set all the values to 0 with the exception of 5 which are c(1565, 1569,
> 1674, 415, 1564))
>
> I realize its basic but the routine eludes me, I have googled and there are
> plenty of urls for setting to NA, etc.. but nothing I found, yet, where it is a
> subset routine excluding a few values.
>
> I expect the routine would be something like --
>
> set df1$ClaimManagerID = 0 where df$ClaimManagerID NOT IN
> c(1565,1569,1674,415,1564)
>
> str(df$ClaimManagerID)
>  int [1:18015] 1558 0 1565 1565 1565 1565 1565 0 1565 1565 ...
>
> |ClaimManagerID |       cnt|       pct|   cum_pct|
> |:--------------           |--------:|--------       -:|--------       -:|
> |1565                      | 11412| 0.6334721| 0.6334721|
> |0                            |  6120| 0.3397169| 0.9731890|
> |1569                     |    162| 0.0089925| 0.9821815|
> |1674                     |      25| 0.0013877| 0.9835692|
> |415                       |      21| 0.0011657| 0.9847349|
> |1564                     |      20| 0.0011102| 0.9858451|
> |234                       |      19| 0.0010547| 0.9868998|
> |521                       |      17| 0.0009437| 0.9878435|
>
> etc....= 68 ID's
>
> Thank you for any help.
>
> WHP
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From c@t@||nro|bu @end|ng |rom gm@||@com  Thu Apr 18 14:57:10 2019
From: c@t@||nro|bu @end|ng |rom gm@||@com (Catalin Roibu)
Date: Thu, 18 Apr 2019 15:57:10 +0300
Subject: [R] (no subject)
Message-ID: <CAEW+BD+fh2H+7G30SUXgL0Q-2z_HN1w5-S2P2FtV2FRrsY2Nfg@mail.gmail.com>

Dear R users,

I want to compute a nlm for each plot an species and after that to save the
regression coef for each species and plot.
Thanks for your help!

I tried something like this

s<-data.frame(unique(ah$sp))
pl<-data.frame(unique(ah$plot))
z<-data.frame(matrix(nrow=0, ncol=5))

for(i in 1:nrow(pl)){
  t1<-filter(ah, plot==pl[i,1])
  for(j in 1:nrow(s)){
    if (t1$sp==s[j,1]) {
      fo<-h~a+b*log(dbh)+c*(log(dbh))^2+1.3
      st1<-expand.grid(a = seq(-100, 100, len = 4),b = seq(-100, 100, len =
4), c = seq(-1, 1, len = 4))
      mo<-nls2(fo, data=t1,start =st1, control = nls.control(warnOnly =
TRUE))
      sumh<-summary(mo)
} else {
  NA
}
    A<-data.frame(t(coef(mo)))
    A$sp<-rep(s[j,1], nrow(A))
    A$plot<-rep(pl[i,1], nrow(A))
    z<-rbind(z, A)
    plotfit(mo, smooth = TRUE)
  }
}

My data is: ah

plot no sp dbh h
Sinca 1 Br 47.25 42
Sinca 2 Br 17 12.1
Sinca 3 Br 7.5 5.7
Sinca 6 Br 19.25 17.9
Sinca 7 Br 16 12.5
Sinca 9 Br 20.75 15.7
Sinca 11 Br 24.25 23.8
Sinca 12 Br 6 4.6
Sinca 4 Fa 66.5 42.2
Sinca 10 Fa 80 37.3
Sinca 14 Fa 87.75 43.2
Sinca 15 Fa 11.25 9.2
Sinca 18 Fa 12.75 9.5
Sinca 20 Fa 13.25 13.9
Sinca 24 Fa 96 45.3
budeni 1 Fa 92 36.6
budeni 2 Fa 69 28.5
budeni 3 Fa 58.75 29.7
budeni 4 Fa 16.75 11.6
budeni 5 Fa 42.5 35.9
budeni 6 Fa 58.5 40.8
budeni 8 Fa 4 6.9
Ceahlau 215 Mo 33.5 21.9
Ceahlau 216 Mo 32 22.7
Ceahlau 217 Mo 29.5 18.7
Ceahlau 218 Mo 36.5 20.3
Ceahlau 220 Mo 43.5 21.6
Ceahlau 221 Mo 29 18
Ceahlau 222 Mo 25 20
Ceahlau 223 Mo 25 16.4
Ceahlau 224 Mo 35 20.1

-- 

-
-
Catalin-Constantin ROIBU
Lecturer PhD, Forestry engineer
Forestry Faculty of Suceava
Str. Universitatii no. 13, Suceava, 720229, Romania
office phone      +4 0230 52 29 78, ext. 531
mobile phone    +4 0745 53 18 01
FAX:                +4 0230 52 16 64
silvic.usv.ro <http://www.usv.ro/>


[image: Mailtrack]
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
Sender
notified by
Mailtrack
<https://mailtrack.io?utm_source=gmail&utm_medium=signature&utm_campaign=signaturevirality5&>
18.04.19,
15:56:09

	[[alternative HTML version deleted]]


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Apr 18 16:10:41 2019
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 18 Apr 2019 16:10:41 +0200
Subject: [R] Pause script at input from terminal (interactive use)
Message-ID: <CAMk+s2TaC0mXOs_s2NFWsRxj0g_sxomRbaaU4N0ZoDTmSfiVtg@mail.gmail.com>

Dear all,
I am trying to write an interactive script where the user type some
input from the terminal. I used readline() but when I launch the file
with Rscript, the function is overwritten directly, there is no
waiting for the user's input. For instance, this example:

VAR1 = as.numeric(readline(prompt = "Enter something -> "))
VAR2 = as.numeric(readline(prompt = "Enter something else -> "))
if(is.na(VAR1)) VAR1 = 0
if(is.na(VAR2)) VAR2 = "empty"
cat("Input was: ", VAR1, " - ", VAR2, "\n")

is executed till the end without typing anything on terminal :

$ Rscript test.R
Enter something ->
Enter something else ->
Input was:  0  -  empty

I also tried with ',1' at the end of readline, but the effect is the
same. I should use the interactive() function but I am confused on its
use.
It is possible to launch R scritps in the interactive mode in the
first place? and if yes, how? Or would python or julia be better
choices in this case?
Thank you.
-- 
Best regards,
Luigi


From gumb|ex @end|ng |rom @o@c@|o  Wed Apr 17 08:26:43 2019
From: gumb|ex @end|ng |rom @o@c@|o (Dingyuan Wang)
Date: Wed, 17 Apr 2019 14:26:43 +0800
Subject: [R] lm fails on some large input
Message-ID: <836dfcbe-d2e5-7b96-86aa-a1e33b6db966@aosc.io>

Hi,

This input doesn't have any interesting properties except y is unix 
time. Spreadsheets can do this well.
Is this a bug that lm can't do x ~ y?

R version 3.5.2 (2018-12-20) -- "Eggshell Igloo"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

 > x = c(79.744, 123.904, 87.29601, 116.352, 67.71201, 72.96001, 
101.632, 108.928, 94.08)
 > y = c(1506705739.385, 1506705766.895, 1506705746.293, 1506705761.873, 
1506705734.743, 1506705735.351, 1506705756.26, 1506705761.307, 
1506705747.372)
 > m = lm(x ~ y)
 > summary(m)

Call:
lm(formula = x ~ y)

Residuals:
      Min       1Q   Median       3Q      Max
-27.0222 -14.9902  -0.6542  14.1938  29.1698

Coefficients: (1 not defined because of singularities)
             Estimate Std. Error t value Pr(>|t|)
(Intercept)   94.734      6.511   14.55 4.88e-07 ***
y                 NA         NA      NA       NA
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 19.53 on 8 degrees of freedom

 > summary(lm(y ~ x))

Call:
lm(formula = y ~ x)

Residuals:
     Min      1Q  Median      3Q     Max
-2.1687 -1.3345 -0.9466  1.3826  2.6551

Coefficients:
              Estimate Std. Error   t value Pr(>|t|)
(Intercept) 1.507e+09  3.294e+00 4.574e+08  < 2e-16 ***
x           6.136e-01  3.413e-02 1.798e+01 4.07e-07 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 1.885 on 7 degrees of freedom
Multiple R-squared:  0.9788,	Adjusted R-squared:  0.9758
F-statistic: 323.3 on 1 and 7 DF,  p-value: 4.068e-07


From @j@ykum@rcp @end|ng |rom gm@||@com  Wed Apr 17 16:30:31 2019
From: @j@ykum@rcp @end|ng |rom gm@||@com (ajaykumar cp)
Date: Wed, 17 Apr 2019 20:00:31 +0530
Subject: [R] Is it possible to calculate in r the number of days and count
 of b in var r from the following table:
In-Reply-To: <CABRiLjYmD7wqNkWVqVCawvV_3C9CxoJ1841HbhDcscOndgm8Qw@mail.gmail.com>
References: <CABRiLjZ0MjZLYTXKcLRErmAhG9DS3pZ3AKuR74CCmigGaXSfGw@mail.gmail.com>
 <CABRiLjYmD7wqNkWVqVCawvV_3C9CxoJ1841HbhDcscOndgm8Qw@mail.gmail.com>
Message-ID: <CABRiLjYoWxXoA7UkyFx5gSYE48EXY_R+Fsi9Y9i5Z2VigaZjCA@mail.gmail.com>

Hello

Is it possible to calculate in r the number of days and count of b in var r
from the following table:


id r s t u
1 a 100 1 27-06-2017
1 a 200 0 29-06-2017
1 b 300 0 01-07-2017
2 a 500 1 12-06-2017
3 b 100 0 02-07-2017
3 a 600 1 02-07-2017
4 a 200 0 12-06-2017
4 a 300 1 15-06-2017
4 b 200 0 18-06-2017
4 a 100 0 01-07-2017
5 a 200 0 04-06-2017

grouped by unique ID where the condition = when r = b, sum of s >= sum of s
when t = 1?

https://stackoverflow.com/q/55724900/11373077 for the discussions

Thank you in advance


-- 
C P Ajaykumar

	[[alternative HTML version deleted]]


From g@@@uu| @end|ng |rom gm@||@com  Thu Apr 18 07:44:33 2019
From: g@@@uu| @end|ng |rom gm@||@com (ani jaya)
Date: Thu, 18 Apr 2019 14:44:33 +0900
Subject: [R] Looping with looping
Message-ID: <CAHXS41w+=pbxPS9maMiqN4_hAv54MVLYfV+c=+jrfo2yNpAFSA@mail.gmail.com>

Dear R community,

I'm trying to create a looping to see the effect of number of samples from
one dataset.
Lets say I have 10 values in a single data frame and I want to see the mean
of each sampling let say from 2-9 number of sampling. But I want to do the
repetition let say up to 100 for each number of sampling and put it in a
different dataframe, let say a2,a3,a4,... which contain a2[1] is the mean
of first repetition and so on. I believe this is possible but I'm newbie
here.

> version

platform       x86_64-w64-mingw32
arch           x86_64
os             mingw32
system         x86_64, mingw32
status
major          3
minor          5.3
year           2019
month          03
day            11
svn rev        76217
language       R
version.string R version 3.5.3 (2019-03-11)
nickname       Great Truth


 The simple code that I have:

sam<-c(9,7,8,6,6,7,8,6,7,3)
for (k in seq(2,9,1)){
    a <- numeric(100)
      for (i in 1:100){
      a[i] <- mean(sample(sam,k,replace=T))

      }
  }

I can do enough with this code but i want to the variable name also
move based on k.

I have googling enough and meet assign and paste command but not really help.
Any help would be appreciate.



Best,

Saat M.

	[[alternative HTML version deleted]]


From @dmu|doon @end|ng |rom em@||@wm@edu  Thu Apr 18 14:19:57 2019
From: @dmu|doon @end|ng |rom em@||@wm@edu (Stephen Muldoon)
Date: Thu, 18 Apr 2019 08:19:57 -0400
Subject: [R] R 3.4.4 is released
Message-ID: <817ABAF4-92B2-461B-A361-7CD2350E0C61@email.wm.edu>

Hi,

I am new to R studio. If my R studio continually asks to restart for new packages to run, should I remove R studio and reinstall this latest version?

Thanks,
Stephen

From ||@t@ @end|ng |rom dewey@myzen@co@uk  Thu Apr 18 17:24:41 2019
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Thu, 18 Apr 2019 16:24:41 +0100
Subject: [R] lm fails on some large input
In-Reply-To: <836dfcbe-d2e5-7b96-86aa-a1e33b6db966@aosc.io>
References: <836dfcbe-d2e5-7b96-86aa-a1e33b6db966@aosc.io>
Message-ID: <bef865ce-3f89-24d0-18b7-6653cdd59449@dewey.myzen.co.uk>

Perhaps subtract 1506705766 from y?

Saying some other software does it well implies you know what the 
_correct_ answer is here but I would question what that means with this 
sort of data-set.

On 17/04/2019 07:26, Dingyuan Wang wrote:
> Hi,
> 
> This input doesn't have any interesting properties except y is unix 
> time. Spreadsheets can do this well.
> Is this a bug that lm can't do x ~ y?
> 
> R version 3.5.2 (2018-12-20) -- "Eggshell Igloo"
> Copyright (C) 2018 The R Foundation for Statistical Computing
> Platform: x86_64-pc-linux-gnu (64-bit)
> 
>  > x = c(79.744, 123.904, 87.29601, 116.352, 67.71201, 72.96001, 
> 101.632, 108.928, 94.08)
>  > y = c(1506705739.385, 1506705766.895, 1506705746.293, 1506705761.873, 
> 1506705734.743, 1506705735.351, 1506705756.26, 1506705761.307, 
> 1506705747.372)
>  > m = lm(x ~ y)
>  > summary(m)
> 
> Call:
> lm(formula = x ~ y)
> 
> Residuals:
>  ???? Min?????? 1Q?? Median?????? 3Q????? Max
> -27.0222 -14.9902? -0.6542? 14.1938? 29.1698
> 
> Coefficients: (1 not defined because of singularities)
>  ??????????? Estimate Std. Error t value Pr(>|t|)
> (Intercept)?? 94.734????? 6.511?? 14.55 4.88e-07 ***
> y???????????????? NA???????? NA????? NA?????? NA
> ---
> Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Residual standard error: 19.53 on 8 degrees of freedom
> 
>  > summary(lm(y ~ x))
> 
> Call:
> lm(formula = y ~ x)
> 
> Residuals:
>  ??? Min????? 1Q? Median????? 3Q???? Max
> -2.1687 -1.3345 -0.9466? 1.3826? 2.6551
> 
> Coefficients:
>  ???????????? Estimate Std. Error?? t value Pr(>|t|)
> (Intercept) 1.507e+09? 3.294e+00 4.574e+08? < 2e-16 ***
> x?????????? 6.136e-01? 3.413e-02 1.798e+01 4.07e-07 ***
> ---
> Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Residual standard error: 1.885 on 7 degrees of freedom
> Multiple R-squared:? 0.9788,??? Adjusted R-squared:? 0.9758
> F-statistic: 323.3 on 1 and 7 DF,? p-value: 4.068e-07
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ---
> This email has been checked for viruses by AVG.
> https://www.avg.com
> 
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From ||@t@ @end|ng |rom dewey@myzen@co@uk  Thu Apr 18 17:26:55 2019
From: ||@t@ @end|ng |rom dewey@myzen@co@uk (Michael Dewey)
Date: Thu, 18 Apr 2019 16:26:55 +0100
Subject: [R] R 3.4.4 is released
In-Reply-To: <817ABAF4-92B2-461B-A361-7CD2350E0C61@email.wm.edu>
References: <817ABAF4-92B2-461B-A361-7CD2350E0C61@email.wm.edu>
Message-ID: <3e5108a7-81ee-3092-c8dc-7e11aa1c709b@dewey.myzen.co.uk>

Dear Stephen

Questions about RStudio ae best asked in their help forums but I would 
definitely install the latest version of R and RStudio and do 
update.packages before asking

Michael

On 18/04/2019 13:19, Stephen Muldoon wrote:
> Hi,
> 
> I am new to R studio. If my R studio continually asks to restart for new packages to run, should I remove R studio and reinstall this latest version?
> 
> Thanks,
> Stephen
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ---
> This email has been checked for viruses by AVG.
> https://www.avg.com
> 
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From bgunter@4567 @end|ng |rom gm@||@com  Thu Apr 18 17:45:16 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 18 Apr 2019 08:45:16 -0700
Subject: [R] 
 Is it possible to calculate in r the number of days and count
 of b in var r from the following table:
In-Reply-To: <CABRiLjYoWxXoA7UkyFx5gSYE48EXY_R+Fsi9Y9i5Z2VigaZjCA@mail.gmail.com>
References: <CABRiLjZ0MjZLYTXKcLRErmAhG9DS3pZ3AKuR74CCmigGaXSfGw@mail.gmail.com>
 <CABRiLjYmD7wqNkWVqVCawvV_3C9CxoJ1841HbhDcscOndgm8Qw@mail.gmail.com>
 <CABRiLjYoWxXoA7UkyFx5gSYE48EXY_R+Fsi9Y9i5Z2VigaZjCA@mail.gmail.com>
Message-ID: <CAGxFJbQ_008a=28BNrOBoCLJNvfLyjDj5qaM1XRtFaadJuj58A@mail.gmail.com>

Yes.

Have you gone through any R tutorials, yet? There are many good ones on the
web, some of which are listed here:
https://www.rstudio.com/online-learning/
See also the "Intro to R" tutorial that ships with R.

Spending a little time with these will help you understand R's capabilities
and, of course, learn how to use them.

Cheers,
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Apr 18, 2019 at 8:18 AM ajaykumar cp <ajaykumarcp at gmail.com> wrote:

> Hello
>
> Is it possible to calculate in r the number of days and count of b in var r
> from the following table:
>
>
> id r s t u
> 1 a 100 1 27-06-2017
> 1 a 200 0 29-06-2017
> 1 b 300 0 01-07-2017
> 2 a 500 1 12-06-2017
> 3 b 100 0 02-07-2017
> 3 a 600 1 02-07-2017
> 4 a 200 0 12-06-2017
> 4 a 300 1 15-06-2017
> 4 b 200 0 18-06-2017
> 4 a 100 0 01-07-2017
> 5 a 200 0 04-06-2017
>
> grouped by unique ID where the condition = when r = b, sum of s >= sum of s
> when t = 1?
>
> https://stackoverflow.com/q/55724900/11373077 for the discussions
>
> Thank you in advance
>
>
> --
> C P Ajaykumar
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From j|ox @end|ng |rom mcm@@ter@c@  Thu Apr 18 17:56:02 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Thu, 18 Apr 2019 15:56:02 +0000
Subject: [R] lm fails on some large input
In-Reply-To: <32297_1555601783_x3IFaMQG029261_bef865ce-3f89-24d0-18b7-6653cdd59449@dewey.myzen.co.uk>
References: <836dfcbe-d2e5-7b96-86aa-a1e33b6db966@aosc.io>
 <32297_1555601783_x3IFaMQG029261_bef865ce-3f89-24d0-18b7-6653cdd59449@dewey.myzen.co.uk>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836B81E72@FHSDB2D11-2.csu.mcmaster.ca>

Dear Michael and Dingyuan Wang,

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael
> Dewey
> Sent: Thursday, April 18, 2019 11:25 AM
> To: Dingyuan Wang <gumblex at aosc.io>; r-help at r-project.org
> Subject: Re: [R] lm fails on some large input
> 
> Perhaps subtract 1506705766 from y?
> 
> Saying some other software does it well implies you know what the _correct_
> answer is here but I would question what that means with this sort of data-
> set.

It's rather an interesting problem, though, because the na?ve computation of the LS solution works:

plot(x, y)
X <- cbind(1, x)
b <- solve(t(X) %*% X) %*% t(X) %*% y
b
abline(b)

That surprised me, because I expected that lm() computation, using the QR decomposition, would be more numerically stable.

Best,
 John

-----------------------------------------------------------------
John Fox
Professor Emeritus
McMaster University
Hamilton, Ontario, Canada
Web: https://socialsciences.mcmaster.ca/jfox/



> 
> On 17/04/2019 07:26, Dingyuan Wang wrote:
> > Hi,
> >
> > This input doesn't have any interesting properties except y is unix
> > time. Spreadsheets can do this well.
> > Is this a bug that lm can't do x ~ y?
> >
> > R version 3.5.2 (2018-12-20) -- "Eggshell Igloo"
> > Copyright (C) 2018 The R Foundation for Statistical Computing
> > Platform: x86_64-pc-linux-gnu (64-bit)
> >
> >  > x = c(79.744, 123.904, 87.29601, 116.352, 67.71201, 72.96001,
> > 101.632, 108.928, 94.08)  > y = c(1506705739.385, 1506705766.895,
> > 1506705746.293, 1506705761.873, 1506705734.743, 1506705735.351,
> > 1506705756.26, 1506705761.307,
> > 1506705747.372)
> >  > m = lm(x ~ y)
> >  > summary(m)
> >
> > Call:
> > lm(formula = x ~ y)
> >
> > Residuals:
> >  ???? Min?????? 1Q?? Median?????? 3Q????? Max
> > -27.0222 -14.9902? -0.6542? 14.1938? 29.1698
> >
> > Coefficients: (1 not defined because of singularities)
> >  ??????????? Estimate Std. Error t value Pr(>|t|)
> > (Intercept)?? 94.734????? 6.511?? 14.55 4.88e-07 *** y
> > NA???????? NA????? NA?????? NA
> > ---
> > Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > Residual standard error: 19.53 on 8 degrees of freedom
> >
> >  > summary(lm(y ~ x))
> >
> > Call:
> > lm(formula = y ~ x)
> >
> > Residuals:
> >  ??? Min????? 1Q? Median????? 3Q???? Max
> > -2.1687 -1.3345 -0.9466? 1.3826? 2.6551
> >
> > Coefficients:
> >  ???????????? Estimate Std. Error?? t value Pr(>|t|)
> > (Intercept) 1.507e+09? 3.294e+00 4.574e+08? < 2e-16 *** x
> > 6.136e-01? 3.413e-02 1.798e+01 4.07e-07 ***
> > ---
> > Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > Residual standard error: 1.885 on 7 degrees of freedom Multiple
> > R-squared:? 0.9788,??? Adjusted R-squared:? 0.9758
> > F-statistic: 323.3 on 1 and 7 DF,? p-value: 4.068e-07
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> > ---
> > This email has been checked for viruses by AVG.
> > https://www.avg.com
> >
> >
> 
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From pd@|gd @end|ng |rom gm@||@com  Thu Apr 18 18:23:07 2019
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Thu, 18 Apr 2019 18:23:07 +0200
Subject: [R] lm fails on some large input
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC836B81E72@FHSDB2D11-2.csu.mcmaster.ca>
References: <836dfcbe-d2e5-7b96-86aa-a1e33b6db966@aosc.io>
 <32297_1555601783_x3IFaMQG029261_bef865ce-3f89-24d0-18b7-6653cdd59449@dewey.myzen.co.uk>
 <ACD1644AA6C67E4FBD0C350625508EC836B81E72@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <0F5B4606-CD08-46C0-91FB-6365BBC0003B@gmail.com>

Um, you need to reverse y and x there. The question was about lm(y ~ x)....

> X <- cbind(1, y)
> solve(crossprod(X))
Error in solve.default(crossprod(X)) : 
  system is computationally singular: reciprocal condition number = 6.19587e-35

Actually, lm can QR perfectly OK, but it gets caught by its singularity detection:

> qr <- qr(X, tol=1e-10)
> qr # without the tol bit, you get same thing but $rank == 1
$qr
                             y
 [1,] -3.0000000 -4.520117e+09
 [2,]  0.3333333 -3.426530e+01
 [3,]  0.3333333 -2.947103e-02
 [4,]  0.3333333  4.252164e-01
 [5,]  0.3333333 -3.665468e-01
 [6,]  0.3333333 -3.488029e-01
 [7,]  0.3333333  2.614064e-01
 [8,]  0.3333333  4.086982e-01
 [9,]  0.3333333  2.018556e-03

$rank
[1] 2

$qraux
[1] 1.333333 1.571779

$pivot
[1] 1 2

attr(,"class")
[1] "qr"
> x = c(79.744, 123.904, 87.29601, 116.352, 67.71201, 72.96001, 101.632, 108.928, 94.08)
> qr.coef(qr,x)
                          y 
-2.403345e+09  1.595099e+00 

> lm(x~y)

Call:
lm(formula = x ~ y)

Coefficients:
(Intercept)            y  
      94.73           NA  

> lm(x~y, tol=1e-10)

Call:
lm(formula = x ~ y, tol = 1e-10)

Coefficients:
(Intercept)            y  
 -2.403e+09    1.595e+00  

> lm(x~I(y-mean(y)))

Call:
lm(formula = x ~ I(y - mean(y)))

Coefficients:
   (Intercept)  I(y - mean(y))  
        94.734           1.595  


> On 18 Apr 2019, at 17:56 , Fox, John <jfox at mcmaster.ca> wrote:
> 
> Dear Michael and Dingyuan Wang,
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael
>> Dewey
>> Sent: Thursday, April 18, 2019 11:25 AM
>> To: Dingyuan Wang <gumblex at aosc.io>; r-help at r-project.org
>> Subject: Re: [R] lm fails on some large input
>> 
>> Perhaps subtract 1506705766 from y?
>> 
>> Saying some other software does it well implies you know what the _correct_
>> answer is here but I would question what that means with this sort of data-
>> set.
> 
> It's rather an interesting problem, though, because the na?ve computation of the LS solution works:
> 
> plot(x, y)
> X <- cbind(1, x)
> b <- solve(t(X) %*% X) %*% t(X) %*% y
> b
> abline(b)
> 
> That surprised me, because I expected that lm() computation, using the QR decomposition, would be more numerically stable.
> 
> Best,
> John
> 
> -----------------------------------------------------------------
> John Fox
> Professor Emeritus
> McMaster University
> Hamilton, Ontario, Canada
> Web: https://socialsciences.mcmaster.ca/jfox/
> 
> 
> 
>> 
>> On 17/04/2019 07:26, Dingyuan Wang wrote:
>>> Hi,
>>> 
>>> This input doesn't have any interesting properties except y is unix
>>> time. Spreadsheets can do this well.
>>> Is this a bug that lm can't do x ~ y?
>>> 
>>> R version 3.5.2 (2018-12-20) -- "Eggshell Igloo"
>>> Copyright (C) 2018 The R Foundation for Statistical Computing
>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>> 
>>>> x = c(79.744, 123.904, 87.29601, 116.352, 67.71201, 72.96001,
>>> 101.632, 108.928, 94.08)  > y = c(1506705739.385, 1506705766.895,
>>> 1506705746.293, 1506705761.873, 1506705734.743, 1506705735.351,
>>> 1506705756.26, 1506705761.307,
>>> 1506705747.372)
>>>> m = lm(x ~ y)
>>>> summary(m)
>>> 
>>> Call:
>>> lm(formula = x ~ y)
>>> 
>>> Residuals:
>>>      Min       1Q   Median       3Q      Max
>>> -27.0222 -14.9902  -0.6542  14.1938  29.1698
>>> 
>>> Coefficients: (1 not defined because of singularities)
>>>             Estimate Std. Error t value Pr(>|t|)
>>> (Intercept)   94.734      6.511   14.55 4.88e-07 *** y
>>> NA         NA      NA       NA
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>> 
>>> Residual standard error: 19.53 on 8 degrees of freedom
>>> 
>>>> summary(lm(y ~ x))
>>> 
>>> Call:
>>> lm(formula = y ~ x)
>>> 
>>> Residuals:
>>>     Min      1Q  Median      3Q     Max
>>> -2.1687 -1.3345 -0.9466  1.3826  2.6551
>>> 
>>> Coefficients:
>>>              Estimate Std. Error   t value Pr(>|t|)
>>> (Intercept) 1.507e+09  3.294e+00 4.574e+08  < 2e-16 *** x
>>> 6.136e-01  3.413e-02 1.798e+01 4.07e-07 ***
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>> 
>>> Residual standard error: 1.885 on 7 degrees of freedom Multiple
>>> R-squared:  0.9788,    Adjusted R-squared:  0.9758
>>> F-statistic: 323.3 on 1 and 7 DF,  p-value: 4.068e-07
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ---
>>> This email has been checked for viruses by AVG.
>>> https://www.avg.com
>>> 
>>> 
>> 
>> --
>> Michael
>> http://www.dewey.myzen.co.uk/home.html
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From wdun|@p @end|ng |rom t|bco@com  Thu Apr 18 18:32:09 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Thu, 18 Apr 2019 09:32:09 -0700
Subject: [R] lm fails on some large input
In-Reply-To: <bef865ce-3f89-24d0-18b7-6653cdd59449@dewey.myzen.co.uk>
References: <836dfcbe-d2e5-7b96-86aa-a1e33b6db966@aosc.io>
 <bef865ce-3f89-24d0-18b7-6653cdd59449@dewey.myzen.co.uk>
Message-ID: <CAF8bMca8wQVs0j4S91je8uyxHVoxj=LfyvhRnPhn7qmanKmoUA@mail.gmail.com>

This sort of data arises quite easily if you deal with time/dates around
now.  E.g.,

> d <- data.frame(
+     when = seq(as.POSIXct("2017-09-29 18:22:01"), by="secs", len=10),
+     measurement = log2(1:10))
> coef(lm(data=d, measurement ~ when))
       (Intercept)               when
2.1791061114716954                 NA
> as.numeric(d$when)[1:2]
[1] 1506734521 1506734522

There are problems with the time units (seconds vs. hours) if you subtract
off a time because the units of -.POSIXt depend on the data:

> coef(lm(data=d, measurement ~ I(when - min(when))))
        (Intercept) I(when - min(when))
0.68327571513124297 0.33240675474232279
> coef(lm(data=d, measurement ~ I(when - as.POSIXct("2017-09-29
00:00:00"))))
                                (Intercept) I(when - as.POSIXct("2017-09-29
00:00:00"))
                       -21978.3837546251634
1196.6643170736229


Hence you have to use difftime and specify the units

> coef(lm(data=d, measurement ~ difftime(when, as.POSIXct("2017-09-29
00:00:00"), units="secs")))
                                                      (Intercept)
                                          -2.1978383754612696e+04
difftime(when, as.POSIXct("2017-09-29 00:00:00"), units = "secs")
                                           3.3240675474248449e-01
> coef(lm(data=d, measurement ~ difftime(when, min(when), units="secs")))
                              (Intercept) difftime(when, min(when), units =
"secs")
                      0.68327571513124297
 0.33240675474232279



Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Apr 18, 2019 at 8:24 AM Michael Dewey <lists at dewey.myzen.co.uk>
wrote:

> Perhaps subtract 1506705766 from y?
>
> Saying some other software does it well implies you know what the
> _correct_ answer is here but I would question what that means with this
> sort of data-set.
>
> On 17/04/2019 07:26, Dingyuan Wang wrote:
> > Hi,
> >
> > This input doesn't have any interesting properties except y is unix
> > time. Spreadsheets can do this well.
> > Is this a bug that lm can't do x ~ y?
> >
> > R version 3.5.2 (2018-12-20) -- "Eggshell Igloo"
> > Copyright (C) 2018 The R Foundation for Statistical Computing
> > Platform: x86_64-pc-linux-gnu (64-bit)
> >
> >  > x = c(79.744, 123.904, 87.29601, 116.352, 67.71201, 72.96001,
> > 101.632, 108.928, 94.08)
> >  > y = c(1506705739.385, 1506705766.895, 1506705746.293, 1506705761.873,
> > 1506705734.743, 1506705735.351, 1506705756.26, 1506705761.307,
> > 1506705747.372)
> >  > m = lm(x ~ y)
> >  > summary(m)
> >
> > Call:
> > lm(formula = x ~ y)
> >
> > Residuals:
> >       Min       1Q   Median       3Q      Max
> > -27.0222 -14.9902  -0.6542  14.1938  29.1698
> >
> > Coefficients: (1 not defined because of singularities)
> >              Estimate Std. Error t value Pr(>|t|)
> > (Intercept)   94.734      6.511   14.55 4.88e-07 ***
> > y                 NA         NA      NA       NA
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > Residual standard error: 19.53 on 8 degrees of freedom
> >
> >  > summary(lm(y ~ x))
> >
> > Call:
> > lm(formula = y ~ x)
> >
> > Residuals:
> >      Min      1Q  Median      3Q     Max
> > -2.1687 -1.3345 -0.9466  1.3826  2.6551
> >
> > Coefficients:
> >               Estimate Std. Error   t value Pr(>|t|)
> > (Intercept) 1.507e+09  3.294e+00 4.574e+08  < 2e-16 ***
> > x           6.136e-01  3.413e-02 1.798e+01 4.07e-07 ***
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > Residual standard error: 1.885 on 7 degrees of freedom
> > Multiple R-squared:  0.9788,    Adjusted R-squared:  0.9758
> > F-statistic: 323.3 on 1 and 7 DF,  p-value: 4.068e-07
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> > ---
> > This email has been checked for viruses by AVG.
> > https://www.avg.com
> >
> >
>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ccberry @end|ng |rom uc@d@edu  Thu Apr 18 18:39:38 2019
From: ccberry @end|ng |rom uc@d@edu (Berry, Charles)
Date: Thu, 18 Apr 2019 16:39:38 +0000
Subject: [R] lm fails on some large input
In-Reply-To: <bef865ce-3f89-24d0-18b7-6653cdd59449@dewey.myzen.co.uk>
References: <836dfcbe-d2e5-7b96-86aa-a1e33b6db966@aosc.io>
 <bef865ce-3f89-24d0-18b7-6653cdd59449@dewey.myzen.co.uk>
Message-ID: <2E721B57-F767-4108-A683-E5944586F2D1@ucsd.edu>



> On Apr 18, 2019, at 8:24 AM, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
> 
> Perhaps subtract 1506705766 from y?

Good advice. Some further notes follow.

One can specify `tol` to have a smaller than default value

e.g.

  m2 <- lm(x ~ y, tol=1e-12)

which is accurate:

  plot(y,x)
  abline(coef=coef(m2))
 

Users of numerical procedures need to be mindful of the default settings of the algorithms they use.

As is well known, the use of a too large default for convergence of an optimization algorithm can lead to seriously wrong results. There is an example described here:

https://science.sciencemag.org/content/296/5575/1945/tab-pdf

One might quibble with the choice of tol=1e-7 (the default in lm.fit), and 64 bit floating point will support much smaller values. However, there are usually statistical issues surrounding fitting highly collinear variables.

So,  `tol = 1e-07` seems more like a feature than a bug.

HTH,

Chuck

> 
> Saying some other software does it well implies you know what the _correct_ answer is here but I would question what that means with this sort of data-set.
> 
> On 17/04/2019 07:26, Dingyuan Wang wrote:
>> Hi,
>> This input doesn't have any interesting properties except y is unix time. Spreadsheets can do this well.
>> Is this a bug that lm can't do x ~ y?
>> R version 3.5.2 (2018-12-20) -- "Eggshell Igloo"
>> Copyright (C) 2018 The R Foundation for Statistical Computing
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> > x = c(79.744, 123.904, 87.29601, 116.352, 67.71201, 72.96001, 101.632, 108.928, 94.08)
>> > y = c(1506705739.385, 1506705766.895, 1506705746.293, 1506705761.873, 1506705734.743, 1506705735.351, 1506705756.26, 1506705761.307, 1506705747.372)
>> > m = lm(x ~ y)
>> > summary(m)
>> Call:
>> lm(formula = x ~ y)
>> Residuals:
>>      Min       1Q   Median       3Q      Max
>> -27.0222 -14.9902  -0.6542  14.1938  29.1698
>> Coefficients: (1 not defined because of singularities)
>>             Estimate Std. Error t value Pr(>|t|)
>> (Intercept)   94.734      6.511   14.55 4.88e-07 ***
>> y                 NA         NA      NA       NA
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> Residual standard error: 19.53 on 8 degrees of freedom
>> > summary(lm(y ~ x))
>> Call:
>> lm(formula = y ~ x)
>> Residuals:
>>     Min      1Q  Median      3Q     Max
>> -2.1687 -1.3345 -0.9466  1.3826  2.6551
>> Coefficients:
>>              Estimate Std. Error   t value Pr(>|t|)
>> (Intercept) 1.507e+09  3.294e+00 4.574e+08  < 2e-16 ***
>> x           6.136e-01  3.413e-02 1.798e+01 4.07e-07 ***
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> Residual standard error: 1.885 on 7 degrees of freedom
>> Multiple R-squared:  0.9788,    Adjusted R-squared:  0.9758
>> F-statistic: 323.3 on 1 and 7 DF,  p-value: 4.068e-07
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> ---
>> This email has been checked for viruses by AVG.
>> https://www.avg.com
> 
> -- 
> Michael
> http://www.dewey.myzen.co.uk/home.html
> 


From j|ox @end|ng |rom mcm@@ter@c@  Thu Apr 18 19:06:38 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Thu, 18 Apr 2019 17:06:38 +0000
Subject: [R] lm fails on some large input
In-Reply-To: <0F5B4606-CD08-46C0-91FB-6365BBC0003B@gmail.com>
References: <836dfcbe-d2e5-7b96-86aa-a1e33b6db966@aosc.io>
 <32297_1555601783_x3IFaMQG029261_bef865ce-3f89-24d0-18b7-6653cdd59449@dewey.myzen.co.uk>
 <ACD1644AA6C67E4FBD0C350625508EC836B81E72@FHSDB2D11-2.csu.mcmaster.ca>
 <0F5B4606-CD08-46C0-91FB-6365BBC0003B@gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836B8241F@FHSDB2D11-2.csu.mcmaster.ca>

Dear Peter,

> -----Original Message-----
> From: peter dalgaard [mailto:pdalgd at gmail.com]
> Sent: Thursday, April 18, 2019 12:23 PM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: Michael Dewey <lists at dewey.myzen.co.uk>; Dingyuan Wang
> <gumblex at aosc.io>; r-help at r-project.org
> Subject: Re: [R] lm fails on some large input
> 
> Um, you need to reverse y and x there. The question was about lm(y ~ x)....
> 

Good catch! I missed that in the original posting, and lm() does indeed produce the LS solution for the regression of y on x. And, as I'd have expected, the na?ve approach also fails for the regression of x on y:

> Y <- cbind(1, y)
> b <- solve(t(Y) %*% Y) %*% t(Y) %*% x
Error in solve.default(t(Y) %*% Y) : 
  system is computationally singular: reciprocal condition number = 6.19587e-35

resolving the mystery.

Thanks,
 John

> > X <- cbind(1, y)
> > solve(crossprod(X))
> Error in solve.default(crossprod(X)) :
>   system is computationally singular: reciprocal condition number = 6.19587e-
> 35
> 
> Actually, lm can QR perfectly OK, but it gets caught by its singularity detection:
> 
> > qr <- qr(X, tol=1e-10)
> > qr # without the tol bit, you get same thing but $rank == 1
> $qr
>                              y
>  [1,] -3.0000000 -4.520117e+09
>  [2,]  0.3333333 -3.426530e+01
>  [3,]  0.3333333 -2.947103e-02
>  [4,]  0.3333333  4.252164e-01
>  [5,]  0.3333333 -3.665468e-01
>  [6,]  0.3333333 -3.488029e-01
>  [7,]  0.3333333  2.614064e-01
>  [8,]  0.3333333  4.086982e-01
>  [9,]  0.3333333  2.018556e-03
> 
> $rank
> [1] 2
> 
> $qraux
> [1] 1.333333 1.571779
> 
> $pivot
> [1] 1 2
> 
> attr(,"class")
> [1] "qr"
> > x = c(79.744, 123.904, 87.29601, 116.352, 67.71201, 72.96001, 101.632,
> > 108.928, 94.08)
> > qr.coef(qr,x)
>                           y
> -2.403345e+09  1.595099e+00
> 
> > lm(x~y)
> 
> Call:
> lm(formula = x ~ y)
> 
> Coefficients:
> (Intercept)            y
>       94.73           NA
> 
> > lm(x~y, tol=1e-10)
> 
> Call:
> lm(formula = x ~ y, tol = 1e-10)
> 
> Coefficients:
> (Intercept)            y
>  -2.403e+09    1.595e+00
> 
> > lm(x~I(y-mean(y)))
> 
> Call:
> lm(formula = x ~ I(y - mean(y)))
> 
> Coefficients:
>    (Intercept)  I(y - mean(y))
>         94.734           1.595
> 
> 
> > On 18 Apr 2019, at 17:56 , Fox, John <jfox at mcmaster.ca> wrote:
> >
> > Dear Michael and Dingyuan Wang,
> >
> >> -----Original Message-----
> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> >> Michael Dewey
> >> Sent: Thursday, April 18, 2019 11:25 AM
> >> To: Dingyuan Wang <gumblex at aosc.io>; r-help at r-project.org
> >> Subject: Re: [R] lm fails on some large input
> >>
> >> Perhaps subtract 1506705766 from y?
> >>
> >> Saying some other software does it well implies you know what the
> >> _correct_ answer is here but I would question what that means with
> >> this sort of data- set.
> >
> > It's rather an interesting problem, though, because the na?ve computation of
> the LS solution works:
> >
> > plot(x, y)
> > X <- cbind(1, x)
> > b <- solve(t(X) %*% X) %*% t(X) %*% y
> > b
> > abline(b)
> >
> > That surprised me, because I expected that lm() computation, using the QR
> decomposition, would be more numerically stable.
> >
> > Best,
> > John
> >
> > -----------------------------------------------------------------
> > John Fox
> > Professor Emeritus
> > McMaster University
> > Hamilton, Ontario, Canada
> > Web: https://socialsciences.mcmaster.ca/jfox/
> >
> >
> >
> >>
> >> On 17/04/2019 07:26, Dingyuan Wang wrote:
> >>> Hi,
> >>>
> >>> This input doesn't have any interesting properties except y is unix
> >>> time. Spreadsheets can do this well.
> >>> Is this a bug that lm can't do x ~ y?
> >>>
> >>> R version 3.5.2 (2018-12-20) -- "Eggshell Igloo"
> >>> Copyright (C) 2018 The R Foundation for Statistical Computing
> >>> Platform: x86_64-pc-linux-gnu (64-bit)
> >>>
> >>>> x = c(79.744, 123.904, 87.29601, 116.352, 67.71201, 72.96001,
> >>> 101.632, 108.928, 94.08)  > y = c(1506705739.385, 1506705766.895,
> >>> 1506705746.293, 1506705761.873, 1506705734.743, 1506705735.351,
> >>> 1506705756.26, 1506705761.307,
> >>> 1506705747.372)
> >>>> m = lm(x ~ y)
> >>>> summary(m)
> >>>
> >>> Call:
> >>> lm(formula = x ~ y)
> >>>
> >>> Residuals:
> >>>      Min       1Q   Median       3Q      Max
> >>> -27.0222 -14.9902  -0.6542  14.1938  29.1698
> >>>
> >>> Coefficients: (1 not defined because of singularities)
> >>>             Estimate Std. Error t value Pr(>|t|)
> >>> (Intercept)   94.734      6.511   14.55 4.88e-07 *** y
> >>> NA         NA      NA       NA
> >>> ---
> >>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >>>
> >>> Residual standard error: 19.53 on 8 degrees of freedom
> >>>
> >>>> summary(lm(y ~ x))
> >>>
> >>> Call:
> >>> lm(formula = y ~ x)
> >>>
> >>> Residuals:
> >>>     Min      1Q  Median      3Q     Max
> >>> -2.1687 -1.3345 -0.9466  1.3826  2.6551
> >>>
> >>> Coefficients:
> >>>              Estimate Std. Error   t value Pr(>|t|)
> >>> (Intercept) 1.507e+09  3.294e+00 4.574e+08  < 2e-16 *** x
> >>> 6.136e-01  3.413e-02 1.798e+01 4.07e-07 ***
> >>> ---
> >>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >>>
> >>> Residual standard error: 1.885 on 7 degrees of freedom Multiple
> >>> R-squared:  0.9788,    Adjusted R-squared:  0.9758
> >>> F-statistic: 323.3 on 1 and 7 DF,  p-value: 4.068e-07
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>> ---
> >>> This email has been checked for viruses by AVG.
> >>> https://www.avg.com
> >>>
> >>>
> >>
> >> --
> >> Michael
> >> http://www.dewey.myzen.co.uk/home.html
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html and provide commented, minimal, self-contained,
> >> reproducible code.
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School Solbjerg Plads 3, 2000
> Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 


From B|||@Po||ng @end|ng |rom ze||@@com  Thu Apr 18 19:18:34 2019
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Thu, 18 Apr 2019 17:18:34 +0000
Subject: [R] 
 Help with a setting some values of a df vector to 0 but not all
 values
In-Reply-To: <8ba4c3a9597145308e6d1fa359f06918@SRVEXCHCM1301.precheza.cz>
References: <BN7PR02MB5073DF0401D32B8C2507D572EA260@BN7PR02MB5073.namprd02.prod.outlook.com>
 <8ba4c3a9597145308e6d1fa359f06918@SRVEXCHCM1301.precheza.cz>
Message-ID: <BN7PR02MB50733C205783AA78670BC908EA260@BN7PR02MB5073.namprd02.prod.outlook.com>


Thank you PIKAL Petr.


From: PIKAL Petr <petr.pikal at precheza.cz>
Sent: Thursday, April 18, 2019 8:54 AM
To: Bill Poling <Bill.Poling at zelis.com>; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: RE: Help with a setting some values of a df vector to 0 but not all values

Hi

seems to me simple

Sample data
> nozero <- c(1565, 1569, 1674, 415, 1564)
> test <- sample(c(1:10, nozero), 250, replace=T)
> test
[1] 10 2 6 4 415 5 9 1565 1569 2 10 1569 415 1569 3
[16] 4 9 10 1 1 5 10 1 3 10 9 1564 4 10 8
[31] 6 1674 10 2 9 415 1674 4 1674 1569 6 6 1565 6 5
...

change all except nozero to zero

> test[!test %in% nozero] <- 0
> test
[1] 0 0 0 0 415 0 0 1565 1569 0 0 1569 415 1569 0
[16] 0 0 0 0 0 0 0 0 0 0 0 1564 0 0 0
[31] 0 1674 0 0 0 415 1674 0 1674 1569 0 0 1565 0 0
...

Cheers
Petr


> -----Original Message-----
> From: R-help <mailto:r-help-bounces at r-project.org> On Behalf Of Bill Poling
> Sent: Thursday, April 18, 2019 2:39 PM
> To: r-help (mailto:r-help at r-project.org) <mailto:r-help at r-project.org>
> Subject: [R] Help with a setting some values of a df vector to 0 but not all
> values
>
> Good morning.
>
> #RStudio Version 1.1.456
> sessionInfo()
> #R version 3.5.3 (2019-03-11)
> #Platform: x86_64-w64-mingw32/x64 (64-bit) #Running under: Windows >= 8
> x64 (build 9200)
>
> I have a df column that looks like the below.
>
> #68 ID's including the 0 value
>
> I want to set all the values to 0 with the exception of 5 which are c(1565, 1569,
> 1674, 415, 1564))
>
> I realize its basic but the routine eludes me, I have googled and there are
> plenty of urls for setting to NA, etc.. but nothing I found, yet, where it is a
> subset routine excluding a few values.
>
> I expect the routine would be something like --
>
> set df1$ClaimManagerID = 0 where df$ClaimManagerID NOT IN
> c(1565,1569,1674,415,1564)
>
> str(df$ClaimManagerID)
> int [1:18015] 1558 0 1565 1565 1565 1565 1565 0 1565 1565 ...
>
> |ClaimManagerID | cnt| pct| cum_pct|
> |:-------------- |--------:|-------- -:|-------- -:|
> |1565 | 11412| 0.6334721| 0.6334721|
> |0 | 6120| 0.3397169| 0.9731890|
> |1569 | 162| 0.0089925| 0.9821815|
> |1674 | 25| 0.0013877| 0.9835692|
> |415 | 21| 0.0011657| 0.9847349|
> |1564 | 20| 0.0011102| 0.9858451|
> |234 | 19| 0.0010547| 0.9868998|
> |521 | 17| 0.0009437| 0.9878435|
>
> etc....= 68 ID's
>
> Thank you for any help.
>
> WHP
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}
>
> ______________________________________________
> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Apr 18 19:23:00 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 18 Apr 2019 10:23:00 -0700
Subject: [R] R 3.4.4 is released
In-Reply-To: <3e5108a7-81ee-3092-c8dc-7e11aa1c709b@dewey.myzen.co.uk>
References: <817ABAF4-92B2-461B-A361-7CD2350E0C61@email.wm.edu>
 <3e5108a7-81ee-3092-c8dc-7e11aa1c709b@dewey.myzen.co.uk>
Message-ID: <2DDFABE8-BF3D-42C9-A1C0-6F1E07E0FF7A@dcn.davis.ca.us>

To be clear, if you encounter problems with R using RStudio, try doing "the same thing" using an interface provided in the R installed software directly... under Windows that might be through RGui or on Mac using R.app or on any platform via the terminal command line R program. If the problem goes away when you do that then you need to ask RStudio about it.

On April 18, 2019 8:26:55 AM PDT, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
>Dear Stephen
>
>Questions about RStudio ae best asked in their help forums but I would 
>definitely install the latest version of R and RStudio and do 
>update.packages before asking
>
>Michael
>
>On 18/04/2019 13:19, Stephen Muldoon wrote:
>> Hi,
>> 
>> I am new to R studio. If my R studio continually asks to restart for
>new packages to run, should I remove R studio and reinstall this latest
>version?
>> 
>> Thanks,
>> Stephen
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ---
>> This email has been checked for viruses by AVG.
>> https://www.avg.com
>> 
>> 

-- 
Sent from my phone. Please excuse my brevity.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Apr 18 20:44:03 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 18 Apr 2019 11:44:03 -0700
Subject: [R] lm fails on some large input
In-Reply-To: <CAF8bMca8wQVs0j4S91je8uyxHVoxj=LfyvhRnPhn7qmanKmoUA@mail.gmail.com>
References: <836dfcbe-d2e5-7b96-86aa-a1e33b6db966@aosc.io>
 <bef865ce-3f89-24d0-18b7-6653cdd59449@dewey.myzen.co.uk>
 <CAF8bMca8wQVs0j4S91je8uyxHVoxj=LfyvhRnPhn7qmanKmoUA@mail.gmail.com>
Message-ID: <656F3F0A-EA99-43E6-A54C-3EBB039B2D01@dcn.davis.ca.us>

I make a general rule not to stick time values into numerical analysis algorithms without first subtracting a reasonable epoch (to obtain difftime) and then using as.numeric.POSIXt with the units argument set explicitly so the analysis uses numeric values that I can interpret. While the explicit use of difftime function does something similar, if any other operations are performed on it the units could change again before the inevitable conversion to numeric occurs somewhere down the line so I think taking responsibility for the numeric conversion myself is less likely to leave surprises.

On April 18, 2019 9:32:09 AM PDT, William Dunlap via R-help <r-help at r-project.org> wrote:
>This sort of data arises quite easily if you deal with time/dates
>around
>now.  E.g.,
>
>> d <- data.frame(
>+     when = seq(as.POSIXct("2017-09-29 18:22:01"), by="secs", len=10),
>+     measurement = log2(1:10))
>> coef(lm(data=d, measurement ~ when))
>       (Intercept)               when
>2.1791061114716954                 NA
>> as.numeric(d$when)[1:2]
>[1] 1506734521 1506734522
>
>There are problems with the time units (seconds vs. hours) if you
>subtract
>off a time because the units of -.POSIXt depend on the data:
>
>> coef(lm(data=d, measurement ~ I(when - min(when))))
>        (Intercept) I(when - min(when))
>0.68327571513124297 0.33240675474232279
>> coef(lm(data=d, measurement ~ I(when - as.POSIXct("2017-09-29
>00:00:00"))))
>                            (Intercept) I(when - as.POSIXct("2017-09-29
>00:00:00"))
>                       -21978.3837546251634
>1196.6643170736229
>
>
>Hence you have to use difftime and specify the units
>
>> coef(lm(data=d, measurement ~ difftime(when, as.POSIXct("2017-09-29
>00:00:00"), units="secs")))
>                                                      (Intercept)
>                                          -2.1978383754612696e+04
>difftime(when, as.POSIXct("2017-09-29 00:00:00"), units = "secs")
>                                           3.3240675474248449e-01
>> coef(lm(data=d, measurement ~ difftime(when, min(when),
>units="secs")))
>                          (Intercept) difftime(when, min(when), units =
>"secs")
>                      0.68327571513124297
> 0.33240675474232279
>
>
>
>Bill Dunlap
>TIBCO Software
>wdunlap tibco.com
>
>
>On Thu, Apr 18, 2019 at 8:24 AM Michael Dewey <lists at dewey.myzen.co.uk>
>wrote:
>
>> Perhaps subtract 1506705766 from y?
>>
>> Saying some other software does it well implies you know what the
>> _correct_ answer is here but I would question what that means with
>this
>> sort of data-set.
>>
>> On 17/04/2019 07:26, Dingyuan Wang wrote:
>> > Hi,
>> >
>> > This input doesn't have any interesting properties except y is unix
>> > time. Spreadsheets can do this well.
>> > Is this a bug that lm can't do x ~ y?
>> >
>> > R version 3.5.2 (2018-12-20) -- "Eggshell Igloo"
>> > Copyright (C) 2018 The R Foundation for Statistical Computing
>> > Platform: x86_64-pc-linux-gnu (64-bit)
>> >
>> >  > x = c(79.744, 123.904, 87.29601, 116.352, 67.71201, 72.96001,
>> > 101.632, 108.928, 94.08)
>> >  > y = c(1506705739.385, 1506705766.895, 1506705746.293,
>1506705761.873,
>> > 1506705734.743, 1506705735.351, 1506705756.26, 1506705761.307,
>> > 1506705747.372)
>> >  > m = lm(x ~ y)
>> >  > summary(m)
>> >
>> > Call:
>> > lm(formula = x ~ y)
>> >
>> > Residuals:
>> >       Min       1Q   Median       3Q      Max
>> > -27.0222 -14.9902  -0.6542  14.1938  29.1698
>> >
>> > Coefficients: (1 not defined because of singularities)
>> >              Estimate Std. Error t value Pr(>|t|)
>> > (Intercept)   94.734      6.511   14.55 4.88e-07 ***
>> > y                 NA         NA      NA       NA
>> > ---
>> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> >
>> > Residual standard error: 19.53 on 8 degrees of freedom
>> >
>> >  > summary(lm(y ~ x))
>> >
>> > Call:
>> > lm(formula = y ~ x)
>> >
>> > Residuals:
>> >      Min      1Q  Median      3Q     Max
>> > -2.1687 -1.3345 -0.9466  1.3826  2.6551
>> >
>> > Coefficients:
>> >               Estimate Std. Error   t value Pr(>|t|)
>> > (Intercept) 1.507e+09  3.294e+00 4.574e+08  < 2e-16 ***
>> > x           6.136e-01  3.413e-02 1.798e+01 4.07e-07 ***
>> > ---
>> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> >
>> > Residual standard error: 1.885 on 7 degrees of freedom
>> > Multiple R-squared:  0.9788,    Adjusted R-squared:  0.9758
>> > F-statistic: 323.3 on 1 and 7 DF,  p-value: 4.068e-07
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ---
>> > This email has been checked for viruses by AVG.
>> > https://www.avg.com
>> >
>> >
>>
>> --
>> Michael
>> http://www.dewey.myzen.co.uk/home.html
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From 538280 @end|ng |rom gm@||@com  Thu Apr 18 20:47:24 2019
From: 538280 @end|ng |rom gm@||@com (Greg Snow)
Date: Thu, 18 Apr 2019 12:47:24 -0600
Subject: [R] Pause script at input from terminal (interactive use)
In-Reply-To: <CAMk+s2TaC0mXOs_s2NFWsRxj0g_sxomRbaaU4N0ZoDTmSfiVtg@mail.gmail.com>
References: <CAMk+s2TaC0mXOs_s2NFWsRxj0g_sxomRbaaU4N0ZoDTmSfiVtg@mail.gmail.com>
Message-ID: <CAFEqCdzWfcoSF42G2TD25SVdMcWaqeZa7sAeM-XQSGTRSrtDnA@mail.gmail.com>

I am not an expert on Rscript, but I don't think that an actual
terminal is ever used when using Rscript.  And `interactive()` will
probably always be false.

So if you want the script to pause for input, you need to have some
form of user interface to work with.

One option is to use the tcltk package (this works on all OS's to my
knowledge, but not if you are accessing the computer remotely).  This
answer on stack overflow shows some code that may help:
https://stackoverflow.com/questions/16847621/get-data-out-of-a-tcltk-function/16847918#16847918


On Thu, Apr 18, 2019 at 8:11 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Dear all,
> I am trying to write an interactive script where the user type some
> input from the terminal. I used readline() but when I launch the file
> with Rscript, the function is overwritten directly, there is no
> waiting for the user's input. For instance, this example:
>
> VAR1 = as.numeric(readline(prompt = "Enter something -> "))
> VAR2 = as.numeric(readline(prompt = "Enter something else -> "))
> if(is.na(VAR1)) VAR1 = 0
> if(is.na(VAR2)) VAR2 = "empty"
> cat("Input was: ", VAR1, " - ", VAR2, "\n")
>
> is executed till the end without typing anything on terminal :
>
> $ Rscript test.R
> Enter something ->
> Enter something else ->
> Input was:  0  -  empty
>
> I also tried with ',1' at the end of readline, but the effect is the
> same. I should use the interactive() function but I am confused on its
> use.
> It is possible to launch R scritps in the interactive mode in the
> first place? and if yes, how? Or would python or julia be better
> choices in this case?
> Thank you.
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From 538280 @end|ng |rom gm@||@com  Thu Apr 18 21:13:54 2019
From: 538280 @end|ng |rom gm@||@com (Greg Snow)
Date: Thu, 18 Apr 2019 13:13:54 -0600
Subject: [R] Looping with looping
In-Reply-To: <CAHXS41w+=pbxPS9maMiqN4_hAv54MVLYfV+c=+jrfo2yNpAFSA@mail.gmail.com>
References: <CAHXS41w+=pbxPS9maMiqN4_hAv54MVLYfV+c=+jrfo2yNpAFSA@mail.gmail.com>
Message-ID: <CAFEqCdyrLG-vzYBq7jeUe=YUM-0h8Sxjc+nTFNNnNq4hUgdeZQ@mail.gmail.com>

When the goal of looping is to compute something and save each
iteration into a vector or list, then it is usually easier to use the
lapply/sapply/replicate functions and save the result into a single
list rather than a bunch of global variables.

Here is a quick example that does the same computations as your code,
but save the results into a list where each element is a vector of
length 100:

sam<-c(9,7,8,6,6,7,8,6,7,3)
a <- lapply(2:9, function(k){
  replicate(100, mean(sample(sam, k, replace=TRUE)))
})

# optional
names(a) <- sprintf("a%i", 2:9)

hist(a[["a2"]]
hist(a$a9)
w <- "a5"
hist(a[[w]])


Saving everything into a single list (or matrix/array/etc.) makes it
easier to loop over all of the results later on (and prevents the hard
to track down bugs from using dynamically named global variables).
Here is an example based on the results from above:

par(mfrow=c(3,3))
for(i in seq_along(a)) {
  hist(a[[i]], xlab='x', main=sprintf("k = %i", (2:9)[i]))
}





On Thu, Apr 18, 2019 at 9:19 AM ani jaya <gaaauul at gmail.com> wrote:
>
> Dear R community,
>
> I'm trying to create a looping to see the effect of number of samples from
> one dataset.
> Lets say I have 10 values in a single data frame and I want to see the mean
> of each sampling let say from 2-9 number of sampling. But I want to do the
> repetition let say up to 100 for each number of sampling and put it in a
> different dataframe, let say a2,a3,a4,... which contain a2[1] is the mean
> of first repetition and so on. I believe this is possible but I'm newbie
> here.
>
> > version
>
> platform       x86_64-w64-mingw32
> arch           x86_64
> os             mingw32
> system         x86_64, mingw32
> status
> major          3
> minor          5.3
> year           2019
> month          03
> day            11
> svn rev        76217
> language       R
> version.string R version 3.5.3 (2019-03-11)
> nickname       Great Truth
>
>
>  The simple code that I have:
>
> sam<-c(9,7,8,6,6,7,8,6,7,3)
> for (k in seq(2,9,1)){
>     a <- numeric(100)
>       for (i in 1:100){
>       a[i] <- mean(sample(sam,k,replace=T))
>
>       }
>   }
>
> I can do enough with this code but i want to the variable name also
> move based on k.
>
> I have googling enough and meet assign and paste command but not really help.
> Any help would be appreciate.
>
>
>
> Best,
>
> Saat M.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From gk@r@v@@ @end|ng |rom ee@duth@gr  Wed Apr 17 09:15:52 2019
From: gk@r@v@@ @end|ng |rom ee@duth@gr (George Karavasilis)
Date: Wed, 17 Apr 2019 10:15:52 +0300
Subject: [R] power analysis for Friedman's test
Message-ID: <d3554fe6-fbb2-65ae-ccb9-362bdbec509d@ee.duth.gr>

Hello,
I am running a non parametric repeated measures experiment with 
Friedman?s test:

 ??????? Friedman rank sum test

data:? glikozi and week and subject
Friedman chi-squared = 18.538, df = 3, p-value = 0.0003405

How could I run a power analysis for this test in R?
Thank you!

-- 
George Karavasilis
Department of Business Administration & 	
Serres, Greece


---
???? ?? e-mail ????????? ??? ???? ??? ?? ????????? Avast antivirus.
https://www.avast.com/antivirus


From gumb|ex @end|ng |rom @o@c@|o  Thu Apr 18 18:35:55 2019
From: gumb|ex @end|ng |rom @o@c@|o (Dingyuan Wang)
Date: Fri, 19 Apr 2019 00:35:55 +0800
Subject: [R] lm fails on some large input
In-Reply-To: <bef865ce-3f89-24d0-18b7-6653cdd59449@dewey.myzen.co.uk>
References: <836dfcbe-d2e5-7b96-86aa-a1e33b6db966@aosc.io>
 <bef865ce-3f89-24d0-18b7-6653cdd59449@dewey.myzen.co.uk>
Message-ID: <20645481-ad46-0570-104f-acee78c60566@aosc.io>

I just want to make a line out of timestamps vs some coordinates, so y~x 
or x~y doesn't matter.

Yes, I know the answer. When trying R, I'm surprised that R can't solve 
that either. I first noticed that PostgreSQL can't solve it, and found 
that they fixed that in pg 12.

https://www.postgresql.org/message-id/153313051300.1397.9594490737341194671%40wrigleys.postgresql.org

Therefore I come to ask whether someone know how to fix this in R, or I 
must submit it as a bug?

2019/4/18 23:24, Michael Dewey:
> Perhaps subtract 1506705766 from y?
> 
> Saying some other software does it well implies you know what the 
> _correct_ answer is here but I would question what that means with this 
> sort of data-set.
> 
> On 17/04/2019 07:26, Dingyuan Wang wrote:
>> Hi,
>>
>> This input doesn't have any interesting properties except y is unix 
>> time. Spreadsheets can do this well.
>> Is this a bug that lm can't do x ~ y?
>>
>> R version 3.5.2 (2018-12-20) -- "Eggshell Igloo"
>> Copyright (C) 2018 The R Foundation for Statistical Computing
>> Platform: x86_64-pc-linux-gnu (64-bit)
>>
>> ?> x = c(79.744, 123.904, 87.29601, 116.352, 67.71201, 72.96001, 
>> 101.632, 108.928, 94.08)
>> ?> y = c(1506705739.385, 1506705766.895, 1506705746.293, 
>> 1506705761.873, 1506705734.743, 1506705735.351, 1506705756.26, 
>> 1506705761.307, 1506705747.372)
>> ?> m = lm(x ~ y)
>> ?> summary(m)
>>
>> Call:
>> lm(formula = x ~ y)
>>
>> Residuals:
>> ????? Min?????? 1Q?? Median?????? 3Q????? Max
>> -27.0222 -14.9902? -0.6542? 14.1938? 29.1698
>>
>> Coefficients: (1 not defined because of singularities)
>> ???????????? Estimate Std. Error t value Pr(>|t|)
>> (Intercept)?? 94.734????? 6.511?? 14.55 4.88e-07 ***
>> y???????????????? NA???????? NA????? NA?????? NA
>> ---
>> Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Residual standard error: 19.53 on 8 degrees of freedom
>>
>> ?> summary(lm(y ~ x))
>>
>> Call:
>> lm(formula = y ~ x)
>>
>> Residuals:
>> ???? Min????? 1Q? Median????? 3Q???? Max
>> -2.1687 -1.3345 -0.9466? 1.3826? 2.6551
>>
>> Coefficients:
>> ????????????? Estimate Std. Error?? t value Pr(>|t|)
>> (Intercept) 1.507e+09? 3.294e+00 4.574e+08? < 2e-16 ***
>> x?????????? 6.136e-01? 3.413e-02 1.798e+01 4.07e-07 ***
>> ---
>> Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> Residual standard error: 1.885 on 7 degrees of freedom
>> Multiple R-squared:? 0.9788,??? Adjusted R-squared:? 0.9758
>> F-statistic: 323.3 on 1 and 7 DF,? p-value: 4.068e-07
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ---
>> This email has been checked for viruses by AVG.
>> https://www.avg.com
>>
>>
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Apr 18 22:12:41 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 18 Apr 2019 13:12:41 -0700
Subject: [R] lm fails on some large input
In-Reply-To: <20645481-ad46-0570-104f-acee78c60566@aosc.io>
References: <836dfcbe-d2e5-7b96-86aa-a1e33b6db966@aosc.io>
 <bef865ce-3f89-24d0-18b7-6653cdd59449@dewey.myzen.co.uk>
 <20645481-ad46-0570-104f-acee78c60566@aosc.io>
Message-ID: <21692899-DD30-4349-A0B8-BC10D638ADAD@dcn.davis.ca.us>

The fact that you think x~y is interchangeable with y~x suggests to me that you will have a difficult time convincing R Core that this is a bug. I recommend that you take at leastan upper division college course in linear regression first.

On April 18, 2019 9:35:55 AM PDT, Dingyuan Wang <gumblex at aosc.io> wrote:
>I just want to make a line out of timestamps vs some coordinates, so
>y~x 
>or x~y doesn't matter.
>
>Yes, I know the answer. When trying R, I'm surprised that R can't solve
>
>that either. I first noticed that PostgreSQL can't solve it, and found 
>that they fixed that in pg 12.
>
>https://www.postgresql.org/message-id/153313051300.1397.9594490737341194671%40wrigleys.postgresql.org
>
>Therefore I come to ask whether someone know how to fix this in R, or I
>
>must submit it as a bug?
>
>2019/4/18 23:24, Michael Dewey:
>> Perhaps subtract 1506705766 from y?
>> 
>> Saying some other software does it well implies you know what the 
>> _correct_ answer is here but I would question what that means with
>this 
>> sort of data-set.
>> 
>> On 17/04/2019 07:26, Dingyuan Wang wrote:
>>> Hi,
>>>
>>> This input doesn't have any interesting properties except y is unix 
>>> time. Spreadsheets can do this well.
>>> Is this a bug that lm can't do x ~ y?
>>>
>>> R version 3.5.2 (2018-12-20) -- "Eggshell Igloo"
>>> Copyright (C) 2018 The R Foundation for Statistical Computing
>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>>
>>> ?> x = c(79.744, 123.904, 87.29601, 116.352, 67.71201, 72.96001, 
>>> 101.632, 108.928, 94.08)
>>> ?> y = c(1506705739.385, 1506705766.895, 1506705746.293, 
>>> 1506705761.873, 1506705734.743, 1506705735.351, 1506705756.26, 
>>> 1506705761.307, 1506705747.372)
>>> ?> m = lm(x ~ y)
>>> ?> summary(m)
>>>
>>> Call:
>>> lm(formula = x ~ y)
>>>
>>> Residuals:
>>> ????? Min?????? 1Q?? Median?????? 3Q????? Max
>>> -27.0222 -14.9902? -0.6542? 14.1938? 29.1698
>>>
>>> Coefficients: (1 not defined because of singularities)
>>> ???????????? Estimate Std. Error t value Pr(>|t|)
>>> (Intercept)?? 94.734????? 6.511?? 14.55 4.88e-07 ***
>>> y???????????????? NA???????? NA????? NA?????? NA
>>> ---
>>> Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>
>>> Residual standard error: 19.53 on 8 degrees of freedom
>>>
>>> ?> summary(lm(y ~ x))
>>>
>>> Call:
>>> lm(formula = y ~ x)
>>>
>>> Residuals:
>>> ???? Min????? 1Q? Median????? 3Q???? Max
>>> -2.1687 -1.3345 -0.9466? 1.3826? 2.6551
>>>
>>> Coefficients:
>>> ????????????? Estimate Std. Error?? t value Pr(>|t|)
>>> (Intercept) 1.507e+09? 3.294e+00 4.574e+08? < 2e-16 ***
>>> x?????????? 6.136e-01? 3.413e-02 1.798e+01 4.07e-07 ***
>>> ---
>>> Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>
>>> Residual standard error: 1.885 on 7 degrees of freedom
>>> Multiple R-squared:? 0.9788,??? Adjusted R-squared:? 0.9758
>>> F-statistic: 323.3 on 1 and 7 DF,? p-value: 4.068e-07
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ---
>>> This email has been checked for viruses by AVG.
>>> https://www.avg.com
>>>
>>>
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From 538280 @end|ng |rom gm@||@com  Thu Apr 18 23:08:16 2019
From: 538280 @end|ng |rom gm@||@com (Greg Snow)
Date: Thu, 18 Apr 2019 15:08:16 -0600
Subject: [R] power analysis for Friedman's test
In-Reply-To: <d3554fe6-fbb2-65ae-ccb9-362bdbec509d@ee.duth.gr>
References: <d3554fe6-fbb2-65ae-ccb9-362bdbec509d@ee.duth.gr>
Message-ID: <CAFEqCdznUhg28sDevq5EwwvDU6GnRXui7+5dVhLD=jG1W7F9_g@mail.gmail.com>

Generally you should do the power analysis before collecting any data.
Since you have results it looks like you already have the data
collected.

But if you want to compute the power for a future study, one option is
to use simulation.

1. decide what the data will look like
2. decide how you will analyze the data
3. simulate data and analyze it based on 1 and 2
4. repeat step 3 a bunch of times, the proportion of "Significant"
results is your estimated power

Here is an example to use as a starting point:

simfun <- function(nblocks=10, means=c(0,0,0), within.sd=1, between.sd=1) {
  g <- factor(rep(seq_len(nblocks), each=length(means)))
  t <- rep(seq_along(means), nblocks)
  y <- means[t] + rnorm(nblocks, 0, between.sd)[g] + rnorm(length(g),
0, within.sd)
  friedman.test(y ~ t | g)$p.value
}

# test size of test
out <- replicate(1000, simfun())
hist(out)
mean(out <= 0.05)

# now for power
out2 <- replicate(1000, simfun(nblocks=25, means=c(10, 10.5, 11)))
hist(out2)
mean(out2 <= 0.05)


On Thu, Apr 18, 2019 at 1:40 PM George Karavasilis <gkaravas at ee.duth.gr> wrote:
>
> Hello,
> I am running a non parametric repeated measures experiment with
> Friedman?s test:
>
>          Friedman rank sum test
>
> data:  glikozi and week and subject
> Friedman chi-squared = 18.538, df = 3, p-value = 0.0003405
>
> How could I run a power analysis for this test in R?
> Thank you!
>
> --
> George Karavasilis
> Department of Business Administration &
> Serres, Greece
>
>
> ---
> ???? ?? e-mail ????????? ??? ???? ??? ?? ????????? Avast antivirus.
> https://www.avast.com/antivirus
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From j|ox @end|ng |rom mcm@@ter@c@  Thu Apr 18 23:11:25 2019
From: j|ox @end|ng |rom mcm@@ter@c@ (Fox, John)
Date: Thu, 18 Apr 2019 21:11:25 +0000
Subject: [R] lm fails on some large input
In-Reply-To: <30656_1555616534_x3IJgDlp020213_20645481-ad46-0570-104f-acee78c60566@aosc.io>
References: <836dfcbe-d2e5-7b96-86aa-a1e33b6db966@aosc.io>
 <bef865ce-3f89-24d0-18b7-6653cdd59449@dewey.myzen.co.uk>
 <30656_1555616534_x3IJgDlp020213_20645481-ad46-0570-104f-acee78c60566@aosc.io>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC836B836D2@FHSDB2D11-2.csu.mcmaster.ca>

Dear Dingyuan Wang,

But your question was answered clearly earlier in this thread (I forget by whom), showing that lm() provides the solution to the regression of x on y if the criterion for singularity is tightened:

> lm(x ~ y)

Call:
lm(formula = x ~ y)

Coefficients:
(Intercept)            y  
      94.73           NA  

> lm(x ~ y, tol=1e-10)

Call:
lm(formula = x ~ y, tol = 1e-10)

Coefficients:
(Intercept)            y  
 -2.403e+09    1.595e+00  

Best,
 John

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Dingyuan
> Wang
> Sent: Thursday, April 18, 2019 12:36 PM
> To: Michael Dewey <lists at dewey.myzen.co.uk>; r-help at r-project.org
> Subject: Re: [R] lm fails on some large input
> 
> I just want to make a line out of timestamps vs some coordinates, so y~x or
> x~y doesn't matter.
> 
> Yes, I know the answer. When trying R, I'm surprised that R can't solve that
> either. I first noticed that PostgreSQL can't solve it, and found that they fixed
> that in pg 12.
> 
> https://www.postgresql.org/message-
> id/153313051300.1397.9594490737341194671%40wrigleys.postgresql.org
> 
> Therefore I come to ask whether someone know how to fix this in R, or I must
> submit it as a bug?
> 
> 2019/4/18 23:24, Michael Dewey:
> > Perhaps subtract 1506705766 from y?
> >
> > Saying some other software does it well implies you know what the
> > _correct_ answer is here but I would question what that means with
> > this sort of data-set.
> >
> > On 17/04/2019 07:26, Dingyuan Wang wrote:
> >> Hi,
> >>
> >> This input doesn't have any interesting properties except y is unix
> >> time. Spreadsheets can do this well.
> >> Is this a bug that lm can't do x ~ y?
> >>
> >> R version 3.5.2 (2018-12-20) -- "Eggshell Igloo"
> >> Copyright (C) 2018 The R Foundation for Statistical Computing
> >> Platform: x86_64-pc-linux-gnu (64-bit)
> >>
> >> ?> x = c(79.744, 123.904, 87.29601, 116.352, 67.71201, 72.96001,
> >> 101.632, 108.928, 94.08)
> >> ?> y = c(1506705739.385, 1506705766.895, 1506705746.293,
> >> 1506705761.873, 1506705734.743, 1506705735.351, 1506705756.26,
> >> 1506705761.307, 1506705747.372)
> >> ?> m = lm(x ~ y)
> >> ?> summary(m)
> >>
> >> Call:
> >> lm(formula = x ~ y)
> >>
> >> Residuals:
> >> ????? Min?????? 1Q?? Median?????? 3Q????? Max
> >> -27.0222 -14.9902? -0.6542? 14.1938? 29.1698
> >>
> >> Coefficients: (1 not defined because of singularities)
> >> ???????????? Estimate Std. Error t value Pr(>|t|)
> >> (Intercept)?? 94.734????? 6.511?? 14.55 4.88e-07 *** y
> >> NA???????? NA????? NA?????? NA
> >> ---
> >> Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >>
> >> Residual standard error: 19.53 on 8 degrees of freedom
> >>
> >> ?> summary(lm(y ~ x))
> >>
> >> Call:
> >> lm(formula = y ~ x)
> >>
> >> Residuals:
> >> ???? Min????? 1Q? Median????? 3Q???? Max
> >> -2.1687 -1.3345 -0.9466? 1.3826? 2.6551
> >>
> >> Coefficients:
> >> ????????????? Estimate Std. Error?? t value Pr(>|t|)
> >> (Intercept) 1.507e+09? 3.294e+00 4.574e+08? < 2e-16 *** x
> >> 6.136e-01? 3.413e-02 1.798e+01 4.07e-07 ***
> >> ---
> >> Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >>
> >> Residual standard error: 1.885 on 7 degrees of freedom Multiple
> >> R-squared:? 0.9788,??? Adjusted R-squared:? 0.9758
> >> F-statistic: 323.3 on 1 and 7 DF,? p-value: 4.068e-07
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ---
> >> This email has been checked for viruses by AVG.
> >> https://www.avg.com
> >>
> >>
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

From gumb|ex @end|ng |rom @o@c@|o  Fri Apr 19 06:34:29 2019
From: gumb|ex @end|ng |rom @o@c@|o (Dingyuan Wang)
Date: Fri, 19 Apr 2019 12:34:29 +0800
Subject: [R] lm fails on some large input
In-Reply-To: <21692899-DD30-4349-A0B8-BC10D638ADAD@dcn.davis.ca.us>
References: <836dfcbe-d2e5-7b96-86aa-a1e33b6db966@aosc.io>
 <bef865ce-3f89-24d0-18b7-6653cdd59449@dewey.myzen.co.uk>
 <20645481-ad46-0570-104f-acee78c60566@aosc.io>
 <21692899-DD30-4349-A0B8-BC10D638ADAD@dcn.davis.ca.us>
Message-ID: <fcb67cef-9d43-1da2-05e9-1635657af3ea@aosc.io>

The final goal is to make two lines and find the intersection point.
I don't want to argue more about the reason.

The tol suggestion is reasonable, and I'll take that.

2019/4/19 4:12, Jeff Newmiller:
> The fact that you think x~y is interchangeable with y~x suggests to me that you will have a difficult time convincing R Core that this is a bug. I recommend that you take at leastan upper division college course in linear regression first.
> 
> On April 18, 2019 9:35:55 AM PDT, Dingyuan Wang <gumblex at aosc.io> wrote:
>> I just want to make a line out of timestamps vs some coordinates, so
>> y~x
>> or x~y doesn't matter.
>>
>> Yes, I know the answer. When trying R, I'm surprised that R can't solve
>>
>> that either. I first noticed that PostgreSQL can't solve it, and found
>> that they fixed that in pg 12.
>>
>> https://www.postgresql.org/message-id/153313051300.1397.9594490737341194671%40wrigleys.postgresql.org
>>
>> Therefore I come to ask whether someone know how to fix this in R, or I
>>
>> must submit it as a bug?
>>
>> 2019/4/18 23:24, Michael Dewey:
>>> Perhaps subtract 1506705766 from y?
>>>
>>> Saying some other software does it well implies you know what the
>>> _correct_ answer is here but I would question what that means with
>> this
>>> sort of data-set.
>>>
>>> On 17/04/2019 07:26, Dingyuan Wang wrote:
>>>> Hi,
>>>>
>>>> This input doesn't have any interesting properties except y is unix
>>>> time. Spreadsheets can do this well.
>>>> Is this a bug that lm can't do x ~ y?
>>>>
>>>> R version 3.5.2 (2018-12-20) -- "Eggshell Igloo"
>>>> Copyright (C) 2018 The R Foundation for Statistical Computing
>>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>>>
>>>>  ?> x = c(79.744, 123.904, 87.29601, 116.352, 67.71201, 72.96001,
>>>> 101.632, 108.928, 94.08)
>>>>  ?> y = c(1506705739.385, 1506705766.895, 1506705746.293,
>>>> 1506705761.873, 1506705734.743, 1506705735.351, 1506705756.26,
>>>> 1506705761.307, 1506705747.372)
>>>>  ?> m = lm(x ~ y)
>>>>  ?> summary(m)
>>>>
>>>> Call:
>>>> lm(formula = x ~ y)
>>>>
>>>> Residuals:
>>>>  ????? Min?????? 1Q?? Median?????? 3Q????? Max
>>>> -27.0222 -14.9902? -0.6542? 14.1938? 29.1698
>>>>
>>>> Coefficients: (1 not defined because of singularities)
>>>>  ???????????? Estimate Std. Error t value Pr(>|t|)
>>>> (Intercept)?? 94.734????? 6.511?? 14.55 4.88e-07 ***
>>>> y???????????????? NA???????? NA????? NA?????? NA
>>>> ---
>>>> Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>
>>>> Residual standard error: 19.53 on 8 degrees of freedom
>>>>
>>>>  ?> summary(lm(y ~ x))
>>>>
>>>> Call:
>>>> lm(formula = y ~ x)
>>>>
>>>> Residuals:
>>>>  ???? Min????? 1Q? Median????? 3Q???? Max
>>>> -2.1687 -1.3345 -0.9466? 1.3826? 2.6551
>>>>
>>>> Coefficients:
>>>>  ????????????? Estimate Std. Error?? t value Pr(>|t|)
>>>> (Intercept) 1.507e+09? 3.294e+00 4.574e+08? < 2e-16 ***
>>>> x?????????? 6.136e-01? 3.413e-02 1.798e+01 4.07e-07 ***
>>>> ---
>>>> Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>>
>>>> Residual standard error: 1.885 on 7 degrees of freedom
>>>> Multiple R-squared:? 0.9788,??? Adjusted R-squared:? 0.9758
>>>> F-statistic: 323.3 on 1 and 7 DF,? p-value: 4.068e-07
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> ---
>>>> This email has been checked for viruses by AVG.
>>>> https://www.avg.com
>>>>
>>>>
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Fri Apr 19 07:12:23 2019
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Fri, 19 Apr 2019 07:12:23 +0200
Subject: [R] Pause script at input from terminal (interactive use)
In-Reply-To: <CAFEqCdzWfcoSF42G2TD25SVdMcWaqeZa7sAeM-XQSGTRSrtDnA@mail.gmail.com>
References: <CAMk+s2TaC0mXOs_s2NFWsRxj0g_sxomRbaaU4N0ZoDTmSfiVtg@mail.gmail.com>
 <CAFEqCdzWfcoSF42G2TD25SVdMcWaqeZa7sAeM-XQSGTRSrtDnA@mail.gmail.com>
Message-ID: <CAMk+s2T=wtHT2uv659P8QkGRit=X-cS-kHR8_PTSqAqxmMtNFw@mail.gmail.com>

I am realizing as well that R is not the best option for an
interactive session. I changed the script to get the input from a
config file; it is less elegant because the procedure now requires
double the files than with CLI input, but at the end of the day is
more practical when most of the answer remains the same between
sessions. Thanks.

On Thu, Apr 18, 2019 at 8:47 PM Greg Snow <538280 at gmail.com> wrote:
>
> I am not an expert on Rscript, but I don't think that an actual
> terminal is ever used when using Rscript.  And `interactive()` will
> probably always be false.
>
> So if you want the script to pause for input, you need to have some
> form of user interface to work with.
>
> One option is to use the tcltk package (this works on all OS's to my
> knowledge, but not if you are accessing the computer remotely).  This
> answer on stack overflow shows some code that may help:
> https://stackoverflow.com/questions/16847621/get-data-out-of-a-tcltk-function/16847918#16847918
>
>
> On Thu, Apr 18, 2019 at 8:11 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> >
> > Dear all,
> > I am trying to write an interactive script where the user type some
> > input from the terminal. I used readline() but when I launch the file
> > with Rscript, the function is overwritten directly, there is no
> > waiting for the user's input. For instance, this example:
> >
> > VAR1 = as.numeric(readline(prompt = "Enter something -> "))
> > VAR2 = as.numeric(readline(prompt = "Enter something else -> "))
> > if(is.na(VAR1)) VAR1 = 0
> > if(is.na(VAR2)) VAR2 = "empty"
> > cat("Input was: ", VAR1, " - ", VAR2, "\n")
> >
> > is executed till the end without typing anything on terminal :
> >
> > $ Rscript test.R
> > Enter something ->
> > Enter something else ->
> > Input was:  0  -  empty
> >
> > I also tried with ',1' at the end of readline, but the effect is the
> > same. I should use the interactive() function but I am confused on its
> > use.
> > It is possible to launch R scritps in the interactive mode in the
> > first place? and if yes, how? Or would python or julia be better
> > choices in this case?
> > Thank you.
> > --
> > Best regards,
> > Luigi
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com



-- 
Best regards,
Luigi


From g@@@uu| @end|ng |rom gm@||@com  Fri Apr 19 02:25:39 2019
From: g@@@uu| @end|ng |rom gm@||@com (ani jaya)
Date: Fri, 19 Apr 2019 09:25:39 +0900
Subject: [R] Looping with looping
In-Reply-To: <CAFEqCdyrLG-vzYBq7jeUe=YUM-0h8Sxjc+nTFNNnNq4hUgdeZQ@mail.gmail.com>
References: <CAHXS41w+=pbxPS9maMiqN4_hAv54MVLYfV+c=+jrfo2yNpAFSA@mail.gmail.com>
 <CAFEqCdyrLG-vzYBq7jeUe=YUM-0h8Sxjc+nTFNNnNq4hUgdeZQ@mail.gmail.com>
Message-ID: <CAHXS41xE1=TX-11G2PQFz7M6Up9d-YaU3DkqaSGL5p5F46Lobg@mail.gmail.com>

Thank you very much, Dr. Snow, your suggestion helps a lot.

Best,
Saat

On Fri, Apr 19, 2019 at 4:14 AM Greg Snow <538280 at gmail.com> wrote:

> When the goal of looping is to compute something and save each
> iteration into a vector or list, then it is usually easier to use the
> lapply/sapply/replicate functions and save the result into a single
> list rather than a bunch of global variables.
>
> Here is a quick example that does the same computations as your code,
> but save the results into a list where each element is a vector of
> length 100:
>
> sam<-c(9,7,8,6,6,7,8,6,7,3)
> a <- lapply(2:9, function(k){
>   replicate(100, mean(sample(sam, k, replace=TRUE)))
> })
>
> # optional
> names(a) <- sprintf("a%i", 2:9)
>
> hist(a[["a2"]]
> hist(a$a9)
> w <- "a5"
> hist(a[[w]])
>
>
> Saving everything into a single list (or matrix/array/etc.) makes it
> easier to loop over all of the results later on (and prevents the hard
> to track down bugs from using dynamically named global variables).
> Here is an example based on the results from above:
>
> par(mfrow=c(3,3))
> for(i in seq_along(a)) {
>   hist(a[[i]], xlab='x', main=sprintf("k = %i", (2:9)[i]))
> }
>
>
>
>
>
> On Thu, Apr 18, 2019 at 9:19 AM ani jaya <gaaauul at gmail.com> wrote:
> >
> > Dear R community,
> >
> > I'm trying to create a looping to see the effect of number of samples
> from
> > one dataset.
> > Lets say I have 10 values in a single data frame and I want to see the
> mean
> > of each sampling let say from 2-9 number of sampling. But I want to do
> the
> > repetition let say up to 100 for each number of sampling and put it in a
> > different dataframe, let say a2,a3,a4,... which contain a2[1] is the mean
> > of first repetition and so on. I believe this is possible but I'm newbie
> > here.
> >
> > > version
> >
> > platform       x86_64-w64-mingw32
> > arch           x86_64
> > os             mingw32
> > system         x86_64, mingw32
> > status
> > major          3
> > minor          5.3
> > year           2019
> > month          03
> > day            11
> > svn rev        76217
> > language       R
> > version.string R version 3.5.3 (2019-03-11)
> > nickname       Great Truth
> >
> >
> >  The simple code that I have:
> >
> > sam<-c(9,7,8,6,6,7,8,6,7,3)
> > for (k in seq(2,9,1)){
> >     a <- numeric(100)
> >       for (i in 1:100){
> >       a[i] <- mean(sample(sam,k,replace=T))
> >
> >       }
> >   }
> >
> > I can do enough with this code but i want to the variable name also
> > move based on k.
> >
> > I have googling enough and meet assign and paste command but not really
> help.
> > Any help would be appreciate.
> >
> >
> >
> > Best,
> >
> > Saat M.
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
>

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Fri Apr 19 10:25:29 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Fri, 19 Apr 2019 11:25:29 +0300
Subject: [R] Pause script at input from terminal (interactive use)
In-Reply-To: <CAMk+s2TaC0mXOs_s2NFWsRxj0g_sxomRbaaU4N0ZoDTmSfiVtg@mail.gmail.com>
References: <CAMk+s2TaC0mXOs_s2NFWsRxj0g_sxomRbaaU4N0ZoDTmSfiVtg@mail.gmail.com>
Message-ID: <20190419112529.0361c560@Tarkus>

On Thu, 18 Apr 2019 16:10:41 +0200
Luigi Marongiu <marongiu.luigi at gmail.com> wrote:

> It is possible to launch R scritps in the interactive mode in the
> first place? and if yes, how?

One option would be to use littler
<http://dirk.eddelbuettel.com/code/littler.html> with its -i
(--interactive) option.

-- 
Best regards,
Ivan


From @k@h@y_e4 @end|ng |rom hotm@||@com  Fri Apr 19 12:12:06 2019
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Fri, 19 Apr 2019 10:12:06 +0000
Subject: [R] picewise function in nls....
In-Reply-To: <20190418142039.660f3ed1@trisector>
References: <SL2P216MB00917CB471C1477FC9B0FDCDC8260@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>,
 <20190418142039.660f3ed1@trisector>
Message-ID: <SL2P216MB009199CC81EC4D6C452EF8B8C8270@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear Ivan,
                   THanks for the reply......But what do you mean by "since fx does not depend on any of the parameters you
optimize in the nls() call."? Can you give an example?

very many thanks for your time and effort.....
Yours sincerely,

AKSHAY M KULKARNI



________________________________
From: Ivan Krylov <krylov.r00t at gmail.com>
Sent: Thursday, April 18, 2019 4:50 PM
To: akshay kulkarni
Cc: R help Mailing list
Subject: Re: [R] picewise function in nls....

On Thu, 18 Apr 2019 10:36:10 +0000
akshay kulkarni <akshay_e4 at hotmail.com> wrote:

> fx <-   (x1 <= -2)*(x1^2) + (x1 > -2 && x1 < 2)*(x1^3) + (x1 > =
> 2)*(x1^4)
>
> Can I include fx in an nls call  to create something like this:
>
> NLS1 <- nls(y ~ a*(sin(x2) + fx), start = list(a = 2))   ?

For now, you can, since fx does not depend on any of the parameters you
optimize in the nls() call. (Actually, the model as presented should be
solveable by lm(y ~ I(sin(x2) + fx) + 0), since it is linear in its
only parameter.)

If you make fx a function and use ifelse() to provide different
outcomes depending on a condition in a vectorized fashion, you would
make it easier to add new parameters later, should the need arise:

fx <- function(x1, x2)
        ifelse(x1 <= -2, EXPR_IF_TRUE..., EXPR_IF_FALSE...)

NLS1 <- nls(y ~ a*(sin(x2) + fx(x1, x2)), ...)

--
Best regards,
Ivan

	[[alternative HTML version deleted]]


From kry|ov@r00t @end|ng |rom gm@||@com  Fri Apr 19 12:29:08 2019
From: kry|ov@r00t @end|ng |rom gm@||@com (Ivan Krylov)
Date: Fri, 19 Apr 2019 13:29:08 +0300
Subject: [R] picewise function in nls....
In-Reply-To: <SL2P216MB009199CC81EC4D6C452EF8B8C8270@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00917CB471C1477FC9B0FDCDC8260@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <20190418142039.660f3ed1@trisector>
 <SL2P216MB009199CC81EC4D6C452EF8B8C8270@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <20190419132908.1c28021a@trisector>

On Fri, 19 Apr 2019 10:12:06 +0000
akshay kulkarni <akshay_e4 at hotmail.com> wrote:

> But what do you mean by "since fx does not depend on any of the
> parameters you optimize in the nls() call."? Can you give an example?

By "parameters you optimize in the nls() call" I mean `a`. `a` does
not seem to be used in the calculation of `fx`. If it were, it would
have to look like:

fx <- function(x1, x2, a) { ... }
nls(y ~ a*(sin(x2) + fx(x1, x2, a)), start = list(a = ...))

so that nls() would be able to check different values of `a`.

-- 
Best regards,
Ivan


From mcg@rvey@bern@rd @end|ng |rom comc@@t@net  Fri Apr 19 12:38:18 2019
From: mcg@rvey@bern@rd @end|ng |rom comc@@t@net (Bernard Comcast)
Date: Fri, 19 Apr 2019 06:38:18 -0400
Subject: [R] Pause script at input from terminal (interactive use)
In-Reply-To: <CAMk+s2T=wtHT2uv659P8QkGRit=X-cS-kHR8_PTSqAqxmMtNFw@mail.gmail.com>
References: <CAMk+s2TaC0mXOs_s2NFWsRxj0g_sxomRbaaU4N0ZoDTmSfiVtg@mail.gmail.com>
 <CAFEqCdzWfcoSF42G2TD25SVdMcWaqeZa7sAeM-XQSGTRSrtDnA@mail.gmail.com>
 <CAMk+s2T=wtHT2uv659P8QkGRit=X-cS-kHR8_PTSqAqxmMtNFw@mail.gmail.com>
Message-ID: <30A83F0A-1DFC-48C7-BC15-96615272C539@comcast.net>

I have used the shiny package to create a web page user interface and it works well.

Bernard
Sent from my iPhone so please excuse the spelling!"

> On Apr 19, 2019, at 1:12 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> 
> I am realizing as well that R is not the best option for an
> interactive session. I changed the script to get the input from a
> config file; it is less elegant because the procedure now requires
> double the files than with CLI input, but at the end of the day is
> more practical when most of the answer remains the same between
> sessions. Thanks.
> 
>> On Thu, Apr 18, 2019 at 8:47 PM Greg Snow <538280 at gmail.com> wrote:
>> 
>> I am not an expert on Rscript, but I don't think that an actual
>> terminal is ever used when using Rscript.  And `interactive()` will
>> probably always be false.
>> 
>> So if you want the script to pause for input, you need to have some
>> form of user interface to work with.
>> 
>> One option is to use the tcltk package (this works on all OS's to my
>> knowledge, but not if you are accessing the computer remotely).  This
>> answer on stack overflow shows some code that may help:
>> https://stackoverflow.com/questions/16847621/get-data-out-of-a-tcltk-function/16847918#16847918
>> 
>> 
>>> On Thu, Apr 18, 2019 at 8:11 AM Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>>> 
>>> Dear all,
>>> I am trying to write an interactive script where the user type some
>>> input from the terminal. I used readline() but when I launch the file
>>> with Rscript, the function is overwritten directly, there is no
>>> waiting for the user's input. For instance, this example:
>>> 
>>> VAR1 = as.numeric(readline(prompt = "Enter something -> "))
>>> VAR2 = as.numeric(readline(prompt = "Enter something else -> "))
>>> if(is.na(VAR1)) VAR1 = 0
>>> if(is.na(VAR2)) VAR2 = "empty"
>>> cat("Input was: ", VAR1, " - ", VAR2, "\n")
>>> 
>>> is executed till the end without typing anything on terminal :
>>> 
>>> $ Rscript test.R
>>> Enter something ->
>>> Enter something else ->
>>> Input was:  0  -  empty
>>> 
>>> I also tried with ',1' at the end of readline, but the effect is the
>>> same. I should use the interactive() function but I am confused on its
>>> use.
>>> It is possible to launch R scritps in the interactive mode in the
>>> first place? and if yes, how? Or would python or julia be better
>>> choices in this case?
>>> Thank you.
>>> --
>>> Best regards,
>>> Luigi
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>> --
>> Gregory (Greg) L. Snow Ph.D.
>> 538280 at gmail.com
> 
> 
> 
> -- 
> Best regards,
> Luigi
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @k@h@y_e4 @end|ng |rom hotm@||@com  Fri Apr 19 20:55:44 2019
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Fri, 19 Apr 2019 18:55:44 +0000
Subject: [R] picewise function in nls....
In-Reply-To: <20190419132908.1c28021a@trisector>
References: <SL2P216MB00917CB471C1477FC9B0FDCDC8260@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <20190418142039.660f3ed1@trisector>
 <SL2P216MB009199CC81EC4D6C452EF8B8C8270@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>,
 <20190419132908.1c28021a@trisector>
Message-ID: <SL2P216MB0091FBFB59F1215C6AE7AF18C8270@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear Ivan,
                       Thanks a lot....!

yours sincerely,
AKSHAY M KULKARNI

________________________________
From: Ivan Krylov <krylov.r00t at gmail.com>
Sent: Friday, April 19, 2019 3:59 PM
To: akshay kulkarni
Cc: R help Mailing list
Subject: Re: [R] picewise function in nls....

On Fri, 19 Apr 2019 10:12:06 +0000
akshay kulkarni <akshay_e4 at hotmail.com> wrote:

> But what do you mean by "since fx does not depend on any of the
> parameters you optimize in the nls() call."? Can you give an example?

By "parameters you optimize in the nls() call" I mean `a`. `a` does
not seem to be used in the calculation of `fx`. If it were, it would
have to look like:

fx <- function(x1, x2, a) { ... }
nls(y ~ a*(sin(x2) + fx(x1, x2, a)), start = list(a = ...))

so that nls() would be able to check different values of `a`.

--
Best regards,
Ivan

	[[alternative HTML version deleted]]


From p_conno||y @end|ng |rom @||ng@hot@co@nz  Fri Apr 19 23:03:00 2019
From: p_conno||y @end|ng |rom @||ng@hot@co@nz (Patrick Connolly)
Date: Sat, 20 Apr 2019 09:03:00 +1200
Subject: [R] Debugging Rmarkdown
In-Reply-To: <CAJuCY5y4EAw1-uSyz0JGP2D9N8b4dTgGuLwwfKn2QBzyzRRkzg@mail.gmail.com>
References: <20190418095225.GA4472@slingshot.co.nz>
 <CAJuCY5y4EAw1-uSyz0JGP2D9N8b4dTgGuLwwfKn2QBzyzRRkzg@mail.gmail.com>
Message-ID: <41e7a5fe-0041-e720-c839-6998cd9d65b7@slingshot.co.nz>


On 19/04/19 12:13 AM, Thierry Onkelinx wrote:
> Dear Patrick,
>
> This is not easy to debug without a reprex
>
> I would check the content of zzz and wide.i in the loop
>
> str(wide.i)
> ?zzz <- rbind(zzz, wide.i)
> str(zzz)
>
That's just what I'm trying to achieve but the debugging doesn't work 
how it does with regular R code.

> Note that the Rmd always runs in a clean environment. This might 
> explain the difference
>
The data frames xx and yy are defined in earlier code chunks. Maybe I 
need to define them again.


I'll look closer at it after Easter.


Thanks for the suggestion.

> Best regards,
>
> ir. Thierry Onkelinx
> Statisticus / Statistician
>
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE 
> AND FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be <http://www.inbo.be>
>
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no 
> more than asking him to perform a post-mortem examination: he may be 
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does 
> not ensure that a reasonable answer can be extracted from a given body 
> of data. ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
>
> <https://www.inbo.be>
>
>
> Op do 18 apr. 2019 om 11:53 schreef Patrick Connolly 
> <p_connolly at slingshot.co.nz <mailto:p_connolly at slingshot.co.nz>>:
>
>     I have a function that works in ESS, but it fails if I include it in
>     an .Rmd file that I tried to knit using Rstudio.? I found advice at:
>     https://www.rstudio.com/products/rstudio/release-notes/debugging-with-rstudio/
>
>     It seems to be not referring to markdown files.? Somewhere else
>     suggested calling render() in the console pane.? I tried that.? The
>     browser() function interrupts correctly, but I can't find out what the
>     object zzz in the code below looks like.? Nothing prints the way it
>     would in a "normal" R buffer.
>
>     code outline:? making zzz out of two dataframes xx and yy
>
>     ##
>     ? ? zzz <- NULL
>     ? ? for(i in xx$Sample){
>     ? ? ? ? raw.i <- <stuff>
>
>     ? ? ? ? etc. etc.
>
>     ? ? ? ? zzz <- rbind(zzz, wide.i)
>     }
>     ? ?browser()
>
>     ? ? names(zzz) <- c("Cultivar", "Test", "Change")
>     That line fails, with a complaint about zzz being NULL.
>
>     It appears as though the rbind doesn't do anything, but I can't see
>     what wide.i looks like to get an idea what could be the cause.
>
>     Ideas what I should try are welcome.? I have no idea why the code
>     works in an R environment but not an Rmd one.
>
>
>     R-3.5.2,
>     platform? ? ? ?x86_64-pc-linux-gnu
>     arch? ? ? ? ? ?x86_64
>     os? ? ? ? ? ? ?linux-gnu
>     system? ? ? ? ?x86_64, linux-gnu
>
>     Rstudio Version 1.1.383
>
>
>
>     -- 
>     ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>
>     ? ?___? ? Patrick Connolly
>     ?{~._.~}? ? ? ? ? ? ? ? ? ?Great minds discuss ideas
>     ?_( Y )_? ? ? ? ? ? ? ? ?Average minds discuss events
>     (:_~*~_:)? ? ? ? ? ? ? ? ? Small minds discuss people
>     ?(_)-(_)? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ..... Eleanor Roosevelt
>
>     ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Apr 19 23:44:51 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 19 Apr 2019 14:44:51 -0700
Subject: [R] Debugging Rmarkdown
In-Reply-To: <41e7a5fe-0041-e720-c839-6998cd9d65b7@slingshot.co.nz>
References: <20190418095225.GA4472@slingshot.co.nz>
 <CAJuCY5y4EAw1-uSyz0JGP2D9N8b4dTgGuLwwfKn2QBzyzRRkzg@mail.gmail.com>
 <41e7a5fe-0041-e720-c839-6998cd9d65b7@slingshot.co.nz>
Message-ID: <C1CE750F-6C69-4781-9E92-1FE1E1F4B0DF@dcn.davis.ca.us>

I just run each chunk in sequence starting from an fresh restart of R by copying code to the R console. However you can use knitr::purl to extract all of the code into a regular R script to do whatever debugging you are most familiar with.

On April 19, 2019 2:03:00 PM PDT, Patrick Connolly <p_connolly at slingshot.co.nz> wrote:
>
>On 19/04/19 12:13 AM, Thierry Onkelinx wrote:
>> Dear Patrick,
>>
>> This is not easy to debug without a reprex
>>
>> I would check the content of zzz and wide.i in the loop
>>
>> str(wide.i)
>> ?zzz <- rbind(zzz, wide.i)
>> str(zzz)
>>
>That's just what I'm trying to achieve but the debugging doesn't work 
>how it does with regular R code.
>
>> Note that the Rmd always runs in a clean environment. This might 
>> explain the difference
>>
>The data frames xx and yy are defined in earlier code chunks. Maybe I 
>need to define them again.
>
>
>I'll look closer at it after Easter.
>
>
>Thanks for the suggestion.
>
>> Best regards,
>>
>> ir. Thierry Onkelinx
>> Statisticus / Statistician
>>
>> Vlaamse Overheid / Government of Flanders
>> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR
>NATURE 
>> AND FOREST
>> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
>> thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
>> Havenlaan 88 bus 73, 1000 Brussel
>> www.inbo.be <http://www.inbo.be>
>>
>>
>///////////////////////////////////////////////////////////////////////////////////////////
>> To call in the statistician after the experiment is done may be no 
>> more than asking him to perform a post-mortem examination: he may be 
>> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does 
>> not ensure that a reasonable answer can be extracted from a given
>body 
>> of data. ~ John Tukey
>>
>///////////////////////////////////////////////////////////////////////////////////////////
>>
>> <https://www.inbo.be>
>>
>>
>> Op do 18 apr. 2019 om 11:53 schreef Patrick Connolly 
>> <p_connolly at slingshot.co.nz <mailto:p_connolly at slingshot.co.nz>>:
>>
>>     I have a function that works in ESS, but it fails if I include it
>in
>>     an .Rmd file that I tried to knit using Rstudio.? I found advice
>at:
>>    
>https://www.rstudio.com/products/rstudio/release-notes/debugging-with-rstudio/
>>
>>     It seems to be not referring to markdown files.? Somewhere else
>>     suggested calling render() in the console pane.? I tried that.?
>The
>>     browser() function interrupts correctly, but I can't find out
>what the
>>     object zzz in the code below looks like.? Nothing prints the way
>it
>>     would in a "normal" R buffer.
>>
>>     code outline:? making zzz out of two dataframes xx and yy
>>
>>     ##
>>     ? ? zzz <- NULL
>>     ? ? for(i in xx$Sample){
>>     ? ? ? ? raw.i <- <stuff>
>>
>>     ? ? ? ? etc. etc.
>>
>>     ? ? ? ? zzz <- rbind(zzz, wide.i)
>>     }
>>     ? ?browser()
>>
>>     ? ? names(zzz) <- c("Cultivar", "Test", "Change")
>>     That line fails, with a complaint about zzz being NULL.
>>
>>     It appears as though the rbind doesn't do anything, but I can't
>see
>>     what wide.i looks like to get an idea what could be the cause.
>>
>>     Ideas what I should try are welcome.? I have no idea why the code
>>     works in an R environment but not an Rmd one.
>>
>>
>>     R-3.5.2,
>>     platform? ? ? ?x86_64-pc-linux-gnu
>>     arch? ? ? ? ? ?x86_64
>>     os? ? ? ? ? ? ?linux-gnu
>>     system? ? ? ? ?x86_64, linux-gnu
>>
>>     Rstudio Version 1.1.383
>>
>>
>>
>>     -- 
>>    
>~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>>
>>     ? ?___? ? Patrick Connolly
>>     ?{~._.~}? ? ? ? ? ? ? ? ? ?Great minds discuss ideas
>>     ?_( Y )_? ? ? ? ? ? ? ? ?Average minds discuss events
>>     (:_~*~_:)? ? ? ? ? ? ? ? ? Small minds discuss people
>>     ?(_)-(_)? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ..... Eleanor Roosevelt
>>
>>    
>~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>>
>>     ______________________________________________
>>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>--
>>     To UNSUBSCRIBE and more, see
>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>     PLEASE do read the posting guide
>>     http://www.R-project.org/posting-guide.html
>>     and provide commented, minimal, self-contained, reproducible
>code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @end|ng |rom gm@||@com  Fri Apr 19 23:50:41 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 19 Apr 2019 14:50:41 -0700
Subject: [R] Debugging Rmarkdown
In-Reply-To: <41e7a5fe-0041-e720-c839-6998cd9d65b7@slingshot.co.nz>
References: <20190418095225.GA4472@slingshot.co.nz>
 <CAJuCY5y4EAw1-uSyz0JGP2D9N8b4dTgGuLwwfKn2QBzyzRRkzg@mail.gmail.com>
 <41e7a5fe-0041-e720-c839-6998cd9d65b7@slingshot.co.nz>
Message-ID: <CAGxFJbR2Jj=oqnyaSkVs_OvS6EFyTZRRiTJ0hgzYbg-1f=Nzng@mail.gmail.com>

This might be offbase, but do you need to set options to cache the results
in the original code chunks to reuse in later chunks? (I haven't worked
with knitr lately, so this may be nonsense).

Cheers,
Bert

On Fri, Apr 19, 2019 at 2:03 PM Patrick Connolly <p_connolly at slingshot.co.nz>
wrote:

>
> On 19/04/19 12:13 AM, Thierry Onkelinx wrote:
> > Dear Patrick,
> >
> > This is not easy to debug without a reprex
> >
> > I would check the content of zzz and wide.i in the loop
> >
> > str(wide.i)
> >  zzz <- rbind(zzz, wide.i)
> > str(zzz)
> >
> That's just what I'm trying to achieve but the debugging doesn't work
> how it does with regular R code.
>
> > Note that the Rmd always runs in a clean environment. This might
> > explain the difference
> >
> The data frames xx and yy are defined in earlier code chunks. Maybe I
> need to define them again.
>
>
> I'll look closer at it after Easter.
>
>
> Thanks for the suggestion.
>
> > Best regards,
> >
> > ir. Thierry Onkelinx
> > Statisticus / Statistician
> >
> > Vlaamse Overheid / Government of Flanders
> > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE
> > AND FOREST
> > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> > thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
> > Havenlaan 88 bus 73, 1000 Brussel
> > www.inbo.be <http://www.inbo.be>
> >
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> > To call in the statistician after the experiment is done may be no
> > more than asking him to perform a post-mortem examination: he may be
> > able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does
> > not ensure that a reasonable answer can be extracted from a given body
> > of data. ~ John Tukey
> >
> ///////////////////////////////////////////////////////////////////////////////////////////
> >
> > <https://www.inbo.be>
> >
> >
> > Op do 18 apr. 2019 om 11:53 schreef Patrick Connolly
> > <p_connolly at slingshot.co.nz <mailto:p_connolly at slingshot.co.nz>>:
> >
> >     I have a function that works in ESS, but it fails if I include it in
> >     an .Rmd file that I tried to knit using Rstudio.  I found advice at:
> >
> https://www.rstudio.com/products/rstudio/release-notes/debugging-with-rstudio/
> >
> >     It seems to be not referring to markdown files.  Somewhere else
> >     suggested calling render() in the console pane.  I tried that.  The
> >     browser() function interrupts correctly, but I can't find out what
> the
> >     object zzz in the code below looks like.  Nothing prints the way it
> >     would in a "normal" R buffer.
> >
> >     code outline:  making zzz out of two dataframes xx and yy
> >
> >     ##
> >         zzz <- NULL
> >         for(i in xx$Sample){
> >             raw.i <- <stuff>
> >
> >             etc. etc.
> >
> >             zzz <- rbind(zzz, wide.i)
> >     }
> >        browser()
> >
> >         names(zzz) <- c("Cultivar", "Test", "Change")
> >     That line fails, with a complaint about zzz being NULL.
> >
> >     It appears as though the rbind doesn't do anything, but I can't see
> >     what wide.i looks like to get an idea what could be the cause.
> >
> >     Ideas what I should try are welcome.  I have no idea why the code
> >     works in an R environment but not an Rmd one.
> >
> >
> >     R-3.5.2,
> >     platform       x86_64-pc-linux-gnu
> >     arch           x86_64
> >     os             linux-gnu
> >     system         x86_64, linux-gnu
> >
> >     Rstudio Version 1.1.383
> >
> >
> >
> >     --
> >
>  ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
> >
> >        ___    Patrick Connolly
> >      {~._.~}                   Great minds discuss ideas
> >      _( Y )_                 Average minds discuss events
> >     (:_~*~_:)                  Small minds discuss people
> >      (_)-(_)                              ..... Eleanor Roosevelt
> >
> >
>  ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
> >
> >     ______________________________________________
> >     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
> >     To UNSUBSCRIBE and more, see
> >     https://stat.ethz.ch/mailman/listinfo/r-help
> >     PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >     and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From p_conno||y @end|ng |rom @||ng@hot@co@nz  Sat Apr 20 00:00:33 2019
From: p_conno||y @end|ng |rom @||ng@hot@co@nz (Patrick Connolly)
Date: Sat, 20 Apr 2019 10:00:33 +1200
Subject: [R] Debugging Rmarkdown
In-Reply-To: <CAGxFJbR2Jj=oqnyaSkVs_OvS6EFyTZRRiTJ0hgzYbg-1f=Nzng@mail.gmail.com>
References: <20190418095225.GA4472@slingshot.co.nz>
 <CAJuCY5y4EAw1-uSyz0JGP2D9N8b4dTgGuLwwfKn2QBzyzRRkzg@mail.gmail.com>
 <41e7a5fe-0041-e720-c839-6998cd9d65b7@slingshot.co.nz>
 <CAGxFJbR2Jj=oqnyaSkVs_OvS6EFyTZRRiTJ0hgzYbg-1f=Nzng@mail.gmail.com>
Message-ID: <fce4bf00-42a8-d408-bfc9-bd818fdb4199@slingshot.co.nz>

There are options to set echo and messages but AFAIK, the text appears 
in the resultant file, but if the script fails, there's no file to inspect.

On 20/04/19 9:50 AM, Bert Gunter wrote:
> This might be offbase, but do you need to set options to cache the 
> results in the original code chunks to reuse in later chunks? (I 
> haven't worked with knitr lately, so this may be nonsense).
>
> Cheers,
> Bert
>
> On Fri, Apr 19, 2019 at 2:03 PM Patrick Connolly 
> <p_connolly at slingshot.co.nz <mailto:p_connolly at slingshot.co.nz>> wrote:
>
>
>     On 19/04/19 12:13 AM, Thierry Onkelinx wrote:
>     > Dear Patrick,
>     >
>     > This is not easy to debug without a reprex
>     >
>     > I would check the content of zzz and wide.i in the loop
>     >
>     > str(wide.i)
>     > ?zzz <- rbind(zzz, wide.i)
>     > str(zzz)
>     >
>     That's just what I'm trying to achieve but the debugging doesn't work
>     how it does with regular R code.
>
>     > Note that the Rmd always runs in a clean environment. This might
>     > explain the difference
>     >
>     The data frames xx and yy are defined in earlier code chunks. Maybe I
>     need to define them again.
>
>
>     I'll look closer at it after Easter.
>
>
>     Thanks for the suggestion.
>
>     > Best regards,
>     >
>     > ir. Thierry Onkelinx
>     > Statisticus / Statistician
>     >
>     > Vlaamse Overheid / Government of Flanders
>     > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR
>     NATURE
>     > AND FOREST
>     > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality
>     Assurance
>     > thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
>     <mailto:thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>>
>     > Havenlaan 88 bus 73, 1000 Brussel
>     > www.inbo.be <http://www.inbo.be> <http://www.inbo.be>
>     >
>     >
>     ///////////////////////////////////////////////////////////////////////////////////////////
>     > To call in the statistician after the experiment is done may be no
>     > more than asking him to perform a post-mortem examination: he
>     may be
>     > able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
>     > The plural of anecdote is not data. ~ Roger Brinner
>     > The combination of some data and an aching desire for an answer
>     does
>     > not ensure that a reasonable answer can be extracted from a
>     given body
>     > of data. ~ John Tukey
>     >
>     ///////////////////////////////////////////////////////////////////////////////////////////
>     >
>     > <https://www.inbo.be>
>     >
>     >
>     > Op do 18 apr. 2019 om 11:53 schreef Patrick Connolly
>     > <p_connolly at slingshot.co.nz <mailto:p_connolly at slingshot.co.nz>
>     <mailto:p_connolly at slingshot.co.nz
>     <mailto:p_connolly at slingshot.co.nz>>>:
>     >
>     >? ? ?I have a function that works in ESS, but it fails if I
>     include it in
>     >? ? ?an .Rmd file that I tried to knit using Rstudio.? I found
>     advice at:
>     >
>     https://www.rstudio.com/products/rstudio/release-notes/debugging-with-rstudio/
>     >
>     >? ? ?It seems to be not referring to markdown files. Somewhere else
>     >? ? ?suggested calling render() in the console pane.? I tried
>     that.? The
>     >? ? ?browser() function interrupts correctly, but I can't find
>     out what the
>     >? ? ?object zzz in the code below looks like.? Nothing prints the
>     way it
>     >? ? ?would in a "normal" R buffer.
>     >
>     >? ? ?code outline:? making zzz out of two dataframes xx and yy
>     >
>     >? ? ?##
>     >? ? ?? ? zzz <- NULL
>     >? ? ?? ? for(i in xx$Sample){
>     >? ? ?? ? ? ? raw.i <- <stuff>
>     >
>     >? ? ?? ? ? ? etc. etc.
>     >
>     >? ? ?? ? ? ? zzz <- rbind(zzz, wide.i)
>     >? ? ?}
>     >? ? ?? ?browser()
>     >
>     >? ? ?? ? names(zzz) <- c("Cultivar", "Test", "Change")
>     >? ? ?That line fails, with a complaint about zzz being NULL.
>     >
>     >? ? ?It appears as though the rbind doesn't do anything, but I
>     can't see
>     >? ? ?what wide.i looks like to get an idea what could be the cause.
>     >
>     >? ? ?Ideas what I should try are welcome.? I have no idea why the
>     code
>     >? ? ?works in an R environment but not an Rmd one.
>     >
>     >
>     >? ? ?R-3.5.2,
>     >? ? ?platform? ? ? ?x86_64-pc-linux-gnu
>     >? ? ?arch? ? ? ? ? ?x86_64
>     >? ? ?os? ? ? ? ? ? ?linux-gnu
>     >? ? ?system? ? ? ? ?x86_64, linux-gnu
>     >
>     >? ? ?Rstudio Version 1.1.383
>     >
>     >
>     >
>     >? ? ?--
>     >
>     ?~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>     >
>     >? ? ?? ?___? ? Patrick Connolly
>     >? ? ??{~._.~}? ? ? ? ? ? ? ? ? ?Great minds discuss ideas
>     >? ? ??_( Y )_? ? ? ? ? ? ? ? ?Average minds discuss events
>     >? ? ?(:_~*~_:)? ? ? ? ? ? ? ? ? Small minds discuss people
>     >? ? ??(_)-(_)? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ..... Eleanor Roosevelt
>     >
>     >
>     ?~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>     >
>     >? ? ?______________________________________________
>     > R-help at r-project.org <mailto:R-help at r-project.org>
>     <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>     mailing list --
>     >? ? ?To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     >? ? ?PLEASE do read the posting guide
>     > http://www.R-project.org/posting-guide.html
>     >? ? ?and provide commented, minimal, self-contained, reproducible
>     code.
>     >
>
>     ? ? ? ? [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From |@enj@|bert @end|ng |rom y@hoo@|r  Fri Apr 19 09:17:18 2019
From: |@enj@|bert @end|ng |rom y@hoo@|r (Enjalbert Line)
Date: Fri, 19 Apr 2019 07:17:18 +0000 (UTC)
Subject: [R] Difference between cor_auto (qgraph package) and lavCor (lavaan
 package)
References: <339212555.2738575.1555658238817.ref@mail.yahoo.com>
Message-ID: <339212555.2738575.1555658238817@mail.yahoo.com>

Hello,
I would like to know the diffrence between 2 commands : cor_auto (from qgraph package) and lavCor (from lavaan package) to compute a polychoric correlation matrix in order to do a network analysis.
I have the responses to the SF-36 questionnaire (36 items with ordered responses) and I would like to have a polychoric correlation matrix by following the Sacha Epskamp's method.?But I have a warning if using cor_auto :??"Correlation matrix is not positive definite. Finding nearest positive definite matrix". I can ignore this warning or not ? Because I try to do a polychoric matrix in STATA software and I do not have a warning message.
And I don't understand the difference between lavCor command, because When I use lavCor, I do not have the warning message either.
//cor.auto1 <- cor_auto(Data_1it)
//cor.lav1<-lavCor(Data_1it, ordered=names(Data_1it))
Thank you in advance for your answer.?
Line


	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Apr 20 00:39:28 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 19 Apr 2019 15:39:28 -0700
Subject: [R] Debugging Rmarkdown
In-Reply-To: <fce4bf00-42a8-d408-bfc9-bd818fdb4199@slingshot.co.nz>
References: <20190418095225.GA4472@slingshot.co.nz>
 <CAJuCY5y4EAw1-uSyz0JGP2D9N8b4dTgGuLwwfKn2QBzyzRRkzg@mail.gmail.com>
 <41e7a5fe-0041-e720-c839-6998cd9d65b7@slingshot.co.nz>
 <CAGxFJbR2Jj=oqnyaSkVs_OvS6EFyTZRRiTJ0hgzYbg-1f=Nzng@mail.gmail.com>
 <fce4bf00-42a8-d408-bfc9-bd818fdb4199@slingshot.co.nz>
Message-ID: <D992F67D-E311-4AFA-A10F-7510607B5D6D@dcn.davis.ca.us>

Chunks are not isolated... they are executed in sequence in the same environment, starting with a fresh environment unrelated to whatever is present when you invoke render().

On April 19, 2019 3:00:33 PM PDT, Patrick Connolly <p_connolly at slingshot.co.nz> wrote:
>There are options to set echo and messages but AFAIK, the text appears 
>in the resultant file, but if the script fails, there's no file to
>inspect.
>
>On 20/04/19 9:50 AM, Bert Gunter wrote:
>> This might be offbase, but do you need to set options to cache the 
>> results in the original code chunks to reuse in later chunks? (I 
>> haven't worked with knitr lately, so this may be nonsense).
>>
>> Cheers,
>> Bert
>>
>> On Fri, Apr 19, 2019 at 2:03 PM Patrick Connolly 
>> <p_connolly at slingshot.co.nz <mailto:p_connolly at slingshot.co.nz>>
>wrote:
>>
>>
>>     On 19/04/19 12:13 AM, Thierry Onkelinx wrote:
>>     > Dear Patrick,
>>     >
>>     > This is not easy to debug without a reprex
>>     >
>>     > I would check the content of zzz and wide.i in the loop
>>     >
>>     > str(wide.i)
>>     > ?zzz <- rbind(zzz, wide.i)
>>     > str(zzz)
>>     >
>>     That's just what I'm trying to achieve but the debugging doesn't
>work
>>     how it does with regular R code.
>>
>>     > Note that the Rmd always runs in a clean environment. This
>might
>>     > explain the difference
>>     >
>>     The data frames xx and yy are defined in earlier code chunks.
>Maybe I
>>     need to define them again.
>>
>>
>>     I'll look closer at it after Easter.
>>
>>
>>     Thanks for the suggestion.
>>
>>     > Best regards,
>>     >
>>     > ir. Thierry Onkelinx
>>     > Statisticus / Statistician
>>     >
>>     > Vlaamse Overheid / Government of Flanders
>>     > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR
>>     NATURE
>>     > AND FOREST
>>     > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality
>>     Assurance
>>     > thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
>>     <mailto:thierry.onkelinx at inbo.be
><mailto:thierry.onkelinx at inbo.be>>
>>     > Havenlaan 88 bus 73, 1000 Brussel
>>     > www.inbo.be <http://www.inbo.be> <http://www.inbo.be>
>>     >
>>     >
>>    
>///////////////////////////////////////////////////////////////////////////////////////////
>>     > To call in the statistician after the experiment is done may be
>no
>>     > more than asking him to perform a post-mortem examination: he
>>     may be
>>     > able to say what the experiment died of. ~ Sir Ronald Aylmer
>Fisher
>>     > The plural of anecdote is not data. ~ Roger Brinner
>>     > The combination of some data and an aching desire for an answer
>>     does
>>     > not ensure that a reasonable answer can be extracted from a
>>     given body
>>     > of data. ~ John Tukey
>>     >
>>    
>///////////////////////////////////////////////////////////////////////////////////////////
>>     >
>>     > <https://www.inbo.be>
>>     >
>>     >
>>     > Op do 18 apr. 2019 om 11:53 schreef Patrick Connolly
>>     > <p_connolly at slingshot.co.nz <mailto:p_connolly at slingshot.co.nz>
>>     <mailto:p_connolly at slingshot.co.nz
>>     <mailto:p_connolly at slingshot.co.nz>>>:
>>     >
>>     >? ? ?I have a function that works in ESS, but it fails if I
>>     include it in
>>     >? ? ?an .Rmd file that I tried to knit using Rstudio.? I found
>>     advice at:
>>     >
>>    
>https://www.rstudio.com/products/rstudio/release-notes/debugging-with-rstudio/
>>     >
>>     >? ? ?It seems to be not referring to markdown files. Somewhere
>else
>>     >? ? ?suggested calling render() in the console pane.? I tried
>>     that.? The
>>     >? ? ?browser() function interrupts correctly, but I can't find
>>     out what the
>>     >? ? ?object zzz in the code below looks like.? Nothing prints
>the
>>     way it
>>     >? ? ?would in a "normal" R buffer.
>>     >
>>     >? ? ?code outline:? making zzz out of two dataframes xx and yy
>>     >
>>     >? ? ?##
>>     >? ? ?? ? zzz <- NULL
>>     >? ? ?? ? for(i in xx$Sample){
>>     >? ? ?? ? ? ? raw.i <- <stuff>
>>     >
>>     >? ? ?? ? ? ? etc. etc.
>>     >
>>     >? ? ?? ? ? ? zzz <- rbind(zzz, wide.i)
>>     >? ? ?}
>>     >? ? ?? ?browser()
>>     >
>>     >? ? ?? ? names(zzz) <- c("Cultivar", "Test", "Change")
>>     >? ? ?That line fails, with a complaint about zzz being NULL.
>>     >
>>     >? ? ?It appears as though the rbind doesn't do anything, but I
>>     can't see
>>     >? ? ?what wide.i looks like to get an idea what could be the
>cause.
>>     >
>>     >? ? ?Ideas what I should try are welcome.? I have no idea why
>the
>>     code
>>     >? ? ?works in an R environment but not an Rmd one.
>>     >
>>     >
>>     >? ? ?R-3.5.2,
>>     >? ? ?platform? ? ? ?x86_64-pc-linux-gnu
>>     >? ? ?arch? ? ? ? ? ?x86_64
>>     >? ? ?os? ? ? ? ? ? ?linux-gnu
>>     >? ? ?system? ? ? ? ?x86_64, linux-gnu
>>     >
>>     >? ? ?Rstudio Version 1.1.383
>>     >
>>     >
>>     >
>>     >? ? ?--
>>     >
>>    
>?~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>>     >
>>     >? ? ?? ?___? ? Patrick Connolly
>>     >? ? ??{~._.~}? ? ? ? ? ? ? ? ? ?Great minds discuss ideas
>>     >? ? ??_( Y )_? ? ? ? ? ? ? ? ?Average minds discuss events
>>     >? ? ?(:_~*~_:)? ? ? ? ? ? ? ? ? Small minds discuss people
>>     >? ? ??(_)-(_)? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ..... Eleanor
>Roosevelt
>>     >
>>     >
>>    
>?~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>>     >
>>     >? ? ?______________________________________________
>>     > R-help at r-project.org <mailto:R-help at r-project.org>
>>     <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>>     mailing list --
>>     >? ? ?To UNSUBSCRIBE and more, see
>>     > https://stat.ethz.ch/mailman/listinfo/r-help
>>     >? ? ?PLEASE do read the posting guide
>>     > http://www.R-project.org/posting-guide.html
>>     >? ? ?and provide commented, minimal, self-contained,
>reproducible
>>     code.
>>     >
>>
>>     ? ? ? ? [[alternative HTML version deleted]]
>>
>>     ______________________________________________
>>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>--
>>     To UNSUBSCRIBE and more, see
>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>     PLEASE do read the posting guide
>>     http://www.R-project.org/posting-guide.html
>>     and provide commented, minimal, self-contained, reproducible
>code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From wdun|@p @end|ng |rom t|bco@com  Sat Apr 20 00:58:55 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 19 Apr 2019 15:58:55 -0700
Subject: [R] Debugging Rmarkdown
In-Reply-To: <fce4bf00-42a8-d408-bfc9-bd818fdb4199@slingshot.co.nz>
References: <20190418095225.GA4472@slingshot.co.nz>
 <CAJuCY5y4EAw1-uSyz0JGP2D9N8b4dTgGuLwwfKn2QBzyzRRkzg@mail.gmail.com>
 <41e7a5fe-0041-e720-c839-6998cd9d65b7@slingshot.co.nz>
 <CAGxFJbR2Jj=oqnyaSkVs_OvS6EFyTZRRiTJ0hgzYbg-1f=Nzng@mail.gmail.com>
 <fce4bf00-42a8-d408-bfc9-bd818fdb4199@slingshot.co.nz>
Message-ID: <CAF8bMcaOORTvS6PtbnU2U=d0ndxRAE-VJ2G-nc+4qDjX2XOtxA@mail.gmail.com>

You can set the error handler to save the current state of R in a file,
"last.dump.rda" in the current working directory, when an error occurs with
   options(error=expression(dump.frames(to.file=TRUE,
include.GlobalEnv=TRUE)))
In another R session you can look at what it saved with
   load("last.dump.rda")
   debugger(last.dump)

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Apr 19, 2019 at 3:05 PM Patrick Connolly <p_connolly at slingshot.co.nz>
wrote:

> There are options to set echo and messages but AFAIK, the text appears
> in the resultant file, but if the script fails, there's no file to inspect.
>
> On 20/04/19 9:50 AM, Bert Gunter wrote:
> > This might be offbase, but do you need to set options to cache the
> > results in the original code chunks to reuse in later chunks? (I
> > haven't worked with knitr lately, so this may be nonsense).
> >
> > Cheers,
> > Bert
> >
> > On Fri, Apr 19, 2019 at 2:03 PM Patrick Connolly
> > <p_connolly at slingshot.co.nz <mailto:p_connolly at slingshot.co.nz>> wrote:
> >
> >
> >     On 19/04/19 12:13 AM, Thierry Onkelinx wrote:
> >     > Dear Patrick,
> >     >
> >     > This is not easy to debug without a reprex
> >     >
> >     > I would check the content of zzz and wide.i in the loop
> >     >
> >     > str(wide.i)
> >     >  zzz <- rbind(zzz, wide.i)
> >     > str(zzz)
> >     >
> >     That's just what I'm trying to achieve but the debugging doesn't work
> >     how it does with regular R code.
> >
> >     > Note that the Rmd always runs in a clean environment. This might
> >     > explain the difference
> >     >
> >     The data frames xx and yy are defined in earlier code chunks. Maybe I
> >     need to define them again.
> >
> >
> >     I'll look closer at it after Easter.
> >
> >
> >     Thanks for the suggestion.
> >
> >     > Best regards,
> >     >
> >     > ir. Thierry Onkelinx
> >     > Statisticus / Statistician
> >     >
> >     > Vlaamse Overheid / Government of Flanders
> >     > INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR
> >     NATURE
> >     > AND FOREST
> >     > Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality
> >     Assurance
> >     > thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
> >     <mailto:thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>>
> >     > Havenlaan 88 bus 73, 1000 Brussel
> >     > www.inbo.be <http://www.inbo.be> <http://www.inbo.be>
> >     >
> >     >
> >
>  ///////////////////////////////////////////////////////////////////////////////////////////
> >     > To call in the statistician after the experiment is done may be no
> >     > more than asking him to perform a post-mortem examination: he
> >     may be
> >     > able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> >     > The plural of anecdote is not data. ~ Roger Brinner
> >     > The combination of some data and an aching desire for an answer
> >     does
> >     > not ensure that a reasonable answer can be extracted from a
> >     given body
> >     > of data. ~ John Tukey
> >     >
> >
>  ///////////////////////////////////////////////////////////////////////////////////////////
> >     >
> >     > <https://www.inbo.be>
> >     >
> >     >
> >     > Op do 18 apr. 2019 om 11:53 schreef Patrick Connolly
> >     > <p_connolly at slingshot.co.nz <mailto:p_connolly at slingshot.co.nz>
> >     <mailto:p_connolly at slingshot.co.nz
> >     <mailto:p_connolly at slingshot.co.nz>>>:
> >     >
> >     >     I have a function that works in ESS, but it fails if I
> >     include it in
> >     >     an .Rmd file that I tried to knit using Rstudio.  I found
> >     advice at:
> >     >
> >
> https://www.rstudio.com/products/rstudio/release-notes/debugging-with-rstudio/
> >     >
> >     >     It seems to be not referring to markdown files. Somewhere else
> >     >     suggested calling render() in the console pane.  I tried
> >     that.  The
> >     >     browser() function interrupts correctly, but I can't find
> >     out what the
> >     >     object zzz in the code below looks like.  Nothing prints the
> >     way it
> >     >     would in a "normal" R buffer.
> >     >
> >     >     code outline:  making zzz out of two dataframes xx and yy
> >     >
> >     >     ##
> >     >         zzz <- NULL
> >     >         for(i in xx$Sample){
> >     >             raw.i <- <stuff>
> >     >
> >     >             etc. etc.
> >     >
> >     >             zzz <- rbind(zzz, wide.i)
> >     >     }
> >     >        browser()
> >     >
> >     >         names(zzz) <- c("Cultivar", "Test", "Change")
> >     >     That line fails, with a complaint about zzz being NULL.
> >     >
> >     >     It appears as though the rbind doesn't do anything, but I
> >     can't see
> >     >     what wide.i looks like to get an idea what could be the cause.
> >     >
> >     >     Ideas what I should try are welcome.  I have no idea why the
> >     code
> >     >     works in an R environment but not an Rmd one.
> >     >
> >     >
> >     >     R-3.5.2,
> >     >     platform       x86_64-pc-linux-gnu
> >     >     arch           x86_64
> >     >     os             linux-gnu
> >     >     system         x86_64, linux-gnu
> >     >
> >     >     Rstudio Version 1.1.383
> >     >
> >     >
> >     >
> >     >     --
> >     >
> >
>   ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
> >     >
> >     >        ___    Patrick Connolly
> >     >      {~._.~}                   Great minds discuss ideas
> >     >      _( Y )_                 Average minds discuss events
> >     >     (:_~*~_:)                  Small minds discuss people
> >     >      (_)-(_)                              ..... Eleanor Roosevelt
> >     >
> >     >
> >
>   ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
> >     >
> >     >     ______________________________________________
> >     > R-help at r-project.org <mailto:R-help at r-project.org>
> >     <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
> >     mailing list --
> >     >     To UNSUBSCRIBE and more, see
> >     > https://stat.ethz.ch/mailman/listinfo/r-help
> >     >     PLEASE do read the posting guide
> >     > http://www.R-project.org/posting-guide.html
> >     >     and provide commented, minimal, self-contained, reproducible
> >     code.
> >     >
> >
> >             [[alternative HTML version deleted]]
> >
> >     ______________________________________________
> >     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
> >     To UNSUBSCRIBE and more, see
> >     https://stat.ethz.ch/mailman/listinfo/r-help
> >     PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >     and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dr@ke@go@@| @end|ng |rom gm@||@com  Sat Apr 20 01:39:39 2019
From: dr@ke@go@@| @end|ng |rom gm@||@com (Drake Gossi)
Date: Fri, 19 Apr 2019 16:39:39 -0700
Subject: [R] creating a data.frame from scratch
Message-ID: <CAPSTy5dO_rCammVB7XA3B-D4JOdwkmFOjPHNvakAqSrLXOJPbQ@mail.gmail.com>

Hello everyone,

Is there any way to create a data.frame from scratch? other than, say, this?

> structure(list(Fruit = structure(c(1L, 2L, 5L, 4L, 3L), .Label =
c("apple",
"banana", "kiwi", "orange", "pear"), class = "factor"), Color =
structure(c(3L,
4L, 1L, 2L, 1L), .Label = c("green", "orange", "red", "yellow"
), class = "factor"), Shape = structure(c(3L, 1L, 2L, 3L, 3L), .Label =
c("oblong",
"pear", "round"), class = "factor"), Juice = c(1, 0, 0.5, 1,
0)), class = "data.frame", row.names = c("1", "2", "3", "4",
"5"))


which yields

   Fruit  Color  Shape  Juice
1  apple    red  round  1.0
2 banana yellow oblong   0.0
3   pear  green   pear   0.5
4 orange orange  round   1.0
5   kiwi  green  round   0.0


I get *that* it works. I just don't know *how* it works, and whether or not
there is another, easier way...

For example,

> structure(list(Fruit = structure(c(1L, 2L, 5L, 4L, 3L), .Label =
c("apple", "banana", "kiwi", "orange", "pear") ...


What on earth are these numbers? c(1L, 2L, 5L, 4L, 3L)? and why are they
out of order?

And then why put the fruits out of order? c("apple",
"banana", "kiwi", "orange", "pear")? since that's not a descending order?
since, in the final data.frame, it goes apple, banana, *pear*, *orange*,
kiwi?

So many questions!

Drake

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Apr 20 03:08:23 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 19 Apr 2019 18:08:23 -0700 (PDT)
Subject: [R] creating a data.frame from scratch
In-Reply-To: <CAPSTy5dO_rCammVB7XA3B-D4JOdwkmFOjPHNvakAqSrLXOJPbQ@mail.gmail.com>
References: <CAPSTy5dO_rCammVB7XA3B-D4JOdwkmFOjPHNvakAqSrLXOJPbQ@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1904191734060.51201@pedal.dcn.davis.ca.us>

You seem to be trying to learn R ... sideways... or backwards, perhaps.

Have you read An Introduction to R[1], included with every copy of the 
software? In particular, there are sections on data frames [2] (which 
should be read in the context of the discussion on lists, as it 
is presented. There is also the discussion of factors [3] where the idea 
of using integers to keep track of categorical data is discussed. There 
are many other introductory resources as well which would fill you in on 
these kinds of basic concepts if you find the ItR too computerish.

No R programmer I have ever met constructs data frames by typing in the 
kind of R you showed... that is distinctly characteristic of the 
output of the "dput" function, which is completely general and precise in 
an R-language sense and useful in reproducing whatever data you have in 
your R environment in someone elses environment.

So, one of these might be more typical:

dta1 <- data.frame( Fruit = c( "apple", "banana", "pear", "orange", "kiwi" )
                   , Color = c( "red", "yellow", "green", "orange", "green" )
                   , Shape = c( "round", "oblong", "pear", "round", "round" )
                   , Juice = Juice = c( 1, 0, 0.5, 1, 0 )
                   )

dta2 <- read.table( text =
"Fruit  Color  Shape  Juice
apple   red    round  1.0
banana  yellow oblong 0.0
pear    green  pear   0.5
orange  orange round  1.0
kiwi    green  round  0.0
", header = TRUE )

I would also strongly encourage you to read the Posting Guide mentioned at 
the bottom of every posting on this mailing list. One issue with your 
email is that sending HTML-formatted email to this list often leads to us 
receiving gibberish because this is a text-only mailing list and the 
translation from HTML to plain text is done differently by different mail 
handling software. Please find the setting for your email software that 
causes it to send plain text (Gmail has a button... you just have to look 
for it). Another issue is that there is an expectation on this list that 
you will have made some effort to wade through the documentation and at 
least mention what documentation you looked at so interested people can 
learn from your difficulty and possibly fix problems in the documentation 
for future users.

[1] https://cran.r-project.org/doc/manuals/r-release/R-intro.html
[2] https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Data-frames
[3] https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Factors

On Fri, 19 Apr 2019, Drake Gossi wrote:

> Hello everyone,
>
> Is there any way to create a data.frame from scratch? other than, say, this?
>
>> structure(list(Fruit = structure(c(1L, 2L, 5L, 4L, 3L), .Label =
> c("apple",
> "banana", "kiwi", "orange", "pear"), class = "factor"), Color =
> structure(c(3L,
> 4L, 1L, 2L, 1L), .Label = c("green", "orange", "red", "yellow"
> ), class = "factor"), Shape = structure(c(3L, 1L, 2L, 3L, 3L), .Label =
> c("oblong",
> "pear", "round"), class = "factor"), Juice = c(1, 0, 0.5, 1,
> 0)), class = "data.frame", row.names = c("1", "2", "3", "4",
> "5"))
>
>
> which yields
>
>   Fruit  Color  Shape  Juice
> 1  apple    red  round  1.0
> 2 banana yellow oblong   0.0
> 3   pear  green   pear   0.5
> 4 orange orange  round   1.0
> 5   kiwi  green  round   0.0
>
>
> I get *that* it works. I just don't know *how* it works, and whether or not
> there is another, easier way...
>
> For example,
>
>> structure(list(Fruit = structure(c(1L, 2L, 5L, 4L, 3L), .Label =
> c("apple", "banana", "kiwi", "orange", "pear") ...
>
>
> What on earth are these numbers? c(1L, 2L, 5L, 4L, 3L)? and why are they
> out of order?
>
> And then why put the fruits out of order? c("apple",
> "banana", "kiwi", "orange", "pear")? since that's not a descending order?
> since, in the final data.frame, it goes apple, banana, *pear*, *orange*,
> kiwi?
>
> So many questions!
>
> Drake
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From youy||ong @end|ng |rom gm@||@com  Fri Apr 19 19:25:57 2019
From: youy||ong @end|ng |rom gm@||@com (Youyi Fong)
Date: Fri, 19 Apr 2019 10:25:57 -0700
Subject: [R] .Call using multiple cores on linux after R 3.3.3
Message-ID: <CAA4m0GbGj=kKgdLpo7Sfe7HEYf-VYi5APzRd0zB7S2iH2nUy3w@mail.gmail.com>

Hi, I am wondering why it is the case that in R 3.3.3, calling
chngpt:chngptm uses only 1 core, but in later releases, e.g. R 3.4.3, it
uses multiple cores on linux. The function chngpt:chngptm has a .Call to
invoke a C/C++ function that performs bootstrapping. No explicit parallel
computing instructions are used.
Thanks,
Youyi

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Apr 20 18:06:02 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 20 Apr 2019 09:06:02 -0700
Subject: [R] .Call using multiple cores on linux after R 3.3.3
In-Reply-To: <CAA4m0GbGj=kKgdLpo7Sfe7HEYf-VYi5APzRd0zB7S2iH2nUy3w@mail.gmail.com>
References: <CAA4m0GbGj=kKgdLpo7Sfe7HEYf-VYi5APzRd0zB7S2iH2nUy3w@mail.gmail.com>
Message-ID: <07C2D9C6-92FD-48D9-B8A1-496A84ED6C59@dcn.davis.ca.us>

My guess would be that you are running with a non-CRAN distribution of R like Anaconda or MRAN that has MKL enabled?

On April 19, 2019 10:25:57 AM PDT, Youyi Fong <youyifong at gmail.com> wrote:
>Hi, I am wondering why it is the case that in R 3.3.3, calling
>chngpt:chngptm uses only 1 core, but in later releases, e.g. R 3.4.3,
>it
>uses multiple cores on linux. The function chngpt:chngptm has a .Call
>to
>invoke a C/C++ function that performs bootstrapping. No explicit
>parallel
>computing instructions are used.
>Thanks,
>Youyi
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @co|we|| @end|ng |rom uogue|ph@c@  Sat Apr 20 18:49:54 2019
From: @co|we|| @end|ng |rom uogue|ph@c@ (Scott Colwell)
Date: Sat, 20 Apr 2019 16:49:54 +0000
Subject: [R] Creating hanging bar plot in r from dplyr
Message-ID: <D312F32F-ACF4-4809-AF06-3CBD6E3F4FA6@contoso.com>

I am trying to figure out how to create a hanging bar plot from dplyr.
I have used dplyr as follows:
table4 <- cr %>%
  group_by(samp.N, RSQ) %>%
  summarize(
    MRB_uc = mean(CF.F1F2/0.40*100)-100,
    MRB_sb = mean(SBC.F1F2.Alpha/0.40*100) - 100,
    MRB_bp = mean(BPC.F1F2.Alpha/0.40*100) - 100
  )
which provides me with this:
   samp.N   RSQ MRB_uc MRB_sb MRB_bp
    <dbl> <dbl>  <dbl>  <dbl>  <dbl>
1     50   0.3   1.42  37.6   37.6
 2     50   0.4   8.61  43.1   43.1
 3     50   0.5   7.41  31.6   31.6
 4     50   0.6   5.06  21.5   21.5
 5     50   0.7   3.38  14.1   14.1
 6     50   0.8  -1.07   5.16   5.16
7    100   0.3  -6.41  40.3   40.3
 8    100   0.4 -10.6   21.0   21.0
 9    100   0.5  -9.02  13.2   13.2
10    100   0.6  -9.85   5.14   5.14
11    100   0.7  -7.94   2.08   2.08
12    100   0.8  -4.81   1.28   1.28
What I want to do is create a hanging bar plot with the x-axis being samp.N value by RSQ value. The bars are then values of MRB_uc, MRB_sb, and MRB_bp. Given some values are negative, some bars will be above zero and others below (hence the hanging bar plot)
I don't have any code yet as I am completely unfamiliar with how to do this. Any suggestions would be really appreciated.
Thank you!
Scott




--
Scott R. Colwell, PhD


	[[alternative HTML version deleted]]


From p@tr|ck@g|r@udoux @end|ng |rom un|v-|comte@|r  Sat Apr 20 18:57:31 2019
From: p@tr|ck@g|r@udoux @end|ng |rom un|v-|comte@|r (Patrick Giraudoux)
Date: Sat, 20 Apr 2019 18:57:31 +0200
Subject: [R] troubles with foreign:read.dbf
Message-ID: <084e230d-e0df-f54d-aa8e-2202fc2e25cf@univ-fcomte.fr>

Dear listers,

I am using the package foreign function read.dbf and meet the following 
issue:

i<-"Mailles_2011a.dbf"

dbf<-read.dbf(i)

works well BUT

if I have a vector such as

files <- c("Mailles_2011a.shp", "Mailles_2011p.shp", 
"Mailles_2012a.shp", "Mailles_2012p.shp", "Mailles_2013a.shp", 
"Mailles_2013p.shp", "Mailles_2014p.shp", "Mailles_2015a.shp", 
"Mailles_2015p.shp", "Mailles_2016p.shp")

for(i in files) {
dbf<-read.dbf(i)
names(dbf)
}

gives the following error message:

Error in read.dbf(i) : unable to open DBF file

Same error with e.g.

dbf<-read.dbf(files[1])

Any idea about what's happening?

Patrick


	[[alternative HTML version deleted]]


From er|cjberger @end|ng |rom gm@||@com  Sat Apr 20 19:13:39 2019
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sat, 20 Apr 2019 20:13:39 +0300
Subject: [R] troubles with foreign:read.dbf
In-Reply-To: <084e230d-e0df-f54d-aa8e-2202fc2e25cf@univ-fcomte.fr>
References: <084e230d-e0df-f54d-aa8e-2202fc2e25cf@univ-fcomte.fr>
Message-ID: <CAGgJW77PYJ+EG0ZTVXhm8015P-9fq_oo9auaXhKucbsQ69juAw@mail.gmail.com>

You seem to have a typo.
In the case that works your filename is "Mailles_2011a.dbf"
but in the case that fails your filename is "Mailles_2011a.shp"
(different extensions)

HTH,
Eric


On Sat, Apr 20, 2019 at 8:00 PM Patrick Giraudoux <
patrick.giraudoux at univ-fcomte.fr> wrote:

> Dear listers,
>
> I am using the package foreign function read.dbf and meet the following
> issue:
>
> i<-"Mailles_2011a.dbf"
>
> dbf<-read.dbf(i)
>
> works well BUT
>
> if I have a vector such as
>
> files <- c("Mailles_2011a.shp", "Mailles_2011p.shp",
> "Mailles_2012a.shp", "Mailles_2012p.shp", "Mailles_2013a.shp",
> "Mailles_2013p.shp", "Mailles_2014p.shp", "Mailles_2015a.shp",
> "Mailles_2015p.shp", "Mailles_2016p.shp")
>
> for(i in files) {
> dbf<-read.dbf(i)
> names(dbf)
> }
>
> gives the following error message:
>
> Error in read.dbf(i) : unable to open DBF file
>
> Same error with e.g.
>
> dbf<-read.dbf(files[1])
>
> Any idea about what's happening?
>
> Patrick
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From p@tr|ck@g|r@udoux @end|ng |rom un|v-|comte@|r  Sat Apr 20 19:19:51 2019
From: p@tr|ck@g|r@udoux @end|ng |rom un|v-|comte@|r (Patrick Giraudoux)
Date: Sat, 20 Apr 2019 19:19:51 +0200
Subject: [R] troubles with foreign:read.dbf
In-Reply-To: <CAGgJW77PYJ+EG0ZTVXhm8015P-9fq_oo9auaXhKucbsQ69juAw@mail.gmail.com>
References: <084e230d-e0df-f54d-aa8e-2202fc2e25cf@univ-fcomte.fr>
 <CAGgJW77PYJ+EG0ZTVXhm8015P-9fq_oo9auaXhKucbsQ69juAw@mail.gmail.com>
Message-ID: <4d39bd08-36ea-4b57-43da-19df710cb452@univ-fcomte.fr>

Ashes of my head and all those sorts of things...
If I was a totally a newbie in R, I could claim for some sort of excuse, 
but it is definitely not the case, even.
Thanks !
Patrick


Le 20/04/2019 ? 19:13, Eric Berger a ?crit?:
> You seem to have a typo.
> In the case that works your filename is "Mailles_2011a.dbf"
> but in the case that fails your filename is "Mailles_2011a.shp"
> (different extensions)
>
> HTH,
> Eric
>
>
> On Sat, Apr 20, 2019 at 8:00 PM Patrick Giraudoux 
> <patrick.giraudoux at univ-fcomte.fr 
> <mailto:patrick.giraudoux at univ-fcomte.fr>> wrote:
>
>     Dear listers,
>
>     I am using the package foreign function read.dbf and meet the
>     following
>     issue:
>
>     i<-"Mailles_2011a.dbf"
>
>     dbf<-read.dbf(i)
>
>     works well BUT
>
>     if I have a vector such as
>
>     files <- c("Mailles_2011a.shp", "Mailles_2011p.shp",
>     "Mailles_2012a.shp", "Mailles_2012p.shp", "Mailles_2013a.shp",
>     "Mailles_2013p.shp", "Mailles_2014p.shp", "Mailles_2015a.shp",
>     "Mailles_2015p.shp", "Mailles_2016p.shp")
>
>     for(i in files) {
>     dbf<-read.dbf(i)
>     names(dbf)
>     }
>
>     gives the following error message:
>
>     Error in read.dbf(i) : unable to open DBF file
>
>     Same error with e.g.
>
>     dbf<-read.dbf(files[1])
>
>     Any idea about what's happening?
>
>     Patrick
>
>
>     ? ? ? ? [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>


	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Apr 20 19:27:19 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 20 Apr 2019 10:27:19 -0700 (PDT)
Subject: [R] Creating hanging bar plot in r from dplyr
In-Reply-To: <D312F32F-ACF4-4809-AF06-3CBD6E3F4FA6@contoso.com>
References: <D312F32F-ACF4-4809-AF06-3CBD6E3F4FA6@contoso.com>
Message-ID: <alpine.BSF.2.00.1904201025001.96147@pedal.dcn.davis.ca.us>

Not really sure I understand what you want. Here is some code to 
consider:

################

library(ggplot2)
library(dplyr)
library(tidyr)

dta <- read.table( text =
"samp.N   RSQ    MRB_uc  MRB_sb  MRB_bp
  50      0.3      1.42    37.6   37.6
  50      0.4      8.61    43.1   43.1
  50      0.5      7.41    31.6   31.6
  50      0.6      5.06    21.5   21.5
  50      0.7      3.38    14.1   14.1
  50      0.8     -1.07    5.16   5.16
100      0.3     -6.41    40.3   40.3
100      0.4     -10.6    21.0   21.0
100      0.5     -9.02    13.2   13.2
100      0.6     -9.85    5.14   5.14
100      0.7     -7.94    2.08   2.08
100      0.8     -4.81    1.28   1.28
", header = TRUE )
dta2 <- (   dta
         %>% mutate( samp.N = factor( samp.N )
                   , RSQ = factor( RSQ )
                   )
         %>% gather( Measure, value, -c( samp.N, RSQ ) )
         )

ggplot( dta2, aes( x = RSQ, y = value, fill = samp.N ) ) +
   geom_bar( stat = "identity", position = "dodge", colour = "black" ) +
   facet_wrap( ~ Measure, ncol = 1, scale = "free_y" ) +
   ylab( "" )

################


On Sat, 20 Apr 2019, Scott Colwell wrote:

> I am trying to figure out how to create a hanging bar plot from dplyr.
> I have used dplyr as follows:
> table4 <- cr %>%
>  group_by(samp.N, RSQ) %>%
>  summarize(
>    MRB_uc = mean(CF.F1F2/0.40*100)-100,
>    MRB_sb = mean(SBC.F1F2.Alpha/0.40*100) - 100,
>    MRB_bp = mean(BPC.F1F2.Alpha/0.40*100) - 100
>  )
> which provides me with this:
>   samp.N   RSQ MRB_uc MRB_sb MRB_bp
>    <dbl> <dbl>  <dbl>  <dbl>  <dbl>
> 1     50   0.3   1.42  37.6   37.6
> 2     50   0.4   8.61  43.1   43.1
> 3     50   0.5   7.41  31.6   31.6
> 4     50   0.6   5.06  21.5   21.5
> 5     50   0.7   3.38  14.1   14.1
> 6     50   0.8  -1.07   5.16   5.16
> 7    100   0.3  -6.41  40.3   40.3
> 8    100   0.4 -10.6   21.0   21.0
> 9    100   0.5  -9.02  13.2   13.2
> 10    100   0.6  -9.85   5.14   5.14
> 11    100   0.7  -7.94   2.08   2.08
> 12    100   0.8  -4.81   1.28   1.28
> What I want to do is create a hanging bar plot with the x-axis being samp.N value by RSQ value. The bars are then values of MRB_uc, MRB_sb, and MRB_bp. Given some values are negative, some bars will be above zero and others below (hence the hanging bar plot)
> I don't have any code yet as I am completely unfamiliar with how to do this. Any suggestions would be really appreciated.
> Thank you!
> Scott
>
>
>
>
> --
> Scott R. Colwell, PhD
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From @co|we|| @end|ng |rom uogue|ph@c@  Sat Apr 20 19:55:52 2019
From: @co|we|| @end|ng |rom uogue|ph@c@ (Scott Colwell)
Date: Sat, 20 Apr 2019 17:55:52 +0000
Subject: [R] Creating hanging bar plot in r from dplyr
In-Reply-To: <alpine.BSF.2.00.1904201025001.96147@pedal.dcn.davis.ca.us>
References: <D312F32F-ACF4-4809-AF06-3CBD6E3F4FA6@contoso.com>
 <alpine.BSF.2.00.1904201025001.96147@pedal.dcn.davis.ca.us>
Message-ID: <C6669C7A-B5BB-400C-AC9C-8BB4859368F1@uoguelph.ca>

That is perfect. Thanks!

--
Scott R. Colwell, PhD

?On 2019-04-20, 1:23 PM, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us> wrote:

    Not really sure I understand what you want. Here is some code to 
    consider:
    
    ################
    
    library(ggplot2)
    library(dplyr)
    library(tidyr)
    
    dta <- read.table( text =
    "samp.N   RSQ    MRB_uc  MRB_sb  MRB_bp
      50      0.3      1.42    37.6   37.6
      50      0.4      8.61    43.1   43.1
      50      0.5      7.41    31.6   31.6
      50      0.6      5.06    21.5   21.5
      50      0.7      3.38    14.1   14.1
      50      0.8     -1.07    5.16   5.16
    100      0.3     -6.41    40.3   40.3
    100      0.4     -10.6    21.0   21.0
    100      0.5     -9.02    13.2   13.2
    100      0.6     -9.85    5.14   5.14
    100      0.7     -7.94    2.08   2.08
    100      0.8     -4.81    1.28   1.28
    ", header = TRUE )
    dta2 <- (   dta
             %>% mutate( samp.N = factor( samp.N )
                       , RSQ = factor( RSQ )
                       )
             %>% gather( Measure, value, -c( samp.N, RSQ ) )
             )
    
    ggplot( dta2, aes( x = RSQ, y = value, fill = samp.N ) ) +
       geom_bar( stat = "identity", position = "dodge", colour = "black" ) +
       facet_wrap( ~ Measure, ncol = 1, scale = "free_y" ) +
       ylab( "" )
    
    ################
    
    
    On Sat, 20 Apr 2019, Scott Colwell wrote:
    
    > I am trying to figure out how to create a hanging bar plot from dplyr.
    > I have used dplyr as follows:
    > table4 <- cr %>%
    >  group_by(samp.N, RSQ) %>%
    >  summarize(
    >    MRB_uc = mean(CF.F1F2/0.40*100)-100,
    >    MRB_sb = mean(SBC.F1F2.Alpha/0.40*100) - 100,
    >    MRB_bp = mean(BPC.F1F2.Alpha/0.40*100) - 100
    >  )
    > which provides me with this:
    >   samp.N   RSQ MRB_uc MRB_sb MRB_bp
    >    <dbl> <dbl>  <dbl>  <dbl>  <dbl>
    > 1     50   0.3   1.42  37.6   37.6
    > 2     50   0.4   8.61  43.1   43.1
    > 3     50   0.5   7.41  31.6   31.6
    > 4     50   0.6   5.06  21.5   21.5
    > 5     50   0.7   3.38  14.1   14.1
    > 6     50   0.8  -1.07   5.16   5.16
    > 7    100   0.3  -6.41  40.3   40.3
    > 8    100   0.4 -10.6   21.0   21.0
    > 9    100   0.5  -9.02  13.2   13.2
    > 10    100   0.6  -9.85   5.14   5.14
    > 11    100   0.7  -7.94   2.08   2.08
    > 12    100   0.8  -4.81   1.28   1.28
    > What I want to do is create a hanging bar plot with the x-axis being samp.N value by RSQ value. The bars are then values of MRB_uc, MRB_sb, and MRB_bp. Given some values are negative, some bars will be above zero and others below (hence the hanging bar plot)
    > I don't have any code yet as I am completely unfamiliar with how to do this. Any suggestions would be really appreciated.
    > Thank you!
    > Scott
    >
    >
    >
    >
    > --
    > Scott R. Colwell, PhD
    >
    >
    > 	[[alternative HTML version deleted]]
    >
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    >
    
    ---------------------------------------------------------------------------
    Jeff Newmiller                        The     .....       .....  Go Live...
    DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                           Live:   OO#.. Dead: OO#..  Playing
    Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
    /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
    ---------------------------------------------------------------------------
    


From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Mon Apr 22 02:06:06 2019
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Sun, 21 Apr 2019 20:06:06 -0400
Subject: [R] Help installing netReg
In-Reply-To: <CAPQaxLM5aJM5uW9NsmXtG1Qbx4Mco7B=uiQ8kdRX+06kGZHCYg@mail.gmail.com>
References: <CAPQaxLPmhsdh5OaOErFQZXym7JpMY9EuPAjEL70-0DFbDks6LA@mail.gmail.com>
 <2826429b-ff8b-6606-a6ba-c27388075d7f@comcast.net>
 <CAPQaxLM5aJM5uW9NsmXtG1Qbx4Mco7B=uiQ8kdRX+06kGZHCYg@mail.gmail.com>
Message-ID: <CAPQaxLMXYAzjTJjoCemYVE+Pw47HvZaYAq-=wanTZdnxkE5jaQ@mail.gmail.com>

Good evening,

 I am having problems with downloading the package used to generate
regression models on R. The following is the error message I received. I
tried installing BiocManager instead as suggested, but this too did not
work. Any ideas?

The following is the full summary of what I?ve tried thus far...

install.packages("ggplot2")
install.packages("ggplot2")
source("https://bioconductor.org/biocLite.R")
?BiocUpgrade
source("https://bioconductor.org/biocLite.R")biocLite("BiocUpgrade")
source("https://bioconductor.org/biocLite.R")
biocLite("BiocUpgrade")
source("https://bioconductor.org/bioLite.R")
biocLite("netReg")
help("Deprecated")
'BiocManager::install'
biocLite("netReg")
help("oldName-deprecated")
???oldName-deprecated?
.Deprecated(new, package=NULL, msg,
old = as.character(sys.call(sys.parent()))[1L])

Best,

Spencer

On Sun, Apr 14, 2019 at 7:58 PM Spencer Brackett <
spbrackett20 at saintjosephhs.com> wrote:

> My apologies... here is the full code in summary
>
> install.packages("ggplot2")
> install.packages("ggplot2")
> source("https://bioconductor.org/biocLite.R")
> ?BiocUpgrade
> source("https://bioconductor.org/biocLite.R")biocLite("BiocUpgrade")
> source("https://bioconductor.org/biocLite.R")
> biocLite("BiocUpgrade")
> source("https://bioconductor.org/bioLite.R")
> biocLite("netReg")
> help("Deprecated")
> 'BiocManager::install'
> biocLite("netReg")
> help("oldName-deprecated")
> ???oldName-deprecated?
> .Deprecated(new, package=NULL, msg,
> old = as.character(sys.call(sys.parent()))[1L])
>
> Best,
>
> Spencer
>
>
>
> On Sun, Apr 14, 2019 at 7:20 PM David Winsemius <dwinsemius at comcast.net>
> wrote:
>
>>
>> On 4/14/19 3:20 PM, Spencer Brackett wrote:
>> > Good evening,
>> >
>> >   I am having problems with downloading the package used to generate
>> > regression models on R. The following is the error message I received. I
>> > tried installing BiocManager instead as suggested, but this too did not
>> > work. Any ideas?
>> >
>> > The downloaded binary packages are in
>> > C:\Users\Spencer\AppData\Local\Temp\Rtmp8YKVqx\downloaded_packages
>> > installation path not writeable, unable to update packages: class,
>> cluster,
>> > codetools, foreign,
>> >    lattice, MASS, Matrix, mgcv, nlme, rpart, survival
>> > Warning message:
>> > 'biocLite' is deprecated.
>> > Use 'BiocManager::install' instead.
>> > See help("Deprecated")
>>
>>
>> Since you did not include the code that provoked this message we can
>> only guess that you did in fact use `bioLite`. We also cannot tell what
>> you mean by "problems with downloading the package used to generate
>> regression models on R". The typical first step is to use the glm or lm
>> function for this task and those are both in the stats package which is
>> installed with the base version of R and is loaded by default when R is
>> started up.
>>
>> "
>>
>> Have you tried following the suggestion at the end of the message?
>>
>>
>> And do read the Posting Guide and include "commented, minimal,
>> self-contained, reproducible code."
>>
>>
>> --
>>
>> David.
>>
>> >
>> > Best,
>> >
>> > Spencer
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Apr 22 02:34:54 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 21 Apr 2019 17:34:54 -0700
Subject: [R] Help installing netReg
In-Reply-To: <CAPQaxLMXYAzjTJjoCemYVE+Pw47HvZaYAq-=wanTZdnxkE5jaQ@mail.gmail.com>
References: <CAPQaxLPmhsdh5OaOErFQZXym7JpMY9EuPAjEL70-0DFbDks6LA@mail.gmail.com>
 <2826429b-ff8b-6606-a6ba-c27388075d7f@comcast.net>
 <CAPQaxLM5aJM5uW9NsmXtG1Qbx4Mco7B=uiQ8kdRX+06kGZHCYg@mail.gmail.com>
 <CAPQaxLMXYAzjTJjoCemYVE+Pw47HvZaYAq-=wanTZdnxkE5jaQ@mail.gmail.com>
Message-ID: <CAGxFJbT-zkTa8xa77VSv+Awr51Dgi4yz+-CxeNfmezDZWNi7-Q@mail.gmail.com>

netReg is not "the package that generates regression models in R." Tons of
packages generate regression models in R, including lm(), which is in the
stats package that is part of R's standard distro.

So what exactly is it that you want to do that you think requires netReg?
And if netReg is required, have you tried addressing your queries to the
Bioconductor list, as it is one of their packages?

Cheers,
Bert


"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Apr 21, 2019 at 5:06 PM Spencer Brackett <
spbrackett20 at saintjosephhs.com> wrote:

> Good evening,
>
>  I am having problems with downloading the package used to generate
> regression models on R. The following is the error message I received. I
> tried installing BiocManager instead as suggested, but this too did not
> work. Any ideas?
>
> The following is the full summary of what I?ve tried thus far...
>
> install.packages("ggplot2")
> install.packages("ggplot2")
> source("https://bioconductor.org/biocLite.R")
> ?BiocUpgrade
> source("https://bioconductor.org/biocLite.R")biocLite("BiocUpgrade")
> source("https://bioconductor.org/biocLite.R")
> biocLite("BiocUpgrade")
> source("https://bioconductor.org/bioLite.R")
> biocLite("netReg")
> help("Deprecated")
> 'BiocManager::install'
> biocLite("netReg")
> help("oldName-deprecated")
> ???oldName-deprecated?
> .Deprecated(new, package=NULL, msg,
> old = as.character(sys.call(sys.parent()))[1L])
>
> Best,
>
> Spencer
>
> On Sun, Apr 14, 2019 at 7:58 PM Spencer Brackett <
> spbrackett20 at saintjosephhs.com> wrote:
>
> > My apologies... here is the full code in summary
> >
> > install.packages("ggplot2")
> > install.packages("ggplot2")
> > source("https://bioconductor.org/biocLite.R")
> > ?BiocUpgrade
> > source("https://bioconductor.org/biocLite.R")biocLite("BiocUpgrade")
> > source("https://bioconductor.org/biocLite.R")
> > biocLite("BiocUpgrade")
> > source("https://bioconductor.org/bioLite.R")
> > biocLite("netReg")
> > help("Deprecated")
> > 'BiocManager::install'
> > biocLite("netReg")
> > help("oldName-deprecated")
> > ???oldName-deprecated?
> > .Deprecated(new, package=NULL, msg,
> > old = as.character(sys.call(sys.parent()))[1L])
> >
> > Best,
> >
> > Spencer
> >
> >
> >
> > On Sun, Apr 14, 2019 at 7:20 PM David Winsemius <dwinsemius at comcast.net>
> > wrote:
> >
> >>
> >> On 4/14/19 3:20 PM, Spencer Brackett wrote:
> >> > Good evening,
> >> >
> >> >   I am having problems with downloading the package used to generate
> >> > regression models on R. The following is the error message I
> received. I
> >> > tried installing BiocManager instead as suggested, but this too did
> not
> >> > work. Any ideas?
> >> >
> >> > The downloaded binary packages are in
> >> > C:\Users\Spencer\AppData\Local\Temp\Rtmp8YKVqx\downloaded_packages
> >> > installation path not writeable, unable to update packages: class,
> >> cluster,
> >> > codetools, foreign,
> >> >    lattice, MASS, Matrix, mgcv, nlme, rpart, survival
> >> > Warning message:
> >> > 'biocLite' is deprecated.
> >> > Use 'BiocManager::install' instead.
> >> > See help("Deprecated")
> >>
> >>
> >> Since you did not include the code that provoked this message we can
> >> only guess that you did in fact use `bioLite`. We also cannot tell what
> >> you mean by "problems with downloading the package used to generate
> >> regression models on R". The typical first step is to use the glm or lm
> >> function for this task and those are both in the stats package which is
> >> installed with the base version of R and is loaded by default when R is
> >> started up.
> >>
> >> "
> >>
> >> Have you tried following the suggestion at the end of the message?
> >>
> >>
> >> And do read the Posting Guide and include "commented, minimal,
> >> self-contained, reproducible code."
> >>
> >>
> >> --
> >>
> >> David.
> >>
> >> >
> >> > Best,
> >> >
> >> > Spencer
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Mon Apr 22 03:35:05 2019
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Sun, 21 Apr 2019 21:35:05 -0400
Subject: [R] Help installing netReg
In-Reply-To: <CAGxFJbT-zkTa8xa77VSv+Awr51Dgi4yz+-CxeNfmezDZWNi7-Q@mail.gmail.com>
References: <CAPQaxLPmhsdh5OaOErFQZXym7JpMY9EuPAjEL70-0DFbDks6LA@mail.gmail.com>
 <2826429b-ff8b-6606-a6ba-c27388075d7f@comcast.net>
 <CAPQaxLM5aJM5uW9NsmXtG1Qbx4Mco7B=uiQ8kdRX+06kGZHCYg@mail.gmail.com>
 <CAPQaxLMXYAzjTJjoCemYVE+Pw47HvZaYAq-=wanTZdnxkE5jaQ@mail.gmail.com>
 <CAGxFJbT-zkTa8xa77VSv+Awr51Dgi4yz+-CxeNfmezDZWNi7-Q@mail.gmail.com>
Message-ID: <CAPQaxLOoeTeoY0Z+uSMAE7sdHYrTQeDDNoLWzkTSQpk_mjLwBg@mail.gmail.com>

Mr. Gunter,

Yes I have reached out to the bioconductor list but was informed that my
inquiry concerning this package was not appropriate for the mailing list.
However, I have since tried re implementing the code which I sent and my R
Studio says that netReg has successfully been unpacked, so for now it
appears that my problem is solved :)

Best,

Spencer Brackett

On Sun, Apr 21, 2019 at 8:35 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> netReg is not "the package that generates regression models in R." Tons of
> packages generate regression models in R, including lm(), which is in the
> stats package that is part of R's standard distro.
>
> So what exactly is it that you want to do that you think requires netReg?
> And if netReg is required, have you tried addressing your queries to the
> Bioconductor list, as it is one of their packages?
>
> Cheers,
> Bert
>
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, Apr 21, 2019 at 5:06 PM Spencer Brackett <
> spbrackett20 at saintjosephhs.com> wrote:
>
>> Good evening,
>>
>>  I am having problems with downloading the package used to generate
>> regression models on R. The following is the error message I received. I
>> tried installing BiocManager instead as suggested, but this too did not
>> work. Any ideas?
>>
>> The following is the full summary of what I?ve tried thus far...
>>
>> install.packages("ggplot2")
>> install.packages("ggplot2")
>> source("https://bioconductor.org/biocLite.R")
>> ?BiocUpgrade
>> source("https://bioconductor.org/biocLite.R")biocLite("BiocUpgrade")
>> source("https://bioconductor.org/biocLite.R")
>> biocLite("BiocUpgrade")
>> source("https://bioconductor.org/bioLite.R")
>> biocLite("netReg")
>> help("Deprecated")
>> 'BiocManager::install'
>> biocLite("netReg")
>> help("oldName-deprecated")
>> ???oldName-deprecated?
>> .Deprecated(new, package=NULL, msg,
>> old = as.character(sys.call(sys.parent()))[1L])
>>
>> Best,
>>
>> Spencer
>>
>> On Sun, Apr 14, 2019 at 7:58 PM Spencer Brackett <
>> spbrackett20 at saintjosephhs.com> wrote:
>>
>> > My apologies... here is the full code in summary
>> >
>> > install.packages("ggplot2")
>> > install.packages("ggplot2")
>> > source("https://bioconductor.org/biocLite.R")
>> > ?BiocUpgrade
>> > source("https://bioconductor.org/biocLite.R")biocLite("BiocUpgrade")
>> > source("https://bioconductor.org/biocLite.R")
>> > biocLite("BiocUpgrade")
>> > source("https://bioconductor.org/bioLite.R")
>> > biocLite("netReg")
>> > help("Deprecated")
>> > 'BiocManager::install'
>> > biocLite("netReg")
>> > help("oldName-deprecated")
>> > ???oldName-deprecated?
>> > .Deprecated(new, package=NULL, msg,
>> > old = as.character(sys.call(sys.parent()))[1L])
>> >
>> > Best,
>> >
>> > Spencer
>> >
>> >
>> >
>> > On Sun, Apr 14, 2019 at 7:20 PM David Winsemius <dwinsemius at comcast.net
>> >
>> > wrote:
>> >
>> >>
>> >> On 4/14/19 3:20 PM, Spencer Brackett wrote:
>> >> > Good evening,
>> >> >
>> >> >   I am having problems with downloading the package used to generate
>> >> > regression models on R. The following is the error message I
>> received. I
>> >> > tried installing BiocManager instead as suggested, but this too did
>> not
>> >> > work. Any ideas?
>> >> >
>> >> > The downloaded binary packages are in
>> >> > C:\Users\Spencer\AppData\Local\Temp\Rtmp8YKVqx\downloaded_packages
>> >> > installation path not writeable, unable to update packages: class,
>> >> cluster,
>> >> > codetools, foreign,
>> >> >    lattice, MASS, Matrix, mgcv, nlme, rpart, survival
>> >> > Warning message:
>> >> > 'biocLite' is deprecated.
>> >> > Use 'BiocManager::install' instead.
>> >> > See help("Deprecated")
>> >>
>> >>
>> >> Since you did not include the code that provoked this message we can
>> >> only guess that you did in fact use `bioLite`. We also cannot tell what
>> >> you mean by "problems with downloading the package used to generate
>> >> regression models on R". The typical first step is to use the glm or lm
>> >> function for this task and those are both in the stats package which is
>> >> installed with the base version of R and is loaded by default when R is
>> >> started up.
>> >>
>> >> "
>> >>
>> >> Have you tried following the suggestion at the end of the message?
>> >>
>> >>
>> >> And do read the Posting Guide and include "commented, minimal,
>> >> self-contained, reproducible code."
>> >>
>> >>
>> >> --
>> >>
>> >> David.
>> >>
>> >> >
>> >> > Best,
>> >> >
>> >> > Spencer
>> >> >
>> >> >       [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Mon Apr 22 04:27:54 2019
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Sun, 21 Apr 2019 22:27:54 -0400
Subject: [R] Help installing netReg
In-Reply-To: <CAPQaxLOoeTeoY0Z+uSMAE7sdHYrTQeDDNoLWzkTSQpk_mjLwBg@mail.gmail.com>
References: <CAPQaxLPmhsdh5OaOErFQZXym7JpMY9EuPAjEL70-0DFbDks6LA@mail.gmail.com>
 <2826429b-ff8b-6606-a6ba-c27388075d7f@comcast.net>
 <CAPQaxLM5aJM5uW9NsmXtG1Qbx4Mco7B=uiQ8kdRX+06kGZHCYg@mail.gmail.com>
 <CAPQaxLMXYAzjTJjoCemYVE+Pw47HvZaYAq-=wanTZdnxkE5jaQ@mail.gmail.com>
 <CAGxFJbT-zkTa8xa77VSv+Awr51Dgi4yz+-CxeNfmezDZWNi7-Q@mail.gmail.com>
 <CAPQaxLOoeTeoY0Z+uSMAE7sdHYrTQeDDNoLWzkTSQpk_mjLwBg@mail.gmail.com>
Message-ID: <CAPQaxLNj8jHnwzux3zsYgfmG-tOhrb-iAQUeDeSmR2e6SZNWrg@mail.gmail.com>

R users,

  I am trying to download R Studio onto my Chrombook for convenience, but
exited out of the Linux terminal that had opened upon my turning on of
Linux(Beta) through my settings. Because of this I am unable to prompt the
same type of Linex terminal and can only enable a new one via ctrl alt t .
Running the same line of commands (as shown below) that I was following
before encountering my error w/ the first terminal is not working. Note,
the hostname for the new terminal that I have prompted is crosh> if that
effects anything.

Commands I was instructed to make after enabling Linux on my Chrome...

lsb_release
sudo apt search r-base | grep ^r-base (to download R)

-y gnupg2
?keyserver keys.gnupg.net ?recv-key ? ?
***where my terminal experienced some sort of error causing me to abandon
it***

Any pointers for how I may proceed or alternative tutorials that I may
follow?

Best,

Spencer Brackett


On Sun, Apr 21, 2019 at 9:35 PM Spencer Brackett <
spbrackett20 at saintjosephhs.com> wrote:

> Mr. Gunter,
>
> Yes I have reached out to the bioconductor list but was informed that my
> inquiry concerning this package was not appropriate for the mailing list.
> However, I have since tried re implementing the code which I sent and my R
> Studio says that netReg has successfully been unpacked, so for now it
> appears that my problem is solved :)
>
> Best,
>
> Spencer Brackett
>
> On Sun, Apr 21, 2019 at 8:35 PM Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
>> netReg is not "the package that generates regression models in R." Tons
>> of packages generate regression models in R, including lm(), which is in
>> the stats package that is part of R's standard distro.
>>
>> So what exactly is it that you want to do that you think requires netReg?
>> And if netReg is required, have you tried addressing your queries to the
>> Bioconductor list, as it is one of their packages?
>>
>> Cheers,
>> Bert
>>
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sun, Apr 21, 2019 at 5:06 PM Spencer Brackett <
>> spbrackett20 at saintjosephhs.com> wrote:
>>
>>> Good evening,
>>>
>>>  I am having problems with downloading the package used to generate
>>> regression models on R. The following is the error message I received. I
>>> tried installing BiocManager instead as suggested, but this too did not
>>> work. Any ideas?
>>>
>>> The following is the full summary of what I?ve tried thus far...
>>>
>>> install.packages("ggplot2")
>>> install.packages("ggplot2")
>>> source("https://bioconductor.org/biocLite.R")
>>> ?BiocUpgrade
>>> source("https://bioconductor.org/biocLite.R")biocLite("BiocUpgrade")
>>> source("https://bioconductor.org/biocLite.R")
>>> biocLite("BiocUpgrade")
>>> source("https://bioconductor.org/bioLite.R")
>>> biocLite("netReg")
>>> help("Deprecated")
>>> 'BiocManager::install'
>>> biocLite("netReg")
>>> help("oldName-deprecated")
>>> ???oldName-deprecated?
>>> .Deprecated(new, package=NULL, msg,
>>> old = as.character(sys.call(sys.parent()))[1L])
>>>
>>> Best,
>>>
>>> Spencer
>>>
>>> On Sun, Apr 14, 2019 at 7:58 PM Spencer Brackett <
>>> spbrackett20 at saintjosephhs.com> wrote:
>>>
>>> > My apologies... here is the full code in summary
>>> >
>>> > install.packages("ggplot2")
>>> > install.packages("ggplot2")
>>> > source("https://bioconductor.org/biocLite.R")
>>> > ?BiocUpgrade
>>> > source("https://bioconductor.org/biocLite.R")biocLite("BiocUpgrade")
>>> > source("https://bioconductor.org/biocLite.R")
>>> > biocLite("BiocUpgrade")
>>> > source("https://bioconductor.org/bioLite.R")
>>> > biocLite("netReg")
>>> > help("Deprecated")
>>> > 'BiocManager::install'
>>> > biocLite("netReg")
>>> > help("oldName-deprecated")
>>> > ???oldName-deprecated?
>>> > .Deprecated(new, package=NULL, msg,
>>> > old = as.character(sys.call(sys.parent()))[1L])
>>> >
>>> > Best,
>>> >
>>> > Spencer
>>> >
>>> >
>>> >
>>> > On Sun, Apr 14, 2019 at 7:20 PM David Winsemius <
>>> dwinsemius at comcast.net>
>>> > wrote:
>>> >
>>> >>
>>> >> On 4/14/19 3:20 PM, Spencer Brackett wrote:
>>> >> > Good evening,
>>> >> >
>>> >> >   I am having problems with downloading the package used to generate
>>> >> > regression models on R. The following is the error message I
>>> received. I
>>> >> > tried installing BiocManager instead as suggested, but this too did
>>> not
>>> >> > work. Any ideas?
>>> >> >
>>> >> > The downloaded binary packages are in
>>> >> > C:\Users\Spencer\AppData\Local\Temp\Rtmp8YKVqx\downloaded_packages
>>> >> > installation path not writeable, unable to update packages: class,
>>> >> cluster,
>>> >> > codetools, foreign,
>>> >> >    lattice, MASS, Matrix, mgcv, nlme, rpart, survival
>>> >> > Warning message:
>>> >> > 'biocLite' is deprecated.
>>> >> > Use 'BiocManager::install' instead.
>>> >> > See help("Deprecated")
>>> >>
>>> >>
>>> >> Since you did not include the code that provoked this message we can
>>> >> only guess that you did in fact use `bioLite`. We also cannot tell
>>> what
>>> >> you mean by "problems with downloading the package used to generate
>>> >> regression models on R". The typical first step is to use the glm or
>>> lm
>>> >> function for this task and those are both in the stats package which
>>> is
>>> >> installed with the base version of R and is loaded by default when R
>>> is
>>> >> started up.
>>> >>
>>> >> "
>>> >>
>>> >> Have you tried following the suggestion at the end of the message?
>>> >>
>>> >>
>>> >> And do read the Posting Guide and include "commented, minimal,
>>> >> self-contained, reproducible code."
>>> >>
>>> >>
>>> >> --
>>> >>
>>> >> David.
>>> >>
>>> >> >
>>> >> > Best,
>>> >> >
>>> >> > Spencer
>>> >> >
>>> >> >       [[alternative HTML version deleted]]
>>> >> >
>>> >> > ______________________________________________
>>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> > PLEASE do read the posting guide
>>> >> http://www.R-project.org/posting-guide.html
>>> >> > and provide commented, minimal, self-contained, reproducible code.
>>> >>
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>

	[[alternative HTML version deleted]]


From bor|@@@te|pe @end|ng |rom utoronto@c@  Mon Apr 22 04:44:17 2019
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Mon, 22 Apr 2019 02:44:17 +0000
Subject: [R] Example for  Roxygen @eval tag?
Message-ID: <8CAFE8EB-9356-4DD6-A9EE-834B1A027211@utoronto.ca>

Playing with Roxygen features, but can't get @eval to work. E.g. ...

#' @eval sprintf("%s", Sys.time())

... does not do what I thought it would (i.e. substitute the tag and the expression with the string). Instead I see nothing in the .RD file.

Any working examples out there?
Thanks!
Boris


From bor|@@@te|pe @end|ng |rom utoronto@c@  Mon Apr 22 04:57:23 2019
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Mon, 22 Apr 2019 02:57:23 +0000
Subject: [R] Help installing netReg
In-Reply-To: <CAPQaxLNj8jHnwzux3zsYgfmG-tOhrb-iAQUeDeSmR2e6SZNWrg@mail.gmail.com>
References: <CAPQaxLPmhsdh5OaOErFQZXym7JpMY9EuPAjEL70-0DFbDks6LA@mail.gmail.com>
 <2826429b-ff8b-6606-a6ba-c27388075d7f@comcast.net>
 <CAPQaxLM5aJM5uW9NsmXtG1Qbx4Mco7B=uiQ8kdRX+06kGZHCYg@mail.gmail.com>
 <CAPQaxLMXYAzjTJjoCemYVE+Pw47HvZaYAq-=wanTZdnxkE5jaQ@mail.gmail.com>
 <CAGxFJbT-zkTa8xa77VSv+Awr51Dgi4yz+-CxeNfmezDZWNi7-Q@mail.gmail.com>
 <CAPQaxLOoeTeoY0Z+uSMAE7sdHYrTQeDDNoLWzkTSQpk_mjLwBg@mail.gmail.com>
 <CAPQaxLNj8jHnwzux3zsYgfmG-tOhrb-iAQUeDeSmR2e6SZNWrg@mail.gmail.com>
Message-ID: <8102D2B8-110C-487E-9BA4-E03258108692@utoronto.ca>

This is unrelated to the question on the subject line, we call this "thread hijacking" and that's one of the Things Not To Do. Post a new question.

I just wanted to give you the proper incantation for Bioconductor packages. As you already know, don't use bioclite(), which needed to be sourced from an URL. Instead install.packages("Biocmanager") from CRAN, then - there's no need to load it - use Biocmanager::install(<package name>) from there on. I usually have it in scripts like so:

if (! requireNamespace("BiocManager", quietly = TRUE)) {
  install.packages("BiocManager")
}
if (! requireNamespace("biomaRt", quietly = TRUE)) {
  BiocManager::install("biomaRt")
}


Cheers,
Boris

> On 2019-04-21, at 22:27, Spencer Brackett <spbrackett20 at saintjosephhs.com> wrote:
> 
> R users,
> 
>  I am trying to download R Studio onto my Chrombook for convenience, but
> exited out of the Linux terminal that had opened upon my turning on of
> Linux(Beta) through my settings. Because of this I am unable to prompt the
> same type of Linex terminal and can only enable a new one via ctrl alt t .
> Running the same line of commands (as shown below) that I was following
> before encountering my error w/ the first terminal is not working. Note,
> the hostname for the new terminal that I have prompted is crosh> if that
> effects anything.
> 
> Commands I was instructed to make after enabling Linux on my Chrome...
> 
> lsb_release
> sudo apt search r-base | grep ^r-base (to download R)
> 
> -y gnupg2
> ?keyserver keys.gnupg.net ?recv-key ? ?
> ***where my terminal experienced some sort of error causing me to abandon
> it***
> 
> Any pointers for how I may proceed or alternative tutorials that I may
> follow?
> 
> Best,
> 
> Spencer Brackett
> 
> 
> On Sun, Apr 21, 2019 at 9:35 PM Spencer Brackett <
> spbrackett20 at saintjosephhs.com> wrote:
> 
>> Mr. Gunter,
>> 
>> Yes I have reached out to the bioconductor list but was informed that my
>> inquiry concerning this package was not appropriate for the mailing list.
>> However, I have since tried re implementing the code which I sent and my R
>> Studio says that netReg has successfully been unpacked, so for now it
>> appears that my problem is solved :)
>> 
>> Best,
>> 
>> Spencer Brackett
>> 
>> On Sun, Apr 21, 2019 at 8:35 PM Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>> 
>>> netReg is not "the package that generates regression models in R." Tons
>>> of packages generate regression models in R, including lm(), which is in
>>> the stats package that is part of R's standard distro.
>>> 
>>> So what exactly is it that you want to do that you think requires netReg?
>>> And if netReg is required, have you tried addressing your queries to the
>>> Bioconductor list, as it is one of their packages?
>>> 
>>> Cheers,
>>> Bert
>>> 
>>> 
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> 
>>> 
>>> On Sun, Apr 21, 2019 at 5:06 PM Spencer Brackett <
>>> spbrackett20 at saintjosephhs.com> wrote:
>>> 
>>>> Good evening,
>>>> 
>>>> I am having problems with downloading the package used to generate
>>>> regression models on R. The following is the error message I received. I
>>>> tried installing BiocManager instead as suggested, but this too did not
>>>> work. Any ideas?
>>>> 
>>>> The following is the full summary of what I?ve tried thus far...
>>>> 
>>>> install.packages("ggplot2")
>>>> install.packages("ggplot2")
>>>> source("https://bioconductor.org/biocLite.R")
>>>> ?BiocUpgrade
>>>> source("https://bioconductor.org/biocLite.R")biocLite("BiocUpgrade")
>>>> source("https://bioconductor.org/biocLite.R")
>>>> biocLite("BiocUpgrade")
>>>> source("https://bioconductor.org/bioLite.R")
>>>> biocLite("netReg")
>>>> help("Deprecated")
>>>> 'BiocManager::install'
>>>> biocLite("netReg")
>>>> help("oldName-deprecated")
>>>> ???oldName-deprecated?
>>>> .Deprecated(new, package=NULL, msg,
>>>> old = as.character(sys.call(sys.parent()))[1L])
>>>> 
>>>> Best,
>>>> 
>>>> Spencer
>>>> 
>>>> On Sun, Apr 14, 2019 at 7:58 PM Spencer Brackett <
>>>> spbrackett20 at saintjosephhs.com> wrote:
>>>> 
>>>>> My apologies... here is the full code in summary
>>>>> 
>>>>> install.packages("ggplot2")
>>>>> install.packages("ggplot2")
>>>>> source("https://bioconductor.org/biocLite.R")
>>>>> ?BiocUpgrade
>>>>> source("https://bioconductor.org/biocLite.R")biocLite("BiocUpgrade")
>>>>> source("https://bioconductor.org/biocLite.R")
>>>>> biocLite("BiocUpgrade")
>>>>> source("https://bioconductor.org/bioLite.R")
>>>>> biocLite("netReg")
>>>>> help("Deprecated")
>>>>> 'BiocManager::install'
>>>>> biocLite("netReg")
>>>>> help("oldName-deprecated")
>>>>> ???oldName-deprecated?
>>>>> .Deprecated(new, package=NULL, msg,
>>>>> old = as.character(sys.call(sys.parent()))[1L])
>>>>> 
>>>>> Best,
>>>>> 
>>>>> Spencer
>>>>> 
>>>>> 
>>>>> 
>>>>> On Sun, Apr 14, 2019 at 7:20 PM David Winsemius <
>>>> dwinsemius at comcast.net>
>>>>> wrote:
>>>>> 
>>>>>> 
>>>>>> On 4/14/19 3:20 PM, Spencer Brackett wrote:
>>>>>>> Good evening,
>>>>>>> 
>>>>>>>  I am having problems with downloading the package used to generate
>>>>>>> regression models on R. The following is the error message I
>>>> received. I
>>>>>>> tried installing BiocManager instead as suggested, but this too did
>>>> not
>>>>>>> work. Any ideas?
>>>>>>> 
>>>>>>> The downloaded binary packages are in
>>>>>>> C:\Users\Spencer\AppData\Local\Temp\Rtmp8YKVqx\downloaded_packages
>>>>>>> installation path not writeable, unable to update packages: class,
>>>>>> cluster,
>>>>>>> codetools, foreign,
>>>>>>>   lattice, MASS, Matrix, mgcv, nlme, rpart, survival
>>>>>>> Warning message:
>>>>>>> 'biocLite' is deprecated.
>>>>>>> Use 'BiocManager::install' instead.
>>>>>>> See help("Deprecated")
>>>>>> 
>>>>>> 
>>>>>> Since you did not include the code that provoked this message we can
>>>>>> only guess that you did in fact use `bioLite`. We also cannot tell
>>>> what
>>>>>> you mean by "problems with downloading the package used to generate
>>>>>> regression models on R". The typical first step is to use the glm or
>>>> lm
>>>>>> function for this task and those are both in the stats package which
>>>> is
>>>>>> installed with the base version of R and is loaded by default when R
>>>> is
>>>>>> started up.
>>>>>> 
>>>>>> "
>>>>>> 
>>>>>> Have you tried following the suggestion at the end of the message?
>>>>>> 
>>>>>> 
>>>>>> And do read the Posting Guide and include "commented, minimal,
>>>>>> self-contained, reproducible code."
>>>>>> 
>>>>>> 
>>>>>> --
>>>>>> 
>>>>>> David.
>>>>>> 
>>>>>>> 
>>>>>>> Best,
>>>>>>> 
>>>>>>> Spencer
>>>>>>> 
>>>>>>>      [[alternative HTML version deleted]]
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>> 
>>>>> 
>>>> 
>>>>        [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Mon Apr 22 05:49:08 2019
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Sun, 21 Apr 2019 23:49:08 -0400
Subject: [R] Help installing netReg
In-Reply-To: <8102D2B8-110C-487E-9BA4-E03258108692@utoronto.ca>
References: <CAPQaxLPmhsdh5OaOErFQZXym7JpMY9EuPAjEL70-0DFbDks6LA@mail.gmail.com>
 <2826429b-ff8b-6606-a6ba-c27388075d7f@comcast.net>
 <CAPQaxLM5aJM5uW9NsmXtG1Qbx4Mco7B=uiQ8kdRX+06kGZHCYg@mail.gmail.com>
 <CAPQaxLMXYAzjTJjoCemYVE+Pw47HvZaYAq-=wanTZdnxkE5jaQ@mail.gmail.com>
 <CAGxFJbT-zkTa8xa77VSv+Awr51Dgi4yz+-CxeNfmezDZWNi7-Q@mail.gmail.com>
 <CAPQaxLOoeTeoY0Z+uSMAE7sdHYrTQeDDNoLWzkTSQpk_mjLwBg@mail.gmail.com>
 <CAPQaxLNj8jHnwzux3zsYgfmG-tOhrb-iAQUeDeSmR2e6SZNWrg@mail.gmail.com>
 <8102D2B8-110C-487E-9BA4-E03258108692@utoronto.ca>
Message-ID: <CAPQaxLMm1JNO=MR5Fi4cb_n9egtvbaWgbq2j+6970jogT2qCmg@mail.gmail.com>

Boris,
'
My apologies. Thanks for the tip! I tried the command you suggested in your
response and got the following...

> BiocManager::install("netReg")
Bioconductor version 3.8 (BiocManager 1.30.4), R 3.5.1 (2018-07-02)
Installing package(s) 'BiocVersion', 'netReg'
trying URL '
https://bioconductor.org/packages/3.8/bioc/bin/windows/contrib/3.5/BiocVersion_3.8.0.zip
'
Content type 'application/zip' length 8843 bytes
downloaded 8843 bytes

trying URL '
https://bioconductor.org/packages/3.8/bioc/bin/windows/contrib/3.5/netReg_1.6.0.zip
'
Content type 'application/zip' length 4143315 bytes (4.0 MB)
downloaded 4.0 MB

package ?BiocVersion? successfully unpacked and MD5 sums checked
package ?netReg? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
C:\Users\Spencer\AppData\Local\Temp\RtmpW6FwPY\downloaded_packages
installation path not writeable, unable to update packages: class, cluster,
codetools, foreign,
  lattice, MASS, Matrix, mgcv, nlme, rpart, survival

***Does it matter that the packages above are unable to be updated? For
insight, I am trying to generate linear regression models that model
expression of methylation w/ in a TCGA dataset.***

Best,

Spencer

On Sun, Apr 21, 2019 at 10:57 PM Boris Steipe <boris.steipe at utoronto.ca>
wrote:

> This is unrelated to the question on the subject line, we call this
> "thread hijacking" and that's one of the Things Not To Do. Post a new
> question.
>
> I just wanted to give you the proper incantation for Bioconductor
> packages. As you already know, don't use bioclite(), which needed to be
> sourced from an URL. Instead install.packages("Biocmanager") from CRAN,
> then - there's no need to load it - use Biocmanager::install(<package
> name>) from there on. I usually have it in scripts like so:
>
> if (! requireNamespace("BiocManager", quietly = TRUE)) {
>   install.packages("BiocManager")
> }
> if (! requireNamespace("biomaRt", quietly = TRUE)) {
>   BiocManager::install("biomaRt")
> }
>
>
> Cheers,
> Boris
>
> > On 2019-04-21, at 22:27, Spencer Brackett <
> spbrackett20 at saintjosephhs.com> wrote:
> >
> > R users,
> >
> >  I am trying to download R Studio onto my Chrombook for convenience, but
> > exited out of the Linux terminal that had opened upon my turning on of
> > Linux(Beta) through my settings. Because of this I am unable to prompt
> the
> > same type of Linex terminal and can only enable a new one via ctrl alt t
> .
> > Running the same line of commands (as shown below) that I was following
> > before encountering my error w/ the first terminal is not working. Note,
> > the hostname for the new terminal that I have prompted is crosh> if that
> > effects anything.
> >
> > Commands I was instructed to make after enabling Linux on my Chrome...
> >
> > lsb_release
> > sudo apt search r-base | grep ^r-base (to download R)
> >
> > -y gnupg2
> > ?keyserver keys.gnupg.net ?recv-key ? ?
> > ***where my terminal experienced some sort of error causing me to abandon
> > it***
> >
> > Any pointers for how I may proceed or alternative tutorials that I may
> > follow?
> >
> > Best,
> >
> > Spencer Brackett
> >
> >
> > On Sun, Apr 21, 2019 at 9:35 PM Spencer Brackett <
> > spbrackett20 at saintjosephhs.com> wrote:
> >
> >> Mr. Gunter,
> >>
> >> Yes I have reached out to the bioconductor list but was informed that my
> >> inquiry concerning this package was not appropriate for the mailing
> list.
> >> However, I have since tried re implementing the code which I sent and
> my R
> >> Studio says that netReg has successfully been unpacked, so for now it
> >> appears that my problem is solved :)
> >>
> >> Best,
> >>
> >> Spencer Brackett
> >>
> >> On Sun, Apr 21, 2019 at 8:35 PM Bert Gunter <bgunter.4567 at gmail.com>
> >> wrote:
> >>
> >>> netReg is not "the package that generates regression models in R." Tons
> >>> of packages generate regression models in R, including lm(), which is
> in
> >>> the stats package that is part of R's standard distro.
> >>>
> >>> So what exactly is it that you want to do that you think requires
> netReg?
> >>> And if netReg is required, have you tried addressing your queries to
> the
> >>> Bioconductor list, as it is one of their packages?
> >>>
> >>> Cheers,
> >>> Bert
> >>>
> >>>
> >>> "The trouble with having an open mind is that people keep coming along
> >>> and sticking things into it."
> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>
> >>>
> >>> On Sun, Apr 21, 2019 at 5:06 PM Spencer Brackett <
> >>> spbrackett20 at saintjosephhs.com> wrote:
> >>>
> >>>> Good evening,
> >>>>
> >>>> I am having problems with downloading the package used to generate
> >>>> regression models on R. The following is the error message I
> received. I
> >>>> tried installing BiocManager instead as suggested, but this too did
> not
> >>>> work. Any ideas?
> >>>>
> >>>> The following is the full summary of what I?ve tried thus far...
> >>>>
> >>>> install.packages("ggplot2")
> >>>> install.packages("ggplot2")
> >>>> source("https://bioconductor.org/biocLite.R")
> >>>> ?BiocUpgrade
> >>>> source("https://bioconductor.org/biocLite.R")biocLite("BiocUpgrade")
> >>>> source("https://bioconductor.org/biocLite.R")
> >>>> biocLite("BiocUpgrade")
> >>>> source("https://bioconductor.org/bioLite.R")
> >>>> biocLite("netReg")
> >>>> help("Deprecated")
> >>>> 'BiocManager::install'
> >>>> biocLite("netReg")
> >>>> help("oldName-deprecated")
> >>>> ???oldName-deprecated?
> >>>> .Deprecated(new, package=NULL, msg,
> >>>> old = as.character(sys.call(sys.parent()))[1L])
> >>>>
> >>>> Best,
> >>>>
> >>>> Spencer
> >>>>
> >>>> On Sun, Apr 14, 2019 at 7:58 PM Spencer Brackett <
> >>>> spbrackett20 at saintjosephhs.com> wrote:
> >>>>
> >>>>> My apologies... here is the full code in summary
> >>>>>
> >>>>> install.packages("ggplot2")
> >>>>> install.packages("ggplot2")
> >>>>> source("https://bioconductor.org/biocLite.R")
> >>>>> ?BiocUpgrade
> >>>>> source("https://bioconductor.org/biocLite.R")biocLite("BiocUpgrade")
> >>>>> source("https://bioconductor.org/biocLite.R")
> >>>>> biocLite("BiocUpgrade")
> >>>>> source("https://bioconductor.org/bioLite.R")
> >>>>> biocLite("netReg")
> >>>>> help("Deprecated")
> >>>>> 'BiocManager::install'
> >>>>> biocLite("netReg")
> >>>>> help("oldName-deprecated")
> >>>>> ???oldName-deprecated?
> >>>>> .Deprecated(new, package=NULL, msg,
> >>>>> old = as.character(sys.call(sys.parent()))[1L])
> >>>>>
> >>>>> Best,
> >>>>>
> >>>>> Spencer
> >>>>>
> >>>>>
> >>>>>
> >>>>> On Sun, Apr 14, 2019 at 7:20 PM David Winsemius <
> >>>> dwinsemius at comcast.net>
> >>>>> wrote:
> >>>>>
> >>>>>>
> >>>>>> On 4/14/19 3:20 PM, Spencer Brackett wrote:
> >>>>>>> Good evening,
> >>>>>>>
> >>>>>>>  I am having problems with downloading the package used to generate
> >>>>>>> regression models on R. The following is the error message I
> >>>> received. I
> >>>>>>> tried installing BiocManager instead as suggested, but this too did
> >>>> not
> >>>>>>> work. Any ideas?
> >>>>>>>
> >>>>>>> The downloaded binary packages are in
> >>>>>>> C:\Users\Spencer\AppData\Local\Temp\Rtmp8YKVqx\downloaded_packages
> >>>>>>> installation path not writeable, unable to update packages: class,
> >>>>>> cluster,
> >>>>>>> codetools, foreign,
> >>>>>>>   lattice, MASS, Matrix, mgcv, nlme, rpart, survival
> >>>>>>> Warning message:
> >>>>>>> 'biocLite' is deprecated.
> >>>>>>> Use 'BiocManager::install' instead.
> >>>>>>> See help("Deprecated")
> >>>>>>
> >>>>>>
> >>>>>> Since you did not include the code that provoked this message we can
> >>>>>> only guess that you did in fact use `bioLite`. We also cannot tell
> >>>> what
> >>>>>> you mean by "problems with downloading the package used to generate
> >>>>>> regression models on R". The typical first step is to use the glm or
> >>>> lm
> >>>>>> function for this task and those are both in the stats package which
> >>>> is
> >>>>>> installed with the base version of R and is loaded by default when R
> >>>> is
> >>>>>> started up.
> >>>>>>
> >>>>>> "
> >>>>>>
> >>>>>> Have you tried following the suggestion at the end of the message?
> >>>>>>
> >>>>>>
> >>>>>> And do read the Posting Guide and include "commented, minimal,
> >>>>>> self-contained, reproducible code."
> >>>>>>
> >>>>>>
> >>>>>> --
> >>>>>>
> >>>>>> David.
> >>>>>>
> >>>>>>>
> >>>>>>> Best,
> >>>>>>>
> >>>>>>> Spencer
> >>>>>>>
> >>>>>>>      [[alternative HTML version deleted]]
> >>>>>>>
> >>>>>>> ______________________________________________
> >>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>> PLEASE do read the posting guide
> >>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>>
> >>>>>
> >>>>
> >>>>        [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Mon Apr 22 05:53:41 2019
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Sun, 21 Apr 2019 23:53:41 -0400
Subject: [R] Installing R Studio onto Chromebook
Message-ID: <CAPQaxLMyrP5HToqTeZ-QHP6v1LwvU1FXA2yBe7OHMDK+eeHo9Q@mail.gmail.com>

R users,

  I am trying to download R Studio onto my Chromebook for convenience but
exited out of the Linux terminal that had opened upon my turning on of
Linux(Beta) through my settings. Because of this I am unable to prompt the
same type of Linex terminal and can only enable a new one via ctrl alt t .
Running the same line of commands (as shown below) that I was following
before encountering my error w/ the first terminal is not working. In other
words, I am not longer able to automatically prompt the Linux terminal
(hostname 'penguin') through turning on Beta Linux directly via Settings.
Note:  the hostname for the new terminal that I have prompted is crosh> if
that effects anything.

Commands I was instructed to make after enabling Linux on my Chrome...

lsb_release
sudo apt search r-base | grep ^r-base (to download R)

-y gnupg2
?keyserver keys.gnupg.net ?recv-key ? ?
***where my terminal experienced some sort of error causing me to abandon
it***

Any pointers for how I may proceed or alternative tutorials that I may
follow?

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Apr 22 06:03:54 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 21 Apr 2019 21:03:54 -0700
Subject: [R] Installing R Studio onto Chromebook
In-Reply-To: <CAPQaxLMyrP5HToqTeZ-QHP6v1LwvU1FXA2yBe7OHMDK+eeHo9Q@mail.gmail.com>
References: <CAPQaxLMyrP5HToqTeZ-QHP6v1LwvU1FXA2yBe7OHMDK+eeHo9Q@mail.gmail.com>
Message-ID: <CAGxFJbTBKB2YtO8wMjgyNCECSZkwP3kWP7V7xjcYFRsN5nW1OQ@mail.gmail.com>

RStudio is not R.You need to seek help at the RStudio user forum,not here.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Apr 21, 2019 at 8:59 PM Spencer Brackett <
spbrackett20 at saintjosephhs.com> wrote:

> R users,
>
>   I am trying to download R Studio onto my Chromebook for convenience but
> exited out of the Linux terminal that had opened upon my turning on of
> Linux(Beta) through my settings. Because of this I am unable to prompt the
> same type of Linex terminal and can only enable a new one via ctrl alt t .
> Running the same line of commands (as shown below) that I was following
> before encountering my error w/ the first terminal is not working. In other
> words, I am not longer able to automatically prompt the Linux terminal
> (hostname 'penguin') through turning on Beta Linux directly via Settings.
> Note:  the hostname for the new terminal that I have prompted is crosh> if
> that effects anything.
>
> Commands I was instructed to make after enabling Linux on my Chrome...
>
> lsb_release
> sudo apt search r-base | grep ^r-base (to download R)
>
> -y gnupg2
> ?keyserver keys.gnupg.net ?recv-key ? ?
> ***where my terminal experienced some sort of error causing me to abandon
> it***
>
> Any pointers for how I may proceed or alternative tutorials that I may
> follow?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bor|@@@te|pe @end|ng |rom utoronto@c@  Mon Apr 22 06:04:50 2019
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Mon, 22 Apr 2019 04:04:50 +0000
Subject: [R] Help installing netReg
In-Reply-To: <CAPQaxLMm1JNO=MR5Fi4cb_n9egtvbaWgbq2j+6970jogT2qCmg@mail.gmail.com>
References: <CAPQaxLPmhsdh5OaOErFQZXym7JpMY9EuPAjEL70-0DFbDks6LA@mail.gmail.com>
 <2826429b-ff8b-6606-a6ba-c27388075d7f@comcast.net>
 <CAPQaxLM5aJM5uW9NsmXtG1Qbx4Mco7B=uiQ8kdRX+06kGZHCYg@mail.gmail.com>
 <CAPQaxLMXYAzjTJjoCemYVE+Pw47HvZaYAq-=wanTZdnxkE5jaQ@mail.gmail.com>
 <CAGxFJbT-zkTa8xa77VSv+Awr51Dgi4yz+-CxeNfmezDZWNi7-Q@mail.gmail.com>
 <CAPQaxLOoeTeoY0Z+uSMAE7sdHYrTQeDDNoLWzkTSQpk_mjLwBg@mail.gmail.com>
 <CAPQaxLNj8jHnwzux3zsYgfmG-tOhrb-iAQUeDeSmR2e6SZNWrg@mail.gmail.com>
 <8102D2B8-110C-487E-9BA4-E03258108692@utoronto.ca>
 <CAPQaxLMm1JNO=MR5Fi4cb_n9egtvbaWgbq2j+6970jogT2qCmg@mail.gmail.com>
Message-ID: <F723CEA2-0CDD-483B-B6FA-5F88C10FCB77@utoronto.ca>

"installation path not writeable" tells you that there is a permissions problem with your setup. Sounds like a pretty standard problem. Someone who works with Windows will know the standard solution.

Cheers,
B.



> On 2019-04-21, at 23:49, Spencer Brackett <spbrackett20 at saintjosephhs.com> wrote:
> 
> Boris, 
> '
> My apologies. Thanks for the tip! I tried the command you suggested in your response and got the following...
> 
> > BiocManager::install("netReg")
> Bioconductor version 3.8 (BiocManager 1.30.4), R 3.5.1 (2018-07-02)
> Installing package(s) 'BiocVersion', 'netReg'
> trying URL 'https://bioconductor.org/packages/3.8/bioc/bin/windows/contrib/3.5/BiocVersion_3.8.0.zip'
> Content type 'application/zip' length 8843 bytes
> downloaded 8843 bytes
> 
> trying URL 'https://bioconductor.org/packages/3.8/bioc/bin/windows/contrib/3.5/netReg_1.6.0.zip'
> Content type 'application/zip' length 4143315 bytes (4.0 MB)
> downloaded 4.0 MB
> 
> package ?BiocVersion? successfully unpacked and MD5 sums checked
> package ?netReg? successfully unpacked and MD5 sums checked
> 
> The downloaded binary packages are in
> 	C:\Users\Spencer\AppData\Local\Temp\RtmpW6FwPY\downloaded_packages
> installation path not writeable, unable to update packages: class, cluster, codetools, foreign,
>   lattice, MASS, Matrix, mgcv, nlme, rpart, survival
> 
> ***Does it matter that the packages above are unable to be updated? For insight, I am trying to generate linear regression models that model expression of methylation w/ in a TCGA dataset.***
> 
> Best, 
> 
> Spencer
> 
> On Sun, Apr 21, 2019 at 10:57 PM Boris Steipe <boris.steipe at utoronto.ca> wrote:
> This is unrelated to the question on the subject line, we call this "thread hijacking" and that's one of the Things Not To Do. Post a new question.
> 
> I just wanted to give you the proper incantation for Bioconductor packages. As you already know, don't use bioclite(), which needed to be sourced from an URL. Instead install.packages("Biocmanager") from CRAN, then - there's no need to load it - use Biocmanager::install(<package name>) from there on. I usually have it in scripts like so:
> 
> if (! requireNamespace("BiocManager", quietly = TRUE)) {
>   install.packages("BiocManager")
> }
> if (! requireNamespace("biomaRt", quietly = TRUE)) {
>   BiocManager::install("biomaRt")
> }
> 
> 
> Cheers,
> Boris
> 
> > On 2019-04-21, at 22:27, Spencer Brackett <spbrackett20 at saintjosephhs.com> wrote:
> > 
> > R users,
> > 
> >  I am trying to download R Studio onto my Chrombook for convenience, but
> > exited out of the Linux terminal that had opened upon my turning on of
> > Linux(Beta) through my settings. Because of this I am unable to prompt the
> > same type of Linex terminal and can only enable a new one via ctrl alt t .
> > Running the same line of commands (as shown below) that I was following
> > before encountering my error w/ the first terminal is not working. Note,
> > the hostname for the new terminal that I have prompted is crosh> if that
> > effects anything.
> > 
> > Commands I was instructed to make after enabling Linux on my Chrome...
> > 
> > lsb_release
> > sudo apt search r-base | grep ^r-base (to download R)
> > 
> > -y gnupg2
> > ?keyserver keys.gnupg.net ?recv-key ? ?
> > ***where my terminal experienced some sort of error causing me to abandon
> > it***
> > 
> > Any pointers for how I may proceed or alternative tutorials that I may
> > follow?
> > 
> > Best,
> > 
> > Spencer Brackett
> > 
> > 
> > On Sun, Apr 21, 2019 at 9:35 PM Spencer Brackett <
> > spbrackett20 at saintjosephhs.com> wrote:
> > 
> >> Mr. Gunter,
> >> 
> >> Yes I have reached out to the bioconductor list but was informed that my
> >> inquiry concerning this package was not appropriate for the mailing list.
> >> However, I have since tried re implementing the code which I sent and my R
> >> Studio says that netReg has successfully been unpacked, so for now it
> >> appears that my problem is solved :)
> >> 
> >> Best,
> >> 
> >> Spencer Brackett
> >> 
> >> On Sun, Apr 21, 2019 at 8:35 PM Bert Gunter <bgunter.4567 at gmail.com>
> >> wrote:
> >> 
> >>> netReg is not "the package that generates regression models in R." Tons
> >>> of packages generate regression models in R, including lm(), which is in
> >>> the stats package that is part of R's standard distro.
> >>> 
> >>> So what exactly is it that you want to do that you think requires netReg?
> >>> And if netReg is required, have you tried addressing your queries to the
> >>> Bioconductor list, as it is one of their packages?
> >>> 
> >>> Cheers,
> >>> Bert
> >>> 
> >>> 
> >>> "The trouble with having an open mind is that people keep coming along
> >>> and sticking things into it."
> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>> 
> >>> 
> >>> On Sun, Apr 21, 2019 at 5:06 PM Spencer Brackett <
> >>> spbrackett20 at saintjosephhs.com> wrote:
> >>> 
> >>>> Good evening,
> >>>> 
> >>>> I am having problems with downloading the package used to generate
> >>>> regression models on R. The following is the error message I received. I
> >>>> tried installing BiocManager instead as suggested, but this too did not
> >>>> work. Any ideas?
> >>>> 
> >>>> The following is the full summary of what I?ve tried thus far...
> >>>> 
> >>>> install.packages("ggplot2")
> >>>> install.packages("ggplot2")
> >>>> source("https://bioconductor.org/biocLite.R")
> >>>> ?BiocUpgrade
> >>>> source("https://bioconductor.org/biocLite.R")biocLite("BiocUpgrade")
> >>>> source("https://bioconductor.org/biocLite.R")
> >>>> biocLite("BiocUpgrade")
> >>>> source("https://bioconductor.org/bioLite.R")
> >>>> biocLite("netReg")
> >>>> help("Deprecated")
> >>>> 'BiocManager::install'
> >>>> biocLite("netReg")
> >>>> help("oldName-deprecated")
> >>>> ???oldName-deprecated?
> >>>> .Deprecated(new, package=NULL, msg,
> >>>> old = as.character(sys.call(sys.parent()))[1L])
> >>>> 
> >>>> Best,
> >>>> 
> >>>> Spencer
> >>>> 
> >>>> On Sun, Apr 14, 2019 at 7:58 PM Spencer Brackett <
> >>>> spbrackett20 at saintjosephhs.com> wrote:
> >>>> 
> >>>>> My apologies... here is the full code in summary
> >>>>> 
> >>>>> install.packages("ggplot2")
> >>>>> install.packages("ggplot2")
> >>>>> source("https://bioconductor.org/biocLite.R")
> >>>>> ?BiocUpgrade
> >>>>> source("https://bioconductor.org/biocLite.R")biocLite("BiocUpgrade")
> >>>>> source("https://bioconductor.org/biocLite.R")
> >>>>> biocLite("BiocUpgrade")
> >>>>> source("https://bioconductor.org/bioLite.R")
> >>>>> biocLite("netReg")
> >>>>> help("Deprecated")
> >>>>> 'BiocManager::install'
> >>>>> biocLite("netReg")
> >>>>> help("oldName-deprecated")
> >>>>> ???oldName-deprecated?
> >>>>> .Deprecated(new, package=NULL, msg,
> >>>>> old = as.character(sys.call(sys.parent()))[1L])
> >>>>> 
> >>>>> Best,
> >>>>> 
> >>>>> Spencer
> >>>>> 
> >>>>> 
> >>>>> 
> >>>>> On Sun, Apr 14, 2019 at 7:20 PM David Winsemius <
> >>>> dwinsemius at comcast.net>
> >>>>> wrote:
> >>>>> 
> >>>>>> 
> >>>>>> On 4/14/19 3:20 PM, Spencer Brackett wrote:
> >>>>>>> Good evening,
> >>>>>>> 
> >>>>>>>  I am having problems with downloading the package used to generate
> >>>>>>> regression models on R. The following is the error message I
> >>>> received. I
> >>>>>>> tried installing BiocManager instead as suggested, but this too did
> >>>> not
> >>>>>>> work. Any ideas?
> >>>>>>> 
> >>>>>>> The downloaded binary packages are in
> >>>>>>> C:\Users\Spencer\AppData\Local\Temp\Rtmp8YKVqx\downloaded_packages
> >>>>>>> installation path not writeable, unable to update packages: class,
> >>>>>> cluster,
> >>>>>>> codetools, foreign,
> >>>>>>>   lattice, MASS, Matrix, mgcv, nlme, rpart, survival
> >>>>>>> Warning message:
> >>>>>>> 'biocLite' is deprecated.
> >>>>>>> Use 'BiocManager::install' instead.
> >>>>>>> See help("Deprecated")
> >>>>>> 
> >>>>>> 
> >>>>>> Since you did not include the code that provoked this message we can
> >>>>>> only guess that you did in fact use `bioLite`. We also cannot tell
> >>>> what
> >>>>>> you mean by "problems with downloading the package used to generate
> >>>>>> regression models on R". The typical first step is to use the glm or
> >>>> lm
> >>>>>> function for this task and those are both in the stats package which
> >>>> is
> >>>>>> installed with the base version of R and is loaded by default when R
> >>>> is
> >>>>>> started up.
> >>>>>> 
> >>>>>> "
> >>>>>> 
> >>>>>> Have you tried following the suggestion at the end of the message?
> >>>>>> 
> >>>>>> 
> >>>>>> And do read the Posting Guide and include "commented, minimal,
> >>>>>> self-contained, reproducible code."
> >>>>>> 
> >>>>>> 
> >>>>>> --
> >>>>>> 
> >>>>>> David.
> >>>>>> 
> >>>>>>> 
> >>>>>>> Best,
> >>>>>>> 
> >>>>>>> Spencer
> >>>>>>> 
> >>>>>>>      [[alternative HTML version deleted]]
> >>>>>>> 
> >>>>>>> ______________________________________________
> >>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>> PLEASE do read the posting guide
> >>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>> 
> >>>>> 
> >>>> 
> >>>>        [[alternative HTML version deleted]]
> >>>> 
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>> 
> >>> 
> > 
> >       [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Apr 22 06:22:19 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 21 Apr 2019 21:22:19 -0700
Subject: [R] Help installing netReg
In-Reply-To: <CAPQaxLMm1JNO=MR5Fi4cb_n9egtvbaWgbq2j+6970jogT2qCmg@mail.gmail.com>
References: <CAPQaxLPmhsdh5OaOErFQZXym7JpMY9EuPAjEL70-0DFbDks6LA@mail.gmail.com>
 <2826429b-ff8b-6606-a6ba-c27388075d7f@comcast.net>
 <CAPQaxLM5aJM5uW9NsmXtG1Qbx4Mco7B=uiQ8kdRX+06kGZHCYg@mail.gmail.com>
 <CAPQaxLMXYAzjTJjoCemYVE+Pw47HvZaYAq-=wanTZdnxkE5jaQ@mail.gmail.com>
 <CAGxFJbT-zkTa8xa77VSv+Awr51Dgi4yz+-CxeNfmezDZWNi7-Q@mail.gmail.com>
 <CAPQaxLOoeTeoY0Z+uSMAE7sdHYrTQeDDNoLWzkTSQpk_mjLwBg@mail.gmail.com>
 <CAPQaxLNj8jHnwzux3zsYgfmG-tOhrb-iAQUeDeSmR2e6SZNWrg@mail.gmail.com>
 <8102D2B8-110C-487E-9BA4-E03258108692@utoronto.ca>
 <CAPQaxLMm1JNO=MR5Fi4cb_n9egtvbaWgbq2j+6970jogT2qCmg@mail.gmail.com>
Message-ID: <2FB686C4-615B-4476-9A39-521C94E2A6AC@dcn.davis.ca.us>

I don't know anything about the Bioconductor installation, but it is normal practice on Windows to install updates to packages distributed with R (such as those below) by "superceding" them in your user library. This happens automatically if you don't specify the destination library to install to. Just do a normal update.packages and the Program Files library will stay unchanged but your user library versions of the base R packages will be loaded instead.

On April 21, 2019 8:49:08 PM PDT, Spencer Brackett <spbrackett20 at saintjosephhs.com> wrote:
>Boris,
>'
>My apologies. Thanks for the tip! I tried the command you suggested in
>your
>response and got the following...
>
>> BiocManager::install("netReg")
>Bioconductor version 3.8 (BiocManager 1.30.4), R 3.5.1 (2018-07-02)
>Installing package(s) 'BiocVersion', 'netReg'
>trying URL '
>https://bioconductor.org/packages/3.8/bioc/bin/windows/contrib/3.5/BiocVersion_3.8.0.zip
>'
>Content type 'application/zip' length 8843 bytes
>downloaded 8843 bytes
>
>trying URL '
>https://bioconductor.org/packages/3.8/bioc/bin/windows/contrib/3.5/netReg_1.6.0.zip
>'
>Content type 'application/zip' length 4143315 bytes (4.0 MB)
>downloaded 4.0 MB
>
>package ?BiocVersion? successfully unpacked and MD5 sums checked
>package ?netReg? successfully unpacked and MD5 sums checked
>
>The downloaded binary packages are in
>C:\Users\Spencer\AppData\Local\Temp\RtmpW6FwPY\downloaded_packages
>installation path not writeable, unable to update packages: class,
>cluster,
>codetools, foreign,
>  lattice, MASS, Matrix, mgcv, nlme, rpart, survival
>
>***Does it matter that the packages above are unable to be updated? For
>insight, I am trying to generate linear regression models that model
>expression of methylation w/ in a TCGA dataset.***
>
>Best,
>
>Spencer
>
>On Sun, Apr 21, 2019 at 10:57 PM Boris Steipe
><boris.steipe at utoronto.ca>
>wrote:
>
>> This is unrelated to the question on the subject line, we call this
>> "thread hijacking" and that's one of the Things Not To Do. Post a new
>> question.
>>
>> I just wanted to give you the proper incantation for Bioconductor
>> packages. As you already know, don't use bioclite(), which needed to
>be
>> sourced from an URL. Instead install.packages("Biocmanager") from
>CRAN,
>> then - there's no need to load it - use Biocmanager::install(<package
>> name>) from there on. I usually have it in scripts like so:
>>
>> if (! requireNamespace("BiocManager", quietly = TRUE)) {
>>   install.packages("BiocManager")
>> }
>> if (! requireNamespace("biomaRt", quietly = TRUE)) {
>>   BiocManager::install("biomaRt")
>> }
>>
>>
>> Cheers,
>> Boris
>>
>> > On 2019-04-21, at 22:27, Spencer Brackett <
>> spbrackett20 at saintjosephhs.com> wrote:
>> >
>> > R users,
>> >
>> >  I am trying to download R Studio onto my Chrombook for
>convenience, but
>> > exited out of the Linux terminal that had opened upon my turning on
>of
>> > Linux(Beta) through my settings. Because of this I am unable to
>prompt
>> the
>> > same type of Linex terminal and can only enable a new one via ctrl
>alt t
>> .
>> > Running the same line of commands (as shown below) that I was
>following
>> > before encountering my error w/ the first terminal is not working.
>Note,
>> > the hostname for the new terminal that I have prompted is crosh> if
>that
>> > effects anything.
>> >
>> > Commands I was instructed to make after enabling Linux on my
>Chrome...
>> >
>> > lsb_release
>> > sudo apt search r-base | grep ^r-base (to download R)
>> >
>> > -y gnupg2
>> > ?keyserver keys.gnupg.net ?recv-key ? ?
>> > ***where my terminal experienced some sort of error causing me to
>abandon
>> > it***
>> >
>> > Any pointers for how I may proceed or alternative tutorials that I
>may
>> > follow?
>> >
>> > Best,
>> >
>> > Spencer Brackett
>> >
>> >
>> > On Sun, Apr 21, 2019 at 9:35 PM Spencer Brackett <
>> > spbrackett20 at saintjosephhs.com> wrote:
>> >
>> >> Mr. Gunter,
>> >>
>> >> Yes I have reached out to the bioconductor list but was informed
>that my
>> >> inquiry concerning this package was not appropriate for the
>mailing
>> list.
>> >> However, I have since tried re implementing the code which I sent
>and
>> my R
>> >> Studio says that netReg has successfully been unpacked, so for now
>it
>> >> appears that my problem is solved :)
>> >>
>> >> Best,
>> >>
>> >> Spencer Brackett
>> >>
>> >> On Sun, Apr 21, 2019 at 8:35 PM Bert Gunter
><bgunter.4567 at gmail.com>
>> >> wrote:
>> >>
>> >>> netReg is not "the package that generates regression models in
>R." Tons
>> >>> of packages generate regression models in R, including lm(),
>which is
>> in
>> >>> the stats package that is part of R's standard distro.
>> >>>
>> >>> So what exactly is it that you want to do that you think requires
>> netReg?
>> >>> And if netReg is required, have you tried addressing your queries
>to
>> the
>> >>> Bioconductor list, as it is one of their packages?
>> >>>
>> >>> Cheers,
>> >>> Bert
>> >>>
>> >>>
>> >>> "The trouble with having an open mind is that people keep coming
>along
>> >>> and sticking things into it."
>> >>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip
>)
>> >>>
>> >>>
>> >>> On Sun, Apr 21, 2019 at 5:06 PM Spencer Brackett <
>> >>> spbrackett20 at saintjosephhs.com> wrote:
>> >>>
>> >>>> Good evening,
>> >>>>
>> >>>> I am having problems with downloading the package used to
>generate
>> >>>> regression models on R. The following is the error message I
>> received. I
>> >>>> tried installing BiocManager instead as suggested, but this too
>did
>> not
>> >>>> work. Any ideas?
>> >>>>
>> >>>> The following is the full summary of what I?ve tried thus far...
>> >>>>
>> >>>> install.packages("ggplot2")
>> >>>> install.packages("ggplot2")
>> >>>> source("https://bioconductor.org/biocLite.R")
>> >>>> ?BiocUpgrade
>> >>>>
>source("https://bioconductor.org/biocLite.R")biocLite("BiocUpgrade")
>> >>>> source("https://bioconductor.org/biocLite.R")
>> >>>> biocLite("BiocUpgrade")
>> >>>> source("https://bioconductor.org/bioLite.R")
>> >>>> biocLite("netReg")
>> >>>> help("Deprecated")
>> >>>> 'BiocManager::install'
>> >>>> biocLite("netReg")
>> >>>> help("oldName-deprecated")
>> >>>> ???oldName-deprecated?
>> >>>> .Deprecated(new, package=NULL, msg,
>> >>>> old = as.character(sys.call(sys.parent()))[1L])
>> >>>>
>> >>>> Best,
>> >>>>
>> >>>> Spencer
>> >>>>
>> >>>> On Sun, Apr 14, 2019 at 7:58 PM Spencer Brackett <
>> >>>> spbrackett20 at saintjosephhs.com> wrote:
>> >>>>
>> >>>>> My apologies... here is the full code in summary
>> >>>>>
>> >>>>> install.packages("ggplot2")
>> >>>>> install.packages("ggplot2")
>> >>>>> source("https://bioconductor.org/biocLite.R")
>> >>>>> ?BiocUpgrade
>> >>>>>
>source("https://bioconductor.org/biocLite.R")biocLite("BiocUpgrade")
>> >>>>> source("https://bioconductor.org/biocLite.R")
>> >>>>> biocLite("BiocUpgrade")
>> >>>>> source("https://bioconductor.org/bioLite.R")
>> >>>>> biocLite("netReg")
>> >>>>> help("Deprecated")
>> >>>>> 'BiocManager::install'
>> >>>>> biocLite("netReg")
>> >>>>> help("oldName-deprecated")
>> >>>>> ???oldName-deprecated?
>> >>>>> .Deprecated(new, package=NULL, msg,
>> >>>>> old = as.character(sys.call(sys.parent()))[1L])
>> >>>>>
>> >>>>> Best,
>> >>>>>
>> >>>>> Spencer
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>> On Sun, Apr 14, 2019 at 7:20 PM David Winsemius <
>> >>>> dwinsemius at comcast.net>
>> >>>>> wrote:
>> >>>>>
>> >>>>>>
>> >>>>>> On 4/14/19 3:20 PM, Spencer Brackett wrote:
>> >>>>>>> Good evening,
>> >>>>>>>
>> >>>>>>>  I am having problems with downloading the package used to
>generate
>> >>>>>>> regression models on R. The following is the error message I
>> >>>> received. I
>> >>>>>>> tried installing BiocManager instead as suggested, but this
>too did
>> >>>> not
>> >>>>>>> work. Any ideas?
>> >>>>>>>
>> >>>>>>> The downloaded binary packages are in
>> >>>>>>>
>C:\Users\Spencer\AppData\Local\Temp\Rtmp8YKVqx\downloaded_packages
>> >>>>>>> installation path not writeable, unable to update packages:
>class,
>> >>>>>> cluster,
>> >>>>>>> codetools, foreign,
>> >>>>>>>   lattice, MASS, Matrix, mgcv, nlme, rpart, survival
>> >>>>>>> Warning message:
>> >>>>>>> 'biocLite' is deprecated.
>> >>>>>>> Use 'BiocManager::install' instead.
>> >>>>>>> See help("Deprecated")
>> >>>>>>
>> >>>>>>
>> >>>>>> Since you did not include the code that provoked this message
>we can
>> >>>>>> only guess that you did in fact use `bioLite`. We also cannot
>tell
>> >>>> what
>> >>>>>> you mean by "problems with downloading the package used to
>generate
>> >>>>>> regression models on R". The typical first step is to use the
>glm or
>> >>>> lm
>> >>>>>> function for this task and those are both in the stats package
>which
>> >>>> is
>> >>>>>> installed with the base version of R and is loaded by default
>when R
>> >>>> is
>> >>>>>> started up.
>> >>>>>>
>> >>>>>> "
>> >>>>>>
>> >>>>>> Have you tried following the suggestion at the end of the
>message?
>> >>>>>>
>> >>>>>>
>> >>>>>> And do read the Posting Guide and include "commented, minimal,
>> >>>>>> self-contained, reproducible code."
>> >>>>>>
>> >>>>>>
>> >>>>>> --
>> >>>>>>
>> >>>>>> David.
>> >>>>>>
>> >>>>>>>
>> >>>>>>> Best,
>> >>>>>>>
>> >>>>>>> Spencer
>> >>>>>>>
>> >>>>>>>      [[alternative HTML version deleted]]
>> >>>>>>>
>> >>>>>>> ______________________________________________
>> >>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>>>>> PLEASE do read the posting guide
>> >>>>>> http://www.R-project.org/posting-guide.html
>> >>>>>>> and provide commented, minimal, self-contained, reproducible
>code.
>> >>>>>>
>> >>>>>
>> >>>>
>> >>>>        [[alternative HTML version deleted]]
>> >>>>
>> >>>> ______________________________________________
>> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>> PLEASE do read the posting guide
>> >>>> http://www.R-project.org/posting-guide.html
>> >>>> and provide commented, minimal, self-contained, reproducible
>code.
>> >>>>
>> >>>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Apr 22 07:29:16 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 21 Apr 2019 22:29:16 -0700
Subject: [R] Example for  Roxygen @eval tag?
In-Reply-To: <8CAFE8EB-9356-4DD6-A9EE-834B1A027211@utoronto.ca>
References: <8CAFE8EB-9356-4DD6-A9EE-834B1A027211@utoronto.ca>
Message-ID: <AF82D83F-3C8E-4CC6-80C6-08603C2C446A@dcn.davis.ca.us>

I have not used it... but did you read the vignette [1]? It sounds like it is a bit more meta than you think it is...

[1] https://cran.r-project.org/web/packages/roxygen2/vignettes/rd.html

On April 21, 2019 7:44:17 PM PDT, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>Playing with Roxygen features, but can't get @eval to work. E.g. ...
>
>#' @eval sprintf("%s", Sys.time())
>
>... does not do what I thought it would (i.e. substitute the tag and
>the expression with the string). Instead I see nothing in the .RD file.
>
>Any working examples out there?
>Thanks!
>Boris
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bor|@@@te|pe @end|ng |rom utoronto@c@  Mon Apr 22 07:40:27 2019
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Mon, 22 Apr 2019 05:40:27 +0000
Subject: [R] Example for  Roxygen @eval tag?
In-Reply-To: <AF82D83F-3C8E-4CC6-80C6-08603C2C446A@dcn.davis.ca.us>
References: <8CAFE8EB-9356-4DD6-A9EE-834B1A027211@utoronto.ca>
 <AF82D83F-3C8E-4CC6-80C6-08603C2C446A@dcn.davis.ca.us>
Message-ID: <BDB22E42-3D80-4D0A-86A3-1D23F51F9AA1@utoronto.ca>

Yes, that's where I started -  the vignette says:

    ... Run arbtirary R code with @eval.

    ... the @eval tag. It evaluates code and treats the result as if it
    was a literal roxygen tags. This makes it possible to eliminate
    duplication by writing functions.

The first thing I noticed was that it does not say anything about delimiters. By trial and error it seems to consider everything up to the next @... tag in the header. Things that are not R code create an error during devtools::document() processing. It seems the output is captured and processed, i.e. System.time() creates a not-a-string error, but as.character(System.time()) passes ... but then nothing appears in the .Rd - and I haven't been able to find a single example of @eval in use in the wild.

No joy.




> On 2019-04-22, at 01:29, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> I have not used it... but did you read the vignette [1]? It sounds like it is a bit more meta than you think it is...
> 
> [1] https://cran.r-project.org/web/packages/roxygen2/vignettes/rd.html
> 
> On April 21, 2019 7:44:17 PM PDT, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>> Playing with Roxygen features, but can't get @eval to work. E.g. ...
>> 
>> #' @eval sprintf("%s", Sys.time())
>> 
>> ... does not do what I thought it would (i.e. substitute the tag and
>> the expression with the string). Instead I see nothing in the .RD file.
>> 
>> Any working examples out there?
>> Thanks!
>> Boris
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Sent from my phone. Please excuse my brevity.


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Apr 22 08:25:30 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 21 Apr 2019 23:25:30 -0700
Subject: [R] Example for  Roxygen @eval tag?
In-Reply-To: <BDB22E42-3D80-4D0A-86A3-1D23F51F9AA1@utoronto.ca>
References: <8CAFE8EB-9356-4DD6-A9EE-834B1A027211@utoronto.ca>
 <AF82D83F-3C8E-4CC6-80C6-08603C2C446A@dcn.davis.ca.us>
 <BDB22E42-3D80-4D0A-86A3-1D23F51F9AA1@utoronto.ca>
Message-ID: <9308C8A3-D4D1-4052-88D4-413DF6D889DA@dcn.davis.ca.us>

What tag are you creating with the eval? Your example wouldn't create valid roxygen code... as I said, it looks rather meta....

On April 21, 2019 10:40:27 PM PDT, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>Yes, that's where I started -  the vignette says:
>
>    ... Run arbtirary R code with @eval.
>
>    ... the @eval tag. It evaluates code and treats the result as if it
>    was a literal roxygen tags. This makes it possible to eliminate
>    duplication by writing functions.
>
>The first thing I noticed was that it does not say anything about
>delimiters. By trial and error it seems to consider everything up to
>the next @... tag in the header. Things that are not R code create an
>error during devtools::document() processing. It seems the output is
>captured and processed, i.e. System.time() creates a not-a-string
>error, but as.character(System.time()) passes ... but then nothing
>appears in the .Rd - and I haven't been able to find a single example
>of @eval in use in the wild.
>
>No joy.
>
>
>
>
>> On 2019-04-22, at 01:29, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>> 
>> I have not used it... but did you read the vignette [1]? It sounds
>like it is a bit more meta than you think it is...
>> 
>> [1]
>https://cran.r-project.org/web/packages/roxygen2/vignettes/rd.html
>> 
>> On April 21, 2019 7:44:17 PM PDT, Boris Steipe
><boris.steipe at utoronto.ca> wrote:
>>> Playing with Roxygen features, but can't get @eval to work. E.g. ...
>>> 
>>> #' @eval sprintf("%s", Sys.time())
>>> 
>>> ... does not do what I thought it would (i.e. substitute the tag and
>>> the expression with the string). Instead I see nothing in the .RD
>file.
>>> 
>>> Any working examples out there?
>>> Thanks!
>>> Boris
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> -- 
>> Sent from my phone. Please excuse my brevity.

-- 
Sent from my phone. Please excuse my brevity.


From b|oprogr@mmer @end|ng |rom gm@||@com  Mon Apr 22 08:34:16 2019
From: b|oprogr@mmer @end|ng |rom gm@||@com (Caitlin Gibbons)
Date: Sun, 21 Apr 2019 23:34:16 -0700
Subject: [R] Help installing netReg
In-Reply-To: <2FB686C4-615B-4476-9A39-521C94E2A6AC@dcn.davis.ca.us>
References: <CAPQaxLPmhsdh5OaOErFQZXym7JpMY9EuPAjEL70-0DFbDks6LA@mail.gmail.com>
 <2826429b-ff8b-6606-a6ba-c27388075d7f@comcast.net>
 <CAPQaxLM5aJM5uW9NsmXtG1Qbx4Mco7B=uiQ8kdRX+06kGZHCYg@mail.gmail.com>
 <CAPQaxLMXYAzjTJjoCemYVE+Pw47HvZaYAq-=wanTZdnxkE5jaQ@mail.gmail.com>
 <CAGxFJbT-zkTa8xa77VSv+Awr51Dgi4yz+-CxeNfmezDZWNi7-Q@mail.gmail.com>
 <CAPQaxLOoeTeoY0Z+uSMAE7sdHYrTQeDDNoLWzkTSQpk_mjLwBg@mail.gmail.com>
 <CAPQaxLNj8jHnwzux3zsYgfmG-tOhrb-iAQUeDeSmR2e6SZNWrg@mail.gmail.com>
 <8102D2B8-110C-487E-9BA4-E03258108692@utoronto.ca>
 <CAPQaxLMm1JNO=MR5Fi4cb_n9egtvbaWgbq2j+6970jogT2qCmg@mail.gmail.com>
 <2FB686C4-615B-4476-9A39-521C94E2A6AC@dcn.davis.ca.us>
Message-ID: <891EF976-9601-4856-843B-6B9A7EC5D56B@gmail.com>

Hi Spencer.

On a Windows machine, the message ?Installation path not writeable? can be solved by starting RStudio as an administrator. Right click the RStudio icon and select ?Run as Administrator?. This should solve that problem. 

Hope this helps. 

~Caitlin


Sent from my iPhone

> On Apr 21, 2019, at 9:22 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> I don't know anything about the Bioconductor installation, but it is normal practice on Windows to install updates to packages distributed with R (such as those below) by "superceding" them in your user library. This happens automatically if you don't specify the destination library to install to. Just do a normal update.packages and the Program Files library will stay unchanged but your user library versions of the base R packages will be loaded instead.
> 
>> On April 21, 2019 8:49:08 PM PDT, Spencer Brackett <spbrackett20 at saintjosephhs.com> wrote:
>> Boris,
>> '
>> My apologies. Thanks for the tip! I tried the command you suggested in
>> your
>> response and got the following...
>> 
>>> BiocManager::install("netReg")
>> Bioconductor version 3.8 (BiocManager 1.30.4), R 3.5.1 (2018-07-02)
>> Installing package(s) 'BiocVersion', 'netReg'
>> trying URL '
>> https://bioconductor.org/packages/3.8/bioc/bin/windows/contrib/3.5/BiocVersion_3.8.0.zip
>> '
>> Content type 'application/zip' length 8843 bytes
>> downloaded 8843 bytes
>> 
>> trying URL '
>> https://bioconductor.org/packages/3.8/bioc/bin/windows/contrib/3.5/netReg_1.6.0.zip
>> '
>> Content type 'application/zip' length 4143315 bytes (4.0 MB)
>> downloaded 4.0 MB
>> 
>> package ?BiocVersion? successfully unpacked and MD5 sums checked
>> package ?netReg? successfully unpacked and MD5 sums checked
>> 
>> The downloaded binary packages are in
>> C:\Users\Spencer\AppData\Local\Temp\RtmpW6FwPY\downloaded_packages
>> installation path not writeable, unable to update packages: class,
>> cluster,
>> codetools, foreign,
>> lattice, MASS, Matrix, mgcv, nlme, rpart, survival
>> 
>> ***Does it matter that the packages above are unable to be updated? For
>> insight, I am trying to generate linear regression models that model
>> expression of methylation w/ in a TCGA dataset.***
>> 
>> Best,
>> 
>> Spencer
>> 
>> On Sun, Apr 21, 2019 at 10:57 PM Boris Steipe
>> <boris.steipe at utoronto.ca>
>> wrote:
>> 
>>> This is unrelated to the question on the subject line, we call this
>>> "thread hijacking" and that's one of the Things Not To Do. Post a new
>>> question.
>>> 
>>> I just wanted to give you the proper incantation for Bioconductor
>>> packages. As you already know, don't use bioclite(), which needed to
>> be
>>> sourced from an URL. Instead install.packages("Biocmanager") from
>> CRAN,
>>> then - there's no need to load it - use Biocmanager::install(<package
>>> name>) from there on. I usually have it in scripts like so:
>>> 
>>> if (! requireNamespace("BiocManager", quietly = TRUE)) {
>>>  install.packages("BiocManager")
>>> }
>>> if (! requireNamespace("biomaRt", quietly = TRUE)) {
>>>  BiocManager::install("biomaRt")
>>> }
>>> 
>>> 
>>> Cheers,
>>> Boris
>>> 
>>>> On 2019-04-21, at 22:27, Spencer Brackett <
>>> spbrackett20 at saintjosephhs.com> wrote:
>>>> 
>>>> R users,
>>>> 
>>>> I am trying to download R Studio onto my Chrombook for
>> convenience, but
>>>> exited out of the Linux terminal that had opened upon my turning on
>> of
>>>> Linux(Beta) through my settings. Because of this I am unable to
>> prompt
>>> the
>>>> same type of Linex terminal and can only enable a new one via ctrl
>> alt t
>>> .
>>>> Running the same line of commands (as shown below) that I was
>> following
>>>> before encountering my error w/ the first terminal is not working.
>> Note,
>>>> the hostname for the new terminal that I have prompted is crosh> if
>> that
>>>> effects anything.
>>>> 
>>>> Commands I was instructed to make after enabling Linux on my
>> Chrome...
>>>> 
>>>> lsb_release
>>>> sudo apt search r-base | grep ^r-base (to download R)
>>>> 
>>>> -y gnupg2
>>>> ?keyserver keys.gnupg.net ?recv-key ? ?
>>>> ***where my terminal experienced some sort of error causing me to
>> abandon
>>>> it***
>>>> 
>>>> Any pointers for how I may proceed or alternative tutorials that I
>> may
>>>> follow?
>>>> 
>>>> Best,
>>>> 
>>>> Spencer Brackett
>>>> 
>>>> 
>>>> On Sun, Apr 21, 2019 at 9:35 PM Spencer Brackett <
>>>> spbrackett20 at saintjosephhs.com> wrote:
>>>> 
>>>>> Mr. Gunter,
>>>>> 
>>>>> Yes I have reached out to the bioconductor list but was informed
>> that my
>>>>> inquiry concerning this package was not appropriate for the
>> mailing
>>> list.
>>>>> However, I have since tried re implementing the code which I sent
>> and
>>> my R
>>>>> Studio says that netReg has successfully been unpacked, so for now
>> it
>>>>> appears that my problem is solved :)
>>>>> 
>>>>> Best,
>>>>> 
>>>>> Spencer Brackett
>>>>> 
>>>>> On Sun, Apr 21, 2019 at 8:35 PM Bert Gunter
>> <bgunter.4567 at gmail.com>
>>>>> wrote:
>>>>> 
>>>>>> netReg is not "the package that generates regression models in
>> R." Tons
>>>>>> of packages generate regression models in R, including lm(),
>> which is
>>> in
>>>>>> the stats package that is part of R's standard distro.
>>>>>> 
>>>>>> So what exactly is it that you want to do that you think requires
>>> netReg?
>>>>>> And if netReg is required, have you tried addressing your queries
>> to
>>> the
>>>>>> Bioconductor list, as it is one of their packages?
>>>>>> 
>>>>>> Cheers,
>>>>>> Bert
>>>>>> 
>>>>>> 
>>>>>> "The trouble with having an open mind is that people keep coming
>> along
>>>>>> and sticking things into it."
>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip
>> )
>>>>>> 
>>>>>> 
>>>>>> On Sun, Apr 21, 2019 at 5:06 PM Spencer Brackett <
>>>>>> spbrackett20 at saintjosephhs.com> wrote:
>>>>>> 
>>>>>>> Good evening,
>>>>>>> 
>>>>>>> I am having problems with downloading the package used to
>> generate
>>>>>>> regression models on R. The following is the error message I
>>> received. I
>>>>>>> tried installing BiocManager instead as suggested, but this too
>> did
>>> not
>>>>>>> work. Any ideas?
>>>>>>> 
>>>>>>> The following is the full summary of what I?ve tried thus far...
>>>>>>> 
>>>>>>> install.packages("ggplot2")
>>>>>>> install.packages("ggplot2")
>>>>>>> source("https://bioconductor.org/biocLite.R")
>>>>>>> ?BiocUpgrade
>>>>>>> 
>> source("https://bioconductor.org/biocLite.R")biocLite("BiocUpgrade")
>>>>>>> source("https://bioconductor.org/biocLite.R")
>>>>>>> biocLite("BiocUpgrade")
>>>>>>> source("https://bioconductor.org/bioLite.R")
>>>>>>> biocLite("netReg")
>>>>>>> help("Deprecated")
>>>>>>> 'BiocManager::install'
>>>>>>> biocLite("netReg")
>>>>>>> help("oldName-deprecated")
>>>>>>> ???oldName-deprecated?
>>>>>>> .Deprecated(new, package=NULL, msg,
>>>>>>> old = as.character(sys.call(sys.parent()))[1L])
>>>>>>> 
>>>>>>> Best,
>>>>>>> 
>>>>>>> Spencer
>>>>>>> 
>>>>>>> On Sun, Apr 14, 2019 at 7:58 PM Spencer Brackett <
>>>>>>> spbrackett20 at saintjosephhs.com> wrote:
>>>>>>> 
>>>>>>>> My apologies... here is the full code in summary
>>>>>>>> 
>>>>>>>> install.packages("ggplot2")
>>>>>>>> install.packages("ggplot2")
>>>>>>>> source("https://bioconductor.org/biocLite.R")
>>>>>>>> ?BiocUpgrade
>>>>>>>> 
>> source("https://bioconductor.org/biocLite.R")biocLite("BiocUpgrade")
>>>>>>>> source("https://bioconductor.org/biocLite.R")
>>>>>>>> biocLite("BiocUpgrade")
>>>>>>>> source("https://bioconductor.org/bioLite.R")
>>>>>>>> biocLite("netReg")
>>>>>>>> help("Deprecated")
>>>>>>>> 'BiocManager::install'
>>>>>>>> biocLite("netReg")
>>>>>>>> help("oldName-deprecated")
>>>>>>>> ???oldName-deprecated?
>>>>>>>> .Deprecated(new, package=NULL, msg,
>>>>>>>> old = as.character(sys.call(sys.parent()))[1L])
>>>>>>>> 
>>>>>>>> Best,
>>>>>>>> 
>>>>>>>> Spencer
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> On Sun, Apr 14, 2019 at 7:20 PM David Winsemius <
>>>>>>> dwinsemius at comcast.net>
>>>>>>>> wrote:
>>>>>>>> 
>>>>>>>>> 
>>>>>>>>>> On 4/14/19 3:20 PM, Spencer Brackett wrote:
>>>>>>>>>> Good evening,
>>>>>>>>>> 
>>>>>>>>>> I am having problems with downloading the package used to
>> generate
>>>>>>>>>> regression models on R. The following is the error message I
>>>>>>> received. I
>>>>>>>>>> tried installing BiocManager instead as suggested, but this
>> too did
>>>>>>> not
>>>>>>>>>> work. Any ideas?
>>>>>>>>>> 
>>>>>>>>>> The downloaded binary packages are in
>>>>>>>>>> 
>> C:\Users\Spencer\AppData\Local\Temp\Rtmp8YKVqx\downloaded_packages
>>>>>>>>>> installation path not writeable, unable to update packages:
>> class,
>>>>>>>>> cluster,
>>>>>>>>>> codetools, foreign,
>>>>>>>>>>  lattice, MASS, Matrix, mgcv, nlme, rpart, survival
>>>>>>>>>> Warning message:
>>>>>>>>>> 'biocLite' is deprecated.
>>>>>>>>>> Use 'BiocManager::install' instead.
>>>>>>>>>> See help("Deprecated")
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> Since you did not include the code that provoked this message
>> we can
>>>>>>>>> only guess that you did in fact use `bioLite`. We also cannot
>> tell
>>>>>>> what
>>>>>>>>> you mean by "problems with downloading the package used to
>> generate
>>>>>>>>> regression models on R". The typical first step is to use the
>> glm or
>>>>>>> lm
>>>>>>>>> function for this task and those are both in the stats package
>> which
>>>>>>> is
>>>>>>>>> installed with the base version of R and is loaded by default
>> when R
>>>>>>> is
>>>>>>>>> started up.
>>>>>>>>> 
>>>>>>>>> "
>>>>>>>>> 
>>>>>>>>> Have you tried following the suggestion at the end of the
>> message?
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> And do read the Posting Guide and include "commented, minimal,
>>>>>>>>> self-contained, reproducible code."
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> --
>>>>>>>>> 
>>>>>>>>> David.
>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> Best,
>>>>>>>>>> 
>>>>>>>>>> Spencer
>>>>>>>>>> 
>>>>>>>>>>     [[alternative HTML version deleted]]
>>>>>>>>>> 
>>>>>>>>>> ______________________________________________
>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> see
>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>>> and provide commented, minimal, self-contained, reproducible
>> code.
>>>>>>>>> 
>>>>>>>> 
>>>>>>> 
>>>>>>>       [[alternative HTML version deleted]]
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible
>> code.
>>>>>>> 
>>>>>> 
>>>> 
>>>>      [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>> 
>>    [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bor|@@@te|pe @end|ng |rom utoronto@c@  Mon Apr 22 08:40:39 2019
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Mon, 22 Apr 2019 06:40:39 +0000
Subject: [R] Example for  Roxygen @eval tag?
In-Reply-To: <9308C8A3-D4D1-4052-88D4-413DF6D889DA@dcn.davis.ca.us>
References: <8CAFE8EB-9356-4DD6-A9EE-834B1A027211@utoronto.ca>
 <AF82D83F-3C8E-4CC6-80C6-08603C2C446A@dcn.davis.ca.us>
 <BDB22E42-3D80-4D0A-86A3-1D23F51F9AA1@utoronto.ca>
 <9308C8A3-D4D1-4052-88D4-413DF6D889DA@dcn.davis.ca.us>
Message-ID: <7B1EF153-1644-4139-A533-DAB3F42E35D5@utoronto.ca>

I see .. you mean code that extends Roxygen. I was thinking something simple like an .Rmd chunk. But just creating an existing tag doesn't do much either:

  #' @eval sprintf("@section Time: %s", Sys.time() )

Renders as...

  @eval sprintf("@section Time: 

 ... in the .Rd - more than before, but not what I thought. 

An actual example would be most enlightening.
Thanks Jeff,
Boris



> On 2019-04-22, at 02:25, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> What tag are you creating with the eval? Your example wouldn't create valid roxygen code... as I said, it looks rather meta....
> 
> On April 21, 2019 10:40:27 PM PDT, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>> Yes, that's where I started -  the vignette says:
>> 
>>   ... Run arbtirary R code with @eval.
>> 
>>   ... the @eval tag. It evaluates code and treats the result as if it
>>   was a literal roxygen tags. This makes it possible to eliminate
>>   duplication by writing functions.
>> 
>> The first thing I noticed was that it does not say anything about
>> delimiters. By trial and error it seems to consider everything up to
>> the next @... tag in the header. Things that are not R code create an
>> error during devtools::document() processing. It seems the output is
>> captured and processed, i.e. System.time() creates a not-a-string
>> error, but as.character(System.time()) passes ... but then nothing
>> appears in the .Rd - and I haven't been able to find a single example
>> of @eval in use in the wild.
>> 
>> No joy.
>> 
>> 
>> 
>> 
>>> On 2019-04-22, at 01:29, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> wrote:
>>> 
>>> I have not used it... but did you read the vignette [1]? It sounds
>> like it is a bit more meta than you think it is...
>>> 
>>> [1]
>> https://cran.r-project.org/web/packages/roxygen2/vignettes/rd.html
>>> 
>>> On April 21, 2019 7:44:17 PM PDT, Boris Steipe
>> <boris.steipe at utoronto.ca> wrote:
>>>> Playing with Roxygen features, but can't get @eval to work. E.g. ...
>>>> 
>>>> #' @eval sprintf("%s", Sys.time())
>>>> 
>>>> ... does not do what I thought it would (i.e. substitute the tag and
>>>> the expression with the string). Instead I see nothing in the .RD
>> file.
>>>> 
>>>> Any working examples out there?
>>>> Thanks!
>>>> Boris
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> -- 
>>> Sent from my phone. Please excuse my brevity.
> 
> -- 
> Sent from my phone. Please excuse my brevity.


From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Apr 22 10:13:45 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 22 Apr 2019 04:13:45 -0400
Subject: [R] Example for Roxygen @eval tag?
In-Reply-To: <7B1EF153-1644-4139-A533-DAB3F42E35D5@utoronto.ca>
References: <8CAFE8EB-9356-4DD6-A9EE-834B1A027211@utoronto.ca>
 <AF82D83F-3C8E-4CC6-80C6-08603C2C446A@dcn.davis.ca.us>
 <BDB22E42-3D80-4D0A-86A3-1D23F51F9AA1@utoronto.ca>
 <9308C8A3-D4D1-4052-88D4-413DF6D889DA@dcn.davis.ca.us>
 <7B1EF153-1644-4139-A533-DAB3F42E35D5@utoronto.ca>
Message-ID: <b918b634-f2b9-3f2d-a80f-f0b1e7533f9c@gmail.com>

On 22/04/2019 2:40 a.m., Boris Steipe wrote:
> I see .. you mean code that extends Roxygen. I was thinking something simple like an .Rmd chunk. But just creating an existing tag doesn't do much either:
> 
>    #' @eval sprintf("@section Time: %s", Sys.time() )
> 
> Renders as...
> 
>    @eval sprintf("@section Time:
> 
>   ... in the .Rd - more than before, but not what I though
> 
> An actual example would be most enlightening.

If you look in the Roxygen2 code you'll find some, e.g. in R/rd.R, which 
displays in ?rd_roclet.

I'd guess the percent sign is messing things up.  It's a comment in Rd 
files, and perhaps also in roxygen.

Doing the search through the source code also turned up @evalRd and 
@evalNamespace, which might be worth exploring.

Duncan Murdoch


> Thanks Jeff,
> Boris
> 
> 
> 
>> On 2019-04-22, at 02:25, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>
>> What tag are you creating with the eval? Your example wouldn't create valid roxygen code... as I said, it looks rather meta....
>>
>> On April 21, 2019 10:40:27 PM PDT, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>>> Yes, that's where I started -  the vignette says:
>>>
>>>    ... Run arbtirary R code with @eval.
>>>
>>>    ... the @eval tag. It evaluates code and treats the result as if it
>>>    was a literal roxygen tags. This makes it possible to eliminate
>>>    duplication by writing functions.
>>>
>>> The first thing I noticed was that it does not say anything about
>>> delimiters. By trial and error it seems to consider everything up to
>>> the next @... tag in the header. Things that are not R code create an
>>> error during devtools::document() processing. It seems the output is
>>> captured and processed, i.e. System.time() creates a not-a-string
>>> error, but as.character(System.time()) passes ... but then nothing
>>> appears in the .Rd - and I haven't been able to find a single example
>>> of @eval in use in the wild.
>>>
>>> No joy.
>>>
>>>
>>>
>>>
>>>> On 2019-04-22, at 01:29, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>> wrote:
>>>>
>>>> I have not used it... but did you read the vignette [1]? It sounds
>>> like it is a bit more meta than you think it is...
>>>>
>>>> [1]
>>> https://cran.r-project.org/web/packages/roxygen2/vignettes/rd.html
>>>>
>>>> On April 21, 2019 7:44:17 PM PDT, Boris Steipe
>>> <boris.steipe at utoronto.ca> wrote:
>>>>> Playing with Roxygen features, but can't get @eval to work. E.g. ...
>>>>>
>>>>> #' @eval sprintf("%s", Sys.time())
>>>>>
>>>>> ... does not do what I thought it would (i.e. substitute the tag and
>>>>> the expression with the string). Instead I see nothing in the .RD
>>> file.
>>>>>
>>>>> Any working examples out there?
>>>>> Thanks!
>>>>> Boris
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> -- 
>>>> Sent from my phone. Please excuse my brevity.
>>
>> -- 
>> Sent from my phone. Please excuse my brevity.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ju@t|nthong93 @end|ng |rom gm@||@com  Mon Apr 22 10:29:07 2019
From: ju@t|nthong93 @end|ng |rom gm@||@com (Justin Thong)
Date: Mon, 22 Apr 2019 16:29:07 +0800
Subject: [R] Opportunities for Developing R Packages (Research-Based,
 Open-Source)
Message-ID: <CAEtAGeo3sw3CTeKUFjY+EONSxj2ACtZPmb59Ke5OBr5Af54=-A@mail.gmail.com>

Dear R package community,

I am uncertain whether this is appropriate for this mailing list. Please
let me know. If not, would you be so kind as to point me in a better
direction?

I am a mathematics major with a well-developed R experience. I have
graduated two years ago and have been working in business operations in a
cryptocurrency startup. I am rather rusty and I wish to venture back into
statistical research and R-package development.

My question is: For those researchers who are interested in developing
tools and algorithms for their new-founded research, be it in medical
statistics or data visualisation or machine learning, I was wondering
whether is there a possibility for collaboration. This will help me extend
my experience and possibly open more avenues for me to enter research.
I am quite aware of statistical concepts and can read research papers (I've
done a research internship in experimental design, linear algebra and data
compression, particle filters and bayes analyses). I do not expect to be
paid and am willing to commit to a project.


Yours sincerely,
Justin

*I check my email at 9AM and 4PM everyday*
*If you have an EMERGENCY, contact me at +447938674419(UK) or
+60125056192(Malaysia)*

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Apr 22 12:35:14 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 22 Apr 2019 03:35:14 -0700
Subject: [R] Help installing netReg
In-Reply-To: <891EF976-9601-4856-843B-6B9A7EC5D56B@gmail.com>
References: <CAPQaxLPmhsdh5OaOErFQZXym7JpMY9EuPAjEL70-0DFbDks6LA@mail.gmail.com>
 <2826429b-ff8b-6606-a6ba-c27388075d7f@comcast.net>
 <CAPQaxLM5aJM5uW9NsmXtG1Qbx4Mco7B=uiQ8kdRX+06kGZHCYg@mail.gmail.com>
 <CAPQaxLMXYAzjTJjoCemYVE+Pw47HvZaYAq-=wanTZdnxkE5jaQ@mail.gmail.com>
 <CAGxFJbT-zkTa8xa77VSv+Awr51Dgi4yz+-CxeNfmezDZWNi7-Q@mail.gmail.com>
 <CAPQaxLOoeTeoY0Z+uSMAE7sdHYrTQeDDNoLWzkTSQpk_mjLwBg@mail.gmail.com>
 <CAPQaxLNj8jHnwzux3zsYgfmG-tOhrb-iAQUeDeSmR2e6SZNWrg@mail.gmail.com>
 <8102D2B8-110C-487E-9BA4-E03258108692@utoronto.ca>
 <CAPQaxLMm1JNO=MR5Fi4cb_n9egtvbaWgbq2j+6970jogT2qCmg@mail.gmail.com>
 <2FB686C4-615B-4476-9A39-521C94E2A6AC@dcn.davis.ca.us>
 <891EF976-9601-4856-843B-6B9A7EC5D56B@gmail.com>
Message-ID: <D45C1DCD-1DD9-47DF-BA92-DB33A342CF1A@dcn.davis.ca.us>

Spoken like someone who hasn't encountered the nightmare that ensues when some schmuck fails to limit their actions to only updating the system R library while following it. It is straightforward and painless to simply update the user library instead, and so much the better if they don't have Admin privileges and think they "need" to harass their sysadmins to deal with this for them.

library(fortunes)
fortune(337)

On April 21, 2019 11:34:16 PM PDT, Caitlin Gibbons <bioprogrammer at gmail.com> wrote:
>Hi Spencer.
>
>On a Windows machine, the message ?Installation path not writeable? can
>be solved by starting RStudio as an administrator. Right click the
>RStudio icon and select ?Run as Administrator?. This should solve that
>problem. 
>
>Hope this helps. 
>
>~Caitlin
>
>
>Sent from my iPhone
>
>> On Apr 21, 2019, at 9:22 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>> 
>> I don't know anything about the Bioconductor installation, but it is
>normal practice on Windows to install updates to packages distributed
>with R (such as those below) by "superceding" them in your user
>library. This happens automatically if you don't specify the
>destination library to install to. Just do a normal update.packages and
>the Program Files library will stay unchanged but your user library
>versions of the base R packages will be loaded instead.
>> 
>>> On April 21, 2019 8:49:08 PM PDT, Spencer Brackett
><spbrackett20 at saintjosephhs.com> wrote:
>>> Boris,
>>> '
>>> My apologies. Thanks for the tip! I tried the command you suggested
>in
>>> your
>>> response and got the following...
>>> 
>>>> BiocManager::install("netReg")
>>> Bioconductor version 3.8 (BiocManager 1.30.4), R 3.5.1 (2018-07-02)
>>> Installing package(s) 'BiocVersion', 'netReg'
>>> trying URL '
>>>
>https://bioconductor.org/packages/3.8/bioc/bin/windows/contrib/3.5/BiocVersion_3.8.0.zip
>>> '
>>> Content type 'application/zip' length 8843 bytes
>>> downloaded 8843 bytes
>>> 
>>> trying URL '
>>>
>https://bioconductor.org/packages/3.8/bioc/bin/windows/contrib/3.5/netReg_1.6.0.zip
>>> '
>>> Content type 'application/zip' length 4143315 bytes (4.0 MB)
>>> downloaded 4.0 MB
>>> 
>>> package ?BiocVersion? successfully unpacked and MD5 sums checked
>>> package ?netReg? successfully unpacked and MD5 sums checked
>>> 
>>> The downloaded binary packages are in
>>> C:\Users\Spencer\AppData\Local\Temp\RtmpW6FwPY\downloaded_packages
>>> installation path not writeable, unable to update packages: class,
>>> cluster,
>>> codetools, foreign,
>>> lattice, MASS, Matrix, mgcv, nlme, rpart, survival
>>> 
>>> ***Does it matter that the packages above are unable to be updated?
>For
>>> insight, I am trying to generate linear regression models that model
>>> expression of methylation w/ in a TCGA dataset.***
>>> 
>>> Best,
>>> 
>>> Spencer
>>> 
>>> On Sun, Apr 21, 2019 at 10:57 PM Boris Steipe
>>> <boris.steipe at utoronto.ca>
>>> wrote:
>>> 
>>>> This is unrelated to the question on the subject line, we call this
>>>> "thread hijacking" and that's one of the Things Not To Do. Post a
>new
>>>> question.
>>>> 
>>>> I just wanted to give you the proper incantation for Bioconductor
>>>> packages. As you already know, don't use bioclite(), which needed
>to
>>> be
>>>> sourced from an URL. Instead install.packages("Biocmanager") from
>>> CRAN,
>>>> then - there's no need to load it - use
>Biocmanager::install(<package
>>>> name>) from there on. I usually have it in scripts like so:
>>>> 
>>>> if (! requireNamespace("BiocManager", quietly = TRUE)) {
>>>>  install.packages("BiocManager")
>>>> }
>>>> if (! requireNamespace("biomaRt", quietly = TRUE)) {
>>>>  BiocManager::install("biomaRt")
>>>> }
>>>> 
>>>> 
>>>> Cheers,
>>>> Boris
>>>> 
>>>>> On 2019-04-21, at 22:27, Spencer Brackett <
>>>> spbrackett20 at saintjosephhs.com> wrote:
>>>>> 
>>>>> R users,
>>>>> 
>>>>> I am trying to download R Studio onto my Chrombook for
>>> convenience, but
>>>>> exited out of the Linux terminal that had opened upon my turning
>on
>>> of
>>>>> Linux(Beta) through my settings. Because of this I am unable to
>>> prompt
>>>> the
>>>>> same type of Linex terminal and can only enable a new one via ctrl
>>> alt t
>>>> .
>>>>> Running the same line of commands (as shown below) that I was
>>> following
>>>>> before encountering my error w/ the first terminal is not working.
>>> Note,
>>>>> the hostname for the new terminal that I have prompted is crosh>
>if
>>> that
>>>>> effects anything.
>>>>> 
>>>>> Commands I was instructed to make after enabling Linux on my
>>> Chrome...
>>>>> 
>>>>> lsb_release
>>>>> sudo apt search r-base | grep ^r-base (to download R)
>>>>> 
>>>>> -y gnupg2
>>>>> ?keyserver keys.gnupg.net ?recv-key ? ?
>>>>> ***where my terminal experienced some sort of error causing me to
>>> abandon
>>>>> it***
>>>>> 
>>>>> Any pointers for how I may proceed or alternative tutorials that I
>>> may
>>>>> follow?
>>>>> 
>>>>> Best,
>>>>> 
>>>>> Spencer Brackett
>>>>> 
>>>>> 
>>>>> On Sun, Apr 21, 2019 at 9:35 PM Spencer Brackett <
>>>>> spbrackett20 at saintjosephhs.com> wrote:
>>>>> 
>>>>>> Mr. Gunter,
>>>>>> 
>>>>>> Yes I have reached out to the bioconductor list but was informed
>>> that my
>>>>>> inquiry concerning this package was not appropriate for the
>>> mailing
>>>> list.
>>>>>> However, I have since tried re implementing the code which I sent
>>> and
>>>> my R
>>>>>> Studio says that netReg has successfully been unpacked, so for
>now
>>> it
>>>>>> appears that my problem is solved :)
>>>>>> 
>>>>>> Best,
>>>>>> 
>>>>>> Spencer Brackett
>>>>>> 
>>>>>> On Sun, Apr 21, 2019 at 8:35 PM Bert Gunter
>>> <bgunter.4567 at gmail.com>
>>>>>> wrote:
>>>>>> 
>>>>>>> netReg is not "the package that generates regression models in
>>> R." Tons
>>>>>>> of packages generate regression models in R, including lm(),
>>> which is
>>>> in
>>>>>>> the stats package that is part of R's standard distro.
>>>>>>> 
>>>>>>> So what exactly is it that you want to do that you think
>requires
>>>> netReg?
>>>>>>> And if netReg is required, have you tried addressing your
>queries
>>> to
>>>> the
>>>>>>> Bioconductor list, as it is one of their packages?
>>>>>>> 
>>>>>>> Cheers,
>>>>>>> Bert
>>>>>>> 
>>>>>>> 
>>>>>>> "The trouble with having an open mind is that people keep coming
>>> along
>>>>>>> and sticking things into it."
>>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip
>>> )
>>>>>>> 
>>>>>>> 
>>>>>>> On Sun, Apr 21, 2019 at 5:06 PM Spencer Brackett <
>>>>>>> spbrackett20 at saintjosephhs.com> wrote:
>>>>>>> 
>>>>>>>> Good evening,
>>>>>>>> 
>>>>>>>> I am having problems with downloading the package used to
>>> generate
>>>>>>>> regression models on R. The following is the error message I
>>>> received. I
>>>>>>>> tried installing BiocManager instead as suggested, but this too
>>> did
>>>> not
>>>>>>>> work. Any ideas?
>>>>>>>> 
>>>>>>>> The following is the full summary of what I?ve tried thus
>far...
>>>>>>>> 
>>>>>>>> install.packages("ggplot2")
>>>>>>>> install.packages("ggplot2")
>>>>>>>> source("https://bioconductor.org/biocLite.R")
>>>>>>>> ?BiocUpgrade
>>>>>>>> 
>>> source("https://bioconductor.org/biocLite.R")biocLite("BiocUpgrade")
>>>>>>>> source("https://bioconductor.org/biocLite.R")
>>>>>>>> biocLite("BiocUpgrade")
>>>>>>>> source("https://bioconductor.org/bioLite.R")
>>>>>>>> biocLite("netReg")
>>>>>>>> help("Deprecated")
>>>>>>>> 'BiocManager::install'
>>>>>>>> biocLite("netReg")
>>>>>>>> help("oldName-deprecated")
>>>>>>>> ???oldName-deprecated?
>>>>>>>> .Deprecated(new, package=NULL, msg,
>>>>>>>> old = as.character(sys.call(sys.parent()))[1L])
>>>>>>>> 
>>>>>>>> Best,
>>>>>>>> 
>>>>>>>> Spencer
>>>>>>>> 
>>>>>>>> On Sun, Apr 14, 2019 at 7:58 PM Spencer Brackett <
>>>>>>>> spbrackett20 at saintjosephhs.com> wrote:
>>>>>>>> 
>>>>>>>>> My apologies... here is the full code in summary
>>>>>>>>> 
>>>>>>>>> install.packages("ggplot2")
>>>>>>>>> install.packages("ggplot2")
>>>>>>>>> source("https://bioconductor.org/biocLite.R")
>>>>>>>>> ?BiocUpgrade
>>>>>>>>> 
>>> source("https://bioconductor.org/biocLite.R")biocLite("BiocUpgrade")
>>>>>>>>> source("https://bioconductor.org/biocLite.R")
>>>>>>>>> biocLite("BiocUpgrade")
>>>>>>>>> source("https://bioconductor.org/bioLite.R")
>>>>>>>>> biocLite("netReg")
>>>>>>>>> help("Deprecated")
>>>>>>>>> 'BiocManager::install'
>>>>>>>>> biocLite("netReg")
>>>>>>>>> help("oldName-deprecated")
>>>>>>>>> ???oldName-deprecated?
>>>>>>>>> .Deprecated(new, package=NULL, msg,
>>>>>>>>> old = as.character(sys.call(sys.parent()))[1L])
>>>>>>>>> 
>>>>>>>>> Best,
>>>>>>>>> 
>>>>>>>>> Spencer
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> 
>>>>>>>>> On Sun, Apr 14, 2019 at 7:20 PM David Winsemius <
>>>>>>>> dwinsemius at comcast.net>
>>>>>>>>> wrote:
>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>>> On 4/14/19 3:20 PM, Spencer Brackett wrote:
>>>>>>>>>>> Good evening,
>>>>>>>>>>> 
>>>>>>>>>>> I am having problems with downloading the package used to
>>> generate
>>>>>>>>>>> regression models on R. The following is the error message I
>>>>>>>> received. I
>>>>>>>>>>> tried installing BiocManager instead as suggested, but this
>>> too did
>>>>>>>> not
>>>>>>>>>>> work. Any ideas?
>>>>>>>>>>> 
>>>>>>>>>>> The downloaded binary packages are in
>>>>>>>>>>> 
>>> C:\Users\Spencer\AppData\Local\Temp\Rtmp8YKVqx\downloaded_packages
>>>>>>>>>>> installation path not writeable, unable to update packages:
>>> class,
>>>>>>>>>> cluster,
>>>>>>>>>>> codetools, foreign,
>>>>>>>>>>>  lattice, MASS, Matrix, mgcv, nlme, rpart, survival
>>>>>>>>>>> Warning message:
>>>>>>>>>>> 'biocLite' is deprecated.
>>>>>>>>>>> Use 'BiocManager::install' instead.
>>>>>>>>>>> See help("Deprecated")
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> Since you did not include the code that provoked this message
>>> we can
>>>>>>>>>> only guess that you did in fact use `bioLite`. We also cannot
>>> tell
>>>>>>>> what
>>>>>>>>>> you mean by "problems with downloading the package used to
>>> generate
>>>>>>>>>> regression models on R". The typical first step is to use the
>>> glm or
>>>>>>>> lm
>>>>>>>>>> function for this task and those are both in the stats
>package
>>> which
>>>>>>>> is
>>>>>>>>>> installed with the base version of R and is loaded by default
>>> when R
>>>>>>>> is
>>>>>>>>>> started up.
>>>>>>>>>> 
>>>>>>>>>> "
>>>>>>>>>> 
>>>>>>>>>> Have you tried following the suggestion at the end of the
>>> message?
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> And do read the Posting Guide and include "commented,
>minimal,
>>>>>>>>>> self-contained, reproducible code."
>>>>>>>>>> 
>>>>>>>>>> 
>>>>>>>>>> --
>>>>>>>>>> 
>>>>>>>>>> David.
>>>>>>>>>> 
>>>>>>>>>>> 
>>>>>>>>>>> Best,
>>>>>>>>>>> 
>>>>>>>>>>> Spencer
>>>>>>>>>>> 
>>>>>>>>>>>     [[alternative HTML version deleted]]
>>>>>>>>>>> 
>>>>>>>>>>> ______________________________________________
>>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
>more,
>>> see
>>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>>>> and provide commented, minimal, self-contained, reproducible
>>> code.
>>>>>>>>>> 
>>>>>>>>> 
>>>>>>>> 
>>>>>>>>       [[alternative HTML version deleted]]
>>>>>>>> 
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>> see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible
>>> code.
>>>>>>>> 
>>>>>>> 
>>>>> 
>>>>>      [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> 
>>> 
>>>    [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> -- 
>> Sent from my phone. Please excuse my brevity.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From B|||@Po||ng @end|ng |rom ze||@@com  Mon Apr 22 16:37:10 2019
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Mon, 22 Apr 2019 14:37:10 +0000
Subject: [R] Help with Rmarkdown HTML Logo
Message-ID: <BN7PR02MB5073D00DF8FC83BBF1200E74EA220@BN7PR02MB5073.namprd02.prod.outlook.com>

Hello.

#RStudio Version 1.1.456
sessionInfo()
#R version 3.5.3 (2019-03-11)
#Platform: x86_64-w64-mingw32/x64 (64-bit)
#Running under: Windows >= 8 x64 (build 9200)

I feel I have made great progress teaching myself RMarkdown using HTML reporting for the moment.

However, one formatting item eludes me, the Logo.

It works fine as positioned in the script below, however, it does not travel with the HTML when I distribute it.

I understand why, because it resides in the same file as the report.

Looking at various urls for this topic I find that this appears to do the trick:

https://stackoverflow.com/questions/43009788/insert-a-logo-in-upper-right-corner-of-r-markdown-html-document

My problem is how does my file path work in this example please?

#MY File Path:
C:\WHP\Revenue Development Products\BRA AutoDistribution\ Zelis.jpg


---
title: AUTO DISTRIBUTION ANALYSIS
author: DRAFT FOR DISCUSSION
date:
output:
  html_document:
  params:
    interactive: TRUE
---
<script>
   $(document).ready(function() {
     $head = $('#header');
     $head.prepend('<img src=\"Zelis.jpg\" style=\"float: left;width: 150px;\"/>')
   });
</script>

<style type="text/css">
h1.title {
  font-size: 38px;
  color: Purple;
  text-align: center;
}
h4.author { /* Header 4 - and the author and data headers use this too  */
    font-size: 18px;
  font-family: "Times New Roman", Times, serif;
  color: Purple;
  text-align: center;
</style>


Everything above is fine, I want to enhance this report by making the logo a traveler so to speak.
Of course once I get this to work below I will remove the reference to it above.


```{r, echo=FALSE}
htmltools::img(src = knitr::image_uri(file.path(R.home("doc"), "html", "Zelis.jpg")),
               alt = 'logo',
               style = 'position:absolute; top:0; left:0; padding:10px;')
```

<!---
#https://stackoverflow.com/questions/43009788/insert-a-logo-in-upper-right-corner-of-r-markdown-html-document
#http://freerangestats.info/blog/2017/09/09/rmarkdown
--->

Thank you for your assistance.

WHP




Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}


From ev@n@cooch @end|ng |rom gm@||@com  Mon Apr 22 16:44:51 2019
From: ev@n@cooch @end|ng |rom gm@||@com (Evan Cooch)
Date: Mon, 22 Apr 2019 10:44:51 -0400
Subject: [R] problem(s) compiling RWinEdt
Message-ID: <fa207bfc-b71a-62ca-6ee7-6715ad11426b@gmail.com>

[Note: if this should go to one of the other R maillists, 
apologies...and let me know *which* other list...]


I use the WinEdt editor for ll my TeX work, and several years back, 
installed the RWinEdt package in R to allow me to use WinEdt as my R 
edtior as well. Worked, and continues to work, perfectly (currently 
using R 3.5.3, RWinEdt 2.0, and WinEdt 6 -- WinEdt 6 being way behind 
the current release 10.x, but newer version have no new features I felt 
compelled to get by upgrading).

However, with the likelihood I'll need to move some of my Windows 7 
machines -> Windows 10, I wondered about getting the WinEdt-RWinEdt 
combination working on a new machine. So, I built a Win 10 machine, 
clean install, and then did a base install of R 3.5.3 (nothing else 
beyond base). Installed latest RTools, and put it in the path (since 
there doesn't seem to be a Windows binary for RWinEdt). Fired up R with 
admin privileges, and then tried to install RWinEdt. Tried, but...failed 
miserably (console log of one attempt, below). Got the following compile 
failures -- replete with NameSpace errors, and a strange comment that 
RWinEdt is designed for the Windows RGui only (strange, since I *am* 
installing/compiling on a Windows machine).

Being curious, I then re-tried the same exercise using a clean Windows 7 
install. Same issue. Then, retried both, using WinEdt 6. Same issue.


So, there seems to be a problem with getting RWinEdt installed. For the 
moment, I'm not too fussed, since I have it working fine on my main work 
machines. However, if I need to setup a new machine in future (Win 7 or 
Win 10), I'd like to be able to do a 'fresh' install of R, WinEdt and 
RWinEdt.

Any suggestions?

Thanks...


-----<console log, below>-----------

--- Please select a CRAN mirror for use in this session ---
Package which is only available in source form, and may need
 ? compilation of C/C++/Fortran: ?RWinEdt?
installing the source package ?RWinEdt?

trying URL 'https://cran.mtu.edu/src/contrib/RWinEdt_2.0-6.tar.gz'
Content type 'application/x-gzip' length 801476 bytes (782 KB)
downloaded 782 KB

* installing *source* package 'RWinEdt' ...
** package 'RWinEdt' successfully unpacked and MD5 sums checked
** libs

*** arch - i386
c:/Rtools/mingw_32/bin/gcc? -I"C:/PROGRA~1/R/R-35~1.3/include" 
-DNDEBUG????????? -O3 -Wall? -std=gnu99 -mtune=generic -c ismdi.c -o ismdi.o
c:/Rtools/mingw_32/bin/gcc -shared -s -static-libgcc -o RWinEdt.dll 
tmp.def ismdi.o -lRgraphapp -LC:/PROGRA~1/R/R-35~1.3/bin/i386 -lR
installing to C:/Program Files/R/R-3.5.3/library/RWinEdt/libs/i386

*** arch - x64
c:/Rtools/mingw_64/bin/gcc? -I"C:/PROGRA~1/R/R-35~1.3/include" 
-DNDEBUG????????? -O2 -Wall? -std=gnu99 -mtune=generic -c ismdi.c -o ismdi.o
c:/Rtools/mingw_64/bin/gcc -shared -s -static-libgcc -o RWinEdt.dll 
tmp.def ismdi.o -lRgraphapp -LC:/PROGRA~1/R/R-35~1.3/bin/x64 -lR
installing to C:/Program Files/R/R-3.5.3/library/RWinEdt/libs/x64
** R
** inst
** byte-compile and prepare package for lazy loading
** help
*** installing help indices
 ? converting help for package 'RWinEdt'
 ??? finding HTML links ... done
 ??? WinEdt????????????????????????????????? html
 ??? ismdi?????????????????????????????????? html
** building package indices
** installing vignettes
 ?? 'RWinEdt.Rnw'

** testing if installed package can be loaded
*** arch - i386
Error: package or namespace load failed for 'RWinEdt':
 ?.onAttach failed in attachNamespace() for 'RWinEdt', details:
 ? call: fun(libname, pkgname)
 ? error:
R-WinEdt is designed only for *RGui* on Windows!
Error: loading failed
Execution halted
*** arch - x64
Error: package or namespace load failed for 'RWinEdt':
 ?.onAttach failed in attachNamespace() for 'RWinEdt', details:
 ? call: fun(libname, pkgname)
 ? error:
R-WinEdt is designed only for *RGui* on Windows!
Error: loading failed
Execution halted
ERROR: loading failed for 'i386', 'x64'
* removing 'C:/Program Files/R/R-3.5.3/library/RWinEdt'
In R CMD INSTALL

The downloaded source packages are in
?C:\Users\egc\AppData\Local\Temp\RtmpiYRr5e\downloaded_packages?
Warning message:
In install.packages(NULL, .libPaths()[1L], dependencies = NA, type = type) :
 ? installation of package ?RWinEdt? had non-zero exit status


From wdun|@p @end|ng |rom t|bco@com  Mon Apr 22 20:00:07 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Mon, 22 Apr 2019 11:00:07 -0700
Subject: [R] problem(s) compiling RWinEdt
In-Reply-To: <fa207bfc-b71a-62ca-6ee7-6715ad11426b@gmail.com>
References: <fa207bfc-b71a-62ca-6ee7-6715ad11426b@gmail.com>
Message-ID: <CAF8bMcZLem532wVf4SixM7T3yn0mYJx8xcQxYbGLW+0HQbYL4w@mail.gmail.com>

Trying adding INSTALL_opts="--no-test-load" to your
install.packages(type="source",...) command.   This package is being too
clever in its .onAttach function.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Apr 22, 2019 at 9:07 AM Evan Cooch <evan.cooch at gmail.com> wrote:

> [Note: if this should go to one of the other R maillists,
> apologies...and let me know *which* other list...]
>
>
> I use the WinEdt editor for ll my TeX work, and several years back,
> installed the RWinEdt package in R to allow me to use WinEdt as my R
> edtior as well. Worked, and continues to work, perfectly (currently
> using R 3.5.3, RWinEdt 2.0, and WinEdt 6 -- WinEdt 6 being way behind
> the current release 10.x, but newer version have no new features I felt
> compelled to get by upgrading).
>
> However, with the likelihood I'll need to move some of my Windows 7
> machines -> Windows 10, I wondered about getting the WinEdt-RWinEdt
> combination working on a new machine. So, I built a Win 10 machine,
> clean install, and then did a base install of R 3.5.3 (nothing else
> beyond base). Installed latest RTools, and put it in the path (since
> there doesn't seem to be a Windows binary for RWinEdt). Fired up R with
> admin privileges, and then tried to install RWinEdt. Tried, but...failed
> miserably (console log of one attempt, below). Got the following compile
> failures -- replete with NameSpace errors, and a strange comment that
> RWinEdt is designed for the Windows RGui only (strange, since I *am*
> installing/compiling on a Windows machine).
>
> Being curious, I then re-tried the same exercise using a clean Windows 7
> install. Same issue. Then, retried both, using WinEdt 6. Same issue.
>
>
> So, there seems to be a problem with getting RWinEdt installed. For the
> moment, I'm not too fussed, since I have it working fine on my main work
> machines. However, if I need to setup a new machine in future (Win 7 or
> Win 10), I'd like to be able to do a 'fresh' install of R, WinEdt and
> RWinEdt.
>
> Any suggestions?
>
> Thanks...
>
>
> -----<console log, below>-----------
>
> --- Please select a CRAN mirror for use in this session ---
> Package which is only available in source form, and may need
>    compilation of C/C++/Fortran: ?RWinEdt?
> installing the source package ?RWinEdt?
>
> trying URL 'https://cran.mtu.edu/src/contrib/RWinEdt_2.0-6.tar.gz'
> Content type 'application/x-gzip' length 801476 bytes (782 KB)
> downloaded 782 KB
>
> * installing *source* package 'RWinEdt' ...
> ** package 'RWinEdt' successfully unpacked and MD5 sums checked
> ** libs
>
> *** arch - i386
> c:/Rtools/mingw_32/bin/gcc  -I"C:/PROGRA~1/R/R-35~1.3/include"
> -DNDEBUG          -O3 -Wall  -std=gnu99 -mtune=generic -c ismdi.c -o
> ismdi.o
> c:/Rtools/mingw_32/bin/gcc -shared -s -static-libgcc -o RWinEdt.dll
> tmp.def ismdi.o -lRgraphapp -LC:/PROGRA~1/R/R-35~1.3/bin/i386 -lR
> installing to C:/Program Files/R/R-3.5.3/library/RWinEdt/libs/i386
>
> *** arch - x64
> c:/Rtools/mingw_64/bin/gcc  -I"C:/PROGRA~1/R/R-35~1.3/include"
> -DNDEBUG          -O2 -Wall  -std=gnu99 -mtune=generic -c ismdi.c -o
> ismdi.o
> c:/Rtools/mingw_64/bin/gcc -shared -s -static-libgcc -o RWinEdt.dll
> tmp.def ismdi.o -lRgraphapp -LC:/PROGRA~1/R/R-35~1.3/bin/x64 -lR
> installing to C:/Program Files/R/R-3.5.3/library/RWinEdt/libs/x64
> ** R
> ** inst
> ** byte-compile and prepare package for lazy loading
> ** help
> *** installing help indices
>    converting help for package 'RWinEdt'
>      finding HTML links ... done
>      WinEdt                                  html
>      ismdi                                   html
> ** building package indices
> ** installing vignettes
>     'RWinEdt.Rnw'
>
> ** testing if installed package can be loaded
> *** arch - i386
> Error: package or namespace load failed for 'RWinEdt':
>   .onAttach failed in attachNamespace() for 'RWinEdt', details:
>    call: fun(libname, pkgname)
>    error:
> R-WinEdt is designed only for *RGui* on Windows!
> Error: loading failed
> Execution halted
> *** arch - x64
> Error: package or namespace load failed for 'RWinEdt':
>   .onAttach failed in attachNamespace() for 'RWinEdt', details:
>    call: fun(libname, pkgname)
>    error:
> R-WinEdt is designed only for *RGui* on Windows!
> Error: loading failed
> Execution halted
> ERROR: loading failed for 'i386', 'x64'
> * removing 'C:/Program Files/R/R-3.5.3/library/RWinEdt'
> In R CMD INSTALL
>
> The downloaded source packages are in
> ?C:\Users\egc\AppData\Local\Temp\RtmpiYRr5e\downloaded_packages?
> Warning message:
> In install.packages(NULL, .libPaths()[1L], dependencies = NA, type = type)
> :
>    installation of package ?RWinEdt? had non-zero exit status
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ev@n@cooch @end|ng |rom gm@||@com  Mon Apr 22 20:10:55 2019
From: ev@n@cooch @end|ng |rom gm@||@com (Evan Cooch)
Date: Mon, 22 Apr 2019 14:10:55 -0400
Subject: [R] problem(s) compiling RWinEdt
In-Reply-To: <CAF8bMcZLem532wVf4SixM7T3yn0mYJx8xcQxYbGLW+0HQbYL4w@mail.gmail.com>
References: <fa207bfc-b71a-62ca-6ee7-6715ad11426b@gmail.com>
 <CAF8bMcZLem532wVf4SixM7T3yn0mYJx8xcQxYbGLW+0HQbYL4w@mail.gmail.com>
Message-ID: <071c61a1-47a5-d771-1c12-d8431aa1d338@gmail.com>



On 4/22/2019 2:00 PM, William Dunlap wrote:
> Trying adding INSTALL_opts="--no-test-load" to your 
> install.packages(type="source",...) command.? ?This package is being 
> too clever in its .onAttach function.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com>
>
>

Thanks -- solved problem #1 (being, couldn't get it to compile from 
source in the first place).

	[[alternative HTML version deleted]]


From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Mon Apr 22 20:34:31 2019
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Mon, 22 Apr 2019 14:34:31 -0400
Subject: [R] Help installing netReg
In-Reply-To: <D45C1DCD-1DD9-47DF-BA92-DB33A342CF1A@dcn.davis.ca.us>
References: <CAPQaxLPmhsdh5OaOErFQZXym7JpMY9EuPAjEL70-0DFbDks6LA@mail.gmail.com>
 <2826429b-ff8b-6606-a6ba-c27388075d7f@comcast.net>
 <CAPQaxLM5aJM5uW9NsmXtG1Qbx4Mco7B=uiQ8kdRX+06kGZHCYg@mail.gmail.com>
 <CAPQaxLMXYAzjTJjoCemYVE+Pw47HvZaYAq-=wanTZdnxkE5jaQ@mail.gmail.com>
 <CAGxFJbT-zkTa8xa77VSv+Awr51Dgi4yz+-CxeNfmezDZWNi7-Q@mail.gmail.com>
 <CAPQaxLOoeTeoY0Z+uSMAE7sdHYrTQeDDNoLWzkTSQpk_mjLwBg@mail.gmail.com>
 <CAPQaxLNj8jHnwzux3zsYgfmG-tOhrb-iAQUeDeSmR2e6SZNWrg@mail.gmail.com>
 <8102D2B8-110C-487E-9BA4-E03258108692@utoronto.ca>
 <CAPQaxLMm1JNO=MR5Fi4cb_n9egtvbaWgbq2j+6970jogT2qCmg@mail.gmail.com>
 <2FB686C4-615B-4476-9A39-521C94E2A6AC@dcn.davis.ca.us>
 <891EF976-9601-4856-843B-6B9A7EC5D56B@gmail.com>
 <D45C1DCD-1DD9-47DF-BA92-DB33A342CF1A@dcn.davis.ca.us>
Message-ID: <CAPQaxLM9B-s=tkcnPByTj0f7FVjtcv4nWJ4svmoF=bnvLS=rDg@mail.gmail.com>

I updated my rStudio to the newest version. "netReg" is apparently
unavailable here but I will try to use another function to generate the
regression models I am looking for.

Thanks,

Spencer

On Mon, Apr 22, 2019 at 6:35 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Spoken like someone who hasn't encountered the nightmare that ensues when
> some schmuck fails to limit their actions to only updating the system R
> library while following it. It is straightforward and painless to simply
> update the user library instead, and so much the better if they don't have
> Admin privileges and think they "need" to harass their sysadmins to deal
> with this for them.
>
> library(fortunes)
> fortune(337)
>
> On April 21, 2019 11:34:16 PM PDT, Caitlin Gibbons <
> bioprogrammer at gmail.com> wrote:
> >Hi Spencer.
> >
> >On a Windows machine, the message ?Installation path not writeable? can
> >be solved by starting RStudio as an administrator. Right click the
> >RStudio icon and select ?Run as Administrator?. This should solve that
> >problem.
> >
> >Hope this helps.
> >
> >~Caitlin
> >
> >
> >Sent from my iPhone
> >
> >> On Apr 21, 2019, at 9:22 PM, Jeff Newmiller
> ><jdnewmil at dcn.davis.ca.us> wrote:
> >>
> >> I don't know anything about the Bioconductor installation, but it is
> >normal practice on Windows to install updates to packages distributed
> >with R (such as those below) by "superceding" them in your user
> >library. This happens automatically if you don't specify the
> >destination library to install to. Just do a normal update.packages and
> >the Program Files library will stay unchanged but your user library
> >versions of the base R packages will be loaded instead.
> >>
> >>> On April 21, 2019 8:49:08 PM PDT, Spencer Brackett
> ><spbrackett20 at saintjosephhs.com> wrote:
> >>> Boris,
> >>> '
> >>> My apologies. Thanks for the tip! I tried the command you suggested
> >in
> >>> your
> >>> response and got the following...
> >>>
> >>>> BiocManager::install("netReg")
> >>> Bioconductor version 3.8 (BiocManager 1.30.4), R 3.5.1 (2018-07-02)
> >>> Installing package(s) 'BiocVersion', 'netReg'
> >>> trying URL '
> >>>
> >
> https://bioconductor.org/packages/3.8/bioc/bin/windows/contrib/3.5/BiocVersion_3.8.0.zip
> >>> '
> >>> Content type 'application/zip' length 8843 bytes
> >>> downloaded 8843 bytes
> >>>
> >>> trying URL '
> >>>
> >
> https://bioconductor.org/packages/3.8/bioc/bin/windows/contrib/3.5/netReg_1.6.0.zip
> >>> '
> >>> Content type 'application/zip' length 4143315 bytes (4.0 MB)
> >>> downloaded 4.0 MB
> >>>
> >>> package ?BiocVersion? successfully unpacked and MD5 sums checked
> >>> package ?netReg? successfully unpacked and MD5 sums checked
> >>>
> >>> The downloaded binary packages are in
> >>> C:\Users\Spencer\AppData\Local\Temp\RtmpW6FwPY\downloaded_packages
> >>> installation path not writeable, unable to update packages: class,
> >>> cluster,
> >>> codetools, foreign,
> >>> lattice, MASS, Matrix, mgcv, nlme, rpart, survival
> >>>
> >>> ***Does it matter that the packages above are unable to be updated?
> >For
> >>> insight, I am trying to generate linear regression models that model
> >>> expression of methylation w/ in a TCGA dataset.***
> >>>
> >>> Best,
> >>>
> >>> Spencer
> >>>
> >>> On Sun, Apr 21, 2019 at 10:57 PM Boris Steipe
> >>> <boris.steipe at utoronto.ca>
> >>> wrote:
> >>>
> >>>> This is unrelated to the question on the subject line, we call this
> >>>> "thread hijacking" and that's one of the Things Not To Do. Post a
> >new
> >>>> question.
> >>>>
> >>>> I just wanted to give you the proper incantation for Bioconductor
> >>>> packages. As you already know, don't use bioclite(), which needed
> >to
> >>> be
> >>>> sourced from an URL. Instead install.packages("Biocmanager") from
> >>> CRAN,
> >>>> then - there's no need to load it - use
> >Biocmanager::install(<package
> >>>> name>) from there on. I usually have it in scripts like so:
> >>>>
> >>>> if (! requireNamespace("BiocManager", quietly = TRUE)) {
> >>>>  install.packages("BiocManager")
> >>>> }
> >>>> if (! requireNamespace("biomaRt", quietly = TRUE)) {
> >>>>  BiocManager::install("biomaRt")
> >>>> }
> >>>>
> >>>>
> >>>> Cheers,
> >>>> Boris
> >>>>
> >>>>> On 2019-04-21, at 22:27, Spencer Brackett <
> >>>> spbrackett20 at saintjosephhs.com> wrote:
> >>>>>
> >>>>> R users,
> >>>>>
> >>>>> I am trying to download R Studio onto my Chrombook for
> >>> convenience, but
> >>>>> exited out of the Linux terminal that had opened upon my turning
> >on
> >>> of
> >>>>> Linux(Beta) through my settings. Because of this I am unable to
> >>> prompt
> >>>> the
> >>>>> same type of Linex terminal and can only enable a new one via ctrl
> >>> alt t
> >>>> .
> >>>>> Running the same line of commands (as shown below) that I was
> >>> following
> >>>>> before encountering my error w/ the first terminal is not working.
> >>> Note,
> >>>>> the hostname for the new terminal that I have prompted is crosh>
> >if
> >>> that
> >>>>> effects anything.
> >>>>>
> >>>>> Commands I was instructed to make after enabling Linux on my
> >>> Chrome...
> >>>>>
> >>>>> lsb_release
> >>>>> sudo apt search r-base | grep ^r-base (to download R)
> >>>>>
> >>>>> -y gnupg2
> >>>>> ?keyserver keys.gnupg.net ?recv-key ? ?
> >>>>> ***where my terminal experienced some sort of error causing me to
> >>> abandon
> >>>>> it***
> >>>>>
> >>>>> Any pointers for how I may proceed or alternative tutorials that I
> >>> may
> >>>>> follow?
> >>>>>
> >>>>> Best,
> >>>>>
> >>>>> Spencer Brackett
> >>>>>
> >>>>>
> >>>>> On Sun, Apr 21, 2019 at 9:35 PM Spencer Brackett <
> >>>>> spbrackett20 at saintjosephhs.com> wrote:
> >>>>>
> >>>>>> Mr. Gunter,
> >>>>>>
> >>>>>> Yes I have reached out to the bioconductor list but was informed
> >>> that my
> >>>>>> inquiry concerning this package was not appropriate for the
> >>> mailing
> >>>> list.
> >>>>>> However, I have since tried re implementing the code which I sent
> >>> and
> >>>> my R
> >>>>>> Studio says that netReg has successfully been unpacked, so for
> >now
> >>> it
> >>>>>> appears that my problem is solved :)
> >>>>>>
> >>>>>> Best,
> >>>>>>
> >>>>>> Spencer Brackett
> >>>>>>
> >>>>>> On Sun, Apr 21, 2019 at 8:35 PM Bert Gunter
> >>> <bgunter.4567 at gmail.com>
> >>>>>> wrote:
> >>>>>>
> >>>>>>> netReg is not "the package that generates regression models in
> >>> R." Tons
> >>>>>>> of packages generate regression models in R, including lm(),
> >>> which is
> >>>> in
> >>>>>>> the stats package that is part of R's standard distro.
> >>>>>>>
> >>>>>>> So what exactly is it that you want to do that you think
> >requires
> >>>> netReg?
> >>>>>>> And if netReg is required, have you tried addressing your
> >queries
> >>> to
> >>>> the
> >>>>>>> Bioconductor list, as it is one of their packages?
> >>>>>>>
> >>>>>>> Cheers,
> >>>>>>> Bert
> >>>>>>>
> >>>>>>>
> >>>>>>> "The trouble with having an open mind is that people keep coming
> >>> along
> >>>>>>> and sticking things into it."
> >>>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip
> >>> )
> >>>>>>>
> >>>>>>>
> >>>>>>> On Sun, Apr 21, 2019 at 5:06 PM Spencer Brackett <
> >>>>>>> spbrackett20 at saintjosephhs.com> wrote:
> >>>>>>>
> >>>>>>>> Good evening,
> >>>>>>>>
> >>>>>>>> I am having problems with downloading the package used to
> >>> generate
> >>>>>>>> regression models on R. The following is the error message I
> >>>> received. I
> >>>>>>>> tried installing BiocManager instead as suggested, but this too
> >>> did
> >>>> not
> >>>>>>>> work. Any ideas?
> >>>>>>>>
> >>>>>>>> The following is the full summary of what I?ve tried thus
> >far...
> >>>>>>>>
> >>>>>>>> install.packages("ggplot2")
> >>>>>>>> install.packages("ggplot2")
> >>>>>>>> source("https://bioconductor.org/biocLite.R")
> >>>>>>>> ?BiocUpgrade
> >>>>>>>>
> >>> source("https://bioconductor.org/biocLite.R")biocLite("BiocUpgrade")
> >>>>>>>> source("https://bioconductor.org/biocLite.R")
> >>>>>>>> biocLite("BiocUpgrade")
> >>>>>>>> source("https://bioconductor.org/bioLite.R")
> >>>>>>>> biocLite("netReg")
> >>>>>>>> help("Deprecated")
> >>>>>>>> 'BiocManager::install'
> >>>>>>>> biocLite("netReg")
> >>>>>>>> help("oldName-deprecated")
> >>>>>>>> ???oldName-deprecated?
> >>>>>>>> .Deprecated(new, package=NULL, msg,
> >>>>>>>> old = as.character(sys.call(sys.parent()))[1L])
> >>>>>>>>
> >>>>>>>> Best,
> >>>>>>>>
> >>>>>>>> Spencer
> >>>>>>>>
> >>>>>>>> On Sun, Apr 14, 2019 at 7:58 PM Spencer Brackett <
> >>>>>>>> spbrackett20 at saintjosephhs.com> wrote:
> >>>>>>>>
> >>>>>>>>> My apologies... here is the full code in summary
> >>>>>>>>>
> >>>>>>>>> install.packages("ggplot2")
> >>>>>>>>> install.packages("ggplot2")
> >>>>>>>>> source("https://bioconductor.org/biocLite.R")
> >>>>>>>>> ?BiocUpgrade
> >>>>>>>>>
> >>> source("https://bioconductor.org/biocLite.R")biocLite("BiocUpgrade")
> >>>>>>>>> source("https://bioconductor.org/biocLite.R")
> >>>>>>>>> biocLite("BiocUpgrade")
> >>>>>>>>> source("https://bioconductor.org/bioLite.R")
> >>>>>>>>> biocLite("netReg")
> >>>>>>>>> help("Deprecated")
> >>>>>>>>> 'BiocManager::install'
> >>>>>>>>> biocLite("netReg")
> >>>>>>>>> help("oldName-deprecated")
> >>>>>>>>> ???oldName-deprecated?
> >>>>>>>>> .Deprecated(new, package=NULL, msg,
> >>>>>>>>> old = as.character(sys.call(sys.parent()))[1L])
> >>>>>>>>>
> >>>>>>>>> Best,
> >>>>>>>>>
> >>>>>>>>> Spencer
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>>
> >>>>>>>>> On Sun, Apr 14, 2019 at 7:20 PM David Winsemius <
> >>>>>>>> dwinsemius at comcast.net>
> >>>>>>>>> wrote:
> >>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>>> On 4/14/19 3:20 PM, Spencer Brackett wrote:
> >>>>>>>>>>> Good evening,
> >>>>>>>>>>>
> >>>>>>>>>>> I am having problems with downloading the package used to
> >>> generate
> >>>>>>>>>>> regression models on R. The following is the error message I
> >>>>>>>> received. I
> >>>>>>>>>>> tried installing BiocManager instead as suggested, but this
> >>> too did
> >>>>>>>> not
> >>>>>>>>>>> work. Any ideas?
> >>>>>>>>>>>
> >>>>>>>>>>> The downloaded binary packages are in
> >>>>>>>>>>>
> >>> C:\Users\Spencer\AppData\Local\Temp\Rtmp8YKVqx\downloaded_packages
> >>>>>>>>>>> installation path not writeable, unable to update packages:
> >>> class,
> >>>>>>>>>> cluster,
> >>>>>>>>>>> codetools, foreign,
> >>>>>>>>>>>  lattice, MASS, Matrix, mgcv, nlme, rpart, survival
> >>>>>>>>>>> Warning message:
> >>>>>>>>>>> 'biocLite' is deprecated.
> >>>>>>>>>>> Use 'BiocManager::install' instead.
> >>>>>>>>>>> See help("Deprecated")
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>> Since you did not include the code that provoked this message
> >>> we can
> >>>>>>>>>> only guess that you did in fact use `bioLite`. We also cannot
> >>> tell
> >>>>>>>> what
> >>>>>>>>>> you mean by "problems with downloading the package used to
> >>> generate
> >>>>>>>>>> regression models on R". The typical first step is to use the
> >>> glm or
> >>>>>>>> lm
> >>>>>>>>>> function for this task and those are both in the stats
> >package
> >>> which
> >>>>>>>> is
> >>>>>>>>>> installed with the base version of R and is loaded by default
> >>> when R
> >>>>>>>> is
> >>>>>>>>>> started up.
> >>>>>>>>>>
> >>>>>>>>>> "
> >>>>>>>>>>
> >>>>>>>>>> Have you tried following the suggestion at the end of the
> >>> message?
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>> And do read the Posting Guide and include "commented,
> >minimal,
> >>>>>>>>>> self-contained, reproducible code."
> >>>>>>>>>>
> >>>>>>>>>>
> >>>>>>>>>> --
> >>>>>>>>>>
> >>>>>>>>>> David.
> >>>>>>>>>>
> >>>>>>>>>>>
> >>>>>>>>>>> Best,
> >>>>>>>>>>>
> >>>>>>>>>>> Spencer
> >>>>>>>>>>>
> >>>>>>>>>>>     [[alternative HTML version deleted]]
> >>>>>>>>>>>
> >>>>>>>>>>> ______________________________________________
> >>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> >more,
> >>> see
> >>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>>>>> PLEASE do read the posting guide
> >>>>>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>>>>> and provide commented, minimal, self-contained, reproducible
> >>> code.
> >>>>>>>>>>
> >>>>>>>>>
> >>>>>>>>
> >>>>>>>>       [[alternative HTML version deleted]]
> >>>>>>>>
> >>>>>>>> ______________________________________________
> >>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >>> see
> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>> PLEASE do read the posting guide
> >>>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>> and provide commented, minimal, self-contained, reproducible
> >>> code.
> >>>>>>>>
> >>>>>>>
> >>>>>
> >>>>>      [[alternative HTML version deleted]]
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>>
> >>>
> >>>    [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com  Mon Apr 22 20:49:26 2019
From: @pbr@ckett20 @end|ng |rom @@|ntjo@ephh@@com (Spencer Brackett)
Date: Mon, 22 Apr 2019 14:49:26 -0400
Subject: [R] Problems w/ creating object
Message-ID: <CAPQaxLPzgYKwg_vkdZkN+shdUPRsK_HOjjE-r8r4LNxvESHYNw@mail.gmail.com>

Hello R users,

I am trying to create an object out of some data a colleague sent my way,
so to duplicate the following code...

library(data.table)
anno = as.data.frame(fread(file =
"/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt", sep ="\t",
header = T))
meth = read.table(file =
"/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/27K/GBM.txt", sep  ="\t",
header = T, row.names = 1)
meth = as.matrix(meth)
""" the loop just formats the methylation column names to match format"""
colnames(meth) = sapply(colnames(meth), function(i){
  c1 = strsplit(i,split = '.', fixed = T)[[1]]
  c1[4] = paste(strsplit(c1[4],split = "",fixed = T)[[1]][1:2],collapse =
"")
  paste(c1,collapse = ".")
})
exp = read.table(file =
"/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/RNAseq/GBM.txt", sep = "\t",
header = T, row.names = 1)
exp = as.matrix(exp)
c = intersect(colnames(exp),colnames(meth))
exp = exp[,c]
meth = meth[,c]
m = apply(meth, 1, function(i){
  log2(i/(1-i))
})
m = t(as.matrix(m))
an = anno[anno$probe %in% rownames(m),]
an = an[an$gene %in% rownames(exp),]
an = an[an$location %in% c("TSS200","TSS1500"),]

p = apply(an,1,function(i){
  tryCatch(summary(lm(exp[as.character(i[2]),] ~
m[as.character(i[1]),]))$coefficient[2,4], error= function(e)NA)
})
t = apply(an,1,function(i){
  tryCatch(summary(lm(exp[as.character(i[2]),] ~
m[as.character(i[1]),]))$coefficient[2,3], error= function(e)NA)
})
an1 =cbind(an,p)
an1 = cbind(an1,t)
an1$q = p.adjust(as.numeric(an1$p))
summary(lm(exp["MAOB",] ~ m["cg00121904",]$coefficient[2,c(3:4)]
###############################################

m2 = m
ll = list()
for(i in colnames(m2)){
  str = strsplit(i, split = ".", fixed = T)[[1]]
  if(str[4] == "11"){

  }else{
    ll = c(ll,i)
  }
}
ll = unlist(ll)
m2 = m2[,ll]
colnames(m2) = sapply(colnames(m2), function(i){
  str = strsplit(i,split = ".", fixed = T)[[1]]
  p = paste(str[c(1:3)], collapse = "-")
})


clin = as.data.frame(fread(file =
"/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/survival/FireHose/GBM/GBM.clin.merged.txt",
sep = "\t", header = F))
clin = t(clin)
colnames(clin) = clin[1,]
rownames(clin) = toupper(clin[,"patient.bcr_patient_barcode"])
clin = clin[2:length(clin[,1]),]
#"patient.stage_event.pathologic_stage"
clin1 =
clin[,c("patient.age_at_initial_pathologic_diagnosis","patient.days_to_death","patient.days_to_last_followup","patient.vital_status")]
clin1 = cbind(clin1,rep("bla",length(clin1[,1])))
clin2 = as.matrix(clin1)
colnames(clin2)[length(colnames(clin2))] = "time"

for(i in rownames(clin2)){

  if(clin2[i,"patient.vital_status"] %in% c("alive")){
    clin2[i,"patient.vital_status"] =0
  }else if(clin2[i,"patient.vital_status"] %in% c("dead")){
    clin2[i,"patient.vital_status"] =1
  }else{
    clin2[i,"patient.vital_status"] = "NA"
  }

  if(is.na(clin2[i,"patient.days_to_last_followup"])){
    clin2[i,"time"] = clin2[i,"patient.days_to_death"]
  }else{
    clin2[i,"time"] = clin2[i,"patient.days_to_last_followup"]
  }
}

clin2 = clin2[!is.na(clin2[,"time"]),]
clin2 = clin2[!is.na(clin2[,"patient.vital_status"]),]

library(survival)
p = intersect(colnames(m2), rownames(clin2))
surv =
Surv(as.numeric(clin2[p,"time"]),as.numeric(clin2[p,"patient.vital_status"]))

an_m = anno[anno$probe %in% rownames(m2),]
an_m = an[an$gene %in% rownames(exp),]

sur_z = apply(an_m, 1, function(i){
  tryCatch(summary(coxph(surv ~
as.numeric(m2[as.character(i[1]),p])+as.numeric(clin2[p,"patient.age_at_initial_pathologic_diagnosis"])))$coefficients[1,c("z")],
error = function(e) NA)
})

sur_p = apply(an_m, 1, function(i){
  tryCatch(summary(coxph(surv ~
as.numeric(m2[as.character(i[1]),p])+as.numeric(clin2[p,"patient.age_at_initial_pathologic_diagnosis"])))$coefficients[1,c("Pr(>|z|)")],
error = function(e) NA)
})

qsur = p.adjust(as.numeric(sur_p))
sur = cbind(sur_z,sur_p)
sur = cbind(sur,qsur)


The file is a text file
"/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt", which is
then proceeded by another txt. file
"/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/27K/GBM.txt, which I wish to
load subsequently. However, when i tried copying the procedure above I
received the following error message..

library(data.table)
> anno = as.data.frame(fread(file =
"/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt", sep ="\t",
header = T))
Error in fread(file =
"/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt",  :
  File '/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt' does
not exist or is non-readable.
getwd()=='C:/Users/Spencer/Documents'

The file does exit so in what context is it 'unreadable' and how might I
solve this situation?

Best,

Spencer

	[[alternative HTML version deleted]]


From dw|n@em|u@ @end|ng |rom comc@@t@net  Mon Apr 22 22:57:55 2019
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 22 Apr 2019 13:57:55 -0700
Subject: [R] Problems w/ creating object
In-Reply-To: <CAPQaxLPzgYKwg_vkdZkN+shdUPRsK_HOjjE-r8r4LNxvESHYNw@mail.gmail.com>
References: <CAPQaxLPzgYKwg_vkdZkN+shdUPRsK_HOjjE-r8r4LNxvESHYNw@mail.gmail.com>
Message-ID: <860d5cb6-c6de-f498-8553-5e63e6502b5c@comcast.net>


On 4/22/19 11:49 AM, Spencer Brackett wrote:
> Hello R users,
>
> I am trying to create an object out of some data a colleague sent my way,
> so to duplicate the following code...
>
> library(data.table)
> anno = as.data.frame(fread(file =
> "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt", sep ="\t",
> header = T))


At first glance it appeared that you sent the list a rather extensive 
bit of code and asked us to figure something out, but after looking at 
the error message it instead appears the it was the first effort at 
reading data from disk that threw an error. So the rest of the code is 
at best unnecessary and at worst seriously distracting (to us and more 
crucially to you).

You should run your code one line at a time so you and the rest of us 
are not completely distracted. This was the error message:

> anno = as.data.frame(fread(file =

"/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt", sep ="\t",
header = T))
Error in fread(file =
"/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt",  :
   File '/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt' does
not exist or is non-readable.

You claim this file exists, but I'm uncertain how convincing that 
assertion should be "scored". What do either of these show?

 ?list.files(pattern =".txt$")

# Or

"mapper.txt" %in% list.files( paste0 ( getwd(), "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K"))

-- 

David.


PS Please learn to post in plain-text. It didn't cause a problem this 
time but it probably will at some time in the future.

> meth = read.table(file =
> "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/27K/GBM.txt", sep  ="\t",
> header = T, row.names = 1)
> meth = as.matrix(meth)
> """ the loop just formats the methylation column names to match format"""
> colnames(meth) = sapply(colnames(meth), function(i){
>    c1 = strsplit(i,split = '.', fixed = T)[[1]]
>    c1[4] = paste(strsplit(c1[4],split = "",fixed = T)[[1]][1:2],collapse =
> "")
>    paste(c1,collapse = ".")
> })
> exp = read.table(file =
> "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/RNAseq/GBM.txt", sep = "\t",
> header = T, row.names = 1)
> exp = as.matrix(exp)
> c = intersect(colnames(exp),colnames(meth))
> exp = exp[,c]
> meth = meth[,c]
> m = apply(meth, 1, function(i){
>    log2(i/(1-i))
> })
> m = t(as.matrix(m))
> an = anno[anno$probe %in% rownames(m),]
> an = an[an$gene %in% rownames(exp),]
> an = an[an$location %in% c("TSS200","TSS1500"),]
>
> p = apply(an,1,function(i){
>    tryCatch(summary(lm(exp[as.character(i[2]),] ~
> m[as.character(i[1]),]))$coefficient[2,4], error= function(e)NA)
> })
> t = apply(an,1,function(i){
>    tryCatch(summary(lm(exp[as.character(i[2]),] ~
> m[as.character(i[1]),]))$coefficient[2,3], error= function(e)NA)
> })
> an1 =cbind(an,p)
> an1 = cbind(an1,t)
> an1$q = p.adjust(as.numeric(an1$p))
> summary(lm(exp["MAOB",] ~ m["cg00121904",]$coefficient[2,c(3:4)]
> ###############################################
>
> m2 = m
> ll = list()
> for(i in colnames(m2)){
>    str = strsplit(i, split = ".", fixed = T)[[1]]
>    if(str[4] == "11"){
>
>    }else{
>      ll = c(ll,i)
>    }
> }
> ll = unlist(ll)
> m2 = m2[,ll]
> colnames(m2) = sapply(colnames(m2), function(i){
>    str = strsplit(i,split = ".", fixed = T)[[1]]
>    p = paste(str[c(1:3)], collapse = "-")
> })
>
>
> clin = as.data.frame(fread(file =
> "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/survival/FireHose/GBM/GBM.clin.merged.txt",
> sep = "\t", header = F))
> clin = t(clin)
> colnames(clin) = clin[1,]
> rownames(clin) = toupper(clin[,"patient.bcr_patient_barcode"])
> clin = clin[2:length(clin[,1]),]
> #"patient.stage_event.pathologic_stage"
> clin1 =
> clin[,c("patient.age_at_initial_pathologic_diagnosis","patient.days_to_death","patient.days_to_last_followup","patient.vital_status")]
> clin1 = cbind(clin1,rep("bla",length(clin1[,1])))
> clin2 = as.matrix(clin1)
> colnames(clin2)[length(colnames(clin2))] = "time"
>
> for(i in rownames(clin2)){
>
>    if(clin2[i,"patient.vital_status"] %in% c("alive")){
>      clin2[i,"patient.vital_status"] =0
>    }else if(clin2[i,"patient.vital_status"] %in% c("dead")){
>      clin2[i,"patient.vital_status"] =1
>    }else{
>      clin2[i,"patient.vital_status"] = "NA"
>    }
>
>    if(is.na(clin2[i,"patient.days_to_last_followup"])){
>      clin2[i,"time"] = clin2[i,"patient.days_to_death"]
>    }else{
>      clin2[i,"time"] = clin2[i,"patient.days_to_last_followup"]
>    }
> }
>
> clin2 = clin2[!is.na(clin2[,"time"]),]
> clin2 = clin2[!is.na(clin2[,"patient.vital_status"]),]
>
> library(survival)
> p = intersect(colnames(m2), rownames(clin2))
> surv =
> Surv(as.numeric(clin2[p,"time"]),as.numeric(clin2[p,"patient.vital_status"]))
>
> an_m = anno[anno$probe %in% rownames(m2),]
> an_m = an[an$gene %in% rownames(exp),]
>
> sur_z = apply(an_m, 1, function(i){
>    tryCatch(summary(coxph(surv ~
> as.numeric(m2[as.character(i[1]),p])+as.numeric(clin2[p,"patient.age_at_initial_pathologic_diagnosis"])))$coefficients[1,c("z")],
> error = function(e) NA)
> })
>
> sur_p = apply(an_m, 1, function(i){
>    tryCatch(summary(coxph(surv ~
> as.numeric(m2[as.character(i[1]),p])+as.numeric(clin2[p,"patient.age_at_initial_pathologic_diagnosis"])))$coefficients[1,c("Pr(>|z|)")],
> error = function(e) NA)
> })
>
> qsur = p.adjust(as.numeric(sur_p))
> sur = cbind(sur_z,sur_p)
> sur = cbind(sur,qsur)
>
>
> The file is a text file
> "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt", which is
> then proceeded by another txt. file
> "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/27K/GBM.txt, which I wish to
> load subsequently. However, when i tried copying the procedure above I
> received the following error message..
>
> library(data.table)
>> anno = as.data.frame(fread(file =
> "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt", sep ="\t",
> header = T))
> Error in fread(file =
> "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt",  :
>    File '/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt' does
> not exist or is non-readable.
> getwd()=='C:/Users/Spencer/Documents'
>
> The file does exit so in what context is it 'unreadable' and how might I
> solve this situation?
>
> Best,
>
> Spencer
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdun|@p @end|ng |rom t|bco@com  Mon Apr 22 23:09:16 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Mon, 22 Apr 2019 14:09:16 -0700
Subject: [R] Problems w/ creating object
In-Reply-To: <860d5cb6-c6de-f498-8553-5e63e6502b5c@comcast.net>
References: <CAPQaxLPzgYKwg_vkdZkN+shdUPRsK_HOjjE-r8r4LNxvESHYNw@mail.gmail.com>
 <860d5cb6-c6de-f498-8553-5e63e6502b5c@comcast.net>
Message-ID: <CAF8bMcb=vTD6aoMxkJDCaOXWO=wMxjr0L=2ayzYY3pf0NPOpPA@mail.gmail.com>

  file.info( "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt" )
would tell about the permissions on the file, if it exists (and give NA's
if it did not).

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Apr 22, 2019 at 2:00 PM David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On 4/22/19 11:49 AM, Spencer Brackett wrote:
> > Hello R users,
> >
> > I am trying to create an object out of some data a colleague sent my way,
> > so to duplicate the following code...
> >
> > library(data.table)
> > anno = as.data.frame(fread(file =
> > "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt", sep ="\t",
> > header = T))
>
>
> At first glance it appeared that you sent the list a rather extensive
> bit of code and asked us to figure something out, but after looking at
> the error message it instead appears the it was the first effort at
> reading data from disk that threw an error. So the rest of the code is
> at best unnecessary and at worst seriously distracting (to us and more
> crucially to you).
>
> You should run your code one line at a time so you and the rest of us
> are not completely distracted. This was the error message:
>
> > anno = as.data.frame(fread(file =
>
> "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt", sep ="\t",
> header = T))
> Error in fread(file =
> "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt",  :
>    File '/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt' does
> not exist or is non-readable.
>
> You claim this file exists, but I'm uncertain how convincing that
> assertion should be "scored". What do either of these show?
>
>   list.files(pattern =".txt$")
>
> # Or
>
> "mapper.txt" %in% list.files( paste0 ( getwd(),
> "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K"))
>
> --
>
> David.
>
>
> PS Please learn to post in plain-text. It didn't cause a problem this
> time but it probably will at some time in the future.
>
> > meth = read.table(file =
> > "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/27K/GBM.txt", sep  ="\t",
> > header = T, row.names = 1)
> > meth = as.matrix(meth)
> > """ the loop just formats the methylation column names to match format"""
> > colnames(meth) = sapply(colnames(meth), function(i){
> >    c1 = strsplit(i,split = '.', fixed = T)[[1]]
> >    c1[4] = paste(strsplit(c1[4],split = "",fixed = T)[[1]][1:2],collapse
> =
> > "")
> >    paste(c1,collapse = ".")
> > })
> > exp = read.table(file =
> > "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/RNAseq/GBM.txt", sep = "\t",
> > header = T, row.names = 1)
> > exp = as.matrix(exp)
> > c = intersect(colnames(exp),colnames(meth))
> > exp = exp[,c]
> > meth = meth[,c]
> > m = apply(meth, 1, function(i){
> >    log2(i/(1-i))
> > })
> > m = t(as.matrix(m))
> > an = anno[anno$probe %in% rownames(m),]
> > an = an[an$gene %in% rownames(exp),]
> > an = an[an$location %in% c("TSS200","TSS1500"),]
> >
> > p = apply(an,1,function(i){
> >    tryCatch(summary(lm(exp[as.character(i[2]),] ~
> > m[as.character(i[1]),]))$coefficient[2,4], error= function(e)NA)
> > })
> > t = apply(an,1,function(i){
> >    tryCatch(summary(lm(exp[as.character(i[2]),] ~
> > m[as.character(i[1]),]))$coefficient[2,3], error= function(e)NA)
> > })
> > an1 =cbind(an,p)
> > an1 = cbind(an1,t)
> > an1$q = p.adjust(as.numeric(an1$p))
> > summary(lm(exp["MAOB",] ~ m["cg00121904",]$coefficient[2,c(3:4)]
> > ###############################################
> >
> > m2 = m
> > ll = list()
> > for(i in colnames(m2)){
> >    str = strsplit(i, split = ".", fixed = T)[[1]]
> >    if(str[4] == "11"){
> >
> >    }else{
> >      ll = c(ll,i)
> >    }
> > }
> > ll = unlist(ll)
> > m2 = m2[,ll]
> > colnames(m2) = sapply(colnames(m2), function(i){
> >    str = strsplit(i,split = ".", fixed = T)[[1]]
> >    p = paste(str[c(1:3)], collapse = "-")
> > })
> >
> >
> > clin = as.data.frame(fread(file =
> >
> "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/survival/FireHose/GBM/GBM.clin.merged.txt",
> > sep = "\t", header = F))
> > clin = t(clin)
> > colnames(clin) = clin[1,]
> > rownames(clin) = toupper(clin[,"patient.bcr_patient_barcode"])
> > clin = clin[2:length(clin[,1]),]
> > #"patient.stage_event.pathologic_stage"
> > clin1 =
> >
> clin[,c("patient.age_at_initial_pathologic_diagnosis","patient.days_to_death","patient.days_to_last_followup","patient.vital_status")]
> > clin1 = cbind(clin1,rep("bla",length(clin1[,1])))
> > clin2 = as.matrix(clin1)
> > colnames(clin2)[length(colnames(clin2))] = "time"
> >
> > for(i in rownames(clin2)){
> >
> >    if(clin2[i,"patient.vital_status"] %in% c("alive")){
> >      clin2[i,"patient.vital_status"] =0
> >    }else if(clin2[i,"patient.vital_status"] %in% c("dead")){
> >      clin2[i,"patient.vital_status"] =1
> >    }else{
> >      clin2[i,"patient.vital_status"] = "NA"
> >    }
> >
> >    if(is.na(clin2[i,"patient.days_to_last_followup"])){
> >      clin2[i,"time"] = clin2[i,"patient.days_to_death"]
> >    }else{
> >      clin2[i,"time"] = clin2[i,"patient.days_to_last_followup"]
> >    }
> > }
> >
> > clin2 = clin2[!is.na(clin2[,"time"]),]
> > clin2 = clin2[!is.na(clin2[,"patient.vital_status"]),]
> >
> > library(survival)
> > p = intersect(colnames(m2), rownames(clin2))
> > surv =
> >
> Surv(as.numeric(clin2[p,"time"]),as.numeric(clin2[p,"patient.vital_status"]))
> >
> > an_m = anno[anno$probe %in% rownames(m2),]
> > an_m = an[an$gene %in% rownames(exp),]
> >
> > sur_z = apply(an_m, 1, function(i){
> >    tryCatch(summary(coxph(surv ~
> >
> as.numeric(m2[as.character(i[1]),p])+as.numeric(clin2[p,"patient.age_at_initial_pathologic_diagnosis"])))$coefficients[1,c("z")],
> > error = function(e) NA)
> > })
> >
> > sur_p = apply(an_m, 1, function(i){
> >    tryCatch(summary(coxph(surv ~
> >
> as.numeric(m2[as.character(i[1]),p])+as.numeric(clin2[p,"patient.age_at_initial_pathologic_diagnosis"])))$coefficients[1,c("Pr(>|z|)")],
> > error = function(e) NA)
> > })
> >
> > qsur = p.adjust(as.numeric(sur_p))
> > sur = cbind(sur_z,sur_p)
> > sur = cbind(sur,qsur)
> >
> >
> > The file is a text file
> > "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt", which is
> > then proceeded by another txt. file
> > "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/27K/GBM.txt, which I wish to
> > load subsequently. However, when i tried copying the procedure above I
> > received the following error message..
> >
> > library(data.table)
> >> anno = as.data.frame(fread(file =
> > "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt", sep ="\t",
> > header = T))
> > Error in fread(file =
> > "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt",  :
> >    File '/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt'
> does
> > not exist or is non-readable.
> > getwd()=='C:/Users/Spencer/Documents'
> >
> > The file does exit so in what context is it 'unreadable' and how might I
> > solve this situation?
> >
> > Best,
> >
> > Spencer
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdun|@p @end|ng |rom t|bco@com  Mon Apr 22 23:24:37 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Mon, 22 Apr 2019 14:24:37 -0700
Subject: [R] Problems w/ creating object
In-Reply-To: <CAF8bMcb=vTD6aoMxkJDCaOXWO=wMxjr0L=2ayzYY3pf0NPOpPA@mail.gmail.com>
References: <CAPQaxLPzgYKwg_vkdZkN+shdUPRsK_HOjjE-r8r4LNxvESHYNw@mail.gmail.com>
 <860d5cb6-c6de-f498-8553-5e63e6502b5c@comcast.net>
 <CAF8bMcb=vTD6aoMxkJDCaOXWO=wMxjr0L=2ayzYY3pf0NPOpPA@mail.gmail.com>
Message-ID: <CAF8bMcbn-8_SEnNHtagLRfMGZc9PFSrs9k0Qc5e4m=Sj+r778Q@mail.gmail.com>

Also, recall that on Windows each drive has its own root directory so the
meaning of "/some/file" depends on where your working directory is at the
moment.  E.g.,

> setwd("C:/tmp")
> cat(file="junk.txt",1:10)
> file.info("/tmp/junk.txt")
              size isdir mode               mtime               ctime
         atime exe
/tmp/junk.txt   20 FALSE  666 2019-04-22 14:20:06 2018-05-15 09:38:02
2018-05-15 09:38:02  no
> setwd("Z:/") # I've mapped Z: to a network location
> file.info("/tmp/junk.txt")
              size isdir mode mtime ctime atime  exe
/tmp/junk.txt   NA    NA <NA>  <NA>  <NA>  <NA> <NA>
> file.info("C:/tmp/junk.txt") # add drive-colon to file name
                size isdir mode               mtime               ctime
           atime exe
C:/tmp/junk.txt   20 FALSE  666 2019-04-22 14:20:06 2018-05-15 09:38:02
2018-05-15 09:38:02  no

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Apr 22, 2019 at 2:09 PM William Dunlap <wdunlap at tibco.com> wrote:

>   file.info(
> "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt" )
> would tell about the permissions on the file, if it exists (and give NA's
> if it did not).
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Mon, Apr 22, 2019 at 2:00 PM David Winsemius <dwinsemius at comcast.net>
> wrote:
>
>>
>> On 4/22/19 11:49 AM, Spencer Brackett wrote:
>> > Hello R users,
>> >
>> > I am trying to create an object out of some data a colleague sent my
>> way,
>> > so to duplicate the following code...
>> >
>> > library(data.table)
>> > anno = as.data.frame(fread(file =
>> > "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt", sep
>> ="\t",
>> > header = T))
>>
>>
>> At first glance it appeared that you sent the list a rather extensive
>> bit of code and asked us to figure something out, but after looking at
>> the error message it instead appears the it was the first effort at
>> reading data from disk that threw an error. So the rest of the code is
>> at best unnecessary and at worst seriously distracting (to us and more
>> crucially to you).
>>
>> You should run your code one line at a time so you and the rest of us
>> are not completely distracted. This was the error message:
>>
>> > anno = as.data.frame(fread(file =
>>
>> "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt", sep ="\t",
>> header = T))
>> Error in fread(file =
>> "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt",  :
>>    File '/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt' does
>> not exist or is non-readable.
>>
>> You claim this file exists, but I'm uncertain how convincing that
>> assertion should be "scored". What do either of these show?
>>
>>   list.files(pattern =".txt$")
>>
>> # Or
>>
>> "mapper.txt" %in% list.files( paste0 ( getwd(),
>> "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K"))
>>
>> --
>>
>> David.
>>
>>
>> PS Please learn to post in plain-text. It didn't cause a problem this
>> time but it probably will at some time in the future.
>>
>> > meth = read.table(file =
>> > "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/27K/GBM.txt", sep  ="\t",
>> > header = T, row.names = 1)
>> > meth = as.matrix(meth)
>> > """ the loop just formats the methylation column names to match
>> format"""
>> > colnames(meth) = sapply(colnames(meth), function(i){
>> >    c1 = strsplit(i,split = '.', fixed = T)[[1]]
>> >    c1[4] = paste(strsplit(c1[4],split = "",fixed =
>> T)[[1]][1:2],collapse =
>> > "")
>> >    paste(c1,collapse = ".")
>> > })
>> > exp = read.table(file =
>> > "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/RNAseq/GBM.txt", sep =
>> "\t",
>> > header = T, row.names = 1)
>> > exp = as.matrix(exp)
>> > c = intersect(colnames(exp),colnames(meth))
>> > exp = exp[,c]
>> > meth = meth[,c]
>> > m = apply(meth, 1, function(i){
>> >    log2(i/(1-i))
>> > })
>> > m = t(as.matrix(m))
>> > an = anno[anno$probe %in% rownames(m),]
>> > an = an[an$gene %in% rownames(exp),]
>> > an = an[an$location %in% c("TSS200","TSS1500"),]
>> >
>> > p = apply(an,1,function(i){
>> >    tryCatch(summary(lm(exp[as.character(i[2]),] ~
>> > m[as.character(i[1]),]))$coefficient[2,4], error= function(e)NA)
>> > })
>> > t = apply(an,1,function(i){
>> >    tryCatch(summary(lm(exp[as.character(i[2]),] ~
>> > m[as.character(i[1]),]))$coefficient[2,3], error= function(e)NA)
>> > })
>> > an1 =cbind(an,p)
>> > an1 = cbind(an1,t)
>> > an1$q = p.adjust(as.numeric(an1$p))
>> > summary(lm(exp["MAOB",] ~ m["cg00121904",]$coefficient[2,c(3:4)]
>> > ###############################################
>> >
>> > m2 = m
>> > ll = list()
>> > for(i in colnames(m2)){
>> >    str = strsplit(i, split = ".", fixed = T)[[1]]
>> >    if(str[4] == "11"){
>> >
>> >    }else{
>> >      ll = c(ll,i)
>> >    }
>> > }
>> > ll = unlist(ll)
>> > m2 = m2[,ll]
>> > colnames(m2) = sapply(colnames(m2), function(i){
>> >    str = strsplit(i,split = ".", fixed = T)[[1]]
>> >    p = paste(str[c(1:3)], collapse = "-")
>> > })
>> >
>> >
>> > clin = as.data.frame(fread(file =
>> >
>> "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/survival/FireHose/GBM/GBM.clin.merged.txt",
>> > sep = "\t", header = F))
>> > clin = t(clin)
>> > colnames(clin) = clin[1,]
>> > rownames(clin) = toupper(clin[,"patient.bcr_patient_barcode"])
>> > clin = clin[2:length(clin[,1]),]
>> > #"patient.stage_event.pathologic_stage"
>> > clin1 =
>> >
>> clin[,c("patient.age_at_initial_pathologic_diagnosis","patient.days_to_death","patient.days_to_last_followup","patient.vital_status")]
>> > clin1 = cbind(clin1,rep("bla",length(clin1[,1])))
>> > clin2 = as.matrix(clin1)
>> > colnames(clin2)[length(colnames(clin2))] = "time"
>> >
>> > for(i in rownames(clin2)){
>> >
>> >    if(clin2[i,"patient.vital_status"] %in% c("alive")){
>> >      clin2[i,"patient.vital_status"] =0
>> >    }else if(clin2[i,"patient.vital_status"] %in% c("dead")){
>> >      clin2[i,"patient.vital_status"] =1
>> >    }else{
>> >      clin2[i,"patient.vital_status"] = "NA"
>> >    }
>> >
>> >    if(is.na(clin2[i,"patient.days_to_last_followup"])){
>> >      clin2[i,"time"] = clin2[i,"patient.days_to_death"]
>> >    }else{
>> >      clin2[i,"time"] = clin2[i,"patient.days_to_last_followup"]
>> >    }
>> > }
>> >
>> > clin2 = clin2[!is.na(clin2[,"time"]),]
>> > clin2 = clin2[!is.na(clin2[,"patient.vital_status"]),]
>> >
>> > library(survival)
>> > p = intersect(colnames(m2), rownames(clin2))
>> > surv =
>> >
>> Surv(as.numeric(clin2[p,"time"]),as.numeric(clin2[p,"patient.vital_status"]))
>> >
>> > an_m = anno[anno$probe %in% rownames(m2),]
>> > an_m = an[an$gene %in% rownames(exp),]
>> >
>> > sur_z = apply(an_m, 1, function(i){
>> >    tryCatch(summary(coxph(surv ~
>> >
>> as.numeric(m2[as.character(i[1]),p])+as.numeric(clin2[p,"patient.age_at_initial_pathologic_diagnosis"])))$coefficients[1,c("z")],
>> > error = function(e) NA)
>> > })
>> >
>> > sur_p = apply(an_m, 1, function(i){
>> >    tryCatch(summary(coxph(surv ~
>> >
>> as.numeric(m2[as.character(i[1]),p])+as.numeric(clin2[p,"patient.age_at_initial_pathologic_diagnosis"])))$coefficients[1,c("Pr(>|z|)")],
>> > error = function(e) NA)
>> > })
>> >
>> > qsur = p.adjust(as.numeric(sur_p))
>> > sur = cbind(sur_z,sur_p)
>> > sur = cbind(sur,qsur)
>> >
>> >
>> > The file is a text file
>> > "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt", which is
>> > then proceeded by another txt. file
>> > "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/27K/GBM.txt, which I wish
>> to
>> > load subsequently. However, when i tried copying the procedure above I
>> > received the following error message..
>> >
>> > library(data.table)
>> >> anno = as.data.frame(fread(file =
>> > "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt", sep
>> ="\t",
>> > header = T))
>> > Error in fread(file =
>> > "/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt",  :
>> >    File '/rsrch1/bcb/kchen_group/v_mohanty/data/TCGA/450K/mapper.txt'
>> does
>> > not exist or is non-readable.
>> > getwd()=='C:/Users/Spencer/Documents'
>> >
>> > The file does exit so in what context is it 'unreadable' and how might I
>> > solve this situation?
>> >
>> > Best,
>> >
>> > Spencer
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Tue Apr 23 08:59:29 2019
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 23 Apr 2019 06:59:29 +0000
Subject: [R] combining data.frames with is.na & match (), two questions
In-Reply-To: <CAPSTy5ciQhNOL4oOTJ2FMW-Scr2ChktCCcmgSmM_iMi-kK-Pvw@mail.gmail.com>
References: <CAPSTy5e_6-_p1OwVBN6WmKi6oju24PnEmaHBPvDh4B34c3AEkg@mail.gmail.com>
 <f3b067bd7b674f51ac3b6347e39af02d@SRVEXCHCM1301.precheza.cz>
 <CAPSTy5ciQhNOL4oOTJ2FMW-Scr2ChktCCcmgSmM_iMi-kK-Pvw@mail.gmail.com>
Message-ID: <512de57b37704f56a1974cfadd3db678@SRVEXCHCM1302.precheza.cz>

Hi

Keep posts also to r-help, others could give you different/better solutions.

Regarding ordering, see ?order or ?sort. However this is mainly necessary only for plotting or exporting data.

Cheers
Petr

From: Drake Gossi <drake.gossi at gmail.com>
Sent: Thursday, April 18, 2019 9:27 PM
To: PIKAL Petr <petr.pikal at precheza.cz>
Subject: Re: [R] combining data.frames with is.na & match (), two questions

Thanks Pikal,

Your answer was super helpful. I just learned a lot from you. The only thing I have to figure out now is how to rearrange the numbers, say, so that 200 is on top, and NA is on bottom, or so that the two 100 calories are together. Something like that. Perhaps I'll try an ascending/descending function.

Thank you again.

D

On Thu, Apr 18, 2019 at 1:31 AM PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

I wonder why such combination is so complicated in your text book.

Having data frames fr1 and fr2

> dput(fr1)
structure(list(Fruit = structure(c(1L, 3L, 2L), .Label = c("banana",
"mango", "pear"), class = "factor"), Calories = c(100L, 100L,
200L)), class = "data.frame", row.names = c("1", "2", "3"))
> dput(fr2)
structure(list(Fruit = structure(c(1L, 2L, 5L, 4L, 3L), .Label = c("apple",
"banana", "kiwi", "orange", "pear"), class = "factor"), Color = structure(c(3L,
4L, 1L, 2L, 1L), .Label = c("green", "orange", "red", "yellow"
), class = "factor"), Shape = structure(c(3L, 1L, 2L, 3L, 3L), .Label = c("oblong",
"pear", "round"), class = "factor"), Juice = c(1, 0, 0.5, 1,
0)), class = "data.frame", row.names = c("1", "2", "3", "4",
"5"))
>

> fr1
   Fruit Calories
1 banana      100
2   pear      100
3  mango      200
>

you can use merge to combine those 2 data frames to get either all values from both

> merge(fr2, fr1, all=T)
   Fruit  Color  Shape Juice Calories
1  apple    red  round   1.0       NA
2 banana yellow oblong   0.0      100
3   kiwi  green  round   0.0       NA
4 orange orange  round   1.0       NA
5   pear  green   pear   0.5      100
6  mango   <NA>   <NA>    NA      200

just values from data frame with calories

> merge(fr2, fr1, all.y=T)
   Fruit  Color  Shape Juice Calories
1 banana yellow oblong   0.0      100
2   pear  green   pear   0.5      100
3  mango   <NA>   <NA>    NA      200

or just values from data frame with colours

> merge(fr2, fr1, all.x=T)
   Fruit  Color  Shape Juice Calories
1  apple    red  round   1.0       NA
2 banana yellow oblong   0.0      100
3   kiwi  green  round   0.0       NA
4 orange orange  round   1.0       NA
5   pear  green   pear   0.5      100

Cheers
Petr


> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>> On Behalf Of Drake Gossi
> Sent: Thursday, April 18, 2019 1:24 AM
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] combining data.frames with is.na<http://is.na> & match (), two questions
>
> Hello everyone,
>
> I'm working through this book, *Humanities Data in R* (Arnold & Tilton), and
> I'm just having trouble understanding this maneuver.
>
> In sum, I'm trying to combine data in two different data.frames.
>
> This data.frame is called fruitNutr
>
> Fruit  Calories
> 1 banana 100
> 2 pear 100
> 3 mango 200
>
> And this data.frame is called fruitData
>
> Fruit Color Shape Juice
> 1 apple red round 1
> 2 banana yellow oblong 0
> 3 pear green pear 0.5
> 4 orange orange round 1
> 5 kiwi green round 0
>
> So, as you can see, these two data.frames overlap insofar as they both have
> banana and pear. So, what happens next is the book suggests this:
>
> fruitData$calories <- NA
>
>
> As a result, I've created a new column for the fruitData data.frame:
>
> Fruit Color Shape Juice Calories
> 1 apple red round 1            N/A
> 2 banana yellow oblong 0            N/A
> 3 pear green pear 0.5            N/A
> 4 orange orange round 1            N/A
> 5 kiwi green round 0            N/A
>
> Then:
>
> > index <- match (x=fruitData$Fruit, table=fruitNutr$Fruit) index
>   [1]    NA       1       2      NA      NA
> > is.na<http://is.na>(index)
>   [1]    TRUE   FALSE    FALSE   TRUE    TRUE
> > fruitData$Calories [!is.na<http://is.na>(index)] <- fruitNutr$Calories[index[!is.na<http://is.na>
> (index)]]
> > fruitData
>
> Fruit Color Shape Juice Calories
> 1 apple red round 1            N/A
> 2 banana yellow oblong 0 100
> 3 pear green pear 0.5 100
> 4 orange orange round 1            N/A
> 5 kiwi green round 0            N/A
>
> I get what the first part means, that first part being this:
> fruitData$Calories [!is.na<http://is.na>(index)]
> go into the fruitData data.frame, specifically into the calories column, and only
> for what's true according to is.na<http://is.na>(index). But I just literally can't understand
> this last part.  fruitNutr$Calories[index[!is.na<http://is.na>(index)]]
>
> Two questions.
>
>
>    1. I just literally don't understand how this code works. It does work,
>    of course, but I don't know what it's doing, specifically this [index[!
>    is.na<http://is.na>(index)]] part. Could someone explain it to me like I'm five? I'm
>    new at this...
>    2. And then: is there any other way to combine these two data.frames so
>    that we get this same result? maybe an easier to understand method?
>
> That same result, again, is
>
> Fruit Color Shape Juice Calories
> 1 apple red round 1            N/A
> 2 banana yellow oblong 0 100
> 3 pear green pear 0.5 100
> 4 orange orange round 1            N/A
> 5 kiwi green round 0            N/A
>
>
> Drake
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/

	[[alternative HTML version deleted]]


From petr@p|k@| @end|ng |rom prechez@@cz  Tue Apr 23 09:07:17 2019
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 23 Apr 2019 07:07:17 +0000
Subject: [R] creating a data.frame from scratch
In-Reply-To: <CAPSTy5dO_rCammVB7XA3B-D4JOdwkmFOjPHNvakAqSrLXOJPbQ@mail.gmail.com>
References: <CAPSTy5dO_rCammVB7XA3B-D4JOdwkmFOjPHNvakAqSrLXOJPbQ@mail.gmail.com>
Message-ID: <7f0da9d0356a472bb3166474ce0a0838@SRVEXCHCM1302.precheza.cz>

Hi

Structure is usefull for exchanging information and it is result of ?dput function. I wonder if anybody would like to use it for **creating** data frames.

For creating data frames see functions like

?read.table,
?read.delim,
or other ?read.* functions.

Your questions are mainly adressed in R-intro which should be part of your R installation.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Drake Gossi
> Sent: Saturday, April 20, 2019 1:40 AM
> To: r-help at r-project.org
> Subject: [R] creating a data.frame from scratch
>
> Hello everyone,
>
> Is there any way to create a data.frame from scratch? other than, say, this?
>
> > structure(list(Fruit = structure(c(1L, 2L, 5L, 4L, 3L), .Label =
> c("apple",
> "banana", "kiwi", "orange", "pear"), class = "factor"), Color = structure(c(3L, 4L,
> 1L, 2L, 1L), .Label = c("green", "orange", "red", "yellow"
> ), class = "factor"), Shape = structure(c(3L, 1L, 2L, 3L, 3L), .Label = c("oblong",
> "pear", "round"), class = "factor"), Juice = c(1, 0, 0.5, 1, 0)), class =
> "data.frame", row.names = c("1", "2", "3", "4",
> "5"))
>
>
> which yields
>
>    Fruit  Color  Shape  Juice
> 1  apple    red  round  1.0
> 2 banana yellow oblong   0.0
> 3   pear  green   pear   0.5
> 4 orange orange  round   1.0
> 5   kiwi  green  round   0.0
>
>
> I get *that* it works. I just don't know *how* it works, and whether or not
> there is another, easier way...
>
> For example,
>
> > structure(list(Fruit = structure(c(1L, 2L, 5L, 4L, 3L), .Label =
> c("apple", "banana", "kiwi", "orange", "pear") ...
>
>
> What on earth are these numbers? c(1L, 2L, 5L, 4L, 3L)? and why are they out
> of order?
>
> And then why put the fruits out of order? c("apple", "banana", "kiwi",
> "orange", "pear")? since that's not a descending order?
> since, in the final data.frame, it goes apple, banana, *pear*, *orange*, kiwi?
>
> So many questions!
>
> Drake
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From petr@p|k@| @end|ng |rom prechez@@cz  Tue Apr 23 09:11:17 2019
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 23 Apr 2019 07:11:17 +0000
Subject: [R] 
 Is it possible to calculate in r the number of days and count
 of b in var r from the following table:
In-Reply-To: <CABRiLjYoWxXoA7UkyFx5gSYE48EXY_R+Fsi9Y9i5Z2VigaZjCA@mail.gmail.com>
References: <CABRiLjZ0MjZLYTXKcLRErmAhG9DS3pZ3AKuR74CCmigGaXSfGw@mail.gmail.com>
 <CABRiLjYmD7wqNkWVqVCawvV_3C9CxoJ1841HbhDcscOndgm8Qw@mail.gmail.com>
 <CABRiLjYoWxXoA7UkyFx5gSYE48EXY_R+Fsi9Y9i5Z2VigaZjCA@mail.gmail.com>
Message-ID: <4886c4e409594041be8040a14b9f7eab@SRVEXCHCM1302.precheza.cz>

Hi

Your question is barely understandable. Maybe you wanted

?aggregate

but without further precisement it is difficult to provide definitive answer.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of ajaykumar cp
> Sent: Wednesday, April 17, 2019 4:31 PM
> To: r-help at r-project.org
> Subject: [R] Is it possible to calculate in r the number of days and count of b in
> var r from the following table:
>
> Hello
>
> Is it possible to calculate in r the number of days and count of b in var r from
> the following table:
>
>
> id r s t u
> 1 a 100 1 27-06-2017
> 1 a 200 0 29-06-2017
> 1 b 300 0 01-07-2017
> 2 a 500 1 12-06-2017
> 3 b 100 0 02-07-2017
> 3 a 600 1 02-07-2017
> 4 a 200 0 12-06-2017
> 4 a 300 1 15-06-2017
> 4 b 200 0 18-06-2017
> 4 a 100 0 01-07-2017
> 5 a 200 0 04-06-2017
>
> grouped by unique ID where the condition = when r = b, sum of s >= sum of s
> when t = 1?
>
> https://stackoverflow.com/q/55724900/11373077 for the discussions
>
> Thank you in advance
>
>
> --
> C P Ajaykumar
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From petr@p|k@| @end|ng |rom prechez@@cz  Tue Apr 23 09:22:16 2019
From: petr@p|k@| @end|ng |rom prechez@@cz (PIKAL Petr)
Date: Tue, 23 Apr 2019 07:22:16 +0000
Subject: [R] Pause script at input from terminal (interactive use)
In-Reply-To: <CAMk+s2TaC0mXOs_s2NFWsRxj0g_sxomRbaaU4N0ZoDTmSfiVtg@mail.gmail.com>
References: <CAMk+s2TaC0mXOs_s2NFWsRxj0g_sxomRbaaU4N0ZoDTmSfiVtg@mail.gmail.com>
Message-ID: <0b05d978ca984e0dbc961ee1b4b294ae@SRVEXCHCM1302.precheza.cz>

Hi

Maybe you could think about transfering **script** to **function**.

In function your construction seems to be OK.

Cheers
Petr

> -----Original Message-----
> From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
> Sent: Thursday, April 18, 2019 4:11 PM
> To: r-help <r-help at r-project.org>
> Subject: [R] Pause script at input from terminal (interactive use)
>
> Dear all,
> I am trying to write an interactive script where the user type some input from
> the terminal. I used readline() but when I launch the file with Rscript, the
> function is overwritten directly, there is no waiting for the user's input. For
> instance, this example:
>
> VAR1 = as.numeric(readline(prompt = "Enter something -> "))
> VAR2 = as.numeric(readline(prompt = "Enter something else -> "))
> if(is.na(VAR1)) VAR1 = 0
> if(is.na(VAR2)) VAR2 = "empty"
> cat("Input was: ", VAR1, " - ", VAR2, "\n")
>
> is executed till the end without typing anything on terminal :
>
> $ Rscript test.R
> Enter something ->
> Enter something else ->
> Input was:  0  -  empty
>
> I also tried with ',1' at the end of readline, but the effect is the same. I should
> use the interactive() function but I am confused on its use.
> It is possible to launch R scritps in the interactive mode in the first place? and if
> yes, how? Or would python or julia be better choices in this case?
> Thank you.
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/


From m@rong|u@|u|g| @end|ng |rom gm@||@com  Tue Apr 23 09:37:43 2019
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Tue, 23 Apr 2019 09:37:43 +0200
Subject: [R] Pause script at input from terminal (interactive use)
In-Reply-To: <0b05d978ca984e0dbc961ee1b4b294ae@SRVEXCHCM1302.precheza.cz>
References: <CAMk+s2TaC0mXOs_s2NFWsRxj0g_sxomRbaaU4N0ZoDTmSfiVtg@mail.gmail.com>
 <0b05d978ca984e0dbc961ee1b4b294ae@SRVEXCHCM1302.precheza.cz>
Message-ID: <CAMk+s2TTN6RGLJnXsB-HezxCr07OLdFmuMePbYkxUk=KmjCQRA@mail.gmail.com>

Thank you, I'll try that!

On Tue, Apr 23, 2019 at 9:22 AM PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Hi
>
> Maybe you could think about transfering **script** to **function**.
>
> In function your construction seems to be OK.
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help <r-help-bounces at r-project.org> On Behalf Of Luigi Marongiu
> > Sent: Thursday, April 18, 2019 4:11 PM
> > To: r-help <r-help at r-project.org>
> > Subject: [R] Pause script at input from terminal (interactive use)
> >
> > Dear all,
> > I am trying to write an interactive script where the user type some input from
> > the terminal. I used readline() but when I launch the file with Rscript, the
> > function is overwritten directly, there is no waiting for the user's input. For
> > instance, this example:
> >
> > VAR1 = as.numeric(readline(prompt = "Enter something -> "))
> > VAR2 = as.numeric(readline(prompt = "Enter something else -> "))
> > if(is.na(VAR1)) VAR1 = 0
> > if(is.na(VAR2)) VAR2 = "empty"
> > cat("Input was: ", VAR1, " - ", VAR2, "\n")
> >
> > is executed till the end without typing anything on terminal :
> >
> > $ Rscript test.R
> > Enter something ->
> > Enter something else ->
> > Input was:  0  -  empty
> >
> > I also tried with ',1' at the end of readline, but the effect is the same. I should
> > use the interactive() function but I am confused on its use.
> > It is possible to launch R scritps in the interactive mode in the first place? and if
> > yes, how? Or would python or julia be better choices in this case?
> > Thank you.
> > --
> > Best regards,
> > Luigi
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> Osobn? ?daje: Informace o zpracov?n? a ochran? osobn?ch ?daj? obchodn?ch partner? PRECHEZA a.s. jsou zve?ejn?ny na: https://www.precheza.cz/zasady-ochrany-osobnich-udaju/ | Information about processing and protection of business partner?s personal data are available on website: https://www.precheza.cz/en/personal-data-protection-principles/
> D?v?rnost: Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a podl?haj? tomuto pr?vn? z?vazn?mu prohl??en? o vylou?en? odpov?dnosti: https://www.precheza.cz/01-dovetek/ | This email and any documents attached to it may be confidential and are subject to the legally binding disclaimer: https://www.precheza.cz/en/01-disclaimer/
>


-- 
Best regards,
Luigi


From p_conno||y @end|ng |rom @||ng@hot@co@nz  Tue Apr 23 11:35:40 2019
From: p_conno||y @end|ng |rom @||ng@hot@co@nz (Patrick Connolly)
Date: Tue, 23 Apr 2019 21:35:40 +1200
Subject: [R] Debugging Rmarkdown
In-Reply-To: <C1CE750F-6C69-4781-9E92-1FE1E1F4B0DF@dcn.davis.ca.us>
References: <20190418095225.GA4472@slingshot.co.nz>
 <CAJuCY5y4EAw1-uSyz0JGP2D9N8b4dTgGuLwwfKn2QBzyzRRkzg@mail.gmail.com>
 <41e7a5fe-0041-e720-c839-6998cd9d65b7@slingshot.co.nz>
 <C1CE750F-6C69-4781-9E92-1FE1E1F4B0DF@dcn.davis.ca.us>
Message-ID: <20190423093540.GB4472@slingshot.co.nz>

knitr::purl -- thats a great tip!  As soon as got hold of a reqular .R
script, I spotted the reason why my Fmd file wouldn't knit in a matter
of seconds.  Thank you Jeff.  Thanks also to all the other suggestions.



On Fri, 19-Apr-2019 at 02:44PM -0700, Jeff Newmiller wrote:

|> I just run each chunk in sequence starting from an fresh restart of
|> R by copying code to the R console. However you can use knitr::purl
|> to extract all of the code into a regular R script to do whatever
|> debugging you are most familiar with.


|> On April 19, 2019 2:03:00 PM PDT, Patrick Connolly <p_connolly at slingshot.co.nz> wrote:
|> >
|> >On 19/04/19 12:13 AM, Thierry Onkelinx wrote:
|> >> Dear Patrick,
|> >>
|> >> This is not easy to debug without a reprex
|> >>
|> >> I would check the content of zzz and wide.i in the loop
|> >>
|> >> str(wide.i)
|> >> ?zzz <- rbind(zzz, wide.i)
|> >> str(zzz)
|> >>
|> >That's just what I'm trying to achieve but the debugging doesn't work 
|> >how it does with regular R code.
|> >
|> >> Note that the Rmd always runs in a clean environment. This might 
|> >> explain the difference
|> >>
|> >The data frames xx and yy are defined in earlier code chunks. Maybe I 
|> >need to define them again.
|> >
|> >
|> >I'll look closer at it after Easter.
|> >
|> >
|> >Thanks for the suggestion.
|> >
|> >> Best regards,
|> >>
|> >> ir. Thierry Onkelinx
|> >> Statisticus / Statistician
|> >>
|> >> Vlaamse Overheid / Government of Flanders
|> >> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR
|> >NATURE 
|> >> AND FOREST
|> >> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
|> >> thierry.onkelinx at inbo.be <mailto:thierry.onkelinx at inbo.be>
|> >> Havenlaan 88 bus 73, 1000 Brussel
|> >> www.inbo.be <http://www.inbo.be>
|> >>
|> >>
|> >///////////////////////////////////////////////////////////////////////////////////////////
|> >> To call in the statistician after the experiment is done may be no 
|> >> more than asking him to perform a post-mortem examination: he may be 
|> >> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
|> >> The plural of anecdote is not data. ~ Roger Brinner
|> >> The combination of some data and an aching desire for an answer does 
|> >> not ensure that a reasonable answer can be extracted from a given
|> >body 
|> >> of data. ~ John Tukey
|> >>
|> >///////////////////////////////////////////////////////////////////////////////////////////
|> >>
|> >> <https://www.inbo.be>
|> >>
|> >>
|> >> Op do 18 apr. 2019 om 11:53 schreef Patrick Connolly 
|> >> <p_connolly at slingshot.co.nz <mailto:p_connolly at slingshot.co.nz>>:
|> >>
|> >>     I have a function that works in ESS, but it fails if I include it
|> >in
|> >>     an .Rmd file that I tried to knit using Rstudio.? I found advice
|> >at:
|> >>    
|> >https://www.rstudio.com/products/rstudio/release-notes/debugging-with-rstudio/
|> >>
|> >>     It seems to be not referring to markdown files.? Somewhere else
|> >>     suggested calling render() in the console pane.? I tried that.?
|> >The
|> >>     browser() function interrupts correctly, but I can't find out
|> >what the
|> >>     object zzz in the code below looks like.? Nothing prints the way
|> >it
|> >>     would in a "normal" R buffer.
|> >>
|> >>     code outline:? making zzz out of two dataframes xx and yy
|> >>
|> >>     ##
|> >>     ? ? zzz <- NULL
|> >>     ? ? for(i in xx$Sample){
|> >>     ? ? ? ? raw.i <- <stuff>
|> >>
|> >>     ? ? ? ? etc. etc.
|> >>
|> >>     ? ? ? ? zzz <- rbind(zzz, wide.i)
|> >>     }
|> >>     ? ?browser()
|> >>
|> >>     ? ? names(zzz) <- c("Cultivar", "Test", "Change")
|> >>     That line fails, with a complaint about zzz being NULL.
|> >>
|> >>     It appears as though the rbind doesn't do anything, but I can't
|> >see
|> >>     what wide.i looks like to get an idea what could be the cause.
|> >>
|> >>     Ideas what I should try are welcome.? I have no idea why the code
|> >>     works in an R environment but not an Rmd one.
|> >>
|> >>
|> >>     R-3.5.2,
|> >>     platform? ? ? ?x86_64-pc-linux-gnu
|> >>     arch? ? ? ? ? ?x86_64
|> >>     os? ? ? ? ? ? ?linux-gnu
|> >>     system? ? ? ? ?x86_64, linux-gnu
|> >>
|> >>     Rstudio Version 1.1.383
|> >>
|> >>
|> >>
|> >>     -- 
|> >>    
|> >~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
|> >>
|> >>     ? ?___? ? Patrick Connolly
|> >>     ?{~._.~}? ? ? ? ? ? ? ? ? ?Great minds discuss ideas
|> >>     ?_( Y )_? ? ? ? ? ? ? ? ?Average minds discuss events
|> >>     (:_~*~_:)? ? ? ? ? ? ? ? ? Small minds discuss people
|> >>     ?(_)-(_)? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ..... Eleanor Roosevelt
|> >>
|> >>    
|> >~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
|> >>
|> >>     ______________________________________________
|> >>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list
|> >--
|> >>     To UNSUBSCRIBE and more, see
|> >>     https://stat.ethz.ch/mailman/listinfo/r-help
|> >>     PLEASE do read the posting guide
|> >>     http://www.R-project.org/posting-guide.html
|> >>     and provide commented, minimal, self-contained, reproducible
|> >code.
|> >>
|> >
|> >	[[alternative HTML version deleted]]
|> >
|> >______________________________________________
|> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
|> >https://stat.ethz.ch/mailman/listinfo/r-help
|> >PLEASE do read the posting guide
|> >http://www.R-project.org/posting-guide.html
|> >and provide commented, minimal, self-contained, reproducible code.
|> 
|> -- 
|> Sent from my phone. Please excuse my brevity.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From B|||@Po||ng @end|ng |rom ze||@@com  Tue Apr 23 13:16:50 2019
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Tue, 23 Apr 2019 11:16:50 +0000
Subject: [R] Help with Rmarkdown HTML Logo
In-Reply-To: <BN7PR02MB5073D00DF8FC83BBF1200E74EA220@BN7PR02MB5073.namprd02.prod.outlook.com>
References: <BN7PR02MB5073D00DF8FC83BBF1200E74EA220@BN7PR02MB5073.namprd02.prod.outlook.com>
Message-ID: <BN7PR02MB507314B5B8F464229B75F39DEA230@BN7PR02MB5073.namprd02.prod.outlook.com>

I got it to work. Yay Me!

```{r, echo=FALSE}
htmltools::img(src = knitr::image_uri(file.path("C:/WHP/Revenue Development Products/BRA AutoDistribution/Zelis.jpg")),
               alt = 'logo',
               style = 'position:absolute; top:0; left:0; padding:10px;')
```
WHP


-----Original Message-----
From: Bill Poling
Sent: Monday, April 22, 2019 10:37 AM
To: r-help (r-help at r-project.org) <r-help at r-project.org>
Cc: Bill Poling <Bill.Poling at zelis.com>
Subject: Help with Rmarkdown HTML Logo

Hello.

#RStudio Version 1.1.456
sessionInfo()
#R version 3.5.3 (2019-03-11)
#Platform: x86_64-w64-mingw32/x64 (64-bit) #Running under: Windows >= 8 x64 (build 9200)

I feel I have made great progress teaching myself RMarkdown using HTML reporting for the moment.

However, one formatting item eludes me, the Logo.

It works fine as positioned in the script below, however, it does not travel with the HTML when I distribute it.

I understand why, because it resides in the same file as the report.

Looking at various urls for this topic I find that this appears to do the trick:

https://stackoverflow.com/questions/43009788/insert-a-logo-in-upper-right-corner-of-r-markdown-html-document

My problem is how does my file path work in this example please?

#MY File Path:
C:\WHP\Revenue Development Products\BRA AutoDistribution\ Zelis.jpg


---
title: AUTO DISTRIBUTION ANALYSIS
author: DRAFT FOR DISCUSSION
date:
output:
  html_document:
  params:
    interactive: TRUE
---
<script>
   $(document).ready(function() {
     $head = $('#header');
     $head.prepend('<img src=\"Zelis.jpg\" style=\"float: left;width: 150px;\"/>')
   });
</script>

<style type="text/css">
h1.title {
  font-size: 38px;
  color: Purple;
  text-align: center;
}
h4.author { /* Header 4 - and the author and data headers use this too  */
    font-size: 18px;
  font-family: "Times New Roman", Times, serif;
  color: Purple;
  text-align: center;
</style>


Everything above is fine, I want to enhance this report by making the logo a traveler so to speak.
Of course once I get this to work below I will remove the reference to it above.


```{r, echo=FALSE}
htmltools::img(src = knitr::image_uri(file.path(R.home("doc"), "html", "Zelis.jpg")),
               alt = 'logo',
               style = 'position:absolute; top:0; left:0; padding:10px;') ```

<!---
#https://stackoverflow.com/questions/43009788/insert-a-logo-in-upper-right-corner-of-r-markdown-html-document
#http://freerangestats.info/blog/2017/09/09/rmarkdown
--->

Thank you for your assistance.

WHP




Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}


From p@u|bern@|07 @end|ng |rom gm@||@com  Tue Apr 23 14:26:45 2019
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Tue, 23 Apr 2019 07:26:45 -0500
Subject: [R] Logistic Regression with Panel Data
Message-ID: <CAMOcQfPhBQXzxxGaFumOYpeJpn_2SUXix_5YATq6-3xqBvvvdA@mail.gmail.com>

Dear friends, hope you are all doing great,

I would like to know if there is any R package that allows fitting of
logistic regression to panel data.

I installed and loaded package plm, but from what I have read so far, plm
only allows fitting of linear regression to panel data, not logistic.

Any help and/or guidance will be greatly appreciated,

Best regards,

Paul

	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @end|ng |rom me@com  Tue Apr 23 14:47:03 2019
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Tue, 23 Apr 2019 08:47:03 -0400
Subject: [R] Logistic Regression with Panel Data
In-Reply-To: <CAMOcQfPhBQXzxxGaFumOYpeJpn_2SUXix_5YATq6-3xqBvvvdA@mail.gmail.com>
References: <CAMOcQfPhBQXzxxGaFumOYpeJpn_2SUXix_5YATq6-3xqBvvvdA@mail.gmail.com>
Message-ID: <1F07A2ED-08BB-4EB2-95BE-9E57685FFF16@me.com>


> On Apr 23, 2019, at 8:26 AM, Paul Bernal <paulbernal07 at gmail.com> wrote:
> 
> Dear friends, hope you are all doing great,
> 
> I would like to know if there is any R package that allows fitting of
> logistic regression to panel data.
> 
> I installed and loaded package plm, but from what I have read so far, plm
> only allows fitting of linear regression to panel data, not logistic.
> 
> Any help and/or guidance will be greatly appreciated,
> 
> Best regards,
> 
> Paul


Hi Paul,

You might look at the pglm package on CRAN.

Since there can be multiple methodologies that are apropos in this setting, such as GEE, mixed-effects, robust covariance matrix, etc., you might want to look at the CRAN task view that covers this domain:

  https://cran.r-project.org/web/views/Econometrics.html

Regards,

Marc Schwartz


From |orenzo@|@e||@ @end|ng |rom gm@||@com  Tue Apr 23 15:10:31 2019
From: |orenzo@|@e||@ @end|ng |rom gm@||@com (Lorenzo Isella)
Date: Tue, 23 Apr 2019 15:10:31 +0200
Subject: [R] Multiple Lags with Dplyr
Message-ID: <20190423131031.dhhdfveipmvnuoqh@chicca2>

Dear All,
I refer to the excellent post at

https://purrple.cat/blog/2018/03/02/multiple-lags-with-tidy-evaluation/

What I want to do is to create a function capable, ? la dplyr, to
generate new columns which are a lagged version of existing columns in
a data frame.
For instance, you can do this manually as


d2 <- tibble(x1 =1:10, x2=10:19,  x3=50:59)


d3 <- d2%>%mutate(x1lag1=lag(x1, 1), x1lag2=lag(x1,2))


but this becomes quickly tedious when you need to take several lags of
different columns.
One solution in the link above is the following


lags <- function(var, n=10){
  var <- enquo(var)
  
  indices <- seq_len(n)
  map( indices, ~quo(lag(!!var, !!.x)) ) %>% 
    set_names(sprintf("lag_%s_%02d", quo_text(var), indices))
  
}


d4 <- d2 %>% 
  mutate( !!!lags(x1, 3), !!!lags(x2,3) )


does anybody know how this could be made more general? I mean that I
would like to take a fixed number of lags of a list of columns (x1 and
x2, for instance), just by passing the list of columns and without
repeating the commands for x1 and x2.
Any suggestion is appreciated.
Cheers

Lorenzo


From |orenzo@|@e||@ @end|ng |rom gm@||@com  Tue Apr 23 15:27:53 2019
From: |orenzo@|@e||@ @end|ng |rom gm@||@com (Lorenzo Isella)
Date: Tue, 23 Apr 2019 15:27:53 +0200
Subject: [R] Multiple Lags with Dplyr
Message-ID: <20190423132753.ragz4vsxmfviezsf@chicca2>

Dear All,
I refer to the excellent post at

https://purrple.cat/blog/2018/03/02/multiple-lags-with-tidy-evaluation/

What I want to do is to create a function capable, ? la dplyr, to
generate new columns which are a lagged version of existing columns in
a data frame.
For instance, you can do this manually as

 library(dplyr)
 library(rlang)


d2 <- tibble(x1 =1:10, x2=10:19,  x3=50:59)


d3 <- d2%>%mutate(x1lag1=lag(x1, 1), x1lag2=lag(x1,2))


but this becomes quickly tedious when you need to take several lags of
different columns.
One solution in the link above is the following


lags <- function(var, n=10){
  var <- enquo(var)
  
  indices <- seq_len(n)
  map( indices, ~quo(lag(!!var, !!.x)) ) %>% 
    set_names(sprintf("lag_%s_%02d", quo_text(var), indices))
  
}


d4 <- d2 %>% 
  mutate( !!!lags(x1, 3), !!!lags(x2,3) )


does anybody know how this could be made more general? I mean that I
would like to take a fixed number of lags of a list of columns (x1 and
x2, for instance), just by passing the list of columns and without
repeating the commands for x1 and x2.
Any suggestion is appreciated.
Cheers

Lorenzo


From ggrothend|eck @end|ng |rom gm@||@com  Tue Apr 23 16:09:59 2019
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Tue, 23 Apr 2019 10:09:59 -0400
Subject: [R] Multiple Lags with Dplyr
In-Reply-To: <20190423131031.dhhdfveipmvnuoqh@chicca2>
References: <20190423131031.dhhdfveipmvnuoqh@chicca2>
Message-ID: <CAP01uRmPY9wYMTAoissow709Z8TfdVtgrfnHBm63VKfx1cDKgg@mail.gmail.com>

lag.zoo supports vector-based lags on zoo objects.
A few caveats:

- dplyr's lag clobbers the base R lag (which you need to
invoke lag's methods) so if you have dplyr loaded be sure
to refer to stats::lag.

- dplyr's lag works backwards relative to the standard set
in base R so dplyr::lag(x, 1) corresponds to stat::lag(x, -1) in
base R

- zoo follows base R's standard

- you can use as.data.frame or fortify.zoo to convert a zoo
object to a data frame if you need that.  The first one
drops the time index and the second one includes it.

  library(zoo)
  stats::lag(zoo(d2$x1), 0:-2)

giving this zoo object:

   lag0 lag-1 lag-2
1     1    NA    NA
2     2     1    NA
3     3     2     1
4     4     3     2
5     5     4     3
6     6     5     4
7     7     6     5
8     8     7     6
9     9     8     7
10   10     9     8


On Tue, Apr 23, 2019 at 9:10 AM Lorenzo Isella <lorenzo.isella at gmail.com> wrote:
>
> Dear All,
> I refer to the excellent post at
>
> https://purrple.cat/blog/2018/03/02/multiple-lags-with-tidy-evaluation/
>
> What I want to do is to create a function capable, ? la dplyr, to
> generate new columns which are a lagged version of existing columns in
> a data frame.
> For instance, you can do this manually as
>
>
> d2 <- tibble(x1 =1:10, x2=10:19,  x3=50:59)
>
>
> d3 <- d2%>%mutate(x1lag1=lag(x1, 1), x1lag2=lag(x1,2))
>
>
> but this becomes quickly tedious when you need to take several lags of
> different columns.
> One solution in the link above is the following
>
>
> lags <- function(var, n=10){
>   var <- enquo(var)
>
>   indices <- seq_len(n)
>   map( indices, ~quo(lag(!!var, !!.x)) ) %>%
>     set_names(sprintf("lag_%s_%02d", quo_text(var), indices))
>
> }
>
>
> d4 <- d2 %>%
>   mutate( !!!lags(x1, 3), !!!lags(x2,3) )
>
>
> does anybody know how this could be made more general? I mean that I
> would like to take a fixed number of lags of a list of columns (x1 and
> x2, for instance), just by passing the list of columns and without
> repeating the commands for x1 and x2.
> Any suggestion is appreciated.
> Cheers
>
> Lorenzo
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From m@rk@c|ement@ @end|ng |rom k|@@e  Tue Apr 23 14:11:44 2019
From: m@rk@c|ement@ @end|ng |rom k|@@e (Mark Clements)
Date: Tue, 23 Apr 2019 12:11:44 +0000
Subject: [R] Vectorised uniroot function
Message-ID: <6E62DCB74E59D246B410609BB7A9D7230249A06F6B@KIMSX02.user.ki.se>

A vectorised uniroot function would be useful for function inversion,
e.g. for quantile functions and random number generation. To address
this, I have implemented rstpm2::vuniroot that adapts the C function
R_zeroin2 for Brent's method for a vectorised objective. The function
currently uses Rcpp, but could be re-implemented using the C API.

As an example, we can now rapidly sample from a proportional hazards
mixture Weibull distribution:

pweibullMixturePH <- function(q, p1, RR, shape1, shape2, scale1=1, scale2=1)
    1 - (p1*pweibull(q, shape1, scale1, lower.tail=FALSE) +
         (1-p1)*pweibull(q, shape2, scale2, lower.tail=FALSE))^RR
rfun <- function(pfun) function(n, ..., lower=1e-5, upper=1e6) {
    u <- runif(n)
    objective <- function(q) pfun(q, ...) - u
    rstpm2::vuniroot(objective, lower=rep(lower,length=n),
                     upper=rep(upper,length=n))$root
}
rweibullMixturePH <- rfun(pweibullMixturePH)
set.seed(12345)
y <- rweibullMixturePH(n=1e4,p1=0.5,RR=2,shape1=1.5,shape2=0.5)

Has anyone previously developed a similar vectorised uniroot function?
Finally, would this be a useful addition to core R?

-- Mark


N?r du skickar e-post till Karolinska Institutet (KI) inneb?r detta att KI kommer att behandla dina personuppgifter. H?r finns information om hur KI behandlar personuppgifter<https://ki.se/medarbetare/integritetsskyddspolicy>.


Sending email to Karolinska Institutet (KI) will result in KI processing your personal data. You can read more about KI?s processing of personal data here<https://ki.se/en/staff/data-protection-policy>.


From SW@y @end|ng |rom meco@com  Tue Apr 23 18:29:36 2019
From: SW@y @end|ng |rom meco@com (Shawn Way)
Date: Tue, 23 Apr 2019 16:29:36 +0000
Subject: [R] Vectorised uniroot function
In-Reply-To: <6E62DCB74E59D246B410609BB7A9D7230249A06F6B@KIMSX02.user.ki.se>
References: <6E62DCB74E59D246B410609BB7A9D7230249A06F6B@KIMSX02.user.ki.se>
Message-ID: <99739b6598d34d719d6223d90b07b043@CTC-DAL-EXMB-02.ctcloud.local>

I've had to do something similar for some of my engineering calculations.  I would welcome something like this.  It would make the language more amenable for engineering usage.

Thank you kindly!

Shawn Way, PE


-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Mark Clements
Sent: Tuesday, April 23, 2019 7:12 AM
To: r-help at r-project.org
Subject: [R] Vectorised uniroot function

** External Email **: This email originated from outside of the organization. Do not click links or open attachments unless you recognize the sender and know the content is safe.



A vectorised uniroot function would be useful for function inversion, e.g. for quantile functions and random number generation. To address this, I have implemented rstpm2::vuniroot that adapts the C function
R_zeroin2 for Brent's method for a vectorised objective. The function currently uses Rcpp, but could be re-implemented using the C API.

As an example, we can now rapidly sample from a proportional hazards mixture Weibull distribution:

pweibullMixturePH <- function(q, p1, RR, shape1, shape2, scale1=1, scale2=1)
    1 - (p1*pweibull(q, shape1, scale1, lower.tail=FALSE) +
         (1-p1)*pweibull(q, shape2, scale2, lower.tail=FALSE))^RR rfun <- function(pfun) function(n, ..., lower=1e-5, upper=1e6) {
    u <- runif(n)
    objective <- function(q) pfun(q, ...) - u
    rstpm2::vuniroot(objective, lower=rep(lower,length=n),
                     upper=rep(upper,length=n))$root } rweibullMixturePH <- rfun(pweibullMixturePH)
set.seed(12345)
y <- rweibullMixturePH(n=1e4,p1=0.5,RR=2,shape1=1.5,shape2=0.5)

Has anyone previously developed a similar vectorised uniroot function?
Finally, would this be a useful addition to core R?

-- Mark


N?r du skickar e-post till Karolinska Institutet (KI) inneb?r detta att KI kommer att behandla dina personuppgifter. H?r finns information om hur KI behandlar personuppgifter<https://ki.se/medarbetare/integritetsskyddspolicy>.


Sending email to Karolinska Institutet (KI) will result in KI processing your personal data. You can read more about KI?s processing of personal data here<https://ki.se/en/staff/data-protection-policy>.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From @purd|e@@ @end|ng |rom gm@||@com  Tue Apr 23 04:04:56 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abs Spurdle)
Date: Tue, 23 Apr 2019 14:04:56 +1200
Subject: [R] (no subject)
Message-ID: <CAB8pepz7k8r1VZfCk66HRb4h0SPYWmy62qURyNozW4DTCCvVxA@mail.gmail.com>

Note that your post has no subject line.
I can't find it in my emails, which may explain why no one else has replied.

> fo<-h~a+b*log(dbh)+c*(log(dbh))^2+1.3

I'm assuming that you want to fit a model with three parameters, a, b and c.
This would be a linear model (linear in the parameters).
I'm going to ignore the +1.3 (because you don't need two intercepts),
but you can modify the following script if you want.

> I want to compute a nlm for each plot

So, three models?

How about this:
> r1 = lm (h ~ log (dbh) + I ( (log (dbh) ) ^ 2), data=ah [ah$plot=="Sinca",])$coef
> r2 = lm (h ~ log (dbh) + I ( (log (dbh) ) ^ 2), data=ah [ah$plot=="budeni",])$coef
> r3 = lm (h ~ log (dbh) + I ( (log (dbh) ) ^ 2), data=ah [ah$plot=="Ceahlau",])$coef

> params = rbind (r1, r2, r3)
> rownames (params) = c ("Sinca", "budeni", "Ceahlau")
> colnames (params) = c ("a", "b", "c")

> params
                 a         b          c
Sinca    -13.05110  5.657927   1.606357
budeni    -2.11277  3.997636   1.104683
Ceahlau -135.57911 82.836952 -10.918932


From p@u|bern@|07 @end|ng |rom gm@||@com  Tue Apr 23 20:43:57 2019
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Tue, 23 Apr 2019 13:43:57 -0500
Subject: [R] Error in pglm function when performing logit regression on
 Panel Data
Message-ID: <CAMOcQfPsxQFqMUhAvqAkZHywYRTd21ebA5tBn3riaBdVNDqbHQ@mail.gmail.com>

Dear friends,

The following error is generated when trying to fit a logistic regression
with the pglm function:

> PGLM_Model2 <-
pglm(dataframe2$TRANSIT~dataframe2$Draft+dataframe2$TOTALCOST+dataframe2$BUNKER+dataframe2$CHARTERVALUE,
effect=c("twoways"), family=binomial('logit'), index=dataframe2$ID,
data=dataframe2)
Error in pdata.frame(data, index) :
  'index' can be of length 3 at the most (one index variable for
individual, time, group)

This doesn?t make sense to me because the maximum length for ID is 3 and I
checked it twice.

A few things to keep in mind:
1. I am using R version 3.5.3
2. My worstation has Windows 8 and it is a 64-bit OS

I would like to know what I?m doing wrong and how to solve this issue (if
possible). I provide a dput() of my dataset below:

dput(dataframe2)
structure(list(TRANSIT = c(1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 0L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L,
0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 1L, 0L,
1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L,
1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 0L,
1L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 1L,
0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L,
1L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 0L,
0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L,
0L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
0L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 1L,
1L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 0L,
1L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 0L,
0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 0L,
0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 0L,
1L, 1L, 1L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L,
1L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 1L,
0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 0L,
0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L,
1L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L,
0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L,
0L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L,
0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 0L,
0L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L,
0L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L,
1L, 1L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L), ID = c(1L, 1L, 2L, 2L, 3L, 4L, 5L, 5L,
6L, 7L, 7L, 7L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L,
17L, 18L, 19L, 20L, 21L, 21L, 22L, 23L, 24L, 24L, 25L, 26L, 27L,
28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L, 38L, 39L, 40L,
41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L, 48L, 49L, 50L, 51L, 52L,
53L, 54L, 54L, 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 63L, 64L,
65L, 66L, 67L, 67L, 68L, 69L, 70L, 71L, 72L, 73L, 74L, 75L, 76L,
77L, 78L, 79L, 80L, 81L, 82L, 83L, 84L, 85L, 86L, 87L, 88L, 89L,
90L, 91L, 92L, 93L, 93L, 94L, 95L, 96L, 97L, 98L, 99L, 100L,
101L, 102L, 103L, 104L, 105L, 106L, 107L, 108L, 108L, 109L, 110L,
111L, 112L, 113L, 114L, 115L, 115L, 115L, 115L, 116L, 117L, 118L,
119L, 120L, 121L, 122L, 123L, 124L, 125L, 126L, 127L, 128L, 128L,
129L, 130L, 131L, 132L, 133L, 134L, 135L, 136L, 137L, 138L, 139L,
139L, 140L, 140L, 141L, 142L, 143L, 144L, 145L, 145L, 146L, 146L,
147L, 148L, 149L, 149L, 150L, 150L, 150L, 151L, 152L, 153L, 154L,
155L, 156L, 157L, 158L, 159L, 160L, 161L, 162L, 163L, 164L, 165L,
166L, 167L, 168L, 169L, 170L, 171L, 172L, 173L, 174L, 175L, 176L,
177L, 178L, 179L, 180L, 181L, 182L, 182L, 183L, 184L, 185L, 186L,
187L, 188L, 189L, 190L, 191L, 192L, 192L, 193L, 193L, 194L, 195L,
196L, 197L, 198L, 199L, 199L, 200L, 201L, 202L, 203L, 204L, 205L,
206L, 207L, 208L, 208L, 209L, 210L, 211L, 212L, 213L, 214L, 215L,
216L, 217L, 218L, 218L, 219L, 220L, 221L, 222L, 222L, 223L, 224L,
225L, 226L, 227L, 228L, 229L, 230L, 231L, 232L, 233L, 234L, 235L,
236L, 237L, 238L, 239L, 240L, 241L, 241L, 241L, 242L, 243L, 244L,
245L, 246L, 247L, 247L, 248L, 248L, 249L, 249L, 250L, 251L, 252L,
253L, 254L, 255L, 256L, 257L, 258L, 259L, 260L, 261L, 262L, 263L,
264L, 265L, 266L, 267L, 268L, 269L, 270L, 271L, 272L, 273L, 273L,
274L, 275L, 276L, 277L, 278L, 279L, 280L, 281L, 282L, 283L, 284L,
285L, 286L, 287L, 288L, 288L, 289L, 290L, 291L, 292L, 293L, 294L,
295L, 296L, 297L, 298L, 299L, 300L, 301L, 301L, 302L, 303L, 304L,
305L, 306L, 307L, 308L, 308L, 309L, 309L, 309L, 310L, 311L, 312L,
313L, 313L, 314L, 315L, 316L, 317L, 318L, 319L, 320L, 321L, 322L,
323L, 324L, 325L, 326L, 327L, 327L, 328L, 329L, 330L, 331L, 332L,
333L, 334L, 335L, 336L, 337L, 338L, 339L, 340L, 341L, 342L, 343L,
344L, 345L, 346L, 347L, 348L, 349L, 350L, 351L, 352L, 353L, 354L,
354L, 354L, 354L, 355L, 356L, 357L, 358L, 359L, 360L, 361L, 362L,
363L, 364L, 365L, 366L, 367L, 368L, 369L, 370L, 371L, 372L, 373L,
374L, 375L, 376L, 377L, 378L, 379L, 380L, 381L, 382L, 383L, 384L,
385L, 386L, 387L, 388L, 389L, 390L, 391L, 392L, 393L, 394L, 395L,
396L, 397L, 398L, 399L, 400L, 401L, 402L, 402L, 403L, 404L, 405L,
406L, 407L, 408L, 409L, 410L, 411L, 412L, 413L, 413L, 414L, 415L,
416L, 417L, 418L, 419L, 420L, 421L, 422L, 423L, 424L, 425L, 426L,
427L, 428L, 429L, 430L, 431L, 432L, 433L, 434L, 434L, 435L, 436L,
437L, 438L, 439L, 440L, 441L, 442L, 443L, 444L, 445L, 446L, 447L,
448L, 449L, 450L, 451L, 452L, 453L, 454L, 455L, 456L, 457L, 458L,
459L, 460L, 461L, 462L, 463L, 464L, 464L, 465L, 465L, 466L, 467L,
467L, 468L, 468L, 469L, 470L, 471L, 472L, 473L), DATE = structure(c(210L,
30L, 172L, 75L, 100L, 98L, 255L, 214L, 282L, 175L, 312L, 219L,
340L, 327L, 305L, 265L, 360L, 181L, 75L, 80L, 86L, 311L, 284L,
362L, 287L, 240L, 24L, 141L, 351L, 168L, 231L, 350L, 108L, 253L,
368L, 320L, 352L, 375L, 272L, 318L, 61L, 111L, 136L, 87L, 101L,
313L, 186L, 375L, 128L, 250L, 132L, 91L, 243L, 121L, 304L, 199L,
15L, 200L, 284L, 85L, 353L, 79L, 371L, 110L, 2L, 78L, 52L, 287L,
319L, 244L, 247L, 262L, 83L, 62L, 336L, 207L, 331L, 42L, 304L,
104L, 206L, 333L, 360L, 260L, 37L, 233L, 55L, 116L, 296L, 124L,
7L, 285L, 254L, 112L, 281L, 19L, 315L, 60L, 209L, 370L, 225L,
252L, 328L, 325L, 201L, 140L, 223L, 67L, 70L, 137L, 120L, 267L,
146L, 238L, 31L, 77L, 134L, 314L, 42L, 16L, 299L, 195L, 216L,
338L, 220L, 104L, 278L, 21L, 129L, 234L, 29L, 242L, 153L, 293L,
164L, 149L, 98L, 311L, 119L, 32L, 64L, 160L, 172L, 167L, 334L,
298L, 122L, 169L, 374L, 344L, 26L, 79L, 298L, 337L, 129L, 178L,
180L, 306L, 109L, 23L, 248L, 329L, 224L, 266L, 237L, 264L, 46L,
108L, 267L, 123L, 321L, 22L, 246L, 124L, 290L, 358L, 302L, 179L,
250L, 305L, 156L, 276L, 213L, 332L, 103L, 363L, 312L, 346L, 82L,
236L, 71L, 174L, 43L, 219L, 14L, 349L, 235L, 297L, 103L, 72L,
283L, 293L, 310L, 270L, 133L, 215L, 274L, 223L, 353L, 303L, 68L,
284L, 279L, 294L, 267L, 123L, 349L, 198L, 133L, 339L, 169L, 309L,
77L, 138L, 298L, 345L, 73L, 5L, 200L, 58L, 12L, 293L, 348L, 224L,
370L, 182L, 2L, 258L, 193L, 307L, 316L, 152L, 345L, 18L, 275L,
83L, 59L, 295L, 155L, 144L, 359L, 135L, 202L, 172L, 274L, 271L,
88L, 38L, 91L, 303L, 210L, 114L, 265L, 349L, 251L, 315L, 217L,
25L, 207L, 56L, 127L, 306L, 214L, 40L, 28L, 316L, 323L, 148L,
184L, 9L, 245L, 314L, 162L, 84L, 239L, 321L, 218L, 187L, 194L,
146L, 280L, 377L, 81L, 357L, 377L, 117L, 139L, 265L, 274L, 330L,
204L, 196L, 128L, 343L, 128L, 337L, 335L, 257L, 203L, 317L, 356L,
89L, 256L, 370L, 65L, 200L, 260L, 322L, 289L, 94L, 301L, 309L,
150L, 202L, 161L, 365L, 63L, 111L, 309L, 76L, 274L, 158L, 273L,
377L, 85L, 64L, 285L, 47L, 279L, 16L, 27L, 131L, 132L, 106L,
230L, 99L, 4L, 324L, 53L, 263L, 36L, 43L, 3L, 253L, 188L, 373L,
373L, 295L, 191L, 220L, 362L, 41L, 93L, 293L, 362L, 145L, 265L,
317L, 49L, 1L, 247L, 327L, 285L, 277L, 190L, 13L, 341L, 71L,
205L, 130L, 342L, 300L, 281L, 291L, 232L, 229L, 214L, 147L, 267L,
57L, 208L, 157L, 245L, 60L, 113L, 237L, 293L, 161L, 268L, 211L,
170L, 241L, 306L, 107L, 254L, 334L, 87L, 61L, 70L, 54L, 337L,
327L, 11L, 122L, 246L, 361L, 159L, 187L, 326L, 305L, 51L, 179L,
264L, 177L, 223L, 249L, 154L, 250L, 309L, 324L, 165L, 115L, 166L,
39L, 250L, 183L, 95L, 308L, 90L, 176L, 372L, 173L, 292L, 262L,
163L, 355L, 35L, 151L, 226L, 185L, 189L, 180L, 102L, 118L, 127L,
366L, 136L, 33L, 77L, 113L, 221L, 323L, 96L, 5L, 140L, 105L,
10L, 2L, 192L, 85L, 288L, 54L, 303L, 48L, 364L, 69L, 269L, 286L,
261L, 228L, 143L, 347L, 50L, 145L, 61L, 369L, 354L, 66L, 142L,
112L, 126L, 280L, 92L, 97L, 20L, 367L, 211L, 187L, 212L, 3L,
70L, 44L, 13L, 17L, 67L, 46L, 227L, 317L, 283L, 45L, 253L, 74L,
256L, 171L, 376L, 34L, 222L, 8L, 17L, 31L, 94L, 46L, 197L, 6L,
103L, 259L, 125L), .Label = c("April 10, 2018", "April 11, 2018",
"April 16, 2018", "April 17, 2018", "April 18, 2018", "April 19, 2018",
"April 21, 2018", "April 22, 2018", "April 23 2018", "April 25, 2018",
"April 26, 2018", "April 27, 2018", "April 3, 2018", "April 30, 2018",
"April 5 2018", "April 7, 2018", "April 8, 2018", "April 9, 2018",
"August 1, 2017", "August 1, 2018", "August 10, 2017", "August 11, 2017",
"August 11, 2018", "August 12, 2017", "August 13, 2018", "August 14 2017",
"August 15 2017", "August 17, 2018", "August 18, 2018", "August 19, 2018",
"August 2, 2018", "August 20, 2017", "August 21, 2017", "August 22, 2017",
"August 23, 2017", "August 23, 2018", "August 24 2017", "August 24, 2018",
"August 25 2017", "August 25, 2018", "August 26 2017", "August 26, 2018",
"August 27, 2017", "August 27, 2018", "August 28, 2017", "August 29, 2018",
"August 3, 2017", "August 30 2017", "August 30, 2018", "August 31, 2017",
"August 5, 2017", "August 6 2017", "August 6, 2017", "August 7 2017",
"August 7, 2017", "August 8 2017", "August 8, 2018", "August 9, 2017",
"August 9, 2018", "December 1 2017", "December 10 2017", "December 10,
2017",
"December 11 2017", "December 11, 2017", "December 12 2017",
"December 12, 2017", "December 13 2017", "December 13, 2017",
"December 14 2017", "December 15 2017", "December 15, 2017",
"December 16, 2017", "December 18 2017", "December 18, 2017",
"December 19 2017", "December 20, 2017", "December 21 2017",
"December 21, 2017", "December 22 2017", "December 23, 2017",
"December 24 2017", "December 24, 2017", "December 27 2017",
"December 27, 2017", "December 28 2017", "December 28, 2017",
"December 29 2017", "December 29, 2017", "December 3 2017", "December 3,
2017",
"December 30 2017", "December 31, 2017", "December 4 2017", "December 4,
2017",
"December 5 2017", "December 5, 2017", "December 6 2017", "December 8,
2017",
"February 1 2018", "February 1, 2018", "February 10 2018", "February 10,
2018",
"February 11, 2018", "February 12 2018", "February 13 2018",
"February 15 2018", "February 15, 2018", "February 16 2018",
"February 17, 2018", "February 18, 2018", "February 19 2018",
"February 20 2018", "February 20, 2018", "February 21, 2018",
"February 22, 2018", "February 23, 2018", "February 25 2018",
"February 28 2018", "February 28, 2018", "February 3 2018", "February 4
2017",
"February 4, 2018", "February 5 2018", "February 5, 2018", "February 7,
2018",
"February 8 2018", "February 9, 2018", "January 1 2018", "January 1, 2018",
"January 10 2018", "January 11 2018", "January 13 2018", "January 14 2018",
"January 15 2018", "January 17, 2018", "January 19, 2018", "January 20
2018",
"January 21, 2018", "January 23 2018", "January 24 2018", "January 24,
2018",
"January 26 2018", "January 26, 2018", "January 29 2018", "January 29,
2018",
"January 3 2018", "January 3, 2018", "January 30 2018", "January 30, 2018",
"January 31 2018", "January 31, 2018", "January 4 2018", "January 4, 2018",
"January 5, 2018", "January 6 2018", "January 7 2018", "January 7, 2018",
"January 8 2018", "January 9 2018", "July 1, 2017", "July 10, 2017",
"July 10, 2018", "July 12, 2017", "July 12, 2018", "July 13 2018",
"July 15, 2018", "July 17, 2017", "July 17, 2018", "July 18, 2017",
"July 18, 2018", "July 19, 2017", "July 20, 2017", "July 20, 2018",
"July 22, 2017", "July 23, 2017", "July 24, 2017", "July 25, 2017",
"July 26, 2017", "July 26, 2018", "July 27, 2018", "July 28, 2017",
"July 29, 2017", "July 29, 2018", "July 3, 2017", "July 30 2017",
"July 30, 2017", "July 31, 2017", "July 31, 2018", "July 5, 2017",
"July 7, 2017", "July 7, 2018", "June 11, 2018", "June 14, 2018",
"June 17 2018", "June 17, 2018", "June 18, 2018", "June 2, 2018",
"June 20, 2018", "June 28, 2018", "June 29, 2018", "June 30, 2018",
"June 6, 2018", "June 8 2018", "March 1, 2018", "March 10 2018",
"March 10, 2018", "March 11, 2018", "March 12, 2018", "March 13 2018",
"March 15, 2018", "March 17, 2018", "March 18 2018", "March 18, 2018",
"March 21, 2018", "March 22 2018", "March 24 2018", "March 26, 2018",
"March 28 2018", "March 28, 2018", "March 29, 2018", "March 3 2018",
"March 30, 2018", "March 4, 2018", "March 5, 2018", "March 6, 2018",
"March 8, 2018", "March 9, 2018", "May 10, 2018", "May 12, 2018",
"May 15, 2018", "May 17, 2018", "May 18, 2018", "May 19, 2018",
"May 2, 2018", "May 22, 2018", "May 24, 2018", "May 25, 2018",
"May 26, 2018", "May 28, 2018", "May 3, 2018", "May 30, 2018",
"May 31, 2018", "May 5, 2018", "May 8, 2018", "November 1 2017",
"November 1, 2017", "November 10 2017", "November 10, 2017",
"November 11 2017", "November 12 2017", "November 13 2017", "November 13,
2017",
"November 15 2017", "November 17 2017", "November 17, 2017",
"November 18 2017", "November 19 2017", "November 21 2017", "November 21,
2017",
"November 22 2017", "November 22, 2017", "November 23 2017",
"November 23, 2017", "November 24, 2017", "November 25 2017",
"November 25, 2017", "November 27 2017", "November 27, 2017",
"November 28 2017", "November 28, 2017", "November 29, 2017",
"November 3 2017", "November 3, 2017", "November 4 2017", "November 4,
2017",
"November 5 2017", "November 5, 2017", "November 6 2017", "November 6,
2017",
"November 7 2017", "November 8 2017", "November 8, 2017", "November 9
2017",
"November 9, 2017", "October 1 2017", "October 1, 2017", "October 10 2017",
"October 10, 2017", "October 11 2017", "October 12 2017", "October 12,
2017",
"October 13, 2017", "October 14 2017", "October 15 2017", "October 16
2017",
"October 17 2017", "October 17, 2017", "October 18 2017", "October 19
2017",
"October 2, 2017", "October 20 2017", "October 20, 2017", "October 21
2017",
"October 21, 2017", "October 23 2017", "October 24, 2017", "October 25
2017",
"October 25, 2017", "October 26 2017", "October 27 2017", "October 28
2017",
"October 28, 2017", "October 29 2017", "October 29, 2017", "October 3
2017",
"October 30 2017", "October 31 2017", "October 31, 2017", "October 4 2017",
"October 4, 2017", "October 5 2017", "October 6 2017", "October 7 2017",
"October 9 2017", "October 9, 2017", "September 1 2017", "September 1,
2017",
"September 10 2017", "September 10, 2017", "September 11 2017",
"September 11, 2017", "September 11, 2018", "September 12 2017",
"September 12, 2018", "September 13 2017", "September 14, 2017",
"September 15 2017", "September 15, 2018", "September 16 2017",
"September 16, 2018", "September 17 2017", "September 18, 2017",
"September 19 2017", "September 19, 2017", "September 2, 2017",
"September 2, 2018", "September 20, 2018", "September 21 2017",
"September 21, 2017", "September 21, 2018", "September 22 2017",
"September 23, 2018", "September 24 2017", "September 25, 2017",
"September 25, 2018", "September 26 2017", "September 27 2017",
"September 27, 2018", "September 28, 2017", "September 29 2017",
"September 29, 2017", "September 3 2017", "September 3, 2017",
"September 3, 2018", "September 30 2017", "September 30, 2018",
"September 4, 2018", "September 5 2017", "September 5, 2017",
"September 6 2017", "September 6, 2017", "September 6, 2018",
"September 7 2017", "September 7, 2017", "September 8 2017",
"September 8, 2018", "September 9 2017"), class = "factor"),
    IMO = c(9146950L, 9146950L, 9149366L, 9149366L, 9174634L,
    9180918L, 9185798L, 9185798L, 9187447L, 9187708L, 9187708L,
    9187708L, 9187708L, 9205835L, 9207778L, 9209532L, 9215543L,
    9216212L, 9221607L, 9221621L, 9222479L, 9224697L, 9224714L,
    9225201L, 9231274L, 9244908L, 9245196L, 9245196L, 9248904L,
    9249908L, 9251327L, 9251327L, 9254563L, 9254707L, 9254719L,
    9267431L, 9268980L, 9279537L, 9280770L, 9284300L, 9284867L,
    9284879L, 9285017L, 9285562L, 9286865L, 9286932L, 9286968L,
    9288459L, 9288473L, 9288514L, 9288538L, 9290696L, 9290854L,
    9291092L, 9291119L, 9291406L, 9291406L, 9291432L, 9294496L,
    9296626L, 9301055L, 9302774L, 9303039L, 9303039L, 9303510L,
    9304239L, 9305087L, 9309485L, 9310276L, 9311165L, 9313307L,
    9316048L, 9316854L, 9316880L, 9317157L, 9317353L, 9317365L,
    9317365L, 9317377L, 9317456L, 9317547L, 9318357L, 9323053L,
    9328936L, 9328948L, 9330329L, 9330654L, 9330812L, 9330898L,
    9331907L, 9331919L, 9335989L, 9336036L, 9336581L, 9336610L,
    9336866L, 9336878L, 9336880L, 9342815L, 9342918L, 9343522L,
    9349320L, 9350343L, 9351737L, 9351737L, 9354844L, 9354856L,
    9362229L, 9363649L, 9364447L, 9364758L, 9370185L, 9370771L,
    9375939L, 9376361L, 9376373L, 9381213L, 9382683L, 9382695L,
    9384930L, 9384930L, 9389239L, 9392432L, 9395226L, 9397834L,
    9398656L, 9401506L, 9402017L, 9402017L, 9402017L, 9402017L,
    9403073L, 9407495L, 9418456L, 9420265L, 9420291L, 9421439L,
    9423360L, 9423499L, 9425801L, 9425930L, 9426245L, 9426336L,
    9433559L, 9433559L, 9433626L, 9440928L, 9440980L, 9441300L,
    9442225L, 9442378L, 9442380L, 9442471L, 9442926L, 9443126L,
    9452907L, 9452907L, 9452919L, 9452919L, 9453494L, 9456379L,
    9460332L, 9460514L, 9460526L, 9460526L, 9460605L, 9460605L,
    9461087L, 9461099L, 9461192L, 9461192L, 9461233L, 9461233L,
    9461233L, 9461324L, 9462445L, 9465150L, 9467859L, 9469510L,
    9473121L, 9473171L, 9474711L, 9475040L, 9476288L, 9478561L,
    9478585L, 9478597L, 9478779L, 9478884L, 9480930L, 9480966L,
    9482122L, 9482134L, 9483231L, 9483243L, 9483451L, 9488566L,
    9492397L, 9493535L, 9493688L, 9494084L, 9494096L, 9494383L,
    9494474L, 9497062L, 9497402L, 9497402L, 9499462L, 9500273L,
    9500302L, 9500584L, 9500675L, 9500699L, 9502611L, 9502623L,
    9502647L, 9503990L, 9503990L, 9505352L, 9505352L, 9507776L,
    9510333L, 9510345L, 9511014L, 9512343L, 9512355L, 9512355L,
    9514066L, 9514121L, 9514339L, 9515046L, 9518086L, 9518098L,
    9518115L, 9518165L, 9520651L, 9520651L, 9520778L, 9520962L,
    9523158L, 9527233L, 9527283L, 9533323L, 9538945L, 9541837L,
    9542489L, 9544059L, 9544059L, 9544102L, 9545285L, 9552953L,
    9552965L, 9552965L, 9552989L, 9552991L, 9553232L, 9558153L,
    9561942L, 9563615L, 9563627L, 9566473L, 9566849L, 9567180L,
    9569229L, 9569750L, 9574406L, 9575137L, 9578294L, 9580209L,
    9582465L, 9583017L, 9583108L, 9583108L, 9583108L, 9583122L,
    9583196L, 9583201L, 9583225L, 9583550L, 9584592L, 9584592L,
    9584889L, 9584889L, 9584906L, 9584906L, 9585730L, 9586356L,
    9589164L, 9589267L, 9591507L, 9591519L, 9591806L, 9591832L,
    9591997L, 9592006L, 9592056L, 9592070L, 9592094L, 9592707L,
    9592719L, 9593311L, 9593347L, 9593402L, 9595711L, 9596090L,
    9597020L, 9597032L, 9597109L, 9597202L, 9597202L, 9597343L,
    9597381L, 9597800L, 9598189L, 9598220L, 9598725L, 9600633L,
    9600657L, 9601912L, 9602992L, 9603154L, 9603300L, 9603972L,
    9604964L, 9605645L, 9605645L, 9607112L, 9607162L, 9609146L,
    9609158L, 9609433L, 9609500L, 9609512L, 9611254L, 9611709L,
    9611802L, 9613056L, 9615731L, 9615767L, 9615767L, 9616905L,
    9619775L, 9619804L, 9619854L, 9619878L, 9622552L, 9622667L,
    9622667L, 9622801L, 9622801L, 9622801L, 9622825L, 9622849L,
    9623556L, 9623702L, 9623702L, 9623738L, 9623752L, 9623764L,
    9624639L, 9626651L, 9626687L, 9628893L, 9630248L, 9630664L,
    9633252L, 9633408L, 9633410L, 9634438L, 9634830L, 9634830L,
    9636448L, 9636917L, 9638472L, 9638824L, 9640621L, 9640671L,
    9642136L, 9643154L, 9646649L, 9647277L, 9650157L, 9650860L,
    9650937L, 9652583L, 9658941L, 9658977L, 9663623L, 9667095L,
    9667899L, 9668051L, 9668908L, 9670810L, 9673202L, 9675767L,
    9676084L, 9677387L, 9679282L, 9679282L, 9679282L, 9679282L,
    9682837L, 9684213L, 9685621L, 9686273L, 9687758L, 9687837L,
    9687849L, 9687851L, 9689835L, 9689847L, 9691395L, 9691412L,
    9691618L, 9693197L, 9693214L, 9693408L, 9696785L, 9698850L,
    9698862L, 9699323L, 9699335L, 9699373L, 9699842L, 9702522L,
    9705354L, 9705366L, 9706530L, 9706542L, 9706554L, 9706566L,
    9708942L, 9708954L, 9710555L, 9710593L, 9712199L, 9712486L,
    9712515L, 9712943L, 9713480L, 9715828L, 9715854L, 9720304L,
    9720926L, 9722003L, 9722015L, 9722041L, 9722338L, 9723631L,
    9723631L, 9724178L, 9725744L, 9726047L, 9726528L, 9727144L,
    9727297L, 9727405L, 9729348L, 9729879L, 9730270L, 9731834L,
    9731834L, 9731896L, 9732424L, 9734721L, 9734733L, 9735098L,
    9735127L, 9735799L, 9736341L, 9737357L, 9737589L, 9737618L,
    9738026L, 9738466L, 9738789L, 9739020L, 9740067L, 9740110L,
    9743590L, 9746798L, 9747405L, 9747467L, 9747467L, 9748033L,
    9748473L, 9748837L, 9749910L, 9750309L, 9752383L, 9755804L,
    9757785L, 9758131L, 9758404L, 9758765L, 9763980L, 9764001L,
    9764051L, 9765718L, 9767065L, 9767479L, 9767558L, 9767572L,
    9771092L, 9774288L, 9774460L, 9775177L, 9781023L, 9781035L,
    9781956L, 9782209L, 9782948L, 9783136L, 9789805L, 9789805L,
    9792424L, 9792424L, 9797694L, 9799733L, 9799733L, 9799745L,
    9799745L, 9799769L, 9811490L, 9811878L, 9812482L, 9817561L
    ), SHIPNAME = structure(c(295L, 295L, 151L, 151L, 19L, 41L,
    292L, 292L, 201L, 148L, 148L, 148L, 148L, 413L, 39L, 74L,
    460L, 54L, 462L, 8L, 22L, 347L, 307L, 354L, 311L, 296L, 297L,
    297L, 118L, 279L, 230L, 230L, 340L, 358L, 473L, 271L, 309L,
    451L, 40L, 404L, 120L, 127L, 209L, 90L, 274L, 260L, 252L,
    344L, 165L, 363L, 356L, 425L, 192L, 133L, 56L, 440L, 439L,
    276L, 361L, 333L, 273L, 308L, 235L, 235L, 426L, 234L, 93L,
    111L, 325L, 283L, 107L, 48L, 101L, 212L, 246L, 400L, 338L,
    338L, 422L, 20L, 369L, 471L, 7L, 409L, 412L, 310L, 70L, 157L,
    357L, 103L, 452L, 49L, 349L, 4L, 226L, 465L, 362L, 128L,
    264L, 136L, 50L, 18L, 323L, 11L, 11L, 25L, 408L, 302L, 180L,
    394L, 113L, 434L, 477L, 461L, 305L, 174L, 104L, 152L, 132L,
    291L, 410L, 250L, 382L, 351L, 23L, 119L, 284L, 480L, 480L,
    480L, 480L, 457L, 272L, 262L, 81L, 346L, 239L, 58L, 149L,
    402L, 373L, 82L, 251L, 244L, 244L, 135L, 24L, 345L, 156L,
    227L, 324L, 215L, 222L, 286L, 55L, 281L, 281L, 280L, 280L,
    322L, 393L, 243L, 34L, 418L, 418L, 334L, 334L, 221L, 220L,
    6L, 6L, 479L, 479L, 479L, 166L, 196L, 298L, 71L, 160L, 282L,
    213L, 147L, 315L, 433L, 458L, 207L, 208L, 186L, 91L, 326L,
    466L, 421L, 420L, 98L, 399L, 289L, 134L, 123L, 194L, 173L,
    248L, 64L, 202L, 206L, 95L, 396L, 396L, 131L, 211L, 391L,
    38L, 84L, 455L, 144L, 168L, 389L, 398L, 398L, 35L, 35L, 367L,
    359L, 360L, 105L, 73L, 431L, 430L, 372L, 62L, 312L, 470L,
    263L, 86L, 275L, 219L, 414L, 96L, 125L, 365L, 478L, 342L,
    45L, 241L, 75L, 121L, 355L, 380L, 379L, 216L, 191L, 417L,
    395L, 395L, 31L, 210L, 467L, 146L, 397L, 179L, 181L, 29L,
    171L, 482L, 240L, 288L, 330L, 368L, 287L, 401L, 321L, 217L,
    233L, 233L, 233L, 366L, 247L, 89L, 472L, 336L, 364L, 364L,
    124L, 124L, 163L, 163L, 5L, 37L, 237L, 332L, 183L, 184L,
    444L, 442L, 339L, 126L, 293L, 232L, 150L, 203L, 53L, 475L,
    468L, 327L, 172L, 481L, 61L, 424L, 2L, 28L, 28L, 224L, 304L,
    423L, 66L, 384L, 335L, 387L, 42L, 195L, 200L, 383L, 114L,
    443L, 301L, 68L, 67L, 72L, 214L, 386L, 352L, 381L, 65L, 218L,
    266L, 102L, 51L, 178L, 30L, 137L, 137L, 175L, 161L, 1L, 448L,
    446L, 3L, 190L, 189L, 278L, 278L, 278L, 299L, 116L, 143L,
    44L, 43L, 130L, 285L, 328L, 170L, 185L, 87L, 140L, 437L,
    145L, 245L, 155L, 261L, 258L, 331L, 85L, 16L, 257L, 204L,
    13L, 154L, 459L, 117L, 94L, 320L, 225L, 314L, 259L, 14L,
    456L, 162L, 142L, 26L, 303L, 432L, 231L, 435L, 392L, 313L,
    370L, 474L, 464L, 450L, 450L, 450L, 450L, 438L, 182L, 236L,
    92L, 164L, 79L, 80L, 77L, 169L, 177L, 153L, 176L, 329L, 353L,
    341L, 454L, 69L, 238L, 242L, 269L, 268L, 267L, 115L, 108L,
    199L, 52L, 27L, 59L, 198L, 197L, 253L, 436L, 306L, 106L,
    447L, 378L, 316L, 318L, 99L, 407L, 411L, 36L, 453L, 167L,
    63L, 158L, 188L, 377L, 376L, 32L, 193L, 463L, 129L, 429L,
    9L, 17L, 449L, 21L, 76L, 78L, 78L, 319L, 33L, 390L, 388L,
    343L, 406L, 159L, 270L, 223L, 337L, 88L, 141L, 469L, 100L,
    441L, 300L, 290L, 445L, 46L, 415L, 294L, 294L, 110L, 12L,
    229L, 97L, 138L, 263L, 249L, 265L, 385L, 405L, 47L, 205L,
    350L, 416L, 348L, 476L, 254L, 57L, 15L, 427L, 255L, 428L,
    122L, 109L, 60L, 403L, 256L, 10L, 371L, 112L, 112L, 419L,
    419L, 83L, 317L, 317L, 277L, 277L, 187L, 228L, 375L, 374L,
    139L), .Label = c("Aby Jeannette", "Adelante", "ADM Georgina",
    "ADS Galtesund", "Aeneas", "Aeolian Fortune", "Aeolian Light",
    "AFRICA GRAECA", "AFRICAN ARROW", "AFRICAN BARI BIRD", "AFRICAN BLUE
CRANE",
    "AFRICAN FINFOOT", "AFRICAN JACANA", "AFRICAN KITE", "AFRICAN LEOPARD",
    "AFRICAN PUFFIN", "AFRICAN RAPTOR", "AFTERHOURS", "AGIA SKEPI",
    "Agri Kinsale", "Aiantas", "AKILI", "ALAM MANIS", "ALBION",
    "Alexandra", "ALICIA", "Alma", "Alpha Vision", "AM BREMEN",
    "AMAMI K", "AMIS ACE", "AMIS FORTUNE", "AMIS JUSTICE", "AMSTEL FALCON",
    "Andros", "ANDROS ISLAND", "Androusa", "ANIMA", "Anna S",
    "Anna Smile", "ANTIGONI", "Antiparos", "Aom Gaia", "AOM GAIA",
    "Aom Milena", "APEX", "AREQUIPA QUEEN", "Ariana", "Artemis",
    "ASHIYA STAR", "ASTRA CENTAURUS", "ASTREA", "Athina Carras",
    "ATLANTIC EAGLE", "ATLANTIC GRACE", "ATLANTIC HERO", "ATLANTIC
MANZANILLO",
    "Attalia", "Axios", "Bahia Blanca", "Bali", "BALTIC K", "BALTIC WASP",
    "BBG Ambition", "BBG Dream", "BBG Endeavor", "Belo Horizonte",
    "BELO HORIZONTE", "BLUE AKIHABARA", "BLUE DIAMOND", "BLUE MARLIN I",
    "Bora", "Brasil SW", "Braveheart", "BRIDGEGATE", "BRIGITTE",
    "BTG Denali", "BTG Eiger", "BTG Everest", "BTG Kailach",
    "BULK ARGENTINA", "BULK COLOMBIA", "BULK HERO", "BULK HONDURAS",
    "Bulk Pegasus", "Bulk Portugal", "BW Hazel", "Captain Adams",
    "Captain Antonis", "Cemtex Wisdom", "CENTENARIO BLU", "Cepheus Ocean",
    "Cerafina", "Cetus Ocean", "CF Diamond", "CHARADE", "CHLOE",
    "CLARKE QUAY", "CLIPPER AMSTERDAM", "Clipper Victory", "CMB Sakura",
    "Cofco 1", "COLUMBIA RIVER", "Coral Diamond", "COREFORTUNE OL",
    "Cosmar", "Coventry", "CP GUANGZHOU", "Crimson Ark", "Crimson Kingdom",
    "Cymona Star", "DALIAN STAR", "De Xu Hai", "Densa Pelican",
    "DESERT CHALLENGER", "DEVON BAY", "DIAMOND QUEEN", "Dias",
    "Dimitris Apesakis", "Donousa", "DORIC", "DORIC SHOGUN",
    "DORO", "EASTER N", "Efrain A", "Egret Oasis", "Eirini P",
    "Elena", "Emerald Dongji", "Emerald Star", "ENDLESS HORIZON",
    "ENY", "Erikoussa", "ESSEX STRAIT", "Eternal Bliss", "Eternal Grace",
    "EUROPA BAY", "Ever Grace", "EVER SOVEREIGN", "Everglory",
    "Evmar", "FEDERAL TRIDENT", "FH Fang Cheng", "FH Rizhao",
    "Fiji", "FILIA JOY", "Flag Lama", "FLIPPER", "FLORINDA",
    "Fortune Harmony", "FORTUNE LADY", "FORTUNE UNITY", "FRAMURA",
    "FURNESS VICTORIA", "Galio", "GANNET BULKER", "GENCO RAPTOR",
    "GH CITATION", "GH URBAN SEA", "Giorgakis", "Giorgis", "GLOBAL PRIME",
    "GLOBAL SUCCESS", "GLOBAL VISION", "Glory", "Golden Jake",
    "GOLDEN LIBRA", "Good Wish", "Graecia Aeterna", "GRAND CONCORD",
    "GRAND MARCIA", "Great Rich", "GUARDIANSHIP", "Hampton Bay",
    "Hampton Bridge", "HANTON TRADER I", "Hercules Ocean", "Hermes",
    "Hong Hing", "Hong Jing", "Hong Sheng", "HOPA I", "Huayang Spirit",
    "Huayeng Dream", "Indian Harmony", "INDIGO EVOLUTION", "INDIGO RIVER",
    "INDRA OLDENDORFF", "Innovation", "INNOVATION", "Inspiration",
    "IRIS HALO", "IRIS OLDENDORFF", "ISMENE", "Istria", "IYO WIND",
    "Jag Aalok", "Jag Akshay", "Jag Arnav", "JIA SHENG SHAN",
    "JIN RUN", "Jin Zhu Hai", "John M. Carras", "JOSCO HANGZHOU",
    "JPS AFRODITI", "K SPINEL", "K. GARNET", "K. OPAL", "KANG CHENG",
    "Karlovasi", "Katerina III", "KAVO PALOMA", "Kea", "Kerkyra",
    "Key Evolution", "Key Pacifico", "KING ISLAND", "KING MILO",
    "KM Fukuyama", "KM Hong Kong", "KM Keelung", "KM Yokohama",
    "KMARIN SINGAPORE", "KT Birdie", "KYRA PANAGHIA", "Lady I",
    "LEO ADVANCE", "LESEDI QUEEN", "LILA", "LISSA TOPIC", "LOCH SHUNA",
    "Long Dar", "LOUISIANA MAMA", "LOWLANDS MAINE", "LUMINOUS HALO",
    "LUNITA", "LYRIC HARMONY", "Macheras", "MALMO", "MANDARIN CROWN",
    "MANDARIN NOBLE", "Marathassa", "MARIE GRACE", "MARINER",
    "MARITIME PROSPERITY", "MARY LINA", "Mastro Nikos", "MBA Future",
    "Medi Matsuura", "MEDI SALERNO", "MELBOURNE", "MELIA", "METSOVO",
    "MG Explorer", "MG Kronos", "MG Sakura", "Miao Xiang", "MISATO K",
    "Mistral I", "Miyama", "Mykonos", "Myra", "Myrto", "N Bonanza",
    "Nadeshiko", "Naias", "NAUTICAL MARIE", "NAUTICAL RUNA",
    "NAUTICAL SIF", "Navios Amber", "NAVIOS ARC", "NAVIOS ARMONIA",
    "Navios Harmony", "Navios Orbiter", "NAVIOS SOUTHERN STAR",
    "NEFELI", "NEW BLISS", "NEW DIRECTION", "NEWSEAS PEARL",
    "NIKKEI SIRIUS", "NIKKEI VERDE", "Nikolaos", "NIKOLAS XL",
    "Nikomarin", "Nord Capella", "Nord Fortune", "NOSHIMA", "Nuri Bey",
    "OCCITAN PAUILLAC", "OCEAN BAO", "OCEAN BELT", "OCEAN FAVOUR",
    "Ocean Garlic", "OCEAN HARVEST", "OCEAN PRIDE", "OCEAN PRINCE",
    "OCEAN PRINCESS", "OCEAN ROYAL", "OCEAN SPLENDOR", "OCEAN TIANBAO",
    "OCEAN VENUS", "Ocean Wind", "Oceana", "Odysseas L", "OKINAWA",
    "Olivia R", "OLYMPOS", "Omicron Light", "OMICRON NIKOS",
    "OMICRON SKY", "Omicron Trader", "ORCHID HALO", "Orient Genesis",
    "ORIENT GRACE", "OZGUR AKSOY", "PACIFIC ADVANCE", "PACIFIC NEXUS",
    "PACIFIC TALENT", "PACIFIC VICTORY", "Palais", "Pan Ceres",
    "PAN VIVA", "Panafrican", "Panamanian", "Panasiatic", "PANORIA",
    "Panther Max", "PARADISE ISLAND", "PAUL OLDENDORFF", "Peace Ark",
    "PEAK PEGASUS", "Pedhoulas Farmer", "Pedhoulas Trader", "PENTA",
    "PERIDOT", "PERTH I", "Phaedra", "PHOENIX K", "Phoenix Ocean",
    "Pictor", "PILATUS VENTURE", "Popi S", "PORT ESTRELA", "Proteas",
    "QUEEN JHANSI", "QUEEN KOBE", "Rave", "RB Eden", "Real Happiness",
    "RECCO", "REGAL", "RESURGENCE", "RIGI VENTURE", "Rosalia D? Amato",
    "Rosco Banyan", "Rosco Cypress", "Rosco Ginkgo", "Rosco Lemon",
    "Rosco Litchi", "Rosco Palm", "ROSCO PLUM", "Rosco Poplar",
    "Rosco Sandalwood", "RR Australia", "SAGAR JYOTI", "SAGAR SHAKTI",
    "SAGARJEET", "SAGE COLORADO", "SAGE PIONEER", "SAILING SKY",
    "Sakizaya Power", "SAN ANTONIO", "SANTA KATARINA", "SANTA VALENTINA",
    "SANYU", "SBI Bolero", "SBI BOLERO", "SBI Samba", "Scarlet Cardinal",
    "SCARLET CARDINAL", "Scarlet Falcon", "Sea Duty", "Sea Hermes",
    "Sea Pegasus", "SEA PIONEER", "Sea Pluto", "Seatribute",
    "Shandong Fu Hui", "Shandong Hai Chang", "Shangdong Fu Ze",
    "Shao Shan 5", "Shao Shan 8", "SIFNOS", "Silver Dragon",
    "SIMURGH", "Skiathos", "SKY KNIGHT", "SONGA GLORY", "SOUTHEND",
    "SPARNA", "SPRING AEOLIAN", "SPRING EAGLE", "SPRING ZEPHYR",
    "SSI CHALLENGER", "Stalo", "STAMFORD EAGLE", "STAR AQUARIUS",
    "STAR JENNIFER", "Star Laura", "Star of Sawara", "STAR PISCES",
    "Star Renee", "STAR VANESSA", "STARRY SKY", "STH LONDON",
    "STOVE FRIEND", "STOVE OCEAN", "SUNLEAF GRACE", "SUNLEAF STAR",
    "SUNNY HOPE", "SUNNY ROYAL", "SUZAKU", "Syros I", "Tahiti One",
    "Tai Promotion", "TAI PROSPERITY", "TAI SPRING", "TAI STAR",
    "TAI SUMMIT", "Tangerine Island", "TANGERINE ISLAND", "TANIKAZE",
    "TASSOS N", "Taurus Ocean", "TEAL BULKER", "TENRO MARU",
    "Tenten", "THEMISTOCLES", "Theodor Oldendorff", "THEODOR OLDENDORFF",
    "Theodore Jr.", "Theresa Hebei", "Theresa Jilin", "Theresa Shandong",
    "TIGER HENAN", "TIGER NORTH", "TIGER PIONEER", "Tiger South",
    "TN SUNRISE", "TOMORROW", "Topaz", "TORENIA", "TR Lady",
    "Trade Unity", "TRANS OCEANIC", "TRUSTN TRADER II", "TSCHAIKOWSKY",
    "TTM DRAGON", "Tuo Fu 6", "Tycoon", "ULTRA PANTHER", "Unity",
    "UNITY DISCOVERY", "Valadon", "VEGA ROSE", "VELA OCEAN",
    "VENUS", "VENUS HALO", "VICTORIA", "VISHVA ANAND", "Vitahorizon",
    "Vitakosmos", "Vivian", "VSC CASTOR", "VSC TRITON", "XING XI HAI",
    "Yarrawonga", "Yue Guan Feng", "ZEN-NOH GRAIN MAGNOLIA",
    "ZEN-NOH GRAIN PEGASUS", "Zheng Zhi", "Zhi He"), class = "factor"),
    Draft = c(12L, 12L, 12L, 13L, 12L, 12L, 12L, 12L, 12L, 12L,
    12L, 12L, 12L, 12L, 14L, 14L, 14L, 12L, 13L, 12L, 12L, 14L,
    12L, 14L, 13L, 12L, 12L, 12L, 14L, 12L, 12L, 11L, 13L, 13L,
    14L, 12L, 12L, 13L, 14L, 12L, 13L, 13L, 12L, 14L, 14L, 13L,
    12L, 14L, 14L, 13L, 14L, 14L, 12L, 13L, 12L, 12L, 13L, 12L,
    12L, 14L, 14L, 14L, 12L, 12L, 12L, 12L, 14L, 13L, 14L, 12L,
    13L, 14L, 13L, 12L, 12L, 12L, 12L, 12L, 12L, 14L, 12L, 14L,
    13L, 14L, 14L, 12L, 12L, 12L, 14L, 12L, 12L, 13L, 14L, 13L,
    13L, 12L, 14L, 13L, 13L, 14L, 12L, 12L, 14L, 12L, 12L, 14L,
    12L, 13L, 13L, 14L, 14L, 14L, 14L, 12L, 12L, 14L, 13L, 12L,
    12L, 12L, 13L, 12L, 14L, 12L, 12L, 14L, 14L, 12L, 12L, 12L,
    12L, 12L, 12L, 13L, 12L, 12L, 12L, 13L, 12L, 12L, 12L, 12L,
    12L, 12L, 12L, 14L, 12L, 12L, 12L, 12L, 14L, 14L, 14L, 14L,
    10L, 12L, 11L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
    12L, 13L, 14L, 14L, 14L, 12L, 12L, 12L, 14L, 12L, 12L, 12L,
    14L, 14L, 14L, 14L, 12L, 12L, 11L, 12L, 12L, 12L, 12L, 12L,
    12L, 12L, 12L, 12L, 12L, 10L, 12L, 12L, 12L, 11L, 13L, 14L,
    14L, 12L, 13L, 14L, 14L, 12L, 13L, 14L, 12L, 12L, 12L, 14L,
    13L, 14L, 12L, 12L, 14L, 14L, 12L, 14L, 13L, 12L, 14L, 12L,
    14L, 12L, 12L, 12L, 12L, 14L, 13L, 12L, 13L, 12L, 12L, 14L,
    12L, 14L, 14L, 14L, 12L, 12L, 12L, 13L, 12L, 14L, 14L, 14L,
    12L, 12L, 12L, 12L, 13L, 12L, 12L, 12L, 14L, 14L, 12L, 12L,
    14L, 12L, 14L, 14L, 12L, 12L, 12L, 13L, 12L, 12L, 12L, 12L,
    12L, 14L, 14L, 13L, 12L, 13L, 14L, 12L, 12L, 12L, 12L, 13L,
    14L, 12L, 14L, 13L, 14L, 14L, 14L, 14L, 14L, 13L, 14L, 14L,
    13L, 14L, 12L, 12L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L,
    14L, 14L, 14L, 14L, 13L, 12L, 14L, 14L, 14L, 12L, 14L, 14L,
    14L, 12L, 12L, 14L, 14L, 14L, 14L, 12L, 14L, 14L, 12L, 14L,
    14L, 12L, 13L, 12L, 12L, 12L, 14L, 14L, 13L, 14L, 12L, 13L,
    13L, 13L, 12L, 12L, 12L, 12L, 12L, 14L, 12L, 14L, 13L, 14L,
    12L, 12L, 14L, 13L, 14L, 14L, 14L, 12L, 14L, 14L, 12L, 12L,
    14L, 12L, 14L, 12L, 12L, 12L, 14L, 12L, 13L, 14L, 12L, 12L,
    14L, 12L, 12L, 12L, 12L, 12L, 14L, 12L, 12L, 12L, 14L, 14L,
    12L, 12L, 14L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 14L, 12L,
    13L, 13L, 13L, 14L, 14L, 12L, 12L, 12L, 12L, 12L, 13L, 12L,
    14L, 13L, 12L, 12L, 12L, 12L, 12L, 13L, 12L, 14L, 13L, 13L,
    13L, 11L, 12L, 14L, 14L, 12L, 14L, 12L, 11L, 12L, 12L, 12L,
    12L, 14L, 12L, 12L, 12L, 12L, 14L, 14L, 12L, 12L, 12L, 14L,
    12L, 12L, 12L, 12L, 14L, 12L, 13L, 14L, 12L, 12L, 14L, 14L,
    12L, 12L, 12L, 13L, 12L, 14L, 14L, 14L, 12L, 14L, 13L, 12L,
    12L, 12L, 12L, 12L, 12L, 12L, 13L, 6L, 12L, 12L, 14L, 14L,
    14L, 14L, 12L, 14L, 12L, 12L, 12L, 12L, 14L, 12L, 14L, 12L,
    12L, 12L, 14L, 12L, 12L, 13L, 14L, 12L, 13L, 12L, 14L, 12L,
    12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
    12L), TOTALCOST = c(194364L, 219364L, 198260L, 237456L, 197159L,
    198992L, 194337L, 219337L, 199198L, 196604L, 230607L, 196604L,
    196604L, 194496L, 238600L, 236936L, 237476L, 197220L, 236950L,
    197300L, 182042L, 237938L, 199221L, 237475L, 239190L, 157406L,
    157211L, 182211L, 237475L, 182475L, 181599L, 156599L, 238269L,
    238402L, 238069L, 161436L, 225031L, 238180L, 237572L, 189861L,
    239005L, 239049L, 163814L, 240064L, 239171L, 238410L, 200878L,
    239019L, 239087L, 239350L, 239352L, 240275L, 164844L, 238400L,
    225158L, 202495L, 239681L, 201791L, 226863L, 244092L, 244590L,
    239171L, 189811L, 219412L, 228480L, 203650L, 237514L, 247451L,
    244739L, 211770L, 244308L, 239197L, 238419L, 224977L, 157362L,
    162434L, 162434L, 162434L, 162434L, 239681L, 163316L, 237265L,
    243920L, 244088L, 244163L, 202256L, 159592L, 201346L, 239187L,
    189800L, 191959L, 239476L, 239171L, 238087L, 238052L, 164169L,
    245057L, 244215L, 240812L, 239156L, 156879L, 197853L, 245367L,
    164710L, 164710L, 244192L, 211110L, 239156L, 244213L, 237504L,
    239018L, 241150L, 244447L, 238506L, 210298L, 243482L, 239166L,
    159489L, 184600L, 226439L, 239127L, 235243L, 244296L, 159696L,
    189046L, 244355L, 244446L, 187595L, 162595L, 162595L, 162595L,
    170604L, 188774L, 244103L, 188680L, 163611L, 200551L, 244055L,
    170606L, 169154L, 194154L, 170905L, 200551L, 191412L, 166412L,
    243969L, 170483L, 210719L, 168554L, 164016L, 245158L, 245131L,
    245186L, 239166L, 116360L, 155698L, 155698L, 155698L, 155698L,
    223827L, 191968L, 159650L, 189999L, 201193L, 201011L, 226218L,
    201218L, 243970L, 244291L, 243993L, 243993L, 236035L, 236035L,
    236035L, 244070L, 159692L, 194183L, 169110L, 241994L, 238216L,
    238301L, 242948L, 169810L, 189280L, 164662L, 164156L, 189156L,
    163989L, 163924L, 159577L, 159650L, 170566L, 170598L, 188975L,
    189006L, 99983L, 191595L, 166907L, 228744L, 166621L, 243593L,
    244001L, 239035L, 172934L, 238288L, 241665L, 241665L, 193991L,
    238361L, 238361L, 164215L, 168867L, 194304L, 241732L, 237745L,
    237911L, 195374L, 195374L, 244044L, 244044L, 169118L, 244040L,
    244040L, 198518L, 244106L, 236206L, 244136L, 191390L, 164516L,
    165137L, 232682L, 244021L, 244101L, 236136L, 244101L, 194181L,
    169181L, 244058L, 212313L, 238240L, 242502L, 239175L, 166221L,
    184500L, 170027L, 237701L, 211035L, 244050L, 243745L, 242782L,
    164482L, 166341L, 189482L, 174552L, 244213L, 190960L, 184494L,
    169116L, 239123L, 239121L, 165097L, 206396L, 241738L, 165622L,
    242651L, 250331L, 178778L, 169133L, 238280L, 244044L, 193182L,
    194156L, 194156L, 169156L, 196240L, 244060L, 244060L, 244060L,
    196050L, 243546L, 243546L, 195500L, 195500L, 170389L, 195389L,
    243549L, 243503L, 211398L, 243510L, 238436L, 238546L, 243907L,
    243654L, 238709L, 238656L, 244171L, 244136L, 243215L, 243957L,
    243957L, 164455L, 164455L, 243287L, 238203L, 243738L, 243266L,
    243294L, 243548L, 243262L, 243262L, 237628L, 243266L, 243382L,
    243927L, 243574L, 168364L, 243598L, 243596L, 243647L, 191094L,
    243655L, 244550L, 243907L, 200636L, 210208L, 243632L, 243632L,
    243367L, 243048L, 212125L, 244651L, 243357L, 202542L, 243778L,
    243502L, 170036L, 237911L, 195234L, 195220L, 170220L, 239391L,
    244397L, 244397L, 238631L, 225921L, 244034L, 244051L, 243310L,
    189976L, 164976L, 164976L, 164999L, 165154L, 243439L, 211003L,
    244034L, 243859L, 243859L, 170008L, 175602L, 238078L, 243484L,
    243619L, 243333L, 243289L, 200618L, 243392L, 243376L, 164873L,
    235797L, 243930L, 191502L, 243906L, 195351L, 170527L, 195307L,
    243551L, 175551L, 244759L, 238122L, 178863L, 170249L, 243701L,
    200549L, 236254L, 189982L, 163055L, 203863L, 243561L, 165089L,
    164574L, 193750L, 238061L, 240569L, 175435L, 164313L, 243153L,
    189825L, 189825L, 164825L, 189825L, 164340L, 203691L, 168483L,
    243970L, 193608L, 243054L, 243115L, 243115L, 243043L, 243115L,
    201917L, 204065L, 177917L, 178745L, 178735L, 243911L, 200920L,
    242726L, 243042L, 204204L, 181109L, 179157L, 200093L, 179164L,
    243676L, 235476L, 243862L, 243873L, 243945L, 243927L, 168102L,
    168102L, 243734L, 243929L, 179053L, 246381L, 204130L, 200546L,
    200301L, 174699L, 199699L, 178309L, 243549L, 204424L, 216428L,
    203785L, 204101L, 245074L, 243224L, 163661L, 179036L, 199248L,
    243458L, 199190L, 200330L, 200406L, 174754L, 243138L, 195257L,
    244796L, 243069L, 179132L, 204171L, 243718L, 243719L, 200616L,
    175749L, 179010L, 243037L, 178405L, 243953L, 243923L, 243485L,
    200891L, 239635L, 243661L, 204041L, 179002L, 204070L, 206036L,
    198896L, 164487L, 166891L, 246375L, 200217L, 179153L, 210112L,
    243941L, 243052L, 243724L, 246328L, 164311L, 243736L, 154373L,
    192956L, 237690L, 193282L, 244901L, 198985L, 246315L, 179272L,
    204007L, 202386L, 246315L, 202386L, 178856L, 243704L, 243750L,
    164533L, 246330L, 204082L, 243790L, 189359L, 164359L, 168286L,
    168286L, 175262L, 164395L, 189395L, 164299L, 189299L, 189110L,
    154953L, 166251L, 175373L, 235883L), BUNKER = c(350L, 405L,
    276L, 350L, 373L, 355L, 370L, 343L, 345L, 288L, 313L, 358L,
    440L, 292L, 318L, 360L, 318L, 288L, 350L, 349L, 350L, 318L,
    345L, 313L, 313L, 378L, 298L, 363L, 315L, 435L, 423L, 440L,
    343L, 355L, 313L, 318L, 435L, 313L, 345L, 318L, 349L, 353L,
    368L, 362L, 348L, 345L, 296L, 313L, 365L, 355L, 368L, 362L,
    378L, 348L, 313L, 418L, 348L, 418L, 345L, 362L, 318L, 350L,
    300L, 343L, 348L, 349L, 298L, 313L, 303L, 388L, 370L, 360L,
    362L, 338L, 313L, 350L, 313L, 423L, 313L, 343L, 353L, 313L,
    318L, 360L, 292L, 423L, 298L, 343L, 313L, 367L, 368L, 303L,
    355L, 353L, 370L, 296L, 303L, 355L, 343L, 313L, 353L, 370L,
    313L, 303L, 418L, 373L, 353L, 349L, 349L, 363L, 367L, 355L,
    365L, 443L, 440L, 350L, 363L, 318L, 423L, 364L, 313L, 422L,
    358L, 430L, 358L, 343L, 370L, 298L, 362L, 378L, 419L, 445L,
    362L, 313L, 432L, 373L, 355L, 318L, 353L, 283L, 338L, 255L,
    276L, 276L, 430L, 313L, 367L, 276L, 300L, 313L, 283L, 350L,
    313L, 313L, 362L, 288L, 425L, 313L, 348L, 426L, 345L, 313L,
    353L, 355L, 443L, 355L, 423L, 343L, 355L, 348L, 303L, 298L,
    318L, 367L, 313L, 435L, 313L, 425L, 355L, 318L, 368L, 370L,
    343L, 430L, 348L, 300L, 313L, 423L, 350L, 443L, 338L, 276L,
    292L, 358L, 378L, 313L, 443L, 313L, 348L, 338L, 370L, 313L,
    318L, 360L, 363L, 358L, 345L, 353L, 318L, 313L, 338L, 345L,
    345L, 313L, 355L, 348L, 313L, 422L, 363L, 313L, 276L, 318L,
    350L, 363L, 313L, 292L, 350L, 368L, 418L, 298L, 375L, 313L,
    315L, 353L, 313L, 288L, 348L, 360L, 413L, 318L, 345L, 365L,
    292L, 348L, 318L, 362L, 426L, 313L, 365L, 367L, 315L, 368L,
    425L, 276L, 345L, 360L, 350L, 405L, 362L, 313L, 350L, 343L,
    360L, 313L, 355L, 303L, 358L, 419L, 350L, 298L, 367L, 313L,
    343L, 405L, 419L, 345L, 303L, 367L, 265L, 378L, 345L, 318L,
    432L, 350L, 445L, 303L, 364L, 296L, 418L, 365L, 370L, 313L,
    362L, 318L, 313L, 353L, 373L, 360L, 345L, 313L, 353L, 422L,
    365L, 315L, 365L, 313L, 313L, 360L, 413L, 345L, 318L, 338L,
    355L, 313L, 349L, 418L, 360L, 303L, 313L, 355L, 313L, 318L,
    367L, 425L, 270L, 318L, 349L, 353L, 318L, 349L, 345L, 368L,
    318L, 313L, 362L, 338L, 303L, 296L, 345L, 364L, 283L, 368L,
    368L, 343L, 423L, 367L, 368L, 313L, 298L, 355L, 405L, 292L,
    368L, 355L, 440L, 313L, 313L, 313L, 438L, 358L, 313L, 292L,
    338L, 313L, 313L, 373L, 360L, 345L, 423L, 348L, 370L, 292L,
    303L, 345L, 265L, 364L, 315L, 338L, 350L, 368L, 313L, 318L,
    370L, 303L, 423L, 388L, 343L, 362L, 355L, 426L, 350L, 365L,
    345L, 355L, 343L, 443L, 313L, 270L, 360L, 350L, 435L, 445L,
    313L, 348L, 355L, 430L, 362L, 349L, 349L, 298L, 313L, 292L,
    375L, 367L, 318L, 315L, 368L, 296L, 300L, 318L, 296L, 425L,
    355L, 288L, 353L, 370L, 362L, 355L, 318L, 313L, 435L, 343L,
    435L, 292L, 355L, 440L, 338L, 313L, 355L, 288L, 440L, 435L,
    303L, 360L, 270L, 435L, 283L, 373L, 353L, 265L, 265L, 425L,
    367L, 353L, 367L, 448L, 368L, 283L, 350L, 343L, 353L, 303L,
    355L, 368L, 373L, 343L, 375L, 348L, 413L, 362L, 303L, 298L,
    313L, 300L, 440L, 349L, 355L, 318L, 355L, 388L, 363L, 440L,
    292L, 373L, 349L, 300L, 315L, 338L, 373L, 353L, 348L, 370L,
    362L, 338L, 440L, 440L, 350L, 296L, 343L, 368L, 349L, 423L,
    364L, 348L, 349L, 423L, 353L, 345L, 370L, 292L, 355L, 349L,
    355L, 276L, 440L, 283L, 358L, 375L, 348L, 440L, 355L, 423L,
    445L, 368L, 348L, 355L, 367L), CHARTERVALUE = c(14000L, 12825L,
    10475L, 11850L, 13250L, 12100L, 11875L, 14500L, 12500L, 10500L,
    13375L, 14500L, 13400L, 11000L, 12750L, 11625L, 11875L, 10500L,
    11850L, 11900L, 11850L, 12750L, 12500L, 12000L, 12250L, 12750L,
    10450L, 12900L, 12425L, 13375L, 12075L, 13400L, 12625L, 11125L,
    12000L, 11875L, 13400L, 12000L, 12500L, 12750L, 11900L, 13625L,
    12750L, 11800L, 12500L, 12500L, 9850L, 12000L, 12350L, 11125L,
    12750L, 11800L, 12750L, 12500L, 12250L, 13125L, 13125L, 13125L,
    12500L, 11800L, 11875L, 11850L, 11500L, 12625L, 13125L, 11900L,
    10425L, 12250L, 12375L, 12400L, 11875L, 11625L, 11800L, 12400L,
    12000L, 14000L, 12000L, 13125L, 12250L, 12625L, 13875L, 12400L,
    11875L, 11625L, 11000L, 12075L, 10450L, 12625L, 13375L, 12875L,
    13125L, 12375L, 11125L, 13625L, 11875L, 9850L, 12375L, 12100L,
    14500L, 12000L, 13875L, 11875L, 12400L, 12375L, 13125L, 13250L,
    13875L, 11900L, 11900L, 12900L, 12875L, 12100L, 12350L, 12375L,
    13125L, 11850L, 12900L, 12750L, 13125L, 13875L, 13375L, 13025L,
    14500L, 13400L, 14500L, 12625L, 11875L, 10450L, 11800L, 12750L,
    12625L, 12250L, 11800L, 12250L, 13250L, 13250L, 12100L, 12750L,
    13625L, 11125L, 12400L, 10250L, 10475L, 10475L, 13400L, 13375L,
    12875L, 10475L, 11500L, 12400L, 11125L, 11850L, 13375L, 12400L,
    11800L, 10500L, 13375L, 13375L, 12500L, 12625L, 12500L, 12000L,
    13875L, 11125L, 12375L, 11125L, 13125L, 12625L, 12100L, 12500L,
    12375L, 10450L, 12750L, 12875L, 12250L, 13400L, 12250L, 13375L,
    11125L, 12750L, 12750L, 11875L, 14500L, 13400L, 12500L, 11500L,
    13375L, 13125L, 11850L, 12375L, 12400L, 10475L, 11000L, 14500L,
    12750L, 12400L, 12375L, 12250L, 12500L, 12400L, 11875L, 12250L,
    12750L, 11625L, 12900L, 14500L, 12500L, 13875L, 11875L, 13375L,
    12400L, 12500L, 12500L, 13375L, 12100L, 12500L, 12400L, 13025L,
    12900L, 12400L, 10475L, 12750L, 11850L, 12900L, 13375L, 11000L,
    11850L, 13125L, 13125L, 10450L, 12500L, 12250L, 12425L, 13875L,
    12000L, 10500L, 13125L, 11625L, 12975L, 12750L, 12500L, 12350L,
    11000L, 13125L, 12750L, 11800L, 12625L, 13375L, 12350L, 12875L,
    12425L, 12750L, 12675L, 10475L, 12500L, 11625L, 11850L, 12825L,
    11800L, 13375L, 14000L, 12625L, 11625L, 12400L, 11125L, 12375L,
    14500L, 12625L, 14000L, 10425L, 12875L, 13375L, 14500L, 12825L,
    12625L, 12500L, 12375L, 12875L, 9875L, 12750L, 12500L, 12750L,
    13250L, 11850L, 12250L, 12375L, 13875L, 9850L, 13125L, 12350L,
    11875L, 12000L, 11800L, 11875L, 12000L, 13875L, 13250L, 11625L,
    12500L, 12400L, 13625L, 13025L, 12350L, 12425L, 12350L, 12400L,
    12400L, 11625L, 12975L, 12500L, 11875L, 12400L, 11125L, 12000L,
    11900L, 13125L, 11625L, 12375L, 12250L, 12100L, 13375L, 12750L,
    12875L, 12675L, 10000L, 11875L, 11900L, 13625L, 12750L, 11900L,
    12500L, 12750L, 12750L, 12000L, 11800L, 12400L, 12375L, 9850L,
    12500L, 13875L, 11125L, 12750L, 12750L, 12625L, 12075L, 12875L,
    13125L, 12250L, 10450L, 11125L, 12825L, 11000L, 13125L, 11125L,
    13125L, 12000L, 12000L, 13375L, 13375L, 14500L, 12000L, 11000L,
    12400L, 12250L, 12000L, 13250L, 11625L, 12500L, 13125L, 13125L,
    11875L, 11000L, 12375L, 12500L, 9875L, 13875L, 12425L, 12400L,
    14000L, 12750L, 12400L, 11875L, 11875L, 12375L, 12075L, 12400L,
    14500L, 11800L, 12100L, 12625L, 14000L, 12350L, 12500L, 12100L,
    12625L, 12375L, 12250L, 10000L, 11625L, 14000L, 13375L, 12250L,
    13375L, 12500L, 11125L, 13400L, 11800L, 11900L, 11900L, 10425L,
    12400L, 11000L, 12500L, 12875L, 12750L, 12425L, 12750L, 9850L,
    11500L, 12750L, 9850L, 13375L, 11125L, 10500L, 13875L, 11875L,
    11800L, 11125L, 12750L, 12250L, 13375L, 12625L, 13375L, 11000L,
    11125L, 13125L, 12400L, 13375L, 12100L, 10500L, 13075L, 13375L,
    12375L, 11625L, 10000L, 13400L, 11125L, 13250L, 13875L, 9875L,
    9875L, 13375L, 12875L, 13875L, 12875L, 13500L, 12750L, 11125L,
    11850L, 12625L, 13875L, 12375L, 12100L, 13125L, 13250L, 12625L,
    12500L, 13125L, 12975L, 11800L, 12375L, 10425L, 13375L, 11500L,
    13075L, 11900L, 12100L, 11875L, 11125L, 12400L, 12900L, 13400L,
    11000L, 13250L, 11900L, 11500L, 12425L, 12400L, 13250L, 13625L,
    12500L, 11875L, 11800L, 12400L, 13125L, 13075L, 14000L, 9850L,
    14500L, 13125L, 11900L, 13125L, 13875L, 13125L, 11900L, 13125L,
    13875L, 12500L, 11875L, 11000L, 11125L, 11900L, 11125L, 10475L,
    13075L, 11125L, 14500L, 12500L, 13125L, 13125L, 12100L, 13125L,
    12250L, 13125L, 12500L, 11125L, 12875L)), class = "data.frame",
row.names = c(NA,
-527L))

Any guidance will be greatly appreciated,

Best regards,

Paul

	[[alternative HTML version deleted]]


From m@rc_@chw@rtz @end|ng |rom me@com  Tue Apr 23 21:23:42 2019
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Tue, 23 Apr 2019 15:23:42 -0400
Subject: [R] Error in pglm function when performing logit regression on
 Panel Data
In-Reply-To: <CAMOcQfPsxQFqMUhAvqAkZHywYRTd21ebA5tBn3riaBdVNDqbHQ@mail.gmail.com>
References: <CAMOcQfPsxQFqMUhAvqAkZHywYRTd21ebA5tBn3riaBdVNDqbHQ@mail.gmail.com>
Message-ID: <4A9E6BA5-0325-4ED8-8565-DA236D9069E8@me.com>


> On Apr 23, 2019, at 2:43 PM, Paul Bernal <paulbernal07 at gmail.com> wrote:
> 
> Dear friends,
> 
> The following error is generated when trying to fit a logistic regression
> with the pglm function:
> 
>> PGLM_Model2 <-
> pglm(dataframe2$TRANSIT~dataframe2$Draft+dataframe2$TOTALCOST+dataframe2$BUNKER+dataframe2$CHARTERVALUE,
> effect=c("twoways"), family=binomial('logit'), index=dataframe2$ID,
> data=dataframe2)
> Error in pdata.frame(data, index) :
>  'index' can be of length 3 at the most (one index variable for
> individual, time, group)
> 
> This doesn?t make sense to me because the maximum length for ID is 3 and I
> checked it twice.
> 
> A few things to keep in mind:
> 1. I am using R version 3.5.3
> 2. My worstation has Windows 8 and it is a 64-bit OS
> 
> I would like to know what I?m doing wrong and how to solve this issue (if
> possible). I provide a dput() of my dataset below:
> 
> dput(dataframe2)'

<snip of dput output>

> Any guidance will be greatly appreciated,
> 
> Best regards,
> 
> Paul


Hi Paul,

I do not use pglm, but installed it.

Thanks for providing the dput() output of your data frame.

As is typical with R modeling functions, there is a reason for the 'data' argument, rather than specifying the 'dataframe$' prefix syntax for each DV and IV.

It shortens the code required to specify the formula, but perhaps more importantly, it defines the environment within which the function can find the variables to be used by the function, as specified by the various arguments.

In this case, that is critical, since, as per the examples in ?pglm, the 'index' argument is to be specified as a character vector and not as the vector objects themselves. That is, use "ID" and not ID. Therefore, the function will search for the vector/column named "ID" within the dataframe2 object, which is the argument to 'data'.

Unfortunately, the help for the function does not make it clear that the value for 'index' should be a character vector, it simply says 'the index'. Thus one needs to look at the examples for some guidance.

You might want to point that out to the maintainer of the package (copied here now) as an improvement in the documentation.

Thus:

> pglm(TRANSIT ~ Draft + TOTALCOST + BUNKER + CHARTERVALUE, data = dataframe2, effect = "twoways", family = binomial("logit"), index = "ID")
Maximum Likelihood estimation
Newton-Raphson maximisation, 0 iterations
Return code 100: Initial value out of range.


You now have other issues to deal with, which appear to be coming from the maxLik() function used from the package of the same name, which is a dependency for pglm, and I will leave those to you to resolve, probably using the 'start' argument to pglm().

Regards,

Marc Schwartz


From p@u|bern@|07 @end|ng |rom gm@||@com  Tue Apr 23 22:44:29 2019
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Tue, 23 Apr 2019 15:44:29 -0500
Subject: [R] Unable to Understand Results of pglm function
Message-ID: <CAMOcQfPtCNknO=1c5H4UM6hzbC8ULNtU18LS+ZCQWUxMJxum3g@mail.gmail.com>

Dear Yves,

Hope you are doing great. I have been testing the pglm function from the
pglm package, in order to fit a logit regression to a panel dataset, and I
do not understand the results and/or errors produced by the function, so I
want to be able to understand whether there is a problem with the structure
of my dataset, or I am not using the function properly or if there is
something else going on that I am ignoring. Also, I would like to know what
the start argument is for, or at least an example of how to use it, since I
don?t know how to properly apply it.

Here the details of what I am using and under what environment settings:
1-R version: 3.5.3
2-packages called: plm and pglm
3-Running on a 64-bit Operating System
4-Windows 8

Here is the code with the different things I have tried so far:
> PGLM_Model11 <-
pglm(dataframe3$TRANSIT~dataframe3$Draft+dataframe3$TOTALCOST+dataframe3$BUNKER+dataframe3$CHARTERVALUE,
effect=c("twoways"), model=c("random"), family=binomial('logit'),
index=c("ID","DATE"), start = NULL, data=dataframe3)
>
> summary(PGLM_Model11)
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 0 iterations
Return code 100: Initial value out of range.
--------------------------------------------
>
> PGLM_Model12 <-
pglm(dataframe3$TRANSIT~dataframe3$Draft+dataframe3$TOTALCOST+dataframe3$BUNKER+dataframe3$CHARTERVALUE,
effect=c("twoways"), model=c("pooling"), family=binomial('logit'),
index=c("ID","DATE"), start = NULL, data=dataframe3)
>
> summary(PGLM_Model12)
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 11 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -14.95426
5  free parameters
Estimates:
                          Estimate Std. error t value Pr(> t)
(Intercept)             93.9680425        Inf       0       1
dataframe3$Draft        -5.3820652        Inf       0       1
dataframe3$TOTALCOST    -0.0001689        Inf       0       1
dataframe3$BUNKER        0.0072934        Inf       0       1
dataframe3$CHARTERVALUE  0.0008862        Inf       0       1
--------------------------------------------
>
> PGLM_Model13 <-
pglm(dataframe3$TRANSIT~dataframe3$Draft+dataframe3$TOTALCOST+dataframe3$BUNKER+dataframe3$CHARTERVALUE,
effect=c("twoways"), model=c("within"), family=binomial('logit'),
index=c("ID","DATE"), start = NULL, data=dataframe3)
Error in maxRoutine(fn = logLik, grad = grad, hess = hess, start = start,
:
  argument "start" is missing, with no default
>
> PGLM_Model14 <-
pglm(dataframe3$TRANSIT~dataframe3$Draft+dataframe3$TOTALCOST+dataframe3$BUNKER+dataframe3$CHARTERVALUE,
effect=c("twoways"), model=c("between"), family=binomial('logit'),
index=c("ID","DATE"), start = NULL, data=dataframe3)
Error in maxRoutine(fn = logLik, grad = grad, hess = hess, start = start,
:
  argument "start" is missing, with no default

Below the dput of the dataset I am using for your reference:

> dput(dataframe3)
structure(list(TRANSIT = c(1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 0L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L,
0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 1L, 0L,
1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L,
1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 0L,
1L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 1L,
0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L,
1L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 0L,
0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L,
0L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
0L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 1L,
1L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 0L,
1L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 0L,
0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 0L,
0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 0L,
1L, 1L, 1L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L,
1L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 1L,
0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 0L,
0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L,
1L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L,
0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L,
0L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L,
0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 0L,
0L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L,
0L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L,
1L, 1L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L), ID = c(1L, 1L, 2L, 2L, 3L, 4L, 5L, 5L,
6L, 7L, 7L, 7L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L,
17L, 18L, 19L, 20L, 21L, 21L, 22L, 23L, 24L, 24L, 25L, 26L, 27L,
28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L, 38L, 39L, 40L,
41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L, 48L, 49L, 50L, 51L, 52L,
53L, 54L, 54L, 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 63L, 64L,
65L, 66L, 67L, 67L, 68L, 69L, 70L, 71L, 72L, 73L, 74L, 75L, 76L,
77L, 78L, 79L, 80L, 81L, 82L, 83L, 84L, 85L, 86L, 87L, 88L, 89L,
90L, 91L, 92L, 93L, 93L, 94L, 95L, 96L, 97L, 98L, 99L, 100L,
101L, 102L, 103L, 104L, 105L, 106L, 107L, 108L, 108L, 109L, 110L,
111L, 112L, 113L, 114L, 115L, 115L, 115L, 115L, 116L, 117L, 118L,
119L, 120L, 121L, 122L, 123L, 124L, 125L, 126L, 127L, 128L, 128L,
129L, 130L, 131L, 132L, 133L, 134L, 135L, 136L, 137L, 138L, 139L,
139L, 140L, 140L, 141L, 142L, 143L, 144L, 145L, 145L, 146L, 146L,
147L, 148L, 149L, 149L, 150L, 150L, 150L, 151L, 152L, 153L, 154L,
155L, 156L, 157L, 158L, 159L, 160L, 161L, 162L, 163L, 164L, 165L,
166L, 167L, 168L, 169L, 170L, 171L, 172L, 173L, 174L, 175L, 176L,
177L, 178L, 179L, 180L, 181L, 182L, 182L, 183L, 184L, 185L, 186L,
187L, 188L, 189L, 190L, 191L, 192L, 192L, 193L, 193L, 194L, 195L,
196L, 197L, 198L, 199L, 199L, 200L, 201L, 202L, 203L, 204L, 205L,
206L, 207L, 208L, 208L, 209L, 210L, 211L, 212L, 213L, 214L, 215L,
216L, 217L, 218L, 218L, 219L, 220L, 221L, 222L, 222L, 223L, 224L,
225L, 226L, 227L, 228L, 229L, 230L, 231L, 232L, 233L, 234L, 235L,
236L, 237L, 238L, 239L, 240L, 241L, 241L, 241L, 242L, 243L, 244L,
245L, 246L, 247L, 247L, 248L, 248L, 249L, 249L, 250L, 251L, 252L,
253L, 254L, 255L, 256L, 257L, 258L, 259L, 260L, 261L, 262L, 263L,
264L, 265L, 266L, 267L, 268L, 269L, 270L, 271L, 272L, 273L, 273L,
274L, 275L, 276L, 277L, 278L, 279L, 280L, 281L, 282L, 283L, 284L,
285L, 286L, 287L, 288L, 288L, 289L, 290L, 291L, 292L, 293L, 294L,
295L, 296L, 297L, 298L, 299L, 300L, 301L, 301L, 302L, 303L, 304L,
305L, 306L, 307L, 308L, 308L, 309L, 309L, 309L, 310L, 311L, 312L,
313L, 313L, 314L, 315L, 316L, 317L, 318L, 319L, 320L, 321L, 322L,
323L, 324L, 325L, 326L, 327L, 327L, 328L, 329L, 330L, 331L, 332L,
333L, 334L, 335L, 336L, 337L, 338L, 339L, 340L, 341L, 342L, 343L,
344L, 345L, 346L, 347L, 348L, 349L, 350L, 351L, 352L, 353L, 354L,
354L, 354L, 354L, 355L, 356L, 357L, 358L, 359L, 360L, 361L, 362L,
363L, 364L, 365L, 366L, 367L, 368L, 369L, 370L, 371L, 372L, 373L,
374L, 375L, 376L, 377L, 378L, 379L, 380L, 381L, 382L, 383L, 384L,
385L, 386L, 387L, 388L, 389L, 390L, 391L, 392L, 393L, 394L, 395L,
396L, 397L, 398L, 399L, 400L, 401L, 402L, 402L, 403L, 404L, 405L,
406L, 407L, 408L, 409L, 410L, 411L, 412L, 413L, 413L, 414L, 415L,
416L, 417L, 418L, 419L, 420L, 421L, 422L, 423L, 424L, 425L, 426L,
427L, 428L, 429L, 430L, 431L, 432L, 433L, 434L, 434L, 435L, 436L,
437L, 438L, 439L, 440L, 441L, 442L, 443L, 444L, 445L, 446L, 447L,
448L, 449L, 450L, 451L, 452L, 453L, 454L, 455L, 456L, 457L, 458L,
459L, 460L, 461L, 462L, 463L, 464L, 464L, 465L, 465L, 466L, 467L,
467L, 468L, 468L, 469L, 470L, 471L, 472L, 473L), DATE = structure(c(47L,
75L, 89L, 252L, 3L, 221L, 62L, 99L, 224L, 114L, 154L, 151L, 52L,
9L, 342L, 320L, 370L, 149L, 252L, 112L, 147L, 346L, 231L, 371L,
331L, 171L, 30L, 119L, 366L, 58L, 61L, 103L, 269L, 313L, 373L,
195L, 116L, 376L, 323L, 189L, 245L, 270L, 76L, 258L, 265L, 347L,
178L, 376L, 278L, 311L, 281L, 260L, 203L, 275L, 101L, 150L, 234L,
161L, 231L, 257L, 367L, 254L, 210L, 67L, 21L, 96L, 241L, 331L,
351L, 223L, 309L, 319L, 256L, 12L, 43L, 27L, 28L, 133L, 101L,
266L, 16L, 359L, 370L, 318L, 237L, 78L, 213L, 113L, 337L, 199L,
94L, 330L, 314L, 271L, 328L, 1L, 348L, 244L, 302L, 374L, 208L,
40L, 357L, 232L, 179L, 286L, 193L, 248L, 250L, 284L, 274L, 321L,
289L, 138L, 80L, 253L, 283L, 164L, 133L, 212L, 339L, 59L, 305L,
49L, 162L, 266L, 326L, 11L, 4L, 82L, 65L, 188L, 192L, 334L, 33L,
177L, 221L, 346L, 148L, 86L, 24L, 5L, 89L, 57L, 37L, 338L, 191L,
68L, 218L, 79L, 235L, 254L, 338L, 361L, 4L, 135L, 143L, 123L,
55L, 23L, 18L, 20L, 202L, 128L, 127L, 122L, 156L, 269L, 321L,
276L, 352L, 22L, 7L, 199L, 333L, 145L, 92L, 136L, 311L, 342L,
294L, 325L, 71L, 29L, 25L, 173L, 154L, 85L, 118L, 121L, 44L,
107L, 140L, 151L, 175L, 102L, 108L, 63L, 25L, 51L, 329L, 334L,
345L, 153L, 282L, 304L, 324L, 193L, 367L, 341L, 39L, 231L, 209L,
335L, 321L, 276L, 102L, 91L, 282L, 362L, 68L, 344L, 253L, 98L,
338L, 84L, 251L, 64L, 161L, 227L, 139L, 334L, 365L, 202L, 374L,
159L, 21L, 317L, 42L, 343L, 349L, 292L, 84L, 226L, 194L, 256L,
228L, 336L, 293L, 288L, 155L, 56L, 207L, 89L, 324L, 163L, 157L,
117L, 260L, 341L, 47L, 97L, 320L, 102L, 312L, 348L, 137L, 38L,
27L, 243L, 229L, 123L, 99L, 125L, 54L, 349L, 354L, 290L, 170L,
233L, 308L, 164L, 15L, 142L, 152L, 352L, 306L, 186L, 299L, 289L,
327L, 377L, 255L, 369L, 377L, 272L, 285L, 320L, 324L, 358L, 6L,
70L, 278L, 364L, 278L, 361L, 360L, 316L, 300L, 350L, 368L, 259L,
315L, 374L, 247L, 161L, 318L, 353L, 332L, 190L, 340L, 344L, 291L,
207L, 14L, 372L, 246L, 270L, 344L, 87L, 324L, 295L, 172L, 377L,
257L, 24L, 330L, 167L, 209L, 212L, 236L, 280L, 281L, 268L, 48L,
264L, 53L, 355L, 206L, 115L, 111L, 140L, 50L, 313L, 187L, 375L,
375L, 336L, 217L, 162L, 371L, 239L, 261L, 334L, 371L, 158L, 320L,
350L, 176L, 10L, 309L, 9L, 330L, 204L, 216L, 166L, 363L, 44L,
301L, 279L, 73L, 83L, 328L, 36L, 72L, 35L, 99L, 169L, 321L, 220L,
34L, 215L, 308L, 244L, 88L, 127L, 334L, 14L, 144L, 60L, 69L,
181L, 123L, 45L, 314L, 37L, 258L, 245L, 250L, 242L, 361L, 9L,
132L, 191L, 7L, 165L, 296L, 186L, 356L, 342L, 197L, 136L, 122L,
126L, 193L, 310L, 200L, 311L, 344L, 355L, 297L, 106L, 46L, 238L,
311L, 160L, 262L, 129L, 168L, 120L, 211L, 90L, 41L, 319L, 32L,
131L, 110L, 185L, 222L, 298L, 201L, 143L, 13L, 273L, 229L, 182L,
76L, 95L, 253L, 88L, 307L, 354L, 198L, 64L, 286L, 267L, 124L,
21L, 26L, 257L, 19L, 242L, 341L, 240L, 174L, 249L, 322L, 8L,
109L, 17L, 134L, 93L, 183L, 158L, 245L, 205L, 130L, 31L, 287L,
271L, 277L, 327L, 184L, 263L, 2L, 196L, 60L, 186L, 303L, 50L,
250L, 141L, 166L, 219L, 248L, 156L, 230L, 350L, 329L, 146L, 313L,
66L, 315L, 77L, 225L, 105L, 180L, 104L, 219L, 80L, 190L, 156L,
81L, 74L, 25L, 100L, 214L), .Label = c("1-Aug-17", "1-Aug-18",
"1-Feb-18", "1-Jan-18", "1-Jul-17", "1-Mar-18", "1-Nov-17", "1-Oct-17",
"1-Sep-17", "10-Apr-18", "10-Aug-17", "10-Dec-17", "10-Feb-18",
"10-Jul-17", "10-Jul-18", "10-Mar-18", "10-May-18", "10-Nov-17",
"10-Oct-17", "10-Sep-17", "11-Apr-18", "11-Aug-17", "11-Aug-18",
"11-Dec-17", "11-Feb-18", "11-Jun-18", "11-Mar-18", "11-Sep-17",
"11-Sep-18", "12-Aug-17", "12-Dec-17", "12-Jul-17", "12-Jul-18",
"12-Mar-18", "12-May-18", "12-Oct-17", "12-Sep-18", "13-Aug-18",
"13-Dec-17", "13-Nov-17", "13-Oct-17", "14-Jun-18", "14-Sep-17",
"15-Dec-17", "15-Feb-18", "15-Jul-18", "15-Mar-18", "15-May-18",
"15-Sep-18", "16-Apr-18", "16-Dec-17", "16-Sep-18", "17-Apr-18",
"17-Aug-18", "17-Feb-18", "17-Jan-18", "17-Jul-17", "17-Jul-18",
"17-Jun-18", "17-Mar-18", "17-May-18", "17-Nov-17", "17-Oct-17",
"18-Apr-18", "18-Aug-18", "18-Dec-17", "18-Feb-18", "18-Jul-17",
"18-Jul-18", "18-Jun-18", "18-Mar-18", "18-May-18", "18-Sep-17",
"19-Apr-18", "19-Aug-18", "19-Jan-18", "19-Jul-17", "19-May-18",
"19-Sep-17", "2-Aug-18", "2-Jun-18", "2-May-18", "2-Oct-17",
"2-Sep-17", "2-Sep-18", "20-Aug-17", "20-Dec-17", "20-Feb-18",
"20-Jul-17", "20-Jul-18", "20-Jun-18", "20-Oct-17", "20-Sep-18",
"21-Apr-18", "21-Aug-17", "21-Dec-17", "21-Feb-18", "21-Jan-18",
"21-Mar-18", "21-Nov-17", "21-Oct-17", "21-Sep-17", "21-Sep-18",
"22-Apr-18", "22-Aug-17", "22-Feb-18", "22-Jul-17", "22-May-18",
"22-Nov-17", "23-Aug-17", "23-Aug-18", "23-Dec-17", "23-Feb-18",
"23-Jul-17", "23-Nov-17", "23-Sep-18", "24-Aug-18", "24-Dec-17",
"24-Jan-18", "24-Jul-17", "24-May-18", "24-Nov-17", "24-Oct-17",
"25-Apr-18", "25-Aug-18", "25-Jul-17", "25-May-18", "25-Nov-17",
"25-Oct-17", "25-Sep-17", "25-Sep-18", "26-Apr-18", "26-Aug-18",
"26-Jan-18", "26-Jul-17", "26-Jul-18", "26-Mar-18", "26-May-18",
"27-Apr-18", "27-Aug-17", "27-Aug-18", "27-Dec-17", "27-Jul-18",
"27-Nov-17", "27-Sep-18", "28-Aug-17", "28-Dec-17", "28-Feb-18",
"28-Jul-17", "28-Jun-18", "28-Mar-18", "28-May-18", "28-Nov-17",
"28-Oct-17", "28-Sep-17", "29-Aug-18", "29-Dec-17", "29-Jan-18",
"29-Jul-17", "29-Jul-18", "29-Jun-18", "29-Mar-18", "29-Nov-17",
"29-Oct-17", "29-Sep-17", "3-Apr-18", "3-Aug-17", "3-Dec-17",
"3-Jan-18", "3-Jul-17", "3-May-18", "3-Nov-17", "3-Sep-17", "3-Sep-18",
"30-Apr-18", "30-Aug-18", "30-Jan-18", "30-Jul-17", "30-Jun-18",
"30-Mar-18", "30-May-18", "30-Sep-18", "31-Aug-17", "31-Dec-17",
"31-Jan-18", "31-Jul-17", "31-Jul-18", "31-May-18", "31-Oct-17",
"4-Dec-17", "4-Feb-18", "4-Jan-18", "4-Mar-18", "4-Nov-17", "4-Oct-17",
"4-Sep-18", "5-Aug-17", "5-Dec-17", "5-Feb-18", "5-Jan-18", "5-Jul-17",
"5-Mar-18", "5-May-18", "5-Nov-17", "5-Sep-17", "6-Aug-17", "6-Jun-18",
"6-Mar-18", "6-Nov-17", "6-Sep-17", "6-Sep-18", "7-Apr-18", "7-Aug-17",
"7-Feb-18", "7-Jan-18", "7-Jul-17", "7-Jul-18", "7-Sep-17", "8-Apr-18",
"8-Aug-18", "8-Dec-17", "8-Mar-18", "8-May-18", "8-Nov-17", "8-Sep-18",
"9-Apr-18", "9-Aug-17", "9-Aug-18", "9-Feb-18", "9-Mar-18", "9-Nov-17",
"9-Oct-17", "April 23 2018", "April 5 2018", "August 14 2017",
"August 15 2017", "August 24 2017", "August 25 2017", "August 26 2017",
"August 30 2017", "August 6 2017", "August 7 2017", "August 8 2017",
"December 1 2017", "December 10 2017", "December 11 2017", "December 12
2017",
"December 13 2017", "December 14 2017", "December 15 2017", "December 18
2017",
"December 19 2017", "December 21 2017", "December 22 2017", "December 24
2017",
"December 27 2017", "December 28 2017", "December 29 2017", "December 3
2017",
"December 30 2017", "December 4 2017", "December 5 2017", "December 6
2017",
"February 1 2018", "February 10 2018", "February 12 2018", "February 13
2018",
"February 15 2018", "February 16 2018", "February 19 2018", "February 20
2018",
"February 25 2018", "February 28 2018", "February 3 2018", "February 4
2017",
"February 5 2018", "February 8 2018", "January 1 2018", "January 10 2018",
"January 11 2018", "January 13 2018", "January 14 2018", "January 15 2018",
"January 20 2018", "January 23 2018", "January 24 2018", "January 26 2018",
"January 29 2018", "January 3 2018", "January 30 2018", "January 31 2018",
"January 4 2018", "January 6 2018", "January 7 2018", "January 8 2018",
"January 9 2018", "July 13 2018", "July 30 2017", "June 17 2018",
"June 8 2018", "March 10 2018", "March 13 2018", "March 18 2018",
"March 22 2018", "March 24 2018", "March 28 2018", "March 3 2018",
"November 1 2017", "November 10 2017", "November 11 2017", "November 12
2017",
"November 13 2017", "November 15 2017", "November 17 2017", "November 18
2017",
"November 19 2017", "November 21 2017", "November 22 2017", "November 23
2017",
"November 25 2017", "November 27 2017", "November 28 2017", "November 3
2017",
"November 4 2017", "November 5 2017", "November 6 2017", "November 7 2017",
"November 8 2017", "November 9 2017", "October 1 2017", "October 10 2017",
"October 11 2017", "October 12 2017", "October 14 2017", "October 15 2017",
"October 16 2017", "October 17 2017", "October 18 2017", "October 19 2017",
"October 20 2017", "October 21 2017", "October 23 2017", "October 25 2017",
"October 26 2017", "October 27 2017", "October 28 2017", "October 29 2017",
"October 3 2017", "October 30 2017", "October 31 2017", "October 4 2017",
"October 5 2017", "October 6 2017", "October 7 2017", "October 9 2017",
"September 1 2017", "September 10 2017", "September 11 2017",
"September 12 2017", "September 13 2017", "September 15 2017",
"September 16 2017", "September 17 2017", "September 19 2017",
"September 21 2017", "September 22 2017", "September 24 2017",
"September 26 2017", "September 27 2017", "September 29 2017",
"September 3 2017", "September 30 2017", "September 5 2017",
"September 6 2017", "September 7 2017", "September 8 2017", "September 9
2017"
), class = "factor"), SHIPNAME = structure(c(295L, 295L, 151L,
151L, 19L, 41L, 292L, 292L, 201L, 148L, 148L, 148L, 148L, 413L,
39L, 74L, 460L, 54L, 462L, 8L, 22L, 347L, 307L, 354L, 311L, 296L,
297L, 297L, 118L, 279L, 230L, 230L, 340L, 358L, 473L, 271L, 309L,
451L, 40L, 404L, 120L, 127L, 209L, 90L, 274L, 260L, 252L, 344L,
165L, 363L, 356L, 425L, 192L, 133L, 56L, 440L, 439L, 276L, 361L,
333L, 273L, 308L, 235L, 235L, 426L, 234L, 93L, 111L, 325L, 283L,
107L, 48L, 101L, 212L, 246L, 400L, 338L, 338L, 422L, 20L, 369L,
471L, 7L, 409L, 412L, 310L, 70L, 157L, 357L, 103L, 452L, 49L,
349L, 4L, 226L, 465L, 362L, 128L, 264L, 136L, 50L, 18L, 323L,
11L, 11L, 25L, 408L, 302L, 180L, 394L, 113L, 434L, 477L, 461L,
305L, 174L, 104L, 152L, 132L, 291L, 410L, 250L, 382L, 351L, 23L,
119L, 284L, 480L, 480L, 480L, 480L, 457L, 272L, 262L, 81L, 346L,
239L, 58L, 149L, 402L, 373L, 82L, 251L, 244L, 244L, 135L, 24L,
345L, 156L, 227L, 324L, 215L, 222L, 286L, 55L, 281L, 281L, 280L,
280L, 322L, 393L, 243L, 34L, 418L, 418L, 334L, 334L, 221L, 220L,
6L, 6L, 479L, 479L, 479L, 166L, 196L, 298L, 71L, 160L, 282L,
213L, 147L, 315L, 433L, 458L, 207L, 208L, 186L, 91L, 326L, 466L,
421L, 420L, 98L, 399L, 289L, 134L, 123L, 194L, 173L, 248L, 64L,
202L, 206L, 95L, 396L, 396L, 131L, 211L, 391L, 38L, 84L, 455L,
144L, 168L, 389L, 398L, 398L, 35L, 35L, 367L, 359L, 360L, 105L,
73L, 431L, 430L, 372L, 62L, 312L, 470L, 263L, 86L, 275L, 219L,
414L, 96L, 125L, 365L, 478L, 342L, 45L, 241L, 75L, 121L, 355L,
380L, 379L, 216L, 191L, 417L, 395L, 395L, 31L, 210L, 467L, 146L,
397L, 179L, 181L, 29L, 171L, 482L, 240L, 288L, 330L, 368L, 287L,
401L, 321L, 217L, 233L, 233L, 233L, 366L, 247L, 89L, 472L, 336L,
364L, 364L, 124L, 124L, 163L, 163L, 5L, 37L, 237L, 332L, 183L,
184L, 444L, 442L, 339L, 126L, 293L, 232L, 150L, 203L, 53L, 475L,
468L, 327L, 172L, 481L, 61L, 424L, 2L, 28L, 28L, 224L, 304L,
423L, 66L, 384L, 335L, 387L, 42L, 195L, 200L, 383L, 114L, 443L,
301L, 68L, 67L, 72L, 214L, 386L, 352L, 381L, 65L, 218L, 266L,
102L, 51L, 178L, 30L, 137L, 137L, 175L, 161L, 1L, 448L, 446L,
3L, 190L, 189L, 278L, 278L, 278L, 299L, 116L, 143L, 44L, 43L,
130L, 285L, 328L, 170L, 185L, 87L, 140L, 437L, 145L, 245L, 155L,
261L, 258L, 331L, 85L, 16L, 257L, 204L, 13L, 154L, 459L, 117L,
94L, 320L, 225L, 314L, 259L, 14L, 456L, 162L, 142L, 26L, 303L,
432L, 231L, 435L, 392L, 313L, 370L, 474L, 464L, 450L, 450L, 450L,
450L, 438L, 182L, 236L, 92L, 164L, 79L, 80L, 77L, 169L, 177L,
153L, 176L, 329L, 353L, 341L, 454L, 69L, 238L, 242L, 269L, 268L,
267L, 115L, 108L, 199L, 52L, 27L, 59L, 198L, 197L, 253L, 436L,
306L, 106L, 447L, 378L, 316L, 318L, 99L, 407L, 411L, 36L, 453L,
167L, 63L, 158L, 188L, 377L, 376L, 32L, 193L, 463L, 129L, 429L,
9L, 17L, 449L, 21L, 76L, 78L, 78L, 319L, 33L, 390L, 388L, 343L,
406L, 159L, 270L, 223L, 337L, 88L, 141L, 469L, 100L, 441L, 300L,
290L, 445L, 46L, 415L, 294L, 294L, 110L, 12L, 229L, 97L, 138L,
263L, 249L, 265L, 385L, 405L, 47L, 205L, 350L, 416L, 348L, 476L,
254L, 57L, 15L, 427L, 255L, 428L, 122L, 109L, 60L, 403L, 256L,
10L, 371L, 112L, 112L, 419L, 419L, 83L, 317L, 317L, 277L, 277L,
187L, 228L, 375L, 374L, 139L), .Label = c("Aby Jeannette", "Adelante",
"ADM Georgina", "ADS Galtesund", "Aeneas", "Aeolian Fortune",
"Aeolian Light", "AFRICA GRAECA", "AFRICAN ARROW", "AFRICAN BARI BIRD",
"AFRICAN BLUE CRANE", "AFRICAN FINFOOT", "AFRICAN JACANA", "AFRICAN KITE",
"AFRICAN LEOPARD", "AFRICAN PUFFIN", "AFRICAN RAPTOR", "AFTERHOURS",
"AGIA SKEPI", "Agri Kinsale", "Aiantas", "AKILI", "ALAM MANIS",
"ALBION", "Alexandra", "ALICIA", "Alma", "Alpha Vision", "AM BREMEN",
"AMAMI K", "AMIS ACE", "AMIS FORTUNE", "AMIS JUSTICE", "AMSTEL FALCON",
"Andros", "ANDROS ISLAND", "Androusa", "ANIMA", "Anna S", "Anna Smile",
"ANTIGONI", "Antiparos", "Aom Gaia", "AOM GAIA", "Aom Milena",
"APEX", "AREQUIPA QUEEN", "Ariana", "Artemis", "ASHIYA STAR",
"ASTRA CENTAURUS", "ASTREA", "Athina Carras", "ATLANTIC EAGLE",
"ATLANTIC GRACE", "ATLANTIC HERO", "ATLANTIC MANZANILLO", "Attalia",
"Axios", "Bahia Blanca", "Bali", "BALTIC K", "BALTIC WASP", "BBG Ambition",
"BBG Dream", "BBG Endeavor", "Belo Horizonte", "BELO HORIZONTE",
"BLUE AKIHABARA", "BLUE DIAMOND", "BLUE MARLIN I", "Bora", "Brasil SW",
"Braveheart", "BRIDGEGATE", "BRIGITTE", "BTG Denali", "BTG Eiger",
"BTG Everest", "BTG Kailach", "BULK ARGENTINA", "BULK COLOMBIA",
"BULK HERO", "BULK HONDURAS", "Bulk Pegasus", "Bulk Portugal",
"BW Hazel", "Captain Adams", "Captain Antonis", "Cemtex Wisdom",
"CENTENARIO BLU", "Cepheus Ocean", "Cerafina", "Cetus Ocean",
"CF Diamond", "CHARADE", "CHLOE", "CLARKE QUAY", "CLIPPER AMSTERDAM",
"Clipper Victory", "CMB Sakura", "Cofco 1", "COLUMBIA RIVER",
"Coral Diamond", "COREFORTUNE OL", "Cosmar", "Coventry", "CP GUANGZHOU",
"Crimson Ark", "Crimson Kingdom", "Cymona Star", "DALIAN STAR",
"De Xu Hai", "Densa Pelican", "DESERT CHALLENGER", "DEVON BAY",
"DIAMOND QUEEN", "Dias", "Dimitris Apesakis", "Donousa", "DORIC",
"DORIC SHOGUN", "DORO", "EASTER N", "Efrain A", "Egret Oasis",
"Eirini P", "Elena", "Emerald Dongji", "Emerald Star", "ENDLESS HORIZON",
"ENY", "Erikoussa", "ESSEX STRAIT", "Eternal Bliss", "Eternal Grace",
"EUROPA BAY", "Ever Grace", "EVER SOVEREIGN", "Everglory", "Evmar",
"FEDERAL TRIDENT", "FH Fang Cheng", "FH Rizhao", "Fiji", "FILIA JOY",
"Flag Lama", "FLIPPER", "FLORINDA", "Fortune Harmony", "FORTUNE LADY",
"FORTUNE UNITY", "FRAMURA", "FURNESS VICTORIA", "Galio", "GANNET BULKER",
"GENCO RAPTOR", "GH CITATION", "GH URBAN SEA", "Giorgakis", "Giorgis",
"GLOBAL PRIME", "GLOBAL SUCCESS", "GLOBAL VISION", "Glory", "Golden Jake",
"GOLDEN LIBRA", "Good Wish", "Graecia Aeterna", "GRAND CONCORD",
"GRAND MARCIA", "Great Rich", "GUARDIANSHIP", "Hampton Bay",
"Hampton Bridge", "HANTON TRADER I", "Hercules Ocean", "Hermes",
"Hong Hing", "Hong Jing", "Hong Sheng", "HOPA I", "Huayang Spirit",
"Huayeng Dream", "Indian Harmony", "INDIGO EVOLUTION", "INDIGO RIVER",
"INDRA OLDENDORFF", "Innovation", "INNOVATION", "Inspiration",
"IRIS HALO", "IRIS OLDENDORFF", "ISMENE", "Istria", "IYO WIND",
"Jag Aalok", "Jag Akshay", "Jag Arnav", "JIA SHENG SHAN", "JIN RUN",
"Jin Zhu Hai", "John M. Carras", "JOSCO HANGZHOU", "JPS AFRODITI",
"K SPINEL", "K. GARNET", "K. OPAL", "KANG CHENG", "Karlovasi",
"Katerina III", "KAVO PALOMA", "Kea", "Kerkyra", "Key Evolution",
"Key Pacifico", "KING ISLAND", "KING MILO", "KM Fukuyama", "KM Hong Kong",
"KM Keelung", "KM Yokohama", "KMARIN SINGAPORE", "KT Birdie",
"KYRA PANAGHIA", "Lady I", "LEO ADVANCE", "LESEDI QUEEN", "LILA",
"LISSA TOPIC", "LOCH SHUNA", "Long Dar", "LOUISIANA MAMA", "LOWLANDS
MAINE",
"LUMINOUS HALO", "LUNITA", "LYRIC HARMONY", "Macheras", "MALMO",
"MANDARIN CROWN", "MANDARIN NOBLE", "Marathassa", "MARIE GRACE",
"MARINER", "MARITIME PROSPERITY", "MARY LINA", "Mastro Nikos",
"MBA Future", "Medi Matsuura", "MEDI SALERNO", "MELBOURNE", "MELIA",
"METSOVO", "MG Explorer", "MG Kronos", "MG Sakura", "Miao Xiang",
"MISATO K", "Mistral I", "Miyama", "Mykonos", "Myra", "Myrto",
"N Bonanza", "Nadeshiko", "Naias", "NAUTICAL MARIE", "NAUTICAL RUNA",
"NAUTICAL SIF", "Navios Amber", "NAVIOS ARC", "NAVIOS ARMONIA",
"Navios Harmony", "Navios Orbiter", "NAVIOS SOUTHERN STAR", "NEFELI",
"NEW BLISS", "NEW DIRECTION", "NEWSEAS PEARL", "NIKKEI SIRIUS",
"NIKKEI VERDE", "Nikolaos", "NIKOLAS XL", "Nikomarin", "Nord Capella",
"Nord Fortune", "NOSHIMA", "Nuri Bey", "OCCITAN PAUILLAC", "OCEAN BAO",
"OCEAN BELT", "OCEAN FAVOUR", "Ocean Garlic", "OCEAN HARVEST",
"OCEAN PRIDE", "OCEAN PRINCE", "OCEAN PRINCESS", "OCEAN ROYAL",
"OCEAN SPLENDOR", "OCEAN TIANBAO", "OCEAN VENUS", "Ocean Wind",
"Oceana", "Odysseas L", "OKINAWA", "Olivia R", "OLYMPOS", "Omicron Light",
"OMICRON NIKOS", "OMICRON SKY", "Omicron Trader", "ORCHID HALO",
"Orient Genesis", "ORIENT GRACE", "OZGUR AKSOY", "PACIFIC ADVANCE",
"PACIFIC NEXUS", "PACIFIC TALENT", "PACIFIC VICTORY", "Palais",
"Pan Ceres", "PAN VIVA", "Panafrican", "Panamanian", "Panasiatic",
"PANORIA", "Panther Max", "PARADISE ISLAND", "PAUL OLDENDORFF",
"Peace Ark", "PEAK PEGASUS", "Pedhoulas Farmer", "Pedhoulas Trader",
"PENTA", "PERIDOT", "PERTH I", "Phaedra", "PHOENIX K", "Phoenix Ocean",
"Pictor", "PILATUS VENTURE", "Popi S", "PORT ESTRELA", "Proteas",
"QUEEN JHANSI", "QUEEN KOBE", "Rave", "RB Eden", "Real Happiness",
"RECCO", "REGAL", "RESURGENCE", "RIGI VENTURE", "Rosalia D? Amato",
"Rosco Banyan", "Rosco Cypress", "Rosco Ginkgo", "Rosco Lemon",
"Rosco Litchi", "Rosco Palm", "ROSCO PLUM", "Rosco Poplar", "Rosco
Sandalwood",
"RR Australia", "SAGAR JYOTI", "SAGAR SHAKTI", "SAGARJEET", "SAGE
COLORADO",
"SAGE PIONEER", "SAILING SKY", "Sakizaya Power", "SAN ANTONIO",
"SANTA KATARINA", "SANTA VALENTINA", "SANYU", "SBI Bolero", "SBI BOLERO",
"SBI Samba", "Scarlet Cardinal", "SCARLET CARDINAL", "Scarlet Falcon",
"Sea Duty", "Sea Hermes", "Sea Pegasus", "SEA PIONEER", "Sea Pluto",
"Seatribute", "Shandong Fu Hui", "Shandong Hai Chang", "Shangdong Fu Ze",
"Shao Shan 5", "Shao Shan 8", "SIFNOS", "Silver Dragon", "SIMURGH",
"Skiathos", "SKY KNIGHT", "SONGA GLORY", "SOUTHEND", "SPARNA",
"SPRING AEOLIAN", "SPRING EAGLE", "SPRING ZEPHYR", "SSI CHALLENGER",
"Stalo", "STAMFORD EAGLE", "STAR AQUARIUS", "STAR JENNIFER",
"Star Laura", "Star of Sawara", "STAR PISCES", "Star Renee",
"STAR VANESSA", "STARRY SKY", "STH LONDON", "STOVE FRIEND", "STOVE OCEAN",
"SUNLEAF GRACE", "SUNLEAF STAR", "SUNNY HOPE", "SUNNY ROYAL",
"SUZAKU", "Syros I", "Tahiti One", "Tai Promotion", "TAI PROSPERITY",
"TAI SPRING", "TAI STAR", "TAI SUMMIT", "Tangerine Island", "TANGERINE
ISLAND",
"TANIKAZE", "TASSOS N", "Taurus Ocean", "TEAL BULKER", "TENRO MARU",
"Tenten", "THEMISTOCLES", "Theodor Oldendorff", "THEODOR OLDENDORFF",
"Theodore Jr.", "Theresa Hebei", "Theresa Jilin", "Theresa Shandong",
"TIGER HENAN", "TIGER NORTH", "TIGER PIONEER", "Tiger South",
"TN SUNRISE", "TOMORROW", "Topaz", "TORENIA", "TR Lady", "Trade Unity",
"TRANS OCEANIC", "TRUSTN TRADER II", "TSCHAIKOWSKY", "TTM DRAGON",
"Tuo Fu 6", "Tycoon", "ULTRA PANTHER", "Unity", "UNITY DISCOVERY",
"Valadon", "VEGA ROSE", "VELA OCEAN", "VENUS", "VENUS HALO",
"VICTORIA", "VISHVA ANAND", "Vitahorizon", "Vitakosmos", "Vivian",
"VSC CASTOR", "VSC TRITON", "XING XI HAI", "Yarrawonga", "Yue Guan Feng",
"ZEN-NOH GRAIN MAGNOLIA", "ZEN-NOH GRAIN PEGASUS", "Zheng Zhi",
"Zhi He"), class = "factor"), Draft = c(12L, 12L, 12L, 13L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 14L, 14L, 14L, 12L,
13L, 12L, 12L, 14L, 12L, 14L, 13L, 12L, 12L, 12L, 14L, 12L, 12L,
11L, 13L, 13L, 14L, 12L, 12L, 13L, 14L, 12L, 13L, 13L, 12L, 14L,
14L, 13L, 12L, 14L, 14L, 13L, 14L, 14L, 12L, 13L, 12L, 12L, 13L,
12L, 12L, 14L, 14L, 14L, 12L, 12L, 12L, 12L, 14L, 13L, 14L, 12L,
13L, 14L, 13L, 12L, 12L, 12L, 12L, 12L, 12L, 14L, 12L, 14L, 13L,
14L, 14L, 12L, 12L, 12L, 14L, 12L, 12L, 13L, 14L, 13L, 13L, 12L,
14L, 13L, 13L, 14L, 12L, 12L, 14L, 12L, 12L, 14L, 12L, 13L, 13L,
14L, 14L, 14L, 14L, 12L, 12L, 14L, 13L, 12L, 12L, 12L, 13L, 12L,
14L, 12L, 12L, 14L, 14L, 12L, 12L, 12L, 12L, 12L, 12L, 13L, 12L,
12L, 12L, 13L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 14L, 12L, 12L,
12L, 12L, 14L, 14L, 14L, 14L, 10L, 12L, 11L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 13L, 14L, 14L, 14L, 12L, 12L, 12L,
14L, 12L, 12L, 12L, 14L, 14L, 14L, 14L, 12L, 12L, 11L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 10L, 12L, 12L, 12L, 11L,
13L, 14L, 14L, 12L, 13L, 14L, 14L, 12L, 13L, 14L, 12L, 12L, 12L,
14L, 13L, 14L, 12L, 12L, 14L, 14L, 12L, 14L, 13L, 12L, 14L, 12L,
14L, 12L, 12L, 12L, 12L, 14L, 13L, 12L, 13L, 12L, 12L, 14L, 12L,
14L, 14L, 14L, 12L, 12L, 12L, 13L, 12L, 14L, 14L, 14L, 12L, 12L,
12L, 12L, 13L, 12L, 12L, 12L, 14L, 14L, 12L, 12L, 14L, 12L, 14L,
14L, 12L, 12L, 12L, 13L, 12L, 12L, 12L, 12L, 12L, 14L, 14L, 13L,
12L, 13L, 14L, 12L, 12L, 12L, 12L, 13L, 14L, 12L, 14L, 13L, 14L,
14L, 14L, 14L, 14L, 13L, 14L, 14L, 13L, 14L, 12L, 12L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 13L, 12L, 14L,
14L, 14L, 12L, 14L, 14L, 14L, 12L, 12L, 14L, 14L, 14L, 14L, 12L,
14L, 14L, 12L, 14L, 14L, 12L, 13L, 12L, 12L, 12L, 14L, 14L, 13L,
14L, 12L, 13L, 13L, 13L, 12L, 12L, 12L, 12L, 12L, 14L, 12L, 14L,
13L, 14L, 12L, 12L, 14L, 13L, 14L, 14L, 14L, 12L, 14L, 14L, 12L,
12L, 14L, 12L, 14L, 12L, 12L, 12L, 14L, 12L, 13L, 14L, 12L, 12L,
14L, 12L, 12L, 12L, 12L, 12L, 14L, 12L, 12L, 12L, 14L, 14L, 12L,
12L, 14L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 14L, 12L, 13L, 13L,
13L, 14L, 14L, 12L, 12L, 12L, 12L, 12L, 13L, 12L, 14L, 13L, 12L,
12L, 12L, 12L, 12L, 13L, 12L, 14L, 13L, 13L, 13L, 11L, 12L, 14L,
14L, 12L, 14L, 12L, 11L, 12L, 12L, 12L, 12L, 14L, 12L, 12L, 12L,
12L, 14L, 14L, 12L, 12L, 12L, 14L, 12L, 12L, 12L, 12L, 14L, 12L,
13L, 14L, 12L, 12L, 14L, 14L, 12L, 12L, 12L, 13L, 12L, 14L, 14L,
14L, 12L, 14L, 13L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 13L, 6L,
12L, 12L, 14L, 14L, 14L, 14L, 12L, 14L, 12L, 12L, 12L, 12L, 14L,
12L, 14L, 12L, 12L, 12L, 14L, 12L, 12L, 13L, 14L, 12L, 13L, 12L,
14L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L), TOTALCOST = c(194364L, 219364L, 198260L, 237456L,
197159L, 198992L, 194337L, 219337L, 199198L, 196604L, 230607L,
196604L, 196604L, 194496L, 238600L, 236936L, 237476L, 197220L,
236950L, 197300L, 182042L, 237938L, 199221L, 237475L, 239190L,
157406L, 157211L, 182211L, 237475L, 182475L, 181599L, 156599L,
238269L, 238402L, 238069L, 161436L, 225031L, 238180L, 237572L,
189861L, 239005L, 239049L, 163814L, 240064L, 239171L, 238410L,
200878L, 239019L, 239087L, 239350L, 239352L, 240275L, 164844L,
238400L, 225158L, 202495L, 239681L, 201791L, 226863L, 244092L,
244590L, 239171L, 189811L, 219412L, 228480L, 203650L, 237514L,
247451L, 244739L, 211770L, 244308L, 239197L, 238419L, 224977L,
157362L, 162434L, 162434L, 162434L, 162434L, 239681L, 163316L,
237265L, 243920L, 244088L, 244163L, 202256L, 159592L, 201346L,
239187L, 189800L, 191959L, 239476L, 239171L, 238087L, 238052L,
164169L, 245057L, 244215L, 240812L, 239156L, 156879L, 197853L,
245367L, 164710L, 164710L, 244192L, 211110L, 239156L, 244213L,
237504L, 239018L, 241150L, 244447L, 238506L, 210298L, 243482L,
239166L, 159489L, 184600L, 226439L, 239127L, 235243L, 244296L,
159696L, 189046L, 244355L, 244446L, 187595L, 162595L, 162595L,
162595L, 170604L, 188774L, 244103L, 188680L, 163611L, 200551L,
244055L, 170606L, 169154L, 194154L, 170905L, 200551L, 191412L,
166412L, 243969L, 170483L, 210719L, 168554L, 164016L, 245158L,
245131L, 245186L, 239166L, 116360L, 155698L, 155698L, 155698L,
155698L, 223827L, 191968L, 159650L, 189999L, 201193L, 201011L,
226218L, 201218L, 243970L, 244291L, 243993L, 243993L, 236035L,
236035L, 236035L, 244070L, 159692L, 194183L, 169110L, 241994L,
238216L, 238301L, 242948L, 169810L, 189280L, 164662L, 164156L,
189156L, 163989L, 163924L, 159577L, 159650L, 170566L, 170598L,
188975L, 189006L, 99983L, 191595L, 166907L, 228744L, 166621L,
243593L, 244001L, 239035L, 172934L, 238288L, 241665L, 241665L,
193991L, 238361L, 238361L, 164215L, 168867L, 194304L, 241732L,
237745L, 237911L, 195374L, 195374L, 244044L, 244044L, 169118L,
244040L, 244040L, 198518L, 244106L, 236206L, 244136L, 191390L,
164516L, 165137L, 232682L, 244021L, 244101L, 236136L, 244101L,
194181L, 169181L, 244058L, 212313L, 238240L, 242502L, 239175L,
166221L, 184500L, 170027L, 237701L, 211035L, 244050L, 243745L,
242782L, 164482L, 166341L, 189482L, 174552L, 244213L, 190960L,
184494L, 169116L, 239123L, 239121L, 165097L, 206396L, 241738L,
165622L, 242651L, 250331L, 178778L, 169133L, 238280L, 244044L,
193182L, 194156L, 194156L, 169156L, 196240L, 244060L, 244060L,
244060L, 196050L, 243546L, 243546L, 195500L, 195500L, 170389L,
195389L, 243549L, 243503L, 211398L, 243510L, 238436L, 238546L,
243907L, 243654L, 238709L, 238656L, 244171L, 244136L, 243215L,
243957L, 243957L, 164455L, 164455L, 243287L, 238203L, 243738L,
243266L, 243294L, 243548L, 243262L, 243262L, 237628L, 243266L,
243382L, 243927L, 243574L, 168364L, 243598L, 243596L, 243647L,
191094L, 243655L, 244550L, 243907L, 200636L, 210208L, 243632L,
243632L, 243367L, 243048L, 212125L, 244651L, 243357L, 202542L,
243778L, 243502L, 170036L, 237911L, 195234L, 195220L, 170220L,
239391L, 244397L, 244397L, 238631L, 225921L, 244034L, 244051L,
243310L, 189976L, 164976L, 164976L, 164999L, 165154L, 243439L,
211003L, 244034L, 243859L, 243859L, 170008L, 175602L, 238078L,
243484L, 243619L, 243333L, 243289L, 200618L, 243392L, 243376L,
164873L, 235797L, 243930L, 191502L, 243906L, 195351L, 170527L,
195307L, 243551L, 175551L, 244759L, 238122L, 178863L, 170249L,
243701L, 200549L, 236254L, 189982L, 163055L, 203863L, 243561L,
165089L, 164574L, 193750L, 238061L, 240569L, 175435L, 164313L,
243153L, 189825L, 189825L, 164825L, 189825L, 164340L, 203691L,
168483L, 243970L, 193608L, 243054L, 243115L, 243115L, 243043L,
243115L, 201917L, 204065L, 177917L, 178745L, 178735L, 243911L,
200920L, 242726L, 243042L, 204204L, 181109L, 179157L, 200093L,
179164L, 243676L, 235476L, 243862L, 243873L, 243945L, 243927L,
168102L, 168102L, 243734L, 243929L, 179053L, 246381L, 204130L,
200546L, 200301L, 174699L, 199699L, 178309L, 243549L, 204424L,
216428L, 203785L, 204101L, 245074L, 243224L, 163661L, 179036L,
199248L, 243458L, 199190L, 200330L, 200406L, 174754L, 243138L,
195257L, 244796L, 243069L, 179132L, 204171L, 243718L, 243719L,
200616L, 175749L, 179010L, 243037L, 178405L, 243953L, 243923L,
243485L, 200891L, 239635L, 243661L, 204041L, 179002L, 204070L,
206036L, 198896L, 164487L, 166891L, 246375L, 200217L, 179153L,
210112L, 243941L, 243052L, 243724L, 246328L, 164311L, 243736L,
154373L, 192956L, 237690L, 193282L, 244901L, 198985L, 246315L,
179272L, 204007L, 202386L, 246315L, 202386L, 178856L, 243704L,
243750L, 164533L, 246330L, 204082L, 243790L, 189359L, 164359L,
168286L, 168286L, 175262L, 164395L, 189395L, 164299L, 189299L,
189110L, 154953L, 166251L, 175373L, 235883L), BUNKER = c(350L,
405L, 276L, 350L, 373L, 355L, 370L, 343L, 345L, 288L, 313L, 358L,
440L, 292L, 318L, 360L, 318L, 288L, 350L, 349L, 350L, 318L, 345L,
313L, 313L, 378L, 298L, 363L, 315L, 435L, 423L, 440L, 343L, 355L,
313L, 318L, 435L, 313L, 345L, 318L, 349L, 353L, 368L, 362L, 348L,
345L, 296L, 313L, 365L, 355L, 368L, 362L, 378L, 348L, 313L, 418L,
348L, 418L, 345L, 362L, 318L, 350L, 300L, 343L, 348L, 349L, 298L,
313L, 303L, 388L, 370L, 360L, 362L, 338L, 313L, 350L, 313L, 423L,
313L, 343L, 353L, 313L, 318L, 360L, 292L, 423L, 298L, 343L, 313L,
367L, 368L, 303L, 355L, 353L, 370L, 296L, 303L, 355L, 343L, 313L,
353L, 370L, 313L, 303L, 418L, 373L, 353L, 349L, 349L, 363L, 367L,
355L, 365L, 443L, 440L, 350L, 363L, 318L, 423L, 364L, 313L, 422L,
358L, 430L, 358L, 343L, 370L, 298L, 362L, 378L, 419L, 445L, 362L,
313L, 432L, 373L, 355L, 318L, 353L, 283L, 338L, 255L, 276L, 276L,
430L, 313L, 367L, 276L, 300L, 313L, 283L, 350L, 313L, 313L, 362L,
288L, 425L, 313L, 348L, 426L, 345L, 313L, 353L, 355L, 443L, 355L,
423L, 343L, 355L, 348L, 303L, 298L, 318L, 367L, 313L, 435L, 313L,
425L, 355L, 318L, 368L, 370L, 343L, 430L, 348L, 300L, 313L, 423L,
350L, 443L, 338L, 276L, 292L, 358L, 378L, 313L, 443L, 313L, 348L,
338L, 370L, 313L, 318L, 360L, 363L, 358L, 345L, 353L, 318L, 313L,
338L, 345L, 345L, 313L, 355L, 348L, 313L, 422L, 363L, 313L, 276L,
318L, 350L, 363L, 313L, 292L, 350L, 368L, 418L, 298L, 375L, 313L,
315L, 353L, 313L, 288L, 348L, 360L, 413L, 318L, 345L, 365L, 292L,
348L, 318L, 362L, 426L, 313L, 365L, 367L, 315L, 368L, 425L, 276L,
345L, 360L, 350L, 405L, 362L, 313L, 350L, 343L, 360L, 313L, 355L,
303L, 358L, 419L, 350L, 298L, 367L, 313L, 343L, 405L, 419L, 345L,
303L, 367L, 265L, 378L, 345L, 318L, 432L, 350L, 445L, 303L, 364L,
296L, 418L, 365L, 370L, 313L, 362L, 318L, 313L, 353L, 373L, 360L,
345L, 313L, 353L, 422L, 365L, 315L, 365L, 313L, 313L, 360L, 413L,
345L, 318L, 338L, 355L, 313L, 349L, 418L, 360L, 303L, 313L, 355L,
313L, 318L, 367L, 425L, 270L, 318L, 349L, 353L, 318L, 349L, 345L,
368L, 318L, 313L, 362L, 338L, 303L, 296L, 345L, 364L, 283L, 368L,
368L, 343L, 423L, 367L, 368L, 313L, 298L, 355L, 405L, 292L, 368L,
355L, 440L, 313L, 313L, 313L, 438L, 358L, 313L, 292L, 338L, 313L,
313L, 373L, 360L, 345L, 423L, 348L, 370L, 292L, 303L, 345L, 265L,
364L, 315L, 338L, 350L, 368L, 313L, 318L, 370L, 303L, 423L, 388L,
343L, 362L, 355L, 426L, 350L, 365L, 345L, 355L, 343L, 443L, 313L,
270L, 360L, 350L, 435L, 445L, 313L, 348L, 355L, 430L, 362L, 349L,
349L, 298L, 313L, 292L, 375L, 367L, 318L, 315L, 368L, 296L, 300L,
318L, 296L, 425L, 355L, 288L, 353L, 370L, 362L, 355L, 318L, 313L,
435L, 343L, 435L, 292L, 355L, 440L, 338L, 313L, 355L, 288L, 440L,
435L, 303L, 360L, 270L, 435L, 283L, 373L, 353L, 265L, 265L, 425L,
367L, 353L, 367L, 448L, 368L, 283L, 350L, 343L, 353L, 303L, 355L,
368L, 373L, 343L, 375L, 348L, 413L, 362L, 303L, 298L, 313L, 300L,
440L, 349L, 355L, 318L, 355L, 388L, 363L, 440L, 292L, 373L, 349L,
300L, 315L, 338L, 373L, 353L, 348L, 370L, 362L, 338L, 440L, 440L,
350L, 296L, 343L, 368L, 349L, 423L, 364L, 348L, 349L, 423L, 353L,
345L, 370L, 292L, 355L, 349L, 355L, 276L, 440L, 283L, 358L, 375L,
348L, 440L, 355L, 423L, 445L, 368L, 348L, 355L, 367L), CHARTERVALUE =
c(14000L,
12825L, 10475L, 11850L, 13250L, 12100L, 11875L, 14500L, 12500L,
10500L, 13375L, 14500L, 13400L, 11000L, 12750L, 11625L, 11875L,
10500L, 11850L, 11900L, 11850L, 12750L, 12500L, 12000L, 12250L,
12750L, 10450L, 12900L, 12425L, 13375L, 12075L, 13400L, 12625L,
11125L, 12000L, 11875L, 13400L, 12000L, 12500L, 12750L, 11900L,
13625L, 12750L, 11800L, 12500L, 12500L, 9850L, 12000L, 12350L,
11125L, 12750L, 11800L, 12750L, 12500L, 12250L, 13125L, 13125L,
13125L, 12500L, 11800L, 11875L, 11850L, 11500L, 12625L, 13125L,
11900L, 10425L, 12250L, 12375L, 12400L, 11875L, 11625L, 11800L,
12400L, 12000L, 14000L, 12000L, 13125L, 12250L, 12625L, 13875L,
12400L, 11875L, 11625L, 11000L, 12075L, 10450L, 12625L, 13375L,
12875L, 13125L, 12375L, 11125L, 13625L, 11875L, 9850L, 12375L,
12100L, 14500L, 12000L, 13875L, 11875L, 12400L, 12375L, 13125L,
13250L, 13875L, 11900L, 11900L, 12900L, 12875L, 12100L, 12350L,
12375L, 13125L, 11850L, 12900L, 12750L, 13125L, 13875L, 13375L,
13025L, 14500L, 13400L, 14500L, 12625L, 11875L, 10450L, 11800L,
12750L, 12625L, 12250L, 11800L, 12250L, 13250L, 13250L, 12100L,
12750L, 13625L, 11125L, 12400L, 10250L, 10475L, 10475L, 13400L,
13375L, 12875L, 10475L, 11500L, 12400L, 11125L, 11850L, 13375L,
12400L, 11800L, 10500L, 13375L, 13375L, 12500L, 12625L, 12500L,
12000L, 13875L, 11125L, 12375L, 11125L, 13125L, 12625L, 12100L,
12500L, 12375L, 10450L, 12750L, 12875L, 12250L, 13400L, 12250L,
13375L, 11125L, 12750L, 12750L, 11875L, 14500L, 13400L, 12500L,
11500L, 13375L, 13125L, 11850L, 12375L, 12400L, 10475L, 11000L,
14500L, 12750L, 12400L, 12375L, 12250L, 12500L, 12400L, 11875L,
12250L, 12750L, 11625L, 12900L, 14500L, 12500L, 13875L, 11875L,
13375L, 12400L, 12500L, 12500L, 13375L, 12100L, 12500L, 12400L,
13025L, 12900L, 12400L, 10475L, 12750L, 11850L, 12900L, 13375L,
11000L, 11850L, 13125L, 13125L, 10450L, 12500L, 12250L, 12425L,
13875L, 12000L, 10500L, 13125L, 11625L, 12975L, 12750L, 12500L,
12350L, 11000L, 13125L, 12750L, 11800L, 12625L, 13375L, 12350L,
12875L, 12425L, 12750L, 12675L, 10475L, 12500L, 11625L, 11850L,
12825L, 11800L, 13375L, 14000L, 12625L, 11625L, 12400L, 11125L,
12375L, 14500L, 12625L, 14000L, 10425L, 12875L, 13375L, 14500L,
12825L, 12625L, 12500L, 12375L, 12875L, 9875L, 12750L, 12500L,
12750L, 13250L, 11850L, 12250L, 12375L, 13875L, 9850L, 13125L,
12350L, 11875L, 12000L, 11800L, 11875L, 12000L, 13875L, 13250L,
11625L, 12500L, 12400L, 13625L, 13025L, 12350L, 12425L, 12350L,
12400L, 12400L, 11625L, 12975L, 12500L, 11875L, 12400L, 11125L,
12000L, 11900L, 13125L, 11625L, 12375L, 12250L, 12100L, 13375L,
12750L, 12875L, 12675L, 10000L, 11875L, 11900L, 13625L, 12750L,
11900L, 12500L, 12750L, 12750L, 12000L, 11800L, 12400L, 12375L,
9850L, 12500L, 13875L, 11125L, 12750L, 12750L, 12625L, 12075L,
12875L, 13125L, 12250L, 10450L, 11125L, 12825L, 11000L, 13125L,
11125L, 13125L, 12000L, 12000L, 13375L, 13375L, 14500L, 12000L,
11000L, 12400L, 12250L, 12000L, 13250L, 11625L, 12500L, 13125L,
13125L, 11875L, 11000L, 12375L, 12500L, 9875L, 13875L, 12425L,
12400L, 14000L, 12750L, 12400L, 11875L, 11875L, 12375L, 12075L,
12400L, 14500L, 11800L, 12100L, 12625L, 14000L, 12350L, 12500L,
12100L, 12625L, 12375L, 12250L, 10000L, 11625L, 14000L, 13375L,
12250L, 13375L, 12500L, 11125L, 13400L, 11800L, 11900L, 11900L,
10425L, 12400L, 11000L, 12500L, 12875L, 12750L, 12425L, 12750L,
9850L, 11500L, 12750L, 9850L, 13375L, 11125L, 10500L, 13875L,
11875L, 11800L, 11125L, 12750L, 12250L, 13375L, 12625L, 13375L,
11000L, 11125L, 13125L, 12400L, 13375L, 12100L, 10500L, 13075L,
13375L, 12375L, 11625L, 10000L, 13400L, 11125L, 13250L, 13875L,
9875L, 9875L, 13375L, 12875L, 13875L, 12875L, 13500L, 12750L,
11125L, 11850L, 12625L, 13875L, 12375L, 12100L, 13125L, 13250L,
12625L, 12500L, 13125L, 12975L, 11800L, 12375L, 10425L, 13375L,
11500L, 13075L, 11900L, 12100L, 11875L, 11125L, 12400L, 12900L,
13400L, 11000L, 13250L, 11900L, 11500L, 12425L, 12400L, 13250L,
13625L, 12500L, 11875L, 11800L, 12400L, 13125L, 13075L, 14000L,
9850L, 14500L, 13125L, 11900L, 13125L, 13875L, 13125L, 11900L,
13125L, 13875L, 12500L, 11875L, 11000L, 11125L, 11900L, 11125L,
10475L, 13075L, 11125L, 14500L, 12500L, 13125L, 13125L, 12100L,
13125L, 12250L, 13125L, 12500L, 11125L, 12875L)), class = "data.frame",
row.names = c(NA,
-527L))


Any help and/or guidance will be greatly appreciated,

Best regards,

Paul

	[[alternative HTML version deleted]]


From du|c@|m@ @end|ng |rom b|gpond@com  Wed Apr 24 04:54:57 2019
From: du|c@|m@ @end|ng |rom b|gpond@com (Duncan Mackay)
Date: Wed, 24 Apr 2019 12:54:57 +1000
Subject: [R] Unable to Understand Results of pglm function
In-Reply-To: <CAMOcQfPtCNknO=1c5H4UM6hzbC8ULNtU18LS+ZCQWUxMJxum3g@mail.gmail.com>
References: <CAMOcQfPtCNknO=1c5H4UM6hzbC8ULNtU18LS+ZCQWUxMJxum3g@mail.gmail.com>
Message-ID: <000101d4fa49$1a364d70$4ea2e850$@bigpond.com>

Hi Paul

I think you may have too many IDs DATE for your model as you posted

I converted your DATE into date format and named it df3
str(df3)
'data.frame':   527 obs. of  11 variables:
 $ TRANSIT     : int  1 1 1 0 1 1 1 1 1 1 ...
 $ ID          : int  1 1 2 2 3 4 5 5 6 7 ...
 $ DATE        : Factor w/ 377 levels "1-Aug-17","1-Aug-18",..: 47 75 89 252 3 221 62 99 224 114 ...
 $ SHIPNAME    : Factor w/ 482 levels "Aby Jeannette",..: 295 295 151 151 19 41 292 292 201 148 ...
 $ Draft       : int  12 12 12 13 12 12 12 12 12 12 ...
 $ TOTALCOST   : int  194364 219364 198260 237456 197159 198992 194337 219337 199198 196604 ...
 $ BUNKER      : int  350 405 276 350 373 355 370 343 345 288 ...
 $ CHARTERVALUE: int  14000 12825 10475 11850 13250 12100 11875 14500 12500 10500 ...
 $ dt          : Date, format: "2018-03-15" "2018-08-19" "2017-07-20" "2017-12-19" ...
 $ dtym        : chr  "201803" "201808" "201707" "201712" ...
 $ dty         : chr  "2018" "2018" "2017" "2017" ...

Here are 2 results 

> model1 = pglm(TRANSIT~ Draft+TOTALCOST+BUNKER+CHARTERVALUE + dty,
+      effect=c("time"), 
+      model=c("pooling"), 
+      family=binomial('logit'),
+      index=c("ID"), 
+      start = NULL, data=df3)
> 
> summary(model1)
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 11 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -14.14988 
6  free parameters
Estimates:
               Estimate Std. error t value Pr(> t)
(Intercept)   1.023e+02        Inf       0       1
Draft        -5.088e+00        Inf       0       1
TOTALCOST    -1.708e-04        Inf       0       1
BUNKER       -6.712e-03        Inf       0       1
CHARTERVALUE  2.524e-04        Inf       0       1
dty2018       2.215e+00        Inf       0       1
--------------------------------------------

> model1=pglm(TRANSIT~ Draft+TOTALCOST+BUNKER+CHARTERVALUE + dty,
+      effect=c("time"), 
+      model=c("pooling"), 
+      family=binomial('logit'),
+      index=c("ID","dty"), 
+      start = NULL, data=df3)
Warning messages:
1: In pdata.frame(data, index) :
  duplicate couples (id-time) in resulting pdata.frame
 to find out which, use e.g. table(index(your_pdataframe), useNA = "ifany")
2: In is.pbalanced.default(index[[1]], index[[2]]) :
  duplicate couples (id-time)

> 
> summary(model1)
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 11 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -14.14988 
6  free parameters
Estimates:
               Estimate Std. error t value Pr(> t)
(Intercept)   1.023e+02        Inf       0       1
Draft        -5.088e+00        Inf       0       1
TOTALCOST    -1.708e-04        Inf       0       1
BUNKER       -6.712e-03        Inf       0       1
CHARTERVALUE  2.524e-04        Inf       0       1
dty2018       2.215e+00        Inf       0       1
--------------------------------------------

I have no knowledge of the pglm package and was trying it out on your data without going through the help properly
NBB your DATE column has several formats which do not help

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2350

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paul Bernal
Sent: Wednesday, 24 April 2019 06:44
To: yves.croissant at univ-reunion.fr
Cc: r-help at r-project.org
Subject: [R] Unable to Understand Results of pglm function

Dear Yves,

Hope you are doing great. I have been testing the pglm function from the
pglm package, in order to fit a logit regression to a panel dataset, and I
do not understand the results and/or errors produced by the function, so I
want to be able to understand whether there is a problem with the structure
of my dataset, or I am not using the function properly or if there is
something else going on that I am ignoring. Also, I would like to know what
the start argument is for, or at least an example of how to use it, since I
don?t know how to properly apply it.

Here the details of what I am using and under what environment settings:
1-R version: 3.5.3
2-packages called: plm and pglm
3-Running on a 64-bit Operating System
4-Windows 8

Here is the code with the different things I have tried so far:
> PGLM_Model11 <-
pglm(dataframe3$TRANSIT~dataframe3$Draft+dataframe3$TOTALCOST+dataframe3$BUNKER+dataframe3$CHARTERVALUE,
effect=c("twoways"), model=c("random"), family=binomial('logit'),
index=c("ID","DATE"), start = NULL, data=dataframe3)
>
> summary(PGLM_Model11)
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 0 iterations
Return code 100: Initial value out of range.
--------------------------------------------
>
> PGLM_Model12 <-
pglm(dataframe3$TRANSIT~dataframe3$Draft+dataframe3$TOTALCOST+dataframe3$BUNKER+dataframe3$CHARTERVALUE,
effect=c("twoways"), model=c("pooling"), family=binomial('logit'),
index=c("ID","DATE"), start = NULL, data=dataframe3)
>
> summary(PGLM_Model12)
--------------------------------------------
Maximum Likelihood estimation
Newton-Raphson maximisation, 11 iterations
Return code 2: successive function values within tolerance limit
Log-Likelihood: -14.95426
5  free parameters
Estimates:
                          Estimate Std. error t value Pr(> t)
(Intercept)             93.9680425        Inf       0       1
dataframe3$Draft        -5.3820652        Inf       0       1
dataframe3$TOTALCOST    -0.0001689        Inf       0       1
dataframe3$BUNKER        0.0072934        Inf       0       1
dataframe3$CHARTERVALUE  0.0008862        Inf       0       1
--------------------------------------------
>
> PGLM_Model13 <-
pglm(dataframe3$TRANSIT~dataframe3$Draft+dataframe3$TOTALCOST+dataframe3$BUNKER+dataframe3$CHARTERVALUE,
effect=c("twoways"), model=c("within"), family=binomial('logit'),
index=c("ID","DATE"), start = NULL, data=dataframe3)
Error in maxRoutine(fn = logLik, grad = grad, hess = hess, start = start,
:
  argument "start" is missing, with no default
>
> PGLM_Model14 <-
pglm(dataframe3$TRANSIT~dataframe3$Draft+dataframe3$TOTALCOST+dataframe3$BUNKER+dataframe3$CHARTERVALUE,
effect=c("twoways"), model=c("between"), family=binomial('logit'),
index=c("ID","DATE"), start = NULL, data=dataframe3)
Error in maxRoutine(fn = logLik, grad = grad, hess = hess, start = start,
:
  argument "start" is missing, with no default

Below the dput of the dataset I am using for your reference:

> dput(dataframe3)
structure(list(TRANSIT = c(1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 0L,
1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L,
0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 1L, 0L,
1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L,
1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 0L,
1L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 1L,
0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L,
1L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 0L,
0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L,
0L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
0L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 1L,
1L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 0L,
1L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 0L,
0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 0L,
0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 0L,
1L, 1L, 1L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L,
1L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 1L,
0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 0L,
0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L,
1L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L,
0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L,
0L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L,
0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 1L,
1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
1L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 0L,
0L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L,
0L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L,
1L, 1L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L), ID = c(1L, 1L, 2L, 2L, 3L, 4L, 5L, 5L,
6L, 7L, 7L, 7L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L,
17L, 18L, 19L, 20L, 21L, 21L, 22L, 23L, 24L, 24L, 25L, 26L, 27L,
28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L, 38L, 39L, 40L,
41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L, 48L, 49L, 50L, 51L, 52L,
53L, 54L, 54L, 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 63L, 64L,
65L, 66L, 67L, 67L, 68L, 69L, 70L, 71L, 72L, 73L, 74L, 75L, 76L,
77L, 78L, 79L, 80L, 81L, 82L, 83L, 84L, 85L, 86L, 87L, 88L, 89L,
90L, 91L, 92L, 93L, 93L, 94L, 95L, 96L, 97L, 98L, 99L, 100L,
101L, 102L, 103L, 104L, 105L, 106L, 107L, 108L, 108L, 109L, 110L,
111L, 112L, 113L, 114L, 115L, 115L, 115L, 115L, 116L, 117L, 118L,
119L, 120L, 121L, 122L, 123L, 124L, 125L, 126L, 127L, 128L, 128L,
129L, 130L, 131L, 132L, 133L, 134L, 135L, 136L, 137L, 138L, 139L,
139L, 140L, 140L, 141L, 142L, 143L, 144L, 145L, 145L, 146L, 146L,
147L, 148L, 149L, 149L, 150L, 150L, 150L, 151L, 152L, 153L, 154L,
155L, 156L, 157L, 158L, 159L, 160L, 161L, 162L, 163L, 164L, 165L,
166L, 167L, 168L, 169L, 170L, 171L, 172L, 173L, 174L, 175L, 176L,
177L, 178L, 179L, 180L, 181L, 182L, 182L, 183L, 184L, 185L, 186L,
187L, 188L, 189L, 190L, 191L, 192L, 192L, 193L, 193L, 194L, 195L,
196L, 197L, 198L, 199L, 199L, 200L, 201L, 202L, 203L, 204L, 205L,
206L, 207L, 208L, 208L, 209L, 210L, 211L, 212L, 213L, 214L, 215L,
216L, 217L, 218L, 218L, 219L, 220L, 221L, 222L, 222L, 223L, 224L,
225L, 226L, 227L, 228L, 229L, 230L, 231L, 232L, 233L, 234L, 235L,
236L, 237L, 238L, 239L, 240L, 241L, 241L, 241L, 242L, 243L, 244L,
245L, 246L, 247L, 247L, 248L, 248L, 249L, 249L, 250L, 251L, 252L,
253L, 254L, 255L, 256L, 257L, 258L, 259L, 260L, 261L, 262L, 263L,
264L, 265L, 266L, 267L, 268L, 269L, 270L, 271L, 272L, 273L, 273L,
274L, 275L, 276L, 277L, 278L, 279L, 280L, 281L, 282L, 283L, 284L,
285L, 286L, 287L, 288L, 288L, 289L, 290L, 291L, 292L, 293L, 294L,
295L, 296L, 297L, 298L, 299L, 300L, 301L, 301L, 302L, 303L, 304L,
305L, 306L, 307L, 308L, 308L, 309L, 309L, 309L, 310L, 311L, 312L,
313L, 313L, 314L, 315L, 316L, 317L, 318L, 319L, 320L, 321L, 322L,
323L, 324L, 325L, 326L, 327L, 327L, 328L, 329L, 330L, 331L, 332L,
333L, 334L, 335L, 336L, 337L, 338L, 339L, 340L, 341L, 342L, 343L,
344L, 345L, 346L, 347L, 348L, 349L, 350L, 351L, 352L, 353L, 354L,
354L, 354L, 354L, 355L, 356L, 357L, 358L, 359L, 360L, 361L, 362L,
363L, 364L, 365L, 366L, 367L, 368L, 369L, 370L, 371L, 372L, 373L,
374L, 375L, 376L, 377L, 378L, 379L, 380L, 381L, 382L, 383L, 384L,
385L, 386L, 387L, 388L, 389L, 390L, 391L, 392L, 393L, 394L, 395L,
396L, 397L, 398L, 399L, 400L, 401L, 402L, 402L, 403L, 404L, 405L,
406L, 407L, 408L, 409L, 410L, 411L, 412L, 413L, 413L, 414L, 415L,
416L, 417L, 418L, 419L, 420L, 421L, 422L, 423L, 424L, 425L, 426L,
427L, 428L, 429L, 430L, 431L, 432L, 433L, 434L, 434L, 435L, 436L,
437L, 438L, 439L, 440L, 441L, 442L, 443L, 444L, 445L, 446L, 447L,
448L, 449L, 450L, 451L, 452L, 453L, 454L, 455L, 456L, 457L, 458L,
459L, 460L, 461L, 462L, 463L, 464L, 464L, 465L, 465L, 466L, 467L,
467L, 468L, 468L, 469L, 470L, 471L, 472L, 473L), DATE = structure(c(47L,
75L, 89L, 252L, 3L, 221L, 62L, 99L, 224L, 114L, 154L, 151L, 52L,
9L, 342L, 320L, 370L, 149L, 252L, 112L, 147L, 346L, 231L, 371L,
331L, 171L, 30L, 119L, 366L, 58L, 61L, 103L, 269L, 313L, 373L,
195L, 116L, 376L, 323L, 189L, 245L, 270L, 76L, 258L, 265L, 347L,
178L, 376L, 278L, 311L, 281L, 260L, 203L, 275L, 101L, 150L, 234L,
161L, 231L, 257L, 367L, 254L, 210L, 67L, 21L, 96L, 241L, 331L,
351L, 223L, 309L, 319L, 256L, 12L, 43L, 27L, 28L, 133L, 101L,
266L, 16L, 359L, 370L, 318L, 237L, 78L, 213L, 113L, 337L, 199L,
94L, 330L, 314L, 271L, 328L, 1L, 348L, 244L, 302L, 374L, 208L,
40L, 357L, 232L, 179L, 286L, 193L, 248L, 250L, 284L, 274L, 321L,
289L, 138L, 80L, 253L, 283L, 164L, 133L, 212L, 339L, 59L, 305L,
49L, 162L, 266L, 326L, 11L, 4L, 82L, 65L, 188L, 192L, 334L, 33L,
177L, 221L, 346L, 148L, 86L, 24L, 5L, 89L, 57L, 37L, 338L, 191L,
68L, 218L, 79L, 235L, 254L, 338L, 361L, 4L, 135L, 143L, 123L,
55L, 23L, 18L, 20L, 202L, 128L, 127L, 122L, 156L, 269L, 321L,
276L, 352L, 22L, 7L, 199L, 333L, 145L, 92L, 136L, 311L, 342L,
294L, 325L, 71L, 29L, 25L, 173L, 154L, 85L, 118L, 121L, 44L,
107L, 140L, 151L, 175L, 102L, 108L, 63L, 25L, 51L, 329L, 334L,
345L, 153L, 282L, 304L, 324L, 193L, 367L, 341L, 39L, 231L, 209L,
335L, 321L, 276L, 102L, 91L, 282L, 362L, 68L, 344L, 253L, 98L,
338L, 84L, 251L, 64L, 161L, 227L, 139L, 334L, 365L, 202L, 374L,
159L, 21L, 317L, 42L, 343L, 349L, 292L, 84L, 226L, 194L, 256L,
228L, 336L, 293L, 288L, 155L, 56L, 207L, 89L, 324L, 163L, 157L,
117L, 260L, 341L, 47L, 97L, 320L, 102L, 312L, 348L, 137L, 38L,
27L, 243L, 229L, 123L, 99L, 125L, 54L, 349L, 354L, 290L, 170L,
233L, 308L, 164L, 15L, 142L, 152L, 352L, 306L, 186L, 299L, 289L,
327L, 377L, 255L, 369L, 377L, 272L, 285L, 320L, 324L, 358L, 6L,
70L, 278L, 364L, 278L, 361L, 360L, 316L, 300L, 350L, 368L, 259L,
315L, 374L, 247L, 161L, 318L, 353L, 332L, 190L, 340L, 344L, 291L,
207L, 14L, 372L, 246L, 270L, 344L, 87L, 324L, 295L, 172L, 377L,
257L, 24L, 330L, 167L, 209L, 212L, 236L, 280L, 281L, 268L, 48L,
264L, 53L, 355L, 206L, 115L, 111L, 140L, 50L, 313L, 187L, 375L,
375L, 336L, 217L, 162L, 371L, 239L, 261L, 334L, 371L, 158L, 320L,
350L, 176L, 10L, 309L, 9L, 330L, 204L, 216L, 166L, 363L, 44L,
301L, 279L, 73L, 83L, 328L, 36L, 72L, 35L, 99L, 169L, 321L, 220L,
34L, 215L, 308L, 244L, 88L, 127L, 334L, 14L, 144L, 60L, 69L,
181L, 123L, 45L, 314L, 37L, 258L, 245L, 250L, 242L, 361L, 9L,
132L, 191L, 7L, 165L, 296L, 186L, 356L, 342L, 197L, 136L, 122L,
126L, 193L, 310L, 200L, 311L, 344L, 355L, 297L, 106L, 46L, 238L,
311L, 160L, 262L, 129L, 168L, 120L, 211L, 90L, 41L, 319L, 32L,
131L, 110L, 185L, 222L, 298L, 201L, 143L, 13L, 273L, 229L, 182L,
76L, 95L, 253L, 88L, 307L, 354L, 198L, 64L, 286L, 267L, 124L,
21L, 26L, 257L, 19L, 242L, 341L, 240L, 174L, 249L, 322L, 8L,
109L, 17L, 134L, 93L, 183L, 158L, 245L, 205L, 130L, 31L, 287L,
271L, 277L, 327L, 184L, 263L, 2L, 196L, 60L, 186L, 303L, 50L,
250L, 141L, 166L, 219L, 248L, 156L, 230L, 350L, 329L, 146L, 313L,
66L, 315L, 77L, 225L, 105L, 180L, 104L, 219L, 80L, 190L, 156L,
81L, 74L, 25L, 100L, 214L), .Label = c("1-Aug-17", "1-Aug-18",
"1-Feb-18", "1-Jan-18", "1-Jul-17", "1-Mar-18", "1-Nov-17", "1-Oct-17",
"1-Sep-17", "10-Apr-18", "10-Aug-17", "10-Dec-17", "10-Feb-18",
"10-Jul-17", "10-Jul-18", "10-Mar-18", "10-May-18", "10-Nov-17",
"10-Oct-17", "10-Sep-17", "11-Apr-18", "11-Aug-17", "11-Aug-18",
"11-Dec-17", "11-Feb-18", "11-Jun-18", "11-Mar-18", "11-Sep-17",
"11-Sep-18", "12-Aug-17", "12-Dec-17", "12-Jul-17", "12-Jul-18",
"12-Mar-18", "12-May-18", "12-Oct-17", "12-Sep-18", "13-Aug-18",
"13-Dec-17", "13-Nov-17", "13-Oct-17", "14-Jun-18", "14-Sep-17",
"15-Dec-17", "15-Feb-18", "15-Jul-18", "15-Mar-18", "15-May-18",
"15-Sep-18", "16-Apr-18", "16-Dec-17", "16-Sep-18", "17-Apr-18",
"17-Aug-18", "17-Feb-18", "17-Jan-18", "17-Jul-17", "17-Jul-18",
"17-Jun-18", "17-Mar-18", "17-May-18", "17-Nov-17", "17-Oct-17",
"18-Apr-18", "18-Aug-18", "18-Dec-17", "18-Feb-18", "18-Jul-17",
"18-Jul-18", "18-Jun-18", "18-Mar-18", "18-May-18", "18-Sep-17",
"19-Apr-18", "19-Aug-18", "19-Jan-18", "19-Jul-17", "19-May-18",
"19-Sep-17", "2-Aug-18", "2-Jun-18", "2-May-18", "2-Oct-17",
"2-Sep-17", "2-Sep-18", "20-Aug-17", "20-Dec-17", "20-Feb-18",
"20-Jul-17", "20-Jul-18", "20-Jun-18", "20-Oct-17", "20-Sep-18",
"21-Apr-18", "21-Aug-17", "21-Dec-17", "21-Feb-18", "21-Jan-18",
"21-Mar-18", "21-Nov-17", "21-Oct-17", "21-Sep-17", "21-Sep-18",
"22-Apr-18", "22-Aug-17", "22-Feb-18", "22-Jul-17", "22-May-18",
"22-Nov-17", "23-Aug-17", "23-Aug-18", "23-Dec-17", "23-Feb-18",
"23-Jul-17", "23-Nov-17", "23-Sep-18", "24-Aug-18", "24-Dec-17",
"24-Jan-18", "24-Jul-17", "24-May-18", "24-Nov-17", "24-Oct-17",
"25-Apr-18", "25-Aug-18", "25-Jul-17", "25-May-18", "25-Nov-17",
"25-Oct-17", "25-Sep-17", "25-Sep-18", "26-Apr-18", "26-Aug-18",
"26-Jan-18", "26-Jul-17", "26-Jul-18", "26-Mar-18", "26-May-18",
"27-Apr-18", "27-Aug-17", "27-Aug-18", "27-Dec-17", "27-Jul-18",
"27-Nov-17", "27-Sep-18", "28-Aug-17", "28-Dec-17", "28-Feb-18",
"28-Jul-17", "28-Jun-18", "28-Mar-18", "28-May-18", "28-Nov-17",
"28-Oct-17", "28-Sep-17", "29-Aug-18", "29-Dec-17", "29-Jan-18",
"29-Jul-17", "29-Jul-18", "29-Jun-18", "29-Mar-18", "29-Nov-17",
"29-Oct-17", "29-Sep-17", "3-Apr-18", "3-Aug-17", "3-Dec-17",
"3-Jan-18", "3-Jul-17", "3-May-18", "3-Nov-17", "3-Sep-17", "3-Sep-18",
"30-Apr-18", "30-Aug-18", "30-Jan-18", "30-Jul-17", "30-Jun-18",
"30-Mar-18", "30-May-18", "30-Sep-18", "31-Aug-17", "31-Dec-17",
"31-Jan-18", "31-Jul-17", "31-Jul-18", "31-May-18", "31-Oct-17",
"4-Dec-17", "4-Feb-18", "4-Jan-18", "4-Mar-18", "4-Nov-17", "4-Oct-17",
"4-Sep-18", "5-Aug-17", "5-Dec-17", "5-Feb-18", "5-Jan-18", "5-Jul-17",
"5-Mar-18", "5-May-18", "5-Nov-17", "5-Sep-17", "6-Aug-17", "6-Jun-18",
"6-Mar-18", "6-Nov-17", "6-Sep-17", "6-Sep-18", "7-Apr-18", "7-Aug-17",
"7-Feb-18", "7-Jan-18", "7-Jul-17", "7-Jul-18", "7-Sep-17", "8-Apr-18",
"8-Aug-18", "8-Dec-17", "8-Mar-18", "8-May-18", "8-Nov-17", "8-Sep-18",
"9-Apr-18", "9-Aug-17", "9-Aug-18", "9-Feb-18", "9-Mar-18", "9-Nov-17",
"9-Oct-17", "April 23 2018", "April 5 2018", "August 14 2017",
"August 15 2017", "August 24 2017", "August 25 2017", "August 26 2017",
"August 30 2017", "August 6 2017", "August 7 2017", "August 8 2017",
"December 1 2017", "December 10 2017", "December 11 2017", "December 12
2017",
"December 13 2017", "December 14 2017", "December 15 2017", "December 18
2017",
"December 19 2017", "December 21 2017", "December 22 2017", "December 24
2017",
"December 27 2017", "December 28 2017", "December 29 2017", "December 3
2017",
"December 30 2017", "December 4 2017", "December 5 2017", "December 6
2017",
"February 1 2018", "February 10 2018", "February 12 2018", "February 13
2018",
"February 15 2018", "February 16 2018", "February 19 2018", "February 20
2018",
"February 25 2018", "February 28 2018", "February 3 2018", "February 4
2017",
"February 5 2018", "February 8 2018", "January 1 2018", "January 10 2018",
"January 11 2018", "January 13 2018", "January 14 2018", "January 15 2018",
"January 20 2018", "January 23 2018", "January 24 2018", "January 26 2018",
"January 29 2018", "January 3 2018", "January 30 2018", "January 31 2018",
"January 4 2018", "January 6 2018", "January 7 2018", "January 8 2018",
"January 9 2018", "July 13 2018", "July 30 2017", "June 17 2018",
"June 8 2018", "March 10 2018", "March 13 2018", "March 18 2018",
"March 22 2018", "March 24 2018", "March 28 2018", "March 3 2018",
"November 1 2017", "November 10 2017", "November 11 2017", "November 12
2017",
"November 13 2017", "November 15 2017", "November 17 2017", "November 18
2017",
"November 19 2017", "November 21 2017", "November 22 2017", "November 23
2017",
"November 25 2017", "November 27 2017", "November 28 2017", "November 3
2017",
"November 4 2017", "November 5 2017", "November 6 2017", "November 7 2017",
"November 8 2017", "November 9 2017", "October 1 2017", "October 10 2017",
"October 11 2017", "October 12 2017", "October 14 2017", "October 15 2017",
"October 16 2017", "October 17 2017", "October 18 2017", "October 19 2017",
"October 20 2017", "October 21 2017", "October 23 2017", "October 25 2017",
"October 26 2017", "October 27 2017", "October 28 2017", "October 29 2017",
"October 3 2017", "October 30 2017", "October 31 2017", "October 4 2017",
"October 5 2017", "October 6 2017", "October 7 2017", "October 9 2017",
"September 1 2017", "September 10 2017", "September 11 2017",
"September 12 2017", "September 13 2017", "September 15 2017",
"September 16 2017", "September 17 2017", "September 19 2017",
"September 21 2017", "September 22 2017", "September 24 2017",
"September 26 2017", "September 27 2017", "September 29 2017",
"September 3 2017", "September 30 2017", "September 5 2017",
"September 6 2017", "September 7 2017", "September 8 2017", "September 9
2017"
), class = "factor"), SHIPNAME = structure(c(295L, 295L, 151L,
151L, 19L, 41L, 292L, 292L, 201L, 148L, 148L, 148L, 148L, 413L,
39L, 74L, 460L, 54L, 462L, 8L, 22L, 347L, 307L, 354L, 311L, 296L,
297L, 297L, 118L, 279L, 230L, 230L, 340L, 358L, 473L, 271L, 309L,
451L, 40L, 404L, 120L, 127L, 209L, 90L, 274L, 260L, 252L, 344L,
165L, 363L, 356L, 425L, 192L, 133L, 56L, 440L, 439L, 276L, 361L,
333L, 273L, 308L, 235L, 235L, 426L, 234L, 93L, 111L, 325L, 283L,
107L, 48L, 101L, 212L, 246L, 400L, 338L, 338L, 422L, 20L, 369L,
471L, 7L, 409L, 412L, 310L, 70L, 157L, 357L, 103L, 452L, 49L,
349L, 4L, 226L, 465L, 362L, 128L, 264L, 136L, 50L, 18L, 323L,
11L, 11L, 25L, 408L, 302L, 180L, 394L, 113L, 434L, 477L, 461L,
305L, 174L, 104L, 152L, 132L, 291L, 410L, 250L, 382L, 351L, 23L,
119L, 284L, 480L, 480L, 480L, 480L, 457L, 272L, 262L, 81L, 346L,
239L, 58L, 149L, 402L, 373L, 82L, 251L, 244L, 244L, 135L, 24L,
345L, 156L, 227L, 324L, 215L, 222L, 286L, 55L, 281L, 281L, 280L,
280L, 322L, 393L, 243L, 34L, 418L, 418L, 334L, 334L, 221L, 220L,
6L, 6L, 479L, 479L, 479L, 166L, 196L, 298L, 71L, 160L, 282L,
213L, 147L, 315L, 433L, 458L, 207L, 208L, 186L, 91L, 326L, 466L,
421L, 420L, 98L, 399L, 289L, 134L, 123L, 194L, 173L, 248L, 64L,
202L, 206L, 95L, 396L, 396L, 131L, 211L, 391L, 38L, 84L, 455L,
144L, 168L, 389L, 398L, 398L, 35L, 35L, 367L, 359L, 360L, 105L,
73L, 431L, 430L, 372L, 62L, 312L, 470L, 263L, 86L, 275L, 219L,
414L, 96L, 125L, 365L, 478L, 342L, 45L, 241L, 75L, 121L, 355L,
380L, 379L, 216L, 191L, 417L, 395L, 395L, 31L, 210L, 467L, 146L,
397L, 179L, 181L, 29L, 171L, 482L, 240L, 288L, 330L, 368L, 287L,
401L, 321L, 217L, 233L, 233L, 233L, 366L, 247L, 89L, 472L, 336L,
364L, 364L, 124L, 124L, 163L, 163L, 5L, 37L, 237L, 332L, 183L,
184L, 444L, 442L, 339L, 126L, 293L, 232L, 150L, 203L, 53L, 475L,
468L, 327L, 172L, 481L, 61L, 424L, 2L, 28L, 28L, 224L, 304L,
423L, 66L, 384L, 335L, 387L, 42L, 195L, 200L, 383L, 114L, 443L,
301L, 68L, 67L, 72L, 214L, 386L, 352L, 381L, 65L, 218L, 266L,
102L, 51L, 178L, 30L, 137L, 137L, 175L, 161L, 1L, 448L, 446L,
3L, 190L, 189L, 278L, 278L, 278L, 299L, 116L, 143L, 44L, 43L,
130L, 285L, 328L, 170L, 185L, 87L, 140L, 437L, 145L, 245L, 155L,
261L, 258L, 331L, 85L, 16L, 257L, 204L, 13L, 154L, 459L, 117L,
94L, 320L, 225L, 314L, 259L, 14L, 456L, 162L, 142L, 26L, 303L,
432L, 231L, 435L, 392L, 313L, 370L, 474L, 464L, 450L, 450L, 450L,
450L, 438L, 182L, 236L, 92L, 164L, 79L, 80L, 77L, 169L, 177L,
153L, 176L, 329L, 353L, 341L, 454L, 69L, 238L, 242L, 269L, 268L,
267L, 115L, 108L, 199L, 52L, 27L, 59L, 198L, 197L, 253L, 436L,
306L, 106L, 447L, 378L, 316L, 318L, 99L, 407L, 411L, 36L, 453L,
167L, 63L, 158L, 188L, 377L, 376L, 32L, 193L, 463L, 129L, 429L,
9L, 17L, 449L, 21L, 76L, 78L, 78L, 319L, 33L, 390L, 388L, 343L,
406L, 159L, 270L, 223L, 337L, 88L, 141L, 469L, 100L, 441L, 300L,
290L, 445L, 46L, 415L, 294L, 294L, 110L, 12L, 229L, 97L, 138L,
263L, 249L, 265L, 385L, 405L, 47L, 205L, 350L, 416L, 348L, 476L,
254L, 57L, 15L, 427L, 255L, 428L, 122L, 109L, 60L, 403L, 256L,
10L, 371L, 112L, 112L, 419L, 419L, 83L, 317L, 317L, 277L, 277L,
187L, 228L, 375L, 374L, 139L), .Label = c("Aby Jeannette", "Adelante",
"ADM Georgina", "ADS Galtesund", "Aeneas", "Aeolian Fortune",
"Aeolian Light", "AFRICA GRAECA", "AFRICAN ARROW", "AFRICAN BARI BIRD",
"AFRICAN BLUE CRANE", "AFRICAN FINFOOT", "AFRICAN JACANA", "AFRICAN KITE",
"AFRICAN LEOPARD", "AFRICAN PUFFIN", "AFRICAN RAPTOR", "AFTERHOURS",
"AGIA SKEPI", "Agri Kinsale", "Aiantas", "AKILI", "ALAM MANIS",
"ALBION", "Alexandra", "ALICIA", "Alma", "Alpha Vision", "AM BREMEN",
"AMAMI K", "AMIS ACE", "AMIS FORTUNE", "AMIS JUSTICE", "AMSTEL FALCON",
"Andros", "ANDROS ISLAND", "Androusa", "ANIMA", "Anna S", "Anna Smile",
"ANTIGONI", "Antiparos", "Aom Gaia", "AOM GAIA", "Aom Milena",
"APEX", "AREQUIPA QUEEN", "Ariana", "Artemis", "ASHIYA STAR",
"ASTRA CENTAURUS", "ASTREA", "Athina Carras", "ATLANTIC EAGLE",
"ATLANTIC GRACE", "ATLANTIC HERO", "ATLANTIC MANZANILLO", "Attalia",
"Axios", "Bahia Blanca", "Bali", "BALTIC K", "BALTIC WASP", "BBG Ambition",
"BBG Dream", "BBG Endeavor", "Belo Horizonte", "BELO HORIZONTE",
"BLUE AKIHABARA", "BLUE DIAMOND", "BLUE MARLIN I", "Bora", "Brasil SW",
"Braveheart", "BRIDGEGATE", "BRIGITTE", "BTG Denali", "BTG Eiger",
"BTG Everest", "BTG Kailach", "BULK ARGENTINA", "BULK COLOMBIA",
"BULK HERO", "BULK HONDURAS", "Bulk Pegasus", "Bulk Portugal",
"BW Hazel", "Captain Adams", "Captain Antonis", "Cemtex Wisdom",
"CENTENARIO BLU", "Cepheus Ocean", "Cerafina", "Cetus Ocean",
"CF Diamond", "CHARADE", "CHLOE", "CLARKE QUAY", "CLIPPER AMSTERDAM",
"Clipper Victory", "CMB Sakura", "Cofco 1", "COLUMBIA RIVER",
"Coral Diamond", "COREFORTUNE OL", "Cosmar", "Coventry", "CP GUANGZHOU",
"Crimson Ark", "Crimson Kingdom", "Cymona Star", "DALIAN STAR",
"De Xu Hai", "Densa Pelican", "DESERT CHALLENGER", "DEVON BAY",
"DIAMOND QUEEN", "Dias", "Dimitris Apesakis", "Donousa", "DORIC",
"DORIC SHOGUN", "DORO", "EASTER N", "Efrain A", "Egret Oasis",
"Eirini P", "Elena", "Emerald Dongji", "Emerald Star", "ENDLESS HORIZON",
"ENY", "Erikoussa", "ESSEX STRAIT", "Eternal Bliss", "Eternal Grace",
"EUROPA BAY", "Ever Grace", "EVER SOVEREIGN", "Everglory", "Evmar",
"FEDERAL TRIDENT", "FH Fang Cheng", "FH Rizhao", "Fiji", "FILIA JOY",
"Flag Lama", "FLIPPER", "FLORINDA", "Fortune Harmony", "FORTUNE LADY",
"FORTUNE UNITY", "FRAMURA", "FURNESS VICTORIA", "Galio", "GANNET BULKER",
"GENCO RAPTOR", "GH CITATION", "GH URBAN SEA", "Giorgakis", "Giorgis",
"GLOBAL PRIME", "GLOBAL SUCCESS", "GLOBAL VISION", "Glory", "Golden Jake",
"GOLDEN LIBRA", "Good Wish", "Graecia Aeterna", "GRAND CONCORD",
"GRAND MARCIA", "Great Rich", "GUARDIANSHIP", "Hampton Bay",
"Hampton Bridge", "HANTON TRADER I", "Hercules Ocean", "Hermes",
"Hong Hing", "Hong Jing", "Hong Sheng", "HOPA I", "Huayang Spirit",
"Huayeng Dream", "Indian Harmony", "INDIGO EVOLUTION", "INDIGO RIVER",
"INDRA OLDENDORFF", "Innovation", "INNOVATION", "Inspiration",
"IRIS HALO", "IRIS OLDENDORFF", "ISMENE", "Istria", "IYO WIND",
"Jag Aalok", "Jag Akshay", "Jag Arnav", "JIA SHENG SHAN", "JIN RUN",
"Jin Zhu Hai", "John M. Carras", "JOSCO HANGZHOU", "JPS AFRODITI",
"K SPINEL", "K. GARNET", "K. OPAL", "KANG CHENG", "Karlovasi",
"Katerina III", "KAVO PALOMA", "Kea", "Kerkyra", "Key Evolution",
"Key Pacifico", "KING ISLAND", "KING MILO", "KM Fukuyama", "KM Hong Kong",
"KM Keelung", "KM Yokohama", "KMARIN SINGAPORE", "KT Birdie",
"KYRA PANAGHIA", "Lady I", "LEO ADVANCE", "LESEDI QUEEN", "LILA",
"LISSA TOPIC", "LOCH SHUNA", "Long Dar", "LOUISIANA MAMA", "LOWLANDS
MAINE",
"LUMINOUS HALO", "LUNITA", "LYRIC HARMONY", "Macheras", "MALMO",
"MANDARIN CROWN", "MANDARIN NOBLE", "Marathassa", "MARIE GRACE",
"MARINER", "MARITIME PROSPERITY", "MARY LINA", "Mastro Nikos",
"MBA Future", "Medi Matsuura", "MEDI SALERNO", "MELBOURNE", "MELIA",
"METSOVO", "MG Explorer", "MG Kronos", "MG Sakura", "Miao Xiang",
"MISATO K", "Mistral I", "Miyama", "Mykonos", "Myra", "Myrto",
"N Bonanza", "Nadeshiko", "Naias", "NAUTICAL MARIE", "NAUTICAL RUNA",
"NAUTICAL SIF", "Navios Amber", "NAVIOS ARC", "NAVIOS ARMONIA",
"Navios Harmony", "Navios Orbiter", "NAVIOS SOUTHERN STAR", "NEFELI",
"NEW BLISS", "NEW DIRECTION", "NEWSEAS PEARL", "NIKKEI SIRIUS",
"NIKKEI VERDE", "Nikolaos", "NIKOLAS XL", "Nikomarin", "Nord Capella",
"Nord Fortune", "NOSHIMA", "Nuri Bey", "OCCITAN PAUILLAC", "OCEAN BAO",
"OCEAN BELT", "OCEAN FAVOUR", "Ocean Garlic", "OCEAN HARVEST",
"OCEAN PRIDE", "OCEAN PRINCE", "OCEAN PRINCESS", "OCEAN ROYAL",
"OCEAN SPLENDOR", "OCEAN TIANBAO", "OCEAN VENUS", "Ocean Wind",
"Oceana", "Odysseas L", "OKINAWA", "Olivia R", "OLYMPOS", "Omicron Light",
"OMICRON NIKOS", "OMICRON SKY", "Omicron Trader", "ORCHID HALO",
"Orient Genesis", "ORIENT GRACE", "OZGUR AKSOY", "PACIFIC ADVANCE",
"PACIFIC NEXUS", "PACIFIC TALENT", "PACIFIC VICTORY", "Palais",
"Pan Ceres", "PAN VIVA", "Panafrican", "Panamanian", "Panasiatic",
"PANORIA", "Panther Max", "PARADISE ISLAND", "PAUL OLDENDORFF",
"Peace Ark", "PEAK PEGASUS", "Pedhoulas Farmer", "Pedhoulas Trader",
"PENTA", "PERIDOT", "PERTH I", "Phaedra", "PHOENIX K", "Phoenix Ocean",
"Pictor", "PILATUS VENTURE", "Popi S", "PORT ESTRELA", "Proteas",
"QUEEN JHANSI", "QUEEN KOBE", "Rave", "RB Eden", "Real Happiness",
"RECCO", "REGAL", "RESURGENCE", "RIGI VENTURE", "Rosalia D? Amato",
"Rosco Banyan", "Rosco Cypress", "Rosco Ginkgo", "Rosco Lemon",
"Rosco Litchi", "Rosco Palm", "ROSCO PLUM", "Rosco Poplar", "Rosco
Sandalwood",
"RR Australia", "SAGAR JYOTI", "SAGAR SHAKTI", "SAGARJEET", "SAGE
COLORADO",
"SAGE PIONEER", "SAILING SKY", "Sakizaya Power", "SAN ANTONIO",
"SANTA KATARINA", "SANTA VALENTINA", "SANYU", "SBI Bolero", "SBI BOLERO",
"SBI Samba", "Scarlet Cardinal", "SCARLET CARDINAL", "Scarlet Falcon",
"Sea Duty", "Sea Hermes", "Sea Pegasus", "SEA PIONEER", "Sea Pluto",
"Seatribute", "Shandong Fu Hui", "Shandong Hai Chang", "Shangdong Fu Ze",
"Shao Shan 5", "Shao Shan 8", "SIFNOS", "Silver Dragon", "SIMURGH",
"Skiathos", "SKY KNIGHT", "SONGA GLORY", "SOUTHEND", "SPARNA",
"SPRING AEOLIAN", "SPRING EAGLE", "SPRING ZEPHYR", "SSI CHALLENGER",
"Stalo", "STAMFORD EAGLE", "STAR AQUARIUS", "STAR JENNIFER",
"Star Laura", "Star of Sawara", "STAR PISCES", "Star Renee",
"STAR VANESSA", "STARRY SKY", "STH LONDON", "STOVE FRIEND", "STOVE OCEAN",
"SUNLEAF GRACE", "SUNLEAF STAR", "SUNNY HOPE", "SUNNY ROYAL",
"SUZAKU", "Syros I", "Tahiti One", "Tai Promotion", "TAI PROSPERITY",
"TAI SPRING", "TAI STAR", "TAI SUMMIT", "Tangerine Island", "TANGERINE
ISLAND",
"TANIKAZE", "TASSOS N", "Taurus Ocean", "TEAL BULKER", "TENRO MARU",
"Tenten", "THEMISTOCLES", "Theodor Oldendorff", "THEODOR OLDENDORFF",
"Theodore Jr.", "Theresa Hebei", "Theresa Jilin", "Theresa Shandong",
"TIGER HENAN", "TIGER NORTH", "TIGER PIONEER", "Tiger South",
"TN SUNRISE", "TOMORROW", "Topaz", "TORENIA", "TR Lady", "Trade Unity",
"TRANS OCEANIC", "TRUSTN TRADER II", "TSCHAIKOWSKY", "TTM DRAGON",
"Tuo Fu 6", "Tycoon", "ULTRA PANTHER", "Unity", "UNITY DISCOVERY",
"Valadon", "VEGA ROSE", "VELA OCEAN", "VENUS", "VENUS HALO",
"VICTORIA", "VISHVA ANAND", "Vitahorizon", "Vitakosmos", "Vivian",
"VSC CASTOR", "VSC TRITON", "XING XI HAI", "Yarrawonga", "Yue Guan Feng",
"ZEN-NOH GRAIN MAGNOLIA", "ZEN-NOH GRAIN PEGASUS", "Zheng Zhi",
"Zhi He"), class = "factor"), Draft = c(12L, 12L, 12L, 13L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 14L, 14L, 14L, 12L,
13L, 12L, 12L, 14L, 12L, 14L, 13L, 12L, 12L, 12L, 14L, 12L, 12L,
11L, 13L, 13L, 14L, 12L, 12L, 13L, 14L, 12L, 13L, 13L, 12L, 14L,
14L, 13L, 12L, 14L, 14L, 13L, 14L, 14L, 12L, 13L, 12L, 12L, 13L,
12L, 12L, 14L, 14L, 14L, 12L, 12L, 12L, 12L, 14L, 13L, 14L, 12L,
13L, 14L, 13L, 12L, 12L, 12L, 12L, 12L, 12L, 14L, 12L, 14L, 13L,
14L, 14L, 12L, 12L, 12L, 14L, 12L, 12L, 13L, 14L, 13L, 13L, 12L,
14L, 13L, 13L, 14L, 12L, 12L, 14L, 12L, 12L, 14L, 12L, 13L, 13L,
14L, 14L, 14L, 14L, 12L, 12L, 14L, 13L, 12L, 12L, 12L, 13L, 12L,
14L, 12L, 12L, 14L, 14L, 12L, 12L, 12L, 12L, 12L, 12L, 13L, 12L,
12L, 12L, 13L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 14L, 12L, 12L,
12L, 12L, 14L, 14L, 14L, 14L, 10L, 12L, 11L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 13L, 14L, 14L, 14L, 12L, 12L, 12L,
14L, 12L, 12L, 12L, 14L, 14L, 14L, 14L, 12L, 12L, 11L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 10L, 12L, 12L, 12L, 11L,
13L, 14L, 14L, 12L, 13L, 14L, 14L, 12L, 13L, 14L, 12L, 12L, 12L,
14L, 13L, 14L, 12L, 12L, 14L, 14L, 12L, 14L, 13L, 12L, 14L, 12L,
14L, 12L, 12L, 12L, 12L, 14L, 13L, 12L, 13L, 12L, 12L, 14L, 12L,
14L, 14L, 14L, 12L, 12L, 12L, 13L, 12L, 14L, 14L, 14L, 12L, 12L,
12L, 12L, 13L, 12L, 12L, 12L, 14L, 14L, 12L, 12L, 14L, 12L, 14L,
14L, 12L, 12L, 12L, 13L, 12L, 12L, 12L, 12L, 12L, 14L, 14L, 13L,
12L, 13L, 14L, 12L, 12L, 12L, 12L, 13L, 14L, 12L, 14L, 13L, 14L,
14L, 14L, 14L, 14L, 13L, 14L, 14L, 13L, 14L, 12L, 12L, 14L, 14L,
14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 13L, 12L, 14L,
14L, 14L, 12L, 14L, 14L, 14L, 12L, 12L, 14L, 14L, 14L, 14L, 12L,
14L, 14L, 12L, 14L, 14L, 12L, 13L, 12L, 12L, 12L, 14L, 14L, 13L,
14L, 12L, 13L, 13L, 13L, 12L, 12L, 12L, 12L, 12L, 14L, 12L, 14L,
13L, 14L, 12L, 12L, 14L, 13L, 14L, 14L, 14L, 12L, 14L, 14L, 12L,
12L, 14L, 12L, 14L, 12L, 12L, 12L, 14L, 12L, 13L, 14L, 12L, 12L,
14L, 12L, 12L, 12L, 12L, 12L, 14L, 12L, 12L, 12L, 14L, 14L, 12L,
12L, 14L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 14L, 12L, 13L, 13L,
13L, 14L, 14L, 12L, 12L, 12L, 12L, 12L, 13L, 12L, 14L, 13L, 12L,
12L, 12L, 12L, 12L, 13L, 12L, 14L, 13L, 13L, 13L, 11L, 12L, 14L,
14L, 12L, 14L, 12L, 11L, 12L, 12L, 12L, 12L, 14L, 12L, 12L, 12L,
12L, 14L, 14L, 12L, 12L, 12L, 14L, 12L, 12L, 12L, 12L, 14L, 12L,
13L, 14L, 12L, 12L, 14L, 14L, 12L, 12L, 12L, 13L, 12L, 14L, 14L,
14L, 12L, 14L, 13L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 13L, 6L,
12L, 12L, 14L, 14L, 14L, 14L, 12L, 14L, 12L, 12L, 12L, 12L, 14L,
12L, 14L, 12L, 12L, 12L, 14L, 12L, 12L, 13L, 14L, 12L, 13L, 12L,
14L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L), TOTALCOST = c(194364L, 219364L, 198260L, 237456L,
197159L, 198992L, 194337L, 219337L, 199198L, 196604L, 230607L,
196604L, 196604L, 194496L, 238600L, 236936L, 237476L, 197220L,
236950L, 197300L, 182042L, 237938L, 199221L, 237475L, 239190L,
157406L, 157211L, 182211L, 237475L, 182475L, 181599L, 156599L,
238269L, 238402L, 238069L, 161436L, 225031L, 238180L, 237572L,
189861L, 239005L, 239049L, 163814L, 240064L, 239171L, 238410L,
200878L, 239019L, 239087L, 239350L, 239352L, 240275L, 164844L,
238400L, 225158L, 202495L, 239681L, 201791L, 226863L, 244092L,
244590L, 239171L, 189811L, 219412L, 228480L, 203650L, 237514L,
247451L, 244739L, 211770L, 244308L, 239197L, 238419L, 224977L,
157362L, 162434L, 162434L, 162434L, 162434L, 239681L, 163316L,
237265L, 243920L, 244088L, 244163L, 202256L, 159592L, 201346L,
239187L, 189800L, 191959L, 239476L, 239171L, 238087L, 238052L,
164169L, 245057L, 244215L, 240812L, 239156L, 156879L, 197853L,
245367L, 164710L, 164710L, 244192L, 211110L, 239156L, 244213L,
237504L, 239018L, 241150L, 244447L, 238506L, 210298L, 243482L,
239166L, 159489L, 184600L, 226439L, 239127L, 235243L, 244296L,
159696L, 189046L, 244355L, 244446L, 187595L, 162595L, 162595L,
162595L, 170604L, 188774L, 244103L, 188680L, 163611L, 200551L,
244055L, 170606L, 169154L, 194154L, 170905L, 200551L, 191412L,
166412L, 243969L, 170483L, 210719L, 168554L, 164016L, 245158L,
245131L, 245186L, 239166L, 116360L, 155698L, 155698L, 155698L,
155698L, 223827L, 191968L, 159650L, 189999L, 201193L, 201011L,
226218L, 201218L, 243970L, 244291L, 243993L, 243993L, 236035L,
236035L, 236035L, 244070L, 159692L, 194183L, 169110L, 241994L,
238216L, 238301L, 242948L, 169810L, 189280L, 164662L, 164156L,
189156L, 163989L, 163924L, 159577L, 159650L, 170566L, 170598L,
188975L, 189006L, 99983L, 191595L, 166907L, 228744L, 166621L,
243593L, 244001L, 239035L, 172934L, 238288L, 241665L, 241665L,
193991L, 238361L, 238361L, 164215L, 168867L, 194304L, 241732L,
237745L, 237911L, 195374L, 195374L, 244044L, 244044L, 169118L,
244040L, 244040L, 198518L, 244106L, 236206L, 244136L, 191390L,
164516L, 165137L, 232682L, 244021L, 244101L, 236136L, 244101L,
194181L, 169181L, 244058L, 212313L, 238240L, 242502L, 239175L,
166221L, 184500L, 170027L, 237701L, 211035L, 244050L, 243745L,
242782L, 164482L, 166341L, 189482L, 174552L, 244213L, 190960L,
184494L, 169116L, 239123L, 239121L, 165097L, 206396L, 241738L,
165622L, 242651L, 250331L, 178778L, 169133L, 238280L, 244044L,
193182L, 194156L, 194156L, 169156L, 196240L, 244060L, 244060L,
244060L, 196050L, 243546L, 243546L, 195500L, 195500L, 170389L,
195389L, 243549L, 243503L, 211398L, 243510L, 238436L, 238546L,
243907L, 243654L, 238709L, 238656L, 244171L, 244136L, 243215L,
243957L, 243957L, 164455L, 164455L, 243287L, 238203L, 243738L,
243266L, 243294L, 243548L, 243262L, 243262L, 237628L, 243266L,
243382L, 243927L, 243574L, 168364L, 243598L, 243596L, 243647L,
191094L, 243655L, 244550L, 243907L, 200636L, 210208L, 243632L,
243632L, 243367L, 243048L, 212125L, 244651L, 243357L, 202542L,
243778L, 243502L, 170036L, 237911L, 195234L, 195220L, 170220L,
239391L, 244397L, 244397L, 238631L, 225921L, 244034L, 244051L,
243310L, 189976L, 164976L, 164976L, 164999L, 165154L, 243439L,
211003L, 244034L, 243859L, 243859L, 170008L, 175602L, 238078L,
243484L, 243619L, 243333L, 243289L, 200618L, 243392L, 243376L,
164873L, 235797L, 243930L, 191502L, 243906L, 195351L, 170527L,
195307L, 243551L, 175551L, 244759L, 238122L, 178863L, 170249L,
243701L, 200549L, 236254L, 189982L, 163055L, 203863L, 243561L,
165089L, 164574L, 193750L, 238061L, 240569L, 175435L, 164313L,
243153L, 189825L, 189825L, 164825L, 189825L, 164340L, 203691L,
168483L, 243970L, 193608L, 243054L, 243115L, 243115L, 243043L,
243115L, 201917L, 204065L, 177917L, 178745L, 178735L, 243911L,
200920L, 242726L, 243042L, 204204L, 181109L, 179157L, 200093L,
179164L, 243676L, 235476L, 243862L, 243873L, 243945L, 243927L,
168102L, 168102L, 243734L, 243929L, 179053L, 246381L, 204130L,
200546L, 200301L, 174699L, 199699L, 178309L, 243549L, 204424L,
216428L, 203785L, 204101L, 245074L, 243224L, 163661L, 179036L,
199248L, 243458L, 199190L, 200330L, 200406L, 174754L, 243138L,
195257L, 244796L, 243069L, 179132L, 204171L, 243718L, 243719L,
200616L, 175749L, 179010L, 243037L, 178405L, 243953L, 243923L,
243485L, 200891L, 239635L, 243661L, 204041L, 179002L, 204070L,
206036L, 198896L, 164487L, 166891L, 246375L, 200217L, 179153L,
210112L, 243941L, 243052L, 243724L, 246328L, 164311L, 243736L,
154373L, 192956L, 237690L, 193282L, 244901L, 198985L, 246315L,
179272L, 204007L, 202386L, 246315L, 202386L, 178856L, 243704L,
243750L, 164533L, 246330L, 204082L, 243790L, 189359L, 164359L,
168286L, 168286L, 175262L, 164395L, 189395L, 164299L, 189299L,
189110L, 154953L, 166251L, 175373L, 235883L), BUNKER = c(350L,
405L, 276L, 350L, 373L, 355L, 370L, 343L, 345L, 288L, 313L, 358L,
440L, 292L, 318L, 360L, 318L, 288L, 350L, 349L, 350L, 318L, 345L,
313L, 313L, 378L, 298L, 363L, 315L, 435L, 423L, 440L, 343L, 355L,
313L, 318L, 435L, 313L, 345L, 318L, 349L, 353L, 368L, 362L, 348L,
345L, 296L, 313L, 365L, 355L, 368L, 362L, 378L, 348L, 313L, 418L,
348L, 418L, 345L, 362L, 318L, 350L, 300L, 343L, 348L, 349L, 298L,
313L, 303L, 388L, 370L, 360L, 362L, 338L, 313L, 350L, 313L, 423L,
313L, 343L, 353L, 313L, 318L, 360L, 292L, 423L, 298L, 343L, 313L,
367L, 368L, 303L, 355L, 353L, 370L, 296L, 303L, 355L, 343L, 313L,
353L, 370L, 313L, 303L, 418L, 373L, 353L, 349L, 349L, 363L, 367L,
355L, 365L, 443L, 440L, 350L, 363L, 318L, 423L, 364L, 313L, 422L,
358L, 430L, 358L, 343L, 370L, 298L, 362L, 378L, 419L, 445L, 362L,
313L, 432L, 373L, 355L, 318L, 353L, 283L, 338L, 255L, 276L, 276L,
430L, 313L, 367L, 276L, 300L, 313L, 283L, 350L, 313L, 313L, 362L,
288L, 425L, 313L, 348L, 426L, 345L, 313L, 353L, 355L, 443L, 355L,
423L, 343L, 355L, 348L, 303L, 298L, 318L, 367L, 313L, 435L, 313L,
425L, 355L, 318L, 368L, 370L, 343L, 430L, 348L, 300L, 313L, 423L,
350L, 443L, 338L, 276L, 292L, 358L, 378L, 313L, 443L, 313L, 348L,
338L, 370L, 313L, 318L, 360L, 363L, 358L, 345L, 353L, 318L, 313L,
338L, 345L, 345L, 313L, 355L, 348L, 313L, 422L, 363L, 313L, 276L,
318L, 350L, 363L, 313L, 292L, 350L, 368L, 418L, 298L, 375L, 313L,
315L, 353L, 313L, 288L, 348L, 360L, 413L, 318L, 345L, 365L, 292L,
348L, 318L, 362L, 426L, 313L, 365L, 367L, 315L, 368L, 425L, 276L,
345L, 360L, 350L, 405L, 362L, 313L, 350L, 343L, 360L, 313L, 355L,
303L, 358L, 419L, 350L, 298L, 367L, 313L, 343L, 405L, 419L, 345L,
303L, 367L, 265L, 378L, 345L, 318L, 432L, 350L, 445L, 303L, 364L,
296L, 418L, 365L, 370L, 313L, 362L, 318L, 313L, 353L, 373L, 360L,
345L, 313L, 353L, 422L, 365L, 315L, 365L, 313L, 313L, 360L, 413L,
345L, 318L, 338L, 355L, 313L, 349L, 418L, 360L, 303L, 313L, 355L,
313L, 318L, 367L, 425L, 270L, 318L, 349L, 353L, 318L, 349L, 345L,
368L, 318L, 313L, 362L, 338L, 303L, 296L, 345L, 364L, 283L, 368L,
368L, 343L, 423L, 367L, 368L, 313L, 298L, 355L, 405L, 292L, 368L,
355L, 440L, 313L, 313L, 313L, 438L, 358L, 313L, 292L, 338L, 313L,
313L, 373L, 360L, 345L, 423L, 348L, 370L, 292L, 303L, 345L, 265L,
364L, 315L, 338L, 350L, 368L, 313L, 318L, 370L, 303L, 423L, 388L,
343L, 362L, 355L, 426L, 350L, 365L, 345L, 355L, 343L, 443L, 313L,
270L, 360L, 350L, 435L, 445L, 313L, 348L, 355L, 430L, 362L, 349L,
349L, 298L, 313L, 292L, 375L, 367L, 318L, 315L, 368L, 296L, 300L,
318L, 296L, 425L, 355L, 288L, 353L, 370L, 362L, 355L, 318L, 313L,
435L, 343L, 435L, 292L, 355L, 440L, 338L, 313L, 355L, 288L, 440L,
435L, 303L, 360L, 270L, 435L, 283L, 373L, 353L, 265L, 265L, 425L,
367L, 353L, 367L, 448L, 368L, 283L, 350L, 343L, 353L, 303L, 355L,
368L, 373L, 343L, 375L, 348L, 413L, 362L, 303L, 298L, 313L, 300L,
440L, 349L, 355L, 318L, 355L, 388L, 363L, 440L, 292L, 373L, 349L,
300L, 315L, 338L, 373L, 353L, 348L, 370L, 362L, 338L, 440L, 440L,
350L, 296L, 343L, 368L, 349L, 423L, 364L, 348L, 349L, 423L, 353L,
345L, 370L, 292L, 355L, 349L, 355L, 276L, 440L, 283L, 358L, 375L,
348L, 440L, 355L, 423L, 445L, 368L, 348L, 355L, 367L), CHARTERVALUE =
c(14000L,
12825L, 10475L, 11850L, 13250L, 12100L, 11875L, 14500L, 12500L,
10500L, 13375L, 14500L, 13400L, 11000L, 12750L, 11625L, 11875L,
10500L, 11850L, 11900L, 11850L, 12750L, 12500L, 12000L, 12250L,
12750L, 10450L, 12900L, 12425L, 13375L, 12075L, 13400L, 12625L,
11125L, 12000L, 11875L, 13400L, 12000L, 12500L, 12750L, 11900L,
13625L, 12750L, 11800L, 12500L, 12500L, 9850L, 12000L, 12350L,
11125L, 12750L, 11800L, 12750L, 12500L, 12250L, 13125L, 13125L,
13125L, 12500L, 11800L, 11875L, 11850L, 11500L, 12625L, 13125L,
11900L, 10425L, 12250L, 12375L, 12400L, 11875L, 11625L, 11800L,
12400L, 12000L, 14000L, 12000L, 13125L, 12250L, 12625L, 13875L,
12400L, 11875L, 11625L, 11000L, 12075L, 10450L, 12625L, 13375L,
12875L, 13125L, 12375L, 11125L, 13625L, 11875L, 9850L, 12375L,
12100L, 14500L, 12000L, 13875L, 11875L, 12400L, 12375L, 13125L,
13250L, 13875L, 11900L, 11900L, 12900L, 12875L, 12100L, 12350L,
12375L, 13125L, 11850L, 12900L, 12750L, 13125L, 13875L, 13375L,
13025L, 14500L, 13400L, 14500L, 12625L, 11875L, 10450L, 11800L,
12750L, 12625L, 12250L, 11800L, 12250L, 13250L, 13250L, 12100L,
12750L, 13625L, 11125L, 12400L, 10250L, 10475L, 10475L, 13400L,
13375L, 12875L, 10475L, 11500L, 12400L, 11125L, 11850L, 13375L,
12400L, 11800L, 10500L, 13375L, 13375L, 12500L, 12625L, 12500L,
12000L, 13875L, 11125L, 12375L, 11125L, 13125L, 12625L, 12100L,
12500L, 12375L, 10450L, 12750L, 12875L, 12250L, 13400L, 12250L,
13375L, 11125L, 12750L, 12750L, 11875L, 14500L, 13400L, 12500L,
11500L, 13375L, 13125L, 11850L, 12375L, 12400L, 10475L, 11000L,
14500L, 12750L, 12400L, 12375L, 12250L, 12500L, 12400L, 11875L,
12250L, 12750L, 11625L, 12900L, 14500L, 12500L, 13875L, 11875L,
13375L, 12400L, 12500L, 12500L, 13375L, 12100L, 12500L, 12400L,
13025L, 12900L, 12400L, 10475L, 12750L, 11850L, 12900L, 13375L,
11000L, 11850L, 13125L, 13125L, 10450L, 12500L, 12250L, 12425L,
13875L, 12000L, 10500L, 13125L, 11625L, 12975L, 12750L, 12500L,
12350L, 11000L, 13125L, 12750L, 11800L, 12625L, 13375L, 12350L,
12875L, 12425L, 12750L, 12675L, 10475L, 12500L, 11625L, 11850L,
12825L, 11800L, 13375L, 14000L, 12625L, 11625L, 12400L, 11125L,
12375L, 14500L, 12625L, 14000L, 10425L, 12875L, 13375L, 14500L,
12825L, 12625L, 12500L, 12375L, 12875L, 9875L, 12750L, 12500L,
12750L, 13250L, 11850L, 12250L, 12375L, 13875L, 9850L, 13125L,
12350L, 11875L, 12000L, 11800L, 11875L, 12000L, 13875L, 13250L,
11625L, 12500L, 12400L, 13625L, 13025L, 12350L, 12425L, 12350L,
12400L, 12400L, 11625L, 12975L, 12500L, 11875L, 12400L, 11125L,
12000L, 11900L, 13125L, 11625L, 12375L, 12250L, 12100L, 13375L,
12750L, 12875L, 12675L, 10000L, 11875L, 11900L, 13625L, 12750L,
11900L, 12500L, 12750L, 12750L, 12000L, 11800L, 12400L, 12375L,
9850L, 12500L, 13875L, 11125L, 12750L, 12750L, 12625L, 12075L,
12875L, 13125L, 12250L, 10450L, 11125L, 12825L, 11000L, 13125L,
11125L, 13125L, 12000L, 12000L, 13375L, 13375L, 14500L, 12000L,
11000L, 12400L, 12250L, 12000L, 13250L, 11625L, 12500L, 13125L,
13125L, 11875L, 11000L, 12375L, 12500L, 9875L, 13875L, 12425L,
12400L, 14000L, 12750L, 12400L, 11875L, 11875L, 12375L, 12075L,
12400L, 14500L, 11800L, 12100L, 12625L, 14000L, 12350L, 12500L,
12100L, 12625L, 12375L, 12250L, 10000L, 11625L, 14000L, 13375L,
12250L, 13375L, 12500L, 11125L, 13400L, 11800L, 11900L, 11900L,
10425L, 12400L, 11000L, 12500L, 12875L, 12750L, 12425L, 12750L,
9850L, 11500L, 12750L, 9850L, 13375L, 11125L, 10500L, 13875L,
11875L, 11800L, 11125L, 12750L, 12250L, 13375L, 12625L, 13375L,
11000L, 11125L, 13125L, 12400L, 13375L, 12100L, 10500L, 13075L,
13375L, 12375L, 11625L, 10000L, 13400L, 11125L, 13250L, 13875L,
9875L, 9875L, 13375L, 12875L, 13875L, 12875L, 13500L, 12750L,
11125L, 11850L, 12625L, 13875L, 12375L, 12100L, 13125L, 13250L,
12625L, 12500L, 13125L, 12975L, 11800L, 12375L, 10425L, 13375L,
11500L, 13075L, 11900L, 12100L, 11875L, 11125L, 12400L, 12900L,
13400L, 11000L, 13250L, 11900L, 11500L, 12425L, 12400L, 13250L,
13625L, 12500L, 11875L, 11800L, 12400L, 13125L, 13075L, 14000L,
9850L, 14500L, 13125L, 11900L, 13125L, 13875L, 13125L, 11900L,
13125L, 13875L, 12500L, 11875L, 11000L, 11125L, 11900L, 11125L,
10475L, 13075L, 11125L, 14500L, 12500L, 13125L, 13125L, 12100L,
13125L, 12250L, 13125L, 12500L, 11125L, 12875L)), class = "data.frame",
row.names = c(NA,
-527L))


Any help and/or guidance will be greatly appreciated,

Best regards,

Paul

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From p@u|bern@|07 @end|ng |rom gm@||@com  Wed Apr 24 05:32:10 2019
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Tue, 23 Apr 2019 22:32:10 -0500
Subject: [R] Unable to Understand Results of pglm function
In-Reply-To: <000101d4fa49$1a364d70$4ea2e850$@bigpond.com>
References: <CAMOcQfPtCNknO=1c5H4UM6hzbC8ULNtU18LS+ZCQWUxMJxum3g@mail.gmail.com>
 <000101d4fa49$1a364d70$4ea2e850$@bigpond.com>
Message-ID: <CAMOcQfO8zxzzKa5txy4UnAiyKvgh43KRH-bE6gcS2PPY3AkdkA@mail.gmail.com>

Hi Dr. Mackay,

Thank you so much for your valuable feedback.

I wonder why, when  applying the summary function over the pglm model, it
shows infinite as value for the standard errors.

Is this something we should expect? Or is there something else that needs
to be adjusted, either in the dataset(in the dataset's structure) or in the
pglm parameters.

Best regards,

Paul

El mar., 23 de abril de 2019 9:55 p. m., Duncan Mackay <dulcalma at bigpond.com>
escribi?:

> Hi Paul
>
> I think you may have too many IDs DATE for your model as you posted
>
> I converted your DATE into date format and named it df3
> str(df3)
> 'data.frame':   527 obs. of  11 variables:
>  $ TRANSIT     : int  1 1 1 0 1 1 1 1 1 1 ...
>  $ ID          : int  1 1 2 2 3 4 5 5 6 7 ...
>  $ DATE        : Factor w/ 377 levels "1-Aug-17","1-Aug-18",..: 47 75 89
> 252 3 221 62 99 224 114 ...
>  $ SHIPNAME    : Factor w/ 482 levels "Aby Jeannette",..: 295 295 151 151
> 19 41 292 292 201 148 ...
>  $ Draft       : int  12 12 12 13 12 12 12 12 12 12 ...
>  $ TOTALCOST   : int  194364 219364 198260 237456 197159 198992 194337
> 219337 199198 196604 ...
>  $ BUNKER      : int  350 405 276 350 373 355 370 343 345 288 ...
>  $ CHARTERVALUE: int  14000 12825 10475 11850 13250 12100 11875 14500
> 12500 10500 ...
>  $ dt          : Date, format: "2018-03-15" "2018-08-19" "2017-07-20"
> "2017-12-19" ...
>  $ dtym        : chr  "201803" "201808" "201707" "201712" ...
>  $ dty         : chr  "2018" "2018" "2017" "2017" ...
>
> Here are 2 results
>
> > model1 = pglm(TRANSIT~ Draft+TOTALCOST+BUNKER+CHARTERVALUE + dty,
> +      effect=c("time"),
> +      model=c("pooling"),
> +      family=binomial('logit'),
> +      index=c("ID"),
> +      start = NULL, data=df3)
> >
> > summary(model1)
> --------------------------------------------
> Maximum Likelihood estimation
> Newton-Raphson maximisation, 11 iterations
> Return code 2: successive function values within tolerance limit
> Log-Likelihood: -14.14988
> 6  free parameters
> Estimates:
>                Estimate Std. error t value Pr(> t)
> (Intercept)   1.023e+02        Inf       0       1
> Draft        -5.088e+00        Inf       0       1
> TOTALCOST    -1.708e-04        Inf       0       1
> BUNKER       -6.712e-03        Inf       0       1
> CHARTERVALUE  2.524e-04        Inf       0       1
> dty2018       2.215e+00        Inf       0       1
> --------------------------------------------
>
> > model1=pglm(TRANSIT~ Draft+TOTALCOST+BUNKER+CHARTERVALUE + dty,
> +      effect=c("time"),
> +      model=c("pooling"),
> +      family=binomial('logit'),
> +      index=c("ID","dty"),
> +      start = NULL, data=df3)
> Warning messages:
> 1: In pdata.frame(data, index) :
>   duplicate couples (id-time) in resulting pdata.frame
>  to find out which, use e.g. table(index(your_pdataframe), useNA = "ifany")
> 2: In is.pbalanced.default(index[[1]], index[[2]]) :
>   duplicate couples (id-time)
>
> >
> > summary(model1)
> --------------------------------------------
> Maximum Likelihood estimation
> Newton-Raphson maximisation, 11 iterations
> Return code 2: successive function values within tolerance limit
> Log-Likelihood: -14.14988
> 6  free parameters
> Estimates:
>                Estimate Std. error t value Pr(> t)
> (Intercept)   1.023e+02        Inf       0       1
> Draft        -5.088e+00        Inf       0       1
> TOTALCOST    -1.708e-04        Inf       0       1
> BUNKER       -6.712e-03        Inf       0       1
> CHARTERVALUE  2.524e-04        Inf       0       1
> dty2018       2.215e+00        Inf       0       1
> --------------------------------------------
>
> I have no knowledge of the pglm package and was trying it out on your data
> without going through the help properly
> NBB your DATE column has several formats which do not help
>
> Regards
>
> Duncan
>
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2350
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paul
> Bernal
> Sent: Wednesday, 24 April 2019 06:44
> To: yves.croissant at univ-reunion.fr
> Cc: r-help at r-project.org
> Subject: [R] Unable to Understand Results of pglm function
>
> Dear Yves,
>
> Hope you are doing great. I have been testing the pglm function from the
> pglm package, in order to fit a logit regression to a panel dataset, and I
> do not understand the results and/or errors produced by the function, so I
> want to be able to understand whether there is a problem with the structure
> of my dataset, or I am not using the function properly or if there is
> something else going on that I am ignoring. Also, I would like to know what
> the start argument is for, or at least an example of how to use it, since I
> don?t know how to properly apply it.
>
> Here the details of what I am using and under what environment settings:
> 1-R version: 3.5.3
> 2-packages called: plm and pglm
> 3-Running on a 64-bit Operating System
> 4-Windows 8
>
> Here is the code with the different things I have tried so far:
> > PGLM_Model11 <-
>
> pglm(dataframe3$TRANSIT~dataframe3$Draft+dataframe3$TOTALCOST+dataframe3$BUNKER+dataframe3$CHARTERVALUE,
> effect=c("twoways"), model=c("random"), family=binomial('logit'),
> index=c("ID","DATE"), start = NULL, data=dataframe3)
> >
> > summary(PGLM_Model11)
> --------------------------------------------
> Maximum Likelihood estimation
> Newton-Raphson maximisation, 0 iterations
> Return code 100: Initial value out of range.
> --------------------------------------------
> >
> > PGLM_Model12 <-
>
> pglm(dataframe3$TRANSIT~dataframe3$Draft+dataframe3$TOTALCOST+dataframe3$BUNKER+dataframe3$CHARTERVALUE,
> effect=c("twoways"), model=c("pooling"), family=binomial('logit'),
> index=c("ID","DATE"), start = NULL, data=dataframe3)
> >
> > summary(PGLM_Model12)
> --------------------------------------------
> Maximum Likelihood estimation
> Newton-Raphson maximisation, 11 iterations
> Return code 2: successive function values within tolerance limit
> Log-Likelihood: -14.95426
> 5  free parameters
> Estimates:
>                           Estimate Std. error t value Pr(> t)
> (Intercept)             93.9680425        Inf       0       1
> dataframe3$Draft        -5.3820652        Inf       0       1
> dataframe3$TOTALCOST    -0.0001689        Inf       0       1
> dataframe3$BUNKER        0.0072934        Inf       0       1
> dataframe3$CHARTERVALUE  0.0008862        Inf       0       1
> --------------------------------------------
> >
> > PGLM_Model13 <-
>
> pglm(dataframe3$TRANSIT~dataframe3$Draft+dataframe3$TOTALCOST+dataframe3$BUNKER+dataframe3$CHARTERVALUE,
> effect=c("twoways"), model=c("within"), family=binomial('logit'),
> index=c("ID","DATE"), start = NULL, data=dataframe3)
> Error in maxRoutine(fn = logLik, grad = grad, hess = hess, start = start,
> :
>   argument "start" is missing, with no default
> >
> > PGLM_Model14 <-
>
> pglm(dataframe3$TRANSIT~dataframe3$Draft+dataframe3$TOTALCOST+dataframe3$BUNKER+dataframe3$CHARTERVALUE,
> effect=c("twoways"), model=c("between"), family=binomial('logit'),
> index=c("ID","DATE"), start = NULL, data=dataframe3)
> Error in maxRoutine(fn = logLik, grad = grad, hess = hess, start = start,
> :
>   argument "start" is missing, with no default
>
> Below the dput of the dataset I am using for your reference:
>
> > dput(dataframe3)
> structure(list(TRANSIT = c(1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 1L, 1L, 0L, 1L, 0L, 0L,
> 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L,
> 0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 1L, 1L, 0L,
> 1L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L,
> 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 0L,
> 1L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 1L, 1L,
> 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L,
> 1L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
> 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 0L, 0L,
> 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L,
> 0L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
> 0L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 1L,
> 1L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 0L,
> 1L, 0L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 0L,
> 0L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 0L,
> 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 1L, 0L, 0L,
> 1L, 1L, 1L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 0L, 0L,
> 1L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 0L, 1L,
> 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L, 1L, 1L, 0L,
> 0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L,
> 1L, 0L, 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L,
> 0L, 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 0L,
> 0L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L,
> 0L, 1L, 0L, 0L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 1L,
> 1L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L, 1L, 1L, 1L,
> 1L, 0L, 1L, 0L, 0L, 1L, 1L, 0L, 0L, 1L, 1L, 1L, 0L, 1L, 0L, 0L,
> 0L, 1L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 1L, 1L, 1L, 0L,
> 0L, 0L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 0L,
> 1L, 1L, 0L, 0L, 1L, 0L, 1L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L), ID = c(1L, 1L, 2L, 2L, 3L, 4L, 5L, 5L,
> 6L, 7L, 7L, 7L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L,
> 17L, 18L, 19L, 20L, 21L, 21L, 22L, 23L, 24L, 24L, 25L, 26L, 27L,
> 28L, 29L, 30L, 31L, 32L, 33L, 34L, 35L, 36L, 37L, 38L, 39L, 40L,
> 41L, 42L, 43L, 44L, 45L, 46L, 47L, 48L, 48L, 49L, 50L, 51L, 52L,
> 53L, 54L, 54L, 55L, 56L, 57L, 58L, 59L, 60L, 61L, 62L, 63L, 64L,
> 65L, 66L, 67L, 67L, 68L, 69L, 70L, 71L, 72L, 73L, 74L, 75L, 76L,
> 77L, 78L, 79L, 80L, 81L, 82L, 83L, 84L, 85L, 86L, 87L, 88L, 89L,
> 90L, 91L, 92L, 93L, 93L, 94L, 95L, 96L, 97L, 98L, 99L, 100L,
> 101L, 102L, 103L, 104L, 105L, 106L, 107L, 108L, 108L, 109L, 110L,
> 111L, 112L, 113L, 114L, 115L, 115L, 115L, 115L, 116L, 117L, 118L,
> 119L, 120L, 121L, 122L, 123L, 124L, 125L, 126L, 127L, 128L, 128L,
> 129L, 130L, 131L, 132L, 133L, 134L, 135L, 136L, 137L, 138L, 139L,
> 139L, 140L, 140L, 141L, 142L, 143L, 144L, 145L, 145L, 146L, 146L,
> 147L, 148L, 149L, 149L, 150L, 150L, 150L, 151L, 152L, 153L, 154L,
> 155L, 156L, 157L, 158L, 159L, 160L, 161L, 162L, 163L, 164L, 165L,
> 166L, 167L, 168L, 169L, 170L, 171L, 172L, 173L, 174L, 175L, 176L,
> 177L, 178L, 179L, 180L, 181L, 182L, 182L, 183L, 184L, 185L, 186L,
> 187L, 188L, 189L, 190L, 191L, 192L, 192L, 193L, 193L, 194L, 195L,
> 196L, 197L, 198L, 199L, 199L, 200L, 201L, 202L, 203L, 204L, 205L,
> 206L, 207L, 208L, 208L, 209L, 210L, 211L, 212L, 213L, 214L, 215L,
> 216L, 217L, 218L, 218L, 219L, 220L, 221L, 222L, 222L, 223L, 224L,
> 225L, 226L, 227L, 228L, 229L, 230L, 231L, 232L, 233L, 234L, 235L,
> 236L, 237L, 238L, 239L, 240L, 241L, 241L, 241L, 242L, 243L, 244L,
> 245L, 246L, 247L, 247L, 248L, 248L, 249L, 249L, 250L, 251L, 252L,
> 253L, 254L, 255L, 256L, 257L, 258L, 259L, 260L, 261L, 262L, 263L,
> 264L, 265L, 266L, 267L, 268L, 269L, 270L, 271L, 272L, 273L, 273L,
> 274L, 275L, 276L, 277L, 278L, 279L, 280L, 281L, 282L, 283L, 284L,
> 285L, 286L, 287L, 288L, 288L, 289L, 290L, 291L, 292L, 293L, 294L,
> 295L, 296L, 297L, 298L, 299L, 300L, 301L, 301L, 302L, 303L, 304L,
> 305L, 306L, 307L, 308L, 308L, 309L, 309L, 309L, 310L, 311L, 312L,
> 313L, 313L, 314L, 315L, 316L, 317L, 318L, 319L, 320L, 321L, 322L,
> 323L, 324L, 325L, 326L, 327L, 327L, 328L, 329L, 330L, 331L, 332L,
> 333L, 334L, 335L, 336L, 337L, 338L, 339L, 340L, 341L, 342L, 343L,
> 344L, 345L, 346L, 347L, 348L, 349L, 350L, 351L, 352L, 353L, 354L,
> 354L, 354L, 354L, 355L, 356L, 357L, 358L, 359L, 360L, 361L, 362L,
> 363L, 364L, 365L, 366L, 367L, 368L, 369L, 370L, 371L, 372L, 373L,
> 374L, 375L, 376L, 377L, 378L, 379L, 380L, 381L, 382L, 383L, 384L,
> 385L, 386L, 387L, 388L, 389L, 390L, 391L, 392L, 393L, 394L, 395L,
> 396L, 397L, 398L, 399L, 400L, 401L, 402L, 402L, 403L, 404L, 405L,
> 406L, 407L, 408L, 409L, 410L, 411L, 412L, 413L, 413L, 414L, 415L,
> 416L, 417L, 418L, 419L, 420L, 421L, 422L, 423L, 424L, 425L, 426L,
> 427L, 428L, 429L, 430L, 431L, 432L, 433L, 434L, 434L, 435L, 436L,
> 437L, 438L, 439L, 440L, 441L, 442L, 443L, 444L, 445L, 446L, 447L,
> 448L, 449L, 450L, 451L, 452L, 453L, 454L, 455L, 456L, 457L, 458L,
> 459L, 460L, 461L, 462L, 463L, 464L, 464L, 465L, 465L, 466L, 467L,
> 467L, 468L, 468L, 469L, 470L, 471L, 472L, 473L), DATE = structure(c(47L,
> 75L, 89L, 252L, 3L, 221L, 62L, 99L, 224L, 114L, 154L, 151L, 52L,
> 9L, 342L, 320L, 370L, 149L, 252L, 112L, 147L, 346L, 231L, 371L,
> 331L, 171L, 30L, 119L, 366L, 58L, 61L, 103L, 269L, 313L, 373L,
> 195L, 116L, 376L, 323L, 189L, 245L, 270L, 76L, 258L, 265L, 347L,
> 178L, 376L, 278L, 311L, 281L, 260L, 203L, 275L, 101L, 150L, 234L,
> 161L, 231L, 257L, 367L, 254L, 210L, 67L, 21L, 96L, 241L, 331L,
> 351L, 223L, 309L, 319L, 256L, 12L, 43L, 27L, 28L, 133L, 101L,
> 266L, 16L, 359L, 370L, 318L, 237L, 78L, 213L, 113L, 337L, 199L,
> 94L, 330L, 314L, 271L, 328L, 1L, 348L, 244L, 302L, 374L, 208L,
> 40L, 357L, 232L, 179L, 286L, 193L, 248L, 250L, 284L, 274L, 321L,
> 289L, 138L, 80L, 253L, 283L, 164L, 133L, 212L, 339L, 59L, 305L,
> 49L, 162L, 266L, 326L, 11L, 4L, 82L, 65L, 188L, 192L, 334L, 33L,
> 177L, 221L, 346L, 148L, 86L, 24L, 5L, 89L, 57L, 37L, 338L, 191L,
> 68L, 218L, 79L, 235L, 254L, 338L, 361L, 4L, 135L, 143L, 123L,
> 55L, 23L, 18L, 20L, 202L, 128L, 127L, 122L, 156L, 269L, 321L,
> 276L, 352L, 22L, 7L, 199L, 333L, 145L, 92L, 136L, 311L, 342L,
> 294L, 325L, 71L, 29L, 25L, 173L, 154L, 85L, 118L, 121L, 44L,
> 107L, 140L, 151L, 175L, 102L, 108L, 63L, 25L, 51L, 329L, 334L,
> 345L, 153L, 282L, 304L, 324L, 193L, 367L, 341L, 39L, 231L, 209L,
> 335L, 321L, 276L, 102L, 91L, 282L, 362L, 68L, 344L, 253L, 98L,
> 338L, 84L, 251L, 64L, 161L, 227L, 139L, 334L, 365L, 202L, 374L,
> 159L, 21L, 317L, 42L, 343L, 349L, 292L, 84L, 226L, 194L, 256L,
> 228L, 336L, 293L, 288L, 155L, 56L, 207L, 89L, 324L, 163L, 157L,
> 117L, 260L, 341L, 47L, 97L, 320L, 102L, 312L, 348L, 137L, 38L,
> 27L, 243L, 229L, 123L, 99L, 125L, 54L, 349L, 354L, 290L, 170L,
> 233L, 308L, 164L, 15L, 142L, 152L, 352L, 306L, 186L, 299L, 289L,
> 327L, 377L, 255L, 369L, 377L, 272L, 285L, 320L, 324L, 358L, 6L,
> 70L, 278L, 364L, 278L, 361L, 360L, 316L, 300L, 350L, 368L, 259L,
> 315L, 374L, 247L, 161L, 318L, 353L, 332L, 190L, 340L, 344L, 291L,
> 207L, 14L, 372L, 246L, 270L, 344L, 87L, 324L, 295L, 172L, 377L,
> 257L, 24L, 330L, 167L, 209L, 212L, 236L, 280L, 281L, 268L, 48L,
> 264L, 53L, 355L, 206L, 115L, 111L, 140L, 50L, 313L, 187L, 375L,
> 375L, 336L, 217L, 162L, 371L, 239L, 261L, 334L, 371L, 158L, 320L,
> 350L, 176L, 10L, 309L, 9L, 330L, 204L, 216L, 166L, 363L, 44L,
> 301L, 279L, 73L, 83L, 328L, 36L, 72L, 35L, 99L, 169L, 321L, 220L,
> 34L, 215L, 308L, 244L, 88L, 127L, 334L, 14L, 144L, 60L, 69L,
> 181L, 123L, 45L, 314L, 37L, 258L, 245L, 250L, 242L, 361L, 9L,
> 132L, 191L, 7L, 165L, 296L, 186L, 356L, 342L, 197L, 136L, 122L,
> 126L, 193L, 310L, 200L, 311L, 344L, 355L, 297L, 106L, 46L, 238L,
> 311L, 160L, 262L, 129L, 168L, 120L, 211L, 90L, 41L, 319L, 32L,
> 131L, 110L, 185L, 222L, 298L, 201L, 143L, 13L, 273L, 229L, 182L,
> 76L, 95L, 253L, 88L, 307L, 354L, 198L, 64L, 286L, 267L, 124L,
> 21L, 26L, 257L, 19L, 242L, 341L, 240L, 174L, 249L, 322L, 8L,
> 109L, 17L, 134L, 93L, 183L, 158L, 245L, 205L, 130L, 31L, 287L,
> 271L, 277L, 327L, 184L, 263L, 2L, 196L, 60L, 186L, 303L, 50L,
> 250L, 141L, 166L, 219L, 248L, 156L, 230L, 350L, 329L, 146L, 313L,
> 66L, 315L, 77L, 225L, 105L, 180L, 104L, 219L, 80L, 190L, 156L,
> 81L, 74L, 25L, 100L, 214L), .Label = c("1-Aug-17", "1-Aug-18",
> "1-Feb-18", "1-Jan-18", "1-Jul-17", "1-Mar-18", "1-Nov-17", "1-Oct-17",
> "1-Sep-17", "10-Apr-18", "10-Aug-17", "10-Dec-17", "10-Feb-18",
> "10-Jul-17", "10-Jul-18", "10-Mar-18", "10-May-18", "10-Nov-17",
> "10-Oct-17", "10-Sep-17", "11-Apr-18", "11-Aug-17", "11-Aug-18",
> "11-Dec-17", "11-Feb-18", "11-Jun-18", "11-Mar-18", "11-Sep-17",
> "11-Sep-18", "12-Aug-17", "12-Dec-17", "12-Jul-17", "12-Jul-18",
> "12-Mar-18", "12-May-18", "12-Oct-17", "12-Sep-18", "13-Aug-18",
> "13-Dec-17", "13-Nov-17", "13-Oct-17", "14-Jun-18", "14-Sep-17",
> "15-Dec-17", "15-Feb-18", "15-Jul-18", "15-Mar-18", "15-May-18",
> "15-Sep-18", "16-Apr-18", "16-Dec-17", "16-Sep-18", "17-Apr-18",
> "17-Aug-18", "17-Feb-18", "17-Jan-18", "17-Jul-17", "17-Jul-18",
> "17-Jun-18", "17-Mar-18", "17-May-18", "17-Nov-17", "17-Oct-17",
> "18-Apr-18", "18-Aug-18", "18-Dec-17", "18-Feb-18", "18-Jul-17",
> "18-Jul-18", "18-Jun-18", "18-Mar-18", "18-May-18", "18-Sep-17",
> "19-Apr-18", "19-Aug-18", "19-Jan-18", "19-Jul-17", "19-May-18",
> "19-Sep-17", "2-Aug-18", "2-Jun-18", "2-May-18", "2-Oct-17",
> "2-Sep-17", "2-Sep-18", "20-Aug-17", "20-Dec-17", "20-Feb-18",
> "20-Jul-17", "20-Jul-18", "20-Jun-18", "20-Oct-17", "20-Sep-18",
> "21-Apr-18", "21-Aug-17", "21-Dec-17", "21-Feb-18", "21-Jan-18",
> "21-Mar-18", "21-Nov-17", "21-Oct-17", "21-Sep-17", "21-Sep-18",
> "22-Apr-18", "22-Aug-17", "22-Feb-18", "22-Jul-17", "22-May-18",
> "22-Nov-17", "23-Aug-17", "23-Aug-18", "23-Dec-17", "23-Feb-18",
> "23-Jul-17", "23-Nov-17", "23-Sep-18", "24-Aug-18", "24-Dec-17",
> "24-Jan-18", "24-Jul-17", "24-May-18", "24-Nov-17", "24-Oct-17",
> "25-Apr-18", "25-Aug-18", "25-Jul-17", "25-May-18", "25-Nov-17",
> "25-Oct-17", "25-Sep-17", "25-Sep-18", "26-Apr-18", "26-Aug-18",
> "26-Jan-18", "26-Jul-17", "26-Jul-18", "26-Mar-18", "26-May-18",
> "27-Apr-18", "27-Aug-17", "27-Aug-18", "27-Dec-17", "27-Jul-18",
> "27-Nov-17", "27-Sep-18", "28-Aug-17", "28-Dec-17", "28-Feb-18",
> "28-Jul-17", "28-Jun-18", "28-Mar-18", "28-May-18", "28-Nov-17",
> "28-Oct-17", "28-Sep-17", "29-Aug-18", "29-Dec-17", "29-Jan-18",
> "29-Jul-17", "29-Jul-18", "29-Jun-18", "29-Mar-18", "29-Nov-17",
> "29-Oct-17", "29-Sep-17", "3-Apr-18", "3-Aug-17", "3-Dec-17",
> "3-Jan-18", "3-Jul-17", "3-May-18", "3-Nov-17", "3-Sep-17", "3-Sep-18",
> "30-Apr-18", "30-Aug-18", "30-Jan-18", "30-Jul-17", "30-Jun-18",
> "30-Mar-18", "30-May-18", "30-Sep-18", "31-Aug-17", "31-Dec-17",
> "31-Jan-18", "31-Jul-17", "31-Jul-18", "31-May-18", "31-Oct-17",
> "4-Dec-17", "4-Feb-18", "4-Jan-18", "4-Mar-18", "4-Nov-17", "4-Oct-17",
> "4-Sep-18", "5-Aug-17", "5-Dec-17", "5-Feb-18", "5-Jan-18", "5-Jul-17",
> "5-Mar-18", "5-May-18", "5-Nov-17", "5-Sep-17", "6-Aug-17", "6-Jun-18",
> "6-Mar-18", "6-Nov-17", "6-Sep-17", "6-Sep-18", "7-Apr-18", "7-Aug-17",
> "7-Feb-18", "7-Jan-18", "7-Jul-17", "7-Jul-18", "7-Sep-17", "8-Apr-18",
> "8-Aug-18", "8-Dec-17", "8-Mar-18", "8-May-18", "8-Nov-17", "8-Sep-18",
> "9-Apr-18", "9-Aug-17", "9-Aug-18", "9-Feb-18", "9-Mar-18", "9-Nov-17",
> "9-Oct-17", "April 23 2018", "April 5 2018", "August 14 2017",
> "August 15 2017", "August 24 2017", "August 25 2017", "August 26 2017",
> "August 30 2017", "August 6 2017", "August 7 2017", "August 8 2017",
> "December 1 2017", "December 10 2017", "December 11 2017", "December 12
> 2017",
> "December 13 2017", "December 14 2017", "December 15 2017", "December 18
> 2017",
> "December 19 2017", "December 21 2017", "December 22 2017", "December 24
> 2017",
> "December 27 2017", "December 28 2017", "December 29 2017", "December 3
> 2017",
> "December 30 2017", "December 4 2017", "December 5 2017", "December 6
> 2017",
> "February 1 2018", "February 10 2018", "February 12 2018", "February 13
> 2018",
> "February 15 2018", "February 16 2018", "February 19 2018", "February 20
> 2018",
> "February 25 2018", "February 28 2018", "February 3 2018", "February 4
> 2017",
> "February 5 2018", "February 8 2018", "January 1 2018", "January 10 2018",
> "January 11 2018", "January 13 2018", "January 14 2018", "January 15 2018",
> "January 20 2018", "January 23 2018", "January 24 2018", "January 26 2018",
> "January 29 2018", "January 3 2018", "January 30 2018", "January 31 2018",
> "January 4 2018", "January 6 2018", "January 7 2018", "January 8 2018",
> "January 9 2018", "July 13 2018", "July 30 2017", "June 17 2018",
> "June 8 2018", "March 10 2018", "March 13 2018", "March 18 2018",
> "March 22 2018", "March 24 2018", "March 28 2018", "March 3 2018",
> "November 1 2017", "November 10 2017", "November 11 2017", "November 12
> 2017",
> "November 13 2017", "November 15 2017", "November 17 2017", "November 18
> 2017",
> "November 19 2017", "November 21 2017", "November 22 2017", "November 23
> 2017",
> "November 25 2017", "November 27 2017", "November 28 2017", "November 3
> 2017",
> "November 4 2017", "November 5 2017", "November 6 2017", "November 7 2017",
> "November 8 2017", "November 9 2017", "October 1 2017", "October 10 2017",
> "October 11 2017", "October 12 2017", "October 14 2017", "October 15 2017",
> "October 16 2017", "October 17 2017", "October 18 2017", "October 19 2017",
> "October 20 2017", "October 21 2017", "October 23 2017", "October 25 2017",
> "October 26 2017", "October 27 2017", "October 28 2017", "October 29 2017",
> "October 3 2017", "October 30 2017", "October 31 2017", "October 4 2017",
> "October 5 2017", "October 6 2017", "October 7 2017", "October 9 2017",
> "September 1 2017", "September 10 2017", "September 11 2017",
> "September 12 2017", "September 13 2017", "September 15 2017",
> "September 16 2017", "September 17 2017", "September 19 2017",
> "September 21 2017", "September 22 2017", "September 24 2017",
> "September 26 2017", "September 27 2017", "September 29 2017",
> "September 3 2017", "September 30 2017", "September 5 2017",
> "September 6 2017", "September 7 2017", "September 8 2017", "September 9
> 2017"
> ), class = "factor"), SHIPNAME = structure(c(295L, 295L, 151L,
> 151L, 19L, 41L, 292L, 292L, 201L, 148L, 148L, 148L, 148L, 413L,
> 39L, 74L, 460L, 54L, 462L, 8L, 22L, 347L, 307L, 354L, 311L, 296L,
> 297L, 297L, 118L, 279L, 230L, 230L, 340L, 358L, 473L, 271L, 309L,
> 451L, 40L, 404L, 120L, 127L, 209L, 90L, 274L, 260L, 252L, 344L,
> 165L, 363L, 356L, 425L, 192L, 133L, 56L, 440L, 439L, 276L, 361L,
> 333L, 273L, 308L, 235L, 235L, 426L, 234L, 93L, 111L, 325L, 283L,
> 107L, 48L, 101L, 212L, 246L, 400L, 338L, 338L, 422L, 20L, 369L,
> 471L, 7L, 409L, 412L, 310L, 70L, 157L, 357L, 103L, 452L, 49L,
> 349L, 4L, 226L, 465L, 362L, 128L, 264L, 136L, 50L, 18L, 323L,
> 11L, 11L, 25L, 408L, 302L, 180L, 394L, 113L, 434L, 477L, 461L,
> 305L, 174L, 104L, 152L, 132L, 291L, 410L, 250L, 382L, 351L, 23L,
> 119L, 284L, 480L, 480L, 480L, 480L, 457L, 272L, 262L, 81L, 346L,
> 239L, 58L, 149L, 402L, 373L, 82L, 251L, 244L, 244L, 135L, 24L,
> 345L, 156L, 227L, 324L, 215L, 222L, 286L, 55L, 281L, 281L, 280L,
> 280L, 322L, 393L, 243L, 34L, 418L, 418L, 334L, 334L, 221L, 220L,
> 6L, 6L, 479L, 479L, 479L, 166L, 196L, 298L, 71L, 160L, 282L,
> 213L, 147L, 315L, 433L, 458L, 207L, 208L, 186L, 91L, 326L, 466L,
> 421L, 420L, 98L, 399L, 289L, 134L, 123L, 194L, 173L, 248L, 64L,
> 202L, 206L, 95L, 396L, 396L, 131L, 211L, 391L, 38L, 84L, 455L,
> 144L, 168L, 389L, 398L, 398L, 35L, 35L, 367L, 359L, 360L, 105L,
> 73L, 431L, 430L, 372L, 62L, 312L, 470L, 263L, 86L, 275L, 219L,
> 414L, 96L, 125L, 365L, 478L, 342L, 45L, 241L, 75L, 121L, 355L,
> 380L, 379L, 216L, 191L, 417L, 395L, 395L, 31L, 210L, 467L, 146L,
> 397L, 179L, 181L, 29L, 171L, 482L, 240L, 288L, 330L, 368L, 287L,
> 401L, 321L, 217L, 233L, 233L, 233L, 366L, 247L, 89L, 472L, 336L,
> 364L, 364L, 124L, 124L, 163L, 163L, 5L, 37L, 237L, 332L, 183L,
> 184L, 444L, 442L, 339L, 126L, 293L, 232L, 150L, 203L, 53L, 475L,
> 468L, 327L, 172L, 481L, 61L, 424L, 2L, 28L, 28L, 224L, 304L,
> 423L, 66L, 384L, 335L, 387L, 42L, 195L, 200L, 383L, 114L, 443L,
> 301L, 68L, 67L, 72L, 214L, 386L, 352L, 381L, 65L, 218L, 266L,
> 102L, 51L, 178L, 30L, 137L, 137L, 175L, 161L, 1L, 448L, 446L,
> 3L, 190L, 189L, 278L, 278L, 278L, 299L, 116L, 143L, 44L, 43L,
> 130L, 285L, 328L, 170L, 185L, 87L, 140L, 437L, 145L, 245L, 155L,
> 261L, 258L, 331L, 85L, 16L, 257L, 204L, 13L, 154L, 459L, 117L,
> 94L, 320L, 225L, 314L, 259L, 14L, 456L, 162L, 142L, 26L, 303L,
> 432L, 231L, 435L, 392L, 313L, 370L, 474L, 464L, 450L, 450L, 450L,
> 450L, 438L, 182L, 236L, 92L, 164L, 79L, 80L, 77L, 169L, 177L,
> 153L, 176L, 329L, 353L, 341L, 454L, 69L, 238L, 242L, 269L, 268L,
> 267L, 115L, 108L, 199L, 52L, 27L, 59L, 198L, 197L, 253L, 436L,
> 306L, 106L, 447L, 378L, 316L, 318L, 99L, 407L, 411L, 36L, 453L,
> 167L, 63L, 158L, 188L, 377L, 376L, 32L, 193L, 463L, 129L, 429L,
> 9L, 17L, 449L, 21L, 76L, 78L, 78L, 319L, 33L, 390L, 388L, 343L,
> 406L, 159L, 270L, 223L, 337L, 88L, 141L, 469L, 100L, 441L, 300L,
> 290L, 445L, 46L, 415L, 294L, 294L, 110L, 12L, 229L, 97L, 138L,
> 263L, 249L, 265L, 385L, 405L, 47L, 205L, 350L, 416L, 348L, 476L,
> 254L, 57L, 15L, 427L, 255L, 428L, 122L, 109L, 60L, 403L, 256L,
> 10L, 371L, 112L, 112L, 419L, 419L, 83L, 317L, 317L, 277L, 277L,
> 187L, 228L, 375L, 374L, 139L), .Label = c("Aby Jeannette", "Adelante",
> "ADM Georgina", "ADS Galtesund", "Aeneas", "Aeolian Fortune",
> "Aeolian Light", "AFRICA GRAECA", "AFRICAN ARROW", "AFRICAN BARI BIRD",
> "AFRICAN BLUE CRANE", "AFRICAN FINFOOT", "AFRICAN JACANA", "AFRICAN KITE",
> "AFRICAN LEOPARD", "AFRICAN PUFFIN", "AFRICAN RAPTOR", "AFTERHOURS",
> "AGIA SKEPI", "Agri Kinsale", "Aiantas", "AKILI", "ALAM MANIS",
> "ALBION", "Alexandra", "ALICIA", "Alma", "Alpha Vision", "AM BREMEN",
> "AMAMI K", "AMIS ACE", "AMIS FORTUNE", "AMIS JUSTICE", "AMSTEL FALCON",
> "Andros", "ANDROS ISLAND", "Androusa", "ANIMA", "Anna S", "Anna Smile",
> "ANTIGONI", "Antiparos", "Aom Gaia", "AOM GAIA", "Aom Milena",
> "APEX", "AREQUIPA QUEEN", "Ariana", "Artemis", "ASHIYA STAR",
> "ASTRA CENTAURUS", "ASTREA", "Athina Carras", "ATLANTIC EAGLE",
> "ATLANTIC GRACE", "ATLANTIC HERO", "ATLANTIC MANZANILLO", "Attalia",
> "Axios", "Bahia Blanca", "Bali", "BALTIC K", "BALTIC WASP", "BBG Ambition",
> "BBG Dream", "BBG Endeavor", "Belo Horizonte", "BELO HORIZONTE",
> "BLUE AKIHABARA", "BLUE DIAMOND", "BLUE MARLIN I", "Bora", "Brasil SW",
> "Braveheart", "BRIDGEGATE", "BRIGITTE", "BTG Denali", "BTG Eiger",
> "BTG Everest", "BTG Kailach", "BULK ARGENTINA", "BULK COLOMBIA",
> "BULK HERO", "BULK HONDURAS", "Bulk Pegasus", "Bulk Portugal",
> "BW Hazel", "Captain Adams", "Captain Antonis", "Cemtex Wisdom",
> "CENTENARIO BLU", "Cepheus Ocean", "Cerafina", "Cetus Ocean",
> "CF Diamond", "CHARADE", "CHLOE", "CLARKE QUAY", "CLIPPER AMSTERDAM",
> "Clipper Victory", "CMB Sakura", "Cofco 1", "COLUMBIA RIVER",
> "Coral Diamond", "COREFORTUNE OL", "Cosmar", "Coventry", "CP GUANGZHOU",
> "Crimson Ark", "Crimson Kingdom", "Cymona Star", "DALIAN STAR",
> "De Xu Hai", "Densa Pelican", "DESERT CHALLENGER", "DEVON BAY",
> "DIAMOND QUEEN", "Dias", "Dimitris Apesakis", "Donousa", "DORIC",
> "DORIC SHOGUN", "DORO", "EASTER N", "Efrain A", "Egret Oasis",
> "Eirini P", "Elena", "Emerald Dongji", "Emerald Star", "ENDLESS HORIZON",
> "ENY", "Erikoussa", "ESSEX STRAIT", "Eternal Bliss", "Eternal Grace",
> "EUROPA BAY", "Ever Grace", "EVER SOVEREIGN", "Everglory", "Evmar",
> "FEDERAL TRIDENT", "FH Fang Cheng", "FH Rizhao", "Fiji", "FILIA JOY",
> "Flag Lama", "FLIPPER", "FLORINDA", "Fortune Harmony", "FORTUNE LADY",
> "FORTUNE UNITY", "FRAMURA", "FURNESS VICTORIA", "Galio", "GANNET BULKER",
> "GENCO RAPTOR", "GH CITATION", "GH URBAN SEA", "Giorgakis", "Giorgis",
> "GLOBAL PRIME", "GLOBAL SUCCESS", "GLOBAL VISION", "Glory", "Golden Jake",
> "GOLDEN LIBRA", "Good Wish", "Graecia Aeterna", "GRAND CONCORD",
> "GRAND MARCIA", "Great Rich", "GUARDIANSHIP", "Hampton Bay",
> "Hampton Bridge", "HANTON TRADER I", "Hercules Ocean", "Hermes",
> "Hong Hing", "Hong Jing", "Hong Sheng", "HOPA I", "Huayang Spirit",
> "Huayeng Dream", "Indian Harmony", "INDIGO EVOLUTION", "INDIGO RIVER",
> "INDRA OLDENDORFF", "Innovation", "INNOVATION", "Inspiration",
> "IRIS HALO", "IRIS OLDENDORFF", "ISMENE", "Istria", "IYO WIND",
> "Jag Aalok", "Jag Akshay", "Jag Arnav", "JIA SHENG SHAN", "JIN RUN",
> "Jin Zhu Hai", "John M. Carras", "JOSCO HANGZHOU", "JPS AFRODITI",
> "K SPINEL", "K. GARNET", "K. OPAL", "KANG CHENG", "Karlovasi",
> "Katerina III", "KAVO PALOMA", "Kea", "Kerkyra", "Key Evolution",
> "Key Pacifico", "KING ISLAND", "KING MILO", "KM Fukuyama", "KM Hong Kong",
> "KM Keelung", "KM Yokohama", "KMARIN SINGAPORE", "KT Birdie",
> "KYRA PANAGHIA", "Lady I", "LEO ADVANCE", "LESEDI QUEEN", "LILA",
> "LISSA TOPIC", "LOCH SHUNA", "Long Dar", "LOUISIANA MAMA", "LOWLANDS
> MAINE",
> "LUMINOUS HALO", "LUNITA", "LYRIC HARMONY", "Macheras", "MALMO",
> "MANDARIN CROWN", "MANDARIN NOBLE", "Marathassa", "MARIE GRACE",
> "MARINER", "MARITIME PROSPERITY", "MARY LINA", "Mastro Nikos",
> "MBA Future", "Medi Matsuura", "MEDI SALERNO", "MELBOURNE", "MELIA",
> "METSOVO", "MG Explorer", "MG Kronos", "MG Sakura", "Miao Xiang",
> "MISATO K", "Mistral I", "Miyama", "Mykonos", "Myra", "Myrto",
> "N Bonanza", "Nadeshiko", "Naias", "NAUTICAL MARIE", "NAUTICAL RUNA",
> "NAUTICAL SIF", "Navios Amber", "NAVIOS ARC", "NAVIOS ARMONIA",
> "Navios Harmony", "Navios Orbiter", "NAVIOS SOUTHERN STAR", "NEFELI",
> "NEW BLISS", "NEW DIRECTION", "NEWSEAS PEARL", "NIKKEI SIRIUS",
> "NIKKEI VERDE", "Nikolaos", "NIKOLAS XL", "Nikomarin", "Nord Capella",
> "Nord Fortune", "NOSHIMA", "Nuri Bey", "OCCITAN PAUILLAC", "OCEAN BAO",
> "OCEAN BELT", "OCEAN FAVOUR", "Ocean Garlic", "OCEAN HARVEST",
> "OCEAN PRIDE", "OCEAN PRINCE", "OCEAN PRINCESS", "OCEAN ROYAL",
> "OCEAN SPLENDOR", "OCEAN TIANBAO", "OCEAN VENUS", "Ocean Wind",
> "Oceana", "Odysseas L", "OKINAWA", "Olivia R", "OLYMPOS", "Omicron Light",
> "OMICRON NIKOS", "OMICRON SKY", "Omicron Trader", "ORCHID HALO",
> "Orient Genesis", "ORIENT GRACE", "OZGUR AKSOY", "PACIFIC ADVANCE",
> "PACIFIC NEXUS", "PACIFIC TALENT", "PACIFIC VICTORY", "Palais",
> "Pan Ceres", "PAN VIVA", "Panafrican", "Panamanian", "Panasiatic",
> "PANORIA", "Panther Max", "PARADISE ISLAND", "PAUL OLDENDORFF",
> "Peace Ark", "PEAK PEGASUS", "Pedhoulas Farmer", "Pedhoulas Trader",
> "PENTA", "PERIDOT", "PERTH I", "Phaedra", "PHOENIX K", "Phoenix Ocean",
> "Pictor", "PILATUS VENTURE", "Popi S", "PORT ESTRELA", "Proteas",
> "QUEEN JHANSI", "QUEEN KOBE", "Rave", "RB Eden", "Real Happiness",
> "RECCO", "REGAL", "RESURGENCE", "RIGI VENTURE", "Rosalia D? Amato",
> "Rosco Banyan", "Rosco Cypress", "Rosco Ginkgo", "Rosco Lemon",
> "Rosco Litchi", "Rosco Palm", "ROSCO PLUM", "Rosco Poplar", "Rosco
> Sandalwood",
> "RR Australia", "SAGAR JYOTI", "SAGAR SHAKTI", "SAGARJEET", "SAGE
> COLORADO",
> "SAGE PIONEER", "SAILING SKY", "Sakizaya Power", "SAN ANTONIO",
> "SANTA KATARINA", "SANTA VALENTINA", "SANYU", "SBI Bolero", "SBI BOLERO",
> "SBI Samba", "Scarlet Cardinal", "SCARLET CARDINAL", "Scarlet Falcon",
> "Sea Duty", "Sea Hermes", "Sea Pegasus", "SEA PIONEER", "Sea Pluto",
> "Seatribute", "Shandong Fu Hui", "Shandong Hai Chang", "Shangdong Fu Ze",
> "Shao Shan 5", "Shao Shan 8", "SIFNOS", "Silver Dragon", "SIMURGH",
> "Skiathos", "SKY KNIGHT", "SONGA GLORY", "SOUTHEND", "SPARNA",
> "SPRING AEOLIAN", "SPRING EAGLE", "SPRING ZEPHYR", "SSI CHALLENGER",
> "Stalo", "STAMFORD EAGLE", "STAR AQUARIUS", "STAR JENNIFER",
> "Star Laura", "Star of Sawara", "STAR PISCES", "Star Renee",
> "STAR VANESSA", "STARRY SKY", "STH LONDON", "STOVE FRIEND", "STOVE OCEAN",
> "SUNLEAF GRACE", "SUNLEAF STAR", "SUNNY HOPE", "SUNNY ROYAL",
> "SUZAKU", "Syros I", "Tahiti One", "Tai Promotion", "TAI PROSPERITY",
> "TAI SPRING", "TAI STAR", "TAI SUMMIT", "Tangerine Island", "TANGERINE
> ISLAND",
> "TANIKAZE", "TASSOS N", "Taurus Ocean", "TEAL BULKER", "TENRO MARU",
> "Tenten", "THEMISTOCLES", "Theodor Oldendorff", "THEODOR OLDENDORFF",
> "Theodore Jr.", "Theresa Hebei", "Theresa Jilin", "Theresa Shandong",
> "TIGER HENAN", "TIGER NORTH", "TIGER PIONEER", "Tiger South",
> "TN SUNRISE", "TOMORROW", "Topaz", "TORENIA", "TR Lady", "Trade Unity",
> "TRANS OCEANIC", "TRUSTN TRADER II", "TSCHAIKOWSKY", "TTM DRAGON",
> "Tuo Fu 6", "Tycoon", "ULTRA PANTHER", "Unity", "UNITY DISCOVERY",
> "Valadon", "VEGA ROSE", "VELA OCEAN", "VENUS", "VENUS HALO",
> "VICTORIA", "VISHVA ANAND", "Vitahorizon", "Vitakosmos", "Vivian",
> "VSC CASTOR", "VSC TRITON", "XING XI HAI", "Yarrawonga", "Yue Guan Feng",
> "ZEN-NOH GRAIN MAGNOLIA", "ZEN-NOH GRAIN PEGASUS", "Zheng Zhi",
> "Zhi He"), class = "factor"), Draft = c(12L, 12L, 12L, 13L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 14L, 14L, 14L, 12L,
> 13L, 12L, 12L, 14L, 12L, 14L, 13L, 12L, 12L, 12L, 14L, 12L, 12L,
> 11L, 13L, 13L, 14L, 12L, 12L, 13L, 14L, 12L, 13L, 13L, 12L, 14L,
> 14L, 13L, 12L, 14L, 14L, 13L, 14L, 14L, 12L, 13L, 12L, 12L, 13L,
> 12L, 12L, 14L, 14L, 14L, 12L, 12L, 12L, 12L, 14L, 13L, 14L, 12L,
> 13L, 14L, 13L, 12L, 12L, 12L, 12L, 12L, 12L, 14L, 12L, 14L, 13L,
> 14L, 14L, 12L, 12L, 12L, 14L, 12L, 12L, 13L, 14L, 13L, 13L, 12L,
> 14L, 13L, 13L, 14L, 12L, 12L, 14L, 12L, 12L, 14L, 12L, 13L, 13L,
> 14L, 14L, 14L, 14L, 12L, 12L, 14L, 13L, 12L, 12L, 12L, 13L, 12L,
> 14L, 12L, 12L, 14L, 14L, 12L, 12L, 12L, 12L, 12L, 12L, 13L, 12L,
> 12L, 12L, 13L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 14L, 12L, 12L,
> 12L, 12L, 14L, 14L, 14L, 14L, 10L, 12L, 11L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 13L, 14L, 14L, 14L, 12L, 12L, 12L,
> 14L, 12L, 12L, 12L, 14L, 14L, 14L, 14L, 12L, 12L, 11L, 12L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 10L, 12L, 12L, 12L, 11L,
> 13L, 14L, 14L, 12L, 13L, 14L, 14L, 12L, 13L, 14L, 12L, 12L, 12L,
> 14L, 13L, 14L, 12L, 12L, 14L, 14L, 12L, 14L, 13L, 12L, 14L, 12L,
> 14L, 12L, 12L, 12L, 12L, 14L, 13L, 12L, 13L, 12L, 12L, 14L, 12L,
> 14L, 14L, 14L, 12L, 12L, 12L, 13L, 12L, 14L, 14L, 14L, 12L, 12L,
> 12L, 12L, 13L, 12L, 12L, 12L, 14L, 14L, 12L, 12L, 14L, 12L, 14L,
> 14L, 12L, 12L, 12L, 13L, 12L, 12L, 12L, 12L, 12L, 14L, 14L, 13L,
> 12L, 13L, 14L, 12L, 12L, 12L, 12L, 13L, 14L, 12L, 14L, 13L, 14L,
> 14L, 14L, 14L, 14L, 13L, 14L, 14L, 13L, 14L, 12L, 12L, 14L, 14L,
> 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 13L, 12L, 14L,
> 14L, 14L, 12L, 14L, 14L, 14L, 12L, 12L, 14L, 14L, 14L, 14L, 12L,
> 14L, 14L, 12L, 14L, 14L, 12L, 13L, 12L, 12L, 12L, 14L, 14L, 13L,
> 14L, 12L, 13L, 13L, 13L, 12L, 12L, 12L, 12L, 12L, 14L, 12L, 14L,
> 13L, 14L, 12L, 12L, 14L, 13L, 14L, 14L, 14L, 12L, 14L, 14L, 12L,
> 12L, 14L, 12L, 14L, 12L, 12L, 12L, 14L, 12L, 13L, 14L, 12L, 12L,
> 14L, 12L, 12L, 12L, 12L, 12L, 14L, 12L, 12L, 12L, 14L, 14L, 12L,
> 12L, 14L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 14L, 12L, 13L, 13L,
> 13L, 14L, 14L, 12L, 12L, 12L, 12L, 12L, 13L, 12L, 14L, 13L, 12L,
> 12L, 12L, 12L, 12L, 13L, 12L, 14L, 13L, 13L, 13L, 11L, 12L, 14L,
> 14L, 12L, 14L, 12L, 11L, 12L, 12L, 12L, 12L, 14L, 12L, 12L, 12L,
> 12L, 14L, 14L, 12L, 12L, 12L, 14L, 12L, 12L, 12L, 12L, 14L, 12L,
> 13L, 14L, 12L, 12L, 14L, 14L, 12L, 12L, 12L, 13L, 12L, 14L, 14L,
> 14L, 12L, 14L, 13L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 13L, 6L,
> 12L, 12L, 14L, 14L, 14L, 14L, 12L, 14L, 12L, 12L, 12L, 12L, 14L,
> 12L, 14L, 12L, 12L, 12L, 14L, 12L, 12L, 13L, 14L, 12L, 13L, 12L,
> 14L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L), TOTALCOST = c(194364L, 219364L, 198260L, 237456L,
> 197159L, 198992L, 194337L, 219337L, 199198L, 196604L, 230607L,
> 196604L, 196604L, 194496L, 238600L, 236936L, 237476L, 197220L,
> 236950L, 197300L, 182042L, 237938L, 199221L, 237475L, 239190L,
> 157406L, 157211L, 182211L, 237475L, 182475L, 181599L, 156599L,
> 238269L, 238402L, 238069L, 161436L, 225031L, 238180L, 237572L,
> 189861L, 239005L, 239049L, 163814L, 240064L, 239171L, 238410L,
> 200878L, 239019L, 239087L, 239350L, 239352L, 240275L, 164844L,
> 238400L, 225158L, 202495L, 239681L, 201791L, 226863L, 244092L,
> 244590L, 239171L, 189811L, 219412L, 228480L, 203650L, 237514L,
> 247451L, 244739L, 211770L, 244308L, 239197L, 238419L, 224977L,
> 157362L, 162434L, 162434L, 162434L, 162434L, 239681L, 163316L,
> 237265L, 243920L, 244088L, 244163L, 202256L, 159592L, 201346L,
> 239187L, 189800L, 191959L, 239476L, 239171L, 238087L, 238052L,
> 164169L, 245057L, 244215L, 240812L, 239156L, 156879L, 197853L,
> 245367L, 164710L, 164710L, 244192L, 211110L, 239156L, 244213L,
> 237504L, 239018L, 241150L, 244447L, 238506L, 210298L, 243482L,
> 239166L, 159489L, 184600L, 226439L, 239127L, 235243L, 244296L,
> 159696L, 189046L, 244355L, 244446L, 187595L, 162595L, 162595L,
> 162595L, 170604L, 188774L, 244103L, 188680L, 163611L, 200551L,
> 244055L, 170606L, 169154L, 194154L, 170905L, 200551L, 191412L,
> 166412L, 243969L, 170483L, 210719L, 168554L, 164016L, 245158L,
> 245131L, 245186L, 239166L, 116360L, 155698L, 155698L, 155698L,
> 155698L, 223827L, 191968L, 159650L, 189999L, 201193L, 201011L,
> 226218L, 201218L, 243970L, 244291L, 243993L, 243993L, 236035L,
> 236035L, 236035L, 244070L, 159692L, 194183L, 169110L, 241994L,
> 238216L, 238301L, 242948L, 169810L, 189280L, 164662L, 164156L,
> 189156L, 163989L, 163924L, 159577L, 159650L, 170566L, 170598L,
> 188975L, 189006L, 99983L, 191595L, 166907L, 228744L, 166621L,
> 243593L, 244001L, 239035L, 172934L, 238288L, 241665L, 241665L,
> 193991L, 238361L, 238361L, 164215L, 168867L, 194304L, 241732L,
> 237745L, 237911L, 195374L, 195374L, 244044L, 244044L, 169118L,
> 244040L, 244040L, 198518L, 244106L, 236206L, 244136L, 191390L,
> 164516L, 165137L, 232682L, 244021L, 244101L, 236136L, 244101L,
> 194181L, 169181L, 244058L, 212313L, 238240L, 242502L, 239175L,
> 166221L, 184500L, 170027L, 237701L, 211035L, 244050L, 243745L,
> 242782L, 164482L, 166341L, 189482L, 174552L, 244213L, 190960L,
> 184494L, 169116L, 239123L, 239121L, 165097L, 206396L, 241738L,
> 165622L, 242651L, 250331L, 178778L, 169133L, 238280L, 244044L,
> 193182L, 194156L, 194156L, 169156L, 196240L, 244060L, 244060L,
> 244060L, 196050L, 243546L, 243546L, 195500L, 195500L, 170389L,
> 195389L, 243549L, 243503L, 211398L, 243510L, 238436L, 238546L,
> 243907L, 243654L, 238709L, 238656L, 244171L, 244136L, 243215L,
> 243957L, 243957L, 164455L, 164455L, 243287L, 238203L, 243738L,
> 243266L, 243294L, 243548L, 243262L, 243262L, 237628L, 243266L,
> 243382L, 243927L, 243574L, 168364L, 243598L, 243596L, 243647L,
> 191094L, 243655L, 244550L, 243907L, 200636L, 210208L, 243632L,
> 243632L, 243367L, 243048L, 212125L, 244651L, 243357L, 202542L,
> 243778L, 243502L, 170036L, 237911L, 195234L, 195220L, 170220L,
> 239391L, 244397L, 244397L, 238631L, 225921L, 244034L, 244051L,
> 243310L, 189976L, 164976L, 164976L, 164999L, 165154L, 243439L,
> 211003L, 244034L, 243859L, 243859L, 170008L, 175602L, 238078L,
> 243484L, 243619L, 243333L, 243289L, 200618L, 243392L, 243376L,
> 164873L, 235797L, 243930L, 191502L, 243906L, 195351L, 170527L,
> 195307L, 243551L, 175551L, 244759L, 238122L, 178863L, 170249L,
> 243701L, 200549L, 236254L, 189982L, 163055L, 203863L, 243561L,
> 165089L, 164574L, 193750L, 238061L, 240569L, 175435L, 164313L,
> 243153L, 189825L, 189825L, 164825L, 189825L, 164340L, 203691L,
> 168483L, 243970L, 193608L, 243054L, 243115L, 243115L, 243043L,
> 243115L, 201917L, 204065L, 177917L, 178745L, 178735L, 243911L,
> 200920L, 242726L, 243042L, 204204L, 181109L, 179157L, 200093L,
> 179164L, 243676L, 235476L, 243862L, 243873L, 243945L, 243927L,
> 168102L, 168102L, 243734L, 243929L, 179053L, 246381L, 204130L,
> 200546L, 200301L, 174699L, 199699L, 178309L, 243549L, 204424L,
> 216428L, 203785L, 204101L, 245074L, 243224L, 163661L, 179036L,
> 199248L, 243458L, 199190L, 200330L, 200406L, 174754L, 243138L,
> 195257L, 244796L, 243069L, 179132L, 204171L, 243718L, 243719L,
> 200616L, 175749L, 179010L, 243037L, 178405L, 243953L, 243923L,
> 243485L, 200891L, 239635L, 243661L, 204041L, 179002L, 204070L,
> 206036L, 198896L, 164487L, 166891L, 246375L, 200217L, 179153L,
> 210112L, 243941L, 243052L, 243724L, 246328L, 164311L, 243736L,
> 154373L, 192956L, 237690L, 193282L, 244901L, 198985L, 246315L,
> 179272L, 204007L, 202386L, 246315L, 202386L, 178856L, 243704L,
> 243750L, 164533L, 246330L, 204082L, 243790L, 189359L, 164359L,
> 168286L, 168286L, 175262L, 164395L, 189395L, 164299L, 189299L,
> 189110L, 154953L, 166251L, 175373L, 235883L), BUNKER = c(350L,
> 405L, 276L, 350L, 373L, 355L, 370L, 343L, 345L, 288L, 313L, 358L,
> 440L, 292L, 318L, 360L, 318L, 288L, 350L, 349L, 350L, 318L, 345L,
> 313L, 313L, 378L, 298L, 363L, 315L, 435L, 423L, 440L, 343L, 355L,
> 313L, 318L, 435L, 313L, 345L, 318L, 349L, 353L, 368L, 362L, 348L,
> 345L, 296L, 313L, 365L, 355L, 368L, 362L, 378L, 348L, 313L, 418L,
> 348L, 418L, 345L, 362L, 318L, 350L, 300L, 343L, 348L, 349L, 298L,
> 313L, 303L, 388L, 370L, 360L, 362L, 338L, 313L, 350L, 313L, 423L,
> 313L, 343L, 353L, 313L, 318L, 360L, 292L, 423L, 298L, 343L, 313L,
> 367L, 368L, 303L, 355L, 353L, 370L, 296L, 303L, 355L, 343L, 313L,
> 353L, 370L, 313L, 303L, 418L, 373L, 353L, 349L, 349L, 363L, 367L,
> 355L, 365L, 443L, 440L, 350L, 363L, 318L, 423L, 364L, 313L, 422L,
> 358L, 430L, 358L, 343L, 370L, 298L, 362L, 378L, 419L, 445L, 362L,
> 313L, 432L, 373L, 355L, 318L, 353L, 283L, 338L, 255L, 276L, 276L,
> 430L, 313L, 367L, 276L, 300L, 313L, 283L, 350L, 313L, 313L, 362L,
> 288L, 425L, 313L, 348L, 426L, 345L, 313L, 353L, 355L, 443L, 355L,
> 423L, 343L, 355L, 348L, 303L, 298L, 318L, 367L, 313L, 435L, 313L,
> 425L, 355L, 318L, 368L, 370L, 343L, 430L, 348L, 300L, 313L, 423L,
> 350L, 443L, 338L, 276L, 292L, 358L, 378L, 313L, 443L, 313L, 348L,
> 338L, 370L, 313L, 318L, 360L, 363L, 358L, 345L, 353L, 318L, 313L,
> 338L, 345L, 345L, 313L, 355L, 348L, 313L, 422L, 363L, 313L, 276L,
> 318L, 350L, 363L, 313L, 292L, 350L, 368L, 418L, 298L, 375L, 313L,
> 315L, 353L, 313L, 288L, 348L, 360L, 413L, 318L, 345L, 365L, 292L,
> 348L, 318L, 362L, 426L, 313L, 365L, 367L, 315L, 368L, 425L, 276L,
> 345L, 360L, 350L, 405L, 362L, 313L, 350L, 343L, 360L, 313L, 355L,
> 303L, 358L, 419L, 350L, 298L, 367L, 313L, 343L, 405L, 419L, 345L,
> 303L, 367L, 265L, 378L, 345L, 318L, 432L, 350L, 445L, 303L, 364L,
> 296L, 418L, 365L, 370L, 313L, 362L, 318L, 313L, 353L, 373L, 360L,
> 345L, 313L, 353L, 422L, 365L, 315L, 365L, 313L, 313L, 360L, 413L,
> 345L, 318L, 338L, 355L, 313L, 349L, 418L, 360L, 303L, 313L, 355L,
> 313L, 318L, 367L, 425L, 270L, 318L, 349L, 353L, 318L, 349L, 345L,
> 368L, 318L, 313L, 362L, 338L, 303L, 296L, 345L, 364L, 283L, 368L,
> 368L, 343L, 423L, 367L, 368L, 313L, 298L, 355L, 405L, 292L, 368L,
> 355L, 440L, 313L, 313L, 313L, 438L, 358L, 313L, 292L, 338L, 313L,
> 313L, 373L, 360L, 345L, 423L, 348L, 370L, 292L, 303L, 345L, 265L,
> 364L, 315L, 338L, 350L, 368L, 313L, 318L, 370L, 303L, 423L, 388L,
> 343L, 362L, 355L, 426L, 350L, 365L, 345L, 355L, 343L, 443L, 313L,
> 270L, 360L, 350L, 435L, 445L, 313L, 348L, 355L, 430L, 362L, 349L,
> 349L, 298L, 313L, 292L, 375L, 367L, 318L, 315L, 368L, 296L, 300L,
> 318L, 296L, 425L, 355L, 288L, 353L, 370L, 362L, 355L, 318L, 313L,
> 435L, 343L, 435L, 292L, 355L, 440L, 338L, 313L, 355L, 288L, 440L,
> 435L, 303L, 360L, 270L, 435L, 283L, 373L, 353L, 265L, 265L, 425L,
> 367L, 353L, 367L, 448L, 368L, 283L, 350L, 343L, 353L, 303L, 355L,
> 368L, 373L, 343L, 375L, 348L, 413L, 362L, 303L, 298L, 313L, 300L,
> 440L, 349L, 355L, 318L, 355L, 388L, 363L, 440L, 292L, 373L, 349L,
> 300L, 315L, 338L, 373L, 353L, 348L, 370L, 362L, 338L, 440L, 440L,
> 350L, 296L, 343L, 368L, 349L, 423L, 364L, 348L, 349L, 423L, 353L,
> 345L, 370L, 292L, 355L, 349L, 355L, 276L, 440L, 283L, 358L, 375L,
> 348L, 440L, 355L, 423L, 445L, 368L, 348L, 355L, 367L), CHARTERVALUE =
> c(14000L,
> 12825L, 10475L, 11850L, 13250L, 12100L, 11875L, 14500L, 12500L,
> 10500L, 13375L, 14500L, 13400L, 11000L, 12750L, 11625L, 11875L,
> 10500L, 11850L, 11900L, 11850L, 12750L, 12500L, 12000L, 12250L,
> 12750L, 10450L, 12900L, 12425L, 13375L, 12075L, 13400L, 12625L,
> 11125L, 12000L, 11875L, 13400L, 12000L, 12500L, 12750L, 11900L,
> 13625L, 12750L, 11800L, 12500L, 12500L, 9850L, 12000L, 12350L,
> 11125L, 12750L, 11800L, 12750L, 12500L, 12250L, 13125L, 13125L,
> 13125L, 12500L, 11800L, 11875L, 11850L, 11500L, 12625L, 13125L,
> 11900L, 10425L, 12250L, 12375L, 12400L, 11875L, 11625L, 11800L,
> 12400L, 12000L, 14000L, 12000L, 13125L, 12250L, 12625L, 13875L,
> 12400L, 11875L, 11625L, 11000L, 12075L, 10450L, 12625L, 13375L,
> 12875L, 13125L, 12375L, 11125L, 13625L, 11875L, 9850L, 12375L,
> 12100L, 14500L, 12000L, 13875L, 11875L, 12400L, 12375L, 13125L,
> 13250L, 13875L, 11900L, 11900L, 12900L, 12875L, 12100L, 12350L,
> 12375L, 13125L, 11850L, 12900L, 12750L, 13125L, 13875L, 13375L,
> 13025L, 14500L, 13400L, 14500L, 12625L, 11875L, 10450L, 11800L,
> 12750L, 12625L, 12250L, 11800L, 12250L, 13250L, 13250L, 12100L,
> 12750L, 13625L, 11125L, 12400L, 10250L, 10475L, 10475L, 13400L,
> 13375L, 12875L, 10475L, 11500L, 12400L, 11125L, 11850L, 13375L,
> 12400L, 11800L, 10500L, 13375L, 13375L, 12500L, 12625L, 12500L,
> 12000L, 13875L, 11125L, 12375L, 11125L, 13125L, 12625L, 12100L,
> 12500L, 12375L, 10450L, 12750L, 12875L, 12250L, 13400L, 12250L,
> 13375L, 11125L, 12750L, 12750L, 11875L, 14500L, 13400L, 12500L,
> 11500L, 13375L, 13125L, 11850L, 12375L, 12400L, 10475L, 11000L,
> 14500L, 12750L, 12400L, 12375L, 12250L, 12500L, 12400L, 11875L,
> 12250L, 12750L, 11625L, 12900L, 14500L, 12500L, 13875L, 11875L,
> 13375L, 12400L, 12500L, 12500L, 13375L, 12100L, 12500L, 12400L,
> 13025L, 12900L, 12400L, 10475L, 12750L, 11850L, 12900L, 13375L,
> 11000L, 11850L, 13125L, 13125L, 10450L, 12500L, 12250L, 12425L,
> 13875L, 12000L, 10500L, 13125L, 11625L, 12975L, 12750L, 12500L,
> 12350L, 11000L, 13125L, 12750L, 11800L, 12625L, 13375L, 12350L,
> 12875L, 12425L, 12750L, 12675L, 10475L, 12500L, 11625L, 11850L,
> 12825L, 11800L, 13375L, 14000L, 12625L, 11625L, 12400L, 11125L,
> 12375L, 14500L, 12625L, 14000L, 10425L, 12875L, 13375L, 14500L,
> 12825L, 12625L, 12500L, 12375L, 12875L, 9875L, 12750L, 12500L,
> 12750L, 13250L, 11850L, 12250L, 12375L, 13875L, 9850L, 13125L,
> 12350L, 11875L, 12000L, 11800L, 11875L, 12000L, 13875L, 13250L,
> 11625L, 12500L, 12400L, 13625L, 13025L, 12350L, 12425L, 12350L,
> 12400L, 12400L, 11625L, 12975L, 12500L, 11875L, 12400L, 11125L,
> 12000L, 11900L, 13125L, 11625L, 12375L, 12250L, 12100L, 13375L,
> 12750L, 12875L, 12675L, 10000L, 11875L, 11900L, 13625L, 12750L,
> 11900L, 12500L, 12750L, 12750L, 12000L, 11800L, 12400L, 12375L,
> 9850L, 12500L, 13875L, 11125L, 12750L, 12750L, 12625L, 12075L,
> 12875L, 13125L, 12250L, 10450L, 11125L, 12825L, 11000L, 13125L,
> 11125L, 13125L, 12000L, 12000L, 13375L, 13375L, 14500L, 12000L,
> 11000L, 12400L, 12250L, 12000L, 13250L, 11625L, 12500L, 13125L,
> 13125L, 11875L, 11000L, 12375L, 12500L, 9875L, 13875L, 12425L,
> 12400L, 14000L, 12750L, 12400L, 11875L, 11875L, 12375L, 12075L,
> 12400L, 14500L, 11800L, 12100L, 12625L, 14000L, 12350L, 12500L,
> 12100L, 12625L, 12375L, 12250L, 10000L, 11625L, 14000L, 13375L,
> 12250L, 13375L, 12500L, 11125L, 13400L, 11800L, 11900L, 11900L,
> 10425L, 12400L, 11000L, 12500L, 12875L, 12750L, 12425L, 12750L,
> 9850L, 11500L, 12750L, 9850L, 13375L, 11125L, 10500L, 13875L,
> 11875L, 11800L, 11125L, 12750L, 12250L, 13375L, 12625L, 13375L,
> 11000L, 11125L, 13125L, 12400L, 13375L, 12100L, 10500L, 13075L,
> 13375L, 12375L, 11625L, 10000L, 13400L, 11125L, 13250L, 13875L,
> 9875L, 9875L, 13375L, 12875L, 13875L, 12875L, 13500L, 12750L,
> 11125L, 11850L, 12625L, 13875L, 12375L, 12100L, 13125L, 13250L,
> 12625L, 12500L, 13125L, 12975L, 11800L, 12375L, 10425L, 13375L,
> 11500L, 13075L, 11900L, 12100L, 11875L, 11125L, 12400L, 12900L,
> 13400L, 11000L, 13250L, 11900L, 11500L, 12425L, 12400L, 13250L,
> 13625L, 12500L, 11875L, 11800L, 12400L, 13125L, 13075L, 14000L,
> 9850L, 14500L, 13125L, 11900L, 13125L, 13875L, 13125L, 11900L,
> 13125L, 13875L, 12500L, 11875L, 11000L, 11125L, 11900L, 11125L,
> 10475L, 13075L, 11125L, 14500L, 12500L, 13125L, 13125L, 12100L,
> 13125L, 12250L, 13125L, 12500L, 11125L, 12875L)), class = "data.frame",
> row.names = c(NA,
> -527L))
>
>
> Any help and/or guidance will be greatly appreciated,
>
> Best regards,
>
> Paul
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From m@||km@h23 @end|ng |rom gm@||@com  Wed Apr 24 13:34:34 2019
From: m@||km@h23 @end|ng |rom gm@||@com (Mahnoor Malik)
Date: Wed, 24 Apr 2019 16:34:34 +0500
Subject: [R] (no subject)
Message-ID: <CABiDw9iJX-099986qXuevz+ooto2hTohkPa5L-DsGLB3QzLUnQ@mail.gmail.com>



	[[alternative HTML version deleted]]


From HDor@n @end|ng |rom @|r@org  Wed Apr 24 16:56:28 2019
From: HDor@n @end|ng |rom @|r@org (Doran, Harold)
Date: Wed, 24 Apr 2019 14:56:28 +0000
Subject: [R] Read_fwf in package readr, double vs. numeric
Message-ID: <BN7PR05MB5857A5350CA9BA5A7945AC59CA3C0@BN7PR05MB5857.namprd05.prod.outlook.com>

Suppose I have the following data sitting in a fwf file 'foo.txt'. The point of this email is to ask the group how to properly read in the value in this pseudo-data "1e-20" using the read_fwf function in the package readr.

11e-201043
1712201043
1912201055

First, suppose I do it this way, where in this case "D" is used for double precision.

library(readr)
pos <- fwf_positions(c(1,2,7), c(1,6,10))
type <- c('N','D','N')
types <- paste0(type, collapse = '')
types <- chartr('NCD', 'ncd', types)  

read_fwf(file = myFile, col_positions = pos, col_types = types)

# A tibble: 3 x 3
     X1       X2    X3
  <dbl>    <dbl> <dbl>
1     1 1.00e-20  1043
2     1 7.12e+ 4  1043
3     1 9.12e+ 4  1055

This seemingly works well and properly captures the value. However, if I instead were to indicate to the function that *all* of my columns were numeric (just insert this one line in lieu of the other above)

type <- c('N','N','N')

# A tibble: 3 x 3
     X1    X2    X3
  <dbl> <dbl> <dbl>
1     1     1  1043
2     1 71220  1043
3     1 91220  1055

The read in is not correct. Here is the pragmatic issue. I have a legacy program that spits out the layout structure of the fwf file (start, end positions) and also indicates what the column types are. This layout file we receive always uses a column type of numeric (N) for any numeric types (including the column holding values such as 1e-20). 

This layout file will not change so I need to figure out how to solve the problem within my read in program. I suppose one option is that I could manually change any values of "N" to "D" in my R code. That seems to work. But not sure if that is the "right" way to solve this issue.

Thanks
Harold


From @@r@h@go@|ee @end|ng |rom gm@||@com  Wed Apr 24 17:11:36 2019
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Wed, 24 Apr 2019 11:11:36 -0400
Subject: [R] Read_fwf in package readr, double vs. numeric
In-Reply-To: <BN7PR05MB5857A5350CA9BA5A7945AC59CA3C0@BN7PR05MB5857.namprd05.prod.outlook.com>
References: <BN7PR05MB5857A5350CA9BA5A7945AC59CA3C0@BN7PR05MB5857.namprd05.prod.outlook.com>
Message-ID: <CAM_vju=HGnNGv302cNp9s7sxQN6_thaLdSH2hf+19OTy3C3Fuw@mail.gmail.com>

Hi,

I can't reproduce your problem: with readr 1.1.1 on linux, it works as
expected. Letting read_fwf guess the types also works fine. (See
below.)

If you aren't running the current version of readr, update and retry.
If you are, then we probably need more info, at least sessionInfo().

Sarah



library(readr)
myFile <- "foo.txt"
pos <- fwf_positions(c(1,2,7), c(1,6,10))


type <- c('N','D','N')
types <- paste0(type, collapse = '')
types <- chartr('NCD', 'ncd', types)
read_fwf(file = myFile, col_positions = pos, col_types = types)

# A tibble: 3 x 3
     X1       X2    X3
  <dbl>    <dbl> <dbl>
1     1 1.00e-20  1043
2     1 7.12e+ 4  1043
3     1 9.12e+ 4  1055


type <- c('N','N','N')
types <- paste0(type, collapse = '')
types <- chartr('NCD', 'ncd', types)
read_fwf(file = myFile, col_positions = pos, col_types = types)

# A tibble: 3 x 3
     X1       X2    X3
  <dbl>    <dbl> <dbl>
1     1 1.00e-20  1043
2     1 7.12e+ 4  1043
3     1 9.12e+ 4  1055



> read_fwf(file = myFile, col_positions = pos, col_types = NULL)
Parsed with column specification:
cols(
  X1 = col_double(),
  X2 = col_double(),
  X3 = col_double()
)
# A tibble: 3 x 3
     X1       X2    X3
  <dbl>    <dbl> <dbl>
1     1 1.00e-20  1043
2     1 7.12e+ 4  1043
3     1 9.12e+ 4  1055




> sessionInfo()
R version 3.5.3 (2019-03-11)
Platform: x86_64-redhat-linux-gnu (64-bit)
Running under: Fedora 28 (Workstation Edition)

Matrix products: default
BLAS/LAPACK: /usr/lib64/R/lib/libRblas.so

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] readr_1.3.1    colorout_1.2-0

loaded via a namespace (and not attached):
 [1] compiler_3.5.3   assertthat_0.2.0 R6_2.4.0         cli_1.0.1
 [5] hms_0.4.2        tools_3.5.3      pillar_1.3.1     tibble_2.0.1
 [9] Rcpp_1.0.0       crayon_1.3.4     utf8_1.1.4       fansi_0.4.0
[13] pkgconfig_2.0.2  rlang_0.3.1


On Wed, Apr 24, 2019 at 10:56 AM Doran, Harold <HDoran at air.org> wrote:
>
> Suppose I have the following data sitting in a fwf file 'foo.txt'. The point of this email is to ask the group how to properly read in the value in this pseudo-data "1e-20" using the read_fwf function in the package readr.
>
> 11e-201043
> 1712201043
> 1912201055
>
> First, suppose I do it this way, where in this case "D" is used for double precision.
>
> library(readr)
> pos <- fwf_positions(c(1,2,7), c(1,6,10))
> type <- c('N','D','N')
> types <- paste0(type, collapse = '')
> types <- chartr('NCD', 'ncd', types)
>
> read_fwf(file = myFile, col_positions = pos, col_types = types)
>
> # A tibble: 3 x 3
>      X1       X2    X3
>   <dbl>    <dbl> <dbl>
> 1     1 1.00e-20  1043
> 2     1 7.12e+ 4  1043
> 3     1 9.12e+ 4  1055
>
> This seemingly works well and properly captures the value. However, if I instead were to indicate to the function that *all* of my columns were numeric (just insert this one line in lieu of the other above)
>
> type <- c('N','N','N')
>
> # A tibble: 3 x 3
>      X1    X2    X3
>   <dbl> <dbl> <dbl>
> 1     1     1  1043
> 2     1 71220  1043
> 3     1 91220  1055
>
> The read in is not correct. Here is the pragmatic issue. I have a legacy program that spits out the layout structure of the fwf file (start, end positions) and also indicates what the column types are. This layout file we receive always uses a column type of numeric (N) for any numeric types (including the column holding values such as 1e-20).
>
> This layout file will not change so I need to figure out how to solve the problem within my read in program. I suppose one option is that I could manually change any values of "N" to "D" in my R code. That seems to work. But not sure if that is the "right" way to solve this issue.
>
> Thanks
> Harold
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee (she/her)
http://www.numberwright.com


From HDor@n @end|ng |rom @|r@org  Wed Apr 24 17:37:47 2019
From: HDor@n @end|ng |rom @|r@org (Doran, Harold)
Date: Wed, 24 Apr 2019 15:37:47 +0000
Subject: [R] Read_fwf in package readr, double vs. numeric
In-Reply-To: <CAM_vju=HGnNGv302cNp9s7sxQN6_thaLdSH2hf+19OTy3C3Fuw@mail.gmail.com>
References: <BN7PR05MB5857A5350CA9BA5A7945AC59CA3C0@BN7PR05MB5857.namprd05.prod.outlook.com>
 <CAM_vju=HGnNGv302cNp9s7sxQN6_thaLdSH2hf+19OTy3C3Fuw@mail.gmail.com>
Message-ID: <BN7PR05MB585747FD9E62B9E4EF0BAD8ECA3C0@BN7PR05MB5857.namprd05.prod.outlook.com>

Thank you, Sarah. Seems that updating to a newer version does indeed solve that problem. For completeness, below is the version in which it seems to work properly and below is the version in which I observe the problem I described.

> sessionInfo()
R version 3.5.3 (2019-03-11)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] readr_1.3.1

loaded via a namespace (and not attached):
 [1] compiler_3.5.3   assertthat_0.2.1 R6_2.4.0         cli_1.1.0        hms_0.4.2       
 [6] tools_3.5.3      pillar_1.3.1     tibble_2.1.1     Rcpp_1.0.1       crayon_1.3.4    
[11] utf8_1.1.4       fansi_0.4.0      pkgconfig_2.0.2  rlang_0.3.4     

> sessionInfo()
R version 3.4.2 (2017-09-28)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] readr_1.1.1

loaded via a namespace (and not attached):
 [1] compiler_3.4.2   assertthat_0.2.0 R6_2.2.2         cli_1.0.0        hms_0.3          tools_3.4.2     
 [7] pillar_1.3.0     tibble_1.4.2     Rcpp_1.0.0       crayon_1.3.4     utf8_1.1.4       fansi_0.2.3     
[13] rlang_0.3.0.1     

-----Original Message-----
From: Sarah Goslee <sarah.goslee at gmail.com> 
Sent: Wednesday, April 24, 2019 11:12 AM
To: Doran, Harold <HDoran at air.org>
Cc: r-help at r-project.org
Subject: Re: [R] Read_fwf in package readr, double vs. numeric

Hi,

I can't reproduce your problem: with readr 1.1.1 on linux, it works as expected. Letting read_fwf guess the types also works fine. (See
below.)

If you aren't running the current version of readr, update and retry.
If you are, then we probably need more info, at least sessionInfo().

Sarah



library(readr)
myFile <- "foo.txt"
pos <- fwf_positions(c(1,2,7), c(1,6,10))


type <- c('N','D','N')
types <- paste0(type, collapse = '')
types <- chartr('NCD', 'ncd', types)
read_fwf(file = myFile, col_positions = pos, col_types = types)

# A tibble: 3 x 3
     X1       X2    X3
  <dbl>    <dbl> <dbl>
1     1 1.00e-20  1043
2     1 7.12e+ 4  1043
3     1 9.12e+ 4  1055


type <- c('N','N','N')
types <- paste0(type, collapse = '')
types <- chartr('NCD', 'ncd', types)
read_fwf(file = myFile, col_positions = pos, col_types = types)

# A tibble: 3 x 3
     X1       X2    X3
  <dbl>    <dbl> <dbl>
1     1 1.00e-20  1043
2     1 7.12e+ 4  1043
3     1 9.12e+ 4  1055



> read_fwf(file = myFile, col_positions = pos, col_types = NULL)
Parsed with column specification:
cols(
  X1 = col_double(),
  X2 = col_double(),
  X3 = col_double()
)
# A tibble: 3 x 3
     X1       X2    X3
  <dbl>    <dbl> <dbl>
1     1 1.00e-20  1043
2     1 7.12e+ 4  1043
3     1 9.12e+ 4  1055




> sessionInfo()
R version 3.5.3 (2019-03-11)
Platform: x86_64-redhat-linux-gnu (64-bit) Running under: Fedora 28 (Workstation Edition)

Matrix products: default
BLAS/LAPACK: /usr/lib64/R/lib/libRblas.so

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] readr_1.3.1    colorout_1.2-0

loaded via a namespace (and not attached):
 [1] compiler_3.5.3   assertthat_0.2.0 R6_2.4.0         cli_1.0.1
 [5] hms_0.4.2        tools_3.5.3      pillar_1.3.1     tibble_2.0.1
 [9] Rcpp_1.0.0       crayon_1.3.4     utf8_1.1.4       fansi_0.4.0
[13] pkgconfig_2.0.2  rlang_0.3.1


On Wed, Apr 24, 2019 at 10:56 AM Doran, Harold <HDoran at air.org> wrote:
>
> Suppose I have the following data sitting in a fwf file 'foo.txt'. The point of this email is to ask the group how to properly read in the value in this pseudo-data "1e-20" using the read_fwf function in the package readr.
>
> 11e-201043
> 1712201043
> 1912201055
>
> First, suppose I do it this way, where in this case "D" is used for double precision.
>
> library(readr)
> pos <- fwf_positions(c(1,2,7), c(1,6,10)) type <- c('N','D','N') types 
> <- paste0(type, collapse = '') types <- chartr('NCD', 'ncd', types)
>
> read_fwf(file = myFile, col_positions = pos, col_types = types)
>
> # A tibble: 3 x 3
>      X1       X2    X3
>   <dbl>    <dbl> <dbl>
> 1     1 1.00e-20  1043
> 2     1 7.12e+ 4  1043
> 3     1 9.12e+ 4  1055
>
> This seemingly works well and properly captures the value. However, if 
> I instead were to indicate to the function that *all* of my columns 
> were numeric (just insert this one line in lieu of the other above)
>
> type <- c('N','N','N')
>
> # A tibble: 3 x 3
>      X1    X2    X3
>   <dbl> <dbl> <dbl>
> 1     1     1  1043
> 2     1 71220  1043
> 3     1 91220  1055
>
> The read in is not correct. Here is the pragmatic issue. I have a legacy program that spits out the layout structure of the fwf file (start, end positions) and also indicates what the column types are. This layout file we receive always uses a column type of numeric (N) for any numeric types (including the column holding values such as 1e-20).
>
> This layout file will not change so I need to figure out how to solve the problem within my read in program. I suppose one option is that I could manually change any values of "N" to "D" in my R code. That seems to work. But not sure if that is the "right" way to solve this issue.
>
> Thanks
> Harold
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



--
Sarah Goslee (she/her)
http://www.numberwright.com


From @@r@h@go@|ee @end|ng |rom gm@||@com  Wed Apr 24 17:43:54 2019
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Wed, 24 Apr 2019 11:43:54 -0400
Subject: [R] Read_fwf in package readr, double vs. numeric
In-Reply-To: <BN7PR05MB585747FD9E62B9E4EF0BAD8ECA3C0@BN7PR05MB5857.namprd05.prod.outlook.com>
References: <BN7PR05MB5857A5350CA9BA5A7945AC59CA3C0@BN7PR05MB5857.namprd05.prod.outlook.com>
 <CAM_vju=HGnNGv302cNp9s7sxQN6_thaLdSH2hf+19OTy3C3Fuw@mail.gmail.com>
 <BN7PR05MB585747FD9E62B9E4EF0BAD8ECA3C0@BN7PR05MB5857.namprd05.prod.outlook.com>
Message-ID: <CAM_vju=K=0e2LPNB7xLFM5Air59L7Hvo89p2iXJOoz4aYCncCw@mail.gmail.com>

And just for thoroughness, I meant that it works in readr 1.3.1, as my
sessionInfo (but not what I typed myself) said. Sorry for the typo,
but I'm glad it solved your problem nonetheless.

Sarah

On Wed, Apr 24, 2019 at 11:38 AM Doran, Harold <HDoran at air.org> wrote:
>
> Thank you, Sarah. Seems that updating to a newer version does indeed solve that problem. For completeness, below is the version in which it seems to work properly and below is the version in which I observe the problem I described.
>
> > sessionInfo()
> R version 3.5.3 (2019-03-11)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] readr_1.3.1
>
> loaded via a namespace (and not attached):
>  [1] compiler_3.5.3   assertthat_0.2.1 R6_2.4.0         cli_1.1.0        hms_0.4.2
>  [6] tools_3.5.3      pillar_1.3.1     tibble_2.1.1     Rcpp_1.0.1       crayon_1.3.4
> [11] utf8_1.1.4       fansi_0.4.0      pkgconfig_2.0.2  rlang_0.3.4
>
> > sessionInfo()
> R version 3.4.2 (2017-09-28)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] readr_1.1.1
>
> loaded via a namespace (and not attached):
>  [1] compiler_3.4.2   assertthat_0.2.0 R6_2.2.2         cli_1.0.0        hms_0.3          tools_3.4.2
>  [7] pillar_1.3.0     tibble_1.4.2     Rcpp_1.0.0       crayon_1.3.4     utf8_1.1.4       fansi_0.2.3
> [13] rlang_0.3.0.1
>
> -----Original Message-----
> From: Sarah Goslee <sarah.goslee at gmail.com>
> Sent: Wednesday, April 24, 2019 11:12 AM
> To: Doran, Harold <HDoran at air.org>
> Cc: r-help at r-project.org
> Subject: Re: [R] Read_fwf in package readr, double vs. numeric
>
> Hi,
>
> I can't reproduce your problem: with readr 1.1.1 on linux, it works as expected. Letting read_fwf guess the types also works fine. (See
> below.)
>
> If you aren't running the current version of readr, update and retry.
> If you are, then we probably need more info, at least sessionInfo().
>
> Sarah
>
>
>
> library(readr)
> myFile <- "foo.txt"
> pos <- fwf_positions(c(1,2,7), c(1,6,10))
>
>
> type <- c('N','D','N')
> types <- paste0(type, collapse = '')
> types <- chartr('NCD', 'ncd', types)
> read_fwf(file = myFile, col_positions = pos, col_types = types)
>
> # A tibble: 3 x 3
>      X1       X2    X3
>   <dbl>    <dbl> <dbl>
> 1     1 1.00e-20  1043
> 2     1 7.12e+ 4  1043
> 3     1 9.12e+ 4  1055
>
>
> type <- c('N','N','N')
> types <- paste0(type, collapse = '')
> types <- chartr('NCD', 'ncd', types)
> read_fwf(file = myFile, col_positions = pos, col_types = types)
>
> # A tibble: 3 x 3
>      X1       X2    X3
>   <dbl>    <dbl> <dbl>
> 1     1 1.00e-20  1043
> 2     1 7.12e+ 4  1043
> 3     1 9.12e+ 4  1055
>
>
>
> > read_fwf(file = myFile, col_positions = pos, col_types = NULL)
> Parsed with column specification:
> cols(
>   X1 = col_double(),
>   X2 = col_double(),
>   X3 = col_double()
> )
> # A tibble: 3 x 3
>      X1       X2    X3
>   <dbl>    <dbl> <dbl>
> 1     1 1.00e-20  1043
> 2     1 7.12e+ 4  1043
> 3     1 9.12e+ 4  1055
>
>
>
>
> > sessionInfo()
> R version 3.5.3 (2019-03-11)
> Platform: x86_64-redhat-linux-gnu (64-bit) Running under: Fedora 28 (Workstation Edition)
>
> Matrix products: default
> BLAS/LAPACK: /usr/lib64/R/lib/libRblas.so
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] readr_1.3.1    colorout_1.2-0
>
> loaded via a namespace (and not attached):
>  [1] compiler_3.5.3   assertthat_0.2.0 R6_2.4.0         cli_1.0.1
>  [5] hms_0.4.2        tools_3.5.3      pillar_1.3.1     tibble_2.0.1
>  [9] Rcpp_1.0.0       crayon_1.3.4     utf8_1.1.4       fansi_0.4.0
> [13] pkgconfig_2.0.2  rlang_0.3.1
>
>
> On Wed, Apr 24, 2019 at 10:56 AM Doran, Harold <HDoran at air.org> wrote:
> >
> > Suppose I have the following data sitting in a fwf file 'foo.txt'. The point of this email is to ask the group how to properly read in the value in this pseudo-data "1e-20" using the read_fwf function in the package readr.
> >
> > 11e-201043
> > 1712201043
> > 1912201055
> >
> > First, suppose I do it this way, where in this case "D" is used for double precision.
> >
> > library(readr)
> > pos <- fwf_positions(c(1,2,7), c(1,6,10)) type <- c('N','D','N') types
> > <- paste0(type, collapse = '') types <- chartr('NCD', 'ncd', types)
> >
> > read_fwf(file = myFile, col_positions = pos, col_types = types)
> >
> > # A tibble: 3 x 3
> >      X1       X2    X3
> >   <dbl>    <dbl> <dbl>
> > 1     1 1.00e-20  1043
> > 2     1 7.12e+ 4  1043
> > 3     1 9.12e+ 4  1055
> >
> > This seemingly works well and properly captures the value. However, if
> > I instead were to indicate to the function that *all* of my columns
> > were numeric (just insert this one line in lieu of the other above)
> >
> > type <- c('N','N','N')
> >
> > # A tibble: 3 x 3
> >      X1    X2    X3
> >   <dbl> <dbl> <dbl>
> > 1     1     1  1043
> > 2     1 71220  1043
> > 3     1 91220  1055
> >
> > The read in is not correct. Here is the pragmatic issue. I have a legacy program that spits out the layout structure of the fwf file (start, end positions) and also indicates what the column types are. This layout file we receive always uses a column type of numeric (N) for any numeric types (including the column holding values such as 1e-20).
> >
> > This layout file will not change so I need to figure out how to solve the problem within my read in program. I suppose one option is that I could manually change any values of "N" to "D" in my R code. That seems to work. But not sure if that is the "right" way to solve this issue.
> >
> > Thanks
> > Harold
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Sarah Goslee (she/her)
> http://www.numberwright.com
>


-- 
Sarah Goslee (she/her)
http://www.sarahgoslee.com


From @@h|mk@poor @end|ng |rom gm@||@com  Thu Apr 25 06:55:37 2019
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Thu, 25 Apr 2019 10:25:37 +0530
Subject: [R] Intuition behind time varying parameters regression model.
Message-ID: <CAC8=1erx6XTo4HmwY+BRAcS2kbCqvkREjeXbR2e3f7PPy22ycg@mail.gmail.com>

Dear All,

I have a query which I have posted on Stack Exchange:-

https://stats.stackexchange.com/questions/404353/do-all-parameters-have-to-have-the-same-nature-in-a-structural-change-test

Can some one here please have a look at this ? I posted but I did not
receive any reply.

Many thanks,
Ashim

	[[alternative HTML version deleted]]


From @gr|bh|mch@u|@g@|n @end|ng |rom gm@||@com  Wed Apr 24 20:35:00 2019
From: @gr|bh|mch@u|@g@|n @end|ng |rom gm@||@com (Bhim Chaulagain)
Date: Wed, 24 Apr 2019 14:35:00 -0400
Subject: [R] How to create a ROC curve for a model which has log of odds as
 response?
Message-ID: <CADsnGAxbp5pRMD+PAbW10O2QgYVU4=aSoDuZd+QpOzZVn3qZjg@mail.gmail.com>

I have a question on plotting ROC curve for my model which has log of odds as
the response. For example:

model<-lm((ln(y/1-y)~Temp+RH+DmaxT, data=fit) #'y' is a proportion

Predicted response was obtained for a new data set as:

Predicted_model<-predict(model, newdata, type = 'response')

Predicted values were back-transformed to get values in proportion

I have new observations in proportion and I used 0.05 cutoff value to
represent control (<0.05) and cases (>0.05)

newdata$observed<-ifelse(newdata$observed > 0.05, "cases", "controls")

I plotted ROC curve using the following formula

roc(newdata$observed, predicted_model_backtrans, legacy.axes = TRUE,
plot = TRUE, print.auc = TRUE)

With this formula, I got AUC value 1 and the plot is different than
expected. I couldn't figure out what would be the best way to create ROC
curve for my model type. Any help would be appreciated.

I also tried to create ROC curve where I changed observed and predicted
proportion into binary characteristics (control (<0.05) and cases (>0.05))
which gave me straight line curve rather than smooth.
r <https://stackoverflow.com/questions/tagged/r> linear-regression
<https://stackoverflow.com/questions/tagged/linear-regression> roc
<https://stackoverflow.com/questions/tagged/roc>


-- 
Regards
Bhim Chaulagain

	[[alternative HTML version deleted]]


From bend|x@c@r@ten@en @end|ng |rom reg|onh@dk  Thu Apr 25 13:59:26 2019
From: bend|x@c@r@ten@en @end|ng |rom reg|onh@dk (Bendix Carstensen)
Date: Thu, 25 Apr 2019 11:59:26 +0000
Subject: [R] xtabs ignores l.h.s. rows with NA in just one column - bug or
 facility?
Message-ID: <DB8PR08MB5129691AFF55477612B6944E9D3D0@DB8PR08MB5129.eurprd08.prod.outlook.com>

Here is an example showing that xtabs and cbind are not commutative, which at least I thought reading the help page for xtabs.

print( sessionInfo(), l=F )
xx <- c( 6,11,38,17)
yy <- c(NA,26,18,48)
ff <- c('a','a','b','b')
data.frame( xx, yy, ff )
xtabs( cbind(xx,yy) ~ ff )
cbind( xtabs(xx ~ ff ),
       xtabs(yy ~ ff ) )

Here is the result from my xomputer:

> print( sessionInfo(), l=F )
R version 3.5.3 (2019-03-11)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.6 LTS

Matrix products: default
BLAS: /usr/lib/openblas-base/libopenblas.so.0
LAPACK: /usr/lib/lapack/liblapack.so.3.0

attached base packages:
[1] utils     datasets  graphics  grDevices stats     methods   base

loaded via a namespace (and not attached):
[1] compiler_3.5.3
> xx <- c( 6,11,38,17)
> yy <- c(NA,26,18,48)
> ff <- c('a','a','b','b')
> data.frame( xx, yy, ff )
  xx yy ff
1  6 NA  a
2 11 26  a
3 38 18  b
4 17 48  b
> xtabs( cbind(xx,yy) ~ ff )

ff  xx yy
  a 11 26
  b 55 66
> cbind( xtabs(xx ~ ff ),
+        xtabs(yy ~ ff ) )
  [,1] [,2]
a   17   26
b   55   66
>

I would have guessed the upper left entry would be 17 in the first instance too, but it appears that xtabs does something like complete.cases() on the l.h.s. before summing. At least this should be in the description.

Am I missing something here?
Bendix Carstensen
Steno Diabetes Center Copenhagen

________________________________


Denne e-mail indeholder fortrolig information. Hvis du ikke er den rette modtager af denne e-mail eller hvis du modtager den ved en fejltagelse, beder vi dig venligst informere afsender om fejlen ved at bruge svarfunktionen. Samtidig bedes du slette e-mailen med det samme uden at videresende eller kopiere den.


From dc@r|@on @end|ng |rom t@mu@edu  Thu Apr 25 15:55:17 2019
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Thu, 25 Apr 2019 13:55:17 +0000
Subject: [R] 
 xtabs ignores l.h.s. rows with NA in just one column - bug or
 facility?
In-Reply-To: <DB8PR08MB5129691AFF55477612B6944E9D3D0@DB8PR08MB5129.eurprd08.prod.outlook.com>
References: <DB8PR08MB5129691AFF55477612B6944E9D3D0@DB8PR08MB5129.eurprd08.prod.outlook.com>
Message-ID: <1421734d9eb04ba0a879c922fbcf1bd2@tamu.edu>

The documentation describes how to control the behavior of missing values:

> xtabs( cbind(xx,yy) ~ ff, addNA=TRUE) 
   
ff  xx yy
  a 17   
  b 55 66

But of course, now you do not get 26 in the (a, yy) cell because 26 + NA = NA.

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Bendix Carstensen
Sent: Thursday, April 25, 2019 6:59 AM
To: r-help at r-project.org
Subject: [R] xtabs ignores l.h.s. rows with NA in just one column - bug or facility?

Here is an example showing that xtabs and cbind are not commutative, which at least I thought reading the help page for xtabs.

print( sessionInfo(), l=F )
xx <- c( 6,11,38,17)
yy <- c(NA,26,18,48)
ff <- c('a','a','b','b')
data.frame( xx, yy, ff )
xtabs( cbind(xx,yy) ~ ff )
cbind( xtabs(xx ~ ff ),
       xtabs(yy ~ ff ) )

Here is the result from my xomputer:

> print( sessionInfo(), l=F )
R version 3.5.3 (2019-03-11)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.6 LTS

Matrix products: default
BLAS: /usr/lib/openblas-base/libopenblas.so.0
LAPACK: /usr/lib/lapack/liblapack.so.3.0

attached base packages:
[1] utils     datasets  graphics  grDevices stats     methods   base

loaded via a namespace (and not attached):
[1] compiler_3.5.3
> xx <- c( 6,11,38,17)
> yy <- c(NA,26,18,48)
> ff <- c('a','a','b','b')
> data.frame( xx, yy, ff )
  xx yy ff
1  6 NA  a
2 11 26  a
3 38 18  b
4 17 48  b
> xtabs( cbind(xx,yy) ~ ff )

ff  xx yy
  a 11 26
  b 55 66
> cbind( xtabs(xx ~ ff ),
+        xtabs(yy ~ ff ) )
  [,1] [,2]
a   17   26
b   55   66
>

I would have guessed the upper left entry would be 17 in the first instance too, but it appears that xtabs does something like complete.cases() on the l.h.s. before summing. At least this should be in the description.

Am I missing something here?
Bendix Carstensen
Steno Diabetes Center Copenhagen

________________________________


Denne e-mail indeholder fortrolig information. Hvis du ikke er den rette modtager af denne e-mail eller hvis du modtager den ved en fejltagelse, beder vi dig venligst informere afsender om fejlen ved at bruge svarfunktionen. Samtidig bedes du slette e-mailen med det samme uden at videresende eller kopiere den.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jurr|@@n@n@ge|kerke @end|ng |rom gm@||@com  Thu Apr 25 12:25:04 2019
From: jurr|@@n@n@ge|kerke @end|ng |rom gm@||@com (Jurriaan Nagelkerke)
Date: Thu, 25 Apr 2019 12:25:04 +0200
Subject: [R] [R-pkgs] new CRAN package : modelplotr
Message-ID: <CAGdxdCKc45-RWtKB3BDLPPujBq9K3GRCxWbKFXsQ-2nBdtzwyQ@mail.gmail.com>

Hi there!

We would like to share the news that our package *modelplotr *has recently
been added to CRAN with your audience. Here's a some text for the
introduction:

---------------------
*Title:*

*modelplotr v1.0 now on CRAN: Visualize the Business Value of your
Predictive Models *

*Visual:*
https://modelplot.github.io/img/modelplotr_CRAN-topviz-1.gif

*Intro text:*
Modelplotr - Build plots in R to evaluate the business value of predictive
models. Now on CRAN with new (financial) plots, support for caret, mlr,
h2o, keras and other models and new features to customize your plots.

Read more about modelplotr on our blog:   https://modelplot.github.io/
<https://modelplot.github.io/intro_modelplotr.html>  . Here you find an
introducting blog ( https://modelplot.github.io/intro_modelplotr.html  ) as
well as more info on how to use modelplotr (
https://modelplot.github.io/vignette_modelplotr.html  )

Questions, remarks, suggestions? Please let uw know via github!
---------------------


Hope you like to share this with your R audience!

Kind regards,

Jurriaan Nagelkerke
jurriaan.nagelkerke at gmail.com

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From bend|x@c@r@ten@en @end|ng |rom reg|onh@dk  Thu Apr 25 16:01:04 2019
From: bend|x@c@r@ten@en @end|ng |rom reg|onh@dk (Bendix Carstensen)
Date: Thu, 25 Apr 2019 14:01:04 +0000
Subject: [R] 
 xtabs ignores l.h.s. rows with NA in just one column - bug or
 facility?
In-Reply-To: <1421734d9eb04ba0a879c922fbcf1bd2@tamu.edu>
References: <DB8PR08MB5129691AFF55477612B6944E9D3D0@DB8PR08MB5129.eurprd08.prod.outlook.com>,
 <1421734d9eb04ba0a879c922fbcf1bd2@tamu.edu>
Message-ID: <DB8PR08MB51290159B609B3649B72B6C69D3D0@DB8PR08MB5129.eurprd08.prod.outlook.com>

Thanks for that, but the documentation also says that teh default behaviour is to use na.action=na.pass, which normally just ignores missing values, whereas xtabs seems to ignore the entire row...
/Bendix

________________________________________
From: David L Carlson <dcarlson at tamu.edu>
Sent: 25 April 2019 15:55
To: Bendix Carstensen; r-help at r-project.org
Subject: RE: xtabs ignores l.h.s. rows with NA in just one column - bug or facility?

The documentation describes how to control the behavior of missing values:

> xtabs( cbind(xx,yy) ~ ff, addNA=TRUE)

ff  xx yy
  a 17
  b 55 66

But of course, now you do not get 26 in the (a, yy) cell because 26 + NA = NA.

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Bendix Carstensen
Sent: Thursday, April 25, 2019 6:59 AM
To: r-help at r-project.org
Subject: [R] xtabs ignores l.h.s. rows with NA in just one column - bug or facility?

Here is an example showing that xtabs and cbind are not commutative, which at least I thought reading the help page for xtabs.

print( sessionInfo(), l=F )
xx <- c( 6,11,38,17)
yy <- c(NA,26,18,48)
ff <- c('a','a','b','b')
data.frame( xx, yy, ff )
xtabs( cbind(xx,yy) ~ ff )
cbind( xtabs(xx ~ ff ),
       xtabs(yy ~ ff ) )

Here is the result from my xomputer:

> print( sessionInfo(), l=F )
R version 3.5.3 (2019-03-11)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 14.04.6 LTS

Matrix products: default
BLAS: /usr/lib/openblas-base/libopenblas.so.0
LAPACK: /usr/lib/lapack/liblapack.so.3.0

attached base packages:
[1] utils     datasets  graphics  grDevices stats     methods   base

loaded via a namespace (and not attached):
[1] compiler_3.5.3
> xx <- c( 6,11,38,17)
> yy <- c(NA,26,18,48)
> ff <- c('a','a','b','b')
> data.frame( xx, yy, ff )
  xx yy ff
1  6 NA  a
2 11 26  a
3 38 18  b
4 17 48  b
> xtabs( cbind(xx,yy) ~ ff )

ff  xx yy
  a 11 26
  b 55 66
> cbind( xtabs(xx ~ ff ),
+        xtabs(yy ~ ff ) )
  [,1] [,2]
a   17   26
b   55   66
>

I would have guessed the upper left entry would be 17 in the first instance too, but it appears that xtabs does something like complete.cases() on the l.h.s. before summing. At least this should be in the description.

Am I missing something here?
Bendix Carstensen
Steno Diabetes Center Copenhagen

________________________________


Denne e-mail indeholder fortrolig information. Hvis du ikke er den rette modtager af denne e-mail eller hvis du modtager den ved en fejltagelse, beder vi dig venligst informere afsender om fejlen ved at bruge svarfunktionen. Samtidig bedes du slette e-mailen med det samme uden at videresende eller kopiere den.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

________________________________


Denne e-mail indeholder fortrolig information. Hvis du ikke er den rette modtager af denne e-mail eller hvis du modtager den ved en fejltagelse, beder vi dig venligst informere afsender om fejlen ved at bruge svarfunktionen. Samtidig bedes du slette e-mailen med det samme uden at videresende eller kopiere den.


From kog@|ur@he@r @end|ng |rom gm@||@com  Mon Apr 22 20:53:14 2019
From: kog@|ur@he@r @end|ng |rom gm@||@com (Udaya B. Kogalur)
Date: Mon, 22 Apr 2019 14:53:14 -0400
Subject: [R] [R-pkgs] randomForestSRC 2.9.0 is now available
Message-ID: <CACsjJ_ceQoXq93LsfriKbav2=-rJnJVWBsoCdRp=fwdhjT_Vzw@mail.gmail.com>

Dear useRs:

It's been some time since we last sent out an announcement, so this one
will cover more than just the last update.

The latest release of randomForestSRC is now available on CRAN at:

https://CRAN.R-project.org/package=randomForestSRC

The GitHub repository, through which we prefer to receive bug reports, is
at:

https://github.com/kogalur/randomForestSRC

If you do find issues, please use:

https://github.com/kogalur/randomForestSRC/issues

and take the time to post a minimal script (and data set if necessary) that
isolates the error.

Additional documentation can be found at:

https://kogalur.github.io/randomForestSRC/

------------------------------------------
Details are as follows:

Ensembles in regression now support Greenwald-Khanna approximate quantile
queries via rfsrc(), predict.rfsrc() and the new wrapper
quantileReg.rfsrc(). Related to this, a new split rule "quantile.regr" has
been added.

Another new wrapper, imbalanced.rfsrc(), implements various solutions to
the two-class imbalanced problem, including the newly proposed
quantile-classifier approach of O'Brien and Ishwaran (2017). This also
includes Breiman's balanced random forests under-sampling of the majority
class.  Performance is assessed using the G-mean, but misclassification
error can be requested.

Also, the new parameter get.tree in predict.rfsrc() allows users to extract
the ensembles for a single tree or subset of trees over the forest.

The default nodesize for survival and competing risk has been changed to 15.

We've added new splitrules "auc" and "entropy" for classification. A new
variable importance methodology called Holdout VIMP has been implemented.
Here, we exclude a variable from a subset of trees and compare the error
rates between those trees in which the variables was included against those
in which it was excluded.  The key point here is that no permutation of a
variable is conducted.  See holdout.vimp.rfsrc() and the associated Rd file
for more information.

Finally, some function names were changed as a general move towards name
uniformity in the package.  Sorry about that.

------------------------------------------
Additional side-notes:

Unfortunately there has been no further work on the Spark build.  However,
the Java wrappers have been kept up to date, and the Hello World script is
still functional.  Instructions are provided here:

https://kogalur.github.io/randomForestSRC/building.html

For those requesting and still awaiting CPU performance enhancements, our
continued apologies.  Our focus has been methodological, but our intention
is to address performance in the next build.  We promise.

Thank you!

Udaya B. Kogalur, Ph.D.
ubkogalur at gmail.com

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From youy||ong @end|ng |rom gm@||@com  Tue Apr 23 19:33:59 2019
From: youy||ong @end|ng |rom gm@||@com (Youyi Fong)
Date: Tue, 23 Apr 2019 10:33:59 -0700
Subject: [R] .Call using multiple cores on linux after R 3.3.3
In-Reply-To: <07C2D9C6-92FD-48D9-B8A1-496A84ED6C59@dcn.davis.ca.us>
References: <CAA4m0GbGj=kKgdLpo7Sfe7HEYf-VYi5APzRd0zB7S2iH2nUy3w@mail.gmail.com>
 <07C2D9C6-92FD-48D9-B8A1-496A84ED6C59@dcn.davis.ca.us>
Message-ID: <CAA4m0Gb+ZHpk82Oyri3sfJMC2EP+Tw=8102jiO9iavc-kJ+7wg@mail.gmail.com>

Thanks, Jeff! You are absolutely correct. We have OPENBLAS installed in our
environment that causes this.

One way to "fix" it is:

library(RhpcBLASctl)
blas_get_num_procs()
blas_set_num_threads(1)
stopifnot(blas_get_num_procs()==1)



On Sat, Apr 20, 2019 at 9:06 AM Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> My guess would be that you are running with a non-CRAN distribution of R
> like Anaconda or MRAN that has MKL enabled?
>
> On April 19, 2019 10:25:57 AM PDT, Youyi Fong <youyifong at gmail.com> wrote:
> >Hi, I am wondering why it is the case that in R 3.3.3, calling
> >chngpt:chngptm uses only 1 core, but in later releases, e.g. R 3.4.3,
> >it
> >uses multiple cores on linux. The function chngpt:chngptm has a .Call
> >to
> >invoke a C/C++ function that performs bootstrapping. No explicit
> >parallel
> >computing instructions are used.
> >Thanks,
> >Youyi
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>

	[[alternative HTML version deleted]]


From L@urent|u@N|tu @end|ng |rom |r@@erhe@|th@c@  Tue Apr 23 20:19:00 2019
From: L@urent|u@N|tu @end|ng |rom |r@@erhe@|th@c@ (Nitu, Laurentiu)
Date: Tue, 23 Apr 2019 18:19:00 +0000
Subject: [R] Question about addressing a data frame
Message-ID: <883a357326984f7c818593b1c92473e7@SPEXCM006.healthbc.org>

Hello,


I have this data frame [algae] in the package DMwR. I thought I understand how to refer an element but I cannot explain...

is.na(algae) is giving us the a logical vector with TRUE being the na's.
which(is.na(algae)) gives the positions on the elements in the data frame where is.na returns TRUE.


However which(is.na(algae)) returns


[1]  648  838  862 1055 1056 1057 1058 1059 1060 1061 1062 1161 1199 1262 1399 1462 1599 1662 1799 1828 1999 2055 2056 2057 2058 2059 2060 2061 2062 2063
[31] 2116 2184 2199

Weirs since:


> dim(algae)

[1] 200  18


If I refer back algae[which(is.na(algae))) I get a vector of NA's...

What are the values returned by which(is.na(algae))?

Thanks a lot for your help

	[[alternative HTML version deleted]]


From m@njumoorthy95 @end|ng |rom gm@||@com  Wed Apr 24 08:46:38 2019
From: m@njumoorthy95 @end|ng |rom gm@||@com (manju moorthy)
Date: Wed, 24 Apr 2019 12:16:38 +0530
Subject: [R] Doubt regarding the autoplot function in ggfortify library
Message-ID: <CAN9BOwN8t486C8nO95rAhTMAwoKOeFj3+m5WyDN7wMYzxHDTPw@mail.gmail.com>

Iam using autoplot function from the ggfortify library. I saw that autoplot
gives the 1st two principal components. I am using autoplot to generate 1st
two principal components on a clustered object.
The usage is like :

autoplot(pam(my_data[1:256], 3), label = TRUE, label.size = 4, frame =
TRUE, frame.type = 'norm')

So here autoplot generates the principal components on the clustered
object. So can we actually call this a PCA plot? Also what is the algorithm
used by autoplot for generating principal components?

Thanks in advance for the help.



<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
Virus-free.
www.avg.com
<http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail>
<#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>

	[[alternative HTML version deleted]]


From wdun|@p @end|ng |rom t|bco@com  Thu Apr 25 19:02:55 2019
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Thu, 25 Apr 2019 10:02:55 -0700
Subject: [R] Question about addressing a data frame
In-Reply-To: <883a357326984f7c818593b1c92473e7@SPEXCM006.healthbc.org>
References: <883a357326984f7c818593b1c92473e7@SPEXCM006.healthbc.org>
Message-ID: <CAF8bMcY_hRL0q0LvOzDxwCbm8zkzOvkfE+8V9gkKna61s8o9Pg@mail.gmail.com>

is.na(DF) is a matrix for a data.frame DF.  The semantics of '[" are
different for matrices
and data.frame and that can cause confusion

> DF <- data.frame(X=c(101,NA,NA), Y=c("one","two",NA),
row.names=c("i","ii","iii"))
> is.na(DF) # returns a matrix when given a data.frame
        X     Y
i   FALSE FALSE
ii   TRUE FALSE
iii  TRUE  TRUE
> which(is.na(DF)) # returns a vector when given a data.frame
[1] 2 3 6
> which(is.na(DF), arr.ind=TRUE) # returns a length(dim(matrix))-column
matrix when given an array
    row col
ii    2   1
iii   3   1
iii   3   2
> DF[!is.na(DF)] # as.matrix(DF)[ !is.na(as.matrix(DF)) ]
[1] "101" "one" "two"

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Apr 25, 2019 at 9:27 AM Nitu, Laurentiu <
Laurentiu.Nitu at fraserhealth.ca> wrote:

> Hello,
>
>
> I have this data frame [algae] in the package DMwR. I thought I understand
> how to refer an element but I cannot explain...
>
> is.na(algae) is giving us the a logical vector with TRUE being the na's.
> which(is.na(algae)) gives the positions on the elements in the data frame
> where is.na returns TRUE.
>
>
> However which(is.na(algae)) returns
>
>
> [1]  648  838  862 1055 1056 1057 1058 1059 1060 1061 1062 1161 1199 1262
> 1399 1462 1599 1662 1799 1828 1999 2055 2056 2057 2058 2059 2060 2061 2062
> 2063
> [31] 2116 2184 2199
>
> Weirs since:
>
>
> > dim(algae)
>
> [1] 200  18
>
>
> If I refer back algae[which(is.na(algae))) I get a vector of NA's...
>
> What are the values returned by which(is.na(algae))?
>
> Thanks a lot for your help
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Thu Apr 25 19:13:30 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 25 Apr 2019 10:13:30 -0700
Subject: [R] Doubt regarding the autoplot function in ggfortify library
In-Reply-To: <CAN9BOwN8t486C8nO95rAhTMAwoKOeFj3+m5WyDN7wMYzxHDTPw@mail.gmail.com>
References: <CAN9BOwN8t486C8nO95rAhTMAwoKOeFj3+m5WyDN7wMYzxHDTPw@mail.gmail.com>
Message-ID: <CAGxFJbRpaMdoJts_pABbNrnxQ-_iXk+JyZgNran1ZdXpkaGBtw@mail.gmail.com>

As I believe the posting guide notes, you may do better addressing
questions about specialized packages to the package maintainers, who often
do not monitor this list.

Cheers,
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Apr 25, 2019 at 9:29 AM manju moorthy <manjumoorthy95 at gmail.com>
wrote:

> Iam using autoplot function from the ggfortify library. I saw that autoplot
> gives the 1st two principal components. I am using autoplot to generate 1st
> two principal components on a clustered object.
> The usage is like :
>
> autoplot(pam(my_data[1:256], 3), label = TRUE, label.size = 4, frame =
> TRUE, frame.type = 'norm')
>
> So here autoplot generates the principal components on the clustered
> object. So can we actually call this a PCA plot? Also what is the algorithm
> used by autoplot for generating principal components?
>
> Thanks in advance for the help.
>
>
>
> <
> http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
> >
> Virus-free.
> www.avg.com
> <
> http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
> >
> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mcg@rvey@bern@rd @end|ng |rom comc@@t@net  Thu Apr 25 19:47:38 2019
From: mcg@rvey@bern@rd @end|ng |rom comc@@t@net (Bernard Comcast)
Date: Thu, 25 Apr 2019 13:47:38 -0400
Subject: [R] Surface plots....
Message-ID: <4721E6EC-1B13-464A-85D5-14961AA1844C@comcast.net>

Does anyone have a recommendation for the best package/function for doing surface plots?

Bernard
Sent from my iPhone so please excuse the spelling!"

From bgunter@4567 @end|ng |rom gm@||@com  Thu Apr 25 20:13:58 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 25 Apr 2019 11:13:58 -0700
Subject: [R] Surface plots....
In-Reply-To: <4721E6EC-1B13-464A-85D5-14961AA1844C@comcast.net>
References: <4721E6EC-1B13-464A-85D5-14961AA1844C@comcast.net>
Message-ID: <CAGxFJbScjgWEryaADH=wbzwMV30rpvDJhQH+UdZnZ2dU4FqOTA@mail.gmail.com>

Depends on what you want to do -- context matters.
More details would probably enable better answers.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Apr 25, 2019 at 10:55 AM Bernard Comcast <
mcgarvey.bernard at comcast.net> wrote:

> Does anyone have a recommendation for the best package/function for doing
> surface plots?
>
> Bernard
> Sent from my iPhone so please excuse the spelling!"
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Apr 25 20:14:11 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 25 Apr 2019 14:14:11 -0400
Subject: [R] Surface plots....
In-Reply-To: <4721E6EC-1B13-464A-85D5-14961AA1844C@comcast.net>
References: <4721E6EC-1B13-464A-85D5-14961AA1844C@comcast.net>
Message-ID: <05c8e514-a32e-c595-e37e-e59b1d557e2d@gmail.com>

On 25/04/2019 1:47 p.m., Bernard Comcast wrote:
> Does anyone have a recommendation for the best package/function for doing surface plots?

You've got a pretty wide choice:  graphics::persp, several functions in 
the rgl, plotly, plot3D packages, etc.  You'll need to give a bit more 
information if you want a particular recommendation, such as what form 
your data is in, what you want the plot to look like, what medium do you 
want to display it on, etc.

Duncan Murdoch


From mcg@rvey@bern@rd @end|ng |rom comc@@t@net  Thu Apr 25 20:24:31 2019
From: mcg@rvey@bern@rd @end|ng |rom comc@@t@net (Bernard McGarvey)
Date: Thu, 25 Apr 2019 14:24:31 -0400 (EDT)
Subject: [R] Surface plots....
In-Reply-To: <CAGxFJbScjgWEryaADH=wbzwMV30rpvDJhQH+UdZnZ2dU4FqOTA@mail.gmail.com>
References: <4721E6EC-1B13-464A-85D5-14961AA1844C@comcast.net>
 <CAGxFJbScjgWEryaADH=wbzwMV30rpvDJhQH+UdZnZ2dU4FqOTA@mail.gmail.com>
Message-ID: <1738840731.733856.1556216671637@connect.xfinity.com>

If I have a set of data (x,y,z) and I want to plot z(x,y) as a surface plot. What I am looking for is one with a lot of functionality like easily rotate the plot and so on.


Thanks



Bernard McGarvey

Director, Fort Myers Beach Lions Foundation, Inc.

Retired (Lilly Engineering Fellow).



> On April 25, 2019 at 2:13 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
>     Depends on what you want to do -- context matters.
>     More details would probably enable better answers.
> 
>     Bert Gunter
> 
>     "The trouble with having an open mind is that people keep coming along and sticking things into it."
>     -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
>     On Thu, Apr 25, 2019 at 10:55 AM Bernard Comcast < mcgarvey.bernard at comcast.net mailto:mcgarvey.bernard at comcast.net > wrote:
> 
>         > > Does anyone have a recommendation for the best package/function for doing surface plots?
> > 
> >         Bernard
> >         Sent from my iPhone so please excuse the spelling!"
> >         ______________________________________________
> >         R-help at r-project.org mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >         https://stat.ethz.ch/mailman/listinfo/r-help
> >         PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >         and provide commented, minimal, self-contained, reproducible code.
> > 
> >     > 

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Thu Apr 25 21:21:41 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 25 Apr 2019 15:21:41 -0400
Subject: [R] Surface plots....
In-Reply-To: <1738840731.733856.1556216671637@connect.xfinity.com>
References: <4721E6EC-1B13-464A-85D5-14961AA1844C@comcast.net>
 <CAGxFJbScjgWEryaADH=wbzwMV30rpvDJhQH+UdZnZ2dU4FqOTA@mail.gmail.com>
 <1738840731.733856.1556216671637@connect.xfinity.com>
Message-ID: <05ce4c75-ce51-3560-4b6e-f45522a236f5@gmail.com>

On 25/04/2019 2:24 p.m., Bernard McGarvey wrote:
> If I have a set of data (x,y,z) and I want to plot z(x,y) as a surface plot. What I am looking for is one with a lot of functionality like easily rotate the plot and so on.

If x and y are on a grid, there are lots of choices.  If they are a set 
of irregular points, there aren't so many.  One possibility is to use 
persp3d(z ~ x + y) (see ?persp3d.formula for help.)  Use rglwidget() to 
write it in a form you can view in a web browser.

Duncan Murdoch

> 
> 
> Thanks
> 
> 
> 
> Bernard McGarvey
> 
> Director, Fort Myers Beach Lions Foundation, Inc.
> 
> Retired (Lilly Engineering Fellow).
> 
> 
> 
>> On April 25, 2019 at 2:13 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>
>>      Depends on what you want to do -- context matters.
>>      More details would probably enable better answers.
>>
>>      Bert Gunter
>>
>>      "The trouble with having an open mind is that people keep coming along and sticking things into it."
>>      -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>>      On Thu, Apr 25, 2019 at 10:55 AM Bernard Comcast < mcgarvey.bernard at comcast.net mailto:mcgarvey.bernard at comcast.net > wrote:
>>
>>          > > Does anyone have a recommendation for the best package/function for doing surface plots?
>>>
>>>          Bernard
>>>          Sent from my iPhone so please excuse the spelling!"
>>>          ______________________________________________
>>>          R-help at r-project.org mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>          https://stat.ethz.ch/mailman/listinfo/r-help
>>>          PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>          and provide commented, minimal, self-contained, reproducible code.
>>>
>>>      >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Apr 25 22:10:41 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 25 Apr 2019 13:10:41 -0700
Subject: [R] Doubt regarding the autoplot function in ggfortify library
In-Reply-To: <CAGxFJbRpaMdoJts_pABbNrnxQ-_iXk+JyZgNran1ZdXpkaGBtw@mail.gmail.com>
References: <CAN9BOwN8t486C8nO95rAhTMAwoKOeFj3+m5WyDN7wMYzxHDTPw@mail.gmail.com>
 <CAGxFJbRpaMdoJts_pABbNrnxQ-_iXk+JyZgNran1ZdXpkaGBtw@mail.gmail.com>
Message-ID: <001B0188-FEE5-403F-B99E-62F9FE769A04@dcn.davis.ca.us>

True, but reading the supplied help is appropriate before contacting the maintainer.

Specifically,

help("ggfortify")

and click the link to the index and find the autoplot method in the list and follow that link. 

Or you can read the help for the "pam" function and discover that the class of the returned object is "pam" so you can use

?autoplot.pam

to go right to it. If the documentation doesn't answer your question you can communicate that to the maintainer.

You can also just enter

autoplot.pam

at the console and read the source code if it is written in R to see what calculations are being done.

On April 25, 2019 10:13:30 AM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>As I believe the posting guide notes, you may do better addressing
>questions about specialized packages to the package maintainers, who
>often
>do not monitor this list.
>
>Cheers,
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Thu, Apr 25, 2019 at 9:29 AM manju moorthy
><manjumoorthy95 at gmail.com>
>wrote:
>
>> Iam using autoplot function from the ggfortify library. I saw that
>autoplot
>> gives the 1st two principal components. I am using autoplot to
>generate 1st
>> two principal components on a clustered object.
>> The usage is like :
>>
>> autoplot(pam(my_data[1:256], 3), label = TRUE, label.size = 4, frame
>=
>> TRUE, frame.type = 'norm')
>>
>> So here autoplot generates the principal components on the clustered
>> object. So can we actually call this a PCA plot? Also what is the
>algorithm
>> used by autoplot for generating principal components?
>>
>> Thanks in advance for the help.
>>
>>
>>
>> <
>>
>http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
>> >
>> Virus-free.
>> www.avg.com
>> <
>>
>http://www.avg.com/email-signature?utm_medium=email&utm_source=link&utm_campaign=sig-email&utm_content=webmail
>> >
>> <#DAB4FAD8-2DD7-40BB-A1B8-4E2AA1F9FDF2>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From mcg@rvey@bern@rd @end|ng |rom comc@@t@net  Thu Apr 25 22:40:44 2019
From: mcg@rvey@bern@rd @end|ng |rom comc@@t@net (Bernard Comcast)
Date: Thu, 25 Apr 2019 16:40:44 -0400
Subject: [R] Surface plots....
In-Reply-To: <05ce4c75-ce51-3560-4b6e-f45522a236f5@gmail.com>
References: <4721E6EC-1B13-464A-85D5-14961AA1844C@comcast.net>
 <CAGxFJbScjgWEryaADH=wbzwMV30rpvDJhQH+UdZnZ2dU4FqOTA@mail.gmail.com>
 <1738840731.733856.1556216671637@connect.xfinity.com>
 <05ce4c75-ce51-3560-4b6e-f45522a236f5@gmail.com>
Message-ID: <283B40F0-082D-4FC8-BC4B-6B10903C7268@comcast.net>

That works nicely for what I need
Thanks

Bernard
Sent from my iPhone so please excuse the spelling!"

> On Apr 25, 2019, at 3:21 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
>> On 25/04/2019 2:24 p.m., Bernard McGarvey wrote:
>> If I have a set of data (x,y,z) and I want to plot z(x,y) as a surface plot. What I am looking for is one with a lot of functionality like easily rotate the plot and so on.
> 
> If x and y are on a grid, there are lots of choices.  If they are a set of irregular points, there aren't so many.  One possibility is to use persp3d(z ~ x + y) (see ?persp3d.formula for help.)  Use rglwidget() to write it in a form you can view in a web browser.
> 
> Duncan Murdoch
> 
>> Thanks
>> Bernard McGarvey
>> Director, Fort Myers Beach Lions Foundation, Inc.
>> Retired (Lilly Engineering Fellow).
>>> On April 25, 2019 at 2:13 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> 
>>>     Depends on what you want to do -- context matters.
>>>     More details would probably enable better answers.
>>> 
>>>     Bert Gunter
>>> 
>>>     "The trouble with having an open mind is that people keep coming along and sticking things into it."
>>>     -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> 
>>> 
>>>     On Thu, Apr 25, 2019 at 10:55 AM Bernard Comcast < mcgarvey.bernard at comcast.net mailto:mcgarvey.bernard at comcast.net > wrote:
>>> 
>>>         > > Does anyone have a recommendation for the best package/function for doing surface plots?
>>>> 
>>>>         Bernard
>>>>         Sent from my iPhone so please excuse the spelling!"
>>>>         ______________________________________________
>>>>         R-help at r-project.org mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>>>         PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>         and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>>     >
>>    [[alternative HTML version deleted]]
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From @purd|e@@ @end|ng |rom gm@||@com  Thu Apr 25 22:49:40 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abs Spurdle)
Date: Fri, 26 Apr 2019 08:49:40 +1200
Subject: [R] Surface plots....
Message-ID: <CAB8pepzHqbCx5JzutDEA3MmvpJzATeGNxginUVtOfaey1Z7OSw@mail.gmail.com>

> Does anyone have a recommendation for the best package/function for doing surface plots?

> What I am looking for is one with a lot of functionality like easily rotate the plot and so on.

There is persp() and the rgl package, as Duncan has already mentioned.

However (I'm probably biased here), there's also my package, barsurf.
It doesn't let you rotate the plots and has less features.
However, it does make it easy to put a contour plot next to a surface
plot, and is integrated with HCL color space.


From L@urent|u@N|tu @end|ng |rom |r@@erhe@|th@c@  Thu Apr 25 19:20:47 2019
From: L@urent|u@N|tu @end|ng |rom |r@@erhe@|th@c@ (Nitu, Laurentiu)
Date: Thu, 25 Apr 2019 17:20:47 +0000
Subject: [R] Question about addressing a data frame
In-Reply-To: <CAF8bMcY_hRL0q0LvOzDxwCbm8zkzOvkfE+8V9gkKna61s8o9Pg@mail.gmail.com>
References: <883a357326984f7c818593b1c92473e7@SPEXCM006.healthbc.org>
 <CAF8bMcY_hRL0q0LvOzDxwCbm8zkzOvkfE+8V9gkKna61s8o9Pg@mail.gmail.com>
Message-ID: <43b50e536e4848269eae3ac5f1651caa@SPEXCM006.healthbc.org>

Thank you very much for your answer. Yes, meanwhile I found out ?

Plus, that index that which() is returning  applied on the matrix is calculated as:

matrix[rowIndices + nrow(matrix) * (colIndices - 1)]


thanks again for your help



From: William Dunlap <wdunlap at tibco.com>
Sent: Thursday, April 25, 2019 10:03 AM
To: Nitu, Laurentiu <Laurentiu.Nitu at fraserhealth.ca>
Cc: r-help at r-project.org
Subject: Re: [R] Question about addressing a data frame

is.na<http://is.na>(DF) is a matrix for a data.frame DF.  The semantics of '[" are different for matrices
and data.frame and that can cause confusion

> DF <- data.frame(X=c(101,NA,NA), Y=c("one","two",NA), row.names=c("i","ii","iii"))
> is.na<http://is.na>(DF) # returns a matrix when given a data.frame
        X     Y
i   FALSE FALSE
ii   TRUE FALSE
iii  TRUE  TRUE
> which(is.na<http://is.na>(DF)) # returns a vector when given a data.frame
[1] 2 3 6
> which(is.na<http://is.na>(DF), arr.ind=TRUE) # returns a length(dim(matrix))-column matrix when given an array
    row col
ii    2   1
iii   3   1
iii   3   2
> DF[!is.na<http://is.na>(DF)] # as.matrix(DF)[ !is.na<http://is.na>(as.matrix(DF)) ]
[1] "101" "one" "two"

Bill Dunlap
TIBCO Software
wdunlap tibco.com<http://tibco.com>


On Thu, Apr 25, 2019 at 9:27 AM Nitu, Laurentiu <Laurentiu.Nitu at fraserhealth.ca<mailto:Laurentiu.Nitu at fraserhealth.ca>> wrote:
Hello,


I have this data frame [algae] in the package DMwR. I thought I understand how to refer an element but I cannot explain...

is.na<http://is.na>(algae) is giving us the a logical vector with TRUE being the na's.
which(is.na<http://is.na>(algae)) gives the positions on the elements in the data frame where is.na<http://is.na> returns TRUE.


However which(is.na<http://is.na>(algae)) returns


[1]  648  838  862 1055 1056 1057 1058 1059 1060 1061 1062 1161 1199 1262 1399 1462 1599 1662 1799 1828 1999 2055 2056 2057 2058 2059 2060 2061 2062 2063
[31] 2116 2184 2199

Weirs since:


> dim(algae)

[1] 200  18


If I refer back algae[which(is.na<http://is.na>(algae))) I get a vector of NA's...

What are the values returned by which(is.na<http://is.na>(algae))?

Thanks a lot for your help

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From pd@me@ @end|ng |rom cb@@dk  Fri Apr 26 09:41:13 2019
From: pd@me@ @end|ng |rom cb@@dk (Peter Dalgaard)
Date: Fri, 26 Apr 2019 07:41:13 +0000
Subject: [R] R 3.6.0 is released
Message-ID: <4C32716C-B72B-425F-B91B-44B6E80D055F@cbs.dk>

The build system rolled up R-3.6.0.tar.gz (codename "Planting of a Tree") this morning.

The list below details the changes in this release.

You can get the source code from

http://cran.r-project.org/src/base/R-3/R-3.6.0.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard

These are the checksums (md5 and SHA-256) for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = b9c44f9f78cab3184ad9898bebc854b4
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 28a3942a7129877e9af1d5ea16202052
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = 6d227865440cc1ece3d97bdf4a8ee41e
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 591dcf615162127f904e4e461f330ce9
MD5 (R-latest.tar.gz) = 65601eac6d353f7efb5b48c29097c2fb
MD5 (README) = f468f281c919665e276a1b691decbbe6
MD5 (RESOURCES) = 529223fd3ffef95731d0a87353108435
MD5 (THANKS) = 08158353102084599797db8c9ccf8e2a
MD5 (VERSION-INFO.dcf) = 97d5e3df5e5ac56750695e4b49145fae
MD5 (R-3/R-3.6.0.tar.gz) = 65601eac6d353f7efb5b48c29097c2fb

2cde824a7b18958e5f06b391c801c8288be0f84fa8934b7ddefef23c67e60c09  AUTHORS
e6d6a009505e345fe949e1310334fcb0747f28dae2856759de102ab66b722cb4  COPYING
6095e9ffa777dd22839f7801aa845b31c9ed07f3d6bf8a26dc5d2dec8ccc0ef3  COPYING.LIB
38219d9c6221ccfbf075ef03711b420a1aa8731f890c8f2337148b602a217c2d  FAQ
f87461be6cbaecc4dce44ac58e5bd52364b0491ccdadaf846cb9b452e9550f31  INSTALL
184dfa18e3069782d1092b289a6fe6ef85feb951cd4d1566b225c746d29a5420  NEWS
4e21b62f515b749f80997063fceab626d7258c7d650e81a662ba8e0640f12f62  NEWS.0
12b30c724117b1b2b11484673906a6dcd48a361f69fc420b36194f9218692d01  NEWS.1
ca04f78ffe54afa326fe3ed40e7e1411aca0000ed2fa5ead97ddf51c6aa5b7bc  NEWS.2
36fcac3e452666158e62459c6fc810adc247c7109ed71c5b6c3ad5fc2bf57509  R-latest.tar.gz
2fdd3e90f23f32692d4b3a0c0452f2c219a10882033d1774f8cadf25886c3ddc  README
408737572ecc6e1135fdb2cf7a9dbb1a6cb27967c757f1771b8c39d1fd2f1ab9  RESOURCES
2d2e85e85574c4430951f6b070c08cd5aff1602abfd1bb162bed6d89c436b11f  THANKS
05bd1202b132c8e91a8887d923fcc525cfb3bf81c67847d15876b88bf0c68a71  VERSION-INFO.dcf
36fcac3e452666158e62459c6fc810adc247c7109ed71c5b6c3ad5fc2bf57509  R-3/R-3.6.0.tar.gz

This is the relevant part of the NEWS file

CHANGES IN R 3.6.0:

  SIGNIFICANT USER-VISIBLE CHANGES:

    * Serialization format version 3 becomes the default for
      serialization and saving of the workspace (save(), serialize(),
      saveRDS(), compiler::cmpfile()).  Serialized data in format 3
      cannot be read by versions of R prior to version 3.5.0.
      Serialization format version 2 is still supported and can be
      selected by version = 2 in the save/serialization functions.  The
      default can be changed back for the whole R session by setting
      environment variables R_DEFAULT_SAVE_VERSION and
      R_DEFAULT_SERIALIZE_VERSION to 2.  For maximal
      back-compatibility, files vignette.rds and partial.rdb generated
      by R CMD build are in serialization format version 2, and resave
      by default produces files in serialization format version 2
      (unless the original is already in format version 3).

    * The default method for generating from a discrete uniform
      distribution (used in sample(), for instance) has been changed.
      This addresses the fact, pointed out by Ottoboni and Stark, that
      the previous method made sample() noticeably non-uniform on large
      populations.  See PR#17494 for a discussion.  The previous method
      can be requested using RNGkind() or RNGversion() if necessary for
      reproduction of old results.  Thanks to Duncan Murdoch for
      contributing the patch and Gabe Becker for further assistance.

      The output of RNGkind() has been changed to also return the
      'kind' used by sample().

  NEW FEATURES:

    * Sys.setFileTime() has been vectorized so arguments path and time
      of length greater than one are now supported.

    * axis() gets new option gap.axis = NA for specifying a
      multiplication factor for the minimal "gap" (distance) between
      axis labels drawn.  Its default is 1 for labels _parallel_ to the
      axis, and 0.25 for perpendicular ones.

      Perpendicular labels no longer overlap, fixing bug PR#17384.

    * The default method of plot() gains new arguments xgap.axis = NA
      and ygap.axis = NA to be passed to the x- and y- axis(..,
      gap.axis=*) calls.

    * removeSource() now works not only for functions but also for some
      language objects.

    * as.call(), rep.int(), rep_len() and nchar() dispatch internally.

    * is(object, class2) looks for class2 in the calling namespace
      after looking in the namespace of class(object).

    * extendrange(.., f) with a length-2 f now extends separately to
      the left and the right.

    * lengths() dispatches internally to S4 methods.

    * download.file() on Windows now uses URLdecode() to determine the
      file extension, and uses binary transfer (mode = "wb") also for
      file extension .rds.

      The help page for download.file() now contains the same
      information on all platforms.

    * Setting C locale for collation _via_ environment variables LC_ALL
      and LC_COLLATE and _via_ a call to Sys.setlocale() now takes
      precedence over environment variable R_ICU_LOCALE.

    * There is a new function, nullfile(), to give the file name of the
      null system device (e.g., /dev/null) on the current platform.

    * There are two new options, keep.parse.data and
      keep.parse.data.pkgs, which control whether parse data are
      included into sources when keep.source or keep.source.pkgs is
      TRUE.  By default, keep.parse.data.pkgs is now FALSE, which
      changes previous behavior and significantly reduces space and
      time overhead when sources are kept when installing packages.

    * In rapply(x, ..), x can also be "list-like" and of length >=
      2^{31}.

    * trimws() gets new optional whitespace argument, allowing more
      extensive definitions of "space", such as including Unicode
      spaces (as wished in PR#17431).

    * weighted.mean() no longer coerces the weights to a double/numeric
      vector, since sum() now handles integer overflow. This makes
      weighted.mean() more polymorphic and endomorphic, but be aware
      that the results are no longer guaranteed to be a vector of type
      double.

    * When loading namespaces, S3 method registrations which overwrite
      previous registrations are now noted by default (using
      packageStartupMessage()).

    * compiler::cmpfile() gains a version argument, for use when the
      output file should be saved in serialization format 2.

    * The axis labeling in the default method of pairs() may now be
      toggled by new options horOdd and verOdd.

    * (Not Windows nor macOS.) Package tcltk now supports an
      environment variable R_DONT_USE_TK which if set disables Tk
      initialization.  This is intended for use to circumvent errors in
      loading the package, e.g. with recent Linux running under an
      address sanitizer.

    * The numeric method of all.equal() gets optional arguments countEQ
      and formatFUN.  If countEQ is true, the mean error is more
      sensible when many entries are *eq*ual.

    * outer(x,y, FUN = "*") is more efficient using tcrossprod(u,v)
      instead of u %*% t(v).

    * vcov(<mlm>) is more efficient via new optional arguments in
      summary.mlm().

    * The default method of summary() gets an option to choose the
      _kind_ of quantile()s to use; wish of PR#17438.

    * Fitting multiple linear models _via_ lm() does work with _matrix_
      offsets, as suggested in PR#17407.

    * The new functions mem.maxVSize() and mem.maxMSize() allow the
      maximal size of the vector heap and the maximal number of nodes
      allowed in the current R process to be queried and set.

    * news() gains support for NEWS.md files.

    * An effort has been started to have our reference manuals, i.e.,
      all help pages. show platform-independent information (rather
      than Windows or Unix-alike specifics visible only on that
      platform).  Consequently, the Windows version of X11() / x11()
      got identical formal arguments to the Unix one.

    * sessionInfo()$running has been factored out in a new variable
      osVersion.

    * slice.index() now also works for multi-dimensional margins.

    * untar() used with an external tar command assumes this supports
      decompression including xz and automagically detecting the
      compression type.  This has been true of all mainstream
      implementations since 2009 (for GNU tar, since version 1.22):
      older implementations are still supported _via_ the new argument
      support_old_tars whose default is controlled by environment
      variable R_SUPPORT_OLD_TARS.  (It looks like NetBSD and OpenBSD
      have 'older' tar commands for this purpose.)

    * The new function asplit() allow splitting an array or matrix by
      its margins.

    * New functions errorCondition() and warningCondition() provide a
      convenient way to create structured error and warning objects.

      .Deprecated() now signals a warning of class "deprecatedWarning",
      and .Defunct() now signals an error of class "defunctError".

    * Many 'package not found' errors are now signaled as errors of
      class "packageNotFoundError".

    * As an experimental feature, when loadNamespace() fails because
      the requested package is not available the error is initially
      signaled with a retry_loadNamespace restart available.  This
      allows a calling handler to try to install the package and
      continue.

    * S3method() directives in NAMESPACE can now also be used to
      perform _delayed_ S3 method registration.

    * Experimentally, setting environment variable
      _R_CHECK_LENGTH_1_LOGIC2_ will lead to warnings (or errors if the
      variable is set to a 'true' value) when && or || encounter and
      use arguments of length more than one.

    * Added "lines" and "chars" coordinate systems to grconvertX() and
      grconvertY().

    * getOption() is more efficient notably for the rare case when
      called with two arguments, from several contributors in PR#17394.

    * In .col(dim) and .row(dim), dim now may also be an integer-valued
      "double".

    * sQuote() and dQuote() get an explicit q argument with obvious
      default instead of using getOption("fancyQuotes") implicitly and
      unconditionally.

    * unzip() can list archives with comments and with spaces in file
      names even using an external unzip command.

    * Command line completion has a new setting rc.settings(dots =
      FALSE) to remove ... from the list of possible function
      arguments.

    * library() no longer checks packages with compiled code match
      R.version$platform.  loadNamespace() never has, and increasingly
      the 'canonical name' does not reflect the important
      characteristics of compiled code.

    * The primitive functions drop() and unclass() now avoid
      duplicating their data for atomic vectors that are large enough,
      by returning ALTREP wrapper objects with adjusted attributes.
      R-level assignments to change attributes will also use wrapper
      objects to avoid duplicating data for larger atomic vectors. R
      functions like structure() and unname() will therefore not
      duplicate data in these settings.  Generic vectors as produced by
      list() are not yet covered by this optimization but may be in due
      course.

    * In formals(), envir becomes an optional argument instead of being
      hardwired.

    * Instead of signalling an error for an invalid S4 object x, str(x)
      now gives a warning and subsequently still shows most parts of x,
      e.g., when slots are missing.

    * gamma(x) and lgamma(x) no longer warn when correctly returning
      Inf or underflowing to zero.  This helps maximum likelihood and
      similar computations.

    * convertColor() is now vectorized, so a lot faster for converting
      many colours at once.  The new argument vectorized to
      colorConverter() ensures that non-vectorized colour converters
      still work.  (Thanks to Brodie Gaslam.)

    * download.file() and url() get new argument headers for custom
      HTTP headers, e.g., allowing to perform basic http
      authentication, thanks to a patch contributed by G'abor Cs'ardi.

    * File-based connection functions file(), gzfile(), bzfile() and
      xzfile() now signal an error when used on a directory.

    * For approx(), splinefun() _etc_, a new setting ties =
      c("ordered", <fun>) allows skipping the sorting and still treat
      ties.

    * format(x) gives a more user friendly error message in the case
      where no method is defined.  A minimal method is provided in
      format.default(x) when isS4(x) is true.

    * which(x) now also works when x is a long vector, thanks to
      Suharto Anggono's PR#17201.  *NB*: this may return a double
      result, breaking the previous guarantee of an integer result.

    * seq.default() is more careful to return an integer (as opposed to
      double) result when its arguments are large and/or classed
      objects; see comment #9 of Suharto Anggono's PR#17497.

    * The plot() method for lm and glm fits, plot.lm(), gains a new
      option iter.smooth with a default of 0 for binomial fits, no
      longer down-weighting when smoothing the residuals.

    * zip() passes its list of files _via_ standard input to the
      external command when too long for the command line (on some
      platforms).

    * data() gains an overwrite argument.

    * t.test() now also returns the standard error (in list component
      stderr).

    * model.matrix(*, contrasts.arg = CC) now warns about invalid
      contrasts.args.

    * Performance of substr() and substring() has been improved.

    * stopifnot() has been simplified thanks to Suharto Anggono's
      proposals to become considerably faster for cheap expressions.

    * The default 'user agent' has been changed when accessing http://
      and https:// sites using libcurl.  (A site was found which caused
      libcurl to infinite-loop with the previous default.)

    * sessionInfo() now also contains RNGkind() and prints it when it
      differs from the default; based on a proposal and patch by Gabe
      Becker in PR#17535.  Also, RNGversion(getRversion()) works
      directly.

    * library() and require() now allow more control over handling
      search path conflicts when packages are attached. The policy is
      controlled by the new conflicts.policy option.

    * barplot() gets a formula method, thanks to a patch proposal by
      Arni Magnusson in PR#17521.

    * pmax() and pmin(x) now also work for long vectors, thanks to
      Suharto Anggono's PR#17533.

    * bxp() now warns when omitting duplicated arguments.

    * New hcl.colors() function to provide wide range of HCL-based
      colour palettes with much better perceptual properties than the
      existing RGB/HSV-based palettes like rainbow().

      Also a new hcl.pals() function to list available palette names
      for hcl.colors().

      Contributed by Achim Zeileis.

    * The default colours for image() and filled.contour() are now
      based on hcl.colors().

    * The palette-generating functions rainbow(), gray.colors(), etc.
      get a new rev argument to facilitate reversing the order of
      colors.

    * New str2lang() and str2expression() as streamlined versions of
      parse(text=., keep.source=FALSE) allow to abstract typical call
      constructions, e.g., in formula manipulations.  (Somewhat
      experimental)

    * Add update_PACKAGES() for incrementally updating a package
      repository index, instead of rebuilding the index from scratch.
      Thanks to Gabe Becker in PR#17544 for the patch, based on part of
      his switchr package.

  INSTALLATION on a UNIX-ALIKE:

    * The options selected for the C++ compiler default to the C++11
      standard if supported, otherwise to the C++98 standard.

    * Visibility macros such as C_VISIBILITY can now be user-set
      (including to empty), e.g. in config.site.

    * Macro FCLIBS, which has sometimes been needed on Solaris, has
      been renamed to FCLIBS_XTRA.

    * Macro F77 is always set to the value of FC, so the latter should
      be set to user-select the Fortran compiler for both fixed-form
      and free-form Fortran.  In particular, gfortran is now the first
      choice for F77, not f95.

      Macros FFLAGS and FCFLAGS remain distinct to allow for a compiler
      which needs a flag to select free- or fixed-form Fortran (most
      use the source-file extension to choose: .f is fixed-form and
      .f90 and .f95 are free-form).

      If only one of them is set, its value is used for both.

    * The special-casing of CFLAGS, CXXFLAGS and FFLAGS for Intel
      compilers on Linux has been removed: we do not have recent
      experience but the generic defaults now chosen are the same as
      those previously special-cased for x86_64.

      If necessary, override the defaults on the configure command line
      or in file config.site.

    * Long-untested configure support for HP-UX and very old versions
      of Linux has been removed.

    * configure --with-blas (without specifying a value) includes
      OpenBLAS in its search (before ATLAS and a generic BLAS).  This
      follows recent versions of the ax_blas autoconf macro.

    * The configure macro MAKEINFO has been updated to TEXI2ANY.

    * Support for make install-strip has been enhanced.

  PACKAGE INSTALLATION:

    * Source package installation is by default 'staged': the package
      is installed into a temporary location under the final library
      directory and moved into place once the installation is complete.
      The benefit is that partially-installed packages are hidden from
      other R sessions.

      The overall default is set by environment variable
      R_INSTALL_STAGED.  R CMD INSTALL has new options --staged-install
      and --no-staged-install, and packages can use the StagedInstall
      field in their DESCRIPTION file to opt out.  (That opt-out is a
      temporary measure which may be withdrawn in future.)

      Staged installation requires either --pkglock or --lock, one of
      which is used by default.

    * The interpretation of source code with extension .f is changing.
      Previously this denoted FORTRAN 77 code, but current compilers no
      longer have a FORTRAN 77 mode and interpret it as 'fixed-form'
      Fortran 90 (or later where supported) code.  Extensions .f90 and
      .f95 continue to indicate 'free-form' Fortran code.

      Legal FORTRAN 77 code is also legal fixed-form Fortran 9x;
      however this change legitimizes the use of later features, in
      particular to replace features marked 'obsolescent' in Fortran 90
      and 'deleted' in Fortran 2018 which gfortran 8.x and later warn
      about.

    * Packages containing files in the src directory with extensions
      .f90 or .f95 are now linked using the C or C++ compiler rather
      than the Fortran 9x compiler.  This is consistent with fixed-form
      Fortran code and allows mixing of C++ and free-form Fortran on
      most platforms.

      Consequentially, a package which includes free-form Fortran 9x
      code which uses OpenMP should include SHLIB_OPENMP_CFLAGS (or the
      CXXFLAGS version if they also include C++ code) in PKG_LIBS
      rather than SHLIB_OPENMP_FCFLAGS - fortunately on almost all
      current platforms they are the same flag.

    * Macro PKG_FFLAGS will be used for the compilation of both
      fixed-form and free-form Fortran code unless PKG_FCFLAGS is also
      set (in src/Makevars or src/Makevars.win).

    * The make macro F_VISIBILITY is now preferred for both fixed-form
      and free-form Fortran, for use in src/Makevars and similar.

    * R CMD INSTALL gains a new option --strip which (where supported)
      strips installed shared object(s): this can also be achieved by
      setting the environment variable _R_SHLIB_STRIP_ to a true value.

      The new option --strip-lib attempts stripping of static and
      shared libraries installed under lib.

      These are most useful on platforms using GNU binutils (such as
      Linux) and compiling with -g flags.

    * There is more support for installing UTF-8-encoded packages in a
      strict Latin-1 locale (and probably for other Latin locales):
      non-ASCII comments in R code (and NAMESPACE files) are worked
      around better.

  UTILITIES:

    * R CMD check now optionally checks makefiles for correct and
      portable use of the SHLIB_OPENMP_*FLAGS macros.

    * R CMD check now evaluates \Sexpr{} expressions (including those
      in macros) before checking the contents of Rd files and so
      detects issues both in evaluating the expressions and in the
      expanded contents.

    * R CMD check now lists missing packages separated by commas and
      with regular quotes such as to be useful as argument in calling
      install.packages(c(..)); from a suggestion by Marcel Ramos.

    * tools::Rd2latex() now uses UTF-8 as its default output encoding.

    * R CMD check now checks line endings of files with extension .hpp
      and those under inst/include.  The check now includes that a
      non-empty file is terminated with a newline.

      R CMD build will correct line endings in such files.

    * R CMD check now tries re-building all vignettes rather than
      stopping at the first error: whilst doing so it adds 'bookmarks'
      to the log.  By default (see the 'R Internals' manual) it
      re-builds each vignette in a separate process.

      It now checks for duplicated vignette titles (also known as
      'index entries'): they are used as hyperlinks on CRAN package
      pages and so do need to be unique.

    * R CMD check has more comprehensive checks on the data directory
      and the functioning of data() in a package.

    * R CMD check now checks autoconf-generated configure files have
      their corresponding source files, including optionally attempting
      to regenerate them on platforms with autoreconf.

    * R CMD build has a new option --compression to select the
      compression used for the tarball.

    * R CMD build now removes src/*.mod files on all platforms.

  C-LEVEL FACILITIES:

    * New pointer protection C functions R_PreserveInMSet and
      R_ReleaseFromMSet have been introduced to replace UNPROTECT_PTR,
      which is not safe to mix with UNPROTECT (and with
      PROTECT_WITH_INDEX). Intended for use in parsers only.

    * NAMEDMAX has been raised to 7 to allow further protection of
      intermediate results from (usually ill-advised) assignments in
      arguments to BUILTIN functions. Properly written package code
      should not be affected.

    * R_unif_index is now considered to be part of the C API.

    * R_GetCurrentEnv() allows C code to retrieve the current
      environment.

  DEPRECATED AND DEFUNCT:

    * Argument compressed of untar() is deprecated - it is only used
      for external tar commands which increasingly for extraction
      auto-detect compression and ignore their zjJ flags.

    * var(f) and hence sd(f) now give an error for factor arguments;
      they gave a deprecation warning since R 3.2.3, PR#16564.

    * Package tools' vignetteDepends() has been deprecated (it called a
      function deprecated since Feb 2016), being partly replaced by
      newly exported vignetteInfo().

    * The f77_f2c script has been removed: it no longer sufficed to
      compile the .f files in R.

    * The deprecated legacy support of make macros such as CXX1X has
      been removed: use the CXX11 forms instead.

    * Make macro F77_VISIBILITY is deprecated in favour of
      F_VISIBILITY.

    * Make macros F77, FCPIFCPLAGS and SHLIB_OPENMP_FCFLAGS are
      deprecated in favour of FC, FPICFLAGS and SHLIB_OPENMP_FFLAGS
      respectively.

    * $.data.frame had become an expensive version of the default
      method, so has been removed. (Thanks to Radford Neal for picking
      this up and to Duncan Murdoch for providing a patch.)

  BUG FIXES:

    * replayPlot(r) now also works in the same R session when r has
      been "reproduced" from serialization, typically after saving to
      and reading from an RDS file.

    * substr() and substring() now signal an error when the input is
      invalid UTF-8.

    * file.copy() now works also when its argument to is of length
      greater than one.

    * mantelhaen.test() no longer suffers from integer overflow in
      largish cases, thanks to Ben Bolker's PR#17383.

    * Calling setGeneric("foo") in a package no longer fails when the
      enclosing environment of the implicit generic foo() is
      .GlobalEnv.

    * untar(file("<some>.tar.gz"), *) now gives a better error message,
      suggesting to use gzfile() instead.

    * Method dispatch uses more relevant environments when looking up
      class definitions.

    * The documentation for identify() incorrectly claimed that the
      indices of identified points were returned in the order that the
      points were selected.  identify() now has a new argument order to
      allow the return value to include the order in which points were
      identified; the documentation has been updated.  Reported by
      Richard Rowe and Samuel Granjeaud.

    * order(...., decreasing=c(TRUE, FALSE)) could fail in some cases.
      Reported from StackOverflow via Karl Nordstr"om.

    * User macros in Rd files now accept empty and multi-line
      arguments.

    * Changes in print.*(), thanks to Lionel Henry's patches in
      PR#17398:

        * Printing lists, pairlists or attributes containing calls with
          S3 class no longer evaluate those.

        * Printing S4 objects within lists and pairlists dispatches
          with show() rather than print(), as with auto-printing.

        * The indexing tags (names or [[<n>]]) of recursive data
          structures are now printed correctly in complex cases.

        * Arguments supplied to print() are now properly forwarded to
          methods when printing lists, pairlists or attributes
          containing S3 objects.

        * The print parameters are now preserved when printing S3
          objects or deparsing symbols and calls.  Previously, printing
          lists containing S3 objects or expressions would reset these
          parameters.

        * Printing lists, pairlists or attributes containing functions
          now uses srcref attributes if present.

    * Calling install.packages() with a length zero pkgs argument now
      is a no-op (PR#17422).

    * unlist(x) now returns a correct factor when x is a nested list
      with factor leaves, fixing PR#12572 and PR#17419.

    * The documentation help(family) gives more details about the aic
      component, thanks to Ben Bolker's prompting.

    * The documentation for attributes and `attributes<-` now gives x
      as name of the first and main argument which the implementation
      has been requiring, fixing PR#17434.  For consistency, the first
      argument name is also changed from obj to x for
      `mostattributes<-`.

    * strwidth() now uses par("font") as default font face (PR#17352).

    * plot(<table>, log="x") no longer warns about log.

    * The print() method for "htest" objects now formats the test
      statistic and parameter directly and hence no longer rounds to
      units _before_ the decimal point.  Consequently, printing of
      t.test() results with a small number of digits now shows
      non-large df's to the full precision (PR#17444).

    * kruskal.test() and fligner.test() no longer erroneously insist on
      numeric g group arguments (PR#16719).

    * Printing a news db via the browser now does a much better job
      (PR#17433).

    * print.aov() missed column names in the multivariate case due to
      misspelling (reported by Chris Andrews).

    * axis() now creates valid at locations also for small subnormal
      number ranges in log scale plots.

    * format.POSIXlt() now also recycles the zone and gmtoff list
      components to full length when needed, and its internal C code
      detects have_zone in more cases.  In some cases, this changes its
      output to become compatible with format.POSIXct().

    * On Windows, detectCores() in package parallel now detects
      processors in all processor groups, not just the group R is
      running in (impacts particularly systems with more than 64
      logical processors).  Reported by Arunkumar Srinivasan.

    * On Windows, socketSelect() would hang with more than 64 sockets,
      and hence parallel::clusterApplyLB() would hang with more than 64
      workers.  Reported by Arunkumar Srinivasan.

    * as(1L, "double") now does coerce (PR#17457).

    * lm.influence(), influence.measures(), rstudent() etc now work
      (more) correctly for multivariate models ("mlm"), thanks to
      (anonymous) stackoverflow remarks.

    * sample.int(2.9, *, replace=TRUE) again behaves as documented and
      as in R < 3.0.0, namely identically to sample.int(2, ..).

    * Fixes to convertColor() for chromatic adaptation; thanks to
      Brodie Gaslam PR#17473.

    * Using \Sexpr[stage=install]{..} to create an Rd section no longer
      gives a warning in R CMD check; problem originally posted by
      G'abor Cs'ardi, then reported as PR#17479 with a partial patch by
      Duncan Murdoch.

    * Parse data now include a special node for equal assignment.

    * split.default() no longer relies on [[<-(), so it behaves as
      expected when splitting an object by a factor with the empty
      string as one of its levels.  Thanks to Brad Friedman for the
      report.

    * Line numbers in messages about .Rd files are now more reliable,
      thanks to a patch from Duncan Murdoch.

    * In the numeric method for all.equal(), a numeric scale argument
      is now checked to be positive and allowed to be of length > 1.
      (The latter worked originally and with a warning in recent
      years).

    * Deferred string conversions now record the OutDec option setting
      when not equal to the default.  Reported by Michael Sannella.

    * When y is numeric and f a factor, plot(y ~ f) nicely uses "y" and
      "f" as y- and x-labels.  The more direct boxplot(y ~ f) now does
      too.  The new argument ann = FALSE may be used to suppress these.

    * Subassignment to no/empty rows of a data frame is more consistent
      and typically a no-op in all cases instead of sometimes an error;
      part of Emil Bode's PR#17483.

    * Calls like formatC(*, zero.print = "< 0.001") no longer give an
      error and are further improved via new optional argument
      replace.zero.  Reported by David Hugh-Jones.

    * methods::formalArgs("<fn>") now finds the same function as
      formals("<fn>"), fixing Emil Bode's PR#17499.

    * The methods package better handles duplicated class names across
      packages.

    * The default method of seq() now avoids integer overflow, thanks
      to the report and "cumsum" patch of Suharto Anggono's PR#17497.

    * sub() no longer loses encodings for non-ASCII replacements
      (PR#17509).

    * Fix for rotated raster image on X11 device.  (Partial fix for
      PR#17148; thanks to Mikko Korpela).

    * formula(model.frame(frml, ..)) now returns frml in all cases,
      thanks to Bill Dunlap.  The previous behavior is available as
      DF2formula(<model.frame>).

    * ar.ols() also returns scalar var.pred in univariate case
      (PR#17517).

    * normalizePath() now treats NA path as non-existent and normalizes
      it to NA.  file.access() treats NA file name as non-existent.
      file.edit() and connection functions such as file() now treat NA
      file names as errors.

    * The internal regularize.values() auxiliary of approx(),
      splinefun() etc now warns again when there are ties and the
      caller did not specify ties.  Further, it no longer duplicates x
      and y unnecessarily when x is already sorted (PR#17515).

    * strtoi("", base) now gives NA on all platforms, following its
      documentation.  Reported by Michael Chirico.

    * In the definition of an S4 class, prototype elements are checked
      against the slots of the class, with giving a prototype for an
      undefined slot now being an error.  (Reported by Bill Dunlap.)

    * From setClassUnion(), if environment variable
      _R_METHODS_SHOW_CHECKSUBCLASSES is set to true, the internal
      .checkSubclasses() utility prints debugging info to see where it
      is used.

    * max.col(m) with an m of zero columns now returns integer NA
      (instead of 1).

    * axTicks() no longer returns small "almost zero" numbers (in
      exponential format) instead of zero, fixing Ilario Gelmetti's
      PR#17534.

    * isSymmetric(matrix(0, dimnames=list("A","b"))) is FALSE again, as
      always documented.

    * The cairo_pdf graphics device (and other Cairo-based devices) now
      clip correctly to the right and bottom border.

      There was an off-by-one-pixel bug, reported by Lee Kelvin.

    * as.roman(3) <= 2:4 and all other comparisons now work, as do
      group "Summary" function calls such as max(as.roman(sample(20)))
      and as.roman(NA).  (Partly reported by Bill Dunlap in PR#17542.)

    * reformulate("x", response = "sin(y)") no longer produces extra
      back quotes, PR#17359, and gains new optional argument env.

    * When reading console input from stdin with re-encoding (R
      --encoding=enc < input) the code on a Unix-alike now ensures that
      each converted input line is terminated with a newline even if
      re-encoding fails.

    * as.matrix.data.frame() now produces better strings from logicals,
      thanks to PR#17548 from Gabe Becker.

    * The S4 generic signature of rowSums(), rowMeans(), colSums() and
      colMeans() is restricted to "x".

    * match(x, tab) now works for long _character_ vectors x, thanks to
      PR#17552 by Andreas Kersting.

    * Class unions are unloaded when their namespace is unloaded
      (PR#17531, adapted from a patch by Brodie Gaslam).

    * selectMethod() is robust to ANY-truncation of method signatures
      (thanks to Herve Pages for the report).



-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From |orenzo@|@e||@ @end|ng |rom gm@||@com  Fri Apr 26 16:51:28 2019
From: |orenzo@|@e||@ @end|ng |rom gm@||@com (Lorenzo Isella)
Date: Fri, 26 Apr 2019 16:51:28 +0200
Subject: [R] Sequential Filtering of a Data Set
Message-ID: <20190426145128.2nzpvmbhkbkh5dud@chicca2>

Dear All,
I must be drowning in a glass of water.
Consider the following data set

tt2<-structure(list(year = c(2000, 2001, 2002, 2003, 2004, 2005, 2006, 
2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 
2018), country = c("DE", "DE", "DE", "DE", "DE", "DE", "DE", 
"DE", "DE", "DE", "DE", "DE", "DE", "DE", "DE", "DE", "DE", "DE", 
"DE"), berd = c(35600, 36331.9, 36950, 38029, 38363, 38651.038, 
41148, 43034, 46073, 45275, 46929, 51077.2, 53790.1, 53566.2, 
56996.5, 60952, 62826, 68644, NA)), row.names = c(NA, -19L), class = c("tbl_df", 
"tbl", "data.frame"))


I would like to obtain a list of it, where every element of the list
contains the subset of tt2 for which year>=2000,
year>=2001....year>=2018 etc...
It seems something I can tackle with map or map2 from purrr, but so
far I am banging my head against the wall.
Anyone can help me?
Regards

Lorenzo


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Apr 26 17:06:49 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 26 Apr 2019 16:06:49 +0100
Subject: [R] Sequential Filtering of a Data Set
In-Reply-To: <20190426145128.2nzpvmbhkbkh5dud@chicca2>
References: <20190426145128.2nzpvmbhkbkh5dud@chicca2>
Message-ID: <1390e9c4-0529-4686-bd56-c5557a565fe6@sapo.pt>

Hello,

Something like this?

Map(function(y) {subset(tt2, year >= y)}, 2001:2018)

Or this?

mapply(function(y) {subset(tt2, year >= y)}, 2001:2018, SIMPLIFY = FALSE)


Hope this helps,

Rui Barradas

?s 15:51 de 26/04/19, Lorenzo Isella escreveu:
> Dear All,
> I must be drowning in a glass of water.
> Consider the following data set
> 
> tt2<-structure(list(year = c(2000, 2001, 2002, 2003, 2004, 2005, 2006, 
> 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018), 
> country = c("DE", "DE", "DE", "DE", "DE", "DE", "DE", "DE", "DE", "DE", 
> "DE", "DE", "DE", "DE", "DE", "DE", "DE", "DE", "DE"), berd = c(35600, 
> 36331.9, 36950, 38029, 38363, 38651.038, 41148, 43034, 46073, 45275, 
> 46929, 51077.2, 53790.1, 53566.2, 56996.5, 60952, 62826, 68644, NA)), 
> row.names = c(NA, -19L), class = c("tbl_df", "tbl", "data.frame"))
> 
> 
> I would like to obtain a list of it, where every element of the list
> contains the subset of tt2 for which year>=2000,
> year>=2001....year>=2018 etc...
> It seems something I can tackle with map or map2 from purrr, but so
> far I am banging my head against the wall.
> Anyone can help me?
> Regards
> 
> Lorenzo
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From e@@w|ek @end|ng |rom gm@||@com  Sat Apr 27 16:25:51 2019
From: e@@w|ek @end|ng |rom gm@||@com (Ek Esawi)
Date: Sat, 27 Apr 2019 10:25:51 -0400
Subject: [R] Sequential Filtering of a Data Set
In-Reply-To: <20190426145128.2nzpvmbhkbkh5dud@chicca2>
References: <20190426145128.2nzpvmbhkbkh5dud@chicca2>
Message-ID: <CA+ZkTxvUTnNZtNU_pNkLrLxNC4Ez+yCdKcBQ-Npc-xonZQLVuw@mail.gmail.com>

Hi

If i understand your question correctly, it seems split or split date
will do what you want.

BOL--EK

On Fri, Apr 26, 2019 at 10:51 AM Lorenzo Isella
<lorenzo.isella at gmail.com> wrote:
>
> Dear All,
> I must be drowning in a glass of water.
> Consider the following data set
>
> tt2<-structure(list(year = c(2000, 2001, 2002, 2003, 2004, 2005, 2006,
> 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017,
> 2018), country = c("DE", "DE", "DE", "DE", "DE", "DE", "DE",
> "DE", "DE", "DE", "DE", "DE", "DE", "DE", "DE", "DE", "DE", "DE",
> "DE"), berd = c(35600, 36331.9, 36950, 38029, 38363, 38651.038,
> 41148, 43034, 46073, 45275, 46929, 51077.2, 53790.1, 53566.2,
> 56996.5, 60952, 62826, 68644, NA)), row.names = c(NA, -19L), class = c("tbl_df",
> "tbl", "data.frame"))
>
>
> I would like to obtain a list of it, where every element of the list
> contains the subset of tt2 for which year>=2000,
> year>=2001....year>=2018 etc...
> It seems something I can tackle with map or map2 from purrr, but so
> far I am banging my head against the wall.
> Anyone can help me?
> Regards
>
> Lorenzo
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From |orenzo@|@e||@ @end|ng |rom gm@||@com  Sat Apr 27 21:56:14 2019
From: |orenzo@|@e||@ @end|ng |rom gm@||@com (Lorenzo Isella)
Date: Sat, 27 Apr 2019 21:56:14 +0200
Subject: [R] Sequential Filtering of a Data Set
In-Reply-To: <1390e9c4-0529-4686-bd56-c5557a565fe6@sapo.pt>
References: <20190426145128.2nzpvmbhkbkh5dud@chicca2>
 <1390e9c4-0529-4686-bd56-c5557a565fe6@sapo.pt>
Message-ID: <20190427195614.y73gwl77zufendtf@masha>

Perfect!
Thanks a lot.

Lorenzo

On Fri, Apr 26, 2019 at 04:06:49PM +0100, Rui Barradas wrote:
>Hello,
>
>Something like this?
>
>Map(function(y) {subset(tt2, year >= y)}, 2001:2018)
>
>Or this?
>
>mapply(function(y) {subset(tt2, year >= y)}, 2001:2018, SIMPLIFY = FALSE)
>
>
>Hope this helps,
>
>Rui Barradas
>
>?s 15:51 de 26/04/19, Lorenzo Isella escreveu:
>>Dear All,
>>I must be drowning in a glass of water.
>>Consider the following data set
>>
>>tt2<-structure(list(year = c(2000, 2001, 2002, 2003, 2004, 2005, 
>>2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 
>>2017, 2018), country = c("DE", "DE", "DE", "DE", "DE", "DE", "DE", 
>>"DE", "DE", "DE", "DE", "DE", "DE", "DE", "DE", "DE", "DE", "DE", 
>>"DE"), berd = c(35600, 36331.9, 36950, 38029, 38363, 38651.038, 
>>41148, 43034, 46073, 45275, 46929, 51077.2, 53790.1, 53566.2, 
>>56996.5, 60952, 62826, 68644, NA)), row.names = c(NA, -19L), class = 
>>c("tbl_df", "tbl", "data.frame"))
>>
>>
>>I would like to obtain a list of it, where every element of the list
>>contains the subset of tt2 for which year>=2000,
>>year>=2001....year>=2018 etc...
>>It seems something I can tackle with map or map2 from purrr, but so
>>far I am banging my head against the wall.
>>Anyone can help me?
>>Regards
>>
>>Lorenzo
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide 
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.


From gr@eme@r@d@v|d@on @end|ng |rom gm@||@com  Sun Apr 28 20:53:48 2019
From: gr@eme@r@d@v|d@on @end|ng |rom gm@||@com (Graeme Davidson)
Date: Sun, 28 Apr 2019 19:53:48 +0100
Subject: [R] non alphabetical strings
Message-ID: <90C4E309-DDC3-47FF-898B-CAA6F330A31A@gmail.com>

Hello All,

I can?t find the answer for this so I thought I would ask you lovely people. 

I have a data frame with a column of names, some of which have non-alphabetical letters.

How, do I extract the row indexes which do not meat the criteria of alphabetical [[:alpha:]].

Thanks in advance

All the best

Graeme 
   

library(dplyr)
my_df <- data.frame(name1 = c("david", "mo", "ma4tilda856", "steph", "hadley", "574383"),
                    name2 = c("craig", "salah", "dahl", "paris", "wick", "turing"), sex = c("m", "m", "f", "f", "m", "m?))
my_df %>%
  mutate_all(as.character)
	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Sun Apr 28 21:50:37 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 28 Apr 2019 12:50:37 -0700
Subject: [R] non alphabetical strings
In-Reply-To: <90C4E309-DDC3-47FF-898B-CAA6F330A31A@gmail.com>
References: <90C4E309-DDC3-47FF-898B-CAA6F330A31A@gmail.com>
Message-ID: <CAGxFJbTODq3uvPBZfrgBcpUgeft11pkXfgvv-AXh=z=EcpRenw@mail.gmail.com>

?grepl

gives you a logical vector for indexing.


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Apr 28, 2019 at 11:54 AM Graeme Davidson <
graeme.r.davidson at gmail.com> wrote:

> Hello All,
>
> I can?t find the answer for this so I thought I would ask you lovely
> people.
>
> I have a data frame with a column of names, some of which have
> non-alphabetical letters.
>
> How, do I extract the row indexes which do not meat the criteria of
> alphabetical [[:alpha:]].
>
> Thanks in advance
>
> All the best
>
> Graeme
>
>
> library(dplyr)
> my_df <- data.frame(name1 = c("david", "mo", "ma4tilda856", "steph",
> "hadley", "574383"),
>                     name2 = c("craig", "salah", "dahl", "paris", "wick",
> "turing"), sex = c("m", "m", "f", "f", "m", "m?))
> my_df %>%
>   mutate_all(as.character)
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Apr 28 22:26:40 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 28 Apr 2019 13:26:40 -0700
Subject: [R] non alphabetical strings
In-Reply-To: <CAGxFJbTODq3uvPBZfrgBcpUgeft11pkXfgvv-AXh=z=EcpRenw@mail.gmail.com>
References: <90C4E309-DDC3-47FF-898B-CAA6F330A31A@gmail.com>
 <CAGxFJbTODq3uvPBZfrgBcpUgeft11pkXfgvv-AXh=z=EcpRenw@mail.gmail.com>
Message-ID: <8600AF68-08E6-448D-9BB4-78FB9FB913BF@dcn.davis.ca.us>

Use pattern "[^[:alpha]]" with grepl.

On April 28, 2019 12:50:37 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>?grepl
>
>gives you a logical vector for indexing.
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Sun, Apr 28, 2019 at 11:54 AM Graeme Davidson <
>graeme.r.davidson at gmail.com> wrote:
>
>> Hello All,
>>
>> I can?t find the answer for this so I thought I would ask you lovely
>> people.
>>
>> I have a data frame with a column of names, some of which have
>> non-alphabetical letters.
>>
>> How, do I extract the row indexes which do not meat the criteria of
>> alphabetical [[:alpha:]].
>>
>> Thanks in advance
>>
>> All the best
>>
>> Graeme
>>
>>
>> library(dplyr)
>> my_df <- data.frame(name1 = c("david", "mo", "ma4tilda856", "steph",
>> "hadley", "574383"),
>>                     name2 = c("craig", "salah", "dahl", "paris",
>"wick",
>> "turing"), sex = c("m", "m", "f", "f", "m", "m?))
>> my_df %>%
>>   mutate_all(as.character)
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Apr 28 23:41:43 2019
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Sun, 28 Apr 2019 22:41:43 +0100
Subject: [R] non alphabetical strings
In-Reply-To: <8600AF68-08E6-448D-9BB4-78FB9FB913BF@dcn.davis.ca.us>
References: <90C4E309-DDC3-47FF-898B-CAA6F330A31A@gmail.com>
 <CAGxFJbTODq3uvPBZfrgBcpUgeft11pkXfgvv-AXh=z=EcpRenw@mail.gmail.com>
 <8600AF68-08E6-448D-9BB4-78FB9FB913BF@dcn.davis.ca.us>
Message-ID: <5594c838-320e-46c9-638d-cb574db35237@sapo.pt>

Hello,

There is a typo, the end colon is missing.

grepl(x, '[^[:alpha:]]')


Hope this helps,

Rui Barradas

?s 21:26 de 28/04/19, Jeff Newmiller escreveu:
> Use pattern "[^[:alpha]]" with grepl.
> 
> On April 28, 2019 12:50:37 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> ?grepl
>>
>> gives you a logical vector for indexing.
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sun, Apr 28, 2019 at 11:54 AM Graeme Davidson <
>> graeme.r.davidson at gmail.com> wrote:
>>
>>> Hello All,
>>>
>>> I can?t find the answer for this so I thought I would ask you lovely
>>> people.
>>>
>>> I have a data frame with a column of names, some of which have
>>> non-alphabetical letters.
>>>
>>> How, do I extract the row indexes which do not meat the criteria of
>>> alphabetical [[:alpha:]].
>>>
>>> Thanks in advance
>>>
>>> All the best
>>>
>>> Graeme
>>>
>>>
>>> library(dplyr)
>>> my_df <- data.frame(name1 = c("david", "mo", "ma4tilda856", "steph",
>>> "hadley", "574383"),
>>>                      name2 = c("craig", "salah", "dahl", "paris",
>> "wick",
>>> "turing"), sex = c("m", "m", "f", "f", "m", "m?))
>>> my_df %>%
>>>    mutate_all(as.character)
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From @chm|dtdom|n|k22 @end|ng |rom gm@||@com  Sun Apr 28 13:52:00 2019
From: @chm|dtdom|n|k22 @end|ng |rom gm@||@com (Dominik Schmidt)
Date: Sun, 28 Apr 2019 13:52:00 +0200
Subject: [R] Package for penalized multivariate Regression
Message-ID: <CA+Y3GSrxmge24Urfa2Uw9s=6mgoysTAB7d49QosOmDSznqNhkQ@mail.gmail.com>

Dear all,

I want to do a multivariate regression. So I have Y which is a matrix and
one vector x which is my predictor variable. I want to do a multivariate
regression with penalizing the coefficients I get. Something like: $||y-xb||
+ \lambda b^t P b $ But I have a "own" penalty term which I want to use for
penalized regression.

When I searched for penalized regression, I found a lot of packages but all
of them have predefined penalties like lasso, ridge or second differences.

I used the gam() package in mgcv when I had an univariate response:

gam(Y~x_1, paraPen = penaltymatrix)

but this package do not support multivariate regression.

Is there any R package where I can use an individual penalty matrix to my
coefficients? Or can you give me any advice how I solve the problem I have?

Kind regards,

Dominik

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Apr 29 16:51:02 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 29 Apr 2019 07:51:02 -0700
Subject: [R] Package for penalized multivariate Regression
In-Reply-To: <CA+Y3GSrxmge24Urfa2Uw9s=6mgoysTAB7d49QosOmDSznqNhkQ@mail.gmail.com>
References: <CA+Y3GSrxmge24Urfa2Uw9s=6mgoysTAB7d49QosOmDSznqNhkQ@mail.gmail.com>
Message-ID: <CAGxFJbT6WtFy_0eRZG6dnqMfHb1ku4H9KsN34XohWi6VE4=DTQ@mail.gmail.com>

"but this package do not support multivariate regression."
Wrong.

"Fits a generalized additive model (GAM) to data, the term ?GAM? being
taken to include any quadratically penalized GLM and a variety of other
models estimated by a quadratically penalised likelihood type approach (see
family.mgcv <http://127.0.0.1:24757/help/library/mgcv/help/family.mgcv>). "

So quadratic penalties only.

Also: This list is about R programming. Questions about statistical
methodology are generally off topic. Try stats.stackexchange.com instead
for that.

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Apr 29, 2019 at 5:07 AM Dominik Schmidt <schmidtdominik22 at gmail.com>
wrote:

> Dear all,
>
> I want to do a multivariate regression. So I have Y which is a matrix and
> one vector x which is my predictor variable. I want to do a multivariate
> regression with penalizing the coefficients I get. Something like:
> $||y-xb||
> + \lambda b^t P b $ But I have a "own" penalty term which I want to use for
> penalized regression.
>
> When I searched for penalized regression, I found a lot of packages but all
> of them have predefined penalties like lasso, ridge or second differences.
>
> I used the gam() package in mgcv when I had an univariate response:
>
> gam(Y~x_1, paraPen = penaltymatrix)
>
> but this package do not support multivariate regression.
>
> Is there any R package where I can use an individual penalty matrix to my
> coefficients? Or can you give me any advice how I solve the problem I have?
>
> Kind regards,
>
> Dominik
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@h1@kh|@gh| @end|ng |rom gm@||@com  Sun Apr 28 08:51:47 2019
From: m@h1@kh|@gh| @end|ng |rom gm@||@com (mahboobe akhlaghi)
Date: Sat, 27 Apr 2019 23:51:47 -0700
Subject: [R] (no subject)
Message-ID: <CANjNGqpYh1V8bbvAe2yxa4t4U+dL_U-ysVgL8g81CN1fMwxmpA@mail.gmail.com>

Hello.
I have a question from kamila package. I run this package on my data and
the database is on SQL server. now, I have an error that I don't know what
should I do.
kamrespresc<-kamila(conVarsPresc,catVarsFacPresc,numClust=3,numInit=10)
Error in matrix(data = log(gtools::rdirichlet(n = numClust, alpha = rep(1,
:
  length of 'dimnames' [2] not equal to array extent
In addition: Warning message:
In runif(numClust, min = xx[1], max = xx[2]) : NAs produced
thanks.



-- 
Best Regards,
Mahboobe Akhlaghi
PhD Student in Biostatistics
Isfahan University of Medical Sciences

	[[alternative HTML version deleted]]


From m@h1@kh|@gh| @end|ng |rom gm@||@com  Sun Apr 28 09:00:40 2019
From: m@h1@kh|@gh| @end|ng |rom gm@||@com (mahboobe akhlaghi)
Date: Sun, 28 Apr 2019 00:00:40 -0700
Subject: [R] A Question from kamila package
Message-ID: <CANjNGqpuBbdQ3rnnNk4yUmdsydo8Agxyufz=2pWCZv2pNE7Vng@mail.gmail.com>

Hello.
I have a question from kamila package. I run this package on my data and
the database is on SQL server. now, I have an error that I don't know what
should I do.
kamrespresc<-kamila(conVarsPresc,catVarsFacPresc,numClust=3,numInit=10)
Error in matrix(data = log(gtools::rdirichlet(n = numClust, alpha = rep(1,
:
  length of 'dimnames' [2] not equal to array extent
In addition: Warning message:
In runif(numClust, min = xx[1], max = xx[2]) : NAs produced
thanks.

-- 
Best Regards,
Mahboobe Akhlaghi
PhD Student in Biostatistics
Isfahan University of Medical Sciences

	[[alternative HTML version deleted]]


From bgunter@4567 @end|ng |rom gm@||@com  Mon Apr 29 18:13:51 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 29 Apr 2019 09:13:51 -0700
Subject: [R] Package for penalized multivariate Regression
In-Reply-To: <CAGxFJbT6WtFy_0eRZG6dnqMfHb1ku4H9KsN34XohWi6VE4=DTQ@mail.gmail.com>
References: <CA+Y3GSrxmge24Urfa2Uw9s=6mgoysTAB7d49QosOmDSznqNhkQ@mail.gmail.com>
 <CAGxFJbT6WtFy_0eRZG6dnqMfHb1ku4H9KsN34XohWi6VE4=DTQ@mail.gmail.com>
Message-ID: <CAGxFJbTgCRELV4-tWaR83dq2TXmbuq=UPViGcmFP1NeUhgUO=w@mail.gmail.com>

I should have added: for multivariate gam models see e.g. ?mvn

Bert Gunter


On Mon, Apr 29, 2019 at 7:51 AM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> "but this package do not support multivariate regression."
> Wrong.
>
> "Fits a generalized additive model (GAM) to data, the term ?GAM? being
> taken to include any quadratically penalized GLM and a variety of other
> models estimated by a quadratically penalised likelihood type approach (see
>  family.mgcv <http://127.0.0.1:24757/help/library/mgcv/help/family.mgcv>).
> "
>
> So quadratic penalties only.
>
> Also: This list is about R programming. Questions about statistical
> methodology are generally off topic. Try stats.stackexchange.com instead
> for that.
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Apr 29, 2019 at 5:07 AM Dominik Schmidt <
> schmidtdominik22 at gmail.com> wrote:
>
>> Dear all,
>>
>> I want to do a multivariate regression. So I have Y which is a matrix and
>> one vector x which is my predictor variable. I want to do a multivariate
>> regression with penalizing the coefficients I get. Something like:
>> $||y-xb||
>> + \lambda b^t P b $ But I have a "own" penalty term which I want to use
>> for
>> penalized regression.
>>
>> When I searched for penalized regression, I found a lot of packages but
>> all
>> of them have predefined penalties like lasso, ridge or second differences.
>>
>> I used the gam() package in mgcv when I had an univariate response:
>>
>> gam(Y~x_1, paraPen = penaltymatrix)
>>
>> but this package do not support multivariate regression.
>>
>> Is there any R package where I can use an individual penalty matrix to my
>> coefficients? Or can you give me any advice how I solve the problem I
>> have?
>>
>> Kind regards,
>>
>> Dominik
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From r@turner @end|ng |rom @uck|@nd@@c@nz  Tue Apr 30 00:55:01 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 30 Apr 2019 10:55:01 +1200
Subject: [R] Message produced under R 3.6.0.
Message-ID: <0b18650a-9eb2-b04c-c651-27b39c0badf9@auckland.ac.nz>


I just installed the latest version of R on my laptop (running Ubuntu 
18.04; used "sudo apt-get install r-base".)

Now when I load a package that I have written I get a message on screen:

> Registered S3 methods overwritten by 'ggplot2':
>   method         from 
>   [.quosures     rlang
>   c.quosures     rlang
>   print.quosures rlang
> Registered S3 method overwritten by 'dplyr':
>   method               from  
>   as.data.frame.tbl_df tibble
> Registered S3 method overwritten by 'xts':
>   method     from
>   as.zoo.xts zoo 

What is the import of this (mysterious and cryptic) pronouncement?  I 
don't understand it at all.  My package makes no use of ggplot2, dplyr 
or xts.

Should I be worried?  Are there adjustments that I should make to my 
package (e.g. to NAMESPACE)?

Thanks for any tips.

cheers,

Rolf Turner

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r@turner @end|ng |rom @uck|@nd@@c@nz  Tue Apr 30 01:32:05 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 30 Apr 2019 11:32:05 +1200
Subject: [R] Message produced under R 3.6.0.
In-Reply-To: <CAGxFJbSvCCgELZexXwzYzGPA5cOQaAQ2i33xr8A0ONx3JPjFLg@mail.gmail.com>
References: <0b18650a-9eb2-b04c-c651-27b39c0badf9@auckland.ac.nz>
 <CAGxFJbSvCCgELZexXwzYzGPA5cOQaAQ2i33xr8A0ONx3JPjFLg@mail.gmail.com>
Message-ID: <8afaeace-bacc-87c8-c6a4-1614d19deb42@auckland.ac.nz>


On 30/04/19 11:08 AM, Bert Gunter wrote:

> Offlist, as this might be complete baloney.

Thanks Bert.

I am CC-ing this reply to the r-help list since your suggestion is *NOT* 
complete baloney at all!

> What dependencies does your package have? -- is it possible that some of 
> these dependent packages have made changes or added features that have 
> ggplot2 etc. dependencies that cause these issues?

<SNIP>

The package has no dependencies as such, but "Imports" a number of 
packages.  I tried loading these, one by one, and when I did

library(brms)

I got the message that was triggered by loading my package.  So that is 
the source of the problem.  If it is indeed a problem.

The question remains:  is this message something that I (or the 
maintainer of brms) should be worried about?

cheers,

Rolf

> On Mon, Apr 29, 2019 at 3:55 PM Rolf Turner <r.turner at auckland.ac.nz 
> <mailto:r.turner at auckland.ac.nz>> wrote:
> 
> 
>     I just installed the latest version of R on my laptop (running Ubuntu
>     18.04; used "sudo apt-get install r-base".)
> 
>     Now when I load a package that I have written I get a message on screen:
> 
>      > Registered S3 methods overwritten by 'ggplot2':
>      >? ?method? ? ? ? ?from
>      >? ?[.quosures? ? ?rlang
>      >? ?c.quosures? ? ?rlang
>      >? ?print.quosures rlang
>      > Registered S3 method overwritten by 'dplyr':
>      >? ?method? ? ? ? ? ? ? ?from
>      >? ?as.data.frame.tbl_df tibble
>      > Registered S3 method overwritten by 'xts':
>      >? ?method? ? ?from
>      >? ?as.zoo.xts zoo
> 
>     What is the import of this (mysterious and cryptic) pronouncement?? I
>     don't understand it at all.? My package makes no use of ggplot2, dplyr
>     or xts.
> 
>     Should I be worried?? Are there adjustments that I should make to my
>     package (e.g. to NAMESPACE)?
> 
>     Thanks for any tips.
> 
>     cheers,
> 
>     Rolf Turner
> 
>     -- 
>     Honorary Research Fellow
>     Department of Statistics
>     University of Auckland
>     Phone: +64-9-373-7599 ext. 88276
> 
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From m@rc_@chw@rtz @end|ng |rom me@com  Tue Apr 30 02:01:01 2019
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Mon, 29 Apr 2019 20:01:01 -0400
Subject: [R] Message produced under R 3.6.0.
In-Reply-To: <8afaeace-bacc-87c8-c6a4-1614d19deb42@auckland.ac.nz>
References: <0b18650a-9eb2-b04c-c651-27b39c0badf9@auckland.ac.nz>
 <CAGxFJbSvCCgELZexXwzYzGPA5cOQaAQ2i33xr8A0ONx3JPjFLg@mail.gmail.com>
 <8afaeace-bacc-87c8-c6a4-1614d19deb42@auckland.ac.nz>
Message-ID: <E623C844-5863-4CD4-9E62-06AADABB2155@me.com>

Hi Guys,

I suspect that this entry from news() for 3.6.0 is relevant:

"When loading namespaces, S3 method registrations which overwrite previous registrations are now noted by default (using packageStartupMessage())."


Always a good idea to read the NEWS file with a x.y point release. Peter usually includes it in his release announcement e-mail:

  https://stat.ethz.ch/pipermail/r-help/2019-April/462510.html


Regards,

Marc Schwartz


> On Apr 29, 2019, at 7:32 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> 
> On 30/04/19 11:08 AM, Bert Gunter wrote:
> 
>> Offlist, as this might be complete baloney.
> 
> Thanks Bert.
> 
> I am CC-ing this reply to the r-help list since your suggestion is *NOT* complete baloney at all!
> 
>> What dependencies does your package have? -- is it possible that some of these dependent packages have made changes or added features that have ggplot2 etc. dependencies that cause these issues?
> 
> <SNIP>
> 
> The package has no dependencies as such, but "Imports" a number of packages.  I tried loading these, one by one, and when I did
> 
> library(brms)
> 
> I got the message that was triggered by loading my package.  So that is the source of the problem.  If it is indeed a problem.
> 
> The question remains:  is this message something that I (or the maintainer of brms) should be worried about?
> 
> cheers,
> 
> Rolf
> 
>> On Mon, Apr 29, 2019 at 3:55 PM Rolf Turner <r.turner at auckland.ac.nz <mailto:r.turner at auckland.ac.nz>> wrote:
>>    I just installed the latest version of R on my laptop (running Ubuntu
>>    18.04; used "sudo apt-get install r-base".)
>>    Now when I load a package that I have written I get a message on screen:
>>     > Registered S3 methods overwritten by 'ggplot2':
>>     >   method         from
>>     >   [.quosures     rlang
>>     >   c.quosures     rlang
>>     >   print.quosures rlang
>>     > Registered S3 method overwritten by 'dplyr':
>>     >   method               from
>>     >   as.data.frame.tbl_df tibble
>>     > Registered S3 method overwritten by 'xts':
>>     >   method     from
>>     >   as.zoo.xts zoo
>>    What is the import of this (mysterious and cryptic) pronouncement?  I
>>    don't understand it at all.  My package makes no use of ggplot2, dplyr
>>    or xts.
>>    Should I be worried?  Are there adjustments that I should make to my
>>    package (e.g. to NAMESPACE)?
>>    Thanks for any tips.
>>    cheers,
>>    Rolf Turner
>>    --     Honorary Research Fellow
>>    Department of Statistics
>>    University of Auckland
>>    Phone: +64-9-373-7599 ext. 88276


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Apr 30 02:19:31 2019
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 29 Apr 2019 17:19:31 -0700
Subject: [R] Message produced under R 3.6.0.
In-Reply-To: <8afaeace-bacc-87c8-c6a4-1614d19deb42@auckland.ac.nz>
References: <0b18650a-9eb2-b04c-c651-27b39c0badf9@auckland.ac.nz>
 <CAGxFJbSvCCgELZexXwzYzGPA5cOQaAQ2i33xr8A0ONx3JPjFLg@mail.gmail.com>
 <8afaeace-bacc-87c8-c6a4-1614d19deb42@auckland.ac.nz>
Message-ID: <6D8006BC-35BE-48F1-A728-E092362885AB@dcn.davis.ca.us>

Since you now have this indirect dependency, you should make sure you have updated this gaggle of packages. I have found that the dependencies do not necessarily update when I update the package that relies on them. It can take a few passes  of reading error/warming messages to get them all updated. I suspect you have old versions of packages that now delegate certain functions to lower-level packages, and these errors should go away when you have them all current.

On April 29, 2019 4:32:05 PM PDT, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>On 30/04/19 11:08 AM, Bert Gunter wrote:
>
>> Offlist, as this might be complete baloney.
>
>Thanks Bert.
>
>I am CC-ing this reply to the r-help list since your suggestion is
>*NOT* 
>complete baloney at all!
>
>> What dependencies does your package have? -- is it possible that some
>of 
>> these dependent packages have made changes or added features that
>have 
>> ggplot2 etc. dependencies that cause these issues?
>
><SNIP>
>
>The package has no dependencies as such, but "Imports" a number of 
>packages.  I tried loading these, one by one, and when I did
>
>library(brms)
>
>I got the message that was triggered by loading my package.  So that is
>
>the source of the problem.  If it is indeed a problem.
>
>The question remains:  is this message something that I (or the 
>maintainer of brms) should be worried about?
>
>cheers,
>
>Rolf
>
>> On Mon, Apr 29, 2019 at 3:55 PM Rolf Turner <r.turner at auckland.ac.nz 
>> <mailto:r.turner at auckland.ac.nz>> wrote:
>> 
>> 
>>     I just installed the latest version of R on my laptop (running
>Ubuntu
>>     18.04; used "sudo apt-get install r-base".)
>> 
>>     Now when I load a package that I have written I get a message on
>screen:
>> 
>>      > Registered S3 methods overwritten by 'ggplot2':
>>      >? ?method? ? ? ? ?from
>>      >? ?[.quosures? ? ?rlang
>>      >? ?c.quosures? ? ?rlang
>>      >? ?print.quosures rlang
>>      > Registered S3 method overwritten by 'dplyr':
>>      >? ?method? ? ? ? ? ? ? ?from
>>      >? ?as.data.frame.tbl_df tibble
>>      > Registered S3 method overwritten by 'xts':
>>      >? ?method? ? ?from
>>      >? ?as.zoo.xts zoo
>> 
>>     What is the import of this (mysterious and cryptic)
>pronouncement?? I
>>     don't understand it at all.? My package makes no use of ggplot2,
>dplyr
>>     or xts.
>> 
>>     Should I be worried?? Are there adjustments that I should make to
>my
>>     package (e.g. to NAMESPACE)?
>> 
>>     Thanks for any tips.
>> 
>>     cheers,
>> 
>>     Rolf Turner
>> 
>>     -- 
>>     Honorary Research Fellow
>>     Department of Statistics
>>     University of Auckland
>>     Phone: +64-9-373-7599 ext. 88276
>> 
>>     ______________________________________________
>>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>--
>>     To UNSUBSCRIBE and more, see
>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>     PLEASE do read the posting guide
>>     http://www.R-project.org/posting-guide.html
>>     and provide commented, minimal, self-contained, reproducible
>code.
>> 

-- 
Sent from my phone. Please excuse my brevity.


From r@turner @end|ng |rom @uck|@nd@@c@nz  Tue Apr 30 02:43:04 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 30 Apr 2019 12:43:04 +1200
Subject: [R] Message produced under R 3.6.0.
In-Reply-To: <6D8006BC-35BE-48F1-A728-E092362885AB@dcn.davis.ca.us>
References: <0b18650a-9eb2-b04c-c651-27b39c0badf9@auckland.ac.nz>
 <CAGxFJbSvCCgELZexXwzYzGPA5cOQaAQ2i33xr8A0ONx3JPjFLg@mail.gmail.com>
 <8afaeace-bacc-87c8-c6a4-1614d19deb42@auckland.ac.nz>
 <6D8006BC-35BE-48F1-A728-E092362885AB@dcn.davis.ca.us>
Message-ID: <0171b07b-b5d6-3c98-3c17-621f4bfb7ce6@auckland.ac.nz>


On 30/04/19 12:19 PM, Jeff Newmiller wrote:

> Since you now have this indirect dependency, you should make sure you
> have updated this gaggle of packages. I have found that the
> dependencies do not necessarily update when I update the package that
> relies on them. It can take a few passes  of reading error/warming
> messages to get them all updated. I suspect you have old versions of
> packages that now delegate certain functions to lower-level packages,
> and these errors should go away when you have them all current.

Nope.  Doesn't work.  I reinstalled brms and the messages still appeared 
when I loaded brms.

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r@turner @end|ng |rom @uck|@nd@@c@nz  Tue Apr 30 03:09:29 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 30 Apr 2019 13:09:29 +1200
Subject: [R] Message produced under R 3.6.0.
In-Reply-To: <E623C844-5863-4CD4-9E62-06AADABB2155@me.com>
References: <0b18650a-9eb2-b04c-c651-27b39c0badf9@auckland.ac.nz>
 <CAGxFJbSvCCgELZexXwzYzGPA5cOQaAQ2i33xr8A0ONx3JPjFLg@mail.gmail.com>
 <8afaeace-bacc-87c8-c6a4-1614d19deb42@auckland.ac.nz>
 <E623C844-5863-4CD4-9E62-06AADABB2155@me.com>
Message-ID: <d466a1f4-94c1-6902-51df-aa82fd874622@auckland.ac.nz>


On 30/04/19 12:01 PM, Marc Schwartz wrote:

> Hi Guys,
> 
> I suspect that this entry from news() for 3.6.0 is relevant:
> 
> "When loading namespaces, S3 method registrations which overwrite
> previous registrations are now noted by default (using
> packageStartupMessage())."
> 
> 
> Always a good idea to read the NEWS file with a x.y point release.
> Peter usually includes it in his release announcement e-mail:
> 
> https://stat.ethz.ch/pipermail/r-help/2019-April/462510.html

OK.  This seems to be the issue.  Basically I guess I could just ignore 
the messages --- but I'd really rather not see them.

The news() says they are printed by "default".  How can I move away from 
the default?

I presume that I need to invoke the suppressPackageStartupMessages() 
function, but it is not at all clear to me just how I should do this.

Perhaps I should put a call to this function in a *.R file
(e.g. "First.R") in my R directory.

I've experimented with various ideas; none so far have worked.  The 
function suppressPackageStartupMessages() takes an argument "expr".  It 
is not clear what "expr" should be in this context.

Perhaps I am barking up the wrong tree.

Any advice?

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Apr 30 03:25:51 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 29 Apr 2019 21:25:51 -0400
Subject: [R] Message produced under R 3.6.0.
In-Reply-To: <0171b07b-b5d6-3c98-3c17-621f4bfb7ce6@auckland.ac.nz>
References: <0b18650a-9eb2-b04c-c651-27b39c0badf9@auckland.ac.nz>
 <CAGxFJbSvCCgELZexXwzYzGPA5cOQaAQ2i33xr8A0ONx3JPjFLg@mail.gmail.com>
 <8afaeace-bacc-87c8-c6a4-1614d19deb42@auckland.ac.nz>
 <6D8006BC-35BE-48F1-A728-E092362885AB@dcn.davis.ca.us>
 <0171b07b-b5d6-3c98-3c17-621f4bfb7ce6@auckland.ac.nz>
Message-ID: <61263845-e867-714c-d910-c6064da23e2d@gmail.com>

On 29/04/2019 8:43 p.m., Rolf Turner wrote:
> 
> On 30/04/19 12:19 PM, Jeff Newmiller wrote:
> 
>> Since you now have this indirect dependency, you should make sure you
>> have updated this gaggle of packages. I have found that the
>> dependencies do not necessarily update when I update the package that
>> relies on them. It can take a few passes  of reading error/warming
>> messages to get them all updated. I suspect you have old versions of
>> packages that now delegate certain functions to lower-level packages,
>> and these errors should go away when you have them all current.
> 
> Nope.  Doesn't work.  I reinstalled brms and the messages still appeared
> when I loaded brms.

Those messages probably aren't due to brms directly: for example, the 
first set

 > Registered S3 methods overwritten by 'ggplot2':
 >   method         from
 >   [.quosures     rlang
 >   c.quosures     rlang
 >   print.quosures rlang

is due to issues with ggplot2 or rlang.  Have you tried updating both of 
those?

Duncan Murdoch


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Apr 30 03:31:04 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 29 Apr 2019 21:31:04 -0400
Subject: [R] Message produced under R 3.6.0.
In-Reply-To: <61263845-e867-714c-d910-c6064da23e2d@gmail.com>
References: <0b18650a-9eb2-b04c-c651-27b39c0badf9@auckland.ac.nz>
 <CAGxFJbSvCCgELZexXwzYzGPA5cOQaAQ2i33xr8A0ONx3JPjFLg@mail.gmail.com>
 <8afaeace-bacc-87c8-c6a4-1614d19deb42@auckland.ac.nz>
 <6D8006BC-35BE-48F1-A728-E092362885AB@dcn.davis.ca.us>
 <0171b07b-b5d6-3c98-3c17-621f4bfb7ce6@auckland.ac.nz>
 <61263845-e867-714c-d910-c6064da23e2d@gmail.com>
Message-ID: <cec765a8-1e0a-1481-611f-59033f05c8d1@gmail.com>

On 29/04/2019 9:25 p.m., Duncan Murdoch wrote:
> On 29/04/2019 8:43 p.m., Rolf Turner wrote:
>>
>> On 30/04/19 12:19 PM, Jeff Newmiller wrote:
>>
>>> Since you now have this indirect dependency, you should make sure you
>>> have updated this gaggle of packages. I have found that the
>>> dependencies do not necessarily update when I update the package that
>>> relies on them. It can take a few passes  of reading error/warming
>>> messages to get them all updated. I suspect you have old versions of
>>> packages that now delegate certain functions to lower-level packages,
>>> and these errors should go away when you have them all current.
>>
>> Nope.  Doesn't work.  I reinstalled brms and the messages still appeared
>> when I loaded brms.
> 
> Those messages probably aren't due to brms directly: for example, the
> first set
> 
>   > Registered S3 methods overwritten by 'ggplot2':
>   >   method         from
>   >   [.quosures     rlang
>   >   c.quosures     rlang
>   >   print.quosures rlang
> 
> is due to issues with ggplot2 or rlang.  Have you tried updating both of
> those?

To answer my own question:  this one still appears after updating those 
two, but it appears to be a bug in ggplot2, because that package 
replaces those functions in a file compat-quosures.R with comment

# TODO: Remove once rlang 0.2.0.9001 or later is on CRAN

and the rlang version on CRAN is now 0.3.4.

Duncan Murdoch


From r@turner @end|ng |rom @uck|@nd@@c@nz  Tue Apr 30 03:44:13 2019
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Tue, 30 Apr 2019 13:44:13 +1200
Subject: [R] Message produced under R 3.6.0.
In-Reply-To: <cec765a8-1e0a-1481-611f-59033f05c8d1@gmail.com>
References: <0b18650a-9eb2-b04c-c651-27b39c0badf9@auckland.ac.nz>
 <CAGxFJbSvCCgELZexXwzYzGPA5cOQaAQ2i33xr8A0ONx3JPjFLg@mail.gmail.com>
 <8afaeace-bacc-87c8-c6a4-1614d19deb42@auckland.ac.nz>
 <6D8006BC-35BE-48F1-A728-E092362885AB@dcn.davis.ca.us>
 <0171b07b-b5d6-3c98-3c17-621f4bfb7ce6@auckland.ac.nz>
 <61263845-e867-714c-d910-c6064da23e2d@gmail.com>
 <cec765a8-1e0a-1481-611f-59033f05c8d1@gmail.com>
Message-ID: <b2c45ecb-f8e5-8689-5c02-59c0c8058f96@auckland.ac.nz>


On 30/04/19 1:31 PM, Duncan Murdoch wrote:

> On 29/04/2019 9:25 p.m., Duncan Murdoch wrote:
>> On 29/04/2019 8:43 p.m., Rolf Turner wrote:
>>>
>>> On 30/04/19 12:19 PM, Jeff Newmiller wrote:
>>>
>>>> Since you now have this indirect dependency, you should make sure you
>>>> have updated this gaggle of packages. I have found that the
>>>> dependencies do not necessarily update when I update the package that
>>>> relies on them. It can take a few passes? of reading error/warming
>>>> messages to get them all updated. I suspect you have old versions of
>>>> packages that now delegate certain functions to lower-level packages,
>>>> and these errors should go away when you have them all current.
>>>
>>> Nope.? Doesn't work.? I reinstalled brms and the messages still appeared
>>> when I loaded brms.
>>
>> Those messages probably aren't due to brms directly: for example, the
>> first set
>>
>> ? > Registered S3 methods overwritten by 'ggplot2':
>> ? >?? method???????? from
>> ? >?? [.quosures???? rlang
>> ? >?? c.quosures???? rlang
>> ? >?? print.quosures rlang
>>
>> is due to issues with ggplot2 or rlang.? Have you tried updating both of
>> those?
> 
> To answer my own question:? this one still appears after updating those 
> two, but it appears to be a bug in ggplot2, because that package 
> replaces those functions in a file compat-quosures.R with comment
> 
> # TODO: Remove once rlang 0.2.0.9001 or later is on CRAN
> 
> and the rlang version on CRAN is now 0.3.4.
> 
> Duncan Murdoch

Thanks Duncan.  So I guess I should just wait until Hadley gets around 
to fixing ggplot2?

OTOH --- I would, on general principles, like to learn how to suppress 
such messages ....

cheers,

Rolf

-- 
Honorary Research Fellow
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Apr 30 03:54:47 2019
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 29 Apr 2019 21:54:47 -0400
Subject: [R] Message produced under R 3.6.0.
In-Reply-To: <b2c45ecb-f8e5-8689-5c02-59c0c8058f96@auckland.ac.nz>
References: <0b18650a-9eb2-b04c-c651-27b39c0badf9@auckland.ac.nz>
 <CAGxFJbSvCCgELZexXwzYzGPA5cOQaAQ2i33xr8A0ONx3JPjFLg@mail.gmail.com>
 <8afaeace-bacc-87c8-c6a4-1614d19deb42@auckland.ac.nz>
 <6D8006BC-35BE-48F1-A728-E092362885AB@dcn.davis.ca.us>
 <0171b07b-b5d6-3c98-3c17-621f4bfb7ce6@auckland.ac.nz>
 <61263845-e867-714c-d910-c6064da23e2d@gmail.com>
 <cec765a8-1e0a-1481-611f-59033f05c8d1@gmail.com>
 <b2c45ecb-f8e5-8689-5c02-59c0c8058f96@auckland.ac.nz>
Message-ID: <74270f3a-8b67-8e62-6a4d-16126d6936d7@gmail.com>

On 29/04/2019 9:44 p.m., Rolf Turner wrote:
> 
> On 30/04/19 1:31 PM, Duncan Murdoch wrote:
> 
>> On 29/04/2019 9:25 p.m., Duncan Murdoch wrote:
>>> On 29/04/2019 8:43 p.m., Rolf Turner wrote:
>>>>
>>>> On 30/04/19 12:19 PM, Jeff Newmiller wrote:
>>>>
>>>>> Since you now have this indirect dependency, you should make sure you
>>>>> have updated this gaggle of packages. I have found that the
>>>>> dependencies do not necessarily update when I update the package that
>>>>> relies on them. It can take a few passes? of reading error/warming
>>>>> messages to get them all updated. I suspect you have old versions of
>>>>> packages that now delegate certain functions to lower-level packages,
>>>>> and these errors should go away when you have them all current.
>>>>
>>>> Nope.? Doesn't work.? I reinstalled brms and the messages still appeared
>>>> when I loaded brms.
>>>
>>> Those messages probably aren't due to brms directly: for example, the
>>> first set
>>>
>>>  ? > Registered S3 methods overwritten by 'ggplot2':
>>>  ? >?? method???????? from
>>>  ? >?? [.quosures???? rlang
>>>  ? >?? c.quosures???? rlang
>>>  ? >?? print.quosures rlang
>>>
>>> is due to issues with ggplot2 or rlang.? Have you tried updating both of
>>> those?
>>
>> To answer my own question:? this one still appears after updating those
>> two, but it appears to be a bug in ggplot2, because that package
>> replaces those functions in a file compat-quosures.R with comment
>>
>> # TODO: Remove once rlang 0.2.0.9001 or later is on CRAN
>>
>> and the rlang version on CRAN is now 0.3.4.
>>
>> Duncan Murdoch
> 
> Thanks Duncan.  So I guess I should just wait until Hadley gets around
> to fixing ggplot2?

I think so.

> 
> OTOH --- I would, on general principles, like to learn how to suppress
> such messages ....

I'm not sure you (as package author) can, but your users can do it via

  suppressMessages(library(brms))

(or presumably the same wrapper when attaching your package, or some 
other package that loads ggplot2 or xts).  It appears that dplyr has 
already been fixed.

Duncan Murdoch


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Apr 30 11:31:51 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 30 Apr 2019 11:31:51 +0200
Subject: [R] Message produced under R 3.6.0.
In-Reply-To: <74270f3a-8b67-8e62-6a4d-16126d6936d7@gmail.com>
References: <0b18650a-9eb2-b04c-c651-27b39c0badf9@auckland.ac.nz>
 <CAGxFJbSvCCgELZexXwzYzGPA5cOQaAQ2i33xr8A0ONx3JPjFLg@mail.gmail.com>
 <8afaeace-bacc-87c8-c6a4-1614d19deb42@auckland.ac.nz>
 <6D8006BC-35BE-48F1-A728-E092362885AB@dcn.davis.ca.us>
 <0171b07b-b5d6-3c98-3c17-621f4bfb7ce6@auckland.ac.nz>
 <61263845-e867-714c-d910-c6064da23e2d@gmail.com>
 <cec765a8-1e0a-1481-611f-59033f05c8d1@gmail.com>
 <b2c45ecb-f8e5-8689-5c02-59c0c8058f96@auckland.ac.nz>
 <74270f3a-8b67-8e62-6a4d-16126d6936d7@gmail.com>
Message-ID: <23752.5639.386457.597898@stat.math.ethz.ch>

>>>>> Duncan Murdoch 
>>>>>     on Mon, 29 Apr 2019 21:54:47 -0400 writes:

    > On 29/04/2019 9:44 p.m., Rolf Turner wrote:
    >> 
    >> On 30/04/19 1:31 PM, Duncan Murdoch wrote:
    >> 
    >>> On 29/04/2019 9:25 p.m., Duncan Murdoch wrote:
    >>>> On 29/04/2019 8:43 p.m., Rolf Turner wrote:
    >>>>> 
    >>>>> On 30/04/19 12:19 PM, Jeff Newmiller wrote:
    >>>>> 
>>>>> Since you now have this indirect dependency, you should make sure you
>>>>> have updated this gaggle of packages. I have found that the
>>>>> dependencies do not necessarily update when I update the package that
>>>>> relies on them. It can take a few passes? of reading error/warming
>>>>> messages to get them all updated. I suspect you have old versions of
>>>>> packages that now delegate certain functions to lower-level packages,
>>>>> and these errors should go away when you have them all current.
    >>>>> 
    >>>>> Nope.? Doesn't work.? I reinstalled brms and the messages still appeared
    >>>>> when I loaded brms.
    >>>> 
    >>>> Those messages probably aren't due to brms directly: for example, the
    >>>> first set
    >>>> 
    >>>> ? > Registered S3 methods overwritten by 'ggplot2':
    >>>> ? >?? method???????? from
    >>>> ? >?? [.quosures???? rlang
    >>>> ? >?? c.quosures???? rlang
    >>>> ? >?? print.quosures rlang
    >>>> 
    >>>> is due to issues with ggplot2 or rlang.? Have you tried updating both of
    >>>> those?
    >>> 
    >>> To answer my own question:? this one still appears after updating those
    >>> two, but it appears to be a bug in ggplot2, because that package
    >>> replaces those functions in a file compat-quosures.R with comment
    >>> 
    >>> # TODO: Remove once rlang 0.2.0.9001 or later is on CRAN
    >>> 
    >>> and the rlang version on CRAN is now 0.3.4.
    >>> 
    >>> Duncan Murdoch
    >> 
    >> Thanks Duncan.  So I guess I should just wait until Hadley gets around
    >> to fixing ggplot2?

    > I think so.

    >> 
    >> OTOH --- I would, on general principles, like to learn how to suppress
    >> such messages ....

    > I'm not sure you (as package author) can, but your users can do it via

    > suppressMessages(library(brms))

    > (or presumably the same wrapper when attaching your package, or some 
    > other package that loads ggplot2 or xts).  It appears that dplyr has 
    > already been fixed.

    > Duncan Murdoch

After all, I think the new messages have shown their worth here:

They were only "uttered" because of bugs
(.. and maybe the bugs have only be fixed so quickly because of
 these messages appearing?)

I don't think you (or others) should suppress such messages by
default.  They do indicate someone should do something, even if
it's not you.

Somewhat related, note that the NEWS for 3.6.0 also contain [not prominently
  enough maybe: this is a quite nice set of features which
  notably package maintainers can / should start making use of !] :

    ? library() and require() now allow more control over handling
      search path conflicts when packages are attached. The policy is
      controlled by the new conflicts.policy option.

Martin


From morg@n@em@||box @end|ng |rom gm@||@com  Mon Apr 29 22:42:36 2019
From: morg@n@em@||box @end|ng |rom gm@||@com (Morgan Morgan)
Date: Mon, 29 Apr 2019 21:42:36 +0100
Subject: [R] Bug in R 3.6.0?
Message-ID: <CAL0QV_Mi0sr8yRz83+P_6vSV1oWn35Z5e1=OR++6TraRjc2mtQ@mail.gmail.com>

Hi,

I am using the R 3.6.0 on windows. The issue that I report below does not
exist with previous version of R.
In order to reproduce the error you must install a package of your choice
from source (tar.gz).

-Create a .Rprofile file with the following command in it : setwd("D:/")
-Close your R session and re-open it. Your working directory must be now set
to D:
-Install a package of your choice from source, example :
install.packages("data.table",type="source")

In my case the package fail to install and I get the following error
message:

** R
** inst
** byte-compile and prepare package for lazy loading
Error in tools:::.read_description(file) :
  file 'DESCRIPTION' does not exist
Calls: suppressPackageStartupMessages ... withCallingHandlers ->
.getRequiredPackages -> <Anonymous> -> <Anonymous>
Execution halted
ERROR: lazy loading failed for package 'data.table'
* removing 'C:/Users/Morgan/Documents/R/win-library/3.6/data.table'
* restoring previous
'C:/Users/Morgan/Documents/R/win-library/3.6/data.table'
Warning in install.packages :
  installation of package ?data.table? had non-zero exit status

Now remove the .Rprofile file, restart your R session and try to install the
package with the same command.
In that case everything should be installed just fine.

FYI the issue happens on macOS as well and I suspect it also does on all
linux systems.

My question: Is this expected or is it a bug?

Thank you
Best regards,
Morgan

	[[alternative HTML version deleted]]


From ocjt m@iii@g oii iree@ir  Tue Apr 30 16:15:46 2019
From: ocjt m@iii@g oii iree@ir (ocjt m@iii@g oii iree@ir)
Date: Tue, 30 Apr 2019 16:15:46 +0200
Subject: [R] Bug in R 3.6.0?
In-Reply-To: <CAL0QV_Mi0sr8yRz83+P_6vSV1oWn35Z5e1=OR++6TraRjc2mtQ@mail.gmail.com>
References: <CAL0QV_Mi0sr8yRz83+P_6vSV1oWn35Z5e1=OR++6TraRjc2mtQ@mail.gmail.com>
Message-ID: <002d01d4ff5f$34816be0$9d8443a0$@free.fr>

Hello,

I have exactly the same problem when I install one of my own packages:

Error in tools:::.read_description(file) :
  file 'DESCRIPTION' does not exist
Calls: suppressPackageStartupMessages ... withCallingHandlers -> .getRequiredPackages -> <Anonymous> -> <Anonymous>
Ex?cution arr?t?e
ERROR: lazy loading failed for package 'RRegArch'

Best,
Ollivier


-----Message d'origine-----
De : R-help <r-help-bounces at r-project.org> De la part de Morgan Morgan
Envoy? : lundi 29 avril 2019 22:43
? : r-help at r-project.org
Objet : [R] Bug in R 3.6.0?

Hi,

I am using the R 3.6.0 on windows. The issue that I report below does not exist with previous version of R.
In order to reproduce the error you must install a package of your choice from source (tar.gz).

-Create a .Rprofile file with the following command in it : setwd("D:/") -Close your R session and re-open it. Your working directory must be now set to D:
-Install a package of your choice from source, example :
install.packages("data.table",type="source")

In my case the package fail to install and I get the following error
message:

** R
** inst
** byte-compile and prepare package for lazy loading Error in tools:::.read_description(file) :
  file 'DESCRIPTION' does not exist
Calls: suppressPackageStartupMessages ... withCallingHandlers -> .getRequiredPackages -> <Anonymous> -> <Anonymous> Execution halted
ERROR: lazy loading failed for package 'data.table'
* removing 'C:/Users/Morgan/Documents/R/win-library/3.6/data.table'
* restoring previous
'C:/Users/Morgan/Documents/R/win-library/3.6/data.table'
Warning in install.packages :
  installation of package ?data.table? had non-zero exit status

Now remove the .Rprofile file, restart your R session and try to install the package with the same command.
In that case everything should be installed just fine.

FYI the issue happens on macOS as well and I suspect it also does on all linux systems.

My question: Is this expected or is it a bug?

Thank you
Best regards,
Morgan

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Tue Apr 30 16:54:10 2019
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Tue, 30 Apr 2019 16:54:10 +0200
Subject: [R] Bug in R 3.6.0?
In-Reply-To: <CAL0QV_Mi0sr8yRz83+P_6vSV1oWn35Z5e1=OR++6TraRjc2mtQ@mail.gmail.com>
References: <CAL0QV_Mi0sr8yRz83+P_6vSV1oWn35Z5e1=OR++6TraRjc2mtQ@mail.gmail.com>
Message-ID: <23752.24978.45927.96764@stat.math.ethz.ch>

>>>>> Morgan Morgan 
>>>>>     on Mon, 29 Apr 2019 21:42:36 +0100 writes:

    > Hi,
    > I am using the R 3.6.0 on windows. The issue that I report below does not
    > exist with previous version of R.
    > In order to reproduce the error you must install a package of your choice
    > from source (tar.gz).

    > -Create a .Rprofile file with the following command in it : setwd("D:/")
    > -Close your R session and re-open it. Your working directory must be now set
    > to D:
    > -Install a package of your choice from source, example :
    > install.packages("data.table",type="source")

    > In my case the package fail to install and I get the following error
    > message:

    > ** R
    > ** inst
    > ** byte-compile and prepare package for lazy loading
    > Error in tools:::.read_description(file) :
    > file 'DESCRIPTION' does not exist
    > Calls: suppressPackageStartupMessages ... withCallingHandlers ->
    > .getRequiredPackages -> <Anonymous> -> <Anonymous>
    > Execution halted
    > ERROR: lazy loading failed for package 'data.table'
    > * removing 'C:/Users/Morgan/Documents/R/win-library/3.6/data.table'
    > * restoring previous
    > 'C:/Users/Morgan/Documents/R/win-library/3.6/data.table'
    > Warning in install.packages :
    > installation of package ?data.table? had non-zero exit status

    > Now remove the .Rprofile file, restart your R session and try to install th
e
    > package with the same command.
    > In that case everything should be installed just fine.

    > FYI the issue happens on macOS as well and I suspect it also does on all
    > linux systems.

    > My question: Is this expected or is it a bug?

It is a bug, thank you very much for reporting it.

I've been told privately by ?mer An (thank you!) who's been
affected as well, that this problem seems to affect others, and
that there's a thread about this over at the Rstudio support site

https://support.rstudio.com/hc/en-us/community/posts/200704708-Build-tool-does-not-recognize-DESCRIPTION-file

There, users mention that (all?) packages are affected which
have a multiline 'Description:' field in their DESCRIPTION file.
Of course, many if not most packages have this property.

Indeed, I can reproduce the problem (e.g. with my 'sfsmisc'
package) if I ("silly enough to") add a setwd() call to my
Rprofile file  (the one I set via env.var  R_PROFILE or R_PROFILE_USER). 

This is clearly a bug, and indeed a bad one.

It seems all R core (and other R expert users who have tried R
3.6.0 alpha, beta, and RC versions) have *not* seen the bug as they
are intuitively smart not to mess with R's working directory in
a global R profile file ...

For now you definitively have to work around by not doing what's
the problem : do *NOT* setwd() in your  ~/.Rprofile or other
such R init files.

Best,
Martin Maechler
ETH Zurich and  R Core Team


From c@t@r|n@@g @end|ng |rom gm@||@com  Tue Apr 30 16:57:43 2019
From: c@t@r|n@@g @end|ng |rom gm@||@com (=?UTF-8?Q?Catarina_Serra_Gon=C3=A7alves?=)
Date: Wed, 1 May 2019 00:57:43 +1000
Subject: [R] Time series (trend over time) for irregular sampling dates and
 multiple sites
Message-ID: <CAOQWJbvY+JKy80sksmfC8tu-C+5qq-tzwAd21XbyGvJAyYjQPQ@mail.gmail.com>

I have a dataset of marine debris items (number of items standardized per
effort: Items/(number of volunteers*Hours*Lenght)) taken from 2 main
locations (WA and Queensland) in Australia (8 Sub Sites in total: 4 in WA
and 4 in Queensland) at irregular sampling intervals over a period 15 years.

I want to test if there is a change over the years on the amount of debris
in these locations and more specifically a change after the implementation
of a mitigation strategy (in 2013).
Here?s the head of the data:[image: enter image description here]
<https://i.stack.imgur.com/VNIpb.png>Description of each one of the
varables in the dataframe:

*eventid *= each sampling (clean-up) event Location = Queensland and New
South Wales Sites = all the 9 sampling beaches

*Date *= specific dates for the clean-up events (day-month-year)

*Date1 *= specific dates for the clean-up events (day-month-year) on the
POSICXT format Year= Year of sampling event (2004 to 2018)

*Month*= Month of the sampling event (jan to dec)

*nMonth*= a number was determined to the respective month of the sampling
event (1 to 12)

*Day*= Day of sampling (1 to 31) Days = Days since the first date of clean
up = just another way of using the dates

*MARPOL *= before and after implementation (factor with 2 levels)

*DaysC *= days between sampling events for the same sites = number of days
since the previous clean-up event

*DaysI *= Days since intervention, all the dates before implementation are
zero, and after we count the number of days since the implementation date
(1 jan 2013)

*DaysIa*= same as DayI but instead of zero for before the intervention we
have negative values (days)

*Items *= number of fishing and shipping items counted in each clean-up
event

*Hours *= hours spent by all volunteers together at each clean up event

*Lenght *= Lenght of beach sampled by all volunteers together at each clean
up event volunteers = all volunteers at each clean up event

*HoursVolunteer *= hours spent bt each volunteer at each clean up event
(Hours/volunteers)

*Ieffort *= the items standarized by the effort (hours, volunteers and
lenght)

*GrossWeight & **GrossTotal are not relevant *
------------------------------
Problems:

My data has a few problems: (1) I think I will need to fix the effects of
seasonal variation (Monthly) and (2) of possible spatial correlation
(probability of finding an item is higher after finding one since they can
come from the same ship). (3) How do I handle the fact that the
measurements were not taken at a regular interval?

I was trying to use GAMs to analyse the data and see the trends over time.
The model I came across is the following:

m4<- gamm(Ieffort ~ s(DaysIa)+MARPOL+ s(nMonth, bs = "ps", k = 12),
random=list(Site=~1,Location=~1),data = d)

*thank you in advance.*
-
*Catarina Serra Gon?alves *
PhD candidate

Adrift Lab  <https://adriftlab.org>
University of Tasmania <http://www.utas.edu.au/> | Institute for Marine and
Antarctic Studies  <http://www.imas.utas.edu.au/>
Launceston, TAS | Australia

Personal website <https://catarinasg.wixsite.com/acserra>
<https://catarinasg.wixsite.com/acserra>| E-mail  <acserra at utas.edu.au> |
Twitter <https://twitter.com/CatarinaSerraG>
Research Gate
<https://www.researchgate.net/profile/Catarina_Serra_Goncalves> | Google
Scholar <https://scholar.google.pt/citations?user=8nBrRFwAAAAJ&hl=en>

	[[alternative HTML version deleted]]


From mure|th|h@dd|@on @end|ng |rom gm@||@com  Mon Apr 29 20:38:00 2019
From: mure|th|h@dd|@on @end|ng |rom gm@||@com (Haddison Mureithi)
Date: Mon, 29 Apr 2019 21:38:00 +0300
Subject: [R] (no subject)
Message-ID: <CABVwvn6y_M2M1o41HryKYp=LQcbsajdtginyw_RPVf81o4BmqQ@mail.gmail.com>

Hello guys this problem was never answered and I happened to come across
the same problem , kindly help. This is a simple R program that I have been
trying to run. I keep running into the "singular matrix" error. I end up
with no sensible results. Can anyone suggest any changes or a way around
this?

I am a total rookie when working with R.

Thanks,
Rasika

> library(survival)
Loading required package: splines
> args(coxph)
function (formula, data, weights, subset, na.action, init, control,
    method = c("efron", "breslow", "exact"), singular.ok = TRUE,
    robust = FALSE, model = FALSE, x = FALSE, y = TRUE, tt, ...)
NULL
> test1<-read.table("S:/FISHDO/03_Phase_I_Field_Work/Data_6_28_2011/Working
Folder/R_files/4SondesJuly24.csv", header=T, sep=",")
> sondes<-coxph(Surv(Start, Stop, Depart)~DOLoomis + DOI55 + DODamen,
data=test1)
Warning messages:
1: In fitter(X, Y, strats, offset, init, control, weights = weights,  :
  Loglik converged before variable  1,2 ; beta may be infinite.
2: In coxph(Surv(Start, Stop, Depart) ~ DOLoomis + DOI55 + DODamen,  :
  X matrix deemed to be singular; variable 3
> summary(sondes)
Call:
coxph(formula = Surv(Start, Stop, Depart) ~ DOLoomis + DOI55 +
    DODamen, data = test1)

  n= 1737, number of events= 58
   (1 observation deleted due to missingness)

               coef  exp(coef)   se(coef)  z Pr(>|z|)
DOLoomis -2.152e+00  1.163e-01  1.161e+05  0        1
DOI55     4.560e-01  1.578e+00  3.755e+04  0        1
DODamen          NA         NA  0.000e+00 NA       NA

         exp(coef) exp(-coef) lower .95 upper .95
DOLoomis    0.1163     8.5995         0       Inf
DOI55       1.5777     0.6338         0       Inf
DODamen         NA         NA        NA        NA

Concordance= 0.5  (se = 0 )
Rsquare= 0   (max possible= 0.01 )
Likelihood ratio test= 0  on 2 df,   p=1
Wald test            = 0  on 2 df,   p=1
Score (logrank) test = 0  on 2 df,   p=1

	[[alternative HTML version deleted]]


From jen@@heum@nn @end|ng |rom @tudent@@un|be@ch  Tue Apr 30 17:24:33 2019
From: jen@@heum@nn @end|ng |rom @tudent@@un|be@ch (Jens Heumann)
Date: Tue, 30 Apr 2019 17:24:33 +0200
Subject: [R] Passing formula as parameter to `lm` within `sapply` causes
 error [BUG?]
Message-ID: <75abba2b-c528-460e-df92-08f8479ba399@students.unibe.ch>

Hi,

`lm` won't take formula as a parameter when it is within a `sapply`; see 
example below. Please, could anyone either point me to a syntax error or 
confirm that this might be a bug?

Best,
Jens

[Disclaimer: This is my first post here, following advice of how to 
proceed with possible bugs from here: https://www.r-project.org/bugs.html]


SUMMARY

While `lm` alone accepts formula parameter `FO` well, the same within a 
`sapply` causes an error. When putting everything as parameter but 
formula `FO`, it's still working, though. All parameters work fine 
within a similar `for` loop.


MCVE (see data / R-version at bottom)

 > summary(lm(y ~ x, df1, df1[["z"]] == 1, df1[["w"]]))$coef[1, ]
   Estimate Std. Error    t value   Pr(>|t|)
  1.6269038  0.9042738  1.7991275  0.3229600
 > summary(lm(FO, data, data[[st]] == st1, data[[ws]]))$coef[1, ]
   Estimate Std. Error    t value   Pr(>|t|)
  1.6269038  0.9042738  1.7991275  0.3229600
 > sapply(unique(df1$z), function(s)
+   summary(lm(y ~ x, df1, df1[["z"]] == s, df1[[ws]]))$coef[1, ])
                 [,1]       [,2]         [,3]
Estimate   1.6269038 -0.1404174 -0.010338774
Std. Error 0.9042738  0.4577001  1.858138516
t value    1.7991275 -0.3067890 -0.005564049
Pr(>|t|)   0.3229600  0.8104951  0.996457853
 > sapply(unique(data[[st]]), function(s)
+   summary(lm(FO, data, data[[st]] == s, data[[ws]]))$coef[1, ])  # !!!
Error in eval(substitute(subset), data, env) : object 's' not found
 > sapply(unique(data[[st]]), function(s)
+   summary(lm(y ~ x, data, data[[st]] == s, data[[ws]]))$coef[1, ])
                 [,1]       [,2]         [,3]
Estimate   1.6269038 -0.1404174 -0.010338774
Std. Error 0.9042738  0.4577001  1.858138516
t value    1.7991275 -0.3067890 -0.005564049
Pr(>|t|)   0.3229600  0.8104951  0.996457853
 > m <- matrix(NA, 4, length(unique(data[[st]])))
 > for (s in unique(data[[st]])) {
+   m[, s] <- summary(lm(FO, data, data[[st]] == s, data[[ws]]))$coef[1, ]
+ }
 > m
           [,1]       [,2]         [,3]
[1,] 1.6269038 -0.1404174 -0.010338774
[2,] 0.9042738  0.4577001  1.858138516
[3,] 1.7991275 -0.3067890 -0.005564049
[4,] 0.3229600  0.8104951  0.996457853

# DATA #################################################################

df1 <- structure(list(x = c(1.37095844714667, -0.564698171396089, 
0.363128411337339,
0.63286260496104, 0.404268323140999, -0.106124516091484, 1.51152199743894,
-0.0946590384130976, 2.01842371387704), y = c(1.30824434809425,
0.740171482827397, 2.64977380403845, -0.755998096151299, 0.125479556323628,
-0.239445852485142, 2.14747239550901, -0.37891195982917, -0.638031707027734
), z = c(1L, 1L, 1L, 2L, 2L, 2L, 3L, 3L, 3L), w = c(0.7, 0.8,
1.2, 0.9, 1.3, 1.2, 0.8, 1, 1)), class = "data.frame", row.names = c(NA,
-9L))

FO <- y ~ x; data <- df1; st <- "z"; ws <- "w"; st1 <- 1

########################################################################

 > R.version
                _
platform       x86_64-w64-mingw32
arch           x86_64
os             mingw32
system         x86_64, mingw32
status
major          3
minor          6.0
year           2019
month          04
day            26
svn rev        76424
language       R
version.string R version 3.6.0 (2019-04-26)
nickname       Planting of a Tree

#########################################################################

NOTE: Question on SO two days ago 
(https://stackoverflow.com/questions/55893189/passing-formula-as-parameter-to-lm-within-sapply-causes-error-bug-confirmation) 
brought many views but neither answer nor bug confirmation.


From bgunter@4567 @end|ng |rom gm@||@com  Tue Apr 30 17:28:37 2019
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 30 Apr 2019 08:28:37 -0700
Subject: [R] 
 Time series (trend over time) for irregular sampling dates and
 multiple sites
In-Reply-To: <CAOQWJbvY+JKy80sksmfC8tu-C+5qq-tzwAd21XbyGvJAyYjQPQ@mail.gmail.com>
References: <CAOQWJbvY+JKy80sksmfC8tu-C+5qq-tzwAd21XbyGvJAyYjQPQ@mail.gmail.com>
Message-ID: <CAGxFJbT2YSB1xcs0MajpeqtHbbn4T1ycYoSOBEFvMucFme1t=g@mail.gmail.com>

I have 0 expertise, but I suggest that you check out the SPatioTemporal
taskview on CRAN (or possibly others, like environmetrics). You might also
want to move this to the R-Sig-geo list,where you probably are more likely
to find relevant expertise.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Apr 30, 2019 at 8:13 AM Catarina Serra Gon?alves <
catarinasg at gmail.com> wrote:

> I have a dataset of marine debris items (number of items standardized per
> effort: Items/(number of volunteers*Hours*Lenght)) taken from 2 main
> locations (WA and Queensland) in Australia (8 Sub Sites in total: 4 in WA
> and 4 in Queensland) at irregular sampling intervals over a period 15
> years.
>
> I want to test if there is a change over the years on the amount of debris
> in these locations and more specifically a change after the implementation
> of a mitigation strategy (in 2013).
> Here?s the head of the data:[image: enter image description here]
> <https://i.stack.imgur.com/VNIpb.png>Description of each one of the
> varables in the dataframe:
>
> *eventid *= each sampling (clean-up) event Location = Queensland and New
> South Wales Sites = all the 9 sampling beaches
>
> *Date *= specific dates for the clean-up events (day-month-year)
>
> *Date1 *= specific dates for the clean-up events (day-month-year) on the
> POSICXT format Year= Year of sampling event (2004 to 2018)
>
> *Month*= Month of the sampling event (jan to dec)
>
> *nMonth*= a number was determined to the respective month of the sampling
> event (1 to 12)
>
> *Day*= Day of sampling (1 to 31) Days = Days since the first date of clean
> up = just another way of using the dates
>
> *MARPOL *= before and after implementation (factor with 2 levels)
>
> *DaysC *= days between sampling events for the same sites = number of days
> since the previous clean-up event
>
> *DaysI *= Days since intervention, all the dates before implementation are
> zero, and after we count the number of days since the implementation date
> (1 jan 2013)
>
> *DaysIa*= same as DayI but instead of zero for before the intervention we
> have negative values (days)
>
> *Items *= number of fishing and shipping items counted in each clean-up
> event
>
> *Hours *= hours spent by all volunteers together at each clean up event
>
> *Lenght *= Lenght of beach sampled by all volunteers together at each clean
> up event volunteers = all volunteers at each clean up event
>
> *HoursVolunteer *= hours spent bt each volunteer at each clean up event
> (Hours/volunteers)
>
> *Ieffort *= the items standarized by the effort (hours, volunteers and
> lenght)
>
> *GrossWeight & **GrossTotal are not relevant *
> ------------------------------
> Problems:
>
> My data has a few problems: (1) I think I will need to fix the effects of
> seasonal variation (Monthly) and (2) of possible spatial correlation
> (probability of finding an item is higher after finding one since they can
> come from the same ship). (3) How do I handle the fact that the
> measurements were not taken at a regular interval?
>
> I was trying to use GAMs to analyse the data and see the trends over time.
> The model I came across is the following:
>
> m4<- gamm(Ieffort ~ s(DaysIa)+MARPOL+ s(nMonth, bs = "ps", k = 12),
> random=list(Site=~1,Location=~1),data = d)
>
> *thank you in advance.*
> -
> *Catarina Serra Gon?alves *
> PhD candidate
>
> Adrift Lab  <https://adriftlab.org>
> University of Tasmania <http://www.utas.edu.au/> | Institute for Marine
> and
> Antarctic Studies  <http://www.imas.utas.edu.au/>
> Launceston, TAS | Australia
>
> Personal website <https://catarinasg.wixsite.com/acserra>
> <https://catarinasg.wixsite.com/acserra>| E-mail  <acserra at utas.edu.au> |
> Twitter <https://twitter.com/CatarinaSerraG>
> Research Gate
> <https://www.researchgate.net/profile/Catarina_Serra_Goncalves> | Google
> Scholar <https://scholar.google.pt/citations?user=8nBrRFwAAAAJ&hl=en>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From B|||@Po||ng @end|ng |rom ze||@@com  Tue Apr 30 18:50:48 2019
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Tue, 30 Apr 2019 16:50:48 +0000
Subject: [R] Help with loop for column means into new column by a subset
 Factor w/131 levels
Message-ID: <BN7PR02MB50737455E93F882B58EAA4F4EA3A0@BN7PR02MB5073.namprd02.prod.outlook.com>

Good afternoon.

#RStudio Version 1.1.456
sessionInfo()
#R version 3.5.3 (2019-03-11)
#Platform: x86_64-w64-mingw32/x64 (64-bit)
#Running under: Windows >= 8 x64 (build 9200)



#I have a DF of 8 columns and 14025 rows

str(hcd2tmp2)

# 'data.frame':14025 obs. of  8 variables:
# $ Submitted_Charge: num  21021 15360 40561 29495 7904 ...
# $ Allowed_Amt     : num  18393 6254 40561 29495 7904 ...
# $ Submitted_Units : num  60 240 420 45 120 215 215 15 57 2 ...
# $ Procedure_Code1 : Factor w/ 131 levels "A9606","J0129",..: 43 113 117 125 24 85 85 90 86 25 ...
# $ AllowByLimit    : num  4.268 0.949 7.913 6.124 3.524 ...
# $ UnitsByDose     : num  600 240 420 450 120 215 215 750 570 500 ...
# $ LimitByUnits    : num  4310 6591 5126 4816 2243 ...
# $ HCPCSCodeDose1  : num  10 1 1 10 1 1 1 50 10 250 ...

#I would like to create four additional columns that are the mean of four current columns in the DF.
#Current columns
#Allowed_Amt
#LimitByUnits
#AllowByLimit
#UnitsByDose

#The goal is to be able to identify rows where (for instance) Allowed_Amt is greater than the average (aka outliers).

#The trick Is I want the means of those columns based on a Factor value
#The Factor is:
#Procedure_Code1 : Factor w/ 131 levels "A9606","J0129"

#So each of my four new columns will have 131 distinct values based on the mean for the specific Procedure_Code1 grouping

#In SQL it would look something like this:

#SELECT *,
# NewCol1 = mean(Allowed_Amt) OVER (PARTITION BY Procedure_Code1),
# NewCol2 = mean(LimitByUnits) OVER (PARTITION BY Procedure_Code1),
# NewCol3 = mean(AllowByLimit) OVER (PARTITION BY Procedure_Code1),
# NewCol4 = mean(UnitsByDose) OVER (PARTITION BY Procedure_Code1)
#INTO NewTable
#FROM Oldtable

#Here are some sample data

head(hcd2tmp2, n=40)
#      Submitted_Charge Allowed_Amt Submitted_Units Procedure_Code1 AllowByLimit UnitsByDose LimitByUnits HCPCSCodeDose1
# 1          21020.70    18393.12              60           J1745    4.2679810         600      4309.56             10
# 2          15360.00     6254.40             240           J9299    0.9488785         240      6591.36              1
# 3          40561.32    40561.32             420           J9306    7.9133539         420      5125.68              1
# 4          29495.25    29495.25              45           J9355    6.1244417         450      4815.99             10
# 5           7904.30     7904.30             120           J0897    3.5243000         120      2242.80              1
# 6          15331.95    10614.31             215           J9034    2.0586686         215      5155.91              1
# 7          15331.95    10614.31             215           J9034    2.0586686         215      5155.91              1
# 8            461.90        0.00              15           J9045    0.0000000         750        46.38             50
# 9          27340.96    15092.21              57           J9035    3.2600227         570      4629.48             10
# 10           768.00      576.00               2           J1190    1.3617343         500       422.99            250
# 11           101.00       38.38               5           J2250   59.9687500           5         0.64              1
# 12         17458.40        0.00             200           J9033    0.0000000         200      5990.00              1
# 13          7885.10     7569.70               1           J1745  105.3835445          10        71.83             10
# 14          2015.00     1155.78               4           J2785    5.0051100           0       230.92              0
# 15           443.72      443.72              12           J9045   11.9601078         600        37.10             50
# 16        113750.00   113750.00             600           J2350    3.3025003         600     34443.60              1
# 17          3582.85     3582.85              10           J2469   30.5573561         250       117.25             25
# 18          5152.65     5152.65              50           J2796    1.4362988         500      3587.45             10
# 19          5152.65     5152.65              50           J2796    1.4362988         500      3587.45             10
# 20         39664.09        0.00              74           J9355    0.0000000         740      7919.63             10
# 21           166.71      102.53               9           J9045    3.6841538         450        27.83             50
# 22         13823.61     9676.53               1           J2505    2.0785247           6      4655.48              6
# 23         90954.00    26436.53             360           J1786    1.7443775        3600     15155.28             10
# 24          4800.00     3494.40             800           J3262    0.8861838         800      3943.20              1
# 25           216.00      105.84               4           J0696   42.3360000        1000         2.50            250
# 26          5300.00     4770.00               1           J0178    4.9677151           1       960.20              1
# 27         35203.00    35203.00             200           J9271    3.5772498         200      9840.80              1
# 28         17589.15    17589.15             300           J3380    2.9696855         300      5922.90              1
# 29         18394.64    17842.79               1           J9355  166.7238834          10       107.02             10
# 30           770.00      731.50              10           J2469    6.2388060         250       117.25             25
# 31           461.90        0.00              15           J9045    0.0000000         750        46.38             50
# 32          8160.00     3342.40              80           J1459    1.0260818       40000      3257.44            500
# 33          1653.48      314.16               6           J9305    0.7661505          60       410.05             10
# 34         13036.50        0.00             194           J9034    0.0000000         194      4652.31              1
# 35         10486.87        0.00             156           J9034    0.0000000         156      3741.04              1
# 36         15360.00     6254.40             240           J9299    0.9488785         240      6591.36              1
# 37          1616.83     1616.83             150           J1453    5.2528590         150       307.80              1
# 38         80685.74    34772.43              96           J9035    4.4597077         960      7797.02             10
# 39         85220.58    35925.13             287           J9299    4.5577715         287      7882.17              1
# 40          3860.17     1627.27              13           J9299    4.5577963          13       357.03              1


#I hope this is enough inforamtion to warrant your support
#Thank you
#WHP



Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}


From B|||@Po||ng @end|ng |rom ze||@@com  Tue Apr 30 20:45:40 2019
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Tue, 30 Apr 2019 18:45:40 +0000
Subject: [R] Help with loop for column means into new column by a subset
 Factor w/131 levels
In-Reply-To: <BN7PR02MB50737455E93F882B58EAA4F4EA3A0@BN7PR02MB5073.namprd02.prod.outlook.com>
References: <BN7PR02MB50737455E93F882B58EAA4F4EA3A0@BN7PR02MB5073.namprd02.prod.outlook.com>
Message-ID: <BN7PR02MB5073D732498AB265872F5750EA3A0@BN7PR02MB5073.namprd02.prod.outlook.com>

I ran this routine but I was thinking there must be a more elegant way of doing this.


#https://community.rstudio.com/t/how-to-average-mean-variables-in-r-based-on-the-level-of-another-variable-and-save-this-as-a-new-variable/8764/8

hcd2tmp2_summmary <- hcd2tmp2 %>%
  select(.) %>%
  group_by(Procedure_Code1) %>%
  summarize(average = mean(Allowed_Amt))
# A tibble: 131 x 2
# Procedure_Code1 average
# <fct>             <dbl>
# 1 A9606            57785.
# 2 J0129             5420.
# 3 J0178             4700.
# 4 J0180            13392.
# 5 J0202            56328.
# 6 J0256            17366.
# 7 J0257             7563.
# 8 J0485             2450.
# 9 J0490             6398.
# 10 J0585            4492.
# ... with 121 more rows

hcd2tmp2 <- hcd2tmp %>%
  group_by(Procedure_Code1) %>%
  summarise(Avg_Allowed_Amt = mean(Allowed_Amt))

view(hcd2tmp2)


hcd2tmp3 <- hcd2tmp %>%
  group_by(Procedure_Code1) %>%
  summarise(Avg_AllowByLimit = mean(AllowByLimit))

view(hcd2tmp3)


hcd2tmp4 <- hcd2tmp %>%
  group_by(Procedure_Code1) %>%
  summarise(Avg_UnitsByDose = mean(UnitsByDose))

view(hcd2tmp4)

hcd2tmp5 <- hcd2tmp %>%
  group_by(Procedure_Code1) %>%
  summarise(Avg_LimitByUnits = mean(LimitByUnits))

view(hcd2tmp5)

#Joins----


hcd2tmp <- left_join(hcd2tmp2, hcd2tmp, by = c("Procedure_Code1"="Procedure_Code1"))
hcd2tmp <- left_join(hcd2tmp3, hcd2tmp, by = c("Procedure_Code1"="Procedure_Code1"))
hcd2tmp <- left_join(hcd2tmp4, hcd2tmp, by = c("Procedure_Code1"="Procedure_Code1"))
hcd2tmp <- left_join(hcd2tmp5, hcd2tmp, by = c("Procedure_Code1"="Procedure_Code1"))

view(hcd2tmp)

hcd2tmp$Avg_LimitByUnits <- round(hcd2tmp$Avg_LimitByUnits, digits = 2)
hcd2tmp$Avg_Allowed_Amt <- round(hcd2tmp$Avg_Allowed_Amt, digits = 2)
hcd2tmp$Avg_AllowByLimit <- round(hcd2tmp$Avg_AllowByLimit, digits = 2)
hcd2tmp$Avg_UnitsByDose <- round(hcd2tmp$Avg_UnitsByDose, digits = 2)

view(hcd2tmp)

#Over under columns----
hcd2tmp$AllowByLimitFlag <- hcd2tmp$AllowByLimit > hcd2tmp$Avg_AllowByLimit
hcd2tmp$LimitByUnitsFlag <- hcd2tmp$LimitByUnits > hcd2tmp$Avg_LimitByUnits
hcd2tmp$Allowed_AmtFlag  <- hcd2tmp$Allowed_Amt  > hcd2tmp$Avg_Allowed_Amt
hcd2tmp$UnitsByDoseFlag  <- hcd2tmp$UnitsByDose  > hcd2tmp$Avg_UnitsByDose

view(hcd2tmp)


-----Original Message-----
From: Bill Poling
Sent: Tuesday, April 30, 2019 12:51 PM
To: r-help (r-help at r-project.org) <r-help at r-project.org>
Cc: Bill Poling <Bill.Poling at zelis.com>
Subject: Help with loop for column means into new column by a subset Factor w/131 levels

Good afternoon.

#RStudio Version 1.1.456
sessionInfo()
#R version 3.5.3 (2019-03-11)
#Platform: x86_64-w64-mingw32/x64 (64-bit) #Running under: Windows >= 8 x64 (build 9200)



#I have a DF of 8 columns and 14025 rows

str(hcd2tmp2)

# 'data.frame':14025 obs. of  8 variables:
# $ Submitted_Charge: num  21021 15360 40561 29495 7904 ...
# $ Allowed_Amt     : num  18393 6254 40561 29495 7904 ...
# $ Submitted_Units : num  60 240 420 45 120 215 215 15 57 2 ...
# $ Procedure_Code1 : Factor w/ 131 levels "A9606","J0129",..: 43 113 117 125 24 85 85 90 86 25 ...
# $ AllowByLimit    : num  4.268 0.949 7.913 6.124 3.524 ...
# $ UnitsByDose     : num  600 240 420 450 120 215 215 750 570 500 ...
# $ LimitByUnits    : num  4310 6591 5126 4816 2243 ...
# $ HCPCSCodeDose1  : num  10 1 1 10 1 1 1 50 10 250 ...

#I would like to create four additional columns that are the mean of four current columns in the DF.
#Current columns
#Allowed_Amt
#LimitByUnits
#AllowByLimit
#UnitsByDose

#The goal is to be able to identify rows where (for instance) Allowed_Amt is greater than the average (aka outliers).

#The trick Is I want the means of those columns based on a Factor value
#The Factor is:
#Procedure_Code1 : Factor w/ 131 levels "A9606","J0129"

#So each of my four new columns will have 131 distinct values based on the mean for the specific Procedure_Code1 grouping

#In SQL it would look something like this:

#SELECT *,
# NewCol1 = mean(Allowed_Amt) OVER (PARTITION BY Procedure_Code1),
# NewCol2 = mean(LimitByUnits) OVER (PARTITION BY Procedure_Code1),
# NewCol3 = mean(AllowByLimit) OVER (PARTITION BY Procedure_Code1),
# NewCol4 = mean(UnitsByDose) OVER (PARTITION BY Procedure_Code1)
#INTO NewTable
#FROM Oldtable

#Here are some sample data

head(hcd2tmp2, n=40)
#      Submitted_Charge Allowed_Amt Submitted_Units Procedure_Code1 AllowByLimit UnitsByDose LimitByUnits HCPCSCodeDose1
# 1          21020.70    18393.12              60           J1745    4.2679810         600      4309.56             10
# 2          15360.00     6254.40             240           J9299    0.9488785         240      6591.36              1
# 3          40561.32    40561.32             420           J9306    7.9133539         420      5125.68              1
# 4          29495.25    29495.25              45           J9355    6.1244417         450      4815.99             10
# 5           7904.30     7904.30             120           J0897    3.5243000         120      2242.80              1
# 6          15331.95    10614.31             215           J9034    2.0586686         215      5155.91              1
# 7          15331.95    10614.31             215           J9034    2.0586686         215      5155.91              1
# 8            461.90        0.00              15           J9045    0.0000000         750        46.38             50
# 9          27340.96    15092.21              57           J9035    3.2600227         570      4629.48             10
# 10           768.00      576.00               2           J1190    1.3617343         500       422.99            250
# 11           101.00       38.38               5           J2250   59.9687500           5         0.64              1
# 12         17458.40        0.00             200           J9033    0.0000000         200      5990.00              1
# 13          7885.10     7569.70               1           J1745  105.3835445          10        71.83             10
# 14          2015.00     1155.78               4           J2785    5.0051100           0       230.92              0
# 15           443.72      443.72              12           J9045   11.9601078         600        37.10             50
# 16        113750.00   113750.00             600           J2350    3.3025003         600     34443.60              1
# 17          3582.85     3582.85              10           J2469   30.5573561         250       117.25             25
# 18          5152.65     5152.65              50           J2796    1.4362988         500      3587.45             10
# 19          5152.65     5152.65              50           J2796    1.4362988         500      3587.45             10
# 20         39664.09        0.00              74           J9355    0.0000000         740      7919.63             10
# 21           166.71      102.53               9           J9045    3.6841538         450        27.83             50
# 22         13823.61     9676.53               1           J2505    2.0785247           6      4655.48              6
# 23         90954.00    26436.53             360           J1786    1.7443775        3600     15155.28             10
# 24          4800.00     3494.40             800           J3262    0.8861838         800      3943.20              1
# 25           216.00      105.84               4           J0696   42.3360000        1000         2.50            250
# 26          5300.00     4770.00               1           J0178    4.9677151           1       960.20              1
# 27         35203.00    35203.00             200           J9271    3.5772498         200      9840.80              1
# 28         17589.15    17589.15             300           J3380    2.9696855         300      5922.90              1
# 29         18394.64    17842.79               1           J9355  166.7238834          10       107.02             10
# 30           770.00      731.50              10           J2469    6.2388060         250       117.25             25
# 31           461.90        0.00              15           J9045    0.0000000         750        46.38             50
# 32          8160.00     3342.40              80           J1459    1.0260818       40000      3257.44            500
# 33          1653.48      314.16               6           J9305    0.7661505          60       410.05             10
# 34         13036.50        0.00             194           J9034    0.0000000         194      4652.31              1
# 35         10486.87        0.00             156           J9034    0.0000000         156      3741.04              1
# 36         15360.00     6254.40             240           J9299    0.9488785         240      6591.36              1
# 37          1616.83     1616.83             150           J1453    5.2528590         150       307.80              1
# 38         80685.74    34772.43              96           J9035    4.4597077         960      7797.02             10
# 39         85220.58    35925.13             287           J9299    4.5577715         287      7882.17              1
# 40          3860.17     1627.27              13           J9299    4.5577963          13       357.03              1


#I hope this is enough inforamtion to warrant your support
#Thank you
#WHP



Confidentiality Notice This message is sent from Zelis. ...{{dropped:13}}


From mccorm@ck @end|ng |rom mo|b|o@mgh@h@rv@rd@edu  Tue Apr 30 21:24:57 2019
From: mccorm@ck @end|ng |rom mo|b|o@mgh@h@rv@rd@edu (Matthew)
Date: Tue, 30 Apr 2019 15:24:57 -0400
Subject: [R] transpose and split dataframe
Message-ID: <0d6ac524-4291-ab03-6bcb-592b3996cc74@molbio.mgh.harvard.edu>

I have a data frame that is a lot bigger but for simplicity sake we can 
say it looks like this:

Regulator??? hits
AT1G69490??? AT4G31950,AT5G24110,AT1G26380,AT1G05675
AT2G55980??? AT2G85403,AT4G89223

 ?? In other words:

data.frame : 2 obs. of 2 variables
$Regulator: Factor w/ 2 levels
$hits???????? : Factor w/ 6 levels

 ? I want to transpose it so that Regulator is now the column headings 
and each of the AGI numbers now separated by commas is a row. So, 
AT1G69490 is now the header of the first column and AT4G31950 is row 1 
of column 1, AT5G24110 is row 2 of column 1, etc. AT2G55980 is header of 
column 2 and AT2G85403 is row 1 of column 2, etc.

 ? I have tried playing around with strsplit(TF2list[2:2]) and 
strsplit(as.character(TF2list[2:2]), but I am getting nowhere.

Matthew


From dc@r|@on @end|ng |rom t@mu@edu  Tue Apr 30 23:04:50 2019
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Tue, 30 Apr 2019 21:04:50 +0000
Subject: [R] transpose and split dataframe
Message-ID: <db8cede89a724defb691cea72a25b092@tamu.edu>

I neglected to copy this to the list:

I think we need more information. Can you give us the structure of the data with str(YourDataFrame). Alternatively you could copy a small piece into your email message by copying and pasting the results of the following code:

dput(head(YourDataFrame))

The data frame you present could not be a data frame since you say "hits" is a factor with a variable number of elements. If each value of "hits" was a single character string, it would only have 2 factor levels not 6 and your efforts to parse the string would make more sense. Transposing to a data frame would only be possible if each column was padded with NAs to make them equal in length. Since your example tries use the name TF2list, it is possible that you do not have a data frame but a list and you have no factor levels, just character vectors.

If you are not familiar with R, it may be helpful to tell us what your overall goal is rather than an intermediate step. Very likely R can easily handle what you want by doing things a different way. 

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352



-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Matthew
Sent: Tuesday, April 30, 2019 2:25 PM
To: r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: [R] transpose and split dataframe

I have a data frame that is a lot bigger but for simplicity sake we can 
say it looks like this:

Regulator??? hits
AT1G69490??? AT4G31950,AT5G24110,AT1G26380,AT1G05675
AT2G55980??? AT2G85403,AT4G89223

 ?? In other words:

data.frame : 2 obs. of 2 variables
$Regulator: Factor w/ 2 levels
$hits???????? : Factor w/ 6 levels

 ? I want to transpose it so that Regulator is now the column headings 
and each of the AGI numbers now separated by commas is a row. So, 
AT1G69490 is now the header of the first column and AT4G31950 is row 1 
of column 1, AT5G24110 is row 2 of column 1, etc. AT2G55980 is header of 
column 2 and AT2G85403 is row 1 of column 2, etc.

 ? I have tried playing around with strsplit(TF2list[2:2]) and 
strsplit(as.character(TF2list[2:2]), but I am getting nowhere.

Matthew

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Apr 30 23:03:09 2019
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 30 Apr 2019 15:03:09 -0600
Subject: [R] Passing formula as parameter to `lm` within `sapply` causes
 error [BUG?]
In-Reply-To: <75abba2b-c528-460e-df92-08f8479ba399@students.unibe.ch>
References: <75abba2b-c528-460e-df92-08f8479ba399@students.unibe.ch>
Message-ID: <924255D4-912E-4C24-8E85-6E313EC50203@comcast.net>

Try using do.call

? 
David

Sent from my iPhone

> On Apr 30, 2019, at 9:24 AM, Jens Heumann <jens.heumann at students.unibe.ch> wrote:
> 
> Hi,
> 
> `lm` won't take formula as a parameter when it is within a `sapply`; see example below. Please, could anyone either point me to a syntax error or confirm that this might be a bug?
> 
> Best,
> Jens
> 
> [Disclaimer: This is my first post here, following advice of how to proceed with possible bugs from here: https://www.r-project.org/bugs.html]
> 
> 
> SUMMARY
> 
> While `lm` alone accepts formula parameter `FO` well, the same within a `sapply` causes an error. When putting everything as parameter but formula `FO`, it's still working, though. All parameters work fine within a similar `for` loop.
> 
> 
> MCVE (see data / R-version at bottom)
> 
> > summary(lm(y ~ x, df1, df1[["z"]] == 1, df1[["w"]]))$coef[1, ]
>  Estimate Std. Error    t value   Pr(>|t|)
> 1.6269038  0.9042738  1.7991275  0.3229600
> > summary(lm(FO, data, data[[st]] == st1, data[[ws]]))$coef[1, ]
>  Estimate Std. Error    t value   Pr(>|t|)
> 1.6269038  0.9042738  1.7991275  0.3229600
> > sapply(unique(df1$z), function(s)
> +   summary(lm(y ~ x, df1, df1[["z"]] == s, df1[[ws]]))$coef[1, ])
>                [,1]       [,2]         [,3]
> Estimate   1.6269038 -0.1404174 -0.010338774
> Std. Error 0.9042738  0.4577001  1.858138516
> t value    1.7991275 -0.3067890 -0.005564049
> Pr(>|t|)   0.3229600  0.8104951  0.996457853
> > sapply(unique(data[[st]]), function(s)
> +   summary(lm(FO, data, data[[st]] == s, data[[ws]]))$coef[1, ])  # !!!
> Error in eval(substitute(subset), data, env) : object 's' not found
> > sapply(unique(data[[st]]), function(s)
> +   summary(lm(y ~ x, data, data[[st]] == s, data[[ws]]))$coef[1, ])
>                [,1]       [,2]         [,3]
> Estimate   1.6269038 -0.1404174 -0.010338774
> Std. Error 0.9042738  0.4577001  1.858138516
> t value    1.7991275 -0.3067890 -0.005564049
> Pr(>|t|)   0.3229600  0.8104951  0.996457853
> > m <- matrix(NA, 4, length(unique(data[[st]])))
> > for (s in unique(data[[st]])) {
> +   m[, s] <- summary(lm(FO, data, data[[st]] == s, data[[ws]]))$coef[1, ]
> + }
> > m
>          [,1]       [,2]         [,3]
> [1,] 1.6269038 -0.1404174 -0.010338774
> [2,] 0.9042738  0.4577001  1.858138516
> [3,] 1.7991275 -0.3067890 -0.005564049
> [4,] 0.3229600  0.8104951  0.996457853
> 
> # DATA #################################################################
> 
> df1 <- structure(list(x = c(1.37095844714667, -0.564698171396089, 0.363128411337339,
> 0.63286260496104, 0.404268323140999, -0.106124516091484, 1.51152199743894,
> -0.0946590384130976, 2.01842371387704), y = c(1.30824434809425,
> 0.740171482827397, 2.64977380403845, -0.755998096151299, 0.125479556323628,
> -0.239445852485142, 2.14747239550901, -0.37891195982917, -0.638031707027734
> ), z = c(1L, 1L, 1L, 2L, 2L, 2L, 3L, 3L, 3L), w = c(0.7, 0.8,
> 1.2, 0.9, 1.3, 1.2, 0.8, 1, 1)), class = "data.frame", row.names = c(NA,
> -9L))
> 
> FO <- y ~ x; data <- df1; st <- "z"; ws <- "w"; st1 <- 1
> 
> ########################################################################
> 
> > R.version
>               _
> platform       x86_64-w64-mingw32
> arch           x86_64
> os             mingw32
> system         x86_64, mingw32
> status
> major          3
> minor          6.0
> year           2019
> month          04
> day            26
> svn rev        76424
> language       R
> version.string R version 3.6.0 (2019-04-26)
> nickname       Planting of a Tree
> 
> #########################################################################
> 
> NOTE: Question on SO two days ago (https://stackoverflow.com/questions/55893189/passing-formula-as-parameter-to-lm-within-sapply-causes-error-bug-confirmation) brought many views but neither answer nor bug confirmation.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mccorm@ck @end|ng |rom mo|b|o@mgh@h@rv@rd@edu  Tue Apr 30 23:31:28 2019
From: mccorm@ck @end|ng |rom mo|b|o@mgh@h@rv@rd@edu (Matthew)
Date: Tue, 30 Apr 2019 17:31:28 -0400
Subject: [R] Fwd: Re:  transpose and split dataframe
In-Reply-To: <e154ccbb-71a6-c2ac-41ca-2171c8a9dc76@molbio.mgh.harvard.edu>
References: <e154ccbb-71a6-c2ac-41ca-2171c8a9dc76@molbio.mgh.harvard.edu>
Message-ID: <e4a9e321-b437-eed6-344b-472319e85fec@molbio.mgh.harvard.edu>

Thanks for your reply. I was trying to simplify it a little, but must 
have got it wrong. Here is the real dataframe, TF2list:

 ?str(TF2list)
'data.frame':??? 152 obs. of? 2 variables:
 ?$ Regulator: Factor w/ 87 levels "AT1G02065","AT1G13960",..: 17 6 6 54 
54 82 82 82 82 82 ...
 ?$ hits???? : Factor w/ 97 levels 
"AT1G05675,AT3G12910,AT1G22810,AT1G14540,AT1G21120,AT1G07160,AT5G22520,AT1G56250,AT2G31345,AT5G22530,AT4G11170,A"| 
__truncated__,..: 65 57 90 57 87 57 56 91 31 17 ...

 ?? And the first few lines resulting from dput(head(TF2list)):

dput(head(TF2list))
structure(list(Regulator = structure(c(17L, 6L, 6L, 54L, 54L,
82L), .Label = c("AT1G02065", "AT1G13960", "AT1G18860", "AT1G23380",
"AT1G29280", "AT1G29860", "AT1G30650", "AT1G55600", "AT1G62300",
"AT1G62990", "AT1G64000", "AT1G66550", "AT1G66560", "AT1G66600",
"AT1G68150", "AT1G69310", "AT1G69490", "AT1G69810", "AT1G70510", ...

This is another way of looking at the first 4 entries (Regulator is 
tab-separated from hits):

Regulator
 ? hits
1
AT1G69490
 ?AT4G31950,AT5G24110,AT1G26380,AT1G05675,AT3G12910,AT5G64905,AT1G22810,AT1G79680,AT3G02840,AT5G25260,AT5G57220,AT2G37430,AT2G26560,AT1G56250,AT3G23230,AT1G16420,AT1G78410,AT4G22030,AT5G05300,AT1G69930,AT4G03460,AT4G11470,AT5G25250,AT5G36925,AT2G30750,AT1G16150,AT1G02930,AT2G19190,AT4G11890,AT1G72520,AT4G31940,AT5G37490,AT5G52760,AT5G66020,AT3G57460,AT4G23220,AT3G15518,AT2G43620,AT2G02010,AT1G35210,AT5G46295,AT1G17147,AT1G11925,AT2G39200,AT1G02920,AT2G40180,AT1G59865,AT4G35180,AT4G15417,AT1G51820,AT1G06135,AT1G36622,AT5G42830
2
AT1G29860
 ?AT4G31950,AT5G24110,AT1G05675,AT3G12910,AT5G64905,AT1G22810,AT1G14540,AT1G79680,AT1G07160,AT3G23250,AT5G25260,AT1G53625,AT5G57220,AT2G37430,AT3G54150,AT1G56250,AT3G23230,AT1G16420,AT1G78410,AT4G22030,AT1G69930,AT4G03460,AT4G11470,AT5G25250,AT5G36925,AT4G14450,AT2G30750,AT1G16150,AT1G02930,AT2G19190,AT4G11890,AT1G72520,AT4G31940,AT5G37490,AT4G08555,AT5G66020,AT5G26920,AT3G57460,AT4G23220,AT3G15518,AT2G43620,AT1G35210,AT5G46295,AT1G17147,AT1G11925,AT2G39200,AT1G02920,AT4G35180,AT4G15417,AT1G51820,AT4G40020,AT1G06135

3
AT1G2986
 ?AT5G64905,AT1G21120,AT1G07160,AT5G25260,AT1G53625,AT1G56250,AT2G31345,AT4G11170,AT1G66090,AT1G26410,AT3G55840,AT1G69930,AT4G03460,AT5G25250,AT5G36925,AT1G26420,AT5G42380,AT1G16150,AT2G22880,AT1G02930,AT4G11890,AT1G72520,AT5G66020,AT2G43620,AT2G44370,AT4G15975,AT1G35210,AT5G46295,AT1G11925,AT2G39200,AT1G02920,AT4G14370,AT4G35180,AT4G15417,AT2G18690,AT5G11140,AT1G06135,AT5G42830

 ?? So, the goal would be to

first: Transpose the existing dataframe so that the factor Regulator 
becomes a column name (column 1 name = AT1G69490, column2 name 
AT1G29860, etc.) and the hits associated with each Regulator become 
rows. Hits is a comma separated 'list' ( I do not not know if 
technically it is an R list.), so it would have to be comma 
'unseparated' with each entry becoming a row (col 1 row 1 = AT4G31950, 
col 1 row 2 - AT5G24410, etc); like this :

AT1G69490
AT4G31950
AT5G24110
AT1G05675
AT5G64905

... I did not include all the rows)

I think it would be best to actually make the first entry a separate 
dataframe ( 1 column with name = AT1G69490 and number of rows depending 
on the number of hits), then make the second column (column name = 
AT1G29860, and number of rows depending on the number of hits) into a 
new dataframe and do a full join of of the two dataframes; continue by 
making the third column (column name = AT1G2986) into a dataframe and 
full join it with the previous; continue for the 152 observations so 
that then end result is a dataframe with 152 columns and number of rows 
depending on the entry with the greatest number of hits. The full joins 
I can do with dplyr, but getting up to that point seems rather difficult.

This would get me what my ultimate goal would be; each Regulator is a 
column name (152 columns) and a given row has either NA or the same hit.

 ?? This seems very difficult to me, but I appreciate any attempt.

Matthew

On 4/30/2019 4:34 PM, David L Carlson wrote:
>          External Email - Use Caution
>
> I think we need more information. Can you give us the structure of the data with str(YourDataFrame). Alternatively you could copy a small piece into your email message by copying and pasting the results of the following code:
>
> dput(head(YourDataFrame))
>
> The data frame you present could not be a data frame since you say "hits" is a factor with a variable number of elements. If each value of "hits" was a single character string, it would only have 2 factor levels not 6 and your efforts to parse the string would make more sense. Transposing to a data frame would only be possible if each column was padded with NAs to make them equal in length. Since your example tries use the name TF2list, it is possible that you do not have a data frame but a list and you have no factor levels, just character vectors.
>
> If you are not familiar with R, it may be helpful to tell us what your overall goal is rather than an intermediate step. Very likely R can easily handle what you want by doing things a different way.
>
> ----------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77843-4352
>
>
>
> -----Original Message-----
> From: R-help<r-help-bounces at r-project.org>  On Behalf Of Matthew
> Sent: Tuesday, April 30, 2019 2:25 PM
> To: r-help (r-help at r-project.org)<r-help at r-project.org>
> Subject: [R] transpose and split dataframe
>
> I have a data frame that is a lot bigger but for simplicity sake we can
> say it looks like this:
>
> Regulator??? hits
> AT1G69490??? AT4G31950,AT5G24110,AT1G26380,AT1G05675
> AT2G55980??? AT2G85403,AT4G89223
>
>   ?? In other words:
>
> data.frame : 2 obs. of 2 variables
> $Regulator: Factor w/ 2 levels
> $hits???????? : Factor w/ 6 levels
>
>   ? I want to transpose it so that Regulator is now the column headings
> and each of the AGI numbers now separated by commas is a row. So,
> AT1G69490 is now the header of the first column and AT4G31950 is row 1
> of column 1, AT5G24110 is row 2 of column 1, etc. AT2G55980 is header of
> column 2 and AT2G85403 is row 1 of column 2, etc.
>
>   ? I have tried playing around with strsplit(TF2list[2:2]) and
> strsplit(as.character(TF2list[2:2]), but I am getting nowhere.
>
> Matthew
>
> ______________________________________________
> R-help at r-project.org  mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guidehttp://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From drj|m|emon @end|ng |rom gm@||@com  Tue Apr 30 23:46:32 2019
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Wed, 1 May 2019 07:46:32 +1000
Subject: [R] transpose and split dataframe
In-Reply-To: <0d6ac524-4291-ab03-6bcb-592b3996cc74@molbio.mgh.harvard.edu>
References: <0d6ac524-4291-ab03-6bcb-592b3996cc74@molbio.mgh.harvard.edu>
Message-ID: <CA+8X3fUjv3APb=UcsNQAD61pmOSbvoYBFsW3caZW7p11eD7umg@mail.gmail.com>

Hi Matthew,
Is this what you are trying to do?

mmdf<-read.table(text="Regulator    hits
AT1G69490    AT4G31950,AT5G24110,AT1G26380,AT1G05675
AT2G55980    AT2G85403,AT4G89223",header=TRUE,
stringsAsFactors=FALSE)
# split the second column at the commas
hitsplit<-strsplit(mmdf$hits,",")
# define a function that will fill with NAs
NAfill<-function(x,n) return(x[1:n])
# get the maximum length of hits
maxlen<-max(unlist(lapply(hitsplit,length)))
# fill the list with NAs
hitsplit<-lapply(hitsplit,NAfill,maxlen)
# change the names of the list
names(hitsplit)<-mmdf$Regulator
# convert to a data frame
tmmdf<-as.data.frame(hitsplit)

Jim

On Wed, May 1, 2019 at 5:25 AM Matthew <mccormack at molbio.mgh.harvard.edu> wrote:
>
> I have a data frame that is a lot bigger but for simplicity sake we can
> say it looks like this:
>
> Regulator    hits
> AT1G69490    AT4G31950,AT5G24110,AT1G26380,AT1G05675
> AT2G55980    AT2G85403,AT4G89223
>
>     In other words:
>
> data.frame : 2 obs. of 2 variables
> $Regulator: Factor w/ 2 levels
> $hits         : Factor w/ 6 levels
>
>    I want to transpose it so that Regulator is now the column headings
> and each of the AGI numbers now separated by commas is a row. So,
> AT1G69490 is now the header of the first column and AT4G31950 is row 1
> of column 1, AT5G24110 is row 2 of column 1, etc. AT2G55980 is header of
> column 2 and AT2G85403 is row 1 of column 2, etc.
>
>    I have tried playing around with strsplit(TF2list[2:2]) and
> strsplit(as.character(TF2list[2:2]), but I am getting nowhere.
>
> Matthew
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @purd|e@@ @end|ng |rom gm@||@com  Tue Apr 30 23:58:34 2019
From: @purd|e@@ @end|ng |rom gm@||@com (Abs Spurdle)
Date: Wed, 1 May 2019 09:58:34 +1200
Subject: [R] 
 Time series (trend over time) for irregular sampling dates and
 multiple sites
In-Reply-To: <CAOQWJbvY+JKy80sksmfC8tu-C+5qq-tzwAd21XbyGvJAyYjQPQ@mail.gmail.com>
References: <CAOQWJbvY+JKy80sksmfC8tu-C+5qq-tzwAd21XbyGvJAyYjQPQ@mail.gmail.com>
Message-ID: <CAB8pepxHYbCXQPX5CaUQ868kMAp80z+zSXH7LHak+xDabJOjKg@mail.gmail.com>

> My data has a few problems: (1) I think I will need to fix the effects of
> seasonal variation (Monthly) and (2) of possible spatial correlation
> (probability of finding an item is higher after finding one since they can
> come from the same ship). (3) How do I handle the fact that the
> measurements were not taken at a regular interval?

Can I ask two questions:
(1) Is the data autocorrelated (or "Seasonal") over time?
If not then this problem is a lot simpler.
(2) Can you expand on the following statement?
"possible spatial correlation (probability of finding an item is higher
after finding one since they can come from the same ship"

	[[alternative HTML version deleted]]


